[
  {
    "id": "arXiv:2202.01780",
    "title": "Even Simpler Deterministic Matrix Sketching",
    "abstract": "This paper provides a one-line proof of Frequent Directions (FD) for\nsketching streams of matrices. The simpler proof arises from sketching the\ncovariance of the stream of matrices rather than the stream itself.",
    "descriptor": "",
    "authors": [
      "Edo Liberty"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.01780"
  },
  {
    "id": "arXiv:2202.01781",
    "title": "Predicting the impact of urban change in pedestrian and road safety",
    "abstract": "Increased interaction between and among pedestrians and vehicles in the\ncrowded urban environments of today gives rise to a negative side-effect: a\ngrowth in traffic accidents, with pedestrians being the most vulnerable\nelements. Recent work has shown that Convolutional Neural Networks are able to\naccurately predict accident rates exploiting Street View imagery along urban\nroads. The promising results point to the plausibility of aided design of safe\nurban landscapes, for both pedestrians and vehicles. In this paper, by\nconsidering historical accident data and Street View images, we detail how to\nautomatically predict the impact (increase or decrease) of urban interventions\non accident incidence. The results are positive, rendering an accuracies\nranging from 60 to 80%. We additionally provide an interpretability analysis to\nunveil which specific categories of urban features impact accident rates\npositively or negatively. Considering the transportation network substrates\n(sidewalk and road networks) and their demand, we integrate these results to a\ncomplex network framework, to estimate the effective impact of urban change on\nthe safety of pedestrians and vehicles. Results show that public authorities\nmay leverage on machine learning tools to prioritize targeted interventions,\nsince our analysis show that limited improvement is obtained with current\ntools. Further, our findings have a wider application range such as the design\nof safe urban routes for pedestrians or to the field of driver-assistance\ntechnologies.",
    "descriptor": "",
    "authors": [
      "Cristina Bustos",
      "Daniel Rhoads",
      "Agata Lapedriza",
      "Javier Borge-Holthoefer",
      "Albert Sol\u00e9-Ribalta"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.01781"
  },
  {
    "id": "arXiv:2202.01784",
    "title": "Robust Audio Anomaly Detection",
    "abstract": "We propose an outlier robust multivariate time series model which can be used\nfor detecting previously unseen anomalous sounds based on noisy training data.\nThe presented approach doesn't assume the presence of labeled anomalies in the\ntraining dataset and uses a novel deep neural network architecture to learn the\ntemporal dynamics of the multivariate time series at multiple resolutions while\nbeing robust to contaminations in the training dataset. The temporal dynamics\nare modeled using recurrent layers augmented with attention mechanism. These\nrecurrent layers are built on top of convolutional layers allowing the network\nto extract features at multiple resolutions. The output of the network is an\noutlier robust probability density function modeling the conditional\nprobability of future samples given the time series history. State-of-the-art\napproaches using other multiresolution architectures are contrasted with our\nproposed approach. We validate our solution using publicly available machine\nsound datasets. We demonstrate the effectiveness of our approach in anomaly\ndetection by comparing against several state-of-the-art models.",
    "descriptor": "\nComments: Accepted paper at RobustML Workshop@ICLR 2021\n",
    "authors": [
      "Wo Jae Lee",
      "Karim Helwani",
      "Arvindh Krishnaswamy",
      "Srikanth Tenneti"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2202.01784"
  },
  {
    "id": "arXiv:2202.01797",
    "title": "Understanding Digital Government Transformation",
    "abstract": "In today's era of innovation of technological progression, digitalisation has\nnot only transformed individual lives but also has a prominent influence on\nbusiness activities. The world is surviving in a global yet complex\ntechnological progression that not only changes the lives of civilians but is\nalso transforming the public, private, and academic spheres of life. This\nresearch focuses on the digitalisation of governments, their challenges, and\nsuccess factors. It is found that government faces difficulties in formulating\nstrategies, proper planning, execution strategies, and a lack of organised\ninformation and expertise. However, success can be achieved by working on\ncapabilities of the future workforce, creating leaders for tomorrow, generating\ndigitalisation capabilities, and bringing a purpose-driven digitalisation\nbefore digital government transformation. Overall, the study's findings suggest\nthat digital government transformation creates value, enhances relations,\nimproves service delivery, grows economy, pushes economic activities, enhances\ncitizen engagement, increases the policy implementation and their efficiency,\nand affects business growth positively.",
    "descriptor": "",
    "authors": [
      "Mamdouh Alenezi"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2202.01797"
  },
  {
    "id": "arXiv:2202.01802",
    "title": "Cross-Platform Difference in Facebook and Text Messages Language Use:  Illustrated by Depression Diagnosis",
    "abstract": "How does language differ across one's Facebook status updates vs. one's text\nmessages (SMS)? In this study, we show how Facebook and SMS use differs in\npsycho-linguistic characteristics and how these differences drive downstream\nanalyses with an illustration of depression diagnosis. We use a sample of\nconsenting participants who shared Facebook status updates, SMS data, and\nanswered a standard psychological depression screener. We quantify domain\ndifferences using psychologically driven lexical methods and find that language\non Facebook involves more personal concerns, experiences, and content features\nwhile the language in SMS contains more informal and style features. Next, we\nestimate depression from both text domains, using a depression model trained on\nFacebook data, and find a drop in accuracy when predicting self-reported\ndepression assessments from the SMS-based depression estimates. Finally, we\nevaluate a simple domain adaption correction based on words driving the\ncross-platform differences and applied it to the SMS-derived depression\nestimates, resulting in significant improvement in prediction. Our work shows\nthe Facebook vs. SMS difference in language use and suggests the necessity of\ncross-domain adaption for text-based predictions.",
    "descriptor": "\nComments: 5 pages, 1 figure\n",
    "authors": [
      "Tingting Liu",
      "Salvatore Giorgi",
      "Xiangyu Tao",
      "Douglas Bellew",
      "Brenda Curtis",
      "Lyle Ungar"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.01802"
  },
  {
    "id": "arXiv:2202.01806",
    "title": "Answering Count Queries for Genomic Data with Perfect Privacy",
    "abstract": "In this paper, we consider the problem of answering count queries for genomic\ndata subject to perfect privacy constraints. Count queries are often used in\napplications that collect aggregate (population-wide) information from\nbiomedical Databases (DBs) for analysis, such as Genome-wide association\nstudies. Our goal is to design mechanisms for answering count queries of the\nfollowing form: How many users in the database have a specific set of genotypes\nat certain locations in their genome? At the same time, we aim to achieve\nperfect privacy (zero information leakage) of the sensitive genotypes at a\npre-specified set of secret locations. The sensitive genotypes could indicate\nrare diseases and/or other health traits that one may want to keep private. We\npresent two local count-query mechanisms for the above problem that achieve\nperfect privacy for sensitive genotypes while minimizing the expected absolute\nerror (or per-user error probability) of the query answer. We also derived a\nlower bound of the per-user probability of error for an arbitrary query\nanswering mechanism that satisfies perfect privacy. We show that our mechanisms\nachieve error that is close to the lower bound, and are match the lower bound\nfor some special cases. We numerically show that the performance of each\nmechanism depends on the data prior distribution, the intersection between the\nqueried and sensitive data, and the strength of the correlation in the genomic\ndata sequence.",
    "descriptor": "",
    "authors": [
      "Bo Jiang",
      "Mohamed Seif",
      "Ravi Tandon",
      "Ming Li"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.01806"
  },
  {
    "id": "arXiv:2202.01808",
    "title": "Hacking the Colony: On the Disruptive Effect of Misleading Pheromone and  How to Defend Against It",
    "abstract": "Ants have evolved to seek and retrieve food by leaving trails of pheromones.\nThis mechanism has inspired several approaches to decentralized multi-robot\ncoordination. However, in this paper, we show that pheromone trails are a\nfragile mechanism for coordination, and can be sabotaged to starve the colony.\nWe introduce detractors: malicious agents that leave a misleading, but\nindistinguishable, trail of food pheromone to distract and trap cooperator ants\nin the nest. We analyze the effectiveness of detractors with respect to\nparameters such as evaporation rate of misleading pheromone and fraction of\ndetractors in the colony. In addition, we propose a countermeasure to this\nattack by introducing a new type of pheromone: the cautionary pheromone.\nCooperator ants secrete this type of pheromone atop existing food trails as a\nwarning. When the cautionary pheromone intensity exceeds the food pheromone\nintensity, cooperator ants ignore overlapping food pheromone. We show that,\ndespite its simplicity, this defense mechanism can limit, but not nullify, the\neffect of detractors. Ultimately, our work shows that pheromone-based\ncoordination, while effective, is also fragile.",
    "descriptor": "\nComments: 8 pages, accepted at AAMAS2022\n",
    "authors": [
      "Ashay Aswale",
      "Antonio L\u00f3pez",
      "Aukkawut Ammartayakun",
      "Carlo Pinciroli"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2202.01808"
  },
  {
    "id": "arXiv:2202.01810",
    "title": "Deep Surface Reconstruction from Point Clouds with Visibility  Information",
    "abstract": "Most current neural networks for reconstructing surfaces from point clouds\nignore sensor poses and only operate on raw point locations. Sensor visibility,\nhowever, holds meaningful information regarding space occupancy and surface\norientation. In this paper, we present two simple ways to augment raw point\nclouds with visibility information, so it can directly be leveraged by surface\nreconstruction networks with minimal adaptation. Our proposed modifications\nconsistently improve the accuracy of generated surfaces as well as the\ngeneralization ability of the networks to unseen shape domains. Our code and\ndata is available at https://github.com/raphaelsulzer/dsrv-data.",
    "descriptor": "\nComments: 13 pages\n",
    "authors": [
      "Raphael Sulzer",
      "Loic Landrieu",
      "Alexandre Boulch",
      "Renaud Marlet",
      "Bruno Vallet"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.01810"
  },
  {
    "id": "arXiv:2202.01811",
    "title": "ObjectSeeker: Certifiably Robust Object Detection against Patch Hiding  Attacks via Patch-agnostic Masking",
    "abstract": "Object detectors, which are widely deployed in security-critical systems such\nas autonomous vehicles, have been found vulnerable to physical-world patch\nhiding attacks. The attacker can use a single physically-realizable adversarial\npatch to make the object detector miss the detection of victim objects and\ncompletely undermines the functionality of object detection applications. In\nthis paper, we propose ObjectSeeker as a defense framework for building\ncertifiably robust object detectors against patch hiding attacks. The core\noperation of ObjectSeeker is patch-agnostic masking: we aim to mask out the\nentire adversarial patch without any prior knowledge of the shape, size, and\nlocation of the patch. This masking operation neutralizes the adversarial\neffect and allows any vanilla object detector to safely detect objects on the\nmasked images. Remarkably, we develop a certification procedure to determine if\nObjectSeeker can detect certain objects with a provable guarantee against any\nadaptive attacker within the threat model. Our evaluation with two object\ndetectors and three datasets demonstrates a significant (~10%-40% absolute and\n~2-6x relative) improvement in certified robustness over the prior work, as\nwell as high clean performance (~1% performance drop compared with vanilla\nundefended models).",
    "descriptor": "",
    "authors": [
      "Chong Xiang",
      "Alexander Valtchanov",
      "Saeed Mahloujifar",
      "Prateek Mittal"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.01811"
  },
  {
    "id": "arXiv:2202.01821",
    "title": "Danish Airs and Grounds: A Dataset for Aerial-to-Street-Level Place  Recognition and Localization",
    "abstract": "Place recognition and visual localization are particularly challenging in\nwide baseline configurations. In this paper, we contribute with the\n\\emph{Danish Airs and Grounds} (DAG) dataset, a large collection of\nstreet-level and aerial images targeting such cases. Its main challenge lies in\nthe extreme viewing-angle difference between query and reference images with\nconsequent changes in illumination and perspective. The dataset is larger and\nmore diverse than current publicly available data, including more than 50 km of\nroad in urban, suburban and rural areas. All images are associated with\naccurate 6-DoF metadata that allows the benchmarking of visual localization\nmethods.\nWe also propose a map-to-image re-localization pipeline, that first estimates\na dense 3D reconstruction from the aerial images and then matches query\nstreet-level images to street-level renderings of the 3D model. The dataset can\nbe downloaded at: https://frederikwarburg.github.io/DAG",
    "descriptor": "\nComments: Submitted to RA-L (IROS)\n",
    "authors": [
      "Andrea Vallone",
      "Frederik Warburg",
      "Hans Hansen",
      "S\u00f8ren Hauberg",
      "Javier Civera"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.01821"
  },
  {
    "id": "arXiv:2202.01824",
    "title": "Waveform inversion via reduced order modeling",
    "abstract": "We introduce a novel approach to waveform inversion, based on a data driven\nreduced order model (ROM) of the wave operator. The presentation is for the\nacoustic wave equation, but the approach can be extended to elastic or\nelectromagnetic waves. The data are time resolved measurements of the pressure\nwave at the sensors in an active array, which probe the unknown medium with\npulses and measure the generated waves. The ROM depends nonlinearly on the data\nbut it can be constructed from them using numerical linear algebra methods. We\nshow that the ROM can be used for the inverse problem of velocity estimation.\nWhile the full-waveform inversion approach of {nonlinear least-squares} data\nfitting is challenging without low frequency information, due to multiple\nminima of the objective function, the minimization of the ROM misfit function\nhas a better behavior, even for a poor initial guess. In fact, the ROM misfit\nfunction is demonstrably a convex function for low-dimensional parametrizations\nof the unknown velocity. We give the construction of the ROM, introduce the\ninversion approach based on the ROM misfit and assess its performance with\nnumerical simulations.",
    "descriptor": "",
    "authors": [
      "Liliana Borcea",
      "Josselin Garnier",
      "Alexander V. Mamonov",
      "J\u00f6rn Zimmerling"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Geophysics (physics.geo-ph)"
    ],
    "url": "https://arxiv.org/abs/2202.01824"
  },
  {
    "id": "arXiv:2202.01829",
    "title": "HRBF-Fusion: Accurate 3D reconstruction from RGB-D data using on-the-fly  implicits",
    "abstract": "Reconstruction of high-fidelity 3D objects or scenes is a fundamental\nresearch problem. Recent advances in RGB-D fusion have demonstrated the\npotential of producing 3D models from consumer-level RGB-D cameras. However,\ndue to the discrete nature and limited resolution of their surface\nrepresentations (e.g., point- or voxel-based), existing approaches suffer from\nthe accumulation of errors in camera tracking and distortion in the\nreconstruction, which leads to an unsatisfactory 3D reconstruction. In this\npaper, we present a method using on-the-fly implicits of Hermite Radial Basis\nFunctions (HRBFs) as a continuous surface representation for camera tracking in\nan existing RGB-D fusion framework. Furthermore, curvature estimation and\nconfidence evaluation are coherently derived from the inherent surface\nproperties of the on-the-fly HRBF implicits, which devote to a data fusion with\nbetter quality. We argue that our continuous but on-the-fly surface\nrepresentation can effectively mitigate the impact of noise with its robustness\nand constrain the reconstruction with inherent surface smoothness when being\ncompared with discrete representations. Experimental results on various\nreal-world and synthetic datasets demonstrate that our HRBF-fusion outperforms\nthe state-of-the-art approaches in terms of tracking robustness and\nreconstruction accuracy.",
    "descriptor": "",
    "authors": [
      "Yabin Xu",
      "Liangliang Nan",
      "Laishui Zhou",
      "Jun Wang",
      "Charlie C.L. Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.01829"
  },
  {
    "id": "arXiv:2202.01830",
    "title": "Modularization, Composition, and Hierarchization of Petri Nets with  Heraklit",
    "abstract": "It is known for decades that computer-based systems cannot be understood\nwithout a concept of modularization and decomposition. We suggest a universal,\nexpressive, intuitively attractive composition operator for Petri nets,\ncombined with a refinement concept and an algebraic representation of nets and\ntheir composition. Case studies show exemplarily, how large systems can be\ncomposed from tiny net snippets. In the future, more field studies are needed\nto better understand the consequences of the proposed ideas in the real world.",
    "descriptor": "\nComments: 19 pages, 19 figures, submitted to PETRI NETS 2022\n",
    "authors": [
      "Peter Fettke",
      "Wolfgang Reisig"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2202.01830"
  },
  {
    "id": "arXiv:2202.01832",
    "title": "Adversarially Robust Models may not Transfer Better: Sufficient  Conditions for Domain Transferability from the View of Regularization",
    "abstract": "Machine learning (ML) robustness and domain generalization are fundamentally\ncorrelated: they essentially concern data distribution shifts under adversarial\nand natural settings, respectively. On one hand, recent studies show that more\nrobust (adversarially trained) models are more generalizable. On the other\nhand, there is a lack of theoretical understanding of their fundamental\nconnections. In this paper, we explore the relationship between regularization\nand domain transferability considering different factors such as norm\nregularization and data augmentations (DA). We propose a general theoretical\nframework proving that factors involving the model function class\nregularization are sufficient conditions for relative domain transferability.\nOur analysis implies that \"robustness\" is neither necessary nor sufficient for\ntransferability; rather, robustness induced by adversarial training is a\nby-product of such function class regularization. We then discuss popular DA\nprotocols and show when they can be viewed as the function class regularization\nunder certain conditions and therefore improve generalization. We conduct\nextensive experiments to verify our theoretical findings and show several\ncounterexamples where robustness and generalization are negatively correlated\non different datasets.",
    "descriptor": "",
    "authors": [
      "Xiaojun Xu",
      "Jacky Yibo Zhang",
      "Evelyn Ma",
      "Danny Son",
      "Oluwasanmi Koyejo",
      "Bo Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.01832"
  },
  {
    "id": "arXiv:2202.01838",
    "title": "Characterizing & Finding Good Data Orderings for Fast Convergence of  Sequential Gradient Methods",
    "abstract": "While SGD, which samples from the data with replacement is widely studied in\ntheory, a variant called Random Reshuffling (RR) is more common in practice. RR\niterates through random permutations of the dataset and has been shown to\nconverge faster than SGD. When the order is chosen deterministically, a variant\ncalled incremental gradient descent (IG), the existing convergence bounds show\nimprovement over SGD but are worse than RR. However, these bounds do not\ndifferentiate between a good and a bad ordering and hold for the worst choice\nof order. Meanwhile, in some cases, choosing the right order when using IG can\nlead to convergence faster than RR. In this work, we quantify the effect of\norder on convergence speed, obtaining convergence bounds based on the chosen\nsequence of permutations while also recovering previous results for RR. In\naddition, we show benefits of using structured shuffling when various levels of\nabstractions (e.g. tasks, classes, augmentations, etc.) exists in the dataset\nin theory and in practice. Finally, relying on our measure, we develop a greedy\nalgorithm for choosing good orders during training, achieving superior\nperformance (by more than 14 percent in accuracy) over RR.",
    "descriptor": "",
    "authors": [
      "Amirkeivan Mohtashami Sebastian Stich Martin Jaggi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.01838"
  },
  {
    "id": "arXiv:2202.01840",
    "title": "Hidden Heterogeneity: When to Choose Similarity-Based Calibration",
    "abstract": "Trustworthy classifiers are essential to the adoption of machine learning\npredictions in many real-world settings. The predicted probability of possible\noutcomes can inform high-stakes decision making, particularly when assessing\nthe expected value of alternative decisions or the risk of bad outcomes. These\ndecisions require well calibrated probabilities, not just the correct\nprediction of the most likely class. Black-box classifier calibration methods\ncan improve the reliability of a classifier's output without requiring\nretraining. However, these methods are unable to detect subpopulations where\ncalibration could improve prediction accuracy. Such subpopulations are said to\nexhibit \"hidden heterogeneity\" (HH), because the original classifier did not\ndetect them. The paper proposes a quantitative measure for HH. It also\nintroduces two similarity-weighted calibration methods that can address HH by\nadapting locally to each test item: SWC weights the calibration set by\nsimilarity to the test item, and SWC-HH explicitly incorporates hidden\nheterogeneity to filter the calibration set. Experiments show that the\nimprovements in calibration achieved by similarity-based calibration methods\ncorrelate with the amount of HH present and, given sufficient calibration data,\ngenerally exceed calibration achieved by global methods. HH can therefore serve\nas a useful diagnostic tool for identifying when local calibration methods are\nneeded.",
    "descriptor": "\nComments: Draft version currently under review. Do not cite. Comments and feedback welcome! 33 pages, 10 figures\n",
    "authors": [
      "Kiri L. Wagstaff",
      "Thomas G. Dietterich"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.01840"
  },
  {
    "id": "arXiv:2202.01842",
    "title": "Distributed State Estimation with Deep Neural Networks for Uncertain  Nonlinear Systems under Event-Triggered Communication",
    "abstract": "Distributed state estimation is examined for a sensor network tasked with\nreconstructing a system's state through the use of a distributed and\nevent-triggered observer. Each agent in the sensor network employs a deep\nneural network (DNN) to approximate the uncertain nonlinear dynamics of the\nsystem, which is trained using a multiple timescale approach. Specifically, the\nouter weights of each DNN are updated online using a Lyapunov-based gradient\ndescent update law, while the inner weights and biases are trained offline\nusing a supervised learning method and collected input-output data. The\nobserver utilizes event-triggered communication to promote the efficient use of\nnetwork resources. A nonsmooth Lyapunov analysis shows the distributed\nevent-triggered observer has a uniformly ultimately bounded state\nreconstruction error. A simulation study is provided to validate the result and\ndemonstrate the performance improvements afforded by the DNNs.",
    "descriptor": "",
    "authors": [
      "Federico M. Zegers",
      "Runhan Sun",
      "Girish Chowdhary",
      "Warren E. Dixon"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.01842"
  },
  {
    "id": "arXiv:2202.01843",
    "title": "The Swapped Dragonfly",
    "abstract": "This paper describes the Swapped Dragonfly. It is a two-parameter family of\ndiameter three interconnection networks, D3(K,M), which are linearly scalable\nin M. Although D3(K,M) is a Dragonfly, it differs from standard Dragonflies in\nmany respects. It has a K by M by M coordinate system (c;d; p). The routers\n(c,d,p) and (c',p,d) are globally connected using a swap of p and d. If L < K\nand/or N < M, D3(K;M) contains D3(L,N). The coordinate system enables source\nvector routing on D3(K,M). A source-vector induces KM squared parallel paths on\nD3(K,M). Because of this, the Swapped Dragonfly can support conflict-free\nparallelism over local ports, global ports, routers and source-vectors. In\nparticular, there is an all-to-all algorithm which is not a pairwise exchange\nalgorithm.\nKeywords: interconnection network, Dragonfly network, swapped network,\nsource-vector routing, all-to-all exchange",
    "descriptor": "\nComments: 20 pages 3 figures\n",
    "authors": [
      "Richard Draper"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2202.01843"
  },
  {
    "id": "arXiv:2202.01846",
    "title": "A Population's Feasible Posterior Beliefs",
    "abstract": "We consider a population of Bayesian agents who share a common prior over\nsome finite state space and each agent is exposed to some information about the\nstate. We ask which distributions over empirical distributions of posteriors\nbeliefs in the population are feasible. We provide a necessary and sufficient\ncondition for feasibility. We apply this result in several domains. First, we\nstudy the problem of maximizing the polarization of beliefs in a population.\nSecond, we provide a characterization of the feasible agent-symmetric product\ndistributions of posteriors. Finally, we study an instance of a private\nBayesian persuasion problem and provide a clean formula for the sender's\noptimal value.",
    "descriptor": "",
    "authors": [
      "Itai Arieli",
      "Yakov Babichenko"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2202.01846"
  },
  {
    "id": "arXiv:2202.01851",
    "title": "A Note on \"Assessing Generalization of SGD via Disagreement\"",
    "abstract": "Jiang et al. (2021) give empirical evidence that the average test error of\ndeep neural networks can be estimated via the prediction disagreement of two\nseparately trained networks. They also provide a theoretical explanation that\nthis 'Generalization Disagreement Equality' follows from the well-calibrated\nnature of deep ensembles under the notion of a proposed 'class-aggregated\ncalibration'. In this paper we show that the approach suggested might be\nimpractical because a deep ensemble's calibration deteriorates under\ndistribution shift, which is exactly when the coupling of test error and\ndisagreement would be of practical value. We present both theoretical and\nexperimental evidence, re-deriving the theoretical statements using a simple\nBayesian perspective and show them to be straightforward and more generic: they\napply to any discriminative model -- not only ensembles whose members output\none-hot class predictions. The proposed calibration metrics are also equivalent\nto two metrics introduced by Nixon et al. (2019): 'ACE' and 'SCE'.",
    "descriptor": "",
    "authors": [
      "Andreas Kirsch",
      "Yarin Gal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.01851"
  },
  {
    "id": "arXiv:2202.01855",
    "title": "Self-supervised Learning with Random-projection Quantizer for Speech  Recognition",
    "abstract": "We present a simple and effective self-supervised learning approach for\nspeech recognition. The approach learns a model to predict the masked speech\nsignals, in the form of discrete labels generated with a random-projection\nquantizer. In particular the quantizer projects speech inputs with a randomly\ninitialized matrix, and does a nearest-neighbor lookup in a\nrandomly-initialized codebook. Neither the matrix nor the codebook is updated\nduring self-supervised learning. Since the random-projection quantizer is not\ntrained and is separated from the speech recognition model, the design makes\nthe approach flexible and is compatible with universal speech recognition\narchitecture. On LibriSpeech our approach achieves similar word-error-rates as\nprevious work using self-supervised learning with non-streaming models, and\nprovides lower word-error-rates and latency than wav2vec 2.0 and w2v-BERT with\nstreaming models. On multilingual tasks the approach also provides significant\nimprovement over wav2vec 2.0 and w2v-BERT.",
    "descriptor": "",
    "authors": [
      "Chung-Cheng Chiu",
      "James Qin",
      "Yu Zhang",
      "Jiahui Yu",
      "Yonghui Wu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2202.01855"
  },
  {
    "id": "arXiv:2202.01862",
    "title": "Practical Imitation Learning in the Real World via Task Consistency Loss",
    "abstract": "Recent work in visual end-to-end learning for robotics has shown the promise\nof imitation learning across a variety of tasks. Such approaches are expensive\nboth because they require large amounts of real world training demonstrations\nand because identifying the best model to deploy in the real world requires\ntime-consuming real-world evaluations. These challenges can be mitigated by\nsimulation: by supplementing real world data with simulated demonstrations and\nusing simulated evaluations to identify high performing policies. However, this\nintroduces the well-known \"reality gap\" problem, where simulator inaccuracies\ndecorrelate performance in simulation from that of reality. In this paper, we\nbuild on top of prior work in GAN-based domain adaptation and introduce the\nnotion of a Task Consistency Loss (TCL), a self-supervised loss that encourages\nsim and real alignment both at the feature and action-prediction levels. We\ndemonstrate the effectiveness of our approach by teaching a mobile manipulator\nto autonomously approach a door, turn the handle to open the door, and enter\nthe room. The policy performs control from RGB and depth images and generalizes\nto doors not encountered in training data. We achieve 80% success across ten\nseen and unseen scenes using only ~16.2 hours of teleoperated demonstrations in\nsim and real. To the best of our knowledge, this is the first work to tackle\nlatched door opening from a purely end-to-end learning approach, where the task\nof navigation and manipulation are jointly modeled by a single neural network.",
    "descriptor": "",
    "authors": [
      "Mohi Khansari",
      "Daniel Ho",
      "Yuqing Du",
      "Armando Fuentes",
      "Matthew Bennice",
      "Nicolas Sievers",
      "Sean Kirmani",
      "Yunfei Bai",
      "Eric Jang"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.01862"
  },
  {
    "id": "arXiv:2202.01869",
    "title": "Flexible Triggering Kernels for Hawkes Process Modeling",
    "abstract": "Recently proposed encoder-decoder structures for modeling Hawkes processes\nuse transformer-inspired architectures, which encode the history of events via\nembeddings and self-attention mechanisms. These models deliver better\nprediction and goodness-of-fit than their RNN-based counterparts. However, they\noften require high computational and memory complexity requirements and\nsometimes fail to adequately capture the triggering function of the underlying\nprocess. So motivated, we introduce an efficient and general encoding of the\nhistorical event sequence by replacing the complex (multilayered) attention\nstructures with triggering kernels of the observed data. Noting the similarity\nbetween the triggering kernels of a point process and the attention scores, we\nuse a triggering kernel to replace the weights used to build history\nrepresentations. Our estimate for the triggering function is equipped with a\nsigmoid gating mechanism that captures local-in-time triggering effects that\nare otherwise challenging with standard decaying-over-time kernels. Further,\ntaking both event type representations and temporal embeddings as inputs, the\nmodel learns the underlying triggering type-time kernel parameters given pairs\nof event types. We present experiments on synthetic and real data sets widely\nused by competing models, while further including a COVID-19 dataset to\nillustrate a scenario where longitudinal covariates are available. Results show\nthe proposed model outperforms existing approaches while being more efficient\nin terms of computational complexity and yielding interpretable results via\ndirect application of the newly introduced kernel.",
    "descriptor": "",
    "authors": [
      "Yamac Alican Isik",
      "Connor Davis",
      "Paidamoyo Chapfuwa",
      "Ricardo Henao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2202.01869"
  },
  {
    "id": "arXiv:2202.01871",
    "title": "A Bibliometric Perspective of Social Science Scientific Communities of  Pakistan and India",
    "abstract": "In this study, we use research publication data from the field of social\nscience to identify collaboration networks among social science research\ncommunities of India and Pakistan. We have used Scopus database to extract\ninformation of social science journals for both countries India and Pakistan.\nStudy of this data is significant as both countries have common social issues\nand many of common social values. Keywords analysis has been done to see common\nresearch areas in both communities like poverty, education, the issue of gender\netc. Despite having many of the common social issues, collaboration among\nsocial science research communities of both countries is not strong.",
    "descriptor": "\nComments: 35 page, 8 Tables, 10 Figures\n",
    "authors": [
      "Sami Ul-Haq",
      "Saeed-Ul Hassan"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2202.01871"
  },
  {
    "id": "arXiv:2202.01875",
    "title": "Rethinking Explainability as a Dialogue: A Practitioner's Perspective",
    "abstract": "As practitioners increasingly deploy machine learning models in critical\ndomains such as health care, finance, and policy, it becomes vital to ensure\nthat domain experts function effectively alongside these models. Explainability\nis one way to bridge the gap between human decision-makers and machine learning\nmodels. However, most of the existing work on explainability focuses on\none-off, static explanations like feature importances or rule lists. These\nsorts of explanations may not be sufficient for many use cases that require\ndynamic, continuous discovery from stakeholders. In the literature, few works\nask decision-makers about the utility of existing explanations and other\ndesiderata they would like to see in an explanation going forward. In this\nwork, we address this gap and carry out a study where we interview doctors,\nhealthcare professionals, and policymakers about their needs and desires for\nexplanations. Our study indicates that decision-makers would strongly prefer\ninteractive explanations in the form of natural language dialogues. Domain\nexperts wish to treat machine learning models as \"another colleague\", i.e., one\nwho can be held accountable by asking why they made a particular decision\nthrough expressive and accessible natural language interactions. Considering\nthese needs, we outline a set of five principles researchers should follow when\ndesigning interactive explanations as a starting place for future work.\nFurther, we show why natural language dialogues satisfy these principles and\nare a desirable way to build interactive explanations. Next, we provide a\ndesign of a dialogue system for explainability and discuss the risks,\ntrade-offs, and research opportunities of building these systems. Overall, we\nhope our work serves as a starting place for researchers and engineers to\ndesign interactive explainability systems.",
    "descriptor": "",
    "authors": [
      "Himabindu Lakkaraju",
      "Dylan Slack",
      "Yuxin Chen",
      "Chenhao Tan",
      "Sameer Singh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.01875"
  },
  {
    "id": "arXiv:2202.01877",
    "title": "Stackelberg Strategic Guidance for Heterogeneous Robots Collaboration",
    "abstract": "In this study, we explore the application of game theory, in particular\nStackelberg games, to address the issue of effective coordination strategy\ngeneration for heterogeneous robots with one-way communication. To that end,\nfocusing on the task of multi-object rearrangement, we develop a theoretical\nand algorithmic framework that provides strategic guidance for a pair of robot\narms, a leader and a follower where the leader has a model of the follower's\ndecision-making process, through the computation of a feedback Stackelberg\nequilibrium. With built-in tolerance of model uncertainty, the strategic\nguidance generated by our planning algorithm not only improves the overall\nefficiency in solving the rearrangement tasks, but is also robust to common\npitfalls in collaboration, e.g., chattering.",
    "descriptor": "",
    "authors": [
      "Yuhan Zhao",
      "Baichuan Huang",
      "Jingjin Yu",
      "Quanyan Zhu"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.01877"
  },
  {
    "id": "arXiv:2202.01878",
    "title": "On the Benefit of Cooperation in Relay Networks",
    "abstract": "This work addresses the cooperation facilitator (CF) model, in which network\nnodes coordinate through a rate limited communication device. For independent\nmultiple-access channel (MAC) encoders, the CF model is known to show\nsignificant rate benefits, even when the rate of cooperation is negligible.\nSpecifically, the benefit in MAC sum-rate, as a function of the cooperation\nrate $C_{CF}$, sometimes has an infinite slope at $C_{CF}=0$. This work studies\nthe question of whether cooperation through a CF can yield similar\ninfinite-slope benefits when applied to internal network encoders in which\ndependence among MAC transmitters can be established without the help of the\nCF. Towards this end, this work studies the CF model when applied to relay\nnodes of a single-source, single-terminal, diamond network consisting of a\nbroadcast channel followed by a MAC. In the relay channel with orthogonal\nreceiver components, careful generalization of the\npartial-decode-forward/compress-forward lower bound to the CF model yields\nsufficient conditions for an infinite-slope benefit. Additional results include\nderivation of a family of diamond networks for which the infinite-slope\nrate-benefit derives directly from the properties of the corresponding MAC\ncomponent when studied in isolation.",
    "descriptor": "\nComments: Full version of a paper submitted to ISIT 2022. 9 pages, 3 figures\n",
    "authors": [
      "Oliver Kosut",
      "Michelle Effros",
      "Michael Langberg"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.01878"
  },
  {
    "id": "arXiv:2202.01879",
    "title": "Learning from a Learning User for Optimal Recommendations",
    "abstract": "In real-world recommendation problems, especially those with a formidably\nlarge item space, users have to gradually learn to estimate the utility of any\nfresh recommendations from their experience about previously consumed items.\nThis in turn affects their interaction dynamics with the system and can\ninvalidate previous algorithms built on the omniscient user assumption. In this\npaper, we formalize a model to capture such \"learning users\" and design an\nefficient system-side learning solution, coined Noise-Robust Active Ellipsoid\nSearch (RAES), to confront the challenges brought by the non-stationary\nfeedback from such a learning user. Interestingly, we prove that the regret of\nRAES deteriorates gracefully as the convergence rate of user learning becomes\nworse, until reaching linear regret when the user's learning fails to converge.\nExperiments on synthetic datasets demonstrate the strength of RAES for such a\ncontemporaneous system-user learning problem. Our study provides a novel\nperspective on modeling the feedback loop in recommendation problems.",
    "descriptor": "",
    "authors": [
      "Fan Yao",
      "Chuanhao Li",
      "Denis Nekipelov",
      "Hongning Wang",
      "Haifeng Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Retrieval (cs.IR)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2202.01879"
  },
  {
    "id": "arXiv:2202.01882",
    "title": "Theoretical scheme on shape-programming of thin hyperelastic plates  through differential growth",
    "abstract": "In this paper, a theoretical scheme is proposed for shape-programming of thin\nhyperelastic plates through differential growth. First, starting from the 3D\ngoverning system of a hyperelastic (neo-Hookean) plate, a consistent\nfinite-strain plate equation system is formulated through a series-expansion\nand truncation approach. Based on the plate equation system, the problem of\nshape-programming is studied under the stress-free assumption. By equating the\nstress components in the plate equations to be zero, the explicit relations\nbetween growth functions and geometrical quantities of the target shape of the\nplate are derived. Then, a theoretical scheme of shape-programming is proposed,\nwhich can be used to identify the growth fields corresponding to arbitrary 3D\nshapes of the plate. To demonstrate the efficiency of the scheme, some typical\nexamples are studied. The predicted growth functions in these examples are\nadopted in the numerical simulations, from which the target shapes of the plate\ncan be recovered completely. The scheme of shape-programming proposed in the\ncurrent work is applicable for manufacture of intelligent soft devices.",
    "descriptor": "",
    "authors": [
      "Jiong Wang",
      "Zhanfeng Li",
      "Zili Jin"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2202.01882"
  },
  {
    "id": "arXiv:2202.01883",
    "title": "Reduced polynomial invariant integrity basis for in-plane  magneto-mechanical loading",
    "abstract": "The description of the behavior of a material subjected to multi-physics\nloadings requires the formulation of constitutive laws that usually derive from\nGibbs free energies, using invariant quantities depending on the considered\nphysics and material symmetries. On the other hand, most of crystalline\nmaterials can be described by their crystalline texture and the associated\npreferred directions of strong crystalline symmetry (the so-called fibers).\nMoreover, among the materials produced industrially, many are manufactured in\nthe form of sheets or of thin layers. This article has for object the study of\nthe magneto-mechanical coupling which is a function of the stress $\\sigma$ and\nthe magnetization M. We consider a material with cubic symmetry whose texture\ncan be described by one of three fibers denoted as $\\theta$, $\\gamma$ or\n$\\alpha$ ' , and which is thin enough so that both the stress and the\nmagnetization can be considered as in-plane quantities. We propose an algorithm\nable to derive linear relations between the 30 cubic invariants I k of a\nminimal integrity basis describing a magneto-elastic problem, when they are\nrestricted to in-plane loading conditions and for different fiber orientations.\nThe algorithm/program output is a reduced list of invariants of cardinal 7 for\nthe {100}-oriented $\\theta$ fiber, of cardinal 15 for the {110}-oriented\n$\\alpha$ ' fiber and of cardinal 8 for the {111}-oriented $\\gamma$ fiber. This\nreduction (compared to initial cardinal 30) can be of great help for the\nformulation of low-parameter macroscopic magneto-mechanical models.",
    "descriptor": "",
    "authors": [
      "Julien Taurines",
      "Boris Kolev",
      "Rodrigue Desmorat",
      "Olivier Hubert"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Classical Physics (physics.class-ph)"
    ],
    "url": "https://arxiv.org/abs/2202.01883"
  },
  {
    "id": "arXiv:2202.01884",
    "title": "Research on Patch Attentive Neural Process",
    "abstract": "Attentive Neural Process (ANP) improves the fitting ability of Neural Process\n(NP) and improves its prediction accuracy, but the higher time complexity of\nthe model imposes a limitation on the length of the input sequence. Inspired by\nmodels such as Vision Transformer (ViT) and Masked Auto-Encoder (MAE), we\npropose Patch Attentive Neural Process (PANP) using image patches as input and\nimprove the structure of deterministic paths based on ANP, which allows the\nmodel to extract image features more accurately and efficiently reconstruction.",
    "descriptor": "",
    "authors": [
      "Xiaohan Yu",
      "Shaochen Mao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.01884"
  },
  {
    "id": "arXiv:2202.01888",
    "title": "A Hybrid Physics Machine Learning Approach for Macroscopic Traffic State  Estimation",
    "abstract": "Full-field traffic state information (i.e., flow, speed, and density) is\ncritical for the successful operation of Intelligent Transportation Systems\n(ITS) on freeways. However, incomplete traffic information tends to be directly\ncollected from traffic detectors that are insufficiently installed in most\nareas, which is a major obstacle to the popularization of ITS. To tackle this\nissue, this paper introduces an innovative traffic state estimation (TSE)\nframework that hybrid regression machine learning techniques (e.g., artificial\nneural network (ANN), random forest (RF), and support vector machine (SVM))\nwith a traffic physics model (e.g., second-order macroscopic traffic flow\nmodel) using limited information from traffic sensors as inputs to construct\naccurate and full-field estimated traffic state for freeway systems. To examine\nthe effectiveness of the proposed TSE framework, this paper conducted empirical\nstudies on a real-world data set collected from a stretch of I-15 freeway in\nSalt Lake City, Utah. Experimental results show that the proposed method has\nbeen proved to estimate full-field traffic information accurately. Hence, the\nproposed method could provide accurate and full-field traffic information, thus\nproviding the basis for the popularization of ITS.",
    "descriptor": "\nComments: 17 pages, 5 figures, conference paper\n",
    "authors": [
      "Zhao Zhang",
      "Ding Zhao",
      "Xianfeng Terry Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.01888"
  },
  {
    "id": "arXiv:2202.01889",
    "title": "Generalizing to New Physical Systems via Context-Informed Dynamics Model",
    "abstract": "Data-driven approaches to modeling physical systems fail to generalize to\nunseen systems that share the same general dynamics with the learning domain,\nbut correspond to different physical contexts. We propose a new framework for\nthis key problem, context-informed dynamics adaptation (CoDA), which takes into\naccount the distributional shift across systems for fast and efficient\nadaptation to new dynamics. CoDA leverages multiple environments, each\nassociated to a different dynamic, and learns to condition the dynamics model\non contextual parameters, specific to each environment. The conditioning is\nperformed via a hypernetwork, learned jointly with a context vector from\nobserved data. The proposed formulation constrains the search hypothesis space\nto foster fast adaptation and better generalization across environments. It\nextends the expressivity of existing methods. We theoretically motivate our\napproach and show state-ofthe-art generalization results on a set of nonlinear\ndynamics, representative of a variety of application domains. We also show, on\nthese systems, that new system parameters can be inferred from context vectors\nwith minimal supervision.",
    "descriptor": "",
    "authors": [
      "Matthieu Kirchmeyer",
      "Yuan Yin",
      "J\u00e9r\u00e9mie Don\u00e0",
      "Nicolas Baskiotis",
      "Alain Rakotomamonjy",
      "Patrick Gallinari"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.01889"
  },
  {
    "id": "arXiv:2202.01890",
    "title": "Advances in MetaDL: AAAI 2021 challenge and workshop",
    "abstract": "To stimulate advances in metalearning using deep learning techniques\n(MetaDL), we organized in 2021 a challenge and an associated workshop. This\npaper presents the design of the challenge and its results, and summarizes\npresentations made at the workshop. The challenge focused on few-shot learning\nclassification tasks of small images. Participants' code submissions were run\nin a uniform manner, under tight computational constraints. This put pressure\non solution designs to use existing architecture backbones and/or pre-trained\nnetworks. Winning methods featured various classifiers trained on top of the\nsecond last layer of popular CNN backbones, fined-tuned on the meta-training\ndata (not necessarily in an episodic manner), then trained on the labeled\nsupport and tested on the unlabeled query sets of the meta-test data.",
    "descriptor": "\nComments: Proceedings of Machine Learning Research, PMLR, 2021\n",
    "authors": [
      "Adrian El Baz",
      "Isabelle Guyon",
      "Zhengying Liu",
      "Jan van Rijn",
      "Sebastien Treguer",
      "Joaquin Vanschoren"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.01890"
  },
  {
    "id": "arXiv:2202.01891",
    "title": "Weighted Random Cut Forest Algorithm for Anomaly Detections",
    "abstract": "Random cut forest (RCF) algorithms have been developed for anomaly detection,\nparticularly for the anomaly detection in time-series data. The RCF algorithm\nis the improved version of the isolation forest algorithm.\nUnlike the isolation forest algorithm, the RCF algorithm has the power of\ndetermining whether the real-time input has anomaly by inserting the input in\nthe constructed tree network.\nThere have been developed various RCF algorithms including Robust RCF (RRCF)\nwith which the cutting procedure is adaptively chosen probabilistically. RRCF\nshows better performance compared to the isolation forest as the cutting\ndimension is decided based on the geometric range of the data. The overall data\nstructure is, however, not considered in the adaptive cutting algorithm with\nthe RRCF. In this paper, we propose a new RCF, so-called the weighted RCF\n(WRCF). In order to introduce the WRCF, we first introduce a new geometric\nmeasure, i.e., a \\textit{density measure} which is crucial for the construction\nof the WRCF. We provide various mathematical properties of the density measure.\nThe proposed WRCF also cuts the tree network adaptively, but with consideration\nof the denseness of the data. The proposed method is more efficient when the\ndata is structured and achieves the desired anomaly score more rapidly than the\nRRCF. We provide theorems that prove our claims with numerical examples.",
    "descriptor": "\nComments: 30 pages\n",
    "authors": [
      "Sijin Yeom",
      "Jae-Hun Jung"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.01891"
  },
  {
    "id": "arXiv:2202.01893",
    "title": "A Machine Learning Smartphone-based Sensing for Driver Behavior  Classification",
    "abstract": "Driver behavior profiling is one of the main issues in the insurance\nindustries and fleet management, thus being able to classify the driver\nbehavior with low-cost mobile applications remains in the spotlight of\nautonomous driving. However, using mobile sensors may face the challenge of\nsecurity, privacy, and trust issues. To overcome those challenges, we propose\nto collect data sensors using Carla Simulator available in smartphones\n(Accelerometer, Gyroscope, GPS) in order to classify the driver behavior using\nspeed, acceleration, direction, the 3-axis rotation angles (Yaw, Pitch, Roll)\ntaking into account the speed limit of the current road and weather conditions\nto better identify the risky behavior. Secondly, after fusing inter-axial data\nfrom multiple sensors into a single file, we explore different machine learning\nalgorithms for time series classification to evaluate which algorithm results\nin the highest performance.",
    "descriptor": "\nComments: Accepted for publication in IEEE International Symposium on Circuits and Systems (ISCAS 2022), Austin, TX, USA, May 2022\n",
    "authors": [
      "Sarra Ben Brahim",
      "Hakim Ghazzai",
      "Hichem Besbes",
      "Yehia Massoud"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.01893"
  },
  {
    "id": "arXiv:2202.01901",
    "title": "Bunched Fuzz: Sensitivity for Vector Metrics",
    "abstract": "\"Program sensitivity\" measures the distance between the outputs of a program\nwhen it is run on two related inputs. This notion, which plays an important\nrole in areas such as data privacy and optimization, has been the focus of\nseveral program analysis techniques introduced in recent years. One approach\nthat has proved particularly fruitful for this domain is the use of type\nsystems inspired by linear logic, as pioneered by Reed and Pierce in the Fuzz\nprogramming language. In Fuzz, each type is equipped with its own notion of\ndistance, and the typing rules explain how those distances can be treated\nsoundly when analyzing the sensitivity of a program. In particular, Fuzz\nfeatures two products types, corresponding to two different sensitivity\nanalyses: the \"tensor product\" combines the distances of each component by\nadding them, while the \"with product\" takes their maximum.\nIn this work, we show that products in Fuzz can be generalized to arbitrary\n$L^p$ distances, metrics that are often used in privacy and optimization. The\noriginal Fuzz products, tensor and with, correspond to the special cases $L^1$\nand $L^\\infty$. To simplify the handling of such products, we extend the Fuzz\ntype system with bunches -- as in the logic of bunched implications -- where\nthe distances of different groups of variables can be combined using different\n$L^p$ distances. We show that our extension can be used to reason about\nimportant examples of metrics between probability distributions in a natural\nway.",
    "descriptor": "",
    "authors": [
      "june wunder",
      "Arthur Azevedo de Amorim",
      "Patrick Baillot",
      "Marco Gaboardi"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2202.01901"
  },
  {
    "id": "arXiv:2202.01907",
    "title": "Unified Fake News Detection using Transfer Learning of Bidirectional  Encoder Representation from Transformers model",
    "abstract": "Automatic detection of fake news is needed for the public as the\naccessibility of social media platforms has been increasing rapidly. Most of\nthe prior models were designed and validated on individual datasets separately.\nBut the lack of generalization in models might lead to poor performance when\ndeployed in real-world applications since the individual datasets only cover\nlimited subjects and sequence length over the samples. This paper attempts to\ndevelop a unified model by combining publicly available datasets to detect fake\nnews samples effectively.",
    "descriptor": "\nComments: 9 pages, 10 figures\n",
    "authors": [
      "Vijay Srinivas Tida",
      "Dr. Sonya Hsu",
      "Dr. Xiali Hei"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.01907"
  },
  {
    "id": "arXiv:2202.01908",
    "title": "Sampling with Riemannian Hamiltonian Monte Carlo in a Constrained Space",
    "abstract": "We demonstrate for the first time that ill-conditioned, non-smooth,\nconstrained distributions in very high dimension, upwards of 100,000, can be\nsampled efficiently $\\textit{in practice}$. Our algorithm incorporates\nconstraints into the Riemannian version of Hamiltonian Monte Carlo and\nmaintains sparsity. This allows us to achieve a mixing rate independent of\nsmoothness and condition numbers.\nOn benchmark data sets in systems biology and linear programming, our\nalgorithm outperforms existing packages by orders of magnitude. In particular,\nwe achieve a 1,000-fold speed-up for sampling from the largest published human\nmetabolic network (RECON3D). Our package has been incorporated into the COBRA\ntoolbox.",
    "descriptor": "\nComments: 31 pages\n",
    "authors": [
      "Yunbum Kook",
      "Yin Tat Lee",
      "Ruoqi Shen",
      "Santosh S. Vempala"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2202.01908"
  },
  {
    "id": "arXiv:2202.01909",
    "title": "Ad-datasets: a meta-collection of data sets for autonomous driving",
    "abstract": "Autonomous driving is among the largest domains in which deep learning has\nbeen fundamental for progress within the last years. The rise of datasets went\nhand in hand with this development. All the more striking is the fact that\nresearchers do not have a tool available that provides a quick, comprehensive\nand up-to-date overview of data sets and their features in the domain of\nautonomous driving. In this paper, we present ad-datasets, an online tool that\nprovides such an overview for more than 150 data sets. The tool enables users\nto sort and filter the data sets according to currently 16 different\ncategories. ad-datasets is an open-source project with community contributions.\nIt is in constant development, ensuring that the content stays up-to-date.",
    "descriptor": "\nComments: Daniel Bogdoll and Felix Schreyer contributed equally. Accepted for publication at VEHITS 2022\n",
    "authors": [
      "Daniel Bogdoll",
      "Felix Schreyer",
      "J. Marius Z\u00f6llner"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.01909"
  },
  {
    "id": "arXiv:2202.01913",
    "title": "Time-Constrained Learning",
    "abstract": "Consider a scenario in which we have a huge labeled dataset ${\\cal D}$ and a\nlimited time to train some given learner using ${\\cal D}$. Since we may not be\nable to use the whole dataset, how should we proceed? Questions of this nature\nmotivate the definition of the Time-Constrained Learning Task (TCL): Given a\ndataset ${\\cal D}$ sampled from an unknown distribution $\\mu$, a learner ${\\cal\nL}$ and a time limit $T$, the goal is to obtain in at most $T$ units of time\nthe classification model with highest possible accuracy w.r.t. to $\\mu$, among\nthose that can be built by ${\\cal L}$ using the dataset ${\\cal D}$.\nWe propose TCT, an algorithm for the TCL task designed based that on\nprinciples from Machine Teaching. We present an experimental study involving 5\ndifferent Learners and 20 datasets where we show that TCT consistently\noutperforms two other algorithms: the first is a Teacher for black-box learners\nproposed in [Dasgupta et al., ICML 19] and the second is a natural adaptation\nof random sampling for the TCL setting. We also compare TCT with Stochastic\nGradient Descent training -- our method is again consistently better.\nWhile our work is primarily practical, we also show that a stripped-down\nversion of TCT has provable guarantees. Under reasonable assumptions, the time\nour algorithm takes to achieve a certain accuracy is never much bigger than the\ntime it takes the batch teacher (which sends a single batch of examples) to\nachieve similar accuracy, and in some case it is almost exponentially better.",
    "descriptor": "",
    "authors": [
      "Sergio Filho",
      "Eduardo Laber",
      "Pedro Lazera",
      "Marco Molinaro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.01913"
  },
  {
    "id": "arXiv:2202.01914",
    "title": "Tsetlin Machine for Solving Contextual Bandit Problems",
    "abstract": "This paper introduces an interpretable contextual bandit algorithm using\nTsetlin Machines, which solves complex pattern recognition tasks using\npropositional logic. The proposed bandit learning algorithm relies on\nstraightforward bit manipulation, thus simplifying computation and\ninterpretation. We then present a mechanism for performing Thompson sampling\nwith Tsetlin Machine, given its non-parametric nature. Our empirical analysis\nshows that Tsetlin Machine as a base contextual bandit learner outperforms\nother popular base learners on eight out of nine datasets. We further analyze\nthe interpretability of our learner, investigating how arms are selected based\non propositional expressions that model the context.",
    "descriptor": "",
    "authors": [
      "Raihan Seraj",
      "Jivitesh Sharma",
      "Ole-Christoffer Granmo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2202.01914"
  },
  {
    "id": "arXiv:2202.01919",
    "title": "Theoretical Exploration of Solutions of Feedforward ReLU networks",
    "abstract": "This paper aims to interpret the mechanism of feedforward ReLU networks by\nexploring their solutions for piecewise linear functions through basic rules.\nThe constructed solutions should be universal enough to explain the network\narchitectures of engineering. In order for that, we borrow the methodology of\ntheoretical physics to develop the theories. Some of the consequences of our\ntheories include: Under geometric backgrounds, the solutions of both\nthree-layer networks and deep-layer networks are presented, and the solution\nuniversality is ensured by several ways; We give clear and intuitive\ninterpretations of each component of network architectures, such as the\nparameter-sharing mechanism for multi-output, the function of each layer, the\nadvantage of deep layers, the redundancy of parameters, and so on. We explain\nthree typical network architectures: the subnetwork of last three layers of\nconvolutional networks, multi-layer feedforward networks, and the decoder of\nautoencoders. This paper is expected to provide a basic foundation of theories\nof feedforward ReLU networks for further investigations.",
    "descriptor": "",
    "authors": [
      "Changcun Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.01919"
  },
  {
    "id": "arXiv:2202.01924",
    "title": "Zero-Shot Aspect-Based Sentiment Analysis",
    "abstract": "Aspect-based sentiment analysis (ABSA) typically requires in-domain annotated\ndata for supervised training/fine-tuning. It is a big challenge to scale ABSA\nto a large number of new domains. This paper aims to train a unified model that\ncan perform zero-shot ABSA without using any annotated data for a new domain.\nWe propose a method called contrastive post-training on review Natural Language\nInference (CORN). Later ABSA tasks can be cast into NLI for zero-shot transfer.\nWe evaluate CORN on ABSA tasks, ranging from aspect extraction (AE), aspect\nsentiment classification (ASC), to end-to-end aspect-based sentiment analysis\n(E2E ABSA), which show ABSA can be conducted without any human annotated ABSA\ndata.",
    "descriptor": "",
    "authors": [
      "Lei Shu",
      "Jiahua Chen",
      "Bing Liu",
      "Hu Xu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.01924"
  },
  {
    "id": "arXiv:2202.01929",
    "title": "$\\mathcal{F}$-EBM: Energy Based Learning of Functional Data",
    "abstract": "Energy-Based Models (EBMs) have proven to be a highly effective approach for\nmodelling densities on finite-dimensional spaces. Their ability to incorporate\ndomain-specific choices and constraints into the structure of the model through\ncomposition make EBMs an appealing candidate for applications in physics,\nbiology and computer vision and various other fields. In this work, we present\na novel class of EBM which is able to learn distributions of functions (such as\ncurves or surfaces) from functional samples evaluated at finitely many points.\nTwo unique challenges arise in the functional context. Firstly, training data\nis often not evaluated along a fixed set of points. Secondly, steps must be\ntaken to control the behaviour of the model between evaluation points, to\nmitigate overfitting. The proposed infinite-dimensional EBM employs a latent\nGaussian process, which is weighted spectrally by an energy function\nparameterised with a neural network. The resulting EBM has the ability to\nutilize irregularly sampled training data and can output predictions at any\nresolution, providing an effective approach to up-scaling functional data. We\ndemonstrate the efficacy of our proposed approach for modelling a range of\ndatasets, including data collected from Standard and Poor's 500 (S\\&P) and UK\nNational grid.",
    "descriptor": "",
    "authors": [
      "Jen Ning Lim",
      "Sebastian Vollmer",
      "Lorenz Wolf",
      "Andrew Duncan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.01929"
  },
  {
    "id": "arXiv:2202.01934",
    "title": "Smartphone-based Hard-braking Event Detection at Scale for Road Safety  Services",
    "abstract": "Road crashes are the sixth leading cause of lost disability-adjusted\nlife-years (DALYs) worldwide. One major challenge in traffic safety research is\nthe sparsity of crashes, which makes it difficult to achieve a fine-grain\nunderstanding of crash causations and predict future crash risk in a timely\nmanner. Hard-braking events have been widely used as a safety surrogate due to\ntheir relatively high prevalence and ease of detection with embedded vehicle\nsensors. As an alternative to using sensors fixed in vehicles, this paper\npresents a scalable approach for detecting hard-braking events using the\nkinematics data collected from smartphone sensors. We train a Transformer-based\nmachine learning model for hard-braking event detection using concurrent sensor\nreadings from smartphones and vehicle sensors from drivers who connect their\nphone to the vehicle while navigating in Google Maps. The detection model shows\nsuperior performance with a $0.83$ Area under the Precision-Recall Curve\n(PR-AUC), which is $3.8\\times$better than a GPS speed-based heuristic model,\nand $166.6\\times$better than an accelerometer-based heuristic model. The\ndetected hard-braking events are strongly correlated with crashes from publicly\navailable datasets, supporting their use as a safety surrogate. In addition, we\nconduct model fairness and selection bias evaluation to ensure that the safety\nbenefits are equally shared. The developed methodology can benefit many safety\napplications such as identifying safety hot spots at road network level,\nevaluating the safety of new user interfaces, as well as using routing to\nimprove traffic safety.",
    "descriptor": "",
    "authors": [
      "Luyang Liu",
      "David Racz",
      "Kara Vaillancourt",
      "Julie Michelman",
      "Matt Barnes",
      "Stefan Mellem",
      "Paul Eastham",
      "Bradley Green",
      "Charles Armstrong",
      "Rishi Bal",
      "Shawn O'Banion",
      "Feng Guo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.01934"
  },
  {
    "id": "arXiv:2202.01935",
    "title": "Robust Dynamic State Estimator of Integrated Energy Systems based on  Natural Gas Partial Differential Equations",
    "abstract": "The reliability and precision of dynamic database are vital for the optimal\noperating and global control of integrated energy systems. One of the effective\nways to obtain the accurate states is state estimations. A novel robust dynamic\nstate estimation methodology for integrated natural gas and electric power\nsystems is proposed based on Kalman filter. To take full advantage of\nmeasurement redundancies and predictions for enhancing the estimating accuracy,\nthe dynamic state estimation model coupling gas and power systems by gas\nturbine units is established. The exponential smoothing technique and gas\nphysical model are integrated in Kalman filter. Additionally, the time-varying\nscalar matrix is proposed to conquer bad data in Kalman filter algorithm. The\nproposed method is applied to an integrated gas and power systems formed by\nGasLib-40 and IEEE 39-bus system with five gas turbine units. The simulating\nresults show that the method can obtain the accurate dynamic states under three\ndifferent measurement error conditions, and the filtering performance are\nbetter than separate estimation methods. Additionally, the proposed method is\nrobust when the measurements experience bad data.",
    "descriptor": "\nComments: Accepted by IEEE transactions on Industry Applications. arXiv admin note: text overlap with arXiv:2107.05891\n",
    "authors": [
      "Liang Chen",
      "Yang Li",
      "Manyun Huang",
      "Xinxin Hui",
      "Songlin Gu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.01935"
  },
  {
    "id": "arXiv:2202.01936",
    "title": "Brain-Computer-Interface controlled robot via RaspberryPi and PiEEG",
    "abstract": "This paper presents Open-source software and a developed shield board for the\nRaspberry Pi family of single-board computers that can be used to read EEG\nsignals. We have described the mechanism for reading EEG signals and\ndecomposing them into a Fourier series and provided examples of controlling\nLEDs and a toy robot by blinking. Finally, we discussed the prospects of the\nbrain-computer interface for the near future and considered various methods for\ncontrolling external mechanical objects using real-time EEG signals.",
    "descriptor": "",
    "authors": [
      "Ildar Rakhmatulin",
      "Sebastian Volkl"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.01936"
  },
  {
    "id": "arXiv:2202.01938",
    "title": "DYP-SLAM: A Real-time Visual SLAM Based on YOLO and Probability in  Dynamic Environments",
    "abstract": "SLAM algorithm is based on the static assumption of environment. Therefore,\nthe dynamic factors in the environment will have a great impact on the matching\npoints due to violating this assumption, and then directly affect the accuracy\nof subsequent camera pose estimation. Recently, some related works generally\nuse the combination of semantic constraints and geometric constraints to deal\nwith dynamic objects, but there are some problems, such as poor real-time\nperformance, easy to treat people as rigid bodies, and poor performance in low\ndynamic scenes. In this paper, a dynamic scene oriented visual SLAM algorithm\nbased on target detection and static probability named DYP-SLAM is proposed.\nThe algorithm combines semantic constraints and geometric constraints to\ncalculate the static probability of objects, keypoints and map points, and\ntakes them as weights to participate in camera pose estimation. The proposed\nalgorithm is evaluated on the public dataset and compared with a variety of\nadvanced algorithms. It has achieved the best results in almost all low\ndynamics and high dynamic scenarios, and showing quite high real-time.",
    "descriptor": "",
    "authors": [
      "Xinggang Hu",
      "Yunzhou Zhang",
      "Zhenzhong Cao",
      "Yanmin Wu",
      "Zhiqiang Deng",
      "Wenkai Sun",
      "Sonya Coleman",
      "Dermot Kerr"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.01938"
  },
  {
    "id": "arXiv:2202.01943",
    "title": "PSO-PINN: Physics-Informed Neural Networks Trained with Particle Swarm  Optimization",
    "abstract": "Physics-informed neural networks (PINNs) have recently emerged as a promising\napplication of deep learning in a wide range of engineering and scientific\nproblems based on partial differential equation models. However, evidence shows\nthat PINN training by gradient descent displays pathologies and stiffness in\ngradient flow dynamics. In this paper, we propose the use of a hybrid particle\nswarm optimization and gradient descent approach to train PINNs. The resulting\nPSO-PINN algorithm not only mitigates the undesired behaviors of PINNs trained\nwith standard gradient descent, but also presents an ensemble approach to PINN\nthat affords the possibility of robust predictions with quantified uncertainty.\nExperimental results using the Poisson, advection, and Burgers equations show\nthat PSO-PINN consistently outperforms a baseline PINN trained with Adam\ngradient descent.",
    "descriptor": "",
    "authors": [
      "Caio Davi",
      "Ulisses Braga-Neto"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2202.01943"
  },
  {
    "id": "arXiv:2202.01944",
    "title": "Learning Representation from Neural Fisher Kernel with Low-rank  Approximation",
    "abstract": "In this paper, we study the representation of neural networks from the view\nof kernels. We first define the Neural Fisher Kernel (NFK), which is the Fisher\nKernel applied to neural networks. We show that NFK can be computed for both\nsupervised and unsupervised learning models, which can serve as a unified tool\nfor representation extraction. Furthermore, we show that practical NFKs exhibit\nlow-rank structures. We then propose an efficient algorithm that computes a low\nrank approximation of NFK, which scales to large datasets and networks. We show\nthat the low-rank approximation of NFKs derived from unsupervised generative\nmodels and supervised learning models gives rise to high-quality compact\nrepresentations of data, achieving competitive results on a variety of machine\nlearning tasks.",
    "descriptor": "",
    "authors": [
      "Ruixiang Zhang",
      "Shuangfei Zhai",
      "Etai Littwin",
      "Josh Susskind"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.01944"
  },
  {
    "id": "arXiv:2202.01949",
    "title": "A Reinforcement Learning Framework for PQoS in a Teleoperated Driving  Scenario",
    "abstract": "In recent years, autonomous networks have been designed with Predictive\nQuality of Service (PQoS) in mind, as a means for applications operating in the\nindustrial and/or automotive sectors to predict unanticipated Quality of\nService (QoS) changes and react accordingly. In this context, Reinforcement\nLearning (RL) has come out as a promising approach to perform accurate\npredictions, and optimize the efficiency and adaptability of wireless networks.\nAlong these lines, in this paper we propose the design of a new entity,\nimplemented at the RAN-level that, with the support of an RL framework,\nimplements PQoS functionalities. Specifically, we focus on the design of the\nreward function of the learning agent, able to convert QoS estimates into\nappropriate countermeasures if QoS requirements are not satisfied. We\ndemonstrate via ns-3 simulations that our approach achieves the best trade-off\nin terms of QoS and Quality of Experience (QoE) performance of end users in a\nteleoperated-driving-like scenario, compared to other baseline solutions.",
    "descriptor": "\nComments: 6 pages, 5 figures, 2 tables. The paper has been submitted to IEEE WCNC 2022. Copyright may change without notice\n",
    "authors": [
      "Federico Mason",
      "Matteo Drago",
      "Tommaso Zugno",
      "Marco Giordani",
      "Mate Boban",
      "Michele Zorzi"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.01949"
  },
  {
    "id": "arXiv:2202.01950",
    "title": "Reasoning on the Air: An Implicit Semantic Communication Architecture",
    "abstract": "Semantic communication is a novel communication paradigm which draws\ninspiration from human communication focusing on the delivery of the meaning of\na message to the intended users. It has attracted significant interest recently\ndue to its potential to improve efficiency and reliability of communication,\nenhance users' quality-of-experience (QoE), and achieve smoother\ncross-protocol/domain communication. Most existing works in semantic\ncommunication focus on identifying and transmitting explicit semantic meaning,\ne.g., labels of objects, that can be directly identified from the source\nsignal. This paper investigates implicit semantic communication in which the\nhidden information, e.g., implicit causality and reasoning mechanisms of users,\nthat cannot be directly observed from the source signal needs to be transported\nand delivered to the intended users. We propose a novel implicit semantic\ncommunication (iSC) architecture for representing, communicating, and\ninterpreting the implicit semantic meaning. In particular, we first propose a\ngraph-inspired structure to represent implicit meaning of message based on\nthree key components: entity, relation, and reasoning mechanism. We then\npropose a generative adversarial imitation learning-based reasoning mechanism\nlearning (GAML) solution for the destination user to learn and imitate the\nreasoning process of the source user. We prove that, by applying GAML, the\ndestination user can accurately imitate the reasoning process of the users to\ngenerate reasoning paths that follow the same probability distribution as the\nexpert paths. Numerical results suggest that our proposed architecture can\nachieve accurate implicit meaning interpretation at the destination user.",
    "descriptor": "\nComments: Submitted to IEEE ICC Workshop 2022\n",
    "authors": [
      "Yong Xiao",
      "Yingyu Li",
      "Guangming Shi",
      "H. Vincent Poor"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2202.01950"
  },
  {
    "id": "arXiv:2202.01952",
    "title": "Life-long Learning for Reasoning-based Semantic Communication",
    "abstract": "Semantic communication is an emerging paradigm that focuses on understanding\nand delivering semantics, or meaning of messages. Most existing semantic\ncommunication solutions define semantic meaning as the meaning of object labels\nrecognized from a source signal, while ignoring intrinsic information that\ncannot be directly observed. Moreover, existing solutions often assume the\nrecognizable semantic meanings are limited by a pre-defined label database. In\nthis paper, we propose a novel reasoning-based semantic communication\narchitecture in which the semantic meaning is represented by a graph-based\nknowledge structure in terms of object-entity, relationships, and reasoning\nrules. An embedding-based semantic interpretation framework is proposed to\nconvert the high-dimensional graph-based representation of semantic meaning\ninto a low-dimensional representation, which is efficient for channel\ntransmission. We develop a novel inference function-based approach that can\nautomatically infer hidden information such as missing entities and relations\nthat cannot be directly observed from the message. Finally, we introduce a\nlife-long model updating approach in which the receiver can learn from\npreviously received messages and automatically update the reasoning rules of\nusers when new unknown semantic entities and relations have been discovered.\nExtensive experiments are conducted based on a real-world knowledge database\nand numerical results show that our proposed solution achieves 76%\ninterpretation accuracy of semantic meaning at the receiver, notably when some\nentities are missing in the transmitted message.",
    "descriptor": "\nComments: Submitted to IEEE ICC Workshop 2022\n",
    "authors": [
      "Jingming Liang",
      "Yong Xiao",
      "Yingyu Li",
      "Guangming Shi",
      "Mehdi Bennis"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2202.01952"
  },
  {
    "id": "arXiv:2202.01953",
    "title": "Active metric learning and classification using similarity queries",
    "abstract": "Active learning is commonly used to train label-efficient models by\nadaptively selecting the most informative queries. However, most active\nlearning strategies are designed to either learn a representation of the data\n(e.g., embedding or metric learning) or perform well on a task (e.g.,\nclassification) on the data. However, many machine learning tasks involve a\ncombination of both representation learning and a task-specific goal. Motivated\nby this, we propose a novel unified query framework that can be applied to any\nproblem in which a key component is learning a representation of the data that\nreflects similarity. Our approach builds on similarity or nearest neighbor (NN)\nqueries which seek to select samples that result in improved embeddings. The\nqueries consist of a reference and a set of objects, with an oracle selecting\nthe object most similar (i.e., nearest) to the reference. In order to reduce\nthe number of solicited queries, they are chosen adaptively according to an\ninformation theoretic criterion. We demonstrate the effectiveness of the\nproposed strategy on two tasks -- active metric learning and active\nclassification -- using a variety of synthetic and real world datasets. In\nparticular, we demonstrate that actively selected NN queries outperform\nrecently developed active triplet selection methods in a deep metric learning\nsetting. Further, we show that in classification, actively selecting class\nlabels can be reformulated as a process of selecting the most informative NN\nquery, allowing direct application of our method.",
    "descriptor": "\nComments: 23 pages, 14 figures\n",
    "authors": [
      "Namrata Nadagouda",
      "Austin Xu",
      "Mark A. Davenport"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.01953"
  },
  {
    "id": "arXiv:2202.01956",
    "title": "Maximum Likelihood Estimation of Optimal Receiver Operating  Characteristic Curves from Likelihood Ratio Observations",
    "abstract": "The optimal receiver operating characteristic (ROC) curve, giving the maximum\nprobability of detection as a function of the probability of false alarm, is a\nkey information-theoretic indicator of the difficulty of a binary hypothesis\ntesting problem (BHT). It is well known that the optimal ROC curve for a given\nBHT, corresponding to the likelihood ratio test, is theoretically determined by\nthe probability distribution of the observed data under each of the two\nhypotheses. In some cases, these two distributions may be unknown or\ncomputationally intractable, but independent samples of the likelihood ratio\ncan be observed. This raises the problem of estimating the optimal ROC for a\nBHT from such samples. The maximum likelihood estimator of the optimal ROC\ncurve is derived, and it is shown to converge to the true optimal ROC curve in\nthe \\levy\\ metric, as the number of observations tends to infinity. A classical\nempirical estimator, based on estimating the two types of error probabilities\nfrom two separate sets of samples, is also considered. The maximum likelihood\nestimator is observed in simulation experiments to be considerably more\naccurate than the empirical estimator, especially when the number of samples\nobtained under one of the two hypotheses is small. The area under the maximum\nlikelihood estimator is derived; it is a consistent estimator of the true area\nunder the optimal ROC curve.",
    "descriptor": "",
    "authors": [
      "Bruce Hajek",
      "Xiaohan Kang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.01956"
  },
  {
    "id": "arXiv:2202.01958",
    "title": "Demystify Optimization and Generalization of Over-parameterized  PAC-Bayesian Learning",
    "abstract": "PAC-Bayesian is an analysis framework where the training error can be\nexpressed as the weighted average of the hypotheses in the posterior\ndistribution whilst incorporating the prior knowledge. In addition to being a\npure generalization bound analysis tool, PAC-Bayesian bound can also be\nincorporated into an objective function to train a probabilistic neural\nnetwork, making them a powerful and relevant framework that can numerically\nprovide a tight generalization bound for supervised learning. For simplicity,\nwe call probabilistic neural network learned using training objectives derived\nfrom PAC-Bayesian bounds as {\\it PAC-Bayesian learning}. Despite their\nempirical success, the theoretical analysis of PAC-Bayesian learning for neural\nnetworks is rarely explored. This paper proposes a new class of convergence and\ngeneralization analysis for PAC-Bayes learning when it is used to train the\nover-parameterized neural networks by the gradient descent method. For a wide\nprobabilistic neural network, we show that when PAC-Bayes learning is applied,\nthe convergence result corresponds to solving a kernel ridge regression when\nthe probabilistic neural tangent kernel (PNTK) is used as its kernel. Based on\nthis finding, we further characterize the uniform PAC-Bayesian generalization\nbound which improves over the Rademacher complexity-based bound for\nnon-probabilistic neural network. Finally, drawing the insight from our\ntheoretical results, we propose a proxy measure for efficient hyperparameters\nselection, which is proven to be time-saving.",
    "descriptor": "\nComments: 19pages, 5 figures\n",
    "authors": [
      "Wei Huang",
      "Chunrui Liu",
      "Yilan Chen",
      "Tianyu Liu",
      "Richard Yi Da Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.01958"
  },
  {
    "id": "arXiv:2202.01961",
    "title": "Quality-diversity for aesthetic evolution",
    "abstract": "Many creative generative design spaces contain multiple regions with\nindividuals of high aesthetic value. Yet traditional evolutionary computing\nmethods typically focus on optimisation, searching for the fittest individual\nin a population. In this paper we apply quality-diversity search methods to\nexplore a creative generative system (an agent-based line drawing model). We\nperform a random sampling of genotype space and use individual artist-assigned\nevaluations of aesthetic quality to formulate a computable fitness measure\nspecific to the artist and this system. To compute diversity we use a\nconvolutional neural network to discriminate features that are dimensionally\nreduced into two dimensions. We show that the quality-diversity search is able\nto find multiple phenotypes of high aesthetic value. These phenotypes show\ngreater diversity and quality than those the artist was able to find using\nmanual search methods.",
    "descriptor": "\nComments: Preprint of paper accepted for EvoMUSART 2022 Conference\n",
    "authors": [
      "Jon McCormack",
      "Camilo Cruz Gambardella"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2202.01961"
  },
  {
    "id": "arXiv:2202.01966",
    "title": "Predictive Closed-Loop Service Automation in O-RAN based Network Slicing",
    "abstract": "Network slicing provides introduces customized and agile network deployment\nfor managing different service types for various verticals under the same\ninfrastructure. To cater to the dynamic service requirements of these verticals\nand meet the required quality-of-service (QoS) mentioned in the service-level\nagreement (SLA), network slices need to be isolated through dedicated elements\nand resources. Additionally, allocated resources to these slices need to be\ncontinuously monitored and intelligently managed. This enables immediate\ndetection and correction of any SLA violation to support automated service\nassurance in a closed-loop fashion. By reducing human intervention, intelligent\nand closed-loop resource management reduces the cost of offering flexible\nservices. Resource management in a network shared among verticals (potentially\nadministered by different providers), would be further facilitated through open\nand standardized interfaces. Open radio access network (O-RAN) is perhaps the\nmost promising RAN architecture that inherits all the aforementioned features,\nnamely intelligence, open and standard interfaces, and closed control loop.\nInspired by this, in this article we provide a closed-loop and intelligent\nresource provisioning scheme for O-RAN slicing to prevent SLA violations. In\norder to maintain realism, a real-world dataset of a large operator is used to\ntrain a learning solution for optimizing resource utilization in the proposed\nclosed-loop service automation process. Moreover, the deployment architecture\nand the corresponding flow that are cognizant of the O-RAN requirements are\nalso discussed.",
    "descriptor": "\nComments: 7 pages, 3 figures, 1 table\n",
    "authors": [
      "Joseph Thaliath",
      "Solmaz Niknam",
      "Sukhdeep Singh",
      "Rahul Banerji",
      "Navrati Saxena",
      "Harpreet S. Dhillon",
      "Jeffrey H. Reed",
      "Ali Kashif Bashir",
      "Avinash Bhat",
      "Abhishek Roy"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.01966"
  },
  {
    "id": "arXiv:2202.01969",
    "title": "A Novel Assistive Controller Based on Differential Geometry for Users of  the Differential-Drive Wheeled Mobile Robots",
    "abstract": "Certain wheeled mobile robots e.g., electric wheelchairs, can operate through\nindirect joystick controls from users. Correct steering angle becomes essential\nwhen the user should determine the vehicle direction and velocity, in\nparticular for differential wheeled vehicles since the vehicle velocity and\ndirection are controlled with only two actuating wheels. This problem gets more\nchallenging when complex curves should be realized by the user. A novel\nassistive controller with safety constraints is needed to address these\nproblems. Also, the classic control methods mostly require the desired states\nbeforehand which completely contradicts human's spontaneous decisions on the\ndesired location to go. In this work, we develop a novel assistive control\nstrategy based on differential geometry relying on only joystick inputs and\nvehicle states where the controller does not require any desired states. We\nbegin with explaining the vehicle kinematics and our designed Darboux frame\nkinematics on a contact point of a virtual wheel and plane. Next, the geometric\ncontroller using the Darboux frame kinematics is designed for having smooth\ntrajectories under certain safety constraints. We experiment our approach with\ndifferent participants and evaluate its performance in various routes.",
    "descriptor": "\nComments: 10 pages, 12 figures, paper is accepted to 2022 International Conference on Robotics and Automation (ICRA 2022). This is the extended version\n",
    "authors": [
      "Seyed Amir Tafrishi",
      "Ankit A. Ravankar",
      "Jose Salazar",
      "Yasuhisa Hirata"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)",
      "Differential Geometry (math.DG)"
    ],
    "url": "https://arxiv.org/abs/2202.01969"
  },
  {
    "id": "arXiv:2202.01971",
    "title": "Aggregation Service for Federated Learning: An Efficient, Secure, and  More Resilient Realization",
    "abstract": "Federated learning has recently emerged as a paradigm promising the benefits\nof harnessing rich data from diverse sources to train high quality models, with\nthe salient features that training datasets never leave local devices. Only\nmodel updates are locally computed and shared for aggregation to produce a\nglobal model. While federated learning greatly alleviates the privacy concerns\nas opposed to learning with centralized data, sharing model updates still poses\nprivacy risks. In this paper, we present a system design which offers efficient\nprotection of individual model updates throughout the learning procedure,\nallowing clients to only provide obscured model updates while a cloud server\ncan still perform the aggregation. Our federated learning system first departs\nfrom prior works by supporting lightweight encryption and aggregation, and\nresilience against drop-out clients with no impact on their participation in\nfuture rounds. Meanwhile, prior work largely overlooks bandwidth efficiency\noptimization in the ciphertext domain and the support of security against an\nactively adversarial cloud server, which we also fully explore in this paper\nand provide effective and efficient mechanisms. Extensive experiments over\nseveral benchmark datasets (MNIST, CIFAR-10, and CelebA) show our system\nachieves accuracy comparable to the plaintext baseline, with practical\nperformance.",
    "descriptor": "\nComments: Accepted in IEEE Transactions on Dependable and Secure Computing (TDSC), 2022\n",
    "authors": [
      "Yifeng Zheng",
      "Shangqi Lai",
      "Yi Liu",
      "Xingliang Yuan",
      "Xun Yi",
      "Cong Wang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.01971"
  },
  {
    "id": "arXiv:2202.01972",
    "title": "Hybrid Neural Coded Modulation: Design and Training Methods",
    "abstract": "We propose a hybrid coded modulation scheme which composes of inner and outer\ncodes. The outer-code can be any standard binary linear code with efficient\nsoft decoding capability (e.g. low-density parity-check (LDPC) codes). The\ninner code is designed using a deep neural network (DNN) which takes the\nchannel coded bits and outputs modulated symbols. For training the DNN, we\npropose to use a loss function that is inspired by the generalized mutual\ninformation. The resulting constellations are shown to outperform the\nconventional quadrature amplitude modulation (QAM) based coding scheme for\nmodulation order 16 and 64 with 5G standard LDPC codes.",
    "descriptor": "",
    "authors": [
      "Sung Hoon Lim",
      "Jiyong Han",
      "Wonjong Noh",
      "Yujae Song",
      "Sang-Woon Jeon"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.01972"
  },
  {
    "id": "arXiv:2202.01980",
    "title": "Multi-Output Gaussian Process-Based Data Augmentation for Multi-Building  and Multi-Floor Indoor Localization",
    "abstract": "Location fingerprinting based on RSSI becomes a mainstream indoor\nlocalization technique due to its advantage of not requiring the installation\nof new infrastructure and the modification of existing devices, especially\ngiven the prevalence of Wi-Fi-enabled devices and the ubiquitous Wi-Fi access\nin modern buildings. The use of AI/ML technologies like DNNs makes location\nfingerprinting more accurate and reliable, especially for large-scale\nmulti-building and multi-floor indoor localization. The application of DNNs for\nindoor localization, however, depends on a large amount of preprocessed and\ndeliberately-labeled data for their training. Considering the difficulty of the\ndata collection in an indoor environment, especially under the current epidemic\nsituation of COVID-19, we investigate three different methods of RSSI data\naugmentation based on Multi-Output Gaussian Process (MOGP), i.e., by a single\nfloor, by neighboring floors, and by a single building; unlike Single-Output\nGaussian Process (SOGP), MOGP can take into account the correlation among RSSI\nobservations from multiple Access Points (APs) deployed closely to each other\n(e.g., APs on the same floor of a building) by collectively handling them. The\nfeasibility of the MOGP-based RSSI data augmentation is demonstrated through\nexperiments based on the state-of-the-art RNN indoor localization model and the\nUJIIndoorLoc, i.e., the most popular publicly-available multi-building and\nmulti-floor indoor localization database, where the RNN model trained with the\nUJIIndoorLoc database augmented by using the whole RSSI data of a building in\nfitting an MOGP model (i.e., by a single building) outperforms the other two\naugmentation methods as well as the RNN model trained with the original\nUJIIndoorLoc database, resulting in the mean three-dimensional positioning\nerror of 8.42 m.",
    "descriptor": "\nComments: 6 pages, 5 figures\n",
    "authors": [
      "Zhe Tang",
      "Sihao Li",
      "Kyeong Soo Kim",
      "Jeremy Smith"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.01980"
  },
  {
    "id": "arXiv:2202.01987",
    "title": "Robust Vector Quantized-Variational Autoencoder",
    "abstract": "Image generative models can learn the distributions of the training data and\nconsequently generate examples by sampling from these distributions. However,\nwhen the training dataset is corrupted with outliers, generative models will\nlikely produce examples that are also similar to the outliers. In fact, a small\nportion of outliers may induce state-of-the-art generative models, such as\nVector Quantized-Variational AutoEncoder (VQ-VAE), to learn a significant mode\nfrom the outliers. To mitigate this problem, we propose a robust generative\nmodel based on VQ-VAE, which we name Robust VQ-VAE (RVQ-VAE). In order to\nachieve robustness, RVQ-VAE uses two separate codebooks for the inliers and\noutliers. To ensure the codebooks embed the correct components, we iteratively\nupdate the sets of inliers and outliers during each training epoch. To ensure\nthat the encoded data points are matched to the correct codebooks, we quantize\nusing a weighted Euclidean distance, whose weights are determined by\ndirectional variances of the codebooks. Both codebooks, together with the\nencoder and decoder, are trained jointly according to the reconstruction loss\nand the quantization loss. We experimentally demonstrate that RVQ-VAE is able\nto generate examples from inliers even if a large portion of the training data\npoints are corrupted.",
    "descriptor": "",
    "authors": [
      "Chieh-Hsin Lai",
      "Dongmian Zou",
      "Gilad Lerman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.01987"
  },
  {
    "id": "arXiv:2202.01991",
    "title": "Projection-based Point Convolution for Efficient Point Cloud  Segmentation",
    "abstract": "Understanding point cloud has recently gained huge interests following the\ndevelopment of 3D scanning devices and the accumulation of large-scale 3D data.\nMost point cloud processing algorithms can be classified as either point-based\nor voxel-based methods, both of which have severe limitations in processing\ntime or memory, or both. To overcome these limitations, we propose\nProjection-based Point Convolution (PPConv), a point convolutional module that\nuses 2D convolutions and multi-layer perceptrons (MLPs) as its components. In\nPPConv, point features are processed through two branches: point branch and\nprojection branch. Point branch consists of MLPs, while projection branch\ntransforms point features into a 2D feature map and then apply 2D convolutions.\nAs PPConv does not use point-based or voxel-based convolutions, it has\nadvantages in fast point cloud processing. When combined with a learnable\nprojection and effective feature fusion strategy, PPConv achieves superior\nefficiency compared to state-of-the-art methods, even with a simple\narchitecture based on PointNet++. We demonstrate the efficiency of PPConv in\nterms of the trade-off between inference time and segmentation performance. The\nexperimental results on S3DIS and ShapeNetPart show that PPConv is the most\nefficient method among the compared ones. The code is available at\ngithub.com/pahn04/PPConv.",
    "descriptor": "\nComments: Published in IEEE Access (Early Access)\n",
    "authors": [
      "Pyunghwan Ahn",
      "Juyoung Yang",
      "Eojindl Yi",
      "Chanho Lee",
      "Junmo Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.01991"
  },
  {
    "id": "arXiv:2202.01993",
    "title": "Grounding Answers for Visual Questions Asked by Visually Impaired People",
    "abstract": "Visual question answering is the task of answering questions about images. We\nintroduce the VizWiz-VQA-Grounding dataset, the first dataset that visually\ngrounds answers to visual questions asked by people with visual impairments. We\nanalyze our dataset and compare it with five VQA-Grounding datasets to\ndemonstrate what makes it similar and different. We then evaluate the SOTA VQA\nand VQA-Grounding models and demonstrate that current SOTA algorithms often\nfail to identify the correct visual evidence where the answer is located. These\nmodels regularly struggle when the visual evidence occupies a small fraction of\nthe image, for images that are higher quality, as well as for visual questions\nthat require skills in text recognition. The dataset, evaluation server, and\nleaderboard all can be found at the following link:\nhttps://vizwiz.org/tasks-and-datasets/answer-grounding-for-vqa/.",
    "descriptor": "\nComments: Computer Vision and Pattern Recognition\n",
    "authors": [
      "Chongyan Chen",
      "Samreen Anjum",
      "Danna Gurari"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.01993"
  },
  {
    "id": "arXiv:2202.01994",
    "title": "Data Scaling Laws in NMT: The Effect of Noise and Architecture",
    "abstract": "In this work, we study the effect of varying the architecture and training\ndata quality on the data scaling properties of Neural Machine Translation\n(NMT). First, we establish that the test loss of encoder-decoder transformer\nmodels scales as a power law in the number of training samples, with a\ndependence on the model size. Then, we systematically vary aspects of the\ntraining setup to understand how they impact the data scaling laws. In\nparticular, we change the following (1) Architecture and task setup: We compare\nto a transformer-LSTM hybrid, and a decoder-only transformer with a language\nmodeling loss (2) Noise level in the training distribution: We experiment with\nfiltering, and adding iid synthetic noise. In all the above cases, we find that\nthe data scaling exponents are minimally impacted, suggesting that marginally\nworse architectures or training data can be compensated for by adding more\ndata. Lastly, we find that using back-translated data instead of parallel data,\ncan significantly degrade the scaling exponent.",
    "descriptor": "",
    "authors": [
      "Yamini Bansal",
      "Behrooz Ghorbani",
      "Ankush Garg",
      "Biao Zhang",
      "Maxim Krikun",
      "Colin Cherry",
      "Behnam Neyshabur",
      "Orhan Firat"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.01994"
  },
  {
    "id": "arXiv:2202.01997",
    "title": "Semi-Supervised Trajectory-Feedback Controller Synthesis for Signal  Temporal Logic Specifications",
    "abstract": "There are spatio-temporal rules that dictate how robots should operate in\ncomplex environments, e.g., road rules govern how (self-driving) vehicles\nshould behave on the road. However, seamlessly incorporating such rules into a\nrobot control policy remains challenging especially for real-time applications.\nIn this work, given a desired spatio-temporal specification expressed in the\nSignal Temporal Logic (STL) language, we propose a semi-supervised controller\nsynthesis technique that is attuned to human-like behaviors while satisfying\ndesired STL specifications. Offline, we synthesize a trajectory-feedback neural\nnetwork controller via an adversarial training scheme that summarizes past\nspatio-temporal behaviors when computing controls, and then online, we perform\ngradient steps to improve specification satisfaction. Central to the offline\nphase is an imitation-based regularization component that fosters better policy\nexploration and helps induce naturalistic human behaviors. Our experiments\ndemonstrate that having imitation-based regularization leads to higher\nqualitative and quantitative performance compared to optimizing an STL\nobjective only as done in prior work. We demonstrate the efficacy of our\napproach with an illustrative case study and show that our proposed controller\noutperforms a state-of-the-art shooting method in both performance and\ncomputation time.",
    "descriptor": "\nComments: Accepted to American Controls Conference 2022\n",
    "authors": [
      "Karen Leung",
      "Marco Pavone"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.01997"
  },
  {
    "id": "arXiv:2202.01999",
    "title": "Neural Dual Contouring",
    "abstract": "We introduce neural dual contouring (NDC), a new data-driven approach to mesh\nreconstruction based on dual contouring (DC). Like traditional DC, it produces\nexactly one vertex per grid cell and one quad for each grid edge intersection,\na natural and efficient structure for reproducing sharp features. However,\nrather than computing vertex locations and edge crossings with hand-crafted\nfunctions that depend directly on difficult-to-obtain surface gradients, NDC\nuses a neural network to predict them. As a result, NDC can be trained to\nproduce meshes from signed or unsigned distance fields, binary voxel grids, or\npoint clouds (with or without normals); and it can produce open surfaces in\ncases where the input represents a sheet or partial surface. During experiments\nwith five prominent datasets, we find that NDC, when trained on one of the\ndatasets, generalizes well to the others. Furthermore, NDC provides better\nsurface reconstruction accuracy, feature preservation, output complexity,\ntriangle quality, and inference time in comparison to previous learned (e.g.,\nneural marching cubes, convolutional occupancy networks) and traditional (e.g.,\nPoisson) methods.",
    "descriptor": "",
    "authors": [
      "Zhiqin Chen",
      "Andrea Tagliasacchi",
      "Thomas Funkhouser",
      "Hao Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.01999"
  },
  {
    "id": "arXiv:2202.02001",
    "title": "Introducing Block-Toeplitz Covariance Matrices to Remaster Linear  Discriminant Analysis for Event-related Potential Brain-computer Interfaces",
    "abstract": "Covariance matrices of noisy multichannel electroencephalogram time series\ndata are hard to estimate due to high dimensionality. In brain-computer\ninterfaces (BCI) based on event-related potentials and a linear discriminant\nanalysis (LDA) for classification, the state of the art to address this problem\nis by shrinkage regularization. We propose a novel idea to tackle this problem\nby enforcing a block-Toeplitz structure for the covariance matrix of the LDA,\nwhich implements an assumption of signal stationarity in short time windows for\neach channel. On data of 213 subjects collected under 13 event-related\npotential BCI protocols, the resulting 'ToeplitzLDA' significantly increases\nthe binary classification performance compared to shrinkage regularized LDA (up\nto 6 AUC points) and Riemannian classification approaches (up to 2 AUC points).\nThis translates to greatly improved application level performances, as\nexemplified on data recorded during an unsupervised visual speller application,\nwhere spelling errors could be reduced by 81% on average for 25 subjects. Aside\nfrom lower memory and time complexity for LDA training, ToeplitzLDA proved to\nbe almost invariant even to a twenty-fold time dimensionality enlargement,\nwhich reduces the need of expert knowledge regarding feature extraction.",
    "descriptor": "",
    "authors": [
      "Jan Sosulski",
      "Michael Tangermann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2202.02001"
  },
  {
    "id": "arXiv:2202.02002",
    "title": "The devil is in the labels: Semantic segmentation from sentences",
    "abstract": "We propose an approach to semantic segmentation that achieves\nstate-of-the-art supervised performance when applied in a zero-shot setting. It\nthus achieves results equivalent to those of the supervised methods, on each of\nthe major semantic segmentation datasets, without training on those datasets.\nThis is achieved by replacing each class label with a vector-valued embedding\nof a short paragraph that describes the class. The generality and simplicity of\nthis approach enables merging multiple datasets from different domains, each\nwith varying class labels and semantics. The resulting merged semantic\nsegmentation dataset of over 2 Million images enables training a model that\nachieves performance equal to that of state-of-the-art supervised methods on 7\nbenchmark datasets, despite not using any images therefrom. By fine-tuning the\nmodel on standard semantic segmentation datasets, we also achieve a significant\nimprovement over the state-of-the-art supervised segmentation on NYUD-V2 and\nPASCAL-context at 60% and 65% mIoU, respectively. Based on the closeness of\nlanguage embeddings, our method can even segment unseen labels. Extensive\nexperiments demonstrate strong generalization to unseen image domains and\nunseen labels, and that the method enables impressive performance improvements\nin downstream applications, including depth estimation and instance\nsegmentation.",
    "descriptor": "\nComments: 18 pages\n",
    "authors": [
      "Wei Yin",
      "Yifan Liu",
      "Chunhua Shen",
      "Anton van den Hengel",
      "Baichuan Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.02002"
  },
  {
    "id": "arXiv:2202.02003",
    "title": "Capturing and incorporating expert knowledge into machine learning  models for quality prediction in manufacturing",
    "abstract": "Increasing digitalization enables the use of machine learning methods for\nanalyzing and optimizing manufacturing processes. A main application of machine\nlearning is the construction of quality prediction models, which can be used,\namong other things, for documentation purposes, as assistance systems for\nprocess operators, or for adaptive process control. The quality of such machine\nlearning models typically strongly depends on the amount and the quality of\ndata used for training. In manufacturing, the size of available datasets before\nstart of production is often limited. In contrast to data, expert knowledge\ncommonly is available in manufacturing. Therefore, this study introduces a\ngeneral methodology for building quality prediction models with machine\nlearning methods on small datasets by integrating shape expert knowledge, that\nis, prior knowledge about the shape of the input-output relationship to be\nlearned. The proposed methodology is applied to a brushing process with $125$\ndata points for predicting the surface roughness as a function of five process\nvariables. As opposed to conventional machine learning methods for small\ndatasets, the proposed methodology produces prediction models that strictly\ncomply with all the expert knowledge specified by the involved process\nspecialists. In particular, the direct involvement of process experts in the\ntraining of the models leads to a very clear interpretation and, by extension,\nto a high acceptance of the models. Another merit of the proposed methodology\nis that, in contrast to most conventional machine learning methods, it involves\nno time-consuming and often heuristic hyperparameter tuning or model selection\nstep.",
    "descriptor": "\nComments: 22 pages, 9 figures\n",
    "authors": [
      "Patrick Link",
      "Miltiadis Poursanidis",
      "Jochen Schmid",
      "Rebekka Zache",
      "Martin von Kurnatowski",
      "Uwe Teicher",
      "Steffen Ihlenfeldt"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.02003"
  },
  {
    "id": "arXiv:2202.02005",
    "title": "BC-Z: Zero-Shot Task Generalization with Robotic Imitation Learning",
    "abstract": "In this paper, we study the problem of enabling a vision-based robotic\nmanipulation system to generalize to novel tasks, a long-standing challenge in\nrobot learning. We approach the challenge from an imitation learning\nperspective, aiming to study how scaling and broadening the data collected can\nfacilitate such generalization. To that end, we develop an interactive and\nflexible imitation learning system that can learn from both demonstrations and\ninterventions and can be conditioned on different forms of information that\nconvey the task, including pre-trained embeddings of natural language or videos\nof humans performing the task. When scaling data collection on a real robot to\nmore than 100 distinct tasks, we find that this system can perform 24 unseen\nmanipulation tasks with an average success rate of 44%, without any robot\ndemonstrations for those tasks.",
    "descriptor": "\nComments: CoRL 2021, 23 pages\n",
    "authors": [
      "Eric Jang",
      "Alex Irpan",
      "Mohi Khansari",
      "Daniel Kappler",
      "Frederik Ebert",
      "Corey Lynch",
      "Sergey Levine",
      "Chelsea Finn"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.02005"
  },
  {
    "id": "arXiv:2202.02006",
    "title": "5G Network on Wings: A Deep Reinforcement Learning Approach to UAV-based  Integrated Access and Backhaul",
    "abstract": "Fast and reliable wireless communication has become a critical demand in\nhuman life. When natural disasters strike, providing ubiquitous connectivity\nbecomes challenging by using traditional wireless networks. In this context,\nunmanned aerial vehicle (UAV) based aerial networks offer a promising\nalternative for fast, flexible, and reliable wireless communications in\nmission-critical (MC) scenarios. Due to the unique characteristics such as\nmobility, flexible deployment, and rapid reconfiguration, drones can readily\nchange location dynamically to provide on-demand communications to users on the\nground in emergency scenarios. As a result, the usage of UAV base stations\n(UAV-BSs) has been considered as an appropriate approach for providing rapid\nconnection in MC scenarios. In this paper, we study how to control a UAV-BS in\nboth static and dynamic environments. We investigate a situation in which a\nmacro BS is destroyed as a result of a natural disaster and a UAV-BS is\ndeployed using integrated access and backhaul (IAB) technology to provide\ncoverage for users in the disaster area. We present a data collection system,\nsignaling procedures and machine learning applications for this use case. A\ndeep reinforcement learning algorithm is developed to jointly optimize the tilt\nof the access and backhaul antennas of the UAV-BS as well as its\nthree-dimensional placement. Evaluation results show that the proposed\nalgorithm can autonomously navigate and configure the UAV-BS to satisfactorily\nserve the MC users on the ground.",
    "descriptor": "",
    "authors": [
      "Hongyi Zhang",
      "Jingya Li",
      "Zhiqiang Qi",
      "Xingqin Lin",
      "Anders Aronsson",
      "Jan Bosch",
      "Helena Holmstr\u00f6m Olsson"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.02006"
  },
  {
    "id": "arXiv:2202.02010",
    "title": "Globally Minimal Defensive Alliances: A Parameterized Perspective",
    "abstract": "A defensive alliance in an undirected graph $G=(V,E)$ is a non-empty set of\nvertices $S$ satisfying the condition that every vertex $v\\in S$ has at least\nas many neighbours (including itself) in $S$ as it has in $V\\setminus S$. We\nconsider the notion of global minimality in this paper. We are interested in\nglobally minimal defensive alliance of maximum size. This problem is known to\nbe NP-hard but its parameterized complexity remains open until now. We enhance\nour understanding of the problem from the viewpoint of parameterized complexity\nby showing that the Globally Minimal Defensive Alliance problem is FPT\nparameterized by the neighbourhood diversity of the input graph. The result for\nneighborhood diversity implies that the problem is FPT parameterized by vertex\ncover number also. We prove that the problem parameterized by the vertex cover\nnumber of the input graph does not admit a polynomial compression unless coNP\n$\\subseteq$ NP/poly. We show that the problem is W[1]-hard parameterized by a\nwide range of fairly restrictive structural parameters such as the feedback\nvertex set number, pathwidth, treewidth and treedepth. We also proved that,\ngiven a vertex $r \\in V(G)$, deciding if $G$ has a globally minimal defensive\nalliance of any size containing vertex $r$ is NP-complete.",
    "descriptor": "",
    "authors": [
      "Ajinkya Gaikwad",
      "Soumen Maity"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2202.02010"
  },
  {
    "id": "arXiv:2202.02013",
    "title": "A Benchmark Corpus for the Detection of Automatically Generated Text in  Academic Publications",
    "abstract": "Automatic text generation based on neural language models has achieved\nperformance levels that make the generated text almost indistinguishable from\nthose written by humans. Despite the value that text generation can have in\nvarious applications, it can also be employed for malicious tasks. The\ndiffusion of such practices represent a threat to the quality of academic\npublishing. To address these problems, we propose in this paper two datasets\ncomprised of artificially generated research content: a completely synthetic\ndataset and a partial text substitution dataset. In the first case, the content\nis completely generated by the GPT-2 model after a short prompt extracted from\noriginal papers. The partial or hybrid dataset is created by replacing several\nsentences of abstracts with sentences that are generated by the Arxiv-NLP\nmodel. We evaluate the quality of the datasets comparing the generated texts to\naligned original texts using fluency metrics such as BLEU and ROUGE. The more\nnatural the artificial texts seem, the more difficult they are to detect and\nthe better is the benchmark. We also evaluate the difficulty of the task of\ndistinguishing original from generated text by using state-of-the-art\nclassification models.",
    "descriptor": "\nComments: 9 pages including references, submitted to LREC 2022. arXiv admin note: text overlap with arXiv:2110.10577 by other authors\n",
    "authors": [
      "Vijini Liyanage",
      "Davide Buscaldi",
      "Adeline Nazarenko"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.02013"
  },
  {
    "id": "arXiv:2202.02015",
    "title": "Energy-Efficient High-Accuracy Spiking Neural Network Inference Using  Time-Domain Neurons",
    "abstract": "Due to the limitations of realizing artificial neural networks on prevalent\nvon Neumann architectures, recent studies have presented neuromorphic systems\nbased on spiking neural networks (SNNs) to reduce power and computational cost.\nHowever, conventional analog voltage-domain integrate-and-fire (I&F) neuron\ncircuits, based on either current mirrors or op-amps, pose serious issues such\nas nonlinearity or high power consumption, thereby degrading either inference\naccuracy or energy efficiency of the SNN. To achieve excellent energy\nefficiency and high accuracy simultaneously, this paper presents a low-power\nhighly linear time-domain I&F neuron circuit. Designed and simulated in a 28nm\nCMOS process, the proposed neuron leads to more than 4.3x lower error rate on\nthe MNIST inference over the conventional current-mirror-based neurons. In\naddition, the power consumed by the proposed neuron circuit is simulated to be\n0.230uW per neuron, which is orders of magnitude lower than the existing\nvoltage-domain neurons.",
    "descriptor": "",
    "authors": [
      "Joonghyun Song",
      "Jiwon Shin",
      "Hanseok Kim",
      "Woo-Seok Choi"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.02015"
  },
  {
    "id": "arXiv:2202.02016",
    "title": "Identifiability of Label Noise Transition Matrix",
    "abstract": "The noise transition matrix plays a central role in the problem of learning\nfrom noisy labels. Among many other reasons, a significant number of existing\nsolutions rely on access to it. Estimating the transition matrix without using\nground truth labels is a critical and challenging task. When label noise\ntransition depends on each instance, the problem of identifying the\ninstance-dependent noise transition matrix becomes substantially more\nchallenging. Despite recent works proposing solutions for learning from\ninstance-dependent noisy labels, we lack a unified understanding of when such a\nproblem remains identifiable, and therefore learnable. This paper seeks to\nprovide answers to a sequence of related questions: What are the primary\nfactors that contribute to the identifiability of a noise transition matrix?\nCan we explain the observed empirical successes? When a problem is not\nidentifiable, what can we do to make it so? We will relate our theoretical\nfindings to the literature and hope to provide guidelines for developing\neffective solutions for battling instance-dependent label noise.",
    "descriptor": "\nComments: Preprint\n",
    "authors": [
      "Yang Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.02016"
  },
  {
    "id": "arXiv:2202.02018",
    "title": "Image-to-Image MLP-mixer for Image Reconstruction",
    "abstract": "Neural networks are highly effective tools for image reconstruction problems\nsuch as denoising and compressive sensing. To date, neural networks for image\nreconstruction are almost exclusively convolutional. The most popular\narchitecture is the U-Net, a convolutional network with a multi-resolution\narchitecture. In this work, we show that a simple network based on the\nmulti-layer perceptron (MLP)-mixer enables state-of-the art image\nreconstruction performance without convolutions and without a multi-resolution\narchitecture, provided that the training set and the size of the network are\nmoderately large. Similar to the original MLP-mixer, the image-to-image\nMLP-mixer is based exclusively on MLPs operating on linearly-transformed image\npatches. Contrary to the original MLP-mixer, we incorporate structure by\nretaining the relative positions of the image patches. This imposes an\ninductive bias towards natural images which enables the image-to-image\nMLP-mixer to learn to denoise images based on fewer examples than the original\nMLP-mixer. Moreover, the image-to-image MLP-mixer requires fewer parameters to\nachieve the same denoising performance than the U-Net and its parameters scale\nlinearly in the image resolution instead of quadratically as for the original\nMLP-mixer. If trained on a moderate amount of examples for denoising, the\nimage-to-image MLP-mixer outperforms the U-Net by a slight margin. It also\noutperforms the vision transformer tailored for image reconstruction and\nclassical un-trained methods such as BM3D, making it a very effective tool for\nimage reconstruction problems.",
    "descriptor": "",
    "authors": [
      "Youssef Mansour",
      "Kang Lin",
      "Reinhard Heckel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2202.02018"
  },
  {
    "id": "arXiv:2202.02030",
    "title": "On the role of technology in human-dog relationships: a future filled  with dreams or nightmares?",
    "abstract": "Digital technologies that help us take care of our dogs are becoming more\nwidespread. Yet, little research explores what the role of technology in the\nhuman-dog relationship should be. We conducted a mixed-method study\nincorporating quantitative and qualitative thematic analysis of 155 UK dog\nowners reflecting on their daily routines and technology's role in it,\ndisentangling the what-where-why of interspecies routines and activities,\ntechnological desires, and rationales for technological support across common\nhuman-dog activities. We found that increasingly entangled daily routines lead\nto close multi-species households where dog owners conceptualize technology as\nhaving a role to support them in giving care to their dogs. When confronted\nwith the role of technology across various activities, only chores like\ncleaning up after our dogs lead to largely positive considerations, while\nactivities that benefit us like walking together lead to largely negative\nconsiderations. For other activities, whether playing, training, or feeding,\nattitudes remain diverse. In general, across all activities both a nightmare\nscenario of technology taking the human's role and in doing so disentangling\nthe human-dog bond, as well as a dream scenario of technology augmenting our\nabilities arise. We argue that the current trajectory of digital technology for\npets towards allowing dog owners to interact with their dogs while away\n(feeding, playing, and so on) is an example of this nightmare scenario becoming\nreality, and that it is important to redirect this trajectory to one of\ntechnology predominantly supporting us in becoming better and more informed\ncaregivers.",
    "descriptor": "",
    "authors": [
      "Dirk van der Linden",
      "Brittany I. Davidson",
      "Orit Hirsch-Matsioulas",
      "Anna Zamansky"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2202.02030"
  },
  {
    "id": "arXiv:2202.02038",
    "title": "Perspectives of Visualization Onboarding and Guidance in VA",
    "abstract": "A typical problem in Visual Analytics is that users are highly trained\nexperts in their application domains, but have mostly no experience in using VA\nsystems. Thus, users often have difficulties interpreting and working with\nvisual representations. To overcome these problems, user assistance can be\nincorporated into VA systems to guide experts through the analysis while\nclosing their knowledge gaps. Different types of user assistance can be applied\nto extend the power of VA, enhance the user's experience, and broaden the\naudience for VA. Although different approaches to visualization onboarding and\nguidance in VA already exist, there is a lack of research on how to design and\nintegrate them in effective and efficient ways. Therefore, we aim at putting\ntogether the pieces of the mosaic to form a coherent whole. Based on the\nKnowledge-Assisted Visual Analytics model, we contribute a conceptual model of\nuser assistance for VA by integrating the process of visualization onboarding\nand guidance as the two main approaches in this direction. As a result, we\nclarify and discuss the commonalities and differences between visualization\nonboarding and guidance, and discuss how they benefit from the integration of\nknowledge extraction and exploration. Finally, we discuss our descriptive model\nby applying it to VA tools integrating visualization onboarding and guidance,\nand showing how they should be utilized in different phases of the analysis in\norder to be effective and accepted by the user.",
    "descriptor": "\nComments: Elsevier Visual Informatics (revised version under review)\n",
    "authors": [
      "Christina Stoiber",
      "Davide Ceneda",
      "Markus Wagner",
      "Victor Schetinger",
      "Theresia Gschwandtner",
      "Marc Streit",
      "Silvia Miksch",
      "Wolfgang Aigner"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2202.02038"
  },
  {
    "id": "arXiv:2202.02043",
    "title": "With a Little Help from My Friends: Transport Deniability for Instant  Messaging",
    "abstract": "Traffic analysis for instant messaging (IM) applications continues to pose an\nimportant privacy challenge. In particular, transport-level data can leak\nunintentional information about IM -- such as who communicates with whom.\nExisting tools for metadata privacy have adoption obstacles, including the\nrisks of being scrutinized for having a particular app installed, and\nperformance overheads incompatible with mobile devices.\nWe posit that resilience to traffic analysis must be directly supported by\nmajor IM services themselves, and must be done in a low-cost manner without\nbreaking existing features. As a first step in this direction, we propose a\nhybrid messaging model that combines regular and deniable messages. We present\na novel protocol for deniable instant messaging, which we call DenIM. DenIM is\nbuilt on the principle that deniable messages can be made indistinguishable\nfrom regular messages with a little help from a user's friends. Deniable\nmessages' network traffic can then be explained by a plausible cover story.\nDenIM achieves overhead proportional to the messages sent, as opposed to\nscaling with time or number of users. To show the effectiveness of DenIM, we\nimplement a trace simulator, and show that DenIM's deniability guarantees hold\nagainst strong adversaries such as internet service providers.",
    "descriptor": "",
    "authors": [
      "Boel Nelson",
      "Aslan Askarov"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.02043"
  },
  {
    "id": "arXiv:2202.02046",
    "title": "A Framework for Loop and Path Puzzle Satisfiability NP-Hardness Results",
    "abstract": "Building on the results published in arxiv:2004.12849 we present a general\nframework for demonstrating the NP-hardness of satisfying many genres of loop\nand path puzzles using a 'T-metacell' gadget. We then use this to prove the\nNP-completeness of a variety of such genres, and discuss some of the\nlimitations of this gadget.",
    "descriptor": "\nComments: 40 pages, 67 figures\n",
    "authors": [
      "Hadyn Tang"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2202.02046"
  },
  {
    "id": "arXiv:2202.02053",
    "title": "SummaryLens -- A Smartphone App for Exploring Interactive Use of  Automated Text Summarization in Everyday Life",
    "abstract": "We present SummaryLens, a concept and prototype for a mobile tool that\nleverages automated text summarization to enable users to quickly scan and\nsummarize physical text documents. We further combine this with a\ntext-to-speech system to read out the summary on demand. With this concept, we\npropose and explore a concrete application case of bringing ongoing progress in\nAI and Natural Language Processing to a broad audience with interactive use\ncases in everyday life. Based on our implemented features, we describe a set of\npotential usage scenarios and benefits, including support for low-vision,\nlow-literate and dyslexic users. A first usability study shows that the\ninteractive use of automated text summarization in everyday life has noteworthy\npotential. We make the prototype available as an open-source project to\nfacilitate further research on such tools.",
    "descriptor": "\nComments: 4 pages, 1 figure, ACM IUI 2022 Companion\n",
    "authors": [
      "Karim Benharrak",
      "Florian Lehmann",
      "Hai Dang",
      "Daniel Buschek"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2202.02053"
  },
  {
    "id": "arXiv:2202.02056",
    "title": "Twitter Referral Behaviours on News Consumption with Ensemble Clustering  of Click-Stream Data in Turkish Media",
    "abstract": "Click-stream data, which comes with a massive volume generated by the human\nactivities on the websites, has become a prominent feature to identify readers'\ncharacteristics by the newsrooms after the digitization of the news outlets. It\nis essential to have elastic architectures to process the streaming data,\nparticularly for unprecedented traffic, enabling conducting more comprehensive\nanalyses such as recommending mostly related articles to the readers. Although\nthe nature of click-stream data has a similar logic within the websites, it has\ninherent limitations to recognize human behaviors when looking from a broad\nperspective, which brings the need of limiting the problem in niche areas. This\nstudy investigates the anonymized readers' click activities in the\norganizations' websites to identify news consumption patterns following\nreferrals from Twitter, who incidentally reach but propensity is mainly the\nrouted news content. The investigation is widened to a broad perspective by\nlinking the log data with news content to enrich the insights rather than\nsticking into the web journey. The methodologies on ensemble cluster analysis\nwith mixed-type embedding strategies are applied and compared to find similar\nreader groups and interests independent from time. Our results demonstrate that\nthe quality of clustering mixed-type data set approaches to optimal internal\nvalidation scores when embedded by Uniform Manifold Approximation and\nProjection (UMAP) and using consensus function as a key to access the most\napplicable hyper parameter configurations in the given ensemble rather than\nusing consensus function results directly. Evaluation of the resulting clusters\nhighlights specific clusters repeatedly present in the samples, which provide\ninsights to the news organizations and overcome the degradation of the modeling\nbehaviors due to the change in the interest over time.",
    "descriptor": "\nComments: Submitted to Expert Systems with Applications\n",
    "authors": [
      "Didem Makaroglu",
      "Altan Cakir",
      "Behcet Ugur Toreyin"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.02056"
  },
  {
    "id": "arXiv:2202.02057",
    "title": "Grid-Forming Control Design of Dynamic Virtual Power Plants",
    "abstract": "We present a novel grid-forming control design approach for dynamic virtual\npower plants. We consider a group of heterogeneous grid-forming distributed\nenergy resources which collectively provide desired dynamic ancillary services\nsuch as fast frequency and voltage control. To achieve that, we employ an\nadaptive divide-and-conquer strategy which disaggregates the desired control\nspecifications of the aggregate DVPP via adaptive dynamic participation factors\nto obtain local desired behaviors of each device. We then employ local controls\nto realize these desired behaviors. In the process, we ensure that local device\nlimitations are taken into account. Finally, the control performance is\nverified via simulations on a power system testbed.",
    "descriptor": "\nComments: 4 pages, 8 figures\n",
    "authors": [
      "Verena H\u00e4berle",
      "Eduardo Prieto-Araujo",
      "Ali Tayyebi",
      "Florian D\u00f6rfler"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.02057"
  },
  {
    "id": "arXiv:2202.02058",
    "title": "Equivariant Filter Design for Inertial Navigation Systems with Input  Measurement Biases",
    "abstract": "Inertial Navigation Systems (INS) are a key technology for autonomous\nvehicles applications. Recent advances in estimation and filter design for the\nINS problem have exploited geometry and symmetry to overcome limitations of the\nclassical Extended Kalman Filter (EKF) approach that formed the mainstay of INS\nsystems since the mid-twentieth century. The industry standard INS filter, the\nMultiplicative Extended Kalman Filter (MEKF), uses a geometric construction for\nattitude estimation coupled with classical Euclidean construction for position,\nvelocity and bias estimation. The recent Invariant Extended Kalman Filter\n(IEKF) provides a geometric framework for the full navigation states,\nintegrating attitude, position and velocity, but still uses the classical\nEuclidean construction to model the bias states. In this paper, we use the\nrecently proposed Equivariant Filter (EqF) framework to derive a novel observer\nfor biased inertial-based navigation in a fully geometric framework. The\nintroduction of virtual velocity inputs with associated virtual bias leads to a\nfull equivariant symmetry on the augmented system. The resulting filter\nperformance is evaluated with both simulated and real-world data, and\ndemonstrates increased robustness to a wide range of erroneous initial\nconditions, and improved accuracy when compared with the industry standard\nMultiplicative EKF (MEKF) approach.",
    "descriptor": "",
    "authors": [
      "Alessandro Fornasier",
      "Yonhon Ng",
      "Robert Mahony",
      "Stephan Weiss"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.02058"
  },
  {
    "id": "arXiv:2202.02061",
    "title": "Monoidal Streams for Dataflow Programming",
    "abstract": "We introduce monoidal streams: a generalization of causal stream functions to\nmonoidal categories. In the same way that streams provide semantics to dataflow\nprogramming with pure functions, monoidal streams provide semantics to dataflow\nprogramming with theories of processes represented by a symmetric monoidal\ncategory. At the same time, monoidal streams form a feedback monoidal category,\nwhich can be used to interpret signal flow graphs. As an example, we study a\nstochastic dataflow language.",
    "descriptor": "\nComments: Draft, 36 pages\n",
    "authors": [
      "Elena Di Lavore",
      "Giovanni de Felice",
      "Mario Rom\u00e1n"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Programming Languages (cs.PL)",
      "Category Theory (math.CT)"
    ],
    "url": "https://arxiv.org/abs/2202.02061"
  },
  {
    "id": "arXiv:2202.02063",
    "title": "Color Image Inpainting via Robust Pure Quaternion Matrix Completion:  Error Bound and Weighted Loss",
    "abstract": "In this paper, we study color image inpainting as a pure quaternion matrix\ncompletion problem. In the literature, the theoretical guarantee for quaternion\nmatrix completion is not well-established. Our main aim is to propose a new\nminimization problem with an objective combining nuclear norm and a quadratic\nloss weighted among three channels. To fill the theoretical vacancy, we obtain\nthe error bound in both clean and corrupted regimes, which relies on some new\nresults of quaternion matrices. A general Gaussian noise is considered in\nrobust completion where all observations are corrupted. Motivated by the error\nbound, we propose to handle unbalanced or correlated noise via a cross-channel\nweight in the quadratic loss, with the main purpose of rebalancing noise level,\nor removing noise correlation. Extensive experimental results on synthetic and\ncolor image data are presented to confirm and demonstrate our theoretical\nfindings.",
    "descriptor": "",
    "authors": [
      "Junren Chen",
      "Michael K. Ng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2202.02063"
  },
  {
    "id": "arXiv:2202.02067",
    "title": "An exponentially convergent discretization for space-time fractional  parabolic equations using $hp$-FEM",
    "abstract": "We consider a space-time fractional parabolic problem. Combining a\nsinc-quadrature based method for discretizing the Riesz-Dunford integral with\n$hp$-FEM in space yields an exponentially convergent scheme for the initial\nboundary value problem with homogeneous right-hand side. For the inhomogeneous\nproblem, an $hp$-quadrature scheme is implemented. We rigorously prove\nexponential convergence with focus on small times $t$, proving robustness with\nrespect to startup singularities due to data incompatibilities.",
    "descriptor": "",
    "authors": [
      "Jens Markus Melenk",
      "Alexander Rieder"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.02067"
  },
  {
    "id": "arXiv:2202.02068",
    "title": "Well-balanced adaptive compact approximate Taylor methods for systems of  balance laws",
    "abstract": "Compact Approximate Taylor (CAT) methods for systems of conservation laws\nwere introduced by Carrillo and Pares in 2019. These methods, based on a\nstrategy that allows one to extend high-order Lax-Wendroff methods to nonlinear\nsystems without using the Cauchy-Kovalevskaya procedure, have arbitrary even\norder of accuracy 2p and use (2p + 1)-point stencils, where p is an arbitrary\npositive integer. More recently in 2021 Carrillo, Macca, Pares, Russo and Zorio\nintroduced a strategy to get rid of the spurious oscillations close to\ndiscontinuities produced by CAT methods. This strategy led to the so-called\nAdaptive CAT (ACAT) methods, in which the order of accuracy, and thus the width\nof the stencils, is adapted to the local smoothness of the solution. The goal\nof this paper is to extend CAT and ACAT methods to systems of balance laws. To\ndo this, the source term is written as the derivative of its indefinite\nintegral that is formally treated as a flux function. The well-balanced\nproperty of the methods is discussed and a variant that allows in principle to\npreserve any stationary solution is presented. The resulting methods are then\napplied to a number of systems going from a linear scalar conservation law to\nthe 2D Euler equations with gravity, passing by the Burgers equations with\nsource term and the 1D shallow water equations: the order and well-balanced\nproperties are checked in several numerical tests.",
    "descriptor": "",
    "authors": [
      "H. Carrillo",
      "E. Macca",
      "C. Pares",
      "G. Russo"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.02068"
  },
  {
    "id": "arXiv:2202.02069",
    "title": "Beware of Greeks bearing entanglement? Quantum covert channels,  information flow and non-local games",
    "abstract": "Can quantum entanglement increase the capacity of (classical) covert\nchannels? To one familiar with Holevo's Theorem it is tempting to think that\nthe answer is obviously no. However, in this work we show: quantum entanglement\ncan in fact increase the capacity of a classical covert channel, in the\npresence of an active adversary; on the other hand, a zero-capacity channel is\nnot improved by entanglement, so entanglement cannot create `purely quantum'\ncovert channels; the problem of determining the capacity of a given channel in\nthe presence of entanglement is undecidable; but there is an algorithm to bound\nthe entangled capacity of a channel from above, adapted from the semi-definite\nhierarchy from the theory of non-local games, whose close connection to channel\ncapacity is at the core of all of our results.",
    "descriptor": "\nComments: 35th IEEE Symposium on Computer Security Foundations (CSF 2022)\n",
    "authors": [
      "David Mestel"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2202.02069"
  },
  {
    "id": "arXiv:2202.02070",
    "title": "CGS-Net: Aggregating Colour, Geometry and Semantic Features for  Large-Scale Indoor Place Recognition",
    "abstract": "We describe an approach to large-scale indoor place recognition that\naggregates low-level colour and geometric features with high-level semantic\nfeatures. We use a deep learning network that takes in RGB point clouds and\nextracts local features with five 3-D kernel point convolutional (KPConv)\nlayers. We specifically train the KPConv layers on the semantic segmentation\ntask to ensure that the extracted local features are semantically meaningful.\nThen, feature maps from all the five KPConv layers are concatenated together\nand fed into the NetVLAD layer to generate the global descriptors. The approach\nis trained and evaluated using a large-scale indoor place recognition dataset\nderived from the ScanNet dataset, with a test set comprising 3,608 point clouds\ngenerated from 100 different rooms. Comparison with a traditional feature based\nmethod and three state-of-the-art deep learning methods demonstrate that the\napproach significantly outperforms all four methods, achieving, for example, a\ntop-3 average recall rate of 75% compared with 41% for the closest rival\nmethod.",
    "descriptor": "\nComments: 8 pages, 5 figures\n",
    "authors": [
      "Yuhang Ming",
      "Xingrui Yang",
      "Guofeng Zhang",
      "Andrew Calway"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.02070"
  },
  {
    "id": "arXiv:2202.02071",
    "title": "Alea-BFT: Practical Asynchronous Byzantine Fault Tolerance",
    "abstract": "Traditional Byzantine Fault Tolerance (BFT) state machine replication\nprotocols assume a partial synchrony model, leading to a design where a leader\nreplica drives the protocol and is replaced after a timeout. Recently, we\nwitnessed a surge of asynchronous BFT protocols that use randomization to\nremove the assumptions of bounds on message delivery times, making them more\nresilient to adverse network conditions. However, these protocols still fall\nshort of being practical across a broad range of scenarios due to their cubic\ncommunication costs, use of expensive primitives, and overall protocol\ncomplexity. In this paper, we present Alea-BFT, the first asynchronous BFT\nprotocol to achieve quadratic communication complexity, allowing it to scale to\nlarge networks. Alea-BFT brings the key design insight from classical protocols\nof concentrating part of the work on a single designated replica, and\nincorporates this principle in a two stage pipelined design, with an efficient\nbroadcast led by the designated replica followed by an inexpensive binary\nagreement. We evaluated our prototype implementation across 10 sites in 4\ncontinents, and our results show significant scalability gains from the\nproposed design.",
    "descriptor": "",
    "authors": [
      "Afonso Oliveira",
      "Henrique Moniz",
      "Rodrigo Rodrigues"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2202.02071"
  },
  {
    "id": "arXiv:2202.02074",
    "title": "Urban Region Profiling via A Multi-Graph Representation Learning  Framework",
    "abstract": "Urban region profiling can benefit urban analytics. Although existing studies\nhave made great efforts to learn urban region representation from multi-source\nurban data, there are still three limitations: (1) Most related methods focused\nmerely on global-level inter-region relations while overlooking local-level\ngeographical contextual signals and intra-region information; (2) Most previous\nworks failed to develop an effective yet integrated fusion module which can\ndeeply fuse multi-graph correlations; (3) State-of-the-art methods do not\nperform well in regions with high variance socioeconomic attributes. To address\nthese challenges, we propose a multi-graph representative learning framework,\ncalled Region2Vec, for urban region profiling. Specifically, except that human\nmobility is encoded for inter-region relations, geographic neighborhood is\nintroduced for capturing geographical contextual information while POI side\ninformation is adopted for representing intra-region information by knowledge\ngraph. Then, graphs are used to capture accessibility, vicinity, and\nfunctionality correlations among regions. To consider the discriminative\nproperties of multiple graphs, an encoder-decoder multi-graph fusion module is\nfurther proposed to jointly learn comprehensive representations. Experiments on\nreal-world datasets show that Region2Vec can be employed in three applications\nand outperforms all state-of-the-art baselines. Particularly, Region2Vec has\nbetter performance than previous studies in regions with high variance\nsocioeconomic attributes.",
    "descriptor": "\nComments: 17 pages, 9 figures\n",
    "authors": [
      "Y. Luo",
      "F. Chung",
      "K. Chen"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.02074"
  },
  {
    "id": "arXiv:2202.02077",
    "title": "Exploring the Feature Space of TSP Instances Using Quality Diversity",
    "abstract": "Generating instances of different properties is key to algorithm selection\nmethods that differentiate between the performance of different solvers for a\ngiven combinatorial optimization problem. A wide range of methods using\nevolutionary computation techniques has been introduced in recent years. With\nthis paper, we contribute to this area of research by providing a new approach\nbased on quality diversity (QD) that is able to explore the whole feature\nspace. QD algorithms allow to create solutions of high quality within a given\nfeature space by splitting it up into boxes and improving solution quality\nwithin each box. We use our QD approach for the generation of TSP instances to\nvisualize and analyze the variety of instances differentiating various TSP\nsolvers and compare it to instances generated by a $(\\mu+1)$-EA for TSP\ninstance generation.",
    "descriptor": "",
    "authors": [
      "Jakob Bossek",
      "Frank Neumann"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2202.02077"
  },
  {
    "id": "arXiv:2202.02078",
    "title": "Heed the Noise in Performance Evaluations in Neural Architecture Search",
    "abstract": "Neural Architecture Search (NAS) has recently become a topic of great\ninterest. However, there is a potentially impactful issue within NAS that\nremains largely unrecognized: noise. Due to stochastic factors in neural\nnetwork initialization, training, and the chosen train/validation dataset\nsplit, the performance evaluation of a neural network architecture, which is\noften based on a single learning run, is also stochastic. This may have a\nparticularly large impact if a dataset is small. We therefore propose to reduce\nthe noise by having architecture evaluations comprise averaging of scores over\nmultiple network training runs using different random seeds and\ncross-validation. We perform experiments for a combinatorial optimization\nformulation of NAS in which we vary noise reduction levels. We use the same\ncomputational budget for each noise level in terms of network training runs,\ni.e., we allow less architecture evaluations when averaging over more training\nruns. Multiple search algorithms are considered, including evolutionary\nalgorithms which generally perform well for NAS. We use two publicly available\ndatasets from the medical image segmentation domain where datasets are often\nlimited and variability among samples is often high. Our results show that\nreducing noise in architecture evaluations enables finding better architectures\nby all considered search algorithms.",
    "descriptor": "",
    "authors": [
      "Arkadiy Dushatskiy",
      "Tanja Alderliesten",
      "Peter A. N. Bosman"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2202.02078"
  },
  {
    "id": "arXiv:2202.02080",
    "title": "Robust Linear Regression for General Feature Distribution",
    "abstract": "We investigate robust linear regression where data may be contaminated by an\noblivious adversary, i.e., an adversary than may know the data distribution but\nis otherwise oblivious to the realizations of the data samples. This model has\nbeen previously analyzed under strong assumptions. Concretely, $\\textbf{(i)}$\nall previous works assume that the covariance matrix of the features is\npositive definite; and $\\textbf{(ii)}$ most of them assume that the features\nare centered (i.e. zero mean). Additionally, all previous works make additional\nrestrictive assumption, e.g., assuming that the features are Gaussian or that\nthe corruptions are symmetrically distributed.\nIn this work we go beyond these assumptions and investigate robust regression\nunder a more general set of assumptions: $\\textbf{(i)}$ we allow the covariance\nmatrix to be either positive definite or positive semi definite,\n$\\textbf{(ii)}$ we do not necessarily assume that the features are centered,\n$\\textbf{(iii)}$ we make no further assumption beyond boundedness\n(sub-Gaussianity) of features and measurement noise.\nUnder these assumption we analyze a natural SGD variant for this problem and\nshow that it enjoys a fast convergence rate when the covariance matrix is\npositive definite. In the positive semi definite case we show that there are\ntwo regimes: if the features are centered we can obtain a standard convergence\nrate; otherwise the adversary can cause any learner to fail arbitrarily.",
    "descriptor": "",
    "authors": [
      "Tom Norman",
      "Nir Weinberger",
      "Kfir Y. Levy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.02080"
  },
  {
    "id": "arXiv:2202.02081",
    "title": "Tracking Discourse Influence in Darknet Forums",
    "abstract": "This technical report documents our efforts in addressing the tasks set forth\nby the 2021 AMoC (Advanced Modelling of Cyber Criminal Careers) Hackathon. Our\nmain contribution is a joint visualisation of semantic and temporal features,\ngenerating insight into the supplied data on darknet cybercrime through the\naspects of novelty, transience, and resonance, which describe the potential\nimpact a message might have on the overall discourse in darknet communities.\nAll code and data produced by us as part of this hackathon is publicly\navailable.",
    "descriptor": "\nComments: Submitted as an entry by Leipzig University's TEMIR group to the Bristol Cyber Security Group's AMoC (Advanced Modelling of Cyber Criminal Careers) project hackathon\n",
    "authors": [
      "Christopher Akiki",
      "Lukas Gienapp",
      "Martin Potthast"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2202.02081"
  },
  {
    "id": "arXiv:2202.02082",
    "title": "The influence of funding on the Open Access citation advantage",
    "abstract": "Some of the citation advantage in open access is likely due to more access\nallows more people to read and hence cite articles they otherwise would not.\nHowever, causation is difficult to establish and there are many possible bias.\nSeveral factors can affect the observed differences in citation rates. Funder\nmandates can be one of them. Funders are likely to have OA requirement, and\nwell-funded studies are more likely to receive more citations than poorly\nfunded studies. In this paper this hypothesis is tested. Thus, we studied the\neffect of funding on the publication modality and the citations received in\nmore than 128 thousand research articles, of which 31% were funded. These\nresearch articles come from 40 randomly selected subject categories in the year\n2016, and the citations received from the period 2016-2020 in the Scopus\ndatabase. We found open articles published in hybrid journals were considerably\nmore cited than those in open access journals. Thus, articles under the hybrid\ngold modality are cite on average twice as those in the gold modality. This is\nthe case regardless of funding, so this evidence is strong. Moreover, within\nthe same publication modality, we found that funded articles generally obtain\n50% more citations than unfunded ones. The most cited modality is the hybrid\ngold and the least cited is the gold, well below even the paywalled.\nFurthermore, the use of open access repositories considerably increases the\ncitations received, especially for those articles without funding. Thus, the\narticles in open access repositories (green) are 50% more cited than the\npaywalled ones. This evidence is remarkable and does not depend on funding.\nExcluding the gold modality, there is a citation advantage in more than 75% of\nthe cases and it is considerably greater among unfunded articles. This result\nis strong both across fields and over time.",
    "descriptor": "\nComments: 31 pages, 7 figures, 6 tables. arXiv admin note: substantial text overlap with arXiv:2201.09284\n",
    "authors": [
      "Pablo Dorta-Gonz\u00e1lez",
      "Mar\u00eda Isabel Dorta-Gonz\u00e1lez"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2202.02082"
  },
  {
    "id": "arXiv:2202.02085",
    "title": "SignSGD: Fault-Tolerance to Blind and Byzantine Adversaries",
    "abstract": "Distributed learning has become a necessity for training ever-growing models.\nIn a distributed setting, the task is shared among several devices. Typically,\nthe learning process is monitored by a server. Also, some of the devices can be\nfaulty, deliberately or not, and the usual distributed SGD algorithm cannot\ndefend itself from omniscient adversaries. Therefore, we need to devise a\nfault-tolerant gradient descent algorithm. We based our article on the SignSGD\nalgorithm, which relies on the sharing of gradients signs between the devices\nand the server. We provide a theoretical upper bound for the convergence rate\nof SignSGD to extend the results of the original paper. Our theoretical results\nestimate the convergence rate of SignSGD against a proportion of general\nadversaries, such as Byzantine adversaries. We implemented the algorithm along\nwith Byzantine strategies in order to try to crush the learning process.\nTherefore, we provide empirical observations from our experiments to support\nour theory. Our code is available on GitHub and our experiments are\nreproducible by using the provided parameters.",
    "descriptor": "\nComments: this https URL\n",
    "authors": [
      "Jason Akoun",
      "Sebastien Meyer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.02085"
  },
  {
    "id": "arXiv:2202.02086",
    "title": "About Code Equivalence -- a Geometric Approach",
    "abstract": "The equivalence test is a main part in any classification problem. It helps\nto prove bounds for the main parameters of the considered combinatorial\nstructures and to study their properties. In this paper, we present algorithms\nfor equivalence of linear codes, based on their relation to multisets of points\nin a projective geometry.",
    "descriptor": "",
    "authors": [
      "Iliya Bouyukliev",
      "Stefka Bouyuklieva"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2202.02086"
  },
  {
    "id": "arXiv:2202.02093",
    "title": "Temporal Attention for Language Models",
    "abstract": "Pretrained language models based on the transformer architecture have shown\ngreat success in NLP. Textual training data often comes from the web and is\nthus tagged with time-specific information, but most language models ignore\nthis information. They are trained on the textual data alone, limiting their\nability to generalize temporally. In this work, we extend the key component of\nthe transformer architecture, i.e., the self-attention mechanism, and propose\ntemporal attention - a time-aware self-attention mechanism. Temporal attention\ncan be applied to any transformer model and requires the input texts to be\naccompanied with their relevant time points. It allows the transformer to\ncapture this temporal information and create time-specific contextualized word\nrepresentations. We leverage these representations for the task of semantic\nchange detection; we apply our proposed mechanism to BERT and experiment on\nthree datasets in different languages (English, German, and Latin) that also\nvary in time, size, and genre. Our proposed model achieves state-of-the-art\nresults on all the datasets.",
    "descriptor": "\nComments: 8 pages\n",
    "authors": [
      "Guy D. Rosin",
      "Kira Radinsky"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.02093"
  },
  {
    "id": "arXiv:2202.02094",
    "title": "Numerical Demonstration of Multiple Actuator Constraint Enforcement  Algorithm for a Molten Salt Loop",
    "abstract": "To advance the paradigm of autonomous operation for nuclear power plants, a\ndata-driven machine learning approach to control is sought. Autonomous\noperation for next-generation reactor designs is anticipated to bolster safety\nand improve economics. However, any algorithms that are utilized need to be\ninterpretable, adaptable, and robust.\nIn this work, we focus on the specific problem of optimal control during\nautonomous operation. We will demonstrate an interpretable and adaptable\ndata-driven machine learning approach to autonomous control of a molten salt\nloop. To address interpretability, we utilize a data-driven algorithm to\nidentify system dynamics in state-space representation. To address\nadaptability, a control algorithm will be utilized to modify actuator setpoints\nwhile enforcing constant, and time-dependent constraints. Robustness is not\naddressed in this work, and is part of future work. To demonstrate the\napproach, we designed a numerical experiment requiring intervention to enforce\nconstraints during a load-follow type transient.",
    "descriptor": "\nComments: 4 pages, 6 figures. To be submitted to 2022 American Nuclear Society Annual Meeting\n",
    "authors": [
      "Akshay J. Dave",
      "Haoyu Wang",
      "Roberto Ponciroli",
      "Richard B. Vilim"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.02094"
  },
  {
    "id": "arXiv:2202.02095",
    "title": "Fixed-Point Code Synthesis For Neural Networks",
    "abstract": "Over the last few years, neural networks have started penetrating safety\ncritical systems to take decisions in robots, rockets, autonomous driving car,\netc. A problem is that these critical systems often have limited computing\nresources. Often, they use the fixed-point arithmetic for its many advantages\n(rapidity, compatibility with small memory devices.) In this article, a new\ntechnique is introduced to tune the formats (precision) of already trained\nneural networks using fixed-point arithmetic, which can be implemented using\ninteger operations only. The new optimized neural network computes the output\nwith fixed-point numbers without modifying the accuracy up to a threshold fixed\nby the user. A fixed-point code is synthesized for the new optimized neural\nnetwork ensuring the respect of the threshold for any input vector belonging\nthe range [xmin, xmax] determined during the analysis. From a technical point\nof view, we do a preliminary analysis of our floating neural network to\ndetermine the worst cases, then we generate a system of linear constraints\namong integer variables that we can solve by linear programming. The solution\nof this system is the new fixed-point format of each neuron. The experimental\nresults obtained show the efficiency of our method which can ensure that the\nnew fixed-point neural network has the same behavior as the initial\nfloating-point neural network.",
    "descriptor": "",
    "authors": [
      "Hanane Benmaghnia",
      "Matthieu Martel",
      "Yassamine Seladji"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.02095"
  },
  {
    "id": "arXiv:2202.02097",
    "title": "Explicit port-Hamiltonian FEM models for geometrically nonlinear  mechanical systems",
    "abstract": "In this article, we present the port-Hamiltonian representation, the\nstructure preserving discretization and the resulting finite-dimensional state\nspace model of geometrically nonlinear mechanical systems based on a mixed\nfinite element formulation. This article focuses on St. Venant-Kirchhoff\nmaterials connecting the Green strain and the second Piola-Kirchhoff stress\ntensor in a linear relationship which allows a port-Hamiltonian representation\nby means of its co-energy (effort) variables. Due to treatment of both\nDirichlet and Neumann boundary conditions in the appropriate variational\nformulation, the resulting port-Hamiltonian state space model features both of\nthem as explicit (control) inputs. Numerical experiments generated with FEniCS\nillustrate the properties of the resulting FE models.",
    "descriptor": "\nComments: 11 pgaes, 9 figures, submitted to Mathematical and Computer Modelling of Dynamical Systems\n",
    "authors": [
      "Tobias Thoma",
      "Paul Kotyczka"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.02097"
  },
  {
    "id": "arXiv:2202.02098",
    "title": "Supervised Contrastive Learning for Product Matching",
    "abstract": "Contrastive learning has seen increasing success in the fields of computer\nvision and information retrieval in recent years. This poster is the first work\nthat applies contrastive learning to the task of product matching in e-commerce\nusing product offers from different e-shops. More specifically, we employ a\nsupervised contrastive learning technique to pre-train a Transformer encoder\nwhich is afterwards fine-tuned for the matching problem using pair-wise\ntraining data. We further propose a source-aware sampling strategy which\nenables contrastive learning to be applied for use cases in which the training\ndata does not contain product idenifiers. We show that applying supervised\ncontrastive pre-training in combination with source-aware sampling\nsignificantly improves the state-of-the art performance on several widely used\nbenchmark datasets: For Abt-Buy, we reach an F1 of 94.29 (+3.24 compared to the\nprevious state-of-the-art), for Amazon-Google 79.28 (+ 3.7). For WDC Computers\ndatasets, we reach improvements between +0.8 and +8.84 F1 depending on the\ntraining set size. Further experiments with data augmentation and\nself-supervised contrastive pre-training show, that the former can be helpful\nfor smaller training sets while the latter leads to a significant decline in\nperformance due to inherent label-noise. We thus conclude that contrastive\npre-training has a high potential for product matching use cases in which\nexplicit supervision is available.",
    "descriptor": "",
    "authors": [
      "Ralph Peeters",
      "Christian Bizer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.02098"
  },
  {
    "id": "arXiv:2202.02104",
    "title": "Brokenwire : Wireless Disruption of CCS Electric Vehicle Charging",
    "abstract": "We present a novel attack against the Combined Charging System, one of the\nmost widely used DC rapid charging systems for electric vehicles (EVs). Our\nattack, Brokenwire, interrupts necessary control communication between the\nvehicle and charger, causing charging sessions to abort. The attack can be\nconducted wirelessly from a distance, allowing individual vehicles or entire\nfleets to be disrupted stealthily and simultaneously. In addition, it can be\nmounted with off-the-shelf radio hardware and minimal technical knowledge. The\nexploited behavior is a required part of the HomePlug Green PHY, DIN 70121 &\nISO 15118 standards and all known implementations exhibit it.\nWe first study the attack in a controlled testbed and then demonstrate it\nagainst seven vehicles and 18 chargers in real deployments. We find the attack\nto be successful in the real world, at ranges up to 47 m, for a power budget of\nless than 1 W. We further show that the attack can work between the floors of a\nbuilding (e.g., multi-story parking), through perimeter fences, and from\n'drive-by' attacks. We present a heuristic model to estimate the number of\nvehicles that can be attacked simultaneously for a given output power.\nBrokenwire has immediate implications for many of the around 12 million\nbattery EVs on the roads worldwide - and profound effects on the new wave of\nelectrification for vehicle fleets, both for private enterprise and crucial\npublic services. As such, we conducted a disclosure to the industry and\ndiscussed a range of mitigation techniques that could be deployed to limit the\nimpact.",
    "descriptor": "",
    "authors": [
      "Sebastian K\u00f6hler",
      "Richard Baker",
      "Martin Strohmeier",
      "Ivan Martinovic"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.02104"
  },
  {
    "id": "arXiv:2202.02107",
    "title": "Implementation of a Type-2 Fuzzy Logic Based Prediction System for the  Nigerian Stock Exchange",
    "abstract": "Stock Market can be easily seen as one of the most attractive places for\ninvestors, but it is also very complex in terms of making trading decisions.\nPredicting the market is a risky venture because of the uncertainties and\nnonlinear nature of the market. Deciding on the right time to trade is key to\nevery successful trader as it can lead to either a huge gain of money or\ntotally a loss in investment that will be recorded as a careless trade. The aim\nof this research is to develop a prediction system for stock market using Fuzzy\nLogic Type2 which will handle these uncertainties and complexities of human\nbehaviour in general when it comes to buy, hold or sell decision making in\nstock trading. The proposed system was developed using VB.NET programming\nlanguage as frontend and Microsoft SQL Server as backend. A total of four\ndifferent technical indicators were selected for this research. The selected\nindicators are the Relative Strength Index, William Average, Moving Average\nConvergence and Divergence, and Stochastic Oscillator. These indicators serve\nas input variable to the Fuzzy System. The MACD and SO are deployed as primary\nindicators, while the RSI and WA are used as secondary indicators. Fibonacci\nretracement ratio was adopted for the secondary indicators to determine their\nsupport and resistance level in terms of making trading decisions. The input\nvariables to the Fuzzy System is fuzzified to Low, Medium, and High using the\nTriangular and Gaussian Membership Function. The Mamdani Type Fuzzy Inference\nrules were used for combining the trading rules for each input variable to the\nfuzzy system. The developed system was tested using sample data collected from\nten different companies listed on the Nigerian Stock Exchange for a total of\nfifty two periods. The dataset collected are Opening, High, Low, and Closing\nprices of each security.",
    "descriptor": "\nComments: 8 pages\n",
    "authors": [
      "Isobo Nelson Davies",
      "Donald Ene",
      "Ibiere Boma Cookey",
      "Godwin Fred Lenu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2202.02107"
  },
  {
    "id": "arXiv:2202.02110",
    "title": "New Inner and Outer Bounds for 2-User Gaussian Broadcast Channels with  Heterogeneous Blocklength Constraints",
    "abstract": "We investigate both a novel inner and outer bound on the rate region of a\n2-user Gaussian broadcast channel with finite, heterogeneous blocklength\nconstraints (HB-GBC). In particular, we introduce a new, modified Sato-type\nouter bound that can be applied in the finite blocklength regime and does not\nrequire the same marginal property. We then develop and analyze concatenated\nshell codes, which are suitable for the HB-GBC. Especially, to achieve a\nsmaller decoding latency for the user with shorter blocklength constraint when\nsuccessive interference cancellation is used, we derive the number of symbols\nneeded to successfully early decode the other user's message. We numerically\ncompare our derived outer bound to the best known achievable rate regions.\nNumerical results show that the new early decoding performance is significantly\nimproved compared to the state of the art, and performs very close to the\nasymptotic limit.",
    "descriptor": "\nComments: 4 Figures\n",
    "authors": [
      "Marcel Mross",
      "Pin-Hsun Lin",
      "Eduard A. Jorswieck"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.02110"
  },
  {
    "id": "arXiv:2202.02112",
    "title": "Musical Audio Similarity with Self-supervised Convolutional Neural  Networks",
    "abstract": "We have built a music similarity search engine that lets video producers\nsearch by listenable music excerpts, as a complement to traditional full-text\nsearch. Our system suggests similar sounding track segments in a large music\ncatalog by training a self-supervised convolutional neural network with triplet\nloss terms and musical transformations. Semi-structured user interviews\ndemonstrate that we can successfully impress professional video producers with\nthe quality of the search experience, and perceived similarities to query\ntracks averaged 7.8/10 in user testing. We believe this search tool will make\nfor a more natural search experience that is easier to find music to soundtrack\nvideos with.",
    "descriptor": "\nComments: ISMIR LBD 2021\n",
    "authors": [
      "Carl Thom\u00e9",
      "Sebastian Piwell",
      "Oscar Utterb\u00e4ck"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2202.02112"
  },
  {
    "id": "arXiv:2202.02113",
    "title": "From Discrimination to Generation: Knowledge Graph Completion with  Generative Transformer",
    "abstract": "Knowledge graph completion aims to address the problem of extending a KG with\nmissing triples. In this paper, we provide an approach GenKGC, which converts\nknowledge graph completion to sequence-to-sequence generation task with the\npre-trained language model. We further introduce relation-guided demonstration\nand entity-aware hierarchical decoding for better representation learning and\nfast inference. Experimental results on three datasets show that our approach\ncan obtain better or comparable performance than baselines and achieve faster\ninference speed compared with previous methods with pre-trained language\nmodels. We also release a new large-scale Chinese knowledge graph dataset\nAliopenKG500 for research purpose. Code and datasets are available in\nhttps://github.com/zjunlp/PromptKGC/tree/main/GenKGC.",
    "descriptor": "\nComments: Work in progress. arXiv admin note: text overlap with arXiv:2201.05575\n",
    "authors": [
      "Xin Xie",
      "Ningyu Zhang",
      "Zhoubo Li",
      "Shumin Deng",
      "Hui Chen",
      "Feiyu Xiong",
      "Mosha Chen",
      "Huajun Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.02113"
  },
  {
    "id": "arXiv:2202.02115",
    "title": "Polyphonic pitch detection with convolutional recurrent neural networks",
    "abstract": "Recent directions in automatic speech recognition (ASR) research have shown\nthat applying deep learning models from image recognition challenges in\ncomputer vision is beneficial. As automatic music transcription (AMT) is\nsuperficially similar to ASR, in the sense that methods often rely on\ntransforming spectrograms to symbolic sequences of events (e.g. words or\nnotes), deep learning should benefit AMT as well. In this work, we outline an\nonline polyphonic pitch detection system that streams audio to MIDI by\nConvLSTMs. Our system achieves state-of-the-art results on the 2007 MIREX\nmulti-F0 development set, with an F-measure of 83\\% on the bassoon, clarinet,\nflute, horn and oboe ensemble recording without requiring any musical language\nmodelling or assumptions of instrument timbre.",
    "descriptor": "\nComments: MIREX 2017\n",
    "authors": [
      "Carl Thom\u00e9",
      "Sven Ahlb\u00e4ck"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2202.02115"
  },
  {
    "id": "arXiv:2202.02124",
    "title": "TIML: Task-Informed Meta-Learning for Agriculture",
    "abstract": "Labeled datasets for agriculture are extremely spatially imbalanced. When\ndeveloping algorithms for data-sparse regions, a natural approach is to use\ntransfer learning from data-rich regions. While standard transfer learning\napproaches typically leverage only direct inputs and outputs, geospatial\nimagery and agricultural data are rich in metadata that can inform transfer\nlearning algorithms, such as the spatial coordinates of data-points or the\nclass of task being learned. We build on previous work exploring the use of\nmeta-learning for agricultural contexts in data-sparse regions and introduce\ntask-informed meta-learning (TIML), an augmentation to model-agnostic\nmeta-learning which takes advantage of task-specific metadata. We apply TIML to\ncrop type classification and yield estimation, and find that TIML significantly\nimproves performance compared to a range of benchmarks in both contexts, across\na diversity of model architectures. While we focus on tasks from agriculture,\nTIML could offer benefits to any meta-learning setup with task-specific\nmetadata, such as classification of geo-tagged images and species distribution\nmodelling.",
    "descriptor": "\nComments: 12 pages, 4 figures\n",
    "authors": [
      "Gabriel Tseng",
      "Hannah Kerner",
      "David Rolnick"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.02124"
  },
  {
    "id": "arXiv:2202.02125",
    "title": "OntoSeer -- A Recommendation System to Improve the Quality of Ontologies",
    "abstract": "Building an ontology is not only a time-consuming process, but it is also\nconfusing, especially for beginners and the inexperienced. Although ontology\ndevelopers can take the help of domain experts in building an ontology, they\nare not readily available in several cases for a variety of reasons. Ontology\ndevelopers have to grapple with several questions related to the choice of\nclasses, properties, and the axioms that should be included. Apart from this,\nthere are aspects such as modularity and reusability that should be taken care\nof. From among the thousands of publicly available ontologies and vocabularies\nin repositories such as Linked Open Vocabularies (LOV) and BioPortal, it is\nhard to know the terms (classes and properties) that can be reused in the\ndevelopment of an ontology. A similar problem exists in implementing the right\nset of ontology design patterns (ODPs) from among the several available.\nGenerally, ontology developers make use of their experience in handling these\nissues, and the inexperienced ones have a hard time. In order to bridge this\ngap, we propose a tool named OntoSeer, that monitors the ontology development\nprocess and provides suggestions in real-time to improve the quality of the\nontology under development. It can provide suggestions on the naming\nconventions to follow, vocabulary to reuse, ODPs to implement, and axioms to be\nadded to the ontology. OntoSeer has been implemented as a Prot\\'eg\\'e plug-in.",
    "descriptor": "",
    "authors": [
      "Pramit Bhattacharyya",
      "Raghava Mutharaju"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.02125"
  },
  {
    "id": "arXiv:2202.02131",
    "title": "Interpretability methods of machine learning algorithms with  applications in breast cancer diagnosis",
    "abstract": "Early detection of breast cancer is a powerful tool towards decreasing its\nsocioeconomic burden. Although, artificial intelligence (AI) methods have shown\nremarkable results towards this goal, their \"black box\" nature hinders their\nwide adoption in clinical practice. To address the need for AI guided breast\ncancer diagnosis, interpretability methods can be utilized. In this study, we\nused AI methods, i.e., Random Forests (RF), Neural Networks (NN) and Ensembles\nof Neural Networks (ENN), towards this goal and explained and optimized their\nperformance through interpretability techniques, such as the Global Surrogate\n(GS) method, the Individual Conditional Expectation (ICE) plots and the Shapley\nvalues (SV). The Wisconsin Diagnostic Breast Cancer (WDBC) dataset of the open\nUCI repository was used for the training and evaluation of the AI algorithms.\nThe best performance for breast cancer diagnosis was achieved by the proposed\nENN (96.6% accuracy and 0.96 area under the ROC curve), and its predictions\nwere explained by ICE plots, proving that its decisions were compliant with\ncurrent medical knowledge and can be further utilized to gain new insights in\nthe pathophysiological mechanisms of breast cancer. Feature selection based on\nfeatures' importance according to the GS model improved the performance of the\nRF (leading the accuracy from 96.49% to 97.18% and the area under the ROC curve\nfrom 0.96 to 0.97) and feature selection based on features' importance\naccording to SV improved the performance of the NN (leading the accuracy from\n94.6% to 95.53% and the area under the ROC curve from 0.94 to 0.95). Compared\nto other approaches on the same dataset, our proposed models demonstrated state\nof the art performance while being interpretable.",
    "descriptor": "\nComments: 2021 43rd Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC)\n",
    "authors": [
      "Panagiota Karatza",
      "Kalliopi V. Dalakleidi",
      "Maria Athanasiou",
      "Konstantina S. Nikita"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Medical Physics (physics.med-ph)"
    ],
    "url": "https://arxiv.org/abs/2202.02131"
  },
  {
    "id": "arXiv:2202.02135",
    "title": "Extracting Software Requirements from Unstructured Documents",
    "abstract": "Requirements identification in textual documents or extraction is a tedious\nand error prone task that many researchers suggest automating. We manually\nannotated the PURE dataset and thus created a new one containing both\nrequirements and non-requirements. Using this dataset, we fine-tuned the BERT\nmodel and compare the results with several baselines such as fastText and ELMo.\nIn order to evaluate the model on semantically more complex documents we\ncompare the PURE dataset results with experiments on Request For Information\n(RFI) documents. The RFIs often include software requirements, but in a less\nstandardized way. The fine-tuned BERT showed promising results on PURE dataset\non the binary sentence classification task. Comparing with previous and recent\nstudies dealing with constrained inputs, our approach demonstrates high\nperformance in terms of precision and recall metrics, while being agnostic to\nthe unstructured textual input.",
    "descriptor": "",
    "authors": [
      "Vladimir Ivanov",
      "Andrey Sadovykh",
      "Alexandr Naumchev",
      "Alessandra Bagnato",
      "Kirill Yakovlev"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2202.02135"
  },
  {
    "id": "arXiv:2202.02139",
    "title": "Multi Objective Resource Optimization of Wireless Network Based on Cross  Domain Virtual Network Embedding",
    "abstract": "The rapid development of virtual network architecture makes it possible for\nwireless network to be widely used. With the popularity of artificial\nintelligence (AI) industry in daily life, efficient resource allocation of\nwireless network has become a problem. Especially when network users request\nwireless network resources from different management domains, they still face\nmany practical problems. From the perspective of virtual network embedding\n(VNE), this paper designs and implements a multi-objective optimization VNE\nalgorithm for wireless network resource allocation. Resource allocation in\nvirtual network is essentially a problem of allocating underlying resources for\nvirtual network requests (VNRs). According to the proposed objective formula,\nwe consider the optimization mapping cost, network delay and VNR acceptance\nrate. VNE is completed by node mapping and link mapping. In the experiment and\nsimulation stage, it is compared with other VNE algorithms, the cross domain\nVNE algorithm proposed in this paper is optimal in the above three indicators.\nThis shows the effectiveness of the algorithm in wireless network resource\nallocation.",
    "descriptor": "",
    "authors": [
      "Chao Wang",
      "Tao Dong",
      "Youxiang Duan",
      "Qifeng Sun",
      "Peiying Zhang"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.02139"
  },
  {
    "id": "arXiv:2202.02140",
    "title": "Dynamic Virtual Network Embedding Algorithm based on Graph Convolution  Neural Network and Reinforcement Learning",
    "abstract": "Network virtualization (NV) is a technology with broad application prospects.\nVirtual network embedding (VNE) is the core orientation of VN, which aims to\nprovide more flexible underlying physical resource allocation for user function\nrequests. The classical VNE problem is usually solved by heuristic method, but\nthis method often limits the flexibility of the algorithm and ignores the time\nlimit. In addition, the partition autonomy of physical domain and the dynamic\ncharacteristics of virtual network request (VNR) also increase the difficulty\nof VNE. This paper proposed a new type of VNE algorithm, which applied\nreinforcement learning (RL) and graph neural network (GNN) theory to the\nalgorithm, especially the combination of graph convolutional neural network\n(GCNN) and RL algorithm. Based on a self-defined fitness matrix and fitness\nvalue, we set up the objective function of the algorithm implementation,\nrealized an efficient dynamic VNE algorithm, and effectively reduced the degree\nof resource fragmentation. Finally, we used comparison algorithms to evaluate\nthe proposed method. Simulation experiments verified that the dynamic VNE\nalgorithm based on RL and GCNN has good basic VNE characteristics. By changing\nthe resource attributes of physical network and virtual network, it can be\nproved that the algorithm has good flexibility.",
    "descriptor": "",
    "authors": [
      "Peiying Zhang",
      "Chao Wang",
      "Neeraj Kumar",
      "Weishan Zhang",
      "Lei Liu"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.02140"
  },
  {
    "id": "arXiv:2202.02141",
    "title": "Incorporating Distributed DRL into Storage Resource Optimization of  Space-Air-Ground Integrated Wireless Communication Network",
    "abstract": "Space-air-ground integrated network (SAGIN) is a new type of wireless network\nmode. The effective management of SAGIN resources is a prerequisite for\nhigh-reliability communication. However, the storage capacity of space-air\nnetwork segment is extremely limited. The air servers also do not have\nsufficient storage resources to centrally accommodate the information uploaded\nby each edge server. So the problem of how to coordinate the storage resources\nof SAGIN has arisen. This paper proposes a SAGIN storage resource management\nalgorithm based on distributed deep reinforcement learning (DRL). The resource\nmanagement process is modeled as a Markov decision model. In each edge physical\ndomain, we extract the network attributes represented by storage resources for\nthe agent to build a training environment, so as to realize the distributed\ntraining. In addition, we propose a SAGIN resource management framework based\non distributed DRL. Simulation results show that the agent has an ideal\ntraining effect. Compared with other algorithms, the resource allocation\nrevenue and user request acceptance rate of the proposed algorithm are\nincreased by about 18.15\\% and 8.35\\% respectively. Besides, the proposed\nalgorithm has good flexibility in dealing with the changes of resource\nconditions.",
    "descriptor": "",
    "authors": [
      "Chao Wang",
      "Lei Liu",
      "Chunxiao Jiang",
      "Shangguang Wang",
      "Peiying Zhang",
      "Shigen Shen"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2202.02141"
  },
  {
    "id": "arXiv:2202.02142",
    "title": "Deep invariant networks with differentiable augmentation layers",
    "abstract": "Designing learning systems which are invariant to certain data\ntransformations is critical in machine learning. Practitioners can typically\nenforce a desired invariance on the trained model through the choice of a\nnetwork architecture, e.g. using convolutions for translations, or using data\naugmentation. Yet, enforcing true invariance in the network can be difficult,\nand data invariances are not always known a piori. State-of-the-art methods for\nlearning data augmentation policies require held-out data and are based on\nbilevel optimization problems, which are complex to solve and often\ncomputationally demanding. In this work we investigate new ways of learning\ninvariances only from the training data. Using learnable augmentation layers\nbuilt directly in the network, we demonstrate that our method is very\nversatile. It can incorporate any type of differentiable augmentation and be\napplied to a broad class of learning problems beyond computer vision. We\nprovide empirical evidence showing that our approach is easier and faster to\ntrain than modern automatic data augmentation techniques based on bilevel\noptimization, while achieving comparable results. Experiments show that while\nthe invariances transferred to a model through automatic data augmentation are\nlimited by the model expressivity, the invariance yielded by our approach is\ninsensitive to it by design.",
    "descriptor": "",
    "authors": [
      "C\u00e9dric Rommel",
      "Thomas Moreau",
      "Alexandre Gramfort"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.02142"
  },
  {
    "id": "arXiv:2202.02144",
    "title": "Proceedings 10th International Workshop on Theorem Proving Components  for Educational Software",
    "abstract": "This EPTCS volume contains the proceedings of the ThEdu'21 workshop, promoted\non 11 July 2021, as a satellite event of CADE-28. Due to the COVID-19 pandemic,\nCADE-28 and all its co-located events happened as virtual events. ThEdu'21 was\na vibrant workshop, with an invited talk by Gilles Dowek (ENS Paris-Saclay),\neleven contributions, and one demonstration. After the workshop an open call\nfor papers was issued and attracted 10 submissions, 7 of which have been\naccepted by the reviewers, and collected in the present post-proceedings\nvolume.\nThe ThEdu series pursues the smooth transition from an intuitive way of doing\nmathematics at secondary school to a more formal approach to the subject in\nSTEM education, while favouring software support for this transition by\nexploiting the power of theorem-proving technologies.\nThe volume editors hope that this collection of papers will further promote\nthe development of theorem-proving based software, and that it will collaborate\non improving mutual understanding between computer scientists, mathematicians\nand stakeholders in education.",
    "descriptor": "",
    "authors": [
      "Jo\u00e3o Marcos",
      "Walther Neuper",
      "Pedro Quaresma"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.02144"
  },
  {
    "id": "arXiv:2202.02145",
    "title": "Generative Modeling of Complex Data",
    "abstract": "In recent years, several models have improved the capacity to generate\nsynthetic tabular datasets. However, such models focus on synthesizing simple\ncolumnar tables and are not useable on real-life data with complex structures.\nThis paper puts forward a generic framework to synthesize more complex data\nstructures with composite and nested types. It then proposes one practical\nimplementation, built with causal transformers, for struct (mappings of types)\nand lists (repeated instances of a type). The results on standard benchmark\ndatasets show that such implementation consistently outperforms current\nstate-of-the-art models both in terms of machine learning utility and\nstatistical similarity. Moreover, it shows very strong results on two complex\nhierarchical datasets with multiple nesting and sparse data, that were\npreviously out of reach.",
    "descriptor": "",
    "authors": [
      "Luca Canale",
      "Nicolas Grislain",
      "Gr\u00e9goire Lothe",
      "Johan Leduc"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.02145"
  },
  {
    "id": "arXiv:2202.02149",
    "title": "Edge-Selective Feature Weaving for Point Cloud Matching",
    "abstract": "This paper tackles the problem of accurately matching the points of two 3D\npoint clouds. Most conventional methods improve their performance by extracting\nrepresentative features from each point via deep-learning-based algorithms. On\nthe other hand, the correspondence calculation between the extracted features\nhas not been examined in depth, and non-trainable algorithms (e.g. the Sinkhorn\nalgorithm) are frequently applied. As a result, the extracted features may be\nforcibly fitted to a non-trainable algorithm. Furthermore, the extracted\nfeatures frequently contain stochastically unavoidable errors, which degrades\nthe matching accuracy. In this paper, instead of using a non-trainable\nalgorithm, we propose a differentiable matching network that can be jointly\noptimized with the feature extraction procedure. Our network first constructs\ngraphs with edges connecting the points of each point cloud and then extracts\ndiscriminative edge features by using two main components: a shared set-encoder\nand an edge-selective cross-concatenation. These components enable us to\nsymmetrically consider two point clouds and to extract discriminative edge\nfeatures, respectively. By using the extracted discriminative edge features,\nour network can accurately calculate the correspondence between points. Our\nexperimental results show that the proposed network can significantly improve\nthe performance of point cloud matching. Our code is available at\nhttps://github.com/yanarin/ESFW",
    "descriptor": "",
    "authors": [
      "Rintaro Yanagi",
      "Atsushi Hashimoto",
      "Shusaku Sone",
      "Naoya Chiba",
      "Jiaxin Ma",
      "Yoshitaka Ushiku"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.02149"
  },
  {
    "id": "arXiv:2202.02155",
    "title": "Source data selection for out-of-domain generalization",
    "abstract": "Models that perform out-of-domain generalization borrow knowledge from\nheterogeneous source data and apply it to a related but distinct target task.\nTransfer learning has proven effective for accomplishing this generalization in\nmany applications. However, poor selection of a source dataset can lead to poor\nperformance on the target, a phenomenon called negative transfer. In order to\ntake full advantage of available source data, this work studies source data\nselection with respect to a target task. We propose two source selection\nmethods that are based on the multi-bandit theory and random search,\nrespectively. We conduct a thorough empirical evaluation on both simulated and\nreal data. Our proposals can be also viewed as diagnostics for the existence of\na reweighted source subsamples that perform better than the random selection of\navailable samples.",
    "descriptor": "\nComments: 18 pages, 16 figures\n",
    "authors": [
      "Xinran Miao",
      "Kris Sankaran"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2202.02155"
  },
  {
    "id": "arXiv:2202.02163",
    "title": "COIL: Constrained Optimization in Learned Latent Space -- Learning  Representations for Valid Solutions",
    "abstract": "Constrained optimization problems can be difficult because their search\nspaces have properties not conducive to search, e.g., multimodality,\ndiscontinuities, or deception. To address such difficulties, considerable\nresearch has been performed on creating novel evolutionary algorithms or\nspecialized genetic operators. However, if the representation that defined the\nsearch space could be altered such that it only permitted valid solutions that\nsatisfied the constraints, the task of finding the optimal would be made more\nfeasible without any need for specialized optimization algorithms. We propose\nthe use of a Variational Autoencoder to learn such representations. We present\nConstrained Optimization in Latent Space (COIL), which uses a VAE to generate a\nlearned latent representation from a dataset comprising samples from the valid\nregion of the search space according to a constraint, thus enabling the\noptimizer to find the objective in the new space defined by the learned\nrepresentation. We investigate the value of this approach on different\nconstraint types and for different numbers of variables. We show that, compared\nto an identical GA using a standard representation, COIL with its learned\nlatent representation can satisfy constraints and find solutions with distance\nto objective up to two orders of magnitude closer.",
    "descriptor": "\nComments: 10 pages\n",
    "authors": [
      "Peter J Bentley",
      "Soo Ling Lim",
      "Adam Gaier",
      "Linh Tran"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.02163"
  },
  {
    "id": "arXiv:2202.02164",
    "title": "Group invariant machine learning by fundamental domain projections",
    "abstract": "We approach the well-studied problem of supervised group invariant and\nequivariant machine learning from the point of view of geometric topology. We\npropose a novel approach using a pre-processing step, which involves projecting\nthe input data into a geometric space which parametrises the orbits of the\nsymmetry group. This new data can then be the input for an arbitrary machine\nlearning model (neural network, random forest, support-vector machine etc).\nWe give an algorithm to compute the geometric projection, which is efficient\nto implement, and we illustrate our approach on some example machine learning\nproblems (including the well-studied problem of predicting Hodge numbers of\nCICY matrices), in each case finding an improvement in accuracy versus others\nin the literature. The geometric topology viewpoint also allows us to give a\nunified description of so-called intrinsic approaches to group equivariant\nmachine learning, which encompasses many other approaches in the literature.",
    "descriptor": "\nComments: 21 pages, 4 figures\n",
    "authors": [
      "Benjamin Aslan",
      "Daniel Platt",
      "David Sheard"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Geometric Topology (math.GT)"
    ],
    "url": "https://arxiv.org/abs/2202.02164"
  },
  {
    "id": "arXiv:2202.02169",
    "title": "Wideband Multi-User MIMO Communications with Frequency Selective RISs:  Element Response Modeling and Sum-Rate Maximization",
    "abstract": "Reconfigurable Intelligent Surfaces (RISs) are an emerging technology for\nfuture wireless communication systems, enabling improved coverage in an energy\nefficient manner. RISs are usually metasurfaces, constituting of\ntwo-dimensional arrangements of metamaterial elements, whose individual\nresponse is commonly modeled in the literature as an adjustable phase shifter.\nHowever, this model holds only for narrow communications, and when wideband\ntransmissions are utilized, one has to account for the frequency selectivity of\nmetamaterials, whose response follows a Lorentzian profile. In this paper, we\nconsider the uplink of a wideband RIS-empowered multi-user Multiple-Input\nMultiple-Output (MIMO) wireless system with Orthogonal Frequency Division\nMultiplexing (OFDM) signaling, while accounting for the frequency selectivity\nof RISs. In particular, we focus on designing the controllable parameters\ndictating the Lorentzian response of each RIS metamaterial element in order to\nmaximize the achievable sum-rate. We devise a scheme combining block coordinate\ndescent with penalty dual decomposition to tackle the resulting challenging\noptimization framework. Our simulation results reveal the achievable rates one\ncan achieve using realistically frequency selective RISs in wideband settings,\nand quantify the performance loss that occurs when using state-of-the-art\nmethods which assume that the RIS elements behave as frequency-flat phase\nshifters.",
    "descriptor": "\nComments: 6 pages; 4 figures; IEEE conference\n",
    "authors": [
      "Konstantinos D. Katsanos",
      "Nir Shlezinger",
      "Mohammadreza F. Imani",
      "George C. Alexandropoulos"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.02169"
  },
  {
    "id": "arXiv:2202.02170",
    "title": "The Ecological Footprint of Neural Machine Translation Systems",
    "abstract": "Over the past decade, deep learning (DL) has led to significant advancements\nin various fields of artificial intelligence, including machine translation\n(MT). These advancements would not be possible without the ever-growing volumes\nof data and the hardware that allows large DL models to be trained efficiently.\nDue to the large amount of computing cores as well as dedicated memory,\ngraphics processing units (GPUs) are a more effective hardware solution for\ntraining and inference with DL models than central processing units (CPUs).\nHowever, the former is very power demanding. The electrical power consumption\nhas economical as well as ecological implications.\nThis chapter focuses on the ecological footprint of neural MT systems. It\nstarts from the power drain during the training of and the inference with\nneural MT models and moves towards the environment impact, in terms of carbon\ndioxide emissions. Different architectures (RNN and Transformer) and different\nGPUs (consumer-grate NVidia 1080Ti and workstation-grade NVidia P100) are\ncompared. Then, the overall CO2 offload is calculated for Ireland and the\nNetherlands. The NMT models and their ecological impact are compared to common\nhousehold appliances to draw a more clear picture.\nThe last part of this chapter analyses quantization, a technique for reducing\nthe size and complexity of models, as a way to reduce power consumption. As\nquantized models can run on CPUs, they present a power-efficient inference\nsolution without depending on a GPU.",
    "descriptor": "\nComments: 25 pages, 3 figures, 10 tables\n",
    "authors": [
      "Dimitar Sherionov",
      "Eva Vanmassenhove"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.02170"
  },
  {
    "id": "arXiv:2202.02171",
    "title": "NeAT: Neural Adaptive Tomography",
    "abstract": "In this paper, we present Neural Adaptive Tomography (NeAT), the first\nadaptive, hierarchical neural rendering pipeline for multi-view inverse\nrendering. Through a combination of neural features with an adaptive explicit\nrepresentation, we achieve reconstruction times far superior to existing neural\ninverse rendering methods. The adaptive explicit representation improves\nefficiency by facilitating empty space culling and concentrating samples in\ncomplex regions, while the neural features act as a neural regularizer for the\n3D reconstruction. The NeAT framework is designed specifically for the\ntomographic setting, which consists only of semi-transparent volumetric scenes\ninstead of opaque objects. In this setting, NeAT outperforms the quality of\nexisting optimization-based tomography solvers while being substantially\nfaster.",
    "descriptor": "",
    "authors": [
      "Darius R\u00fcckert",
      "Yuanhao Wang",
      "Rui Li",
      "Ramzi Idoughi",
      "Wolfgang Heidrich"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2202.02171"
  },
  {
    "id": "arXiv:2202.02172",
    "title": "Evaluating the Efficacy of Facebook's Vaccine Misinformation Content  Removal Policies",
    "abstract": "Social media platforms have attempted to remove misinformation about vaccines\nbecause it obstructs efforts to end the COVID-19 pandemic. We examined whether\nFacebook's vaccine misinformation removal policies were effective. Posts and\nengagements in anti-vaccine pages were reduced to 29% and 23% of pre-policy\nlevels, respectively, but recovered over the subsequent six months. Posts and\nengagements in pro-vaccine pages were also reduced -- to 68% and 30% of\npre-policy levels, respectively. Low-credibility content became more prevalent\nin anti-vaccine pages and groups, and high-credibility content became less\nprevalent in pro-vaccine pages. Links between anti-vaccine pages and\ncoordinated inauthentic behavior were also reduced. Our results suggest that\nFacebook's policies were only partially successful. Facebook's attempts at\nself-regulation appear to have been resource intensive, and ineffective in the\nlong term.",
    "descriptor": "",
    "authors": [
      "David A. Broniatowski",
      "Jiayan Gu",
      "Amelia M. Jamison",
      "Lorien C. Abroms"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.02172"
  },
  {
    "id": "arXiv:2202.02174",
    "title": "Lossy Planarization: A Constant-Factor Approximate Kernelization for  Planar Vertex Deletion",
    "abstract": "In the F-minor-free deletion problem we want to find a minimum vertex set in\na given graph that intersects all minor models of graphs from the family F. The\nVertex planarization problem is a special case of F-minor-free deletion for the\nfamily F = {K_5, K_{3,3}}. Whenever the family F contains at least one planar\ngraph, then F-minor-free deletion is known to admit a constant-factor\napproximation algorithm and a polynomial kernelization [Fomin, Lokshtanov,\nMisra, and Saurabh, FOCS'12]. The Vertex planarization problem is arguably the\nsimplest setting for which F does not contain a planar graph and the existence\nof a constant-factor approximation or a polynomial kernelization remains a\nmajor open problem.\nIn this work we show that Vertex planarization admits an algorithm which is a\ncombination of both approaches. Namely, we present a polynomial A-approximate\nkernelization, for some constant A > 1, based on the framework of lossy\nkernelization [Lokshtanov, Panolan, Ramanujan, and Saurabh, STOC'17]. Simply\nspeaking, when given a graph G and integer k, we show how to compute a graph G'\non poly(k) vertices so that any B-approximate solution to G' can be lifted to\nan (A*B)-approximate solution to G, as long as A*B*OPT(G) <= k. In order to\nachieve this, we develop a framework for sparsification of planar graphs which\napproximately preserves all separators and near-separators between subsets of\nthe given terminal set.\nOur result yields an improvement over the state-of-art approximation\nalgorithms for Vertex planarization. The problem admits a polynomial-time\nO(n^eps)-approximation algorithm, for any eps > 0, and a quasi-polynomial-time\n(log n)^O(1) approximation algorithm, both randomized [Kawarabayashi and\nSidiropoulos, FOCS'17]. By pipelining these algorithms with our approximate\nkernelization, we improve the approximation factors to respectively O(OPT^eps)\nand (log OPT)^O(1).",
    "descriptor": "\nComments: To appear at STOC'22\n",
    "authors": [
      "Bart M. P. Jansen",
      "Micha\u0142 W\u0142odarczyk"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2202.02174"
  },
  {
    "id": "arXiv:2202.02175",
    "title": "Crystalline: Lowering the Cost for Developers to Collect and Organize  Information for Decision Making",
    "abstract": "Developers perform online sensemaking on a daily basis, such as researching\nand choosing libraries and APIs. Prior research has introduced tools that help\ndevelopers capture information from various sources and organize it into\nstructures useful for subsequent decision-making. However, it remains a\nlaborious process for developers to manually identify and clip content,\nmaintaining its provenance and synthesizing it with other content. In this\nwork, we introduce a new system called Crystalline that attempts to\nautomatically collect and organize information into tabular structures as the\nuser searches and browses the web. It leverages natural language processing to\nautomatically group similar criteria together to reduce clutter as well as\npassive behavioral signals such as mouse movement and dwell time to infer what\ninformation to collect and how to visualize and prioritize it. Our user study\nsuggests that developers are able to create comparison tables about 20% faster\nwith a 60% reduction in operational cost without sacrificing the quality of the\ntables.",
    "descriptor": "",
    "authors": [
      "Michael Xieyang Liu",
      "Aniket Kittur",
      "Brad A. Myers"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2202.02175"
  },
  {
    "id": "arXiv:2202.02177",
    "title": "Generalised Score Distribution: A Two-Parameter Discrete Distribution  Accurately Describing Responses from Quality of Experience Subjective  Experiments",
    "abstract": "Subjective responses from Multimedia Quality Assessment (MQA) experiments are\nconventionally analysed with methods not suitable for the data type these\nresponses represent. Furthermore, obtaining subjective responses is resource\nintensive. A method allowing reuse of existing responses would be thus\nbeneficial. Applying improper data analysis methods leads to difficult to\ninterpret results. This encourages drawing erroneous conclusions. Building upon\nexisting subjective responses is resource friendly and helps develop machine\nlearning (ML) based visual quality predictors. We show that using a discrete\nmodel for analysis of responses from MQA subjective experiments is feasible. We\nindicate that our proposed Generalised Score Distribution (GSD) properly\ndescribes response distributions observed in typical MQA experiments. We\nhighlight interpretability of GSD parameters and indicate that the GSD\noutperforms the approach based on sample empirical distribution when it comes\nto bootstrapping. We evidence that the GSD outcompetes the state-of-the-art\nmodel both in terms of goodness-of-fit and bootstrapping capabilities. To do\nall of that we analyse more than one million subjective responses from more\nthan 30 subjective experiments. Furthermore, we make the code implementing the\nGSD model and related analyses available through our GitHub repository:\nhttps://github.com/Qub3k/subjective-exp-consistency-check",
    "descriptor": "\nComments: 15 pages, 6 figures. Under review in IEEE Transactions on Multimedia\n",
    "authors": [
      "Jakub Nawa\u0142a",
      "Lucjan Janowski",
      "Bogdan \u0106miel",
      "Krzysztof Rusek",
      "Pablo P\u00e9rez"
    ],
    "subjectives": [
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2202.02177"
  },
  {
    "id": "arXiv:2202.02179",
    "title": "DelTact: A Vision-based Tactile Sensor Using Dense Color Pattern",
    "abstract": "Tactile sensing is an essential perception for robots to complete dexterous\ntasks. As a promising tactile sensing technique, vision-based tactile sensors\nhave been developed to improve robot manipulation performance. Here we propose\na new design of our vision-based tactile sensor, DelTact, with its\nhigh-resolution sensing abilities of multiple modality surface contact\ninformation. The sensor adopts an improved dense random color pattern based on\nprevious version, using a modular hardware architecture to achieve higher\naccuracy of contact deformation tracking whilst at the same time maintaining a\ncompact and robust overall design. In particular, we optimized the color\npattern generation process and selected the appropriate pattern for\ncoordinating with a dense optical flow in a real-world experimental sensory\nsetting using varied contact objects. A dense tactile flow was obtained from\nthe raw image in order to determine shape and force distribution on the contact\nsurface. This sensor can be easily integrated with a parallel gripper where\nexperimental results using qualitative and quantitative analysis demonstrated\nthat the sensor is capable of providing tactile measurements with high temporal\nand spatial resolution.",
    "descriptor": "\nComments: 8 pages contents, 1 page references, 9 figures, 1 table\n",
    "authors": [
      "Guanlan Zhang",
      "Yipai Du",
      "Hongyu Yu",
      "Michael Yu Wang"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.02179"
  },
  {
    "id": "arXiv:2202.02180",
    "title": "Identifying Self-Admitted Technical Debt in Issue Tracking Systems using  Machine Learning",
    "abstract": "Technical debt is a metaphor indicating sub-optimal solutions implemented for\nshort-term benefits by sacrificing the long-term maintainability and\nevolvability of software. A special type of technical debt is explicitly\nadmitted by software engineers (e.g. using a TODO comment); this is called\nSelf-Admitted Technical Debt or SATD. Most work on automatically identifying\nSATD focuses on source code comments. In addition to source code comments,\nissue tracking systems have shown to be another rich source of SATD, but there\nare no approaches specifically for automatically identifying SATD in issues. In\nthis paper, we first create a training dataset by collecting and manually\nanalyzing 4,200 issues (that break down to 23,180 sections of issues) from\nseven open-source projects (i.e., Camel, Chromium, Gerrit, Hadoop, HBase,\nImpala, and Thrift) using two popular issue tracking systems (i.e., Jira and\nGoogle Monorail). We then propose and optimize an approach for automatically\nidentifying SATD in issue tracking systems using machine learning. Our findings\nindicate that: 1) our approach outperforms baseline approaches by a wide margin\nwith regard to the F1-score; 2) transferring knowledge from suitable datasets\ncan improve the predictive performance of our approach; 3) extracted SATD\nkeywords are intuitive and potentially indicating types and indicators of SATD;\n4) projects using different issue tracking systems have less common SATD\nkeywords compared to projects using the same issue tracking system; 5) a small\namount of training data is needed to achieve good accuracy.",
    "descriptor": "\nComments: Accepted for publication in the EMSE journal\n",
    "authors": [
      "Yikun Li",
      "Mohamed Soliman",
      "Paris Avgeriou"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.02180"
  },
  {
    "id": "arXiv:2202.02183",
    "title": "Feature-Style Encoder for Style-Based GAN Inversion",
    "abstract": "We propose a novel architecture for GAN inversion, which we call\nFeature-Style encoder. The style encoder is key for the manipulation of the\nobtained latent codes, while the feature encoder is crucial for optimal image\nreconstruction. Our model achieves accurate inversion of real images from the\nlatent space of a pre-trained style-based GAN model, obtaining better\nperceptual quality and lower reconstruction error than existing methods. Thanks\nto its encoder structure, the model allows fast and accurate image editing.\nAdditionally, we demonstrate that the proposed encoder is especially\nwell-suited for inversion and editing on videos. We conduct extensive\nexperiments for several style-based generators pre-trained on different data\ndomains. Our proposed method yields state-of-the-art results for style-based\nGAN inversion, significantly outperforming competing approaches. Source codes\nare available at https://github.com/InterDigitalInc/FeatureStyleEncoder .",
    "descriptor": "",
    "authors": [
      "Xu Yao",
      "Alasdair Newson",
      "Yann Gousseau",
      "Pierre Hellier"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.02183"
  },
  {
    "id": "arXiv:2202.02185",
    "title": "Investigations of c-Differential Uniformity of Permutations with Carlitz  Rank 3",
    "abstract": "The $c$-differential uniformity is recently proposed to reflect resistance\nagainst some variants of differential attack. Finding functions with low\n$c$-differential uniformity is attracting attention from many researchers. For\neven characteristic, it is known that permutations of low Carlitz rank have\ngood cryptographic parameters, for example, low differential uniformity, high\nnonlinearity, etc. In this paper we show that permutations with low Carlitz\nrank have low $c$-differential uniformity. We also investigate $c$-differential\nuniformity of permutations with Carlitz rank 3 in detail.",
    "descriptor": "",
    "authors": [
      "Jaeseong Jeong",
      "Namhun Koo",
      "Soonhak Kwon"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.02185"
  },
  {
    "id": "arXiv:2202.02186",
    "title": "Voice-Based Conversational Agents for self-reporting fluid consumption  and sleep quality",
    "abstract": "Intelligent conversational agents and virtual assistants, such as chatbots\nand voice assistants, have the potential of augmenting health service capacity\nto screen symptoms and deliver healthcare interventions. In this paper, we\ndeveloped voice-based conversational agents (VCAs) in the Google Actions\nConsole to deliver periodic self-assessment health surveys. The focus of this\npaper is to accommodate self-monitoring for patients with specific fluid\nconsumption requirements or sleep disorders. Our VCAs, named FluidMonitor and\nSleepy, have been tested to integrate naturally into a patient's daily\nlifestyle for the purpose of providing useful interventions. We show the\nfunctionality of our Google Actions and discuss the considerations for using\nVCAs as an at-home self-reporting survey technique. User testing showed\nsatisfaction with the ease of use, likeability, and burden level of the VCAs.",
    "descriptor": "",
    "authors": [
      "Abdalsalam Almzayyen",
      "Angel Vela de la Garza Evia",
      "Nick Coronato",
      "Mehdi Boukhechba"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2202.02186"
  },
  {
    "id": "arXiv:2202.02192",
    "title": "Comparison of the performance and reliability between improved sampling  strategies for polynomial chaos expansion",
    "abstract": "With the ever growing importance of uncertainty and sensitivity analysis of\ncomplex model evaluations and the difficulty of their timely realizations comes\na need for more efficient numerical operations. Non-intrusive Polynomial Chaos\nmethods are highly efficient and accurate to map input-output relationships to\ninvestigate complex models. There is a lot of potential to increase the\nefficacy of the method regarding the selected sampling scheme. We examined\nstate-of-the-art sampling schemes categorized in space-filling-optimal designs\nsuch as Latin Hypercube sampling and L1 optimal sampling and compare their\nempirical performance against standard random sampling. The analysis was\nperformed in the context of L1 minimization using the least-angle regression\nalgorithm to fit the gPC regression models. The sampling schemes are thoroughly\ninvestigated by evaluating the quality of the constructed surrogate models\nconsidering distinct test cases representing different problem classes covering\nlow, medium and high dimensional problems. Finally, the samplings schemes are\ntested on an application example to estimate the sensitivity of the\nself-impedance of a probe, which is used to measure the impedance of biological\ntissues at different frequencies. Due to the random nature, we compared the\nsampling schemes using statistical stability measures and evaluated the success\nrates to construct a surrogate model with an accuracy of <0.1%. We observed\nstrong differences in the convergence properties of the methods between the\nanalyzed test functions.",
    "descriptor": "\nComments: 30 pages, 9 figures, 3 tables\n",
    "authors": [
      "Konstantin Weise",
      "Erik M\u00fcller",
      "Lucas Po\u00dfner",
      "Thomas R. Kn\u00f6sche"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.02192"
  },
  {
    "id": "arXiv:2202.02199",
    "title": "ABSNFT: Securitization and Repurchase Scheme for Non-Fungible Tokens  Based on Game Theoretical Analysis",
    "abstract": "The Non-Fungible Token (NFT) is viewed as one of the important applications\nof blockchain technology. Although NFT has a large market scale and multiple\npractical standards, several limitations of the existing mechanism in NFT\nmarkets exist. This work proposes a novel securitization and repurchase scheme\nfor NFT to overcome these limitations. We first provide an Asset-Backed\nSecurities (ABS) solution to settle the limitations of non-fungibility of NFT.\nOur securitization design aims to enhance the liquidity of NFTs and enable\nOracles and Automatic Market Makers (AMMs) for NFTs. Then we propose a novel\nrepurchase protocol for a participant owing a portion of NFT to repurchase\nother shares to obtain the complete ownership. As participants may\nstrategically bid during the acquisition process, our repurchase process is\nformulated as a Stackelberg game to explore the equilibrium prices. We also\nprovide solutions to handle difficulties at market such as budget constraints\nand lazy bidders.",
    "descriptor": "\nComments: To appear in Financial Cryptography and Data Security 2022\n",
    "authors": [
      "Hongyin Chen",
      "Yukun Cheng",
      "Xiaotie Deng",
      "Wenhan Huang",
      "Linxuan Rong"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Theoretical Economics (econ.TH)"
    ],
    "url": "https://arxiv.org/abs/2202.02199"
  },
  {
    "id": "arXiv:2202.02200",
    "title": "Learning with Neighbor Consistency for Noisy Labels",
    "abstract": "Recent advances in deep learning have relied on large, labelled datasets to\ntrain high-capacity models. However, collecting large datasets in a time- and\ncost-efficient manner often results in label noise. We present a method for\nlearning from noisy labels that leverages similarities between training\nexamples in feature space, encouraging the prediction of each example to be\nsimilar to its nearest neighbours. Compared to training algorithms that use\nmultiple models or distinct stages, our approach takes the form of a simple,\nadditional regularization term. It can be interpreted as an inductive version\nof the classical, transductive label propagation algorithm. We thoroughly\nevaluate our method on datasets evaluating both synthetic (CIFAR-10, CIFAR-100)\nand realistic (mini-WebVision, Clothing1M, mini-ImageNet-Red) noise, and\nachieve competitive or state-of-the-art accuracies across all of them.",
    "descriptor": "",
    "authors": [
      "Ahmet Iscen",
      "Jack Valmadre",
      "Anurag Arnab",
      "Cordelia Schmid"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.02200"
  },
  {
    "id": "arXiv:2202.02207",
    "title": "Active Visuo-Tactile Interactive Robotic Perception for Accurate Object  Pose Estimation in Dense Clutter",
    "abstract": "This work presents a novel active visuo-tactile based framework for robotic\nsystems to accurately estimate pose of objects in dense cluttered environments.\nThe scene representation is derived using a novel declutter graph (DG) which\ndescribes the relationship among objects in the scene for decluttering by\nleveraging semantic segmentation and grasp affordances networks. The graph\nformulation allows robots to efficiently declutter the workspace by\nautonomously selecting the next best object to remove and the optimal action\n(prehensile or non-prehensile) to perform. Furthermore, we propose a novel\ntranslation-invariant Quaternion filter (TIQF) for active vision and active\ntactile based pose estimation. Both active visual and active tactile points are\nselected by maximizing the expected information gain. We evaluate our proposed\nframework on a system with two robots coordinating on randomized scenes of\ndense cluttered objects and perform ablation studies with static vision and\nactive vision based estimation prior and post decluttering as baselines. Our\nproposed active visuo-tactile interactive perception framework shows upto 36%\nimprovement in pose accuracy compared to the active vision baseline.",
    "descriptor": "\nComments: Accepted for publication at IEEE Robotics and Automation Letters and IEEE International Conference on Robotics and Automation (ICRA) 2022\n",
    "authors": [
      "Prajval Kumar Murali",
      "Anirvan Dutta",
      "Michael Gentner",
      "Etienne Burdet",
      "Ravinder Dahiya",
      "Mohsen Kaboli"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.02207"
  },
  {
    "id": "arXiv:2202.02210",
    "title": "Simulating and visualizing COVID-19 contact tracing with Corona-Warn-App  for increased understanding of its privacy-preserving design",
    "abstract": "The world is under an ongoing pandemic, COVID-19, of a scale last seen a\ncentury ago. Contact tracing is one of the most critical and highly effective\ntools for containing and breaking the chain of infections especially in the\ncase of infectious respiratory diseases like COVID-19. Thanks to the\ntechnological progress in our times, we now have digital mobile applications\nlike the Corona-Warn-App for digital contact tracing. However, due to the\ninvasive nature of contact tracing, it is very important to preserve the\nprivacy of the users. Privacy preservation is important for increasing trust in\nthe app and subsequently enabling its widespread usage in a privacy-valuing\npopulation. In this paper, we present a visual simulation of the working of the\nCorona-Warn-App to demonstrate how the privacy of its users is preserved, how\nthey're notified of infectious contacts and how it helps in containing the\nspread of COVID-19.",
    "descriptor": "",
    "authors": [
      "Nikolas Gritsch",
      "Benjamin Tegeler",
      "Faheem Hassan Zunjani"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.02210"
  },
  {
    "id": "arXiv:2202.02212",
    "title": "Video Violence Recognition and Localization using a Semi-Supervised  Hard-Attention Model",
    "abstract": "Empowering automated violence monitoring and surveillance systems amid the\ngrowing social violence and extremist activities worldwide could keep\ncommunities safe and save lives. The questionable reliability of human\nmonitoring personnel and the increasing number of surveillance cameras makes\nautomated artificial intelligence-based solutions compelling. Improving the\ncurrent state-of-the-art deep learning approaches to video violence recognition\nto higher levels of accuracy and performance could enable surveillance systems\nto be more reliable and scalable. The main contribution of the proposed deep\nreinforcement learning method is to achieve state-of-the-art accuracy on RWF,\nHockey, and Movies datasets while removing some of the computationally\nexpensive processes and input features used in the previous solutions. The\nimplementation of hard attention using a semi-supervised learning method made\nthe proposed method capable of rough violence localization and added increased\nagent interpretability to the violence detection system.",
    "descriptor": "\nComments: 8 pages, 2 figures\n",
    "authors": [
      "Hamid Mohammadi",
      "Ehsan Nazerfard"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.02212"
  },
  {
    "id": "arXiv:2202.02215",
    "title": "A Survey on Safety-critical Scenario Generation from Methodological  Perspective",
    "abstract": "Autonomous driving systems have witnessed a great development during the past\nyears thanks to the advance in sensing and decision-making. One critical\nobstacle for their massive deployment in the real world is the evaluation of\nsafety. Most existing driving systems are still trained and evaluated on\nnaturalistic scenarios that account for the vast majority of daily life or\nheuristically-generated adversarial ones. However, the large population of cars\nrequires an extremely low collision rate, indicating safety-critical scenarios\ncollected in the real world would be rare. Thus, methods to artificially\ngenerate artificial scenarios becomes critical to manage the risk and reduce\nthe cost. In this survey, we focus on the algorithms of safety-critical\nscenario generation. We firstly provide a comprehensive taxonomy of existing\nalgorithms by dividing them into three categories: data-driven generation,\nadversarial generation, and knowledge-based generation. Then, we discuss useful\ntools for scenario generation, including simulation platforms and packages.\nFinally, we extend our discussion to five main challenges of current works --\nfidelity, efficiency, diversity, transferability, controllability -- and the\nresearch opportunities lighted up by these challenges.",
    "descriptor": "\nComments: 16 pages, 4 figures\n",
    "authors": [
      "Wenhao Ding",
      "Chejian Xu",
      "Haohong Lin",
      "Bo Li",
      "Ding Zhao"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.02215"
  },
  {
    "id": "arXiv:2202.02216",
    "title": "Geometrically Higher Order Unfitted Space-Time Methods for PDEs on  Moving Domains",
    "abstract": "In this paper, we propose new geometrically unfitted space-time Finite\nElement methods for partial differential equations posed on moving domains of\nhigher order accuracy in space and time. As a model problem, the\nconvection-diffusion problem on a moving domain is studied. For geometrically\nhigher order accuracy, we apply a parametric mapping on a background space-time\ntensor-product mesh. Concerning discretisation in time, we consider\ndiscontinuous Galerkin, as well as related continuous (Petrov-)Galerkin and\nGalerkin collocation methods. For stabilisation with respect to bad cut\nconfigurations and as an extension mechanism that is required for the latter\ntwo schemes, a ghost penalty stabilisation is employed. The article puts an\nemphasis on the techniques that allow to achieve a robust but higher order\ngeometry handling for smooth domains. We investigate the computational\nproperties of the respective methods in a series of numerical experiments.\nThese include studies in different dimensions for different polynomial degrees\nin space and time, validating the higher order accuracy in both variables.",
    "descriptor": "",
    "authors": [
      "Fabian Heimann",
      "Christoph Lehrenfeld",
      "Janosch Preu\u00df"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.02216"
  },
  {
    "id": "arXiv:2202.02217",
    "title": "Flow Time Scheduling and Prefix Beck-Fiala",
    "abstract": "We relate discrepancy theory with the classic scheduling problems of\nminimizing max flow time and total flow time on unrelated machines.\nSpecifically, we give a general reduction that allows us to transfer\ndiscrepancy bounds in the prefix Beck-Fiala (bounded $\\ell_1$-norm) setting to\nbounds on the flow time of an optimal schedule.\nCombining our reduction with a deep result proved by Banaszczyk via convex\ngeometry, give guarantees of $O(\\sqrt{\\log n})$ and $O(\\sqrt{\\log n} \\log P)$\nfor max flow time and total flow time, respectively, improving upon the\nprevious best guarantees of $O(\\log n)$ and $O(\\log n \\log P)$. Apart from the\nimproved guarantees, the reduction motivates seemingly easy versions of prefix\ndiscrepancy questions: any constant bound on prefix Beck-Fiala where vectors\nhave sparsity two (sparsity one being trivial) would already yield tight\nguarantees for both max flow time and total flow time. While known techniques\nsolve this case when the entries take values in $\\{-1,0,1\\}$, we show that they\nare unlikely to transfer to the more general $2$-sparse case of bounded\n$\\ell_1$-norm.",
    "descriptor": "\nComments: An extended abstract will appear in the proceedings of STOC'22\n",
    "authors": [
      "Nikhil Bansal",
      "Lars Rohwedder",
      "Ola Svensson"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2202.02217"
  },
  {
    "id": "arXiv:2202.02219",
    "title": "Hyper-differential sensitivity analysis for nonlinear Bayesian inverse  problems",
    "abstract": "We consider hyper-differential sensitivity analysis (HDSA) of nonlinear\nBayesian inverse problems governed by PDEs with infinite-dimensional\nparameters. In previous works, HDSA has been used to assess the sensitivity of\nthe solution of deterministic inverse problems to additional model\nuncertainties and also different types of measurement data. In the present\nwork, we extend HDSA to the class of Bayesian inverse problems governed by\nPDEs. The focus is on assessing the sensitivity of certain key quantities\nderived from the posterior distribution. Specifically, we focus on analyzing\nthe sensitivity of the MAP point and the Bayes risk and make full use of the\ninformation embedded in the Bayesian inverse problem. After establishing our\nmathematical framework for HDSA of Bayesian inverse problems, we present a\ndetailed computational approach for computing the proposed HDSA indices. We\nexamine the effectiveness of the proposed approach on a model inverse problem\ngoverned by a PDE for heat conduction.",
    "descriptor": "",
    "authors": [
      "Isaac Sunseri",
      "Alen Alexanderian",
      "Joseph Hart",
      "Bart van Bloemen Waanders"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.02219"
  },
  {
    "id": "arXiv:2202.02223",
    "title": "Systems for Memory Disaggregation: Challenges & Opportunities",
    "abstract": "Memory disaggregation addresses memory imbalance in a cluster by decoupling\nCPU and memory allocations of applications while also increasing the effective\nmemory capacity for (memory-intensive) applications beyond the local memory\nlimit imposed by traditional fixed-capacity servers. As the network speeds in\nthe tightly-knit environments like modern datacenters inch closer to the DRAM\nspeeds, there has been a recent proliferation of work in this space ranging\nfrom software solutions that pool memory of traditional servers for the shared\nuse of the cluster to systems targeting the memory disaggregation in the\nhardware. In this report, we look at some of these recent memory disaggregation\nsystems and study the important factors that guide their design, such as the\ninterface through which the memory is exposed to the application, their runtime\ndesign and relevant optimizations to retain the near-native application\nperformance, various approaches they employ in managing cluster memory to\nmaximize utilization, etc. and we analyze the associated trade-offs. We\nconclude with a discussion on some open questions and potential future\ndirections that can render disaggregation more amenable for adoption.",
    "descriptor": "\nComments: 11 pages\n",
    "authors": [
      "Anil Yelam"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Operating Systems (cs.OS)"
    ],
    "url": "https://arxiv.org/abs/2202.02223"
  },
  {
    "id": "arXiv:2202.02232",
    "title": "Bootstrapped Representation Learning for Skeleton-Based Action  Recognition",
    "abstract": "In this work, we study self-supervised representation learning for 3D\nskeleton-based action recognition. We extend Bootstrap Your Own Latent (BYOL)\nfor representation learning on skeleton sequence data and propose a new data\naugmentation strategy including two asymmetric transformation pipelines. We\nalso introduce a multi-viewpoint sampling method that leverages multiple\nviewing angles of the same action captured by different cameras. In the\nsemi-supervised setting, we show that the performance can be further improved\nby knowledge distillation from wider networks, leveraging once more the\nunlabeled samples. We conduct extensive experiments on the NTU-60 and NTU-120\ndatasets to demonstrate the performance of our proposed method. Our method\nconsistently outperforms the current state of the art on both linear evaluation\nand semi-supervised benchmarks.",
    "descriptor": "\nComments: 10 pages, 3 figures, under review\n",
    "authors": [
      "Olivier Moliner",
      "Sangxia Huang",
      "Kalle \u00c5str\u00f6m"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.02232"
  },
  {
    "id": "arXiv:2202.02236",
    "title": "Pixle: a fast and effective black-box attack based on rearranging pixels",
    "abstract": "Recent research has found that neural networks are vulnerable to several\ntypes of adversarial attacks, where the input samples are modified in such a\nway that the model produces a wrong prediction that misclassifies the\nadversarial sample. In this paper we focus on black-box adversarial attacks,\nthat can be performed without knowing the inner structure of the attacked\nmodel, nor the training procedure, and we propose a novel attack that is\ncapable of correctly attacking a high percentage of samples by rearranging a\nsmall number of pixels within the attacked image. We demonstrate that our\nattack works on a large number of datasets and models, that it requires a small\nnumber of iterations, and that the distance between the original sample and the\nadversarial one is negligible to the human eye.",
    "descriptor": "",
    "authors": [
      "Jary Pomponi",
      "Simone Scardapane",
      "Aurelio Uncini"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.02236"
  },
  {
    "id": "arXiv:2202.02241",
    "title": "Sparse Polynomial Optimisation for Neural Network Verification",
    "abstract": "The prevalence of neural networks in society is expanding at an increasing\nrate. It is becoming clear that providing robust guarantees on systems that use\nneural networks is very important, especially in safety-critical applications.\nA trained neural network's sensitivity to adversarial attacks is one of its\ngreatest shortcomings. To provide robust guarantees, one popular method that\nhas seen success is to bound the activation functions using equality and\ninequality constraints. However, there are numerous ways to form these bounds,\nproviding a trade-off between conservativeness and complexity. Depending on the\ncomplexity of these bounds, the computational time of the optimisation problem\nvaries, with longer solve times often leading to tighter bounds. We approach\nthe problem from a different perspective, using sparse polynomial optimisation\ntheory and the Positivstellensatz, which derives from the field of real\nalgebraic geometry. The former exploits the natural cascading structure of the\nneural network using ideas from chordal sparsity while the later asserts the\nemptiness of a semi-algebraic set with a nested family of tests of\nnon-decreasing accuracy to provide tight bounds. We show that bounds can be\ntightened significantly, whilst the computational time remains reasonable. We\ncompare the solve times of different solvers and show how the accuracy can be\nimproved at the expense of increased computation time. We show that by using\nthis sparse polynomial framework the solve time and accuracy can be improved\nover other methods for neural network verification with ReLU, sigmoid and tanh\nactivation functions.",
    "descriptor": "\nComments: 25 pages, 20 figures\n",
    "authors": [
      "Matthew Newton",
      "Antonis Papachristodoulou"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.02241"
  },
  {
    "id": "arXiv:2202.02242",
    "title": "Dikaios: Privacy Auditing of Algorithmic Fairness via Attribute  Inference Attacks",
    "abstract": "Machine learning (ML) models have been deployed for high-stakes applications.\nDue to class imbalance in the sensitive attribute observed in the datasets, ML\nmodels are unfair on minority subgroups identified by a sensitive attribute,\nsuch as race and sex. In-processing fairness algorithms ensure model\npredictions are independent of sensitive attribute. Furthermore, ML models are\nvulnerable to attribute inference attacks where an adversary can identify the\nvalues of sensitive attribute by exploiting their distinguishable model\npredictions. Despite privacy and fairness being important pillars of\ntrustworthy ML, the privacy risk introduced by fairness algorithms with respect\nto attribute leakage has not been studied. We identify attribute inference\nattacks as an effective measure for auditing blackbox fairness algorithms to\nenable model builder to account for privacy and fairness in the model design.\nWe proposed Dikaios, a privacy auditing tool for fairness algorithms for model\nbuilders which leveraged a new effective attribute inference attack that\naccount for the class imbalance in sensitive attributes through an adaptive\nprediction threshold. We evaluated Dikaios to perform a privacy audit of two\nin-processing fairness algorithms over five datasets. We show that our\nattribute inference attacks with adaptive prediction threshold significantly\noutperform prior attacks. We highlighted the limitations of in-processing\nfairness algorithms to ensure indistinguishable predictions across different\nvalues of sensitive attributes. Indeed, the attribute privacy risk of these\nin-processing fairness schemes is highly variable according to the proportion\nof the sensitive attributes in the dataset. This unpredictable effect of\nfairness mechanisms on the attribute privacy risk is an important limitation on\ntheir utilization which has to be accounted by the model builder.",
    "descriptor": "",
    "authors": [
      "Jan Aalmoes",
      "Vasisht Duddu",
      "Antoine Boutet"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.02242"
  },
  {
    "id": "arXiv:2202.02248",
    "title": "Backpropagation Neural Tree",
    "abstract": "We propose a novel algorithm called Backpropagation Neural Tree (BNeuralT),\nwhich is a stochastic computational dendritic tree. BNeuralT takes random\nrepeated inputs through its leaves and imposes dendritic nonlinearities through\nits internal connections like a biological dendritic tree would do. Considering\nthe dendritic-tree like plausible biological properties, BNeuralT is a single\nneuron neural tree model with its internal sub-trees resembling dendritic\nnonlinearities. BNeuralT algorithm produces an ad hoc neural tree which is\ntrained using a stochastic gradient descent optimizer like gradient descent\n(GD), momentum GD, Nesterov accelerated GD, Adagrad, RMSprop, or Adam. BNeuralT\ntraining has two phases, each computed in a depth-first search manner: the\nforward pass computes neural tree's output in a post-order traversal, while the\nerror backpropagation during the backward pass is performed recursively in a\npre-order traversal. A BNeuralT model can be considered a minimal subset of a\nneural network (NN), meaning it is a \"thinned\" NN whose complexity is lower\nthan an ordinary NN. Our algorithm produces high-performing and parsimonious\nmodels balancing the complexity with descriptive ability on a wide variety of\nmachine learning problems: classification, regression, and pattern recognition.",
    "descriptor": "",
    "authors": [
      "Varun Ojha",
      "Giuseppe Nicosia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.02248"
  },
  {
    "id": "arXiv:2202.02259",
    "title": "Targeted Code Inspection based on Human Errors",
    "abstract": "As a direct cause of software defects, human error is the key to\nunderstanding and identifying defects. We propose a new code inspection method:\ntargeted code inspection based on human error mechanisms of software engineers.\nBased on the common erroneous mechanisms of human cognition, the method targets\nerror-prone codes with high efficiency and minimum effort. The proposed method\nis supported by preliminary evidence in a pilot study.",
    "descriptor": "\nComments: Fast Abstract, The 32nd International Symposium on Software Reliability Engineering (ISSRE 2021), Oct.25-28, 2021\n",
    "authors": [
      "Fuqun Huang",
      "Henrique Madeira"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2202.02259"
  },
  {
    "id": "arXiv:2202.02262",
    "title": "Decoupling Local and Global Representations of Time Series",
    "abstract": "Real-world time series data are often generated from several sources of\nvariation. Learning representations that capture the factors contributing to\nthis variability enables a better understanding of the data via its underlying\ngenerative process and improves performance on downstream machine learning\ntasks. This paper proposes a novel generative approach for learning\nrepresentations for the global and local factors of variation in time series.\nThe local representation of each sample models non-stationarity over time with\na stochastic process prior, and the global representation of the sample encodes\nthe time-independent characteristics. To encourage decoupling between the\nrepresentations, we introduce counterfactual regularization that minimizes the\nmutual information between the two variables. In experiments, we demonstrate\nsuccessful recovery of the true local and global variability factors on\nsimulated data, and show that representations learned using our method yield\nsuperior performance on downstream tasks on real-world datasets. We believe\nthat the proposed way of defining representations is beneficial for data\nmodelling and yields better insights into the complexity of real-world data.",
    "descriptor": "",
    "authors": [
      "Sana Tonekaboni",
      "Chun-Liang Li",
      "Sercan Arik",
      "Anna Goldenberg",
      "Tomas Pfister"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.02262"
  },
  {
    "id": "arXiv:2202.02265",
    "title": "Iterative Self Knowledge Distillation -- From Pothole Classification to  Fine-Grained and COVID Recognition",
    "abstract": "Pothole classification has become an important task for road inspection\nvehicles to save drivers from potential car accidents and repair bills. Given\nthe limited computational power and fixed number of training epochs, we propose\niterative self knowledge distillation (ISKD) to train lightweight pothole\nclassifiers. Designed to improve both the teacher and student models over time\nin knowledge distillation, ISKD outperforms the state-of-the-art self knowledge\ndistillation method on three pothole classification datasets across four\nlightweight network architectures, which supports that self knowledge\ndistillation should be done iteratively instead of just once. The accuracy\nrelation between the teacher and student models shows that the student model\ncan still benefit from a moderately trained teacher model. Implying that better\nteacher models generally produce better student models, our results justify the\ndesign of ISKD. In addition to pothole classification, we also demonstrate the\nefficacy of ISKD on six additional datasets associated with generic\nclassification, fine-grained classification, and medical imaging application,\nwhich supports that ISKD can serve as a general-purpose performance booster\nwithout the need of a given teacher model and extra trainable parameters.",
    "descriptor": "\nComments: ICASSP 2022\n",
    "authors": [
      "Kuan-Chuan Peng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2202.02265"
  },
  {
    "id": "arXiv:2202.02268",
    "title": "StonkBERT: Can Language Models Predict Medium-Run Stock Price Movements?",
    "abstract": "To answer this question, we fine-tune transformer-based language models,\nincluding BERT, on different sources of company-related text data for a\nclassification task to predict the one-year stock price performance. We use\nthree different types of text data: News articles, blogs, and annual reports.\nThis allows us to analyze to what extent the performance of language models is\ndependent on the type of the underlying document. StonkBERT, our\ntransformer-based stock performance classifier, shows substantial improvement\nin predictive accuracy compared to traditional language models. The highest\nperformance was achieved with news articles as text source. Performance\nsimulations indicate that these improvements in classification accuracy also\ntranslate into above-average stock market returns.",
    "descriptor": "",
    "authors": [
      "Stefan Pasch",
      "Daniel Ehnes"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Computational Finance (q-fin.CP)"
    ],
    "url": "https://arxiv.org/abs/2202.02268"
  },
  {
    "id": "arXiv:2202.02270",
    "title": "Direct Telemetry Access",
    "abstract": "The emergence of programmable switches allows operators to collect a vast\namount of fine-grained telemetry data in real time. However, consolidating the\ntelemetry reports at centralized collectors to gain a network-wide view poses\nan immense challenge. The received data has to be transported from the\nswitches, parsed, manipulated, and inserted in queryable data structures. As\nthe network scales, this requires excessive CPU processing. RDMA is a transport\nprotocol that bypasses the CPU and allows extremely high data transfer rates.\nYet, RDMA is not designed for telemetry collection: it requires a stateful\nconnection, supports only a small number of concurrent writers, and has limited\nwriting primitives, which restricts its data aggregation applicability.\nWe introduce Direct Telemetry Access (DTA), a solution that allows fast and\nefficient telemetry collection, aggregation, and indexing. Our system\nestablishes RDMA connections only from collectors' ToR switches, called\n\\emph{translators}, that process DTA reports from all other switches. DTA\nfeatures novel and expressive reporting primitives such as Key-Write, Append,\nSketch-Merge, and Key-Increment that allow integration of telemetry systems\nsuch as INT and others. The translators then aggregate, batch, and write the\nreports to collectors' memory in queryable form.",
    "descriptor": "",
    "authors": [
      "Jonatan Langlet",
      "Ran Ben Basat",
      "Sivaramakrishnan Ramanathan",
      "Gabriele Oliaro",
      "Michael Mitzenmacher",
      "Minlan Yu",
      "Gianni Antichi"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2202.02270"
  },
  {
    "id": "arXiv:2202.02278",
    "title": "LTU Attacker for Membership Inference",
    "abstract": "We address the problem of defending predictive models, such as machine\nlearning classifiers (Defender models), against membership inference attacks,\nin both the black-box and white-box setting, when the trainer and the trained\nmodel are publicly released. The Defender aims at optimizing a dual objective:\nutility and privacy. Both utility and privacy are evaluated with an external\napparatus including an Attacker and an Evaluator. On one hand, Reserved data,\ndistributed similarly to the Defender training data, is used to evaluate\nUtility; on the other hand, Reserved data, mixed with Defender training data,\nis used to evaluate membership inference attack robustness. In both cases\nclassification accuracy or error rate are used as the metric: Utility is\nevaluated with the classification accuracy of the Defender model; Privacy is\nevaluated with the membership prediction error of a so-called\n\"Leave-Two-Unlabeled\" LTU Attacker, having access to all of the Defender and\nReserved data, except for the membership label of one sample from each. We\nprove that, under certain conditions, even a \"na\\\"ive\" LTU Attacker can achieve\nlower bounds on privacy loss with simple attack strategies, leading to concrete\nnecessary conditions to protect privacy, including: preventing over-fitting and\nadding some amount of randomness. However, we also show that such a na\\\"ive LTU\nAttacker can fail to attack the privacy of models known to be vulnerable in the\nliterature, demonstrating that knowledge must be complemented with strong\nattack strategies to turn the LTU Attacker into a powerful means of evaluating\nprivacy. Our experiments on the QMNIST and CIFAR-10 datasets validate our\ntheoretical results and confirm the roles of over-fitting prevention and\nrandomness in the algorithms to protect against privacy attacks.",
    "descriptor": "\nComments: 10 pages, 4 figures, accepted for presentation at the Third AAAI Workshop on Privacy-Preserving Artificial Intelligence (PPAI-22), February 2022\n",
    "authors": [
      "Joseph Pedersen",
      "Rafael Mu\u00f1oz-G\u00f3mez",
      "Jiangnan Huang",
      "Haozhe Sun",
      "Wei-Wei Tu",
      "Isabelle Guyon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.02278"
  },
  {
    "id": "arXiv:2202.02281",
    "title": "\"I'm Just Overwhelmed\": Investigating Physical Therapy Accessibility and  Technology Interventions for People with Disabilities and/or Chronic  Conditions",
    "abstract": "Many individuals with disabilities and/or chronic conditions (da/cc)\nexperience symptoms that may require intermittent or ongoing medical care.\nHowever, healthcare is an often-overlooked domain for accessibility work, where\naccess needs associated with temporary and long-term disability must be\naddressed to increase the utility of physical and digital interactions with\nhealthcare workers and spaces. Our work focuses on a specific domain of\nhealthcare often used by individuals with da/ccs: Physical Therapy (PT).\nThrough a twelve-person interview study, we examined how people's access to PT\nfor their da/cc is hampered by social (e.g., physically visiting a PT clinic)\nand physiological (e.g., chronic pain) barriers, and how technology could\nimprove PT access. In-person PT is often inaccessible to our participants due\nto lack of transportation and insufficient insurance coverage. As such, many of\nour participants relied on at-home PT to manage their da/cc symptoms and worked\ntowards PT goals. Participants felt that PT barriers, such as having\nparticularly bad symptoms or feeling short on time, could be addressed with\nwell-designed technology that flexibly adapts to the person's dynamically\nchanging needs while supporting their PT goals. We introduce core design\nprinciples (flexibility, movement tracking, community building) and tensions\n(insurance) to consider when developing technology to support PT access.\nRethinking da/cc access to PT from a lens that includes social and\nphysiological barriers presents opportunities to integrate accessibility and\nflexibility into PT technology.",
    "descriptor": "\nComments: 21 pages, 2 tables\n",
    "authors": [
      "Momona Yamagami",
      "Kelly Mack",
      "Jennifer Mankoff",
      "Katherine M. Steele"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2202.02281"
  },
  {
    "id": "arXiv:2202.02282",
    "title": "Benefits of Rate-Sharing for Distributed Hypothesis Testing",
    "abstract": "We study distributed binary hypothesis testing with a single sensor and two\nremote decision centers that are also equipped with local sensors. The\ncommunication between the sensor and the two decision centers takes place over\nthree links: a shared link to both centers and an individual link to each of\nthe two centers. All communication links are subject to expected rate\nconstraints. This paper characterizes the optimal exponents region of the\ntype-II error for given type-I error thresholds at the two decision centers and\nfurther simplifies the expressions in the special case of having only the\nsingle shared link. The exponents region illustrates a gain under expected rate\nconstraints compared to equivalent maximum rate constraints. Moreover, it\nexhibits a tradeoff between the exponents achieved at the two centers.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2106.12299\n",
    "authors": [
      "Mustapha Hamad",
      "Mireille Sarkiss",
      "Mich\u00e8le Wigger"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.02282"
  },
  {
    "id": "arXiv:2202.02283",
    "title": "Choosing an Appropriate Platform and Workflow for Processing Camera Trap  Data using Artificial Intelligence",
    "abstract": "Camera traps have transformed how ecologists study wildlife species\ndistributions, activity patterns, and interspecific interactions. Although\ncamera traps provide a cost-effective method for monitoring species, the time\nrequired for data processing can limit survey efficiency. Thus, the potential\nof Artificial Intelligence (AI), specifically Deep Learning (DL), to process\ncamera-trap data has gained considerable attention. Using DL for these\napplications involves training algorithms, such as Convolutional Neural\nNetworks (CNNs), to automatically detect objects and classify species. To\novercome technical challenges associated with training CNNs, several research\ncommunities have recently developed platforms that incorporate DL in\neasy-to-use interfaces. We review key characteristics of four AI-powered\nplatforms --Wildlife Insights (WI), MegaDetector (MD), Machine Learning for\nWildlife Image Classification (MLWIC2), and Conservation AI-- including data\nmanagement tools and AI features. We also provide R code in an open-source\nGitBook, to demonstrate how users can evaluate model performance, and\nincorporate AI output in semi-automated workflows. We found that species\nclassifications from WI and MLWIC2 generally had low recall values (animals\nthat were present in the images often were not classified to the correct\nspecies). Yet, the precision of WI and MLWIC2 classifications for some species\nwas high (i.e., when classifications were made, they were generally accurate).\nMD, which classifies images using broader categories (e.g., \"blank\" or\n\"animal\"), also performed well. Thus, we conclude that, although species\nclassifiers were not accurate enough to automate image processing, DL could be\nused to improve efficiencies by accepting classifications with high confidence\nvalues for certain species or by filtering images containing blanks.",
    "descriptor": "\nComments: 30 pages, 2 figures, 3 tables\n",
    "authors": [
      "Juliana V\u00e9lez",
      "Paula J. Castiblanco-Camacho",
      "Michael A. Tabak",
      "Carl Chalmers",
      "Paul Fergus",
      "John Fieberg"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.02283"
  },
  {
    "id": "arXiv:2202.02293",
    "title": "A nonlinear PPH-type reconstruction based on equilateral triangles",
    "abstract": "In this paper we introduce a new nonlinear reconstruction operator over two\ndimensional triangularized domains with equilateral triangles. We focus on the\nlocal definition of the operator. The ideas behind this definition come from\nsome basic properties of the Harmonic mean of three positive values. We prove\nsome results regarding the approximation properties of the operator and we\ncarry out some numerical tests giving evidence of the avoidance of any Gibbs\neffects.",
    "descriptor": "\nComments: 12 pages, 3 figures\n",
    "authors": [
      "S. Amat",
      "P. Ortiz",
      "J. Ruiz",
      "J.C. Trillo",
      "D. F. Ya\u00f1ez"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.02293"
  },
  {
    "id": "arXiv:2202.02294",
    "title": "Pre-Trained Neural Language Models for Automatic Mobile App User  Feedback Answer Generation",
    "abstract": "Studies show that developers' answers to the mobile app users' feedbacks on\napp stores can increase the apps' star rating. To help app developers generate\nanswers that are related to the users' issues, recent studies develop models to\ngenerate the answers automatically. Aims: The app response generation models\nuse deep neural networks and require training data. Pre-Trained neural language\nModels (PTM) used in Natural Language Processing (NLP) take advantage of the\ninformation they learned from a large corpora in an unsupervised manner, and\ncan reduce the amount of required training data. In this paper, we evaluate\nPTMs to generate replies to the mobile app user feedbacks. Method: We train a\nTransformer model from scratch and fine-tune two PTMs to evaluate the generated\nresponses, which are compared to RRGEN, a current app response model. We also\nevaluate the models with different portions of the training data. Results: The\nresults on a large dataset evaluated by automatic metrics show that PTMs obtain\nlower scores than the baselines. However, our human evaluation confirms that\nPTMs can generate more relevant and meaningful responses to the posted\nfeedbacks. Moreover, the performance of PTMs has less drop compared to other\nmodels when the amount of training data is reduced to 1/3. Conclusion: PTMs are\nuseful in generating responses to app reviews and are more robust models to the\namount of training data provided. However, the prediction time is 19X than\nRRGEN. This study can provide new avenues for research in adapting the PTMs for\nanalyzing mobile app user feedbacks. Index Terms-mobile app user feedback\nanalysis, neural pre-trained language models, automatic answer generation",
    "descriptor": "\nComments: 6 pages, published in the 2021 ASE RAISE workshop\n",
    "authors": [
      "Yue Cao",
      "Fatemeh H. Fard"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2202.02294"
  },
  {
    "id": "arXiv:2202.02296",
    "title": "Graph-Coupled Oscillator Networks",
    "abstract": "We propose Graph-Coupled Oscillator Networks (GraphCON), a novel framework\nfor deep learning on graphs. It is based on discretizations of a second-order\nsystem of ordinary differential equations (ODEs), which model a network of\nnonlinear forced and damped oscillators, coupled via the adjacency structure of\nthe underlying graph. The flexibility of our framework permits any basic GNN\nlayer (e.g. convolutional or attentional) as the coupling function, from which\na multi-layer deep neural network is built up via the dynamics of the proposed\nODEs. We relate the oversmoothing problem, commonly encountered in GNNs, to the\nstability of steady states of the underlying ODE and show that zero-Dirichlet\nenergy steady states are not stable for our proposed ODEs. This demonstrates\nthat the proposed framework mitigates the oversmoothing problem. Finally, we\nshow that our approach offers competitive performance with respect to the\nstate-of-the-art on a variety of graph-based learning tasks.",
    "descriptor": "",
    "authors": [
      "T. Konstantin Rusch",
      "Benjamin P. Chamberlain",
      "James Rowbottom",
      "Siddhartha Mishra",
      "Michael M. Bronstein"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.02296"
  },
  {
    "id": "arXiv:2202.02298",
    "title": "Towards a consistent interpretation of AIOps models",
    "abstract": "Artificial Intelligence for IT Operations (AIOps) has been adopted in\norganizations in various tasks, including interpreting models to identify\nindicators of service failures. To avoid misleading practitioners, AIOps model\ninterpretations should be consistent (i.e., different AIOps models on the same\ntask agree with one another on feature importance). However, many AIOps studies\nviolate established practices in the machine learning community when deriving\ninterpretations, such as interpreting models with suboptimal performance,\nthough the impact of such violations on the interpretation consistency has not\nbeen studied. In this paper, we investigate the consistency of AIOps model\ninterpretation along three dimensions: internal consistency, external\nconsistency, and time consistency. We conduct a case study on two AIOps tasks:\npredicting Google cluster job failures, and Backblaze hard drive failures. We\nfind that the randomness from learners, hyperparameter tuning, and data\nsampling should be controlled to generate consistent interpretations. AIOps\nmodels with AUCs greater than 0.75 yield more consistent interpretation\ncompared to low-performing models. Finally, AIOps models that are constructed\nwith the Sliding Window or Full History approaches have the most consistent\ninterpretation with the trends presented in the entire datasets. Our study\nprovides valuable guidelines for practitioners to derive consistent AIOps model\ninterpretation.",
    "descriptor": "",
    "authors": [
      "Yingzhe Lyu",
      "Gopi Krishnan Rajbahadur",
      "Dayi Lin",
      "Boyuan Chen",
      "Zhen Ming",
      "Jiang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2202.02298"
  },
  {
    "id": "arXiv:2202.02299",
    "title": "Multi-task head pose estimation in-the-wild",
    "abstract": "We present a deep learning-based multi-task approach for head pose estimation\nin images. We contribute with a network architecture and training strategy that\nharness the strong dependencies among face pose, alignment and visibility, to\nproduce a top performing model for all three tasks. Our architecture is an\nencoder-decoder CNN with residual blocks and lateral skip connections. We show\nthat the combination of head pose estimation and landmark-based face alignment\nsignificantly improve the performance of the former task. Further, the location\nof the pose task at the bottleneck layer, at the end of the encoder, and that\nof tasks depending on spatial information, such as visibility and alignment, in\nthe final decoder layer, also contribute to increase the final performance. In\nthe experiments conducted the proposed model outperforms the state-of-the-art\nin the face pose and visibility tasks. By including a final landmark regression\nstep it also produces face alignment results on par with the state-of-the-art.",
    "descriptor": "",
    "authors": [
      "Roberto Valle",
      "Jos\u00e9 Miguel Buenaposada",
      "Luis Baumela"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.02299"
  },
  {
    "id": "arXiv:2202.02300",
    "title": "On Robust Optimal Linear Feedback Stock Trading",
    "abstract": "The take-off point for this paper is the Simultaneous Long-Short (SLS)\ncontrol class, which is known to guarantee the so-called robust positive\nexpectation (RPE) property. That is, the expected cumulative trading gain-loss\nfunction is guaranteed to be positive for a broad class of stock price\nprocesses. This fact attracts many new extensions and ramifications to the SLS\ntheory. However, it is arguable that \"systematic\" way to select an optimal\ndecision variable that is robust in the RPE sense is still unresolved. To this\nend, we propose a modified SLS control structure, which we call the {double\nlinear feedback control scheme}, that allows us to solve the issue above for\nstock price processes involving independent returns. In this paper, we go\nbeyond the existing literature by not only deriving explicit expressions for\nthe expected value and variance of cumulative gain-loss function but also\nproving various theoretical results regarding {robust positive expected growth}\nand {monotonicity}. Subsequently, we propose a new {robust optimal gain\nselection problem} that seeks a solution maximizing the expected trading\ngain-loss subject to the prespecified standard deviation {and} RPE constraints.\nUnder some mild conditions, we show that the optimal solution exists and is\nunique. Moreover, a simple graphical approach that allows one to systematically\ndetermine the optimal solution is also proposed. Finally, some numerical and\nempirical studies using historical price data are also provided to support our\ntheory.",
    "descriptor": "\nComments: Submitted for possible publication\n",
    "authors": [
      "Chung-Han Hsieh"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)",
      "Computational Finance (q-fin.CP)",
      "Mathematical Finance (q-fin.MF)"
    ],
    "url": "https://arxiv.org/abs/2202.02300"
  },
  {
    "id": "arXiv:2202.02307",
    "title": "Privacy-aware Distributed Hypothesis Testing in Gray-Wyner Network with  Side Information",
    "abstract": "The problem of distributed binary hypothesis testing in the Gray-Wyner\nnetwork with side information is studied in this paper. An observer has access\nto a discrete memoryless and stationary source and describes its observation to\ntwo detectors via one common and two private channels. The channels are\nconsidered error-free but rate-limited. Each detector also has access to its\nown discrete memoryless and stationary source, i.e., the side information. The\ngoal is to perform two distinct binary hypothesis testings on the joint\ndistribution of observations at detectors. Additionally, the observer aims to\nkeep a correlated latent source private against the detectors. Equivocation is\nused as the measure of the privacy preserved for the latent source. An\nachievable inner bound is derived for the general case by introducing a\nnon-asymptotic account of the output statistics of the random binning.",
    "descriptor": "",
    "authors": [
      "Reza Abbasalipour",
      "Mahtab Mirmohseni"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.02307"
  },
  {
    "id": "arXiv:2202.02309",
    "title": "Neural Collision Detection for Deformable Objects",
    "abstract": "We propose a neural network-based approach for collision detection with\ndeformable objects. Unlike previous approaches based on bounding volume\nhierarchies, our neural approach does not require an update of the spatial data\nstructure when the object deforms. Our network is trained on the reduced\ndegrees of freedom of the object, so that we can use the same network to query\nfor collisions even when the object deforms. Our approach is simple to use and\nimplement, and it can readily be employed on the GPU. We demonstrate our\napproach with two concrete examples: a haptics application with a finite\nelement mesh, and cloth simulation with a skinned character.",
    "descriptor": "",
    "authors": [
      "Ryan S. Zesch",
      "Bethany R. Witemeyer",
      "Ziyan Xiong",
      "David I.W. Levin",
      "Shinjiro Sueda"
    ],
    "subjectives": [
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2202.02309"
  },
  {
    "id": "arXiv:2202.02310",
    "title": "EcoFlow: Efficient Convolutional Dataflows for Low-Power Neural Network  Accelerators",
    "abstract": "Dilated and transposed convolutions are widely used in modern convolutional\nneural networks (CNNs). These kernels are used extensively during CNN training\nand inference of applications such as image segmentation and high-resolution\nimage generation. Although these kernels have grown in popularity, they stress\ncurrent compute systems due to their high memory intensity, exascale compute\ndemands, and large energy consumption.\nWe find that commonly-used low-power CNN inference accelerators based on\nspatial architectures are not optimized for both of these convolutional\nkernels. Dilated and transposed convolutions introduce significant zero padding\nwhen mapped to the underlying spatial architecture, significantly degrading\nperformance and energy efficiency. Existing approaches that address this issue\nrequire significant design changes to the otherwise simple, efficient, and\nwell-adopted architectures used to compute direct convolutions.\nTo address this challenge, we propose EcoFlow, a new set of dataflows and\nmapping algorithms for dilated and transposed convolutions. These algorithms\nare tailored to execute efficiently on existing low-cost, small-scale spatial\narchitectures and requires minimal changes to the network-on-chip of existing\naccelerators. EcoFlow eliminates zero padding through careful dataflow\norchestration and data mapping tailored to the spatial architecture. EcoFlow\nenables flexible and high-performance transpose and dilated convolutions on\narchitectures that are otherwise optimized for CNN inference.\nWe evaluate the efficiency of EcoFlow on CNN training workloads and\nGenerative Adversarial Network (GAN) training workloads. Experiments in our new\ncycle-accurate simulator show that EcoFlow 1) reduces end-to-end CNN training\ntime between 7-85%, and 2) improves end-to-end GAN training performance between\n29-42%, compared to state-of-the-art CNN inference accelerators.",
    "descriptor": "",
    "authors": [
      "Lois Orosa",
      "Skanda Koppula",
      "Yaman Umuroglu",
      "Konstantinos Kanellopoulos",
      "Juan Gomez-Luna",
      "Michaela Blott",
      "Kees Vissers",
      "Onur Mutlu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2202.02310"
  },
  {
    "id": "arXiv:2202.02312",
    "title": "Interactive Mobile App Navigation with Uncertain or Under-specified  Natural Language Commands",
    "abstract": "We introduce Mobile app Tasks with Iterative Feedback (MoTIF), a new dataset\nwhere the goal is to complete a natural language query in a mobile app. Current\ndatasets for related tasks in interactive question answering, visual common\nsense reasoning, and question-answer plausibility prediction do not support\nresearch in resolving ambiguous natural language requests or operating in\ndiverse digital domains. As a result, they fail to capture complexities of real\nquestion answering or interactive tasks. In contrast, MoTIF contains natural\nlanguage requests that are not satisfiable, the first such work to investigate\nthis issue for interactive vision-language tasks. MoTIF also contains follow up\nquestions for ambiguous queries to enable research on task uncertainty\nresolution. We introduce task feasibility prediction and propose an initial\nmodel which obtains an F1 score of 61.1. We next benchmark task automation with\nour dataset and find adaptations of prior work perform poorly due to our\nrealistic language requests, obtaining an accuracy of only 20.2% when mapping\ncommands to grounded actions. We analyze performance and gain insight for\nfuture work that may bridge the gap between current model ability and what is\nneeded for successful use in application.",
    "descriptor": "",
    "authors": [
      "Andrea Burns",
      "Deniz Arsan",
      "Sanjna Agrawal",
      "Ranjitha Kumar",
      "Kate Saenko",
      "Bryan A. Plummer"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2202.02312"
  },
  {
    "id": "arXiv:2202.02314",
    "title": "Towards To-a-T Spatio-Temporal Focus for Skeleton-Based Action  Recognition",
    "abstract": "Graph Convolutional Networks (GCNs) have been widely used to model the\nhigh-order dynamic dependencies for skeleton-based action recognition. Most\nexisting approaches do not explicitly embed the high-order spatio-temporal\nimportance to joints' spatial connection topology and intensity, and they do\nnot have direct objectives on their attention module to jointly learn when and\nwhere to focus on in the action sequence. To address these problems, we propose\nthe To-a-T Spatio-Temporal Focus (STF), a skeleton-based action recognition\nframework that utilizes the spatio-temporal gradient to focus on relevant\nspatio-temporal features. We first propose the STF modules with learnable\ngradient-enforced and instance-dependent adjacency matrices to model the\nhigh-order spatio-temporal dynamics. Second, we propose three loss terms\ndefined on the gradient-based spatio-temporal focus to explicitly guide the\nclassifier when and where to look at, distinguish confusing classes, and\noptimize the stacked STF modules. STF outperforms the state-of-the-art methods\non the NTU RGB+D 60, NTU RGB+D 120, and Kinetics Skeleton 400 datasets in all\n15 settings over different views, subjects, setups, and input modalities, and\nSTF also shows better accuracy on scarce data and dataset shifting settings.",
    "descriptor": "\nComments: AAAI 2022\n",
    "authors": [
      "Lipeng Ke",
      "Kuan-Chuan Peng",
      "Siwei Lyu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.02314"
  },
  {
    "id": "arXiv:2202.02317",
    "title": "Webly Supervised Concept Expansion for General Purpose Vision Models",
    "abstract": "General purpose vision (GPV) systems are models that are designed to solve a\nwide array of visual tasks without requiring architectural changes. Today, GPVs\nprimarily learn both skills and concepts from large fully supervised datasets.\nScaling GPVs to tens of thousands of concepts by acquiring data to learn each\nconcept for every skill quickly becomes prohibitive. This work presents an\neffective and inexpensive alternative: learn skills from fully supervised\ndatasets, learn concepts from web image search results, and leverage a key\ncharacteristic of GPVs -- the ability to transfer visual knowledge across\nskills. We use a dataset of 1M+ images spanning 10k+ visual concepts to\ndemonstrate webly-supervised concept expansion for two existing GPVs (GPV-1 and\nVL-T5) on 3 benchmarks - 5 COCO based datasets (80 primary concepts), a newly\ncurated series of 5 datasets based on the OpenImages and VisualGenome\nrepositories (~500 concepts) and the Web-derived dataset (10k+ concepts). We\nalso propose a new architecture, GPV-2 that supports a variety of tasks -- from\nvision tasks like classification and localization to vision+language tasks like\nQA and captioning to more niche ones like human-object interaction recognition.\nGPV-2 benefits hugely from web data, outperforms GPV-1 and VL-T5 across these\nbenchmarks, and does well in a 0-shot setting at action and attribute\nrecognition.",
    "descriptor": "",
    "authors": [
      "Amita Kamath",
      "Christopher Clark",
      "Tanmay Gupta",
      "Eric Kolve",
      "Derek Hoiem",
      "Aniruddha Kembhavi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.02317"
  },
  {
    "id": "arXiv:2202.01782",
    "title": "Retinal Vessel Segmentation with Pixel-wise Adaptive Filters",
    "abstract": "Accurate retinal vessel segmentation is challenging because of the complex\ntexture of retinal vessels and low imaging contrast. Previous methods generally\nrefine segmentation results by cascading multiple deep networks, which are\ntime-consuming and inefficient. In this paper, we propose two novel methods to\naddress these challenges. First, we devise a light-weight module, named\nmulti-scale residual similarity gathering (MRSG), to generate pixel-wise\nadaptive filters (PA-Filters). Different from cascading multiple deep networks,\nonly one PA-Filter layer can improve the segmentation results. Second, we\nintroduce a response cue erasing (RCE) strategy to enhance the segmentation\naccuracy. Experimental results on the DRIVE, CHASE_DB1, and STARE datasets\ndemonstrate that our proposed method outperforms state-of-the-art methods while\nmaintaining a compact structure. Code is available at\nhttps://github.com/Limingxing00/Retinal-Vessel-Segmentation-ISBI20222.",
    "descriptor": "\nComments: Accepted by ISBI 2022\n",
    "authors": [
      "Mingxing Li",
      "Shenglong Zhou",
      "Chang Chen",
      "Yueyi Zhang",
      "Dong Liu",
      "Zhiwei Xiong"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.01782"
  },
  {
    "id": "arXiv:2202.01783",
    "title": "Oral cancer detection and interpretation: Deep multiple instance  learning versus conventional deep single instance learning",
    "abstract": "The current medical standard for setting an oral cancer (OC) diagnosis is\nhistological examination of a tissue sample from the oral cavity. This process\nis time consuming and more invasive than an alternative approach of acquiring a\nbrush sample followed by cytological analysis. Skilled cytotechnologists are\nable to detect changes due to malignancy, however, to introduce this approach\ninto clinical routine is associated with challenges such as a lack of experts\nand labour-intensive work. To design a trustworthy OC detection system that\nwould assist cytotechnologists, we are interested in AI-based methods that\nreliably can detect cancer given only per-patient labels (minimizing annotation\nbias), and also provide information on which cells are most relevant for the\ndiagnosis (enabling supervision and understanding). We, therefore, perform a\ncomparison of a conventional single instance learning (SIL) approach and a\nmodern multiple instance learning (MIL) method suitable for OC detection and\ninterpretation, utilizing three different neural network architectures. To\nfacilitate systematic evaluation of the considered approaches, we introduce a\nsynthetic PAP-QMNIST dataset, that serves as a model of OC data, while offering\naccess to per-instance ground truth. Our study indicates that on PAP-QMNIST,\nthe SIL performs better, on average, than the MIL approach. Performance at the\nbag level on real-world cytological data is similar for both methods, yet the\nsingle instance approach performs better on average. Visual examination by\ncytotechnologist indicates that the methods manage to identify cells which\ndeviate from normality, including malignant cells as well as those suspicious\nfor dysplasia. We share the code as open source at\nhttps://github.com/MIDA-group/OralCancerMILvsSIL",
    "descriptor": "",
    "authors": [
      "Nadezhda Koriakina",
      "Nata\u0161a Sladoje",
      "Vladimir Ba\u0161i\u0107",
      "Joakim Lindblad"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.01783"
  },
  {
    "id": "arXiv:2202.01793",
    "title": "Incorporating Sum Constraints into Multitask Gaussian Processes",
    "abstract": "Machine learning models can be improved by adapting them to respect existing\nbackground knowledge. In this paper we consider multitask Gaussian processes,\nwith background knowledge in the form of constraints that require a specific\nsum of the outputs to be constant. This is achieved by conditioning the prior\ndistribution on the constraint fulfillment. The approach allows for both linear\nand nonlinear constraints. We demonstrate that the constraints are fulfilled\nwith high precision and that the construction can improve the overall\nprediction accuracy as compared to the standard Gaussian process.",
    "descriptor": "",
    "authors": [
      "Philipp Pilar",
      "Carl Jidling",
      "Thomas B. Sch\u00f6n",
      "Niklas Wahlstr\u00f6m"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.01793"
  },
  {
    "id": "arXiv:2202.01816",
    "title": "SAFE-OCC: A Novelty Detection Framework for Convolutional Neural Network  Sensors and its Application in Process Control",
    "abstract": "We present a novelty detection framework for Convolutional Neural Network\n(CNN) sensors that we call Sensor-Activated Feature Extraction One-Class\nClassification (SAFE-OCC). We show that this framework enables the safe use of\ncomputer vision sensors in process control architectures. Emergent control\napplications use CNN models to map visual data to a state signal that can be\ninterpreted by the controller. Incorporating such sensors introduces a\nsignificant system operation vulnerability because CNN sensors can exhibit high\nprediction errors when exposed to novel (abnormal) visual data. Unfortunately,\nidentifying such novelties in real-time is nontrivial. To address this issue,\nthe SAFE-OCC framework leverages the convolutional blocks of the CNN to create\nan effective feature space to conduct novelty detection using a desired\none-class classification technique. This approach engenders a feature space\nthat directly corresponds to that used by the CNN sensor and avoids the need to\nderive an independent latent space. We demonstrate the effectiveness of\nSAFE-OCC via simulated control environments.",
    "descriptor": "",
    "authors": [
      "Joshua L. Pulsipher",
      "Luke D. J. Coutinho",
      "Tyler A. Soderstrom",
      "Victor M. Zavala"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.01816"
  },
  {
    "id": "arXiv:2202.01827",
    "title": "Proofs and Supplementary Material: Unified Characterization and  Precoding for Non-Stationary Channels",
    "abstract": "This document provides the supplementary material including a comprehensive\nrelated work, the complete proofs and extended evaluation results that support\nthe manuscript, \"Unified Characterization and Precoding for Non-Stationary\nChannels\", that was accepted for publication at IEEE International Conference\non Communications (ICC) 2022. Equations (1)--(34) refer to the equations from\nthe main manuscript, and the Theorem, Lemma and Corollaries correspond to those\nfrom the manuscript.",
    "descriptor": "",
    "authors": [
      "Zhibin Zou",
      "Maqsood Careem",
      "Aveek Dutta",
      "Ngwe Thawdar"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.01827"
  },
  {
    "id": "arXiv:2202.01828",
    "title": "Astronomical data organization, management and access in Scientific Data  Lakes",
    "abstract": "The data volumes stored in telescope archives is constantly increasing due to\nthe development and improvements in the instrumentation. Often the archives\nneed to be stored over a distributed storage architecture, provided by\nindependent compute centres. Such a distributed data archive requires\noverarching data management orchestration. Such orchestration comprises of\ntools which handle data storage and cataloguing, and steering transfers\nintegrating different storage systems and protocols, while being aware of data\npolicies and locality. In addition, it needs a common Authorisation and\nAuthentication Infrastructure (AAI) layer which is perceived as a single entity\nby end users and provides transparent data access.\nThe scientific domain of particle physics also uses complex and distributed\ndata management systems. The experiments at the Large Hadron Collider\\,(LHC)\naccelerator at CERN generate several hundred petabytes of data per year. This\ndata is globally distributed to partner sites and users using national compute\nfacilities. Several innovative tools were developed to successfully address the\ndistributed computing challenges in the context of the Worldwide LHC Computing\nGrid (WLCG).\nThe work being carried out in the ESCAPE project and in the Data\nInfrastructure for Open Science (DIOS) work package is to prototype a\nScientific Data Lake using the tools developed in the context of the WLCG,\nharnessing different physics scientific disciplines addressing FAIR standards\nand Open Data. We present how the Scientific Data Lake prototype is applied to\naddress astronomical data use cases. We introduce the software stack and also\ndiscuss some of the differences between the domains.",
    "descriptor": "\nComments: 4 pages, 1 figure, to appear in the proceedings of Astronomical Data Analysis Software and Systems XXXI published by ASP\n",
    "authors": [
      "Y.G. Grange",
      "V.N. Pandey",
      "X. Espinal",
      "R. Di Maria",
      "A.P. Millar"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2202.01828"
  },
  {
    "id": "arXiv:2202.01841",
    "title": "Transport Score Climbing: Variational Inference using Forward KL and  Adaptive Neural Transport",
    "abstract": "Variational inference often minimizes the \"reverse\" Kullbeck-Leibler (KL)\nKL(q||p) from the approximate distribution q to the posterior p. Recent work\nstudies the \"forward\" KL KL(p||q), which unlike reverse KL does not lead to\nvariational approximations that underestimate uncertainty. This paper\nintroduces Transport Score Climbing (TSC), a method that optimizes KL(p||q) by\nusing Hamiltonian Monte Carlo (HMC) and a novel adaptive transport map. The\ntransport map improves the trajectory of HMC by acting as a change of variable\nbetween the latent variable space and a warped space. TSC uses HMC samples to\ndynamically train the transport map while optimizing KL(p||q). TSC leverages\nsynergies, where better transport maps lead to better HMC sampling, which then\nleads to better transport maps. We demonstrate TSC on synthetic and real data.\nWe find that TSC achieves competitive performance when training variational\nautoencoders on large-scale data.",
    "descriptor": "\nComments: 14 pages, 8 figures\n",
    "authors": [
      "Liyi Zhang",
      "Christian A. Naesseth",
      "David M. Blei"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2202.01841"
  },
  {
    "id": "arXiv:2202.01850",
    "title": "A Robust Phased Elimination Algorithm for Corruption-Tolerant Gaussian  Process Bandits",
    "abstract": "We consider the sequential optimization of an unknown, continuous, and\nexpensive to evaluate reward function, from noisy and adversarially corrupted\nobserved rewards. When the corruption attacks are subject to a suitable budget\n$C$ and the function lives in a Reproducing Kernel Hilbert Space (RKHS), the\nproblem can be posed as corrupted Gaussian process (GP) bandit optimization. We\npropose a novel robust elimination-type algorithm that runs in epochs, combines\nexploration with infrequent switching to select a small subset of actions, and\nplays each action for multiple time instants. Our algorithm, Robust GP Phased\nElimination (RGP-PE), successfully balances robustness to corruptions with\nexploration and exploitation such that its performance degrades minimally in\nthe presence (or absence) of adversarial corruptions. When $T$ is the number of\nsamples and $\\gamma_T$ is the maximal information gain, the\ncorruption-dependent term in our regret bound is $O(C \\gamma_T^{3/2})$, which\nis significantly tighter than the existing $O(C \\sqrt{T \\gamma_T})$ for several\ncommonly-considered kernels. We perform the first empirical study of robustness\nin the corrupted GP bandit setting, and show that our algorithm is robust\nagainst a variety of adversarial attacks.",
    "descriptor": "\nComments: Preprint\n",
    "authors": [
      "Ilija Bogunovic",
      "Zihan Li",
      "Andreas Krause",
      "Jonathan Scarlett"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.01850"
  },
  {
    "id": "arXiv:2202.01854",
    "title": "Causal emergence is widespread across measures of causation",
    "abstract": "Causal emergence is the theory that macroscales can reduce the noise in\ncausal relationships, leading to stronger causes at the macroscale. First\nidentified using the effective information and later the integrated information\nin model systems, causal emergence has been analyzed in real data across the\nsciences since. But is it simply a quirk of these original measures? To answer\nthis question we examined over a dozen popular measures of causation, all\nindependently developed and widely used, and spanning different fields from\nphilosophy to statistics to psychology to genetics. All showed cases of causal\nemergence. This is because, we prove, measures of causation are based on a\nsmall set of related \"causal primitives.\" This consilience of\nindependently-developed measures of causation shows that macroscale causation\nis a general fact about causal relationships, is scientifically detectable, and\nis not a quirk of any particular measure of causation. This finding sets the\nscience of emergence on firmer ground, opening the door for the detection of\nintrinsic scales of function in complex systems, as well as assisting with\nscientific modeling and experimental interventions.",
    "descriptor": "\nComments: 22 pages, 8 figures\n",
    "authors": [
      "Renzo Comolatti",
      "Erik Hoel"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.01854"
  },
  {
    "id": "arXiv:2202.01856",
    "title": "Data-Driven Optimal Control via Linear Transfer Operators: A Convex  Approach",
    "abstract": "This paper is concerned with data-driven optimal control of nonlinear\nsystems. We present a convex formulation to the optimal control problem (OCP)\nwith a discounted cost function. We consider OCP with both positive and\nnegative discount factor. The convex approach relies on lifting nonlinear\nsystem dynamics in the space of densities using the linear Perron-Frobenius\n(P-F) operator. This lifting leads to an infinite-dimensional convex\noptimization formulation of the optimal control problem. The data-driven\napproximation of the optimization problem relies on the approximation of the\nKoopman operator using the polynomial basis function. We write the approximate\nfinite-dimensional optimization problem as a polynomial optimization which is\nthen solved efficiently using a sum-of-squares-based optimization framework.\nSimulation results are presented to demonstrate the efficacy of the developed\ndata-driven optimal control framework.",
    "descriptor": "",
    "authors": [
      "Joseph Moyalan",
      "Hyungjin Choi",
      "Yongxin Chen",
      "Umesh Vaidya"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)",
      "Functional Analysis (math.FA)"
    ],
    "url": "https://arxiv.org/abs/2202.01856"
  },
  {
    "id": "arXiv:2202.01857",
    "title": "Brain Cancer Survival Prediction on Treatment-na ive MRI using Deep  Anchor Attention Learning with Vision Transformer",
    "abstract": "Image-based brain cancer prediction models, based on radiomics, quantify the\nradiologic phenotype from magnetic resonance imaging (MRI). However, these\nfeatures are difficult to reproduce because of variability in acquisition and\npreprocessing pipelines. Despite evidence of intra-tumor phenotypic\nheterogeneity, the spatial diversity between different slices within an MRI\nscan has been relatively unexplored using such methods. In this work, we\npropose a deep anchor attention aggregation strategy with a Vision Transformer\nto predict survival risk for brain cancer patients. A Deep Anchor Attention\nLearning (DAAL) algorithm is proposed to assign different weights to\nslice-level representations with trainable distance measurements. We evaluated\nour method on N = 326 MRIs. Our results outperformed attention multiple\ninstance learning-based techniques. DAAL highlights the importance of critical\nslices and corroborates the clinical intuition that inter-slice spatial\ndiversity can reflect disease severity and is implicated in outcome.",
    "descriptor": "",
    "authors": [
      "Xuan Xu",
      "Prateek Prasanna"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.01857"
  },
  {
    "id": "arXiv:2202.01858",
    "title": "Modeling unknown dynamical systems with hidden parameters",
    "abstract": "We present a data-driven numerical approach for modeling unknown dynamical\nsystems with missing/hidden parameters. The method is based on training a deep\nneural network (DNN) model for the unknown system using its trajectory data. A\nkey feature is that the unknown dynamical system contains system parameters\nthat are completely hidden, in the sense that no information about the\nparameters is available through either the measurement trajectory data or our\nprior knowledge of the system. We demonstrate that by training a DNN using the\ntrajectory data with sufficient time history, the resulting DNN model can\naccurately model the unknown dynamical system. For new initial conditions\nassociated with new, and unknown, system parameters, the DNN model can produce\naccurate system predictions over longer time.",
    "descriptor": "",
    "authors": [
      "Xiaohan Fu",
      "Weize Mao",
      "Lo-Bin Chang",
      "Dongbin Xiu"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.01858"
  },
  {
    "id": "arXiv:2202.01863",
    "title": "Best Practices and Scoring System on Reviewing A.I. based Medical  Imaging Papers: Part 1 Classification",
    "abstract": "With the recent advances in A.I. methodologies and their application to\nmedical imaging, there has been an explosion of related research programs\nutilizing these techniques to produce state-of-the-art classification\nperformance. Ultimately, these research programs culminate in submission of\ntheir work for consideration in peer reviewed journals. To date, the criteria\nfor acceptance vs. rejection is often subjective; however, reproducible science\nrequires reproducible review. The Machine Learning Education Sub-Committee of\nSIIM has identified a knowledge gap and a serious need to establish guidelines\nfor reviewing these studies. Although there have been several recent papers\nwith this goal, this present work is written from the machine learning\npractitioners standpoint. In this series, the committee will address the best\npractices to be followed in an A.I.-based study and present the required\nsections in terms of examples and discussion of what should be included to make\nthe studies cohesive, reproducible, accurate, and self-contained. This first\nentry in the series focuses on the task of image classification. Elements such\nas dataset curation, data pre-processing steps, defining an appropriate\nreference standard, data partitioning, model architecture and training are\ndiscussed. The sections are presented as they would be detailed in a typical\nmanuscript, with content describing the necessary information that should be\nincluded to make sure the study is of sufficient quality to be considered for\npublication. The goal of this series is to provide resources to not only help\nimprove the review process for A.I.-based medical imaging papers, but to\nfacilitate a standard for the information that is presented within all\ncomponents of the research study. We hope to provide quantitative metrics in\nwhat otherwise may be a qualitative review process.",
    "descriptor": "",
    "authors": [
      "Timothy L. Kline",
      "Felipe Kitamura",
      "Ian Pan",
      "Amine M. Korchi",
      "Neil Tenenholtz",
      "Linda Moy",
      "Judy Wawira Gichoya",
      "Igor Santos",
      "Steven Blumer",
      "Misha Ysabel Hwang",
      "Kim-Ann Git",
      "Abishek Shroff",
      "Elad Walach",
      "George Shih",
      "Steve Langer"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.01863"
  },
  {
    "id": "arXiv:2202.01864",
    "title": "Exploiting Independent Instruments: Identification and Distribution  Generalization",
    "abstract": "Instrumental variable models allow us to identify a causal function between\ncovariates X and a response Y, even in the presence of unobserved confounding.\nMost of the existing estimators assume that the error term in the response Y\nand the hidden confounders are uncorrelated with the instruments Z. This is\noften motivated by a graphical separation, an argument that also justifies\nindependence. Posing an independence condition, however, leads to strictly\nstronger identifiability results. We connect to existing literature in\neconometrics and provide a practical method for exploiting independence that\ncan be combined with any gradient-based learning procedure. We see that even in\nidentifiable settings, taking into account higher moments may yield better\nfinite sample results. Furthermore, we exploit the independence for\ndistribution generalization. We prove that the proposed estimator is invariant\nto distributional shifts on the instruments and worst-case optimal whenever\nthese shifts are sufficiently strong. These results hold even in the\nunder-identified case where the instruments are not sufficiently rich to\nidentify the causal function.",
    "descriptor": "",
    "authors": [
      "Sorawit Saengkyongam",
      "Leonard Henckel",
      "Niklas Pfister",
      "Jonas Peters"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2202.01864"
  },
  {
    "id": "arXiv:2202.01866",
    "title": "Enhancing Organ at Risk Segmentation with Improved Deep Neural Networks",
    "abstract": "Organ at risk (OAR) segmentation is a crucial step for treatment planning and\noutcome determination in radiotherapy treatments of cancer patients. Several\ndeep learning based segmentation algorithms have been developed in recent\nyears, however, U-Net remains the de facto algorithm designed specifically for\nbiomedical image segmentation and has spawned many variants with known\nweaknesses. In this study, our goal is to present simple architectural changes\nin U-Net to improve its accuracy and generalization properties. Unlike many\nother available studies evaluating their algorithms on single center data, we\nthoroughly evaluate several variations of U-Net as well as our proposed\nenhanced architecture on multiple data sets for an extensive and reliable study\nof the OAR segmentation problem. Our enhanced segmentation model includes\n(a)architectural changes in the loss function, (b)optimization framework, and\n(c)convolution type. Testing on three publicly available multi-object\nsegmentation data sets, we achieved an average of 80% dice score compared to\nthe baseline U-Net performance of 63%.",
    "descriptor": "\nComments: 7 pages, 3 figures, 6 tables, The paper is published in SPIE Medical Imaging 2022\n",
    "authors": [
      "Ilkin Isler",
      "Curtis Lisle",
      "Justin Rineer",
      "Patrick Kelly",
      "Damla Turgut",
      "Jacob Ricci",
      "Ulas Bagci"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.01866"
  },
  {
    "id": "arXiv:2202.01892",
    "title": "Univalent foundations and the equivalence principle",
    "abstract": "In this paper, we explore the 'equivalence principle' (EP): roughly,\nstatements about mathematical objects should be invariant under an appropriate\nnotion of equivalence for the kinds of objects under consideration. In set\ntheoretic foundations, EP may not always hold: for instance, the statement '1\n\\in N' is not invariant under isomorphism of sets. In univalent foundations, on\nthe other hand, EP has been proven for many mathematical structures. We first\ngive an overview of earlier attempts at designing foundations that satisfy EP.\nWe then describe how univalent foundations validates EP.",
    "descriptor": "",
    "authors": [
      "Benedikt Ahrens",
      "Paige Randall North"
    ],
    "subjectives": [
      "Logic (math.LO)",
      "Logic in Computer Science (cs.LO)",
      "History and Overview (math.HO)"
    ],
    "url": "https://arxiv.org/abs/2202.01892"
  },
  {
    "id": "arXiv:2202.01896",
    "title": "Yordle: An Efficient Imitation Learning for Branch and Bound",
    "abstract": "Combinatorial optimization problems have aroused extensive research interests\ndue to its huge application potential. In practice, there are highly redundant\npatterns and characteristics during solving the combinatorial optimization\nproblem, which can be captured by machine learning models. Thus, the 2021\nNeurIPS Machine Learning for Combinatorial Optimization (ML4CO) competition is\nproposed with the goal of improving state-of-the-art combinatorial optimization\nsolvers by replacing key heuristic components with machine learning techniques.\nThis work presents our solution and insights gained by team qqy in the dual\ntask of the competition. Our solution is a highly efficient imitation learning\nframework for performance improvement of Branch and Bound (B&B), named Yordle.\nIt employs a hybrid sampling method and an efficient data selection method,\nwhich not only accelerates the model training but also improves the decision\nquality during branching variable selection. In our experiments, Yordle greatly\noutperforms the baseline algorithm adopted by the competition while requiring\nsignificantly less time and amounts of data to train the decision model.\nSpecifically, we use only 1/4 of the amount of data compared to that required\nfor the baseline algorithm, to achieve around 50% higher score than baseline\nalgorithm. The proposed framework Yordle won the championship of the student\nleaderboard.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2201.06213\n",
    "authors": [
      "Qingyu Qu",
      "Xijun Li",
      "Yunfan Zhou"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.01896"
  },
  {
    "id": "arXiv:2202.01897",
    "title": "AtmoDist: Self-supervised Representation Learning for Atmospheric  Dynamics",
    "abstract": "Representation learning has proven to be a powerful methodology in a wide\nvariety of machine learning applications. For atmospheric dynamics, however, it\nhas so far not been considered, arguably due to the lack of large-scale,\nlabeled datasets that could be used for training. In this work, we show that\nthe difficulty is benign and introduce a self-supervised learning task that\ndefines a categorical loss for a wide variety of unlabeled atmospheric\ndatasets. Specifically, we train a neural network on the simple yet intricate\ntask of predicting the temporal distance between atmospheric fields, e.g. the\ncomponents of the wind field, from distinct but nearby times. Despite this\nsimplicity, a neural network will provide good predictions only when it\ndevelops an internal representation that captures intrinsic aspects of\natmospheric dynamics. We demonstrate this by introducing a data-driven distance\nmetric for atmospheric states based on representations learned from ERA5\nreanalysis. When employ as a loss function for downscaling, this Atmodist\ndistance leads to downscaled fields that match the true statistics more closely\nthan the previous state-of-the-art based on an l2-loss and whose local behavior\nis more realistic. Since it is derived from observational data, AtmoDist also\nprovides a novel perspective on atmospheric predictability.",
    "descriptor": "\nComments: Submitted to \"Environmental Data Science\", Cambridge University Press. Journal-version of \"Towards Representation Learning for Atmospheric Dynamics. arXiv:2109.09076\"\n",
    "authors": [
      "Sebastian Hoffmann",
      "Christian Lessig"
    ],
    "subjectives": [
      "Atmospheric and Oceanic Physics (physics.ao-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.01897"
  },
  {
    "id": "arXiv:2202.01899",
    "title": "DeepQMLP: A Scalable Quantum-Classical Hybrid DeepNeural Network  Architecture for Classification",
    "abstract": "Quantum machine learning (QML) is promising for potential speedups and\nimprovements in conventional machine learning (ML) tasks (e.g.,\nclassification/regression). The search for ideal QML models is an active\nresearch field. This includes identification of efficient classical-to-quantum\ndata encoding scheme, construction of parametric quantum circuits (PQC) with\noptimal expressivity and entanglement capability, and efficient output decoding\nscheme to minimize the required number of measurements, to name a few. However,\nmost of the empirical/numerical studies lack a clear path towards scalability.\nAny potential benefit observed in a simulated environment may diminish in\npractical applications due to the limitations of noisy quantum hardware (e.g.,\nunder decoherence, gate-errors, and crosstalk). We present a scalable\nquantum-classical hybrid deep neural network (DeepQMLP) architecture inspired\nby classical deep neural network architectures. In DeepQMLP, stacked shallow\nQuantum Neural Network (QNN) models mimic the hidden layers of a classical\nfeed-forward multi-layer perceptron network. Each QNN layer produces a new and\npotentially rich representation of the input data for the next layer. This new\nrepresentation can be tuned by the parameters of the circuit. Shallow QNN\nmodels experience less decoherence, gate errors, etc. which make them (and the\nnetwork) more resilient to quantum noise. We present numerical studies on a\nvariety of classification problems to show the trainability of DeepQMLP. We\nalso show that DeepQMLP performs reasonably well on unseen data and exhibits\ngreater resilience to noise over QNN models that use a deep quantum circuit.\nDeepQMLP provided up to 25.3% lower loss and 7.92% higher accuracy during\ninference under noise than QMLP.",
    "descriptor": "",
    "authors": [
      "Mahabubul Alam",
      "Swaroop Ghosh"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Emerging Technologies (cs.ET)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.01899"
  },
  {
    "id": "arXiv:2202.01905",
    "title": "Modified ResNet Model for MSI and MSS Classification of Gastrointestinal  Cancer",
    "abstract": "In this work, a modified ResNet model is proposed for the classification of\nMicrosatellite instability(MSI) and Microsatellite stability(MSS) of\ngastrointestinal cancer. The performance of this model is analyzed and compared\nwith existing models. The proposed model surpassed the existing models with an\naccuracy of 0.8981 and F1 score of 0.9178.",
    "descriptor": "\nComments: 10 pages, 7 figures, 2 tables, Springer Nature\n",
    "authors": [
      "CH Sai Venkatesh",
      "Caleb Meriga",
      "M.G.V.L Geethika",
      "T Lakshmi Gayatri",
      "V.B.K.L Aruna"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.01905"
  },
  {
    "id": "arXiv:2202.01906",
    "title": "Net benefit, calibration, threshold selection, and training objectives  for algorithmic fairness in healthcare",
    "abstract": "A growing body of work uses the paradigm of algorithmic fairness to frame the\ndevelopment of techniques to anticipate and proactively mitigate the\nintroduction or exacerbation of health inequities that may follow from the use\nof model-guided decision-making. We evaluate the interplay between measures of\nmodel performance, fairness, and the expected utility of decision-making to\noffer practical recommendations for the operationalization of algorithmic\nfairness principles for the development and evaluation of predictive models in\nhealthcare. We conduct an empirical case-study via development of models to\nestimate the ten-year risk of atherosclerotic cardiovascular disease to inform\nstatin initiation in accordance with clinical practice guidelines. We\ndemonstrate that approaches that incorporate fairness considerations into the\nmodel training objective typically do not improve model performance or confer\ngreater net benefit for any of the studied patient populations compared to the\nuse of standard learning paradigms followed by threshold selection concordant\nwith patient preferences, evidence of intervention effectiveness, and model\ncalibration. These results hold when the measured outcomes are not subject to\ndifferential measurement error across patient populations and threshold\nselection is unconstrained, regardless of whether differences in model\nperformance metrics, such as in true and false positive error rates, are\npresent. In closing, we argue for focusing model development efforts on\ndeveloping calibrated models that predict outcomes well for all patient\npopulations while emphasizing that such efforts are complementary to\ntransparent reporting, participatory design, and reasoning about the impact of\nmodel-informed interventions in context.",
    "descriptor": "",
    "authors": [
      "Stephen R. Pfohl",
      "Yizhe Xu",
      "Agata Foryciarz",
      "Nikolaos Ignatiadis",
      "Julian Genkins",
      "Nigam H. Shah"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.01906"
  },
  {
    "id": "arXiv:2202.01916",
    "title": "Artificial Intelligence Powered Material Search Engine",
    "abstract": "Many data-driven applications in material science have been made possible\nbecause of recent breakthroughs in artificial intelligence(AI). The use of AI\nin material engineering is becoming more viable as the number of material data\nsuch as X-Ray diffraction, various spectroscopy, and microscope data grows. In\nthis work, we have reported a material search engine that uses the interatomic\nspace (d value) from X-ray diffraction to provide material information. We have\ninvestigated various techniques for predicting prospective material using X-ray\ndiffraction data. We used the Random Forest, Naive Bayes (Gaussian), and Neural\nNetwork algorithms to achieve this. These algorithms have an average accuracy\nof 88.50\\%, 100.0\\%, and 88.89\\%, respectively. Finally, we combined all these\ntechniques into an ensemble approach to make the prediction more generic. This\nensemble method has a ~100\\% accuracy rate. Furthermore, we are designing a\ngraph neural network (GNN)-based architecture to improve interpretability and\naccuracy. Thus, we want to solve the computational and time complexity of\ntraditional dictionary-based and metadata-based material search engines and to\nprovide a more generic prediction.",
    "descriptor": "\nComments: 4 pages\n",
    "authors": [
      "Mohendra Roy"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.01916"
  },
  {
    "id": "arXiv:2202.01926",
    "title": "Knowledge Graph Based Waveform Recommendation: A New Communication  Waveform Design Paradigm",
    "abstract": "Traditionally, a communication waveform is designed by experts based on\ncommunication theory and their experiences on a case-by-case basis, which is\nusually laborious and time-consuming. In this paper, we investigate the\nwaveform design from a novel perspective and propose a new waveform design\nparadigm with the knowledge graph (KG)-based intelligent recommendation system.\nThe proposed paradigm aims to improve the design efficiency by structural\ncharacterization and representations of existing waveforms and intelligently\nutilizing the knowledge learned from them. To achieve this goal, we first build\na communication waveform knowledge graph (CWKG) with a first-order neighbor\nnode, for which both structured semantic knowledge and numerical parameters of\na waveform are integrated by representation learning. Based on the developed\nCWKG, we further propose an intelligent communication waveform recommendation\nsystem (CWRS) to generate waveform candidates. In the CWRS, an improved\ninvolution1D operator, which is channel-agnostic and space-specific, is\nintroduced according to the characteristics of KG-based waveform representation\nfor feature extraction, and the multi-head self-attention is adopted to weigh\nthe influence of various components for feature fusion. Meanwhile, multilayer\nperceptron-based collaborative filtering is used to evaluate the matching\ndegree between the requirement and the waveform candidate. Simulation results\nshow that the proposed CWKG-based CWRS can automatically recommend waveform\ncandidates with high reliability.",
    "descriptor": "",
    "authors": [
      "Wei Huang",
      "Tianfu Qi",
      "Yundi Guan",
      "Qihang Peng",
      "Jun Wang"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.01926"
  },
  {
    "id": "arXiv:2202.01933",
    "title": "Identifying stimulus-driven neural activity patterns in multi-patient  intracranial recordings",
    "abstract": "Identifying stimulus-driven neural activity patterns is critical for studying\nthe neural basis of cognition. This can be particularly challenging in\nintracranial datasets, where electrode locations typically vary across\npatients. This chapter first presents an overview of the major challenges to\nidentifying stimulus-driven neural activity patterns in the general case. Next,\nwe will review several modality-specific considerations and approaches, along\nwith a discussion of several issues that are particular to intracranial\nrecordings. Against this backdrop, we will consider a variety of within-subject\nand across-subject approaches to identifying and modeling stimulus-driven\nneural activity patterns in multi-patient intracranial recordings. These\napproaches include generalized linear models, multivariate pattern analysis,\nrepresentational similarity analysis, joint stimulus-activity models,\nhierarchical matrix factorization models, Gaussian process models, geometric\nalignment models, inter-subject correlations, and inter-subject functional\ncorrelations. Examples from the recent literature serve to illustrate the major\nconcepts and provide the conceptual intuitions for each approach.",
    "descriptor": "\nComments: Forthcoming chapter in \"Intracranial EEG for Cognitive Neuroscience\"\n",
    "authors": [
      "Jeremy R. Manning"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.01933"
  },
  {
    "id": "arXiv:2202.01940",
    "title": "Distribution Embedding Networks for Meta-Learning with Heterogeneous  Covariate Spaces",
    "abstract": "We propose Distribution Embedding Networks (DEN) for classification with\nsmall data using meta-learning techniques. Unlike existing meta-learning\napproaches that focus on image recognition tasks and require the training and\ntarget tasks to be similar, DEN is specifically designed to be trained on a\ndiverse set of training tasks and applied on tasks whose number and\ndistribution of covariates differ vastly from its training tasks. Such property\nof DEN is enabled by its three-block architecture: a covariate transformation\nblock followed by a distribution embedding block and then a classification\nblock. We provide theoretical insights to show that this architecture allows\nthe embedding and classification blocks to be fixed after pre-training on a\ndiverse set of tasks; only the covariate transformation block with relatively\nfew parameters needs to be updated for each new task. To facilitate the\ntraining of DEN, we also propose an approach to synthesize binary\nclassification training tasks, and demonstrate that DEN outperforms existing\nmethods in a number of synthetic and real tasks in numerical studies.",
    "descriptor": "",
    "authors": [
      "Lang Liu",
      "Mahdi Milani Fard",
      "Sen Zhao"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.01940"
  },
  {
    "id": "arXiv:2202.01941",
    "title": "Dirty derivatives for output feedback stabilization",
    "abstract": "Dirty derivatives are routinely used in industrial settings, particularly in\nthe implementation of the derivative term in PID control, and are especially\nappealing due to their noise-attenuation and model-free characteristics. In\nthis paper, we provide a Lyapunov-based proof for the stability of linear\ntime-invariant control systems in controller canonical form when utilizing\ndirty derivatives in place of observers for the purpose of output feedback.\nThis is, to the best of the authors' knowledge, the first time that stability\nproofs are provided for the use of dirty derivatives in lieu of derivatives of\ndifferent orders. In the spirit of adaptive control, we also show how dirty\nderivatives can be used for output feedback control when the control gain is\nunknown.",
    "descriptor": "\nComments: 18 pages and 5 figures. The first two authors contributed equally to this paper\n",
    "authors": [
      "Matteo Marchi",
      "Lucas Fraile",
      "Paulo Tabuada"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.01941"
  },
  {
    "id": "arXiv:2202.01946",
    "title": "Unsupervised Learning Based Hybrid Beamforming with Low-Resolution Phase  Shifters for MU-MIMO Systems",
    "abstract": "Millimeter wave (mmWave) is a key technology for fifth-generation (5G) and\nbeyond communications. Hybrid beamforming has been proposed for large-scale\nantenna systems in mmWave communications. Existing hybrid beamforming designs\nbased on infinite-resolution phase shifters (PSs) are impractical due to\nhardware cost and power consumption. In this paper, we propose an\nunsupervised-learning-based scheme to jointly design the analog precoder and\ncombiner with low-resolution PSs for multiuser multiple-input multiple-output\n(MU-MIMO) systems. We transform the analog precoder and combiner design problem\ninto a phase classification problem and propose a generic neural network\narchitecture, termed the phase classification network (PCNet), capable of\nproducing solutions of various PS resolutions. Simulation results demonstrate\nthe superior sum-rate and complexity performance of the proposed scheme, as\ncompared to state-of-the-art hybrid beamforming designs for the most commonly\nused low-resolution PS configurations.",
    "descriptor": "\nComments: IEEE International Conference on Communications (ICC) 2022\n",
    "authors": [
      "Chia-Ho Kuo",
      "Hsin-Yuan Chang",
      "Ronald Y. Chang",
      "Wei-Ho Chung"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.01946"
  },
  {
    "id": "arXiv:2202.01954",
    "title": "Multi-task graph neural networks for simultaneous prediction of global  and atomic properties in ferromagnetic systems",
    "abstract": "We introduce a multi-tasking graph convolutional neural network, HydraGNN, to\nsimultaneously predict both global and atomic physical properties and\ndemonstrate with ferromagnetic materials. We train HydraGNN on an open-source\nab initio density functional theory (DFT) dataset for iron-platinum (FePt) with\na fixed body centered tetragonal (BCT) lattice structure and fixed volume to\nsimultaneously predict the mixing enthalpy (a global feature of the system),\nthe atomic charge transfer, and the atomic magnetic moment across\nconfigurations that span the entire compositional range. By taking advantage of\nunderlying physical correlations between material properties, multi-task\nlearning (MTL) with HydraGNN provides effective training even with modest\namounts of data. Moreover, this is achieved with just one architecture instead\nof three, as required by single-task learning (STL). The first convolutional\nlayers of the HydraGNN architecture are shared by all learning tasks and\nextract features common to all material properties. The following layers\ndiscriminate the features of the different properties, the results of which are\nfed to the separate heads of the final layer to produce predictions. Numerical\nresults show that HydraGNN effectively captures the relation between the\nconfigurational entropy and the material properties over the entire\ncompositional range. Overall, the accuracy of simultaneous MTL predictions is\ncomparable to the accuracy of the STL predictions. In addition, the\ncomputational cost of training HydraGNN for MTL is much lower than the original\nDFT calculations and also lower than training separate STL models for each\nproperty.",
    "descriptor": "\nComments: 13 pages, 6 figures\n",
    "authors": [
      "Massimiliano Lupo Pasini",
      "Pei Zhang",
      "Samuel Temple Reeve",
      "Jong Youl Choi"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2202.01954"
  },
  {
    "id": "arXiv:2202.01974",
    "title": "A Nano-Architecture for Fertility Monitoring via Intra-body  Communication",
    "abstract": "Fertility monitoring in humans for either natural conception or artificial\ninsemination and fertilization has been a critical challenge both for the\ntreating physician and the treated patients. Eggs in human female can be\nfertilized when they reach the Fallopian tube from the upper parts of the\nreproductive system. However, no technology, till date, on its own could detect\nthe presence of eggs in the Fallopian tube and communicate their presence to\nthe consulting physician or nurse and the patient, so that the next step can be\ninitiated in a timely fashion. In this paper, we propose a conceptual\narchitecture from a communications engineering point of view. The architecture\ncombines intra-body nano-sensor network for detecting Fallopian tube activity,\nwith body-area network for receiving information from the intra-body network\nand communicating the same over-the-air to the involved personnel\n(physician/nurse/patient). Preliminary simulations have been conducted using\nparticle based stochastic simulator to investigate the relationship between\nachievable information rates, signal to noise ratio (SNR) and distance. It has\nbeen found that data rate as high as 300 Mbps is achievable at SNR 45. Hence,\nthe proposed architecture ensures transfer of information with near-zero\nlatency and minimum energy along with high throughput, so that necessary action\ncan be taken within the short time-window of the Fallopian tube activity.",
    "descriptor": "",
    "authors": [
      "Shama Siddiqui",
      "Anwar Ahmed Khan",
      "Qammer H. Abbasi",
      "Muhammad Ali Imran",
      "Indrakshi Dey"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.01974"
  },
  {
    "id": "arXiv:2202.01975",
    "title": "Performance of multilabel machine learning models and risk  stratification schemas for predicting stroke and bleeding risk in patients  with non-valvular atrial fibrillation",
    "abstract": "Appropriate antithrombotic therapy for patients with atrial fibrillation (AF)\nrequires assessment of ischemic stroke and bleeding risks. However, risk\nstratification schemas such as CHA2DS2-VASc and HAS-BLED have modest predictive\ncapacity for patients with AF. Machine learning (ML) techniques may improve\npredictive performance and support decision-making for appropriate\nantithrombotic therapy. We compared the performance of multilabel ML models\nwith the currently used risk scores for predicting outcomes in AF patients.\nMaterials and Methods This was a retrospective cohort study of 9670 patients,\nmean age 76.9 years, 46% women, who were hospitalized with non-valvular AF, and\nhad 1-year follow-up. The primary outcome was ischemic stroke and major\nbleeding admission. The secondary outcomes were all-cause death and event-free\nsurvival. The discriminant power of ML models was compared with clinical risk\nscores by the area under the curve (AUC). Risk stratification was assessed\nusing the net reclassification index. Results Multilabel gradient boosting\nmachine provided the best discriminant power for stroke, major bleeding, and\ndeath (AUC = 0.685, 0.709, and 0.765 respectively) compared to other ML models.\nIt provided modest performance improvement for stroke compared to CHA2DS2-VASc\n(AUC = 0.652), but significantly improved major bleeding prediction compared to\nHAS-BLED (AUC = 0.522). It also had a much greater discriminant power for death\ncompared with CHA2DS2-VASc (AUC = 0.606). Also, models identified additional\nrisk features (such as hemoglobin level, renal function, etc.) for each\noutcome. Conclusions Multilabel ML models can outperform clinical risk\nstratification scores for predicting the risk of major bleeding and death in\nnon-valvular AF patients.",
    "descriptor": "",
    "authors": [
      "Juan Lu",
      "Rebecca Hutchens",
      "Joseph Hung",
      "Mohammed Bennamoun",
      "Brendan McQuillan",
      "Tom Briffa",
      "Ferdous Sohel",
      "Kevin Murray",
      "Jonathon Stewart",
      "Benjamin Chow",
      "Frank Sanfilippo",
      "Girish Dwivedi"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.01975"
  },
  {
    "id": "arXiv:2202.01986",
    "title": "The CUHK-TENCENT speaker diarization system for the ICASSP 2022  multi-channel multi-party meeting transcription challenge",
    "abstract": "This paper describes our speaker diarization system submitted to the\nMulti-channel Multi-party Meeting Transcription (M2MeT) challenge, where\nMandarin meeting data were recorded in multi-channel format for diarization and\nautomatic speech recognition (ASR) tasks. In these meeting scenarios, the\nuncertainty of the speaker number and the high ratio of overlapped speech\npresent great challenges for diarization. Based on the assumption that there is\nvaluable complementary information between acoustic features, spatial-related\nand speaker-related features, we propose a multi-level feature fusion mechanism\nbased target-speaker voice activity detection (FFM-TS-VAD) system to improve\nthe performance of the conventional TS-VAD system. Furthermore, we propose a\ndata augmentation method during training to improve the system robustness when\nthe angular difference between two speakers is relatively small. We provide\ncomparisons for different sub-systems we used in M2MeT challenge. Our\nsubmission is a fusion of several sub-systems and ranks second in the\ndiarization task.",
    "descriptor": "\nComments: submitted to ICASSP2022\n",
    "authors": [
      "Naijun Zheng",
      "Na Li",
      "Xixin Wu",
      "Lingwei Meng",
      "Jiawen Kang",
      "Haibin Wu",
      "Chao Weng",
      "Dan Su",
      "Helen Meng"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2202.01986"
  },
  {
    "id": "arXiv:2202.02000",
    "title": "Cross-Modality Multi-Atlas Segmentation Using Deep Neural Networks",
    "abstract": "Multi-atlas segmentation (MAS) is a promising framework for medical image\nsegmentation. Generally, MAS methods register multiple atlases, i.e., medical\nimages with corresponding labels, to a target image; and the transformed atlas\nlabels can be combined to generate target segmentation via label fusion\nschemes. Many conventional MAS methods employed the atlases from the same\nmodality as the target image. However, the number of atlases with the same\nmodality may be limited or even missing in many clinical applications. Besides,\nconventional MAS methods suffer from the computational burden of registration\nor label fusion procedures. In this work, we design a novel cross-modality MAS\nframework, which uses available atlases from a certain modality to segment a\ntarget image from another modality. To boost the computational efficiency of\nthe framework, both the image registration and label fusion are achieved by\nwell-designed deep neural networks. For the atlas-to-target image registration,\nwe propose a bi-directional registration network (BiRegNet), which can\nefficiently align images from different modalities. For the label fusion, we\ndesign a similarity estimation network (SimNet), which estimates the fusion\nweight of each atlas by measuring its similarity to the target image. SimNet\ncan learn multi-scale information for similarity estimation to improve the\nperformance of label fusion. The proposed framework was evaluated by the left\nventricle and liver segmentation tasks on the MM-WHS and CHAOS datasets,\nrespectively. Results have shown that the framework is effective for\ncross-modality MAS in both registration and label fusion. The code will be\nreleased publicly on \\url{https://github.com/NanYoMy/cmmas} once the manuscript\nis accepted.",
    "descriptor": "",
    "authors": [
      "Wangbin Ding",
      "Lei Li",
      "Xiahai Zhuang",
      "Liqin Huang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.02000"
  },
  {
    "id": "arXiv:2202.02031",
    "title": "Complex-to-Real Random Features for Polynomial Kernels",
    "abstract": "Kernel methods are ubiquitous in statistical modeling due to their\ntheoretical guarantees as well as their competitive empirical performance.\nPolynomial kernels are of particular importance as their feature maps model the\ninteractions between the dimensions of the input data. However, the\nconstruction time of explicit feature maps scales exponentially with the\npolynomial degree and a naive application of the kernel trick does not scale to\nlarge datasets. In this work, we propose Complex-to-Real (CtR) random features\nfor polynomial kernels that leverage intermediate complex random projections\nand can yield kernel estimates with much lower variances than their real-valued\nanalogs. The resulting features are real-valued, simple to construct and have\nthe following advantages over the state-of-the-art: 1) shorter construction\ntimes, 2) lower kernel approximation errors for commonly used degrees, 3) they\nenable us to obtain a closed-form expression for their variance.",
    "descriptor": "\nComments: 26 pages\n",
    "authors": [
      "Jonas Wacker",
      "Ruben Ohana",
      "Maurizio Filippone"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2202.02031"
  },
  {
    "id": "arXiv:2202.02096",
    "title": "To Impute or not to Impute? -- Missing Data in Treatment Effect  Estimation",
    "abstract": "Missing data is a systemic problem in practical scenarios that causes noise\nand bias when estimating treatment effects. This makes treatment effect\nestimation from data with missingness a particularly tricky endeavour. A key\nreason for this is that standard assumptions on missingness are rendered\ninsufficient due to the presence of an additional variable, treatment, besides\nthe individual and the outcome. Having a treatment variable introduces\nadditional complexity with respect to why some variables are missing that is\nnot fully explored by previous work. In our work we identify a new missingness\nmechanism, which we term mixed confounded missingness (MCM), where some\nmissingness determines treatment selection and other missingness is determined\nby treatment selection. Given MCM, we show that naively imputing all data leads\nto poor performing treatment effects models, as the act of imputation\neffectively removes information necessary to provide unbiased estimates.\nHowever, no imputation at all also leads to biased estimates, as missingness\ndetermined by treatment divides the population in distinct subpopulations,\nwhere estimates across these populations will be biased. Our solution is\nselective imputation, where we use insights from MCM to inform precisely which\nvariables should be imputed and which should not. We empirically demonstrate\nhow various learners benefit from selective imputation compared to other\nsolutions for missing data.",
    "descriptor": "",
    "authors": [
      "Jeroen Berrevoets",
      "Fergus Imrie",
      "Trent Kyono",
      "James Jordon",
      "Mihaela van der Schaar"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.02096"
  },
  {
    "id": "arXiv:2202.02150",
    "title": "Correcting Confounding via Random Selection of Background Variables",
    "abstract": "We propose a method to distinguish causal influence from hidden confounding\nin the following scenario: given a target variable Y, potential causal drivers\nX, and a large number of background features, we propose a novel criterion for\nidentifying causal relationship based on the stability of regression\ncoefficients of X on Y with respect to selecting different background features.\nTo this end, we propose a statistic V measuring the coefficient's variability.\nWe prove, subject to a symmetry assumption for the background influence, that V\nconverges to zero if and only if X contains no causal drivers. In experiments\nwith simulated data, the method outperforms state of the art algorithms.\nFurther, we report encouraging results for real-world data. Our approach aligns\nwith the general belief that causal insights admit better generalization of\nstatistical associations across environments, and justifies similar existing\nheuristic approaches from the literature.",
    "descriptor": "\nComments: 14 pages + 16 pages appendix\n",
    "authors": [
      "You-Lin Chen",
      "Lenon Minorics",
      "Dominik Janzing"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.02150"
  },
  {
    "id": "arXiv:2202.02188",
    "title": "Koopman von Neumann mechanics and the Koopman representation: A  perspective on solving nonlinear dynamical systems with quantum computers",
    "abstract": "A number of recent studies have proposed that linear representations are\nappropriate for solving nonlinear dynamical systems with quantum computers,\nwhich fundamentally act linearly on a wave function in a Hilbert space. Linear\nrepresentations, such as the Koopman representation and Koopman von Neumann\nmechanics, have regained attention from the dynamical-systems research\ncommunity. Here, we aim to present a unified theoretical framework, currently\nmissing in the literature, with which one can compare and relate existing\nmethods, their conceptual basis, and their representations. We also aim to show\nthat, despite the fact that quantum simulation of nonlinear classical systems\nmay be possible with such linear representations, a necessary projection into a\nfeasible finite-dimensional space will in practice eventually induce numerical\nartifacts which can be hard to eliminate or even control. As a result a\npractical, reliable and accurate way to use quantum computation for solving\ngeneral nonlinear dynamical systems is still an open problem.",
    "descriptor": "\nComments: 23 pages, 12 figures\n",
    "authors": [
      "Yen Ting Lin",
      "Robert B. Lowrie",
      "Denis Aslangil",
      "Yi\u011fit Suba\u015f\u0131",
      "Andrew T. Sornborger"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Data Structures and Algorithms (cs.DS)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2202.02188"
  },
  {
    "id": "arXiv:2202.02190",
    "title": "An Overview of Ultra-WideBand (UWB) Standards(IEEE 802.15.4, FiRa,  Apple): Interoperability Aspects and Future Research Directions",
    "abstract": "The increasing popularity of ultra-wideband (UWB) technology for\nlocation-based services such as access control and real-time indoor\ntrack\\&tracing, as well as UWB support in new consumer devices such as\nsmartphones, has resulted in the availability of multiple new UWB radio chips.\nHowever, due to this increase in UWB device availability, the question of which\n(industry) standards and configuration factors impact UWB interoperability and\ncompatibility becomes increasingly important. In this paper, the fundamentals\nof UWB compatibility are investigated by first giving an overview of different\nUWB radio chips on the market. After that, an overview of UWB standards and\nstandardisation entities is given. Next, this overview is used to discuss the\nfocus of these different standards and to identify the differences between\nthem. We describe compatibility issues and associated interoperability aspects\nrelated to PHY, MAC, and upper layers. For the PHY layer, compatibility is\npossible for all UWB chips if the correct settings are configured. For the MAC\nlayer, the implementation of the multiple access scheme as well as the\nlocalization technique is mostly proprietary. For the device discovery, several\nstandards are currently being drafted. Finally, future challenges related to\nUWB interoperability are discussed.",
    "descriptor": "\nComments: 20 pages, 18 figures, 12 tables\n",
    "authors": [
      "Dieter Coppens",
      "Eli De Poorter",
      "Adnan Shahid",
      "Sam Lemey",
      "Chris Marshall"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.02190"
  },
  {
    "id": "arXiv:2202.02193",
    "title": "Stochastic smoothing of the top-K calibrated hinge loss for deep  imbalanced classification",
    "abstract": "In modern classification tasks, the number of labels is getting larger and\nlarger, as is the size of the datasets encountered in practice. As the number\nof classes increases, class ambiguity and class imbalance become more and more\nproblematic to achieve high top-1 accuracy. Meanwhile, Top-K metrics (metrics\nallowing K guesses) have become popular, especially for performance reporting.\nYet, proposing top-K losses tailored for deep learning remains a challenge,\nboth theoretically and practically. In this paper we introduce a stochastic\ntop-K hinge loss inspired by recent developments on top-K calibrated losses.\nOur proposal is based on the smoothing of the top-K operator building on the\nflexible \"perturbed optimizer\" framework. We show that our loss function\nperforms very well in the case of balanced datasets, while benefiting from a\nsignificantly lower computational time than the state-of-the-art top-K loss\nfunction. In addition, we propose a simple variant of our loss for the\nimbalanced case. Experiments on a heavy-tailed dataset show that our loss\nfunction significantly outperforms other baseline loss functions.",
    "descriptor": "",
    "authors": [
      "Camille Garcin",
      "Maximilien Servajean",
      "Alexis Joly",
      "Joseph Salmon"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.02193"
  },
  {
    "id": "arXiv:2202.02195",
    "title": "Deep End-to-end Causal Inference",
    "abstract": "Causal inference is essential for data-driven decision making across domains\nsuch as business engagement, medical treatment or policy making. However,\nresearch on causal discovery and inference has evolved separately, and the\ncombination of the two domains is not trivial. In this work, we develop Deep\nEnd-to-end Causal Inference (DECI), a single flow-based method that takes in\nobservational data and can perform both causal discovery and inference,\nincluding conditional average treatment effect (CATE) estimation. We provide a\ntheoretical guarantee that DECI can recover the ground truth causal graph under\nmild assumptions. In addition, our method can handle heterogeneous, real-world,\nmixed-type data with missing values, allowing for both continuous and discrete\ntreatment decisions. Moreover, the design principle of our method can\ngeneralize beyond DECI, providing a general End-to-end Causal Inference (ECI)\nrecipe, which enables different ECI frameworks to be built using existing\nmethods. Our results show the superior performance of DECI when compared to\nrelevant baselines for both causal discovery and (C)ATE estimation in over a\nthousand experiments on both synthetic datasets and other causal machine\nlearning benchmark datasets.",
    "descriptor": "",
    "authors": [
      "Tomas Geffner",
      "Javier Antoran",
      "Adam Foster",
      "Wenbo Gong",
      "Chao Ma",
      "Emre Kiciman",
      "Amit Sharma",
      "Angus Lamb",
      "Martin Kukla",
      "Nick Pawlowski",
      "Miltiadis Allamanis",
      "Cheng Zhang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.02195"
  },
  {
    "id": "arXiv:2202.02228",
    "title": "Uncertainty in fMRI Functional Networks of Autism Brain Imaging Data",
    "abstract": "In this paper we review the preprocessing pipeline through which fMRI data is\ntransformed into a network. We discuss three parameters that mostly affect our\nunderstanding of the existence of functional correlations between the brain\nregions. In the end, we conclude that the existence of functional correlations\nbetween pairs of the brain's regions can be modeled with probabilistic edges,\nnot to lose the uncertainty that is inherent in the network generation process.",
    "descriptor": "",
    "authors": [
      "Amin Kaveh",
      "Matteo Magnani",
      "Christian Rohner"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Other Computer Science (cs.OH)"
    ],
    "url": "https://arxiv.org/abs/2202.02228"
  },
  {
    "id": "arXiv:2202.02239",
    "title": "Posterior Representations for Bayesian Context Trees: Sampling,  Estimation and Convergence",
    "abstract": "We revisit the Bayesian Context Trees (BCT) modelling framework for discrete\ntime series, which was recently found to be very effective in numerous tasks\nincluding model selection, estimation and prediction. A novel representation of\nthe induced posterior distribution on model space is derived in terms of a\nsimple branching process, and several consequences of this are explored in\ntheory and in practice. First, it is shown that the branching process\nrepresentation leads to a simple variable-dimensional Monte Carlo sampler for\nthe joint posterior distribution on models and parameters, which can\nefficiently produce independent samples. This sampler is found to be more\nefficient than earlier MCMC samplers for the same tasks. Then, the branching\nprocess representation is used to establish the asymptotic consistency of the\nBCT posterior, including the derivation of an almost-sure convergence rate.\nFinally, an extensive study is carried out on the performance of the induced\nBayesian entropy estimator. Its utility is illustrated through both simulation\nexperiments and real-world applications, where it is found to outperform\nseveral state-of-the-art methods.",
    "descriptor": "",
    "authors": [
      "Ioannis Papageorgiou",
      "Ioannis Kontoyiannis"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Information Theory (cs.IT)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2202.02239"
  },
  {
    "id": "arXiv:2202.02245",
    "title": "Personalized visual encoding model construction with small data",
    "abstract": "Encoding models that predict brain response patterns to stimuli are one way\nto capture this relationship between variability in bottom-up neural systems\nand individual's behavior or pathological state. However, they generally need a\nlarge amount of training data to achieve optimal accuracy. Here, we propose and\ntest an alternative personalized ensemble encoding model approach to utilize\nexisting encoding models, to create encoding models for novel individuals with\nrelatively little stimuli-response data. We show that these personalized\nensemble encoding models trained with small amounts of data for a specific\nindividual, i.e. ~400 image-response pairs, achieve accuracy not different from\nmodels trained on ~24,000 image-response pairs for the same individual.\nImportantly, the personalized ensemble encoding models preserve patterns of\ninter-individual variability in the image-response relationship. Additionally,\nwe use our personalized ensemble encoding model within the recently developed\nNeuroGen framework to generate optimal stimuli designed to maximize specific\nregions' activations for a specific individual. We show that the\ninter-individual differences in face area responses to images of dog vs human\nfaces observed previously is replicated using NeuroGen with the ensemble\nencoding model. Finally, and most importantly, we show the proposed approach is\nrobust against domain shift by validating on a prospectively collected set of\nimage-response data in novel individuals with a different scanner and\nexperimental setup. Our approach shows the potential to use previously\ncollected, deeply sampled data to efficiently create accurate, personalized\nencoding models and, subsequently, personalized optimal synthetic images for\nnew individuals scanned under different experimental conditions.",
    "descriptor": "",
    "authors": [
      "Zijin Gu",
      "Keith Jamison",
      "Mert Sabuncu",
      "Amy Kuceyeski"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.02245"
  },
  {
    "id": "arXiv:2202.02247",
    "title": "Beam Management with Orientation and RSRP using Deep Learning for Beyond  5G Systems",
    "abstract": "Beam management (BM), i.e., the process of finding and maintaining a suitable\ntransmit and receive beam pair, can be challenging, particularly in highly\ndynamic scenarios. Side-information, e.g., orientation, from on-board sensors\ncan assist the user equipment (UE) BM. In this work, we use the orientation\ninformation coming from the inertial measurement unit (IMU) for effective BM.\nWe use a data-driven strategy that fuses the reference signal received power\n(RSRP) with orientation information using a recurrent neural network (RNN).\nSimulation results show that the proposed strategy performs much better than\nthe conventional BM and an orientation-assisted BM strategy that utilizes\nparticle filter in another study. Specifically, the proposed data-driven\nstrategy improves the beam-prediction accuracy up to 34% and increases mean\nRSRP by up to 4.2 dB when the UE orientation changes quickly.",
    "descriptor": "",
    "authors": [
      "Khuong N. Nguyen",
      "Anum Ali",
      "Jianhua Mo",
      "Boon Loong Ng",
      "Vutha Va",
      "Jianzhong Charlie Zhang"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.02247"
  },
  {
    "id": "arXiv:2202.02249",
    "title": "Functional Mixtures-of-Experts",
    "abstract": "We consider the statistical analysis of heterogeneous data for clustering and\nprediction purposes, in situations where the observations include functions,\ntypically time series. We extend the modeling with Mixtures-of-Experts (ME), as\na framework of choice in modeling heterogeneity in data for prediction and\nclustering with vectorial observations, to this functional data analysis\ncontext. We first present a new family of functional ME (FME) models, in which\nthe predictors are potentially noisy observations, from entire functions, and\nthe data generating process of the pair predictor and the real response, is\ngoverned by a hidden discrete variable representing an unknown partition,\nleading to complex situations to which the standard ME framework is not\nadapted. Second, we provide sparse and interpretable functional representations\nof the FME models, thanks to Lasso-like regularizations, notably on the\nderivatives of the underlying functional parameters of the model, projected\nonto a set of continuous basis functions. We develop dedicated\nexpectation--maximization algorithms for Lasso-like regularized\nmaximum-likelihood parameter estimation strategies, to encourage sparse and\ninterpretable solutions. The proposed FME models and the developed EM-Lasso\nalgorithms are studied in simulated scenarios and in applications to two real\ndata sets, and the obtained results demonstrate their performance in accurately\ncapturing complex nonlinear relationships between the response and the\nfunctional predictor, and in clustering.",
    "descriptor": "",
    "authors": [
      "Fa\u00efcel Chamroukhi",
      "Nhat Thien Pham",
      "Van H\u00e0 Hoang",
      "Geoffrey J. McLachlan"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.02249"
  },
  {
    "id": "arXiv:2202.02261",
    "title": "Infinite-horizon risk-sensitive performance criteria for translation  invariant networks of linear quantum stochastic systems",
    "abstract": "This paper is concerned with networks of identical linear quantum stochastic\nsystems which interact with each other and external bosonic fields in a\ntranslation invariant fashion. The systems are associated with sites of a\nmultidimensional lattice and are governed by coupled linear quantum stochastic\ndifferential equations (QSDEs). The block Toeplitz coefficients of these QSDEs\nare specified by the energy and coupling matrices which quantify the\nHamiltonian and coupling operators for the component systems. We discuss the\ninvariant Gaussian quantum state of the network when it satisfies a stability\ncondition and is driven by statistically independent vacuum fields. A\nquadratic-exponential functional (QEF) is considered as a risk-sensitive\nperformance criterion for a finite fragment of the network over a bounded time\ninterval. This functional involves a quadratic function of dynamic variables of\nthe component systems with a block Toeplitz weighting matrix. Assuming the\ninvariant state, we study the spatio-temporal asymptotic rate of the QEF per\nunit time and per lattice site in the thermodynamic limit of unboundedly\ngrowing time horizons and fragments of the lattice. A spatio-temporal\nfrequency-domain formula is obtained for the QEF rate in terms of two spectral\nfunctions associated with the real and imaginary parts of the invariant quantum\ncovariance kernel of the network variables. A homotopy method and asymptotic\nexpansions for evaluating the QEF rate are also discussed.",
    "descriptor": "\nComments: 30 pages, 3 figures, to be submitted to Infinite Dimensional Analysis, Quantum Probability and Related Topics\n",
    "authors": [
      "Igor G. Vladimirov",
      "Ian R. Petersen"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2202.02261"
  },
  {
    "id": "arXiv:2202.02264",
    "title": "De-Sequentialized Monte Carlo: a parallel-in-time particle smoother",
    "abstract": "Particle smoothers are SMC (Sequential Monte Carlo) algorithms designed to\napproximate the joint distribution of the states given observations from a\nstate-space model. We propose dSMC (de-Sequentialized Monte Carlo), a new\nparticle smoother that is able to process $T$ observations in $\\mathcal{O}(\\log\nT)$ time on parallel architecture. This compares favourably with standard\nparticle smoothers, the complexity of which is linear in $T$. We derive\n$\\mathcal{L}_p$ convergence results for dSMC, with an explicit upper bound,\npolynomial in $T$. We then discuss how to reduce the variance of the smoothing\nestimates computed by dSMC by (i) designing good proposal distributions for\nsampling the particles at the initialization of the algorithm, as well as by\n(ii) using lazy resampling to increase the number of particles used in dSMC.\nFinally, we design a particle Gibbs sampler based on dSMC, which is able to\nperform parameter inference in a state-space model at a $\\mathcal{O}(\\log(T))$\ncost on parallel hardware.",
    "descriptor": "\nComments: 31 pages, 6 figures\n",
    "authors": [
      "Adrien Corenflos",
      "Nicolas Chopin",
      "Simo S\u00e4rkk\u00e4"
    ],
    "subjectives": [
      "Computation (stat.CO)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.02264"
  },
  {
    "id": "arXiv:2202.02266",
    "title": "Polynomial convergence of iterations of certain random operators in  Hilbert space",
    "abstract": "We study the convergence of random iterative sequence of a family of\noperators on infinite dimensional Hilbert spaces, which are inspired by the\nStochastic Gradient Descent (SGD) algorithm in the case of the noiseless\nregression, as studied in [1]. We demonstrate that its polynomial convergence\nrate depends on the initial state, while the randomness plays a role only in\nthe choice of the best constant factor and we close the gap between the upper\nand lower bounds.",
    "descriptor": "",
    "authors": [
      "Soumyadip Ghosh",
      "Yingdong Lu",
      "Tomasz J. Nowicki"
    ],
    "subjectives": [
      "Functional Analysis (math.FA)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.02266"
  },
  {
    "id": "arXiv:2202.02272",
    "title": "A multi-model ensemble Kalman filter for data assimilation and  forecasting",
    "abstract": "Data assimilation (DA) aims to optimally combine model forecasts and noisy\nobservations. Multi-model DA generalizes the variational or Bayesian\nformulation of the Kalman filter, and we prove here that it is also the minimum\nvariance linear unbiased estimator. However, previous implementations of this\napproach have not estimated the model error, and have therewith not been able\nto correctly weight the separate models and the observations. Here, we show how\nmultiple models can be combined for both forecasting and DA by using an\nensemble Kalman filter with adaptive model error estimation. This methodology\nis applied to the Lorenz96 model, and it results in significant error\nreductions compared to the best model and to an unweighted multi-model\nensemble.",
    "descriptor": "\nComments: 18 pages, 8 figures\n",
    "authors": [
      "Eviatar Bach",
      "Michael Ghil"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)",
      "Atmospheric and Oceanic Physics (physics.ao-ph)"
    ],
    "url": "https://arxiv.org/abs/2202.02272"
  },
  {
    "id": "arXiv:2202.02277",
    "title": "Quality Assessment of Low Light Restored Images: A Subjective Study and  an Unsupervised Model",
    "abstract": "The quality assessment (QA) of restored low light images is an important tool\nfor benchmarking and improving low light restoration (LLR) algorithms. While\nseveral LLR algorithms exist, the subjective perception of the restored images\nhas been much less studied. Challenges in capturing aligned low light and\nwell-lit image pairs and collecting a large number of human opinion scores of\nquality for training, warrant the design of unsupervised (or opinion unaware)\nno-reference (NR) QA methods. This work studies the subjective perception of\nlow light restored images and their unsupervised NR QA. Our contributions are\ntwo-fold. We first create a dataset of restored low light images using various\nLLR methods, conduct a subjective QA study and benchmark the performance of\nexisting QA methods. We then present a self-supervised contrastive learning\ntechnique to extract distortion aware features from the restored low light\nimages. We show that these features can be effectively used to build an opinion\nunaware image quality analyzer. Detailed experiments reveal that our\nunsupervised NR QA model achieves state-of-the-art performance among all such\nquality measures for low light restored images.",
    "descriptor": "",
    "authors": [
      "Vignesh Kannan",
      "Sameer Malik",
      "Rajiv Soundararajan"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.02277"
  },
  {
    "id": "arXiv:2202.02279",
    "title": "A $J$-Symmetric Quasi-Newton Method for Minimax Problems",
    "abstract": "Minimax problems have gained tremendous attentions across the optimization\nand machine learning community recently. In this paper, we introduce a new\nquasi-Newton method for minimax problems, which we call $J$-symmetric\nquasi-Newton method. The method is obtained by exploiting the $J$-symmetric\nstructure of the second-order derivative of the objective function in minimax\nproblem. We show that the Hessian estimation (as well as its inverse) can be\nupdated by a rank-2 operation, and it turns out that the update rule is a\nnatural generalization of the classic Powell symmetric Broyden (PSB) method\nfrom minimization problems to minimax problems. In theory, we show that our\nproposed quasi-Newton algorithm enjoys local Q-superlinear convergence to a\ndesirable solution under standard regularity conditions. Furthermore, we\nintroduce a trust-region variant of the algorithm that enjoys global\nR-superlinear convergence. Finally, we present numerical experiments that\nverify our theory and show the effectiveness of our proposed algorithms\ncompared to Broyden's method and the extragradient method on three classes of\nminimax problems.",
    "descriptor": "",
    "authors": [
      "Azam Asl",
      "Haihao Lu"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.02279"
  },
  {
    "id": "arXiv:2202.02297",
    "title": "Uniform tail estimates and $L^p(\\mathbb{R}^N)$-convergence for  finite-difference approximations of nonlinear diffusion equations",
    "abstract": "We obtain new equitightness and $C([0,T];L^p(\\mathbb{R}^N))$-convergence\nresults for numerical approximations of generalized porous medium equations of\nthe form $$ \\partial_tu-\\mathfrak{L}[\\varphi(u)]=g\\qquad\\text{in\n$\\mathbb{R}^N\\times(0,T)$}, $$ where $\\varphi:\\mathbb{R}\\to\\mathbb{R}$ is\ncontinuous and nondecreasing, and $\\mathfrak{L}$ is a local or nonlocal\ndiffusion operator. Our results include slow diffusions, strongly degenerate\nStefan problems, and fast diffusions above a critical exponent. These results\nimprove the previous $C([0,T];L_{\\text{loc}}^p(\\mathbb{R}^N))$-convergence\nobtained in a series of papers on the topic by the authors. To have\nequitightness and global $L^p$-convergence, some additional restrictions on\n$\\mathfrak{L}$ and $\\varphi$ are needed. Most commonly used symmetric operators\n$\\mathfrak{L}$ are still included: the Laplacian, fractional Laplacians, and\nother generators of symmetric L\\'evy processes with some fractional moment. We\nalso discuss extensions to nonlinear possibly strongly degenerate\nconvection-diffusion equations.",
    "descriptor": "\nComments: 27 pages\n",
    "authors": [
      "F\u00e9lix del Teso",
      "J\u00f8rgen Endal",
      "Espen R. Jakobsen"
    ],
    "subjectives": [
      "Analysis of PDEs (math.AP)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.02297"
  },
  {
    "id": "arXiv:2202.02305",
    "title": "Faster exact solution of sparse MaxCut and QUBO problems",
    "abstract": "The maximum-cut problem is one of the fundamental problems in combinatorial\noptimization. With the advent of quantum computers, both the maximum-cut and\nthe equivalent quadratic unconstrained binary optimization problem have\nexperienced much interest in recent years.\nThis article aims to advance the state of the art in the exact solution of\nboth problems -- by using mathematical programming techniques on digital\ncomputers. The main focus lies on sparse problem instances, although also dense\nones can be solved. We enhance several algorithmic components such as reduction\ntechniques and cutting-plane separation algorithms, and combine them in an\nexact branch-and-cut solver. Furthermore, we provide a parallel implementation.\nThe new solver is shown to significantly outperform existing state-of-the-art\nsoftware for sparse MaxCut and QUBO instances. Furthermore, we improve the best\nknown bounds for several instances from the 7th DIMACS Challenge and the QPLIB,\nand solve some of them (for the first time) to optimality.",
    "descriptor": "",
    "authors": [
      "Daniel Rehfeldt",
      "Thorsten Koch",
      "Yuji Shinano"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2202.02305"
  },
  {
    "id": "arXiv:2202.02306",
    "title": "Rediscovering orbital mechanics with machine learning",
    "abstract": "We present an approach for using machine learning to automatically discover\nthe governing equations and hidden properties of real physical systems from\nobservations. We train a \"graph neural network\" to simulate the dynamics of our\nsolar system's Sun, planets, and large moons from 30 years of trajectory data.\nWe then use symbolic regression to discover an analytical expression for the\nforce law implicitly learned by the neural network, which our results showed is\nequivalent to Newton's law of gravitation. The key assumptions that were\nrequired were translational and rotational equivariance, and Newton's second\nand third laws of motion. Our approach correctly discovered the form of the\nsymbolic force law. Furthermore, our approach did not require any assumptions\nabout the masses of planets and moons or physical constants. They, too, were\naccurately inferred through our methods. Though, of course, the classical law\nof gravitation has been known since Isaac Newton, our result serves as a\nvalidation that our method can discover unknown laws and hidden properties from\nobserved data. More broadly this work represents a key step toward realizing\nthe potential of machine learning for accelerating scientific discovery.",
    "descriptor": "\nComments: 12 pages, 6 figures, under review\n",
    "authors": [
      "Pablo Lemos",
      "Niall Jeffrey",
      "Miles Cranmer",
      "Shirley Ho",
      "Peter Battaglia"
    ],
    "subjectives": [
      "Earth and Planetary Astrophysics (astro-ph.EP)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.02306"
  },
  {
    "id": "arXiv:1802.03652",
    "title": "Approximating Sparse Graphs: The Random Overlapping Communities Model",
    "abstract": "Comments: This paper subsumes the paper \"Random Overlapping Communities: Approximating Motif Densities of Large Graphs,\" arXiv:1709.09477",
    "descriptor": "\nComments: This paper subsumes the paper \"Random Overlapping Communities: Approximating Motif Densities of Large Graphs,\" arXiv:1709.09477\n",
    "authors": [
      "Samantha Petti",
      "Santosh S. Vempala"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/1802.03652"
  },
  {
    "id": "arXiv:1803.05085",
    "title": "The $\\mathbb{Z}_2$-genus of Kuratowski minors",
    "abstract": "Comments: 25 pages, 10 figures; minor revision",
    "descriptor": "\nComments: 25 pages, 10 figures; minor revision\n",
    "authors": [
      "Radoslav Fulek",
      "Jan Kyn\u010dl"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/1803.05085"
  },
  {
    "id": "arXiv:1804.02801",
    "title": "A $5k$-vertex Kernel for $P_2$-packing",
    "abstract": "A $5k$-vertex Kernel for $P_2$-packing",
    "descriptor": "",
    "authors": [
      "Wenjun Li",
      "Junjie Ye",
      "Yixin Cao"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/1804.02801"
  },
  {
    "id": "arXiv:1810.08743",
    "title": "Quantifying the Burden of Exploration and the Unfairness of Free Riding",
    "abstract": "Quantifying the Burden of Exploration and the Unfairness of Free Riding",
    "descriptor": "",
    "authors": [
      "Christopher Jung",
      "Sampath Kannan",
      "Neil Lutz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1810.08743"
  },
  {
    "id": "arXiv:1904.00326",
    "title": "MedGCN: Medication recommendation and lab test imputation via graph  convolutional networks",
    "abstract": "MedGCN: Medication recommendation and lab test imputation via graph  convolutional networks",
    "descriptor": "",
    "authors": [
      "Chengsheng Mao",
      "Liang Yao",
      "Yuan Luo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1904.00326"
  },
  {
    "id": "arXiv:1907.05082",
    "title": "How should we score athletes and candidates: geometric scoring rules",
    "abstract": "Comments: 40 pages, 3 figures, 5 tables",
    "descriptor": "\nComments: 40 pages, 3 figures, 5 tables\n",
    "authors": [
      "Aleksei Y. Kondratev",
      "Egor Ianovski",
      "Alexander S. Nesterov"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/1907.05082"
  },
  {
    "id": "arXiv:1909.12346",
    "title": "System-level, Input-output and New Parameterizations of Stabilizing  Controllers, and Their Numerical Computation",
    "abstract": "Comments: 21 pages; 6 figures; minor updates on the numerical robustness of closed-loop parameterization; accepted for publication as a regular paper in Automatica",
    "descriptor": "\nComments: 21 pages; 6 figures; minor updates on the numerical robustness of closed-loop parameterization; accepted for publication as a regular paper in Automatica\n",
    "authors": [
      "Yang Zheng",
      "Luca Furieri",
      "Maryam Kamgarpour",
      "Na Li"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/1909.12346"
  },
  {
    "id": "arXiv:1909.13492",
    "title": "Manifold Fitting in Ambient Space",
    "abstract": "Comments: 34 pages",
    "descriptor": "\nComments: 34 pages\n",
    "authors": [
      "Zhigang Yao",
      "Bingjie Li",
      "Wee Chin Tan"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/1909.13492"
  },
  {
    "id": "arXiv:1911.09646",
    "title": "Ocular Recognition Databases and Competitions: A Survey",
    "abstract": "Comments: Artificial Intelligence Review, vol. 55, pp. 129-180, 2022",
    "descriptor": "\nComments: Artificial Intelligence Review, vol. 55, pp. 129-180, 2022\n",
    "authors": [
      "Luiz A. Zanlorensi",
      "Rayson Laroca",
      "Eduardo Luz",
      "Alceu S. Britto Jr.",
      "Luiz S. Oliveira",
      "David Menotti"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/1911.09646"
  },
  {
    "id": "arXiv:1912.01082",
    "title": "Fundamental Structure of Optimal Cache Placement for Coded Caching with  Nonuniform Demands",
    "abstract": "Comments: 19 pages, 12 figures",
    "descriptor": "\nComments: 19 pages, 12 figures\n",
    "authors": [
      "Yong Deng",
      "Min Dong"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/1912.01082"
  },
  {
    "id": "arXiv:2001.03741",
    "title": "On Polynomial Modular Number Systems over $\\mathbb{Z}/p\\mathbb{Z}$",
    "abstract": "On Polynomial Modular Number Systems over $\\mathbb{Z}/p\\mathbb{Z}$",
    "descriptor": "",
    "authors": [
      "Jean Claude Bajard",
      "J\u00e9r\u00e9my Marrez",
      "Thomas Plantard",
      "Pascal V\u00e9ron"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Number Theory (math.NT)"
    ],
    "url": "https://arxiv.org/abs/2001.03741"
  },
  {
    "id": "arXiv:2002.04011",
    "title": "The Bang Calculus Revisited",
    "abstract": "The Bang Calculus Revisited",
    "descriptor": "",
    "authors": [
      "Antonio Bucciarelli",
      "Delia Kesner",
      "Alejandro R\u00edos",
      "Andr\u00e9s Viso"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2002.04011"
  },
  {
    "id": "arXiv:2002.08894",
    "title": "On rectangle-decomposable 2-parameter persistence modules",
    "abstract": "Comments: This is the final version to be published in DCG. Changed the algorithm in Section 3 for computing the rank invariant, which was incorrect. The new algorithm reduces to computing 1-parameter vineyards along a family of paths in the grid. It was first proposed in the PhD thesis of D. Morozov",
    "descriptor": "\nComments: This is the final version to be published in DCG. Changed the algorithm in Section 3 for computing the rank invariant, which was incorrect. The new algorithm reduces to computing 1-parameter vineyards along a family of paths in the grid. It was first proposed in the PhD thesis of D. Morozov\n",
    "authors": [
      "Magnus Bakke Botnan",
      "Vadim Lebovici",
      "Steve Oudot"
    ],
    "subjectives": [
      "Algebraic Topology (math.AT)",
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2002.08894"
  },
  {
    "id": "arXiv:2003.01492",
    "title": "Contention Window Optimization in IEEE 802.11ax Networks with Deep  Reinforcement Learning",
    "abstract": "Comments: 6 pages, 6 figures, published in 2021 IEEE Wireless Communications and Networking Conference (WCNC)",
    "descriptor": "\nComments: 6 pages, 6 figures, published in 2021 IEEE Wireless Communications and Networking Conference (WCNC)\n",
    "authors": [
      "Witold Wydma\u0144ski",
      "Szymon Szott"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2003.01492"
  },
  {
    "id": "arXiv:2005.08487",
    "title": "Sigma Delta quantization for images",
    "abstract": "Sigma Delta quantization for images",
    "descriptor": "",
    "authors": [
      "He Lyu",
      "Rongrong Wang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2005.08487"
  },
  {
    "id": "arXiv:2006.08505",
    "title": "Diversity Policy Gradient for Sample Efficient Quality-Diversity  Optimization",
    "abstract": "Comments: Add several baselines (Policy Gradient assisted MAP Elites, DIAYN, AGAC) Change writing to take the point of view of the evo community Change style, writing, explanation, figures",
    "descriptor": "\nComments: Add several baselines (Policy Gradient assisted MAP Elites, DIAYN, AGAC) Change writing to take the point of view of the evo community Change style, writing, explanation, figures\n",
    "authors": [
      "Thomas Pierrot",
      "Valentin Mac\u00e9",
      "F\u00e9lix Chalumeau",
      "Arthur Flajolet",
      "Geoffrey Cideron",
      "Karim Beguir",
      "Antoine Cully",
      "Olivier Sigaud",
      "Nicolas Perrin-Gilbert"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2006.08505"
  },
  {
    "id": "arXiv:2008.01681",
    "title": "Multimodal Image-to-Image Translation via a Single Generative  Adversarial Network",
    "abstract": "Comments: pages 13, 15 figures",
    "descriptor": "\nComments: pages 13, 15 figures\n",
    "authors": [
      "Shihua Huang",
      "Cheng He",
      "Ran Cheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2008.01681"
  },
  {
    "id": "arXiv:2008.02653",
    "title": "OpenStreetMap data use cases during the early months of the COVID-19  pandemic",
    "abstract": "Comments: 15 pages, 6 figures. Submitted to the UN GGIM (this http URL) edited book titled COVID - 19 : Geospatial Information and Community Resilience. The volume is edited by Prof. Abbas Rajabifard from the University of Melbourne",
    "descriptor": "\nComments: 15 pages, 6 figures. Submitted to the UN GGIM (this http URL) edited book titled COVID - 19 : Geospatial Information and Community Resilience. The volume is edited by Prof. Abbas Rajabifard from the University of Melbourne\n",
    "authors": [
      "Peter Mooney",
      "A. Yair Grinberger",
      "Marco Minghini",
      "Serena Coetzee",
      "Levente Juhasz",
      "Godwin Yeboah"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2008.02653"
  },
  {
    "id": "arXiv:2008.09831",
    "title": "From noisy point clouds to complete ear shapes: unsupervised pipeline",
    "abstract": "From noisy point clouds to complete ear shapes: unsupervised pipeline",
    "descriptor": "",
    "authors": [
      "Filipa Valdeira",
      "Ricardo Ferreira",
      "Alessandra Micheletti",
      "Cl\u00e1udia Soares"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2008.09831"
  },
  {
    "id": "arXiv:2008.10937",
    "title": "A Survey on Evolutionary Neural Architecture Search",
    "abstract": "Comments: this paper has been accepted for publication by IEEE Transactions on Neural Networks and Learning Systems (2021)",
    "descriptor": "\nComments: this paper has been accepted for publication by IEEE Transactions on Neural Networks and Learning Systems (2021)\n",
    "authors": [
      "Yuqiao Liu",
      "Yanan Sun",
      "Bing Xue",
      "Mengjie Zhang",
      "Gary G. Yen",
      "Kay Chen Tan"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2008.10937"
  },
  {
    "id": "arXiv:2008.11543",
    "title": "The tree search game for two players",
    "abstract": "Comments: 24 pages. Essentially the same as published version (this http URL)",
    "descriptor": "\nComments: 24 pages. Essentially the same as published version (this http URL)\n",
    "authors": [
      "Ravi B. Boppana",
      "Joel Brewster Lewis"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Computer Science and Game Theory (cs.GT)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2008.11543"
  },
  {
    "id": "arXiv:2009.01054",
    "title": "Generalized vec trick for fast learning of pairwise kernel models",
    "abstract": "Comments: 36 pages, 9 figures",
    "descriptor": "\nComments: 36 pages, 9 figures\n",
    "authors": [
      "Markus Viljanen",
      "Antti Airola",
      "Tapio Pahikkala"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2009.01054"
  },
  {
    "id": "arXiv:2009.14043",
    "title": "Online Simple Knapsack with Reservation Costs",
    "abstract": "Comments: Third version, closed remaining gaps",
    "descriptor": "\nComments: Third version, closed remaining gaps\n",
    "authors": [
      "Hans-Joachim Boeckenhauer",
      "Elisabet Burjons",
      "Fabian Frei",
      "Juraj Hromkovic",
      "Henri Lotze",
      "Peter Rossmanith"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2009.14043"
  },
  {
    "id": "arXiv:2011.15081",
    "title": "DEF: Deep Estimation of Sharp Geometric Features in 3D Shapes",
    "abstract": "DEF: Deep Estimation of Sharp Geometric Features in 3D Shapes",
    "descriptor": "",
    "authors": [
      "Albert Matveev",
      "Ruslan Rakhimov",
      "Alexey Artemov",
      "Gleb Bobrovskikh",
      "Vage Egiazarian",
      "Emil Bogomolov",
      "Daniele Panozzo",
      "Denis Zorin",
      "Evgeny Burnaev"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2011.15081"
  },
  {
    "id": "arXiv:2012.00113",
    "title": "The FEDHC Bayesian network learning algorithm",
    "abstract": "The FEDHC Bayesian network learning algorithm",
    "descriptor": "",
    "authors": [
      "Michail Tsagris"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2012.00113"
  },
  {
    "id": "arXiv:2012.09820",
    "title": "Explicit RKF-Compact Scheme for Pricing Regime Switching American  Options with Varying Time Step",
    "abstract": "Explicit RKF-Compact Scheme for Pricing Regime Switching American  Options with Varying Time Step",
    "descriptor": "",
    "authors": [
      "Chinonso Nwankwo",
      "Weizhong Dai"
    ],
    "subjectives": [
      "Computational Finance (q-fin.CP)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Numerical Analysis (math.NA)",
      "Mathematical Finance (q-fin.MF)",
      "Pricing of Securities (q-fin.PR)"
    ],
    "url": "https://arxiv.org/abs/2012.09820"
  },
  {
    "id": "arXiv:2101.08939",
    "title": "A Rich Type System for Quantum Programs",
    "abstract": "Comments: 49 pages, 3 figures",
    "descriptor": "\nComments: 49 pages, 3 figures\n",
    "authors": [
      "Aarthi Sundaram",
      "Robert Rand",
      "Kartik Singhal",
      "Brad Lackey"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Emerging Technologies (cs.ET)",
      "Logic in Computer Science (cs.LO)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2101.08939"
  },
  {
    "id": "arXiv:2101.09162",
    "title": "A Robust Blockchain Readiness Index Model",
    "abstract": "Comments: The final authenticated version is available online at this https URL",
    "descriptor": "\nComments: The final authenticated version is available online at this https URL\n",
    "authors": [
      "Elias Iosif",
      "Klitos Christodoulou",
      "Andreas Vlachos"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2101.09162"
  },
  {
    "id": "arXiv:2102.04903",
    "title": "FeedRec: News Feed Recommendation with Various User Feedbacks",
    "abstract": "Comments: WWW 2022",
    "descriptor": "\nComments: WWW 2022\n",
    "authors": [
      "Chuhan Wu",
      "Fangzhao Wu",
      "Tao Qi",
      "Yongfeng Huang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2102.04903"
  },
  {
    "id": "arXiv:2102.05892",
    "title": "Visualizing hierarchies in scRNA-seq data using a density tree-biased  autoencoder",
    "abstract": "Visualizing hierarchies in scRNA-seq data using a density tree-biased  autoencoder",
    "descriptor": "",
    "authors": [
      "Quentin Garrido",
      "Sebastian Damrich",
      "Alexander J\u00e4ger",
      "Dario Cerletti",
      "Manfred Claassen",
      "Laurent Najman",
      "Fred Hamprecht"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2102.05892"
  },
  {
    "id": "arXiv:2102.06966",
    "title": "Graph Convolution for Semi-Supervised Classification: Improved Linear  Separability and Out-of-Distribution Generalization",
    "abstract": "Comments: 30 pages, 9 figures, 2 tables",
    "descriptor": "\nComments: 30 pages, 9 figures, 2 tables\n",
    "authors": [
      "Aseem Baranwal",
      "Kimon Fountoulakis",
      "Aukosh Jagannath"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2102.06966"
  },
  {
    "id": "arXiv:2102.09977",
    "title": "Exploring Factors and Metrics to Select Open Source Software Components  for Integration: An Empirical Study",
    "abstract": "Exploring Factors and Metrics to Select Open Source Software Components  for Integration: An Empirical Study",
    "descriptor": "",
    "authors": [
      "Xiaozhou Li",
      "Sergio Moreschini",
      "Zheying Zhang",
      "Davide Taibi"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2102.09977"
  },
  {
    "id": "arXiv:2103.04922",
    "title": "Deep Generative Modelling: A Comparative Review of VAEs, GANs,  Normalizing Flows, Energy-Based and Autoregressive Models",
    "abstract": "Comments: 20 pages, 9 figures, will appear in IEEE Transactions on Pattern Analysis and Machine Intelligence",
    "descriptor": "\nComments: 20 pages, 9 figures, will appear in IEEE Transactions on Pattern Analysis and Machine Intelligence\n",
    "authors": [
      "Sam Bond-Taylor",
      "Adam Leach",
      "Yang Long",
      "Chris G. Willcocks"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2103.04922"
  },
  {
    "id": "arXiv:2104.08700",
    "title": "Lottery Jackpots Exist in Pre-trained Models",
    "abstract": "Comments: 10 pages, 7 figures",
    "descriptor": "\nComments: 10 pages, 7 figures\n",
    "authors": [
      "Yuxin Zhang",
      "Mingbao Lin",
      "Fei Chao",
      "Yan Wang",
      "Ke Li",
      "Yunhang Shen",
      "Yongjian Wu",
      "Rongrong Ji"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2104.08700"
  },
  {
    "id": "arXiv:2104.13020",
    "title": "Simple yet Sharp Sensitivity Analysis for Unmeasured Confounding",
    "abstract": "Simple yet Sharp Sensitivity Analysis for Unmeasured Confounding",
    "descriptor": "",
    "authors": [
      "Jose M. Pe\u00f1a"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2104.13020"
  },
  {
    "id": "arXiv:2105.04137",
    "title": "On the inversion number of oriented graphs",
    "abstract": "On the inversion number of oriented graphs",
    "descriptor": "",
    "authors": [
      "J\u00f8rgen Bang-Jensen",
      "Jonas Costa Ferreira da Silva",
      "Fr\u00e9d\u00e9ric Havet"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2105.04137"
  },
  {
    "id": "arXiv:2105.06194",
    "title": "Geometric Model Checking of Continuous Space",
    "abstract": "Geometric Model Checking of Continuous Space",
    "descriptor": "",
    "authors": [
      "Nick Bezhanishvili",
      "Vincenzo Ciancia",
      "David Gabelaia",
      "Gianluca Grilletti",
      "Diego Latella",
      "Mieke Massink"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2105.06194"
  },
  {
    "id": "arXiv:2105.14829",
    "title": "Q-attention: Enabling Efficient Learning for Vision-based Robotic  Manipulation",
    "abstract": "Comments: IEEE Robotics and Automation Letters, 2022 (+ presentation at ICRA 2022). Videos and code found at: this https URL",
    "descriptor": "\nComments: IEEE Robotics and Automation Letters, 2022 (+ presentation at ICRA 2022). Videos and code found at: this https URL\n",
    "authors": [
      "Stephen James",
      "Andrew J. Davison"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.14829"
  },
  {
    "id": "arXiv:2106.00906",
    "title": "Learn to Predict Equilibria via Fixed Point Networks",
    "abstract": "Learn to Predict Equilibria via Fixed Point Networks",
    "descriptor": "",
    "authors": [
      "Howard Heaton",
      "Daniel McKenzie",
      "Qiuwei Li",
      "Samy Wu Fung",
      "Stanley Osher",
      "Wotao Yin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Science and Game Theory (cs.GT)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2106.00906"
  },
  {
    "id": "arXiv:2106.01285",
    "title": "Sample-based Approximation of Nash in Large Many-Player Games via  Gradient Descent",
    "abstract": "Comments: Published in AAMAS 2022 (code available as part of open_spiel on github -- search ADIDAS in repo)",
    "descriptor": "\nComments: Published in AAMAS 2022 (code available as part of open_spiel on github -- search ADIDAS in repo)\n",
    "authors": [
      "Ian Gemp",
      "Rahul Savani",
      "Marc Lanctot",
      "Yoram Bachrach",
      "Thomas Anthony",
      "Richard Everett",
      "Andrea Tacchetti",
      "Tom Eccles",
      "J\u00e1nos Kram\u00e1r"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2106.01285"
  },
  {
    "id": "arXiv:2106.01513",
    "title": "Granger Causality from Quantized Measurements",
    "abstract": "Granger Causality from Quantized Measurements",
    "descriptor": "",
    "authors": [
      "Salman Ahmadi",
      "Girish N. Nair",
      "Erik Weyer"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.01513"
  },
  {
    "id": "arXiv:2106.01628",
    "title": "A Coalgebraic Approach to Dualities for Neighborhood Frames",
    "abstract": "A Coalgebraic Approach to Dualities for Neighborhood Frames",
    "descriptor": "",
    "authors": [
      "Guram Bezhanishvili",
      "Nick Bezhanishvili",
      "Jim de Groot"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Logic (math.LO)"
    ],
    "url": "https://arxiv.org/abs/2106.01628"
  },
  {
    "id": "arXiv:2106.03496",
    "title": "Self-Supervision & Meta-Learning for One-Shot Unsupervised Cross-Domain  Detection",
    "abstract": "Comments: This paper is under consideration for publication at Computer Vision and Image Understanding",
    "descriptor": "\nComments: This paper is under consideration for publication at Computer Vision and Image Understanding\n",
    "authors": [
      "F. Cappio Borlino",
      "S. Polizzotto",
      "A. D'Innocente",
      "S. Bucci",
      "B. Caputo",
      "T. Tommasi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.03496"
  },
  {
    "id": "arXiv:2106.04149",
    "title": "To Smooth or Not? When Label Smoothing Meets Noisy Labels",
    "abstract": "Comments: Under Review",
    "descriptor": "\nComments: Under Review\n",
    "authors": [
      "Jiaheng Wei",
      "Hangyu Liu",
      "Tongliang Liu",
      "Gang Niu",
      "Masashi Sugiyama",
      "Yang Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.04149"
  },
  {
    "id": "arXiv:2106.06907",
    "title": "ADVERT: An Adaptive and Data-Driven Attention Enhancement Mechanism for  Phishing Prevention",
    "abstract": "ADVERT: An Adaptive and Data-Driven Attention Enhancement Mechanism for  Phishing Prevention",
    "descriptor": "",
    "authors": [
      "Linan Huang",
      "Shumeng Jia",
      "Emily Balcetis",
      "Quanyan Zhu"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.06907"
  },
  {
    "id": "arXiv:2106.06959",
    "title": "Do Not Escape From the Manifold: Discovering the Local Coordinates on  the Latent Space of GANs",
    "abstract": "Comments: 24 pages, 19 figures",
    "descriptor": "\nComments: 24 pages, 19 figures\n",
    "authors": [
      "Jaewoong Choi",
      "Junho Lee",
      "Changyeon Yoon",
      "Jung Ho Park",
      "Geonho Hwang",
      "Myungjoo Kang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.06959"
  },
  {
    "id": "arXiv:2106.09256",
    "title": "Seeing Differently, Acting Similarly: Imitation Learning with  Heterogeneous Observations",
    "abstract": "Seeing Differently, Acting Similarly: Imitation Learning with  Heterogeneous Observations",
    "descriptor": "",
    "authors": [
      "Xin-Qiang Cai",
      "Yao-Xiang Ding",
      "Zi-Xuan Chen",
      "Yuan Jiang",
      "Masashi Sugiyama",
      "Zhi-Hua Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.09256"
  },
  {
    "id": "arXiv:2106.10994",
    "title": "BernNet: Learning Arbitrary Graph Spectral Filters via Bernstein  Approximation",
    "abstract": "Comments: NeurIPS 2021",
    "descriptor": "\nComments: NeurIPS 2021\n",
    "authors": [
      "Mingguo He",
      "Zhewei Wei",
      "Zengfeng Huang",
      "Hongteng Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.10994"
  },
  {
    "id": "arXiv:2106.11068",
    "title": "Affine-Invariant Integrated Rank-Weighted Depth: Definition, Properties  and Finite Sample Analysis",
    "abstract": "Affine-Invariant Integrated Rank-Weighted Depth: Definition, Properties  and Finite Sample Analysis",
    "descriptor": "",
    "authors": [
      "Guillaume Staerman",
      "Pavlo Mozharovskyi",
      "St\u00e9phan Cl\u00e9men\u00e7on"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.11068"
  },
  {
    "id": "arXiv:2106.11810",
    "title": "NuPlan: A closed-loop ML-based planning benchmark for autonomous  vehicles",
    "abstract": "Comments: Minor updates to Related Work",
    "descriptor": "\nComments: Minor updates to Related Work\n",
    "authors": [
      "Holger Caesar",
      "Juraj Kabzan",
      "Kok Seang Tan",
      "Whye Kit Fong",
      "Eric Wolff",
      "Alex Lang",
      "Luke Fletcher",
      "Oscar Beijbom",
      "Sammy Omari"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.11810"
  },
  {
    "id": "arXiv:2106.13695",
    "title": "CADDA: Class-wise Automatic Differentiable Data Augmentation for EEG  Signals",
    "abstract": "CADDA: Class-wise Automatic Differentiable Data Augmentation for EEG  Signals",
    "descriptor": "",
    "authors": [
      "C\u00e9dric Rommel",
      "Thomas Moreau",
      "Joseph Paillard",
      "Alexandre Gramfort"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.13695"
  },
  {
    "id": "arXiv:2106.14917",
    "title": "Striking the Right Balance: Recall Loss for Semantic Segmentation",
    "abstract": "Comments: Paper accepted to ICRA2022",
    "descriptor": "\nComments: Paper accepted to ICRA2022\n",
    "authors": [
      "Junjiao Tian",
      "Niluthpol Mithun",
      "Zach Seymour",
      "Han-Pang Chiu",
      "Zsolt Kira"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.14917"
  },
  {
    "id": "arXiv:2107.03428",
    "title": "Management of Resource at the Network Edge for Federated Learning",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:1803.05255 by other authors",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:1803.05255 by other authors\n",
    "authors": [
      "Silvana Trindade",
      "Luiz F. Bittencourt",
      "Nelson L. S. da Fonseca"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.03428"
  },
  {
    "id": "arXiv:2107.05018",
    "title": "CLAP: A New Algorithm for Promise CSPs",
    "abstract": "Comments: Full version of a SODA 2020 paper",
    "descriptor": "\nComments: Full version of a SODA 2020 paper\n",
    "authors": [
      "Lorenzo Ciardo",
      "Stanislav \u017divn\u00fd"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2107.05018"
  },
  {
    "id": "arXiv:2107.05256",
    "title": "Rate-Splitting Multiple Access for Communications and Jamming in  Multi-Antenna Multi-Carrier Cognitive Radio Systems",
    "abstract": "Rate-Splitting Multiple Access for Communications and Jamming in  Multi-Antenna Multi-Carrier Cognitive Radio Systems",
    "descriptor": "",
    "authors": [
      "Onur Dizdar",
      "Bruno Clerckx"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2107.05256"
  },
  {
    "id": "arXiv:2107.08374",
    "title": "Detecting Braess Routes: an Algorithm Accounting for Queuing Delays With  an Extended Graph",
    "abstract": "Detecting Braess Routes: an Algorithm Accounting for Queuing Delays With  an Extended Graph",
    "descriptor": "",
    "authors": [
      "Mikhail Burov",
      "Can Kizilkale",
      "Alexander Kurzhanskiy",
      "Murat Arcak"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2107.08374"
  },
  {
    "id": "arXiv:2107.13265",
    "title": "Learned Optimizers for Analytic Continuation",
    "abstract": "Comments: 11 pages, 7 figures, 6 tables",
    "descriptor": "\nComments: 11 pages, 7 figures, 6 tables\n",
    "authors": [
      "Dongchen Huang",
      "Yi-feng Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Strongly Correlated Electrons (cond-mat.str-el)"
    ],
    "url": "https://arxiv.org/abs/2107.13265"
  },
  {
    "id": "arXiv:2108.01775",
    "title": "Solo-learn: A Library of Self-supervised Methods for Visual  Representation Learning",
    "abstract": "Comments: Accepted to JMLR",
    "descriptor": "\nComments: Accepted to JMLR\n",
    "authors": [
      "Victor G. Turrisi da Costa",
      "Enrico Fini",
      "Moin Nabi",
      "Nicu Sebe",
      "Elisa Ricci"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.01775"
  },
  {
    "id": "arXiv:2108.03702",
    "title": "BIGRoC: Boosting Image Generation via a Robust Classifier",
    "abstract": "BIGRoC: Boosting Image Generation via a Robust Classifier",
    "descriptor": "",
    "authors": [
      "Roy Ganz",
      "Michael Elad"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.03702"
  },
  {
    "id": "arXiv:2108.04526",
    "title": "A Survey on Deep Reinforcement Learning for Data Processing and  Analytics",
    "abstract": "Comments: 39 pages, 3 figures and 3 tables",
    "descriptor": "\nComments: 39 pages, 3 figures and 3 tables\n",
    "authors": [
      "Qingpeng Cai",
      "Can Cui",
      "Yiyuan Xiong",
      "Wei Wang",
      "Zhongle Xie",
      "Meihui Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2108.04526"
  },
  {
    "id": "arXiv:2108.07707",
    "title": "On Incorrectness Logic and Kleene Algebra with Top and Tests",
    "abstract": "On Incorrectness Logic and Kleene Algebra with Top and Tests",
    "descriptor": "",
    "authors": [
      "Cheng Zhang",
      "Arthur Azevedo de Amorim",
      "Marco Gaboardi"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2108.07707"
  },
  {
    "id": "arXiv:2108.13233",
    "title": "Whole Brain Vessel Graphs: A Dataset and Benchmark for Graph Learning  and Neuroscience (VesselGraph)",
    "abstract": "Comments: Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track",
    "descriptor": "\nComments: Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track\n",
    "authors": [
      "Johannes C. Paetzold",
      "Julian McGinnis",
      "Suprosanna Shit",
      "Ivan Ezhov",
      "Paul B\u00fcschl",
      "Chinmay Prabhakar",
      "Mihail I. Todorov",
      "Anjany Sekuboyina",
      "Georgios Kaissis",
      "Ali Ert\u00fcrk",
      "Stephan G\u00fcnnemann",
      "Bjoern H. Menze"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2108.13233"
  },
  {
    "id": "arXiv:2109.02839",
    "title": "Self-adaptive deep neural network: Numerical approximation to functions  and PDEs",
    "abstract": "Comments: Published in Journal of Computational Physics",
    "descriptor": "\nComments: Published in Journal of Computational Physics\n",
    "authors": [
      "Zhiqiang Cai",
      "Jingshuang Chen",
      "Min Liu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.02839"
  },
  {
    "id": "arXiv:2109.03506",
    "title": "Towards Natural Language Interfaces for Data Visualization: A Survey",
    "abstract": "Comments: 20 pages, 15 figures, accepted by IEEE TVCG",
    "descriptor": "\nComments: 20 pages, 15 figures, accepted by IEEE TVCG\n",
    "authors": [
      "Leixian Shen",
      "Enya Shen",
      "Yuyu Luo",
      "Xiaocong Yang",
      "Xuming Hu",
      "Xiongshuai Zhang",
      "Zhiwei Tai",
      "Jianmin Wang"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2109.03506"
  },
  {
    "id": "arXiv:2109.05113",
    "title": "Natural Multicontact Walking for Robotic Assistive Devices via  Musculoskeletal Models and Hybrid Zero Dynamics",
    "abstract": "Comments: 8 pages, 7 figures",
    "descriptor": "\nComments: 8 pages, 7 figures\n",
    "authors": [
      "Kejun Li",
      "Maegan Tucker",
      "Rachel Gehlhar",
      "Yisong Yue",
      "Aaron D. Ames"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.05113"
  },
  {
    "id": "arXiv:2109.06054",
    "title": "Minimizing Quantum Renyi Divergences via Mirror Descent with Polyak Step  Size",
    "abstract": "Comments: 22 pages, proof of Theorem 5.3 improved, Section 5.3 added",
    "descriptor": "\nComments: 22 pages, proof of Theorem 5.3 improved, Section 5.3 added\n",
    "authors": [
      "Jun-Kai You",
      "Hao-Chung Cheng",
      "Yen-Huan Li"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Optimization and Control (math.OC)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2109.06054"
  },
  {
    "id": "arXiv:2109.06550",
    "title": "Fast and Accurate Extrinsic Calibration for Multiple LiDARs and Cameras",
    "abstract": "Comments: 10 pages, 15 figures",
    "descriptor": "\nComments: 10 pages, 15 figures\n",
    "authors": [
      "Xiyuan Liu",
      "Chongjian Yuan",
      "Fu Zhang"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.06550"
  },
  {
    "id": "arXiv:2109.08521",
    "title": "Focus on Impact: Indoor Exploration with Intrinsic Motivation",
    "abstract": "Comments: Published in IEEE Robotics and Automation Letters. To appear in ICRA 2022",
    "descriptor": "\nComments: Published in IEEE Robotics and Automation Letters. To appear in ICRA 2022\n",
    "authors": [
      "Roberto Bigazzi",
      "Federico Landi",
      "Silvia Cascianelli",
      "Lorenzo Baraldi",
      "Marcella Cornia",
      "Rita Cucchiara"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.08521"
  },
  {
    "id": "arXiv:2109.09495",
    "title": "GhostShiftAddNet: More Features from Energy-Efficient Operations",
    "abstract": "GhostShiftAddNet: More Features from Energy-Efficient Operations",
    "descriptor": "",
    "authors": [
      "Jia Bi",
      "Jonathon Hare",
      "Geoff V. Merrett"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2109.09495"
  },
  {
    "id": "arXiv:2109.09901",
    "title": "Modeling Adversarial Noise for Adversarial Training",
    "abstract": "Modeling Adversarial Noise for Adversarial Training",
    "descriptor": "",
    "authors": [
      "Dawei Zhou",
      "Nannan Wang",
      "Bo Han",
      "Tongliang Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.09901"
  },
  {
    "id": "arXiv:2109.10883",
    "title": "ENERO: Efficient Real-Time WAN Routing Optimization with Deep  Reinforcement Learning",
    "abstract": "Comments: 11 pages, 9 figures",
    "descriptor": "\nComments: 11 pages, 9 figures\n",
    "authors": [
      "Paul Almasan",
      "Shihan Xiao",
      "Xiangle Cheng",
      "Xiang Shi",
      "Pere Barlet-Ros",
      "Albert Cabellos-Aparicio"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.10883"
  },
  {
    "id": "arXiv:2109.12264",
    "title": "More Than Reading Comprehension: A Survey on Datasets and Metrics of  Textual Question Answering",
    "abstract": "Comments: 18 pages, 11 figures, 6 tables",
    "descriptor": "\nComments: 18 pages, 11 figures, 6 tables\n",
    "authors": [
      "Yang Bai",
      "Daisy Zhe Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.12264"
  },
  {
    "id": "arXiv:2109.12784",
    "title": "Learning from Small Samples: Transformation-Invariant SVMs with  Composition and Locality at Multiple Scales",
    "abstract": "Learning from Small Samples: Transformation-Invariant SVMs with  Composition and Locality at Multiple Scales",
    "descriptor": "",
    "authors": [
      "Tao Liu",
      "P. R. Kumar",
      "Ruida Zhou",
      "Xi Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2109.12784"
  },
  {
    "id": "arXiv:2110.00736",
    "title": "Stanford Pupper: A Low-Cost Agile Quadruped Robot for Benchmarking and  Education",
    "abstract": "Stanford Pupper: A Low-Cost Agile Quadruped Robot for Benchmarking and  Education",
    "descriptor": "",
    "authors": [
      "Nathan Kau"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.00736"
  },
  {
    "id": "arXiv:2110.01763",
    "title": "DNSMOS P.835: A Non-Intrusive Perceptual Objective Speech Quality Metric  to Evaluate Noise Suppressors",
    "abstract": "Comments: arXiv admin note: substantial text overlap with arXiv:2010.15258",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2010.15258\n",
    "authors": [
      "Chandan K A Reddy",
      "Vishak Gopal",
      "Ross Cutler"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2110.01763"
  },
  {
    "id": "arXiv:2110.02802",
    "title": "Self-conditioning pre-trained language models",
    "abstract": "Comments: 8 pages and supplementary material",
    "descriptor": "\nComments: 8 pages and supplementary material\n",
    "authors": [
      "Xavier Suau",
      "Luca Zappella",
      "Nicholas Apostoloff"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.02802"
  },
  {
    "id": "arXiv:2110.03002",
    "title": "Multi-Scale Convolutional Neural Network for Automated AMD  Classification using Retinal OCT Images",
    "abstract": "Multi-Scale Convolutional Neural Network for Automated AMD  Classification using Retinal OCT Images",
    "descriptor": "",
    "authors": [
      "Saman Sotoudeh-Paima",
      "Ata Jodeiri",
      "Fedra Hajizadeh",
      "Hamid Soltanian-Zadeh"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.03002"
  },
  {
    "id": "arXiv:2110.03243",
    "title": "Sound Event Detection Guided by Semantic Contexts of Scenes",
    "abstract": "Comments: Accepted to ICASSP 2022",
    "descriptor": "\nComments: Accepted to ICASSP 2022\n",
    "authors": [
      "Noriyuki Tonami",
      "Keisuke Imoto",
      "Ryotaro Nagase",
      "Yuki Okamoto",
      "Takahiro Fukumori",
      "Yoichi Yamashita"
    ],
    "subjectives": [
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2110.03243"
  },
  {
    "id": "arXiv:2110.03765",
    "title": "Spectroscopy Approaches for Food Safety Applications: Improving Data  Efficiency Using Active Learning and Semi-Supervised Learning",
    "abstract": "Spectroscopy Approaches for Food Safety Applications: Improving Data  Efficiency Using Active Learning and Semi-Supervised Learning",
    "descriptor": "",
    "authors": [
      "Huanle Zhang",
      "Nicharee Wisuthiphaet",
      "Hemiao Cui",
      "Nitin Nitin",
      "Xin Liu",
      "Qing Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.03765"
  },
  {
    "id": "arXiv:2110.03876",
    "title": "Phone-to-audio alignment without text: A Semi-supervised Approach",
    "abstract": "Comments: ICASSP 2022",
    "descriptor": "\nComments: ICASSP 2022\n",
    "authors": [
      "Jian Zhu",
      "Cong Zhang",
      "David Jurgens"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.03876"
  },
  {
    "id": "arXiv:2110.04156",
    "title": "Showing Your Offline Reinforcement Learning Work: Online Evaluation  Budget Matters",
    "abstract": "Comments: Major revision",
    "descriptor": "\nComments: Major revision\n",
    "authors": [
      "Vladislav Kurenkov",
      "Sergey Kolesnikov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.04156"
  },
  {
    "id": "arXiv:2110.04260",
    "title": "Taming Sparsely Activated Transformer with Stochastic Experts",
    "abstract": "Comments: ICLR 2022",
    "descriptor": "\nComments: ICLR 2022\n",
    "authors": [
      "Simiao Zuo",
      "Xiaodong Liu",
      "Jian Jiao",
      "Young Jin Kim",
      "Hany Hassan",
      "Ruofei Zhang",
      "Tuo Zhao",
      "Jianfeng Gao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.04260"
  },
  {
    "id": "arXiv:2110.04267",
    "title": "Exploring Heterogeneous Characteristics of Layers in ASR Models for More  Efficient Training",
    "abstract": "Comments: \\c{opyright} 2021 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works",
    "descriptor": "\nComments: \\c{opyright} 2021 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works\n",
    "authors": [
      "Lillian Zhou",
      "Dhruv Guliani",
      "Andreas Kabel",
      "Giovanni Motta",
      "Fran\u00e7oise Beaufays"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.04267"
  },
  {
    "id": "arXiv:2110.04350",
    "title": "FRL: Federated Rank Learning",
    "abstract": "FRL: Federated Rank Learning",
    "descriptor": "",
    "authors": [
      "Hamid Mozaffari",
      "Virat Shejwalkar",
      "Amir Houmansadr"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.04350"
  },
  {
    "id": "arXiv:2110.05005",
    "title": "Quasi-Cyclic Stern Proof of Knowledge",
    "abstract": "Quasi-Cyclic Stern Proof of Knowledge",
    "descriptor": "",
    "authors": [
      "Lo\u00efc Bidoux",
      "Philippe Gaborit",
      "Mukul Kulkarni",
      "Nicolas Sendrier"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.05005"
  },
  {
    "id": "arXiv:2110.08500",
    "title": "On Model Selection Consistency of Lasso for High-Dimensional Ising  Models on Tree-like Graphs",
    "abstract": "Comments: 27 pages, 2 figures",
    "descriptor": "\nComments: 27 pages, 2 figures\n",
    "authors": [
      "Xiangming Meng",
      "Tomoyuki Obuchi",
      "Yoshiyuki Kabashima"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2110.08500"
  },
  {
    "id": "arXiv:2110.09911",
    "title": "Predicate and relation liftings for coalgebras with side effects: an  application in coalgebraic modal logic",
    "abstract": "Predicate and relation liftings for coalgebras with side effects: an  application in coalgebraic modal logic",
    "descriptor": "",
    "authors": [
      "H. Beohar",
      "B. K\u00f6nig",
      "S. K\u00fcpper",
      "C. Mika-Michalski"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2110.09911"
  },
  {
    "id": "arXiv:2110.10461",
    "title": "Scalable One-Pass Optimisation of High-Dimensional Weight-Update  Hyperparameters by Implicit Differentiation",
    "abstract": "Comments: 41 pages, 19 figures, 15 tables; ICLR 2022 camera-ready version",
    "descriptor": "\nComments: 41 pages, 19 figures, 15 tables; ICLR 2022 camera-ready version\n",
    "authors": [
      "Ross M. Clarke",
      "Elre T. Oldewage",
      "Jos\u00e9 Miguel Hern\u00e1ndez-Lobato"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.10461"
  },
  {
    "id": "arXiv:2110.11346",
    "title": "Data-Driven Offline Optimization For Architecting Hardware Accelerators",
    "abstract": "Comments: First two authors contributed equally; published at ICLR 2022",
    "descriptor": "\nComments: First two authors contributed equally; published at ICLR 2022\n",
    "authors": [
      "Aviral Kumar",
      "Amir Yazdanbakhsh",
      "Milad Hashemi",
      "Kevin Swersky",
      "Sergey Levine"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.11346"
  },
  {
    "id": "arXiv:2110.12734",
    "title": "Fast Gradient Non-sign Methods",
    "abstract": "Fast Gradient Non-sign Methods",
    "descriptor": "",
    "authors": [
      "Yaya Cheng",
      "Jingkuan Song",
      "Xiaosu Zhu",
      "Qilong Zhang",
      "Lianli Gao",
      "Heng Tao Shen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.12734"
  },
  {
    "id": "arXiv:2110.12810",
    "title": "Learning What to Memorize: Using Intrinsic Motivation to Form Useful  Memory in Partially Observable Reinforcement Learning",
    "abstract": "Comments: Acknowledgements are added",
    "descriptor": "\nComments: Acknowledgements are added\n",
    "authors": [
      "Alper Demir"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.12810"
  },
  {
    "id": "arXiv:2110.14789",
    "title": "Millimeter Wave Wireless Assisted Robot Navigation with Link State  Classification",
    "abstract": "Comments: 14 pages, 20 figures",
    "descriptor": "\nComments: 14 pages, 20 figures\n",
    "authors": [
      "Mingsheng Yin",
      "Akshaj Veldanda",
      "Amee Trivedi",
      "Jeff Zhang",
      "Kai Pfeiffer",
      "Yaqi Hu",
      "Siddharth Garg",
      "Elza Erkip",
      "Ludovic Righetti",
      "Sundeep Rangan"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.14789"
  },
  {
    "id": "arXiv:2111.00552",
    "title": "Policy Optimization for Constrained MDPs with Provable Fast Global  Convergence",
    "abstract": "Policy Optimization for Constrained MDPs with Provable Fast Global  Convergence",
    "descriptor": "",
    "authors": [
      "Tao Liu",
      "Ruida Zhou",
      "Dileep Kalathil",
      "P. R. Kumar",
      "Chao Tian"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2111.00552"
  },
  {
    "id": "arXiv:2111.01363",
    "title": "Knowledge Cross-Distillation for Membership Privacy",
    "abstract": "Comments: Accepted by PETS 2022",
    "descriptor": "\nComments: Accepted by PETS 2022\n",
    "authors": [
      "Rishav Chourasia",
      "Batnyam Enkhtaivan",
      "Kunihiro Ito",
      "Junki Mori",
      "Isamu Teranishi",
      "Hikaru Tsuchida"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.01363"
  },
  {
    "id": "arXiv:2111.05214",
    "title": "A Topological Data Analysis Based Classifier",
    "abstract": "Comments: The paper is under consideration at Advances in Data Analysis and Classification. arXiv admin note: text overlap with arXiv:2102.03709",
    "descriptor": "\nComments: The paper is under consideration at Advances in Data Analysis and Classification. arXiv admin note: text overlap with arXiv:2102.03709\n",
    "authors": [
      "Rolando Kindelan",
      "Jos\u00e9 Fr\u00edas",
      "Mauricio Cerda",
      "Nancy Hitschfeld"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2111.05214"
  },
  {
    "id": "arXiv:2111.05463",
    "title": "An Open-Source RRAM Compiler",
    "abstract": "Comments: 5 pages",
    "descriptor": "\nComments: 5 pages\n",
    "authors": [
      "Dimitris Antoniadis",
      "Andrea Mifsud",
      "Peilong Feng",
      "Timothy G. Constandinou"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2111.05463"
  },
  {
    "id": "arXiv:2111.05960",
    "title": "Grand-potential-based phase-field model of dissolution/precipitation:  lattice Boltzmann simulations of counter term effect on porous medium",
    "abstract": "Comments: 25 pages, 20 figures, 4 tables",
    "descriptor": "\nComments: 25 pages, 20 figures, 4 tables\n",
    "authors": [
      "T\u00e9o Boutin",
      "Werner Verdier",
      "Alain Cartalade"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Materials Science (cond-mat.mtrl-sci)",
      "Cellular Automata and Lattice Gases (nlin.CG)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2111.05960"
  },
  {
    "id": "arXiv:2111.05968",
    "title": "Linear Speedup in Personalized Collaborative Learning",
    "abstract": "Linear Speedup in Personalized Collaborative Learning",
    "descriptor": "",
    "authors": [
      "El Mahdi Chayti",
      "Sai Praneeth Karimireddy",
      "Sebastian U. Stich",
      "Nicolas Flammarion",
      "Martin Jaggi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.05968"
  },
  {
    "id": "arXiv:2111.07725",
    "title": "Investigating self-supervised front ends for speech spoofing  countermeasures",
    "abstract": "Comments: V3: added sub-band analysis, submitted to ISCA Odyssey2022; V2: added min tDCF results on 2019 and 2021 LA. EERs on LA 2021 were slightly updated to fix one glitch in the score file. EERs and min tDCFs on 2021 LA and DF can be computed using the latest official code this https URL Work in progress. Feedback is welcome!",
    "descriptor": "\nComments: V3: added sub-band analysis, submitted to ISCA Odyssey2022; V2: added min tDCF results on 2019 and 2021 LA. EERs on LA 2021 were slightly updated to fix one glitch in the score file. EERs and min tDCFs on 2021 LA and DF can be computed using the latest official code this https URL Work in progress. Feedback is welcome!\n",
    "authors": [
      "Xin Wang",
      "Junichi Yamagishi"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2111.07725"
  },
  {
    "id": "arXiv:2111.08066",
    "title": "Exploiting Action Impact Regularity and Exogenous State Variables for  Offline Reinforcement Learning",
    "abstract": "Exploiting Action Impact Regularity and Exogenous State Variables for  Offline Reinforcement Learning",
    "descriptor": "",
    "authors": [
      "Vincent Liu",
      "James Wright",
      "Martha White"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.08066"
  },
  {
    "id": "arXiv:2111.08617",
    "title": "Project CGX: Algorithmic and System Support for Scalable Deep Learning  on a Budget",
    "abstract": "Project CGX: Algorithmic and System Support for Scalable Deep Learning  on a Budget",
    "descriptor": "",
    "authors": [
      "Ilia Markov",
      "Hamidreza Ramezanikebrya",
      "Dan Alistarh"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.08617"
  },
  {
    "id": "arXiv:2111.10364",
    "title": "Generalized Decision Transformer for Offline Hindsight Information  Matching",
    "abstract": "Comments: Accepted to ICLR2022, Spotlight. Website: this https URL and Code: this https URL",
    "descriptor": "\nComments: Accepted to ICLR2022, Spotlight. Website: this https URL and Code: this https URL\n",
    "authors": [
      "Hiroki Furuta",
      "Yutaka Matsuo",
      "Shixiang Shane Gu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.10364"
  },
  {
    "id": "arXiv:2111.10985",
    "title": "Efficient Non-Compression Auto-Encoder for Driving Noise-based Road  Surface Anomaly Detection",
    "abstract": "Comments: 8 pages, 5 figures, 6 tables",
    "descriptor": "\nComments: 8 pages, 5 figures, 6 tables\n",
    "authors": [
      "YeongHyeon Park",
      "JongHee Jung"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2111.10985"
  },
  {
    "id": "arXiv:2111.12193",
    "title": "Multiset-Equivariant Set Prediction with Approximate Implicit  Differentiation",
    "abstract": "Comments: Published at International Conference on Learning Representations (ICLR) 2022",
    "descriptor": "\nComments: Published at International Conference on Learning Representations (ICLR) 2022\n",
    "authors": [
      "Yan Zhang",
      "David W. Zhang",
      "Simon Lacoste-Julien",
      "Gertjan J. Burghouts",
      "Cees G. M. Snoek"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.12193"
  },
  {
    "id": "arXiv:2111.15264",
    "title": "EdiBERT, a generative model for image editing",
    "abstract": "EdiBERT, a generative model for image editing",
    "descriptor": "",
    "authors": [
      "Thibaut Issenhuth",
      "Ugo Tanielian",
      "J\u00e9r\u00e9mie Mary",
      "David Picard"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.15264"
  },
  {
    "id": "arXiv:2112.00209",
    "title": "Environmental Sound Extraction Using Onomatopoeia",
    "abstract": "Comments: Accepted to ICASSP2022",
    "descriptor": "\nComments: Accepted to ICASSP2022\n",
    "authors": [
      "Yuki Okamoto",
      "Shota Horiguchi",
      "Masaaki Yamamoto",
      "Keisuke Imoto",
      "Yohei Kawaguchi"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2112.00209"
  },
  {
    "id": "arXiv:2112.00662",
    "title": "A general locomotion control framework for multi-legged locomotors",
    "abstract": "A general locomotion control framework for multi-legged locomotors",
    "descriptor": "",
    "authors": [
      "Baxi Chong",
      "Yasemin O. Aydin",
      "Jennifer M. Rieser",
      "Guillaume Sartoretti",
      "Tianyu Wang",
      "Julian Whitman",
      "Abdul Kaba",
      "Enes Aydin",
      "Ciera McFarland",
      "Kelimar Diaz Cruz",
      "Jeffery W. Rankin",
      "Krijn B Michel",
      "Alfredo Nicieza",
      "John R Hutchinson",
      "Howie Choset",
      "Daniel I. Goldman"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2112.00662"
  },
  {
    "id": "arXiv:2112.03534",
    "title": "Deep Surrogate Assisted MAP-Elites for Automated Hearthstone  Deckbuilding",
    "abstract": "Deep Surrogate Assisted MAP-Elites for Automated Hearthstone  Deckbuilding",
    "descriptor": "",
    "authors": [
      "Yulun Zhang",
      "Matthew C. Fontaine",
      "Amy K. Hoover",
      "Stefanos Nikolaidis"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2112.03534"
  },
  {
    "id": "arXiv:2112.04586",
    "title": "Monolithic Integration of Quantum Resonant Tunneling Gate on a 22nm  FD-SOI CMOS Process",
    "abstract": "Monolithic Integration of Quantum Resonant Tunneling Gate on a 22nm  FD-SOI CMOS Process",
    "descriptor": "",
    "authors": [
      "Imran Bashir",
      "Dirk Leipold",
      "Elena Blokhina",
      "Mike Asker",
      "David Redmond",
      "Ali Esmailiyan",
      "Panagiotis Giounanlis",
      "Hans Haenlein",
      "Xuton Wu",
      "Andrii Sokolov",
      "Dennis Andrade-Miceli",
      "Andrew K. Mitchell",
      "Robert Bogdan Staszewski"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.04586"
  },
  {
    "id": "arXiv:2112.05139",
    "title": "CLIP-NeRF: Text-and-Image Driven Manipulation of Neural Radiance Fields",
    "abstract": "Comments: updated missing references",
    "descriptor": "\nComments: updated missing references\n",
    "authors": [
      "Can Wang",
      "Menglei Chai",
      "Mingming He",
      "Dongdong Chen",
      "Jing Liao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2112.05139"
  },
  {
    "id": "arXiv:2112.11318",
    "title": "A Discontinuous Galerkin Solver in the FLASH Multi-Physics Framework",
    "abstract": "A Discontinuous Galerkin Solver in the FLASH Multi-Physics Framework",
    "descriptor": "",
    "authors": [
      "Johannes Markert",
      "Stefanie Walch",
      "Gregor Gassner"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2112.11318"
  },
  {
    "id": "arXiv:2112.11393",
    "title": "A Survey on Perfectly-Secure Verifiable Secret-Sharing",
    "abstract": "Comments: 38 pages, 17 figures",
    "descriptor": "\nComments: 38 pages, 17 figures\n",
    "authors": [
      "Anirudh Chandramouli",
      "Ashish Choudhury",
      "Arpita Patra"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2112.11393"
  },
  {
    "id": "arXiv:2112.11663",
    "title": "Accelerated Proximal Alternating Gradient-Descent-Ascent for Nonconvex  Minimax Machine Learning",
    "abstract": "Comments: 12 pages, 1 figure. Corrected proof and complexity order from the previous version. arXiv admin note: text overlap with arXiv:2102.04653",
    "descriptor": "\nComments: 12 pages, 1 figure. Corrected proof and complexity order from the previous version. arXiv admin note: text overlap with arXiv:2102.04653\n",
    "authors": [
      "Ziyi Chen",
      "Shaocong Ma",
      "Yi Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2112.11663"
  },
  {
    "id": "arXiv:2112.12228",
    "title": "Direct Behavior Specification via Constrained Reinforcement Learning",
    "abstract": "Direct Behavior Specification via Constrained Reinforcement Learning",
    "descriptor": "",
    "authors": [
      "Julien Roy",
      "Roger Girgis",
      "Joshua Romoff",
      "Pierre-Luc Bacon",
      "Christopher Pal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.12228"
  },
  {
    "id": "arXiv:2112.14804",
    "title": "Learning Inception Attention for Image Synthesis and Image Recognition",
    "abstract": "Learning Inception Attention for Image Synthesis and Image Recognition",
    "descriptor": "",
    "authors": [
      "Jianghao Shen",
      "Tianfu Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.14804"
  },
  {
    "id": "arXiv:2201.01346",
    "title": "Exploratory Analysis of Academic Collaborations between French and US",
    "abstract": "Exploratory Analysis of Academic Collaborations between French and US",
    "descriptor": "",
    "authors": [
      "George Panagopoulos",
      "Michalis Vazirgiannis"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2201.01346"
  },
  {
    "id": "arXiv:2201.01823",
    "title": "Learning Semantic Ambiguities for Zero-Shot Learning",
    "abstract": "Learning Semantic Ambiguities for Zero-Shot Learning",
    "descriptor": "",
    "authors": [
      "Celina Hanouti",
      "Herv\u00e9 Le Borgne"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2201.01823"
  },
  {
    "id": "arXiv:2201.05275",
    "title": "Deep Leaning-Based Ultra-Fast Stair Detection",
    "abstract": "Deep Leaning-Based Ultra-Fast Stair Detection",
    "descriptor": "",
    "authors": [
      "Chen Wang",
      "Zhongcai Pei",
      "Shuang Qiu",
      "Zhiyong Tang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.05275"
  },
  {
    "id": "arXiv:2201.07438",
    "title": "MHTTS: Fast multi-head text-to-speech for spontaneous speech with  imperfect transcription",
    "abstract": "MHTTS: Fast multi-head text-to-speech for spontaneous speech with  imperfect transcription",
    "descriptor": "",
    "authors": [
      "Dabiao Ma",
      "Yitong Zhang",
      "Meng Li",
      "Feng Ye"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2201.07438"
  },
  {
    "id": "arXiv:2201.08025",
    "title": "Low-Pass Filtering SGD for Recovering Flat Optima in the Deep Learning  Optimization Landscape",
    "abstract": "Low-Pass Filtering SGD for Recovering Flat Optima in the Deep Learning  Optimization Landscape",
    "descriptor": "",
    "authors": [
      "Devansh Bisla",
      "Jing Wang",
      "Anna Choromanska"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.08025"
  },
  {
    "id": "arXiv:2201.09693",
    "title": "Shape-consistent Generative Adversarial Networks for multi-modal Medical  segmentation maps",
    "abstract": "Shape-consistent Generative Adversarial Networks for multi-modal Medical  segmentation maps",
    "descriptor": "",
    "authors": [
      "Leo Segre",
      "Or Hirschorn",
      "Dvir Ginzburg",
      "Dan Raviv"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.09693"
  },
  {
    "id": "arXiv:2201.09765",
    "title": "Generative Planning for Temporally Coordinated Exploration in  Reinforcement Learning",
    "abstract": "Comments: Spotlight paper at the 10th International Conference on Learning Representations (ICLR 2022)",
    "descriptor": "\nComments: Spotlight paper at the 10th International Conference on Learning Representations (ICLR 2022)\n",
    "authors": [
      "Haichao Zhang",
      "Wei Xu",
      "Haonan Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.09765"
  },
  {
    "id": "arXiv:2201.09862",
    "title": "Learning to Act with Affordance-Aware Multimodal Neural SLAM",
    "abstract": "Learning to Act with Affordance-Aware Multimodal Neural SLAM",
    "descriptor": "",
    "authors": [
      "Zhiwei Jia",
      "Kaixiang Lin",
      "Yizhou Zhao",
      "Qiaozi Gao",
      "Govind Thattai",
      "Gaurav Sukhatme"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2201.09862"
  },
  {
    "id": "arXiv:2201.10147",
    "title": "TGFuse: An Infrared and Visible Image Fusion Approach Based on  Transformer and Generative Adversarial Network",
    "abstract": "TGFuse: An Infrared and Visible Image Fusion Approach Based on  Transformer and Generative Adversarial Network",
    "descriptor": "",
    "authors": [
      "Dongyu Rao",
      "Xiao-Jun Wu",
      "Tianyang Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.10147"
  },
  {
    "id": "arXiv:2201.11183",
    "title": "A dual approach for federated learning",
    "abstract": "A dual approach for federated learning",
    "descriptor": "",
    "authors": [
      "Zhenan Fan",
      "Huang Fang",
      "Michael P. Friedlander"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.11183"
  },
  {
    "id": "arXiv:2201.11433",
    "title": "ETAP: Energy-aware Timing Analysis of Intermittent Programs",
    "abstract": "Comments: Corrected typos in the previous submission",
    "descriptor": "\nComments: Corrected typos in the previous submission\n",
    "authors": [
      "Ferhat Erata",
      "Arda Goknil",
      "Eren Y\u0131ld\u0131z",
      "Kas\u0131m Sinan Y\u0131ld\u0131r\u0131m",
      "Ruzica Piskac",
      "Jakub Szefer",
      "G\u00f6k\u00e7in Sezgin"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2201.11433"
  },
  {
    "id": "arXiv:2201.11548",
    "title": "Vizing's and Shannon's Theorems for defective edge colouring",
    "abstract": "Vizing's and Shannon's Theorems for defective edge colouring",
    "descriptor": "",
    "authors": [
      "Pierre Aboulker",
      "Guillaume Aubian",
      "Chien-Chung Huang"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2201.11548"
  },
  {
    "id": "arXiv:2201.11639",
    "title": "Capacity of Finite State Channels with Feedback: Algorithmic and  Optimization Theoretic Properties",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:2008.13270",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2008.13270\n",
    "authors": [
      "Andrea Grigorescu",
      "Holger Boche",
      "Rafael F. Schaefer",
      "H. Vincent Poor"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2201.11639"
  },
  {
    "id": "arXiv:2201.11925",
    "title": "POLYLLA: Polygonal meshing algorithm based on terminal-edge regions",
    "abstract": "POLYLLA: Polygonal meshing algorithm based on terminal-edge regions",
    "descriptor": "",
    "authors": [
      "Sergio Salinas",
      "Nancy Hitschfeld-Kahler",
      "Alejandro Ortiz-Bernardin",
      "Hang Si"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2201.11925"
  },
  {
    "id": "arXiv:2201.11990",
    "title": "Using DeepSpeed and Megatron to Train Megatron-Turing NLG 530B, A  Large-Scale Generative Language Model",
    "abstract": "Comments: Shaden Smith and Mostofa Patwary contributed equally",
    "descriptor": "\nComments: Shaden Smith and Mostofa Patwary contributed equally\n",
    "authors": [
      "Shaden Smith",
      "Mostofa Patwary",
      "Brandon Norick",
      "Patrick LeGresley",
      "Samyam Rajbhandari",
      "Jared Casper",
      "Zhun Liu",
      "Shrimai Prabhumoye",
      "George Zerveas",
      "Vijay Korthikanti",
      "Elton Zhang",
      "Rewon Child",
      "Reza Yazdani Aminabadi",
      "Julie Bernauer",
      "Xia Song",
      "Mohammad Shoeybi",
      "Yuxiong He",
      "Michael Houston",
      "Saurabh Tiwary",
      "Bryan Catanzaro"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2201.11990"
  },
  {
    "id": "arXiv:2202.00397",
    "title": "Efficient computation of the Wright function and its applications to  fractional diffusion-wave equations",
    "abstract": "Efficient computation of the Wright function and its applications to  fractional diffusion-wave equations",
    "descriptor": "",
    "authors": [
      "Lidia Aceto",
      "Fabio Durastante"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.00397"
  },
  {
    "id": "arXiv:2202.00619",
    "title": "Insights into the Core of the Assignment Game via Complementarity",
    "abstract": "Comments: 10 pages",
    "descriptor": "\nComments: 10 pages\n",
    "authors": [
      "Vijay V. Vazirani"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Data Structures and Algorithms (cs.DS)",
      "Theoretical Economics (econ.TH)"
    ],
    "url": "https://arxiv.org/abs/2202.00619"
  },
  {
    "id": "arXiv:2202.00645",
    "title": "Stability and Generalization Capabilities of Message Passing Graph  Neural Networks",
    "abstract": "Comments: typos corrected",
    "descriptor": "\nComments: typos corrected\n",
    "authors": [
      "Sohir Maskey",
      "Yunseok Lee",
      "Ron Levie",
      "Gitta Kutyniok"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Numerical Analysis (math.NA)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2202.00645"
  },
  {
    "id": "arXiv:2202.00838",
    "title": "Finding Biological Plausibility for Adversarially Robust Features via  Metameric Tasks",
    "abstract": "Comments: Accepted to ICLR 2022 as a Spotlight",
    "descriptor": "\nComments: Accepted to ICLR 2022 as a Spotlight\n",
    "authors": [
      "Anne Harrington",
      "Arturo Deza"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2202.00838"
  },
  {
    "id": "arXiv:2202.00855",
    "title": "Extension -- Adaptive Sampling with Implicit Radiance Field",
    "abstract": "Extension -- Adaptive Sampling with Implicit Radiance Field",
    "descriptor": "",
    "authors": [
      "Yuchi Huo"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.00855"
  },
  {
    "id": "arXiv:2202.01011",
    "title": "Auto-Transfer: Learning to Route Transferrable Representations",
    "abstract": "Comments: Accepted for publication in ICLR 2022",
    "descriptor": "\nComments: Accepted for publication in ICLR 2022\n",
    "authors": [
      "Keerthiram Murugesan",
      "Vijay Sadashivaiah",
      "Ronny Luss",
      "Karthikeyan Shanmugam",
      "Pin-Yu Chen",
      "Amit Dhurandhar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.01011"
  },
  {
    "id": "arXiv:2202.01197",
    "title": "VOS: Learning What You Don't Know by Virtual Outlier Synthesis",
    "abstract": "Comments: ICLR 2022",
    "descriptor": "\nComments: ICLR 2022\n",
    "authors": [
      "Xuefeng Du",
      "Zhaoning Wang",
      "Mu Cai",
      "Yixuan Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.01197"
  },
  {
    "id": "arXiv:2202.01300",
    "title": "Causal Inference Through the Structural Causal Marginal Problem",
    "abstract": "Comments: 31 pages (9 pages main paper + bibliography and appendix), 6 figures",
    "descriptor": "\nComments: 31 pages (9 pages main paper + bibliography and appendix), 6 figures\n",
    "authors": [
      "Luigi Gresele",
      "Julius von K\u00fcgelgen",
      "Jonas M. K\u00fcbler",
      "Elke Kirschbaum",
      "Bernhard Sch\u00f6lkopf",
      "Dominik Janzing"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.01300"
  },
  {
    "id": "arXiv:2202.01336",
    "title": "Can Transformers be Strong Treatment Effect Estimators?",
    "abstract": "Comments: Technical Report. The first two authors contributed equally to this work",
    "descriptor": "\nComments: Technical Report. The first two authors contributed equally to this work\n",
    "authors": [
      "Yi-Fan Zhang",
      "Hanlin Zhang",
      "Zachary C. Lipton",
      "Li Erran Li",
      "Eric P. Xing"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.01336"
  },
  {
    "id": "arXiv:2202.01358",
    "title": "Safe Learning for Uncertainty-Aware Planning via Interval MDP  Abstraction",
    "abstract": "Comments: 8 pages, 3 figures; submitted to L-CSS with CDC option; typos corrected",
    "descriptor": "\nComments: 8 pages, 3 figures; submitted to L-CSS with CDC option; typos corrected\n",
    "authors": [
      "Jesse Jiang",
      "Ye Zhao",
      "Samuel Coogan"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.01358"
  },
  {
    "id": "arXiv:2202.01461",
    "title": "ExPoSe: Combining State-Based Exploration with Gradient-Based Online  Search",
    "abstract": "ExPoSe: Combining State-Based Exploration with Gradient-Based Online  Search",
    "descriptor": "",
    "authors": [
      "Dixant Mittal",
      "Siddharth Aravindan",
      "Wee Sun Lee"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.01461"
  },
  {
    "id": "arXiv:2202.01560",
    "title": "Extending turbulence model uncertainty quantification using machine  learning",
    "abstract": "Comments: NeurIPS2021 - Thirty-fifth Conference on Neural Information Processing Systems, Fourth Workshop on Machine Learning and the Physical Sciences, 5 pages, 4 figures",
    "descriptor": "\nComments: NeurIPS2021 - Thirty-fifth Conference on Neural Information Processing Systems, Fourth Workshop on Machine Learning and the Physical Sciences, 5 pages, 4 figures\n",
    "authors": [
      "Marcel Matha",
      "Christian Morsbach"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2202.01560"
  },
  {
    "id": "arXiv:2202.01602",
    "title": "The Disagreement Problem in Explainable Machine Learning: A  Practitioner's Perspective",
    "abstract": "The Disagreement Problem in Explainable Machine Learning: A  Practitioner's Perspective",
    "descriptor": "",
    "authors": [
      "Satyapriya Krishna",
      "Tessa Han",
      "Alex Gu",
      "Javin Pombra",
      "Shahin Jabbari",
      "Steven Wu",
      "Himabindu Lakkaraju"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.01602"
  },
  {
    "id": "arXiv:2202.01624",
    "title": "MFA: TDNN with Multi-scale Frequency-channel Attention for  Text-independent Speaker Verification with Short Utterances",
    "abstract": "Comments: Accepted by ICASSP 2022",
    "descriptor": "\nComments: Accepted by ICASSP 2022\n",
    "authors": [
      "Tianchi Liu",
      "Rohan Kumar Das",
      "Kong Aik Lee",
      "Haizhou Li"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.01624"
  },
  {
    "id": "arXiv:2202.01627",
    "title": "Non-Vacuous Generalisation Bounds for Shallow Neural Networks",
    "abstract": "Comments: 25 pages, 12 figures",
    "descriptor": "\nComments: 25 pages, 12 figures\n",
    "authors": [
      "Felix Biggs",
      "Benjamin Guedj"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.01627"
  },
  {
    "id": "arXiv:2202.01649",
    "title": "HECO: Automatic Code Optimizations for Efficient Fully Homomorphic  Encryption",
    "abstract": "Comments: (this version addresses some arxiv-specific layout issues with the initial upload)",
    "descriptor": "\nComments: (this version addresses some arxiv-specific layout issues with the initial upload)\n",
    "authors": [
      "Alexander Viand",
      "Patrick Jattke",
      "Miro Haller",
      "Anwar Hithnawi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.01649"
  },
  {
    "id": "arXiv:2202.01725",
    "title": "RipsNet: a general architecture for fast and robust estimation of the  persistent homology of point clouds",
    "abstract": "Comments: 23 pages, 4 figures",
    "descriptor": "\nComments: 23 pages, 4 figures\n",
    "authors": [
      "Thibault de Surrel",
      "Felix Hensel",
      "Mathieu Carri\u00e8re",
      "Th\u00e9o Lacombe",
      "Yuichi Ike",
      "Hiroaki Kurihara",
      "Marc Glisse",
      "Fr\u00e9d\u00e9ric Chazal"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.01725"
  }
]
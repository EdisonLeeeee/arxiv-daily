[
  {
    "id": "arXiv:2202.03422",
    "title": "Development of a deep learning platform for optimising sheet stamping  geometries subject to manufacturing constraints",
    "abstract": "The latest sheet stamping processes enable efficient manufacturing of complex\nshape structural components that have high stiffness to weight ratios, but\nthese processes can introduce defects. To assist component design for stamping\nprocesses, this paper presents a novel deep-learning-based platform for\noptimising 3D component geometries. The platform adopts a non-parametric\nmodelling approach that is capable of optimising arbitrary geometries from\nmultiple geometric parameterisation schema. This approach features the\ninteraction of two neural networks: 1) a geometry generator and 2) a\nmanufacturing performance evaluator. The generator predicts continuous 3D\nsigned distance fields (SDFs) for geometries of different classes, and each SDF\nis conditioned on a latent vector. The zero-level-set of each SDF implicitly\nrepresents a generated geometry. Novel training strategies for the generator\nare introduced and include a new loss function which is tailored for sheet\nstamping applications. These strategies enable the differentiable generation of\nhigh quality, large scale component geometries with tight local features for\nthe first time. The evaluator maps a 2D projection of these generated\ngeometries to their post-stamping physical (e.g., strain) distributions.\nManufacturing constraints are imposed based on these distributions and are used\nto formulate a novel objective function for optimisation. A new gradient-based\noptimisation technique is employed to iteratively update the latent vectors,\nand therefore geometries, to minimise this objective function and thus meet the\nmanufacturing constraints. Case studies based on optimising box geometries\nsubject to a sheet thinning constraint for a hot stamping process are presented\nand discussed. The results show that expressive geometric changes are\nachievable, and that these changes are driven by stamping performance.",
    "descriptor": "\nComments: 44 pages, 35 figures\n",
    "authors": [
      "Hamid Reza Attar",
      "Alistair Foster",
      "Nan Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.03422"
  },
  {
    "id": "arXiv:2202.03423",
    "title": "Backdoor Defense via Decoupling the Training Process",
    "abstract": "Recent studies have revealed that deep neural networks (DNNs) are vulnerable\nto backdoor attacks, where attackers embed hidden backdoors in the DNN model by\npoisoning a few training samples. The attacked model behaves normally on benign\nsamples, whereas its prediction will be maliciously changed when the backdoor\nis activated. We reveal that poisoned samples tend to cluster together in the\nfeature space of the attacked DNN model, which is mostly due to the end-to-end\nsupervised training paradigm. Inspired by this observation, we propose a novel\nbackdoor defense via decoupling the original end-to-end training process into\nthree stages. Specifically, we first learn the backbone of a DNN model via\n\\emph{self-supervised learning} based on training samples without their labels.\nThe learned backbone will map samples with the same ground-truth label to\nsimilar locations in the feature space. Then, we freeze the parameters of the\nlearned backbone and train the remaining fully connected layers via standard\ntraining with all (labeled) training samples. Lastly, to further alleviate\nside-effects of poisoned samples in the second stage, we remove labels of some\n`low-credible' samples determined based on the learned model and conduct a\n\\emph{semi-supervised fine-tuning} of the whole model. Extensive experiments on\nmultiple benchmark datasets and DNN models verify that the proposed defense is\neffective in reducing backdoor threats while preserving high accuracy in\npredicting benign samples. Our code is available at\n\\url{https://github.com/SCLBD/DBD}.",
    "descriptor": "\nComments: This work is accepted by the ICLR 2022. The first two authors contributed equally to this work. 25 pages\n",
    "authors": [
      "Kunzhe Huang",
      "Yiming Li",
      "Baoyuan Wu",
      "Zhan Qin",
      "Kui Ren"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.03423"
  },
  {
    "id": "arXiv:2202.03424",
    "title": "Reinforcement learning for multi-item retrieval in the puzzle-based  storage system",
    "abstract": "Nowadays, fast delivery services have created the need for high-density\nwarehouses. The puzzle-based storage system is a practical way to enhance the\nstorage density, however, facing difficulties in the retrieval process. In this\nwork, a deep reinforcement learning algorithm, specifically the Double&Dueling\nDeep Q Network, is developed to solve the multi-item retrieval problem in the\nsystem with general settings, where multiple desired items, escorts, and I/O\npoints are placed randomly. Additionally, we propose a general compact integer\nprogramming model to evaluate the solution quality. Extensive numerical\nexperiments demonstrate that the reinforcement learning approach can yield\nhigh-quality solutions and outperforms three related state-of-the-art heuristic\nalgorithms. Furthermore, a conversion algorithm and a decomposition framework\nare proposed to handle simultaneous movement and large-scale instances\nrespectively, thus improving the applicability of the PBS system.",
    "descriptor": "\nComments: 32 pages, 13 figures, 5 tables, journal\n",
    "authors": [
      "Jing He",
      "Xinglu Liu",
      "Qiyao Duan",
      "Wai Kin Victor Chan",
      "Mingyao Qi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Discrete Mathematics (cs.DM)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2202.03424"
  },
  {
    "id": "arXiv:2202.03428",
    "title": "A Reliable Data-transmission Mechanism using Blockchain in Edge  Computing Scenarios",
    "abstract": "With the advent of the Internet of things (IoT) era, more and more devices\nare connected to the IoT. Under the traditional cloud-thing centralized\nmanagement mode, the transmission of massive data is facing many difficulties,\nand the reliability of data is difficult to be guaranteed. As emerging\ntechnologies, blockchain technology and edge computing (EC) technology have\nattracted the attention of academia in improving the reliability, privacy and\ninvariability of IoT technology. In this paper, we combine the characteristics\nof the EC and blockchain to ensure the reliability of data transmission in the\nIoT. First of all, we propose a data transmission mechanism based on\nblockchain, which uses the distributed architecture of blockchain to ensure\nthat the data is not tampered with; secondly, we introduce the three-tier\nstructure in the architecture in turn; finally, we introduce the four working\nsteps of the mechanism, which are similar to the working mechanism of\nblockchain. In the end, the simulation results show that the proposed scheme\ncan ensure the reliability of data transmission in the Internet of things to a\ngreat extent.",
    "descriptor": "",
    "authors": [
      "Peiying Zhang",
      "Xue Pang",
      "Neeraj Kumar",
      "Gagangeet Singh Aujla",
      "Haotong Cao"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.03428"
  },
  {
    "id": "arXiv:2202.03429",
    "title": "VNE Strategy based on Chaotic Hybrid Flower Pollination Algorithm  Considering Multi-criteria Decision Making",
    "abstract": "With the development of science and technology and the need for\nMulti-Criteria Decision-Making (MCDM), the optimization problem to be solved\nbecomes extremely complex. The theoretically accurate and optimal solutions are\noften difficult to obtain. Therefore, meta-heuristic algorithms based on\nmulti-point search have received extensive attention. Aiming at these problems,\nthe design strategy of hybrid flower pollination algorithm for Virtual Network\nEmbedding (VNE) problem is discussed. Combining the advantages of the Genetic\nAlgorithm (GA) and FPA, the algorithm is optimized for the characteristics of\ndiscrete optimization problems. The cross operation is used to replace the\ncross-pollination operation to complete the global search and replace the\nmutation operation with self-pollination operation to enhance the ability of\nlocal search. Moreover, a life cycle mechanism is introduced as a complement to\nthe traditional fitness-based selection strategy to avoid premature\nconvergence. A chaotic optimization strategy is introduced to replace the\nrandom sequence-guided crossover process to strengthen the global search\ncapability and reduce the probability of producing invalid individuals.",
    "descriptor": "",
    "authors": [
      "Peiying Zhang",
      "Fanglin Liu",
      "Gagangeet Singh Aujla",
      "Sahil Vashist"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.03429"
  },
  {
    "id": "arXiv:2202.03457",
    "title": "Selecting Seed Words for Wordle using Character Statistics",
    "abstract": "Wordle, a word guessing game rose to global popularity in the January of\n2022. The goal of the game is to guess a five-letter English word within six\ntries. Each try provides the player with hints by means of colour changing\ntiles which inform whether or not a given character is part of the solution as\nwell as, in cases where it is part of the solution, whether or not it is in the\ncorrect placement. Numerous attempts have been made to find the best starting\nword and best strategy to solve the daily wordle. This study uses character\nstatistics of five-letter words to determine the best three starting words.",
    "descriptor": "",
    "authors": [
      "Nisansa de Silva"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.03457"
  },
  {
    "id": "arXiv:2202.03460",
    "title": "Deletion Inference, Reconstruction, and Compliance in Machine  (Un)Learning",
    "abstract": "Privacy attacks on machine learning models aim to identify the data that is\nused to train such models. Such attacks, traditionally, are studied on static\nmodels that are trained once and are accessible by the adversary. Motivated to\nmeet new legal requirements, many machine learning methods are recently\nextended to support machine unlearning, i.e., updating models as if certain\nexamples are removed from their training sets, and meet new legal requirements.\nHowever, privacy attacks could potentially become more devastating in this new\nsetting, since an attacker could now access both the original model before\ndeletion and the new model after the deletion. In fact, the very act of\ndeletion might make the deleted record more vulnerable to privacy attacks.\nInspired by cryptographic definitions and the differential privacy framework,\nwe formally study privacy implications of machine unlearning. We formalize\n(various forms of) deletion inference and deletion reconstruction attacks, in\nwhich the adversary aims to either identify which record is deleted or to\nreconstruct (perhaps part of) the deleted records. We then present successful\ndeletion inference and reconstruction attacks for a variety of machine learning\nmodels and tasks such as classification, regression, and language models.\nFinally, we show that our attacks would provably be precluded if the schemes\nsatisfy (variants of) Deletion Compliance (Garg, Goldwasser, and Vasudevan,\nEurocrypt' 20).",
    "descriptor": "\nComments: Full version of a paper appearing in the 22nd Privacy Enhancing Technologies Symposium (PETS 2022)\n",
    "authors": [
      "Ji Gao",
      "Sanjam Garg",
      "Mohammad Mahmoody",
      "Prashant Nalini Vasudevan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.03460"
  },
  {
    "id": "arXiv:2202.03463",
    "title": "On learning Whittle index policy for restless bandits with scalable  regret",
    "abstract": "Reinforcement learning is an attractive approach to learn good resource\nallocation and scheduling policies based on data when the system model is\nunknown. However, the cumulative regret of most RL algorithms scales as $\\tilde\nO(\\mathsf{S} \\sqrt{\\mathsf{A} T})$, where $\\mathsf{S}$ is the size of the state\nspace, $\\mathsf{A}$ is the size of the action space, $T$ is the horizon, and\nthe $\\tilde{O}(\\cdot)$ notation hides logarithmic terms. Due to the linear\ndependence on the size of the state space, these regret bounds are\nprohibitively large for resource allocation and scheduling problems. In this\npaper, we present a model-based RL algorithm for such problem which has\nscalable regret. In particular, we consider a restless bandit model, and\npropose a Thompson-sampling based learning algorithm which is tuned to the\nunderlying structure of the model. We present two characterizations of the\nregret of the proposed algorithm with respect to the Whittle index policy.\nFirst, we show that for a restless bandit with $n$ arms and at most $m$\nactivations at each time, the regret scales either as $\\tilde{O}(mn\\sqrt{T})$\nor $\\tilde{O}(n^2 \\sqrt{T})$ depending on the reward model. Second, under an\nadditional technical assumption, we show that the regret scales as\n$\\tilde{O}(n^{1.5} \\sqrt{T})$. We present numerical examples to illustrate the\nsalient features of the algorithm.",
    "descriptor": "",
    "authors": [
      "Nima Akbarzadeh",
      "Aditya Mahajan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.03463"
  },
  {
    "id": "arXiv:2202.03466",
    "title": "Reward-Respecting Subtasks for Model-Based Reinforcement Learning",
    "abstract": "To achieve the ambitious goals of artificial intelligence, reinforcement\nlearning must include planning with a model of the world that is abstract in\nstate and time. Deep learning has made progress in state abstraction, but,\nalthough the theory of time abstraction has been extensively developed based on\nthe options framework, in practice options have rarely been used in planning.\nOne reason for this is that the space of possible options is immense and the\nmethods previously proposed for option discovery do not take into account how\nthe option models will be used in planning. Options are typically discovered by\nposing subsidiary tasks such as reaching a bottleneck state, or maximizing a\nsensory signal other than the reward. Each subtask is solved to produce an\noption, and then a model of the option is learned and made available to the\nplanning process. The subtasks proposed in most previous work ignore the reward\non the original problem, whereas we propose subtasks that use the original\nreward plus a bonus based on a feature of the state at the time the option\nstops. We show that options and option models obtained from such\nreward-respecting subtasks are much more likely to be useful in planning and\ncan be learned online and off-policy using existing learning algorithms. Reward\nrespecting subtasks strongly constrain the space of options and thereby also\nprovide a partial solution to the problem of option discovery. Finally, we show\nhow the algorithms for learning values, policies, options, and models can be\nunified using general value functions.",
    "descriptor": "",
    "authors": [
      "Richard S. Sutton",
      "Marlos C. Machado",
      "G. Zacharias Holland",
      "David Szepesvari Finbarr Timbers",
      "Brian Tanner",
      "Adam White"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.03466"
  },
  {
    "id": "arXiv:2202.03469",
    "title": "Locally Random P-adic Alloy Codes with ChannelCoding Theorems for  Distributed Coded Tensors",
    "abstract": "Tensors, i.e., multi-linear functions, are a fundamental building block of\nmachine learning algorithms. In order to train on large data-sets, it is common\npractice to distribute the computation amongst workers. However, stragglers and\nother faults can severely impact the performance and overall training time. A\nnovel strategy to mitigate these failures is the use of coded computation. We\nintroduce a new metric for analysis called the typical recovery threshold,\nwhich focuses on the most likely event and provide a novel construction of\ndistributed coded tensor operations which are optimal with this measure. We\nshow that our general framework encompasses many other computational schemes\nand metrics as a special case. In particular, we prove that the recovery\nthreshold and the tensor rank can be recovered as a special case of the typical\nrecovery threshold when the probability of noise, i.e., a fault, is equal to\nzero, thereby providing a noisy generalization of noiseless computation as a\nserendipitous result. Far from being a purely theoretical construction, these\ndefinitions lead us to practical random code constructions, i.e., locally\nrandom p-adic alloy codes, which are optimal with respect to the measures. We\nanalyze experiments conducted on Amazon EC2 and establish that they are faster\nand more numerically stable than many other benchmark computation schemes in\npractice, as is predicted by theory.",
    "descriptor": "\nComments: 6 pages, preprint\n",
    "authors": [
      "Pedro Soto",
      "Haibin Guan",
      "Jun Li"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)",
      "Symbolic Computation (cs.SC)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.03469"
  },
  {
    "id": "arXiv:2202.03472",
    "title": "New Bounds on the Size of Binary Codes with Large Minimum Distance",
    "abstract": "Let A(n, d) denote the maximum number of codewords in a binary code of length\nn and minimum Hamming distance d. Deriving upper and lower bounds on A(n, d)\nhave been a subject for extensive research in coding theory. In this paper, we\nexamine upper and lower bounds on A(n, d) in the high-minimum distance regime,\nin particular, when $d = n/2 - \\Theta(\\sqrt{n})$. We will first provide a lower\nbound based on a cyclic construction for codes of length $n= 2^m -1$ and show\nthat $A(n, d= n/2 - 2^{c-1}\\sqrt{n}) \\geq n^c$, where c is an integer with $1\n\\leq c \\leq m/2-1$. With a Fourier-analytic view of Delsarte's linear program,\nnovel upper bounds on $A(n, n/2 - \\sqrt{n})$ and $A(n, n/2 - 2 \\sqrt{n})$ are\nobtained, and, to the best of the authors' knowledge, are the first upper\nbounds scaling polynomially in n for the regime with $d = n/2 -\n\\Theta(\\sqrt{n})$.",
    "descriptor": "\nComments: 5 pages of content, 1 page of references\n",
    "authors": [
      "James",
      "Pang",
      "Hessam Mahdavifar",
      "S. Sandeep Pradhan"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.03472"
  },
  {
    "id": "arXiv:2202.03474",
    "title": "Random Gegenbauer Features for Scalable Kernel Methods",
    "abstract": "We propose efficient random features for approximating a new and rich class\nof kernel functions that we refer to as Generalized Zonal Kernels (GZK). Our\nproposed GZK family, generalizes the zonal kernels (i.e., dot-product kernels\non the unit sphere) by introducing radial factors in their Gegenbauer series\nexpansion, and includes a wide range of ubiquitous kernel functions such as the\nentirety of dot-product kernels as well as the Gaussian and the recently\nintroduced Neural Tangent kernels. Interestingly, by exploiting the reproducing\nproperty of the Gegenbauer polynomials, we can construct efficient random\nfeatures for the GZK family based on randomly oriented Gegenbauer kernels. We\nprove subspace embedding guarantees for our Gegenbauer features which ensures\nthat our features can be used for approximately solving learning problems such\nas kernel k-means clustering, kernel ridge regression, etc. Empirical results\nshow that our proposed features outperform recent kernel approximation methods.",
    "descriptor": "",
    "authors": [
      "Insu Han",
      "Amir Zandieh",
      "Haim Avron"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.03474"
  },
  {
    "id": "arXiv:2202.03477",
    "title": "Current Studies and Applications of Shuffled Frog Leaping Algorithm: A  Review",
    "abstract": "Shuffled Frog Leaping Algorithm (SFLA) is one of the most widespread\nalgorithms. It was developed by Eusuff and Lansey in 2006. SFLA is a\npopulation-based metaheuristic algorithm that combines the benefits of memetics\nwith particle swarm optimization. It has been used in various areas, especially\nin engineering problems due to its implementation easiness and limited\nvariables. Many improvements have been made to the algorithm to alleviate its\ndrawbacks, whether they were achieved through modifications or hybridizations\nwith other well-known algorithms. This paper reviews the most relevant works on\nthis algorithm. An overview of the SFLA is first conducted, followed by the\nalgorithm's most recent modifications and hybridizations. Next, recent\napplications of the algorithm are discussed. Then, an operational framework of\nSLFA and its variants is proposed to analyze their uses on different cohorts of\napplications. Finally, future improvements to the algorithm are suggested. The\nmain incentive to conduct this survey to provide useful information about the\nSFLA to researchers interested in working on the algorithm's enhancement or\napplication",
    "descriptor": "\nComments: 28 pages\n",
    "authors": [
      "Bestan B. Maaroof",
      "Tarik A. Rashid",
      "Jaza M. Abdulla",
      "Bryar A. Hassan",
      "Abeer Alsadoon",
      "Mokhtar Mohammadi",
      "Mohammad Khishe",
      "Seyedali Mirjalili"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2202.03477"
  },
  {
    "id": "arXiv:2202.03480",
    "title": "Universal Spam Detection using Transfer Learning of BERT Model",
    "abstract": "Deep learning transformer models become important by training on text data\nbased on self-attention mechanisms. This manuscript demonstrated a novel\nuniversal spam detection model using pre-trained Google's Bidirectional Encoder\nRepresentations from Transformers (BERT) base uncased models with four datasets\nby efficiently classifying ham or spam emails in real-time scenarios. Different\nmethods for Enron, Spamassain, Lingspam, and Spamtext message classification\ndatasets, were used to train models individually in which a single model was\nobtained with acceptable performance on four datasets. The Universal Spam\nDetection Model (USDM) was trained with four datasets and leveraged\nhyperparameters from each model. The combined model was finetuned with the same\nhyperparameters from these four models separately. When each model using its\ncorresponding dataset, an F1-score is at and above 0.9 in individual models. An\noverall accuracy reached 97%, with an F1 score of 0.96. Research results and\nimplications were discussed.",
    "descriptor": "",
    "authors": [
      "Vijay Srinivas Tida",
      "Sonya Hsu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.03480"
  },
  {
    "id": "arXiv:2202.03481",
    "title": "A Ranking Game for Imitation Learning",
    "abstract": "We propose a new framework for imitation learning - treating imitation as a\ntwo-player ranking-based Stackelberg game between a $\\textit{policy}$ and a\n$\\textit{reward}$ function. In this game, the reward agent learns to satisfy\npairwise performance rankings within a set of policies, while the policy agent\nlearns to maximize this reward. This game encompasses a large subset of both\ninverse reinforcement learning (IRL) methods and methods which learn from\noffline preferences. The Stackelberg game formulation allows us to use\noptimization methods that take the game structure into account, leading to more\nsample efficient and stable learning dynamics compared to existing IRL methods.\nWe theoretically analyze the requirements of the loss function used for ranking\npolicy performances to facilitate near-optimal imitation learning at\nequilibrium. We use insights from this analysis to further increase sample\nefficiency of the ranking game by using automatically generated rankings or\nwith offline annotated rankings. Our experiments show that the proposed method\nachieves state-of-the-art sample efficiency and is able to solve previously\nunsolvable tasks in the Learning from Observation (LfO) setting.",
    "descriptor": "",
    "authors": [
      "Harshit Sikchi",
      "Akanksha Saran",
      "Wonjoon Goo",
      "Scott Niekum"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.03481"
  },
  {
    "id": "arXiv:2202.03482",
    "title": "PatClArC: Using Pattern Concept Activation Vectors for Noise-Robust  Model Debugging",
    "abstract": "State-of-the-art machine learning models are commonly (pre-)trained on large\nbenchmark datasets. These often contain biases, artifacts, or errors that have\nremained unnoticed in the data collection process and therefore fail in\nrepresenting the real world truthfully. This can cause models trained on these\ndatasets to learn undesired behavior based upon spurious correlations, e.g.,\nthe existence of a copyright tag in an image. Concept Activation Vectors (CAV)\nhave been proposed as a tool to model known concepts in latent space and have\nbeen used for concept sensitivity testing and model correction. Specifically,\nclass artifact compensation (ClArC) corrects models using CAVs to represent\ndata artifacts in feature space linearly. Modeling CAVs with filters of linear\nmodels, however, causes a significant influence of the noise portion within the\ndata, as recent work proposes the unsuitability of linear model filters to find\nthe signal direction in the input, which can be avoided by instead using\npatterns. In this paper we propose Pattern Concept Activation Vectors (PCAV)\nfor noise-robust concept representations in latent space. We demonstrate that\npattern-based artifact modeling has beneficial effects on the application of\nCAVs as a means to remove influence of confounding features from models via the\nClArC framework.",
    "descriptor": "",
    "authors": [
      "Frederik Pahde",
      "Leander Weber",
      "Christopher J. Anders",
      "Wojciech Samek",
      "Sebastian Lapuschkin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.03482"
  },
  {
    "id": "arXiv:2202.03483",
    "title": "MAML and ANIL Provably Learn Representations",
    "abstract": "Recent empirical evidence has driven conventional wisdom to believe that\ngradient-based meta-learning (GBML) methods perform well at few-shot learning\nbecause they learn an expressive data representation that is shared across\ntasks. However, the mechanics of GBML have remained largely mysterious from a\ntheoretical perspective. In this paper, we prove that two well-known GBML\nmethods, MAML and ANIL, as well as their first-order approximations, are\ncapable of learning common representation among a set of given tasks.\nSpecifically, in the well-known multi-task linear representation learning\nsetting, they are able to recover the ground-truth representation at an\nexponentially fast rate. Moreover, our analysis illuminates that the driving\nforce causing MAML and ANIL to recover the underlying representation is that\nthey adapt the final layer of their model, which harnesses the underlying task\ndiversity to improve the representation in all directions of interest. To the\nbest of our knowledge, these are the first results to show that MAML and/or\nANIL learn expressive representations and to rigorously explain why they do so.",
    "descriptor": "",
    "authors": [
      "Liam Collins",
      "Aryan Mokhtari",
      "Sewoong Oh",
      "Sanjay Shakkottai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.03483"
  },
  {
    "id": "arXiv:2202.03484",
    "title": "Self-supervised Speaker Recognition Training Using Human-Machine  Dialogues",
    "abstract": "Speaker recognition, recognizing speaker identities based on voice alone,\nenables important downstream applications, such as personalization and\nauthentication. Learning speaker representations, in the context of supervised\nlearning, heavily depends on both clean and sufficient labeled data, which is\nalways difficult to acquire. Noisy unlabeled data, on the other hand, also\nprovides valuable information that can be exploited using self-supervised\ntraining methods. In this work, we investigate how to pretrain speaker\nrecognition models by leveraging dialogues between customers and smart-speaker\ndevices. However, the supervisory information in such dialogues is inherently\nnoisy, as multiple speakers may speak to a device in the course of the same\ndialogue. To address this issue, we propose an effective rejection mechanism\nthat selectively learns from dialogues based on their acoustic homogeneity.\nBoth reconstruction-based and contrastive-learning-based self-supervised\nmethods are compared. Experiments demonstrate that the proposed method provides\nsignificant performance improvements, superior to earlier work. Dialogue\npretraining when combined with the rejection mechanism yields 27.10% equal\nerror rate (EER) reduction in speaker recognition, compared to a model without\nself-supervised pretraining.",
    "descriptor": "\nComments: 5 pages, 2 figures\n",
    "authors": [
      "Metehan Cekic",
      "Ruirui Li",
      "Zeya Chen",
      "Yuguang Yang",
      "Andreas Stolcke",
      "Upamanyu Madhow"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.03484"
  },
  {
    "id": "arXiv:2202.03486",
    "title": "Optimizing Warfarin Dosing using Deep Reinforcement Learning",
    "abstract": "Warfarin is a widely used anticoagulant, and has a narrow therapeutic range.\nDosing of warfarin should be individualized, since slight overdosing or\nunderdosing can have catastrophic or even fatal consequences. Despite much\nresearch on warfarin dosing, current dosing protocols do not live up to\nexpectations, especially for patients sensitive to warfarin. We propose a deep\nreinforcement learning-based dosing model for warfarin. To overcome the issue\nof relatively small sample sizes in dosing trials, we use a Pharmacokinetic/\nPharmacodynamic (PK/PD) model of warfarin to simulate dose-responses of virtual\npatients. Applying the proposed algorithm on virtual test patients shows that\nthis model outperforms a set of clinically accepted dosing protocols by a wide\nmargin.",
    "descriptor": "\nComments: submitted to Journal of Biomedical Informatics\n",
    "authors": [
      "Sadjad Anzabi Zadeh",
      "W. Nick Street",
      "Barrett W. Thomas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.03486"
  },
  {
    "id": "arXiv:2202.03487",
    "title": "Targeted-BEHRT: Deep learning for observational causal inference on  longitudinal electronic health records",
    "abstract": "Observational causal inference is useful for decision making in medicine when\nrandomized clinical trials (RCT) are infeasible or non generalizable. However,\ntraditional approaches fail to deliver unconfounded causal conclusions in\npractice. The rise of \"doubly robust\" non-parametric tools coupled with the\ngrowth of deep learning for capturing rich representations of multimodal data,\noffers a unique opportunity to develop and test such models for causal\ninference on comprehensive electronic health records (EHR). In this paper, we\ninvestigate causal modelling of an RCT-established null causal association: the\neffect of antihypertensive use on incident cancer risk. We develop a dataset\nfor our observational study and a Transformer-based model, Targeted BEHRT\ncoupled with doubly robust estimation, we estimate average risk ratio (RR). We\ncompare our model to benchmark statistical and deep learning models for causal\ninference in multiple experiments on semi-synthetic derivations of our dataset\nwith various types and intensities of confounding. In order to further test the\nreliability of our approach, we test our model on situations of limited data.\nWe find that our model provides more accurate estimates of RR (least sum\nabsolute error from ground truth) compared to benchmarks for risk ratio\nestimation on high-dimensional EHR across experiments. Finally, we apply our\nmodel to investigate the original case study: antihypertensives' effect on\ncancer and demonstrate that our model generally captures the validated null\nassociation.",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Shishir Rao",
      "Mohammad Mamouei",
      "Gholamreza Salimi-Khorshidi",
      "Yikuan Li",
      "Rema Ramakrishnan",
      "Abdelaali Hassaine",
      "Dexter Canoy",
      "Kazem Rahimi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.03487"
  },
  {
    "id": "arXiv:2202.03488",
    "title": "IoV Scenario: Implementation of a Bandwidth Aware Algorithm in Wireless  Network Communication Mode",
    "abstract": "The wireless network communication mode represented by the Internet of\nvehicles (IoV) has been widely used. However, due to the limitations of\ntraditional network architecture, resource scheduling in wireless network\nenvironment is still facing great challenges. This paper focuses on the\nallocation of bandwidth resources in the virtual network environment. This\npaper proposes a bandwidth aware multi domain virtual network embedding\nalgorithm (BA-VNE). The algorithm is mainly aimed at the problem that users\nneed a lot of bandwidth in wireless communication mode, and solves the problem\nof bandwidth resource allocation from the perspective of virtual network\nembedding (VNE). In order to improve the performance of the algorithm, we\nintroduce particle swarm optimization (PSO) algorithm to optimize the\nperformance of the algorithm. In order to verify the effectiveness of the\nalgorithm, we have carried out simulation experiments from link bandwidth,\nmapping cost and virtual network request (VNR) acceptance rate. The final\nresults show that the proposed algorithm is better than other representative\nalgorithms in the above indicators.",
    "descriptor": "",
    "authors": [
      "Peiying Zhang",
      "Chao Wang",
      "Gagangeet Singh Aujla",
      "Neeraj Kumar",
      "Mohsen Guizani"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.03488"
  },
  {
    "id": "arXiv:2202.03492",
    "title": "Approximation Algorithms for ROUND-UFP and ROUND-SAP",
    "abstract": "We study ROUND-UFP and ROUND-SAP, two generalizations of the classical BIN\nPACKING problem that correspond to the unsplittable flow problem on a path\n(UFP) and the storage allocation problem (SAP), respectively. We are given a\npath with capacities on its edges and a set of tasks where for each task we are\ngiven a demand and a subpath. In ROUND-UFP, the goal is to find a packing of\nall tasks into a minimum number of copies (rounds) of the given path such that\nfor each copy, the total demand of tasks on any edge does not exceed the\ncapacity of the respective edge. In ROUND-SAP, the tasks are considered to be\nrectangles and the goal is to find a non-overlapping packing of these\nrectangles into a minimum number of rounds such that all rectangles lie\ncompletely below the capacity profile of the edges.\nWe show that in contrast to BIN PACKING, both the problems do not admit an\nasymptotic polynomial-time approximation scheme (APTAS), even when all edge\ncapacities are equal. However, for this setting, we obtain asymptotic\n$(2+\\varepsilon)$-approximations for both problems. For the general case, we\nobtain an $O(\\log\\log n)$-approximation algorithm and an\n$O(\\log\\log\\frac{1}{\\delta})$-approximation under $(1+\\delta)$-resource\naugmentation for both problems. For the intermediate setting of the no\nbottleneck assumption (i.e., the maximum task demand is at most the minimum\nedge capacity), we obtain absolute $12$- and asymptotic\n$(16+\\varepsilon)$-approximation algorithms for ROUND-UFP and ROUND-SAP,\nrespectively.",
    "descriptor": "\nComments: 26 pages, 5 figures\n",
    "authors": [
      "Debajyoti Kar",
      "Arindam Khan",
      "Andreas Wiese"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computation and Language (cs.CL)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2202.03492"
  },
  {
    "id": "arXiv:2202.03493",
    "title": "DeepStability: A Study of Unstable Numerical Methods and Their Solutions  in Deep Learning",
    "abstract": "Deep learning (DL) has become an integral part of solutions to various\nimportant problems, which is why ensuring the quality of DL systems is\nessential. One of the challenges of achieving reliability and robustness of DL\nsoftware is to ensure that algorithm implementations are numerically stable. DL\nalgorithms require a large amount and a wide variety of numerical computations.\nA naive implementation of numerical computation can lead to errors that may\nresult in incorrect or inaccurate learning and results. A numerical algorithm\nor a mathematical formula can have several implementations that are\nmathematically equivalent, but have different numerical stability properties.\nDesigning numerically stable algorithm implementations is challenging, because\nit requires an interdisciplinary knowledge of software engineering, DL, and\nnumerical analysis. In this paper, we study two mature DL libraries PyTorch and\nTensorflow with the goal of identifying unstable numerical methods and their\nsolutions. Specifically, we investigate which DL algorithms are numerically\nunstable and conduct an in-depth analysis of the root cause, manifestation, and\npatches to numerical instabilities. Based on these findings, we launch, the\nfirst database of numerical stability issues and solutions in DL. Our findings\nand provide future references to developers and tool builders to prevent,\ndetect, localize and fix numerically unstable algorithm implementations. To\ndemonstrate that, using {\\it DeepStability} we have located numerical stability\nissues in Tensorflow, and submitted a fix which has been accepted and merged\nin.",
    "descriptor": "\nComments: to be published in ICSE (2022)\n",
    "authors": [
      "E. Kloberdanz",
      "K. G. Kloberdanz",
      "W. Le"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.03493"
  },
  {
    "id": "arXiv:2202.03497",
    "title": "An origami crawling robot driven by a folded self-sustained oscillator",
    "abstract": "Locomotive robots that do not rely on electronics and/or electromagnetic\ncomponents will open up new perspectives and applications for robotics.\nHowever, these robots usually involve complicated and tedious fabrication\nprocesses, limiting their applications. Here, we develop an easy-to-fabricate\ncrawling robot by embedding simple control and actuation into origami-inspired\nmechanisms through folding, eliminating the need for discrete electronics and\ntransducers. Our crawling robot locomotes through directional friction\npropelled by an onboard origami self-sustained oscillator, which generates\nperiodic actuation from a single source of constant power. The crawling robot\nis lightweight (~ 3.8 gram), ultra low-cost (~ US $1), nonmagnetic, and\nelectronic-free; it may enable practical applications in extreme environments,\ne.g., large radiation or magnetic fields. The robot can be fabricated through a\nmonolithic origami-inspired folding-based method with universal materials,\ni.e., sheet materials and conductive threads. This rapid design and fabrication\napproach enables the programmable assembly of various mechanisms within this\nmanufacturing paradigm, laying the foundation for autonomous, untethered robots\nwithout requiring electronics.",
    "descriptor": "\nComments: 6 pages, 8 figures, has been accepted by RoboSoft 2022\n",
    "authors": [
      "Wenzhong Yan",
      "Ankur Mehta"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Applied Physics (physics.app-ph)"
    ],
    "url": "https://arxiv.org/abs/2202.03497"
  },
  {
    "id": "arXiv:2202.03498",
    "title": "Random Ferns for Semantic Segmentation of PolSAR Images",
    "abstract": "Random Ferns -- as a less known example of Ensemble Learning -- have been\nsuccessfully applied in many Computer Vision applications ranging from keypoint\nmatching to object detection. This paper extends the Random Fern framework to\nthe semantic segmentation of polarimetric synthetic aperture radar images. By\nusing internal projections that are defined over the space of Hermitian\nmatrices, the proposed classifier can be directly applied to the polarimetric\ncovariance matrices without the need to explicitly compute predefined image\nfeatures. Furthermore, two distinct optimization strategies are proposed: The\nfirst based on pre-selection and grouping of internal binary features before\nthe creation of the classifier; and the second based on iteratively improving\nthe properties of a given Random Fern. Both strategies are able to boost the\nperformance by filtering features that are either redundant or have a low\ninformation content and by grouping correlated features to best fulfill the\nindependence assumptions made by the Random Fern classifier. Experiments show\nthat results can be achieved that are similar to a more complex Random Forest\nmodel and competitive to a deep learning baseline.",
    "descriptor": "\nComments: This is the author's version of the article as accepted for publication in IEEE Transactions on Geoscience and Remote Sensing, 2021. Link to original: this https URL\n",
    "authors": [
      "Pengchao Wei",
      "Ronny H\u00e4nsch"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2202.03498"
  },
  {
    "id": "arXiv:2202.03501",
    "title": "Scribble-based Boundary-aware Network for Weakly Supervised Salient  Object Detection in Remote Sensing Images",
    "abstract": "Existing CNNs-based salient object detection (SOD) heavily depends on the\nlarge-scale pixel-level annotations, which is labor-intensive, time-consuming,\nand expensive. By contrast, the sparse annotations become appealing to the\nsalient object detection community. However, few efforts are devoted to\nlearning salient object detection from sparse annotations, especially in the\nremote sensing field. In addition, the sparse annotation usually contains\nscanty information, which makes it challenging to train a well-performing\nmodel, resulting in its performance largely lagging behind the fully-supervised\nmodels. Although some SOD methods adopt some prior cues to improve the\ndetection performance, they usually lack targeted discrimination of object\nboundaries and thus provide saliency maps with poor boundary localization. To\nthis end, in this paper, we propose a novel weakly-supervised salient object\ndetection framework to predict the saliency of remote sensing images from\nsparse scribble annotations. To implement it, we first construct the\nscribble-based remote sensing saliency dataset by relabelling an existing\nlarge-scale SOD dataset with scribbles, namely S-EOR dataset. After that, we\npresent a novel scribble-based boundary-aware network (SBA-Net) for remote\nsensing salient object detection. Specifically, we design a boundary-aware\nmodule (BAM) to explore the object boundary semantics, which is explicitly\nsupervised by the high-confidence object boundary (pseudo) labels generated by\nthe boundary label generation (BLG) module, forcing the model to learn features\nthat highlight the object structure and thus boosting the boundary localization\nof objects. Then, the boundary semantics are integrated with high-level\nfeatures to guide the salient object detection under the supervision of\nscribble labels.",
    "descriptor": "\nComments: 33 pages, 10 figures\n",
    "authors": [
      "Zhou Huang",
      "Tian-Zhu Xiang",
      "Huai-Xin Chen",
      "Hang Dai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.03501"
  },
  {
    "id": "arXiv:2202.03514",
    "title": "Maximizing Audio Event Detection Model Performance on Small Datasets  Through Knowledge Transfer, Data Augmentation, And Pretraining: An Ablation  Study",
    "abstract": "An Xception model reaches state-of-the-art (SOTA) accuracy on the ESC-50\ndataset for audio event detection through knowledge transfer from ImageNet\nweights, pretraining on AudioSet, and an on-the-fly data augmentation pipeline.\nThis paper presents an ablation study that analyzes which components contribute\nto the boost in performance and training time. A smaller Xception model is also\npresented which nears SOTA performance with almost a third of the parameters.",
    "descriptor": "",
    "authors": [
      "Daniel Tompkins",
      "Kshitiz Kumar",
      "Jian Wu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2202.03514"
  },
  {
    "id": "arXiv:2202.03519",
    "title": "Online Optimization with Untrusted Predictions",
    "abstract": "We examine the problem of online optimization, where a decision maker must\nsequentially choose points in a general metric space to minimize the sum of\nper-round, non-convex hitting costs and the costs of switching decisions\nbetween rounds. The decision maker has access to a black-box oracle, such as a\nmachine learning model, that provides untrusted and potentially inaccurate\npredictions of the optimal decision in each round. The goal of the decision\nmaker is to exploit the predictions if they are accurate, while guaranteeing\nperformance that is not much worse than the hindsight optimal sequence of\ndecisions, even when predictions are inaccurate. We impose the standard\nassumption that hitting costs are globally $\\alpha$-polyhedral. We propose a\nnovel algorithm, Adaptive Online Switching (AOS), and prove that, for any\ndesired $\\delta > 0$, it is $(1+2\\delta)$-competitive if predictions are\nperfect, while also maintaining a uniformly bounded competitive ratio of\n$2^{\\tilde{\\mathcal{O}}(1/(\\alpha \\delta))}$ even when predictions are\nadversarial. Further, we prove that this trade-off is necessary and nearly\noptimal in the sense that any deterministic algorithm which is\n$(1+\\delta)$-competitive if predictions are perfect must be at least\n$2^{\\tilde{\\Omega}(1/(\\alpha \\delta))}$-competitive when predictions are\ninaccurate.",
    "descriptor": "\nComments: 35 pages, 3 figures\n",
    "authors": [
      "Daan Rutten",
      "Nico Christianson",
      "Debankur Mukherjee",
      "Adam Wierman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2202.03519"
  },
  {
    "id": "arXiv:2202.03520",
    "title": "Stakeholder utility measures for declarative processes and their use in  process comparisons",
    "abstract": "We present a method for calculating and analyzing stakeholder utilities of\nprocesses that arise in, but are not limited to, the social sciences. These\nareas include business process analysis, healthcare workflow analysis and\npolicy process analysis. This method is quite general and applicable to any\nsituation in which declarative-type constraints of a modal and/or temporal\nnature play a part.\nA declarative process is a process in which activities may freely happen\nwhile respecting a set of constraints. For such a process, anything may happen\nso long as it is not explicitly forbidden. Declarative processes have been used\nand studied as models of business and healthcare workflows by several authors.\nIn considering a declarative process as a model of some system it is natural to\nconsider how the process behaves with respect to stakeholders. We derive a\nmeasure for stakeholder utility that can be applied in a very general setting.\nThis derivation is achieved by listing a collection a properties which we argue\nsuch a stakeholder utility function ought to satisfy, and then using these to\nshow a very specific form must hold for such a utility. The utility measure\ndepends on the set of unique traces of the declarative process, and calculating\nthis set requires a combinatorial analysis of the declarative graph that\nrepresents the process.\nThis builds on previous work of the author wherein the combinatorial\ndiversity metrics for declarative processes were derived for use in policy\nprocess analysis. The collection of stakeholder utilities can themselves then\nbe used to form a metric with which we can compare different declarative\nprocesses to one another. These are illustrated using several examples of\ndeclarative processes that already exist in the literature.",
    "descriptor": "",
    "authors": [
      "Mark Dukes"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.03520"
  },
  {
    "id": "arXiv:2202.03524",
    "title": "Finite-Sum Optimization: A New Perspective for Convergence to a Global  Solution",
    "abstract": "Deep neural networks (DNNs) have shown great success in many machine learning\ntasks. Their training is challenging since the loss surface of the network\narchitecture is generally non-convex, or even non-smooth. How and under what\nassumptions is guaranteed convergence to a \\textit{global} minimum possible? We\npropose a reformulation of the minimization problem allowing for a new\nrecursive algorithmic framework. By using bounded style assumptions, we prove\nconvergence to an $\\varepsilon$-(global) minimum using\n$\\mathcal{\\tilde{O}}(1/\\varepsilon^3)$ gradient computations. Our theoretical\nfoundation motivates further study, implementation, and optimization of the new\nalgorithmic framework and further investigation of its non-standard bounded\nstyle assumptions. This new direction broadens our understanding of why and\nunder what circumstances training of a DNN converges to a global minimum.",
    "descriptor": "",
    "authors": [
      "Lam M. Nguyen",
      "Trang H. Tran",
      "Marten van Dijk"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.03524"
  },
  {
    "id": "arXiv:2202.03527",
    "title": "Integrated Multiscale Domain Adaptive YOLO",
    "abstract": "The area of domain adaptation has been instrumental in addressing the domain\nshift problem encountered by many applications. This problem arises due to the\ndifference between the distributions of source data used for training in\ncomparison with target data used during realistic testing scenarios. In this\npaper, we introduce a novel MultiScale Domain Adaptive YOLO (MS-DAYOLO)\nframework that employs multiple domain adaptation paths and corresponding\ndomain classifiers at different scales of the recently introduced YOLOv4 object\ndetector. Building on our baseline multiscale DAYOLO framework, we introduce\nthree novel deep learning architectures for a Domain Adaptation Network (DAN)\nthat generates domain-invariant features. In particular, we propose a\nProgressive Feature Reduction (PFR), a Unified Classifier (UC), and an\nIntegrated architecture. We train and test our proposed DAN architectures in\nconjunction with YOLOv4 using popular datasets. Our experiments show\nsignificant improvements in object detection performance when training YOLOv4\nusing the proposed MS-DAYOLO architectures and when tested on target data for\nautonomous driving applications. Moreover, MS-DAYOLO framework achieves an\norder of magnitude real-time speed improvement relative to Faster R-CNN\nsolutions while providing comparable object detection performance.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2106.01483\n",
    "authors": [
      "Mazin Hnewa",
      "Hayder Radha"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.03527"
  },
  {
    "id": "arXiv:2202.03528",
    "title": "TACTiS: Transformer-Attentional Copulas for Time Series",
    "abstract": "The estimation of time-varying quantities is a fundamental component of\ndecision making in fields such as healthcare and finance. However, the\npractical utility of such estimates is limited by how accurately they quantify\npredictive uncertainty. In this work, we address the problem of estimating the\njoint predictive distribution of high-dimensional multivariate time series. We\npropose a versatile method, based on the transformer architecture, that\nestimates joint distributions using an attention-based decoder that provably\nlearns to mimic the properties of non-parametric copulas. The resulting model\nhas several desirable properties: it can scale to hundreds of time series,\nsupports both forecasting and interpolation, can handle unaligned and\nnon-uniformly sampled data, and can seamlessly adapt to missing data during\ntraining. We demonstrate these properties empirically and show that our model\nproduces state-of-the-art predictions on several real-world datasets.",
    "descriptor": "\nComments: 27 pages, 15 figures\n",
    "authors": [
      "Alexandre Drouin",
      "\u00c9tienne Marcotte",
      "Nicolas Chapados"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.03528"
  },
  {
    "id": "arXiv:2202.03532",
    "title": "MINER: Multiscale Implicit Neural Representations",
    "abstract": "We introduce a new neural signal representation designed for the efficient\nhigh-resolution representation of large-scale signals. The key innovation in\nour multiscale implicit neural representation (MINER) is an internal\nrepresentation via a Laplacian pyramid, which provides a sparse multiscale\nrepresentation of the signal that captures orthogonal parts of the signal\nacross scales. We leverage the advantages of the Laplacian pyramid by\nrepresenting small disjoint patches of the pyramid at each scale with a tiny\nMLP. This enables the capacity of the network to adaptively increase from\ncoarse to fine scales, and only represent parts of the signal with strong\nsignal energy. The parameters of each MLP are optimized from coarse-to-fine\nscale which results in faster approximations at coarser scales, thereby\nultimately an extremely fast training process. We apply MINER to a range of\nlarge-scale signal representation tasks, including gigapixel images and very\nlarge point clouds, and demonstrate that it requires fewer than 25% of the\nparameters, 33% of the memory footprint, and 10% of the computation time of\ncompeting techniques such as ACORN to reach the same representation error.",
    "descriptor": "",
    "authors": [
      "Vishwanath Saragadam",
      "Jasper Tan",
      "Guha Balakrishnan",
      "Richard G. Baraniuk",
      "Ashok Veeraraghavan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.03532"
  },
  {
    "id": "arXiv:2202.03535",
    "title": "Noise Regularizes Over-parameterized Rank One Matrix Recovery, Provably",
    "abstract": "We investigate the role of noise in optimization algorithms for learning\nover-parameterized models. Specifically, we consider the recovery of a rank one\nmatrix $Y^*\\in R^{d\\times d}$ from a noisy observation $Y$ using an\nover-parameterization model. We parameterize the rank one matrix $Y^*$ by\n$XX^\\top$, where $X\\in R^{d\\times d}$. We then show that under mild conditions,\nthe estimator, obtained by the randomly perturbed gradient descent algorithm\nusing the square loss function, attains a mean square error of $O(\\sigma^2/d)$,\nwhere $\\sigma^2$ is the variance of the observational noise. In contrast, the\nestimator obtained by gradient descent without random perturbation only attains\na mean square error of $O(\\sigma^2)$. Our result partially justifies the\nimplicit regularization effect of noise when learning over-parameterized\nmodels, and provides new understanding of training over-parameterized neural\nnetworks.",
    "descriptor": "",
    "authors": [
      "Tianyi Liu",
      "Yan Li",
      "Enlu Zhou",
      "Tuo Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.03535"
  },
  {
    "id": "arXiv:2202.03539",
    "title": "Structured Time Series Prediction without Structural Prior",
    "abstract": "Time series prediction is a widespread and well studied problem with\napplications in many domains (medical, geoscience, network analysis, finance,\neconometry etc.). In the case of multivariate time series, the key to good\nperformances is to properly capture the dependencies between the variates.\nOften, these variates are structured, i.e. they are localised in an abstract\nspace, usually representing an aspect of the physical world, and prediction\namounts to a form of diffusion of the information across that space over time.\nSeveral neural network models of diffusion have been proposed in the\nliterature. However, most of the existing proposals rely on some a priori\nknowledge on the structure of the space, usually in the form of a graph\nweighing the pairwise diffusion capacity of its points. We argue that this\npiece of information can often be dispensed with, since data already contains\nthe diffusion capacity information, and in a more reliable form than that\nobtained from the usually largely hand-crafted graphs. We propose instead a\nfully data-driven model which does not rely on such a graph, nor any other\nprior structural information. We conduct a first set of experiments to measure\nthe impact on performance of a structural prior, as used in baseline models,\nand show that, except at very low data levels, it remains negligible, and\nbeyond a threshold, it may even become detrimental. We then investigate,\nthrough a second set of experiments, the capacity of our model in two respects:\ntreatment of missing data and domain adaptation.",
    "descriptor": "\nComments: 13 pages, 6 figures\n",
    "authors": [
      "Darko Drakulic",
      "Jean-Marc Andreoli"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.03539"
  },
  {
    "id": "arXiv:2202.03540",
    "title": "SliTraNet: Automatic Detection of Slide Transitions in Lecture Videos  using Convolutional Neural Networks",
    "abstract": "With the increasing number of online learning material in the web, search for\nspecific content in lecture videos can be time consuming. Therefore, automatic\nslide extraction from the lecture videos can be helpful to give a brief\noverview of the main content and to support the students in their studies. For\nthis task, we propose a deep learning method to detect slide transitions in\nlectures videos. We first process each frame of the video by a heuristic-based\napproach using a 2-D convolutional neural network to predict transition\ncandidates. Then, we increase the complexity by employing two 3-D convolutional\nneural networks to refine the transition candidates. Evaluation results\ndemonstrate the effectiveness of our method in finding slide transitions.",
    "descriptor": "\nComments: 6 pages, 5 figures, 1 table, accepted to OAGM Workshop 2021\n",
    "authors": [
      "Aline Sindel",
      "Abner Hernandez",
      "Seung Hee Yang",
      "Vincent Christlein",
      "Andreas Maier"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.03540"
  },
  {
    "id": "arXiv:2202.03541",
    "title": "On Continuous Integration / Continuous Delivery for Automated Deployment  of Machine Learning Models using MLOps",
    "abstract": "Model deployment in machine learning has emerged as an intriguing field of\nresearch in recent years. It is comparable to the procedure defined for\nconventional software development. Continuous Integration and Continuous\nDelivery (CI/CD) have been shown to smooth down software advancement and speed\nup businesses when used in conjunction with development and operations\n(DevOps). Using CI/CD pipelines in an application that includes Machine\nLearning Operations (MLOps) components, on the other hand, has difficult\ndifficulties, and pioneers in the area solve them by using unique tools, which\nis typically provided by cloud providers. This research provides a more\nin-depth look at the machine learning lifecycle and the key distinctions\nbetween DevOps and MLOps. In the MLOps approach, we discuss tools and\napproaches for executing the CI/CD pipeline of machine learning frameworks.\nFollowing that, we take a deep look into push and pull-based deployments in\nGithub Operations (GitOps). Open exploration issues are also identified and\nadded, which may guide future study.",
    "descriptor": "\nComments: Paper Accepted in AIKE 2021 : IEEE Artificial Intelligence & Knowledge Engineering 2021. The final version of this paper will appear in the conference proceedings\n",
    "authors": [
      "Satvik Garg",
      "Pradyumn Pundir",
      "Geetanjali Rathee",
      "P.K. Gupta",
      "Somya Garg",
      "Saransh Ahlawat"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.03541"
  },
  {
    "id": "arXiv:2202.03544",
    "title": "LwPosr: Lightweight Efficient Fine-Grained Head Pose Estimation",
    "abstract": "This paper presents a lightweight network for head pose estimation (HPE)\ntask. While previous approaches rely on convolutional neural networks, the\nproposed network \\textit{LwPosr} uses mixture of depthwise separable\nconvolutional (DSC) and transformer encoder layers which are structured in two\nstreams and three stages to provide fine-grained regression for predicting head\nposes. The quantitative and qualitative demonstration is provided to show that\nthe proposed network is able to learn head poses efficiently while using less\nparameter space. Extensive ablations are conducted using three open-source\ndatasets namely 300W-LP, AFLW2000, and BIWI datasets. To our knowledge, (1)\n\\textit{LwPosr} is the lightest network proposed for estimating head poses\ncompared to both keypoints-based and keypoints-free approaches; (2) it sets a\nbenchmark for both overperforming the previous lightweight network on mean\nabsolute error and on reducing number of parameters; (3) it is first of its\nkind to use mixture of DSCs and transformer encoders for HPE. This approach is\nsuitable for mobile devices which require lightweight networks.",
    "descriptor": "\nComments: 11 pages, 3 figures\n",
    "authors": [
      "Naina Dhingra"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.03544"
  },
  {
    "id": "arXiv:2202.03548",
    "title": "HeadPosr: End-to-end Trainable Head Pose Estimation using Transformer  Encoders",
    "abstract": "In this paper, HeadPosr is proposed to predict the head poses using a single\nRGB image. \\textit{HeadPosr} uses a novel architecture which includes a\ntransformer encoder. In concrete, it consists of: (1) backbone; (2) connector;\n(3) transformer encoder; (4) prediction head. The significance of using a\ntransformer encoder for HPE is studied. An extensive ablation study is\nperformed on varying the (1) number of encoders; (2) number of heads; (3)\ndifferent position embeddings; (4) different activations; (5) input channel\nsize, in a transformer used in HeadPosr. Further studies on using: (1)\ndifferent backbones, (2) using different learning rates are also shown. The\nelaborated experiments and ablations studies are conducted using three\ndifferent open-source widely used datasets for HPE, i.e., 300W-LP, AFLW2000,\nand BIWI datasets. Experiments illustrate that \\textit{HeadPosr} outperforms\nall the state-of-art methods including both the landmark-free and the others\nbased on using landmark or depth estimation on the AFLW2000 dataset and BIWI\ndatasets when trained with 300W-LP. It also outperforms when averaging the\nresults from the compared datasets, hence setting a benchmark for the problem\nof HPE, also demonstrating the effectiveness of using transformers over the\nstate-of-the-art.",
    "descriptor": "\nComments: 8 pages, 4 figures\n",
    "authors": [
      "Naina Dhingra"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.03548"
  },
  {
    "id": "arXiv:2202.03555",
    "title": "data2vec: A General Framework for Self-supervised Learning in Speech,  Vision and Language",
    "abstract": "While the general idea of self-supervised learning is identical across\nmodalities, the actual algorithms and objectives differ widely because they\nwere developed with a single modality in mind. To get us closer to general\nself-supervised learning, we present data2vec, a framework that uses the same\nlearning method for either speech, NLP or computer vision. The core idea is to\npredict latent representations of the full input data based on a masked view of\nthe input in a self-distillation setup using a standard Transformer\narchitecture. Instead of predicting modality-specific targets such as words,\nvisual tokens or units of human speech which are local in nature, data2vec\npredicts contextualized latent representations that contain information from\nthe entire input. Experiments on the major benchmarks of speech recognition,\nimage classification, and natural language understanding demonstrate a new\nstate of the art or competitive performance to predominant approaches.",
    "descriptor": "",
    "authors": [
      "Alexei Baevski",
      "Wei-Ning Hsu",
      "Qiantong Xu",
      "Arun Babu",
      "Jiatao Gu",
      "Michael Auli"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.03555"
  },
  {
    "id": "arXiv:2202.03558",
    "title": "Evaluating Robustness of Cooperative MARL: A Model-based Approach",
    "abstract": "In recent years, a proliferation of methods were developed for cooperative\nmulti-agent reinforcement learning (c-MARL). However, the robustness of c-MARL\nagents against adversarial attacks has been rarely explored. In this paper, we\npropose to evaluate the robustness of c-MARL agents via a model-based approach.\nOur proposed formulation can craft stronger adversarial state perturbations of\nc-MARL agents(s) to lower total team rewards more than existing model-free\napproaches. In addition, we propose the first victim-agent selection strategy\nwhich allows us to develop even stronger adversarial attack. Numerical\nexperiments on multi-agent MuJoCo benchmarks illustrate the advantage of our\napproach over other baselines. The proposed model-based attack consistently\noutperforms other baselines in all tested environments.",
    "descriptor": "",
    "authors": [
      "Nhan H. Pham",
      "Lam M. Nguyen",
      "Jie Chen",
      "Hoang Thanh Lam",
      "Subhro Das",
      "Tsui-Wei Weng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.03558"
  },
  {
    "id": "arXiv:2202.03565",
    "title": "Automated Instantiation of Control Flow Tracing Exercises",
    "abstract": "One of the first steps in learning how to program is reading and tracing\nexisting code. In order to avoid the error-prone task of generating variations\nof a tracing exercise, our tool Tatsu generates instances of a given code\nskeleton automatically. This is achieved by a finite unwinding of the program\nin the style of bounded model checking and using the SMT solver Z3 to find\nmodels for this unwinded program.",
    "descriptor": "\nComments: In Proceedings ThEdu'21, arXiv:2202.02144\n",
    "authors": [
      "Clemens Eisenhofer",
      "Martin Riener"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2202.03565"
  },
  {
    "id": "arXiv:2202.03566",
    "title": "Four Geometry Problems to Introduce Automated Deduction in Secondary  Schools",
    "abstract": "The introduction of automated deduction systems in secondary schools face\nseveral bottlenecks, the absence of the subject of rigorous mathematical\ndemonstrations in the curricula, the lack of knowledge by the teachers about\nthe subject and the difficulty of tackling the task by automatic means.\nDespite those difficulties we claim that the subject of automated deduction\nin geometry can be introduced, by addressing it in particular cases: simple to\nmanipulate by students and teachers and reasonably easy to be dealt by\nautomatic deduction tools.\nThe subject is discussed by addressing four secondary schools geometry\nproblems: their rigorous proofs, visual proofs, numeric proofs, algebraic\nformal proofs, synthetic formal proofs, or the lack of them. For these problems\nwe discuss a lesson plan to address them with the help of Information and\nCommunications Technology, more specifically, automated deduction tools.",
    "descriptor": "\nComments: In Proceedings ThEdu'21, arXiv:2202.02144\n",
    "authors": [
      "Pedro Quaresma",
      "Vanda Santos"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2202.03566"
  },
  {
    "id": "arXiv:2202.03567",
    "title": "Teaching Intuitionistic and Classical Propositional Logic Using Isabelle",
    "abstract": "We describe a natural deduction formalization of intuitionistic and classical\npropositional logic in the Isabelle/Pure framework. In contrast to earlier\nwork, where we explored the pedagogical benefits of using a deep embedding\napproach to logical modelling, here we employ a logical framework modelling.\nThis gives rise to simple and natural teaching examples and we report on the\nrole it played in teaching our Automated Reasoning course in 2020 and 2021.",
    "descriptor": "\nComments: In Proceedings ThEdu'21, arXiv:2202.02144\n",
    "authors": [
      "J\u00f8rgen Villadsen",
      "Asta Halkj\u00e6r From",
      "Patrick Blackburn"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2202.03567"
  },
  {
    "id": "arXiv:2202.03568",
    "title": "Evolution of SASyLF 2008-2021",
    "abstract": "SASyLF was released in 2008 and used as a proof assistant in courses at\nseveral universities. It proved itself useful and has continued to be used, and\neach iteration of use has encouraged further development: fixing bugs and\nadding enhancements. This paper describes how SASyLF was developed while\nkeeping true to its purpose. Most notable are making substitutions explicit,\nsupport of \"and\" and \"or,\" support for mutual and lexicographic induction, and\nIDE support.",
    "descriptor": "\nComments: In Proceedings ThEdu'21, arXiv:2202.02144\n",
    "authors": [
      "John Tang Boyland"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2202.03568"
  },
  {
    "id": "arXiv:2202.03573",
    "title": "A Viral Marketing-Based Model For Opinion Dynamics in Online Social  Networks",
    "abstract": "Online social networks provide a medium for citizens to form opinions on\ndifferent societal issues, and a forum for public discussion. They also expose\nusers to viral content, such as breaking news articles. In this paper, we study\nthe interplay between these two aspects: opinion formation and information\ncascades in online social networks. We present a new model that allows us to\nquantify how users change their opinion as they are exposed to viral content.\nOur model is a combination of the popular Friedkin--Johnsen model for opinion\ndynamics and the independent cascade model for information propagation. We\npresent algorithms for simulating our model, and we provide approximation\nalgorithms for optimizing certain network indices, such as the sum of user\nopinions or the disagreement--controversy index; our approach can be used to\nobtain insights into how much viral content can increase these indices in\nonline social networks. Finally, we evaluate our model on real-world datasets.\nWe show experimentally that marketing campaigns and polarizing contents have\nvastly different effects on the network: while the former have only limited\neffect on the polarization in the network, the latter can increase the\npolarization up to 59% even when only 0.5% of the users start sharing a\npolarizing content. We believe that this finding sheds some light into the\ngrowing segregation in today's online media.",
    "descriptor": "\nComments: To appear at WebConf'22\n",
    "authors": [
      "Sijing Tu",
      "Stefan Neumann"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2202.03573"
  },
  {
    "id": "arXiv:2202.03574",
    "title": "Structured Prediction Problem Archive",
    "abstract": "Structured prediction problems are one of the fundamental tools in machine\nlearning. In order to facilitate algorithm development for their numerical\nsolution, we collect in one place a large number of datasets in easy to read\nformats for a diverse set of problem classes. We provide archival links to\ndatasets, description of the considered problems and problem formats, and a\nshort summary of problem characteristics including size, number of instances\netc. For reference we also give a non-exhaustive selection of algorithms\nproposed in the literature for their solution. We hope that this central\nrepository will make benchmarking and comparison to established works easier.\nWe welcome submission of interesting new datasets and algorithms for inclusion\nin our archive.",
    "descriptor": "",
    "authors": [
      "Paul Swoboda",
      "Andrea Hornakova",
      "Paul Roetzer",
      "Ahmed Abbas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.03574"
  },
  {
    "id": "arXiv:2202.03575",
    "title": "Deep Reinforcement Learning Assisted Federated Learning Algorithm for  Data Management of IIoT",
    "abstract": "The continuous expanded scale of the industrial Internet of Things (IIoT)\nleads to IIoT equipments generating massive amounts of user data every moment.\nAccording to the different requirement of end users, these data usually have\nhigh heterogeneity and privacy, while most of users are reluctant to expose\nthem to the public view. How to manage these time series data in an efficient\nand safe way in the field of IIoT is still an open issue, such that it has\nattracted extensive attention from academia and industry. As a new machine\nlearning (ML) paradigm, federated learning (FL) has great advantages in\ntraining heterogeneous and private data. This paper studies the FL technology\napplications to manage IIoT equipment data in wireless network environments. In\norder to increase the model aggregation rate and reduce communication costs, we\napply deep reinforcement learning (DRL) to IIoT equipment selection process,\nspecifically to select those IIoT equipment nodes with accurate models.\nTherefore, we propose a FL algorithm assisted by DRL, which can take into\naccount the privacy and efficiency of data training of IIoT equipment. By\nanalyzing the data characteristics of IIoT equipments, we use MNIST, fashion\nMNIST and CIFAR-10 data sets to represent the data generated by IIoT. During\nthe experiment, we employ the deep neural network (DNN) model to train the\ndata, and experimental results show that the accuracy can reach more than 97\\%,\nwhich corroborates the effectiveness of the proposed algorithm.",
    "descriptor": "",
    "authors": [
      "Peiying Zhang",
      "Chao Wang",
      "Chunxiao Jiang",
      "Zhu Han"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.03575"
  },
  {
    "id": "arXiv:2202.03576",
    "title": "Learnability Lock: Authorized Learnability Control Through Adversarial  Invertible Transformations",
    "abstract": "Owing much to the revolution of information technology, the recent progress\nof deep learning benefits incredibly from the vastly enhanced access to data\navailable in various digital formats. However, in certain scenarios, people may\nnot want their data being used for training commercial models and thus studied\nhow to attack the learnability of deep learning models. Previous works on\nlearnability attack only consider the goal of preventing unauthorized\nexploitation on the specific dataset but not the process of restoring the\nlearnability for authorized cases. To tackle this issue, this paper introduces\nand investigates a new concept called \"learnability lock\" for controlling the\nmodel's learnability on a specific dataset with a special key. In particular,\nwe propose adversarial invertible transformation, that can be viewed as a\nmapping from image to image, to slightly modify data samples so that they\nbecome \"unlearnable\" by machine learning models with negligible loss of visual\nfeatures. Meanwhile, one can unlock the learnability of the dataset and train\nmodels normally using the corresponding key. The proposed learnability lock\nleverages class-wise perturbation that applies a universal transformation\nfunction on data samples of the same label. This ensures that the learnability\ncan be easily restored with a simple inverse transformation while remaining\ndifficult to be detected or reverse-engineered. We empirically demonstrate the\nsuccess and practicability of our method on visual classification tasks.",
    "descriptor": "\nComments: Accepted at ICLR 2022\n",
    "authors": [
      "Weiqi Peng",
      "Jinghui Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.03576"
  },
  {
    "id": "arXiv:2202.03577",
    "title": "Integration of a machine learning model into a decision support tool to  predict absenteeism at work of prospective employees",
    "abstract": "Purpose - Inefficient hiring may result in lower productivity and higher\ntraining costs. Productivity losses caused by absenteeism at work cost U.S.\nemployers billions of dollars each year. Also, employers typically spend a\nconsiderable amount of time managing employees who perform poorly. The purpose\nof this study is to develop a decision support tool to predict absenteeism\namong potential employees. Design/methodology/approach - We utilized a popular\nopen-access dataset. In order to categorize absenteeism classes, the data have\nbeen preprocessed, and four methods of machine learning classification have\nbeen applied: Multinomial Logistic Regression (MLR), Support Vector Machines\n(SVM), Artificial Neural Networks (ANN), and Random Forests (RF). We selected\nthe best model, based on several validation scores, and compared its\nperformance against the existing model; we then integrated the best model into\nour proposed web-based for hiring managers. Findings - A web-based decision\ntool allows hiring managers to make more informed decisions before hiring a\npotential employee, thus reducing time, financial loss and reducing the\nprobability of economic insolvency. Originality/value - In this paper, we\npropose a model that is trained based on attributes that can be collected\nduring the hiring process. Furthermore, hiring managers may lack experience in\nmachine learning or do not have the time to spend developing machine learning\nalgorithms. Thus, we propose a web-based interactive tool that can be used\nwithout prior knowledge of machine learning algorithms.",
    "descriptor": "",
    "authors": [
      "Gopal Nath",
      "Antoine Harfouche",
      "Austin Coursey",
      "Krishna K. Saha",
      "Srikanth Prabhu",
      "Saptarshi Sengupta"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.03577"
  },
  {
    "id": "arXiv:2202.03578",
    "title": "Data driven design of optical resonators",
    "abstract": "Optical devices lie at the heart of most of the technology we see around us.\nWhen one actually wants to make such an optical device, one can predict its\noptical behavior using computational simulations of Maxwell's equations. If one\nthen asks what the optimal design would be in order to obtain a certain optical\nbehavior, the only way to go further would be to try out all of the possible\ndesigns and compute the electromagnetic spectrum they produce. When there are\nmany design parameters, this brute force approach quickly becomes too\ncomputationally expensive. We therefore need other methods to create optimal\noptical devices. An alternative to the brute force approach is inverse design.\nIn this paradigm, one starts from the desired optical response of a material\nand then determines the design parameters that are needed to obtain this\noptical response. There are many algorithms known in the literature that\nimplement this inverse design. Some of the best performing, recent approaches\nare based on Deep Learning. The central idea is to train a neural network to\npredict the optical response for given design parameters. Since neural networks\nare completely differentiable, we can compute gradients of the response with\nrespect to the design parameters. We can use these gradients to update the\ndesign parameters and get an optical response closer to the one we want. This\nallows us to obtain an optimal design much faster compared to the brute force\napproach. In my thesis, I use Deep Learning for the inverse design of the\nFabry-P\\'erot resonator. This system can be described fully analytically and is\ntherefore ideal to study.",
    "descriptor": "\nComments: 85 pages, 68 figures, Master thesis in Physics and Astronomy\n",
    "authors": [
      "Joeri Lenaerts",
      "Hannah Pinson",
      "Vincent Ginis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.03578"
  },
  {
    "id": "arXiv:2202.03579",
    "title": "Stop Oversampling for Class Imbalance Learning: A Critical Review",
    "abstract": "For the last two decades, oversampling has been employed to overcome the\nchallenge of learning from imbalanced datasets. Many approaches to solving this\nchallenge have been offered in the literature. Oversampling, on the other hand,\nis a concern. That is, models trained on fictitious data may fail spectacularly\nwhen put to real-world problems. The fundamental difficulty with oversampling\napproaches is that, given a real-life population, the synthesized samples may\nnot truly belong to the minority class. As a result, training a classifier on\nthese samples while pretending they represent minority may result in incorrect\npredictions when the model is used in the real world. We analyzed a large\nnumber of oversampling methods in this paper and devised a new oversampling\nevaluation system based on hiding a number of majority examples and comparing\nthem to those generated by the oversampling process. Based on our evaluation\nsystem, we ranked all these methods based on their incorrectly generated\nexamples for comparison. Our experiments using more than 70 oversampling\nmethods and three imbalanced real-world datasets reveal that all oversampling\nmethods studied generate minority samples that are most likely to be majority.\nGiven data and methods in hand, we argue that oversampling in its current forms\nand methodologies is unreliable for learning from class imbalanced data and\nshould be avoided in real-world applications.",
    "descriptor": "\nComments: 19 pages, 5 figures, 4 tables, and more than 72 m=oversampling methods reviewed\n",
    "authors": [
      "Ahmad B. Hassanat",
      "Ahmad S. Tarawneh",
      "Ghada A. Altarawneh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.03579"
  },
  {
    "id": "arXiv:2202.03580",
    "title": "Convolutional Neural Networks on Graphs with Chebyshev Approximation,  Revisited",
    "abstract": "Designing spectral convolutional networks is a challenging problem in graph\nlearning. ChebNet, one of the early attempts, approximates the spectral\nconvolution using Chebyshev polynomials. GCN simplifies ChebNet by utilizing\nonly the first two Chebyshev polynomials while still outperforming it on\nreal-world datasets. GPR-GNN and BernNet demonstrate that the Monomial and\nBernstein bases also outperform the Chebyshev basis in terms of learning the\nspectral convolution. Such conclusions are counter-intuitive in the field of\napproximation theory, where it is established that the Chebyshev polynomial\nachieves the optimum convergent rate for approximating a function.\nIn this paper, we revisit the problem of approximating the spectral\nconvolution with Chebyshev polynomials. We show that ChebNet's inferior\nperformance is primarily due to illegal coefficients learnt by ChebNet\napproximating analytic filter functions, which leads to over-fitting. We then\npropose ChebNetII, a new GNN model based on Chebyshev interpolation, which\nenhances the original Chebyshev polynomial approximation while reducing the\nRunge phenomena. We conducted an extensive experimental study to demonstrate\nthat ChebNetII can learn arbitrary graph spectrum filters and achieve superior\nperformance in both full- and semi-supervised node classification tasks.",
    "descriptor": "\nComments: 13 pages\n",
    "authors": [
      "Mingguo He",
      "Zhewei Wei",
      "Ji-Rong Wen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.03580"
  },
  {
    "id": "arXiv:2202.03582",
    "title": "Simulators for Mobile Social Robots:State-of-the-Art and Challenges",
    "abstract": "The future robots are expected to work in a shared physical space with humans\n[1], however, the presence of humans leads to a dynamic environment that is\nchallenging for mobile robots to navigate. The path planning algorithms\ndesigned to navigate a collision free path in complex human environments are\noften tested in real environments due to the lack of simulation frameworks.\nThis paper identifies key requirements for an ideal simulator for this task,\nevaluates existing simulation frameworks and most importantly, it identifies\nthe challenges and limitations of the existing simulation techniques. First and\nforemost, we recognize that the simulators needed for the purpose of testing\nmobile robots designed for human environments are unique as they must model\nrealistic pedestrian behavior in addition to the modelling of mobile robots.\nOur study finds that Pedsim_ros [2] and a more recent SocNavBench framework [3]\nare the only two 3D simulation frameworks that meet most of the key\nrequirements defined in our paper. In summary, we identify the need for\ndeveloping more simulators that offer an ability to create realistic 3D\npedestrian rich virtual environments along with the flexibility of designing\ncomplex robots and their sensor models from scratch.",
    "descriptor": "\nComments: 10 pages\n",
    "authors": [
      "Prabhjot Kaur",
      "Zichuan Liu",
      "Weisong Shi"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.03582"
  },
  {
    "id": "arXiv:2202.03586",
    "title": "Fair SA: Sensitivity Analysis for Fairness in Face Recognition",
    "abstract": "As the use of deep learning in high impact domains becomes ubiquitous, it is\nincreasingly important to assess the resilience of models. One such high impact\ndomain is that of face recognition, with real world applications involving\nimages affected by various degradations, such as motion blur or high exposure.\nMoreover, images captured across different attributes, such as gender and race,\ncan also challenge the robustness of a face recognition algorithm. While\ntraditional summary statistics suggest that the aggregate performance of face\nrecognition models has continued to improve, these metrics do not directly\nmeasure the robustness or fairness of the models. Visual Psychophysics\nSensitivity Analysis (VPSA) [1] provides a way to pinpoint the individual\ncauses of failure by way of introducing incremental perturbations in the data.\nHowever, perturbations may affect subgroups differently. In this paper, we\npropose a new fairness evaluation based on robustness in the form of a generic\nframework that extends VPSA. With this framework, we can analyze the ability of\na model to perform fairly for different subgroups of a population affected by\nperturbations, and pinpoint the exact failure modes for a subgroup by measuring\ntargeted robustness. With the increasing focus on the fairness of models, we\nuse face recognition as an example application of our framework and propose to\ncompactly visualize the fairness analysis of a model via AUC matrices. We\nanalyze the performance of common face recognition models and empirically show\nthat certain subgroups are at a disadvantage when images are perturbed, thereby\nuncovering trends that were not visible using the model's performance on\nsubgroups without perturbations.",
    "descriptor": "\nComments: 8 pages, 5 figures, to be published in NeurIPS 2021 Workshop, Algorithmic Fairness through the Lens of Causality and Robustness\n",
    "authors": [
      "Aparna R. Joshi",
      "Xavier Suau",
      "Nivedha Sivakumar",
      "Luca Zappella",
      "Nicholas Apostoloff"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.03586"
  },
  {
    "id": "arXiv:2202.03588",
    "title": "Representative Scenarios to Capture Renewable Generation Stochasticity  and Cross-Correlations",
    "abstract": "Generating representative scenarios for power system planning in which the\nstochasticity of renewable generation and cross-correlations between renewables\nand load are fully captured, is a challenging problem. Traditional methods for\nscenario generation often fail to generate diverse scenarios that include both\nseasonal (frequently occurring) and atypical (extreme) days required for\nplanning purposes. This paper presents a methodical approach to generate\nrepresentative scenarios. It also proposes new metrics that are more relevant\nfor evaluating the generated scenarios from an applications perspective. When\napplied to historical data from a power utility, the proposed approach resulted\nin scenarios that included a good mix of seasonal and atypical days. The\nresults also demonstrated pertinence of the proposed cluster validation\nmetrics. Finally, the paper presents a trade-off for determining optimal number\nof scenarios for a given application.",
    "descriptor": "\nComments: 5 pages, 8 Figures, IEEE PES GM 2022\n",
    "authors": [
      "Dhaval Dalal",
      "Anamitra Pal",
      "Philip Augustin"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.03588"
  },
  {
    "id": "arXiv:2202.03590",
    "title": "Moral Emotions Shape the Virality of COVID-19 Misinformation on Social  Media",
    "abstract": "While false rumors pose a threat to the successful overcoming of the COVID-19\npandemic, an understanding of how rumors diffuse in online social networks is -\neven for non-crisis situations - still in its infancy. Here we analyze a large\nsample consisting of COVID-19 rumor cascades from Twitter that have been\nfact-checked by third-party organizations. The data comprises N=10,610 rumor\ncascades that have been retweeted more than 24 million times. We investigate\nwhether COVID-19 misinformation spreads more viral than the truth and whether\nthe differences in the diffusion of true vs. false rumors can be explained by\nthe moral emotions they carry. We observe that, on average, COVID-19\nmisinformation is more likely to go viral than truthful information. However,\nthe veracity effect is moderated by moral emotions: false rumors are more viral\nthan the truth if the source tweets embed a high number of other-condemning\nemotion words, whereas a higher number of self-conscious emotion words is\nlinked to a less viral spread. The effects are pronounced both for health\nmisinformation and false political rumors. These findings offer insights into\nhow true vs. false rumors spread and highlight the importance of considering\nemotions from the moral emotion families in social media content.",
    "descriptor": "",
    "authors": [
      "Kirill Solovev",
      "Nicolas Pr\u00f6llochs"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2202.03590"
  },
  {
    "id": "arXiv:2202.03593",
    "title": "Nonmyopic Multiclass Active Search for Diverse Discovery",
    "abstract": "Active search is a setting in adaptive experimental design where we aim to\nuncover members of rare, valuable class(es) subject to a budget constraint. An\nimportant consideration in this problem is diversity among the discovered\ntargets -- in many applications, diverse discoveries offer more insight and may\nbe preferable in downstream tasks. However, most existing active search\npolicies either assume that all targets belong to a common positive class or\nencourage diversity via simple heuristics. We present a novel formulation of\nactive search with multiple target classes, characterized by a utility function\nthat naturally induces a preference for label diversity among discoveries via a\ndiminishing returns mechanism. We then study this problem under the Bayesian\nlens and prove a hardness result for approximating the optimal policy. Finally,\nwe propose an efficient, nonmyopic approximation to the optimal policy and\ndemonstrate its superior empirical performance across a wide variety of\nexperimental settings, including drug discovery.",
    "descriptor": "",
    "authors": [
      "Quan Nguyen",
      "Roman Garnett"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.03593"
  },
  {
    "id": "arXiv:2202.03596",
    "title": "MOST-Net: A Memory Oriented Style Transfer Network for Face Sketch  Synthesis",
    "abstract": "Face sketch synthesis has been widely used in multi-media entertainment and\nlaw enforcement. Despite the recent developments in deep neural networks,\naccurate and realistic face sketch synthesis is still a challenging task due to\nthe diversity and complexity of human faces. Current image-to-image\ntranslation-based face sketch synthesis frequently encounters over-fitting\nproblems when it comes to small-scale datasets. To tackle this problem, we\npresent an end-to-end Memory Oriented Style Transfer Network (MOST-Net) for\nface sketch synthesis which can produce high-fidelity sketches with limited\ndata. Specifically, an external self-supervised dynamic memory module is\nintroduced to capture the domain alignment knowledge in the long term. In this\nway, our proposed model could obtain the domain-transfer ability by\nestablishing the durable relationship between faces and corresponding sketches\non the feature level. Furthermore, we design a novel Memory Refinement Loss (MR\nLoss) for feature alignment in the memory module, which enhances the accuracy\nof memory slots in an unsupervised manner. Extensive experiments on the CUFS\nand the CUFSF datasets show that our MOST-Net achieves state-of-the-art\nperformance, especially in terms of the Structural Similarity Index(SSIM).",
    "descriptor": "\nComments: 7 pages, 4 figures\n",
    "authors": [
      "Fan Ji",
      "Muyi Sun",
      "Xingqun Qi",
      "Qi Li",
      "Zhenan Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.03596"
  },
  {
    "id": "arXiv:2202.03597",
    "title": "Local Explanations for Reinforcement Learning",
    "abstract": "Many works in explainable AI have focused on explaining black-box\nclassification models. Explaining deep reinforcement learning (RL) policies in\na manner that could be understood by domain users has received much less\nattention. In this paper, we propose a novel perspective to understanding RL\npolicies based on identifying important states from automatically learned\nmeta-states. The key conceptual difference between our approach and many\nprevious ones is that we form meta-states based on locality governed by the\nexpert policy dynamics rather than based on similarity of actions, and that we\ndo not assume any particular knowledge of the underlying topology of the state\nspace. Theoretically, we show that our algorithm to find meta-states converges\nand the objective that selects important states from each meta-state is\nsubmodular leading to efficient high quality greedy selection. Experiments on\nfour domains (four rooms, door-key, minipacman, and pong) and a carefully\nconducted user study illustrate that our perspective leads to better\nunderstanding of the policy. We conjecture that this is a result of our\nmeta-states being more intuitive in that the corresponding important states are\nstrong indicators of tractable intermediate goals that are easier for humans to\ninterpret and follow.",
    "descriptor": "",
    "authors": [
      "Ronny Luss",
      "Amit Dhurandhar",
      "Miao Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.03597"
  },
  {
    "id": "arXiv:2202.03599",
    "title": "Penalizing Gradient Norm for Efficiently Improving Generalization in  Deep Learning",
    "abstract": "How to train deep neural networks (DNNs) to generalize well is a central\nconcern in deep learning, especially for severely overparameterized networks\nnowadays. In this paper, we propose an effective method to improve the model\ngeneralization by additionally penalizing the gradient norm of loss function\nduring optimization. We demonstrate that confining the gradient norm of loss\nfunction could help lead the optimizers towards finding flat minima. We\nleverage the first-order approximation to efficiently implement the\ncorresponding gradient to fit well in the gradient descent framework. In our\nexperiments, we confirm that when using our methods, generalization performance\nof various models could be improved on different datasets. Also, we show that\nthe recent sharpness-aware minimization method \\cite{DBLP:conf/iclr/ForetKMN21}\nis a special, but not the best, case of our method, where the best case of our\nmethod could give new state-of-art performance on these tasks.",
    "descriptor": "",
    "authors": [
      "Yang Zhao",
      "Hao Zhang",
      "Xiuyuan Hu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.03599"
  },
  {
    "id": "arXiv:2202.03601",
    "title": "Two-Step Spike Encoding Scheme and Architecture for Highly Sparse  Spiking-Neural-Network",
    "abstract": "This paper proposes a two-step spike encoding scheme, which consists of the\nsource encoding and the process encoding for a high energy-efficient\nspiking-neural-network (SNN) acceleration. The eigen-train generation and its\nsuperposition generate spike trains which show high accuracy with low spike\nratio. Sparsity boosting (SB) and spike generation skipping (SGS) reduce the\namount of operations for SNN. Time shrinking multi-level encoding (TS-MLE)\ncompresses the number of spikes in a train along time axis, and spike-level\nclock skipping (SLCS) decreases the processing time. Eigen-train generation\nachieves 90.3% accuracy, the same accuracy of CNN, under the condition of 4.18%\nspike ratio for CIFAR-10 classification. SB reduces spike ratio by 0.49x with\nonly 0.1% accuracy loss, and the SGS reduces the spike ratio by 20.9% with 0.5%\naccuracy loss. TS-MLE and SLCS increases the throughput of SNN by 2.8x while\ndecreasing the hardware resource for spike generator by 75% compared with\nprevious generators.",
    "descriptor": "\nComments: 5 pages, 10 figures\n",
    "authors": [
      "Sangyeob Kim",
      "Sangjin Kim",
      "Soyeon Um",
      "Soyeon Kim",
      "Hoi-Jun Yoo"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2202.03601"
  },
  {
    "id": "arXiv:2202.03609",
    "title": "Backdoor Detection in Reinforcement Learning",
    "abstract": "While the real world application of reinforcement learning (RL) is becoming\npopular, the safety concern and the robustness of an RL system require more\nattention. A recent work reveals that, in a multi-agent RL environment,\nbackdoor trigger actions can be injected into a victim agent (a.k.a. trojan\nagent), which can result in a catastrophic failure as soon as it sees the\nbackdoor trigger action. We propose the problem of RL Backdoor Detection,\naiming to address this safety vulnerability. An interesting observation we drew\nfrom extensive empirical studies is a trigger smoothness property where normal\nactions similar to the backdoor trigger actions can also trigger low\nperformance of the trojan agent. Inspired by this observation, we propose a\nreinforcement learning solution TrojanSeeker to find approximate trigger\nactions for the trojan agents, and further propose an efficient approach to\nmitigate the trojan agents based on machine unlearning. Experiments show that\nour approach can correctly distinguish and mitigate all the trojan agents\nacross various types of agents and environments.",
    "descriptor": "",
    "authors": [
      "Junfeng Guo",
      "Ang Li",
      "Cong Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.03609"
  },
  {
    "id": "arXiv:2202.03610",
    "title": "Codebook Design for Composite Beamforming in Next-generation mmWave  Systems",
    "abstract": "In pursuance of the unused spectrum in higher frequencies, millimeter wave\n(mmWave) bands have a pivotal role. However, the high path-loss and poor\nscattering associated with mmWave communications highlight the necessity of\nemploying effective beamforming techniques. In order to efficiently search for\nthe beam to serve a user and to jointly serve multiple users it is often\nrequired to use a composite beam which consists of multiple disjoint lobes. A\ncomposite beam covers multiple desired angular coverage intervals (ACIs) and\nideally has maximum and uniform gain (smoothness) within each desired ACI,\nnegligible gain (leakage) outside the desired ACIs, and sharp edges. We propose\nan algorithm for designing such ideal composite codebook by providing an\nanalytical closed-form solution with low computational complexity. There is a\nfundamental trade-off between the gain, leakage and smoothness of the beams.\nOur design allows to achieve different values in such trade-off based on\nchanging the design parameters. We highlight the shortcomings of the uniform\nlinear arrays (ULAs) in building arbitrary composite beams. Consequently, we\nuse a recently introduced twin-ULA (TULA) antenna structure to effectively\nresolve these inefficiencies. Numerical results are used to validate the\ntheoretical findings.",
    "descriptor": "\nComments: Accepted at IEEE WCNC 2022\n",
    "authors": [
      "Nariman Torkzaban",
      "Mohamamd A.",
      "Khojastepour",
      "John S. Baras"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.03610"
  },
  {
    "id": "arXiv:2202.03611",
    "title": "Do Language Models Learn Position-Role Mappings?",
    "abstract": "How is knowledge of position-role mappings in natural language learned? We\nexplore this question in a computational setting, testing whether a variety of\nwell-performing pertained language models (BERT, RoBERTa, and DistilBERT)\nexhibit knowledge of these mappings, and whether this knowledge persists across\nalternations in syntactic, structural, and lexical alternations. In Experiment\n1, we show that these neural models do indeed recognize distinctions between\ntheme and recipient roles in ditransitive constructions, and that these\ndistinct patterns are shared across construction type. We strengthen this\nfinding in Experiment 2 by showing that fine-tuning these language models on\nnovel theme- and recipient-like tokens in one paradigm allows the models to\nmake correct predictions about their placement in other paradigms, suggesting\nthat the knowledge of these mappings is shared rather than independently\nlearned. We do, however, observe some limitations of this generalization when\ntasks involve constructions with novel ditransitive verbs, hinting at a degree\nof lexical specificity which underlies model performance.",
    "descriptor": "\nComments: To appear in the BUCLD 46 Proceedings\n",
    "authors": [
      "Jackson Petty",
      "Michael Wilson",
      "Robert Frank"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.03611"
  },
  {
    "id": "arXiv:2202.03612",
    "title": "HistBERT: A Pre-trained Language Model for Diachronic Lexical Semantic  Analysis",
    "abstract": "Contextualized word embeddings have demonstrated state-of-the-art performance\nin various natural language processing tasks including those that concern\nhistorical semantic change. However, language models such as BERT was trained\nprimarily on contemporary corpus data. To investigate whether training on\nhistorical corpus data improves diachronic semantic analysis, we present a\npre-trained BERT-based language model, HistBERT, trained on the balanced Corpus\nof Historical American English. We examine the effectiveness of our approach by\ncomparing the performance of the original BERT and that of HistBERT, and we\nreport promising results in word similarity and semantic shift analysis. Our\nwork suggests that the effectiveness of contextual embeddings in diachronic\nsemantic analysis is dependent on the temporal profile of the input text and\ncare should be taken in applying this methodology to study historical semantic\nchange.",
    "descriptor": "",
    "authors": [
      "Wenjun Qiu",
      "Yang Xu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.03612"
  },
  {
    "id": "arXiv:2202.03613",
    "title": "Conformal prediction for the design problem",
    "abstract": "In many real-world deployments of machine learning, we use a prediction\nalgorithm to choose what data to test next. For example, in the protein design\nproblem, we have a regression model that predicts some real-valued property of\na protein sequence, which we use to propose new sequences believed to exhibit\nhigher property values than observed in the training data. Since validating\ndesigned sequences in the wet lab is typically costly, it is important to know\nhow much we can trust the model's predictions. In such settings, however, there\nis a distinct type of distribution shift between the training and test data:\none where the training and test data are statistically dependent, as the latter\nis chosen based on the former. Consequently, the model's error on the test data\n-- that is, the designed sequences -- has some non-trivial relationship with\nits error on the training data. Herein, we introduce a method to quantify\npredictive uncertainty in such settings. We do so by constructing confidence\nsets for predictions that account for the dependence between the training and\ntest data. The confidence sets we construct have finite-sample guarantees that\nhold for any prediction algorithm, even when a trained model chooses the\ntest-time input distribution. As a motivating use case, we demonstrate how our\nmethod quantifies uncertainty for the predicted fitness of designed protein\nusing several real data sets.",
    "descriptor": "\nComments: 32 pages, 8 figures\n",
    "authors": [
      "Clara Fannjiang",
      "Stephen Bates",
      "Anastasios Angelopoulos",
      "Jennifer Listgarten",
      "Michael I. Jordan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2202.03613"
  },
  {
    "id": "arXiv:2202.03614",
    "title": "An Exact Method for the Daily Package Shipment Problem with Outsourcing",
    "abstract": "The package shipment problem requires to optimally co-design paths for both\npackages and a heterogeneous fleet in a transit center network (TCN). Instances\narising from the package delivery industry in China usually involve more than\nten thousand origin-destination (OD) pairs and have to be solved daily within\nan hour. Motivated by the fact that there is no interaction among different\norigin centers due to their competitive relationship, we propose a novel\ntwo-layer localized package shipment on a TCN (LPS-TCN) model that exploits\noutsourcing for cost saving. Consequently, the original problem breaks into a\nset of much smaller shipment problems, each of which has hundreds of OD pairs\nand is subsequently modelled as a mixed integer program (MIP). Since the\nLPS-TCN model is proved to be Strongly NP-hard and contains tens of thousands\nof feasible paths, an off-the-shelf MIP solver cannot produce a reliable\nsolution in a practically acceptable amount of time. We develop a column\ngeneration based algorithm that iteratively adds \"profitable\" paths and further\nenhance it by problem-specific cutting planes and variable bound tightening\ntechniques. Computational experiments on realistic instances from a major\nChinese package express company demonstrate that the LPS-TCN model can yield\nsolutions that bring daily economic cost reduction up to 1 million CNY for the\nwhole TCN. In addition, our proposed algorithm solves the LPS-TCN model\nsubstantially faster than CPLEX, one of the state-of-the-art commercial MIP\nsolvers.",
    "descriptor": "",
    "authors": [
      "Zhuolin Wang",
      "Rongping Zhu",
      "Jian-Ya Ding",
      "Yu Yang",
      "Keyou You"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.03614"
  },
  {
    "id": "arXiv:2202.03616",
    "title": "Towards Property-Based Tests in Natural Language",
    "abstract": "We consider a new approach to generate tests from natural language. Rather\nthan relying on machine learning or templated extraction from structured\ncomments, we propose to apply classic ideas from linguistics to translate\nnatural-language sentences into executable tests. This paper explores the\napplication of combinatory categorial grammars (CCGs) to generating\nproperty-based tests. Our prototype is able to generate tests from English\ndescriptions for each example in a textbook chapter on property-based testing.",
    "descriptor": "",
    "authors": [
      "Colin S. Gordon"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.03616"
  },
  {
    "id": "arXiv:2202.03617",
    "title": "The role of Blockchain in DDoS attacks mitigation: techniques, open  challenges and future directions",
    "abstract": "With the proliferation of new technologies such as Internet of Things (IOT)\nand Software-Defined Networking(SDN) in the recent years, the distributed\ndenial of service (DDoS)attack vector has broadened and opened new\nopportunities for more sophisticated DDoS attacks on the targeted victims. The\nnew attack vector includes unsecured and vulnerable IoT devices connected to\nthe internet, denial of service vulnerabilities like southbound channel\nsaturation in the SDN architecture. Given the high-volume and pervasive nature\nof these attacks, it is beneficial for stakeholders to collaborate in detecting\nand mitigating the denial of service attacks in a timely manner. The blockchain\ntechnology is considered to improve the security aspects owing to the\ndecentralized design, secured distributed storage and privacy. A thorough\nexploration and classification of blockchain techniques used for DDoS attack\nmitigation is not explored in the prior art. This paper reviews and categorizes\nthe existed state-of-the-art DDoS mitigation solutions based on blockchain\ntechnology. The DDoS mitigation techniques are classified based on the solution\ndeployment location i.e. network based, near attacker location, near victim\nlocation and hybrid solutions in the network architecture with emphasis on the\nIoT and SDN architectures. Additionally, based on our study, the research\nchallenges and future directions to implement the blockchain based DDoS\nmitigation solutions are discussed. We believe that this paper could serve as a\nstarting point and reference resource for future researchers working on denial\nof service attacks detection and mitigation using blockchain technology.",
    "descriptor": "",
    "authors": [
      "Rajasekhar Chaganti",
      "Bharat Bhushan",
      "Vinayakumar Ravi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.03617"
  },
  {
    "id": "arXiv:2202.03621",
    "title": "Bandit Sampling for Multiplex Networks",
    "abstract": "Graph neural networks have gained prominence due to their excellent\nperformance in many classification and prediction tasks. In particular, they\nare used for node classification and link prediction which have a wide range of\napplications in social networks, biomedical data sets, and financial\ntransaction graphs. Most of the existing work focuses primarily on the monoplex\nsetting where we have access to a network with only a single type of connection\nbetween entities. However, in the multiplex setting, where there are multiple\ntypes of connections, or \\emph{layers}, between entities, performance on tasks\nsuch as link prediction has been shown to be stronger when information from\nother connection types is taken into account. We propose an algorithm for\nscalable learning on multiplex networks with a large number of layers. The\nefficiency of our method is enabled by an online learning algorithm that learns\nhow to sample relevant neighboring layers so that only the layers with relevant\ninformation are aggregated during training. This sampling differs from prior\nwork, such as MNE, which aggregates information across \\emph{all} layers and\nconsequently leads to computational intractability on large networks. Our\napproach also improves on the recent layer sampling method of \\textsc{DeePlex}\nin that the unsampled layers do not need to be trained, enabling further\nincreases in efficiency.We present experimental results on both synthetic and\nreal-world scenarios that demonstrate the practical effectiveness of our\nproposed approach.",
    "descriptor": "",
    "authors": [
      "Cenk Baykal",
      "Vamsi K. Potluru",
      "Sameena Shah",
      "Manuela M. Veloso"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.03621"
  },
  {
    "id": "arXiv:2202.03624",
    "title": "Understanding the Trustworthiness Management in the Social Internet of  Things: A Survey",
    "abstract": "The next generation of the Internet of Things (IoT) facilitates the\nintegration of the notion of social networking into smart objects (i.e.,\nthings) in a bid to establish the social network of interconnected objects.\nThis integration has led to the evolution of a promising and emerging paradigm\nof Social Internet of Things (SIoT), wherein the smart objects act as social\nobjects and intelligently impersonate the social behaviour similar to that of\nhumans. These social objects are capable of establishing social relationships\nwith the other objects in the network and can utilize these relationships for\nservice discovery. Trust plays a significant role to achieve the common goal of\ntrustworthy collaboration and cooperation among the objects and provide\nsystems' credibility and reliability. In SIoT, an untrustworthy object can\ndisrupt the basic functionality of a service by delivering malicious messages\nand adversely affect the quality and reliability of the service. In this\nsurvey, we present a holistic view of trustworthiness management for SIoT. The\nessence of trust in various disciplines has been discussed along with the Trust\nin SIoT followed by a detailed study on trust management components in SIoT.\nFurthermore, we analyzed and compared the trust management schemes by primarily\ncategorizing them into four groups in terms of their strengths, limitations,\ntrust management components employed in each of the referred trust management\nschemes, and the performance of these studies vis-a-vis numerous trust\nevaluation dimensions. Finally, we have discussed the future research\ndirections of the emerging paradigm of SIoT particularly for trustworthiness\nmanagement in SIoT.",
    "descriptor": "",
    "authors": [
      "Subhash Sagar",
      "Adnan Mahmood",
      "Quan Z. Sheng",
      "Jitander Kumar Pabani",
      "Wei Emma Zhang"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.03624"
  },
  {
    "id": "arXiv:2202.03628",
    "title": "Graph-Relational Domain Adaptation",
    "abstract": "Existing domain adaptation methods tend to treat every domain equally and\nalign them all perfectly. Such uniform alignment ignores topological structures\namong different domains; therefore it may be beneficial for nearby domains, but\nnot necessarily for distant domains. In this work, we relax such uniform\nalignment by using a domain graph to encode domain adjacency, e.g., a graph of\nstates in the US with each state as a domain and each edge indicating\nadjacency, thereby allowing domains to align flexibly based on the graph\nstructure. We generalize the existing adversarial learning framework with a\nnovel graph discriminator using encoding-conditioned graph embeddings.\nTheoretical analysis shows that at equilibrium, our method recovers classic\ndomain adaptation when the graph is a clique, and achieves non-trivial\nalignment for other types of graphs. Empirical results show that our approach\nsuccessfully generalizes uniform alignment, naturally incorporates domain\ninformation represented by graphs, and improves upon existing domain adaptation\nmethods on both synthetic and real-world datasets. Code will soon be available\nat https://github.com/Wang-ML-Lab/GRDA.",
    "descriptor": "\nComments: Accepted by ICLR 2022\n",
    "authors": [
      "Zihao Xu",
      "Hao he",
      "Guang-He Lee",
      "Yuyang Wang",
      "Hao Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.03628"
  },
  {
    "id": "arXiv:2202.03629",
    "title": "Survey of Hallucination in Natural Language Generation",
    "abstract": "Natural Language Generation (NLG) has improved exponentially in recent years\nthanks to the development of deep learning technologies such as\nTransformer-based language models. This advancement has led to more fluent and\ncoherent natural language generation, naturally leading to development in\ndownstream tasks such as abstractive summarization, dialogue generation and\ndata-to-text generation. However, it is also investigated that such generation\nincludes hallucinated texts, which makes the performances of text generation\nfail to meet users' expectations in many real-world scenarios. In order to\naddress this issue, studies in evaluation and mitigation methods of\nhallucinations have been presented in various tasks, but have not been reviewed\nin a combined manner. In this survey, we provide a broad overview of the\nresearch progress and challenges in the hallucination problem of NLG. The\nsurvey is organized into two big divisions: (i) a general overview of metrics,\nmitigation methods, and future directions; (ii) task-specific research progress\nfor hallucinations in a large set of downstream tasks: abstractive\nsummarization, dialogue generation, generative question answering, data-to-text\ngeneration, and machine translation. This survey could facilitate collaborative\nefforts among researchers in these tasks.",
    "descriptor": "",
    "authors": [
      "Ziwei Ji",
      "Nayeon Lee",
      "Rita Frieske",
      "Tiezheng Yu",
      "Dan Su",
      "Yan Xu",
      "Etsuko Ishii",
      "Yejin Bang",
      "Andrea Madotto",
      "Pascale Fung"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.03629"
  },
  {
    "id": "arXiv:2202.03630",
    "title": "Domain Adversarial Spatial-Temporal Network: A Transferable Framework  for Short-term Traffic Forecasting across Cities",
    "abstract": "Accurate real-time traffic forecast is critical for intelligent\ntransportation systems (ITS) and it serves as the cornerstone of various smart\nmobility applications. Though this research area is dominated by deep learning,\nrecent studies indicate that the accuracy improvement by developing new model\nstructures is becoming marginal. Instead, we envision that the improvement can\nbe achieved by transferring the \"forecasting-related knowledge\" across cities\nwith different data distributions and network topologies. To this end, this\npaper aims to propose a novel transferable traffic forecasting framework:\nDomain Adversarial Spatial-Temporal Network (DASTNet). DASTNet is pre-trained\non multiple source networks and fine-tuned with the target network's traffic\ndata. Specifically, we leverage the graph representation learning and\nadversarial domain adaptation techniques to learn the domain-invariant node\nembeddings, which are further incorporated to model the temporal traffic data.\nTo the best of our knowledge, we are the first to employ adversarial\nmulti-domain adaptation for network-wide traffic forecasting problems. DASTNet\nconsistently outperforms all state-of-the-art baseline methods on three\nbenchmark datasets. The trained DASTNet is applied to Hong Kong's new traffic\ndetectors, and accurate traffic predictions can be delivered immediately\n(within one day) when the detector is available. Overall, this study suggests\nan alternative to enhance the traffic forecasting methods and provides\npractical implications for cities lacking historical traffic data.",
    "descriptor": "",
    "authors": [
      "Yihong Tang",
      "Ao Qu",
      "Andy H.F. Chow",
      "William H.K. Lam",
      "S.C. Wong",
      "Wei Ma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.03630"
  },
  {
    "id": "arXiv:2202.03631",
    "title": "Robotic Grasping from Classical to Modern: A Survey",
    "abstract": "Robotic Grasping has always been an active topic in robotics since grasping\nis one of the fundamental but most challenging skills of robots. It demands the\ncoordination of robotic perception, planning, and control for robustness and\nintelligence. However, current solutions are still far behind humans,\nespecially when confronting unstructured scenarios. In this paper, we survey\nthe advances of robotic grasping, starting from the classical formulations and\nsolutions to the modern ones. By reviewing the history of robotic grasping, we\nwant to provide a complete view of this community, and perhaps inspire the\ncombination and fusion of different ideas, which we think would be helpful to\ntouch and explore the essence of robotic grasping problems. In detail, we\nfirstly give an overview of the analytic methods for robotic grasping. After\nthat, we provide a discussion on the recent state-of-the-art data-driven\ngrasping approaches rising in recent years. With the development of computer\nvision, semantic grasping is being widely investigated and can be the basis of\nintelligent manipulation and skill learning for autonomous robotic systems in\nthe future. Therefore, in our survey, we also briefly review the recent\nprogress in this topic. Finally, we discuss the open problems and the future\nresearch directions that may be important for the human-level robustness,\nautonomy, and intelligence of robots.",
    "descriptor": "",
    "authors": [
      "Hanbo Zhang",
      "Jian Tang",
      "Shiguang Sun",
      "Xuguang Lan"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.03631"
  },
  {
    "id": "arXiv:2202.03632",
    "title": "ECRECer: Enzyme Commission Number Recommendation and Benchmarking based  on Multiagent Dual-core Learning",
    "abstract": "Enzyme Commission (EC) numbers, which associate a protein sequence with the\nbiochemical reactions it catalyzes, are essential for the accurate\nunderstanding of enzyme functions and cellular metabolism. Many ab-initio\ncomputational approaches were proposed to predict EC numbers for given input\nsequences directly. However, the prediction performance (accuracy, recall,\nprecision), usability, and efficiency of existing methods still have much room\nto be improved. Here, we report ECRECer, a cloud platform for accurately\npredicting EC numbers based on novel deep learning techniques. To build\nECRECer, we evaluate different protein representation methods and adopt a\nprotein language model for protein sequence embedding. After embedding, we\npropose a multi-agent hierarchy deep learning-based framework to learn the\nproposed tasks in a multi-task manner. Specifically, we used an extreme\nmulti-label classifier to perform the EC prediction and employed a greedy\nstrategy to integrate and fine-tune the final model. Comparative analyses\nagainst four representative methods demonstrate that ECRECer delivers the\nhighest performance, which improves accuracy and F1 score by 70% and 20% over\nthe state-of-the-the-art, respectively. With ECRECer, we can annotate numerous\nenzymes in the Swiss-Prot database with incomplete EC numbers to their full\nfourth level. Take UniPort protein \"A0A0U5GJ41\" as an example (1.14.-.-),\nECRECer annotated it with \"1.14.11.38\", which supported by further protein\nstructure analysis based on AlphaFold2. Finally, we established a webserver\n(https://ecrecer.biodesign.ac.cn) and provided an offline bundle to improve\nusability.",
    "descriptor": "\nComments: 16 pages, 14 figures\n",
    "authors": [
      "Zhenkun Shi",
      "Qianqian Yuan",
      "Ruoyu Wang",
      "Hoaran Li",
      "Xiaoping Liao",
      "Hongwu Ma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2202.03632"
  },
  {
    "id": "arXiv:2202.03633",
    "title": "An Exploration of a New Group of Channel Symmetries",
    "abstract": "We study a certain symmetry group associated to any given communication\nchannel, which can informally be viewed as the set of transformations of the\nset of inputs that \"commute\" with the action of the channel. In a general\nsetting, we show that the distribution over the inputs that maximizes the\nmutual information between the input and output of a given channel is a \"fixed\npoint\" of the action of the channel's group. We consider as examples the groups\nassociated with the binary symmetric channel and the binary deletion channel.\nWe show that the group of the binary symmetric channel is extremely large (it\ncontains a number of elements that grows faster than any exponential function\nof $n$), and we give empirical evidence that the group of the binary deletion\nchannel is extremely small (it contains a number of elements constant in $n$).\nThis serves as some formal justification for why the analysis of the binary\ndeletion channel has proved much more difficult than its memoryless\ncounterparts.",
    "descriptor": "\nComments: Ancillary data files included\n",
    "authors": [
      "Francisco Pernice"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.03633"
  },
  {
    "id": "arXiv:2202.03634",
    "title": "Multi-Agent Path Finding with Prioritized Communication Learning",
    "abstract": "Multi-agent path finding (MAPF) has been widely used to solve large-scale\nreal-world problems, e.g. automation warehouse. The learning-based fully\ndecentralized framework has been introduced to simultaneously alleviate\nreal-time problem and pursuit the optimal planning policy. However, existing\nmethods might generate significantly more vertex conflicts (called collision),\nwhich lead to low success rate or more makespan. In this paper, we propose a\nPrIoritized COmmunication learning method (PICO), which incorporates the\nimplicit planning priorities into the communication topology within the\ndecentralized multi-agent reinforcement learning framework. Assembling with the\nclassic coupled planners, the implicit priority learning module can be utilized\nto form the dynamic communication topology, which also build an effective\ncollision-avoiding mechanism. PICO performs significantly better in large-scale\nmulti-agent path finding tasks in both success rates and collision rates than\nstate-of-the-art learning-based planners.",
    "descriptor": "\nComments: 7 pages, 5 figures, 4 tables, published at ICRA 2022\n",
    "authors": [
      "Wenhao Li",
      "Hongjun Chen",
      "Bo Jin",
      "Wenzhe Tan",
      "Hongyuan Zha",
      "Xiangfeng Wang"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2202.03634"
  },
  {
    "id": "arXiv:2202.03636",
    "title": "Invertible Tabular GANs: Killing Two Birds with OneStone for Tabular  Data Synthesis",
    "abstract": "Tabular data synthesis has received wide attention in the literature. This is\nbecause available data is often limited, incomplete, or cannot be obtained\neasily, and data privacy is becoming increasingly important. In this work, we\npresent a generalized GAN framework for tabular synthesis, which combines the\nadversarial training of GANs and the negative log-density regularization of\ninvertible neural networks. The proposed framework can be used for two\ndistinctive objectives. First, we can further improve the synthesis quality, by\ndecreasing the negative log-density of real records in the process of\nadversarial training. On the other hand, by increasing the negative log-density\nof real records, realistic fake records can be synthesized in a way that they\nare not too much close to real records and reduce the chance of potential\ninformation leakage. We conduct experiments with real-world datasets for\nclassification, regression, and privacy attacks. In general, the proposed\nmethod demonstrates the best synthesis quality (in terms of task-oriented\nevaluation metrics, e.g., F1) when decreasing the negative log-density during\nthe adversarial training. If increasing the negative log-density, our\nexperimental results show that the distance between real and fake records\nincreases, enhancing robustness against privacy attacks.",
    "descriptor": "\nComments: 19 pages\n",
    "authors": [
      "Jaehoon Lee",
      "Jihyeon Hyeong",
      "Jinsung Jeon",
      "Noseong Park",
      "Jihoon Cho"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.03636"
  },
  {
    "id": "arXiv:2202.03637",
    "title": "Boolean Observation Games",
    "abstract": "We introduce Boolean Observation Games, a subclass of multi-player finite\nstrategic games with incomplete information and qualitative objectives. In\nBoolean observation games, each player is associated with a finite set of\npropositional variables of which only it can observe the value, and it controls\nwhether and to whom it can reveal that value. It does not control the given,\nfixed, value of variables. Boolean observation games are a generalization of\nBoolean games, a well-studied subclass of strategic games but with complete\ninformation, and wherein each player controls the value of its variables.\nIn Boolean observation games player goals describe multi-agent knowledge of\nvariables. As in classical strategic games, players choose their strategies\nsimultaneously and therefore observation games capture aspects of both\nimperfect and incomplete information. They require reasoning about sets of\noutcomes given sets of indistinguishable valuations of variables. What a Nash\nequilibrium is, depends on an outcome relation between such sets. We present\nvarious outcome relations, including a qualitative variant of ex-post\nequilibrium. We identify conditions under which, given an outcome relation,\nNash equilibria are guaranteed to exist. We also study the complexity of\nchecking for the existence of Nash equilibria and of verifying if a strategy\nprofile is a Nash equilibrium. We further study the subclass of Boolean\nobservation games with `knowing whether' goal formulas, for which the\nsatisfaction does not depend on the value of variables. We show that each such\nBoolean observation game corresponds to a Boolean game and vice versa, by a\ndifferent correspondence, and that both correspondences are precise in terms of\nexistence of Nash equilibria.",
    "descriptor": "",
    "authors": [
      "Hans van Ditmarsch",
      "Sunil Simon"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.03637"
  },
  {
    "id": "arXiv:2202.03639",
    "title": "Contrastive predictive coding for Anomaly Detection in Multi-variate  Time Series Data",
    "abstract": "Anomaly detection in multi-variate time series (MVTS) data is a huge\nchallenge as it requires simultaneous representation of long term temporal\ndependencies and correlations across multiple variables. More often, this is\nsolved by breaking the complexity through modeling one dependency at a time. In\nthis paper, we propose a Time-series Representational Learning through\nContrastive Predictive Coding (TRL-CPC) towards anomaly detection in MVTS data.\nFirst, we jointly optimize an encoder, an auto-regressor and a non-linear\ntransformation function to effectively learn the representations of the MVTS\ndata sets, for predicting future trends. It must be noted that the context\nvectors are representative of the observation window in the MTVS. Next, the\nlatent representations for the succeeding instants obtained through non-linear\ntransformations of these context vectors, are contrasted with the latent\nrepresentations of the encoder for the multi-variables such that the density\nfor the positive pair is maximized. Thus, the TRL-CPC helps to model the\ntemporal dependencies and the correlations of the parameters for a healthy\nsignal pattern. Finally, fitting the latent representations are fit into a\nGaussian scoring function to detect anomalies. Evaluation of the proposed\nTRL-CPC on three MVTS data sets against SOTA anomaly detection methods shows\nthe superiority of TRL-CPC.",
    "descriptor": "",
    "authors": [
      "Theivendiram Pranavan",
      "Terence Sim",
      "Arulmurugan Ambikapathi",
      "Savitha Ramasamy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.03639"
  },
  {
    "id": "arXiv:2202.03643",
    "title": "SNPSFuzzer: A Fast Greybox Fuzzer for Stateful Network Protocols using  Snapshots",
    "abstract": "Greybox fuzzing has been widely used in stateless programs and has achieved\ngreat success. However, most state-of-the-art greybox fuzzers generally have\nthe problems of slow speed and shallow state depth coverage in the process of\nfuzzing stateful network protocol programs which are able to remember and store\ndetails of the interactions. The existing greybox fuzzers for network protocol\nprograms send a series of well-defined prefix sequences of input messages first\nand then send mutated messages to test the target state of a stateful network\nprotocol. The process mentioned above causes a high time cost. In this paper,\nwe propose SNPSFuzzer, a fast greybox fuzzer for stateful network protocol\nusing snapshots. SNPSFuzzer dumps the context information when the network\nprotocol program is under a specific state and restores it when the state needs\nto be fuzzed. Furthermore, we design a message chain analysis algorithm to\nexplore more and deeper network protocol states. Our evaluation shows that,\ncompared with the state-of-the-art network protocol greybox fuzzer AFLNET,\nSNPSFuzzer increases the speed of network protocol fuzzing by 112.0%-168.9% and\nimproves path coverage by 21.4%-27.5% within 24 hours. Moreover, SNPSFuzzer\nexposes a previously unreported vulnerability in program Tinydtls.",
    "descriptor": "",
    "authors": [
      "Junqiang Li",
      "Senyi Li",
      "Gang Sun",
      "Ting Chen",
      "Hongfang Yu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2202.03643"
  },
  {
    "id": "arXiv:2202.03645",
    "title": "NxtPost: User to Post Recommendations in Facebook Groups",
    "abstract": "In this paper, we present NxtPost, a deployed user-to-post content-based\nsequential recommender system for Facebook Groups. Inspired by recent advances\nin NLP, we have adapted a Transformer-based model to the domain of sequential\nrecommendation. We explore causal masked multi-head attention that optimizes\nboth short and long-term user interests. From a user's past activities\nvalidated by defined safety process, NxtPost seeks to learn a representation\nfor the user's dynamic content preference and to predict the next post user may\nbe interested in. In contrast to previous Transformer-based methods, we do not\nassume that the recommendable posts have a fixed corpus. Accordingly, we use an\nexternal item/token embedding to extend a sequence-based approach to a large\nvocabulary. We achieve 49% abs. improvement in offline evaluation. As a result\nof NxtPost deployment, 0.6% more users are meeting new people, engaging with\nthe community, sharing knowledge and getting support. The paper shares our\nexperience in developing a personalized sequential recommender system, lessons\ndeploying the model for cold start users, how to deal with freshness, and\ntuning strategies to reach higher efficiency in online A/B experiments.",
    "descriptor": "\nComments: 9 pages\n",
    "authors": [
      "Kaushik Rangadurai",
      "Yiqun Liu",
      "Siddarth Malreddy",
      "Xiaoyi Liu",
      "Piyush Maheshwari",
      "Vishwanath Sangale",
      "Fedor Borisyuk"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.03645"
  },
  {
    "id": "arXiv:2202.03647",
    "title": "Summary On The ICASSP 2022 Multi-Channel Multi-Party Meeting  Transcription Grand Challenge",
    "abstract": "The ICASSP 2022 Multi-channel Multi-party Meeting Transcription Grand\nChallenge (M2MeT) focuses on one of the most valuable and the most challenging\nscenarios of speech technologies. The M2MeT challenge has particularly set up\ntwo tracks, speaker diarization (track 1) and multi-speaker automatic speech\nrecognition (ASR) (track 2). Along with the challenge, we released 120 hours of\nreal-recorded Mandarin meeting speech data with manual annotation, including\nfar-field data collected by 8-channel microphone array as well as near-field\ndata collected by each participants' headset microphone. We briefly describe\nthe released dataset, track setups, baselines and summarize the challenge\nresults and major techniques used in the submissions.",
    "descriptor": "\nComments: 5 pages, 4 tables\n",
    "authors": [
      "Fan Yu",
      "Shiliang Zhang",
      "Pengcheng Guo",
      "Yihui Fu",
      "Zhihao Du",
      "Siqi Zheng",
      "Weilong Huang",
      "Lei Xie",
      "Zheng-Hua Tan",
      "DeLiang Wang",
      "Yanmin Qian",
      "Kong Aik Lee",
      "Zhijie Yan",
      "Bin Ma",
      "Xin Xu",
      "Hui Bu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2202.03647"
  },
  {
    "id": "arXiv:2202.03648",
    "title": "Energy Efficiency and Delay Tradeoff in an MEC-Enabled Mobile IoT  Network",
    "abstract": "Mobile Edge Computing (MEC) has recently emerged as a promising technology in\nthe 5G era. It is deemed an effective paradigm to support computation-intensive\nand delay critical applications even at energy-constrained and\ncomputation-limited Internet of Things (IoT) devices. To effectively exploit\nthe performance benefits enabled by MEC, it is imperative to jointly allocate\nradio and computational resources by considering non-stationary computation\ndemands, user mobility, and wireless fading channels. This paper aims to study\nthe tradeoff between energy efficiency (EE) and service delay for multi-user\nmulti-server MEC-enabled IoT systems when provisioning offloading services in a\nuser mobility scenario. Particularly, we formulate a stochastic optimization\nproblem with the objective of minimizing the long-term average network EE with\nthe constraints of the task queue stability, peak transmit power, maximum\nCPU-cycle frequency, and maximum user number. To tackle the problem, we propose\nan online offloading and resource allocation algorithm by transforming the\noriginal problem into several individual subproblems in each time slot based on\nLyapunov optimization theory, which are then solved by convex decomposition and\nsubmodular methods. Theoretical analysis proves that the proposed algorithm can\nachieve a $[O(1/V), O(V)]$ tradeoff between EE and service delay. Simulation\nresults verify the theoretical analysis and demonstrate our proposed algorithm\ncan offer much better EE-delay performance in task offloading challenges,\ncompared to several baselines.",
    "descriptor": "",
    "authors": [
      "Han Hu",
      "Weiwei Song",
      "Qun Wang",
      "Rose Qingyang Hu",
      "Hongbo Zhu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.03648"
  },
  {
    "id": "arXiv:2202.03651",
    "title": "Causal Scene BERT: Improving object detection by searching for  challenging groups of data",
    "abstract": "Modern computer vision applications rely on learning-based perception modules\nparameterized with neural networks for tasks like object detection. These\nmodules frequently have low expected error overall but high error on atypical\ngroups of data due to biases inherent in the training process. In building\nautonomous vehicles (AV), this problem is an especially important challenge\nbecause their perception modules are crucial to the overall system performance.\nAfter identifying failures in AV, a human team will comb through the associated\ndata to group perception failures that share common causes. More data from\nthese groups is then collected and annotated before retraining the model to fix\nthe issue. In other words, error groups are found and addressed in hindsight.\nOur main contribution is a pseudo-automatic method to discover such groups in\nforesight by performing causal interventions on simulated scenes. To keep our\ninterventions on the data manifold, we utilize masked language models. We\nverify that the prioritized groups found via intervention are challenging for\nthe object detector and show that retraining with data collected from these\ngroups helps inordinately compared to adding more IID data. We also plan to\nrelease software to run interventions in simulated scenes, which we hope will\nbenefit the causality community.",
    "descriptor": "",
    "authors": [
      "Cinjon Resnick",
      "Or Litany",
      "Amlan Kar",
      "Karsten Kreis",
      "James Lucas",
      "Kyunghyun Cho",
      "Sanja Fidler"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.03651"
  },
  {
    "id": "arXiv:2202.03652",
    "title": "Real-time disease prediction with local differential privacy in Internet  of Medical Things",
    "abstract": "The rapid development in Internet of Medical Things (IoMT) boosts the\nopportunity for real-time health monitoring using various data types such as\nelectroencephalography (EEG) and electrocardiography (ECG). Security issues\nhave significantly impeded the e-healthcare system implementation. Three\nimportant challenges for privacy preserving system need to be addressed:\naccurate matching, privacy enhancement without compromising security, and\ncomputation efficiency. It is essential to guarantee prediction accuracy since\ndisease diagnosis is strongly related to health and life. In this paper, we\npropose efficient disease prediction that guarantees security against malicious\nclients and honest-but-curious server using matrix encryption technique. A\nbiomedical signal provided by the client is diagnosed such that the server does\nnot get any information about the signal as well as the final result of the\ndiagnosis while the client does not learn any information about the server's\nmedical data. Thorough security analysis illustrates the disclosure resilience\nof the proposed scheme and the encryption algorithm satisfies local\ndifferential privacy. After result decryption performed by the client's device,\nperformance is not degraded to perform prediction on encrypted data. The\nproposed scheme is efficient to implement real-time health monitoring.",
    "descriptor": "",
    "authors": [
      "Guanhong Miao",
      "A. Adam Ding",
      "Samuel S. Wu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Other Statistics (stat.OT)"
    ],
    "url": "https://arxiv.org/abs/2202.03652"
  },
  {
    "id": "arXiv:2202.03654",
    "title": "Low-Complexity Decoding of a Class of Reed-Muller Subcodes for  Low-Capacity Channels",
    "abstract": "We present a low-complexity and low-latency decoding algorithm for a class of\nReed-Muller (RM) subcodes that are defined based on the product of smaller RM\ncodes. More specifically, the input sequence is shaped as a multi-dimensional\narray, and the encoding over each dimension is done separately via a smaller RM\nencoder. Similarly, the decoding is performed over each dimension via a\nlow-complexity decoder for smaller RM codes. The proposed construction is of\nparticular interest to low-capacity channels that are relevant to emerging\nlow-rate communication scenarios. We present an efficient soft-input\nsoft-output (SISO) iterative decoding algorithm for the product of RM codes and\ndemonstrate its superiority compared to hard decoding over RM code components.\nThe proposed coding scheme has decoding (as well as encoding) complexity of\n$\\mathcal{O}(n\\log n)$ and latency of $\\mathcal{O}(\\log n)$ for blocklength\n$n$. This research renders a general framework toward efficient decoding of RM\ncodes.",
    "descriptor": "\nComments: Accepted for presentation in the 2022 IEEE International Conference on Communications (ICC)\n",
    "authors": [
      "Mohammad Vahid Jamali",
      "Mohammad Fereydounian",
      "Hessam Mahdavifar",
      "Hamed Hassani"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.03654"
  },
  {
    "id": "arXiv:2202.03655",
    "title": "Linear Time Kernel Matrix Approximation via Hyperspherical Harmonics",
    "abstract": "We propose a new technique for constructing low-rank approximations of\nmatrices that arise in kernel methods for machine learning. Our approach pairs\na novel automatically constructed analytic expansion of the underlying kernel\nfunction with a data-dependent compression step to further optimize the\napproximation. This procedure works in linear time and is applicable to any\nisotropic kernel. Moreover, our method accepts the desired error tolerance as\ninput, in contrast to prevalent methods which accept the rank as input.\nExperimental results show our approach compares favorably to the commonly used\nNystrom method with respect to both accuracy for a given rank and computational\ntime for a given accuracy across a variety of kernels, dimensions, and\ndatasets. Notably, in many of these problem settings our approach produces\nnear-optimal low-rank approximations. We provide an efficient open-source\nimplementation of our new technique to complement our theoretical developments\nand experimental results.",
    "descriptor": "",
    "authors": [
      "John Paul Ryan",
      "Anil Damle"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.03655"
  },
  {
    "id": "arXiv:2202.03666",
    "title": "Approximating Gradients for Differentiable Quality Diversity in  Reinforcement Learning",
    "abstract": "Consider a walking agent that must adapt to damage. To approach this task, we\ncan train a collection of policies and have the agent select a suitable policy\nwhen damaged. Training this collection may be viewed as a quality diversity\n(QD) optimization problem, where we search for solutions (policies) which\nmaximize an objective (walking forward) while spanning a set of measures\n(measurable characteristics). Recent work shows that differentiable quality\ndiversity (DQD) algorithms greatly accelerate QD optimization when exact\ngradients are available for the objective and measures. However, such gradients\nare typically unavailable in RL settings due to non-differentiable\nenvironments. To apply DQD in RL settings, we propose to approximate objective\nand measure gradients with evolution strategies and actor-critic methods. We\ndevelop two variants of the DQD algorithm CMA-MEGA, each with different\ngradient approximations, and evaluate them on four simulated walking tasks. One\nvariant achieves comparable performance (QD score) with the state-of-the-art\nPGA-MAP-Elites in two tasks. The other variant performs comparably in all tasks\nbut is less efficient than PGA-MAP-Elites in two tasks. These results provide\ninsight into the limitations of CMA-MEGA in domains that require rigorous\noptimization of the objective and where exact gradients are unavailable.",
    "descriptor": "\nComments: Online article available at this http URL\n",
    "authors": [
      "Bryon Tjanaka",
      "Matthew C. Fontaine",
      "Julian Togelius",
      "Stefanos Nikolaidis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2202.03666"
  },
  {
    "id": "arXiv:2202.03670",
    "title": "How to Understand Masked Autoencoders",
    "abstract": "\"Masked Autoencoders (MAE) Are Scalable Vision Learners\" revolutionizes the\nself-supervised learning that not only achieves the state-of-the-art for image\npretraining, but also is a milestone that bridged the gap between the visual\nand linguistic masked autoencoding (BERT-style) pretrainings. However, to our\nknowledge, to date there are no theoretical perspectives to explain the\npowerful expressivity of MAE. In this paper, we, for the first time, propose a\nunified theoretical framework that provides a mathematical understanding for\nMAE. Particularly, we explain the patch-based attention approaches of MAE using\nan integral kernel under a non-overlapping domain decomposition setting. To\nhelp the researchers to further grasp the main reasons of the great success of\nMAE, based on our framework, we contribute five questions and answer them by\ninsights from operator theory with mathematical rigor.",
    "descriptor": "",
    "authors": [
      "Shuhao Cao",
      "Peng Xu",
      "David A. Clifton"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.03670"
  },
  {
    "id": "arXiv:2202.03672",
    "title": "APPFL: Open-Source Software Framework for Privacy-Preserving Federated  Learning",
    "abstract": "Federated learning (FL) enables training models at different sites and\nupdating the weights from the training instead of transferring data to a\ncentral location and training as in classical machine learning. The FL\ncapability is especially important to domains such as biomedicine and smart\ngrid, where data may not be shared freely or stored at a central location\nbecause of policy challenges. Thanks to the capability of learning from\ndecentralized datasets, FL is now a rapidly growing research field, and\nnumerous FL frameworks have been developed. In this work, we introduce APPFL,\nthe Argonne Privacy-Preserving Federated Learning framework. APPFL allows users\nto leverage implemented privacy-preserving algorithms, implement new\nalgorithms, and simulate and deploy various FL algorithms with\nprivacy-preserving techniques. The modular framework enables users to customize\nthe components for algorithms, privacy, communication protocols, neural network\nmodels, and user data. We also present a new communication-efficient algorithm\nbased on an inexact alternating direction method of multipliers. The algorithm\nrequires significantly less communication between the server and the clients\nthan does the current state of the art. We demonstrate the computational\ncapabilities of APPFL, including differentially private FL on various test\ndatasets and its scalability, by using multiple algorithms and datasets on\ndifferent computing environments.",
    "descriptor": "\nComments: 9 pages, 4 figures, 1 table\n",
    "authors": [
      "Minseok Ryu",
      "Youngdae Kim",
      "Kibaek Kim",
      "Ravi K. Madduri"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.03672"
  },
  {
    "id": "arXiv:2202.03673",
    "title": "Calibrated Learning to Defer with One-vs-All Classifiers",
    "abstract": "The learning to defer (L2D) framework has the potential to make AI systems\nsafer. For a given input, the system can defer the decision to a human if the\nhuman is more likely than the model to take the correct action. We study the\ncalibration of L2D systems, investigating if the probabilities they output are\nsound. We find that Mozannar & Sontag's (2020) multiclass framework is not\ncalibrated with respect to expert correctness. Moreover, it is not even\nguaranteed to produce valid probabilities due to its parameterization being\ndegenerate for this purpose. We propose an L2D system based on one-vs-all\nclassifiers that is able to produce calibrated probabilities of expert\ncorrectness. Furthermore, our loss function is also a consistent surrogate for\nmulticlass L2D, like Mozannar & Sontag's (2020). Our experiments verify that\nnot only is our system calibrated, but this benefit comes at no cost to\naccuracy. Our model's accuracy is always comparable (and often superior) to\nMozannar & Sontag's (2020) model's in tasks ranging from hate speech detection\nto galaxy classification to diagnosis of skin lesions.",
    "descriptor": "",
    "authors": [
      "Rajeev Verma",
      "Eric Nalisnick"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.03673"
  },
  {
    "id": "arXiv:2202.03674",
    "title": "Trained Model in Supervised Deep Learning is a Conditional Risk  Minimizer",
    "abstract": "We proved that a trained model in supervised deep learning minimizes the\nconditional risk for each input (Theorem 2.1). This property provided insights\ninto the behavior of trained models and established a connection between\nsupervised and unsupervised learning in some cases. In addition, when the\nlabels are intractable but can be written as a conditional risk minimizer, we\nproved an equivalent form of the original supervised learning problem with\naccessible labels (Theorem 2.2). We demonstrated that many existing works, such\nas Noise2Score, Noise2Noise and score function estimation can be explained by\nour theorem. Moreover, we derived a property of classification problem with\nnoisy labels using Theorem 2.1 and validated it using MNIST dataset.\nFurthermore, We proposed a method to estimate uncertainty in image\nsuper-resolution based on Theorem 2.2 and validated it using ImageNet dataset.\nOur code is available on github.",
    "descriptor": "",
    "authors": [
      "Yutong Xie",
      "Dufan Wu",
      "Bin Dong",
      "Quanzheng Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.03674"
  },
  {
    "id": "arXiv:2202.03677",
    "title": "A Novel Image Descriptor with Aggregated Semantic Skeleton  Representation for Long-term Visual Place Recognition",
    "abstract": "In a Simultaneous Localization and Mapping (SLAM) system, a loop-closure can\neliminate accumulated errors, which is accomplished by Visual Place Recognition\n(VPR), a task that retrieves the current scene from a set of pre-stored\nsequential images through matching specific scene-descriptors. In urban scenes,\nthe appearance variation caused by seasons and illumination has brought great\nchallenges to the robustness of scene descriptors. Semantic segmentation images\ncan not only deliver the shape information of objects but also their categories\nand spatial relations that will not be affected by the appearance variation of\nthe scene. Innovated by the Vector of Locally Aggregated Descriptor (VLAD), in\nthis paper, we propose a novel image descriptor with aggregated semantic\nskeleton representation (SSR), dubbed SSR-VLAD, for the VPR under drastic\nappearance-variation of environments. The SSR-VLAD of one image aggregates the\nsemantic skeleton features of each category and encodes the spatial-temporal\ndistribution information of the image semantic information. We conduct a series\nof experiments on three public datasets of challenging urban scenes. Compared\nwith four state-of-the-art VPR methods- CoHOG, NetVLAD, LOST-X, and\nRegion-VLAD, VPR by matching SSR-VLAD outperforms those methods and maintains\ncompetitive real-time performance at the same time.",
    "descriptor": "",
    "authors": [
      "Nie Jiwei",
      "Feng Joe-Mei",
      "Xue Dingyu",
      "Pan Feng",
      "Liu Wei",
      "Hu Jun",
      "Cheng Shuai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.03677"
  },
  {
    "id": "arXiv:2202.03678",
    "title": "Quality Metric Guided Portrait Line Drawing Generation from Unpaired  Training Data",
    "abstract": "Face portrait line drawing is a unique style of art which is highly abstract\nand expressive. However, due to its high semantic constraints, many existing\nmethods learn to generate portrait drawings using paired training data, which\nis costly and time-consuming to obtain. In this paper, we propose a novel\nmethod to automatically transform face photos to portrait drawings using\nunpaired training data with two new features; i.e., our method can (1) learn to\ngenerate high quality portrait drawings in multiple styles using a single\nnetwork and (2) generate portrait drawings in a \"new style\" unseen in the\ntraining data. To achieve these benefits, we (1) propose a novel quality metric\nfor portrait drawings which is learned from human perception, and (2) introduce\na quality loss to guide the network toward generating better looking portrait\ndrawings. We observe that existing unpaired translation methods such as\nCycleGAN tend to embed invisible reconstruction information indiscriminately in\nthe whole drawings due to significant information imbalance between the photo\nand portrait drawing domains, which leads to important facial features missing.\nTo address this problem, we propose a novel asymmetric cycle mapping that\nenforces the reconstruction information to be visible and only embedded in the\nselected facial regions. Along with localized discriminators for important\nfacial regions, our method well preserves all important facial features in the\ngenerated drawings. Generator dissection further explains that our model learns\nto incorporate face semantic information during drawing generation. Extensive\nexperiments including a user study show that our model outperforms\nstate-of-the-art methods.",
    "descriptor": "\nComments: Accepted by IEEE Transactions on Pattern Analysis and Machine Intelligence, this https URL, code: this https URL\n",
    "authors": [
      "Ran Yi",
      "Yong-Jin Liu",
      "Yu-Kun Lai",
      "Paul L. Rosin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2202.03678"
  },
  {
    "id": "arXiv:2202.03679",
    "title": "A Unified Prediction Framework for Signal Maps",
    "abstract": "Signal maps are essential for the planning and operation of cellular\nnetworks. However, the measurements needed to create such maps are expensive,\noften biased, not always reflecting the metrics of interest, and posing privacy\nrisks. In this paper, we develop a unified framework for predicting cellular\nsignal maps from limited measurements. We propose and combine three mechanisms\nthat deal with the fact that not all measurements are equally important for a\nparticular prediction task. First, we design \\emph{quality-of-service functions\n($Q$)}, including signal strength (RSRP) but also other metrics of interest,\nsuch as coverage (improving recall by 76\\%-92\\%) and call drop probability\n(reducing error by as much as 32\\%). By implicitly altering the training loss\nfunction, quality functions can also improve prediction for RSRP itself where\nit matters (e.g. MSE reduction up to 27\\% in the low signal strength regime,\nwhere errors are critical). Second, we introduce \\emph{weight functions} ($W$)\nto specify the relative importance of prediction at different parts of the\nfeature space. We propose re-weighting based on importance sampling to obtain\nunbiased estimators when the sampling and target distributions\nmismatch(yielding 20\\% improvement for targets on spatially uniform loss or on\nuser population density). Third, we apply the {\\em Data Shapley} framework for\nthe first time in this context: to assign values ($\\phi$) to individual\nmeasurement points, which capture the importance of their contribution to the\nprediction task. This can improve prediction (e.g. from 64\\% to 94\\% in recall\nfor coverage loss) by removing points with negative values, and can also enable\ndata minimization (i.e. we show that we can remove 70\\% of data w/o loss in\nperformance). We evaluate our methods and demonstrate significant improvement\nin prediction performance, using several real-world datasets.",
    "descriptor": "\nComments: Coverage Maps; Signal Strength Maps; LTE; RSRP; CQI; RSRQ; RSS; Importance Sampling; Random Forests; Carrier's Objectives; Call Drops;Key Performance Indicators\n",
    "authors": [
      "Emmanouil Alimpertis",
      "Athina Markopoulou",
      "Carter T. Butts",
      "Evita Bakopoulou",
      "Konstantinos Psounis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2202.03679"
  },
  {
    "id": "arXiv:2202.03680",
    "title": "Exploring Inter-Channel Correlation for Diversity-preserved  KnowledgeDistillation",
    "abstract": "Knowledge Distillation has shown very promising abil-ity in transferring\nlearned representation from the largermodel (teacher) to the smaller one\n(student).Despitemany efforts, prior methods ignore the important role\nofretaining inter-channel correlation of features, leading tothe lack of\ncapturing intrinsic distribution of the featurespace and sufficient diversity\nproperties of features in theteacher network.To solve the issue, we propose\nthenovel Inter-Channel Correlation for Knowledge Distillation(ICKD), with which\nthe diversity and homology of the fea-ture space of the student network can\nalign with that ofthe teacher network. The correlation between these\ntwochannels is interpreted as diversity if they are irrelevantto each other,\notherwise homology. Then the student isrequired to mimic the correlation within\nits own embed-ding space. In addition, we introduce the grid-level\ninter-channel correlation, making it capable of dense predictiontasks.\nExtensive experiments on two vision tasks, includ-ing ImageNet classification\nand Pascal VOC segmentation,demonstrate the superiority of our ICKD, which\nconsis-tently outperforms many existing methods, advancing thestate-of-the-art\nin the fields of Knowledge Distillation. Toour knowledge, we are the first\nmethod based on knowl-edge distillation boosts ResNet18 beyond 72% Top-1\nac-curacy on ImageNet classification. Code is available\nat:https://github.com/ADLab-AutoDrive/ICKD.",
    "descriptor": "\nComments: Accepted by ICCV 2021\n",
    "authors": [
      "Li Liu",
      "Qingle Huang",
      "Sihao Lin",
      "Hongwei Xie",
      "Bing Wang",
      "Xiaojun Chang",
      "Xiaodan Liang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.03680"
  },
  {
    "id": "arXiv:2202.03684",
    "title": "Efficiently Escaping Saddle Points in Bilevel Optimization",
    "abstract": "Bilevel optimization is one of the fundamental problems in machine learning\nand optimization. Recent theoretical developments in bilevel optimization focus\non finding the first-order stationary points for nonconvex-strongly-convex\ncases. In this paper, we analyze algorithms that can escape saddle points in\nnonconvex-strongly-convex bilevel optimization. Specifically, we show that the\nperturbed approximate implicit differentiation (AID) with a warm start strategy\nfinds $\\epsilon$-approximate local minimum of bilevel optimization in\n$\\tilde{O}(\\epsilon^{-2})$ iterations with high probability. Moreover, we\npropose an inexact NEgative-curvature-Originated-from-Noise Algorithm (iNEON),\na pure first-order algorithm that can escape saddle point and find local\nminimum of stochastic bilevel optimization. As a by-product, we provide the\nfirst nonasymptotic analysis of perturbed multi-step gradient descent ascent\n(GDmax) algorithm that converges to local minimax point for minimax problems.",
    "descriptor": "",
    "authors": [
      "Minhui Huang",
      "Kaiyi Ji",
      "Shiqian Ma",
      "Lifeng Lai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.03684"
  },
  {
    "id": "arXiv:2202.03687",
    "title": "CyberOps: Situational Awareness in Cybersecurity Operations",
    "abstract": "Cybersecurity operations, CyberOps, is the use and application of\ncybersecurity capabilities to a domain, department, organisation or nation. It\nis fundamentally to protect digital investments, contribute to national\neconomic wellbeing by providing a safe, secure and conducive environment to\nconduct business and to protect national critical national infrastructures and\ncitizens welfare. In this paper, we investigate operational factors that\ninfluence situational awareness of CyberOps, specifically, the features that\ndeals with understanding and comprehension of operational and human factors\naspects and that helps with insights on human operator decision making such as\ncognition, teamwork, knowledge, skills and abilities. The operational factors\ndiscussed in this paper range from tools, techniques, integration, architecture\nto automation, cognition, people, policy, process and procedures.",
    "descriptor": "\nComments: 26 pages, 3 figures. arXiv admin note: text overlap with arXiv:2202.02537\n",
    "authors": [
      "Cyril Onwubiko"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2202.03687"
  },
  {
    "id": "arXiv:2202.03689",
    "title": "A Decision Support Design Framework for Selecting a Robotic Interface",
    "abstract": "The design and development of robots involve the essential step of selecting\nand testing robotic interfaces. This interface selection requires careful\nconsideration as the robot's physical embodiment influences and adds to the\ntraditional interfaces' complexities. Our paper presents a decision support\ndesign framework for the a priori selection of robotic interface that was\ninductively formulated from our case study of designing a robot to collaborate\nwith employees with cognitive disabilities. Our framework outlines the\ninterface requirements according to User, Robot, Tasks and Environment and\nfacilitates a structured comparison of interfaces against those requirements.\nThe framework is assessed for its potential applicability and usefulness\nthrough a qualitative study with HRI experts. The framework is appreciated as a\nsystematic tool that enables documentation and discussion, and identified\nissues inform the frameworks' iteration. The themes of ownership of this\nprocess in interdisciplinary teams and its role in iteratively designing\ninterfaces are discussed.",
    "descriptor": "\nComments: To be submitted to a relevant Human-Robot Interaction conference\n",
    "authors": [
      "Shreepriya Gonzalez Jimenez",
      "Danilo Gallo",
      "Ricardo Sosa",
      "Eduardo B. Sandoval",
      "Tommasso Colombino",
      "Antonietta Grasso"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.03689"
  },
  {
    "id": "arXiv:2202.03691",
    "title": "Challenges towards Building an effective Cyber Security Operations  Centre",
    "abstract": "The increasing dependency of modern society on IT systems and infrastructures\nfor essential services (e.g. internet banking, vehicular network, health-IT,\netc.) coupled with the growing number of cyber incidents and security\nvulnerabilities have made Cyber Security Operations Centre (CSOC) undoubtedly\nvital. As such security operations monitoring is now an integral part of most\nbusiness operations. SOCs (used interchangeably as CSOCs) are responsible for\ncontinuously and protectively monitoring business services, IT systems and\ninfrastructures to identify vulnerabilities, detect cyber-attacks, security\nbreaches, policy violations, and to respond to cyber incidents swiftly. They\nmust also ensure that security events and alerts are triaged and analysed,\nwhile coordinating and managing cyber incidents to resolution. Because SOCs are\nvital, it is also necessary that SOCs are effective. But unfortunately, the\neffectiveness of SOCs are a widespread concern and a focus of boundless debate.\nIn this paper, we identify and discuss some of the pertinent challenges to\nbuilding an effective SOC. We investigate some of the factors contributing to\nthe inefficiencies in SOCs and explain some of the challenges they face.\nFurther, we provide and prioritise recommendations to addressing the identified\nissues.",
    "descriptor": "\nComments: 20 pages, 3 figures\n",
    "authors": [
      "Cyril Onwubiko",
      "Karim Ouazzane"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2202.03691"
  },
  {
    "id": "arXiv:2202.03692",
    "title": "The factorization method and Capon's method for random source  identification in experimental aeroacoustics",
    "abstract": "Experimental aeroacoustics is concerned with the estimation of acoustic\nsource power distributions, which are for instance caused by fluid structure\ninteractions on scaled aircraft models inside a wind tunnel, from microphone\narray measurements of associated sound pressure fluctuations. In the frequency\ndomain aeroacoustic sound propagation can be modelled as a random source\nproblem for a convected Helmholtz equation. This article is concerned with the\ninverse random source problem to recover the support of an uncorrelated\naeroacoustic source from correlations of observed pressure signals. We show a\nvariant of the factorization method from inverse scattering theory can be used\nfor this purpose. We also discuss a surprising relation between the\nfactorization method and a commonly used beamforming algorithm from\nexperimental aeroacoustics, which is known as Capon's method or as the minimum\nvariance method. Numerical examples illustrate our theoretical findings.",
    "descriptor": "",
    "authors": [
      "Roland Griesmaier",
      "Hans-Georg Raumer"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.03692"
  },
  {
    "id": "arXiv:2202.03695",
    "title": "Network Comparison Study of Deep Activation Feature Discriminability  with Novel Objects",
    "abstract": "Feature extraction has always been a critical component of the computer\nvision field. More recently, state-of-the-art computer visions algorithms have\nincorporated Deep Neural Networks (DNN) in feature extracting roles, creating\nDeep Convolutional Activation Features (DeCAF). The transferability of DNN\nknowledge domains has enabled the wide use of pretrained DNN feature extraction\nfor applications with novel object classes, especially those with limited\ntraining data. This study analyzes the general discriminability of novel object\nvisual appearances encoded into the DeCAF space of six of the leading visual\nrecognition DNN architectures. The results of this study characterize the\nMahalanobis distances and cosine similarities between DeCAF object manifolds\nacross two visual object tracking benchmark data sets. The backgrounds\nsurrounding each object are also included as an object classes in the manifold\nanalysis, providing a wider range of novel classes. This study found that\ndifferent network architectures led to different network feature focuses that\nmust to be considered in the network selection process. These results are\ngenerated from the VOT2015 and UAV123 benchmark data sets; however, the\nproposed methods can be applied to efficiently compare estimated network\nperformance characteristics for any labeled visual data set.",
    "descriptor": "",
    "authors": [
      "Michael Karnes",
      "Alper Yilmaz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.03695"
  },
  {
    "id": "arXiv:2202.03696",
    "title": "Hybrid Kinetic/Fluid numerical method for the Vlasov-BGK equation in the  diffusive scaling",
    "abstract": "This paper presents a hybrid numerical method for linear collisional kinetic\nequations with diffusive scaling. The aim of the method is to reduce the\ncomputational cost of kinetic equations by taking advantage of the lower\ndimensionality of the asymptotic fluid model while reducing the error induced\nby the latter approach. It relies on two criteria motivated by a pertubative\napproach to obtain a dynamic domain decomposition. The first criterion\nquantifies how far from a local equilibrium in velocity the distribution\nfunction of particles is. The second one depends only on the macroscopic\nquantities that are available on the whole computing domain. Interface\nconditions are dealt with using a micro-macro decomposition and the method is\nsignificantly more efficient than a standard full kinetic approach. Some\nproperties of the hybrid method are also investigated, such as the conservation\nof mass.",
    "descriptor": "\nComments: 31 pages, 20 figures, 6 Tables\n",
    "authors": [
      "Tino Laidin"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.03696"
  },
  {
    "id": "arXiv:2202.03697",
    "title": "DURableVS: Data-efficient Unsupervised Recalibrating Visual Servoing via  online learning in a structured generative model",
    "abstract": "Visual servoing enables robotic systems to perform accurate closed-loop\ncontrol, which is required in many applications. However, existing methods\neither require precise calibration of the robot kinematic model and cameras or\nuse neural architectures that require large amounts of data to train. In this\nwork, we present a method for unsupervised learning of visual servoing that\ndoes not require any prior calibration and is extremely data-efficient. Our key\ninsight is that visual servoing does not depend on identifying the veridical\nkinematic and camera parameters, but instead only on an accurate generative\nmodel of image feature observations from the joint positions of the robot. We\ndemonstrate that with our model architecture and learning algorithm, we can\nconsistently learn accurate models from less than 50 training samples (which\namounts to less than 1 min of unsupervised data collection), and that such\ndata-efficient learning is not possible with standard neural architectures.\nFurther, we show that by using the generative model in the loop and learning\nonline, we can enable a robotic system to recover from calibration errors and\nto detect and quickly adapt to possibly unexpected changes in the robot-camera\nsystem (e.g. bumped camera, new objects).",
    "descriptor": "",
    "authors": [
      "Nishad Gothoskar",
      "Miguel L\u00e1zaro-Gredilla",
      "Yasemin Bekiroglu",
      "Abhishek Agarwal",
      "Joshua B. Tenenbaum",
      "Vikash K. Mansinghka",
      "Dileep George"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.03697"
  },
  {
    "id": "arXiv:2202.03702",
    "title": "Human-Robot Creative Interactions (HRCI): Exploring Creativity in  Artificial Agents Using a Story-Telling Game",
    "abstract": "Creativity in social robots requires further attention in the\ninterdisciplinary field of Human-Robot Interaction (HRI). This paper\ninvestigates the hypothesised connection between the perceived creative agency\nand the animacy of social robots. The goal of this work is to assess the\nrelevance of robot movements in the attribution of creativity to robots. The\nresults of this work inform the design of future Human-Robot Creative\nInteractions (HRCI). The study uses a storytelling game based on visual imagery\ninspired by the game 'Story Cubes' to explore the perceived creative agency of\nsocial robots. This game is used to tell a classic story for children with an\nalternative ending. A 2x2 experiment was designed to compare two conditions:\nthe robot telling the original version of the story and the robot plot-twisting\nthe end of the story. A Robotis Mini humanoid robot was used for the\nexperiment. As a novel contribution, we propose an adaptation of the Short\nScale Creative Self scale (SSCS) to measure perceived creative agency in\nrobots. We also use the Godspeed scale to explore different attributes of\nsocial robots in this setting. We did not obtain significant main effects of\nthe robot movements or the story in the participants' scores. However, we\nidentified significant main effects of the robot movements in features of\nanimacy, likeability, and perceived safety. This initial work encourages\nfurther studies experimenting with different robot embodiment and movements to\nevaluate the perceived creative agency in robots and inform the design of\nfuture robots that participate in creative interactions.",
    "descriptor": "\nComments: This paper is under review for the Frontiers in Robotics and AI journal since April 2021\n",
    "authors": [
      "Eduardo Benitez Sandoval",
      "Ricardo Sosa",
      "Massimiliano Cappuccio",
      "Tomasz Bednarz"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2202.03702"
  },
  {
    "id": "arXiv:2202.03703",
    "title": "Self-Paced Imbalance Rectification for Class Incremental Learning",
    "abstract": "Exemplar-based class-incremental learning is to recognize new classes while\nnot forgetting old ones, whose samples can only be saved in limited memory. The\nratio fluctuation of new samples to old exemplars, which is caused by the\nvariation of memory capacity at different environments, will bring challenges\nto stabilize the incremental optimization process. To address this problem, we\npropose a novel self-paced imbalance rectification scheme, which dynamically\nmaintains the incremental balance during the representation learning phase.\nSpecifically, our proposed scheme consists of a frequency compensation strategy\nthat adjusts the logits margin between old and new classes with the\ncorresponding number ratio to strengthen the expression ability of the old\nclasses, and an inheritance transfer strategy to reduce the representation\nconfusion by estimating the similarity of different classes in the old\nembedding space. Furthermore, a chronological attenuation mechanism is proposed\nto mitigate the repetitive optimization of the older classes at multiple\nstep-wise increments. Extensive experiments on three benchmarks demonstrate\nstable incremental performance, significantly outperforming the\nstate-of-the-art methods.",
    "descriptor": "",
    "authors": [
      "Zhiheng Liu",
      "Kai Zhu",
      "Yang Cao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.03703"
  },
  {
    "id": "arXiv:2202.03704",
    "title": "Budgeted Combinatorial Multi-Armed Bandits",
    "abstract": "We consider a budgeted combinatorial multi-armed bandit setting where, in\nevery round, the algorithm selects a super-arm consisting of one or more arms.\nThe goal is to minimize the total expected regret after all rounds within a\nlimited budget. Existing techniques in this literature either fix the budget\nper round or fix the number of arms pulled in each round. Our setting is more\ngeneral where based on the remaining budget and remaining number of rounds, the\nalgorithm can decide how many arms to be pulled in each round. First, we\npropose CBwK-Greedy-UCB algorithm, which uses a greedy technique, CBwK-Greedy,\nto allocate the arms to the rounds. Next, we propose a reduction of this\nproblem to Bandits with Knapsacks (BwK) with a single pull. With this\nreduction, we propose CBwK-LPUCB that uses PrimalDualBwK ingeniously. We\nrigorously prove regret bounds for CBwK-LP-UCB. We experimentally compare the\ntwo algorithms and observe that CBwK-Greedy-UCB performs incrementally better\nthan CBwK-LP-UCB. We also show that for very high budgets, the regret goes to\nzero.",
    "descriptor": "\nComments: 9 pages, 4 figures. To be published in AAMAS 2022. arXiv admin note: text overlap with arXiv:1305.2545 by other authors\n",
    "authors": [
      "Debojit Das",
      "Shweta Jain",
      "Sujit Gujar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2202.03704"
  },
  {
    "id": "arXiv:2202.03705",
    "title": "A Survey on Sematic Communications for Intelligent Wireless Networks",
    "abstract": "With deployment of 6G technology, it is envisioned that competitive edge of\nwireless networks will be sustained and next decade's communication\nrequirements will be stratified. Also 6G will aim to aid development of a human\nsociety which is ubiquitous and mobile, simultaneously providing solutions to\nkey challenges such as, coverage, capacity, etc. In addition, 6G will focus on\nproviding intelligent use-cases and applications using higher data-rates over\nmill-meter waves and Tera-Hertz frequency. However, at higher frequencies\nmultiple non-desired phenomena such as atmospheric absorption, blocking, etc.,\noccur which create a bottleneck owing to resource (spectrum and energy)\nscarcity. Hence, following same trend of making efforts towards reproducing at\nreceiver, exact information which was sent by transmitter, will result in a\nnever ending need for higher bandwidth. A possible solution to such a challenge\nlies in semantic communications which focuses on meaning (context) of received\ndata as opposed to only reproducing correct transmitted data. This in turn will\nrequire less bandwidth, and will reduce bottleneck due to various undesired\nphenomenon. In this respect, current article presents a detailed survey on\nrecent technological trends in regard to semantic communications for\nintelligent wireless networks. We focus on semantic communications architecture\nincluding model, and source and channel coding. Next, we detail cross-layer\ninteraction, and various goal-oriented communication applications. We also\npresent overall semantic communications trends in detail, and identify\nchallenges which need timely solutions before practical implementation of\nsemantic communications within 6G wireless technology. Our survey article is an\nattempt to significantly contribute towards initiating future research\ndirections in area of semantic communications for intelligent 6G wireless\nnetworks.",
    "descriptor": "",
    "authors": [
      "Sridhar Iyer",
      "Rajashri Khanai",
      "Dattaprasad Torse",
      "Rahul Jashvantbhai Pandya",
      "Khaled Rabie",
      "Krishna Pai",
      "Wali Ullah Khan",
      "Zubair Fadlullah"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.03705"
  },
  {
    "id": "arXiv:2202.03706",
    "title": "Temporal Walk Centrality: Ranking Nodes in Evolving Networks",
    "abstract": "We propose the Temporal Walk Centrality, which quantifies the importance of a\nnode by measuring its ability to obtain and distribute information in a\ntemporal network. In contrast to the widely-used betweenness centrality, we\nassume that information does not necessarily spread on shortest paths but on\ntemporal random walks that satisfy the time constraints of the network. We show\nthat temporal walk centrality can identify nodes playing central roles in\ndissemination processes that might not be detected by related betweenness\nconcepts and other common static and temporal centrality measures. We propose\nexact and approximation algorithms with different running times depending on\nthe properties of the temporal network and parameters of our new centrality\nmeasure. A technical contribution is a general approach to lift existing\nalgebraic methods for counting walks in static networks to temporal networks.\nOur experiments on real-world temporal networks show the efficiency and\naccuracy of our algorithms. Finally, we demonstrate that the rankings by\ntemporal walk centrality often differ significantly from those of other\nstate-of-the-art temporal centralities.",
    "descriptor": "\nComments: Accepted at the ACM Web Conference (WWW) 2022\n",
    "authors": [
      "Lutz Oettershagen",
      "Petra Mutzel",
      "Nils M. Kriege"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Data Structures and Algorithms (cs.DS)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2202.03706"
  },
  {
    "id": "arXiv:2202.03711",
    "title": "Rate-Distortion Theory for Strategic Semantic Communication",
    "abstract": "This paper analyzes the fundamental limit of the strategic semantic\ncommunication problem in which a transmitter obtains a limited number of\nindirect observation of an intrinsic semantic information source and can then\ninfluence the receiver's decoding by sending a limited number of messages to an\nimperfect channel. The transmitter and the receiver can have different\ndistortion measures and can make rational decision about their encoding and\ndecoding strategies, respectively. The decoder can also have some side\ninformation (e.g., background knowledge and/or information obtained from\nprevious communications) about the semantic source to assist its interpretation\nof the semantic information. We focus particularly on the case that the\ntransmitter can commit to an encoding strategy and study the impact of the\nstrategic decision making on the rate distortion of semantic communication.\nThree equilibrium solutions including the strong Stackelberg equilibrium, weak\nStackelberg equilibrium, as well as Nash equilibrium have been studied and\ncompared. The optimal encoding and decoding strategy profiles under various\nequilibrium solutions have been derived. We prove that committing to an\nencoding strategy cannot always bring benefit to the encoder. We therefore\npropose a feasible condition under which committing to an encoding strategy can\nalways reduce the distortion performance of semantic communication.",
    "descriptor": "\nComments: This work has been submitted to IEEE for possible publication\n",
    "authors": [
      "Yong Xiao",
      "Xu Zhang",
      "Yingyu Li",
      "Guangming Shi"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2202.03711"
  },
  {
    "id": "arXiv:2202.03712",
    "title": "Fourier Representations for Black-Box Optimization over Categorical  Variables",
    "abstract": "Optimization of real-world black-box functions defined over purely\ncategorical variables is an active area of research. In particular,\noptimization and design of biological sequences with specific functional or\nstructural properties have a profound impact in medicine, materials science,\nand biotechnology. Standalone search algorithms, such as simulated annealing\n(SA) and Monte Carlo tree search (MCTS), are typically used for such\noptimization problems. In order to improve the performance and sample\nefficiency of such algorithms, we propose to use existing methods in\nconjunction with a surrogate model for the black-box evaluations over purely\ncategorical variables. To this end, we present two different representations, a\ngroup-theoretic Fourier expansion and an abridged one-hot encoded Boolean\nFourier expansion. To learn such representations, we consider two different\nsettings to update our surrogate model. First, we utilize an adversarial online\nregression setting where Fourier characters of each representation are\nconsidered as experts and their respective coefficients are updated via an\nexponential weight update rule each time the black box is evaluated. Second, we\nconsider a Bayesian setting where queries are selected via Thompson sampling\nand the posterior is updated via a sparse Bayesian regression model (over our\nproposed representation) with a regularized horseshoe prior. Numerical\nexperiments over synthetic benchmarks as well as real-world RNA sequence\noptimization and design problems demonstrate the representational power of the\nproposed methods, which achieve competitive or superior performance compared to\nstate-of-the-art counterparts, while improving the computation cost and/or\nsample efficiency, substantially.",
    "descriptor": "",
    "authors": [
      "Hamid Dadkhahi",
      "Jesus Rios",
      "Karthikeyan Shanmugam",
      "Payel Das"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.03712"
  },
  {
    "id": "arXiv:2202.03714",
    "title": "What's Cracking? A Review and Analysis of Deep Learning Methods for  Structural Crack Segmentation, Detection and Quantification",
    "abstract": "Surface cracks are a very common indicator of potential structural faults.\nTheir early detection and monitoring is an important factor in structural\nhealth monitoring. Left untreated, they can grow in size over time and require\nexpensive repairs or maintenance. With recent advances in computer vision and\ndeep learning algorithms, the automatic detection and segmentation of cracks\nfor this monitoring process have become a major topic of interest. This review\naims to give researchers an overview of the published work within the field of\ncrack analysis algorithms that make use of deep learning. It outlines the\nvarious tasks that are solved through applying computer vision algorithms to\nsurface cracks in a structural health monitoring setting and also provides\nin-depth reviews of recent fully, semi and unsupervised approaches that perform\ncrack classification, detection, segmentation and quantification. Additionally,\nthis review also highlights popular datasets used for cracks and the metrics\nthat are used to evaluate the performance of those algorithms. Finally,\npotential research gaps are outlined and further research directions are\nprovided.",
    "descriptor": "",
    "authors": [
      "Jacob K\u00f6nig",
      "Mark Jenkins",
      "Mike Mannion",
      "Peter Barrie",
      "Gordon Morison"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.03714"
  },
  {
    "id": "arXiv:2202.03716",
    "title": "Binary Neural Networks as a general-propose compute paradigm for  on-device computer vision",
    "abstract": "For binary neural networks (BNNs) to become the mainstream on-device computer\nvision algorithm, they must achieve a superior speed-vs-accuracy tradeoff than\n8-bit quantization and establish a similar degree of general applicability in\nvision tasks. To this end, we propose a BNN framework comprising 1) a\nminimalistic inference scheme for hardware-friendliness, 2) an\nover-parameterized training scheme for high accuracy, and 3) a simple procedure\nto adapt to different vision tasks. The resultant framework overtakes 8-bit\nquantization in the speed-vs-accuracy tradeoff for classification, detection,\nsegmentation, super-resolution and matching: our BNNs not only retain the\naccuracy levels of their 8-bit baselines but also showcase 1.3-2.4$\\times$\nfaster FPS on mobile CPUs. Similar conclusions can be drawn for prototypical\nsystolic-array-based AI accelerators, where our BNNs promise 2.8-7$\\times$\nfewer execution cycles than 8-bit and 2.1-2.7$\\times$ fewer cycles than\nalternative BNN designs. These results suggest that the time for large-scale\nBNN adoption could be upon us.",
    "descriptor": "\nComments: 13 pages, 3 figures\n",
    "authors": [
      "Guhong Nie",
      "Lirui Xiao",
      "Menglong Zhu",
      "Dongliang Chu",
      "Yue Shen",
      "Peng Li",
      "Kang Yang",
      "Li Du",
      "Bo Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.03716"
  },
  {
    "id": "arXiv:2202.03721",
    "title": "Predicting and Visualizing Daily Mood of People Using Tracking Data of  Consumer Devices and Services",
    "abstract": "Users can easily export personal data from devices (e.g., weather station and\nfitness tracker) and services (e.g., screentime tracker and commits on GitHub)\nthey use but struggle to gain valuable insights. To tackle this problem, we\npresent the self-tracking meta app called InsightMe, which aims to show users\nhow data relate to their wellbeing, health, and performance. This paper focuses\non mood, which is closely associated with wellbeing. With data collected by one\nperson, we show how a person's sleep, exercise, nutrition, weather, air\nquality, screentime, and work correlate to the average mood the person\nexperiences during the day. Furthermore, the app predicts the mood via multiple\nlinear regression and a neural network, achieving an explained variance of 0.55\nand 0.50, respectively. We strive for explainability and transparency by\nshowing the users p-values of the correlations, drawing prediction intervals.\nIn addition, we conducted a small A-B test on illustrating how the original\ndata influence predictions. The source code and app are available online.",
    "descriptor": "",
    "authors": [
      "Christian Reiser"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2202.03721"
  },
  {
    "id": "arXiv:2202.03723",
    "title": "Hair Color Digitization through Imaging and Deep Inverse Graphics",
    "abstract": "Hair appearance is a complex phenomenon due to hair geometry and how the\nlight bounces on different hair fibers. For this reason, reproducing a specific\nhair color in a rendering environment is a challenging task that requires\nmanual work and expert knowledge in computer graphics to tune the result\nvisually. While current hair capture methods focus on hair shape estimation\nmany applications could benefit from an automated method for capturing the\nappearance of a physical hair sample, from augmented/virtual reality to hair\ndying development. Building on recent advances in inverse graphics and material\ncapture using deep neural networks, we introduce a novel method for hair color\ndigitization. Our proposed pipeline allows capturing the color appearance of a\nphysical hair sample and renders synthetic images of hair with a similar\nappearance, simulating different hair styles and/or lighting environments.\nSince rendering realistic hair images requires path-tracing rendering, the\nconventional inverse graphics approach based on differentiable rendering is\nuntractable. Our method is based on the combination of a controlled imaging\ndevice, a path-tracing renderer, and an inverse graphics model based on\nself-supervised machine learning, which does not require to use differentiable\nrendering to be trained. We illustrate the performance of our hair digitization\nmethod on both real and synthetic images and show that our approach can\naccurately capture and render hair color.",
    "descriptor": "\nComments: Electronic Imaging (EI) 2022\n",
    "authors": [
      "Robin Kips",
      "Panagiotis-Alexandros Bokaris",
      "Matthieu Perrot",
      "Pietro Gori",
      "Isabelle Bloch"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.03723"
  },
  {
    "id": "arXiv:2202.03725",
    "title": "A two-step approach to leverage contextual data: speech recognition in  air-traffic communications",
    "abstract": "Automatic Speech Recognition (ASR), as the assistance of speech communication\nbetween pilots and air-traffic controllers, can significantly reduce the\ncomplexity of the task and increase the reliability of transmitted information.\nASR application can lead to a lower number of incidents caused by\nmisunderstanding and improve air traffic management (ATM) efficiency.\nEvidently, high accuracy predictions, especially, of key information, i.e.,\ncallsigns and commands, are required to minimize the risk of errors. We prove\nthat combining the benefits of ASR and Natural Language Processing (NLP)\nmethods to make use of surveillance data (i.e. additional modality) helps to\nconsiderably improve the recognition of callsigns (named entity). In this\npaper, we investigate a two-step callsign boosting approach: (1) at the 1 step\n(ASR), weights of probable callsign n-grams are reduced in G.fst and/or in the\ndecoding FST (lattices), (2) at the 2 step (NLP), callsigns extracted from the\nimproved recognition outputs with Named Entity Recognition (NER) are correlated\nwith the surveillance data to select the most suitable one. Boosting callsign\nn-grams with the combination of ASR and NLP methods eventually leads up to\n53.7% of an absolute, or 60.4% of a relative, improvement in callsign\nrecognition.",
    "descriptor": "\nComments: 20XX IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works. arXiv admin note: text overlap with arXiv:2108.12156\n",
    "authors": [
      "Iuliia Nigmatulina",
      "Juan Zuluaga-Gomez",
      "Amrutha Prasad",
      "Seyyed Saeed Sarfjoo",
      "Petr Motlicek"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2202.03725"
  },
  {
    "id": "arXiv:2202.03726",
    "title": "Cyrus 2D Simulation Team Description Paper 2016",
    "abstract": "This description includes some explanation about algorithms and also\nalgorithms that are being implemented by Cyrus team members. The objectives of\nthis description are to express a brief explanation about shoot, block, mark\nand defensive decision will be given. It also explained about the parts that\nhas been implemented. The base code that Cyrus used is agent 3.11.",
    "descriptor": "\nComments: RoboCup 2016, Soccer Simulation 2D league\n",
    "authors": [
      "Nader Zare",
      "Ashkan Keshavarzi",
      "Seyed Ehsan Beheshtian",
      "Hadi Mowla",
      "Aryan Akbarpour",
      "Hossein Jafari",
      "Keyvan Arab Baraghi",
      "Mohammad Amin Zarifi",
      "Reza Javidan"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.03726"
  },
  {
    "id": "arXiv:2202.03728",
    "title": "The Weights can be Harmful: Pareto Search versus Weighted Search in  Multi-Objective Search-Based Software Engineering",
    "abstract": "In presence of multiple objectives to be optimized in Search-Based Software\nEngineering (SBSE), Pareto search has been commonly adopted. It searches for a\ngood approximation of the problem's Pareto optimal solutions, from which the\nstakeholders choose the most preferred solution according to their preferences.\nHowever, when clear preferences of the stakeholders (e.g., a set of weights\nwhich reflect relative importance between objectives) are available prior to\nthe search, weighted search is believed to be the first choice since it\nsimplifies the search via converting the original multi-objective problem into\na single-objective one and enable the search to focus on what only the\nstakeholders are interested in.\nThis paper questions such a \"weighted search first\" belief. We show that the\nweights can, in fact, be harmful to the search process even in the presence of\nclear preferences. Specifically, we conduct a large scale empirical study which\nconsists of 38 systems/projects from three representative SBSE problems,\ntogether with two types of search budget and nine sets of weights, leading to\n604 cases of comparisons. Our key finding is that weighted search reaches a\ncertain level of solution quality by consuming relatively less resources at the\nearly stage of the search; however, Pareto search is at the majority of the\ntime (up to 77% of the cases) significantly better than its weighted\ncounterpart, as long as we allow a sufficient, but not unrealistic search\nbudget. This, together with other findings and actionable suggestions in the\npaper, allows us to codify pragmatic and comprehensive guidance on choosing\nweighted and Pareto search for SBSE under the circumstance that clear\npreferences are available. All code and data can be accessed at:\nhttps://github.com/ideas-labo/pareto-vs-weight-for-sbse.",
    "descriptor": "\nComments: This paper has been accepted by the ACM Transactions on Software Engineering and Methodology (TOSEM); DOI: 10.1145/3514233\n",
    "authors": [
      "Tao Chen",
      "Miqing Li"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.03728"
  },
  {
    "id": "arXiv:2202.03730",
    "title": "Computing H-Partitions in ASP and Datalog",
    "abstract": "A $H$-partition of a finite undirected simple graph $G$ is a labeling of\n$G$'s vertices such that the constraints expressed by the model graph $H$ are\nsatisfied. For every model graph $H$, it can be decided in non-deterministic\npolynomial time whether a given input graph $G$ admits a $H$-partition.\nMoreover, it has been shown by Dantas et al. that for most model graphs, this\ndecision problem is in deterministic polynomial time. In this paper, we show\nthat these polynomial-time algorithms for finding $H$-partitions can be\nexpressed in Datalog with stratified negation. Moreover, using the answer set\nsolver Clingo, we have conducted experiments to compare straightforward\nguess-and-check programs with Datalog programs. Our experiments indicate that\nin Clingo, guess-and-check programs run faster than their equivalent Datalog\nprograms.",
    "descriptor": "\nComments: 17 pages, 8 figures\n",
    "authors": [
      "Chlo\u00e9 Capon",
      "Nicolas Lecomte",
      "Jef Wijsen"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2202.03730"
  },
  {
    "id": "arXiv:2202.03734",
    "title": "Cascaded Debiasing : Studying the Cumulative Effect of Multiple  Fairness-Enhancing Interventions",
    "abstract": "Understanding the cumulative effect of multiple fairness enhancing\ninterventions at different stages of the machine learning (ML) pipeline is a\ncritical and underexplored facet of the fairness literature. Such knowledge can\nbe valuable to data scientists/ML practitioners in designing fair ML pipelines.\nThis paper takes the first step in exploring this area by undertaking an\nextensive empirical study comprising 60 combinations of interventions, 9\nfairness metrics, 2 utility metrics (Accuracy and F1 Score) across 4 benchmark\ndatasets. We quantitatively analyze the experimental data to measure the impact\nof multiple interventions on fairness, utility and population groups. We found\nthat applying multiple interventions results in better fairness and lower\nutility than individual interventions on aggregate. However, adding more\ninterventions do no always result in better fairness or worse utility. The\nlikelihood of achieving high performance (F1 Score) along with high fairness\nincreases with larger number of interventions. On the downside, we found that\nfairness-enhancing interventions can negatively impact different population\ngroups, especially the privileged group. This study highlights the need for new\nfairness metrics that account for the impact on different population groups\napart from just the disparity between groups. Lastly, we offer a list of\ncombinations of interventions that perform best for different fairness and\nutility metrics to aid the design of fair ML pipelines.",
    "descriptor": "",
    "authors": [
      "Bhavya Ghai",
      "Mihir Mishra",
      "Klaus Mueller"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2202.03734"
  },
  {
    "id": "arXiv:2202.03735",
    "title": "Navigating to Objects in Unseen Environments by Distance Prediction",
    "abstract": "Object Goal Navigation (ObjectNav) task is to navigate an agent to an object\ninstance in unseen environments. The traditional navigation paradigm plans the\nshortest path on a pre-built map. Inspired by this, we propose an object goal\nnavigation framework, which could directly perform path planning based on an\nestimated distance map. Specifically, our model takes a birds-eye-view semantic\nmap as input, and estimates the distance from the map cells to the target\nobject based on the learned prior knowledge. With the estimated distance map,\nthe agent could explore the environment and navigate to the target objects\nbased on either human-designed or learned navigation policy. Empirical results\nin visually realistic simulation environments show that the proposed method\noutperforms a wide range of baselines on success rate and efficiency.",
    "descriptor": "\nComments: Tech report\n",
    "authors": [
      "Minzhao Zhu",
      "Binglei Zhao",
      "Tao Kong"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.03735"
  },
  {
    "id": "arXiv:2202.03740",
    "title": "Consistency-Regularized Region-Growing Network for Semantic Segmentation  of Urban Scenes with Point-Level Annotations",
    "abstract": "Deep learning algorithms have obtained great success in semantic segmentation\nof very high-resolution (VHR) images. Nevertheless, training these models\ngenerally requires a large amount of accurate pixel-wise annotations, which is\nvery laborious and time-consuming to collect. To reduce the annotation burden,\nthis paper proposes a consistency-regularized region-growing network (CRGNet)\nto achieve semantic segmentation of VHR images with point-level annotations.\nThe key idea of CRGNet is to iteratively select unlabeled pixels with high\nconfidence to expand the annotated area from the original sparse points.\nHowever, since there may exist some errors and noises in the expanded\nannotations, directly learning from them may mislead the training of the\nnetwork. To this end, we further propose the consistency regularization\nstrategy, where a base classifier and an expanded classifier are employed.\nSpecifically, the base classifier is supervised by the original sparse\nannotations, while the expanded classifier aims to learn from the expanded\nannotations generated by the base classifier with the region-growing mechanism.\nThe consistency regularization is thereby achieved by minimizing the\ndiscrepancy between the predictions from both the base and the expanded\nclassifiers. We find such a simple regularization strategy is yet very useful\nto control the quality of the region-growing mechanism. Extensive experiments\non two benchmark datasets demonstrate that the proposed CRGNet significantly\noutperforms the existing state-of-the-art methods. Codes and pre-trained models\nwill be available online.",
    "descriptor": "",
    "authors": [
      "Yonghao Xu",
      "Pedram Ghamisi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.03740"
  },
  {
    "id": "arXiv:2202.03747",
    "title": "STC: Spatio-Temporal Contrastive Learning for Video Instance  Segmentation",
    "abstract": "Video Instance Segmentation (VIS) is a task that simultaneously requires\nclassification, segmentation, and instance association in a video. Recent VIS\napproaches rely on sophisticated pipelines to achieve this goal, including\nRoI-related operations or 3D convolutions. In contrast, we present a simple and\nefficient single-stage VIS framework based on the instance segmentation method\nCondInst by adding an extra tracking head. To improve instance association\naccuracy, a novel bi-directional spatio-temporal contrastive learning strategy\nfor tracking embedding across frames is proposed. Moreover, an instance-wise\ntemporal consistency scheme is utilized to produce temporally coherent results.\nExperiments conducted on the YouTube-VIS-2019, YouTube-VIS-2021, and OVIS-2021\ndatasets validate the effectiveness and efficiency of the proposed method. We\nhope the proposed framework can serve as a simple and strong alternative for\nmany other instance-level video association tasks. Code will be made available.",
    "descriptor": "",
    "authors": [
      "Zhengkai Jiang",
      "Zhangxuan Gu",
      "Jinlong Peng",
      "Hang Zhou",
      "Liang Liu",
      "Yabiao Wang",
      "Ying Tai",
      "Chengjie Wang",
      "Liqing Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.03747"
  },
  {
    "id": "arXiv:2202.03748",
    "title": "On the implementation of an adaptive multirate framework for coupled  transport and flow",
    "abstract": "In this work, a multirate in time approach resolving the different time\nscales of a convection-dominated transport and coupled fluid flow is developed\nand studied in view of goal-oriented error control by means of the Dual\nWeighted Residual (DWR) method. Key ingredients are an arbitrary degree\ndiscontinuous Galerkin time discretization of the underlying subproblems, an a\nposteriori error representation for the transport problem coupled with flow and\nits implementation using space-time tensor-product spaces. The error\nrepresentation allows the separation of the temporal and spatial discretization\nerror which serve as local error indicators for adaptive mesh refinement. The\nperformance of the approach and its software implementation are studied by\nnumerical convergence examples as well as an example of physical interest for\nconvection-dominated transport.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2002.06855\n",
    "authors": [
      "Marius Paul Bruchh\u00e4user",
      "Uwe K\u00f6cher",
      "Markus Bause"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.03748"
  },
  {
    "id": "arXiv:2202.03749",
    "title": "CVA6's Data cache: Structure and Behavior",
    "abstract": "Since Spectre and Meltdown's disclosure in 2018, a new category of attacks\nhas been identified and characterized by the scientific community. The\nForeshadow attack, which was the first one to target Intel's secure enclave\ntechnology (namely SGX) has been developed shortly after. It opened the way to\nmicro architectural attacks on Intel's architecture, and led to the quick\ndevelopment of micro architectural attacks until today. While Spectre and\nMeltdown are often considered as the first micro architectural attacks, one can\nargue that cache attacks, as introduced by Osvik et al. in 2006, can be seen as\nthe first types of micro architectural attacks that were developed. Now, even\nthough there are many variants, they are still the most prominent type of micro\narchitectural attacks. One example of cache micro architectural covert-channel\nis the Prime+Probe. Lately targeting the Intel architecture, the micro\narchitectural attacks are now challenging a wider variety of CPUs. Recently,\nCPUs running the RISC-V Instruction Set Architecture have been targeted. One\nfamous and widely used RISC-V CPU is the ETH Zurich's CVA6 (formerly Ariane)\ncore. CVA6 is a 6-stage, single issue, in-order CPU. To the best of our\nknowledge, there is no existing document presenting very detailed aspects of\nthe CVA6's micro architecture, especially with respect to the data cache. Such\ninformation is mandatory to deeply understand any architectural or micro\narchitectural study successfully, such as the replication of the Prime+Probe\nattack on the CVA6 CPU proposed by Nils Wistoff. This paper presents the\nimplementation of the Data cache in the CVA6 CPU from OpenHW Group by focusing\non its memory structure and explaining through several examples what happens\nwhen a request for memory allocation occurs.",
    "descriptor": "\nComments: 13 pages, 10 figures, 1 table\n",
    "authors": [
      "Valentin Martinoli",
      "Yannick Teglia",
      "Abdellah Bouagoun",
      "R\u00e9gis Leveugle"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2202.03749"
  },
  {
    "id": "arXiv:2202.03753",
    "title": "Semantic features of object concepts generated with GPT-3",
    "abstract": "Semantic features have been playing a central role in investigating the\nnature of our conceptual representations. Yet the enormous time and effort\nrequired to empirically sample and norm features from human raters has\nrestricted their use to a limited set of manually curated concepts. Given\nrecent promising developments with transformer-based language models, here we\nasked whether it was possible to use such models to automatically generate\nmeaningful lists of properties for arbitrary object concepts and whether these\nmodels would produce features similar to those found in humans. To this end, we\nprobed a GPT-3 model to generate semantic features for 1,854 objects and\ncompared automatically-generated features to existing human feature norms.\nGPT-3 generated many more features than humans, yet showed a similar\ndistribution in the types of generated features. Generated feature norms\nrivaled human norms in predicting similarity, relatedness, and category\nmembership, while variance partitioning demonstrated that these predictions\nwere driven by similar variance in humans and GPT-3. Together, these results\nhighlight the potential of large language models to capture important facets of\nhuman knowledge and yield a new approach for automatically generating\ninterpretable feature sets, thus drastically expanding the potential use of\nsemantic features in psychological and linguistic studies.",
    "descriptor": "",
    "authors": [
      "Hannes Hansen",
      "Martin N. Hebart"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.03753"
  },
  {
    "id": "arXiv:2202.03755",
    "title": "Can We Generate Shellcodes via Natural Language? An Empirical Study",
    "abstract": "Writing software exploits is an important practice for offensive security\nanalysts to investigate and prevent attacks. In particular, shellcodes are\nespecially time-consuming and a technical challenge, as they are written in\nassembly language. In this work, we address the task of automatically\ngenerating shellcodes, starting purely from descriptions in natural language,\nby proposing an approach based on Neural Machine Translation (NMT). We then\npresent an empirical study using a novel dataset (Shellcode_IA32), which\nconsists of 3,200 assembly code snippets of real Linux/x86 shellcodes from\npublic databases, annotated using natural language. Moreover, we propose novel\nmetrics to evaluate the accuracy of NMT at generating shellcodes. The empirical\nanalysis shows that NMT can generate assembly code snippets from the natural\nlanguage with high accuracy and that in many cases can generate entire\nshellcodes with no errors.",
    "descriptor": "\nComments: 33 pages, 5 figures, 9 tables. To be published in Automated Software Engineering journal\n",
    "authors": [
      "Pietro Liguori",
      "Erfan Al-Hossami",
      "Domenico Cotroneo",
      "Roberto Natella",
      "Bojan Cukic",
      "Samira Shaikh"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.03755"
  },
  {
    "id": "arXiv:2202.03756",
    "title": "Consensus on Demand",
    "abstract": "Digital money can be implemented efficiently by avoiding consensus. However,\nno-consensus implementations have drawbacks, as they cannot support smart\ncontracts, and (even more fundamentally) they cannot deal with conflicting\ntransactions. We present a novel protocol that combines the benefits of an\nasynchronous, broadcast-based digital currency, with the capacity to perform\nconsensus. This is achieved by selectively performing consensus a posteriori,\ni.e., only when absolutely necessary. Our on-demand consensus comes at the\nprice of restricting the byzantine participants to be less than a one-fifth\nminority in the system, which we show to be the optimal threshold. We formally\nprove the correctness of our system and present an open-source implementation,\nwhich inherits many features from the Ethereum ecosystem.",
    "descriptor": "\nComments: 11 pages, 3 figues\n",
    "authors": [
      "Jakub Sliwinski",
      "Yann Vonlanthen",
      "Roger Wattenhofer"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.03756"
  },
  {
    "id": "arXiv:2202.03758",
    "title": "Practical Challenges in Differentially-Private Federated Survival  Analysis of Medical Data",
    "abstract": "Survival analysis or time-to-event analysis aims to model and predict the\ntime it takes for an event of interest to happen in a population or an\nindividual. In the medical context this event might be the time of dying,\nmetastasis, recurrence of cancer, etc. Recently, the use of neural networks\nthat are specifically designed for survival analysis has become more popular\nand an attractive alternative to more traditional methods. In this paper, we\ntake advantage of the inherent properties of neural networks to federate the\nprocess of training of these models. This is crucial in the medical domain\nsince data is scarce and collaboration of multiple health centers is essential\nto make a conclusive decision about the properties of a treatment or a disease.\nTo ensure the privacy of the datasets, it is common to utilize differential\nprivacy on top of federated learning. Differential privacy acts by introducing\nrandom noise to different stages of training, thus making it harder for an\nadversary to extract details about the data. However, in the realistic setting\nof small medical datasets and only a few data centers, this noise makes it\nharder for the models to converge. To address this problem, we propose\nDPFed-post which adds a post-processing stage to the private federated learning\nscheme. This extra step helps to regulate the magnitude of the noisy average\nparameter update and easier convergence of the model. For our experiments, we\nchoose 3 real-world datasets in the realistic setting when each health center\nhas only a few hundred records, and we show that DPFed-post successfully\nincreases the performance of the models by an average of up to $17\\%$ compared\nto the standard differentially private federated learning scheme.",
    "descriptor": "",
    "authors": [
      "Shadi Rahimian",
      "Raouf Kerkouche",
      "Ina Kurth",
      "Mario Fritz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.03758"
  },
  {
    "id": "arXiv:2202.03759",
    "title": "Time to Focus: A Comprehensive Benchmark Using Time Series Attribution  Methods",
    "abstract": "In the last decade neural network have made huge impact both in industry and\nresearch due to their ability to extract meaningful features from imprecise or\ncomplex data, and by achieving super human performance in several domains.\nHowever, due to the lack of transparency the use of these networks is hampered\nin the areas with safety critical areas. In safety-critical areas, this is\nnecessary by law. Recently several methods have been proposed to uncover this\nblack box by providing interpreation of predictions made by these models. The\npaper focuses on time series analysis and benchmark several state-of-the-art\nattribution methods which compute explanations for convolutional classifiers.\nThe presented experiments involve gradient-based and perturbation-based\nattribution methods. A detailed analysis shows that perturbation-based\napproaches are superior concerning the Sensitivity and occlusion game. These\nmethods tend to produce explanations with higher continuity. Contrarily, the\ngradient-based techniques are superb in runtime and Infidelity. In addition, a\nvalidation the dependence of the methods on the trained model, feasible\napplication domains, and individual characteristics is attached. The findings\naccentuate that choosing the best-suited attribution method is strongly\ncorrelated with the desired use case. Neither category of attribution methods\nnor a single approach has shown outstanding performance across all aspects.",
    "descriptor": "\nComments: 12 pages, 6 figures, 8 tables, Presented at ICAART 2022\n",
    "authors": [
      "Dominique Mercier",
      "Jwalin Bhatt",
      "Andreas Dengel",
      "Sheraz Ahmed"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.03759"
  },
  {
    "id": "arXiv:2202.03760",
    "title": "Modeling Structure with Undirected Neural Networks",
    "abstract": "Neural networks are powerful function estimators, leading to their status as\na paradigm of choice for modeling structured data. However, unlike other\nstructured representations that emphasize the modularity of the problem --\ne.g., factor graphs -- neural networks are usually monolithic mappings from\ninputs to outputs, with a fixed computation order. This limitation prevents\nthem from capturing different directions of computation and interaction between\nthe modeled variables.\nIn this paper, we combine the representational strengths of factor graphs and\nof neural networks, proposing undirected neural networks (UNNs): a flexible\nframework for specifying computations that can be performed in any order. For\nparticular choices, our proposed models subsume and extend many existing\narchitectures: feed-forward, recurrent, self-attention networks, auto-encoders,\nand networks with implicit layers. We demonstrate the effectiveness of\nundirected neural architectures, both unstructured and structured, on a range\nof tasks: tree-constrained dependency parsing, convolutional image\nclassification, and sequence completion with attention. By varying the\ncomputation order, we show how a single UNN can be used both as a classifier\nand a prototype generator, and how it can fill in missing parts of an input\nsequence, making them a promising field for further research.",
    "descriptor": "",
    "authors": [
      "Tsvetomila Mihaylova",
      "Vlad Niculae",
      "Andr\u00e9 F. T. Martins"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.03760"
  },
  {
    "id": "arXiv:2202.03762",
    "title": "Eliminating Sandwich Attacks with the Help of Game Theory",
    "abstract": "Predatory trading bots lurking in Ethereum's mempool present invisible\ntaxation of traders on automated market makers (AMMs). AMM traders specify a\nslippage tolerance to indicate the maximum price movement they are willing to\naccept. This way, traders avoid automatic transaction failure in case of small\nprice movements before their trade request executes. However, while a too-small\nslippage tolerance may lead to trade failures, a too-large tolerance allows\npredatory trading bots to profit from sandwich attacks. These bots can extract\nthe difference between the slippage tolerance and the actual price movement as\nprofit.\nIn this work, we introduce the sandwich game to analyze sandwich attacks\nanalytically from both the attacker and victim perspectives. Moreover, we\nprovide a simple and highly effective algorithm that traders can use to set the\nslippage. We unveil that the vast majority of broadcast transactions can avoid\nsandwich attacks while simultaneously only experiencing a low risk of\ntransaction failure. Thereby, we demonstrate that a constant auto-slippage\ncannot adjust to varying trade sizes and pool characteristics. Our algorithm\noutperforms the constant auto-slippage suggested by the biggest AMM, Uniswap,\nin all performed tests. Specifically, our algorithm repeatedly demonstrates a\ncost reduction exceeding a factor of 100.",
    "descriptor": "",
    "authors": [
      "Lioba Heimbach",
      "Roger Wattenhofer"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.03762"
  },
  {
    "id": "arXiv:2202.03770",
    "title": "Impact of Parameter Sparsity on Stochastic Gradient MCMC Methods for  Bayesian Deep Learning",
    "abstract": "Bayesian methods hold significant promise for improving the uncertainty\nquantification ability and robustness of deep neural network models. Recent\nresearch has seen the investigation of a number of approximate Bayesian\ninference methods for deep neural networks, building on both the variational\nBayesian and Markov chain Monte Carlo (MCMC) frameworks. A fundamental issue\nwith MCMC methods is that the improvements they enable are obtained at the\nexpense of increased computation time and model storage costs. In this paper,\nwe investigate the potential of sparse network structures to flexibly trade-off\nmodel storage costs and inference run time against predictive performance and\nuncertainty quantification ability. We use stochastic gradient MCMC methods as\nthe core Bayesian inference method and consider a variety of approaches for\nselecting sparse network structures. Surprisingly, our results show that\ncertain classes of randomly selected substructures can perform as well as\nsubstructures derived from state-of-the-art iterative pruning methods while\ndrastically reducing model training times.",
    "descriptor": "\nComments: Preprint. Work in progress\n",
    "authors": [
      "Meet P. Vadera",
      "Adam D. Cobb",
      "Brian Jalaian",
      "Benjamin M. Marlin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.03770"
  },
  {
    "id": "arXiv:2202.03771",
    "title": "Energy Management Based on Multi-Agent Deep Reinforcement Learning for A  Multi-Energy Industrial Park",
    "abstract": "Owing to large industrial energy consumption, industrial production has\nbrought a huge burden to the grid in terms of renewable energy access and power\nsupply. Due to the coupling of multiple energy sources and the uncertainty of\nrenewable energy and demand, centralized methods require large calculation and\ncoordination overhead. Thus, this paper proposes a multi-energy management\nframework achieved by decentralized execution and centralized training for an\nindustrial park. The energy management problem is formulated as a\npartially-observable Markov decision process, which is intractable by dynamic\nprogramming due to the lack of the prior knowledge of the underlying stochastic\nprocess. The objective is to minimize long-term energy costs while ensuring the\ndemand of users. To solve this issue and improve the calculation speed, a novel\nmulti-agent deep reinforcement learning algorithm is proposed, which contains\nthe following key points: counterfactual baseline for facilitating contributing\nagents to learn better policies, soft actor-critic for improving robustness and\nexploring optimal solutions. A novel reward is designed by Lagrange multiplier\nmethod to ensure the capacity constraints of energy storage. In addition,\nconsidering that the increase in the number of agents leads to performance\ndegradation due to large observation spaces, an attention mechanism is\nintroduced to enhance the stability of policy and enable agents to focus on\nimportant energy-related information, which improves the exploration efficiency\nof soft actor-critic. Numerical results based on actual data verify the\nperformance of the proposed algorithm with high scalability, indicating that\nthe industrial park can minimize energy costs under different demands.",
    "descriptor": "\nComments: Accepted by Applied Energy\n",
    "authors": [
      "Dafeng Zhu",
      "Bo Yang",
      "Yuxiang Liu",
      "Zhaojian Wang",
      "Kai Ma",
      "Xinping Guan"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.03771"
  },
  {
    "id": "arXiv:2202.03775",
    "title": "Addressing Data Scarcity in Multimodal User State Recognition by  Combining Semi-Supervised and Supervised Learning",
    "abstract": "Detecting mental states of human users is crucial for the development of\ncooperative and intelligent robots, as it enables the robot to understand the\nuser's intentions and desires. Despite their importance, it is difficult to\nobtain a large amount of high quality data for training automatic recognition\nalgorithms as the time and effort required to collect and label such data is\nprohibitively high. In this paper we present a multimodal machine learning\napproach for detecting dis-/agreement and confusion states in a human-robot\ninteraction environment, using just a small amount of manually annotated data.\nWe collect a data set by conducting a human-robot interaction study and develop\na novel preprocessing pipeline for our machine learning approach. By combining\nsemi-supervised and supervised architectures, we are able to achieve an average\nF1-score of 81.1\\% for dis-/agreement detection with a small amount of labeled\ndata and a large unlabeled data set, while simultaneously increasing the\nrobustness of the model compared to the supervised approach.",
    "descriptor": "",
    "authors": [
      "Hendric Vo\u00df",
      "Heiko Wersing",
      "Stefan Kopp"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.03775"
  },
  {
    "id": "arXiv:2202.03777",
    "title": "Optimal $L^2$ error estimates of the penalty finite element method for  the unsteady Navier-Stokes equations with nonsmooth initial data",
    "abstract": "In this paper, both semidiscrete and fully discrete finite element methods\nare analyzed for the penalized two-dimensional unsteady Navier-Stokes equations\nwith nonsmooth initial data. First order backward Euler method is applied for\nthe time discretization, whereas conforming finite element method is used for\nthe spatial discretization. Optimal $L^2$ error estimates for the semidiscrete\nas well as the fully discrete approximations of the velocity and of the\npressure are derived for realistically assumed conditions on the data. The main\ningredient in the proof is the appropriate exploitation of the inverse of the\npenalized Stokes operator, negative norm estimates and time weighted estimates.\nNumerical examples are discussed at the end which conform our theoretical\nresults.",
    "descriptor": "\nComments: 31 pages, 11 figures\n",
    "authors": [
      "Bikram Bir",
      "Deepjyoti Goswami",
      "Amiya K. Pani"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.03777"
  },
  {
    "id": "arXiv:2202.03784",
    "title": "SCR: Smooth Contour Regression with Geometric Priors",
    "abstract": "While object detection methods traditionally make use of pixel-level masks or\nbounding boxes, alternative representations such as polygons or active contours\nhave recently emerged. Among them, methods based on the regression of Fourier\nor Chebyshev coefficients have shown high potential on freeform objects. By\ndefining object shapes as polar functions, they are however limited to\nstar-shaped domains. We address this issue with SCR: a method that captures\nresolution-free object contours as complex periodic functions. The method\noffers a good compromise between accuracy and compactness thanks to the design\nof efficient geometric shape priors. We benchmark SCR on the popular COCO 2017\ninstance segmentation dataset, and show its competitiveness against existing\nalgorithms in the field. In addition, we design a compact version of our\nnetwork, which we benchmark on embedded hardware with a wide range of power\ntargets, achieving up to real-time performance.",
    "descriptor": "",
    "authors": [
      "Gaetan Bahl",
      "Lionel Daniel",
      "Florent Lafarge"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.03784"
  },
  {
    "id": "arXiv:2202.03785",
    "title": "Extended Object Tracking in Curvilinear Road Coordinates for Autonomous  Driving",
    "abstract": "In literature, Extended Object Tracking (EOT) algorithms developed for\nautonomous driving predominantly provide obstacles state estimation in\ncartesian coordinates in the Vehicle Reference Frame. However, in many\nscenarios, state representation in road-aligned curvilinear coordinates is\npreferred when implementing autonomous driving subsystems like cruise control,\nlane-keeping assist, platooning, etc. This paper proposes a Gaussian Mixture\nProbability Hypothesis Density~(GM-PHD) filter with an Unscented Kalman\nFilter~(UKF) estimator that provides obstacle state estimates in curvilinear\nroad coordinates. We employ a hybrid sensor fusion architecture between Lidar\nand Radar sensors to obtain rich measurement point representations for EOT. The\nmeasurement model for the UKF estimator is developed with the integration of\ncoordinate conversion from curvilinear road coordinates to cartesian\ncoordinates by using cubic hermit spline road model. The proposed algorithm is\nvalidated through Matlab Driving Scenario Designer simulation and experimental\ndata collected at Monza Eni Circuit.",
    "descriptor": "",
    "authors": [
      "Pragyan Dahal",
      "Simone Mentasti",
      "Stefano Arrigoni",
      "Francesco Braghin",
      "Matteo Matteucci",
      "Federico Cheli"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.03785"
  },
  {
    "id": "arXiv:2202.03786",
    "title": "Coordination of resources at the edge of the electricity grid:  systematic review and taxonomy",
    "abstract": "This paper proposes a novel taxonomy of coordination strategies for\ndistributed energy resources at the edge of the electricity grid, based on a\nsystematic analysis of key literature trends. The coordination of distributed\nenergy resources such as decentralised generation and flexibility sources is\ncritical for decarbonising electricity and achieving climate goals. The\nliterature on the topic is growing exponentially; however, there is ambiguity\nin the terminology used to date. We seek to resolve this lack of clarity by\nsynthesising the categories of coordination strategies in a novel exhaustive,\nmutually exclusive taxonomy based on agency, information and game type. The\nrelevance of these concepts in the literature is illustrated through a\nsystematic literature review of 84,741 publications using a structured topic\nsearch query. Then 93 selected coordination strategies are analysed in more\ndetail and mapped onto this framework. Clarity on structural assumptions is key\nfor selecting appropriate coordination strategies for differing contexts within\nenergy systems. We argue that a plurality of complementary strategies is needed\nto coordinate energy systems' different components and achieve deep\ndecarbonisation.",
    "descriptor": "\nComments: 28 pages, 4 figures\n",
    "authors": [
      "Flora Charbonnier",
      "Thomas Morstyn",
      "Malcolm McCulloch"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.03786"
  },
  {
    "id": "arXiv:2202.03791",
    "title": "A Kleene Theorem for Higher-Dimensional Automata",
    "abstract": "We prove a Kleene theorem for higher-dimensional automata. It states that the\nlanguages they recognise are precisely the rational subsumption-closed sets of\nlabelled interval orders. Higher-dimensional automata are general models of\nconcurrency that subsume, for instance, Petri nets, event structures and\nasynchronous transition systems. We formalise them as presheaves over labelled\nprecube categories. Interval orders are used as non-interleaving semantics of\nconcurrent or distributed systems where events have duration. For the proof, we\nintroduce higher-dimensional automata with interfaces and several tools\ninspired by model categories, such as cylinders, necessary for handling cycles,\nand (co)fibrations.",
    "descriptor": "",
    "authors": [
      "Uli Fahrenberg",
      "Christian Johansen",
      "Georg Struth",
      "Krzysztof Ziemia\u0144ski"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Algebraic Topology (math.AT)"
    ],
    "url": "https://arxiv.org/abs/2202.03791"
  },
  {
    "id": "arXiv:2202.03792",
    "title": "Counterfactual Multi-Token Fairness in Text Classification",
    "abstract": "The counterfactual token generation has been limited to perturbing only a\nsingle token in texts that are generally short and single sentences. These\ntokens are often associated with one of many sensitive attributes. With limited\ncounterfactuals generated, the goal to achieve invariant nature for machine\nlearning classification models towards any sensitive attribute gets bounded,\nand the formulation of Counterfactual Fairness gets narrowed. In this paper, we\novercome these limitations by solving root problems and opening bigger domains\nfor understanding. We have curated a resource of sensitive tokens and their\ncorresponding perturbation tokens, even extending the support beyond\ntraditionally used sensitive attributes like \\textit{Age}, \\textit{Gender}, and\n\\textit{Race} to \\textit{Nationality}, \\textit{Disability}, and\n\\textit{Religion}. The concept of Counterfactual Generation has been extended\nto multi-token support valid over all forms of texts and documents. We define\nthe method of generating counterfactuals by perturbing multiple sensitive\ntokens as \\textbf{Counterfactual Multi-token Generation}. The method has been\nconceptualized to showcase significant performance improvement over\nsingle-token methods and validated over multiple benchmark datasets. The\nemendation in counterfactual generation propagates in achieving improved\n\\textbf{Counterfactual Multi-token Fairness}.",
    "descriptor": "",
    "authors": [
      "Pranay Lohia"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.03792"
  },
  {
    "id": "arXiv:2202.03795",
    "title": "Feature subset selection for Big Data via Chaotic Binary Differential  Evolution under Apache Spark",
    "abstract": "Feature subset selection (FSS) using a wrapper approach is essentially a\ncombinatorial optimization problem having two objective functions namely\ncardinality of the selected-feature-subset, which should be minimized and the\ncorresponding area under the ROC curve (AUC) to be maximized. In this research\nstudy, we propose a novel multiplicative single objective function involving\ncardinality and AUC. The randomness involved in the Binary Differential\nEvolution (BDE) may yield less diverse solutions thereby getting trapped in\nlocal minima. Hence, we embed Logistic and Tent chaotic maps into the BDE and\nnamed it as Chaotic Binary Differential Evolution (CBDE). Designing a scalable\nsolution to the FSS is critical when dealing with high-dimensional and\nvoluminous datasets. Hence, we propose a scalable island (iS) based\nparallelization approach where the data is divided into multiple\npartitions/islands thereby the solution evolves individually and gets combined\neventually in a migration strategy. The results empirically show that the\nproposed parallel Chaotic Binary Differential Evolution (P-CBDE-iS) is able to\nfind the better quality feature subsets than the Parallel Bi-nary Differential\nEvolution (P-BDE-iS). Logistic Regression (LR) is used as a classifier owing to\nits simplicity and power. The speedup attained by the proposed parallel\napproach signifies the importance.",
    "descriptor": "\nComments: 14 pages; 3 figures; 6 tables\n",
    "authors": [
      "Yelleti Vivek",
      "Vadlamani Ravi",
      "P. Radhakrishna"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2202.03795"
  },
  {
    "id": "arXiv:2202.03799",
    "title": "What are the best systems? New perspectives on NLP Benchmarking",
    "abstract": "In Machine Learning, a benchmark refers to an ensemble of datasets associated\nwith one or multiple metrics together with a way to aggregate different systems\nperformances. They are instrumental in (i) assessing the progress of new\nmethods along different axes and (ii) selecting the best systems for practical\nuse. This is particularly the case for NLP with the development of large\npre-trained models (e.g. GPT, BERT) that are expected to generalize well on a\nvariety of tasks. While the community mainly focused on developing new datasets\nand metrics, there has been little interest in the aggregation procedure, which\nis often reduced to a simple average over various performance measures.\nHowever, this procedure can be problematic when the metrics are on a different\nscale, which may lead to spurious conclusions. This paper proposes a new\nprocedure to rank systems based on their performance across different tasks.\nMotivated by the social choice theory, the final system ordering is obtained\nthrough aggregating the rankings induced by each task and is theoretically\ngrounded. We conduct extensive numerical experiments (on over 270k scores) to\nassess the soundness of our approach both on synthetic and real scores (e.g.\nGLUE, EXTREM, SEVAL, TAC, FLICKR). In particular, we show that our method\nyields different conclusions on state-of-the-art systems than the\nmean-aggregation procedure while being both more reliable and robust.",
    "descriptor": "",
    "authors": [
      "Pierre Colombo",
      "Nathan Noiry",
      "Ekhine Irurozki",
      "Stephan Clemencon"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.03799"
  },
  {
    "id": "arXiv:2202.03800",
    "title": "Ada-NETS: Face Clustering via Adaptive Neighbour Discovery in the  Structure Space",
    "abstract": "Face clustering has attracted rising research interest recently to take\nadvantage of massive amounts of face images on the web. State-of-the-art\nperformance has been achieved by Graph Convolutional Networks (GCN) due to\ntheir powerful representation capacity. However, existing GCN-based methods\nbuild face graphs mainly according to kNN relations in the feature space, which\nmay lead to a lot of noise edges connecting two faces of different classes. The\nface features will be polluted when messages pass along these noise edges, thus\ndegrading the performance of GCNs. In this paper, a novel algorithm named\nAda-NETS is proposed to cluster faces by constructing clean graphs for GCNs. In\nAda-NETS, each face is transformed to a new structure space, obtaining robust\nfeatures by considering face features of the neighbour images. Then, an\nadaptive neighbour discovery strategy is proposed to determine a proper number\nof edges connecting to each face image. It significantly reduces the noise\nedges while maintaining the good ones to build a graph with clean yet rich\nedges for GCNs to cluster faces. Experiments on multiple public clustering\ndatasets show that Ada-NETS significantly outperforms current state-of-the-art\nmethods, proving its superiority and generalization.",
    "descriptor": "",
    "authors": [
      "Yaohua Wang",
      "Yaobin Zhang",
      "Fangyi Zhang",
      "Senzhang Wang",
      "Ming Lin",
      "YuQi Zhang",
      "Xiuyu Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.03800"
  },
  {
    "id": "arXiv:2202.03803",
    "title": "Private Information Delivery with Coded Storage",
    "abstract": "In private information delivery (PID) problem, there are $K$ messages stored\nacross $N$ servers, each capable of storing $M$ messages and a user. Servers\nwant to convey one of the $K$ messages to the user without revealing the\nidentity (index) of the message conveyed. The capacity of PID problem is\ndefined as maximum number of bits of the desired message that can be conveyed\nprivately, per bit of total communication, to the user. For the restricted case\nof replicated systems, where coded messages or splitting one message into\nseveral servers is not allowed, the capacity of PID has been characterized by\nHua Sun in \"Private Information Delivery, IEEE Transactions on Information\nTheory, December 2020\" in terms of $K, N$ and $M.$ In this paper, we study the\nproblem of PID with coded storage at the servers. For a class of problems\ncalled {\\it bi-regular PID} we characterize the capacity for $N=K/M$ and for\n$N>K/M$ we provide an achievable scheme. In both the cases the rates achieved\nare more than the rates achievable with the replicated systems.",
    "descriptor": "\nComments: 8 pages, 3 figures\n",
    "authors": [
      "Kanishak Vaidya",
      "B Sundar Rajan"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.03803"
  },
  {
    "id": "arXiv:2202.03805",
    "title": "Quantifying the topic disparity of scientific articles",
    "abstract": "Citation count is a popular index for assessing scientific papers. However,\nit depends on not only the quality of a paper but also various factors, such as\nconventionality, team size, and gender. Here, we examine the extent to which\nthe conventionality of a paper is related to its citation percentile in a\ndiscipline by using our measure, topic disparity. The topic disparity is the\ncosine distance between a paper and its discipline on a neural embedding space.\nUsing this measure, we show that the topic disparity is negatively associated\nwith the citation percentile in many disciplines, even after controlling team\nsize and the genders of the first and last authors. This result indicates that\nless conventional research tends to receive fewer citations than conventional\nresearch. Our proposed method can be used to complement the raw citation counts\nand to recommend papers at the periphery of a discipline because of their less\nconventional topics.",
    "descriptor": "\nComments: 5 pages, 2 figures\n",
    "authors": [
      "Munjung Kim",
      "Jisung Yoon",
      "Woo-Sung Jung",
      "Hyunuk Kim"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2202.03805"
  },
  {
    "id": "arXiv:2202.03807",
    "title": "Indy Autonomous Challenge -- Autonomous Race Cars at the Handling Limits",
    "abstract": "Motorsport has always been an enabler for technological advancement, and the\nsame applies to the autonomous driving industry. The team TUM Auton-omous\nMotorsports will participate in the Indy Autonomous Challenge in Octo-ber 2021\nto benchmark its self-driving software-stack by racing one out of ten\nautonomous Dallara AV-21 racecars at the Indianapolis Motor Speedway. The first\npart of this paper explains the reasons for entering an autonomous vehicle race\nfrom an academic perspective: It allows focusing on several edge cases\nen-countered by autonomous vehicles, such as challenging evasion maneuvers and\nunstructured scenarios. At the same time, it is inherently safe due to the\nmotor-sport related track safety precautions. It is therefore an ideal testing\nground for the development of autonomous driving algorithms capable of\nmastering the most challenging and rare situations. In addition, we provide\ninsight into our soft-ware development workflow and present our\nHardware-in-the-Loop simulation setup. It is capable of running simulations of\nup to eight autonomous vehicles in real time. The second part of the paper\ngives a high-level overview of the soft-ware architecture and covers our\ndevelopment priorities in building a high-per-formance autonomous racing\nsoftware: maximum sensor detection range, relia-ble handling of multi-vehicle\nsituations, as well as reliable motion control under uncertainty.",
    "descriptor": "",
    "authors": [
      "Alexander Wischnewski",
      "Maximilian Geisslinger",
      "Johannes Betz",
      "Tobias Betz",
      "Felix Fent",
      "Alexander Heilmeier",
      "Leonhard Hermansdorfer",
      "Thomas Herrmann",
      "Sebastian Huch",
      "Phillip Karle",
      "Felix Nobis",
      "Levent \u00d6gretmen",
      "Matthias Rowold",
      "Florian Sauerbeck",
      "Tim Stahl",
      "Rainer Trauth",
      "Markus Lienkamp",
      "Boris Lohmann"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.03807"
  },
  {
    "id": "arXiv:2202.03808",
    "title": "NIMSA: Non-Interactive Multihoming Security Authentication Scheme for  vehicular communications in Mobile Heterogeneous Networks",
    "abstract": "In vehicular communications, in-vehicle devices' mobile and multihoming\ncharacteristics bring new requirements for devicevsecurity authentication. On\nthe one hand, the existing network layer authentication methods rely on the PKI\nsystem; on the other hand, key negotiation needs interaction. These two points\ndetermine that the traditional security authentication method requires\nbandwidth consumption and additional delay. It is unsuitable for heterogeneous\nwireless scenarios with a high packet loss rate and limited bandwidth\nresources. In addition, the establishment of a security association state is\ncontrary to the original design that the network layer only provides a\nforwarding function. We proposed a non-interactive multihoming security\nauthentication (NIMSA) scheme, a stateless network layer security\nauthentication scheme triggered by data forwarding. Our scheme adopts an\nidentity-based non-interactive key agreement strategy to avoid the interaction\nof signaling information, which is lightweight and has good support for mobile\nand multipath parallel transmission scenarios. The comparison with IKEv2 and\nits mobility and multihoming extension scheme (MOBIKE) shows that the proposed\nscheme has shorter authentication and handover delay and data transmission\ndelay and can bring better bandwidth aggregation effect in the scenario of\nmultipath parallel transmission.",
    "descriptor": "",
    "authors": [
      "Zongzheng Wang",
      "Ping Dong"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2202.03808"
  },
  {
    "id": "arXiv:2202.03811",
    "title": "Predictive Beamforming for Integrated Sensing and Communication in  Vehicular Networks: A Deep Learning Approach",
    "abstract": "The implementation of integrated sensing and communication (ISAC) highly\ndepends on the effective beamforming design exploiting accurate instantaneous\nchannel state information (ICSI). However, channel tracking in ISAC requires\nlarge amount of training overhead and prohibitively large computational\ncomplexity. To address this problem, in this paper, we focus on ISAC-assisted\nvehicular networks and exploit a deep learning approach to implicitly learn the\nfeatures of historical channels and directly predict the beamforming matrix for\nthe next time slot to maximize the average achievable sum-rate of system, thus\nbypassing the need of explicit channel tracking for reducing the system\nsignaling overhead. To this end, a general sum-rate maximization problem with\nCramer-Rao lower bounds-based sensing constraints is first formulated for the\nconsidered ISAC system. Then, a historical channels-based convolutional long\nshort-term memory network is designed for predictive beamforming that can\nexploit the spatial and temporal dependencies of communication channels to\nfurther improve the learning performance. Finally, simulation results show that\nthe proposed method can satisfy the requirement of sensing performance, while\nits achievable sum-rate can approach the upper bound obtained by a genie-aided\nscheme with perfect ICSI available.",
    "descriptor": "\nComments: 8 pages, 5 figures, this work has been accepted by ICC 2022\n",
    "authors": [
      "Chang Liu",
      "Weijie Yuan",
      "Shuangyang Li",
      "Xuemeng Liu",
      "Derrick Wing Kwan Ng",
      "Yonghui Li"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.03811"
  },
  {
    "id": "arXiv:2202.03814",
    "title": "Optimal Transport of Binary Classifiers to Fairness",
    "abstract": "Much of the past work on fairness in machine learning has focused on forcing\nthe predictions of classifiers to have similar statistical properties for\nindividuals of different demographics. Yet, such methods often simply perform a\nrescaling of the classifier scores and ignore whether individuals of different\ngroups have similar features. Our proposed method, Optimal Transport to\nFairness (OTF), applies Optimal Transport (OT) to take this similarity into\naccount by quantifying unfairness as the smallest cost of OT between a\nclassifier and any score function that satisfies fairness constraints. For a\nflexible class of linear fairness constraints, we show a practical way to\ncompute OTF as an unfairness cost term that can be added to any standard\nclassification setting. Experiments show that OTF can be used to achieve an\neffective trade-off between predictive power and fairness.",
    "descriptor": "",
    "authors": [
      "Maarten Buyl",
      "Tijl De Bie"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.03814"
  },
  {
    "id": "arXiv:2202.03817",
    "title": "New results on vectorial dual-bent functions and partial difference sets",
    "abstract": "Bent functions $f: V_{n}\\rightarrow \\mathbb{F}_{p}$ with certain additional\nproperties play an important role in constructing partial difference sets,\nwhere $V_{n}$ denotes an $n$-dimensional vector space over $\\mathbb{F}_{p}$,\n$p$ is an odd prime. In \\cite{Cesmelioglu1,Cesmelioglu2}, the so-called\nvectorial dual-bent functions are considered to construct partial difference\nsets. In \\cite{Cesmelioglu1}, \\c{C}e\\c{s}melio\\v{g}lu \\emph{et al.} showed that\nfor vectorial dual-bent functions $F: V_{n}\\rightarrow V_{s}$ with certain\nadditional properties, the preimage set of $0$ for $F$ forms a partial\ndifference set. In \\cite{Cesmelioglu2}, \\c{C}e\\c{s}melio\\v{g}lu \\emph{et al.}\nshowed that for a class of Maiorana-McFarland vectorial dual-bent functions $F:\nV_{n}\\rightarrow \\mathbb{F}_{p^s}$, the preimage set of the squares\n(non-squares) in $\\mathbb{F}_{p^s}^{*}$ for $F$ forms a partial difference set.\nIn this paper, we further study vectorial dual-bent functions and partial\ndifference sets. We prove that for vectorial dual-bent functions $F:\nV_{n}\\rightarrow \\mathbb{F}_{p^s}$ with certain additional properties, the\npreimage set of the squares (non-squares) in $\\mathbb{F}_{p^s}^{*}$ for $F$ and\nthe preimage set of any coset of some subgroup of $\\mathbb{F}_{p^s}^{*}$ for\n$F$ form partial difference sets. Furthermore, explicit constructions of\npartial difference sets are yielded from some (non)-quadratic vectorial\ndual-bent functions. In this paper, we illustrate that almost all the results\nof using weakly regular $p$-ary bent functions to construct partial difference\nsets are special cases of our results.",
    "descriptor": "",
    "authors": [
      "Jiaxin Wang",
      "Fang-Wei Fu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.03817"
  },
  {
    "id": "arXiv:2202.03822",
    "title": "A Novel Plug-in Module for Fine-Grained Visual Classification",
    "abstract": "Visual classification can be divided into coarse-grained and fine-grained\nclassification. Coarse-grained classification represents categories with a\nlarge degree of dissimilarity, such as the classification of cats and dogs,\nwhile fine-grained classification represents classifications with a large\ndegree of similarity, such as cat species, bird species, and the makes or\nmodels of vehicles. Unlike coarse-grained visual classification, fine-grained\nvisual classification often requires professional experts to label data, which\nmakes data more expensive. To meet this challenge, many approaches propose to\nautomatically find the most discriminative regions and use local features to\nprovide more precise features. These approaches only require image-level\nannotations, thereby reducing the cost of annotation. However, most of these\nmethods require two- or multi-stage architectures and cannot be trained\nend-to-end. Therefore, we propose a novel plug-in module that can be integrated\nto many common backbones, including CNN-based or Transformer-based networks to\nprovide strongly discriminative regions. The plugin module can output\npixel-level feature maps and fuse filtered features to enhance fine-grained\nvisual classification. Experimental results show that the proposed plugin\nmodule outperforms state-of-the-art approaches and significantly improves the\naccuracy to 92.77\\% and 92.83\\% on CUB200-2011 and NABirds, respectively. We\nhave released our source code in Github\nhttps://github.com/chou141253/FGVC-PIM.git.",
    "descriptor": "",
    "authors": [
      "Po-Yung Chou",
      "Cheng-Hung Lin",
      "Wen-Chung Kao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.03822"
  },
  {
    "id": "arXiv:2202.03825",
    "title": "skrl: Modular and Flexible Library for Reinforcement Learning",
    "abstract": "skrl is an open-source modular library for reinforcement learning written in\nPython and designed with a focus on readability, simplicity, and transparency\nof algorithm implementations. Apart from supporting environments that use the\ntraditional OpenAI Gym interface, it allows loading, configuring, and operating\nNVIDIA Isaac Gym environments, enabling the parallel training of several agents\nwith adjustable scopes, which may or may not share resources, in the same\nexecution. The library's documentation can be found at\nhttps://skrl.readthedocs.io and its source code is available on GitHub at\nurl{https://github.com/Toni-SM/skrl.",
    "descriptor": "\nComments: 6 pages, 7 figures\n",
    "authors": [
      "Antonio Serrano-Mu\u00f1oz",
      "Nestor Arana-Arexolaleiba",
      "Dimitrios Chrysostomou",
      "Simon B\u00f8gh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.03825"
  },
  {
    "id": "arXiv:2202.03829",
    "title": "TimeLMs: Diachronic Language Models from Twitter",
    "abstract": "Despite its importance, the time variable has been largely neglected in the\nNLP and language model literature. In this paper, we present TimeLMs, a set of\nlanguage models specialized on diachronic Twitter data. We show that a\ncontinual learning strategy contributes to enhancing Twitter-based language\nmodels' capacity to deal with future and out-of-distribution tweets, while\nmaking them competitive with standardized and more monolithic benchmarks. We\nalso perform a number of qualitative analyses showing how they cope with trends\nand peaks in activity involving specific named entities or concept drift.",
    "descriptor": "\nComments: GitHub: this https URL\n",
    "authors": [
      "Daniel Loureiro",
      "Francesco Barbieri",
      "Leonardo Neves",
      "Luis Espinosa Anke",
      "Jose Camacho-Collados"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.03829"
  },
  {
    "id": "arXiv:2202.03832",
    "title": "Joint position and trajectory optimization of flying base station in 5G  cellular networks, based on users' current and predicted location",
    "abstract": "Nowadays, Unmanned Aerial Vehicles (UAVs) have been significantly improved,\nand one of their most important applications is to provide temporary coverage\nfor cellular users. Static Base Station cannot service all users due to\ntemporary crashes because of temporary events such as ground BS breakdowns, bad\nweather conditions, natural disasters, transmission errors, etc., drones\nequipped with small cellular BS. The Drone Base Station is immediately sent to\nthe target location and establishes the necessary communication links without\nrequiring any predetermined infrastructure and covers that area. Finding the\noptimal location and the appropriate number (DBS) of drone-BS in this area is a\nchallenge. Therefore, in this paper, the optimal location and optimal number of\nDBSs are distributed in the current state of the users and the subsequent user\nstates determined by the prediction. Finally, the DBS transition is optimized\nfrom the current state to the predicted future locations. The simulation\nresults show that the proposed method can provide acceptable coverage on the\nnetwork.",
    "descriptor": "",
    "authors": [
      "Mehdi Sookhak",
      "Amir Hossein Mohajerzadeh"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.03832"
  },
  {
    "id": "arXiv:2202.03834",
    "title": "FSM: FBS Set Management, An energy efficient multi-drone 3D trajectory  approach in cellular networks",
    "abstract": "In this paper, we consider a cellular network demand in an urban area. We aim\nto cover users and serve their required data rate in a period of time using a\n5G cellular network. The type of considered UAV in this scenario is The Scout\nB- 330 UAV helicopter which can fly up to 3 km height. In these scenarios, to\nfind the most proper trajectory of UAVs, we first must find the best positions\nof UAVs in different snapshots. We consider orthogonal frequency reuse to avoid\ninterference between UAVs in the network. We also consider the number of\ncommunication channels constraint in intra cellular network. To find the\noptimum position of UAVs in each snapshot. We consider Non-Line of Sight (NLoS)\npath loss in these scenarios and aim to cover all users in each snapshot. To\nfind the optimum trajectory of UAVs, we propose a mathematical model based on\ntransportation problem to minimize the total distance tracked by UAVs. In each\nstep we solve the proposed mathematical model for transiting UAVs between two\nsnapshots. We also consider that users can be placed in different altitudes an\ntheir positions follows the Poison Point Process distribution and their\nmobility follows the random way point. The UAVs battery and flight limitations\nare also considered. To tackle the energy problem we introduce the Drone Cell\nOff (DCO) approach to avoid losing energy in idle hover mode.",
    "descriptor": "",
    "authors": [
      "Mehdi Sookhak",
      "Amir Hossein Mohajerzadeh"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.03834"
  },
  {
    "id": "arXiv:2202.03836",
    "title": "An Improved Analysis of Gradient Tracking for Decentralized Machine  Learning",
    "abstract": "We consider decentralized machine learning over a network where the training\ndata is distributed across $n$ agents, each of which can compute stochastic\nmodel updates on their local data. The agent's common goal is to find a model\nthat minimizes the average of all local loss functions. While gradient tracking\n(GT) algorithms can overcome a key challenge, namely accounting for differences\nbetween workers' local data distributions, the known convergence rates for GT\nalgorithms are not optimal with respect to their dependence on the mixing\nparameter $p$ (related to the spectral gap of the connectivity matrix).\nWe provide a tighter analysis of the GT method in the stochastic strongly\nconvex, convex and non-convex settings. We improve the dependency on $p$ from\n$\\mathcal{O}(p^{-2})$ to $\\mathcal{O}(p^{-1}c^{-1})$ in the noiseless case and\nfrom $\\mathcal{O}(p^{-3/2})$ to $\\mathcal{O}(p^{-1/2}c^{-1})$ in the general\nstochastic case, where $c \\geq p$ is related to the negative eigenvalues of the\nconnectivity matrix (and is a constant in most practical applications). This\nimprovement was possible due to a new proof technique which could be of\nindependent interest.",
    "descriptor": "\nComments: published at NeurIPS 2021\n",
    "authors": [
      "Anastasia Koloskova",
      "Tao Lin",
      "Sebastian U. Stich"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2202.03836"
  },
  {
    "id": "arXiv:2202.03841",
    "title": "Width is Less Important than Depth in ReLU Neural Networks",
    "abstract": "We solve an open question from Lu et al. (2017), by showing that any target\nnetwork with inputs in $\\mathbb{R}^d$ can be approximated by a width $O(d)$\nnetwork (independent of the target network's architecture), whose number of\nparameters is essentially larger only by a linear factor. In light of previous\ndepth separation theorems, which imply that a similar result cannot hold when\nthe roles of width and depth are interchanged, it follows that depth plays a\nmore significant role than width in the expressive power of neural networks.\nWe extend our results to constructing networks with bounded weights, and to\nconstructing networks with width at most $d+2$, which is close to the minimal\npossible width due to previous lower bounds. Both of these constructions cause\nan extra polynomial factor in the number of parameters over the target network.\nWe also show an exact representation of wide and shallow networks using deep\nand narrow networks which, in certain cases, does not increase the number of\nparameters over the target network.",
    "descriptor": "",
    "authors": [
      "Gal Vardi",
      "Gilad Yehudai",
      "Ohad Shamir"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.03841"
  },
  {
    "id": "arXiv:2202.03843",
    "title": "A Unified Multi-Task Learning Framework of Real-Time Drone Supervision  for Crowd Counting",
    "abstract": "In this paper, a novel Unified Multi-Task Learning Framework of Real-Time\nDrone Supervision for Crowd Counting (MFCC) is proposed, which utilizes an\nimage fusion network architecture to fuse images from the visible and thermal\ninfrared image, and a crowd counting network architecture to estimate the\ndensity map. The purpose of our framework is to fuse two modalities, including\nvisible and thermal infrared images captured by drones in real-time, that\nexploit the complementary information to accurately count the dense population\nand then automatically guide the flight of the drone to supervise the dense\ncrowd. To this end, we propose the unified multi-task learning framework for\ncrowd counting for the first time and re-design the unified training loss\nfunctions to align the image fusion network and crowd counting network. We also\ndesign the Assisted Learning Module (ALM) to fuse the density map feature to\nthe image fusion encoder process for learning the counting features. To improve\nthe accuracy, we propose the Extensive Context Extraction Module (ECEM) that is\nbased on a dense connection architecture to encode multi-receptive-fields\ncontextual information and apply the Multi-domain Attention Block (MAB) for\nconcerning the head region in the drone view. Finally, we apply the prediction\nmap to automatically guide the drones to supervise the dense crowd. The\nexperimental results on the DroneRGBT dataset show that, compared with the\nexisting methods, ours has comparable results on objective evaluations and an\neasier training process.",
    "descriptor": "",
    "authors": [
      "Siqi Gu",
      "Zhichao Lian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.03843"
  },
  {
    "id": "arXiv:2202.03844",
    "title": "EvoPruneDeepTL: An Evolutionary Pruning Model for Transfer Learning  based Deep Neural Networks",
    "abstract": "In recent years, Deep Learning models have shown a great performance in\ncomplex optimization problems. They generally require large training datasets,\nwhich is a limitation in most practical cases. Transfer learning allows\nimporting the first layers of a pre-trained architecture and connecting them to\nfully-connected layers to adapt them to a new problem. Consequently, the\nconfiguration of the these layers becomes crucial for the performance of the\nmodel. Unfortunately, the optimization of these models is usually a\ncomputationally demanding task. One strategy to optimize Deep Learning models\nis the pruning scheme. Pruning methods are focused on reducing the complexity\nof the network, assuming an expected performance penalty of the model once\npruned. However, the pruning could potentially be used to improve the\nperformance, using an optimization algorithm to identify and eventually remove\nunnecessary connections among neurons. This work proposes EvoPruneDeepTL, an\nevolutionary pruning model for Transfer Learning based Deep Neural Networks\nwhich replaces the last fully-connected layers with sparse layers optimized by\na genetic algorithm. Depending on its solution encoding strategy, our proposed\nmodel can either perform optimized pruning or feature selection over the\ndensely connected part of the neural network. We carry out different\nexperiments with several datasets to assess the benefits of our proposal.\nResults show the contribution of EvoPruneDeepTL and feature selection to the\noverall computational efficiency of the network as a result of the optimization\nprocess. In particular, the accuracy is improved reducing at the same time the\nnumber of active neurons in the final layers.",
    "descriptor": "",
    "authors": [
      "Javier Poyatos",
      "Daniel Molina",
      "Aritz. D. Martinez",
      "Javier Del Ser",
      "Francisco Herrera"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2202.03844"
  },
  {
    "id": "arXiv:2202.03845",
    "title": "BeeHIVE: Behavioral Biometric System based on Object Interactions in  Smart Environments",
    "abstract": "The lack of standard input interfaces in Internet of Things (IoT) ecosystems\npresents a challenge in securing such infrastructure. To tackle this challenge,\nwe introduce a novel behavioural biometric system based on naturally occurring\ninteractions with objects in smart environments. This biometric leverages\nexisting sensors to authenticate users in such environments without requiring\nany hardware modifications of existing smart home devices. The system is\ndesigned to reduce the need for phone-based authentication mechanisms, on which\nsmart home systems currently rely. It requires the user to approve transactions\non their phone only when the user cannot be authenticated with high confidence\nthrough their interactions with the smart environment.\nWe conduct a real-world experiment that involves 13 participants in a company\nenvironment, using this experiment to also study mimicry attacks on our\nproposed system. We show that our system can provide seamless and unobtrusive\nauthentication while still staying highly resistant to zero-effort, video, and\nin-person observation-based mimicry attacks. Even when at most 1% of the\nstrongest type of mimicry attacks are successful, our system does not require\nthe user to take out their phone to approve legitimate transactions in more\nthan 80% of cases for a single interaction. This increases to 92% of\ntransactions when interactions with more objects are considered.",
    "descriptor": "",
    "authors": [
      "Klaudia Krawiecka",
      "Simon Birnbach",
      "Simon Eberz",
      "Ivan Martinovic"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.03845"
  },
  {
    "id": "arXiv:2202.03846",
    "title": "The Soft Compiler: A Web-Based Tool for the Design of Modular Pneumatic  Circuits for Soft Robots",
    "abstract": "Developing soft circuits from individual soft logic gates poses a unique\nchallenge: with increasing numbers of logic gates, the design and\nimplementation of circuits leads to inefficiencies due to mathematically\nunoptimized circuits and wiring mistakes during assembly. It is therefore\npractically important to introduce design tools that support the development of\nsoft circuits. We developed a web-based graphical user interface, the Soft\nCompiler, that accepts a user-defined robot behavior as a truth table to\ngenerate a mathematically optimized circuit diagram that guides the assembly of\na soft fluidic circuit. We describe the design and experimental verification of\nthree soft circuits of increasing complexity, using the Soft Compiler as a\ndesign tool and a novel pneumatic glove as an input interface. In one example,\nwe reduce the size of a soft circuit from the original 11 logic gates to 4\nlogic gates while maintaining circuit functionality. The Soft Compiler is a\nweb-based design tool for fluidic, soft circuits and published under\nopen-source MIT License.",
    "descriptor": "\nComments: Accepted manuscript (journal): Robotics and Automation Letter, 2022\n",
    "authors": [
      "Lauryn Whiteside",
      "Savita V. Kendre",
      "Tian Y. Fan",
      "Jovanna A. Tracz",
      "Gus T. Teran",
      "Thomas C. Underwood",
      "Mohammed E. Sayed",
      "Haihui J. Jiang",
      "Adam A. Stokes",
      "Daniel J. Preston",
      "George M. Whitesides",
      "Markus P. Nemitz"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.03846"
  },
  {
    "id": "arXiv:2202.03851",
    "title": "MetaKG: Meta-learning on Knowledge Graph for Cold-start Recommendation",
    "abstract": "A knowledge graph (KG) consists of a set of interconnected typed entities and\ntheir attributes. Recently, KGs are popularly used as the auxiliary information\nto enable more accurate, explainable, and diverse user preference\nrecommendations. Specifically, existing KG-based recommendation methods target\nmodeling high-order relations/dependencies from long connectivity user-item\ninteractions hidden in KG. However, most of them ignore the cold-start problems\n(i.e., user cold-start and item cold-start) of recommendation analytics, which\nrestricts their performance in scenarios when involving new users or new items.\nInspired by the success of meta-learning on scarce training samples, we propose\na novel meta-learning based framework called MetaKG, which encompasses a\ncollaborative-aware meta learner and a knowledge-aware meta learner, to capture\nmeta users' preference and entities' knowledge for cold-start recommendations.\nThe collaborative-aware meta learner aims to locally aggregate user preferences\nfor each user preference learning task. In contrast, the knowledge-aware meta\nlearner is to globally generalize knowledge representation across different\nuser preference learning tasks. Guided by two meta learners, MetaKG can\neffectively capture the high-order collaborative relations and semantic\nrepresentations, which could be easily adapted to cold-start scenarios.\nBesides, we devise a novel adaptive task scheduler which can adaptively select\nthe informative tasks for meta learning in order to prevent the model from\nbeing corrupted by noisy tasks. Extensive experiments on various cold-start\nscenarios using three real data sets demonstrate that our presented MetaKG\noutperforms all the existing state-of-the-art competitors in terms of\neffectiveness, efficiency, and scalability.",
    "descriptor": "\nComments: TKDE 2022 Under review\n",
    "authors": [
      "Yuntao Du",
      "Xinjun Zhu",
      "Lu Chen",
      "Ziquan Fang",
      "Yunjun Gao"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.03851"
  },
  {
    "id": "arXiv:2202.03854",
    "title": "Comparative Study Between Distance Measures On Supervised Optimum-Path  Forest Classification",
    "abstract": "Machine Learning has attracted considerable attention throughout the past\ndecade due to its potential to solve far-reaching tasks, such as image\nclassification, object recognition, anomaly detection, and data forecasting. A\nstandard approach to tackle such applications is based on supervised learning,\nwhich is assisted by large sets of labeled data and is conducted by the\nso-called classifiers, such as Logistic Regression, Decision Trees, Random\nForests, and Support Vector Machines, among others. An alternative to\ntraditional classifiers is the parameterless Optimum-Path Forest (OPF), which\nuses a graph-based methodology and a distance measure to create arcs between\nnodes and hence sets of trees, responsible for conquering the nodes, defining\ntheir labels, and shaping the forests. Nevertheless, its performance is\nstrongly associated with an appropriate distance measure, which may vary\naccording to the dataset's nature. Therefore, this work proposes a comparative\nstudy over a wide range of distance measures applied to the supervised\nOptimum-Path Forest classification. The experimental results are conducted\nusing well-known literature datasets and compared across benchmarking\nclassifiers, illustrating OPF's ability to adapt to distinct domains.",
    "descriptor": "\nComments: 16 pages, 2 figures\n",
    "authors": [
      "Gustavo Henrique de Rosa",
      "Mateus Roder",
      "Jo\u00e3o Paulo Papa"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.03854"
  },
  {
    "id": "arXiv:2202.03856",
    "title": "Class Density and Dataset Quality in High-Dimensional, Unstructured Data",
    "abstract": "We provide a definition for class density that can be used to measure the\naggregate similarity of the samples within each of the classes in a\nhigh-dimensional, unstructured dataset. We then put forth several candidate\nmethods for calculating class density and analyze the correlation between the\nvalues each method produces with the corresponding individual class test\naccuracies achieved on a trained model. Additionally, we propose a definition\nfor dataset quality for high-dimensional, unstructured data and show that those\ndatasets that met a certain quality threshold (experimentally demonstrated to\nbe > 10 for the datasets studied) were candidates for eliding redundant data\nbased on the individual class densities.",
    "descriptor": "\nComments: 13 pages, 27 tables\n",
    "authors": [
      "Adam Byerly",
      "Tatiana Kalganova"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.03856"
  },
  {
    "id": "arXiv:2202.03857",
    "title": "Learning Optical Flow with Adaptive Graph Reasoning",
    "abstract": "Estimating per-pixel motion between video frames, known as optical flow, is a\nlong-standing problem in video understanding and analysis. Most contemporary\noptical flow techniques largely focus on addressing the cross-image matching\nwith feature similarity, with few methods considering how to explicitly reason\nover the given scene for achieving a holistic motion understanding. In this\nwork, taking a fresh perspective, we introduce a novel graph-based approach,\ncalled adaptive graph reasoning for optical flow (AGFlow), to emphasize the\nvalue of scene/context information in optical flow. Our key idea is to decouple\nthe context reasoning from the matching procedure, and exploit scene\ninformation to effectively assist motion estimation by learning to reason over\nthe adaptive graph. The proposed AGFlow can effectively exploit the context\ninformation and incorporate it within the matching procedure, producing more\nrobust and accurate results. On both Sintel clean and final passes, our AGFlow\nachieves the best accuracy with EPE of 1.43 and 2.47 pixels, outperforming\nstate-of-the-art approaches by 11.2% and 13.6%, respectively.",
    "descriptor": "\nComments: To appear in AAAI-22\n",
    "authors": [
      "Ao Luo",
      "Fan Yang",
      "Kunming Luo",
      "Xin Li",
      "Haoqiang Fan",
      "Shuaicheng Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.03857"
  },
  {
    "id": "arXiv:2202.03859",
    "title": "The application of Evolutionary and Nature Inspired Algorithms in Data  Science and Data Analytics",
    "abstract": "In the past 30 years, scientists have searched nature, including animals and\ninsects, and biology in order to discover, understand, and model solutions for\nsolving large-scale science challenges. The study of bionics reveals that how\nthe biological structures, functions found in nature have improved our modern\ntechnologies. In this study, we present our discovery of evolutionary and\nnature-inspired algorithms applications in Data Science and Data Analytics in\nthree main topics of pre-processing, supervised algorithms, and unsupervised\nalgorithms. Among all applications, in this study, we aim to investigate four\noptimization algorithms that have been performed using the evolutionary and\nnature-inspired algorithms within data science and analytics. Feature selection\noptimization in pre-processing section, Hyper-parameter tuning optimization,\nand knowledge discovery optimization in supervised algorithms, and clustering\noptimization in the unsupervised algorithms.",
    "descriptor": "",
    "authors": [
      "Farid Ghareh Mohammadi",
      "Farzan Shenavarmasouleh",
      "Khaled Rasheed",
      "Thiab Taha",
      "M. Hadi Amini",
      "Hamid R. Arabnia"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.03859"
  },
  {
    "id": "arXiv:2202.03861",
    "title": "Targeted Trojan-Horse Attacks on Language-based Image Retrieval",
    "abstract": "When a retrieval system expands data, its database is at risk of being\nattacked. In this paper, we introduce the concept of targeted Trojan-horse\n(TTH) attacks for language-based image retrieval (LBIR), the first keyword-wise\ntargeted attack against the database of the retrieval system. Specifically,\ngiven a specific keyword, TTH generates a QR-code patch that can be applied to\na set of different images to gain the targeted Trojan-horse images, which\ncloses to the target keyword in the common space of cross-modal matching of\nretrieval model. With Uploading the generated TTH images to the database, TTH\nimages will rank high in a normal search, even though the images are completely\nirrelevant to the query. We evaluate the attacks on standard language-based\nimage retrieval benchmarks (i.e. Flickr30k and MSCOCO) and compare the results\nretrieved with and without the Trojan-horse images.",
    "descriptor": "",
    "authors": [
      "Fan Hu",
      "Aozhu Chen",
      "Xirong Li"
    ],
    "subjectives": [
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2202.03861"
  },
  {
    "id": "arXiv:2202.03865",
    "title": "Backtrack Tie-Breaking for Decision Trees: A Note on Deodata Predictors",
    "abstract": "A tie-breaking method is proposed for choosing the predicted class, or\noutcome, in a decision tree. The method is an adaptation of a similar technique\nused for deodata predictors.",
    "descriptor": "",
    "authors": [
      "Cristian Alb"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.03865"
  },
  {
    "id": "arXiv:2202.03866",
    "title": "NFT Wash Trading: Quantifying suspicious behaviour in NFT markets",
    "abstract": "The smart contract-based markets for non-fungible tokens (NFTs) on the\nEthereum blockchain have seen tremendous growth in 2021, with trading volumes\npeaking at 3.5b in September 2021. This dramatic surge has led to industry\nobservers questioning the authenticity of on-chain volumes, given the absence\nof identity requirements and the ease with which agents can control multiple\naddresses. We examine potentially illicit trading patterns in the NFT markets\nfrom January 2018 to mid-November 2021, gathering data from the 52 largest\ncollections by volume. Our findings indicate that within our sample 3.93% of\naddresses, processing a total of 2.04% of sale transactions, trigger suspicions\nof market abuse. Flagged transactions contaminate nearly all collections and\nmay have inflated the authentic trading volumes by as much as 149,5m for the\nperiod. Most flagged transaction patterns alternate between a few addresses,\nindicating a predisposition for manual trading. We submit that the results\npresented here may serve as a viable lower bound estimate for NFT wash trading\non Ethereum. Even so, we argue that wash trading may be less common than what\nindustry observers have previously estimated. We contribute to the emerging\ndiscourse on the identification and deterrence of market abuse in the\ncryptocurrency markets.",
    "descriptor": "\nComments: DeFi, Blockchain, NFT, wash trading, graph analysis Financial Cryptography & Data Security 2022 (To appear)\n",
    "authors": [
      "Victor von Wachter",
      "Johannes Rude Jensen",
      "Ferdinand Regner",
      "Omri Ross"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.03866"
  },
  {
    "id": "arXiv:2202.03867",
    "title": "Offline Reinforcement Learning for Mobile Notifications",
    "abstract": "Mobile notification systems have taken a major role in driving and\nmaintaining user engagement for online platforms. They are interesting\nrecommender systems to machine learning practitioners with more sequential and\nlong-term feedback considerations. Most machine learning applications in\nnotification systems are built around response-prediction models, trying to\nattribute both short-term impact and long-term impact to a notification\ndecision. However, a user's experience depends on a sequence of notifications\nand attributing impact to a single notification is not always accurate, if not\nimpossible. In this paper, we argue that reinforcement learning is a better\nframework for notification systems in terms of performance and iteration speed.\nWe propose an offline reinforcement learning framework to optimize sequential\nnotification decisions for driving user engagement. We describe a\nstate-marginalized importance sampling policy evaluation approach, which can be\nused to evaluate the policy offline and tune learning hyperparameters. Through\nsimulations that approximate the notifications ecosystem, we demonstrate the\nperformance and benefits of the offline evaluation approach as a part of the\nreinforcement learning modeling approach. Finally, we collect data through\nonline exploration in the production system, train an offline Double Deep\nQ-Network and launch a successful policy online. We also discuss the practical\nconsiderations and results obtained by deploying these policies for a\nlarge-scale recommendation system use-case.",
    "descriptor": "\nComments: 11 pages, 5 figures. submitted\n",
    "authors": [
      "Yiping Yuan",
      "Ajith Muralidharan",
      "Preetam Nandy",
      "Miao Cheng",
      "Prakruthi Prabhakar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.03867"
  },
  {
    "id": "arXiv:2202.03868",
    "title": "Mapping DNN Embedding Manifolds for Network Generalization Prediction",
    "abstract": "Understanding Deep Neural Network (DNN) performance in changing conditions is\nessential for deploying DNNs in safety critical applications with unconstrained\nenvironments, e.g., perception for self-driving vehicles or medical image\nanalysis. Recently, the task of Network Generalization Prediction (NGP) has\nbeen proposed to predict how a DNN will generalize in a new operating domain.\nPrevious NGP approaches have relied on labeled metadata and known distributions\nfor the new operating domains. In this study, we propose the first NGP approach\nthat predicts DNN performance based solely on how unlabeled images from an\nexternal operating domain map in the DNN embedding space. We demonstrate this\ntechnique for pedestrian, melanoma, and animal classification tasks and show\nstate of the art NGP in 13 of 15 NGP tasks without requiring domain knowledge.\nAdditionally, we show that our NGP embedding maps can be used to identify\nmisclassified images when the DNN performance is poor.",
    "descriptor": "\nComments: 11 pages, 5 figures\n",
    "authors": [
      "Molly O'Brien",
      "Julia Bukowski",
      "Mathias Unberath",
      "Aria Pezeshk",
      "Greg Hager"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.03868"
  },
  {
    "id": "arXiv:2202.03869",
    "title": "COVID-19 Hospitalizations Forecasts Using Internet Search Data",
    "abstract": "As the COVID-19 spread over the globe and new variants of COVID-19 keep\noccurring, reliable real-time forecasts of COVID-19 hospitalizations are\ncritical for public health decision on medical resources allocations such as\nICU beds, ventilators, and personnel to prepare for the surge of COVID-19\npandemics. Inspired by the strong association between public search behavior\nand hospitalization admission, we extended previously-proposed influenza\ntracking model, ARGO (AutoRegression with GOogle search data), to predict\nfuture 2-week national and state-level COVID-19 new hospital admissions.\nLeveraging the COVID-19 related time series information and Google search data,\nour method is able to robustly capture new COVID-19 variants' surges, and\nself-correct at both national and state level. Based on our retrospective\nout-of-sample evaluation over 12-month comparison period, our method achieves\non average 15\\% error reduction over the best alternative models collected from\nCOVID-19 forecast hub. Overall, we showed that our method is flexible,\nself-correcting, robust, accurate, and interpretable, making it a potentially\npowerful tool to assist health-care officials and decision making for the\ncurrent and future infectious disease outbreak.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2202.02621\n",
    "authors": [
      "Tao Wang",
      "Simin Ma",
      "Soobin Baek",
      "Shihao Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Medical Physics (physics.med-ph)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2202.03869"
  },
  {
    "id": "arXiv:2202.03870",
    "title": "Maximum Likelihood Uncertainty Estimation: Robustness to Outliers",
    "abstract": "We benchmark the robustness of maximum likelihood based uncertainty\nestimation methods to outliers in training data for regression tasks. Outliers\nor noisy labels in training data results in degraded performances as well as\nincorrect estimation of uncertainty. We propose the use of a heavy-tailed\ndistribution (Laplace distribution) to improve the robustness to outliers. This\nproperty is evaluated using standard regression benchmarks and on a\nhigh-dimensional regression task of monocular depth estimation, both containing\noutliers. In particular, heavy-tailed distribution based maximum likelihood\nprovides better uncertainty estimates, better separation in uncertainty for\nout-of-distribution data, as well as better detection of adversarial attacks in\nthe presence of outliers.",
    "descriptor": "\nComments: 8 Pages, 8 Figures, The Thirty-Sixth AAAI Conference on Artificial Intelligence (AAAI-22), The AAAI's Workshop on Artificial Intelligence Safety\n",
    "authors": [
      "Deebul S. Nair",
      "Nico Hochgeschwender",
      "Miguel A. Olivares-Mendez"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.03870"
  },
  {
    "id": "arXiv:2202.03872",
    "title": "A parallel algorithm for minimum weight set cover with small  neighborhood property",
    "abstract": "This paper studies the minimum weight set cover (MinWSC) problem with a {\\em\nsmall neighborhood cover} (SNC) property proposed by Agarwal {\\it et al.} in\n\\cite{Agarwal.}. A parallel algorithm for MinWSC with $\\tau$-SNC property is\npresented, obtaining approximation ratio $\\tau(1+3\\varepsilon)$ in\n$O(L\\log_{1+\\varepsilon}\\frac{n^3}{\\varepsilon^2}+ 4\\tau^{3}2^\\tau L^2\\log n)$\nrounds, where $0< \\varepsilon <\\frac{1}{2}$ is a constant, $n$ is the number of\nelements, and $L$ is a parameter related to SNC property. Our results not only\nimprove the approximation ratio obtained in \\cite{Agarwal.}, but also answer\ntwo questions proposed in \\cite{Agarwal.}.",
    "descriptor": "",
    "authors": [
      "Yingli Ran",
      "Yaoyao Zhang",
      "Zhao Zhang"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2202.03872"
  },
  {
    "id": "arXiv:2202.03879",
    "title": "BIQ2021: A Large-Scale Blind Image Quality Assessment Database",
    "abstract": "The assessment of the perceptual quality of digital images is becoming\nincreasingly important as a result of the widespread use of digital multimedia\ndevices. Smartphones and high-speed internet are just two examples of\ntechnologies that have multiplied the amount of multimedia content available.\nThus, obtaining a representative dataset, which is required for objective\nquality assessment training, is a significant challenge. The Blind Image\nQuality Assessment Database, BIQ2021, is presented in this article. By\nselecting images with naturally occurring distortions and reliable labeling,\nthe dataset addresses the challenge of obtaining representative images for\nno-reference image quality assessment. The dataset consists of three sets of\nimages: those taken without the intention of using them for image quality\nassessment, those taken with intentionally introduced natural distortions, and\nthose taken from an open-source image-sharing platform. It is attempted to\nmaintain a diverse collection of images from various devices, containing a\nvariety of different types of objects and varying degrees of foreground and\nbackground information. To obtain reliable scores, these images are\nsubjectively scored in a laboratory environment using a single stimulus method.\nThe database contains information about subjective scoring, human subject\nstatistics, and the standard deviation of each image. The dataset's Mean\nOpinion Scores (MOS) make it useful for assessing visual quality. Additionally,\nthe proposed database is used to evaluate existing blind image quality\nassessment approaches, and the scores are analyzed using Pearson and Spearman's\ncorrelation coefficients. The image database and MOS are freely available for\nuse and benchmarking.",
    "descriptor": "",
    "authors": [
      "Nisar Ahmed",
      "Shahzad Asif"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2202.03879"
  },
  {
    "id": "arXiv:2202.03880",
    "title": "Group Fairness Is Not Derivable From Justice: a Mathematical Proof",
    "abstract": "We argue that an imperfect criminal law procedure cannot be group-fair, if\n'group fairness' involves ensuring the same chances of acquittal or convictions\nto all innocent defendants independently of their morally arbitrary features.\nWe show mathematically that only a perfect procedure (involving no mistake), a\nnon-deterministic one, or a degenerate one (everyone or no one is convicted)\ncan guarantee group fairness, in the general case. Following a recent proposal,\nwe adopt a definition of group fairness, requiring that individuals who are\nequal in merit ought to have the same statistical chances of obtaining\nadvantages and disadvantages, in a way that is statistically independent of any\nof their feature that does not count as merit. We explain by mathematical\nargument that the only imperfect procedures offering an a-priori guarantee of\nfairness in relation to all non-merit trait are lotteries or degenerate ones\n(i.e., everyone or no one is convicted). To provide a more intuitive point of\nview, we exploit an adjustment of the well-known ROC space, in order to\nrepresent all possible procedures in our model by a schematic diagram. The\nargument seems to be equally valid for all human procedures, provided they are\nimperfect. This clearly includes algorithmic decision-making, including\ndecisions based on statistical predictions, since in practice all statistical\nmodels are error prone.",
    "descriptor": "\nComments: 20 pages, 2 figures\n",
    "authors": [
      "Nicol\u00f2 Cangiotti",
      "Michele Loi"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2202.03880"
  },
  {
    "id": "arXiv:2202.03881",
    "title": "Robust Hybrid Learning With Expert Augmentation",
    "abstract": "Hybrid modelling reduces the misspecification of expert models by combining\nthem with machine learning (ML) components learned from data. Like for many ML\nalgorithms, hybrid model performance guarantees are limited to the training\ndistribution. Leveraging the insight that the expert model is usually valid\neven outside the training domain, we overcome this limitation by introducing a\nhybrid data augmentation strategy termed \\textit{expert augmentation}. Based on\na probabilistic formalization of hybrid modelling, we show why expert\naugmentation improves generalization. Finally, we validate the practical\nbenefits of augmented hybrid models on a set of controlled experiments,\nmodelling dynamical systems described by ordinary and partial differential\nequations.",
    "descriptor": "",
    "authors": [
      "Antoine Wehenkel",
      "Jens Behrmann",
      "Hsiang Hsu",
      "Guillermo Sapiro",
      "Gilles Louppe and",
      "J\u00f6rn-Henrik Jacobsen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.03881"
  },
  {
    "id": "arXiv:2202.03884",
    "title": "GraphDCA -- a Framework for Node Distribution Comparison in Real and  Synthetic Graphs",
    "abstract": "We argue that when comparing two graphs, the distribution of node structural\nfeatures is more informative than global graph statistics which are often used\nin practice, especially to evaluate graph generative models. Thus, we present\nGraphDCA - a framework for evaluating similarity between graphs based on the\nalignment of their respective node representation sets. The sets are compared\nusing a recently proposed method for comparing representation spaces, called\nDelaunay Component Analysis (DCA), which we extend to graph data. To evaluate\nour framework, we generate a benchmark dataset of graphs exhibiting different\nstructural patterns and show, using three node structure feature extractors,\nthat GraphDCA recognizes graphs with both similar and dissimilar local\nstructure. We then apply our framework to evaluate three publicly available\nreal-world graph datasets and demonstrate, using gradual edge perturbations,\nthat GraphDCA satisfyingly captures gradually decreasing similarity, unlike\nglobal statistics. Finally, we use GraphDCA to evaluate two state-of-the-art\ngraph generative models, NetGAN and CELL, and conclude that further\nimprovements are needed for these models to adequately reproduce local\nstructural features.",
    "descriptor": "",
    "authors": [
      "Ciwan Ceylan",
      "Petra Poklukar",
      "Hanna Hultin",
      "Alexander Kravchenko",
      "Anastasia Varava",
      "Danica Kragic"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.03884"
  },
  {
    "id": "arXiv:2202.03888",
    "title": "Learning MAX-SAT from Contextual Examples for Combinatorial Optimisation",
    "abstract": "Combinatorial optimisation problems are ubiquitous in artificial\nintelligence. Designing the underlying models, however, requires substantial\nexpertise, which is a limiting factor in practice. The models typically consist\nof hard and soft constraints, or combine hard constraints with an objective\nfunction. We introduce a novel setting for learning combinatorial optimisation\nproblems from contextual examples. These positive and negative examples show -\nin a particular context - whether the solutions are good enough or not. We\ndevelop our framework using the MAX-SAT formalism as it is simple yet powerful\nsetting having these features. We study the learnability of MAX-SAT models. Our\ntheoretical results show that high-quality MAX-SAT models can be learned from\ncontextual examples in the realisable and agnostic settings, as long as the\ndata satisfies an intuitive \"representativeness\" condition. We also contribute\ntwo implementations based on our theoretical results: one leverages ideas from\nsyntax-guided synthesis while the other makes use of stochastic local search\ntechniques. The two implementations are evaluated by recovering synthetic and\nbenchmark models from contextual examples. The experimental results support our\ntheoretical analysis, showing that MAX-SAT models can be learned from\ncontextual examples. Among the two implementations, the stochastic local search\nlearner scales much better than the syntax-guided implementation while\nproviding comparable or better models.",
    "descriptor": "",
    "authors": [
      "Mohit Kumar",
      "Samuel Kolb",
      "Stefano Teso",
      "Luc De Raedt"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.03888"
  },
  {
    "id": "arXiv:2202.03896",
    "title": "Speech Emotion Recognition using Self-Supervised Features",
    "abstract": "Self-supervised pre-trained features have consistently delivered state-of-art\nresults in the field of natural language processing (NLP); however, their\nmerits in the field of speech emotion recognition (SER) still need further\ninvestigation. In this paper we introduce a modular End-to- End (E2E) SER\nsystem based on an Upstream + Downstream architecture paradigm, which allows\neasy use/integration of a large variety of self-supervised features. Several\nSER experiments for predicting categorical emotion classes from the IEMOCAP\ndataset are performed. These experiments investigate interactions among\nfine-tuning of self-supervised feature models, aggregation of frame-level\nfeatures into utterance-level features and back-end classification networks.\nThe proposed monomodal speechonly based system not only achieves SOTA results,\nbut also brings light to the possibility of powerful and well finetuned\nself-supervised acoustic features that reach results similar to the results\nachieved by SOTA multimodal systems using both Speech and Text modalities.",
    "descriptor": "\nComments: 5 pages, 4 figures, 2 tables, ICASSP 2022\n",
    "authors": [
      "Edmilson Morais",
      "Ron Hoory",
      "Weizhong Zhu",
      "Itai Gat",
      "Matheus Damasceno",
      "Hagai Aronowitz"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2202.03896"
  },
  {
    "id": "arXiv:2202.03898",
    "title": "Verification-Aided Deep Ensemble Selection",
    "abstract": "Deep neural networks (DNNs) have become the technology of choice for\nrealizing a variety of complex tasks. However, as highlighted by many recent\nstudies, even an imperceptible perturbation to a correctly classified input can\nlead to misclassification by a DNN. This renders DNNs vulnerable to strategic\ninput manipulations by attackers, and also prone to oversensitivity to\nenvironmental noise.\nTo mitigate this phenomenon, practitioners apply joint classification by an\nensemble of DNNs. By aggregating the classification outputs of different\nindividual DNNs for the same input, ensemble-based classification reduces the\nrisk of misclassifications due to the specific realization of the stochastic\ntraining process of any single DNN. However, the effectiveness of a DNN\nensemble is highly dependent on its members not simultaneously erring on many\ndifferent inputs.\nIn this case study, we harness recent advances in DNN verification to devise\na methodology for identifying ensemble compositions that are less prone to\nsimultaneous errors, even when the input is adversarially perturbed --\nresulting in more robustly-accurate ensemble-based classification.\nOur proposed framework uses a DNN verifier as a backend, and includes\nheuristics that help reduce the high complexity of directly verifying\nensembles. More broadly, our work puts forth a novel universal objective for\nformal verification that can potentially improve the robustness of real-world,\ndeep-learning-based systems across a variety of application domains.",
    "descriptor": "",
    "authors": [
      "Guy Amir",
      "Guy Katz",
      "Michael Schapira"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Logic in Computer Science (cs.LO)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2202.03898"
  },
  {
    "id": "arXiv:2202.03899",
    "title": "Covert backscatter communication with directional MIMO",
    "abstract": "We study a backscatter communication protocol over a AWGN channel, where a\ntransmitter illuminates a tag with a directional multi-antenna. The tag\nperforms load modulation on the signal while hiding its physical presence from\na warden. We show that, if the transmitter-to-tag channel is inaccessible to\nthe warden, then $\\Theta(n)$ reliable and covert bits can be transmitted over\n$n$ channel usages. This overcomes the square-root law for covert\ncommunication. This paper provides the first evidence for practical\nimplementation of covert backscatter communication, with potential applications\nin IoT security.",
    "descriptor": "\nComments: 4 pages, 2 figures\n",
    "authors": [
      "Roberto Di Candia",
      "Saneea Malik",
      "Huseyin Yi\u011fitler",
      "Riku J\u00e4ntti"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.03899"
  },
  {
    "id": "arXiv:2202.03901",
    "title": "GLPU: A Geometric Approach For Lidar Pointcloud Upsampling",
    "abstract": "In autonomous driving, lidar is inherent for the understanding of the 3D\nenvironment. Lidar sensors vary in vertical resolutions, where a denser\npointcloud depicts a more detailed environment, albeit at a significantly\nhigher cost. Pointcloud upsampling predicts high-resolution pointclouds from\nsparser ones to bridge this performance gap at a lower cost. Although many\nupsampling frameworks have achieved a robust performance, a fair comparison is\ndifficult as they were tested on different datasets and metrics. In this work,\nwe first conduct a consistent comparative study to benchmark the existing\nalgorithms on the KITTI dataset. Then, we observe that there are three common\nfactors that hinder the performance: an inefficient data representation, a\nsmall receptive field, and low-frequency losses. By leveraging the scene\ngeometry, a new self-supervised geometric lidar pointcloud upsampling (GLPU)\nframework is proposed to address the aforementioned limitations. Our\nexperiments demonstrate the effectiveness and superior performance of GLPU\ncompared to other techniques on the KITTI benchmark.",
    "descriptor": "",
    "authors": [
      "George Eskandar",
      "Janaranjani Palaniswamy",
      "Karim Guirguis",
      "Barath Somashekar",
      "Bin Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.03901"
  },
  {
    "id": "arXiv:2202.03903",
    "title": "KENN: Enhancing Deep Neural Networks by Leveraging Knowledge for Time  Series Forecasting",
    "abstract": "End-to-end data-driven machine learning methods often have exuberant\nrequirements in terms of quality and quantity of training data which are often\nimpractical to fulfill in real-world applications. This is specifically true in\ntime series domain where problems like disaster prediction, anomaly detection,\nand demand prediction often do not have a large amount of historical data.\nMoreover, relying purely on past examples for training can be sub-optimal since\nin doing so we ignore one very important domain i.e knowledge, which has its\nown distinct advantages. In this paper, we propose a novel knowledge fusion\narchitecture, Knowledge Enhanced Neural Network (KENN), for time series\nforecasting that specifically aims towards combining strengths of both\nknowledge and data domains while mitigating their individual weaknesses. We\nshow that KENN not only reduces data dependency of the overall framework but\nalso improves performance by producing predictions that are better than the\nones produced by purely knowledge and data driven domains. We also compare KENN\nwith state-of-the-art forecasting methods and show that predictions produced by\nKENN are significantly better even when trained on only 50\\% of the data.",
    "descriptor": "",
    "authors": [
      "Muhammad Ali Chattha",
      "Ludger van Elst",
      "Muhammad Imran Malik",
      "Andreas Dengel",
      "Sheraz Ahmed"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.03903"
  },
  {
    "id": "arXiv:2202.03904",
    "title": "Efficient approximation of cardiac mechanics through reduced order  modeling with deep learning-based operator approximation",
    "abstract": "Reducing the computational time required by high-fidelity, full order models\n(FOMs) for the solution of problems in cardiac mechanics is crucial to allow\nthe translation of patient-specific simulations into clinical practice. While\nFOMs, such as those based on the finite element method, provide valuable\ninformation of the cardiac mechanical function, up to hundreds of thousands\ndegrees of freedom may be needed to obtain accurate numerical results. As a\nmatter of fact, simulating even just a few heartbeats can require hours to days\nof CPU time even on powerful supercomputers. In addition, cardiac models depend\non a set of input parameters that we could let vary in order to explore\nmultiple virtual scenarios. To compute reliable solutions at a greatly reduced\ncomputational cost, we rely on a reduced basis method empowered with a new\ndeep-learning based operator approximation, which we refer to as Deep-HyROMnet\ntechnique. Our strategy combines a projection-based POD-Galerkin method with\ndeep neural networks for the approximation of (reduced) nonlinear operators,\novercoming the typical computational bottleneck associated with standard\nhyper-reduction techniques. This method is shown to provide reliable\napproximations to cardiac mechanics problems outperforming classical\nprojection-based ROMs in terms of computational speed-up of orders of\nmagnitude, and enhancing forward uncertainty quantification analysis otherwise\nunaffordable.",
    "descriptor": "\nComments: 30 pages\n",
    "authors": [
      "Ludovica Cicci",
      "Stefania Fresca",
      "Andrea Manzoni",
      "Alfio Quarteroni"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.03904"
  },
  {
    "id": "arXiv:2202.03905",
    "title": "Tube-Balloon Logic for the Exploration of Fluidic Control Elements",
    "abstract": "The control of pneumatically driven soft robots typically requires\nelectronics. Microcontrollers are connected to power electronics that switch\nvalves and pumps on and off. As a recent alternative, fluidic control methods\nhave been introduced, in which soft digital logic gates permit multiple\nactuation states to be achieved in soft systems. Such systems have demonstrated\nautonomous behaviors without the use of electronics. However, fluidic\ncontrollers have required complex fabrication processes. To democratize the\nexploration of fluidic controllers, we developed tube-balloon logic circuitry,\nwhich consists of logic gates made from straws and balloons. Each tube-balloon\nlogic device takes a novice five minutes to fabricate and costs $0.45.\nTube-balloon logic devices can also operate at pressures of up to 200 kPa and\noscillate at frequencies of up to 15 Hz. We configure the tube-balloon logic\ndevice as NOT-, NAND-, and NOR-gates and assemble them into a three-ring\noscillator to demonstrate a vibrating sieve that separates sugar from rice.\nBecause tube-balloon logic devices are low-cost, easy to fabricate, and their\noperating principle is simple, they are well suited for exploring fundamental\nconcepts of fluidic control schemes while encouraging design inquiry for\npneumatically driven soft robots",
    "descriptor": "\nComments: Accepted manuscript (journal): Robotics and Automation Letter, 2022\n",
    "authors": [
      "Jovanna A. Tracz",
      "Lukas Wille",
      "Dylan Pathiraja",
      "Savita V. Kendre",
      "Ron Pfisterer",
      "Ethan Turett",
      "Gus T. Teran",
      "Christoffer K. Abrahamsson",
      "Samuel E. Root",
      "Won-Kyu Lee",
      "Daniel J. Preston",
      "Haihui Joy Jiang",
      "George M. Whitesides",
      "Markus P. Nemitz"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.03905"
  },
  {
    "id": "arXiv:2202.03907",
    "title": "Context-Aware Discrimination Detection in Job Vacancies using  Computational Language Models",
    "abstract": "Discriminatory job vacancies are disapproved worldwide, but remain\npersistent. Discrimination in job vacancies can be explicit by directly\nreferring to demographic memberships of candidates. More implicit forms of\ndiscrimination are also present that may not always be illegal but still\ninfluence the diversity of applicants. Explicit written discrimination is still\npresent in numerous job vacancies, as was recently observed in the Netherlands.\nCurrent efforts for the detection of explicit discrimination concern the\nidentification of job vacancies containing potentially discriminating terms\nsuch as \"young\" or \"male\". However, automatic detection is inefficient due to\nlow precision: e.g. \"we are a young company\" or \"working with mostly male\npatients\" are phrases that contain explicit terms, while the context shows that\nthese do not reflect discriminatory content.\nIn this paper, we show how machine learning based computational language\nmodels can raise precision in the detection of explicit discrimination by\nidentifying when the potentially discriminating terms are used in a\ndiscriminatory context. We focus on gender discrimination, which indeed suffers\nfrom low precision when filtering explicit terms. First, we created a data set\nfor gender discrimination in job vacancies. Second, we investigated a variety\nof computational language models for discriminatory context detection. Third,\nwe evaluated the capability of these models to detect unforeseen discriminating\nterms in context. The results show that machine learning based methods can\ndetect explicit gender discrimination with high precision and help in finding\nnew forms of discrimination. Accordingly, the proposed methods can\nsubstantially increase the effectiveness of detecting job vacancies which are\nhighly suspected to be discriminatory. In turn, this may lower the\ndiscrimination experienced at the start of the recruitment process.",
    "descriptor": "\nComments: 17 pages, 2 figures\n",
    "authors": [
      "S. Vethman",
      "A. Adhikari",
      "M. H. T. de Boer",
      "J. A. G. M. van Genabeek",
      "C. J. Veenman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.03907"
  },
  {
    "id": "arXiv:2202.03918",
    "title": "Network Coding Multicast Key-Capacity",
    "abstract": "For a multi-source multi-terminal noiseless network, the key-dissemination\nproblem involves the task of multicasting a secret key K from the network\nsources to its terminals. As in secure multicast network-coding, in the\nkey-dissemination problem the source nodes have access to independent\nrandomness and, as the network is noiseless, the resulting key K is a function\nof the sources' information. However, different from traditional forms of\nmulticast, in key-dissemination the key K need not consist of source messages,\nbut rather may be any function of the information generated at the sources, as\nlong as it is shared by all terminals. Allowing the shared key K to be a\nmixture of source information grants a flexibility to the communication process\nwhich gives rise to the potential of increased key-rates when compared to\ntraditional secure multicast. The multicast key-capacity is the supremum of\nachievable key-rates, subject to the security requirement that the shared key\nis not revealed to an eavesdropper with predefined eavesdropping capabilities.\nThe key-dissemination problem (termed also, secret key-agreement) has seen\nsignificant studies over the past decades in memoryless network structures. In\nthis work, we initiate the study of key-dissemination in the context of\nnoiseless networks, i.e., network coding. In this context, we study\nsimilarities and differences between traditional secure-multicast and the more\nlenient task of key-dissemination.",
    "descriptor": "",
    "authors": [
      "Michael Langberg",
      "Michelle Effros"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.03918"
  },
  {
    "id": "arXiv:2202.03925",
    "title": "Learnings from Federated Learning in the Real world",
    "abstract": "Federated Learning (FL) applied to real world data may suffer from several\nidiosyncrasies. One such idiosyncrasy is the data distribution across devices.\nData across devices could be distributed such that there are some \"heavy\ndevices\" with large amounts of data while there are many \"light users\" with\nonly a handful of data points. There also exists heterogeneity of data across\ndevices. In this study, we evaluate the impact of such idiosyncrasies on\nNatural Language Understanding (NLU) models trained using FL. We conduct\nexperiments on data obtained from a large scale NLU system serving thousands of\ndevices and show that simple non-uniform device selection based on the number\nof interactions at each round of FL training boosts the performance of the\nmodel. This benefit is further amplified in continual FL on consecutive time\nperiods, where non-uniform sampling manages to swiftly catch up with FL methods\nusing all data at once.",
    "descriptor": "",
    "authors": [
      "Christophe Dupuy",
      "Tanya G. Roosta",
      "Leo Long",
      "Clement Chung",
      "Rahul Gupta",
      "Salman Avestimehr"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.03925"
  },
  {
    "id": "arXiv:2202.03930",
    "title": "If a Human Can See It, So Should Your System: Reliability Requirements  for Machine Vision Components",
    "abstract": "Machine Vision Components (MVC) are becoming safety-critical. Assuring their\nquality, including safety, is essential for their successful deployment.\nAssurance relies on the availability of precisely specified and, ideally,\nmachine-verifiable requirements. MVCs with state-of-the-art performance rely on\nmachine learning (ML) and training data but largely lack such requirements.\nIn this paper, we address the need for defining machine-verifiable\nreliability requirements for MVCs against transformations that simulate the\nfull range of realistic and safety-critical changes in the environment. Using\nhuman performance as a baseline, we define reliability requirements as: 'if the\nchanges in an image do not affect a human's decision, neither should they\naffect the MVC's.' To this end, we provide: (1) a class of safety-related image\ntransformations; (2) reliability requirement classes to specify\ncorrectness-preservation and prediction-preservation for MVCs; (3) a method to\ninstantiate machine-verifiable requirements from these requirements classes\nusing human performance experiment data; (4) human performance experiment data\nfor image recognition involving eight commonly used transformations, from about\n2000 human participants; and (5) a method for automatically checking whether an\nMVC satisfies our requirements. Further, we show that our reliability\nrequirements are feasible and reusable by evaluating our methods on 13\nstate-of-the-art pre-trained image classification models. Finally, we\ndemonstrate that our approach detects reliability gaps in MVCs that other\nexisting methods are unable to detect.",
    "descriptor": "",
    "authors": [
      "Boyue Caroline Hu",
      "Lina Marsso",
      "Krzysztof Czarnecki",
      "Rick Salay",
      "Huakun Shen",
      "Marsha Chechik"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.03930"
  },
  {
    "id": "arXiv:2202.03932",
    "title": "Robustness Verification for Attention Networks using Mixed Integer  Programming",
    "abstract": "Attention networks such as transformers have been shown powerful in many\napplications ranging from natural language processing to object recognition.\nThis paper further considers their robustness properties from both theoretical\nand empirical perspectives. Theoretically, we formulate a variant of attention\nnetworks containing linearized layer normalization and sparsemax activation,\nand reduce its robustness verification to a Mixed Integer Programming problem.\nApart from a na\\\"ive encoding, we derive tight intervals from admissible\nperturbation regions and examine several heuristics to speed up the\nverification process. More specifically, we find a novel bounding technique for\nsparsemax activation, which is also applicable to softmax activation in general\nneural networks. Empirically, we evaluate our proposed techniques with a case\nstudy on lane departure warning and demonstrate a performance gain of\napproximately an order of magnitude. Furthermore, although attention networks\ntypically deliver higher accuracy than general neural networks, contrasting its\nrobustness against a similar-sized multi-layer perceptron surprisingly shows\nthat they are not necessarily more robust.",
    "descriptor": "\nComments: Submitted to IROS 2022\n",
    "authors": [
      "Hsuan-Cheng Liao",
      "Chih-Hong Cheng",
      "Maximilian Kneissl",
      "Alois Knoll"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.03932"
  },
  {
    "id": "arXiv:2202.03933",
    "title": "Scalable computational kernels for mortar finite element methods",
    "abstract": "Targeting simulations on parallel hardware architectures, this paper presents\ncomputational kernels for efficient computations in mortar finite element\nmethods. Mortar methods enable a variationally consistent imposition of\ncoupling conditions at high accuracy, but come with considerable numerical\neffort and cost for the evaluation of the mortar integrals to compute the\ncoupling operators. In this paper, we identify bottlenecks in parallel data\nlayout and domain decomposition that hinder an efficient evaluation of the\nmortar integrals. We then propose a set of computational strategies to restore\noptimal parallel communication and scalability for the core kernels devoted to\nthe evaluation of mortar terms. We exemplarily study the proposed algorithmic\ncomponents in the context of three-dimensional large-deformation contact\nmechanics, both for cases with fixed and dynamically varying interface\ntopology, yet these concepts can naturally and easily be transferred to other\nmortar applications, e.g. classical meshtying problems. To restore parallel\nscalability, we employ overlapping domain decompositions of the interface\ndiscretization independent from the underlying volumes and then tackle parallel\ncommunication for the mortar evaluation by a geometrically motivated reduction\nof ghosting data. Using three-dimensional contact examples, we demonstrate\nstrong and weak scalability of the proposed algorithms up to 480 parallel\nprocesses as well as study and discuss improvements in parallel communication\nrelated to mortar finite element methods. For the first time, dynamic load\nbalancing is applied to mortar contact problems with evolving contact zones,\nsuch that the computational work is well balanced among all parallel processors\nindependent of the current state of the simulation.",
    "descriptor": "",
    "authors": [
      "Matthias Mayr",
      "Alexander Popp"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2202.03933"
  },
  {
    "id": "arXiv:2202.03934",
    "title": "Alexa, in you, I trust! Fairness and Interpretability Issues in  E-commerce Search through Smart Speakers",
    "abstract": "In traditional (desktop) e-commerce search, a customer issues a specific\nquery and the system returns a ranked list of products in order of relevance to\nthe query. An increasingly popular alternative in e-commerce search is to issue\na voice-query to a smart speaker (e.g., Amazon Echo) powered by a voice\nassistant (VA, e.g., Alexa). In this situation, the VA usually spells out the\ndetails of only one product, an explanation citing the reason for its\nselection, and a default action of adding the product to the customer's cart.\nThis reduced autonomy of the customer in the choice of a product during\nvoice-search makes it necessary for a VA to be far more responsible and\ntrustworthy in its explanation and default action.\nIn this paper, we ask whether the explanation presented for a product\nselection by the Alexa VA installed on an Amazon Echo device is consistent with\nhuman understanding as well as with the observations on other traditional\nmediums (e.g., desktop ecommerce search). Through a user survey, we find that\nin 81% cases the interpretation of 'a top result' by the users is different\nfrom that of Alexa. While investigating for the fairness of the default action,\nwe observe that over a set of as many as 1000 queries, in nearly 68% cases,\nthere exist one or more products which are more relevant (as per Amazon's own\ndesktop search results) than the product chosen by Alexa. Finally, we conducted\na survey over 30 queries for which the Alexa-selected product was different\nfrom the top desktop search result, and observed that in nearly 73% cases, the\nparticipants preferred the top desktop search result as opposed to the product\nchosen by Alexa. Our results raise several concerns and necessitates more\ndiscussions around the related fairness and interpretability issues of VAs for\ne-commerce search.",
    "descriptor": "\nComments: This work has been accepted in Web4Good track at The Web Conference 2022 (WWW'22)\n",
    "authors": [
      "Abhisek Dash",
      "Abhijnan Chakraborty",
      "Saptarshi Ghosh",
      "Animesh Mukherjee",
      "Krishna P. Gummadi"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2202.03934"
  },
  {
    "id": "arXiv:2202.03936",
    "title": "Accelerometer-based Bed Occupancy Detection for Automatic, Non-invasive  Long-term Cough Monitoring",
    "abstract": "We present a machine learning based long-term cough monitoring system by\ndetecting patient's bed occupancy from a bed-attached smartphone-inbuilt\naccelerometer automatically. Previously this system was used to detect cough\nevents successfully and long-term cough monitoring requires bed occupancy\ndetection, as the initial experiments show that patients leave their bed very\noften for long period of time and using video-monitoring or pressure sensors\nare not patient-favourite alternatives. We have compiled a 249-hour dataset of\nmanually-labelled acceleration signals gathered from seven adult male patients\nundergoing treatment for tuberculosis (TB). The bed occupancy detection process\nconsists of three detectors, among which the first one classifies\noccupancy-change with high sensitivity, low specificity and the second one\nclassifies occupancy-interval with high specificity, low sensitivity. The final\nstate detector corrects the miss-classified sections. After using a\nleave-one-patient-out cross-validation scheme to train and evaluate four\nclassifiers such as LR, MLP, CNN and LSTM; LSTM produces the highest area under\nthe curve (AUC) of 0.94 while comparing the predicted bed occupancy as the\noutput from the final state detector with the actual bed occupancy sample by\nsample. We have also calculated colony forming unit and time to positivity of\nthe sputum samples of TB positive patients who were monitored for 14 days and\nthe proposed system was used to predict daily cough rates. The results show\nthat patients who improve under TB treatment have decreasing daily cough rates,\nindicating the proposed automatic, quick, non-invasive, non-intrusive,\ncost-effective long-term cough monitoring system can be extremely useful in\nmonitoring patients' recovery rate.",
    "descriptor": "",
    "authors": [
      "Madhurananda Pahar",
      "Igor Miranda",
      "Andreas Diacon",
      "Thomas Niesler"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.03936"
  },
  {
    "id": "arXiv:2202.03943",
    "title": "SPIDER: Specification-based Integration Defect Revealer",
    "abstract": "Modern software design practice implies widespread use in the development of\nready-made components, usually designed as external libraries. The undoubted\nadvantages of reusing third-party code can be offset by integration errors that\nappear in the developed software. The reason for the appearance of such errors\nis mainly due to misunderstanding or incomplete understanding by the programmer\nof the details of external libraries such as an internal structure and the\nsubtleties of functioning. The documentation provided with the libraries is\noften very sparse and describes only the main intended scenarios for the\ninteraction of the program and the library. In this paper, we propose the\napproach based on the use of formal library specifications, which allows\ndetecting integration errors using static analysis methods. To do this, the\nexternal library is described using the LibSL specification language, the\nresulting description is translated into the internal data structures of the\nKEX analyzer. The execution of the incorrect scenarios of library usage, such\nas the incorrect sequence of method calls or the violation of the API function\ncontract, is marked in the program model with special built-in functions of the\nKEX analyzer. Later, when analyzing the program, KEX becomes able to detect\nintegration errors, since incorrect library usage scenarios are diagnosed as\ncalling marked functions. The proposed approach is implemented as SPIDER\n(SPecification-based Integration Defect Revealer), which is an extension of the\nKex analyzer and has proven its efficiency by detecting integration errors of\ndifferent classes on several special-made projects, as well as on several\nprojects taken from open repositories.",
    "descriptor": "\nComments: 12 pages, 2 figures, 5 listings To be published in Communications in Computer and Information Science book series\n",
    "authors": [
      "Vladislav Feofilaktov",
      "Vladimir Itsykson"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2202.03943"
  },
  {
    "id": "arXiv:2202.03944",
    "title": "Detecting Anomalies within Time Series using Local Neural  Transformations",
    "abstract": "We develop a new method to detect anomalies within time series, which is\nessential in many application domains, reaching from self-driving cars,\nfinance, and marketing to medical diagnosis and epidemiology. The method is\nbased on self-supervised deep learning that has played a key role in\nfacilitating deep anomaly detection on images, where powerful image\ntransformations are available. However, such transformations are widely\nunavailable for time series. Addressing this, we develop Local Neural\nTransformations(LNT), a method learning local transformations of time series\nfrom data. The method produces an anomaly score for each time step and thus can\nbe used to detect anomalies within time series. We prove in a theoretical\nanalysis that our novel training objective is more suitable for transformation\nlearning than previous deep Anomaly detection(AD) methods. Our experiments\ndemonstrate that LNT can find anomalies in speech segments from the LibriSpeech\ndata set and better detect interruptions to cyber-physical systems than\nprevious work. Visualization of the learned transformations gives insight into\nthe type of transformations that LNT learns.",
    "descriptor": "",
    "authors": [
      "Tim Schneider",
      "Chen Qiu",
      "Marius Kloft",
      "Decky Aspandi Latif",
      "Steffen Staab",
      "Stephan Mandt",
      "Maja Rudolph"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.03944"
  },
  {
    "id": "arXiv:2202.03947",
    "title": "Minimum-Time Quadrotor Waypoint Flight in Cluttered Environments",
    "abstract": "We tackle the problem of planning a minimum-time trajectory for a quadrotor\nover a sequence of specified waypoints in the presence of obstacles while\nexploiting the full quadrotor dynamics. This problem is crucial for autonomous\nsearch and rescue and drone racing scenarios but was, so far, unaddressed by\nthe robotics community \\emph{in its entirety} due to the challenges of\nminimizing time in the presence of the non-convex constraints posed by\ncollision avoidance. Early works relied on simplified dynamics or polynomial\ntrajectory representations that did not exploit the full actuator potential of\na quadrotor and, thus, did not aim at minimizing time. We address this\nchallenging problem by using a hierarchical, sampling-based method with an\nincrementally more complex quadrotor model. Our method first finds paths in\ndifferent topologies to guide subsequent trajectory search for a kinodynamic\npoint-mass model. Then, it uses an asymptotically-optimal, kinodynamic\nsampling-based method based on a full quadrotor model on top of the point-mass\nsolution to find a feasible trajectory with a time-optimal objective. The\nproposed method is shown to outperform all related baselines in cluttered\nenvironments and is further validated in real-world flights at over 60km/h in\none of the world's largest motion capture systems. We release the code open\nsource.",
    "descriptor": "\nComments: Accepted in IEEE Robotics and Automation Letters\n",
    "authors": [
      "Robert Penicka",
      "Davide Scaramuzza"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.03947"
  },
  {
    "id": "arXiv:2202.03949",
    "title": "Systematically improving existing k-means initialization algorithms at  nearly no cost, by pairwise-nearest-neighbor smoothing",
    "abstract": "We present a meta-method for initializing (seeding) the $k$-means clustering\nalgorithm called PNN-smoothing. It consists in splitting a given dataset into\n$J$ random subsets, clustering each of them individually, and merging the\nresulting clusterings with the pairwise-nearest-neighbor (PNN) method. It is a\nmeta-method in the sense that when clustering the individual subsets any\nseeding algorithm can be used. If the computational complexity of that seeding\nalgorithm is linear in the size of the data $N$ and the number of clusters $k$,\nPNN-smoothing is also almost linear with an appropriate choice of $J$, and in\nfact only at most a few percent slower in most cases in practice. We show\nempirically, using several existing seeding methods and testing on several\nsynthetic and real datasets, that this procedure results in systematically\nbetter costs. It can even be applied recursively, and easily parallelized. Our\nimplementation is publicly available at\nhttps://github.com/carlobaldassi/KMeansPNNSmoothing.jl",
    "descriptor": "\nComments: 10 pages (+10 appendix), 2 figures (+1 appendix), 3 tables (+11 appendix)\n",
    "authors": [
      "Carlo Baldassi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.03949"
  },
  {
    "id": "arXiv:2202.03950",
    "title": "PACSan: Enforcing Memory Safety Based on ARM PA",
    "abstract": "Memory safety is a key security property that stops memory corruption\nvulnerabilities. Existing sanitizers enforce checks and catch such bugs during\ndevelopment and testing. However, they either provide partial memory safety or\nhave overwhelmingly high performance overheads. Our novel sanitizer PACSan\nenforces spatial and temporal memory safety with no false positives at low\nperformance overheads. PACSan removes the majority of the overheads involved in\npointer tracking by sealing metadata in pointers through ARM PA (Pointer\nAuthentication), and performing the memory safety checks when pointers are\ndereferenced. We have developed a prototype of PACSan and systematically\nevaluated its security and performance on the Magma, Juliet, Nginx, and SPEC\nCPU2017 test suites, respectively. In our evaluation, PACSan shows no false\npositives together with negligible false negatives, while introducing stronger\nsecurity guarantees and lower performance overheads than state-of-the-art\nsanitizers, including HWASan, ASan, SoftBound+CETS, Memcheck, LowFat, and\nPTAuth. Specifically, PACSan has 0.84x runtime overhead and 1.92x memory\noverhead on average. Compared to the widely deployed ASan, PACSan has no false\npositives and much fewer false negatives and reduces 7.172% runtime overheads\nand 89.063%memory overheads.",
    "descriptor": "\nComments: 11 pages\n",
    "authors": [
      "Yuan Li",
      "Wende Tan",
      "Zhizheng Lv",
      "Songtao Yang",
      "Mathias Payer",
      "Ying Liu",
      "Chao Zhang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.03950"
  },
  {
    "id": "arXiv:2202.03951",
    "title": "On Sibson's $\u03b1$-Mutual Information",
    "abstract": "We explore a family of information measures that stems from R\\'enyi's\n$\\alpha$-Divergences with $\\alpha<0$. In particular, we extend the definition\nof Sibson's $\\alpha$-Mutual Information to negative values of $\\alpha$ and show\nseveral properties of these objects. Moreover, we highlight how this family of\ninformation measures is related to functional inequalities that can be employed\nin a variety of fields, including lower-bounds on the Risk in Bayesian\nEstimation Procedures.",
    "descriptor": "\nComments: Submitted to ISIT 2022\n",
    "authors": [
      "Amedeo Roberto Esposito",
      "Adrien Vandenbroucque",
      "Michael Gastpar"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2202.03951"
  },
  {
    "id": "arXiv:2202.03954",
    "title": "Social-DualCVAE: Multimodal Trajectory Forecasting Based on Social  Interactions Pattern Aware and Dual Conditional Variational Auto-Encoder",
    "abstract": "Pedestrian trajectory forecasting is a fundamental task in multiple utility\nareas, such as self-driving, autonomous robots, and surveillance systems. The\nfuture trajectory forecasting is multi-modal, influenced by physical\ninteraction with scene contexts and intricate social interactions among\npedestrians. The mainly existing literature learns representations of social\ninteractions by deep learning networks, while the explicit interaction patterns\nare not utilized. Different interaction patterns, such as following or\ncollision avoiding, will generate different trends of next movement, thus, the\nawareness of social interaction patterns is important for trajectory\nforecasting. Moreover, the social interaction patterns are privacy concerned or\nlack of labels. To jointly address the above issues, we present a social-dual\nconditional variational auto-encoder (Social-DualCVAE) for multi-modal\ntrajectory forecasting, which is based on a generative model conditioned not\nonly on the past trajectories but also the unsupervised classification of\ninteraction patterns. After generating the category distribution of the\nunlabeled social interaction patterns, DualCVAE, conditioned on the past\ntrajectories and social interaction pattern, is proposed for multi-modal\ntrajectory prediction by latent variables estimating. A variational bound is\nderived as the minimization objective during training. The proposed model is\nevaluated on widely used trajectory benchmarks and outperforms the prior\nstate-of-the-art methods.",
    "descriptor": "",
    "authors": [
      "Jiashi Gao",
      "Xinming Shi",
      "James J.Q. Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.03954"
  },
  {
    "id": "arXiv:2202.03956",
    "title": "From Generalisation Error to Transportation-cost Inequalities and Back",
    "abstract": "In this work, we connect the problem of bounding the expected generalisation\nerror with transportation-cost inequalities. Exposing the underlying pattern\nbehind both approaches we are able to generalise them and go beyond\nKullback-Leibler Divergences/Mutual Information and sub-Gaussian measures. In\nparticular, we are able to provide a result showing the equivalence between two\nfamilies of inequalities: one involving functionals and one involving measures.\nThis result generalises the one proposed by Bobkov and G\\\"otze that connects\ntransportation-cost inequalities with concentration of measure. Moreover, it\nallows us to recover all standard generalisation error bounds involving mutual\ninformation and to introduce new, more general bounds, that involve arbitrary\ndivergence measures.",
    "descriptor": "\nComments: Submitted to ISIT 2022\n",
    "authors": [
      "Amedeo Roberto Esposito",
      "Michael Gastpar"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Functional Analysis (math.FA)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2202.03956"
  },
  {
    "id": "arXiv:2202.03957",
    "title": "Bingham Policy Parameterization for 3D Rotations in Reinforcement  Learning",
    "abstract": "We propose a new policy parameterization for representing 3D rotations during\nreinforcement learning. Today in the continuous control reinforcement learning\nliterature, many stochastic policy parameterizations are Gaussian. We argue\nthat universally applying a Gaussian policy parameterization is not always\ndesirable for all environments. One such case in particular where this is true\nare tasks that involve predicting a 3D rotation output, either in isolation, or\ncoupled with translation as part of a full 6D pose output. Our proposed Bingham\nPolicy Parameterization (BPP) models the Bingham distribution and allows for\nbetter rotation (quaternion) prediction over a Gaussian policy parameterization\nin a range of reinforcement learning tasks. We evaluate BPP on the rotation\nWahba problem task, as well as a set of vision-based next-best pose robot\nmanipulation tasks from RLBench. We hope that this paper encourages more\nresearch into developing other policy parameterization that are more suited for\nparticular environments, rather than always assuming Gaussian.",
    "descriptor": "\nComments: Project page and code: this https URL\n",
    "authors": [
      "Stephen James",
      "Pieter Abbeel"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.03957"
  },
  {
    "id": "arXiv:2202.03958",
    "title": "Uncertainty Modeling for Out-of-Distribution Generalization",
    "abstract": "Though remarkable progress has been achieved in various vision tasks, deep\nneural networks still suffer obvious performance degradation when tested in\nout-of-distribution scenarios. We argue that the feature statistics (mean and\nstandard deviation), which carry the domain characteristics of the training\ndata, can be properly manipulated to improve the generalization ability of deep\nlearning models. Common methods often consider the feature statistics as\ndeterministic values measured from the learned features and do not explicitly\nconsider the uncertain statistics discrepancy caused by potential domain shifts\nduring testing. In this paper, we improve the network generalization ability by\nmodeling the uncertainty of domain shifts with synthesized feature statistics\nduring training. Specifically, we hypothesize that the feature statistic, after\nconsidering the potential uncertainties, follows a multivariate Gaussian\ndistribution. Hence, each feature statistic is no longer a deterministic value,\nbut a probabilistic point with diverse distribution possibilities. With the\nuncertain feature statistics, the models can be trained to alleviate the domain\nperturbations and achieve better robustness against potential domain shifts.\nOur method can be readily integrated into networks without additional\nparameters. Extensive experiments demonstrate that our proposed method\nconsistently improves the network generalization ability on multiple vision\ntasks, including image classification, semantic segmentation, and instance\nretrieval. The code will be released soon at\nhttps://github.com/lixiaotong97/DSU.",
    "descriptor": "\nComments: Accepted by ICLR 2022\n",
    "authors": [
      "Xiaotong Li",
      "Yongxing Dai",
      "Yixiao Ge",
      "Jun Liu",
      "Ying Shan",
      "Ling-Yu Duan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.03958"
  },
  {
    "id": "arXiv:2202.03961",
    "title": "Predicting Voting Outcomes in the Presence of Communities, Echo Chambers  and Multiple Parties",
    "abstract": "A recently proposed graph-theoretic metric, the influence gap, has shown to\nbe a reliable predictor of the effect of social influence in two-party\nelections, albeit only tested on regular and scale-free graphs. Here, we\ninvestigate whether the influence gap is able to predict the outcome of\nmulti-party elections on networks exhibiting community structure, i.e., made of\nhighly interconnected components, and therefore more resembling of real-world\ninteraction. To encode communities we build on the classical model of caveman\ngraphs, which we extend to a richer graph family that displays different levels\nof homophily, i.e., how much connections and opinions are intertwined. First,\nwe study the predictive power of the influence gap in the presence of\ncommunities. We show that when there is no clear initial majority the influence\ngap is not a good predictor of the election outcome. When we instead allow for\nvarying majorities, although the influence gap improves as a predictor,\ncounting the initial partisan majority does consistently better, across all\nlevels of homophily. Second, we study the combined effect of the more\npredictive metrics, as function of the homophily levels. Using regression\nmodels, we demonstrate that the influence gap combined with the initial votes\ncount does increase the overall predictive power for some levels of homophily.\nThird, we study elections with more than two parties. Specifically, we extend\nthe definition of the influence gap to any number of parties, considering\nvarious generalisations, and show that the initial votes count has an even\nhigher predictive power when compared to influence gap than it did in the\ntwo-party case.",
    "descriptor": "",
    "authors": [
      "Jacques Bara",
      "Omer Lev",
      "Paolo Turrini"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Multiagent Systems (cs.MA)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2202.03961"
  },
  {
    "id": "arXiv:2202.03966",
    "title": "Blockchain-based Digital Twin for Supply Chain Management: A Literature  Review and Future Research Directions",
    "abstract": "Supply chain management plays an essential role in our economy, as evidenced\nby recent COVID-19-induced supply chain challenges. Traditional supply chain\nmanagement faces security and efficiency issues, but they can be addressed by\nleveraging digital twins and blockchain technology. The integration of\nblockchain technology can benefit the digital twins through improved security,\ntraceability, transparency, and efficiency of digital twin data processing. A\ndigital twin is an exact virtual representation of a physical asset, system, or\nprocess to synchronise data for the monitoring, simulation, and prediction of\nperformance. Thus, the combination of blockchain and digital twins can refine\nthe concepts of both technologies and reform supply chain management to advance\ninto Industry 4.0. In this literature survey, we provide a comprehensive\nliterature review of the blockchain-based digital twin solutions to optimise\nthe processes of data management, data storage, and data sharing. We also\ninvestigate the key benefits of the integration of blockchain and digital twins\nand study their potential implementation in various processes of supply chains,\nincluding smart manufacturing, intelligent maintenance, and blockchain-based\ndigital twin shop floor, warehouse, and logistics. This paper has implications\nfor research and practice, which we detail in future research opportunities.",
    "descriptor": "",
    "authors": [
      "Jiongbin Liu",
      "William Yeoh",
      "Youyang Qu",
      "Longxiang Gao"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.03966"
  },
  {
    "id": "arXiv:2202.03967",
    "title": "Improving the Sample-Complexity of Deep Classification Networks with  Invariant Integration",
    "abstract": "Leveraging prior knowledge on intraclass variance due to transformations is a\npowerful method to improve the sample complexity of deep neural networks. This\nmakes them applicable to practically important use-cases where training data is\nscarce. Rather than being learned, this knowledge can be embedded by enforcing\ninvariance to those transformations. Invariance can be imposed using\ngroup-equivariant convolutions followed by a pooling operation.\nFor rotation-invariance, previous work investigated replacing the spatial\npooling operation with invariant integration which explicitly constructs\ninvariant representations. Invariant integration uses monomials which are\nselected using an iterative approach requiring expensive pre-training. We\npropose a novel monomial selection algorithm based on pruning methods to allow\nan application to more complex problems. Additionally, we replace monomials\nwith different functions such as weighted sums, multi-layer perceptrons and\nself-attention, thereby streamlining the training of\ninvariant-integration-based architectures.\nWe demonstrate the improved sample complexity on the Rotated-MNIST, SVHN and\nCIFAR-10 datasets where rotation-invariant-integration-based Wide-ResNet\narchitectures using monomials and weighted sums outperform the respective\nbaselines in the limited sample regime. We achieve state-of-the-art results\nusing full data on Rotated-MNIST and SVHN where rotation is a main source of\nintraclass variation. On STL-10 we outperform a standard and a\nrotation-equivariant convolutional neural network using pooling.",
    "descriptor": "\nComments: Accepted at VISAPP 2022\n",
    "authors": [
      "Matthias Rath",
      "Alexandru Paul Condurache"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.03967"
  },
  {
    "id": "arXiv:2202.03968",
    "title": "Self-supervised Contrastive Learning for Cross-domain Hyperspectral  Image Representation",
    "abstract": "Recently, self-supervised learning has attracted attention due to its\nremarkable ability to acquire meaningful representations for classification\ntasks without using semantic labels. This paper introduces a self-supervised\nlearning framework suitable for hyperspectral images that are inherently\nchallenging to annotate. The proposed framework architecture leverages\ncross-domain CNN, allowing for learning representations from different\nhyperspectral images with varying spectral characteristics and no pixel-level\nannotation. In the framework, cross-domain representations are learned via\ncontrastive learning where neighboring spectral vectors in the same image are\nclustered together in a common representation space encompassing multiple\nhyperspectral images. In contrast, spectral vectors in different hyperspectral\nimages are separated into distinct clusters in the space. To verify that the\nlearned representation through contrastive learning is effectively transferred\ninto a downstream task, we perform a classification task on hyperspectral\nimages. The experimental results demonstrate the advantage of the proposed\nself-supervised representation over models trained from scratch or other\ntransfer learning methods.",
    "descriptor": "\nComments: Accepted to ICASSP 2022\n",
    "authors": [
      "Hyungtae Lee",
      "Heesung Kwon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.03968"
  },
  {
    "id": "arXiv:2202.03971",
    "title": "Computing Rule-Based Explanations of Machine Learning Classifiers using  Knowledge Graphs",
    "abstract": "The use of symbolic knowledge representation and reasoning as a way to\nresolve the lack of transparency of machine learning classifiers is a research\narea that lately attracts many researchers. In this work, we use knowledge\ngraphs as the underlying framework providing the terminology for representing\nexplanations for the operation of a machine learning classifier. In particular,\ngiven a description of the application domain of the classifier in the form of\na knowledge graph, we introduce a novel method for extracting and representing\nblack-box explanations of its operation, in the form of first-order logic rules\nexpressed in the terminology of the knowledge graph.",
    "descriptor": "",
    "authors": [
      "Edmund Dervakos",
      "Orfeas Menis-Mastromichalakis",
      "Alexandros Chortaras",
      "Giorgos Stamou"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.03971"
  },
  {
    "id": "arXiv:2202.03973",
    "title": "Hearing Loss, Cognitive Load and Dementia: An Overview of Interrelation,  Detection and Monitoring Challenges with Wearable Non-invasive Microwave  Sensors",
    "abstract": "This paper provides an overview of hearing loss effects on neurological\nfunction and progressive diseases; and explores the role of cognitive load\nmonitoring to detect dementia. It also investigates the prospects of utilizing\nhearing aid technology to reverse cognitive decline and delay the onset of\ndementia, for the old age population. The interrelation between hearing loss,\ncognitive load and dementia is discussed. Future considerations for improvement\nwith respect to robust diagnosis, user centricity, device accuracy and privacy\nfor wider clinical practice is also explored. The review concludes by\ndiscussing the future scope and potential of designing practical wearable\nmicrowave technologies and evaluating their use in smart care homes setting.",
    "descriptor": "\nComments: 5 pages, 1 figure, conference (submitted)\n",
    "authors": [
      "Usman Anwar",
      "Tughrul Arslan",
      "Amir Hussain"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.03973"
  },
  {
    "id": "arXiv:2202.03974",
    "title": "Rainbow Differential Privacy",
    "abstract": "We extend a previous framework for designing differentially private (DP)\nmechanisms via randomized graph colorings that was restricted to binary\nfunctions, corresponding to colorings in a graph, to multi-valued functions. As\nbefore, datasets are nodes in the graph and any two neighboring datasets are\nconnected by an edge. In our setting, we assume each dataset has a preferential\nordering for the possible outputs of the mechanism, which we refer to as a\nrainbow. Different rainbows partition the graph of datasets into different\nregions. We show that when the DP mechanism is pre-specified at the boundary of\nsuch regions, at most one optimal mechanism can exist. Moreover, if the\nmechanism is to behave identically for all same-rainbow boundary datasets, the\nproblem can be greatly simplified and solved by means of a morphism to a line\ngraph. We then show closed form expressions for the line graph in the case of\nternary functions. Treatment of ternary queries in this paper displays enough\nrichness to be extended to higher-dimensional query spaces with preferential\nquery ordering, but the optimality proof does not seem to follow directly from\nthe ternary proof.",
    "descriptor": "",
    "authors": [
      "Ziqi Zhou",
      "Onur G\u00fcnl\u00fc",
      "Rafael G. L. D'Oliveira",
      "Muriel M\u00e9dard",
      "Parastoo Sadeghi",
      "Rafael F. Schaefer"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.03974"
  },
  {
    "id": "arXiv:2202.03976",
    "title": "Communication-Control Co-design in Wireless Edge Industrial Systems",
    "abstract": "We consider the problem of controlling a series of industrial systems, such\nas industrial robotics, in a factory environment over a shared wireless channel\nleveraging edge computing capabilities. The wireless control system model\nsupports the offloading of computational intensive functions, such as\nperception workloads, to an edge server. However, wireless communications is\nprone to packet loss and latency and can lead to instability or task failure if\nthe link is not kept sufficiently reliable. Because maintaining high\nreliability and low latency at all times prohibits scalability due to resource\nlimitations, we propose a communication-control co-design paradigm that varies\nthe network quality of service (QoS) and resulting control actions to the\ndynamic needs of each plant. We further propose a modular learning framework to\nsolve the complex learning task without knowledge of plant or communication\nmodels in a series of learning steps and demonstrate its effectiveness in\nlearning resource-efficient co-design policies in a robotic conveyor belt task.",
    "descriptor": "",
    "authors": [
      "Mark Eisen",
      "Santosh Shukla",
      "Dave Cavalcanti",
      "Amit S. Baxi"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.03976"
  },
  {
    "id": "arXiv:2202.03977",
    "title": "List Decoding of Quaternary Codes in the Lee Metric",
    "abstract": "We present a list decoding algorithm for quaternary negacyclic codes over the\nLee metric. To achieve this result, we use a Sudan-Guruswami type list decoding\nalgorithm for Reed-Solomon codes over certain ring alphabets. Our decoding\nstrategy for negacyclic codes over the ring $\\mathbb Z_4$ combines the list\ndecoding algorithm by Wu with the Gr\\\"obner basis approach for solving a key\nequation due to Byrne and Fitzpatrick.",
    "descriptor": "\nComments: 5 pages\n",
    "authors": [
      "Marcus Greferath",
      "Jens Zumbr\u00e4gel"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.03977"
  },
  {
    "id": "arXiv:2202.03978",
    "title": "Segmentation by Test-Time Optimization (TTO) for CBCT-based Adaptive  Radiation Therapy",
    "abstract": "Online adaptive radiotherapy (ART) requires accurate and efficient\nauto-segmentation of target volumes and organs-at-risk (OARs) in mostly\ncone-beam computed tomography (CBCT) images. Propagating expert-drawn contours\nfrom the pre-treatment planning CT (pCT) through traditional or deep learning\n(DL) based deformable image registration (DIR) can achieve improved results in\nmany situations. Typical DL-based DIR models are population based, that is,\ntrained with a dataset for a population of patients, so they may be affected by\nthe generalizability problem. In this paper, we propose a method called\ntest-time optimization (TTO) to refine a pre-trained DL-based DIR population\nmodel, first for each individual test patient, and then progressively for each\nfraction of online ART treatment. Our proposed method is less susceptible to\nthe generalizability problem, and thus can improve overall performance of\ndifferent DL-based DIR models by improving model accuracy, especially for\noutliers. Our experiments used data from 239 patients with head and neck\nsquamous cell carcinoma to test the proposed method. Firstly, we trained a\npopulation model with 200 patients, and then applied TTO to the remaining 39\ntest patients by refining the trained population model to obtain 39\nindividualized models. We compared each of the individualized models with the\npopulation model in terms of segmentation accuracy. The number of patients with\nat least 0.05 DSC improvement or 2 mm HD95 improvement by TTO averaged over the\n17 selected structures for the state-of-the-art architecture Voxelmorph is 10\nout of 39 test patients. The average time for deriving the individualized model\nusing TTO from the pre-trained population model is approximately four minutes.\nWhen adapting the individualized model to a later fraction of the same patient,\nthe average time is reduced to about one minute and the accuracy is slightly\nimproved.",
    "descriptor": "",
    "authors": [
      "Xiao Liang",
      "Jaehee Chun",
      "Howard Morgan",
      "Ti Bai",
      "Dan Nguyen",
      "Justin C. Park",
      "Steve Jiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Medical Physics (physics.med-ph)"
    ],
    "url": "https://arxiv.org/abs/2202.03978"
  },
  {
    "id": "arXiv:2202.03980",
    "title": "Transferable Student Performance Modeling for Intelligent Tutoring  Systems",
    "abstract": "Millions of learners worldwide are now using intelligent tutoring systems\n(ITSs). At their core, ITSs rely on machine learning algorithms to track each\nuser's changing performance level over time to provide personalized\ninstruction. Crucially, student performance models are trained using\ninteraction sequence data of previous learners to analyse data generated by\nfuture learners. This induces a cold-start problem when a new course is\nintroduced for which no training data is available. Here, we consider transfer\nlearning techniques as a way to provide accurate performance predictions for\nnew courses by leveraging log data from existing courses. We study two\nsettings: (i) In the naive transfer setting, we propose course-agnostic\nperformance models that can be applied to any course. (ii) In the inductive\ntransfer setting, we tune pre-trained course-agnostic performance models to new\ncourses using small-scale target course data (e.g., collected during a pilot\nstudy). We evaluate the proposed techniques using student interaction sequence\ndata from 5 different mathematics courses containing data from over 47,000\nstudents in a real world large-scale ITS. The course-agnostic models that use\nadditional features provided by human domain experts (e.g, difficulty ratings\nfor questions in the new course) but no student interaction training data for\nthe new course, achieve prediction accuracy on par with standard BKT and PFA\nmodels that use training data from thousands of students in the new course. In\nthe inductive setting our transfer learning approach yields more accurate\npredictions than conventional performance models when only limited student\ninteraction training data (<100 students) is available to both.",
    "descriptor": "",
    "authors": [
      "Robin Schmucker",
      "Tom M. Mitchell"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2202.03980"
  },
  {
    "id": "arXiv:2202.03983",
    "title": "Provable Reinforcement Learning with a Short-Term Memory",
    "abstract": "Real-world sequential decision making problems commonly involve partial\nobservability, which requires the agent to maintain a memory of history in\norder to infer the latent states, plan and make good decisions. Coping with\npartial observability in general is extremely challenging, as a number of\nworst-case statistical and computational barriers are known in learning\nPartially Observable Markov Decision Processes (POMDPs). Motivated by the\nproblem structure in several physical applications, as well as a commonly used\ntechnique known as \"frame stacking\", this paper proposes to study a new\nsubclass of POMDPs, whose latent states can be decoded by the most recent\nhistory of a short length $m$. We establish a set of upper and lower bounds on\nthe sample complexity for learning near-optimal policies for this class of\nproblems in both tabular and rich-observation settings (where the number of\nobservations is enormous). In particular, in the rich-observation setting, we\ndevelop new algorithms using a novel \"moment matching\" approach with a sample\ncomplexity that scales exponentially with the short length $m$ rather than the\nproblem horizon, and is independent of the number of observations. Our results\nshow that a short-term memory suffices for reinforcement learning in these\nenvironments.",
    "descriptor": "",
    "authors": [
      "Yonathan Efroni",
      "Chi Jin",
      "Akshay Krishnamurthy",
      "Sobhan Miryoosefi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.03983"
  },
  {
    "id": "arXiv:2202.03984",
    "title": "CAUSPref: Causal Preference Learning for Out-of-Distribution  Recommendation",
    "abstract": "In spite of the tremendous development of recommender system owing to the\nprogressive capability of machine learning recently, the current recommender\nsystem is still vulnerable to the distribution shift of users and items in\nrealistic scenarios, leading to the sharp decline of performance in testing\nenvironments. It is even more severe in many common applications where only the\nimplicit feedback from sparse data is available. Hence, it is crucial to\npromote the performance stability of recommendation method in different\nenvironments. In this work, we first make a thorough analysis of implicit\nrecommendation problem from the viewpoint of out-of-distribution (OOD)\ngeneralization. Then under the guidance of our theoretical analysis, we propose\nto incorporate the recommendation-specific DAG learner into a novel causal\npreference-based recommendation framework named CAUSPref, mainly consisting of\ncausal learning of invariant user preference and anti-preference negative\nsampling to deal with implicit feedback. Extensive experimental results from\nreal-world datasets clearly demonstrate that our approach surpasses the\nbenchmark models significantly under types of out-of-distribution settings, and\nshow its impressive interpretability.",
    "descriptor": "\nComments: WWW '22: The ACM Web Conference Proceedings\n",
    "authors": [
      "Yue He",
      "Zimu Wang",
      "Peng Cui",
      "Hao Zou",
      "Yafeng Zhang",
      "Qiang Cui",
      "Yong Jiang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.03984"
  },
  {
    "id": "arXiv:2202.03986",
    "title": "Analysis of Voltage Stability in Terms of Interactions of  Q(U)-Characteristic Control in Distribution Grids",
    "abstract": "As the amount of volatile, renewable energy sources in power distribution\ngrids is increasing, the stability of the latter is a vital aspect for grid\noperators. Within the STABEEL project, the authors develop rules on how to\nparametrize the reactive power control of distributed energy resources to\nincrease the performance while guaranteeing stability. The work focuses on\ndistribution grids with a high penetration of distributed energy resources\nequipped with Q(U)-characteristic. This contribution is based on the stability\nassessment of previous work and introduces a new approach to stability\nutilizing the circle criterion. With the aim of extending existing technical\nguidelines, stability assessment methods are applied to various distribution\ngrids - including those from the SimBench project. Herein, distributed energy\nresources can be modelled as detailed control loops or as derived\napproximations based on technical guidelines.",
    "descriptor": "\nComments: 7 pages Submitted to 5th International Conference on Smart Energy Systems and Technologies (SEST)\n",
    "authors": [
      "Sebastian Krahmer",
      "Stefan Ecklebe",
      "Peter Schegner",
      "Klaus Roebenack"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.03986"
  },
  {
    "id": "arXiv:2202.03987",
    "title": "Data Consistency for Weakly Supervised Learning",
    "abstract": "In many applications, training machine learning models involves using large\namounts of human-annotated data. Obtaining precise labels for the data is\nexpensive. Instead, training with weak supervision provides a low-cost\nalternative. We propose a novel weak supervision algorithm that processes noisy\nlabels, i.e., weak signals, while also considering features of the training\ndata to produce accurate labels for training. Our method searches over\nclassifiers of the data representation to find plausible labelings. We call\nthis paradigm data consistent weak supervision. A key facet of our framework is\nthat we are able to estimate labels for data examples low or no coverage from\nthe weak supervision. In addition, we make no assumptions about the joint\ndistribution of the weak signals and true labels of the data. Instead, we use\nweak signals and the data features to solve a constrained optimization that\nenforces data consistency among the labels we generate. Empirical evaluation of\nour method on different datasets shows that it significantly outperforms\nstate-of-the-art weak supervision methods on both text and image classification\ntasks.",
    "descriptor": "",
    "authors": [
      "Chidubem Arachie",
      "Bert Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.03987"
  },
  {
    "id": "arXiv:2202.03989",
    "title": "The amazing mixed polynomial closure and its applications to  two-variable first-order logic",
    "abstract": "Polynomial closure is a standard operator which is applied to a class of\nregular languages. In the paper, we investigate three restrictions called left\n(LPol), right (RPol) and mixed polynomial closure (MPol). The first two were\nknown while MPol is new. We look at two decision problems that are defined for\nevery class C. Membership takes a regular language as input and asks if it\nbelongs to C. Separation takes two regular languages as input and asks if there\nexists a third language in C including the first one and disjoint from the\nsecond. We prove that LPol, RPol and MPol preserve the decidability of\nmembership under mild hypotheses on the input class, and the decidability of\nseparation under much stronger hypotheses. We apply these results to natural\nhierarchies.\nFirst, we look at several language theoretic hierarchies that are built by\napplying LPol, RPol and MPol recursively to a single input class. We prove that\nthese hierarchies can actually be defined using almost exclusively MPol. We\nalso consider quantifier alternation hierarchies for two-variable first-order\nlogic and prove that one can climb them using MPol. The result is generic in\nthe sense that it holds for most standard choices of signatures. We use it to\nprove that for most of these choices, membership is decidable for all levels in\nthe hierarchy. Finally, we prove that separation is decidable for the hierarchy\nof two-variable first-order logic equipped with only the linear order.",
    "descriptor": "",
    "authors": [
      "Thomas Place"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2202.03989"
  },
  {
    "id": "arXiv:2202.03990",
    "title": "Equivariance versus Augmentation for Spherical Images",
    "abstract": "We analyze the role of rotational equivariance in convolutional neural\nnetworks (CNNs) applied to spherical images. We compare the performance of the\ngroup equivariant networks known as S2CNNs and standard non-equivariant CNNs\ntrained with an increasing amount of data augmentation. The chosen\narchitectures can be considered baseline references for the respective design\nparadigms. Our models are trained and evaluated on single or multiple items\nfrom the MNIST or FashionMNIST dataset projected onto the sphere. For the task\nof image classification, which is inherently rotationally invariant, we find\nthat by considerably increasing the amount of data augmentation and the size of\nthe networks, it is possible for the standard CNNs to reach at least the same\nperformance as the equivariant network. In contrast, for the inherently\nequivariant task of semantic segmentation, the non-equivariant networks are\nconsistently outperformed by the equivariant networks with significantly fewer\nparameters. We also analyze and compare the inference latency and training\ntimes of the different networks, enabling detailed tradeoff considerations\nbetween equivariant architectures and data augmentation for practical problems.\nThe equivariant spherical networks used in the experiments will be made\navailable at https://github.com/JanEGerken/sem_seg_s2cnn .",
    "descriptor": "\nComments: 19 pages of which 8 in main body, 16 figures\n",
    "authors": [
      "Jan E. Gerken",
      "Oscar Carlsson",
      "Hampus Linander",
      "Fredrik Ohlsson",
      "Christoffer Petersson",
      "Daniel Persson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.03990"
  },
  {
    "id": "arXiv:2202.03993",
    "title": "Topological Authentication Technique In Topologically Asymmetric  Cryptosystem",
    "abstract": "Making topological authentication from theory to practical application is an\nimportant and challenging task. More and more researchers pay attention on\ncoming quantum computation, privacy data protection, lattices and cryptography.\nResearch show the advantages of topological authentications through graph\noperations, various matrices, graph colorings and graph labelings are: related\nwith two or more different mathematical areas, be not pictures, there are huge\nnumber of colorings and labelings, rooted on modern mathematics, diversity of\nasymmetric ciphers, simplicity and convenience, easily created,\nirreversibility, computational security, provable security, and so on.\nTopological authentications based on various graph homomorphisms,\ndegree-sequence homomorphisms, graph-set homomorphisms. Randomly topological\ncoding and topological authentications are based on Hanzi authentication,\nrandomly adding-edge-removing operation, randomly leaf-adding algorithms, graph\nrandom increasing techniques, operation graphic lattice and dynamic networked\nmodels and their spanning trees and maximum leaf spanning trees. Realization of\ntopological authentication is an important topic, we study: number-based\nstrings generated from colored graphs, particular graphs (complete graphs,\ntrees, planar graphs), some methods of generating public-keys. some techniques\nof topologically asymmetric cryptosystem are: W-type matching labelings,\ndual-type labelings, reciprocal-type labelings, topological homomorphisms,\nindexed colorings, graphic lattices, degree-sequence lattices, every-zero\nCds-matrix groups of degree-sequences, every-zero graphic groups, graphic\nlattices having coloring closure property, self-similar networked lattices.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2106.15254\n",
    "authors": [
      "Bing Yao",
      "Jing Su",
      "Fei Ma",
      "Hongyu Wang",
      "Chao Yang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.03993"
  },
  {
    "id": "arXiv:2202.03997",
    "title": "Wi-Fi Rate Adaptation using a Simple Deep Reinforcement Learning  Approach",
    "abstract": "The increasing complexity of recent Wi-Fi amendments is making optimal Rate\nAdaptation (RA) a challenge. The use of classic algorithms or heuristic models\nto address RA is becoming unfeasible due to the large combination of\nconfiguration parameters along with the variability of the wireless channel.\nMachine Learning-based solutions have been proposed in the state of art, to\ndeal with this complexity. However, they typically use complex models and their\nimplementation in real scenarios is difficult. We propose a simple Deep\nReinforcement Learning approach for the automatic RA in Wi-Fi networks, named\nData-driven Algorithm for Rate Adaptation (DARA). DARA is standard-compliant.\nIt dynamically adjusts the Wi-Fi Modulation and Coding Scheme (MCS) solely\nbased on the observation of the Signal-to-Noise Ratio (SNR) of the received\nframes at the transmitter. Our simulation results show that DARA achieves up to\n15\\% higher throughput when compared with Minstrel High Throughput (HT) and\nequals the performance of the Ideal Wi-Fi RA algorithm.",
    "descriptor": "",
    "authors": [
      "Ruben Queiros",
      "Eduardo Almeida",
      "Helder Fontes",
      "Jose Ruela",
      "Rui Campos"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2202.03997"
  },
  {
    "id": "arXiv:2202.04000",
    "title": "Learning Sinkhorn divergences for supervised change point detection",
    "abstract": "Many modern applications require detecting change points in complex\nsequential data. Most existing methods for change point detection are\nunsupervised and, as a consequence, lack any information regarding what kind of\nchanges we want to detect or if some kinds of changes are safe to ignore. This\noften results in poor change detection performance. We present a novel change\npoint detection framework that uses true change point instances as supervision\nfor learning a ground metric such that Sinkhorn divergences can be then used in\ntwo-sample tests on sliding windows to detect change points in an online\nmanner. Our method can be used to learn a sparse metric which can be useful for\nboth feature selection and interpretation in high-dimensional change point\ndetection settings. Experiments on simulated as well as real world sequences\nshow that our proposed method can substantially improve change point detection\nperformance over existing unsupervised change point detection methods using\nonly few labeled change point instances.",
    "descriptor": "\nComments: 19 pages, 13 figures\n",
    "authors": [
      "Nauman Ahad",
      "Eva L. Dyer",
      "Keith B. Hengen",
      "Yao Xie",
      "Mark A. Davenport"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.04000"
  },
  {
    "id": "arXiv:2202.04003",
    "title": "Differentiable N-gram Objective on Abstractive Summarization",
    "abstract": "ROUGE is a standard automatic evaluation metric based on n-grams for\nsequence-to-sequence tasks, while cross-entropy loss is an essential objective\nof neural network language model that optimizes at a unigram level. We present\ndifferentiable n-gram objectives, attempting to alleviate the discrepancy\nbetween training criterion and evaluating criterion. The objective maximizes\nthe probabilistic weight of matched sub-sequences, and the novelty of our work\nis the objective weights the matched sub-sequences equally and does not ceil\nthe number of matched sub-sequences by the ground truth count of n-grams in\nreference sequence. We jointly optimize cross-entropy loss and the proposed\nobjective, providing decent ROUGE score enhancement over abstractive\nsummarization dataset CNN/DM and XSum, outperforming alternative n-gram\nobjectives.",
    "descriptor": "",
    "authors": [
      "Yunqi Zhu",
      "Wensheng Zhang",
      "Mingjin Zhu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.04003"
  },
  {
    "id": "arXiv:2202.04005",
    "title": "Improved Convergence Rates for Sparse Approximation Methods in  Kernel-Based Learning",
    "abstract": "Kernel-based models such as kernel ridge regression and Gaussian processes\nare ubiquitous in machine learning applications for regression and\noptimization. It is well known that a serious downside for kernel-based models\nis the high computational cost; given a dataset of $n$ samples, the cost grows\nas $\\mathcal{O}(n^3)$. Existing sparse approximation methods can yield a\nsignificant reduction in the computational cost, effectively reducing the real\nworld cost down to as low as $\\mathcal{O}(n)$ in certain cases. Despite this\nremarkable empirical success, significant gaps remain in the existing results\nfor the analytical confidence bounds on the error due to approximation. In this\nwork, we provide novel confidence intervals for the Nystr\\\"om method and the\nsparse variational Gaussian processes approximation method. Our confidence\nintervals lead to improved error bounds in both regression and optimization. We\nestablish these confidence intervals using novel interpretations of the\napproximate (surrogate) posterior variance of the models.",
    "descriptor": "",
    "authors": [
      "Sattar Vakili",
      "Jonathan Scarlett",
      "Da-shan Shiu",
      "Alberto Bernacchia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.04005"
  },
  {
    "id": "arXiv:2202.04006",
    "title": "VC-density and abstract cell decomposition for edge relation in graphs  of bounded twin-width",
    "abstract": "We study set systems formed by neighborhoods in graphs of bounded twin-width.\nIn particular, we prove that such classes of graphs admit linear neighborhood\ncomplexity, in analogy to previous results concerning classes with bounded\nexpansion and classes of bounded clique-width. Additionally, we show how, for a\ngiven graph from a class of graphs of bounded twin-width, to efficiently encode\nthe neighborhood of a vertex in a given set of vertices $A$ of the graph. For\nthe encoding we use only a constant number of vertices from $A$. The obtained\nencoding can be decoded using FO formulas. This proves that the edge relation\nin graphs of bounded twin-width, seen as first-order structures, admits a\ndefinable distal cell decomposition. From this fact we derive that we can apply\nto such classes combinatorial tools based on the Distal cutting lemma and the\nDistal regularity lemma.",
    "descriptor": "",
    "authors": [
      "Wojciech Przybyszewski"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2202.04006"
  },
  {
    "id": "arXiv:2202.04007",
    "title": "Results and findings of the 2021 Image Similarity Challenge",
    "abstract": "The 2021 Image Similarity Challenge introduced a dataset to serve as a new\nbenchmark to evaluate recent image copy detection methods. There were 200\nparticipants to the competition. This paper presents a quantitative and\nqualitative analysis of the top submissions. It appears that the most difficult\nimage transformations involve either severe image crops or hiding into\nunrelated images, combined with local pixel perturbations. The key algorithmic\nelements in the winning submissions are: training on strong augmentations,\nself-supervised learning, score normalization, explicit overlay detection, and\nglobal descriptor matching followed by pairwise image comparison.",
    "descriptor": "",
    "authors": [
      "Zo\u00eb Papakipos",
      "Giorgos Tolias",
      "Tomas Jenicek",
      "Ed Pizzi",
      "Shuhei Yokoo",
      "Wenhao Wang",
      "Yifan Sun",
      "Weipu Zhang",
      "Yi Yang",
      "Sanjay Addicam",
      "Sergio Manuel Papadakis",
      "Cristian Canton Ferrer",
      "Ondrej Chum",
      "Matthijs Douze"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.04007"
  },
  {
    "id": "arXiv:2202.04010",
    "title": "Multilevel Binary Polar-Coded Modulation Achieving the Capacity of  Asymmetric Channels",
    "abstract": "A multilevel coded modulation scheme is studied that uses binary polar codes\nand Honda-Yamamoto probabilistic shaping. The scheme is shown to achieve the\ncapacity of discrete memoryless channels with input alphabets of cardinality a\npower of two. The performance of finite-length implementations is compared to\npolar-coded probabilistic amplitude shaping and constant composition\ndistribution matching.",
    "descriptor": "\nComments: 6 pages, 4 figures; submitted to ISIT 2022\n",
    "authors": [
      "Constantin Runge",
      "Thomas Wiegart",
      "Diego Lentner",
      "Tobias Prinz"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.04010"
  },
  {
    "id": "arXiv:2202.04013",
    "title": "Spotting Anomalous Trades in NFT Markets: The Case of NBA Topshot",
    "abstract": "Non-Fungible Token (NFT) markets are one of the fastest growing digital\nmarkets today, with the sales during the third quarter of 2021 exceeding $10\nbillions! Nevertheless, these emerging markets - similar to traditional\nemerging marketplaces - can be seen as a great opportunity for illegal\nactivities (e.g., money laundering, sale of illegal goods etc.). In this study\nwe focus on a specific marketplace, namely NBA TopShot, that facilitates the\npurchase and (peer-to-peer) trading of sports collectibles. Our objective is to\nbuild a framework that is able to label peer-to-peer transactions on the\nplatform as anomalous or not. To achieve our objective we begin by building a\nmodel for the profit to be made by selling a specific collectible on the\nplatform. We then use RFCDE - a random forest model for the conditional density\nof the dependent variable - to model the errors from the profit models. This\nstep allows us to estimate the probability of a transaction being anomalous. We\nfinally label as anomalous any transaction whose aforementioned probability is\nless than 1%. Given the absence of ground truth for evaluating the model in\nterms of its classification of transactions, we analyze the trade networks\nformed from these anomalous transactions and compare it with the full trade\nnetwork of the platform. Our results indicate that these two networks are\nstatistically different when it comes to network metrics such as, edge density,\nclosure, node centrality and node degree distribution. This network analysis\nprovides additional evidence that these transactions do not follow the same\npatterns that the rest of the trades on the platform follow. However, we would\nlike to emphasize here that this does not mean that these transactions are also\nillegal. These transactions will need to be further audited from the\nappropriate entities to verify whether or not they are illicit.",
    "descriptor": "",
    "authors": [
      "Konstantinos Pelechrinis",
      "Xin Liu",
      "Prashant Krishnamurthy",
      "Amy Babay"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2202.04013"
  },
  {
    "id": "arXiv:2202.04015",
    "title": "NEWSKVQA: Knowledge-Aware News Video Question Answering",
    "abstract": "Answering questions in the context of videos can be helpful in video\nindexing, video retrieval systems, video summarization, learning management\nsystems and surveillance video analysis. Although there exists a large body of\nwork on visual question answering, work on video question answering (1) is\nlimited to domains like movies, TV shows, gameplay, or human activity, and (2)\nis mostly based on common sense reasoning. In this paper, we explore a new\nfrontier in video question answering: answering knowledge-based questions in\nthe context of news videos. To this end, we curate a new dataset of 12K news\nvideos spanning across 156 hours with 1M multiple-choice question-answer pairs\ncovering 8263 unique entities. We make the dataset publicly available. Using\nthis dataset, we propose a novel approach, NEWSKVQA (Knowledge-Aware News Video\nQuestion Answering) which performs multi-modal inferencing over textual\nmultiple-choice questions, videos, their transcripts and knowledge base, and\npresents a strong baseline.",
    "descriptor": "",
    "authors": [
      "Pranay Gupta",
      "Manish Gupta"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2202.04015"
  },
  {
    "id": "arXiv:2202.04016",
    "title": "Ontology-based Attack Graph Enrichment",
    "abstract": "Attack graphs provide a representation of possible actions that adversaries\ncan perpetrate to attack a system. They are used by cybersecurity experts to\nmake decisions, e.g., to decide remediation and recovery plans. Different\napproaches can be used to build such graphs. We focus on logical attack graphs,\nbased on predicate logic, to define the causality of adversarial actions. Since\nnetworks and vulnerabilities are constantly changing (e.g., new applications\nget installed on system devices, updated services get publicly exposed, etc.),\nwe propose to enrich the attack graph generation approach with a semantic\naugmentation post-processing of the predicates. Graphs are now mapped to\nmonitoring alerts confirming successful attack actions and updated according to\nnetwork and vulnerability changes. As a result, predicates get periodically\nupdated, based on attack evidences and ontology enrichment. This allows to\nverify whether changes lead the attacker to the initial goals or to cause\nfurther damage to the system not anticipated in the initial graphs. We\nillustrate the approach under the specific domain of cyber-physical security\naffecting smart cities. We validate the approach using existing tools and\nontologies.",
    "descriptor": "\nComments: 18 pages, 3 figures, 1 table, conference paper (TIEMS Annual Conference, December 2021, Paris, France)\n",
    "authors": [
      "K\u00e9ren Saint-Hilaire",
      "Fr\u00e9d\u00e9ric Cuppens",
      "Nora Cuppens",
      "Joaquin Garcia-Alfaro"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.04016"
  },
  {
    "id": "arXiv:2202.04030",
    "title": "Self-supervised Contrastive Learning for Volcanic Unrest Detection",
    "abstract": "Ground deformation measured from Interferometric Synthetic Aperture Radar\n(InSAR) data is considered a sign of volcanic unrest, statistically linked to a\nvolcanic eruption. Recent studies have shown the potential of using Sentinel-1\nInSAR data and supervised deep learning (DL) methods for the detection of\nvolcanic deformation signals, towards global volcanic hazard mitigation.\nHowever, detection accuracy is compromised from the lack of labelled data and\nclass imbalance. To overcome this, synthetic data are typically used for\nfinetuning DL models pre-trained on the ImageNet dataset. This approach suffers\nfrom poor generalisation on real InSAR data. This letter proposes the use of\nself-supervised contrastive learning to learn quality visual representations\nhidden in unlabeled InSAR data. Our approach, based on the SimCLR framework,\nprovides a solution that does not require a specialized architecture nor a\nlarge labelled or synthetic dataset. We show that our self-supervised pipeline\nachieves higher accuracy with respect to the state-of-the-art methods, and\nshows excellent generalisation even for out-of-distribution test data. Finally,\nwe showcase the effectiveness of our approach for detecting the unrest episodes\npreceding the recent Icelandic Fagradalsfjall volcanic eruption.",
    "descriptor": "\nComments: 5 pages, 3 figures\n",
    "authors": [
      "Nikolaos Ioannis Bountos",
      "Ioannis Papoutsis",
      "Dimitrios Michail",
      "Nantheera Anantrasirichai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2202.04030"
  },
  {
    "id": "arXiv:2202.04036",
    "title": "Residual Aligned: Gradient Optimization for Non-Negative Image Synthesis",
    "abstract": "In this work, we address an important problem of optical see through (OST)\naugmented reality: non-negative image synthesis. Most of the image generation\nmethods fail under this condition, since they assume full control over each\npixel and cannot create darker pixels by adding light. In order to solve the\nnon-negative image generation problem in AR image synthesis, prior works have\nattempted to utilize optical illusion to simulate human vision but fail to\npreserve lightness constancy well under situations such as high dynamic range.\nIn our paper, we instead propose a method that is able to preserve lightness\nconstancy at a local level, thus capturing high frequency details. Compared\nwith existing work, our method shows strong performance in image-to-image\ntranslation tasks, particularly in scenarios such as large scale images, high\nresolution images, and high dynamic range image transfer.",
    "descriptor": "",
    "authors": [
      "Flora Yu Shen",
      "Katie Luo",
      "Guandao Yang",
      "Harald Haraldsson",
      "Serge Belongie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.04036"
  },
  {
    "id": "arXiv:2202.04039",
    "title": "Using Genetic Programming to Predict and Optimize Protein Function",
    "abstract": "Protein engineers conventionally use tools such as Directed Evolution to find\nnew proteins with better functionalities and traits. More recently,\ncomputational techniques and especially machine learning approaches have been\nrecruited to assist Directed Evolution, showing promising results. In this\npaper, we propose POET, a computational Genetic Programming tool based on\nevolutionary computation methods to enhance screening and mutagenesis in\nDirected Evolution and help protein engineers to find proteins that have better\nfunctionality. As a proof-of-concept we use peptides that generate MRI contrast\ndetected by the Chemical Exchange Saturation Transfer contrast mechanism. The\nevolutionary methods used in POET are described, and the performance of POET in\ndifferent epochs of our experiments with Chemical Exchange Saturation Transfer\ncontrast are studied. Our results indicate that a computational modelling tool\nlike POET can help to find peptides with 400% better functionality than used\nbefore.",
    "descriptor": "\nComments: 23 pages, 8 figures and 4 tables\n",
    "authors": [
      "Iliya Miralavy",
      "Alexander Bricco",
      "Assaf Gilad",
      "Wolfgang Banzhaf"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Biomolecules (q-bio.BM)"
    ],
    "url": "https://arxiv.org/abs/2202.04039"
  },
  {
    "id": "arXiv:2202.04040",
    "title": "Self-Conditioned Generative Adversarial Networks for Image Editing",
    "abstract": "Generative Adversarial Networks (GANs) are susceptible to bias, learned from\neither the unbalanced data, or through mode collapse. The networks focus on the\ncore of the data distribution, leaving the tails - or the edges of the\ndistribution - behind. We argue that this bias is responsible not only for\nfairness concerns, but that it plays a key role in the collapse of\nlatent-traversal editing methods when deviating away from the distribution's\ncore. Building on this observation, we outline a method for mitigating\ngenerative bias through a self-conditioning process, where distances in the\nlatent-space of a pre-trained generator are used to provide initial labels for\nthe data. By fine-tuning the generator on a re-sampled distribution drawn from\nthese self-labeled data, we force the generator to better contend with rare\nsemantic attributes and enable more realistic generation of these properties.\nWe compare our models to a wide range of latent editing methods, and show that\nby alleviating the bias they achieve finer semantic control and better identity\npreservation through a wider range of transformations. Our code and models will\nbe available at https://github.com/yzliu567/sc-gan",
    "descriptor": "\nComments: Project page: this https URL\n",
    "authors": [
      "Yunzhe Liu",
      "Rinon Gal",
      "Amit H. Bermano",
      "Baoquan Chen",
      "Daniel Cohen-Or"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.04040"
  },
  {
    "id": "arXiv:2202.04041",
    "title": "Physics-informed neural networks for solving parametric magnetostatic  problems",
    "abstract": "The optimal design of magnetic devices becomes intractable using current\ncomputational methods when the number of design parameters is high. The\nemerging physics-informed deep learning framework has the potential to\nalleviate this curse of dimensionality. The objective of this paper is to\ninvestigate the ability of physics-informed neural networks to learn the\nmagnetic field response as a function of design parameters in the context of a\ntwo-dimensional (2-D) magnetostatic problem. Our approach is as follows. We\nderive the variational principle for 2-D parametric magnetostatic problems, and\nprove the existence and uniqueness of the solution that satisfies the equations\nof the governing physics, i.e., Maxwell's equations. We use a deep neural\nnetwork (DNN) to represent the magnetic field as a function of space and a\ntotal of ten parameters that describe geometric features and operating point\nconditions. We train the DNN by minimizing the physics-informed loss function\nusing a variant of stochastic gradient descent. Subsequently, we conduct\nsystematic numerical studies using a parametric EI-core electromagnet problem.\nIn these studies, we vary the DNN architecture trying more than one hundred\ndifferent possibilities. For each study, we evaluate the accuracy of the DNN by\ncomparing its predictions to those of finite element analysis. In an exhaustive\nnon-parametric study, we observe that sufficiently parameterized dense networks\nresult in relative errors of less than 1%. Residual connections always improve\nrelative errors for the same number of training iterations. Also, we observe\nthat Fourier encoding features aligned with the device geometry do improve the\nrate of convergence, albeit higher-order harmonics are not necessary. Finally,\nwe demonstrate our approach on a ten-dimensional problem with parameterized\ngeometry.",
    "descriptor": "\nComments: 77 pages, 12 figures\n",
    "authors": [
      "Andr\u00e9s Beltr\u00e1n-Pulido",
      "Ilias Bilionis",
      "Dionysios Aliprantis"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2202.04041"
  },
  {
    "id": "arXiv:2202.04044",
    "title": "Aging Scientists and Slowed Advance",
    "abstract": "What is the relationship between aging and the character of scientific\nadvance? Prior research focuses on star scientists, their changing dates, and\nrates of breakthrough success through history. Analyzing more than 244 million\nscholars across 241 million articles over the last two centuries, we show that\nfor all fields, periods, and impact levels, scientists research ideas and\nreferences age over time, their research is less likely to disrupt the state of\nscience and more likely to criticize emerging work. Early success accelerates\nscientist aging; while changing institutions and fields and collaborating with\nyoung scientists slows it. These patterns aggregate within fields such that\nthose with a higher proportion of older scientists experience a lower churn of\nideas and more rapid individual aging, suggesting a universal link between\naging, activity, and advance.",
    "descriptor": "\nComments: 37 pages, 18 figures\n",
    "authors": [
      "Haochuan Cui",
      "Lingfei Wu",
      "James A. Evans"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2202.04044"
  },
  {
    "id": "arXiv:2202.04048",
    "title": "Integrating question answering and text-to-SQL in Portuguese",
    "abstract": "Deep learning transformers have drastically improved systems that\nautomatically answer questions in natural language. However, different\nquestions demand different answering techniques; here we propose, build and\nvalidate an architecture that integrates different modules to answer two\ndistinct kinds of queries. Our architecture takes a free-form natural language\ntext and classifies it to send it either to a Neural Question Answering\nReasoner or a Natural Language parser to SQL. We implemented a complete system\nfor the Portuguese language, using some of the main tools available for the\nlanguage and translating training and testing datasets. Experiments show that\nour system selects the appropriate answering method with high accuracy (over\n99\\%), thus validating a modular question answering strategy.",
    "descriptor": "\nComments: Accepted at International Conference on the Computational Processing of Portuguese (PROPOR 2022), but not yet published\n",
    "authors": [
      "Marcos Menon Jos\u00e9",
      "Marcelo Archanjo Jos\u00e9",
      "Denis Deratani Mau\u00e1",
      "F\u00e1bio Gagliardi Cozman"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.04048"
  },
  {
    "id": "arXiv:2202.04049",
    "title": "A 120dB Programmable-Range On-Chip Pulse Generator for Characterizing  Ferroelectric Devices",
    "abstract": "Novel non-volatile memory devices based on ferroelectric thin films represent\na promising emerging technology that is ideally suited for neuromorphic\napplications. The physical switching mechanism in such films is the nucleation\nand growth of ferroelectric domains. Since this has a strong dependence on both\npulse width and voltage amplitude, it is important to use precise pulsing\nschemes for a thorough characterization of their behaviour. In this work, we\npresent an on-chip 120 dB programmable range pulse generator, that can generate\npulse widths ranging from 10ns to 10ms $\\pm$2.5% which eliminates the RLC\nbottleneck in the device characterisation setup. We describe the pulse\ngenerator design and show how the pulse width can be tuned with high accuracy,\nusing Digital to Analog converters. Finally, we present experimental results\nmeasured from the circuit, fabricated using a standard 180nm CMOS technology.",
    "descriptor": "",
    "authors": [
      "Shyam Narayanan",
      "Erika Covi",
      "Viktor Havel",
      "Charlotte Frenkel",
      "Suzanne Lancaster",
      "Quang Duong",
      "Stefan Slesazeck",
      "Thomas Mikolajick",
      "Melika Payvand",
      "Giacomo Indiveri"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.04049"
  },
  {
    "id": "arXiv:2202.04050",
    "title": "Age of Information in the Presence of an Adversary",
    "abstract": "We consider a communication system where a base station serves $N$ users, one\nuser at a time, over a wireless channel. We consider the timeliness of the\ncommunication of each user via the age of information metric. A constrained\nadversary can block at most a given fraction, $\\alpha$, of the time slots over\na horizon of $T$ slots, i.e., it can block at most $\\alpha T$ slots. We show\nthat an optimum adversary blocks $\\alpha T$ consecutive time slots of a\nrandomly selected user. The interesting consecutive property of the blocked\ntime slots is due to the cumulative nature of the age metric.",
    "descriptor": "",
    "authors": [
      "Subhankar Banerjee",
      "Sennur Ulukus"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.04050"
  },
  {
    "id": "arXiv:2202.04051",
    "title": "Towards automated Capability Assessment leveraging Deep Learning",
    "abstract": "Aiming for a higher economic efficiency in manufacturing, an increased degree\nof automation is a key enabler. However, assessing the technical feasibility of\nan automated assembly solution for a dedicated process is difficult and often\ndetermined by the geometry of the given product parts. Among others, decisive\ncriterions of the automation feasibility are the ability to separate and\nisolate single parts or the capability of component self-alignment in final\nposition. To assess the feasibility, a questionnaire based evaluation scheme\nhas been developed and applied by Fraunhofer researchers. However, the results\nstrongly depend on the implicit knowledge and experience of the single engineer\nperforming the assessment. This paper presents NeuroCAD, a software tool that\nautomates the assessment using voxelization techniques. The approach enables\nthe assessment of abstract and production relevant geometries features through\ndeep-learning based on CAD files.",
    "descriptor": "",
    "authors": [
      "Raoul Sch\u00f6nhof",
      "Manuel Fechter"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.04051"
  },
  {
    "id": "arXiv:2202.04052",
    "title": "Decision boundaries and convex hulls in the feature space that deep  learning functions learn from images",
    "abstract": "The success of deep neural networks in image classification and learning can\nbe partly attributed to the features they extract from images. It is often\nspeculated about the properties of a low-dimensional manifold that models\nextract and learn from images. However, there is not sufficient understanding\nabout this low-dimensional space based on theory or empirical evidence. For\nimage classification models, their last hidden layer is the one where images of\neach class is separated from other classes and it also has the least number of\nfeatures. Here, we develop methods and formulations to study that feature space\nfor any model. We study the partitioning of the domain in feature space,\nidentify regions guaranteed to have certain classifications, and investigate\nits implications for the pixel space. We observe that geometric arrangements of\ndecision boundaries in feature space is significantly different compared to\npixel space, providing insights about adversarial vulnerabilities, image\nmorphing, extrapolation, ambiguity in classification, and the mathematical\nunderstanding of image classification models.",
    "descriptor": "",
    "authors": [
      "Roozbeh Yousefzadeh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2202.04052"
  },
  {
    "id": "arXiv:2202.04053",
    "title": "DALL-Eval: Probing the Reasoning Skills and Social Biases of  Text-to-Image Generative Transformers",
    "abstract": "Generating images from textual descriptions has gained a lot of attention.\nRecently, DALL-E, a multimodal transformer language model, and its variants\nhave shown high-quality text-to-image generation capabilities with a simple\narchitecture and training objective, powered by large-scale training data and\ncomputation. However, despite the interesting image generation results, there\nhas not been a detailed analysis on how to evaluate such models. In this work,\nwe investigate the reasoning capabilities and social biases of such\ntext-to-image generative transformers in detail. First, we measure four visual\nreasoning skills: object recognition, object counting, color recognition, and\nspatial relation understanding. For this, we propose PaintSkills, a diagnostic\ndataset and evaluation toolkit that measures these four visual reasoning\nskills. Second, we measure the text alignment and quality of the generated\nimages based on pretrained image captioning, image-text retrieval, and image\nclassification models. Third, we assess social biases in the models. For this,\nwe suggest evaluation of gender and racial biases of text-to-image generation\nmodels based on a pretrained image-text retrieval model and human evaluation.\nIn our experiments, we show that recent text-to-image models perform better in\nrecognizing and counting objects than recognizing colors and understanding\nspatial relations, while there exists a large gap between model performances\nand oracle accuracy on all skills. Next, we demonstrate that recent\ntext-to-image models learn specific gender/racial biases from web image-text\npairs. We also show that our automatic evaluations of visual reasoning skills\nand gender bias are highly correlated with human judgments. We hope our work\nwill help guide future progress in improving text-to-image models on visual\nreasoning skills and social biases. Code and data at:\nhttps://github.com/j-min/DallEval",
    "descriptor": "\nComments: 20 pages, 10 figures, 13 tables\n",
    "authors": [
      "Jaemin Cho",
      "Abhay Zala",
      "Mohit Bansal"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.04053"
  },
  {
    "id": "arXiv:2202.04058",
    "title": "PrivFair: a Library for Privacy-Preserving Fairness Auditing",
    "abstract": "Machine learning (ML) has become prominent in applications that directly\naffect people's quality of life, including in healthcare, justice, and finance.\nML models have been found to exhibit discrimination based on sensitive\nattributes such as gender, race, or disability. Assessing if an ML model is\nfree of bias remains challenging to date, and by definition has to be done with\nsensitive user characteristics that are subject of anti-discrimination and data\nprotection law. Existing libraries for fairness auditing of ML models offer no\nmechanism to protect the privacy of the audit data. We present PrivFair, a\nlibrary for privacy-preserving fairness audits of ML models. Through the use of\nSecure Multiparty Computation (MPC), \\textsc{PrivFair} protects the\nconfidentiality of the model under audit and the sensitive data used for the\naudit, hence it supports scenarios in which a proprietary classifier owned by a\ncompany is audited using sensitive audit data from an external investigator. We\ndemonstrate the use of PrivFair for group fairness auditing with tabular data\nor image data, without requiring the investigator to disclose their data to\nanyone in an unencrypted manner, or the model owner to reveal their model\nparameters to anyone in plaintext.",
    "descriptor": "",
    "authors": [
      "Sikha Pentyala",
      "David Melanson",
      "Martine De Cock",
      "Golnoosh Farnadi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.04058"
  },
  {
    "id": "arXiv:2202.04064",
    "title": "Parallel Contests for Crowdsourcing Reviews: Existence and Quality of  Equilibria",
    "abstract": "Motivated by the intricacies of allocating treasury funds in blockchain\nsettings, we study the problem of crowdsourcing reviews for many different\nproposals, in parallel. During the reviewing phase, every reviewer can select\nthe proposals to write reviews for, as well as the quality of each review. The\nquality levels follow certain very coarse community guidelines and can have\nvalues such as 'excellent' or 'good'. Based on these scores and the\ndistribution of reviews, every reviewer will receive some reward for their\nefforts. In this paper, we design a reward scheme and show that it always has\npure Nash equilibria, for any set of proposals and reviewers. In addition, we\nshow that these equilibria guarantee constant factor approximations for two\nnatural metrics: the total quality of all reviews, as well as the fraction of\nproposals that received at least one review, compared to the optimal outcome.",
    "descriptor": "",
    "authors": [
      "Georgios Birmpas",
      "Lyudmila Kovalchuk",
      "Philip Lazos",
      "Roman Oliynykov"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2202.04064"
  },
  {
    "id": "arXiv:2202.04067",
    "title": "Time Series Anomaly Detection by Cumulative Radon Features",
    "abstract": "Detecting anomalous time series is key for scientific, medical and industrial\ntasks, but is challenging due to its inherent unsupervised nature. In recent\nyears, progress has been made on this task by learning increasingly more\ncomplex features, often using deep neural networks. In this work, we argue that\nshallow features suffice when combined with distribution distance measures. Our\napproach models each time series as a high dimensional empirical distribution\nof features, where each time-point constitutes a single sample. Modeling the\ndistance between a test time series and the normal training set therefore\nrequires efficiently measuring the distance between multivariate probability\ndistributions. We show that by parameterizing each time series using cumulative\nRadon features, we are able to efficiently and effectively model the\ndistribution of normal time series. Our theoretically grounded but\nsimple-to-implement approach is evaluated on multiple datasets and shown to\nachieve better results than established, classical methods as well as complex,\nstate-of-the-art deep learning methods. Code is provided.",
    "descriptor": "",
    "authors": [
      "Yedid Hoshen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.04067"
  },
  {
    "id": "arXiv:2012.03854",
    "title": "Forecasting: theory and practice",
    "abstract": "Forecasting has always been at the forefront of decision making and planning.\nThe uncertainty that surrounds the future is both exciting and challenging,\nwith individuals and organisations seeking to minimise risks and maximise\nutilities. The large number of forecasting applications calls for a diverse set\nof forecasting methods to tackle real-life challenges. This article provides a\nnon-systematic review of the theory and the practice of forecasting. We provide\nan overview of a wide range of theoretical, state-of-the-art models, methods,\nprinciples, and approaches to prepare, produce, organise, and evaluate\nforecasts. We then demonstrate how such theoretical concepts are applied in a\nvariety of real-life contexts.\nWe do not claim that this review is an exhaustive list of methods and\napplications. However, we wish that our encyclopedic presentation will offer a\npoint of reference for the rich work that has been undertaken over the last\ndecades, with some key insights for the future of forecasting theory and\npractice. Given its encyclopedic nature, the intended mode of reading is\nnon-linear. We offer cross-references to allow the readers to navigate through\nthe various topics. We complement the theoretical concepts and applications\ncovered by large lists of free or open-source software implementations and\npublicly-available databases.",
    "descriptor": "",
    "authors": [
      "Fotios Petropoulos",
      "Daniele Apiletti",
      "Vassilios Assimakopoulos",
      "Mohamed Zied Babai",
      "Devon K. Barrow",
      "Souhaib Ben Taieb",
      "Christoph Bergmeir",
      "Ricardo J. Bessa",
      "Jakub Bijak",
      "John E. Boylan",
      "Jethro Browell",
      "Claudio Carnevale",
      "Jennifer L. Castle",
      "Pasquale Cirillo",
      "Michael P. Clements",
      "Clara Cordeiro",
      "Fernando Luiz Cyrino Oliveira",
      "Shari De Baets",
      "Alexander Dokumentov",
      "Joanne Ellison",
      "Piotr Fiszeder",
      "Philip Hans Franses",
      "David T. Frazier",
      "Michael Gilliland",
      "M. Sinan G\u00f6n\u00fcl",
      "Paul Goodwin",
      "Luigi Grossi",
      "Yael Grushka-Cockayne",
      "Mariangela Guidolin",
      "Massimo Guidolin",
      "Ulrich Gunter",
      "Xiaojia Guo",
      "Renato Guseo",
      "Nigel Harvey",
      "David F. Hendry",
      "Ross Hollyman",
      "Tim Januschowski",
      "Jooyoung Jeon",
      "Victor Richmond R. Jose",
      "Yanfei Kang",
      "Anne B. Koehler",
      "Stephan Kolassa",
      "Nikolaos Kourentzes",
      "Sonia Leva",
      "Feng Li"
    ],
    "subjectives": [
      "Applications (stat.AP)",
      "Machine Learning (cs.LG)",
      "Econometrics (econ.EM)",
      "Machine Learning (stat.ML)",
      "Other Statistics (stat.OT)"
    ],
    "url": "https://arxiv.org/abs/2012.03854"
  },
  {
    "id": "arXiv:2202.03427",
    "title": "Performance Evaluation of Infrared Image Enhancement Techniques",
    "abstract": "Infrared (IR) images are widely used in many fields such as medical imaging,\nobject tracking, astronomy and military purposes for securing borders. Infrared\nimages can be captured day or night based on the type of capturing device. The\ncapturing devices use electromagnetic radiation with longer wavelengths. There\nare several types of IR radiation based on the range of wavelength and\ncorresponding frequency. Due to noising and other artifacts, IR images are not\nclearly visible. In this paper, we present a complete up-todate survey on IR\nimaging enhancement techniques. The survey includes IR radiation types and\ndevices and existing IR datasets. The survey covers spatial enhancement\ntechniques, frequency-domain based enhancement techniques and Deep\nlearning-based techniques.",
    "descriptor": "",
    "authors": [
      "Rania Gaber",
      "AbdElmgied Ali",
      "Kareem Ahmed"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2202.03427"
  },
  {
    "id": "arXiv:2202.03430",
    "title": "A Topology-Attention ConvLSTM Network and Its Application to EM Images",
    "abstract": "Structural accuracy of segmentation is important for finescale structures in\nbiomedical images. We propose a novel TopologyAttention ConvLSTM Network\n(TACNet) for 3D image segmentation in order to achieve high structural accuracy\nfor 3D segmentation tasks. Specifically, we propose a Spatial\nTopology-Attention (STA) module to process a 3D image as a stack of 2D image\nslices and adopt ConvLSTM to leverage contextual structure information from\nadjacent slices. In order to effectively transfer topology-critical information\nacross slices, we propose an Iterative-Topology Attention (ITA) module that\nprovides a more stable topology-critical map for segmentation. Quantitative and\nqualitative results show that our proposed method outperforms various baselines\nin terms of topology-aware evaluation metrics.",
    "descriptor": "\nComments: 12 pages, 6 figures, Accepted by MICCAI'21\n",
    "authors": [
      "Jiaqi Yang",
      "Xiaoling Hu",
      "Chao Chen",
      "Chialing Tsai"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.03430"
  },
  {
    "id": "arXiv:2202.03432",
    "title": "Inference of captions from histopathological patches",
    "abstract": "Computational histopathology has made significant strides in the past few\nyears, slowly getting closer to clinical adoption. One area of benefit would be\nthe automatic generation of diagnostic reports from H\\&E-stained whole slide\nimages which would further increase the efficiency of the pathologists' routine\ndiagnostic workflows. In this study, we compiled a dataset (PatchGastricADC22)\nof histopathological captions of stomach adenocarcinoma endoscopic biopsy\nspecimens, which we extracted from diagnostic reports and paired with patches\nextracted from the associated whole slide images. The dataset contains a\nvariety of gastric adenocarcinoma subtypes. We trained a baseline\nattention-based model to predict the captions from features extracted from the\npatches and obtained promising results. We make the captioned dataset of 262K\npatches publicly available.",
    "descriptor": "",
    "authors": [
      "Masayuki Tsuneki",
      "Fahdi Kanavati"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.03432"
  },
  {
    "id": "arXiv:2202.03433",
    "title": "A Coarse-to-fine Morphological Approach With Knowledge-based Rules and  Self-adapting Correction for Lung Nodules Segmentation",
    "abstract": "The segmentation module which precisely outlines the nodules is a crucial\nstep in a computer-aided diagnosis(CAD) system. The most challenging part of\nsuch a module is how to achieve high accuracy of the segmentation, especially\nfor the juxtapleural, non-solid and small nodules. In this research, we present\na coarse-to-fine methodology that greatly improves the thresholding method\nperformance with a novel self-adapting correction algorithm and effectively\nremoves noisy pixels with well-defined knowledge-based principles. Compared\nwith recent strong morphological baselines, our algorithm, by combining dataset\nfeatures, achieves state-of-the-art performance on both the public LIDC-IDRI\ndataset (DSC 0.699) and our private LC015 dataset (DSC 0.760) which closely\napproaches the SOTA deep learning-based models' performances. Furthermore,\nunlike most available morphological methods that can only segment the isolated\nand well-circumscribed nodules accurately, the precision of our method is\ntotally independent of the nodule type or diameter, proving its applicability\nand generality.",
    "descriptor": "",
    "authors": [
      "Xinliang Fu",
      "Jiayin Zheng",
      "Juanyun Mai",
      "Yanbo Shao",
      "Minghao Wang",
      "Linyu Li",
      "Zhaoqi Diao",
      "Yulong Chen",
      "Jianyu Xiao",
      "Jian You",
      "Airu Yin",
      "Yang Yang",
      "Xiangcheng Qiu",
      "Jinsheng Tao",
      "Bo Wang",
      "Hua Ji"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.03433"
  },
  {
    "id": "arXiv:2202.03434",
    "title": "Multi-modal data generation with a deep metric variational autoencoder",
    "abstract": "We present a deep metric variational autoencoder for multi-modal data\ngeneration. The variational autoencoder employs triplet loss in the latent\nspace, which allows for conditional data generation by sampling in the latent\nspace within each class cluster. The approach is evaluated on a multi-modal\ndataset consisting of otoscopy images of the tympanic membrane with\ncorresponding wideband tympanometry measurements. The modalities in this\ndataset are correlated, as they represent different aspects of the state of the\nmiddle ear, but they do not present a direct pixel-to-pixel correlation. The\napproach shows promising results for the conditional generation of pairs of\nimages and tympanograms, and will allow for efficient data augmentation of data\nfrom multi-modal sources.",
    "descriptor": "",
    "authors": [
      "Josefine Vilsb\u00f8ll Sundgaard",
      "Morten Rieger Hannemose",
      "S\u00f8ren Laugesen",
      "Peter Bray",
      "James Harte",
      "Yosuke Kamide",
      "Chiemi Tanaka",
      "Rasmus R. Paulsen",
      "Anders Nymark Christensen"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.03434"
  },
  {
    "id": "arXiv:2202.03502",
    "title": "Variational discretization of the Navier-Stokes-Fourier system",
    "abstract": "This paper presents the variational discretization of the compressible\nNavier-Stokes-Fourier system, in which the viscosity and the heat conduction\nterms are handled within the variational approach to nonequilibrium\nthermodynamics as developed by one of the authors. In a first part, we review\nthe variational framework for the Navier-Stokes-Fourier (NSF) system in the\nsmooth setting. In a second part, we review a discrete exterior calculus based\non discrete diffeomorphisms then proceed to establish the spatially discretized\nvariational principle for the NSF system through the use of this discrete\nexterior calculus, which yields a semi-discrete nonholonomic variational\nprinciple, as well as semi-discrete evolution equations. In order to avoid\nimportant technical difficulties, further treatment of the phenomenological\nconstraint is needed. In a third part we discretize in time the spatial\nvariational principle underlying the NSF system by extending previous work of\nthe authors, which at last yields a nonholonomic variational integrator for the\nNSF system, as well as fully discrete evolution equations.",
    "descriptor": "",
    "authors": [
      "Benjamin Cou\u00e9raud",
      "Fran\u00e7ois Gay-Balmaz"
    ],
    "subjectives": [
      "Differential Geometry (math.DG)",
      "Dynamical Systems (math.DS)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.03502"
  },
  {
    "id": "arXiv:2202.03525",
    "title": "Nesterov Accelerated Shuffling Gradient Method for Convex Optimization",
    "abstract": "In this paper, we propose Nesterov Accelerated Shuffling Gradient (NASG), a\nnew algorithm for the convex finite-sum minimization problems. Our method\nintegrates the traditional Nesterov's acceleration momentum with different\nshuffling sampling schemes. We show that our algorithm has an improved rate of\n$\\mathcal{O}(1/T)$ using unified shuffling schemes, where $T$ is the number of\nepochs. This rate is better than that of any other shuffling gradient methods\nin convex regime. Our convergence analysis does not require an assumption on\nbounded domain or a bounded gradient condition. For randomized shuffling\nschemes, we improve the convergence bound further. When employing some initial\ncondition, we show that our method converges faster near the small neighborhood\nof the solution. Numerical simulations demonstrate the efficiency of our\nalgorithm.",
    "descriptor": "",
    "authors": [
      "Trang H. Tran",
      "Lam M. Nguyen",
      "Katya Scheinberg"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.03525"
  },
  {
    "id": "arXiv:2202.03542",
    "title": "Bijections between planar maps and planar linear normal $\u03bb$-terms  with connectivity condition",
    "abstract": "The enumeration of linear $\\lambda$-terms has attracted quite some attention\nrecently, partly due to their link to combinatorial maps. Zeilberger and\nGiorgetti (2015) gave a recursive bijection between planar linear normal\n$\\lambda$-terms and planar maps, which, when restricted to 2-connected\n$\\lambda$-terms (i.e., without closed sub-terms), leads to bridgeless planar\nmaps. Inspired by this restriction, Zeilberger and Reed (2019) conjectured that\n3-connected planar linear normal $\\lambda$-terms have the same counting formula\nas bipartite planar maps. In this article, we settle this conjecture by giving\na direct bijection between these two families. Furthermore, using a similar\napproach, we give a direct bijection between planar linear normal\n$\\lambda$-terms and planar maps, whose restriction to 2-connected\n$\\lambda$-terms leads to loopless planar maps. This bijection seems different\nfrom that of Zeilberger and Giorgetti, even after taking the map dual. We also\nexplore enumerative consequences of our bijections.",
    "descriptor": "\nComments: 22 pages, 6 figures. Comments are welcome\n",
    "authors": [
      "Wenjie Fang"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2202.03542"
  },
  {
    "id": "arXiv:2202.03543",
    "title": "Self-Supervised Representation Learning for Speech Using Visual  Grounding and Masked Language Modeling",
    "abstract": "In this paper, we describe our submissions to the ZeroSpeech 2021 Challenge\nand SUPERB benchmark. Our submissions are based on the recently proposed\nFaST-VGS model, which is a Transformer-based model that learns to associate raw\nspeech waveforms with semantically related images, all without the use of any\ntranscriptions of the speech. Additionally, we introduce a novel extension of\nthis model, FaST-VGS+, which is learned in a multi-task fashion with a masked\nlanguage modeling objective in addition to the visual grounding objective. On\nZeroSpeech 2021, we show that our models perform competitively on the ABX task,\noutperform all other concurrent submissions on the Syntactic and Semantic\ntasks, and nearly match the best system on the Lexical task. On the SUPERB\nbenchmark, we show that our models also achieve strong performance, in some\ncases even outperforming the popular wav2vec2.0 model.",
    "descriptor": "\nComments: SAS workshop at AAAI2022\n",
    "authors": [
      "Puyuan Peng",
      "David Harwath"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2202.03543"
  },
  {
    "id": "arXiv:2202.03563",
    "title": "Aladdin: Joint Atlas Building and Diffeomorphic Registration Learning  with Pairwise Alignment",
    "abstract": "Atlas building and image registration are important tasks for medical image\nanalysis. Once one or multiple atlases from an image population have been\nconstructed, commonly (1) images are warped into an atlas space to study\nintra-subject or inter-subject variations or (2) a possibly probabilistic atlas\nis warped into image space to assign anatomical labels. Atlas estimation and\nnonparametric transformations are computationally expensive as they usually\nrequire numerical optimization. Additionally, previous approaches for atlas\nbuilding often define similarity measures between a fuzzy atlas and each\nindividual image, which may cause alignment difficulties because a fuzzy atlas\ndoes not exhibit clear anatomical structures in contrast to the individual\nimages. This work explores using a convolutional neural network (CNN) to\njointly predict the atlas and a stationary velocity field (SVF)\nparameterization for diffeomorphic image registration with respect to the\natlas. Our approach does not require affine pre-registrations and utilizes\npairwise image alignment losses to increase registration accuracy. We evaluate\nour model on 3D knee magnetic resonance images (MRI) from the OAI-ZIB dataset.\nOur results show that the proposed framework achieves better performance than\nother state-of-the-art image registration algorithms, allows for end-to-end\ntraining, and for fast inference at test time.",
    "descriptor": "",
    "authors": [
      "Zhipeng Ding",
      "Marc Niethammer"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.03563"
  },
  {
    "id": "arXiv:2202.03564",
    "title": "Accurate super-resolution low-field brain MRI",
    "abstract": "The recent introduction of portable, low-field MRI (LF-MRI) into the clinical\nsetting has the potential to transform neuroimaging. However, LF-MRI is limited\nby lower resolution and signal-to-noise ratio, leading to incomplete\ncharacterization of brain regions. To address this challenge, recent advances\nin machine learning facilitate the synthesis of higher resolution images\nderived from one or multiple lower resolution scans. Here, we report the\nextension of a machine learning super-resolution (SR) algorithm to synthesize 1\nmm isotropic MPRAGE-like scans from LF-MRI T1-weighted and T2-weighted\nsequences. Our initial results on a paired dataset of LF and high-field (HF,\n1.5T-3T) clinical scans show that: (i) application of available automated\nsegmentation tools directly to LF-MRI images falters; but (ii) segmentation\ntools succeed when applied to SR images with high correlation to gold standard\nmeasurements from HF-MRI (e.g., r = 0.85 for hippocampal volume, r = 0.84 for\nthe thalamus, r = 0.92 for the whole cerebrum). This work demonstrates\nproof-of-principle post-processing image enhancement from lower resolution\nLF-MRI sequences. These results lay the foundation for future work to enhance\nthe detection of normal and abnormal image findings at LF and ultimately\nimprove the diagnostic performance of LF-MRI. Our tools are publicly available\non FreeSurfer (surfer.nmr.mgh.harvard.edu/).",
    "descriptor": "",
    "authors": [
      "Juan Eugenio Iglesias",
      "Riana Schleicher",
      "Sonia Laguna",
      "Benjamin Billot",
      "Pamela Schaefer",
      "Brenna McKaig",
      "Joshua N. Goldstein",
      "Kevin N. Sheth",
      "Matthew S. Rosen",
      "W. Taylor Kimberly"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.03564"
  },
  {
    "id": "arXiv:2202.03570",
    "title": "Phase-Stretch Adaptive Gradient-Field Extractor (PAGE)",
    "abstract": "Phase-Stretch Adaptive Gradient-Field Extractor (PAGE) is an edge detection\nalgorithm that is inspired by physics of electromagnetic diffraction and\ndispersion. A computational imaging algorithm, it identifies edges, their\norientations and sharpness in a digital image where the image brightness\nchanges abruptly. Edge detection is a basic operation performed by the eye and\nis crucial to visual perception. PAGE embeds an original image into a set of\nfeature maps that can be used for object representation and classification. The\nalgorithm performs exceptionally well as an edge and texture extractor in low\nlight level and low contrast images. This manuscript is prepared to support the\nopen-source code which is being simultaneously made available within the GitHub\nrepository https://github.com/JalaliLabUCLA.",
    "descriptor": "",
    "authors": [
      "Callen MacPhee",
      "Madhuri Suthar",
      "Bahram Jalali"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.03570"
  },
  {
    "id": "arXiv:2202.03571",
    "title": "Metal Artifact Reduction with Intra-Oral Scan Data for 3D Low Dose  Maxillofacial CBCT Modeling",
    "abstract": "Low-dose dental cone beam computed tomography (CBCT) has been increasingly\nused for maxillofacial modeling. However, the presence of metallic inserts,\nsuch as implants, crowns, and dental filling, causes severe streaking and\nshading artifacts in a CBCT image and loss of the morphological structures of\nthe teeth, which consequently prevents accurate segmentation of bones. A\ntwo-stage metal artifact reduction method is proposed for accurate 3D low-dose\nmaxillofacial CBCT modeling, where a key idea is to utilize explicit tooth\nshape prior information from intra-oral scan data whose acquisition does not\nrequire any extra radiation exposure. In the first stage, an image-to-image\ndeep learning network is employed to mitigate metal-related artifacts. To\nimprove the learning ability, the proposed network is designed to take\nadvantage of the intra-oral scan data as side-inputs and perform multi-task\nlearning of auxiliary tooth segmentation. In the second stage, a 3D\nmaxillofacial model is constructed by segmenting the bones from the dental CBCT\nimage corrected in the first stage. For accurate bone segmentation, weighted\nthresholding is applied, wherein the weighting region is determined depending\non the geometry of the intra-oral scan data. Because acquiring a paired\ntraining dataset of metal-artifact-free and metal artifact-affected dental CBCT\nimages is challenging in clinical practice, an automatic method of generating a\nrealistic dataset according to the CBCT physics model is introduced. Numerical\nsimulations and clinical experiments show the feasibility of the proposed\nmethod, which takes advantage of tooth surface information from intra-oral scan\ndata in 3D low dose maxillofacial CBCT modeling.",
    "descriptor": "",
    "authors": [
      "Chang Min Hyun",
      "Taigyntuya Bayaraa",
      "Hye Sun Yun",
      "Tae Jun Jang",
      "Hyoung Suk Park",
      "Jin Keun Seo"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.03571"
  },
  {
    "id": "arXiv:2202.03583",
    "title": "Multi-Label Classification of Thoracic Diseases using Dense  Convolutional Network on Chest Radiographs",
    "abstract": "Chest X-ray images are one of the most common medical diagnosis techniques to\nidentify different thoracic diseases. However, identification of pathologies in\nX-ray images requires skilled manpower and are often cited as a time-consuming\ntask with varied level of interpretation, particularly in cases where the\nidentification of disease only by images is difficult for human eyes. With\nrecent achievements of deep learning in image classification, its application\nin disease diagnosis has been widely explored. This research project presents a\nmulti-label disease diagnosis model of chest x-rays. Using Dense Convolutional\nNeural Network (DenseNet), the diagnosis system was able to obtain high\nclassification predictions. The model obtained the highest AUC score of 0.896\nfor condition Cardiomegaly and the lowest AUC score for Nodule, 0.655. The\nmodel also localized the parts of the chest radiograph that indicated the\npresence of each pathology using GRADCAM, thus contributing to the model\ninterpretability of a deep learning algorithm.",
    "descriptor": "",
    "authors": [
      "Dipkamal Bhusal",
      "Dr. Sanjeeb Prasad Panday"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.03583"
  },
  {
    "id": "arXiv:2202.03587",
    "title": "CALM: Contrastive Aligned Audio-Language Multirate and Multimodal  Representations",
    "abstract": "Deriving multimodal representations of audio and lexical inputs is a central\nproblem in Natural Language Understanding (NLU). In this paper, we present\nContrastive Aligned Audio-Language Multirate and Multimodal Representations\n(CALM), an approach for learning multimodal representations using contrastive\nand multirate information inherent in audio and lexical inputs. The proposed\nmodel aligns acoustic and lexical information in the input embedding space of a\npretrained language-only contextual embedding model. By aligning audio\nrepresentations to pretrained language representations and utilizing\ncontrastive information between acoustic inputs, CALM is able to bootstrap\naudio embedding competitive with existing audio representation models in only a\nfew hours of training time. Operationally, audio spectrograms are processed\nusing linearized patches through a Spectral Transformer (SpecTran) which is\ntrained using a Contrastive Audio-Language Pretraining objective to align audio\nand language from similar queries. Subsequently, the derived acoustic and\nlexical tokens representations are input into a multimodal transformer to\nincorporate utterance level context and derive the proposed CALM\nrepresentations. We show that these pretrained embeddings can subsequently be\nused in multimodal supervised tasks and demonstrate the benefits of the\nproposed pretraining steps in terms of the alignment of the two embedding\nspaces and the multirate nature of the pretraining. Our system shows 10-25\\%\nimprovement over existing emotion recognition systems including\nstate-of-the-art three-modality systems under various evaluation objectives.",
    "descriptor": "",
    "authors": [
      "Vin Sachidananda",
      "Shao-Yen Tseng",
      "Erik Marchi",
      "Sachin Kajarekar",
      "Panayiotis Georgiou"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.03587"
  },
  {
    "id": "arXiv:2202.03595",
    "title": "Model and predict age and sex in healthy subjects using brain white  matter features: A deep learning approach",
    "abstract": "The human brain's white matter (WM) structure is of immense interest to the\nscientific community. Diffusion MRI gives a powerful tool to describe the brain\nWM structure noninvasively. To potentially enable monitoring of age-related\nchanges and investigation of sex-related brain structure differences on the\nmapping between the brain connectome and healthy subjects' age and sex, we\nextract fiber-cluster-based diffusion features and predict sex and age with a\nnovel ensembled neural network classifier. We conduct experiments on the Human\nConnectome Project (HCP) young adult dataset and show that our model achieves\n94.82% accuracy in sex prediction and 2.51 years MAE in age prediction. We also\nshow that the fractional anisotropy (FA) is the most predictive of sex, while\nthe number of fibers is the most predictive of age and the combination of\ndifferent features can improve the model performance.",
    "descriptor": "\nComments: accepted by ISBI 2022\n",
    "authors": [
      "Hao He",
      "Fan Zhang",
      "Steve Pieper",
      "Nikos Makris",
      "Yogesh Rathi",
      "William Wells III",
      "Lauren J. O'Donnell"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.03595"
  },
  {
    "id": "arXiv:2202.03618",
    "title": "On the Convergence of Gradient Extrapolation Methods for Unbalanced  Optimal Transport",
    "abstract": "We study the Unbalanced Optimal Transport (UOT) between two measures of\npossibly different masses with at most $n$ components, where marginal\nconstraints of the standard Optimal Transport (OT) are relaxed via\nKullback-Leibler divergence with regularization factor $\\tau$. We propose a\nnovel algorithm based on Gradient Extrapolation Method (GEM-UOT) to find an\n$\\varepsilon$-approximate solution to the UOT problem in $O\\big( \\kappa n^2\n\\log\\big(\\frac{\\tau n}{\\varepsilon}\\big) \\big)$, where $\\kappa$ is the\ncondition number depending on only the two input measures. Compared to the only\nknown complexity ${O}\\big(\\tfrac{\\tau n^2 \\log(n)}{\\varepsilon}\n\\log\\big(\\tfrac{\\log(n)}{{\\varepsilon}}\\big)\\big)$ for solving the UOT problem\nvia the Sinkhorn algorithm, ours is better in $\\varepsilon$ and lifts\nSinkhorn's linear dependence on $\\tau$, which hindered its practicality to\napproximate the standard OT via UOT. Our proof technique is based on a novel\ndual formulation of the squared $\\ell_2$-norm regularized UOT objective, which\nis of independent interest and also leads to a new characterization of\napproximation error between UOT and OT in terms of both the transportation plan\nand transport distance. To this end, we further present an algorithm, based on\nGEM-UOT with fine tuned $\\tau$ and a post-process projection step, to find an\n$\\varepsilon$-approximate solution to the standard OT problem in $O\\big( \\kappa\nn^2 \\log\\big(\\frac{ n}{\\varepsilon}\\big) \\big)$, which is a new complexity in\nthe literature of OT. Extensive experiments on synthetic and real datasets\nvalidate our theories and demonstrate the favorable performance of our methods\nin practice.",
    "descriptor": "",
    "authors": [
      "Quang Minh Nguyen",
      "Hoang H. Nguyen",
      "Yi Zhou",
      "Lam M. Nguyen"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.03618"
  },
  {
    "id": "arXiv:2202.03620",
    "title": "Optimal Control with Learning on the Fly: System with Unknown Drift",
    "abstract": "This paper derives an optimal control strategy for a simple stochastic\ndynamical system with constant drift and an additive control input. Motivated\nby the example of a physical system with an unexpected change in its dynamics,\nwe take the drift parameter to be unknown, so that it must be learned while\ncontrolling the system. The state of the system is observed through a linear\nobservation model with Gaussian noise. In contrast to most previous work, which\nfocuses on a controller's asymptotic performance over an infinite time horizon,\nwe minimize a quadratic cost function over a finite time horizon. The\nperformance of our control strategy is quantified by comparing its cost with\nthe cost incurred by an optimal controller that has full knowledge of the\nparameters. This approach gives rise to several notions of \"regret.\" We derive\na set of control strategies that provably minimize the worst-case regret; these\narise from Bayesian strategies that assume a specific fixed prior on the drift\nparameter. This work suggests that examining Bayesian strategies may lead to\noptimal or near-optimal control strategies for a much larger class of realistic\ndynamical models with unknown parameters.",
    "descriptor": "\nComments: 20 pages, 3 figures\n",
    "authors": [
      "Daniel Gurevich",
      "Debdipta Goswami",
      "Charles L. Fefferman",
      "Clarence W. Rowley"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.03620"
  },
  {
    "id": "arXiv:2202.03635",
    "title": "On the classification of non-aCM curves on quintic hypersurfaces in  $\\mathbb{P}^3$",
    "abstract": "In this paper, we call a sub-scheme of dimension one in $\\mathbb{P}^3$ a\ncurve. It is well known that the arithmetic genus and the degree of an aCM\ncurve $D$ in $\\mathbb{P}^3$ is computed by the $h$-vector of $D$. However, for\na given curve $D$ in $\\mathbb{P}^3$, the two invariants of $D$ do not tell us\nwhether $D$ is aCM or not. In this paper, we give a classification of curves on\na smooth quintic hypersurface in $\\mathbb{P}^3$ which are not aCM.",
    "descriptor": "",
    "authors": [
      "Kenta Watanabe"
    ],
    "subjectives": [
      "Algebraic Geometry (math.AG)",
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2202.03635"
  },
  {
    "id": "arXiv:2202.03653",
    "title": "Contribution of directedness in graph spectra",
    "abstract": "In graph analyses, directed edges are often approximated to undirected ones\nso that the adjacency matrices may be symmetric. However, such simplification\nhas not been thoroughly verified. In this study, we investigate how\ndirectedness affects the graph spectra by introducing random directization,\nwhich is an opposite operation of neglecting edge directions. We analytically\nreveal that uniformly random directization typically conserves the relative\nspectral structure of the adjacency matrix in the perturbative regime. The\nresult of random directization implies that the spectrum of the adjacency\nmatrix can be conserved after the directedness is ignored.",
    "descriptor": "\nComments: 14 pages, 18 figures\n",
    "authors": [
      "Masaki Ochi",
      "Tatsuro Kawamoto"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2202.03653"
  },
  {
    "id": "arXiv:2202.03665",
    "title": "Accelerating Part-Scale Simulation in Liquid Metal Jet Additive  Manufacturing via Operator Learning",
    "abstract": "Predicting part quality for additive manufacturing (AM) processes requires\nhigh-fidelity numerical simulation of partial differential equations (PDEs)\ngoverning process multiphysics on a scale of minimum manufacturable features.\nThis makes part-scale predictions computationally demanding, especially when\nthey require many small-scale simulations. We consider drop-on-demand liquid\nmetal jetting (LMJ) as an illustrative example of such computational\ncomplexity. A model describing droplet coalescence for LMJ may include coupled\nincompressible fluid flow, heat transfer, and phase change equations.\nNumerically solving these equations becomes prohibitively expensive when\nsimulating the build process for a full part consisting of thousands to\nmillions of droplets. Reduced-order models (ROMs) based on neural networks (NN)\nor k-nearest neighbor (kNN) algorithms have been built to replace the original\nphysics-based solver and are computationally tractable for part-level\nsimulations. However, their quick inference capabilities often come at the\nexpense of accuracy, robustness, and generalizability. We apply an operator\nlearning (OL) approach to learn a mapping between initial and final states of\nthe droplet coalescence process for enabling rapid and accurate part-scale\nbuild simulation. Preliminary results suggest that OL requires\norder-of-magnitude fewer data points than a kNN approach and is generalizable\nbeyond the training set while achieving similar prediction error.",
    "descriptor": "\nComments: Paper #25\n",
    "authors": [
      "S\u00f8ren Taverniers",
      "Svyatoslav Korneev",
      "Kyle M. Pietrzyk",
      "Morad Behandish"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Machine Learning (cs.LG)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ],
    "url": "https://arxiv.org/abs/2202.03665"
  },
  {
    "id": "arXiv:2202.03671",
    "title": "CAD-RADS Scoring using Deep Learning and Task-Specific Centerline  Labeling",
    "abstract": "With coronary artery disease (CAD) persisting to be one of the leading causes\nof death worldwide, interest in supporting physicians with algorithms to speed\nup and improve diagnosis is high. In clinical practice, the severeness of CAD\nis often assessed with a coronary CT angiography (CCTA) scan and manually\ngraded with the CAD-Reporting and Data System (CAD-RADS) score. The clinical\nquestions this score assesses are whether patients have CAD or not (rule-out)\nand whether they have severe CAD or not (hold-out). In this work, we reach new\nstate-of-the-art performance for automatic CAD-RADS scoring. We propose using\nseverity-based label encoding, test time augmentation (TTA) and model\nensembling for a task-specific deep learning architecture. Furthermore, we\nintroduce a novel task- and model-specific, heuristic coronary segment\nlabeling, which subdivides coronary trees into consistent parts across\npatients. It is fast, robust, and easy to implement. We were able to raise the\npreviously reported area under the receiver operating characteristic curve\n(AUC) from 0.914 to 0.942 in the rule-out and from 0.921 to 0.950 in the\nhold-out task respectively.",
    "descriptor": "\nComments: Under review MIDL 2020\n",
    "authors": [
      "Felix Denzinger",
      "Michael Wels",
      "Oliver Taubmann",
      "Mehmet A. G\u00fcls\u00fcn",
      "Max Sch\u00f6binger",
      "Florian Andr\u00e9",
      "Sebastian J. Buss",
      "Johannes G\u00f6rich",
      "Michael S\u00fchling",
      "Andreas Maier",
      "Katharina Breininger"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.03671"
  },
  {
    "id": "arXiv:2202.03718",
    "title": "Spectrum, algebraicity and normalization in alternate bases",
    "abstract": "The first aim of this article is to give information about the algebraic\nproperties of alternate bases $\\boldsymbol{\\beta}=(\\beta_0,\\dots,\\beta_{p-1})$\ndetermining sofic systems. We show that a necessary condition is that the\nproduct $\\delta=\\prod_{i=0}^{p-1}\\beta_i$ is an algebraic integer and all of\nthe bases $\\beta_0,\\ldots,\\beta_{p-1}$ belong to the algebraic field ${\\mathbb\nQ}(\\delta)$. On the other hand, we also give a sufficient condition: if\n$\\delta$ is a Pisot number and $\\beta_0,\\ldots,\\beta_{p-1}\\in {\\mathbb\nQ}(\\delta)$, then the system associated with the alternate base\n$\\boldsymbol{\\beta}=(\\beta_0,\\dots,\\beta_{p-1})$ is sofic. The second aim of\nthis paper is to provide an analogy of Frougny's result concerning\nnormalization of real bases representations. We show that given an alternate\nbase $\\boldsymbol{\\beta}=(\\beta_0,\\dots,\\beta_{p-1})$ such that $\\delta$ is a\nPisot number and $\\beta_0,\\ldots,\\beta_{p-1}\\in {\\mathbb Q}(\\delta)$, the\nnormalization function is computable by a finite B\\\"uchi automaton, and\nfurthermore, we effectively construct such an automaton. An important tool in\nour study is the spectrum of numeration systems associated with alternate\nbases. The spectrum of a real number $\\delta>1$ and an alphabet $A\\subset\n{\\mathbb Z}$ was introduced by Erd\\H{o}s et al. For our purposes, we use a\ngeneralized concept with $\\delta\\in{\\mathbb C}$ and $A\\subset{\\mathbb C}$ and\nstudy its topological properties.",
    "descriptor": "\nComments: 23 pages, 2 figures\n",
    "authors": [
      "\u00c9milie Charlier",
      "C\u00e9lia Cisternino",
      "Zuzana Mas\u00e1kov\u00e1",
      "Edita Pelantov\u00e1"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)",
      "Number Theory (math.NT)"
    ],
    "url": "https://arxiv.org/abs/2202.03718"
  },
  {
    "id": "arXiv:2202.03732",
    "title": "Defective incidence coloring of graphs",
    "abstract": "We define the $d$-defective incidence chromatic number of a graph,\ngeneralizing the notion of incidence chromatic number, and determine it for\nsome classes of graphs including trees, complete bipartite graphs, complete\ngraphs, and outerplanar graphs. Fast algorithms for constructing the optimal\n$d$-defective incidence colorings of those graphs are presented.",
    "descriptor": "\nComments: 20 pages, 4 figures\n",
    "authors": [
      "Huimin Bi",
      "Xin Zhang"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2202.03732"
  },
  {
    "id": "arXiv:2202.03737",
    "title": "A Survey of Breast Cancer Screening Techniques: Thermography and  Electrical Impedance Tomography",
    "abstract": "Breast cancer is a disease that threatens many women's life, thus, early and\naccurate detection plays a key role in reducing the mortality rate. Mammography\nstands as the reference technique for breast cancer screening; nevertheless,\nmany countries still lack access to mammograms due to economic, social, and\ncultural issues. Last advances in computational tools, infrared cameras, and\ndevices for bio-impedance quantification allowed the development of parallel\ntechniques like thermography, infrared imaging, and electrical impedance\ntomography, these being faster, reliable and cheaper. In the last decades,\nthese have been considered as complement procedures for breast cancer\ndiagnosis, where many studies concluded that false positive and false negative\nrates are greatly reduced. This work aims to review the last breakthroughs\nabout the three above-mentioned techniques describing the benefits of mixing\nseveral computational skills to obtain a better global performance. In\naddition, we provide a comparison between several machine learning techniques\napplied to breast cancer diagnosis going from logistic regression, decision\ntrees, and random forest to artificial, deep, and convolutional neural\nnetworks. Finally, it is mentioned several recommendations for 3D breast\nsimulations, pre-processing techniques, biomedical devices in the research\nfield, prediction of tumor location and size.",
    "descriptor": "\nComments: Article published at: Journal of Medical Engineering & Technology (Volume 43, 2019 - Issue 5)\n",
    "authors": [
      "Juan Zuluaga-Gomez",
      "N. Zerhouni",
      "Z. Al Masry",
      "C. Devalland",
      "C. Varnier"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.03737"
  },
  {
    "id": "arXiv:2202.03738",
    "title": "Conflict-free incidence coloring and two-way radio networks",
    "abstract": "In this paper, we introduce the conflict-free incidence coloring of graphs to\nmodel a problem of designing two-way radio networks efficiently and\neconomically. Specifically, we call the vertex-edge pair $(v,e)$ an incidence\nof a graph. A conflict-free incidence coloring of a graph is a coloring of the\nincidences in such a way that two incidences $(u,e)$ and $(v,f)$ get distinct\ncolors if and only if they conflicts each other, i.e.,(i) $u=v$, (ii) $uv$ is\n$e$ or $f$, or (iii) there is a vertex $w$ such that $uw=e$ and $vw=f$. The\nminimum number of colors used among all conflict-free incidence colorings of a\ngraph is the conflict-free incidence chromatic number. For a simple graph with\nmaximum degree $\\Delta$, we claim that its conflict-free incidence chromatic\nnumber is either $2\\Delta$, $2\\Delta+1$, or $2\\Delta+2$, and each of them can\nbe attained by infinite many graphs. We also show that the conflict-free\nincidence chromatic number of an outer-1-planar graph with maximum degree\n$\\Delta$ is either $2\\Delta$ or $2\\Delta+1$, and moreover, characterize all\nouter-1-planar graphs whose conflict-free incidence chromatic numbers are\nexactly $2\\Delta$ or $2\\Delta+1$.",
    "descriptor": "\nComments: 12 pages, 4 figures\n",
    "authors": [
      "Mengke Qi",
      "Xin Zhang"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2202.03738"
  },
  {
    "id": "arXiv:2202.03746",
    "title": "Two-closure of rank 3 groups in polynomial time",
    "abstract": "A finite permutation group $G$ on $\\Omega$ is called a rank 3 group if it has\nprecisely three orbits in its induced action on $\\Omega \\times \\Omega$. The\nlargest permutation group on $\\Omega$ having the same orbits as $G$ on $\\Omega\n\\times \\Omega$ is called the 2-closure of $G$. We construct a polynomial-time\nalgorithm which given generators of a rank 3 group computes generators of its\n2-closure.",
    "descriptor": "\nComments: 29 pages\n",
    "authors": [
      "Saveliy V. Skresanov"
    ],
    "subjectives": [
      "Group Theory (math.GR)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2202.03746"
  },
  {
    "id": "arXiv:2202.03751",
    "title": "InferGrad: Improving Diffusion Models for Vocoder by Considering  Inference in Training",
    "abstract": "Denoising diffusion probabilistic models (diffusion models for short) require\na large number of iterations in inference to achieve the generation quality\nthat matches or surpasses the state-of-the-art generative models, which\ninvariably results in slow inference speed. Previous approaches aim to optimize\nthe choice of inference schedule over a few iterations to speed up inference.\nHowever, this results in reduced generation quality, mainly because the\ninference process is optimized separately, without jointly optimizing with the\ntraining process. In this paper, we propose InferGrad, a diffusion model for\nvocoder that incorporates inference process into training, to reduce the\ninference iterations while maintaining high generation quality. More\nspecifically, during training, we generate data from random noise through a\nreverse process under inference schedules with a few iterations, and impose a\nloss to minimize the gap between the generated and ground-truth data samples.\nThen, unlike existing approaches, the training of InferGrad considers the\ninference process. The advantages of InferGrad are demonstrated through\nexperiments on the LJSpeech dataset showing that InferGrad achieves better\nvoice quality than the baseline WaveGrad under same conditions while\nmaintaining the same voice quality as the baseline but with $3$x speedup ($2$\niterations for InferGrad vs $6$ iterations for WaveGrad).",
    "descriptor": "\nComments: 5 Pages, 2 figures. Accepted to ICASSP 2022\n",
    "authors": [
      "Zehua Chen",
      "Xu Tan",
      "Ke Wang",
      "Shifeng Pan",
      "Danilo Mandic",
      "Lei He",
      "Sheng Zhao"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2202.03751"
  },
  {
    "id": "arXiv:2202.03772",
    "title": "Particle Transformer for Jet Tagging",
    "abstract": "Jet tagging is a critical yet challenging classification task in particle\nphysics. While deep learning has transformed jet tagging and significantly\nimproved performance, the lack of a large-scale public dataset impedes further\nenhancement. In this work, we present JetClass, a new comprehensive dataset for\njet tagging. The JetClass dataset consists of 100 M jets, about two orders of\nmagnitude larger than existing public datasets. A total of 10 types of jets are\nsimulated, including several types unexplored for tagging so far. Based on the\nlarge dataset, we propose a new Transformer-based architecture for jet tagging,\ncalled Particle Transformer (ParT). By incorporating pairwise particle\ninteractions in the attention mechanism, ParT achieves higher tagging\nperformance than a plain Transformer and surpasses the previous\nstate-of-the-art, ParticleNet, by a large margin. The pre-trained ParT models,\nonce fine-tuned, also substantially enhance the performance on two widely\nadopted jet tagging benchmarks.",
    "descriptor": "\nComments: 12 pages, 3 figures\n",
    "authors": [
      "Huilin Qu",
      "Congqiao Li",
      "Sitian Qian"
    ],
    "subjectives": [
      "High Energy Physics - Phenomenology (hep-ph)",
      "Machine Learning (cs.LG)",
      "High Energy Physics - Experiment (hep-ex)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ],
    "url": "https://arxiv.org/abs/2202.03772"
  },
  {
    "id": "arXiv:2202.03798",
    "title": "Deep learning fluid flow reconstruction around arbitrary two-dimensional  objects from sparse sensors using conformal mappings",
    "abstract": "The usage of deep neural networks (DNNs) for flow reconstruction (FR) tasks\nfrom a limited number of sensors is attracting strong research interest, owing\nto DNNs' ability to replicate very high dimensional relationships. Trained over\na single flow case for a given Reynolds number or over a reduced range of\nReynolds numbers, these models are unfortunately not able to handle fluid flows\naround different objects without re-training. In this work, we propose a new\nframework called Spatial Multi-Geometry FR (SMGFR) task, capable of\nreconstructing fluid flows around different two-dimensional objects without\nre-training, mapping the computational domain as an annulus. Different DNNs for\ndifferent sensor setups (where information about the flow is collected) are\ntrained with high-fidelity simulation data for a Reynolds number equal to\napproximately $300$ for 64 objects randomly generated using Bezier curves. The\nperformance of the models and sensor setups are then assessed for the flow\naround 16 unseen objects. It is shown that our mapping approach improves\npercentage errors by up to 15\\% in SMGFR when compared to a more conventional\napproach where the models are trained on a Cartesian grid. Finally, the SMGFR\ntask is extended to predictions of fluid flow snapshots in the future,\nintroducing the Spatio-temporal MGFR (STMGFR) task. For this spatio-temporal\nreconstruction task, a novel approach is developed involving splitting DNNs\ninto a spatial and a temporal component. Our results demonstrate that this\napproach is able to reproduce, in time and in space, the main features of a\nfluid flow around arbitrary objects.",
    "descriptor": "\nComments: 40 pages, 14 figures. Submitted to Physics of Fluids\n",
    "authors": [
      "Ali Girayhan \u00d6zbay",
      "Sylvain Laizet"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.03798"
  },
  {
    "id": "arXiv:2202.03813",
    "title": "Learning to Predict Graphs with Fused Gromov-Wasserstein Barycenters",
    "abstract": "This paper introduces a novel and generic framework to solve the flagship\ntask of supervised labeled graph prediction by leveraging Optimal Transport\ntools. We formulate the problem as regression with the Fused Gromov-Wasserstein\n(FGW) loss and propose a predictive model relying on a FGW barycenter whose\nweights depend on inputs. First we introduce a non-parametric estimator based\non kernel ridge regression for which theoretical results such as consistency\nand excess risk bound are proved. Next we propose an interpretable parametric\nmodel where the barycenter weights are modeled with a neural network and the\ngraphs on which the FGW barycenter is calculated are additionally learned.\nNumerical experiments show the strength of the method and its ability to\ninterpolate in the labeled graph space on simulated data and on a difficult\nmetabolic identification problem where it can reach very good performance with\nvery little engineering.",
    "descriptor": "",
    "authors": [
      "Luc Brogat-Motte",
      "R\u00e9mi Flamary",
      "C\u00e9line Brouard",
      "Juho Rousu",
      "Florence d'Alch\u00e9-Buc"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.03813"
  },
  {
    "id": "arXiv:2202.03826",
    "title": "On the Pitfalls of Using the Residual Error as Anomaly Score",
    "abstract": "Many current state-of-the-art methods for anomaly localization in medical\nimages rely on calculating a residual image between a potentially anomalous\ninput image and its \"healthy\" reconstruction. As the reconstruction of the\nunseen anomalous region should be erroneous, this yields large residuals as a\nscore to detect anomalies in medical images. However, this assumption does not\ntake into account residuals resulting from imperfect reconstructions of the\nmachine learning models used. Such errors can easily overshadow residuals of\ninterest and therefore strongly question the use of residual images as scoring\nfunction. Our work explores this fundamental problem of residual images in\ndetail. We theoretically define the problem and thoroughly evaluate the\ninfluence of intensity and texture of anomalies against the effect of imperfect\nreconstructions in a series of experiments. Code and experiments are available\nunder https://github.com/FeliMe/residual-score-pitfalls",
    "descriptor": "\nComments: 8 pages, 4 figures, under Review for MIDL 2022\n",
    "authors": [
      "Felix Meissen",
      "Benedikt Wiestler",
      "Georgios Kaissis",
      "Daniel Rueckert"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.03826"
  },
  {
    "id": "arXiv:2202.03874",
    "title": "FisrEbp: Enterprise Bankruptcy Prediction via Fusing its Intra-risk and  Spillover-Risk",
    "abstract": "In this paper, we propose to model enterprise bankruptcy risk by fusing its\nintra-risk and spillover-risk. Under this framework, we propose a novel method\nthat is equipped with an LSTM-based intra-risk encoder and GNNs-based\nspillover-risk encoder. Specifically, the intra-risk encoder is able to capture\nenterprise intra-risk using the statistic correlated indicators from the basic\nbusiness information and litigation information. The spillover-risk encoder\nconsists of hypergraph neural networks and heterogeneous graph neural networks,\nwhich aim to model spillover risk through two aspects, i.e. hyperedge and\nmultiplex heterogeneous relations among enterprise knowledge graph,\nrespectively. To evaluate the proposed model, we collect multi-sources SMEs\ndata and build a new dataset SMEsD, on which the experimental results\ndemonstrate the superiority of the proposed method. The dataset is expected to\nbecome a significant benchmark dataset for SMEs bankruptcy prediction and\npromote the development of financial risk study further.",
    "descriptor": "\nComments: 11 pages, 7 figures\n",
    "authors": [
      "Yu Zhao",
      "Shaopeng Wei",
      "Yu Guo",
      "Qing Yang",
      "Gang Kou"
    ],
    "subjectives": [
      "Risk Management (q-fin.RM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.03874"
  },
  {
    "id": "arXiv:2202.03875",
    "title": "Unsupervised Source Separation via Self-Supervised Training",
    "abstract": "We introduce two novel unsupervised (blind) source separation methods, which\ninvolve self-supervised training from single-channel two-source speech mixtures\nwithout any access to the ground truth source signals. Our first method employs\npermutation invariant training (PIT) to separate artificially-generated\nmixtures of the original mixtures back into the original mixtures, which we\nnamed mixture permutation invariant training (MixPIT). We found this\nchallenging objective to be a valid proxy task for learning to separate the\nunderlying sources. We improve upon this first method by creating mixtures of\nsource estimates and employing PIT to separate these new mixtures in a cyclic\nfashion. We named this second method cyclic mixture permutation invariant\ntraining (MixCycle), where cyclic refers to the fact that we use the same model\nto produce artificial mixtures and to learn from them continuously. We show\nthat MixPIT outperforms a common baseline (MixIT) on our small dataset\n(SC09Mix), and they have comparable performance on a standard dataset\n(LibriMix). Strikingly, we also show that MixCycle surpasses the performance of\nsupervised PIT by being data-efficient, thanks to its inherent data\naugmentation mechanism. To the best of our knowledge, no other purely\nunsupervised method is able to match or exceed the performance of supervised\ntraining.",
    "descriptor": "\nComments: Submitted to IEEE Signal Processing Letters\n",
    "authors": [
      "Ertu\u011f Karamatl\u0131",
      "Serap K\u0131rb\u0131z"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.03875"
  },
  {
    "id": "arXiv:2202.03885",
    "title": "Computer assisted discharging procedure on planar graphs: application to  2-distance coloring",
    "abstract": "Using computational techniques we provide a framework for proving results on\nsubclasses of planar graphs via discharging method. The aim of this paper is to\napply these techniques to study the 2-distance coloring of planar subcubic\ngraphs. Applying these techniques we show that every subcubic planar graph $G$\nof girth at least 8 has 2-distance chromatic number at most 6.",
    "descriptor": "",
    "authors": [
      "Hoang La",
      "Petru Valicov"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2202.03885"
  },
  {
    "id": "arXiv:2202.03893",
    "title": "Influence maximization under limited network information: Seeding  high-degree neighbors",
    "abstract": "The diffusion of information, norms, and practices across a social network\ncan be initiated by compelling a small number of seed individuals to adopt\nfirst. Strategies proposed in previous work either assume full network\ninformation or large degree of control over what information is collected.\nHowever, privacy settings on the Internet and high non-response in surveys\noften severely limit available connectivity information. Here we propose a\nseeding strategy for scenarios with limited network information: Only the\ndegrees and connections of some random nodes are known. This new strategy is a\nmodification of \"random neighbor sampling\" and seeds the highest-degree\nneighbors of randomly selected nodes. In simulations of a linear threshold\nmodel on a range of synthetic and real-world networks, we find that this new\nstrategy outperforms other seeding strategies, including high-degree seeding\nand clustered seeding.",
    "descriptor": "\nComments: 28 pages, 9 figures\n",
    "authors": [
      "Jiamin Ou",
      "Vincent Buskens",
      "Arnout Van De Rijt",
      "Debabrata Panja"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2202.03893"
  },
  {
    "id": "arXiv:2202.03914",
    "title": "Impact of Network Centrality and Income on Slowing Infection Spread  after Outbreaks",
    "abstract": "The COVID-19 pandemic has shed light on how the spread of infectious diseases\nworldwide are importantly shaped by both human mobility networks and\nsocio-economic factors. Few studies, however, have examined the interaction of\nmobility networks with socio-spatial inequalities to understand the spread of\ninfection. We introduce a novel methodology, called the Infection Delay Model,\nto calculate how the arrival time of an infection varies geographically,\nconsidering both effective distance-based metrics and differences in regions'\ncapacity to isolate -- a feature associated with socioeconomic inequalities. To\nillustrate an application of the Infection Delay Model, this paper integrates\nhousehold travel survey data with cell phone mobility data from the S\\~ao Paulo\nmetropolitan region to assess the effectiveness of lockdowns to slow the spread\nof COVID-19. Rather than operating under the assumption that the next pandemic\nwill begin in the same region as the last, the model estimates infection delays\nunder every possible outbreak scenario, allowing for generalizable insights\ninto the effectiveness of interventions to delay a region's first case. The\nmodel sheds light on how the effectiveness of lockdowns to slow the spread of\ndisease is influenced by the interaction of mobility networks and\nsocio-economic levels. We find that a negative relationship emerges between\nnetwork centrality and the infection delay after lockdown, irrespective of\nincome. Furthermore, for regions across all income and centrality levels,\noutbreaks starting in less central locations were more effectively slowed by a\nlockdown. Using the Infection Delay Model, this paper identifies and quantifies\na new dimension of disease risk faced by those most central in a mobility\nnetwork.",
    "descriptor": "\nComments: 21 pages, 11 figures, 3 tables\n",
    "authors": [
      "Shiv G. Y\u00fccel",
      "Rafael H. M. Pereira",
      "Pedro S. Peixoto",
      "Chico Q. Camargo"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2202.03914"
  },
  {
    "id": "arXiv:2202.03917",
    "title": "Edge-based fever screening system over private 5G",
    "abstract": "Edge computing and 5G have made it possible to perform analytics closer to\nthe source of data and achieve super-low latency response times, which is not\npossible with centralized cloud deployment. In this paper, we present a novel\nfever-screening system, which uses edge machine learning techniques and\nleverages private 5G to accurately identify and screen individuals with fever\nin real-time. Particularly, we present deep-learning based novel techniques for\nfusion and alignment of cross-spectral visual and thermal data streams at the\nedge. Our novel Cross-Spectral Generative Adversarial Network (CS-GAN)\nsynthesizes visual images that have the key, representative object level\nfeatures required to uniquely associate objects across visual and thermal\nspectrum. Two key features of CS-GAN are a novel, feature-preserving loss\nfunction that results in high-quality pairing of corresponding cross-spectral\nobjects, and dual bottleneck residual layers with skip connections (a new,\nnetwork enhancement) to not only accelerate real-time inference, but to also\nspeed up convergence during model training at the edge. To the best of our\nknowledge, this is the first technique that leverages 5G networks and limited\nedge resources to enable real-time feature-level association of objects in\nvisual and thermal streams (30 ms per full HD frame on an Intel Core i7-8650\n4-core, 1.9GHz mobile processor). To the best of our knowledge, this is also\nthe first system to achieve real-time operation, which has enabled fever\nscreening of employees and guests in arenas, theme parks, airports and other\ncritical facilities. By leveraging edge computing and 5G, our fever screening\nsystem is able to achieve 98.5% accuracy and is able to process about 5X more\npeople when compared to a centralized cloud deployment.",
    "descriptor": "",
    "authors": [
      "Murugan Sankaradas",
      "Kunal Rao",
      "Ravi Rajendran",
      "Amit Redkar",
      "Srimat Chakradhar"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2202.03917"
  },
  {
    "id": "arXiv:2202.03923",
    "title": "2D discrete Hodge-Dirac operator on the torus",
    "abstract": "We discuss a discretisation of the de Rham-Hodge theory in the\ntwo-dimensional case based on a discrete exterior calculus framework. We\npresent discrete analogues of the Hodge-Dirac and Laplace operators in which\nkey geometric aspects of the continuum counterpart are captured. We provide and\nprove a discrete version of the Hodge decomposition theorem. Special attention\nhas been paid to discrete models on a combinatorial torus. In this particular\ncase, we also define and calculate the cohomology groups.",
    "descriptor": "\nComments: 16 pages\n",
    "authors": [
      "Volodymyr Sushch"
    ],
    "subjectives": [
      "Mathematical Physics (math-ph)",
      "Differential Geometry (math.DG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.03923"
  },
  {
    "id": "arXiv:2202.03926",
    "title": "Distribution Regression with Sliced Wasserstein Kernels",
    "abstract": "The problem of learning functions over spaces of probabilities - or\ndistribution regression - is gaining significant interest in the machine\nlearning community. A key challenge behind this problem is to identify a\nsuitable representation capturing all relevant properties of the underlying\nfunctional mapping. A principled approach to distribution regression is\nprovided by kernel mean embeddings, which lifts kernel-induced similarity on\nthe input domain at the probability level. This strategy effectively tackles\nthe two-stage sampling nature of the problem, enabling one to derive estimators\nwith strong statistical guarantees, such as universal consistency and excess\nrisk bounds. However, kernel mean embeddings implicitly hinge on the maximum\nmean discrepancy (MMD), a metric on probabilities, which may fail to capture\nkey geometrical relations between distributions. In contrast, optimal transport\n(OT) metrics, are potentially more appealing, as documented by the recent\nliterature on the topic. In this work, we propose the first OT-based estimator\nfor distribution regression. We build on the Sliced Wasserstein distance to\nobtain an OT-based representation. We study the theoretical properties of a\nkernel ridge regression estimator based on such representation, for which we\nprove universal consistency and excess risk bounds. Preliminary experiments\ncomplement our theoretical findings by showing the effectiveness of the\nproposed approach and compare it with MMD-based estimators.",
    "descriptor": "",
    "authors": [
      "Dimitri Meunier",
      "Massimiliano Pontil",
      "Carlo Ciliberto"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.03926"
  },
  {
    "id": "arXiv:2202.03972",
    "title": "Enabling Imitation-Based Cooperation in Dynamic Social Networks",
    "abstract": "The emergence of cooperation among self-interested agents has been a key\nconcern of the multi-agent systems community for decades. With the increased\nimportance of network-mediated interaction, researchers have shifted the\nattention on the impact of social networks and their dynamics in promoting or\nhindering cooperation, drawing various context-dependent conclusions. For\nexample, some lines of research, theoretical and experimental, suggest the\nexistence of a threshold effect in the ratio of timescales of network\nevolution, after which cooperation will emerge, whereas other lines dispute\nthis, suggesting instead a Goldilocks zone. In this paper we provide an\nevolutionary game theory framework to understand coevolutionary processes from\na bottom up perspective - in particular the emergence of a cooperator-core and\ndefector-periphery - clarifying the impact of partner selection and imitation\nstrategies in promoting cooperative behaviour, without assuming underlying\ncommunication or reputation mechanisms. In doing so we provide a unifying\nframework to study imitation-based cooperation in dynamic social networks and\nshow that disputes in the literature can in fact coexist in so far as the\nresults stem from different equally valid assumptions.",
    "descriptor": "",
    "authors": [
      "Jacques Bara",
      "Paolo Turrini",
      "Giulia Andrighetto"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Computer Science and Game Theory (cs.GT)",
      "Multiagent Systems (cs.MA)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2202.03972"
  },
  {
    "id": "arXiv:2202.03999",
    "title": "A general framework for quantifying uncertainty at scale and its  application to fusion research",
    "abstract": "In many fields of science, remarkably comprehensive and realistic\ncomputational models are available nowadays. Often, the respective numerical\ncalculations call for the use of powerful supercomputers, and therefore only a\nlimited number of cases can be investigated explicitly. This prevents\nstraightforward approaches to important tasks like uncertainty quantification\nand sensitivity analysis. As it turns out, this challenge can be overcome via\nour recently developed sensitivity-driven dimension-adaptive sparse grid\ninterpolation strategy. The method exploits, via adaptivity, the structure of\nthe underlying model (such as lower intrinsic dimensionality and anisotropic\ncoupling of the uncertain inputs) to enable efficient and accurate uncertainty\nquantification and sensitivity analysis at scale. We demonstrate the efficiency\nof our approach in the context of fusion research, in a realistic,\ncomputationally expensive scenario of turbulent transport in a magnetic\nconfinement device with eight uncertain parameters, reducing the effort by at\nleast two orders of magnitude. In addition, we show that our method\nintrinsically provides an accurate reduced model that is nine orders of\nmagnitude cheaper than the high-fidelity model. Our approach enables studies\npreviously considered infeasible.",
    "descriptor": "\nComments: 16 pages, 4 figures, 1 table\n",
    "authors": [
      "Ionut-Gabriel Farcas",
      "Gabriele Merlo",
      "Frank Jenko"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Plasma Physics (physics.plasm-ph)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2202.03999"
  },
  {
    "id": "arXiv:2202.04020",
    "title": "Efficient Algorithms for High-Dimensional Convex Subspace Optimization  via Strict Complementarity",
    "abstract": "We consider optimization problems in which the goal is find a $k$-dimensional\nsubspace of $\\reals^n$, $k<<n$, which minimizes a convex and smooth loss. Such\nproblemsgeneralize the fundamental task of principal component analysis (PCA)\nto include robust and sparse counterparts, and logistic PCA for binary data,\namong others. While this problem is not convex it admits natural algorithms\nwith very efficient iterations and memory requirements, which is highly desired\nin high-dimensional regimes however, arguing about their fast convergence to a\nglobal optimal solution is difficult. On the other hand, there exists a simple\nconvex relaxation for which convergence to the global optimum is\nstraightforward, however corresponding algorithms are not efficient when the\ndimension is very large. In this work we present a natural deterministic\nsufficient condition so that the optimal solution to the convex relaxation is\nunique and is also the optimal solution to the original nonconvex problem.\nMainly, we prove that under this condition, a natural highly-efficient\nnonconvex gradient method, which we refer to as \\textit{gradient orthogonal\niteration}, when initialized with a \"warm-start\", converges linearly for the\nnonconvex problem. We also establish similar results for the nonconvex\nprojected gradient method, and the Frank-Wolfe method when applied to the\nconvex relaxation. We conclude with empirical evidence on synthetic data which\ndemonstrate the appeal of our approach.",
    "descriptor": "",
    "authors": [
      "Dan Garber",
      "Ron Fisher"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.04020"
  },
  {
    "id": "arXiv:2202.04026",
    "title": "Low-Rank Extragradient Method for Nonsmooth and Low-Rank Matrix  Optimization Problems",
    "abstract": "Low-rank and nonsmooth matrix optimization problems capture many fundamental\ntasks in statistics and machine learning. While significant progress has been\nmade in recent years in developing efficient methods for \\textit{smooth}\nlow-rank optimization problems that avoid maintaining high-rank matrices and\ncomputing expensive high-rank SVDs, advances for nonsmooth problems have been\nslow paced.\nIn this paper we consider standard convex relaxations for such problems.\nMainly, we prove that under a natural \\textit{generalized strict\ncomplementarity} condition and under the relatively mild assumption that the\nnonsmooth objective can be written as a maximum of smooth functions, the\n\\textit{extragradient method}, when initialized with a \"warm-start\" point,\nconverges to an optimal solution with rate $O(1/t)$ while requiring only two\n\\textit{low-rank} SVDs per iteration. We give a precise trade-off between the\nrank of the SVDs required and the radius of the ball in which we need to\ninitialize the method. We support our theoretical results with empirical\nexperiments on several nonsmooth low-rank matrix recovery tasks, demonstrating\nthat using simple initializations, the extragradient method produces exactly\nthe same iterates when full-rank SVDs are replaced with SVDs of rank that\nmatches the rank of the (low-rank) ground-truth matrix to be recovered.",
    "descriptor": "\nComments: Appeared in Conference on Neural Information Processing Systems (NeurIPS), 2021\n",
    "authors": [
      "Dan Garber",
      "Atara Kaplan"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.04026"
  },
  {
    "id": "arXiv:2202.04047",
    "title": "An exact quantum hidden subgroup algorithm and applications to solvable  groups",
    "abstract": "We present a polynomial time exact quantum algorithm for the hidden subgroup\nproblem in $Z_{m^k}^n$. The algorithm uses the quantum Fourier transform modulo\nm and does not require factorization of m. For smooth m, i.e., when the prime\nfactors of m are of size poly(log m), the quantum Fourier transform can be\nexactly computed using the method discovered independently by Cleve and\nCoppersmith, while for general m, the algorithm of Mosca and Zalka is\navailable. Even for m=3 and k=1 our result appears to be new. We also present\napplications to compute the structure of abelian and solvable groups whose\norder has the same (but possibly unknown) prime factors as m. The applications\nfor solvable groups also rely on an exact version of a technique proposed by\nWatrous for computing the uniform superposition of elements of subgroups.",
    "descriptor": "",
    "authors": [
      "Muhammad Imran",
      "Gabor Ivanyos"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2202.04047"
  },
  {
    "id": "arXiv:2202.04060",
    "title": "Streaming word problems",
    "abstract": "We study deterministic and randomized streaming algorithms for word problems\nof finitely generated groups. For finitely generated linear groups, metabelian\ngroups and free solvable groups we show the existence of randomized streaming\nalgorithms with logarithmic space complexity for their word problems. We also\nshow that the class of finitely generated groups with a logspace randomized\nstreaming algorithm for the word problem is closed under several group\ntheoretical constructions: finite extensions, direct products, free products\nand wreath products by free abelian groups. We contrast these results with\nseveral lower bound. An example of a finitely presented group, where the word\nproblem has only a linear space randomized streaming algorithm, is Thompson's\ngroup $F$.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2101.06132 by other authors\n",
    "authors": [
      "Markus Lohrey",
      "Lukas L\u00fcck"
    ],
    "subjectives": [
      "Group Theory (math.GR)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2202.04060"
  },
  {
    "id": "arXiv:1602.08614",
    "title": "A Super-Resolution Framework for Tensor Decomposition",
    "abstract": "A Super-Resolution Framework for Tensor Decomposition",
    "descriptor": "",
    "authors": [
      "Qiuwei Li",
      "Ashley Prater",
      "Lixin Shen",
      "Gongguo Tang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/1602.08614"
  },
  {
    "id": "arXiv:1905.10629",
    "title": "Flexibly Regularized Mixture Models and Application to Image  Segmentation",
    "abstract": "Comments: 34 pages ( 31 + 3 for appendix). 12 figures + 1 in appendix, in press Neural Networks Journal",
    "descriptor": "\nComments: 34 pages ( 31 + 3 for appendix). 12 figures + 1 in appendix, in press Neural Networks Journal\n",
    "authors": [
      "Jonathan Vacher",
      "Claire Launay",
      "Ruben Coen-Cagli"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/1905.10629"
  },
  {
    "id": "arXiv:1906.01296",
    "title": "Algebraic representation of dual scalar products and stabilization of  saddle point problems",
    "abstract": "Algebraic representation of dual scalar products and stabilization of  saddle point problems",
    "descriptor": "",
    "authors": [
      "Silvia Bertoluzza"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/1906.01296"
  },
  {
    "id": "arXiv:1906.06412",
    "title": "Value Functions for Depth-Limited Solving in Zero-Sum  Imperfect-Information Games",
    "abstract": "Comments: The first two authors contributed equally",
    "descriptor": "\nComments: The first two authors contributed equally\n",
    "authors": [
      "Vojt\u011bch Kova\u0159\u00edk",
      "Dominik Seitz",
      "Viliam Lis\u00fd",
      "Jan Rudolf",
      "Shuo Sun",
      "Karel Ha"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/1906.06412"
  },
  {
    "id": "arXiv:1909.11076",
    "title": "Block Factor-width-two Matrices and Their Applications to Semidefinite  and Sum-of-squares Optimization",
    "abstract": "Comments: Accepted for publication as a regular paper at IEEE TAC. Code is available through this https URL",
    "descriptor": "\nComments: Accepted for publication as a regular paper at IEEE TAC. Code is available through this https URL\n",
    "authors": [
      "Yang Zheng",
      "Aivar Sootla",
      "Antonis Papachristodoulou"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/1909.11076"
  },
  {
    "id": "arXiv:1910.07568",
    "title": "On the Computational Complexity of Finding a Sparse Wasserstein  Barycenter",
    "abstract": "On the Computational Complexity of Finding a Sparse Wasserstein  Barycenter",
    "descriptor": "",
    "authors": [
      "Steffen Borgwardt",
      "Stephan Patterson"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/1910.07568"
  },
  {
    "id": "arXiv:1911.11132",
    "title": "Scaling Out-of-Distribution Detection for Real-World Settings",
    "abstract": "Comments: The Species dataset and code are available at this https URL",
    "descriptor": "\nComments: The Species dataset and code are available at this https URL\n",
    "authors": [
      "Dan Hendrycks",
      "Steven Basart",
      "Mantas Mazeika",
      "Andy Zou",
      "Joe Kwon",
      "Mohammadreza Mostajabi",
      "Jacob Steinhardt",
      "Dawn Song"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/1911.11132"
  },
  {
    "id": "arXiv:2003.07694",
    "title": "Parameter-Free Style Projection for Arbitrary Style Transfer",
    "abstract": "Comments: ICASSP 2022. Project page this https URL and Code this https URL",
    "descriptor": "\nComments: ICASSP 2022. Project page this https URL and Code this https URL\n",
    "authors": [
      "Siyu Huang",
      "Haoyi Xiong",
      "Tianyang Wang",
      "Bihan Wen",
      "Qingzhong Wang",
      "Zeyu Chen",
      "Jun Huan",
      "Dejing Dou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2003.07694"
  },
  {
    "id": "arXiv:2003.08683",
    "title": "Optimal Algorithm Allocation for Single Robot Cloud Systems",
    "abstract": "Comments: \\c{opyright} 2021 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works",
    "descriptor": "\nComments: \\c{opyright} 2021 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works\n",
    "authors": [
      "Saeid Alirezazadeh",
      "Lu\u00eds A. Alexandre"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2003.08683"
  },
  {
    "id": "arXiv:2004.09171",
    "title": "Reachability and liveness in parametric timed automata",
    "abstract": "Comments: This manuscript is an extended version of two conference papers published in the proceedings of ICFEM 2016 and ACSD 2017",
    "descriptor": "\nComments: This manuscript is an extended version of two conference papers published in the proceedings of ICFEM 2016 and ACSD 2017\n",
    "authors": [
      "\u00c9tienne Andr\u00e9",
      "Didier Lime",
      "Olivier H. Roux"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2004.09171"
  },
  {
    "id": "arXiv:2004.14318",
    "title": "The Approximate Degree of Bipartite Perfect Matching",
    "abstract": "The Approximate Degree of Bipartite Perfect Matching",
    "descriptor": "",
    "authors": [
      "Gal Beniamini"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2004.14318"
  },
  {
    "id": "arXiv:2006.05714",
    "title": "OptiLIME: Optimized LIME Explanations for Diagnostic Computer Algorithms",
    "abstract": "OptiLIME: Optimized LIME Explanations for Diagnostic Computer Algorithms",
    "descriptor": "",
    "authors": [
      "Giorgio Visani",
      "Enrico Bagli",
      "Federico Chesani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.05714"
  },
  {
    "id": "arXiv:2006.12834",
    "title": "Sparse-RS: a versatile framework for query-efficient sparse black-box  adversarial attacks",
    "abstract": "Comments: Accepted at AAAI 2022. This version contains considerably extended results in the L0 threat model",
    "descriptor": "\nComments: Accepted at AAAI 2022. This version contains considerably extended results in the L0 threat model\n",
    "authors": [
      "Francesco Croce",
      "Maksym Andriushchenko",
      "Naman D. Singh",
      "Nicolas Flammarion",
      "Matthias Hein"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.12834"
  },
  {
    "id": "arXiv:2008.01701",
    "title": "Progressive Update Guided Interdependent Networks for Single Image  Dehazing",
    "abstract": "Comments: First two authors contributed equally. This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible. Project Website: this https URL",
    "descriptor": "\nComments: First two authors contributed equally. This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible. Project Website: this https URL\n",
    "authors": [
      "Aupendu Kar",
      "Sobhan Kanti Dhara",
      "Debashis Sen",
      "Prabir Kumar Biswas"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2008.01701"
  },
  {
    "id": "arXiv:2008.10583",
    "title": "Layered Drawing of Undirected Graphs with Generalized Port Constraints",
    "abstract": "Layered Drawing of Undirected Graphs with Generalized Port Constraints",
    "descriptor": "",
    "authors": [
      "Julian Walter",
      "Johannes Zink",
      "Joachim Baumeister",
      "Alexander Wolff"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2008.10583"
  },
  {
    "id": "arXiv:2009.08647",
    "title": "Global Linear Convergence of Evolution Strategies on More Than Smooth  Strongly Convex Functions",
    "abstract": "Comments: SIAM Journal on Optimization (Accepted)",
    "descriptor": "\nComments: SIAM Journal on Optimization (Accepted)\n",
    "authors": [
      "Youhei Akimoto",
      "Anne Auger",
      "Tobias Glasmachers",
      "Daiki Morinaga"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2009.08647"
  },
  {
    "id": "arXiv:2010.01387",
    "title": "DuoBFT: Resilience vs. Performance Trade-off in Byzantine Fault  Tolerance",
    "abstract": "Comments: 15 pages",
    "descriptor": "\nComments: 15 pages\n",
    "authors": [
      "Balaji Arun",
      "Binoy Ravindran"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2010.01387"
  },
  {
    "id": "arXiv:2010.08054",
    "title": "Pose Estimation for Robot Manipulators via Keypoint Optimization and  Sim-to-Real Transfer",
    "abstract": "Comments: 8 pages, 9 figures. Accepted to IEEE Robotics and Automation Letters January, 2022",
    "descriptor": "\nComments: 8 pages, 9 figures. Accepted to IEEE Robotics and Automation Letters January, 2022\n",
    "authors": [
      "Jingpei Lu",
      "Florian Richter",
      "Michael Yip"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2010.08054"
  },
  {
    "id": "arXiv:2010.09305",
    "title": "Numerical approximations to a singularly perturbed convection-diffusion  problem with a discontinuous initial condition",
    "abstract": "Comments: 24 pages; 10 figures",
    "descriptor": "\nComments: 24 pages; 10 figures\n",
    "authors": [
      "Jose Luis Gracia",
      "Eugene O'Riordan"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2010.09305"
  },
  {
    "id": "arXiv:2010.09307",
    "title": "Parameter-uniform approximations for a singularly perturbed  convection-diffusion problem with a discontinuous initial condition",
    "abstract": "Comments: 28 pages; 2 figures",
    "descriptor": "\nComments: 28 pages; 2 figures\n",
    "authors": [
      "Jose Luis Gracia",
      "Eugene O'Riordan"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2010.09307"
  },
  {
    "id": "arXiv:2010.09343",
    "title": "SelfVoxeLO: Self-supervised LiDAR Odometry with Voxel-based Deep Neural  Networks",
    "abstract": "Comments: Accepted to CoRL 2020",
    "descriptor": "\nComments: Accepted to CoRL 2020\n",
    "authors": [
      "Yan Xu",
      "Zhaoyang Huang",
      "Kwan-Yee Lin",
      "Xinge Zhu",
      "Jianping Shi",
      "Hujun Bao",
      "Guofeng Zhang",
      "Hongsheng Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2010.09343"
  },
  {
    "id": "arXiv:2010.11187",
    "title": "G-Elo: Generalization of the Elo algorithm by modelling the discretized  margin of victory",
    "abstract": "G-Elo: Generalization of the Elo algorithm by modelling the discretized  margin of victory",
    "descriptor": "",
    "authors": [
      "Leszek Szczecinski"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2010.11187"
  },
  {
    "id": "arXiv:2010.12794",
    "title": "X-Class: Text Classification with Extremely Weak Supervision",
    "abstract": "X-Class: Text Classification with Extremely Weak Supervision",
    "descriptor": "",
    "authors": [
      "Zihan Wang",
      "Dheeraj Mekala",
      "Jingbo Shang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2010.12794"
  },
  {
    "id": "arXiv:2011.02256",
    "title": "Advantage of Deep Neural Networks for Estimating Functions with  Singularity on Hypersurfaces",
    "abstract": "Comments: Complete version of arXiv:1802.04474",
    "descriptor": "\nComments: Complete version of arXiv:1802.04474\n",
    "authors": [
      "Masaaki Imaizumi",
      "Kenji Fukumizu"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2011.02256"
  },
  {
    "id": "arXiv:2011.02427",
    "title": "Super-Resolution of Real-World Faces",
    "abstract": "Comments: 15 pages",
    "descriptor": "\nComments: 15 pages\n",
    "authors": [
      "Saurabh Goswami",
      "Aakanksha",
      "Rajagopalan A. N"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2011.02427"
  },
  {
    "id": "arXiv:2011.08562",
    "title": "A Deep Neural Network for SSVEP-based Brain-Computer Interfaces",
    "abstract": "Comments: 12 pages, 9 figures",
    "descriptor": "\nComments: 12 pages, 9 figures\n",
    "authors": [
      "Osman Berke Guney",
      "Muhtasham Oblokulov",
      "Huseyin Ozkan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2011.08562"
  },
  {
    "id": "arXiv:2011.10534",
    "title": "Ambiguity through the lens of measure theory",
    "abstract": "Ambiguity through the lens of measure theory",
    "descriptor": "",
    "authors": [
      "Olivier Carton"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2011.10534"
  },
  {
    "id": "arXiv:2011.14860",
    "title": "Infinite Probabilistic Databases",
    "abstract": "Comments: This is the full version of the paper \"Infinite Probabilistic Databases\" presented at ICDT 2020 (arXiv:1904.06766)",
    "descriptor": "\nComments: This is the full version of the paper \"Infinite Probabilistic Databases\" presented at ICDT 2020 (arXiv:1904.06766)\n",
    "authors": [
      "Martin Grohe",
      "Peter Lindner"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2011.14860"
  },
  {
    "id": "arXiv:2012.01388",
    "title": "Gaussian Process-based Approach for Bilevel Optimization in the Power  System -- A Critical Load Restoration Case",
    "abstract": "Comments: 13 pages, 9 figures, submitted to IEEE",
    "descriptor": "\nComments: 13 pages, 9 figures, submitted to IEEE\n",
    "authors": [
      "Yang Liu",
      "Yu Weng",
      "Rufan Yang",
      "Quoc-Tuan Tran",
      "Hung D. Nguyen"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2012.01388"
  },
  {
    "id": "arXiv:2101.04662",
    "title": "Output Regulation of Linear Aperiodic Sampled-Data Systems",
    "abstract": "Comments: Accepted for presentation at the American Control Conference 2022",
    "descriptor": "\nComments: Accepted for presentation at the American Control Conference 2022\n",
    "authors": [
      "Himadri Basu",
      "Francesco Ferrante",
      "Se Young Yoon"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2101.04662"
  },
  {
    "id": "arXiv:2101.09933",
    "title": "A Survey on Active Deep Learning: From Model-driven to Data-driven",
    "abstract": "Comments: some of contents are being revised",
    "descriptor": "\nComments: some of contents are being revised\n",
    "authors": [
      "Peng Liu",
      "Lizhe Wang",
      "Guojin He",
      "Lei Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2101.09933"
  },
  {
    "id": "arXiv:2102.00053",
    "title": "Poincar\u00e9-Bendixson Limit Sets in Multi-Agent Learning",
    "abstract": "Poincar\u00e9-Bendixson Limit Sets in Multi-Agent Learning",
    "descriptor": "",
    "authors": [
      "Aleksander Czechowski",
      "Georgios Piliouras"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2102.00053"
  },
  {
    "id": "arXiv:2102.05691",
    "title": "Novel Techniques to Assess Predictive Systems and Reduce Their Alarm  Burden",
    "abstract": "Comments: 12 pages, 5 figures, 10 tables",
    "descriptor": "\nComments: 12 pages, 5 figures, 10 tables\n",
    "authors": [
      "Jonathan A. Handler",
      "Craig F. Feied",
      "Michael T. Gillam"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2102.05691"
  },
  {
    "id": "arXiv:2103.05056",
    "title": "LCDNet: Deep Loop Closure Detection and Point Cloud Registration for  LiDAR SLAM",
    "abstract": "Comments: Accepted to IEEE Transactions on Robotics (T-RO), 2022",
    "descriptor": "\nComments: Accepted to IEEE Transactions on Robotics (T-RO), 2022\n",
    "authors": [
      "Daniele Cattaneo",
      "Matteo Vaghi",
      "Abhinav Valada"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.05056"
  },
  {
    "id": "arXiv:2103.07169",
    "title": "Facial emotion expressions in human-robot interaction: A survey",
    "abstract": "Comments: Pre-print version. Accepted in International Journal of Social Robotics",
    "descriptor": "\nComments: Pre-print version. Accepted in International Journal of Social Robotics\n",
    "authors": [
      "Niyati Rawal",
      "Ruth Maria Stock-Homburg"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2103.07169"
  },
  {
    "id": "arXiv:2103.12046",
    "title": "Computing the Riemannian logarithm on the Stiefel manifold: metrics,  methods and performance",
    "abstract": "Comments: 32 pages, 10 figures",
    "descriptor": "\nComments: 32 pages, 10 figures\n",
    "authors": [
      "Ralf Zimmermann",
      "Knut H\u00fcper"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2103.12046"
  },
  {
    "id": "arXiv:2103.16020",
    "title": "Machine learning method for light field refocusing",
    "abstract": "Machine learning method for light field refocusing",
    "descriptor": "",
    "authors": [
      "Eisa Hedayati",
      "Timothy C. Havens",
      "Jeremy P. Bos"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.16020"
  },
  {
    "id": "arXiv:2104.06876",
    "title": "Landmarking for Navigational Streaming of Stored High-Dimensional Media",
    "abstract": "Comments: 15 pages, 13 figures,accepted by TCSVT. With supplementary files",
    "descriptor": "\nComments: 15 pages, 13 figures,accepted by TCSVT. With supplementary files\n",
    "authors": [
      "Yuan Yuan",
      "Gene Cheung",
      "Pascal Frossard",
      "H.Vicky Zhao",
      "Jiwu Huang"
    ],
    "subjectives": [
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2104.06876"
  },
  {
    "id": "arXiv:2104.07487",
    "title": "Lipschitz Selectors may not Yield Competitive Algorithms for Convex Body  Chasing",
    "abstract": "Lipschitz Selectors may not Yield Competitive Algorithms for Convex Body  Chasing",
    "descriptor": "",
    "authors": [
      "C.J. Argue",
      "Anupam Gupta",
      "Marco Molinaro"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2104.07487"
  },
  {
    "id": "arXiv:2104.08673",
    "title": "\"Average\" Approximates \"First Principal Component\"? An Empirical  Analysis on Representations from Neural Language Models",
    "abstract": "\"Average\" Approximates \"First Principal Component\"? An Empirical  Analysis on Representations from Neural Language Models",
    "descriptor": "",
    "authors": [
      "Zihan Wang",
      "Chengyu Dong",
      "Jingbo Shang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.08673"
  },
  {
    "id": "arXiv:2104.13122",
    "title": "Why Does Propositional Quantification Make Logics on Trees Robustly  Hard?",
    "abstract": "Comments: Submitted to LMCS. Full version of our LICS 2019 paper",
    "descriptor": "\nComments: Submitted to LMCS. Full version of our LICS 2019 paper\n",
    "authors": [
      "Bartosz Bednarczyk",
      "St\u00e9phane Demri"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2104.13122"
  },
  {
    "id": "arXiv:2105.06872",
    "title": "Revizor: Testing Black-box CPUs against Speculation Contracts",
    "abstract": "Comments: Published in Proceedings of the 27th ACM International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS'22)",
    "descriptor": "\nComments: Published in Proceedings of the 27th ACM International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS'22)\n",
    "authors": [
      "Oleksii Oleksenko",
      "Christof Fetzer",
      "Boris K\u00f6pf",
      "Mark Silberstein"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2105.06872"
  },
  {
    "id": "arXiv:2105.12801",
    "title": "Dialectica Petri nets",
    "abstract": "Dialectica Petri nets",
    "descriptor": "",
    "authors": [
      "Elena Di Lavore",
      "Wilmer Leal",
      "Valeria de Paiva"
    ],
    "subjectives": [
      "Category Theory (math.CT)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2105.12801"
  },
  {
    "id": "arXiv:2105.13635",
    "title": "Noised Consistency Training for Text Summarization",
    "abstract": "Comments: There were some errors in experiment",
    "descriptor": "\nComments: There were some errors in experiment\n",
    "authors": [
      "Junnan Liu",
      "Qianren Mao",
      "Bang Liu",
      "Hao Peng",
      "Hongdong Zhu",
      "Jianxin Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.13635"
  },
  {
    "id": "arXiv:2105.14328",
    "title": "Transfer Learning under High-dimensional Generalized Linear Models",
    "abstract": "Comments: 94 pages, 11 figures",
    "descriptor": "\nComments: 94 pages, 11 figures\n",
    "authors": [
      "Ye Tian",
      "Yang Feng"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2105.14328"
  },
  {
    "id": "arXiv:2106.00651",
    "title": "Asymptotics of representation learning in finite Bayesian neural  networks",
    "abstract": "Comments: 13+28 pages, 4 figures; v3: extensive revision with improved exposition and new section on CNNs, accepted to NeurIPS 2021; v4: minor updates to supplement; v5: post-NeurIPS update, minor typos fixed",
    "descriptor": "\nComments: 13+28 pages, 4 figures; v3: extensive revision with improved exposition and new section on CNNs, accepted to NeurIPS 2021; v4: minor updates to supplement; v5: post-NeurIPS update, minor typos fixed\n",
    "authors": [
      "Jacob A. Zavatone-Veth",
      "Abdulkadir Canatar",
      "Benjamin S. Ruben",
      "Cengiz Pehlevan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.00651"
  },
  {
    "id": "arXiv:2106.00734",
    "title": "Post-mortem on a deep learning contest: a Simpson's paradox and the  complementary roles of scale metrics versus shape metrics",
    "abstract": "Comments: 21 pages; 9 figures; 6 tables",
    "descriptor": "\nComments: 21 pages; 9 figures; 6 tables\n",
    "authors": [
      "Charles H. Martin",
      "Michael W. Mahoney"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.00734"
  },
  {
    "id": "arXiv:2106.02073",
    "title": "Neural Collapse Under MSE Loss: Proximity to and Dynamics on the Central  Path",
    "abstract": "Comments: ICLR 2022 Oral. Appendix contains [A] empirical experiments, [B-D] proofs of theoretical results, and [E] survey of related works examining Neural Collapse",
    "descriptor": "\nComments: ICLR 2022 Oral. Appendix contains [A] empirical experiments, [B-D] proofs of theoretical results, and [E] survey of related works examining Neural Collapse\n",
    "authors": [
      "X.Y. Han",
      "Vardan Papyan",
      "David L. Donoho"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Differential Geometry (math.DG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.02073"
  },
  {
    "id": "arXiv:2106.04908",
    "title": "Automatic Sexism Detection with Multilingual Transformer Models",
    "abstract": "Comments: Technical Report to the AIT_FHSTP EXIST 2021 Challenge contribution (under review) this http URL",
    "descriptor": "\nComments: Technical Report to the AIT_FHSTP EXIST 2021 Challenge contribution (under review) this http URL\n",
    "authors": [
      "Mina Sch\u00fctz",
      "Jaqueline Boeck",
      "Daria Liakhovets",
      "Djordje Slijep\u010devi\u0107",
      "Armin Kirchknopf",
      "Manuel Hecht",
      "Johannes Bogensperger",
      "Sven Schlarb",
      "Alexander Schindler",
      "Matthias Zeppelzauer"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.04908"
  },
  {
    "id": "arXiv:2106.06338",
    "title": "Understanding approximate and unrolled dictionary learning for pattern  recovery",
    "abstract": "Understanding approximate and unrolled dictionary learning for pattern  recovery",
    "descriptor": "",
    "authors": [
      "Beno\u00eet Mal\u00e9zieux",
      "Thomas Moreau",
      "Matthieu Kowalski"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.06338"
  },
  {
    "id": "arXiv:2106.06468",
    "title": "Locally Sparse Neural Networks for Tabular Biomedical Data",
    "abstract": "Locally Sparse Neural Networks for Tabular Biomedical Data",
    "descriptor": "",
    "authors": [
      "Junchen Yang",
      "Ofir Lindenbaum",
      "Yuval Kluger"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.06468"
  },
  {
    "id": "arXiv:2106.09403",
    "title": "Density of Free Modules over Finite Chain Rings",
    "abstract": "Density of Free Modules over Finite Chain Rings",
    "descriptor": "",
    "authors": [
      "Eimear Byrne",
      "Anna-Lena Horlemann",
      "Karan Khathuria",
      "Violetta Weger"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2106.09403"
  },
  {
    "id": "arXiv:2106.13695",
    "title": "CADDA: Class-wise Automatic Differentiable Data Augmentation for EEG  Signals",
    "abstract": "CADDA: Class-wise Automatic Differentiable Data Augmentation for EEG  Signals",
    "descriptor": "",
    "authors": [
      "C\u00e9dric Rommel",
      "Thomas Moreau",
      "Joseph Paillard",
      "Alexandre Gramfort"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.13695"
  },
  {
    "id": "arXiv:2106.15499",
    "title": "Self-Contrastive Learning: An Efficient Supervised Contrastive Framework  with Single-view and Sub-network",
    "abstract": "Self-Contrastive Learning: An Efficient Supervised Contrastive Framework  with Single-view and Sub-network",
    "descriptor": "",
    "authors": [
      "Sangmin Bae",
      "Sungnyun Kim",
      "Jongwoo Ko",
      "Gihun Lee",
      "Seungjong Noh",
      "Se-Young Yun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.15499"
  },
  {
    "id": "arXiv:2107.01581",
    "title": "Noise Tolerant Identification and Tuning Approach Using Deep Neural  Networks For Visual Servoing Applications",
    "abstract": "Noise Tolerant Identification and Tuning Approach Using Deep Neural  Networks For Visual Servoing Applications",
    "descriptor": "",
    "authors": [
      "Oussama Abdul Hay",
      "Mohamad Chehadeh",
      "Abdulla Ayyad",
      "Mohamad Wahbah",
      "Muhammad Humais",
      "Lakmal Seneviratne",
      "Yahya Zweiri"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2107.01581"
  },
  {
    "id": "arXiv:2107.05434",
    "title": "Polynomial-time algorithm for Maximum Independent Set in bounded-degree  graphs with no long induced claws",
    "abstract": "Polynomial-time algorithm for Maximum Independent Set in bounded-degree  graphs with no long induced claws",
    "descriptor": "",
    "authors": [
      "Tara Abrishami",
      "Maria Chudnovsky",
      "Cemil Dibek",
      "Pawe\u0142 Rz\u0105\u017cewski"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2107.05434"
  },
  {
    "id": "arXiv:2107.09896",
    "title": "Terahertz Meets Untrusted UAV-Relaying: Minimum Secrecy Energy  Efficiency Maximization via Trajectory and Communication Co-design",
    "abstract": "Comments: 16 pages, 10 figures, Accepted by (to appear in) the IEEE Transactions on Vehicular Technology",
    "descriptor": "\nComments: 16 pages, 10 figures, Accepted by (to appear in) the IEEE Transactions on Vehicular Technology\n",
    "authors": [
      "Milad Tatar Mamaghani",
      "Yi Hong"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2107.09896"
  },
  {
    "id": "arXiv:2108.00853",
    "title": "Sea Ice Forecasting using Attention-based Ensemble LSTM",
    "abstract": "Comments: Accepted by the Tackling Climate Change with Machine Learning Workshop at the 2021 International Conference on Machine Learning (ICML 2021)",
    "descriptor": "\nComments: Accepted by the Tackling Climate Change with Machine Learning Workshop at the 2021 International Conference on Machine Learning (ICML 2021)\n",
    "authors": [
      "Sahara Ali",
      "Yiyi Huang",
      "Xin Huang",
      "Jianwu Wang"
    ],
    "subjectives": [
      "Atmospheric and Oceanic Physics (physics.ao-ph)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.00853"
  },
  {
    "id": "arXiv:2108.00937",
    "title": "Modeling and simulation of thin sheet folding",
    "abstract": "Modeling and simulation of thin sheet folding",
    "descriptor": "",
    "authors": [
      "S\u00f6ren Bartels",
      "Andrea Bonito",
      "Peter Hornung"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)"
    ],
    "url": "https://arxiv.org/abs/2108.00937"
  },
  {
    "id": "arXiv:2108.04729",
    "title": "Spectral Robustness for Correlation Clustering Reconstruction in  Semi-Adversarial Models",
    "abstract": "Spectral Robustness for Correlation Clustering Reconstruction in  Semi-Adversarial Models",
    "descriptor": "",
    "authors": [
      "Flavio Chierichetti",
      "Alessandro Panconesi",
      "Giuseppe Re",
      "Luca Trevisan"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.04729"
  },
  {
    "id": "arXiv:2108.13863",
    "title": "Divergence formulas for sampling derivatives of transfer operators on an  orbit",
    "abstract": "Comments: 17 pages, 1 figure. This update added the equivariant divergence formula for the unstable derivative operator, and shortens previous cost estimation for finite-element approximations",
    "descriptor": "\nComments: 17 pages, 1 figure. This update added the equivariant divergence formula for the unstable derivative operator, and shortens previous cost estimation for finite-element approximations\n",
    "authors": [
      "Angxiu Ni"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2108.13863"
  },
  {
    "id": "arXiv:2109.01753",
    "title": "Assessing the Performance of Online Students -- New Data, New  Approaches, Improved Accuracy",
    "abstract": "Assessing the Performance of Online Students -- New Data, New  Approaches, Improved Accuracy",
    "descriptor": "",
    "authors": [
      "Robin Schmucker",
      "Jingbo Wang",
      "Shijia Hu",
      "Tom M. Mitchell"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2109.01753"
  },
  {
    "id": "arXiv:2109.02754",
    "title": "In-situ visualization of regional-scale natural hazards with Galaxy and  Material Point Method",
    "abstract": "In-situ visualization of regional-scale natural hazards with Galaxy and  Material Point Method",
    "descriptor": "",
    "authors": [
      "Greg Abram",
      "Andrew Solis",
      "Yong Liang",
      "Krishna Kumar"
    ],
    "subjectives": [
      "Geophysics (physics.geo-ph)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2109.02754"
  },
  {
    "id": "arXiv:2109.04228",
    "title": "Coordinate Descent Methods for DC Minimization",
    "abstract": "Coordinate Descent Methods for DC Minimization",
    "descriptor": "",
    "authors": [
      "Ganzhao Yuan"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.04228"
  },
  {
    "id": "arXiv:2109.09831",
    "title": "SMAC3: A Versatile Bayesian Optimization Package for Hyperparameter  Optimization",
    "abstract": "SMAC3: A Versatile Bayesian Optimization Package for Hyperparameter  Optimization",
    "descriptor": "",
    "authors": [
      "Marius Lindauer",
      "Katharina Eggensperger",
      "Matthias Feurer",
      "Andr\u00e9 Biedenkapp",
      "Difan Deng",
      "Carolin Benjamins",
      "Tim Ruhopf",
      "Ren\u00e9 Sass",
      "Frank Hutter"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2109.09831"
  },
  {
    "id": "arXiv:2109.11887",
    "title": "Distributionally Robust Joint Chance-Constrained Optimization for  Networked Microgrids Considering Contingencies and Renewable Uncertainty",
    "abstract": "Comments: Accepted by IEEE Transactions on Smart Grid",
    "descriptor": "\nComments: Accepted by IEEE Transactions on Smart Grid\n",
    "authors": [
      "Yifu Ding",
      "Thomas Morstyn",
      "Malcolm D. McCulloch"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2109.11887"
  },
  {
    "id": "arXiv:2110.00641",
    "title": "Batch size-invariance for policy optimization",
    "abstract": "Comments: Submitted to ICLR 2022. 27 pages. Code is available at this https URL",
    "descriptor": "\nComments: Submitted to ICLR 2022. 27 pages. Code is available at this https URL\n",
    "authors": [
      "Jacob Hilton",
      "Karl Cobbe",
      "John Schulman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.00641"
  },
  {
    "id": "arXiv:2110.02868",
    "title": "Coded Shotgun Sequencing",
    "abstract": "Comments: 35 pages, 4 figures, 8 appendices",
    "descriptor": "\nComments: 35 pages, 4 figures, 8 appendices\n",
    "authors": [
      "Aditya Narayan Ravi",
      "Alireza Vahid",
      "Ilan Shomorony"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2110.02868"
  },
  {
    "id": "arXiv:2110.03176",
    "title": "Emergence of Robust and Efficient Networks in a Family of Attachment  Models",
    "abstract": "Emergence of Robust and Efficient Networks in a Family of Attachment  Models",
    "descriptor": "",
    "authors": [
      "Fuxuan Liao",
      "Yukio Hayashi"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)",
      "Adaptation and Self-Organizing Systems (nlin.AO)"
    ],
    "url": "https://arxiv.org/abs/2110.03176"
  },
  {
    "id": "arXiv:2110.03922",
    "title": "A Theory of the Inductive Bias and Generalization of Kernel Regression  and Wide Neural Networks",
    "abstract": "Comments: 9 pages (main text), 23 pages (total), 9 figures",
    "descriptor": "\nComments: 9 pages (main text), 23 pages (total), 9 figures\n",
    "authors": [
      "James B. Simon",
      "Madeline Dickens",
      "Michael R. DeWeese"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.03922"
  },
  {
    "id": "arXiv:2110.04109",
    "title": "Hierarchical Conditional End-to-End ASR with CTC and Multi-Granular  Subword Units",
    "abstract": "Comments: Accepted to ICASSP2022",
    "descriptor": "\nComments: Accepted to ICASSP2022\n",
    "authors": [
      "Yosuke Higuchi",
      "Keita Karube",
      "Tetsuji Ogawa",
      "Tetsunori Kobayashi"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.04109"
  },
  {
    "id": "arXiv:2110.04334",
    "title": "Using Subobservers to Synthesize Opacity-Enforcing Supervisors",
    "abstract": "Comments: 28 pages, 7 figures, submitted to Discrete Event Dynamic Systems",
    "descriptor": "\nComments: 28 pages, 7 figures, submitted to Discrete Event Dynamic Systems\n",
    "authors": [
      "Richard Hugh Moulton",
      "Behnam Behinaein Hamgini",
      "Zahra Abedi Khouzani",
      "R\u00f4mulo Meira-G\u00f3es",
      "Fei Wang",
      "Karen Rudie"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.04334"
  },
  {
    "id": "arXiv:2110.05088",
    "title": "Privacy-Preserving Feature Selection with Fully Homomorphic Encryption",
    "abstract": "Comments: 10 pages",
    "descriptor": "\nComments: 10 pages\n",
    "authors": [
      "Shinji Ono",
      "Jun Takata",
      "Masaharu Kataoka",
      "Tomohiro I",
      "Kilho Shin",
      "Hiroshi Sakamoto"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.05088"
  },
  {
    "id": "arXiv:2110.08058",
    "title": "Quantifying Local Specialization in Deep Neural Networks",
    "abstract": "Comments: 21 pages, 6 figures. Code is available at this https URL",
    "descriptor": "\nComments: 21 pages, 6 figures. Code is available at this https URL\n",
    "authors": [
      "Shlomi Hod",
      "Daniel Filan",
      "Stephen Casper",
      "Andrew Critch",
      "Stuart Russell"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2110.08058"
  },
  {
    "id": "arXiv:2110.08633",
    "title": "Hydra: A System for Large Multi-Model Deep Learning",
    "abstract": "Comments: 14 pages including references. Preprint for VLDB submission",
    "descriptor": "\nComments: 14 pages including references. Preprint for VLDB submission\n",
    "authors": [
      "Kabir Nagrecha",
      "Arun Kumar"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Databases (cs.DB)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.08633"
  },
  {
    "id": "arXiv:2110.11485",
    "title": "Soft Lattice Modules that Behave Independently and Collectively",
    "abstract": "Comments: 8 pages, 15 figures, accepted by Robosoft 2022 and resubmitted to IEEE RA-L",
    "descriptor": "\nComments: 8 pages, 15 figures, accepted by Robosoft 2022 and resubmitted to IEEE RA-L\n",
    "authors": [
      "Luyang Zhao",
      "Yijia Wu",
      "Julien Blanchet",
      "Maxine Perroni-Scharf",
      "Xiaonan Huang",
      "Joran Booth",
      "Rebecca Kramer-Bottiglio",
      "Devin Balkcom"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.11485"
  },
  {
    "id": "arXiv:2110.11665",
    "title": "Diversified Sampling for Batched Bayesian Optimization with  Determinantal Point Processes",
    "abstract": "Comments: To be published in AISTATS 2022",
    "descriptor": "\nComments: To be published in AISTATS 2022\n",
    "authors": [
      "Elvis Nava",
      "Mojm\u00edr Mutn\u00fd",
      "Andreas Krause"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.11665"
  },
  {
    "id": "arXiv:2110.12616",
    "title": "Lower bounds on quantum query complexity for symmetric functions",
    "abstract": "Comments: 26 pages, 2 figures",
    "descriptor": "\nComments: 26 pages, 2 figures\n",
    "authors": [
      "Rajat Mittal",
      "Sanjay S Nair",
      "Sunayana Patro"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2110.12616"
  },
  {
    "id": "arXiv:2110.13136",
    "title": "What Would Jiminy Cricket Do? Towards Agents That Behave Morally",
    "abstract": "Comments: NeurIPS 2021. Environments available here this https URL",
    "descriptor": "\nComments: NeurIPS 2021. Environments available here this https URL\n",
    "authors": [
      "Dan Hendrycks",
      "Mantas Mazeika",
      "Andy Zou",
      "Sahil Patel",
      "Christine Zhu",
      "Jesus Navarro",
      "Dawn Song",
      "Bo Li",
      "Jacob Steinhardt"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2110.13136"
  },
  {
    "id": "arXiv:2110.13423",
    "title": "Towards More Generalizable One-shot Visual Imitation Learning",
    "abstract": "Towards More Generalizable One-shot Visual Imitation Learning",
    "descriptor": "",
    "authors": [
      "Zhao Mandi",
      "Fangchen Liu",
      "Kimin Lee",
      "Pieter Abbeel"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.13423"
  },
  {
    "id": "arXiv:2110.14764",
    "title": "Generalized Funnelling: Ensemble Learning and Heterogeneous Document  Embeddings for Cross-Lingual Text Classification",
    "abstract": "Generalized Funnelling: Ensemble Learning and Heterogeneous Document  Embeddings for Cross-Lingual Text Classification",
    "descriptor": "",
    "authors": [
      "Alejandro Moreo",
      "Andrea Pedrotti",
      "Fabrizio Sebastiani"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.14764"
  },
  {
    "id": "arXiv:2110.14846",
    "title": "Kohn-Sham regularizer for spin density functional theory and weakly  correlated systems",
    "abstract": "Kohn-Sham regularizer for spin density functional theory and weakly  correlated systems",
    "descriptor": "",
    "authors": [
      "Bhupalee Kalita",
      "Ryan Pederson",
      "Jielun Chen",
      "Li Li",
      "Kieron Burke"
    ],
    "subjectives": [
      "Chemical Physics (physics.chem-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.14846"
  },
  {
    "id": "arXiv:2110.14998",
    "title": "An Adaptable Approach to Learn Realistic Legged Locomotion without  Examples",
    "abstract": "Comments: Accepted to ICRA 2022",
    "descriptor": "\nComments: Accepted to ICRA 2022\n",
    "authors": [
      "Daniel Ordonez-Apraez",
      "Antonio Agudo",
      "Francesc Moreno-Noguer",
      "Mario Martin"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Graphics (cs.GR)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.14998"
  },
  {
    "id": "arXiv:2110.15032",
    "title": "OneFlow: Redesign the Distributed Deep Learning Framework from Scratch",
    "abstract": "OneFlow: Redesign the Distributed Deep Learning Framework from Scratch",
    "descriptor": "",
    "authors": [
      "Jinhui Yuan",
      "Xinqi Li",
      "Cheng Cheng",
      "Juncheng Liu",
      "Ran Guo",
      "Shenghang Cai",
      "Chi Yao",
      "Fei Yang",
      "Xiaodong Yi",
      "Chuan Wu",
      "Haoran Zhang",
      "Jie Zhao"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.15032"
  },
  {
    "id": "arXiv:2111.02926",
    "title": "OpenFWI: Benchmark Seismic Datasets for Machine Learning-Based Full  Waveform Inversion",
    "abstract": "OpenFWI: Benchmark Seismic Datasets for Machine Learning-Based Full  Waveform Inversion",
    "descriptor": "",
    "authors": [
      "Chengyuan Deng",
      "Yinan Feng",
      "Shihang Feng",
      "Peng Jin",
      "Xitong Zhang",
      "Qili Zeng",
      "Youzuo Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2111.02926"
  },
  {
    "id": "arXiv:2111.06179",
    "title": "An Enactivist account of Mind Reading in Natural Language Understanding",
    "abstract": "Comments: 18 pages, 46 references, 1 figure (transcript). As submitted to MTI special issue on speech-based interaction",
    "descriptor": "\nComments: 18 pages, 46 references, 1 figure (transcript). As submitted to MTI special issue on speech-based interaction\n",
    "authors": [
      "Peter Wallis"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2111.06179"
  },
  {
    "id": "arXiv:2111.07355",
    "title": "Fracture Detection in Wrist X-ray Images Using Deep Learning-Based  Object Detection Models",
    "abstract": "Comments: This paper is accepted at Sensors, MDPI, 2022, 22, 1285. Section: \"Sensing and Imaging\"",
    "descriptor": "\nComments: This paper is accepted at Sensors, MDPI, 2022, 22, 1285. Section: \"Sensing and Imaging\"\n",
    "authors": [
      "F\u0131rat Hardala\u00e7",
      "Fatih Uysal",
      "Ozan Peker",
      "Murat \u00c7i\u00e7eklida\u011f",
      "Tolga Tolunay",
      "Nil Tokg\u00f6z",
      "U\u011furhan Kutbay",
      "Boran Demirciler",
      "Fatih Mert"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Medical Physics (physics.med-ph)"
    ],
    "url": "https://arxiv.org/abs/2111.07355"
  },
  {
    "id": "arXiv:2111.07917",
    "title": "Best of Both Worlds: Practical and Theoretically Optimal Submodular  Maximization in Parallel",
    "abstract": "Comments: 32 pages, 8 figures, to be published in NeurIPS 2021",
    "descriptor": "\nComments: 32 pages, 8 figures, to be published in NeurIPS 2021\n",
    "authors": [
      "Yixin Chen",
      "Tonmoy Dey",
      "Alan Kuhnle"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.07917"
  },
  {
    "id": "arXiv:2111.08134",
    "title": "A fixed latency ORBGRAND decoder architecture with LUT-aided  error-pattern scheduling",
    "abstract": "Comments: Accepted for publication on IEEE Transactions on Circuits and Systems I",
    "descriptor": "\nComments: Accepted for publication on IEEE Transactions on Circuits and Systems I\n",
    "authors": [
      "Carlo Condo"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2111.08134"
  },
  {
    "id": "arXiv:2111.08410",
    "title": "Thoughts on the Consistency between Ricci Flow and Neural Network  Behavior",
    "abstract": "Thoughts on the Consistency between Ricci Flow and Neural Network  Behavior",
    "descriptor": "",
    "authors": [
      "Jun Chen",
      "Tianxin Huang",
      "Wenzhou Chen",
      "Yong Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2111.08410"
  },
  {
    "id": "arXiv:2111.09389",
    "title": "Low Precision Decentralized Distributed Training over IID and non-IID  Data",
    "abstract": "Comments: 11 pages, 4 figures, 9 tables",
    "descriptor": "\nComments: 11 pages, 4 figures, 9 tables\n",
    "authors": [
      "Sai Aparna Aketi",
      "Sangamesh Kodge",
      "Kaushik Roy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2111.09389"
  },
  {
    "id": "arXiv:2111.10734",
    "title": "Deep Probability Estimation",
    "abstract": "Comments: SL, AK, WZ, ML, SM contributed equally to this work; 36 pages, 16 figures, 11 tables",
    "descriptor": "\nComments: SL, AK, WZ, ML, SM contributed equally to this work; 36 pages, 16 figures, 11 tables\n",
    "authors": [
      "Sheng Liu",
      "Aakash Kaku",
      "Weicheng Zhu",
      "Matan Leibovich",
      "Sreyas Mohan",
      "Boyang Yu",
      "Laure Zanna",
      "Narges Razavian",
      "Carlos Fernandez-Granda"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.10734"
  },
  {
    "id": "arXiv:2112.00427",
    "title": "Research on Event Accumulator Settings for Event-Based SLAM",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:2008.05749 by other authors",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2008.05749 by other authors\n",
    "authors": [
      "Kun Xiao",
      "Guohui Wang",
      "Yi Chen",
      "Yongfeng Xie",
      "Hong Li",
      "Sen Li"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.00427"
  },
  {
    "id": "arXiv:2112.02027",
    "title": "Divergent representations of ethological visual inputs emerge from  supervised, unsupervised, and reinforcement learning",
    "abstract": "Comments: 23 total pages, 9 main figures, 8 Supplementary figures",
    "descriptor": "\nComments: 23 total pages, 9 main figures, 8 Supplementary figures\n",
    "authors": [
      "Grace W. Lindsay",
      "Josh Merel",
      "Tom Mrsic-Flogel",
      "Maneesh Sahani"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.02027"
  },
  {
    "id": "arXiv:2112.04426",
    "title": "Improving language models by retrieving from trillions of tokens",
    "abstract": "Comments: Fix incorrect reported numbers in Table 14",
    "descriptor": "\nComments: Fix incorrect reported numbers in Table 14\n",
    "authors": [
      "Sebastian Borgeaud",
      "Arthur Mensch",
      "Jordan Hoffmann",
      "Trevor Cai",
      "Eliza Rutherford",
      "Katie Millican",
      "George van den Driessche",
      "Jean-Baptiste Lespiau",
      "Bogdan Damoc",
      "Aidan Clark",
      "Diego de Las Casas",
      "Aurelia Guy",
      "Jacob Menick",
      "Roman Ring",
      "Tom Hennigan",
      "Saffron Huang",
      "Loren Maggiore",
      "Chris Jones",
      "Albin Cassirer",
      "Andy Brock",
      "Michela Paganini",
      "Geoffrey Irving",
      "Oriol Vinyals",
      "Simon Osindero",
      "Karen Simonyan",
      "Jack W. Rae",
      "Erich Elsen",
      "Laurent Sifre"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.04426"
  },
  {
    "id": "arXiv:2112.06280",
    "title": "In-Memory Indexed Caching for Distributed Data Processing",
    "abstract": "Comments: Accepted for publication at IEEE IPDPS 2022",
    "descriptor": "\nComments: Accepted for publication at IEEE IPDPS 2022\n",
    "authors": [
      "Alexandru Uta",
      "Bogdan Ghit",
      "Ankur Dave",
      "Jan Rellermeyer",
      "Peter Boncz"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2112.06280"
  },
  {
    "id": "arXiv:2112.08102",
    "title": "Robust Neural Network Classification via Double Regularization",
    "abstract": "Comments: 26 pages, 12 figures",
    "descriptor": "\nComments: 26 pages, 12 figures\n",
    "authors": [
      "Olof Zetterqvist",
      "Rebecka J\u00f6rnsten",
      "Johan Jonasson"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2112.08102"
  },
  {
    "id": "arXiv:2112.08830",
    "title": "Graph-wise Common Latent Factor Extraction for Unsupervised Graph  Representation Learning",
    "abstract": "Comments: Accepted to AAAI 2022",
    "descriptor": "\nComments: Accepted to AAAI 2022\n",
    "authors": [
      "Thilini Cooray",
      "Ngai-Man Cheung"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.08830"
  },
  {
    "id": "arXiv:2112.10510",
    "title": "Transformers Can Do Bayesian Inference",
    "abstract": "Comments: Accepted at ICLR 2022",
    "descriptor": "\nComments: Accepted at ICLR 2022\n",
    "authors": [
      "Samuel M\u00fcller",
      "Noah Hollmann",
      "Sebastian Pineda Arango",
      "Josif Grabocka",
      "Frank Hutter"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.10510"
  },
  {
    "id": "arXiv:2112.11508",
    "title": "PyTracer: Automatically profiling numerical instabilities in Python",
    "abstract": "Comments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Yohan Chatelain",
      "Nigel Yong",
      "Gregory Kiar",
      "Tristan Glatard"
    ],
    "subjectives": [
      "Mathematical Software (cs.MS)",
      "Software Engineering (cs.SE)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2112.11508"
  },
  {
    "id": "arXiv:2112.11663",
    "title": "Accelerated Proximal Alternating Gradient-Descent-Ascent for Nonconvex  Minimax Machine Learning",
    "abstract": "Comments: 12 pages, 1 figure. Corrected proof and complexity order from the previous versions. arXiv admin note: text overlap with arXiv:2102.04653",
    "descriptor": "\nComments: 12 pages, 1 figure. Corrected proof and complexity order from the previous versions. arXiv admin note: text overlap with arXiv:2102.04653\n",
    "authors": [
      "Ziyi Chen",
      "Shaocong Ma",
      "Yi Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2112.11663"
  },
  {
    "id": "arXiv:2112.14162",
    "title": "A New First Order Taylor-like Theorem With An Optimized Reduced  Remainder",
    "abstract": "Comments: 16 pages",
    "descriptor": "\nComments: 16 pages\n",
    "authors": [
      "Joel Chaskalovic",
      "Hessam Jamshidipour"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Classical Analysis and ODEs (math.CA)"
    ],
    "url": "https://arxiv.org/abs/2112.14162"
  },
  {
    "id": "arXiv:2112.14608",
    "title": "HPRN: Holistic Prior-embedded Relation Network for Spectral  Super-Resolution",
    "abstract": "HPRN: Holistic Prior-embedded Relation Network for Spectral  Super-Resolution",
    "descriptor": "",
    "authors": [
      "Chaoxiong Wu",
      "Jiaojiao Li",
      "Rui Song",
      "Yunsong Li",
      "Qian Du"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.14608"
  },
  {
    "id": "arXiv:2112.14624",
    "title": "Towards a Shapley Value Graph Framework for Medical peer-influence",
    "abstract": "Comments: Preliminary work - to be expanded and amended",
    "descriptor": "\nComments: Preliminary work - to be expanded and amended\n",
    "authors": [
      "Jamie Duell",
      "Monika Seisenberger",
      "Gert Aarts",
      "Shangming Zhou",
      "Xiuyi Fan"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.14624"
  },
  {
    "id": "arXiv:2201.00724",
    "title": "Submodular Maximization with Limited Function Access",
    "abstract": "Comments: 14 pages, 8 figures",
    "descriptor": "\nComments: 14 pages, 8 figures\n",
    "authors": [
      "Andrew Downie",
      "Bahman Gharesifard",
      "Stephen L. Smith"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2201.00724"
  },
  {
    "id": "arXiv:2201.02351",
    "title": "Asymptotic Security using Bayesian Defense Mechanism with Application to  Cyber Deception",
    "abstract": "Comments: 16 pages",
    "descriptor": "\nComments: 16 pages\n",
    "authors": [
      "Hampei Sasahara",
      "Henrik Sandberg"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Science and Game Theory (cs.GT)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2201.02351"
  },
  {
    "id": "arXiv:2201.02441",
    "title": "Applications of Signature Methods to Market Anomaly Detection",
    "abstract": "Applications of Signature Methods to Market Anomaly Detection",
    "descriptor": "",
    "authors": [
      "Erdinc Akyildirim",
      "Matteo Gambara",
      "Josef Teichmann",
      "Syang Zhou"
    ],
    "subjectives": [
      "Computational Finance (q-fin.CP)",
      "Machine Learning (cs.LG)",
      "Mathematical Finance (q-fin.MF)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2201.02441"
  },
  {
    "id": "arXiv:2201.03514",
    "title": "Black-Box Tuning for Language-Model-as-a-Service",
    "abstract": "Comments: 14 pages. Code is available at this https URL",
    "descriptor": "\nComments: 14 pages. Code is available at this https URL\n",
    "authors": [
      "Tianxiang Sun",
      "Yunfan Shao",
      "Hong Qian",
      "Xuanjing Huang",
      "Xipeng Qiu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2201.03514"
  },
  {
    "id": "arXiv:2201.04676",
    "title": "UniFormer: Unified Transformer for Efficient Spatiotemporal  Representation Learning",
    "abstract": "Comments: Published as a conference paper at ICLR 2022; 19pages, 7 figures",
    "descriptor": "\nComments: Published as a conference paper at ICLR 2022; 19pages, 7 figures\n",
    "authors": [
      "Kunchang Li",
      "Yali Wang",
      "Peng Gao",
      "Guanglu Song",
      "Yu Liu",
      "Hongsheng Li",
      "Yu Qiao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.04676"
  },
  {
    "id": "arXiv:2201.06566",
    "title": "Sizing of Energy Storage System for Virtual Inertia Emulation",
    "abstract": "Comments: Battery Energy Storage System, Virtual Synchronous Generators, Virtual Inertia, Frequency Response, Renewable Energy Sources, Grid Stability, Droop Control",
    "descriptor": "\nComments: Battery Energy Storage System, Virtual Synchronous Generators, Virtual Inertia, Frequency Response, Renewable Energy Sources, Grid Stability, Droop Control\n",
    "authors": [
      "Mohamed Abuagreb",
      "Ahmed Abuhussein",
      "Saif alZahir"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2201.06566"
  },
  {
    "id": "arXiv:2201.06885",
    "title": "Evidence-aware Fake News Detection with Graph Neural Networks",
    "abstract": "Comments: Accepted by TheWebConf 2022",
    "descriptor": "\nComments: Accepted by TheWebConf 2022\n",
    "authors": [
      "Weizhi Xu",
      "Junfei Wu",
      "Qiang Liu",
      "Shu Wu",
      "Liang Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2201.06885"
  },
  {
    "id": "arXiv:2201.07284",
    "title": "TranAD: Deep Transformer Networks for Anomaly Detection in Multivariate  Time Series Data",
    "abstract": "Comments: Accepted in VLDB 2022",
    "descriptor": "\nComments: Accepted in VLDB 2022\n",
    "authors": [
      "Shreshth Tuli",
      "Giuliano Casale",
      "Nicholas R. Jennings"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.07284"
  },
  {
    "id": "arXiv:2201.07537",
    "title": "Graph Neural Network-based Android Malware Classification with Jumping  Knowledge",
    "abstract": "Comments: 9 pages, 5 figures",
    "descriptor": "\nComments: 9 pages, 5 figures\n",
    "authors": [
      "Wai Weng Lo",
      "Siamak Layeghy",
      "Mohanad Sarhan",
      "Marcus Gallagher",
      "Marius Portmann"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.07537"
  },
  {
    "id": "arXiv:2201.09061",
    "title": "Explore the Expression: Facial Expression Generation using Auxiliary  Classifier Generative Adversarial Network",
    "abstract": "Explore the Expression: Facial Expression Generation using Auxiliary  Classifier Generative Adversarial Network",
    "descriptor": "",
    "authors": [
      "J. Rafid Siddiqui"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.09061"
  },
  {
    "id": "arXiv:2201.10361",
    "title": "Reinforcement Learning-Based Deadline and Battery-Aware Offloading in  Smart Farm IoT-UAV Networks",
    "abstract": "Comments: Accepted Paper. Please check footnote in Page 1 for copyright",
    "descriptor": "\nComments: Accepted Paper. Please check footnote in Page 1 for copyright\n",
    "authors": [
      "Anne Catherine Nguyen",
      "Turgay Pamuklu",
      "Aisha Syed",
      "W. Sean Kennedy",
      "Melike Erol-Kantarci"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2201.10361"
  },
  {
    "id": "arXiv:2201.11429",
    "title": "GMRES using pseudo-inverse for range symmetric singular systems",
    "abstract": "Comments: Numerical experiment results comparing with MNRES and RRMINRES added. Numerical experiment results on nonsymmetric but range-symmetric system added. Reference added. Other minor modifications",
    "descriptor": "\nComments: Numerical experiment results comparing with MNRES and RRMINRES added. Numerical experiment results on nonsymmetric but range-symmetric system added. Reference added. Other minor modifications\n",
    "authors": [
      "Kota Sugihara",
      "Ken Hayami",
      "Liao Zeyu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2201.11429"
  },
  {
    "id": "arXiv:2201.11656",
    "title": "Symmetries in Linear Programming for Information Inequalities",
    "abstract": "Comments: 8 pages, 3 figures",
    "descriptor": "\nComments: 8 pages, 3 figures\n",
    "authors": [
      "Emirhan G\u00fcrp\u0131nar"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2201.11656"
  },
  {
    "id": "arXiv:2201.12329",
    "title": "DAB-DETR: Dynamic Anchor Boxes are Better Queries for DETR",
    "abstract": "Comments: Accepted to ICLR 2022",
    "descriptor": "\nComments: Accepted to ICLR 2022\n",
    "authors": [
      "Shilong Liu",
      "Feng Li",
      "Hao Zhang",
      "Xiao Yang",
      "Xianbiao Qi",
      "Hang Su",
      "Jun Zhu",
      "Lei Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.12329"
  },
  {
    "id": "arXiv:2201.12450",
    "title": "Finding fault-tolerant Clifford circuits using SMT solvers",
    "abstract": "Comments: 22 pages, 8 figures",
    "descriptor": "\nComments: 22 pages, 8 figures\n",
    "authors": [
      "Noah Shutty",
      "Christopher Chamberland"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2201.12450"
  },
  {
    "id": "arXiv:2201.12576",
    "title": "Scale-arbitrary Invertible Image Downscaling",
    "abstract": "Scale-arbitrary Invertible Image Downscaling",
    "descriptor": "",
    "authors": [
      "Jinbo Xing",
      "Wenbo Hu",
      "Tien-Tsin Wong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2201.12576"
  },
  {
    "id": "arXiv:2201.12650",
    "title": "New results on the robust coloring problem",
    "abstract": "New results on the robust coloring problem",
    "descriptor": "",
    "authors": [
      "Delia Garijo",
      "Alberto M\u00e1rquez",
      "Rafael Robles"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2201.12650"
  },
  {
    "id": "arXiv:2201.12896",
    "title": "Augmenting Novelty Search with a Surrogate Model to Engineer  Meta-Diversity in Ensembles of Classifiers",
    "abstract": "Comments: 16 pages, 4 figures, 3 tables, EvoStar 2022",
    "descriptor": "\nComments: 16 pages, 4 figures, 3 tables, EvoStar 2022\n",
    "authors": [
      "Rui P. Cardoso",
      "Emma Hart",
      "David Burth Kurka",
      "Jeremy V. Pitt"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2201.12896"
  },
  {
    "id": "arXiv:2202.00195",
    "title": "Federated Active Learning (F-AL): an Efficient Annotation Strategy for  Federated Learning",
    "abstract": "Comments: 13 pages, 9 figures, submitted for conference publication",
    "descriptor": "\nComments: 13 pages, 9 figures, submitted for conference publication\n",
    "authors": [
      "Jin-Hyun Ahn",
      "Kyungsang Kim",
      "Jeongwan Koh",
      "Quanzheng Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.00195"
  },
  {
    "id": "arXiv:2202.00254",
    "title": "Active Learning Over Multiple Domains in Natural Language Tasks",
    "abstract": "Active Learning Over Multiple Domains in Natural Language Tasks",
    "descriptor": "",
    "authors": [
      "Shayne Longpre",
      "Julia Reisler",
      "Edward Greg Huang",
      "Yi Lu",
      "Andrew Frank",
      "Nikhil Ramesh",
      "Chris DuBois"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.00254"
  },
  {
    "id": "arXiv:2202.00424",
    "title": "Improving Parametric Neural Networks for High-Energy Physics (and  Beyond)",
    "abstract": "Comments: 18 pages, 13 figures, 5 tables; new content",
    "descriptor": "\nComments: 18 pages, 13 figures, 5 tables; new content\n",
    "authors": [
      "Luca Anzalone",
      "Tommaso Diotalevi",
      "Daniele Bonacorsi"
    ],
    "subjectives": [
      "High Energy Physics - Experiment (hep-ex)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.00424"
  },
  {
    "id": "arXiv:2202.00855",
    "title": "Extension: Adaptive Sampling with Implicit Radiance Field",
    "abstract": "Extension: Adaptive Sampling with Implicit Radiance Field",
    "descriptor": "",
    "authors": [
      "Yuchi Huo"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.00855"
  },
  {
    "id": "arXiv:2202.00886",
    "title": "Accurate calibration of multi-perspective cameras from a generalization  of the hand-eye constraint",
    "abstract": "Comments: accepted in the 2022 IEEE International Conference on Robotics and Automation (ICRA), Philadelphia (PA), USA",
    "descriptor": "\nComments: accepted in the 2022 IEEE International Conference on Robotics and Automation (ICRA), Philadelphia (PA), USA\n",
    "authors": [
      "Yifu Wang",
      "Wenqing Jiang",
      "Kun Huang",
      "Soren Schwertfeger",
      "Laurent Kneip"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.00886"
  },
  {
    "id": "arXiv:2202.00893",
    "title": "Mold into a Graph: Efficient Bayesian Optimization over Mixed-Spaces",
    "abstract": "Comments: 14 pages, 10 figures",
    "descriptor": "\nComments: 14 pages, 10 figures\n",
    "authors": [
      "Jaeyeon Ahn",
      "Taehyeon Kim",
      "Seyoung Yun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.00893"
  },
  {
    "id": "arXiv:2202.00914",
    "title": "Lipschitz-constrained Unsupervised Skill Discovery",
    "abstract": "Comments: Accepted to ICLR 2022",
    "descriptor": "\nComments: Accepted to ICLR 2022\n",
    "authors": [
      "Seohong Park",
      "Jongwook Choi",
      "Jaekyeom Kim",
      "Honglak Lee",
      "Gunhee Kim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.00914"
  },
  {
    "id": "arXiv:2202.01339",
    "title": "Understanding Cross-Domain Few-Shot Learning: An Experimental Study",
    "abstract": "Comments: 25 pages, 13 figures, and 15 tables",
    "descriptor": "\nComments: 25 pages, 13 figures, and 15 tables\n",
    "authors": [
      "Jaehoon Oh",
      "Sungnyun Kim",
      "Namgyu Ho",
      "Jin-Hwa Kim",
      "Hwanjun Song",
      "Se-Young Yun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.01339"
  },
  {
    "id": "arXiv:2202.01487",
    "title": "A benchmark of state-of-the-art sound event detection systems evaluated  on synthetic soundscapes",
    "abstract": "A benchmark of state-of-the-art sound event detection systems evaluated  on synthetic soundscapes",
    "descriptor": "",
    "authors": [
      "Francesca Ronchini",
      "Romain Serizel"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2202.01487"
  },
  {
    "id": "arXiv:2202.01602",
    "title": "The Disagreement Problem in Explainable Machine Learning: A  Practitioner's Perspective",
    "abstract": "The Disagreement Problem in Explainable Machine Learning: A  Practitioner's Perspective",
    "descriptor": "",
    "authors": [
      "Satyapriya Krishna",
      "Tessa Han",
      "Alex Gu",
      "Javin Pombra",
      "Shahin Jabbari",
      "Steven Wu",
      "Himabindu Lakkaraju"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.01602"
  },
  {
    "id": "arXiv:2202.01629",
    "title": "Use and abuse of instance parameters in the Lean mathematical library",
    "abstract": "Comments: Submitted to the conference Interactive Theorem Proving 2022 (Haifa, Israel). Unabridged, interactive versions of the listings are available at this https URL",
    "descriptor": "\nComments: Submitted to the conference Interactive Theorem Proving 2022 (Haifa, Israel). Unabridged, interactive versions of the listings are available at this https URL\n",
    "authors": [
      "Anne Baanen"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2202.01629"
  },
  {
    "id": "arXiv:2202.01699",
    "title": "DistrEdge: Speeding up Convolutional Neural Network Inference on  Distributed Edge Devices",
    "abstract": "DistrEdge: Speeding up Convolutional Neural Network Inference on  Distributed Edge Devices",
    "descriptor": "",
    "authors": [
      "Xueyu Hou",
      "Yongjie Guan",
      "Tao Han",
      "Ning Zhang"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2202.01699"
  },
  {
    "id": "arXiv:2202.01919",
    "title": "Theoretical Exploration of Solutions of Feedforward ReLU networks",
    "abstract": "Comments: v2: hyperlink overrun modified",
    "descriptor": "\nComments: v2: hyperlink overrun modified\n",
    "authors": [
      "Changcun Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.01919"
  },
  {
    "id": "arXiv:2202.01924",
    "title": "Zero-Shot Aspect-Based Sentiment Analysis",
    "abstract": "Zero-Shot Aspect-Based Sentiment Analysis",
    "descriptor": "",
    "authors": [
      "Lei Shu",
      "Jiahua Chen",
      "Bing Liu",
      "Hu Xu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.01924"
  },
  {
    "id": "arXiv:2202.02113",
    "title": "From Discrimination to Generation: Knowledge Graph Completion with  Generative Transformer",
    "abstract": "Comments: Work in progress",
    "descriptor": "\nComments: Work in progress\n",
    "authors": [
      "Xin Xie",
      "Ningyu Zhang",
      "Zhoubo Li",
      "Shumin Deng",
      "Hui Chen",
      "Feiyu Xiong",
      "Mosha Chen",
      "Huajun Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.02113"
  },
  {
    "id": "arXiv:2202.02142",
    "title": "Deep invariant networks with differentiable augmentation layers",
    "abstract": "Deep invariant networks with differentiable augmentation layers",
    "descriptor": "",
    "authors": [
      "C\u00e9dric Rommel",
      "Thomas Moreau",
      "Alexandre Gramfort"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.02142"
  },
  {
    "id": "arXiv:2202.02149",
    "title": "Edge-Selective Feature Weaving for Point Cloud Matching",
    "abstract": "Edge-Selective Feature Weaving for Point Cloud Matching",
    "descriptor": "",
    "authors": [
      "Rintaro Yanagi",
      "Atsushi Hashimoto",
      "Shusaku Sone",
      "Naoya Chiba",
      "Jiaxin Ma",
      "Yoshitaka Ushiku"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.02149"
  },
  {
    "id": "arXiv:2202.02215",
    "title": "A Survey on Safety-Critical Scenario Generation for Autonomous Driving  -- A Methodological Perspective",
    "abstract": "Comments: 16 pages, 4 figures",
    "descriptor": "\nComments: 16 pages, 4 figures\n",
    "authors": [
      "Wenhao Ding",
      "Chejian Xu",
      "Haohong Lin",
      "Bo Li",
      "Ding Zhao"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.02215"
  },
  {
    "id": "arXiv:2202.02405",
    "title": "BAM: Bayes with Adaptive Memory",
    "abstract": "Comments: International Conference on Learning Representations (ICLR), 2022",
    "descriptor": "\nComments: International Conference on Learning Representations (ICLR), 2022\n",
    "authors": [
      "Josue Nassar",
      "Jennifer Brennan",
      "Ben Evans",
      "Kendall Lowrey"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.02405"
  },
  {
    "id": "arXiv:2202.02502",
    "title": "A Coalition Formation Game Approach for Personalized Federated Learning",
    "abstract": "Comments: 6 pages exclude the reference, 6 figures",
    "descriptor": "\nComments: 6 pages exclude the reference, 6 figures\n",
    "authors": [
      "Leijie Wu",
      "Song Guo",
      "Yaohong Ding",
      "Yufeng Zhan",
      "Jie Zhang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.02502"
  },
  {
    "id": "arXiv:2202.02510",
    "title": "A Survey on Poisoning Attacks Against Supervised Machine Learning",
    "abstract": "A Survey on Poisoning Attacks Against Supervised Machine Learning",
    "descriptor": "",
    "authors": [
      "Wenjun Qiu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.02510"
  },
  {
    "id": "arXiv:2202.02522",
    "title": "LEAPMood: Light and Efficient Architecture to Predict Mood with Genetic  Algorithm driven Hyperparameter Tuning",
    "abstract": "Comments: Accepted at 16th IEEE International Conference on Semantic Computing (ICSC), January 26-28, 2022 [update: This paper won the \"Best Paper Award\" at ICSC 2022]",
    "descriptor": "\nComments: Accepted at 16th IEEE International Conference on Semantic Computing (ICSC), January 26-28, 2022 [update: This paper won the \"Best Paper Award\" at ICSC 2022]\n",
    "authors": [
      "Harichandana B S S",
      "Sumit Kumar"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.02522"
  },
  {
    "id": "arXiv:2202.02524",
    "title": "PrivPAS: A real time Privacy-Preserving AI System and applied ethics",
    "abstract": "Comments: Accepted at 16th IEEE International Conference on Semantic Computing (ICSC), January 26-28, 2022 [update: Best Paper candidate at ICSC 2022]",
    "descriptor": "\nComments: Accepted at 16th IEEE International Conference on Semantic Computing (ICSC), January 26-28, 2022 [update: Best Paper candidate at ICSC 2022]\n",
    "authors": [
      "Harichandana B S S",
      "Vibhav Agarwal",
      "Sourav Ghosh",
      "Gopi Ramena",
      "Sumit Kumar",
      "Barath Raj Kandur Raja"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.02524"
  },
  {
    "id": "arXiv:2202.02575",
    "title": "Differentially Private Graph Classification with GNNs",
    "abstract": "Differentially Private Graph Classification with GNNs",
    "descriptor": "",
    "authors": [
      "Tamara T. Mueller",
      "Johannes C. Paetzold",
      "Chinmay Prabhakar",
      "Dmitrii Usynin",
      "Daniel Rueckert",
      "Georgios Kaissis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.02575"
  },
  {
    "id": "arXiv:2202.02794",
    "title": "Active Learning on a Budget: Opposite Strategies Suit High and Low  Budgets",
    "abstract": "Active Learning on a Budget: Opposite Strategies Suit High and Low  Budgets",
    "descriptor": "",
    "authors": [
      "Guy Hacohen",
      "Avihu Dekel",
      "Daphna Weinshall"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.02794"
  },
  {
    "id": "arXiv:2202.02796",
    "title": "GLPanoDepth: Global-to-Local Panoramic Depth Estimation",
    "abstract": "GLPanoDepth: Global-to-Local Panoramic Depth Estimation",
    "descriptor": "",
    "authors": [
      "Jiayang Bai",
      "Shuichang Lai",
      "Haoyu Qin",
      "Jie Guo",
      "Yanwen Guo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.02796"
  },
  {
    "id": "arXiv:2202.02906",
    "title": "Universality of parametric Coupling Flows over parametric  diffeomorphisms",
    "abstract": "Comments: 22 pages, 6 figures",
    "descriptor": "\nComments: 22 pages, 6 figures\n",
    "authors": [
      "Junlong Lyu",
      "Zhitang Chen",
      "Chang Feng",
      "Wenjing Cun",
      "Shengyu Zhu",
      "Yanhui Geng",
      "Zhijie Xu",
      "Yongwei Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Differential Geometry (math.DG)",
      "Functional Analysis (math.FA)"
    ],
    "url": "https://arxiv.org/abs/2202.02906"
  },
  {
    "id": "arXiv:2202.02918",
    "title": "Soft Actor-Critic with Inhibitory Networks for Faster Retraining",
    "abstract": "Comments: 16 pages including Appendix",
    "descriptor": "\nComments: 16 pages including Appendix\n",
    "authors": [
      "Jaime S. Ide",
      "Daria Mi\u0107ovi\u0107",
      "Michael J. Guarino",
      "Kevin Alcedo",
      "David Rosenbluth",
      "Adrian P. Pope"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2202.02918"
  },
  {
    "id": "arXiv:2202.02948",
    "title": "Improved Bounds for Fractional Online Matching Problems",
    "abstract": "Improved Bounds for Fractional Online Matching Problems",
    "descriptor": "",
    "authors": [
      "Zhihao Gavin Tang",
      "Yuhao Zhang"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2202.02948"
  },
  {
    "id": "arXiv:2202.02984",
    "title": "Deep Residual Shrinkage Networks for EMG-based Gesture Identification",
    "abstract": "Deep Residual Shrinkage Networks for EMG-based Gesture Identification",
    "descriptor": "",
    "authors": [
      "Yueying Ma",
      "Chengbo Wang",
      "Chengenze Jiang",
      "Zimo Li"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.02984"
  },
  {
    "id": "arXiv:2202.02987",
    "title": "One to Rule them All? A First Look at DNS over QUIC",
    "abstract": "Comments: To be published at PAM 2022",
    "descriptor": "\nComments: To be published at PAM 2022\n",
    "authors": [
      "Mike Kosek",
      "Trinh Viet Doan",
      "Malte Granderath",
      "Vaibhav Bajpai"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2202.02987"
  },
  {
    "id": "arXiv:2202.03074",
    "title": "Imposing Temporal Consistency on Deep Monocular Body Shape and Pose  Estimation",
    "abstract": "Imposing Temporal Consistency on Deep Monocular Body Shape and Pose  Estimation",
    "descriptor": "",
    "authors": [
      "Alexandra Zimmer",
      "Anna Hilsmann",
      "Wieland Morgenstern",
      "Peter Eisert"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.03074"
  },
  {
    "id": "arXiv:2202.03087",
    "title": "Unsupervised Long-Term Person Re-Identification with Clothes Change",
    "abstract": "Unsupervised Long-Term Person Re-Identification with Clothes Change",
    "descriptor": "",
    "authors": [
      "Mingkun Li",
      "Peng Xu",
      "Xiatian Zhu",
      "Jun Guo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.03087"
  },
  {
    "id": "arXiv:2202.03119",
    "title": "Moving Other Way: Exploring Word Mover Distance Extensions",
    "abstract": "Moving Other Way: Exploring Word Mover Distance Extensions",
    "descriptor": "",
    "authors": [
      "Ilya Smirnov",
      "Ivan P. Yamshchikov"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.03119"
  },
  {
    "id": "arXiv:2202.03233",
    "title": "A Variational Edge Partition Model for Supervised Graph Representation  Learning",
    "abstract": "Comments: 15 pages, 3 figures, 13 pages of appendix",
    "descriptor": "\nComments: 15 pages, 3 figures, 13 pages of appendix\n",
    "authors": [
      "Yilin He",
      "Chaojie Wang",
      "Hao Zhang",
      "Bo Chen",
      "Mingyuan Zhou"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2202.03233"
  },
  {
    "id": "arXiv:2202.03279",
    "title": "On the sensitivity of implementations of a least-squares collocation  method for linear higher-index differential-algebraic equations",
    "abstract": "On the sensitivity of implementations of a least-squares collocation  method for linear higher-index differential-algebraic equations",
    "descriptor": "",
    "authors": [
      "Michael Hanke"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.03279"
  },
  {
    "id": "arXiv:2202.03349",
    "title": "Conditional Gradients for the Approximately Vanishing Ideal",
    "abstract": "Comments: 22 pages",
    "descriptor": "\nComments: 22 pages\n",
    "authors": [
      "E. Wirth",
      "S. Pokutta"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.03349"
  },
  {
    "id": "arXiv:2202.03385",
    "title": "Using Multiwinner Voting to Search for Movies",
    "abstract": "Comments: 20 pages, 10 figures, 2 tables",
    "descriptor": "\nComments: 20 pages, 10 figures, 2 tables\n",
    "authors": [
      "Grzegorz Gawron",
      "Piotr Faliszewski"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2202.03385"
  },
  {
    "id": "arXiv:2202.03390",
    "title": "GMC -- Geometric Multimodal Contrastive Representation Learning",
    "abstract": "GMC -- Geometric Multimodal Contrastive Representation Learning",
    "descriptor": "",
    "authors": [
      "Petra Poklukar",
      "Miguel Vasco",
      "Hang Yin",
      "Francisco S. Melo",
      "Ana Paiva",
      "Danica Kragic"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.03390"
  }
]
[
  {
    "id": "arXiv:2202.00003",
    "title": "Green NFTs: A Study on the Environmental Impact of Cryptoart  Technologies",
    "abstract": "We introduce a model of greenhouse gas emissions due to on-chain activity on\nEthereum, focusing on cryptoart. We also estimate the impact of individual\ntransactions on the environment, both before and after the London hard fork. We\nfind that with the current fee mechanism, spending one dollar on transaction\nfees corresponds to emitting at least the equivalent of 1.151 kilograms of CO2.\nWe also describe several techniques to reduce cryptoart emissions, both in the\nshort and long term.",
    "descriptor": "\nComments: This draft was written in May 2021 and might be subject to modifications\n",
    "authors": [
      "Samuele Marro",
      "Luca Donno"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.00003"
  },
  {
    "id": "arXiv:2202.00004",
    "title": "On Polynomial Approximation of Activation Function",
    "abstract": "In this work, we propose an interesting method that aims to approximate an\nactivation function over some domain by polynomials of the presupposing low\ndegree. The main idea behind this method can be seen as an extension of the\nordinary least square method and includes the gradient of activation function\ninto the cost function to minimize.",
    "descriptor": "\nComments: In this work, we proposed an interesting method to approximate the activation function by a polynomial the degree of which is preset low. Our method to approximate the activation function is much more flexible compared to the least square method in the sense that the additional parameters could better control the shape of the resulting polynomial to approximate\n",
    "authors": [
      "John Chiang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.00004"
  },
  {
    "id": "arXiv:2202.00005",
    "title": "5G enabled Mobile Edge Computing security for Autonomous Vehicles",
    "abstract": "The world is moving into a new era with the deployment of 5G communication\ninfrastructure. Many new developments are deployed centred around this\ntechnology. One such advancement is 5G Vehicle to Everything communication.\nThis technology can be used for applications such as driverless delivery of\ngoods, immediate response to emergencies and improving traffic efficiency. The\nconcept of Intelligent Transport Systems (ITS) is built around this system\nwhich is completely autonomous. This paper studies the Distributed Denial of\nService (DDoS) attack carried out over a 5G network and analyses security\nattacks, particularly the DDoS attack. The aim is to implement a machine\nlearning model capable of classifying different types of DDoS attacks and\npredicting the quality of 5G latency. The initial steps of implementation\ninvolved the synthetic addition of 5G parameters into the dataset.\nSubsequently, the data was label encoded, and minority classes were oversampled\nto match the other classes. Finally, the data was split as training and\ntesting, and machine learning models were applied. Although the paper resulted\nin a model that predicted DDoS attacks, the dataset acquired significantly\nlacked 5G related information. Furthermore, the 5G classification model needed\nmore modification. The research was based on largely quantitative research\nmethods in a simulated environment. Hence, the biggest limitation of this\nresearch has been the lack of resources for data collection and sole reliance\non online data sets. Ideally, a Vehicle to Everything (V2X) project would\ngreatly benefit from an autonomous 5G enabled vehicle connected to a mobile\nedge cloud. However, this project was conducted solely online on a single PC\nwhich further limits the outcomes. Although the model underperformed, this\npaper can be used as a framework for future research in Intelligent Transport\nSystem development.",
    "descriptor": "\nComments: 9 pages, 8 figures\n",
    "authors": [
      "Daryll Ralph D'Costa",
      "Dr. Robert Abbas"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.00005"
  },
  {
    "id": "arXiv:2202.00008",
    "title": "MEGA: Model Stealing via Collaborative Generator-Substitute Networks",
    "abstract": "Deep machine learning models are increasingly deployedin the wild for\nproviding services to users. Adversaries maysteal the knowledge of these\nvaluable models by trainingsubstitute models according to the inference results\nof thetargeted deployed models. Recent data-free model stealingmethods are\nshown effective to extract the knowledge of thetarget model without using real\nquery examples, but they as-sume rich inference information, e.g., class\nprobabilities andlogits. However, they are all based on competing\ngenerator-substitute networks and hence encounter training instability.In this\npaper we propose a data-free model stealing frame-work,MEGA, which is based on\ncollaborative generator-substitute networks and only requires the target model\ntoprovide label prediction for synthetic query examples. Thecore of our method\nis a model stealing optimization con-sisting of two collaborative models (i)\nthe substitute modelwhich imitates the target model through the synthetic\nqueryexamples and their inferred labels and (ii) the generatorwhich synthesizes\nimages such that the confidence of thesubstitute model over each query example\nis maximized. Wepropose a novel coordinate descent training procedure\nandanalyze its convergence. We also empirically evaluate thetrained substitute\nmodel on three datasets and its applicationon black-box adversarial attacks.\nOur results show that theaccuracy of our trained substitute model and the\nadversarialattack success rate over it can be up to 33% and 40% higherthan\nstate-of-the-art data-free black-box attacks.",
    "descriptor": "",
    "authors": [
      "Chi Hong",
      "Jiyue Huang",
      "Lydia Y. Chen"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.00008"
  },
  {
    "id": "arXiv:2202.00009",
    "title": "Identifying Interpretable Clinical Subtypes withinHeterogeneous Dementia  Clinic Population",
    "abstract": "Dementia is a highly heterogeneous neurodegenerative disorder. Differences in\nbrain pathologies lead to significant variations in the clinical presentation\nand progression course of patients, increasing the need for individual\nprogression predictions. Unsupervised cluster analysis on a dementia clinic\npopulation using the Clinical Dementia Rating (CDR) component scores uncovered\nsubtypes with different risk of dementia progression. The distribution of the\nCDR components provide validation and interpretability regarding the cognitive\ncharacteristics of the identified subtypes.",
    "descriptor": "\nComments: IEEE International Conference on Healthcare Informatics Poster\n",
    "authors": [
      "Sayantan Kumar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.00009"
  },
  {
    "id": "arXiv:2202.00035",
    "title": "Learning Fair Representations via Rate-Distortion Maximization",
    "abstract": "Text representations learned by machine learning models often encode\nundesirable demographic information of the user. Predictive models based on\nthese representations can rely on such information resulting in biased\ndecisions. We present a novel debiasing technique Fairness-aware Rate\nMaximization (FaRM), that removes demographic information by making\nrepresentations of instances belonging to the same protected attribute class\nuncorrelated using the rate-distortion function. FaRM is able to debias\nrepresentations with or without a target task at hand. FaRM can also be adapted\nto simultaneously remove information about multiple protected attributes.\nEmpirical evaluations show that FaRM achieves state-of-the-art performance on\nseveral datasets, and learned representations leak significantly less protected\nattribute information against an attack by a non-linear probing network.",
    "descriptor": "\nComments: Work in progress\n",
    "authors": [
      "Somnath Basu Roy Chowdhury",
      "Snigdha Chaturvedi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.00035"
  },
  {
    "id": "arXiv:2202.00045",
    "title": "AVTPnet: Convolutional Autoencoder for AVTP anomaly detection in  Automotive Ethernet Networks",
    "abstract": "Network Intrusion Detection Systems are well considered as efficient tools\nfor securing in-vehicle networks against diverse cyberattacks. However, since\ncyberattack are always evolving, signature-based intrusion detection systems\nare no longer adopted. An alternative solution can be the deployment of deep\nlearning based intrusion detection system (IDS) which play an important role in\ndetecting unknown attack patterns in network traffic. To our knowledge, no\nprevious research work has been done to detect anomalies on automotive ethernet\nbased in-vehicle networks using anomaly based approaches. Hence, in this paper,\nwe propose a convolutional autoencoder (CAE) for offline detection of anomalies\non the Audio Video Transport Protocol (AVTP), an application layer protocol\nimplemented in the recent in-vehicle network Automotive Ethernet. The CAE\nconsists of an encoder and a decoder with CNN structures that are asymmetrical.\nAnomalies in AVTP packet stream, which may lead to critical interruption of\nmedia streams, are therefore detected by measuring the reconstruction error of\neach sliding window of AVTP packets. Our proposed approach is evaluated on the\nrecently published \"Automotive Ethernet Intrusion Dataset\", and is also\ncompared with other state-of-the art traditional anomaly detection and\nsignature based models in machine learning. The numerical results show that our\nproposed model outperfoms the other methods and excel at predicting unknown\nin-vehicle intrusions, with 0.94 accuracy. Moreover, our model has a low level\nof false alarm and miss detection rates for different AVTP attack types.",
    "descriptor": "",
    "authors": [
      "Natasha Alkhatib",
      "Maria Mushtaq",
      "Hadi Ghauch",
      "Jean-Luc Danger"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2202.00045"
  },
  {
    "id": "arXiv:2202.00046",
    "title": "Finding Directions in GAN's Latent Space for Neural Face Reenactment",
    "abstract": "This paper is on face/head reenactment where the goal is to transfer the\nfacial pose (3D head orientation and expression) of a target face to a source\nface. Previous methods focus on learning embedding networks for identity and\npose disentanglement which proves to be a rather hard task, degrading the\nquality of the generated images. We take a different approach, bypassing the\ntraining of such networks, by using (fine-tuned) pre-trained GANs which have\nbeen shown capable of producing high-quality facial images. Because GANs are\ncharacterized by weak controllability, the core of our approach is a method to\ndiscover which directions in latent GAN space are responsible for controlling\nfacial pose and expression variations. We present a simple pipeline to learn\nsuch directions with the aid of a 3D shape model which, by construction,\nalready captures disentangled directions for facial pose, identity and\nexpression. Moreover, we show that by embedding real images in the GAN latent\nspace, our method can be successfully used for the reenactment of real-world\nfaces. Our method features several favorable properties including using a\nsingle source image (one-shot) and enabling cross-person reenactment. Our\nqualitative and quantitative results show that our approach often produces\nreenacted faces of significantly higher quality than those produced by\nstate-of-the-art methods for the standard benchmarks of VoxCeleb1 & 2.",
    "descriptor": "\nComments: 8 pages, 5 figures. Project page: this https URL\n",
    "authors": [
      "Stella Bounareli",
      "Vasileios Argyriou",
      "Georgios Tzimiropoulos"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.00046"
  },
  {
    "id": "arXiv:2202.00047",
    "title": "The Stories We Tell About Data: Media Types for Data-Driven Storytelling",
    "abstract": "The emerging practice of data-driven storytelling is framing data using\nfamiliar narrative mechanisms such as slideshows, videos, and comics to make\neven highly complex phenomena understandable. However, current data stories are\nstill not utilizing the full potential of the storytelling domain. One reason\nfor this is that current data-driven storytelling practice does not leverage\nthe full repertoire of media that can be used for storytelling, such as the\nspoken word, e-learning, and video games. In this paper, we propose a taxonomy\nfocused specifically on media types for the purpose of widening the purview of\ndata-driven storytelling simply by putting more tools into the hands of\ndesigners. Using our taxonomy as a generative tool, we also propose three novel\nstorytelling mechanisms, including for live-streaming, gesture-driven oral\npresentations, and textual reports that dynamically incorporate visual\nrepresentations.",
    "descriptor": "",
    "authors": [
      "Zhenpeng Zhao",
      "Niklas Elmqvist"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2202.00047"
  },
  {
    "id": "arXiv:2202.00050",
    "title": "Deep-Disaster: Unsupervised Disaster Detection and Localization Using  Visual Data",
    "abstract": "Social media plays a significant role in sharing essential information, which\nhelps humanitarian organizations in rescue operations during and after disaster\nincidents. However, developing an efficient method that can provide rapid\nanalysis of social media images in the early hours of disasters is still\nlargely an open problem, mainly due to the lack of suitable datasets and the\nsheer complexity of this task. In addition, supervised methods can not\ngeneralize well to novel disaster incidents. In this paper, inspired by the\nsuccess of Knowledge Distillation (KD) methods, we propose an unsupervised deep\nneural network to detect and localize damages in social media images. Our\nproposed KD architecture is a feature-based distillation approach that\ncomprises a pre-trained teacher and a smaller student network, with both\nnetworks having similar GAN architecture containing a generator and a\ndiscriminator. The student network is trained to emulate the behavior of the\nteacher on training input samples, which, in turn, contain images that do not\ninclude any damaged regions. Therefore, the student network only learns the\ndistribution of no damage data and would have different behavior from the\nteacher network-facing damages. To detect damage, we utilize the difference\nbetween features generated by two networks using a defined score function that\ndemonstrates the probability of damages occurring. Our experimental results on\nthe benchmark dataset confirm that our approach outperforms state-of-the-art\nmethods in detecting and localizing the damaged areas, especially for novel\ndisaster types.",
    "descriptor": "",
    "authors": [
      "Soroor Shekarizadeh",
      "Razieh Rastgoo",
      "Saif Al-Kuwari",
      "Mohammad Sabokrou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.00050"
  },
  {
    "id": "arXiv:2202.00056",
    "title": "Accurate Link Lifetime Computation in Autonomous Airborne UAV Networks",
    "abstract": "An autonomous airborne network (AN) consists of multiple unmanned aerial\nvehicles (UAVs), which can self-configure to provide seamless, low-cost and\nsecure connectivity. AN is preferred for applications in civilian and military\nsectors because it can improve the network reliability and fault tolerance,\nreduce mission completion time through collaboration, and adapt to dynamic\nmission requirements. However, facilitating seamless communication in such ANs\nis a challenging task due to their fast node mobility, which results in\nfrequent link disruptions. Many existing AN-specific mobility-aware schemes\nrestrictively assume that UAVs fly in straight lines, to reduce the high\nuncertainty in the mobility pattern and simplify the calculation of link\nlifetime (LLT). Here, LLT represents the duration after which the link between\na node pair terminates. However, the application of such schemes is severely\nlimited, which makes them unsuitable for practical autonomous ANs.\nIn this report, a mathematical framework is described to accurately compute\nthe \\textit{LLT} value for a UAV node pair, where each node flies independently\nin a randomly selected smooth trajectory. In addition, the impact of random\ntrajectory changes on LLT accuracy is also discussed.",
    "descriptor": "\nComments: Mathematical framework to accurately compute link lifetime in an airborne network\n",
    "authors": [
      "Shivam Garg",
      "Alexander Ihler",
      "Sunil Kumar"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.00056"
  },
  {
    "id": "arXiv:2202.00057",
    "title": "A Lightweight Workload-Aware Microservices Autoscaling with QoS  Assurance",
    "abstract": "Cloud applications are increasingly moving away from monolithic services to\nagile microservices-based deployments. However, efficient resource management\nfor microservices poses a significant hurdle due to the sheer number of loosely\ncoupled and interacting components. The interdependencies between various\nmicroservices make existing cloud resource autoscaling techniques ineffective.\nMeanwhile, machine learning (ML) based approaches that try to capture the\ncomplex relationships in microservices require extensive training data and\ncause intentional SLO violations. Moreover, these ML-heavy approaches are slow\nin adapting to dynamically changing microservice operating environments. In\nthis paper, we propose PEMA (Practical Efficient Microservice Autoscaling), a\nlightweight microservice resource manager that finds efficient resource\nallocation through opportunistic resource reduction. PEMA's lightweight design\nenables novel workload-aware and adaptive resource management. Using three\nprototype microservice implementations, we show that PEMA can find close to\noptimum resource allocation and save up to 33% resource compared to the\ncommercial rule-based resource allocations.",
    "descriptor": "\nComments: 11 pages, 19 figures\n",
    "authors": [
      "Md Rajib Hossen",
      "Mohammad A. Islam"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.00057"
  },
  {
    "id": "arXiv:2202.00060",
    "title": "SnAKe: Bayesian Optimization with Pathwise Exploration",
    "abstract": "Bayesian Optimization is a very effective tool for optimizing expensive\nblack-box functions. Inspired by applications developing and characterizing\nreaction chemistry using droplet microfluidic reactors, we consider a novel\nsetting where the expense of evaluating the function can increase significantly\nwhen making large input changes between iterations. We further assume we are\nworking asynchronously, meaning we have to decide on new queries before we\nfinish evaluating previous experiments. This paper investigates the problem and\nintroduces 'Sequential Bayesian Optimization via Adaptive Connecting Samples'\n(SnAKe), which provides a solution by considering future queries and\npreemptively building optimization paths that minimize input costs. We\ninvestigate some convergence properties and empirically show that the algorithm\nis able to achieve regret similar to classical Bayesian Optimization algorithms\nin both the synchronous and asynchronous settings, while reducing the input\ncosts significantly.",
    "descriptor": "\nComments: 8 main pages, 32 with appendix, 29 figures, 8 tables\n",
    "authors": [
      "Jose Pablo Folch",
      "Shiqiang Zhang",
      "Robert M Lee",
      "Behrang Shafei",
      "David Walz",
      "Calvin Tsay",
      "Mark van der Wilk",
      "Ruth Misener"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2202.00060"
  },
  {
    "id": "arXiv:2202.00062",
    "title": "Monte Carlo stochastic Galerkin methods for non-Maxwellian kinetic  models of multiagent systems with uncertainties",
    "abstract": "In this paper, we focus on the construction of a hybrid scheme for the\napproximation of non-Maxwellian kinetic models with uncertainties. In the\ncontext of multiagent systems, the introduction of a kernel at the kinetic\nlevel is useful to avoid unphysical interactions. The methods here proposed,\ncombine a direct simulation Monte Carlo (DSMC) in the phase space together with\nstochastic Galerkin (sG) methods in the random space. The developed schemes\npreserve the main physical properties of the solution together with accuracy in\nthe random space. The consistency of the methods is tested with respect to\nsurrogate Fokker-Planck models that can be obtained in the quasi-invariant\nregime of parameters. Several applications of the schemes to non-Maxwellian\nmodels of multiagent systems are reported.",
    "descriptor": "\nComments: 27 pages, 8 figures\n",
    "authors": [
      "Andrea Medaglia",
      "Andrea Tosin",
      "Mattia Zanella"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Adaptation and Self-Organizing Systems (nlin.AO)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2202.00062"
  },
  {
    "id": "arXiv:2202.00063",
    "title": "Efficient Reinforcement Learning in Block MDPs: A Model-free  Representation Learning Approach",
    "abstract": "We present BRIEE (Block-structured Representation learning with Interleaved\nExplore Exploit), an algorithm for efficient reinforcement learning in Markov\nDecision Processes with block-structured dynamics (i.e., Block MDPs), where\nrich observations are generated from a set of unknown latent states. BRIEE\ninterleaves latent states discovery, exploration, and exploitation together,\nand can provably learn a near-optimal policy with sample complexity scaling\npolynomially in the number of latent states, actions, and the time horizon,\nwith no dependence on the size of the potentially infinite observation space.\nEmpirically, we show that BRIEE is more sample efficient than the state-of-art\nBlock MDP algorithm HOMER and other empirical RL baselines on challenging\nrich-observation combination lock problems that require deep exploration.",
    "descriptor": "",
    "authors": [
      "Xuezhou Zhang",
      "Yuda Song",
      "Masatoshi Uehara",
      "Mengdi Wang",
      "Wen Sun",
      "Alekh Agarwal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.00063"
  },
  {
    "id": "arXiv:2202.00065",
    "title": "Learning affective meanings that derives the social behavior using  Bidirectional Encoder Representations from Transformers",
    "abstract": "Predicting the outcome of a process requires modeling the system dynamic and\nobserving the states. In the context of social behaviors, sentiments\ncharacterize the states of the system. Affect Control Theory (ACT) uses\nsentiments to manifest potential interaction. ACT is a generative theory of\nculture and behavior based on a three-dimensional sentiment lexicon.\nTraditionally, the sentiments are quantified using survey data which is fed\ninto a regression model to explain social behavior. The lexicons used in the\nsurvey are limited due to prohibitive cost. This paper uses a fine-tuned\nBidirectional Encoder Representations from Transformers (BERT) model to develop\na replacement for these surveys. This model achieves state-of-the-art accuracy\nin estimating affective meanings, expanding the affective lexicon, and allowing\nmore behaviors to be explained.",
    "descriptor": "\nComments: Working paper\n",
    "authors": [
      "Moeen Mostafavi",
      "Michael D. Porter",
      "Dawn T. Robinson"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.00065"
  },
  {
    "id": "arXiv:2202.00069",
    "title": "\"How trustworthy is this research?\" Designing a Tool to Help Readers  Understand Evidence and Uncertainty in Science Journalism",
    "abstract": "This article reports on a Research through Design study exploring how to\ndesign a tool for helping readers of science journalism understand the strength\nand uncertainty of scientific evidence in news stories about health science,\nusing both textual and visual information. A central aim has been to teach\nreaders about criteria for assessing scientific evidence, in particular in\norder to help readers differentiate between science and pseudoscience. Working\nin a research-in-the-wild collaboration with a website for popular science, the\nstudy presents the design and evaluation of the Scientific Evidence Indicator,\nwhich uses metadata about scientific publications to present an assessment of\nevidence strength to the readers. Evaluations of the design demonstrate some\nsuccess in helping readers recognize whether studies have undergone scientific\npeer review or not, but point to challenges in facilitating a more in-depth\nunderstanding. Insights from the study point to a potential for developing\nsimilar tools aimed at journalists rather than directly at audiences.",
    "descriptor": "",
    "authors": [
      "Anders Sundnes L\u00f8vlie",
      "Astrid Waagstein",
      "Peter Hyldg\u00e5rd"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2202.00069"
  },
  {
    "id": "arXiv:2202.00070",
    "title": "Implicit Concept Drift Detection for Multi-label Data Streams",
    "abstract": "Many real-world applications adopt multi-label data streams as the need for\nalgorithms to deal with rapidly changing data increases. Changes in data\ndistribution, also known as concept drift, cause the existing classification\nmodels to rapidly lose their effectiveness. To assist the classifiers, we\npropose a novel algorithm called Label Dependency Drift Detector (LD3), an\nimplicit (unsupervised) concept drift detector using label dependencies within\nthe data for multi-label data streams. Our study exploits the dynamic temporal\ndependencies between labels using a label influence ranking method, which\nleverages a data fusion algorithm and uses the produced ranking to detect\nconcept drift. LD3 is the first unsupervised concept drift detection algorithm\nin the multi-label classification problem area. In this study, we perform an\nextensive evaluation of LD3 by comparing it with 14 prevalent supervised\nconcept drift detection algorithms that we adapt to the problem area using 12\ndatasets and a baseline classifier. The results show that LD3 provides between\n19.8\\% and 68.6\\% better predictive performance than comparable detectors on\nboth real-world and synthetic data streams.",
    "descriptor": "\nComments: 18 pages, 7 figures, submitted to Artificial Intelligence Review\n",
    "authors": [
      "Ege Berkay Gulcan",
      "Fazli Can"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2202.00070"
  },
  {
    "id": "arXiv:2202.00071",
    "title": "JULIA: Joint Multi-linear and Nonlinear Identification for Tensor  Completion",
    "abstract": "Tensor completion aims at imputing missing entries from a partially observed\ntensor. Existing tensor completion methods often assume either multi-linear or\nnonlinear relationships between latent components.\nHowever, real-world tensors have much more complex patterns where both\nmulti-linear and nonlinear relationships may coexist. In such cases, the\nexisting methods are insufficient to describe the data structure. This paper\nproposes a Joint mUlti-linear and nonLinear IdentificAtion (JULIA) framework\nfor large-scale tensor completion. JULIA unifies the multi-linear and nonlinear\ntensor completion models with several advantages over the existing methods: 1)\nFlexible model selection, i.e., it fits a tensor by assigning its values as a\ncombination of multi-linear and nonlinear components; 2) Compatible with\nexisting nonlinear tensor completion methods; 3) Efficient training based on a\nwell-designed alternating optimization approach. Experiments on six real\nlarge-scale tensors demonstrate that JULIA outperforms many existing tensor\ncompletion algorithms. Furthermore, JULIA can improve the performance of a\nclass of nonlinear tensor completion methods. The results show that in some\nlarge-scale tensor completion scenarios, baseline methods with JULIA are able\nto obtain up to 55% lower root mean-squared-error and save 67% computational\ncomplexity.",
    "descriptor": "",
    "authors": [
      "Cheng Qian",
      "Kejun Huang",
      "Lucas Glass",
      "Rakshith S. Srinivasa",
      "Jimeng Sun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.00071"
  },
  {
    "id": "arXiv:2202.00074",
    "title": "Prior normalization for certified likelihood-informed subspace detection  of Bayesian inverse problems",
    "abstract": "Markov Chain Monte Carlo (MCMC) methods form one of the algorithmic\nfoundations of high-dimensional Bayesian inverse problems. The recent\ndevelopment of likelihood-informed subspace (LIS) methods offer a viable route\nto designing efficient MCMC methods for exploring high-dimensional posterior\ndistributions via exploiting the intrinsic low-dimensional structure of the\nunderlying inverse problem. However, existing LIS methods and the associated\nperformance analysis often assume that the prior distribution is Gaussian. This\nassumption is limited for inverse problems aiming to promote sparsity in the\nparameter estimation, as heavy-tailed priors, e.g., Laplace distribution or the\nelastic net commonly used in Bayesian LASSO, are often needed in this case. To\novercome this limitation, we consider a prior normalization technique that\ntransforms any non-Gaussian (e.g. heavy-tailed) priors into standard Gaussian\ndistributions, which make it possible to implement LIS methods to accelerate\nMCMC sampling via such transformations. We also rigorously investigate the\nintegration of such transformations with several MCMC methods for\nhigh-dimensional problems. Finally, we demonstrate various aspects of our\ntheoretical claims on two nonlinear inverse problems.",
    "descriptor": "",
    "authors": [
      "Tiangang Cui",
      "Xin Tong",
      "Olivier Zahm"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.00074"
  },
  {
    "id": "arXiv:2202.00075",
    "title": "SUGAR: Efficient Subgraph-level Training via Resource-aware Graph  Partitioning",
    "abstract": "Graph Neural Networks (GNNs) have demonstrated a great potential in a variety\nof graph-based applications, such as recommender systems, drug discovery, and\nobject recognition. Nevertheless, resource-efficient GNN learning is a rarely\nexplored topic despite its many benefits for edge computing and Internet of\nThings (IoT) applications. To improve this state of affairs, this work proposes\nefficient subgraph-level training via resource-aware graph partitioning\n(SUGAR). SUGAR first partitions the initial graph into a set of disjoint\nsubgraphs and then performs local training at the subgraph-level. We provide a\ntheoretical analysis and conduct extensive experiments on five graph benchmarks\nto verify its efficacy in practice. Our results show that SUGAR can achieve up\nto 33 times runtime speedup and 3.8 times memory reduction on large-scale\ngraphs. We believe SUGAR opens a new research direction towards developing GNN\nmethods that are resource-efficient, hence suitable for IoT deployment.",
    "descriptor": "",
    "authors": [
      "Zihui Xue",
      "Yuedong Yang",
      "Mengtian Yang",
      "Radu Marculescu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.00075"
  },
  {
    "id": "arXiv:2202.00079",
    "title": "You May Not Need Ratio Clipping in PPO",
    "abstract": "Proximal Policy Optimization (PPO) methods learn a policy by iteratively\nperforming multiple mini-batch optimization epochs of a surrogate objective\nwith one set of sampled data. Ratio clipping PPO is a popular variant that\nclips the probability ratios between the target policy and the policy used to\ncollect samples. Ratio clipping yields a pessimistic estimate of the original\nsurrogate objective, and has been shown to be crucial for strong performance.\nWe show in this paper that such ratio clipping may not be a good option as it\ncan fail to effectively bound the ratios. Instead, one can directly optimize\nthe original surrogate objective for multiple epochs; the key is to find a\nproper condition to early stop the optimization epoch in each iteration. Our\ntheoretical analysis sheds light on how to determine when to stop the\noptimization epoch, and call the resulting algorithm Early Stopping Policy\nOptimization (ESPO). We compare ESPO with PPO across many continuous control\ntasks and show that ESPO significantly outperforms PPO. Furthermore, we show\nthat ESPO can be easily scaled up to distributed training with many workers,\ndelivering strong performance as well.",
    "descriptor": "",
    "authors": [
      "Mingfei Sun",
      "Vitaly Kurin",
      "Guoqing Liu",
      "Sam Devlin",
      "Tao Qin",
      "Katja Hofmann",
      "Shimon Whiteson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.00079"
  },
  {
    "id": "arXiv:2202.00082",
    "title": "Monotonic Improvement Guarantees under Non-stationarity for  Decentralized PPO",
    "abstract": "We present a new monotonic improvement guarantee for optimizing decentralized\npolicies in cooperative Multi-Agent Reinforcement Learning (MARL), which holds\neven when the transition dynamics are non-stationary. This new analysis\nprovides a theoretical understanding of the strong performance of two recent\nactor-critic methods for MARL, i.e., Independent Proximal Policy Optimization\n(IPPO) and Multi-Agent PPO (MAPPO), which both rely on independent ratios,\ni.e., computing probability ratios separately for each agent's policy. We show\nthat, despite the non-stationarity that independent ratios cause, a monotonic\nimprovement guarantee still arises as a result of enforcing the trust region\nconstraint over all decentralized policies. We also show this trust region\nconstraint can be effectively enforced in a principled way by bounding\nindependent ratios based on the number of agents in training, providing a\ntheoretical foundation for proximal ratio clipping. Moreover, we show that the\nsurrogate objectives optimized in IPPO and MAPPO are essentially equivalent\nwhen their critics converge to a fixed point. Finally, our empirical results\nsupport the hypothesis that the strong performance of IPPO and MAPPO is a\ndirect result of enforcing such a trust region constraint via clipping in\ncentralized training, and the good values of the hyperparameters for this\nenforcement are highly sensitive to the number of agents, as predicted by our\ntheoretical analysis.",
    "descriptor": "",
    "authors": [
      "Mingfei Sun",
      "Sam Devlin",
      "Katja Hofmann",
      "Shimon Whiteson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.00082"
  },
  {
    "id": "arXiv:2202.00088",
    "title": "Reinforcement Learning with Heterogeneous Data: Estimation and Inference",
    "abstract": "Reinforcement Learning (RL) has the promise of providing data-driven support\nfor decision-making in a wide range of problems in healthcare, education,\nbusiness, and other domains. Classical RL methods focus on the mean of the\ntotal return and, thus, may provide misleading results in the setting of the\nheterogeneous populations that commonly underlie large-scale datasets. We\nintroduce the K-Heterogeneous Markov Decision Process (K-Hetero MDP) to address\nsequential decision problems with population heterogeneity. We propose the\nAuto-Clustered Policy Evaluation (ACPE) for estimating the value of a given\npolicy, and the Auto-Clustered Policy Iteration (ACPI) for estimating the\noptimal policy in a given policy class. Our auto-clustered algorithms can\nautomatically detect and identify homogeneous sub-populations, while estimating\nthe Q function and the optimal policy for each sub-population. We establish\nconvergence rates and construct confidence intervals for the estimators\nobtained by the ACPE and ACPI. We present simulations to support our\ntheoretical findings, and we conduct an empirical study on the standard\nMIMIC-III dataset. The latter analysis shows evidence of value heterogeneity\nand confirms the advantages of our new method.",
    "descriptor": "",
    "authors": [
      "Elynn Y. Chen",
      "Rui Song",
      "Michael I. Jordan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2202.00088"
  },
  {
    "id": "arXiv:2202.00089",
    "title": "Understanding AdamW through Proximal Methods and Scale-Freeness",
    "abstract": "Adam has been widely adopted for training deep neural networks due to less\nhyperparameter tuning and remarkable performance. To improve generalization,\nAdam is typically used in tandem with a squared $\\ell_2$ regularizer (referred\nto as Adam-$\\ell_2$). However, even better performance can be obtained with\nAdamW, which decouples the gradient of the regularizer from the update rule of\nAdam-$\\ell_2$. Yet, we are still lacking a complete explanation of the\nadvantages of AdamW. In this paper, we tackle this question from both an\noptimization and an empirical point of view. First, we show how to re-interpret\nAdamW as an approximation of a proximal gradient method, which takes advantage\nof the closed-form proximal mapping of the regularizer instead of only\nutilizing its gradient information as in Adam-$\\ell_2$. Next, we consider the\nproperty of \"scale-freeness\" enjoyed by AdamW and by its proximal counterpart:\ntheir updates are invariant to component-wise rescaling of the gradients. We\nprovide empirical evidence across a wide range of deep learning experiments\nshowing a correlation between the problems in which AdamW exhibits an advantage\nover Adam-$\\ell_2$ and the degree to which we expect the gradients of the\nnetwork to exhibit multiple scales, thus motivating the hypothesis that the\nadvantage of AdamW could be due to the scale-free updates.",
    "descriptor": "",
    "authors": [
      "Zhenxun Zhuang",
      "Mingrui Liu",
      "Ashok Cutkosky",
      "Francesco Orabona"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2202.00089"
  },
  {
    "id": "arXiv:2202.00091",
    "title": "Query Efficient Decision Based Sparse Attacks Against Black-Box Deep  Learning Models",
    "abstract": "Despite our best efforts, deep learning models remain highly vulnerable to\neven tiny adversarial perturbations applied to the inputs. The ability to\nextract information from solely the output of a machine learning model to craft\nadversarial perturbations to black-box models is a practical threat against\nreal-world systems, such as autonomous cars or machine learning models exposed\nas a service (MLaaS). Of particular interest are sparse attacks. The\nrealization of sparse attacks in black-box models demonstrates that machine\nlearning models are more vulnerable than we believe. Because these attacks aim\nto minimize the number of perturbed pixels measured by l_0 norm-required to\nmislead a model by solely observing the decision (the predicted label) returned\nto a model query; the so-called decision-based attack setting. But, such an\nattack leads to an NP-hard optimization problem. We develop an evolution-based\nalgorithm-SparseEvo-for the problem and evaluate against both convolutional\ndeep neural networks and vision transformers. Notably, vision transformers are\nyet to be investigated under a decision-based attack setting. SparseEvo\nrequires significantly fewer model queries than the state-of-the-art sparse\nattack Pointwise for both untargeted and targeted attacks. The attack\nalgorithm, although conceptually simple, is also competitive with only a\nlimited query budget against the state-of-the-art gradient-based whitebox\nattacks in standard computer vision tasks such as ImageNet. Importantly, the\nquery efficient SparseEvo, along with decision-based attacks, in general, raise\nnew questions regarding the safety of deployed systems and poses new directions\nto study and understand the robustness of machine learning models.",
    "descriptor": "\nComments: Published as a conference paper at the International Conference on Learning Representations (ICLR 2022)\n",
    "authors": [
      "Viet Quoc Vo",
      "Ehsan Abbasnejad",
      "Damith C. Ranasinghe"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.00091"
  },
  {
    "id": "arXiv:2202.00094",
    "title": "News Sharing Networks Expose Information Polluters on Social Media",
    "abstract": "The spread of misinformation is a threat to the social media ecosystem. We\npresent three approaches to mine news-sharing networks for detecting\ninformation polluters at scale, which is critical to mitigate their impact.\nEach hinges on an assumption about how credibility flows in different kinds of\ninformation diffusion networks: the retweet network captures the spread of\nmisinformation among accounts, the account-source bipartite network focuses on\nthe credibility of the sources shared by an account, and the news co-sharing\nnetwork considers the similarity between content shared by different accounts.\nWe apply or extend several network centrality and embedding algorithms to\ncalculate account credibility. We then systematically evaluate these methods on\nempirical networks constructed from Twitter data. We find that some of our\nproposed extensions of centrality measures work well for retweet and bipartite\nnetworks. Graph embedding can be applied to retweet and co-sharing networks,\nwhere it outperforms centrality-based methods at the cost of higher complexity\nand lower transparency.",
    "descriptor": "",
    "authors": [
      "Bao Tran Truong",
      "Oliver Melbourne Allen",
      "Filippo Menczer"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2202.00094"
  },
  {
    "id": "arXiv:2202.00096",
    "title": "Semi-supervised Identification and Mapping of Surface Water Extent using  Street-level Monitoring Videos",
    "abstract": "Urban flooding is becoming a common and devastating hazard to cause life loss\nand economic damage. Monitoring and understanding urban flooding in the local\nscale is a challenging task due to the complicated urban landscape, intricate\nhydraulic process, and the lack of high-quality and resolution data. The\nemerging smart city technology such as monitoring cameras provides an\nunprecedented opportunity to address the data issue. However, estimating the\nwater accumulation on the land surface based on the monitoring footage is\nunreliable using the traditional segmentation technique because the boundary of\nthe water accumulation, under the influence of varying weather, background, and\nillumination, is usually too fuzzy to identify, and the oblique angle and image\ndistortion in the video monitoring data prevents georeferencing and\nobject-based measurements. This paper presents a novel semi-supervised\nsegmentation scheme for surface water extent recognition from the footage of an\noblique monitoring camera. The semi-supervised segmentation algorithm was found\nsuitable to determine the water boundary and the monoplotting method was\nsuccessfully applied to georeference the pixels of the monitoring video for the\nvirtual quantification of the local drainage process. The correlation and\nmechanism-based analysis demonstrates the value of the proposed method in\nadvancing the understanding of local drainage hydraulics. The workflow and\ncreated methods in this study has a great potential to study other street-level\nand earth surface processes.",
    "descriptor": "",
    "authors": [
      "Ruo-Qian Wang",
      "Yangmin Ding"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.00096"
  },
  {
    "id": "arXiv:2202.00097",
    "title": "Self-supervised Graphs for Audio Representation Learning with Limited  Labeled Data",
    "abstract": "Large scale databases with high-quality manual annotations are scarce in\naudio domain. We thus explore a self-supervised graph approach to learning\naudio representations from highly limited labelled data. Considering each audio\nsample as a graph node, we propose a subgraph-based framework with novel\nself-supervision tasks that can learn effective audio representations. During\ntraining, subgraphs are constructed by sampling the entire pool of available\ntraining data to exploit the relationship between the labelled and unlabeled\naudio samples. During inference, we use random edges to alleviate the overhead\nof graph construction. We evaluate our model on three benchmark audio\ndatabases, and two tasks: acoustic event detection and speech emotion\nrecognition. Our semi-supervised model performs better or on par with fully\nsupervised models and outperforms several competitive existing models. Our\nmodel is compact (240k parameters), and can produce generalized audio\nrepresentations that are robust to different types of signal noise.",
    "descriptor": "",
    "authors": [
      "Amir Shirian",
      "Krishna Somandepalli",
      "Tanaya Guha"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2202.00097"
  },
  {
    "id": "arXiv:2202.00102",
    "title": "Real-Time Facial Expression Recognition using Facial Landmarks and  Neural Networks",
    "abstract": "This paper presents a lightweight algorithm for feature extraction,\nclassification of seven different emotions, and facial expression recognition\nin a real-time manner based on static images of the human face. In this regard,\na Multi-Layer Perceptron (MLP) neural network is trained based on the foregoing\nalgorithm. In order to classify human faces, first, some pre-processing is\napplied to the input image, which can localize and cut out faces from it. In\nthe next step, a facial landmark detection library is used, which can detect\nthe landmarks of each face. Then, the human face is split into upper and lower\nfaces, which enables the extraction of the desired features from each part. In\nthe proposed model, both geometric and texture-based feature types are taken\ninto account. After the feature extraction phase, a normalized vector of\nfeatures is created. A 3-layer MLP is trained using these feature vectors,\nleading to 96% accuracy on the test set.",
    "descriptor": "\nComments: 7 pages, 8 figures, 6 tables\n",
    "authors": [
      "Mohammad Amin Haghpanah",
      "Ehsan Saeedizade",
      "Mehdi Tale Masouleh",
      "Ahmad Kalhor"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.00102"
  },
  {
    "id": "arXiv:2202.00104",
    "title": "Generalization in Cooperative Multi-Agent Systems",
    "abstract": "Collective intelligence is a fundamental trait shared by several species of\nliving organisms. It has allowed them to thrive in the diverse environmental\nconditions that exist on our planet. From simple organisations in an ant colony\nto complex systems in human groups, collective intelligence is vital for\nsolving complex survival tasks. As is commonly observed, such natural systems\nare flexible to changes in their structure. Specifically, they exhibit a high\ndegree of generalization when the abilities or the total number of agents\nchanges within a system. We term this phenomenon as Combinatorial\nGeneralization (CG). CG is a highly desirable trait for autonomous systems as\nit can increase their utility and deployability across a wide range of\napplications. While recent works addressing specific aspects of CG have shown\nimpressive results on complex domains, they provide no performance guarantees\nwhen generalizing towards novel situations. In this work, we shed light on the\ntheoretical underpinnings of CG for cooperative multi-agent systems (MAS).\nSpecifically, we study generalization bounds under a linear dependence of the\nunderlying dynamics on the agent capabilities, which can be seen as a\ngeneralization of Successor Features to MAS. We then extend the results first\nfor Lipschitz and then arbitrary dependence of rewards on team capabilities.\nFinally, empirical analysis on various domains using the framework of\nmulti-agent reinforcement learning highlights important desiderata for\nmulti-agent algorithms towards ensuring CG.",
    "descriptor": "",
    "authors": [
      "Anuj Mahajan",
      "Mikayel Samvelyan",
      "Tarun Gupta",
      "Benjamin Ellis",
      "Mingfei Sun",
      "Tim Rockt\u00e4schel",
      "Shimon Whiteson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2202.00104"
  },
  {
    "id": "arXiv:2202.00113",
    "title": "Imbedding Deep Neural Networks",
    "abstract": "Continuous depth neural networks, such as Neural ODEs, have refashioned the\nunderstanding of residual neural networks in terms of non-linear vector-valued\noptimal control problems. The common solution is to use the adjoint sensitivity\nmethod to replicate a forward-backward pass optimisation problem. We propose a\nnew approach which explicates the network's `depth' as a fundamental variable,\nthus reducing the problem to a system of forward-facing initial value problems.\nThis new method is based on the principle of `Invariant Imbedding' for which we\nprove a general solution, applicable to all non-linear, vector-valued optimal\ncontrol problems with both running and terminal loss. Our new architectures\nprovide a tangible tool for inspecting the theoretical--and to a great extent\nunexplained--properties of network depth. They also constitute a resource of\ndiscrete implementations of Neural ODEs comparable to classes of imbedded\nresidual neural networks. Through a series of experiments, we show the\ncompetitive performance of the proposed architectures for supervised learning\nand time series prediction.",
    "descriptor": "\nComments: Accepted as a spotlight paper at the 10th International Conference on Learning Representations (ICLR), 2022\n",
    "authors": [
      "Andrew Corbett",
      "Dmitry Kangin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2202.00113"
  },
  {
    "id": "arXiv:2202.00117",
    "title": "Continuous Forecasting via Neural Eigen Decomposition of Stochastic  Dynamics",
    "abstract": "Motivated by a real-world problem of blood coagulation control in\nHeparin-treated patients, we use Stochastic Differential Equations (SDEs) to\nformulate a new class of sequential prediction problems -- with an unknown\nlatent space, unknown non-linear dynamics, and irregular sparse observations.\nWe introduce the Neural Eigen-SDE (NESDE) algorithm for sequential prediction\nwith sparse observations and adaptive dynamics. NESDE applies\neigen-decomposition to the dynamics model to allow efficient frequent\npredictions given sparse observations. In addition, NESDE uses a learning\nmechanism for adaptive dynamics model, which handles changes in the dynamics\nboth between sequences and within sequences. We demonstrate the accuracy and\nefficacy of NESDE for both synthetic problems and real-world data. In\nparticular, to the best of our knowledge, we are the first to provide a\npatient-adapted prediction for blood coagulation following Heparin dosing in\nthe MIMIC-IV dataset. Finally, we publish a simulated gym environment based on\nour prediction model, for experimentation in algorithms for blood coagulation\ncontrol.",
    "descriptor": "",
    "authors": [
      "Stav Belogolovsky",
      "Ido Greenberg",
      "Danny Eitan",
      "Shie Mannor"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.00117"
  },
  {
    "id": "arXiv:2202.00120",
    "title": "QALD-9-plus: A Multilingual Dataset for Question Answering over DBpedia  and Wikidata Translated by Native Speakers",
    "abstract": "The ability to have the same experience for different user groups (i.e.,\naccessibility) is one of the most important characteristics of Web-based\nsystems. The same is true for Knowledge Graph Question Answering (KGQA) systems\nthat provide the access to Semantic Web data via natural language interface.\nWhile following our research agenda on the multilingual aspect of accessibility\nof KGQA systems, we identified several ongoing challenges. One of them is the\nlack of multilingual KGQA benchmarks. In this work, we extend one of the most\npopular KGQA benchmarks - QALD-9 by introducing high-quality questions'\ntranslations to 8 languages provided by native speakers, and transferring the\nSPARQL queries of QALD-9 from DBpedia to Wikidata, s.t., the usability and\nrelevance of the dataset is strongly increased. Five of the languages -\nArmenian, Ukrainian, Lithuanian, Bashkir and Belarusian - to our best knowledge\nwere never considered in KGQA research community before. The latter two of the\nlanguages are considered as \"endangered\" by UNESCO. We call the extended\ndataset QALD-9-plus and made it available online\nhttps://github.com/Perevalov/qald_9_plus.",
    "descriptor": "",
    "authors": [
      "Aleksandr Perevalov",
      "Dennis Diefenbach",
      "Ricardo Usbeck",
      "Andreas Both"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2202.00120"
  },
  {
    "id": "arXiv:2202.00123",
    "title": "3D Visualization and Spatial Data Mining for Analysis of LULC Images",
    "abstract": "The present study is an attempt made to create a new tool for the analysis of\nLand Use Land Cover (LUCL) images in 3D visualization. This study mainly uses\nspatial data mining techniques on high resolution LULC satellite imagery.\nVisualization of feature space allows exploration of patterns in the image data\nand insight into the classification process and related uncertainty. Visual\nData Mining provides added value to image classifications as the user can be\ninvolved in the classification process providing increased confidence in and\nunderstanding of the results. In this study, we present a prototype of image\nsegmentation, K-Means clustering and 3D visualization tool for visual data\nmining (VDM) of LUCL satellite imagery into volume visualization. This volume\nbased representation divides feature space into spheres or voxels. The\nvisualization tool is showcased in a classification study of high-resolution\nLULC imagery of Latur district (Maharashtra state, India) is used as sample\ndata.",
    "descriptor": "\nComments: 5 pages, 7 figures and 3 tables\n",
    "authors": [
      "B. G. Kodge"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.00123"
  },
  {
    "id": "arXiv:2202.00126",
    "title": "Handling Bias in Toxic Speech Detection: A Survey",
    "abstract": "The massive growth of social media usage has witnessed a tsunami of online\ntoxicity in teams of hate speech, abusive posts, cyberbullying, etc. Detecting\nonline toxicity is challenging due to its inherent subjectivity. Factors such\nas the context of the speech, geography, socio-political climate, and\nbackground of the producers and consumers of the posts play a crucial role in\ndetermining if the content can be flagged as toxic. Adoption of automated\ntoxicity detection models in production can lead to a sidelining of the various\ndemographic and psychographic groups they aim to help in the first place. It\nhas piqued researchers' interest in examining unintended biases and their\nmitigation. Due to the nascent and multi-faceted nature of the work, complete\nliterature is chaotic in its terminologies, techniques, and findings. In this\npaper, we put together a systematic study to discuss the limitations and\nchallenges of existing methods.\nWe start by developing a taxonomy for categorising various unintended biases\nand a suite of evaluation metrics proposed to quantify such biases. We take a\ncloser look at each proposed method for evaluating and mitigating bias in toxic\nspeech detection. To examine the limitations of existing methods, we also\nconduct a case study to introduce the concept of bias shift due to\nknowledge-based bias mitigation methods. The survey concludes with an overview\nof the critical challenges, research gaps and future directions. While reducing\ntoxicity on online platforms continues to be an active area of research, a\nsystematic study of various biases and their mitigation strategies will help\nthe research community produce robust and fair models.",
    "descriptor": "\nComments: 28 pages, 4 figures, 7 tables, Under Review at ACM Computing Surveys\n",
    "authors": [
      "Tanmay Garg",
      "Sarah Masud",
      "Tharun Suresh",
      "Tanmoy Chakraborty"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.00126"
  },
  {
    "id": "arXiv:2202.00128",
    "title": "Reply to comment on \"Failure of the simultaneous block diagonalization  technique applied to complete and cluster synchronization of random networks\"",
    "abstract": "We respond briefly to a comment [1, arXiv:2110.15493] recently posted online\non our paper [2, arXiv:2108.07893]. Complete and cluster synchronization of\nrandom networks is undoubtedly a topic of interest in the Physics, Engineering,\nand Nonlinear Dynamics literature. In [3] we study both complete and cluster\nsynchronization of networks and introduce indices that measure success (or\nfailure) of application of the SBD technique in decoupling the stability\nproblem into problems of lower dimensionality. Our usage of the word `failure'\nindicates that the technique does not produce a decomposition which results in\na system which is easier to analyze, not that the technique fails in correctly\ndecoupling these problems.",
    "descriptor": "",
    "authors": [
      "Shirin Panahi",
      "Nelson Amaya",
      "Isaac Klickstein",
      "Galen Novello",
      "Francesco Sorrentino"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.00128"
  },
  {
    "id": "arXiv:2202.00129",
    "title": "Fundamental Performance Limits for Sensor-Based Robot Control and Policy  Learning",
    "abstract": "Our goal is to develop theory and algorithms for establishing fundamental\nlimits on performance for a given task imposed by a robot's sensors. In order\nto achieve this, we define a quantity that captures the amount of task-relevant\ninformation provided by a sensor. Using a novel version of the generalized Fano\ninequality from information theory, we demonstrate that this quantity provides\nan upper bound on the highest achievable expected reward for one-step decision\nmaking tasks. We then extend this bound to multi-step problems via a dynamic\nprogramming approach. We present algorithms for numerically computing the\nresulting bounds, and demonstrate our approach on three examples: (i) the lava\nproblem from the literature on partially observable Markov decision processes,\n(ii) an example with continuous state and observation spaces corresponding to a\nrobot catching a freely-falling object, and (iii) obstacle avoidance using a\ndepth sensor with non-Gaussian noise. We demonstrate the ability of our\napproach to establish strong limits on achievable performance for these\nproblems by comparing our upper bounds with achievable lower bounds (computed\nby synthesizing or learning concrete control policies).",
    "descriptor": "",
    "authors": [
      "Anirudha Majumdar",
      "Vincent Pacelli"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2202.00129"
  },
  {
    "id": "arXiv:2202.00132",
    "title": "Submodularity In Machine Learning and Artificial Intelligence",
    "abstract": "In this manuscript, we offer a gentle review of submodularity and\nsupermodularity and their properties. We offer a plethora of submodular\ndefinitions; a full description of a number of example submodular functions and\ntheir generalizations; example discrete constraints; a discussion of basic\nalgorithms for maximization, minimization, and other operations; a brief\noverview of continuous submodular extensions; and some historical applications.\nWe then turn to how submodularity is useful in machine learning and artificial\nintelligence. This includes summarization, and we offer a complete account of\nthe differences between and commonalities amongst sketching, coresets,\nextractive and abstractive summarization in NLP, data distillation and\ncondensation, and data subset selection and feature selection. We discuss a\nvariety of ways to produce a submodular function useful for machine learning,\nincluding heuristic hand-crafting, learning or approximately learning a\nsubmodular function or aspects thereof, and some advantages of the use of a\nsubmodular function as a coreset producer. We discuss submodular combinatorial\ninformation functions, and how submodularity is useful for clustering, data\npartitioning, parallel machine learning, active and semi-supervised learning,\nprobabilistic modeling, and structured norms and loss functions.",
    "descriptor": "",
    "authors": [
      "Jeff Bilmes"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.00132"
  },
  {
    "id": "arXiv:2202.00134",
    "title": "Using Transition Learning to Enhance Mobile-Controlled Handoff In  Decentralized Future Networks",
    "abstract": "Traditionally, resource management and capacity allocation has been\ncontrolled network-side in cellular deployment. As autonomicity has been added\nto network design, machine learning technologies have largely followed this\nparadigm, benefiting from the higher compute capacity and informational context\navailable at the network core. However, when these network services are\ndisaggregated or decentralized, models that rely on assumed levels of network\nor information availability may no longer function reliably. This paper\npresents an inverted view of the resource management paradigm; one in which the\nclient device executes a learning algorithm and manages its own mobility under\na scenario where the networks and their corresponding data underneath are not\nbeing centrally managed.",
    "descriptor": "\nComments: 8 Pages, 13 figures, IEEE 5G World Forum 2021\n",
    "authors": [
      "Steven Platt",
      "Berkay Demirel",
      "Miquel Oliver"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2202.00134"
  },
  {
    "id": "arXiv:2202.00136",
    "title": "Non-adaptive and two-stage coding over the Z-channel",
    "abstract": "In this paper, we developed new coding strategies for the Z-channel. In\nparticular, we look at the case with two-stage encoding. In this case, the\nencoder uses noiseless feedback once and adjusts the further encoding strategy\nbased on the previous partial output of the channel. Nevertheless, the\ndeveloped codes improve the known results with full feedback for small length\nand 1 error. A tool for the two-stage strategy is the development of a new\noptimality condition for non-adaptive codes. Finally, we give a new\nnon-adaptive code of length 10 and size 110, which corrects one asymmetric\nerror.",
    "descriptor": "",
    "authors": [
      "Alexey Lebedev",
      "Ilya Vorobyev",
      "Vladimir Lebedev",
      "Christian Deppe"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2202.00136"
  },
  {
    "id": "arXiv:2202.00137",
    "title": "Studying the Robustness of Anti-adversarial Federated Learning Models  Detecting Cyberattacks in IoT Spectrum Sensors",
    "abstract": "Device fingerprinting combined with Machine and Deep Learning (ML/DL) report\npromising performance when detecting cyberattacks targeting data managed by\nresource-constrained spectrum sensors. However, the amount of data needed to\ntrain models and the privacy concerns of such scenarios limit the applicability\nof centralized ML/DL-based approaches. Federated learning (FL) addresses these\nlimitations by creating federated and privacy-preserving models. However, FL is\nvulnerable to malicious participants, and the impact of adversarial attacks on\nfederated models detecting spectrum sensing data falsification (SSDF) attacks\non spectrum sensors has not been studied. To address this challenge, the first\ncontribution of this work is the creation of a novel dataset suitable for FL\nand modeling the behavior (usage of CPU, memory, or file system, among others)\nof resource-constrained spectrum sensors affected by different SSDF attacks.\nThe second contribution is a pool of experiments analyzing and comparing the\nrobustness of federated models according to i) three families of spectrum\nsensors, ii) eight SSDF attacks, iii) four scenarios dealing with unsupervised\n(anomaly detection) and supervised (binary classification) federated models,\niv) up to 33% of malicious participants implementing data and model poisoning\nattacks, and v) four aggregation functions acting as anti-adversarial\nmechanisms to increase the models robustness.",
    "descriptor": "",
    "authors": [
      "Pedro Miguel S\u00e1nchez S\u00e1nchez",
      "Alberto Huertas Celdr\u00e1n",
      "Timo Schenk",
      "Adrian Lars Benjamin Iten",
      "G\u00e9r\u00f4me Bovet",
      "Gregorio Mart\u00ednez P\u00e9rez",
      "Burkhard Stiller"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.00137"
  },
  {
    "id": "arXiv:2202.00142",
    "title": "A Sampling-Aware Interpretation of Linear Logic: Syntax and Categorical  Semantics",
    "abstract": "The usual resource interpretation of linear logic says that variables have to\nbe used exactly once. However, there are models of linear logic where this\ninterpretation is too restrictive. In this work we show how in probabilistic\nmodels of linear logic the correct resource interpretation should be sampling,\ni.e. the linear arrow should be read as \"the output may only sample once from\nits input\". We accommodate this new interpretation by defining a multilanguage\nsyntax and its categorical semantics that bridges the Markov kernel and linear\nlogic interpretations of probabilistic programs.",
    "descriptor": "",
    "authors": [
      "Pedro H. Azevedo de Amorim"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2202.00142"
  },
  {
    "id": "arXiv:2202.00144",
    "title": "An Adaptive sampling and domain learning strategy for multivariate  function approximation on unknown domains",
    "abstract": "Many problems in computational science and engineering can be described in\nterms of approximating a smooth function of $d$ variables, defined over an\nunknown domain of interest $\\Omega\\subset \\mathbb{R}^d$, from sample data. Here\nboth the curse of dimensionality ($d\\gg 1$) and the lack of domain knowledge\nwith $\\Omega$ potentially irregular and/or disconnected are confounding factors\nfor sampling-based methods. Na\\\"{i}ve approaches often lead to wasted samples\nand inefficient approximation schemes. For example, uniform sampling can result\nin upwards of 20\\% wasted samples in some problems. In surrogate model\nconstruction in computational uncertainty quantification (UQ), the high cost of\ncomputing samples needs a more efficient sampling procedure. In the last years,\nmethods for computing such approximations from sample data have been studied in\nthe case of irregular domains. The advantages of computing sampling measures\ndepending on an approximation space $P$ of $\\dim(P)=N$ have been shown. In\nparticular, such methods confer advantages such as stability and\nwell-conditioning, with $\\mathcal{O}(N\\log(N))$ as sample complexity. The\nrecently-proposed adaptive sampling for general domains (ASGD) strategy is one\nmethod to construct these sampling measures. The main contribution of this\npaper is to improve ASGD by adaptively updating the sampling measures over\nunknown domains. We achieve this by first introducing a general domain\nadaptivity strategy (GDAS), which approximates the function and domain of\ninterest from sample points. Second, we propose adaptive sampling for unknown\ndomains (ASUD), which generates sampling measures over a domain that may not be\nknown in advance. Then, we derive least squares techniques for polynomial\napproximation on unknown domains. Numerical results show that the ASUD approach\ncan reduce the computational cost by as 50\\% when compared with uniform\nsampling.",
    "descriptor": "",
    "authors": [
      "Ben Adcock",
      "Juan M. Cardenas",
      "Nick Dexter"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.00144"
  },
  {
    "id": "arXiv:2202.00145",
    "title": "Step-size Adaptation Using Exponentiated Gradient Updates",
    "abstract": "Optimizers like Adam and AdaGrad have been very successful in training\nlarge-scale neural networks. Yet, the performance of these methods is heavily\ndependent on a carefully tuned learning rate schedule. We show that in many\nlarge-scale applications, augmenting a given optimizer with an adaptive tuning\nmethod of the step-size greatly improves the performance. More precisely, we\nmaintain a global step-size scale for the update as well as a gain factor for\neach coordinate. We adjust the global scale based on the alignment of the\naverage gradient and the current gradient vectors. A similar approach is used\nfor updating the local gain factors. This type of step-size scale tuning has\nbeen done before with gradient descent updates. In this paper, we update the\nstep-size scale and the gain variables with exponentiated gradient updates\ninstead. Experimentally, we show that our approach can achieve compelling\naccuracy on standard models without using any specially tuned learning rate\nschedule. We also show the effectiveness of our approach for quickly adapting\nto distribution shifts in the data during training.",
    "descriptor": "",
    "authors": [
      "Ehsan Amid",
      "Rohan Anil",
      "Christopher Fifty",
      "Manfred K. Warmuth"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.00145"
  },
  {
    "id": "arXiv:2202.00146",
    "title": "Evaluating Deep Vs. Wide & Deep Learners As Contextual Bandits For  Personalized Email Promo Recommendations",
    "abstract": "Personalization enables businesses to learn customer preferences from past\ninteractions and thus to target individual customers with more relevant\ncontent. We consider the problem of predicting the optimal promotional offer\nfor a given customer out of several options as a contextual bandit problem.\nIdentifying information for the customer and/or the campaign can be used to\ndeduce unknown customer/campaign features that improve optimal offer\nprediction. Using a generated synthetic email promo dataset, we demonstrate\nsimilar prediction accuracies for (a) a wide and deep network that takes\nidentifying information (or other categorical features) as input to the wide\npart and (b) a deep-only neural network that includes embeddings of categorical\nfeatures in the input. Improvements in accuracy from including categorical\nfeatures depends on the variability of the unknown numerical features for each\ncategory. We also show that selecting options using upper confidence bound or\nThompson sampling, approximated via Monte Carlo dropout layers in the wide and\ndeep models, slightly improves model performance.",
    "descriptor": "",
    "authors": [
      "Aleksey A. Kocherzhenko",
      "Nirmal Sobha Kartha",
      "Tengfei Li",
      "Hsin-Yi",
      "Shih",
      "Marco Mandic",
      "Mike Fuller",
      "Arshak Navruzyan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.00146"
  },
  {
    "id": "arXiv:2202.00150",
    "title": "Learning Infinite-Horizon Average-Reward Markov Decision Processes with  Constraints",
    "abstract": "We study regret minimization for infinite-horizon average-reward Markov\nDecision Processes (MDPs) under cost constraints. We start by designing a\npolicy optimization algorithm with carefully designed action-value estimator\nand bonus term, and show that for ergodic MDPs, our algorithm ensures\n$\\widetilde{O}(\\sqrt{T})$ regret and constant constraint violation, where $T$\nis the total number of time steps. This strictly improves over the algorithm of\n(Singh et al., 2020), whose regret and constraint violation are both\n$\\widetilde{O}(T^{2/3})$. Next, we consider the most general class of weakly\ncommunicating MDPs. Through a finite-horizon approximation, we develop another\nalgorithm with $\\widetilde{O}(T^{2/3})$ regret and constraint violation, which\ncan be further improved to $\\widetilde{O}(\\sqrt{T})$ via a simple modification,\nalbeit making the algorithm computationally inefficient. As far as we know,\nthese are the first set of provable algorithms for weakly communicating MDPs\nwith cost constraints.",
    "descriptor": "",
    "authors": [
      "Liyu Chen",
      "Rahul Jain",
      "Haipeng Luo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.00150"
  },
  {
    "id": "arXiv:2202.00151",
    "title": "DRS-LIP: Linear Inverted Pendulum Model for Legged Locomotion on Dynamic  Rigid Surfaces",
    "abstract": "Legged robot locomotion on a dynamic rigid surface (i.e., a rigid surface\nmoving in the inertial frame) involves complex full-order dynamics that is\nhigh-dimensional, nonlinear, and time-varying. Towards deriving an analytically\ntractable dynamic model, this study theoretically extends the reduced-order\nlinear inverted pendulum (LIP) model from legged locomotion on a stationary\nsurface to locomotion on a dynamic rigid surface (DRS). The resulting model is\nherein termed as DRS-LIP. Furthermore, this study introduces an approximate\nanalytical solution of the proposed DRS-LIP that is computationally efficient\nwith high accuracy. To illustrate the practical uses of the analytical results,\nthey are used to develop a hierarchical planning framework that efficiently\ngenerates physically feasible trajectories for DRS locomotion. The\neffectiveness of the proposed theoretical results and motion planner is\ndemonstrated both through simulations and experimentally on a Laikago\nquadrupedal robot that walks on a rocking treadmill.",
    "descriptor": "\nComments: 8 pages, 8 figures. Submitted to AIM2022 concurrent submission\n",
    "authors": [
      "Amir Iqbal",
      "Sushant Veer",
      "Yan Gu"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.00151"
  },
  {
    "id": "arXiv:2202.00153",
    "title": "Transformer-based Models of Text Normalization for Speech Applications",
    "abstract": "Text normalization, or the process of transforming text into a consistent,\ncanonical form, is crucial for speech applications such as text-to-speech\nsynthesis (TTS). In TTS, the system must decide whether to verbalize \"1995\" as\n\"nineteen ninety five\" in \"born in 1995\" or as \"one thousand nine hundred\nninety five\" in \"page 1995\". We present an experimental comparison of various\nTransformer-based sequence-to-sequence (seq2seq) models of text normalization\nfor speech and evaluate them on a variety of datasets of written text aligned\nto its normalized spoken form. These models include variants of the 2-stage\nRNN-based tagging/seq2seq architecture introduced by Zhang et al. (2019), where\nwe replace the RNN with a Transformer in one or more stages, as well as vanilla\nTransformers that output string representations of edit sequences. Of our\napproaches, using Transformers for sentence context encoding within the 2-stage\nmodel proved most effective, with the fine-tuned BERT encoder yielding the best\nperformance.",
    "descriptor": "",
    "authors": [
      "Jae Hun Ro",
      "Felix Stahlberg",
      "Ke Wu",
      "Shankar Kumar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.00153"
  },
  {
    "id": "arXiv:2202.00155",
    "title": "Fortuitous Forgetting in Connectionist Networks",
    "abstract": "Forgetting is often seen as an unwanted characteristic in both human and\nmachine learning. However, we propose that forgetting can in fact be favorable\nto learning. We introduce \"forget-and-relearn\" as a powerful paradigm for\nshaping the learning trajectories of artificial neural networks. In this\nprocess, the forgetting step selectively removes undesirable information from\nthe model, and the relearning step reinforces features that are consistently\nuseful under different conditions. The forget-and-relearn framework unifies\nmany existing iterative training algorithms in the image classification and\nlanguage emergence literature, and allows us to understand the success of these\nalgorithms in terms of the disproportionate forgetting of undesirable\ninformation. We leverage this understanding to improve upon existing algorithms\nby designing more targeted forgetting operations. Insights from our analysis\nprovide a coherent view on the dynamics of iterative training in neural\nnetworks and offer a clear path towards performance improvements.",
    "descriptor": "\nComments: ICLR Camera Ready\n",
    "authors": [
      "Hattie Zhou",
      "Ankit Vani",
      "Hugo Larochelle",
      "Aaron Courville"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2202.00155"
  },
  {
    "id": "arXiv:2202.00158",
    "title": "Learning-Based Framework for Camera Calibration with Distortion  Correction and High Precision Feature Detection",
    "abstract": "Camera calibration is a crucial technique which significantly influences the\nperformance of many robotic systems. Robustness and high precision have always\nbeen the pursuit of diverse calibration methods. State-of-the-art calibration\ntechniques based on classical Zhang's method, however, still suffer from\nenvironmental noise, radial lens distortion and sub-optimal parameter\nestimation. Therefore, in this paper, we propose a hybrid camera calibration\nframework which combines learning-based approaches with traditional methods to\nhandle these bottlenecks. In particular, this framework leverages\nlearning-based approaches to perform efficient distortion correction and robust\nchessboard corner coordinate encoding. For sub-pixel accuracy of corner\ndetection, a specially-designed coordinate decoding algorithm with embed\noutlier rejection mechanism is proposed. To avoid sub-optimal estimation\nresults, we improve the traditional parameter estimation by RANSAC algorithm\nand achieve stable results. Compared with two widely-used camera calibration\ntoolboxes, experiment results on both real and synthetic datasets manifest the\nbetter robustness and higher precision of the proposed framework. The massive\nsynthetic dataset is the basis of our framework's decent performance and will\nbe publicly available along with the code at\nhttps://github.com/Easonyesheng/CCS.",
    "descriptor": "",
    "authors": [
      "Yesheng Zhang",
      "Xu Zhao",
      "Dahong Qian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.00158"
  },
  {
    "id": "arXiv:2202.00159",
    "title": "Content addressable memory without catastrophic forgetting by  heteroassociation with a fixed scaffold",
    "abstract": "Content-addressable memory (CAM) networks, so-called because stored items can\nbe recalled by partial or corrupted versions of the items, exhibit near-perfect\nrecall of a small number of information-dense patterns below capacity and a\n`memory cliff' beyond, such that inserting a single additional pattern results\nin catastrophic forgetting of all stored patterns. We propose a novel ANN\narchitecture, Memory Scaffold with Heteroassociation (MESH), that gracefully\ntrades-off pattern richness with pattern number to generate a CAM continuum\nwithout a memory cliff: Small numbers of patterns are stored with complete\ninformation recovery matching standard CAMs, while inserting more patterns\nstill results in partial recall of every pattern, with an information per\npattern that scales inversely with the number of patterns. Motivated by the\narchitecture of the Entorhinal-Hippocampal memory circuit in the brain, MESH is\na tripartite architecture with pairwise interactions that uses a predetermined\nset of internally stabilized states together with heteroassociation between the\ninternal states and arbitrary external patterns. We show analytically and\nexperimentally that MESH nearly saturates the total information bound (given by\nthe number of synapses) for CAM networks, invariant of the number of stored\npatterns, outperforming all existing CAM models.",
    "descriptor": "",
    "authors": [
      "Sugandha Sharma",
      "Sarthak Chandra",
      "Ila R. Fiete"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.00159"
  },
  {
    "id": "arXiv:2202.00161",
    "title": "CIC: Contrastive Intrinsic Control for Unsupervised Skill Discovery",
    "abstract": "We introduce Contrastive Intrinsic Control (CIC), an algorithm for\nunsupervised skill discovery that maximizes the mutual information between\nskills and state transitions. In contrast to most prior approaches, CIC uses a\ndecomposition of the mutual information that explicitly incentivizes diverse\nbehaviors by maximizing state entropy. We derive a novel lower bound estimate\nfor the mutual information which combines a particle estimator for state\nentropy to generate diverse behaviors and contrastive learning to distill these\nbehaviors into distinct skills. We evaluate our algorithm on the Unsupervised\nReinforcement Learning Benchmark, which consists of a long reward-free\npre-training phase followed by a short adaptation phase to downstream tasks\nwith extrinsic rewards. We find that CIC substantially improves over prior\nunsupervised skill discovery methods and outperforms the next leading overall\nexploration algorithm in terms of downstream task performance.",
    "descriptor": "\nComments: Project website: this https URL\n",
    "authors": [
      "Michael Laskin",
      "Hao Liu",
      "Xue Bin Peng",
      "Denis Yarats",
      "Aravind Rajeswaran",
      "Pieter Abbeel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.00161"
  },
  {
    "id": "arXiv:2202.00162",
    "title": "Dilated Continuous Random Field for Semantic Segmentation",
    "abstract": "Mean field approximation methodology has laid the foundation of modern\nContinuous Random Field (CRF) based solutions for the refinement of semantic\nsegmentation. In this paper, we propose to relax the hard constraint of mean\nfield approximation - minimizing the energy term of each node from\nprobabilistic graphical model, by a global optimization with the proposed\ndilated sparse convolution module (DSConv). In addition, adaptive global\naverage-pooling and adaptive global max-pooling are implemented as replacements\nof fully connected layers. In order to integrate DSConv, we design an\nend-to-end, time-efficient DilatedCRF pipeline. The unary energy term is\nderived either from pre-softmax and post-softmax features, or the predicted\naffordance map using a conventional classifier, making it easier to implement\nDilatedCRF for varieties of classifiers. We also present superior experimental\nresults of proposed approach on the suction dataset comparing to other\nCRF-based approaches.",
    "descriptor": "\nComments: Manuscript accepted by IEEE International Conference on Robotics and Automation (ICRA 2022)\n",
    "authors": [
      "Xi Mo",
      "Xiangyu Chen",
      "Cuncong Zhong",
      "Rui Li",
      "Kaidong Li",
      "Usman Sajid"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.00162"
  },
  {
    "id": "arXiv:2202.00164",
    "title": "DexVIP: Learning Dexterous Grasping with Human Hand Pose Priors from  Video",
    "abstract": "Dexterous multi-fingered robotic hands have a formidable action space, yet\ntheir morphological similarity to the human hand holds immense potential to\naccelerate robot learning. We propose DexVIP, an approach to learn dexterous\nrobotic grasping from human-object interactions present in in-the-wild YouTube\nvideos. We do this by curating grasp images from human-object interaction\nvideos and imposing a prior over the agent's hand pose when learning to grasp\nwith deep reinforcement learning. A key advantage of our method is that the\nlearned policy is able to leverage free-form in-the-wild visual data. As a\nresult, it can easily scale to new objects, and it sidesteps the standard\npractice of collecting human demonstrations in a lab -- a much more expensive\nand indirect way to capture human expertise. Through experiments on 27 objects\nwith a 30-DoF simulated robot hand, we demonstrate that DexVIP compares\nfavorably to existing approaches that lack a hand pose prior or rely on\nspecialized tele-operation equipment to obtain human demonstrations, while also\nbeing faster to train. Project page:\nhttps://vision.cs.utexas.edu/projects/dexvip-dexterous-grasp-pose-prior",
    "descriptor": "",
    "authors": [
      "Priyanka Mandikal",
      "Kristen Grauman"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.00164"
  },
  {
    "id": "arXiv:2202.00165",
    "title": "Design Constraints of Disturbance Observer-based Motion Control Systems  are Stricter in the Discrete-Time Domain",
    "abstract": "This paper shows that the design constraints of the Disturbance Observer\n(DOb) based robust motion control systems become stricter when they are\nimplemented using computers or microcontrollers. The stricter design\nconstraints put new upper bounds on the plant-model mismatch and the bandwidth\nof the DOb, thus limiting the achievable robustness against disturbances and\nthe phase-lead effect in the inner-loop. Violating the design constraints may\nyield severe stability and performance issues in practice; therefore, they\nshould be considered in tuning the control parameters of the robust motion\ncontroller. This paper also shows that continuous-time analysis methods\nfall-short in deriving the fundamental design constraints on the nominal plant\nmodel and the bandwidth of the digital DOb. Therefore, we may observe\nunexpected stability and performance issues when tuning the control parameters\nof the digital robust motion controllers in the continuous-time domain. To\nimprove the robust stability and performance of the motion controllers, this\npaper explains the fundamental design constraints of the DOb by employing the\ngeneralised continuous and discrete Bode Integral Theorems in a unified\nframework. Simulation and experimental results are given to verify the proposed\nanalysis method.",
    "descriptor": "\nComments: IEEE International Workshop on Advanced Motion Control, 2022\n",
    "authors": [
      "Emre Sariyildiz"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.00165"
  },
  {
    "id": "arXiv:2202.00168",
    "title": "A Unified Robust Motion Controller Synthesis for Compliant Robots Driven  by Series Elastic Actuators",
    "abstract": "This paper proposes a unified robust motion controller for the position and\nforce control problems of compliant robot manipulators driven by Series Elastic\nActuators (SEAs). It is shown that the dynamic model of the compliant robot\nincludes not only matched but also mismatched disturbances that act on the\nsystem through a different channel from the control input. To tackle this\ncomplex robust control problem, the unified robust motion controller is\nsynthesised by employing a second-order Disturbance Observer (DOb), which\nallows us to estimate not only disturbances but also their first and second\norder derivatives, and a novel controller design approach in state space. By\nusing the Brunovsky canonical form transformation and the estimations of\ndisturbances and their first and second order derivatives, the dynamic model of\nthe robot is reconstructed so that a new system model that includes only\nmatched disturbances is obtained for compliant robots driven by SEAs. The\nrobust position and force controllers are simply designed by eliminating the\nmatched disturbances of the reconstructed system model via the conventional\nDOb-based robust control method. The stability and performance of the proposed\nrobust motion controllers are verified by simulations.",
    "descriptor": "\nComments: IEEE International Workshop on Advanced Motion Control\n",
    "authors": [
      "Emre Sariyildiz"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.00168"
  },
  {
    "id": "arXiv:2202.00170",
    "title": "A self-organizing multi-agent system for distributed voltage regulation",
    "abstract": "This paper presents a distributed voltage regulation method based on\nmulti-agent system control and network self-organization for a large\ndistribution network. The network autonomously organizes itself into small\nsubnetworks through the epsilon decomposition of the sensitivity matrix, and\nagents group themselves into these subnetworks with the communication links\nbeing autonomously determined. Each subnetwork controls its voltage by locating\nthe closest local distributed generation and optimizing their outputs. This\nsimplifies and reduces the size of the optimization problem and the interaction\nrequirements. This approach also facilitates adaptive grouping of the network\nby self-reorganizing to maintain a stable state in response to time-varying\nnetwork requirements and changes. The effectiveness of the proposed approach is\nvalidated through simulations on a model of a real heavily-meshed secondary\ndistribution network. Simulation results and comparisons with other methods\ndemonstrate the ability of the subnetworks to autonomously and independently\nregulate the voltage and to adapt to unpredictable network conditions over\ntime, thereby enabling autonomous and flexible distribution networks.",
    "descriptor": "\nComments: IEEE PES Transactions on Smart Grid\n",
    "authors": [
      "Badr Al Faiya",
      "Dimitrios Athanasiadis",
      "Minjiang Chen",
      "Stephen McArthur",
      "Ivana Kockar",
      "Haowei Lu",
      "Francisco de Leon"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.00170"
  },
  {
    "id": "arXiv:2202.00173",
    "title": "Industry Experiences with Large-Scale Refactoring",
    "abstract": "Software refactoring plays an important role in software engineering.\nDevelopers often turn to refactoring when they want to restructure software to\nimprove its quality without changing its external behavior. Studies show that\nsmall-scale (floss) refactoring is common in industry and can often be\nperformed by a single developer in short sessions, even though developers do\nmuch of this work manually instead of using refactoring tools. However, some\nrefactoring efforts are much larger in scale, requiring entire teams and months\nof effort, and the role of tools in these efforts is not as well studied. In\nthis paper, we report on a survey we conducted with developers to understand\nlarge-scale refactoring, its prevalence, and how tools support it. Our results\nfrom 107 industry developers demonstrate that projects commonly go through\nmultiple large-scale refactorings, each of which requires considerable effort.\nWhile there is often a desire to refactor, other business concerns such as\ndeveloping new features often take higher priority. Our study finds that\ndevelopers use several categories of tools to support large-scale refactoring\nand rely more heavily on general-purpose tools like IDEs than on tools designed\nspecifically to support refactoring. Tool support varies across the different\nactivities, with some particularly challenging activities seeing little use of\ntools in practice. Our study demonstrates a clear need for better large-scale\nrefactoring tools and an opportunity for refactoring researchers to make a\ndifference in industry. The results we summarize in this paper is one concrete\nstep towards this goal.",
    "descriptor": "\nComments: 10 pages, 7 figures, 4 tables\n",
    "authors": [
      "James Ivers",
      "Robert L. Nord",
      "Ipek Ozkaya",
      "Chris Seifried",
      "Christopher S. Timperley",
      "Marouane Kessentini"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2202.00173"
  },
  {
    "id": "arXiv:2202.00175",
    "title": "Ground Experiment of Full-Duplex Multi-UAV System Enabled by Directional  Antennas",
    "abstract": "A high performance multi-UAV communication system, which bridges multiple\nUAVs and ground station, is one of the key enablers to realize a variety of\nUAV-based systems. To address the issues such as the low spectrum efficiency\ncaused by the co-channel interference, we have proposed a spectrum-efficient\nfull-duplex multi-UA V communication system with low hardware complexity. In\nthis paper, on-ground experiments are conducted to confirm the feasibility and\neffectiveness of the key feature of the proposed system, i.e., co-channel\ninterference cancellation among UAVs by directional antennas and UAV position\ncontrol, instead of energy-consuming dedicated self-interference cancellers on\nUAVs in traditional full-duplex systems. Channel power of interference link\nbetween a pair of two UAVs reusing the same channel is measured, and the\nachievable channel capacity is also measured by a prototype system implemented\nby software-defined radio devices. The results of different antennas and\ndifferent antenna heights are also compared. The experimental results agree\nwell with the designs and confirm the feasibility and effectiveness of the\nproposed system. This ground experiment is a work in progress to provide\npreliminary results for the multi-UAV-based experiments in the air in the\nfuture.",
    "descriptor": "\nComments: This paper was accepted by IEEE Annual Computing and Communication Workshop and Conference (CCWC) 2022\n",
    "authors": [
      "Tao Yu",
      "Kiyomichi Araki",
      "Kei Sakaguchi"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.00175"
  },
  {
    "id": "arXiv:2202.00176",
    "title": "Full-Duplex Aerial Communication System for Multiple UAVs with  Directional Antennas",
    "abstract": "UAV-based wireless systems, such as wireless relay and remote sensing, have\nattracted great attentions from academia and industry. To realize them, a\nhigh-performance wireless aerial communication system, which bridges UAVs and\nground stations, is one of the key enablers. However, there are still issues\nhindering its development, such as the severe co-channel interference among\nUAVs, and the limited payload/battery-life of UAVs. To address the challenges,\nwe propose an aerial communication system which enables system-level\nfull-duplex communication of multiple UAVs with lower hardware complexities\nthan ideal full-duplex communication systems. In the proposed system, each\nchannel is re-assigned to the uplink and downlink of a pair of UAVs, and each\nUAV employ a pair of separated channels for its uplink and downlink. The\nco-channel interference between UAVs that reuse same channels is eliminated by\nexploiting advantages of UAVs' maneuverability and high-gain directional\nantennas equipped in UAVs and ground stations, so that dedicated cancellers are\nnot necessary in the proposed system. The system design and performance\nanalysis are given, and the simulation results well agree with the designs.",
    "descriptor": "\nComments: The paper was accepted by IEEE Consumer Communications & Networking Conference (CCNC) 2022\n",
    "authors": [
      "Tao Yu",
      "Kiyomichi Araki",
      "Kei Sakaguchi"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.00176"
  },
  {
    "id": "arXiv:2202.00177",
    "title": "Spectrum Sharing between Directional-Antenna- Equipped UAV System and  Terrestrial Systems",
    "abstract": "Unmanned aerial vehicles (UAVs)-based applications, such as surveillance\nsystems and wireless relays, are attracting increasing attention from academia\nand industrial fields. The high-performance aerial communication system is one\nof the key enablers for them. However, due to the low attenuation of radio\nwaves in the air-to-ground channels, the interference between aerial and\nterrestrial communication systems would significantly deteriorate their\ncommunication performance and greatly limit the potential UAV applications. To\naddress the problem, in this paper, the spectrum sharing strategy between a\nmultiple UAV communication system, in which both UAVs and ground station (GS)\nare equipped with directional antennas, and terrestrial systems is proposed.\nThe GS position is selected and the flyable areas of the UAVs using certain\nspectrum resources are defined in advance using prior knowledge from spectrum\nmonitoring on terrestrial communication systems to minimize interference and\nmaximize the flyable areas of the UAVs instead of the low-efficient dynamic\nchannel sensing and allocation for interference elimination. The simulations\nare conducted through a case study of the spectrum sharing between a multi-UAV\nvideo transmission system and the terrestrial wireless local area network\n(WLAN) system in the 5.7GHz band. The simulation results show that thanks to\nthe proposed system the entire area can be enabled for UAV flight.",
    "descriptor": "\nComments: This paper was accepted by IEEE Annual Computing and Communication Workshop and Conference (CCWC) 2022\n",
    "authors": [
      "Tao Yu",
      "Kento Kajiwara",
      "Kiyomichi Araki",
      "Kei Sakaguchi"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.00177"
  },
  {
    "id": "arXiv:2202.00181",
    "title": "CLA-NeRF: Category-Level Articulated Neural Radiance Field",
    "abstract": "We propose CLA-NeRF -- a Category-Level Articulated Neural Radiance Field\nthat can perform view synthesis, part segmentation, and articulated pose\nestimation. CLA-NeRF is trained at the object category level using no CAD\nmodels and no depth, but a set of RGB images with ground truth camera poses and\npart segments. During inference, it only takes a few RGB views (i.e., few-shot)\nof an unseen 3D object instance within the known category to infer the object\npart segmentation and the neural radiance field. Given an articulated pose as\ninput, CLA-NeRF can perform articulation-aware volume rendering to generate the\ncorresponding RGB image at any camera pose. Moreover, the articulated pose of\nan object can be estimated via inverse rendering. In our experiments, we\nevaluate the framework across five categories on both synthetic and real-world\ndata. In all cases, our method shows realistic deformation results and accurate\narticulated pose estimation. We believe that both few-shot articulated object\nrendering and articulated pose estimation open doors for robots to perceive and\ninteract with unseen articulated objects.",
    "descriptor": "\nComments: accepted by ICRA 2022\n",
    "authors": [
      "Wei-Cheng Tseng",
      "Hung-Ju Liao",
      "Yen-Chen Lin",
      "Min Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computational Geometry (cs.CG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.00181"
  },
  {
    "id": "arXiv:2202.00182",
    "title": "Semi-supervised 3D Object Detection via Temporal Graph Neural Networks",
    "abstract": "3D object detection plays an important role in autonomous driving and other\nrobotics applications. However, these detectors usually require training on\nlarge amounts of annotated data that is expensive and time-consuming to\ncollect. Instead, we propose leveraging large amounts of unlabeled point cloud\nvideos by semi-supervised learning of 3D object detectors via temporal graph\nneural networks. Our insight is that temporal smoothing can create more\naccurate detection results on unlabeled data, and these smoothed detections can\nthen be used to retrain the detector. We learn to perform this temporal\nreasoning with a graph neural network, where edges represent the relationship\nbetween candidate detections in different time frames. After semi-supervised\nlearning, our method achieves state-of-the-art detection performance on the\nchallenging nuScenes and H3D benchmarks, compared to baselines trained on the\nsame amount of labeled data. Project and code are released at\nhttps://www.jianrenw.com/SOD-TGNN/.",
    "descriptor": "\nComments: 3DV 2021\n",
    "authors": [
      "Jianren Wang",
      "Haiming Gang",
      "Siddarth Ancha",
      "Yi-Ting Chen",
      "David Held"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.00182"
  },
  {
    "id": "arXiv:2202.00183",
    "title": "Mixed Variational Finite Elements for Implicit, General-Purpose  Simulation of Deformables",
    "abstract": "We propose and explore a new, general-purpose method for the implicit time\nintegration of elastica. Key to our approach is the use of a mixed variational\nprinciple. In turn its finite element discretization leads to an efficient\nalternating projections solver with a superset of the desirable properties of\nmany previous fast solution strategies. This framework fits a range of elastic\nconstitutive models and remains stable across a wide span of timestep sizes,\nmaterial parameters (including problems that are quasi-static and approximately\nrigid). It is efficient to evaluate and easily applicable to volume, surface,\nand rods models. We demonstrate the efficacy of our approach on a number of\nsimulated examples across all three codomains.",
    "descriptor": "",
    "authors": [
      "Ty Trust",
      "Danny M. Kaufman",
      "David I W Levin"
    ],
    "subjectives": [
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2202.00183"
  },
  {
    "id": "arXiv:2202.00185",
    "title": "ATEK: Augmenting Transformers with Expert Knowledge for Indoor Layout  Synthesis",
    "abstract": "We address the problem of indoor layout synthesis, which is a topic of\ncontinuing research interest in computer graphics. The newest works made\nsignificant progress using data-driven generative methods; however, these\napproaches rely on suitable datasets. In practice, desirable layout properties\nmay not exist in a dataset, for instance, specific expert knowledge can be\nmissing in the data. We propose a method that combines expert knowledge, for\nexample, knowledge about ergonomics, with a data-driven generator based on the\npopular Transformer architecture. The knowledge is given as differentiable\nscalar functions, which can be used both as weights or as additional terms in\nthe loss function. Using this knowledge, the synthesized layouts can be biased\nto exhibit desirable properties, even if these properties are not present in\nthe dataset. Our approach can also alleviate problems of lack of data and\nimperfections in the data. Our work aims to improve generative machine learning\nfor modeling and provide novel tools for designers and amateurs for the problem\nof interior layout creation.",
    "descriptor": "\nComments: 18 pages including appendix and supplementary figures, 18 figures, preprint submitted to peer-review\n",
    "authors": [
      "Kurt Leimer",
      "Paul Guerrero",
      "Tomer Weiss",
      "Przemyslaw Musialski"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.00185"
  },
  {
    "id": "arXiv:2202.00195",
    "title": "Federated Active Learning (F-AL): an Efficient Annotation Strategy for  Federated Learning",
    "abstract": "Federated learning (FL) has been intensively investigated in terms of\ncommunication efficiency, privacy, and fairness. However, efficient annotation,\nwhich is a pain point in real-world FL applications, is less studied. In this\nproject, we propose to apply active learning (AL) and sampling strategy into\nthe FL framework to reduce the annotation workload. We expect that the AL and\nFL can improve the performance of each other complementarily. In our proposed\nfederated active learning (F-AL) method, the clients collaboratively implement\nthe AL to obtain the instances which are considered as informative to FL in a\ndistributed optimization manner. We compare the test accuracies of the global\nFL models using the conventional random sampling strategy, client-level\nseparate AL (S-AL), and the proposed F-AL. We empirically demonstrate that the\nF-AL outperforms baseline methods in image classification tasks.",
    "descriptor": "\nComments: 13 pages, 9 figures, submitted for conference publication\n",
    "authors": [
      "Jin-Hyun Ahn",
      "Kyungsang Kim",
      "Jeongwan Koh",
      "Quanzheng Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.00195"
  },
  {
    "id": "arXiv:2202.00199",
    "title": "RFUniverse: A Physics-based Action-centric Interactive Environment for  Everyday Household Tasks",
    "abstract": "Household environments are important testbeds for embodied AI research. Many\nsimulation environments have been proposed to develop learning models for\nsolving everyday household tasks. However, though interactions are paid\nattention to in most environments, the actions operating on the objects are not\nwell supported concerning action types, object types, and interaction physics.\nTo bridge the gap at the action level, we propose a novel physics-based\naction-centric environment, RFUniverse, for robot learning of everyday\nhousehold tasks. RFUniverse supports interactions among 87 atomic actions and 8\nbasic object types in a visually and physically plausible way. To demonstrate\nthe usability of the simulation environment, we perform learning algorithms on\nvarious types of tasks, namely fruit-picking, cloth-folding and sponge-wiping\nfor manipulation, stair-chasing for locomotion, room-cleaning for multi-agent\ncollaboration, milk-pouring for task and motion planning, and bimanual-lifting\nfor behavior cloning from VR interface. Client-side Python APIs, learning\ncodes, models, and the database will be released. Demo video for atomic actions\ncan be found in supplementary materials:\n\\url{https://sites.google.com/view/rfuniverse}",
    "descriptor": "\nComments: Technical report\n",
    "authors": [
      "Haoyuan Fu",
      "Wenqiang Xu",
      "Han Xue",
      "Huinan Yang",
      "Ruolin Ye",
      "Yongxi Huang",
      "Zhendong Xue",
      "Yanfeng Wang",
      "Cewu Lu"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.00199"
  },
  {
    "id": "arXiv:2202.00200",
    "title": "Differentiable Digital Signal Processing Mixture Model for Synthesis  Parameter Extraction from Mixture of Harmonic Sounds",
    "abstract": "A differentiable digital signal processing (DDSP) autoencoder is a musical\nsound synthesizer that combines a deep neural network (DNN) and spectral\nmodeling synthesis. It allows us to flexibly edit sounds by changing the\nfundamental frequency, timbre feature, and loudness (synthesis parameters)\nextracted from an input sound. However, it is designed for a monophonic\nharmonic sound and cannot handle mixtures of harmonic sounds. In this paper, we\npropose a model (DDSP mixture model) that represents a mixture as the sum of\nthe outputs of multiple pretrained DDSP autoencoders. By fitting the output of\nthe proposed model to the observed mixture, we can directly estimate the\nsynthesis parameters of each source. Through synthesis parameter extraction\nexperiments, we show that the proposed method has high and stable performance\ncompared with a straightforward method that applies the DDSP autoencoder to the\nsignals separated by an audio source separation method.",
    "descriptor": "\nComments: 5 pages, 2 figures, to appear in 2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP 2022)\n",
    "authors": [
      "Masaya Kawamura",
      "Tomohiko Nakamura",
      "Daichi Kitamura",
      "Hiroshi Saruwatari",
      "Yu Takahashi",
      "Kazunobu Kondo"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2202.00200"
  },
  {
    "id": "arXiv:2202.00206",
    "title": "A pilot study of the Earable device to measure facial muscle and eye  movement tasks among healthy volunteers",
    "abstract": "Many neuromuscular disorders impair function of cranial nerve enervated\nmuscles. Clinical assessment of cranial muscle function has several\nlimitations. Clinician rating of symptoms suffers from inter-rater variation,\nqualitative or semi-quantitative scoring, and limited ability to capture\ninfrequent or fluctuating symptoms. Patient-reported outcomes are limited by\nrecall bias and poor precision. Current tools to measure orofacial and\noculomotor function are cumbersome, difficult to implement, and non-portable.\nHere, we show how Earable, a wearable device, can discriminate certain cranial\nmuscle activities such as chewing, talking, and swallowing. We demonstrate\nusing data from a pilot study of 10 healthy participants how Earable can be\nused to measure features from EMG, EEG, and EOG waveforms from subjects\nperforming mock Performance Outcome Assessments (mock-PerfOs), utilized widely\nin clinical research. Our analysis pipeline provides a framework for how to\ncomputationally process and statistically rank features from the Earable\ndevice. Finally, we demonstrate that Earable data may be used to classify these\nactivities. Our results, conducted in a pilot study of healthy participants,\nenable a more comprehensive strategy for the design, development, and analysis\nof wearable sensor data for investigating clinical populations. Additionally,\nthe results from this study support further evaluation of Earable or similar\ndevices as tools to objectively measure cranial muscle activity in the context\nof a clinical research setting. Future work will be conducted in clinical\ndisease populations, with a focus on detecting disease signatures, as well as\nmonitoring intra-subject treatment responses. Readily available quantitative\nmetrics from wearable sensor devices like Earable support strategies for the\ndevelopment of novel digital endpoints, a hallmark goal of clinical research.",
    "descriptor": "",
    "authors": [
      "Matthew F. Wipperman",
      "Galen Pogoncheff",
      "Katrina F. Mateo",
      "Xuefang Wu",
      "Yiziying Chen",
      "Oren Levy",
      "Andreja Avbersek",
      "Robin R. Deterding",
      "Sara C. Hamon",
      "Tam Vu",
      "Rinol Alaj",
      "Olivier Harari"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Signal Processing (eess.SP)",
      "Quantitative Methods (q-bio.QM)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2202.00206"
  },
  {
    "id": "arXiv:2202.00210",
    "title": "INPUT Team Description Paper in 2022",
    "abstract": "INPUT is a team participating in the RoboCup Soccer Small League (SSL). It\naims to show the world the technological capabilities of the Nagaoka region of\nNiigata Prefecture, which is where the team members are from. For this purpose,\nwe are working on one of the projects from the Nagaoka Activation Zone of\nEnergy (NAZE). Herein, we introduce two robots, v2019 and v2022, as well as AI\nsystems that will be used in RoboCup 2022. In addition, we describe our efforts\nto develop robots in collaboration with companies in the Nagaoka area.",
    "descriptor": "",
    "authors": [
      "Masaki Yasuhara",
      "Tomoya Takahashi",
      "Hiroki Maruta",
      "Hiroyuki Saito",
      "Shota Higuchi",
      "Takaaki Nara",
      "Keitaro Takeuchi",
      "Yota Sakai",
      "Kazuki Ishibashi"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.00210"
  },
  {
    "id": "arXiv:2202.00211",
    "title": "GNNRank: Learning Global Rankings from Pairwise Comparisons via Directed  Graph Neural Networks",
    "abstract": "Recovering global rankings from pairwise comparisons is an important problem\nwith many applications, ranging from time synchronization to sports team\nranking. Pairwise comparisons corresponding to matches in a competition can\nnaturally be construed as edges in a directed graph (digraph), whose nodes\nrepresent competitors with an unknown rank or skill strength. However, existing\nmethods addressing the rank estimation problem have thus far not utilized\npowerful neural network architectures to optimize ranking objectives. Hence, we\npropose to augment an algorithm with neural network, in particular graph neural\nnetwork (GNN) for its coherence to the problem at hand. In this paper, we\nintroduce GNNRank, a modeling framework that is compatible with any GNN capable\nof learning digraph embeddings, and we devise trainable objectives to encode\nranking upsets/violations. This framework includes a ranking score estimation\napproach, and adds a useful inductive bias by unfolding the Fiedler vector\ncomputation of the graph constructed from a learnable similarity matrix.\nExperimental results on a wide range of data sets show that our methods attain\ncompetitive and often superior performance compared with existing approaches.\nIt also shows promising transfer ability to new data based on the trained GNN\nmodel.",
    "descriptor": "\nComments: 33 pages (8 pages for main text)\n",
    "authors": [
      "Yixuan He",
      "Quan Gan",
      "David Wipf",
      "Gesine Reinert",
      "Junchi Yan",
      "Mihai Cucuringu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.00211"
  },
  {
    "id": "arXiv:2202.00216",
    "title": "Semantic Annotation and Querying Framework based on Semi-structured  Ayurvedic Text",
    "abstract": "Knowledge bases (KB) are an important resource in a number of natural\nlanguage processing (NLP) and information retrieval (IR) tasks, such as\nsemantic search, automated question-answering etc. They are also useful for\nresearchers trying to gain information from a text. Unfortunately, however, the\nstate-of-the-art in Sanskrit NLP does not yet allow automated construction of\nknowledge bases due to unavailability or lack of sufficient accuracy of tools\nand methods. Thus, in this work, we describe our efforts on manual annotation\nof Sanskrit text for the purpose of knowledge graph (KG) creation. We choose\nthe chapter Dhanyavarga from Bhavaprakashanighantu of the Ayurvedic text\nBhavaprakasha for annotation. The constructed knowledge graph contains 410\nentities and 764 relationships. Since Bhavaprakashanighantu is a technical\nglossary text that describes various properties of different substances, we\ndevelop an elaborate ontology to capture the semantics of the entity and\nrelationship types present in the text. To query the knowledge graph, we design\n31 query templates that cover most of the common question patterns. For both\nmanual annotation and querying, we customize the Sangrahaka framework\npreviously developed by us. The entire system including the dataset is\navailable from https://sanskrit.iitk.ac.in/ayurveda/ . We hope that the\nknowledge graph that we have created through manual annotation and subsequent\ncuration will help in development and testing of NLP tools in future as well as\nstudying of the Bhavaprakasanighantu text.",
    "descriptor": "\nComments: 19 pages including appendix\n",
    "authors": [
      "Hrishikesh Terdalkar",
      "Arnab Bhattacharya",
      "Madhulika Dubey",
      "Ramamurthy S",
      "Bhavna Naneria Singh"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.00216"
  },
  {
    "id": "arXiv:2202.00217",
    "title": "WebFormer: The Web-page Transformer for Structure Information Extraction",
    "abstract": "Structure information extraction refers to the task of extracting structured\ntext fields from web pages, such as extracting a product offer from a shopping\npage including product title, description, brand and price. It is an important\nresearch topic which has been widely studied in document understanding and web\nsearch. Recent natural language models with sequence modeling have demonstrated\nstate-of-the-art performance on web information extraction. However,\neffectively serializing tokens from unstructured web pages is challenging in\npractice due to a variety of web layout patterns. Limited work has focused on\nmodeling the web layout for extracting the text fields. In this paper, we\nintroduce WebFormer, a Web-page transFormer model for structure information\nextraction from web documents. First, we design HTML tokens for each DOM node\nin the HTML by embedding representations from their neighboring tokens through\ngraph attention. Second, we construct rich attention patterns between HTML\ntokens and text tokens, which leverages the web layout for effective attention\nweight computation. We conduct an extensive set of experiments on SWDE and\nCommon Crawl benchmarks. Experimental results demonstrate the superior\nperformance of the proposed approach over several state-of-the-art methods.",
    "descriptor": "\nComments: Accepted to WWW 2022\n",
    "authors": [
      "Qifan Wang",
      "Yi Fang",
      "Anirudh Ravula",
      "Fuli Feng",
      "Xiaojun Quan",
      "Dongfang Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.00217"
  },
  {
    "id": "arXiv:2202.00224",
    "title": "Blockchain in the Quantum World",
    "abstract": "Blockchain is one of the most discussed and highly accepted technologies,\nprimarily due to its application in almost every field where third parties are\nneeded for trust. Blockchain technology relies on distributed consensus for\ntrust, which is accomplished using hash functions and public-key cryptography.\nMost of the cryptographic algorithms in use today are vulnerable to quantum\nattacks. In this work, a systematic literature review is done so that it can be\nrepeated, starting with identifying the research questions. Focusing on these\nresearch questions, literature is analysed to find the answers to these\nquestions. The survey is completed by answering the research questions and\nidentification of the research gaps. It is found in the literature that 30% of\nthe research solutions are applicable for the data layer, 24% for the\napplication and presentation layer, 23% for the network layer, 16% for the\nconsensus layer and only 1% for hardware and infrastructure layer. We also\nfound that 6% of the solutions are not blockchain-based but present different\ndistributed ledger technology.",
    "descriptor": "\nComments: 11 pages, 4 figures\n",
    "authors": [
      "Arman Rasoodl Faridi",
      "Faraz Masood",
      "Ali Haider Thabet Shamsan",
      "Mohammad Luqman",
      "Monir Yahya Salmony"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.00224"
  },
  {
    "id": "arXiv:2202.00237",
    "title": "Kernelized Multiplicative Weights for 0/1-Polyhedral Games: Bridging the  Gap Between Learning in Extensive-Form and Normal-Form Games",
    "abstract": "While extensive-form games (EFGs) can be converted into normal-form games\n(NFGs), doing so comes at the cost of an exponential blowup of the strategy\nspace. So, progress on NFGs and EFGs has historically followed separate tracks,\nwith the EFG community often having to catch up with advances (e.g.,\nlast-iterate convergence and predictive regret bounds) from the larger NFG\ncommunity. In this paper we show that the Optimistic Multiplicative Weights\nUpdate (OMWU) algorithm -- the premier learning algorithm for NFGs -- can be\nsimulated on the normal-form equivalent of an EFG in linear time per iteration\nin the game tree size using a kernel trick. The resulting algorithm, Kernelized\nOMWU (KOMWU), applies more broadly to all convex games whose strategy space is\na polytope with 0/1 integral vertices, as long as the kernel can be evaluated\nefficiently. In the particular case of EFGs, KOMWU closes several standing gaps\nbetween NFG and EFG learning, by enabling direct, black-box transfer to EFGs of\ndesirable properties of learning dynamics that were so far known to be\nachievable only in NFGs. Specifically, KOMWU gives the first algorithm that\nguarantees at the same time last-iterate convergence, lower dependence on the\nsize of the game tree than all prior algorithms, and $\\tilde{\\mathcal{O}}(1)$\nregret when followed by all players.",
    "descriptor": "",
    "authors": [
      "Gabriele Farina",
      "Chung-Wei Lee",
      "Haipeng Luo",
      "Christian Kroer"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.00237"
  },
  {
    "id": "arXiv:2202.00240",
    "title": "On List Decoding Transitive Codes From Random Errors",
    "abstract": "We study the error resilience of transitive linear codes over $\\mathbb{F}_2$.\nWe give tight bounds on the weight distribution of every such code $C$, and we\nshow how these bounds can be used to infer bounds on the error rates that $C$\ncan tolerate on the binary symmetric channel. Using this connection, we show\nthat every transitive code can be list-decoded from random errors. As an\napplication, our results imply list-decoding bounds for Reed-Muller codes even\nwhen the rate exceeds the channel capacity.",
    "descriptor": "",
    "authors": [
      "Anup Rao",
      "Oscar Sprumont"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.00240"
  },
  {
    "id": "arXiv:2202.00242",
    "title": "Globally Consistent and Tightly Coupled 3D LiDAR Inertial Mapping",
    "abstract": "This paper presents a real-time 3D mapping framework based on global matching\ncost minimization and LiDAR-IMU tight coupling. The proposed framework\ncomprises a preprocessing module and three estimation modules: odometry\nestimation, local mapping, and global mapping, which are all based on the tight\ncoupling of the GPU-accelerated voxelized GICP matching cost factor and the IMU\npreintegration factor. The odometry estimation module employs a keyframe-based\nfixed-lag smoothing approach for efficient and low-drift trajectory estimation,\nwith a bounded computation cost. The global mapping module constructs a factor\ngraph that minimizes the global registration error over the entire map with the\nsupport of IMU constraints, ensuring robust optimization in feature-less\nenvironments. The evaluation results on the Newer College dataset and KAIST\nurban dataset show that the proposed framework enables accurate and robust\nlocalization and mapping in challenging environments.",
    "descriptor": "\nComments: IEEE International Conference on Robotics and Automation (ICRA2022) Video: this https URL\n",
    "authors": [
      "Kenji Koide",
      "Masashi Yokozuka",
      "Shuji Oishi",
      "Atsuhiko Banno"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.00242"
  },
  {
    "id": "arXiv:2202.00243",
    "title": "Adversarial Imitation Learning from Video using a State Observer",
    "abstract": "The imitation learning research community has recently made significant\nprogress towards the goal of enabling artificial agents to imitate behaviors\nfrom video demonstrations alone. However, current state-of-the-art approaches\ndeveloped for this problem exhibit high sample complexity due, in part, to the\nhigh-dimensional nature of video observations. Towards addressing this issue,\nwe introduce here a new algorithm called Visual Generative Adversarial\nImitation from Observation using a State Observer VGAIfO-SO. At its core,\nVGAIfO-SO seeks to address sample inefficiency using a novel, self-supervised\nstate observer, which provides estimates of lower-dimensional proprioceptive\nstate representations from high-dimensional images. We show experimentally in\nseveral continuous control environments that VGAIfO-SO is more sample efficient\nthan other IfO algorithms at learning from video-only demonstrations and can\nsometimes even achieve performance close to the Generative Adversarial\nImitation from Observation (GAIfO) algorithm that has privileged access to the\ndemonstrator's proprioceptive state information.",
    "descriptor": "",
    "authors": [
      "Haresh Karnan",
      "Garrett Warnell",
      "Faraz Torabi",
      "Peter Stone"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.00243"
  },
  {
    "id": "arXiv:2202.00245",
    "title": "Sequential Search with Off-Policy Reinforcement Learning",
    "abstract": "Recent years have seen a significant amount of interests in Sequential\nRecommendation (SR), which aims to understand and model the sequential user\nbehaviors and the interactions between users and items over time. Surprisingly,\ndespite the huge success Sequential Recommendation has achieved, there is\nlittle study on Sequential Search (SS), a twin learning task that takes into\naccount a user's current and past search queries, in addition to behavior on\nhistorical query sessions. The SS learning task is even more important than the\ncounterpart SR task for most of E-commence companies due to its much larger\nonline serving demands as well as traffic volume.\nTo this end, we propose a highly scalable hybrid learning model that consists\nof an RNN learning framework leveraging all features in short-term user-item\ninteractions, and an attention model utilizing selected item-only features from\nlong-term interactions. As a novel optimization step, we fit multiple short\nuser sequences in a single RNN pass within a training batch, by solving a\ngreedy knapsack problem on the fly. Moreover, we explore the use of off-policy\nreinforcement learning in multi-session personalized search ranking.\nSpecifically, we design a pairwise Deep Deterministic Policy Gradient model\nthat efficiently captures users' long term reward in terms of pairwise\nclassification error. Extensive ablation experiments demonstrate significant\nimprovement each component brings to its state-of-the-art baseline, on a\nvariety of offline and online metrics.",
    "descriptor": "\nComments: 10 pages, 7 figures, CIKM 2021\n",
    "authors": [
      "Dadong Miao",
      "Yanan Wang",
      "Guoyu Tang",
      "Lin Liu",
      "Sulong Xu",
      "Bo Long",
      "Yun Xiao",
      "Lingfei Wu",
      "Yunjiang Jiang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.00245"
  },
  {
    "id": "arXiv:2202.00247",
    "title": "ZEL: Net-Zero-Energy Lifelogging System using Heterogeneous Energy  Harvesters",
    "abstract": "We present ZEL, the first net-zero-energy lifelogging system that allows\noffice workers to collect semi-permanent records of when, where, and what\nactivities they perform on company premises. ZEL achieves high accuracy\nlifelogging by using heterogeneous energy harvesters with different\ncharacteristics. The system is based on a 192-gram nametag-shaped wearable\ndevice worn by each employee that is equipped with two comparators to enable\nseamless switching between system states, thereby minimizing the battery usage\nand enabling net-zero-energy, semi-permanent data collection. To demonstrate\nthe effectiveness of our system, we conducted data collection experiments with\n11 participants in a practical environment and found that the person-dependent\n(PD) model achieves an 8-place recognition accuracy level of 87.2% (weighted\nF-measure) and a static/dynamic activities recognition accuracy level of 93.1%\n(weighted F-measure). Additional testing confirmed the practical long-term\noperability of the system and showed it could achieve a zero-energy operation\nrate of 99.6% i.e., net-zero-energy operation.",
    "descriptor": "\nComments: 8 pages, 8 figures, Accepted to IEEE PerCom 2022\n",
    "authors": [
      "Mitsuru Arita",
      "Yugo Nakamura",
      "Shigemi Ishida",
      "Yutaka Arakawa"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2202.00247"
  },
  {
    "id": "arXiv:2202.00248",
    "title": "Entanglement-Assisted Quantum Error-Correcting Codes over Local  Frobenius Rings",
    "abstract": "In this paper, we provide a framework for constructing entanglement-assisted\nquantum error-correcting codes (EAQECCs) from classical additive codes over a\nfinite commutative local Frobenius ring. We derive a formula for the minimum\nnumber of entanglement qudits required to construct an EAQECC from a linear\ncode over the ring $\\mathbb{Z}_{p^s}$. This is used to obtain an exact\nexpression for the minimum number of entanglement qudits required to construct\nan EAQECC from an additive code over a Galois ring, which significantly extends\nknown results for EAQECCs over finite fields.",
    "descriptor": "\nComments: 16 pages, long version of paper submitted to ISIT 2022\n",
    "authors": [
      "Tania Sidana",
      "Navin Kashyap"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2202.00248"
  },
  {
    "id": "arXiv:2202.00250",
    "title": "Securing the data in cloud using Algebra Homomorphic Encryption scheme  based on updated Elgamal(AHEE)",
    "abstract": "Cloud computing is the broad and diverse phenomenon. Users are allowed to\nstore huge amount of data on cloud storage for future use. Most of the cloud\nservice providers store data in plain text format or in secured manner but\nclient will not be known the method in which it is stored. Homomorphic\nencryption is the encryption which allows the operation on cipher text thus\ngenerating an encrypted result which when decrypted, matches the result of\noperations performed on the plaintext. This is sometimes a desirable feature in\nmodern communication system architectures. There are several homomorphic\nalgorithms, one of them is AHEE. User need to use their own encryption\nalgorithm to secure their data if required. The data needs to be decrypted\nwhenever it is to be processed. In this paper, we have focused on providing\nsecurity to the client using AHEE algorithm at the client side, for any data to\nbe stored in the cloud.",
    "descriptor": "\nComments: Accepted and Published in the International Journal of Emerging Trends & Technology in Computer Science (IJETTCS). Volume 6, Issue 3, May- June 2017\n",
    "authors": [
      "Fahina",
      "Shwetha U",
      "Poorna",
      "Supriya",
      "Rama Moorthy H",
      "Dr.Vasudeva"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.00250"
  },
  {
    "id": "arXiv:2202.00251",
    "title": "A Novel Algorithm In Steganography Using Weighted Matching Technique",
    "abstract": "In recent years, the security related to data over the internet has become a\nmajor issue. Different techniques are used to secure the information, one such\ntechnique is steganography. In steganography, one can have a cover media as an\nimage, video or audio. Here we are proposing a method of weighted matching\ntechnique in which we examine higher bits of lower nibble of a byte and find\nthe highest occurrence bit. The PSNR values of both the algorithms are\ntabulated for evaluation purpose.",
    "descriptor": "\nComments: Accepted and Published in the International Journal of Emerging Trends & Technology in Computer Science (IJETTCS). Volume 6, Issue 3, May- June 2017\n",
    "authors": [
      "P N Priya",
      "R Ranjitha",
      "Yashaswini Naik",
      "Shrilekha",
      "Rama Moorthy H"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.00251"
  },
  {
    "id": "arXiv:2202.00253",
    "title": "A Novel Pair and Matching Algorithm for Embedding Secret Messages in  Images",
    "abstract": "Steganography has proven to be one of the practical way of securing data. It\nis a new kind of secret communication used to hide secret data inside other\ninnocent digital mediums. There are various algorithms for pair and matching\ntechnique. One such method uses two bits of secret message to be matched with\ncover image bits. Algorithm had used only 2 pairs to be mapped. Thus limiting\nthe matching to 6 bits per pixel. Here in our proposed algorithm we are\nmatching 3 bits at a time. Thus in the best case scenario we can match up to 9\nbits per pixel. It is also a good foundation to build more secure communication\nin today s data centric world.",
    "descriptor": "\nComments: Accepted and Published in the International Journal of Emerging Trends & Technology in Computer Science (IJETTCS). Volume 6, Issue 3, May- June 2017\n",
    "authors": [
      "P N Priya",
      "R Ranjitha",
      "Yashaswini Naik",
      "Shrilekha",
      "Rama Moorthy H"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2202.00253"
  },
  {
    "id": "arXiv:2202.00254",
    "title": "Active Learning Over Multiple Domains in Natural Language Tasks",
    "abstract": "Studies of active learning traditionally assume the target and source data\nstem from a single domain. However, in realistic applications, practitioners\noften require active learning with multiple sources of out-of-distribution\ndata, where it is unclear a priori which data sources will help or hurt the\ntarget domain. We survey a wide variety of techniques in active learning (AL),\ndomain shift detection (DS), and multi-domain sampling to examine this\nchallenging setting for question answering and sentiment analysis. We ask (1)\nwhat family of methods are effective for this task? And, (2) what properties of\nselected examples and domains achieve strong results? Among 18 acquisition\nfunctions from 4 families of methods, we find H- Divergence methods, and\nparticularly our proposed variant DAL-E, yield effective results, averaging\n2-3% improvements over the random baseline. We also show the importance of a\ndiverse allocation of domains, as well as room-for-improvement of existing\nmethods on both domain and example selection. Our findings yield the first\ncomprehensive analysis of both existing and novel methods for practitioners\nfaced with multi-domain active learning for natural language tasks.",
    "descriptor": "",
    "authors": [
      "Shayne Longpre",
      "Julia Reisler",
      "Edward Greg Huang",
      "Yi Lu",
      "Andrew Frank",
      "Nikhil Ramesh",
      "Chris DuBois"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.00254"
  },
  {
    "id": "arXiv:2202.00255",
    "title": "DoCoM-SGT: Doubly Compressed Momentum-assisted Stochastic Gradient  Tracking Algorithm for Communication Efficient Decentralized Learning",
    "abstract": "This paper proposes the Doubly Compressed Momentum-assisted Stochastic\nGradient Tracking algorithm (DoCoM-SGT) for communication efficient\ndecentralized learning. DoCoM-SGT utilizes two compression steps per\ncommunication round as the algorithm tracks simultaneously the averaged iterate\nand stochastic gradient. Furthermore, DoCoM-SGT incorporates a momentum based\ntechnique for reducing variances in the gradient estimates. We show that\nDoCoM-SGT finds a solution $\\bar{\\theta}$ in $T$ iterations satisfying\n$\\mathbb{E} [ \\| \\nabla f(\\bar{\\theta}) \\|^2 ] = {\\cal O}( 1 / T^{2/3} )$ for\nnon-convex objective functions; and we provide competitive convergence rate\nguarantees for other function classes. Numerical experiments on synthetic and\nreal datasets validate the efficacy of our algorithm.",
    "descriptor": "",
    "authors": [
      "Chung-Yiu Yau",
      "Hoi-To Wai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Data Structures and Algorithms (cs.DS)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2202.00255"
  },
  {
    "id": "arXiv:2202.00257",
    "title": "Position-Dependent Snap Feedforward: A Gaussian Process Framework",
    "abstract": "Mechatronic systems have increasingly high performance requirements for\nmotion control. The low-frequency contribution of the flexible dynamics, i.e.\nthe compliance, should be compensated for by means of snap feedforward to\nachieve high accuracy. Position-dependent compliance, which often occurs in\nmotion systems, requires the snap feedforward parameter to be modeled as a\nfunction of position. Position-dependent compliance is compensated for by using\na Gaussian process to model the snap feedforward parameter as a continuous\nfunction of position. A simulation of a flexible beam shows that a significant\nperformance increase is achieved when using the Gaussian process snap\nfeedforward parameter to compensate for position-dependent compliance.",
    "descriptor": "\nComments: To appear in: 2022 IEEE American Control Conference. arXiv admin note: text overlap with arXiv:2201.07511\n",
    "authors": [
      "Max van Haren",
      "Maurice Poot",
      "Jim Portegies",
      "Tom Oomen"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.00257"
  },
  {
    "id": "arXiv:2202.00259",
    "title": "Detecting Human-Object Interactions with Object-Guided Cross-Modal  Calibrated Semantics",
    "abstract": "Human-Object Interaction (HOI) detection is an essential task to understand\nhuman-centric images from a fine-grained perspective. Although end-to-end HOI\ndetection models thrive, their paradigm of parallel human/object detection and\nverb class prediction loses two-stage methods' merit: object-guided hierarchy.\nThe object in one HOI triplet gives direct clues to the verb to be predicted.\nIn this paper, we aim to boost end-to-end models with object-guided statistical\npriors. Specifically, We propose to utilize a Verb Semantic Model (VSM) and use\nsemantic aggregation to profit from this object-guided hierarchy. Similarity KL\n(SKL) loss is proposed to optimize VSM to align with the HOI dataset's priors.\nTo overcome the static semantic embedding problem, we propose to generate\ncross-modality-aware visual and semantic features by Cross-Modal Calibration\n(CMC). The above modules combined composes Object-guided Cross-modal\nCalibration Network (OCN). Experiments conducted on two popular HOI detection\nbenchmarks demonstrate the significance of incorporating the statistical prior\nknowledge and produce state-of-the-art performances. More detailed analysis\nindicates proposed modules serve as a stronger verb predictor and a more\nsuperior method of utilizing prior knowledge. The codes are available at\n\\url{https://github.com/JacobYuan7/OCN-HOI-Benchmark}.",
    "descriptor": "\nComments: Accepted to AAAI2022\n",
    "authors": [
      "Hangjie Yuan",
      "Mang Wang",
      "Dong Ni",
      "Liangpeng Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.00259"
  },
  {
    "id": "arXiv:2202.00263",
    "title": "Fully Online Meta-Learning Without Task Boundaries",
    "abstract": "While deep networks can learn complex functions such as classifiers,\ndetectors, and trackers, many applications require models that continually\nadapt to changing input distributions, changing tasks, and changing\nenvironmental conditions. Indeed, this ability to continuously accrue knowledge\nand use past experience to learn new tasks quickly in continual settings is one\nof the key properties of an intelligent system. For complex and\nhigh-dimensional problems, simply updating the model continually with standard\nlearning algorithms such as gradient descent may result in slow adaptation.\nMeta-learning can provide a powerful tool to accelerate adaptation yet is\nconventionally studied in batch settings. In this paper, we study how\nmeta-learning can be applied to tackle online problems of this nature,\nsimultaneously adapting to changing tasks and input distributions and\nmeta-training the model in order to adapt more quickly in the future. Extending\nmeta-learning into the online setting presents its own challenges, and although\nseveral prior methods have studied related problems, they generally require a\ndiscrete notion of tasks, with known ground-truth task boundaries. Such methods\ntypically adapt to each task in sequence, resetting the model between tasks,\nrather than adapting continuously across tasks. In many real-world settings,\nsuch discrete boundaries are unavailable, and may not even exist. To address\nthese settings, we propose a Fully Online Meta-Learning (FOML) algorithm, which\ndoes not require any ground truth knowledge about the task boundaries and stays\nfully online without resetting back to pre-trained weights. Our experiments\nshow that FOML was able to learn new tasks faster than the state-of-the-art\nonline learning methods on Rainbow-MNIST, CIFAR100 and CELEBA datasets.",
    "descriptor": "",
    "authors": [
      "Jathushan Rajasegaran",
      "Chesea Finn",
      "Sergey Levine"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.00263"
  },
  {
    "id": "arXiv:2202.00264",
    "title": "Graph-based Neural Acceleration for Nonnegative Matrix Factorization",
    "abstract": "We describe a graph-based neural acceleration technique for nonnegative\nmatrix factorization that builds upon a connection between matrices and\nbipartite graphs that is well-known in certain fields, e.g., sparse linear\nalgebra, but has not yet been exploited to design graph neural networks for\nmatrix computations. We first consider low-rank factorization more broadly and\npropose a graph representation of the problem suited for graph neural networks.\nThen, we focus on the task of nonnegative matrix factorization and propose a\ngraph neural network that interleaves bipartite self-attention layers with\nupdates based on the alternating direction method of multipliers. Our empirical\nevaluation on synthetic and two real-world datasets shows that we attain\nsubstantial acceleration, even though we only train in an unsupervised fashion\non smaller synthetic instances.",
    "descriptor": "\nComments: Authors contributed equally\n",
    "authors": [
      "Jens Sj\u00f6lund",
      "Maria B\u00e5nkestad"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.00264"
  },
  {
    "id": "arXiv:2202.00265",
    "title": "Access Control of Object Detection Models Using Encrypted Feature Maps",
    "abstract": "In this paper, we propose an access control method for object detection\nmodels. The use of encrypted images or encrypted feature maps has been\ndemonstrated to be effective in access control of models from unauthorized\naccess. However, the effectiveness of the approach has been confirmed in only\nimage classification models and semantic segmentation models, but not in object\ndetection models. In this paper, the use of encrypted feature maps is shown to\nbe effective in access control of object detection models for the first time.",
    "descriptor": "\nComments: To appear in 2022 IEEE 4th Global Conference on Life Sciences and Technologies (LifeTech 2022)\n",
    "authors": [
      "Teru Nagamori",
      "Hiroki Ito",
      "April Pyone Maung Maung",
      "Hitoshi Kiya"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.00265"
  },
  {
    "id": "arXiv:2202.00270",
    "title": "Factorized-FL: Agnostic Personalized Federated Learning with Kernel  Factorization & Similarity Matching",
    "abstract": "In real-world federated learning scenarios, participants could have their own\npersonalized labels which are incompatible with those from other clients, due\nto using different label permutations or tackling completely different tasks or\ndomains. However, most existing FL approaches cannot effectively tackle such\nextremely heterogeneous scenarios since they often assume that (1) all\nparticipants use a synchronized set of labels, and (2) they train on the same\ntask from the same domain. In this work, to tackle these challenges, we\nintroduce Factorized-FL, which allows to effectively tackle label- and\ntask-heterogeneous federated learning settings by factorizing the model\nparameters into a pair of vectors, where one captures the common knowledge\nacross different labels and tasks and the other captures knowledge specific to\nthe task each local model tackles. Moreover, based on the distance in the\nclient-specific vector space, Factorized-FL performs selective aggregation\nscheme to utilize only the knowledge from the relevant participants for each\nclient. We extensively validate our method on both label- and\ndomain-heterogeneous settings, on which it outperforms the state-of-the-art\npersonalized federated learning methods.",
    "descriptor": "",
    "authors": [
      "Wonyong Jeong",
      "Sung Ju Hwang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.00270"
  },
  {
    "id": "arXiv:2202.00273",
    "title": "StyleGAN-XL: Scaling StyleGAN to Large Diverse Datasets",
    "abstract": "Computer graphics has experienced a recent surge of data-centric approaches\nfor photorealistic and controllable content creation. StyleGAN in particular\nsets new standards for generative modeling regarding image quality and\ncontrollability. However, StyleGAN's performance severely degrades on large\nunstructured datasets such as ImageNet. StyleGAN was designed for\ncontrollability; hence, prior works suspect its restrictive design to be\nunsuitable for diverse datasets. In contrast, we find the main limiting factor\nto be the current training strategy. Following the recently introduced\nProjected GAN paradigm, we leverage powerful neural network priors and a\nprogressive growing strategy to successfully train the latest StyleGAN3\ngenerator on ImageNet. Our final model, StyleGAN-XL, sets a new\nstate-of-the-art on large-scale image synthesis and is the first to generate\nimages at a resolution of $1024^2$ at such a dataset scale. We demonstrate that\nthis model can invert and edit images beyond the narrow domain of portraits or\nspecific object classes.",
    "descriptor": "\nComments: Project Page: this https URL\n",
    "authors": [
      "Axel Sauer",
      "Katja Schwarz",
      "Andreas Geiger"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.00273"
  },
  {
    "id": "arXiv:2202.00275",
    "title": "Architecture Matters in Continual Learning",
    "abstract": "A large body of research in continual learning is devoted to overcoming the\ncatastrophic forgetting of neural networks by designing new algorithms that are\nrobust to the distribution shifts. However, the majority of these works are\nstrictly focused on the \"algorithmic\" part of continual learning for a \"fixed\nneural network architecture\", and the implications of using different\narchitectures are mostly neglected. Even the few existing continual learning\nmethods that modify the model assume a fixed architecture and aim to develop an\nalgorithm that efficiently uses the model throughout the learning experience.\nHowever, in this work, we show that the choice of architecture can\nsignificantly impact the continual learning performance, and different\narchitectures lead to different trade-offs between the ability to remember\nprevious tasks and learning new ones. Moreover, we study the impact of various\narchitectural decisions, and our findings entail best practices and\nrecommendations that can improve the continual learning performance.",
    "descriptor": "\nComments: preprint\n",
    "authors": [
      "Seyed Iman Mirzadeh",
      "Arslan Chaudhry",
      "Dong Yin",
      "Timothy Nguyen",
      "Razvan Pascanu",
      "Dilan Gorur",
      "Mehrdad Farajtabar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.00275"
  },
  {
    "id": "arXiv:2202.00279",
    "title": "Relative Transformation Estimation Based on Fusion of Odometry and UWB  Ranging Data",
    "abstract": "In this work, the problem of 4 degree-of-freedom (3D position and heading)\nrobot-to-robot relative frame transformation estimation using onboard odometry\nand inter-robot distance measurements is studied. Firstly, we present a\ntheoretical analysis of the problem, namely the derivation and interpretation\nof the Cramer-Rao Lower Bound (CRLB), the Fisher Information Matrix (FIM) and\nits determinant. Secondly, we propose optimization-based methods to solve the\nproblem, including a quadratically constrained quadratic programming (QCQP) and\nthe corresponding semidefinite programming (SDP) relaxation. Moreover, we\naddress practical issues that are ignored in previous works, such as accounting\nfor spatial-temporal offsets between the ultra-wideband (UWB) and odometry\nsensors, rejecting UWB outliers and checking for singular configurations before\ncommencing operation. Lastly, extensive simulations and real-life experiments\nwith aerial robots show that the proposed QCQP and SDP methods outperform\nstate-of-the-art methods, especially in geometrically poor or large measurement\nnoise conditions. In general, the QCQP method provides the best results at the\nexpense of computational time, while the SDP method runs much faster and is\nsufficiently accurate in most cases.",
    "descriptor": "",
    "authors": [
      "Thien Hoang Nguyen",
      "Lihua Xie"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.00279"
  },
  {
    "id": "arXiv:2202.00280",
    "title": "Recycling Model Updates in Federated Learning: Are Gradient Subspaces  Low-Rank?",
    "abstract": "In this paper, we question the rationale behind propagating large numbers of\nparameters through a distributed system during federated learning. We start by\nexamining the rank characteristics of the subspace spanned by gradients across\nepochs (i.e., the gradient-space) in centralized model training, and observe\nthat this gradient-space often consists of a few leading principal components\naccounting for an overwhelming majority (95-99%) of the explained variance.\nMotivated by this, we propose the \"Look-back Gradient Multiplier\" (LBGM)\nalgorithm, which exploits this low-rank property to enable gradient recycling\nbetween model update rounds of federated learning, reducing transmissions of\nlarge parameters to single scalars for aggregation. We analytically\ncharacterize the convergence behavior of LBGM, revealing the nature of the\ntrade-off between communication savings and model performance. Our subsequent\nexperimental results demonstrate the improvement LBGM obtains in communication\noverhead compared to conventional federated learning on several datasets and\ndeep learning models. Additionally, we show that LBGM is a general\nplug-and-play algorithm that can be used standalone or stacked on top of\nexisting sparsification techniques for distributed model training.",
    "descriptor": "\nComments: In Proceedings of the 10th International Conference on Learning Representations (ICLR) 2022\n",
    "authors": [
      "Sheikh Shams Azam",
      "Seyyedali Hosseinalipour",
      "Qiang Qiu",
      "Christopher Brinton"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.00280"
  },
  {
    "id": "arXiv:2202.00282",
    "title": "Surrogate Gradients Design",
    "abstract": "Surrogate gradient (SG) training provides the possibility to quickly transfer\nall the gains made in deep learning to neuromorphic computing and neuromorphic\nprocessors, with the consequent reduction in energy consumption. Evidence\nsupports that training can be robust to the choice of SG shape, after an\nextensive search of hyper-parameters. However, random or grid search of\nhyper-parameters becomes exponentially unfeasible as we consider more\nhyper-parameters. Moreover, every point in the search can itself be highly time\nand energy consuming for large networks and large datasets. In this article we\nshow how complex tasks and networks are more sensitive to SG choice. Secondly,\nwe show how low dampening, high sharpness and low tail fatness are preferred.\nThirdly, we observe that Glorot Uniform initialization is generally preferred\nby most SG choices, with variability in the results. We finally provide a\ntheoretical solution to reduce the need of extensive gridsearch, to find SG\nshape and initializations that result in improved accuracy.",
    "descriptor": "",
    "authors": [
      "Luca Herranz-Celotti",
      "Jean Rouat"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.00282"
  },
  {
    "id": "arXiv:2202.00283",
    "title": "Exponentially fitted methods with a local energy conservation law",
    "abstract": "A new exponentially fitted version of the Discrete Variational Derivative\nmethod for the efficient solution of oscillatory complex Hamiltonian Partial\nDifferential Equations is proposed. When applied to the nonlinear Schroedinger\nequation, the new scheme has discrete conservation laws of charge and energy.\nThe new method is compared with other conservative schemes from the literature\non a benchmark problem whose solution is an oscillatory breather wave.",
    "descriptor": "",
    "authors": [
      "Dajana Conte",
      "Gianluca Frasca-Caccia"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.00283"
  },
  {
    "id": "arXiv:2202.00286",
    "title": "Measurement-Based Validation of Z3RO Precoder to Prevent Nonlinear  Amplifier Distortion in Massive MIMO Systems",
    "abstract": "In multiple input multiple output (MIMO) systems, precoding allows the base\nstation to spatially focus and multiplex signals towards each user. However,\ndistortion introduced by power amplifier nonlinearities coherently combines in\nthe same spatial directions when using a conventional precoder such as maximum\nratio transmission (MRT). This can strongly limit the user performance and\nmoreover create unauthorized out-of-band (OOB) emissions. In order to overcome\nthis problem, the zero third-order distortion (Z3RO) precoder was recently\nintroduced. This precoder constraints the third-order distortion at the user\nlocation to be zero. In this work, the performance of the Z3RO precoder is\nvalidated based on real-world channel measurement data. The results illustrate\nthe reduction in distortion power at the UE locations: an average distortion\nreduction of 6.03 dB in the worst-case single-user scenario and 3.54 dB in the\n2-user case at a back-off rate of -3 dB.",
    "descriptor": "",
    "authors": [
      "Thomas Feys",
      "Gilles Callebaut",
      "Liesbet Van der Perre",
      "Fran\u00e7ois Rottenberg"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.00286"
  },
  {
    "id": "arXiv:2202.00287",
    "title": "Automorphism Ensemble Decoding of Quasi-Cyclic LDPC Codes by Breaking  Graph Symmetries",
    "abstract": "We consider automorphism ensemble decoding (AED) of quasi-cyclic (QC)\nlow-density parity-check (LDPC) codes. Belief propagation (BP) decoding on the\nconventional factor graph is equivariant to the quasi-cyclic automorphisms and\ntherefore prevents gains by AED. However, by applying small modifications to\nthe parity-check matrix at the receiver side, we can break the symmetry without\nchanging the code at the transmitter. This way, we can leverage a gain in\nerror-correcting performance using an ensemble of identical BP decoders,\nwithout increasing the worst-case decoding latency. The proposed method is\ndemonstrated using LDPC codes from the CCSDS, 802.11n and 5G standards and\nproduces gains of 0.2 to 0.3 dB over conventional BP decoding.",
    "descriptor": "\nComments: 5 pages, submitted to IEEE for possible publication\n",
    "authors": [
      "Marvin Geiselhart",
      "Moustafa Ebada",
      "Ahmed Elkelesh",
      "Jannis Clausius",
      "Stephan ten Brink"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.00287"
  },
  {
    "id": "arXiv:2202.00291",
    "title": "XAlign: Cross-lingual Fact-to-Text Alignment and Generation for  Low-Resource Languages",
    "abstract": "Multiple critical scenarios (like Wikipedia text generation given English\nInfoboxes) need automated generation of descriptive text in low resource (LR)\nlanguages from English fact triples. Previous work has focused on English\nfact-to-text (F2T) generation. To the best of our knowledge, there has been no\nprevious attempt on cross-lingual alignment or generation for LR languages.\nBuilding an effective cross-lingual F2T (XF2T) system requires alignment\nbetween English structured facts and LR sentences. We propose two unsupervised\nmethods for cross-lingual alignment. We contribute XALIGN, an XF2T dataset with\n0.45M pairs across 8 languages, of which 5402 pairs have been manually\nannotated. We also train strong baseline XF2T generation models on the XAlign\ndataset.",
    "descriptor": "\nComments: 4 pages, 4 pages appendix, 4 figures and 8 tables\n",
    "authors": [
      "Tushar Abhishek",
      "Shivprasad Sagare",
      "Bhavyajeet Singh",
      "Anubhav Sharma",
      "Manish Gupta",
      "Vasudeva Varma"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.00291"
  },
  {
    "id": "arXiv:2202.00294",
    "title": "The Inverse Problem for Argumentation Gradual Semantics",
    "abstract": "Gradual semantics with abstract argumentation provide each argument with a\nscore reflecting its acceptability, i.e. how \"much\" it is attacked by other\narguments. Many different gradual semantics have been proposed in the\nliterature, each following different principles and producing different\nargument rankings. A sub-class of such semantics, the so-called weighted\nsemantics, takes, in addition to the graph structure, an initial set of weights\nover the arguments as input, with these weights affecting the resultant\nargument ranking. In this work, we consider the inverse problem over such\nweighted semantics. That is, given an argumentation framework and a desired\nargument ranking, we ask whether there exist initial weights such that a\nparticular semantics produces the given ranking. The contribution of this paper\nare: (1) an algorithm to answer this problem, (2) a characterisation of the\nproperties that a gradual semantics must satisfy for the algorithm to operate,\nand (3) an empirical evaluation of the proposed algorithm.",
    "descriptor": "",
    "authors": [
      "Nir Oren",
      "Bruno Yun",
      "Srdjan Vesic",
      "Murilo Baptista"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.00294"
  },
  {
    "id": "arXiv:2202.00295",
    "title": "A novel Large Eddy Simulation model for the Quasi-Geostrophic Equations  in a Finite Volume setting",
    "abstract": "We present a Large Eddy Simulation (LES) approach based on a nonlinear\ndifferential low-pass filter for the simulation of two-dimensional barotropic\nflows with under-refined meshes. For the implementation of such model, we\nchoose a segregated three-step algorithm combined with a computationally\nefficient Finite Volume method. We assess the performance of our approach on\nthe classical double-gyre wind forcing benchmark. The numerical experiments we\npresent demonstrate that our nonlinear filter is an improvement over a linear\nfilter since it is able to recover the four-gyre pattern of the time-averaged\nstream function even with extremely coarse meshes. In addition, our LES\napproach provides an average kinetic energy that compares well with the one\ncomputed with a Direct Numerical Simulation.",
    "descriptor": "\nComments: 16 pages, 11 figures\n",
    "authors": [
      "Michele Girfoglio",
      "Annalisa Quaini",
      "Gianluigi Rozza"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.00295"
  },
  {
    "id": "arXiv:2202.00298",
    "title": "Research on Question Classification Methods in the Medical Field",
    "abstract": "Question classification is one of the important links in the research of\nquestion and answering system. The existing question classification models are\nmore trained on public data sets. At present, there is a lack of question\nclassification data sets in specific fields, especially in the medical field.\nTo make up for this gap, this paper presents a data set for question\nclassification in the medical field. Moreover, this paper proposes a\nmulti-dimensional extraction of the characteristics of the question by\ncombining multiple neural network models, and proposes a question\nclassification model based on multi-dimensional feature extraction. The\nexperimental results show that the proposed method can effectively improve the\nperformance of question classification.",
    "descriptor": "\nComments: 10 pages\n",
    "authors": [
      "Jinzhang Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.00298"
  },
  {
    "id": "arXiv:2202.00299",
    "title": "Learning Physics-Consistent Particle Interactions",
    "abstract": "Interacting particle systems play a key role in science and engineering.\nAccess to the governing particle interaction law is fundamental for a complete\nunderstanding of such systems. However, the inherent system complexity keeps\nthe particle interaction hidden in many cases. Machine learning methods have\nthe potential to learn the behavior of interacting particle systems by\ncombining experiments with data analysis methods. However, most existing\nalgorithms focus on learning the kinetics at the particle level. Learning\npairwise interaction, e.g., pairwise force or pairwise potential energy,\nremains an open challenge. Here, we propose an algorithm that adapts the Graph\nNetworks framework, which contains an edge part to learn the pairwise\ninteraction and a node part to model the dynamics at particle level. Different\nfrom existing approaches that use neural networks in both parts, we design a\ndeterministic operator in the node part. The designed physics operator on the\nnodes restricts the output space of the edge neural network to be exactly the\npairwise interaction. We test the proposed methodology on multiple datasets and\ndemonstrate that it achieves considerably better performance in inferring\ncorrectly the pairwise interactions while also being consistent with the\nunderlying physics on all the datasets than existing purely data-driven models.\nThe developed methodology can support a better understanding and discovery of\nthe underlying particle interaction laws, and hence guide the design of\nmaterials with targeted properties.",
    "descriptor": "\nComments: Under review. 15 pages content, appendix + 12 pages SI. Supporting code link is attached in the end of main content\n",
    "authors": [
      "Zhichao Han",
      "David S. Kammer",
      "Olga Fink"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.00299"
  },
  {
    "id": "arXiv:2202.00307",
    "title": "Laplacian2Mesh: Laplacian-Based Mesh Understanding",
    "abstract": "Geometric deep learning has sparked a rising interest in computer graphics to\nperform shape understanding tasks, such as shape classification and semantic\nsegmentation on three-dimensional (3D) geometric surfaces. Previous works\nexplored the significant direction by defining the operations of convolution\nand pooling on triangle meshes, but most methods explicitly utilized the graph\nconnection structure of the mesh. Motivated by the geometric spectral surface\nreconstruction theory, we introduce a novel and flexible convolutional neural\nnetwork (CNN) model, called Laplacian2Mesh, for 3D triangle mesh, which maps\nthe features of mesh in the Euclidean space to the multi-dimensional\nLaplacian-Beltrami space, which is similar to the multi-resolution input in 2D\nCNN. Mesh pooling is applied to expand the receptive field of the network by\nthe multi-space transformation of Laplacian which retains the surface topology,\nand channel self-attention convolutions are applied in the new space. Since\nimplicitly using the intrinsic geodesic connections of the mesh through the\nadjacency matrix, we do not consider the number of the neighbors of the\nvertices, thereby mesh data with different numbers of vertices can be input.\nExperiments on various learning tasks applied to 3D meshes demonstrate the\neffectiveness and efficiency of Laplacian2Mesh.",
    "descriptor": "\nComments: 12 pages,15 figures,9 tables\n",
    "authors": [
      "Qiujie Dong",
      "Zixiong Wang",
      "Junjie Gao",
      "Shuangmin Chen",
      "Zhenyu Shu",
      "Shiqing Xin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.00307"
  },
  {
    "id": "arXiv:2202.00308",
    "title": "PAGE-PG: A Simple and Loopless Variance-Reduced Policy Gradient Method  with Probabilistic Gradient Estimation",
    "abstract": "Despite their success, policy gradient methods suffer from high variance of\nthe gradient estimate, which can result in unsatisfactory sample complexity.\nRecently, numerous variance-reduced extensions of policy gradient methods with\nprovably better sample complexity and competitive numerical performance have\nbeen proposed. After a compact survey on some of the main variance-reduced\nREINFORCE-type methods, we propose ProbAbilistic Gradient Estimation for Policy\nGradient (PAGE-PG), a novel loopless variance-reduced policy gradient method\nbased on a probabilistic switch between two types of updates. Our method is\ninspired by the PAGE estimator for supervised learning and leverages importance\nsampling to obtain an unbiased gradient estimator. We show that PAGE-PG enjoys\na $\\mathcal{O}\\left( \\epsilon^{-3} \\right)$ average sample complexity to reach\nan $\\epsilon$-stationary solution, which matches the sample complexity of its\nmost competitive counterparts under the same setting. A numerical evaluation\nconfirms the competitive performance of our method on classical control tasks.",
    "descriptor": "",
    "authors": [
      "Matilde Gargiani",
      "Andrea Zanelli",
      "Andrea Martinelli",
      "Tyler Summers",
      "John Lygeros"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2202.00308"
  },
  {
    "id": "arXiv:2202.00312",
    "title": "Rectangular GLT Sequences",
    "abstract": "The theory of generalized locally Toeplitz (GLT) sequences is a powerful\napparatus for computing the asymptotic spectral distribution of square matrices\nAn arising form the discretization of differential problems. Indeed, as the\nmesh fineness parameter $n$ increases to $\\infty$, the sequence $\\{A_n\\}_n$\noften turns out to be a GLT sequence. In this paper, motivated by recent\napplications, we further enhance the GLT apparatus by developing a full theory\nof rectangular GLT sequences as an extension of the theory of classical square\nGLT sequences. We also detail an example of application as an illustration of\nthe potential impact of the theory presented herein.",
    "descriptor": "",
    "authors": [
      "Giovanni Barbarino",
      "Carlo Garoni",
      "Mariarosa Mazza",
      "Stefano Serra-Capizzano"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.00312"
  },
  {
    "id": "arXiv:2202.00315",
    "title": "From Explanations to Segmentation: Using Explainable AI for Image  Segmentation",
    "abstract": "The new era of image segmentation leveraging the power of Deep Neural Nets\n(DNNs) comes with a price tag: to train a neural network for pixel-wise\nsegmentation, a large amount of training samples has to be manually labeled on\npixel-precision. In this work, we address this by following an indirect\nsolution. We build upon the advances of the Explainable AI (XAI) community and\nextract a pixel-wise binary segmentation from the output of the Layer-wise\nRelevance Propagation (LRP) explaining the decision of a classification\nnetwork. We show that we achieve similar results compared to an established\nU-Net segmentation architecture, while the generation of the training data is\nsignificantly simplified. The proposed method can be trained in a weakly\nsupervised fashion, as the training samples must be only labeled on\nimage-level, at the same time enabling the output of a segmentation mask. This\nmakes it especially applicable to a wider range of real applications where\ntedious pixel-level labelling is often not possible.",
    "descriptor": "\nComments: to be published in: 17th International Conference on Computer Vision Theory and Applications (VISAPP), February 2022\n",
    "authors": [
      "Clemens Seibold",
      "Johannes K\u00fcnzel",
      "Anna Hilsmann",
      "Peter Eisert"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.00315"
  },
  {
    "id": "arXiv:2202.00320",
    "title": "Self-Adjusting Ego-Trees Topology for Reconfigurable Datacenter Networks",
    "abstract": "State-of-the-art topologies for datacenters (DC) and high-performance\ncomputing (HPC) networks are demand-oblivious and static. Therefore, such\nnetwork topologies are optimized for the worst-case traffic scenarios and can't\ntake advantage of changing demand patterns when such exist. However, recent\noptical switching technologies enable the concept of dynamically reconfiguring\ncircuit-switched topologies in real-time. This capability opens the door for\nthe design of self-adjusting networks: networks with demand-aware and dynamic\ntopologies in which links between nodes can be established and re-adjusted\nonline and respond to evolving traffic patterns.\nThis paper studies a recently proposed model for optical leaf-spine\nreconfigurable networks. We present a novel algorithm, GreedyEgoTrees, that\ndynamically changes the network topology. The algorithm greedily builds ego\ntrees for nodes in the network, where nodes cooperate to help each other,\ntaking into account the global needs of the network. We show that\nGreedyEgoTrees has nice theoretical properties, outperforms other possible\nalgorithms (like static expander and greedy dynamic matching) and can\nsignificantly improve the average path length for real DC and HPC traces.",
    "descriptor": "\nComments: 11 pages\n",
    "authors": [
      "Chen Griner",
      "Gil Einziger",
      "Chen Avin"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2202.00320"
  },
  {
    "id": "arXiv:2202.00327",
    "title": "On a hybrid continuum-kinetic model for complex fluids",
    "abstract": "In the present work, we first introduce a general framework for modelling\ncomplex multiscale fluids and then focus on the derivation and analysis of a\nnew hybrid continuum-kinetic model. In particular, we combine conservation of\nmass and momentum for an isentropic macroscopic model with a kinetic\nrepresentation of the microscopic behaviour. After introducing a small scale of\ninterest, we compute the complex stress tensor by means of Irving-Kirkwood\nformula. The latter requires an expansion of kinetic distribution around an\nequilibrium state and a successive homogenization over the fast in time and\nsmall in space scale dynamics. For a new hybrid continuum-kinetic model the\nresults of linear stability analysis indicates a conditional stability in the\nrelevant low-speed regimes and instability for high speed regimes for higher\nmodes. Extensive numerical experiments confirm that the proposed multiscale\nmodel can reflect new phenomena of complex fluids not being present in standard\nNewtonian fluids. Consequently, the proposed general technique can be\nsuccessfully used to derive new interesting systems combining the macro and\nmicro structure of a given physical problem.",
    "descriptor": "",
    "authors": [
      "A. Chertock",
      "P. Degond",
      "G. Dimarco",
      "M. Luk\u00e1\u010dova-Medvid'ov\u00e1",
      "A. Ruhi"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.00327"
  },
  {
    "id": "arXiv:2202.00329",
    "title": "Underwater Differential Game: Finite-Time Target Hunting Task with  Communication Delay",
    "abstract": "This work considers designing an unmanned target hunting system for a swarm\nof unmanned underwater vehicles (UUVs) to hunt a target with high\nmaneuverability. Differential game theory is used to analyze combat policies of\nUUVs and the target within finite time. The challenge lies in UUVs must conduct\ntheir control policies in consideration of not only the consistency of the\nhunting team but also escaping behaviors of the target. To obtain stable\nfeedback control policies satisfying Nash equilibrium, we construct the\nHamiltonian function with Leibniz's formula. For further taken underwater\ndisturbances and communication delay into consideration, modified deep\nreinforcement learning (DRL) is provided to investigate the underwater target\nhunting task in an unknown dynamic environment. Simulations show that\nunderwater disturbances have a large impact on the system considering\ncommunication delay. Moreover, consistency tests show that UUVs perform better\nconsistency with a relatively small range of disturbances.",
    "descriptor": "",
    "authors": [
      "Wei Wei",
      "JingJing Wang",
      "Jun Du",
      "Zhengru Fang",
      "Chunxiao Jiang",
      "Yong Ren"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.00329"
  },
  {
    "id": "arXiv:2202.00332",
    "title": "Activity Recognition in Assembly Tasks by Bayesian Filtering in  Multi-Hypergraphs",
    "abstract": "We study sensor-based human activity recognition in manual work processes\nlike assembly tasks. In such processes, the system states often have a rich\nstructure, involving object properties and relations. Thus, estimating the\nhidden system state from sensor observations by recursive Bayesian filtering\ncan be very challenging, due to the combinatorial explosion in the number of\nsystem states. To alleviate this problem, we propose an efficient Bayesian\nfiltering model for such processes. In our approach, system states are\nrepresented by multi-hypergraphs, and the system dynamics is modeled by graph\nrewriting rules. We show a preliminary concept that allows to represent\ndistributions over multi-hypergraphs more compactly than by full enumeration,\nand present an inference algorithm that works directly on this compact\nrepresentation. We demonstrate the applicability of the algorithm on a real\ndataset.",
    "descriptor": "\nComments: Accepted for presentation at the 2nd GCLR workshop in conjunction with AAAI 2022\n",
    "authors": [
      "Timon Felske",
      "Stefan L\u00fcdtke",
      "Sebastian Bader",
      "Thomas Kirste"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.00332"
  },
  {
    "id": "arXiv:2202.00335",
    "title": "Big fish and small ponds: why the departmental h-index should not be  used to rank universities",
    "abstract": "The size-dependent nature of the so-called group or departmental h-index is\nreconsidered in this paper. While the influence of unit size on such collective\nmeasures was already demonstrated a decade ago, institutional ratings based on\nthis metric can still be found and still impact on the reputations and funding\nof many research institutions. The aim of this paper is to demonstrate the\nfallacy of this approach to collective research-quality assessment in a simple\nway, focusing on the h-index in its original form. We show that randomly\nreshuffling real scientometric data (varying numbers of citations) amongst\ninstitutions of varying size, while maintaining the volume of their research\noutputs, has little effect on their departmental h-index. This suggests that\nthe relative position in ratings based on the collective h-index is determined\nnot only by quality (impact) of particular research outputs but by their\nvolume. Therefore, the application of the collective h-index in its original\nform is disputable as a basement for comparison at aggregated levels such as to\nresearch groups, institutions or journals. We suggest a possible remedy for\nthis failing which is implementable in a manner that is as simple and\nunderstandable as the h-index itself.",
    "descriptor": "",
    "authors": [
      "Olesya Mryglod",
      "Yurij Holovatch",
      "Ralph Kenna"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2202.00335"
  },
  {
    "id": "arXiv:2202.00339",
    "title": "Quantifying Relevance in Learning and Inference",
    "abstract": "Learning is a distinctive feature of intelligent behaviour. High-throughput\nexperimental data and Big Data promise to open new windows on complex systems\nsuch as cells, the brain or our societies. Yet, the puzzling success of\nArtificial Intelligence and Machine Learning shows that we still have a poor\nconceptual understanding of learning. These applications push statistical\ninference into uncharted territories where data is high-dimensional and scarce,\nand prior information on \"true\" models is scant if not totally absent. Here we\nreview recent progress on understanding learning, based on the notion of\n\"relevance\". The relevance, as we define it here, quantifies the amount of\ninformation that a dataset or the internal representation of a learning machine\ncontains on the generative model of the data. This allows us to define\nmaximally informative samples, on one hand, and optimal learning machines on\nthe other. These are ideal limits of samples and of machines, that contain the\nmaximal amount of information about the unknown generative process, at a given\nresolution (or level of compression). Both ideal limits exhibit critical\nfeatures in the statistical sense: Maximally informative samples are\ncharacterised by a power-law frequency distribution (statistical criticality)\nand optimal learning machines by an anomalously large susceptibility. The\ntrade-off between resolution (i.e. compression) and relevance distinguishes the\nregime of noisy representations from that of lossy compression. These are\nseparated by a special point characterised by Zipf's law statistics. This\nidentifies samples obeying Zipf's law as the most compressed loss-less\nrepresentations that are optimal in the sense of maximal relevance. Criticality\nin optimal learning machines manifests in an exponential degeneracy of energy\nlevels, that leads to unusual thermodynamic properties.",
    "descriptor": "\nComments: review article, 63 pages, 14 figures\n",
    "authors": [
      "Matteo Marsili",
      "Yasser Roudi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.00339"
  },
  {
    "id": "arXiv:2202.00340",
    "title": "On the Interference Cancellation by Reduced Channel Zero Forcing Class  of Precodings in Massive MIMO Systems",
    "abstract": "In this paper, we study the interference cancellation capabilities of\nreceivers and transmitters in multiple-input-multiple-output (MIMO) systems\nusing theoretical calculations and numerical simulations in Quadriga. We study\nso-called Reduced Channel Zero-Forcing (RCZF) class of precoding as well as\nMinimum MSE Interference Rejection Combiner (MMSE-IRC) and QR Maximum\nLikelihood Detection (QR-MLD) receivers. Based on very simple but extremely\nuseful algebraic manipulations, their asymptotical equivalence is proven\nanalytically and demonstrated via simulations. Our theoretical and experimental\nresults confirm that MMSE-IRC and QR-MLD receivers in combination with the RCZF\nprecoding provide complete interference suppression asymptotically.",
    "descriptor": "\nComments: 5 pages, 5 figures, 1 table, comments are welcome\n",
    "authors": [
      "Dmitry Mineev",
      "Evgeny Bobrov",
      "Viktor Kuznetsov"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2202.00340"
  },
  {
    "id": "arXiv:2202.00343",
    "title": "IDP-Z3: a reasoning engine for FO(.)",
    "abstract": "FO(.) (aka FO-dot) is a language that extends classical first-order logic\nwith constructs to allow complex knowledge to be represented in a natural and\nelaboration-tolerant way.\nIDP-Z3 is a new reasoning engine for the FO(.) language: it can perform a\nvariety of generic computational tasks using knowledge represented in FO(.). It\nsupersedes IDP3, its predecessor, with new capabilities such as support for\nlinear arithmetic over reals and quantification over concepts.\nWe present four knowledge-intensive industrial use cases, and show that\nIDP-Z3 delivers real value to its users at low development costs: it supports\ninteractive applications in a variety of problem domains, with a response time\ntypically below 3 seconds.",
    "descriptor": "\nComments: To be submitted to KR 2022\n",
    "authors": [
      "Pierre Carbonnelle",
      "Simon Vandevelde",
      "Joost Vennekens",
      "Marc Denecker"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.00343"
  },
  {
    "id": "arXiv:2202.00345",
    "title": "Exploring layerwise decision making in DNNs",
    "abstract": "While deep neural networks (DNNs) have become a standard architecture for\nmany machine learning tasks, their internal decision-making process and general\ninterpretability is still poorly understood. Conversely, common decision trees\nare easily interpretable and theoretically well understood. We show that by\nencoding the discrete sample activation values of nodes as a binary\nrepresentation, we are able to extract a decision tree explaining the\nclassification procedure of each layer in a ReLU-activated multilayer\nperceptron (MLP). We then combine these decision trees with existing feature\nattribution techniques in order to produce an interpretation of each layer of a\nmodel. Finally, we provide an analysis of the generated interpretations, the\nbehaviour of the binary encodings and how these relate to sample groupings\ncreated during the training process of the neural network.",
    "descriptor": "",
    "authors": [
      "Coenraad Mouton",
      "Marelie H. Davel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.00345"
  },
  {
    "id": "arXiv:2202.00360",
    "title": "Accelerating Deep Reinforcement Learning for Digital Twin Network  Optimization with Evolutionary Strategies",
    "abstract": "The recent growth of emergent network applications (e.g., satellite networks,\nvehicular networks) is increasing the complexity of managing modern\ncommunication networks. As a result, the community proposed the Digital Twin\nNetworks (DTN) as a key enabler of efficient network management. Network\noperators can leverage the DTN to perform different optimization tasks (e.g.,\nTraffic Engineering, Network Planning). Deep Reinforcement Learning (DRL)\nshowed a high performance when applied to solve network optimization problems.\nIn the context of DTN, DRL can be leveraged to solve optimization problems\nwithout directly impacting the real-world network behavior. However, DRL scales\npoorly with the problem size and complexity. In this paper, we explore the use\nof Evolutionary Strategies (ES) to train DRL agents for solving a routing\noptimization problem. The experimental results show that ES achieved a training\ntime speed-up of 128 and 6 for the NSFNET and GEANT2 topologies respectively.",
    "descriptor": "\nComments: 5 pages, 5 figures\n",
    "authors": [
      "Carlos G\u00fcemes-Palau",
      "Paul Almasan",
      "Shihan Xiao",
      "Xiangle Cheng",
      "Xiang Shi",
      "Pere Barlet-Ros",
      "Albert Cabellos-Aparicio"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.00360"
  },
  {
    "id": "arXiv:2202.00367",
    "title": "Natural Language to Code Using Transformers",
    "abstract": "We tackle the problem of generating code snippets from natural language\ndescriptions using the CoNaLa dataset. We use the self-attention based\ntransformer architecture and show that it performs better than recurrent\nattention-based encoder decoder. Furthermore, we develop a modified form of\nback translation and use cycle consistent losses to train the model in an\nend-to-end fashion. We achieve a BLEU score of 16.99 beating the previously\nreported baseline of the CoNaLa challenge.",
    "descriptor": "",
    "authors": [
      "Uday Kusupati",
      "Venkata Ravi Teja Ailavarapu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.00367"
  },
  {
    "id": "arXiv:2202.00368",
    "title": "Filtered-CoPhy: Unsupervised Learning of Counterfactual Physics in Pixel  Space",
    "abstract": "Learning causal relationships in high-dimensional data (images, videos) is a\nhard task, as they are often defined on low dimensional manifolds and must be\nextracted from complex signals dominated by appearance, lighting, textures and\nalso spurious correlations in the data. We present a method for learning\ncounterfactual reasoning of physical processes in pixel space, which requires\nthe prediction of the impact of interventions on initial conditions. Going\nbeyond the identification of structural relationships, we deal with the\nchallenging problem of forecasting raw video over long horizons. Our method\ndoes not require the knowledge or supervision of any ground truth positions or\nother object or scene properties. Our model learns and acts on a suitable\nhybrid latent representation based on a combination of dense features, sets of\n2D keypoints and an additional latent vector per keypoint. We show that this\nbetter captures the dynamics of physical processes than purely dense or sparse\nrepresentations. We introduce a new challenging and carefully designed\ncounterfactual benchmark for predictions in pixel space and outperform strong\nbaselines in physics-inspired ML and video prediction.",
    "descriptor": "",
    "authors": [
      "Steeven Janny",
      "Fabien Baradel",
      "Natalia Neverova",
      "Madiha Nadri",
      "Greg Mori",
      "Christian Wolf"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.00368"
  },
  {
    "id": "arXiv:2202.00373",
    "title": "Improving BERT-based Query-by-Document Retrieval with Multi-Task  Optimization",
    "abstract": "Query-by-document (QBD) retrieval is an Information Retrieval task in which a\nseed document acts as the query and the goal is to retrieve related documents\n-- it is particular common in professional search tasks. In this work we\nimprove the retrieval effectiveness of the BERT re-ranker, proposing an\nextension to its fine-tuning step to better exploit the context of queries. To\nthis end, we use an additional document-level representation learning objective\nbesides the ranking objective when fine-tuning the BERT re-ranker. Our\nexperiments on two QBD retrieval benchmarks show that the proposed multi-task\noptimization significantly improves the ranking effectiveness without changing\nthe BERT re-ranker or using additional training samples. In future work, the\ngeneralizability of our approach to other retrieval tasks should be further\ninvestigated.",
    "descriptor": "\nComments: Accepted for publication in the 44th European Conference on Information Retrieval (ECIR2022)\n",
    "authors": [
      "Amin Abolghasemi",
      "Suzan Verberne",
      "Leif Azzopardi"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2202.00373"
  },
  {
    "id": "arXiv:2202.00374",
    "title": "Deepfake pornography as a male gaze on fan culture",
    "abstract": "This essay shows the impact of deepfake technology on fan culture. The\ninnovative technology provided the male audience with an instrument to express\nits ideas and plots. Which subsequently led to the rise of deepfake\npornography. It is often seen as a part of celebrity studies; however, the\nessay shows that it could also be considered a type of fanfic and a product of\nparticipatory culture, sharing community origin, exploitation by commercial\ncompanies and deep sexualisation. These two branches of fanfic evolution can be\nconnected via the genre of machinima pornography. Textual fanfics are mainly\ncreated by females for females, depicting males; otherwise, deepfake\npornography and machinima are made by males and for males targeting females.",
    "descriptor": "",
    "authors": [
      "Inna Suvorova"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.00374"
  },
  {
    "id": "arXiv:2202.00377",
    "title": "EPHS: A Port-Hamiltonian Modelling Language",
    "abstract": "A prevalent theme throughout science and engineering is the ongoing paradigm\nshift away from isolated systems towards open and interconnected systems. %\nPort-Hamiltonian theory developed as a synthesis of geometric mechanics and\nnetwork theory. The possibility to model complex multiphysical systems via\ninterconnection of simpler components is often advertised as one of its most\nattractive features. The development of a port-Hamiltonian modelling language\nhowever remains a topic which has not been sufficiently addressed. % We report\non recent progress towards the formalization and implementation of a modelling\nlanguage for exergetic port-Hamiltonian systems. Its diagrammatic syntax\ninspired by bond graphs and its functorial semantics together enable a modular\nand hierarchical approach to model specification.",
    "descriptor": "",
    "authors": [
      "Markus Lohmayer",
      "Sigrid Leyendecker"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.00377"
  },
  {
    "id": "arXiv:2202.00379",
    "title": "NTU VIRAL: A Visual-Inertial-Ranging-Lidar Dataset, From an Aerial  Vehicle Viewpoint",
    "abstract": "In recent years, autonomous robots have become ubiquitous in research and\ndaily life. Among many factors, public datasets play an important role in the\nprogress of this field, as they waive the tall order of initial investment in\nhardware and manpower. However, for research on autonomous aerial systems,\nthere appears to be a relative lack of public datasets on par with those used\nfor autonomous driving and ground robots. Thus, to fill in this gap, we conduct\na data collection exercise on an aerial platform equipped with an extensive and\nunique set of sensors: two 3D lidars, two hardware-synchronized global-shutter\ncameras, multiple Inertial Measurement Units (IMUs), and especially, multiple\nUltra-wideband (UWB) ranging units. The comprehensive sensor suite resembles\nthat of an autonomous driving car, but features distinct and challenging\ncharacteristics of aerial operations. We record multiple datasets in several\nchallenging indoor and outdoor conditions. Calibration results and ground truth\nfrom a high-accuracy laser tracker are also included in each package. All\nresources can be accessed via our webpage\nhttps://ntu-aris.github.io/ntu_viral_dataset.",
    "descriptor": "\nComments: IJRR 2021\n",
    "authors": [
      "Thien-Minh Nguyen",
      "Shenghai Yuan",
      "Muqing Cao",
      "Yang Lyu",
      "Thien Hoang Nguyen",
      "Lihua Xie"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.00379"
  },
  {
    "id": "arXiv:2202.00383",
    "title": "Explainable AI through the Learning of Arguments",
    "abstract": "Learning arguments is highly relevant to the field of explainable artificial\nintelligence. It is a family of symbolic machine learning techniques that is\nparticularly human-interpretable. These techniques learn a set of arguments as\nan intermediate representation. Arguments are small rules with exceptions that\ncan be chained to larger arguments for making predictions or decisions. We\ninvestigate the learning of arguments, specifically the learning of arguments\nfrom a 'case model' proposed by Verheij [34]. The case model in Verheij's\napproach are cases or scenarios in a legal setting. The number of cases in a\ncase model are relatively low. Here, we investigate whether Verheij's approach\ncan be used for learning arguments from other types of data sets with a much\nlarger number of instances. We compare the learning of arguments from a case\nmodel with the HeRO algorithm [15] and learning a decision tree.",
    "descriptor": "\nComments: Presented at the 33rd BeNeLux AI Conference (BNAIC/BENELEARN 2021)\n",
    "authors": [
      "Jonas Bei",
      "David Pomerenke",
      "Lukas Schreiner",
      "Sepideh Sharbaf",
      "Pieter Collins",
      "Nico Roos"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.00383"
  },
  {
    "id": "arXiv:2202.00386",
    "title": "A Comparative Study of Calibration Methods for Imbalanced Class  Incremental Learning",
    "abstract": "Deep learning approaches are successful in a wide range of AI problems and in\nparticular for visual recognition tasks. However, there are still open problems\namong which is the capacity to handle streams of visual information and the\nmanagement of class imbalance in datasets. Existing research approaches these\ntwo problems separately while they co-occur in real world applications. Here,\nwe study the problem of learning incrementally from imbalanced datasets. We\nfocus on algorithms which have a constant deep model complexity and use a\nbounded memory to store exemplars of old classes across incremental states.\nSince memory is bounded, old classes are learned with fewer images than new\nclasses and an imbalance due to incremental learning is added to the initial\ndataset imbalance. A score prediction bias in favor of new classes appears and\nwe evaluate a comprehensive set of score calibration methods to reduce it.\nEvaluation is carried with three datasets, using two dataset imbalance\nconfigurations and three bounded memory sizes. Results show that most\ncalibration methods have beneficial effect and that they are most useful for\nlower bounded memory sizes, which are most interesting in practice. As a\nsecondary contribution, we remove the usual distillation component from the\nloss function of incremental learning algorithms. We show that simpler vanilla\nfine tuning is a stronger backbone for imbalanced incremental learning\nalgorithms.",
    "descriptor": "",
    "authors": [
      "Umang Aggarwal",
      "Adrian Popescu",
      "Eden Belouadah",
      "C\u00e9line Hudelot"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.00386"
  },
  {
    "id": "arXiv:2202.00388",
    "title": "A Novel Method to Estimate Tilt Angle of a Body using a Pendulum",
    "abstract": "Most of the advanced control systems use sensor-based feedback for robust\ncontrol. Tilt angle estimation is key feedback for many robotics and\nmechatronics applications in order to stabilize a system. Tilt angle cannot be\ndirectly measured when the system in consideration is not attached to a\nstationary frame. it is usually estimated through indirect measurements in such\nsystems. The precision of this estimation depends on the measurements; hence it\ncan get expensive and complicated as the precision requirement increases. This\nresearch is aimed at developing a novel and economic method to estimate tilt\nangle with a relatively less sophisticated and complicated system, while\nmaintaining precision in estimating tilt angle. The method is developed to\nexplore a pendulum as an inertial measurement sensor and estimates tilt angle\nbased on dynamics of pendulum and parameter estimation models. Further,\nalgorithms are developed with varying order of complexity and accuracy to have\ncustomization for different applications. Furthermore, this study will validate\nthe developed algorithms by experimental testing. This method focuses on\ndeveloping algorithms to reduce the input measurement error in the Kalman\nfilter.",
    "descriptor": "",
    "authors": [
      "Anandhu Suresh",
      "Dr. Karnam Venkata Manga Raju"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.00388"
  },
  {
    "id": "arXiv:2202.00389",
    "title": "Sense: Model Hardware Co-design for Accelerating Sparse Neural Networks",
    "abstract": "Sparsity is an intrinsic property of neural network(NN). Many software\nresearchers have attempted to improve sparsity through pruning, for reduction\non weight storage and computation workload, while hardware architects are\nworking on how to skip redundant computations for higher energy efciency, but\nthere always exists overhead, causing many architectures suffering from only\nminor proft. Therefrom, systolic array becomes a promising candidate for the\nadvantages of low fanout and high throughput. However, sparsity is irregular,\nmaking it tricky to ft in with the rigid systolic tempo. Thus, this paper\nproposed a systolic-based architecture, called Sense, for both sparse input\nfeature map(IFM) and weight processing, achieving large performance improvement\nwith relatively small resource and power consumption. Meanwhile, we applied\nchannel rearrangement to gather IFMs with approximate sparsity and co-designed\nan adaptive weight training method to keep the sparsity ratio(zero element\npercentage) of each kernel at 1/2, with little accuracy loss. This treatment\ncan effectively reduce the irregularity of sparsity and help better ft with\nsystolic dataflow. Additionally, a dataflow called Partition Reuse is mapped to\nour architecture, enhancing data reuse, lowering 1.9x-2.6x DRAM access\nreduction compared with Eyeriss and further reducing system energy consumption.\nThe whole design is implemented on ZynqZCU102 and performs at a peak throughput\nof 409.6 GOP/s, with power consumption of 11.2W; compared with previous sparse\nNN accelerators based on FPGA, Sense takes up 1/5 less LUTs and 3/4 less BRAMs,\nreaches 2.1x peak energy efciency and achieves 1.15x-1.49x speedup.",
    "descriptor": "\nComments: 21 pages, 18 figures, 7 tables, Transactions on Embedded Computing Systems\n",
    "authors": [
      "Wenhao Sun",
      "Deng Liu",
      "Zhiwei Zou",
      "Wendi Sun",
      "Junpeng Wang",
      "Yi Kang",
      "Song Chen"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2202.00389"
  },
  {
    "id": "arXiv:2202.00390",
    "title": "Minority Class Oriented Active Learning for Imbalanced Datasets",
    "abstract": "Active learning aims to optimize the dataset annotation process when\nresources are constrained. Most existing methods are designed for balanced\ndatasets. Their practical applicability is limited by the fact that a majority\nof real-life datasets are actually imbalanced. Here, we introduce a new active\nlearning method which is designed for imbalanced datasets. It favors samples\nlikely to be in minority classes so as to reduce the imbalance of the labeled\nsubset and create a better representation for these classes. We also compare\ntwo training schemes for active learning: (1) the one commonly deployed in deep\nactive learning using model fine tuning for each iteration and (2) a scheme\nwhich is inspired by transfer learning and exploits generic pre-trained models\nand train shallow classifiers for each iteration. Evaluation is run with three\nimbalanced datasets. Results show that the proposed active learning method\noutperforms competitive baselines. Equally interesting, they also indicate that\nthe transfer learning training scheme outperforms model fine tuning if features\nare transferable from the generic dataset to the unlabeled one. This last\nresult is surprising and should encourage the community to explore the design\nof deep active learning methods.",
    "descriptor": "",
    "authors": [
      "Umang Aggarwal",
      "Adrian Popescu",
      "C\u00e9line Hudelot"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.00390"
  },
  {
    "id": "arXiv:2202.00391",
    "title": "Right for the Right Latent Factors: Debiasing Generative Models via  Disentanglement",
    "abstract": "A key assumption of most statistical machine learning methods is that they\nhave access to independent samples from the distribution of data they encounter\nat test time. As such, these methods often perform poorly in the face of biased\ndata, which breaks this assumption. In particular, machine learning models have\nbeen shown to exhibit Clever-Hans-like behaviour, meaning that spurious\ncorrelations in the training set are inadvertently learnt. A number of works\nhave been proposed to revise deep classifiers to learn the right correlations.\nHowever, generative models have been overlooked so far. We observe that\ngenerative models are also prone to Clever-Hans-like behaviour. To counteract\nthis issue, we propose to debias generative models by disentangling their\ninternal representations, which is achieved via human feedback. Our experiments\nshow that this is effective at removing bias even when human feedback covers\nonly a small fraction of the desired distribution. In addition, we achieve\nstrong disentanglement results in a quantitative comparison with recent\nmethods.",
    "descriptor": "",
    "authors": [
      "Xiaoting Shao",
      "Karl Stelzner",
      "Kristian Kersting"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.00391"
  },
  {
    "id": "arXiv:2202.00394",
    "title": "Recursive Multi-Section on the Fly: Shared-Memory Streaming Algorithms  for Hierarchical Graph Partitioning and Process Mapping",
    "abstract": "Partitioning a graph into balanced blocks such that few edges run between\nblocks is a key problem for large-scale distributed processing. A current trend\nfor partitioning huge graphs are streaming algorithms, which use low\ncomputational resources. In this work, we present a shared-memory streaming\nmulti-recursive partitioning scheme that performs recursive multi-sections on\nthe fly without knowing the overall input graph. Our approach has a\nconsiderably lower running time complexity in comparison with state-of-the-art\nnon-buffered one-pass partitioning algorithms for the standard graph\npartitioning case. Moreover, if the topology of a distributed system is known,\nit is possible to further optimize the communication costs by mapping\npartitions onto processing elements. Our experiments indicate that our\nalgorithm is both faster and produces better process mappings than competing\ntools. In case of graph partitioning, our framework is up to two orders of\nmagnitude faster at the cost of 5% more cut edges compared to Fennel.",
    "descriptor": "",
    "authors": [
      "Marcelo Fonseca Faraj",
      "Christian Schulz"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2202.00394"
  },
  {
    "id": "arXiv:2202.00395",
    "title": "Is the Performance of My Deep Network Too Good to Be True? A Direct  Approach to Estimating the Bayes Error in Binary Classification",
    "abstract": "There is a fundamental limitation in the prediction performance that a\nmachine learning model can achieve due to the inevitable uncertainty of the\nprediction target. In classification problems, this can be characterized by the\nBayes error, which is the best achievable error with any classifier. The Bayes\nerror can be used as a criterion to evaluate classifiers with state-of-the-art\nperformance and can be used to detect test set overfitting. We propose a simple\nand direct Bayes error estimator, where we just take the mean of the labels\nthat show \\emph{uncertainty} of the classes. Our flexible approach enables us\nto perform Bayes error estimation even for weakly supervised data. In contrast\nto others, our method is model-free and even instance-free. Moreover, it has no\nhyperparameters and gives a more accurate estimate of the Bayes error than\nclassifier-based baselines. Experiments using our method suggest that a\nrecently proposed classifier, the Vision Transformer, may have already reached\nthe Bayes error for certain benchmark datasets.",
    "descriptor": "",
    "authors": [
      "Takashi Ishida",
      "Ikko Yamane",
      "Nontawat Charoenphakdee",
      "Gang Niu",
      "Masashi Sugiyama"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.00395"
  },
  {
    "id": "arXiv:2202.00396",
    "title": "Politics and Virality in the Time of Twitter: A Large-Scale Cross-Party  Sentiment Analysis in Greece, Spain and United Kingdom",
    "abstract": "Social media has become extremely influential when it comes to policy making\nin modern societies especially in the western world (e.g., 48% of Europeans use\nsocial media every day or almost every day). Platforms such as Twitter allow\nusers to follow politicians, thus making citizens more involved in political\ndiscussion. In the same vein, politicians use Twitter to express their\nopinions, debate among others on current topics and promote their political\nagenda aiming to influence voter behaviour. Previous studies have shown that\ntweets conveying negative sentiment are likely to be retweeted more frequently.\nIn this paper, we attempt to analyse tweets from politicians from different\ncountries and explore if their tweets follow the same trend. Utilising\nstate-of-the-art pre-trained language models we performed sentiment analysis on\nmultilingual tweets collected from members of parliament of Greece, Spain and\nUnited Kingdom, including devolved administrations. We achieved this by\nsystematically exploring and analysing the differences between influential and\nless popular tweets. Our analysis indicates that politicians' negatively\ncharged tweets spread more widely, especially in more recent times, and\nhighlights interesting trends in the intersection of sentiment and popularity.",
    "descriptor": "\nComments: 12 pages, 5 figures, for code and data used see this https URL\n",
    "authors": [
      "Dimosthenis Antypas",
      "Alun Preece",
      "Jose Camacho Collados"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.00396"
  },
  {
    "id": "arXiv:2202.00397",
    "title": "Efficient computation of the Wright function and its applications to  fractional diffusion-wave equations",
    "abstract": "In this article, we deal with the efficient computation of the Wright\nfunction in the cases of interest for the expression of solutions of some\nfractional differential equations. The proposed algorithm is based on the\ninversion of the Laplace transform of a particular expression of the Wright\nfunction for which we discuss in detail the error analysis. We also present a\ncode package that implements the algorithm proposed here in different\nprogramming languages. The analysis and implementation are accompanied by an\nextensive set of numerical experiments that validate both the theoretical\nestimates of the error and the applicability of the proposed method for\nrepresenting the solutions of fractional differential equations.",
    "descriptor": "",
    "authors": [
      "Lidia Aceto",
      "Fabio Durastante"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.00397"
  },
  {
    "id": "arXiv:2202.00399",
    "title": "Language Dependencies in Adversarial Attacks on Speech Recognition  Systems",
    "abstract": "Automatic speech recognition (ASR) systems are ubiquitously present in our\ndaily devices. They are vulnerable to adversarial attacks, where manipulated\ninput samples fool the ASR system's recognition. While adversarial examples for\nvarious English ASR systems have already been analyzed, there exists no\ninter-language comparative vulnerability analysis.\nWe compare the attackability of a German and an English ASR system, taking\nDeepspeech as an example. We investigate if one of the language models is more\nsusceptible to manipulations than the other. The results of our experiments\nsuggest statistically significant differences between English and German in\nterms of computational effort necessary for the successful generation of\nadversarial examples. This result encourages further research in\nlanguage-dependent characteristics in the robustness analysis of ASR.",
    "descriptor": "",
    "authors": [
      "Karla Markert",
      "Donika Mirdita",
      "Konstantin B\u00f6ttinger"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2202.00399"
  },
  {
    "id": "arXiv:2202.00401",
    "title": "Learning to Speak on Behalf of a Group: Medium Access Control for  Sending a Shared Message",
    "abstract": "The rapid development of Industrial Internet of Things (IIoT) technologies\nhas not only enabled new applications, but also presented new challenges for\nreliable communication with limited resources. In this work, we define a\ndeceptively simple novel problem that can arise in these scenarios, in which a\nset of sensors need to communicate a joint observation. This observation is\nshared by a random subset of the nodes, which need to propagate it to the rest\nof the network, but coordination is complex: as signaling constraints require\nthe use of random access schemes over shared channels, each sensor needs to\nimplicitly coordinate with others with the same observation, so that at least\none of the transmissions gets through without collisions. Unlike existing\nmedium access control schemes, the goal here is not to maximize total goodput,\nbut rather to make sure that the shared message gets through, regardless of the\nsender. The lack of any signaling, aside from an acknowledgment or lack thereof\nfrom the rest of the network, makes determining the optimal collective\ntransmission strategy a significant challenge. We analyze this coordination\nproblem theoretically, prove its hardness, and provide low-complexity\nsolutions. While a low-complexity clustering-based approach is shown to provide\nnear-optimal performance in certain special cases, for the general scenarios,\nwe model each sensor as a multi-armed bandit (MAB), and provide a\nlearning-based solution. Numerical results show the effectiveness of this\napproach in a variety of cases.",
    "descriptor": "\nComments: Submitted to IEEE INFOCOM Workshops 2022\n",
    "authors": [
      "Shaan ul Haque",
      "Siddharth Chandak",
      "Federico Chiariotti",
      "Deniz Gunduz",
      "Petar Popovski"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2202.00401"
  },
  {
    "id": "arXiv:2202.00403",
    "title": "MoCap-less Quantitative Evaluation of Ego-Pose Estimation Without Ground  Truth Measurements",
    "abstract": "The emergence of data-driven approaches for control and planning in robotics\nhave highlighted the need for developing experimental robotic platforms for\ndata collection. However, their implementation is often complex and expensive,\nin particular for flying and terrestrial robots where the precise estimation of\nthe position requires motion capture devices (MoCap) or Lidar. In order to\nsimplify the use of a robotic platform dedicated to research on a wide range of\nindoor and outdoor environments, we present a data validation tool for ego-pose\nestimation that does not require any equipment other than the on-board camera.\nThe method and tool allow a rapid, visual and quantitative evaluation of the\nquality of ego-pose sensors and are sensitive to different sources of flaws in\nthe acquisition chain, ranging from desynchronization of the sensor flows to\nmisevaluation of the geometric parameters of the robotic platform. Using\ncomputer vision, the information from the sensors is used to calculate the\nmotion of a semantic scene point through its projection to the 2D image space\nof the on-board camera. The deviations of these keypoints from references\ncreated with a semi-automatic tool allow rapid and simple quality assessment of\nthe data collected on the platform. To demonstrate the performance of our\nmethod, we evaluate it on two challenging standard UAV datasets as well as one\ndataset taken from a terrestrial robot.",
    "descriptor": "\nComments: 7 pages, 6 figures, 1 table. Submitted to International Conference on Pattern Recognition. For associated videos: this https URL\n",
    "authors": [
      "Quentin Possama\u00ef",
      "Steeven Janny",
      "Guillaume Bono",
      "Madiha Nadri",
      "Laurent Bako",
      "Christian Wolf"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.00403"
  },
  {
    "id": "arXiv:2202.00408",
    "title": "Dimensionality Reduction Meets Message Passing for Graph Node Embeddings",
    "abstract": "Graph Neural Networks (GNNs) have become a popular approach for various\napplications, ranging from social network analysis to modeling chemical\nproperties of molecules. While GNNs often show remarkable performance on public\ndatasets, they can struggle to learn long-range dependencies in the data due to\nover-smoothing and over-squashing tendencies. To alleviate this challenge, we\npropose PCAPass, a method which combines Principal Component Analysis (PCA) and\nmessage passing for generating node embeddings in an unsupervised manner and\nleverages gradient boosted decision trees for classification tasks. We show\nempirically that this approach provides competitive performance compared to\npopular GNNs on node classification benchmarks, while gathering information\nfrom longer distance neighborhoods. Our research demonstrates that applying\ndimensionality reduction with message passing and skip connections is a\npromising mechanism for aggregating long-range dependencies in graph structured\ndata.",
    "descriptor": "",
    "authors": [
      "Krzysztof Sadowski",
      "Micha\u0142 Szarmach",
      "Eddie Mattia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.00408"
  },
  {
    "id": "arXiv:2202.00418",
    "title": "Review of Serial and Parallel Min-Cut/Max-Flow Algorithms for Computer  Vision",
    "abstract": "Minimum cut / maximum flow (min-cut/max-flow) algorithms are used to solve a\nvariety of problems in computer vision and thus significant effort has been put\ninto developing fast min-cut/max-flow algorithms. This makes it difficult to\nchoose an optimal algorithm for a given problem - especially for parallel\nalgorithms, which have not been thoroughly compared. In this paper, we review\nthe state-of-the-art min-cut/max-flow algorithms for unstructured graphs in\ncomputer vision. We evaluate run time performance and memory use of various\nimplementations of both serial and parallel algorithms on a set of graph cut\nproblems. Our results show that the Hochbaum pseudoflow algorithm is the\nfastest serial algorithm closely followed by the Excesses Incremental Breadth\nFirst Search algorithm, while the Boykov-Kolmogorov algorithm is the most\nmemory efficient. The best parallel algorithm is the adaptive bottom-up merging\napproach by Liu and Sun. Additionally, we show significant variations in\nperformance between different implementations the same algorithms highlighting\nthe importance of low-level implementation details. Finally, we note that\nexisting parallel min-cut/max-flow algorithms can significantly outperform\nserial algorithms on large problems but suffers from added overhead on small to\nmedium problems. Implementations of all algorithms are available at\nhttps://github.com/patmjen/maxflow_algorithms",
    "descriptor": "\nComments: 15 pages, 8 figures, submitted for review\n",
    "authors": [
      "Patrick M. Jensen",
      "Niels Jeppesen",
      "Anders B. Dahl",
      "Vedrana A. Dahl"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.00418"
  },
  {
    "id": "arXiv:2202.00423",
    "title": "Memory-based Message Passing: Decoupling the Message for Propogation  from Discrimination",
    "abstract": "Message passing is a fundamental procedure for graph neural networks in the\nfield of graph representation learning. Based on the homophily assumption, the\ncurrent message passing always aggregates features of connected nodes, such as\nthe graph Laplacian smoothing process. However, real-world graphs tend to be\nnoisy and/or non-smooth. The homophily assumption does not always hold, leading\nto sub-optimal results. A revised message passing method needs to maintain each\nnode's discriminative ability when aggregating the message from neighbors. To\nthis end, we propose a Memory-based Message Passing (MMP) method to decouple\nthe message of each node into a self-embedding part for discrimination and a\nmemory part for propagation. Furthermore, we develop a control mechanism and a\ndecoupling regularization to control the ratio of absorbing and excluding the\nmessage in the memory for each node. More importantly, our MMP is a general\nskill that can work as an additional layer to help improve traditional GNNs\nperformance. Extensive experiments on various datasets with different homophily\nratios demonstrate the effectiveness and robustness of the proposed method.",
    "descriptor": "\nComments: Accepted by ICASSP 2022\n",
    "authors": [
      "Jie Chen",
      "Weiqi Liu",
      "Jian Pu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.00423"
  },
  {
    "id": "arXiv:2202.00428",
    "title": "Counting Unreachable Single-Side Pawn Diagrams with Limitless Captures",
    "abstract": "Epiphainein counts unreachable single-side pawn diagrams (in chess) where\npawns can move forward or diagonally-forward without limit whilst remaining on\nthe board. Epiphainein is a serial calculation and takes a few seconds to\ncalculate the number of unreachable diagrams on a regular 8 x 8 board. With a\ndecent machine it should take roughly 4 hours to calculate the same on a 10 x\n10 board.",
    "descriptor": "\nComments: 9 pages, 7 figures, 1 table\n",
    "authors": [
      "Colin McDonagh"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2202.00428"
  },
  {
    "id": "arXiv:2202.00432",
    "title": "Continual Attentive Fusion for Incremental Learning in Semantic  Segmentation",
    "abstract": "Over the past years, semantic segmentation, as many other tasks in computer\nvision, benefited from the progress in deep neural networks, resulting in\nsignificantly improved performance. However, deep architectures trained with\ngradient-based techniques suffer from catastrophic forgetting, which is the\ntendency to forget previously learned knowledge while learning new tasks.\nAiming at devising strategies to counteract this effect, incremental learning\napproaches have gained popularity over the past years. However, the first\nincremental learning methods for semantic segmentation appeared only recently.\nWhile effective, these approaches do not account for a crucial aspect in\npixel-level dense prediction problems, i.e. the role of attention mechanisms.\nTo fill this gap, in this paper we introduce a novel attentive feature\ndistillation approach to mitigate catastrophic forgetting while accounting for\nsemantic spatial- and channel-level dependencies. Furthermore, we propose a\n{continual attentive fusion} structure, which takes advantage of the attention\nlearned from the new and the old tasks while learning features for the new\ntask. Finally, we also introduce a novel strategy to account for the background\nclass in the distillation loss, thus preventing biased predictions. We\ndemonstrate the effectiveness of our approach with an extensive evaluation on\nPascal-VOC 2012 and ADE20K, setting a new state of the art.",
    "descriptor": "",
    "authors": [
      "Guanglei Yang",
      "Enrico Fini",
      "Dan Xu",
      "Paolo Rota",
      "Mingli Ding",
      "Hao Tang",
      "Xavier Alameda-Pineda",
      "Elisa Ricci"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.00432"
  },
  {
    "id": "arXiv:2202.00433",
    "title": "TopoOpt: Optimizing the Network Topology for Distributed DNN Training",
    "abstract": "We explore a novel approach for building DNN training clusters using\ncommodity optical devices. Our proposal, called TopoOpt, co-optimizes the\ndistributed training process across three dimensions: computation,\ncommunication, and network topology. TopoOpt uses a novel alternating\noptimization technique and a group theory-inspired algorithm to find the best\nnetwork topology and routing plan, together with parallelization strategy, for\ndistributed DNN training. To motivate our proposal, we measure the\ncommunication patterns of distributed DNN workloads at a large online service\nprovider. Experiments with a 12-node prototype demonstrate the feasibility of\nTopoOpt. Simulations on real distributed training models show that, compared to\nsimilar-cost FatTree interconnects, TopoOpt reduces DNN training time by up to\n3x.",
    "descriptor": "",
    "authors": [
      "Weiyang Wang",
      "Moein Khazraee",
      "Zhizhen Zhong",
      "Zhijao Jia",
      "Dheevatsa Mudigere",
      "Ying Zhang",
      "Anthony Kewitsch",
      "Manya Ghobadi"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2202.00433"
  },
  {
    "id": "arXiv:2202.00436",
    "title": "Causal Inference Principles for Reasoning about Commonsense Causality",
    "abstract": "Commonsense causality reasoning (CCR) aims at identifying plausible causes\nand effects in natural language descriptions that are deemed reasonable by an\naverage person. Although being of great academic and practical interest, this\nproblem is still shadowed by the lack of a well-posed theoretical framework;\nexisting work usually relies on deep language models wholeheartedly, and is\npotentially susceptible to confounding co-occurrences. Motivated by classical\ncausal principles, we articulate the central question of CCR and draw parallels\nbetween human subjects in observational studies and natural languages to adopt\nCCR to the potential-outcomes framework, which is the first such attempt for\ncommonsense tasks. We propose a novel framework, ROCK, to Reason O(A)bout\nCommonsense K(C)ausality, which utilizes temporal signals as incidental\nsupervision, and balances confounding effects using temporal propensities that\nare analogous to propensity scores. The ROCK implementation is modular and\nzero-shot, and demonstrates good CCR capabilities on various datasets.",
    "descriptor": "",
    "authors": [
      "Jiayao Zhang",
      "Hongming Zhang",
      "Dan Roth",
      "Weijie J. Su"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2202.00436"
  },
  {
    "id": "arXiv:2202.00441",
    "title": "Few-Bit Backward: Quantized Gradients of Activation Functions for Memory  Footprint Reduction",
    "abstract": "Memory footprint is one of the main limiting factors for large neural network\ntraining. In backpropagation, one needs to store the input to each operation in\nthe computational graph. Every modern neural network model has quite a few\npointwise nonlinearities in its architecture, and such operation induces\nadditional memory costs which -- as we show -- can be significantly reduced by\nquantization of the gradients. We propose a systematic approach to compute\noptimal quantization of the retained gradients of the pointwise nonlinear\nfunctions with only a few bits per each element. We show that such\napproximation can be achieved by computing optimal piecewise-constant\napproximation of the derivative of the activation function, which can be done\nby dynamic programming. The drop-in replacements are implemented for all\npopular nonlinearities and can be used in any existing pipeline. We confirm the\nmemory reduction and the same convergence on several open benchmarks.",
    "descriptor": "\nComments: Submitted\n",
    "authors": [
      "Georgii Novikov",
      "Daniel Bershatsky",
      "Julia Gusak",
      "Alex Shonenkov",
      "Denis Dimitrov",
      "Ivan Oseledets"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.00441"
  },
  {
    "id": "arXiv:2202.00443",
    "title": "The Text Anonymization Benchmark (TAB): A Dedicated Corpus and  Evaluation Framework for Text Anonymization",
    "abstract": "We present a novel benchmark and associated evaluation metrics for assessing\nthe performance of text anonymization methods. Text anonymization, defined as\nthe task of editing a text document to prevent the disclosure of personal\ninformation, currently suffers from a shortage of privacy-oriented annotated\ntext resources, making it difficult to properly evaluate the level of privacy\nprotection offered by various anonymization methods. This paper presents TAB\n(Text Anonymization Benchmark), a new, open-source annotated corpus developed\nto address this shortage. The corpus comprises 1,268 English-language court\ncases from the European Court of Human Rights (ECHR) enriched with\ncomprehensive annotations about the personal information appearing in each\ndocument, including their semantic category, identifier type, confidential\nattributes, and co-reference relations. Compared to previous work, the TAB\ncorpus is designed to go beyond traditional de-identification (which is limited\nto the detection of predefined semantic categories), and explicitly marks which\ntext spans ought to be masked in order to conceal the identity of the person to\nbe protected. Along with presenting the corpus and its annotation layers, we\nalso propose a set of evaluation metrics that are specifically tailored towards\nmeasuring the performance of text anonymization, both in terms of privacy\nprotection and utility preservation. We illustrate the use of the benchmark and\nthe proposed metrics by assessing the empirical performance of several baseline\ntext anonymization models. The full corpus along with its privacy-oriented\nannotation guidelines, evaluation scripts and baseline models are available on:\nhttps://github.com/NorskRegnesentral/text-anonymisation-benchmark",
    "descriptor": "",
    "authors": [
      "Ildik\u00f3 Pil\u00e1n",
      "Pierre Lison",
      "Lilja \u00d8vrelid",
      "Anthi Papadopoulou",
      "David S\u00e1nchez",
      "Montserrat Batet"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.00443"
  },
  {
    "id": "arXiv:2202.00446",
    "title": "Multi-Order Networks for Action Unit Detection",
    "abstract": "Deep multi-task methods, where several tasks are learned within a single\nnetwork, have recently attracted increasing attention. Burning point of this\nattention is their capacity to capture inter-task relationships. Current\napproaches either only rely on weight sharing, or add explicit dependency\nmodelling by decomposing the task joint distribution using Bayes chain rule. If\nthe latter strategy yields comprehensive inter-task relationships modelling, it\nrequires imposing an arbitrary order into an unordered task set. Most\nimportantly, this sequence ordering choice has been identified as a critical\nsource of performance variations. In this paper, we present Multi-Order Network\n(MONET), a multi-task learning method with joint task order optimization. MONET\nuses a differentiable order selection based on soft order modelling inside\nBirkhoff's polytope to jointly learn task-wise recurrent modules with their\noptimal chaining order. Furthermore, we introduce warm up and order dropout to\nenhance order selection by encouraging order exploration. Experimentally, we\nfirst validate MONET capacity to retrieve the optimal order in a toy\nenvironment. Second, we use an attribute detection scenario to show that MONET\noutperforms existing multi-task baselines on a wide range of dependency\nsettings. Finally, we demonstrate that MONET significantly extends\nstate-of-the-art performance in Facial Action Unit detection.",
    "descriptor": "",
    "authors": [
      "Gauthier Tallec",
      "Arnaud Dapogny",
      "Kevin Bailly"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.00446"
  },
  {
    "id": "arXiv:2202.00448",
    "title": "Sim2Real Object-Centric Keypoint Detection and Description",
    "abstract": "Keypoint detection and description play a central role in computer vision.\nMost existing methods are in the form of scene-level prediction, without\nreturning the object classes of different keypoints. In this paper, we propose\nthe object-centric formulation, which, beyond the conventional setting,\nrequires further identifying which object each interest point belongs to. With\nsuch fine-grained information, our framework enables more downstream\npotentials, such as object-level matching and pose estimation in a clustered\nenvironment. To get around the difficulty of label collection in the real\nworld, we develop a sim2real contrastive learning mechanism that can generalize\nthe model trained in simulation to real-world applications. The novelties of\nour training method are three-fold: (i) we integrate the uncertainty into the\nlearning framework to improve feature description of hard cases, e.g.,\nless-textured or symmetric patches; (ii) we decouple the object descriptor into\ntwo output branches -- intra-object salience and inter-object distinctness,\nresulting in a better pixel-wise description; (iii) we enforce cross-view\nsemantic consistency for enhanced robustness in representation learning.\nComprehensive experiments on image matching and 6D pose estimation verify the\nencouraging generalization ability of our method from simulation to reality.\nParticularly for 6D pose estimation, our method significantly outperforms\ntypical unsupervised/sim2real methods, achieving a closer gap with the fully\nsupervised counterpart.",
    "descriptor": "\nComments: accepted to AAAI2022\n",
    "authors": [
      "Chengliang Zhong",
      "Chao Yang",
      "Jinshan Qi",
      "Fuchun Sun",
      "Huaping Liu",
      "Xiaodong Mu",
      "Wenbing Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.00448"
  },
  {
    "id": "arXiv:2202.00449",
    "title": "Evaluating Feature Attribution: An Information-Theoretic Perspective",
    "abstract": "With a variety of local feature attribution methods being proposed in recent\nyears, follow-up work suggested several evaluation strategies. To assess the\nattribution quality across different attribution techniques, the most popular\namong these evaluation strategies in the image domain use pixel perturbations.\nHowever, recent advances discovered that different evaluation strategies\nproduce conflicting rankings of attribution methods and can be prohibitively\nexpensive to compute. In this work, we present an information-theoretic\nanalysis of evaluation strategies based on pixel perturbations. Our findings\nreveal that the results output by different evaluation strategies are strongly\naffected by information leakage through the shape of the removed pixels as\nopposed to their actual values. Using our theoretical insights, we propose a\nnovel evaluation framework termed Remove and Debias (ROAD) which offers two\ncontributions: First, it mitigates the impact of the confounders, which entails\nhigher consistency among evaluation strategies. Second, ROAD does not require\nthe computationally expensive retraining step and saves up to 99% in\ncomputational costs compared to the state-of-the-art. Our source code is\navailable at https://github.com/tleemann/road_evaluation.",
    "descriptor": "\nComments: 9 pages, 8 figures. The first two authors contributed equally\n",
    "authors": [
      "Yao Rong",
      "Tobias Leemann",
      "Vadim Borisov",
      "Gjergji Kasneci",
      "Enkelejda Kasneci"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.00449"
  },
  {
    "id": "arXiv:2202.00450",
    "title": "Approximation of Images via Generalized Higher Order Singular Value  Decomposition over Finite-dimensional Commutative Semisimple Algebra",
    "abstract": "Low-rank approximation of images via singular value decomposition is\nwell-received in the era of big data. However, singular value decomposition\n(SVD) is only for order-two data, i.e., matrices. It is necessary to flatten a\nhigher order input into a matrix or break it into a series of order-two slices\nto tackle higher order data such as multispectral images and videos with the\nSVD. Higher order singular value decomposition (HOSVD) extends the SVD and can\napproximate higher order data using sums of a few rank-one components. We\nconsider the problem of generalizing HOSVD over a finite dimensional\ncommutative algebra. This algebra, referred to as a t-algebra, generalizes the\nfield of complex numbers. The elements of the algebra, called t-scalars, are\nfix-sized arrays of complex numbers. One can generalize matrices and tensors\nover t-scalars and then extend many canonical matrix and tensor algorithms,\nincluding HOSVD, to obtain higher-performance versions. The generalization of\nHOSVD is called THOSVD. Its performance of approximating multi-way data can be\nfurther improved by an alternating algorithm. THOSVD also unifies a wide range\nof principal component analysis algorithms. To exploit the potential of\ngeneralized algorithms using t-scalars for approximating images, we use a pixel\nneighborhood strategy to convert each pixel to \"deeper-order\" t-scalar.\nExperiments on publicly available images show that the generalized algorithm\nover t-scalars, namely THOSVD, compares favorably with its canonical\ncounterparts.",
    "descriptor": "\nComments: Generalized matrix theory over a finite-dimensional commutative algebra with applications in image analysis\n",
    "authors": [
      "Liang Liao",
      "Sen Lin",
      "Lun Li",
      "Xiuwei Zhang",
      "Song Zhao",
      "Yan Wang",
      "Xinqiang Wang",
      "Qi Gao",
      "Jingyu Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Commutative Algebra (math.AC)",
      "Representation Theory (math.RT)",
      "Spectral Theory (math.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.00450"
  },
  {
    "id": "arXiv:2202.00452",
    "title": "Sparse Signal Reconstruction with QUBO Formulation in l0-regularized  Linear Regression",
    "abstract": "An l0-regularized linear regression for a sparse signal reconstruction is\nimplemented based on the quadratic unconstrained binary optimization (QUBO)\nformulation. In this method, the signal values are quantized and expressed as\nbit sequences. By transforming l0-norm to a quadratic form of these bits, the\nfully quadratic objective function is provided and optimized by the solver\nspecialized for QUBO, such as the quantum annealer. Numerical experiments with\na commercial quantum annealer show that the proposed method performs slightly\nbetter than conventional methods based on orthogonal matching pursuit (OMP) and\nthe least absolute shrinkage and selection operator (LASSO) under several\nlimited conditions.",
    "descriptor": "",
    "authors": [
      "Naoki Ide",
      "Masayuki Ohzeki"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.00452"
  },
  {
    "id": "arXiv:2202.00453",
    "title": "Changes in co-publication patterns among China, the European Union (28)  and the United States of America, 2016-2021",
    "abstract": "The COVID-19 global pandemic starting in January 2020 disrupted international\ncollaborations in scholarly exchange, reducing mobility and connections across\nthe globe. An examination of Web of Science-indexed publications from China,\nthe European Union-28 and the United States of America shows a drop in\npublications numbers coming from the EU-28 and the United States in 2021.\nImportantly, cooperation between China and the United States drops without a\ncorresponding drop between China and the EU-28. Moreover, the drop in China-USA\ncooperation can be seen beginning in 2019, before the pandemic, at a time when\npolitical tensions around science, technology, and innovation arose, with the\nUnited States claiming that China was violating intellectual property norms.\nThe patterns suggest that political tensions, more than the pandemic,\ninfluenced the drop in China-USA cooperation.",
    "descriptor": "\nComments: 11 pages, 4 figures, 4 tables\n",
    "authors": [
      "Caroline S. Wagner",
      "Xiaojing Cai"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2202.00453"
  },
  {
    "id": "arXiv:2202.00454",
    "title": "TableQuery: Querying tabular data with natural language",
    "abstract": "This paper presents TableQuery, a novel tool for querying tabular data using\ndeep learning models pre-trained to answer questions on free text. Existing\ndeep learning methods for question answering on tabular data have various\nlimitations, such as having to feed the entire table as input into a neural\nnetwork model, making them unsuitable for most real-world applications. Since\nreal-world data might contain millions of rows, it may not entirely fit into\nthe memory. Moreover, data could be stored in live databases, which are updated\nin real-time, and it is impractical to serialize an entire database to a neural\nnetwork-friendly format each time it is updated. In TableQuery, we use deep\nlearning models pre-trained for question answering on free text to convert\nnatural language queries to structured queries, which can be run against a\ndatabase or a spreadsheet. This method eliminates the need for fitting the\nentire data into memory as well as serializing databases. Furthermore, deep\nlearning models pre-trained for question answering on free text are readily\navailable on platforms such as HuggingFace Model Hub (7). TableQuery does not\nrequire re-training; when a newly trained model for question answering with\nbetter performance is available, it can replace the existing model in\nTableQuery.",
    "descriptor": "\nComments: 11 pages, 1 figures\n",
    "authors": [
      "Abhijith Neil Abraham",
      "Fariz Rahman",
      "Damanpreet Kaur"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2202.00454"
  },
  {
    "id": "arXiv:2202.00455",
    "title": "HCSC: Hierarchical Contrastive Selective Coding",
    "abstract": "Hierarchical semantic structures naturally exist in an image dataset, in\nwhich several semantically relevant image clusters can be further integrated\ninto a larger cluster with coarser-grained semantics. Capturing such structures\nwith image representations can greatly benefit the semantic understanding on\nvarious downstream tasks. Existing contrastive representation learning methods\nlack such an important model capability. In addition, the negative pairs used\nin these methods are not guaranteed to be semantically distinct, which could\nfurther hamper the structural correctness of learned image representations. To\ntackle these limitations, we propose a novel contrastive learning framework\ncalled Hierarchical Contrastive Selective Coding (HCSC). In this framework, a\nset of hierarchical prototypes are constructed and also dynamically updated to\nrepresent the hierarchical semantic structures underlying the data in the\nlatent space. To make image representations better fit such semantic\nstructures, we employ and further improve conventional instance-wise and\nprototypical contrastive learning via an elaborate pair selection scheme. This\nscheme seeks to select more diverse positive pairs with similar semantics and\nmore precise negative pairs with truly distinct semantics. On extensive\ndownstream tasks, we verify the superior performance of HCSC over\nstate-of-the-art contrastive methods, and the effectiveness of major model\ncomponents is proved by plentiful analytical studies. Our source code and model\nweights are available at https://github.com/gyfastas/HCSC",
    "descriptor": "\nComments: Research project paper. arXiv v1: code & model weights released\n",
    "authors": [
      "Yuanfan Guo",
      "Minghao Xu",
      "Jiawen Li",
      "Bingbing Ni",
      "Xuanyu Zhu",
      "Zhenbang Sun",
      "Yi Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.00455"
  },
  {
    "id": "arXiv:2202.00458",
    "title": "Firm-based relatedness using machine learning",
    "abstract": "The relatedness between an economic actor (for instance a country, or a firm)\nand a product is a measure of the feasibility of that economic activity. As\nsuch, it is a driver for investments both at a private and institutional level.\nTraditionally, relatedness is measured using complex networks approaches\nderived by country-level co-occurrences. In this work, we compare complex\nnetworks and machine learning algorithms trained on both country and firm-level\ndata. In order to quantitatively compare the different measures of relatedness,\nwe use them to predict the future exports at country and firm-level, assuming\nthat more related products have higher likelihood to be exported in the near\nfuture. Our results show that relatedness is scale-dependent: the best\nassessments are obtained by using machine learning on the same typology of data\none wants to predict. Moreover, while relatedness measures based on country\ndata are not suitable for firms, firm-level data are quite informative also to\npredict the development of countries. In this sense, models built on firm data\nprovide a better assessment of relatedness with respect to country-level data.\nWe also discuss the effect of using community detection algorithms and\nparameter optimization, finding that a partition into a higher number of blocks\ndecreases the computational time while maintaining a prediction performance\nthat is well above the network based benchmarks.",
    "descriptor": "\nComments: 11 pages, 4 figures\n",
    "authors": [
      "Giambattista Albora",
      "Andrea Zaccaria"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.00458"
  },
  {
    "id": "arXiv:2202.00466",
    "title": "Learning Invariable Semantical Representation from Language for  Extensible Policy Generalization",
    "abstract": "Recently, incorporating natural language instructions into reinforcement\nlearning (RL) to learn semantically meaningful representations and foster\ngeneralization has caught many concerns. However, the semantical information in\nlanguage instructions is usually entangled with task-specific state\ninformation, which hampers the learning of semantically invariant and reusable\nrepresentations. In this paper, we propose a method to learn such\nrepresentations called element randomization, which extracts task-relevant but\nenvironment-agnostic semantics from instructions using a set of environments\nwith randomized elements, e.g., topological structures or textures, yet the\nsame language instruction. We theoretically prove the feasibility of learning\nsemantically invariant representations through randomization. In practice, we\naccordingly develop a hierarchy of policies, where a high-level policy is\ndesigned to modulate the behavior of a goal-conditioned low-level policy by\nproposing subgoals as semantically invariant representations. Experiments on\nchallenging long-horizon tasks show that (1) our low-level policy reliably\ngeneralizes to tasks against environment changes; (2) our hierarchical policy\nexhibits extensible generalization in unseen new tasks that can be decomposed\ninto several solvable sub-tasks; and (3) by storing and replaying language\ntrajectories as succinct policy representations, the agent can complete tasks\nin a one-shot fashion, i.e., once one successful trajectory has been attained.",
    "descriptor": "",
    "authors": [
      "Yihan Li",
      "Jinsheng Ren",
      "Tianrun Xu",
      "Tianren Zhang",
      "Haichuan Gao",
      "Feng Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.00466"
  },
  {
    "id": "arXiv:2202.00468",
    "title": "Unified Multimodal Punctuation Restoration Framework for Mixed-Modality  Corpus",
    "abstract": "The punctuation restoration task aims to correctly punctuate the output\ntranscriptions of automatic speech recognition systems. Previous punctuation\nmodels, either using text only or demanding the corresponding audio, tend to be\nconstrained by real scenes, where unpunctuated sentences are a mixture of those\nwith and without audio. This paper proposes a unified multimodal punctuation\nrestoration framework, named UniPunc, to punctuate the mixed sentences with a\nsingle model. UniPunc jointly represents audio and non-audio samples in a\nshared latent space, based on which the model learns a hybrid representation\nand punctuates both kinds of samples. We validate the effectiveness of the\nUniPunc on real-world datasets, which outperforms various strong baselines\n(e.g. BERT, MuSe) by at least 0.8 overall F1 scores, making a new\nstate-of-the-art. Extensive experiments show that UniPunc's design is a\npervasive solution: by grafting onto previous models, UniPunc enables them to\npunctuate on the mixed corpus. Our code is available at\ngithub.com/Yaoming95/UniPunc",
    "descriptor": "\nComments: 5 pages, accepted by ICASSP'2022\n",
    "authors": [
      "Yaoming Zhu",
      "Liwei Wu",
      "Shanbo Cheng",
      "Mingxuan Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.00468"
  },
  {
    "id": "arXiv:2202.00469",
    "title": "Gradient-guided Unsupervised Text Style Transfer via Contrastive  Learning",
    "abstract": "Text style transfer is a challenging text generation problem, which aims at\naltering the style of a given sentence to a target one while keeping its\ncontent unchanged. Since there is a natural scarcity of parallel datasets,\nrecent works mainly focus on solving the problem in an unsupervised manner.\nHowever, previous gradient-based works generally suffer from the deficiencies\nas follows, namely: (1) Content migration. Previous approaches lack explicit\nmodeling of content invariance and are thus susceptible to content shift\nbetween the original sentence and the transferred one. (2) Style\nmisclassification. A natural drawback of the gradient-guided approaches is that\nthe inference process is homogeneous with a line of adversarial attack, making\nlatent optimization easily becomes an attack to the classifier due to\nmisclassification. This leads to difficulties in achieving high transfer\naccuracy. To address the problems, we propose a novel gradient-guided model\nthrough a contrastive paradigm for text style transfer, to explicitly gather\nsimilar semantic sentences, and to design a siamese-structure based style\nclassifier for alleviating such two issues, respectively. Experiments on two\ndatasets show the effectiveness of our proposed approach, as compared to the\nstate-of-the-arts.",
    "descriptor": "",
    "authors": [
      "Chenghao Fan",
      "Ziao Li",
      "Wei wei"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.00469"
  },
  {
    "id": "arXiv:2202.00470",
    "title": "An Assessment of the Impact of OCR Noise on Language Models",
    "abstract": "Neural language models are the backbone of modern-day natural language\nprocessing applications. Their use on textual heritage collections which have\nundergone Optical Character Recognition (OCR) is therefore also increasing.\nNevertheless, our understanding of the impact OCR noise could have on language\nmodels is still limited. We perform an assessment of the impact OCR noise has\non a variety of language models, using data in Dutch, English, French and\nGerman. We find that OCR noise poses a significant obstacle to language\nmodelling, with language models increasingly diverging from their noiseless\ntargets as OCR quality lowers. In the presence of small corpora, simpler models\nincluding PPMI and Word2Vec consistently outperform transformer-based models in\nthis respect.",
    "descriptor": "",
    "authors": [
      "Konstantin Todorov",
      "Giovanni Colavizza"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.00470"
  },
  {
    "id": "arXiv:2202.00471",
    "title": "Causal effect of racial bias in data and machine learning algorithms on  user persuasiveness & discriminatory decision making: An Empirical Study",
    "abstract": "Language data and models demonstrate various types of bias, be it ethnic,\nreligious, gender, or socioeconomic. AI/NLP models, when trained on the\nracially biased dataset, AI/NLP models instigate poor model explainability,\ninfluence user experience during decision making and thus further magnifies\nsocietal biases, raising profound ethical implications for society. The\nmotivation of the study is to investigate how AI systems imbibe bias from data\nand produce unexplainable discriminatory outcomes and influence an individual's\narticulateness of system outcome due to the presence of racial bias features in\ndatasets. The design of the experiment involves studying the counterfactual\nimpact of racial bias features present in language datasets and its associated\neffect on the model outcome. A mixed research methodology is adopted to\ninvestigate the cross implication of biased model outcome on user experience,\neffect on decision-making through controlled lab experimentation. The findings\nprovide foundation support for correlating the implication of carry-over an\nartificial intelligence model solving NLP task due to biased concept presented\nin the dataset. Further, the research outcomes justify the negative influence\non users' persuasiveness that leads to alter the decision-making quotient of an\nindividual when trying to rely on the model outcome to act. The paper bridges\nthe gap across the harm caused in establishing poor customer trustworthiness\ndue to an inequitable system design and provides strong support for\nresearchers, policymakers, and data scientists to build responsible AI\nframeworks within organizations.",
    "descriptor": "",
    "authors": [
      "Kinshuk Sengupta",
      "Praveen Ranjan Srivastava"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2202.00471"
  },
  {
    "id": "arXiv:2202.00475",
    "title": "From Examples to Rules: Neural Guided Rule Synthesis for Information  Extraction",
    "abstract": "While deep learning approaches to information extraction have had many\nsuccesses, they can be difficult to augment or maintain as needs shift.\nRule-based methods, on the other hand, can be more easily modified. However,\ncrafting rules requires expertise in linguistics and the domain of interest,\nmaking it infeasible for most users. Here we attempt to combine the advantages\nof these two directions while mitigating their drawbacks. We adapt recent\nadvances from the adjacent field of program synthesis to information\nextraction, synthesizing rules from provided examples. We use a\ntransformer-based architecture to guide an enumerative search, and show that\nthis reduces the number of steps that need to be explored before a rule is\nfound. Further, we show that without training the synthesis algorithm on the\nspecific domain, our synthesized rules achieve state-of-the-art performance on\nthe 1-shot scenario of a task that focuses on few-shot learning for relation\nclassification, and competitive performance in the 5-shot scenario.",
    "descriptor": "",
    "authors": [
      "Robert Vacareanu",
      "Marco A. Valenzuela-Escarcega",
      "George C. G. Barbosa",
      "Rebecca Sharp",
      "Mihai Surdeanu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.00475"
  },
  {
    "id": "arXiv:2202.00476",
    "title": "Exploring COVID-19 Related Stressors Using Topic Modeling",
    "abstract": "The COVID-19 pandemic has affected lives of people from different countries\nfor almost two years. The changes on lifestyles due to the pandemic may cause\npsychosocial stressors for individuals, and have a potential to lead to mental\nhealth problems. To provide high quality mental health supports, healthcare\norganization need to identify the COVID-19 specific stressors, and notice the\ntrends of prevalence of those stressors. This study aims to apply natural\nlanguage processing (NLP) on social media data to identify the psychosocial\nstressors during COVID-19 pandemic, and to analyze the trend on prevalence of\nstressors at different stages of the pandemic. We obtained dataset of 9266\nReddit posts from subreddit \\rCOVID19_support, from 14th Feb ,2020 to 19th July\n2021. We used Latent Dirichlet Allocation (LDA) topic model and lexicon methods\nto identify the topics that were mentioned on the subreddit. Our result\npresented a dashboard to visualize the trend of prevalence of topics about\ncovid-19 related stressors being discussed on social media platform. The result\ncould provide insights about the prevalence of pandemic related stressors\nduring different stages of COVID-19. The NLP techniques leveraged in this study\ncould also be applied to analyze event specific stressors in the future.",
    "descriptor": "",
    "authors": [
      "Yue Tong Leung",
      "Farzad Khalvati"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.00476"
  },
  {
    "id": "arXiv:2202.00477",
    "title": "Detection of Increased Time Intervals of Anti-Vaccine Tweets for  COVID-19 Vaccine with BERT Model",
    "abstract": "The most effective of the solutions against Covid-19 is the various vaccines\ndeveloped. Distrust of vaccines can hinder the rapid and effective use of this\nremedy. One of the means of expressing the thoughts of society is social media.\nDetermining the time intervals during which anti-vaccination increases in\nsocial media can help institutions determine the strategy to be used in\ncombating anti-vaccination. Recording and tracking every tweet entered with\nhuman labor would be inefficient, so various automation solutions are needed.\nIn this study, The Bidirectional Encoder Representations from Transformers\n(BERT) model, which is a deep learning-based natural language processing (NLP)\nmodel, was used. In a dataset of 1506 tweets divided into four different\ncategories as news, irrelevant, anti-vaccine, and vaccine supporters, the model\nwas trained with a learning rate of 5e-6 for 25 epochs. To determine the\nintervals in which anti-vaccine tweets are concentrated, the categories to\nwhich 652840 tweets belong were determined by using the trained model. The\nchange of the determined categories overtime was visualized and the events that\ncould cause the change were determined. As a result of model training, in the\ntest dataset, the f-score of 0.81 and AUC values for different classes were\nobtained as 0.99,0.91, 0.92, 0.92, respectively. In this model, unlike the\nstudies in the literature, an auxiliary system is designed that provides data\nthat institutions can use when determining their strategy by measuring and\nvisualizing the frequency of anti-vaccine tweets in a time interval, different\nfrom detecting and censoring such tweets.",
    "descriptor": "\nComments: in Turkish language. Accepted at 1st International Congress on Artificial Intelligence and Data Science (ICADA 2021)\n",
    "authors": [
      "\u00dclk\u00fc Tuncer K\u00fc\u00e7\u00fckta\u015f",
      "Fatih Uysal",
      "F\u0131rat Hardala\u00e7",
      "\u0130smail Biri"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.00477"
  },
  {
    "id": "arXiv:2202.00478",
    "title": "NeuraHealthNLP: An Automated Screening Pipeline to Detect Undiagnosed  Cognitive Impairment in Electronic Health Records with Deep Learning and  Natural Language Processing",
    "abstract": "Dementia related cognitive impairment (CI) affects over 55 million people\nworldwide and is growing rapidly at the rate of one new case every 3 seconds.\nWith a recurring failure of clinical trials, early diagnosis is crucial, but\n75% of dementia cases go undiagnosed globally with up to 90% in\nlow-and-middle-income countries. Current diagnostic methods are notoriously\ncomplex, involving manual review of medical notes, numerous cognitive tests,\nexpensive brain scans or spinal fluid tests. Information relevant to CI is\noften found in the electronic health records (EHRs) and can provide vital clues\nfor early diagnosis, but a manual review by experts is tedious and error prone.\nThis project develops a novel state-of-the-art automated screening pipeline for\nscalable and high-speed discovery of undetected CI in EHRs. To understand the\nlinguistic context from complex language structures in EHR, a database of 8,656\nsequences was constructed to train attention-based deep learning natural\nlanguage processing model to classify sequences. A patient level prediction\nmodel based on logistic regression was developed using the sequence level\nclassifier. The deep learning system achieved 93% accuracy and AUC = 0.98 to\nidentify patients who had no earlier diagnosis, dementia-related diagnosis\ncode, or dementia-related medications in their EHR. These patients would have\notherwise gone undetected or detected too late. The EHR screening pipeline was\ndeployed in NeuraHealthNLP, a web application for automated and real-time CI\nscreening by simply uploading EHRs in a browser. NeuraHealthNLP is cheaper,\nfaster, more accessible, and outperforms current clinical methods including\ntext-based analytics and machine learning approaches. It makes early diagnosis\nviable in regions with scarce health care services but accessible internet or\ncellular services.",
    "descriptor": "",
    "authors": [
      "Tanish Tyagi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.00478"
  },
  {
    "id": "arXiv:2202.00480",
    "title": "Intent Matching based Customer Services Chatbot with Natural Language  Understanding",
    "abstract": "Customer service is the lifeblood of any business. Excellent customer service\nnot only generates return business but also creates new customers. Looking at\nthe demanding market to provide a 24/7 service to customers, many organisations\nare increasingly engaged in popular social media and text messaging platforms\nsuch as WhatsApp and Facebook Messenger in providing a 24/7 service to\ncustomers in the current demanding market. In this paper, we present an intent\nmatching based customer services chatbot (IMCSC), which is capable of replacing\nthe customer service work of sales personnel, whilst interacting in a more\nnatural and human-like manner through the employment of Natural Language\nUnderstanding (NLU). The bot is able to answer the most common frequently asked\nquestions and we have also integrated features for the processing and exporting\nof customer orders to a Google Sheet.",
    "descriptor": "\nComments: Accepted by \"the 5th International Conference on Communication and Information Systems (ICCIS 2021)\"\n",
    "authors": [
      "Alvin Chaidrata",
      "Mariyam Imtha Shafeeu",
      "Sze Ker Chew",
      "Zhiyuan Chen",
      "Jin Sheng Cham",
      "Zi Li Yong",
      "Uen Hsieh Yap",
      "Dania Imanina Binti Kamarul Bahrin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.00480"
  },
  {
    "id": "arXiv:2202.00481",
    "title": "RabindraNet, Creating Literary Works in the Style of Rabindranath Tagore",
    "abstract": "Bengali literature has a rich history of hundreds of years with luminary\nfigures such as Rabindranath Tagore and Kazi Nazrul Islam. However, analytical\nworks involving the most recent advancements in NLP have barely scratched the\nsurface utilizing the enormous volume of the collected works from the writers\nof the language. In order to bring attention to the analytical study involving\nthe works of Bengali writers and spearhead the text generation endeavours in\nthe style of existing literature, we are introducing RabindraNet, a character\nlevel RNN model with stacked-LSTM layers trained on the works of Rabindranath\nTagore to produce literary works in his style for multiple genres. We created\nan extensive dataset as well by compiling the digitized works of Rabindranath\nTagore from authentic online sources and published as open source dataset on\ndata science platform Kaggle.",
    "descriptor": "",
    "authors": [
      "Asadullah Al Galib"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.00481"
  },
  {
    "id": "arXiv:2202.00484",
    "title": "Auto-ABSA: Automatic Detection of Aspects in Aspect-Based Sentiment  Analysis",
    "abstract": "After transformer is proposed, lots of pre-trained language models have been\ncome up with and sentiment analysis (SA) task has been improved. In this paper,\nwe proposed a method that uses an auxiliary sentence about aspects that the\nsentence contains to help sentiment prediction. The first is aspect detection,\nwhich uses a multi-aspects detection model to predict all aspects that the\nsentence has. Combining the predicted aspects and the original sentence as\nSentiment Analysis (SA) model's input. The second is to do out-of-domain\naspect-based sentiment analysis(ABSA), train sentiment classification model\nwith one kind of dataset and validate it with another kind of dataset. Finally,\nwe created two baselines, they use no aspect and all aspects as sentiment\nclassification model's input, respectively. Compare two baselines performance\nto our method, found that our method really makes sense.",
    "descriptor": "",
    "authors": [
      "Teng Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.00484"
  },
  {
    "id": "arXiv:2202.00486",
    "title": "Towards a Theoretical Understanding of Word and Relation Representation",
    "abstract": "Representing words by vectors, or embeddings, enables computational reasoning\nand is foundational to automating natural language tasks. For example, if word\nembeddings of similar words contain similar values, word similarity can be\nreadily assessed, whereas judging that from their spelling is often impossible\n(e.g. cat /feline) and to predetermine and store similarities between all words\nis prohibitively time-consuming, memory intensive and subjective. We focus on\nword embeddings learned from text corpora and knowledge graphs. Several\nwell-known algorithms learn word embeddings from text on an unsupervised basis\nby learning to predict those words that occur around each word, e.g. word2vec\nand GloVe. Parameters of such word embeddings are known to reflect word\nco-occurrence statistics, but how they capture semantic meaning has been\nunclear. Knowledge graph representation models learn representations both of\nentities (words, people, places, etc.) and relations between them, typically by\ntraining a model to predict known facts in a supervised manner. Despite steady\nimprovements in fact prediction accuracy, little is understood of the latent\nstructure that enables this.\nThe limited understanding of how latent semantic structure is encoded in the\ngeometry of word embeddings and knowledge graph representations makes a\nprincipled means of improving their performance, reliability or\ninterpretability unclear. To address this:\n1. we theoretically justify the empirical observation that particular\ngeometric relationships between word embeddings learned by algorithms such as\nword2vec and GloVe correspond to semantic relations between words; and\n2. we extend this correspondence between semantics and geometry to the\nentities and relations of knowledge graphs, providing a model for the latent\nstructure of knowledge graph representation linked to that of word embeddings.",
    "descriptor": "\nComments: PhD thesis\n",
    "authors": [
      "Carl Allen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.00486"
  },
  {
    "id": "arXiv:2202.00498",
    "title": "Analysis of Linear Time-Varying & Periodic Systems",
    "abstract": "This thesis applies Floquet theory to analyze linear periodic time-varying\n(LPTV) systems, represented by a system of ordinary differential equations\n(ODEs) that depend on a time variable t and have a matrix of coefficients with\nperiod T>0. The transition matrix of an LPTV system represented by a square\nperiodic-function matrix A(t)=A(t+T) can be expressed as the product of a\nsquare periodic function matrix P(t)=P(t+T) and an exponentiated square matrix\nof the form Rt, where R is a constant matrix (independent of t). Despite the\nvalidity of Floquet theory, it is difficult to find an analytical closed form\nfor the matrices P(t) and R when the transition matrix {\\Phi}_A (t,t_0 ) is\nunknown. In essence, it is difficult to find an analytical solution for an LPTV\nsystem (i.e., a closed form for its transition matrix). The research results\nshow that for a given family of periodic matrices A(t), we can compare the\npowers of {\\omega} that multiply the harmonics (i.e., {\\omega} is part of the\ncoefficients multiplying the cosine [sine] factors in even [odd]\nrepresentations or of the exponential factors in complex representations) to\ndetermine the matrices P(t) and R. In addition, the results lead to relations\nbetween LPTV systems at frequency {\\omega} and the associated linear\ntime-invariant system, which is defined by having zero frequency ({\\omega}=0).",
    "descriptor": "\nComments: 135 pages, 3 figures, 5 tables, Thesis for: MSc, Advisor: Izchak Lewkowicz, institution: Ben Gurion University of the Negev\n",
    "authors": [
      "Oren Fivel"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.00498"
  },
  {
    "id": "arXiv:2202.00500",
    "title": "A Framework for Server Authentication using Communication Protocol  Dialects",
    "abstract": "In today's world, computer networks have become vulnerable to numerous\nattacks. In both wireless and wired networks, one of the most common attacks is\nman-in-the-middle attacks, within which session hijacking, context confusion\nattacks have been the most attempted. A potential attacker may have enough time\nto launch an attack targeting these vulnerabilities (such as rerouting the\ntarget request to a malicious server or hijacking the traffic). A viable\nstrategy to solve this problem is, by dynamically changing the system\nproperties, configurations and create unique fingerprints to identify the\nsource. However, the existing work of fingerprinting mainly focuses on\nlower-level properties (e.g IP address), and only these types of properties are\nrestricted for mutation.\nWe develop a novel system, called Verify-Pro, to provide server\nauthentication using communication protocol dialects, that uses a client-server\narchitecture based on network protocols for customizing the communication\ntransactions. For each session, a particular sequence of handshakes will be\nused as dialects. So, given the context, with the establishment of a one-time\nusername and password, we use the dialects as an authentication mechanism for\neach request (e.g get filename in FTP) throughout the session, which enforces\ncontinuous authentication. Specifically, we leverage a machine learning\napproach on both client and server machines to trigger a specific dialect that\ndynamically changes for each request.\nWe implement a prototype of Verify-Pro and evaluate its practicality on\nstandard communication protocols FTP, HTTP & internet of things protocol MQTT.\nOur experimental results show that by sending misleading information through\nmessage packets from an attacker at the application layer, it is possible for\nthe recipient to identify if the sender is genuine or a spoofed one, with a\nnegligible overhead of 0.536%.",
    "descriptor": "",
    "authors": [
      "Kailash Gogineni",
      "Yongsheng Mei",
      "Guru Venkataramani",
      "Tian Lan"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.00500"
  },
  {
    "id": "arXiv:2202.00504",
    "title": "Fine-grained differentiable physics: a yarn-level model for fabrics",
    "abstract": "Differentiable physics modeling combines physics models with gradient-based\nlearning to provide model explicability and data efficiency. It has been used\nto learn dynamics, solve inverse problems and facilitate design, and is at its\ninception of impact. Current successes have concentrated on general physics\nmodels such as rigid bodies, deformable sheets, etc., assuming relatively\nsimple structures and forces. Their granularity is intrinsically coarse and\ntherefore incapable of modelling complex physical phenomena. Fine-grained\nmodels are still to be developed to incorporate sophisticated material\nstructures and force interactions with gradient-based learning. Following this\nmotivation, we propose a new differentiable fabrics model for composite\nmaterials such as cloths, where we dive into the granularity of yarns and model\nindividual yarn physics and yarn-to-yarn interactions. To this end, we propose\nseveral differentiable forces, whose counterparts in empirical physics are\nindifferentiable, to facilitate gradient-based learning. These forces, albeit\napplied to cloths, are ubiquitous in various physical systems. Through\ncomprehensive evaluation and comparison, we demonstrate our model's\nexplicability in learning meaningful physical parameters, versatility in\nincorporating complex physical structures and heterogeneous materials,\ndata-efficiency in learning, and high-fidelity in capturing subtle dynamics.",
    "descriptor": "",
    "authors": [
      "Deshan Gong",
      "Zhanxing Zhu",
      "Andrew J.Bulpitt",
      "He Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.00504"
  },
  {
    "id": "arXiv:2202.00506",
    "title": "Multi-cell Non-coherent Over-the-Air Computation for Federated Edge  Learning",
    "abstract": "In this paper, we propose a framework where over-the-air computation (OAC)\noccurs in both uplink (UL) and downlink (DL), sequentially, in a multi-cell\nenvironment to address the latency and the scalability issues of federated edge\nlearning (FEEL). To eliminate the channel state information (CSI) at the edge\ndevices (EDs) and edge servers (ESs) and relax the time-synchronization\nrequirement for the OAC, we use a non-coherent computation scheme, i.e.,\nfrequency-shift keying (FSK)-based majority vote (MV) (FSK-MV). With the\nproposed framework, multiple ESs function as the aggregation nodes in the UL\nand each ES determines the MVs independently. After the ESs broadcast the\ndetected MVs, the EDs determine the sign of the gradient through another OAC in\nthe DL. Hence, inter-cell interference is exploited for the OAC. In this study,\nwe prove the convergence of the non-convex optimization problem for the FEEL\nwith the proposed OAC framework. We also numerically evaluate the efficacy of\nthe proposed method by comparing the test accuracy in both multi-cell and\nsingle-cell scenarios for both homogeneous and heterogeneous data\ndistributions.",
    "descriptor": "\nComments: 6 pages, accepted to International Conference on Communications (ICC) 2022\n",
    "authors": [
      "Mohammad Hassan Adeli",
      "Alphan Sahin"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.00506"
  },
  {
    "id": "arXiv:2202.00512",
    "title": "Progressive Distillation for Fast Sampling of Diffusion Models",
    "abstract": "Diffusion models have recently shown great promise for generative modeling,\noutperforming GANs on perceptual quality and autoregressive models at density\nestimation. A remaining downside is their slow sampling time: generating high\nquality samples takes many hundreds or thousands of model evaluations. Here we\nmake two contributions to help eliminate this downside: First, we present new\nparameterizations of diffusion models that provide increased stability when\nusing few sampling steps. Second, we present a method to distill a trained\ndeterministic diffusion sampler, using many steps, into a new diffusion model\nthat takes half as many sampling steps. We then keep progressively applying\nthis distillation procedure to our model, halving the number of required\nsampling steps each time. On standard image generation benchmarks like\nCIFAR-10, ImageNet, and LSUN, we start out with state-of-the-art samplers\ntaking as many as 8192 steps, and are able to distill down to models taking as\nfew as 4 steps without losing much perceptual quality; achieving, for example,\na FID of 3.0 on CIFAR-10 in 4 steps. Finally, we show that the full progressive\ndistillation procedure does not take more time than it takes to train the\noriginal model, thus representing an efficient solution for generative modeling\nusing diffusion at both train and test time.",
    "descriptor": "\nComments: Published as a conference paper at ICLR 2022\n",
    "authors": [
      "Tim Salimans",
      "Jonathan Ho"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.00512"
  },
  {
    "id": "arXiv:2202.00514",
    "title": "Analyzing Community-aware Centrality Measures Using The Linear Threshold  Model",
    "abstract": "Targeting influential nodes in complex networks allows fastening or hindering\nrumors, epidemics, and electric blackouts. Since communities are prevalent in\nreal-world networks, community-aware centrality measures exploit this\ninformation to target influential nodes. Researches show that they compare\nfavorably with classical measures that are agnostic about the community\nstructure. Although the diffusion process is of prime importance, previous\nstudies consider mainly the famous Susceptible-Infected-Recovered (SIR)\nepidemic propagation model. This work investigates the consistency of previous\nanalyses using the popular Linear Threshold (LT) propagation model, which\ncharacterizes many spreading processes in our real life. We perform a\ncomparative analysis of seven influential community-aware centrality measures\non thirteen real-world networks. Overall, results show that Community-based\nMediator, Comm Centrality, and Modularity Vitality outperform the other\nmeasures. Moreover, Community-based Mediator is more effective on a tight\nbudget (i.e., a small fraction of initially activated nodes), while Comm\nCentrality and Modularity Vitality perform better with a medium to a high\nfraction of initially activated nodes.",
    "descriptor": "\nComments: Accepted in International Conference on Complex Networks and Their Applications 2022\n",
    "authors": [
      "Stephany Rajeh",
      "Ali Yassin",
      "Ali Jaber",
      "Hocine Cherifi"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2202.00514"
  },
  {
    "id": "arXiv:2202.00515",
    "title": "Comparing Community-aware Centrality Measures in Online Social Networks",
    "abstract": "Identifying key nodes is crucial for accelerating or impeding dynamic\nspreading in a network. Community-aware centrality measures tackle this problem\nby exploiting the community structure of a network. Although there is a growing\ntrend to design new community-aware centrality measures, there is no systematic\ninvestigation of the proposed measures' effectiveness. This study performs an\nextensive comparative evaluation of prominent community-aware centrality\nmeasures using the Susceptible-Infected-Recovered (SIR) model on real-world\nonline social networks. Overall, results show that K-shell with Community and\nCommunity-based Centrality measures are the most accurate in identifying\ninfluential nodes under a single-spreader problem. Additionally, the epidemic\ntransmission rate doesn't significantly affect the behavior of the\ncommunity-aware centrality measures.",
    "descriptor": "\nComments: Accepted in International Conference on Computational Data and Social Networks - CSoNet 2021: Computational Data and Social Networks\n",
    "authors": [
      "Stephany Rajeh",
      "Marinette Savonnet",
      "Eric Leclercq",
      "Hocine Cherifi"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2202.00515"
  },
  {
    "id": "arXiv:2202.00516",
    "title": "Identifying Influential Nodes Using Overlapping Modularity Vitality",
    "abstract": "It is of paramount importance to uncover influential nodes to control\ndiffusion phenomena in a network. In recent works, there is a growing trend to\ninvestigate the role of the community structure to solve this issue. Up to now,\nthe vast majority of the so-called community-aware centrality measures rely on\nnon-overlapping community structure. However, in many real-world networks, such\nas social networks, the communities overlap. In other words, a node can belong\nto multiple communities. To overcome this drawback, we propose and investigate\nthe \"Overlapping Modularity Vitality\" centrality measure. This extension of\n\"Modularity Vitality\" quantifies the community structure strength variation\nwhen removing a node. It allows identifying a node as a hub or a bridge based\non its contribution to the overlapping modularity of a network. A comparative\nanalysis with its non-overlapping version using the\nSusceptible-Infected-Recovered (SIR) epidemic diffusion model has been\nperformed on a set of six real-world networks. Overall, Overlapping Modularity\nVitality outperforms its alternative. These results illustrate the importance\nof incorporating knowledge about the overlapping community structure to\nidentify influential nodes effectively. Moreover, one can use multiple ranking\nstrategies as the two measures are signed. Results show that selecting the\nnodes with the top positive or the top absolute centrality values is more\neffective than choosing the ones with the maximum negative values to spread the\nepidemic.",
    "descriptor": "\nComments: Conference: ASONAM '21: International Conference on Advances in Social Networks Analysis and Mining\n",
    "authors": [
      "Stephany Rajeh",
      "Marinette Savonnet",
      "Eric Leclercq",
      "Hocine Cherifi"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2202.00516"
  },
  {
    "id": "arXiv:2202.00517",
    "title": "Empirical complexity of comparator-based nearest neighbor descent",
    "abstract": "A Java parallel streams implementation of the $K$-nearest neighbor descent\nalgorithm is presented using a natural statistical termination criterion. Input\ndata consist of a set $S$ of $n$ objects of type V, and a Function<V,\nComparator<V>>, which enables any $x \\in S$ to decide which of $y, z \\in\nS\\setminus\\{x\\}$ is more similar to $x$. Experiments with the Kullback-Leibler\ndivergence Comparator support the prediction that the number of rounds of\n$K$-nearest neighbor updates need not exceed twice the diameter of the\nundirected version of a random regular out-degree $K$ digraph on $n$ vertices.\nOverall complexity was $O(n K^2 \\log_K(n))$ in the class of examples studied.\nWhen objects are sampled uniformly from a $d$-dimensional simplex, accuracy of\nthe $K$-nearest neighbor approximation is high up to $d = 20$, but declines in\nhigher dimensions, as theory would predict.",
    "descriptor": "\nComments: 8 pages, 1 figure\n",
    "authors": [
      "Jacob D. Baron",
      "R. W. R. Darling"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.00517"
  },
  {
    "id": "arXiv:2202.00519",
    "title": "MotifExplainer: a Motif-based Graph Neural Network Explainer",
    "abstract": "We consider the explanation problem of Graph Neural Networks (GNNs). Most\nexisting GNN explanation methods identify the most important edges or nodes but\nfail to consider substructures, which are more important for graph data. The\nonly method that considers subgraphs tries to search all possible subgraphs and\nidentify the most significant subgraphs. However, the subgraphs identified may\nnot be recurrent or statistically important. In this work, we propose a novel\nmethod, known as MotifExplainer, to explain GNNs by identifying important\nmotifs, recurrent and statistically significant patterns in graphs. Our\nproposed motif-based methods can provide better human-understandable\nexplanations than methods based on nodes, edges, and regular subgraphs. Given\nan input graph and a pre-trained GNN model, our method first extracts motifs in\nthe graph using well-designed motif extraction rules. Then we generate motif\nembedding by feeding motifs into the pre-trained GNN. Finally, we employ an\nattention-based method to identify the most influential motifs as explanations\nfor the final prediction results. The empirical studies on both synthetic and\nreal-world datasets demonstrate the effectiveness of our method.",
    "descriptor": "",
    "authors": [
      "Zhaoning Yu",
      "Hongyang Gao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.00519"
  },
  {
    "id": "arXiv:2202.00520",
    "title": "Fast and Exact Matrix Factorization Updates for Nonlinear Programming",
    "abstract": "LU and Cholesky matrix factorization algorithms are core subroutines used to\nsolve systems of linear equations (SLEs) encountered while solving an\noptimization problem. Standard factorization algorithms are highly efficient\nbut remain susceptible to the accumulation roundoff errors, which can lead\nsolvers to return feasibility and optimality certificates that are actually\ninvalid. This paper introduces a novel approach for solving sequences of\nclosely related SLEs encountered in nonlinear programming efficiently and\nwithout roundoff errors. Specifically, it introduces rank-one update algorithms\nfor the roundoff-error-free (REF) factorization framework, a toolset built on\ninteger-preserving arithmetic that has led to the development and\nimplementation of fail-proof SLE solution subroutines for linear programming.\nThe formal guarantees of the proposed algorithms are formally established\nthrough the derivation of theoretical insights. Their computational advantages\nare supported with computational experiments, which demonstrate upwards of\n75x-improvements over exact factorization run-times on fully dense matrices\nwith over one million entries. A significant advantage of the proposed\nmethodology is that the length of any coefficient calculated via the associated\nalgorithms is bounded polynomially in the size of the inputs without having to\nresort to greatest common divisor operations, which are required by and thereby\nhinder an efficient implementation of exact rational arithmetic approaches.",
    "descriptor": "\nComments: 31 pages, 1 figure, 1 table\n",
    "authors": [
      "Adolfo R. Escobedo"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2202.00520"
  },
  {
    "id": "arXiv:2202.00528",
    "title": "Examining Scaling and Transfer of Language Model Architectures for  Machine Translation",
    "abstract": "Natural language understanding and generation models follow one of the two\ndominant architectural paradigms: language models (LMs) that process\nconcatenated sequences in a single stack of layers, and encoder-decoder models\n(EncDec) that utilize separate layer stacks for input and output processing. In\nmachine translation, EncDec has long been the favoured approach, but with few\nstudies investigating the performance of LMs. In this work, we thoroughly\nexamine the role of several architectural design choices on the performance of\nLMs on bilingual, (massively) multilingual and zero-shot translation tasks,\nunder systematic variations of data conditions and model sizes. Our results\nshow that: (i) Different LMs have different scaling properties, where\narchitectural differences often have a significant impact on model performance\nat small scales, but the performance gap narrows as the number of parameters\nincreases, (ii) Several design choices, including causal masking and\nlanguage-modeling objectives for the source sequence, have detrimental effects\non translation quality, and (iii) When paired with full-visible masking for\nsource sequences, LMs could perform on par with EncDec on supervised bilingual\nand multilingual translation tasks, and improve greatly on zero-shot directions\nby facilitating the reduction of off-target translations.",
    "descriptor": "",
    "authors": [
      "Biao Zhang",
      "Behrooz Ghorbani",
      "Ankur Bapna",
      "Yong Cheng",
      "Xavier Garcia",
      "Jonathan Shen",
      "Orhan Firat"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.00528"
  },
  {
    "id": "arXiv:2202.00529",
    "title": "Molecular Graph Representation Learning via Heterogeneous Motif Graph  Construction",
    "abstract": "We consider feature representation learning problem of molecular graphs.\nGraph Neural Networks have been widely used in feature representation learning\nof molecular graphs. However, most existing methods deal with molecular graphs\nindividually while neglecting their connections, such as motif-level\nrelationships. We propose a novel molecular graph representation learning\nmethod by constructing a heterogeneous motif graph to address this issue. In\nparticular, we build a heterogeneous motif graph that contains motif nodes and\nmolecular nodes. Each motif node corresponds to a motif extracted from\nmolecules. Then, we propose a Heterogeneous Motif Graph Neural Network (HM-GNN)\nto learn feature representations for each node in the heterogeneous motif\ngraph. Our heterogeneous motif graph also enables effective multi-task\nlearning, especially for small molecular datasets. To address the potential\nefficiency issue, we propose to use an edge sampler, which can significantly\nreduce computational resources usage. The experimental results show that our\nmodel consistently outperforms previous state-of-the-art models. Under\nmulti-task settings, the promising performances of our methods on combined\ndatasets shed light on a new learning paradigm for small molecular datasets.\nFinally, we show that our model achieves similar performances with\nsignificantly less computational resources by using our edge sampler.",
    "descriptor": "",
    "authors": [
      "Zhaoning Yu",
      "Hongyang Gao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.00529"
  },
  {
    "id": "arXiv:2202.00530",
    "title": "Coordinated Frequency Control through Safe Reinforcement Learning",
    "abstract": "With widespread deployment of renewables, the electric power grids are\nexperiencing increasing dynamics and uncertainties, with its secure operation\nbeing threatened. Existing frequency control schemes based on day-ahead offline\nanalysis and minute-level online sensitivity calculations are difficult to\nadapt to rapidly changing system states. In particular, they are unable to\nfacilitate coordinated control of system frequency and power flows. A refined\napproach and tools are urgently needed to assist system operators to make\ntimely decisions. This paper proposes a novel model-free coordinated frequency\ncontrol framework based on safe reinforcement learning, with multiple control\nobjectives considered. The load frequency control problem is modeled as a\nconstrained Markov decision process, which can be solved by an AI agent\ncontinuously interacting with the grid to achieve sub-second decision making.\nExtensive numerical experiments conducted at East China Power Grid demonstrate\nthe effectiveness and promise of the proposed method.",
    "descriptor": "\nComments: This paper was accepted by 2022 IEEE PES General Meeting\n",
    "authors": [
      "Yi Zhou",
      "Liangcai Zhou",
      "Di Shi",
      "Xiaoying Zhao"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.00530"
  },
  {
    "id": "arXiv:2202.00531",
    "title": "Planner-Reasoner Inside a Multi-task Reasoning Agent",
    "abstract": "We consider the problem of multi-task reasoning (MTR), where an agent can\nsolve multiple tasks via (first-order) logic reasoning. This capability is\nessential for human-like intelligence due to its strong generalizability and\nsimplicity for handling multiple tasks. However, a major challenge in\ndeveloping effective MTR is the intrinsic conflict between reasoning capability\nand efficiency. An MTR-capable agent must master a large set of \"skills\" to\ntackle diverse tasks, but executing a particular task at the inference stage\nrequires only a small subset of immediately relevant skills. How can we\nmaintain broad reasoning capability and also efficient specific-task\nperformance? To address this problem, we propose a Planner-Reasoner framework\ncapable of state-of-the-art MTR capability and high efficiency. The Reasoner\nmodels shareable (first-order) logic deduction rules, from which the Planner\nselects a subset to compose into efficient reasoning paths. The entire model is\ntrained in an end-to-end manner using deep reinforcement learning, and\nexperimental studies over a variety of domains validate its effectiveness.",
    "descriptor": "",
    "authors": [
      "Daoming Lyu",
      "Bo Liu",
      "Jianshu Chen"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.00531"
  },
  {
    "id": "arXiv:2202.00535",
    "title": "Novelty Controlled Paraphrase Generation with Retrieval Augmented  Conditional Prompt Tuning",
    "abstract": "Paraphrase generation is a fundamental and long-standing task in natural\nlanguage processing. In this paper, we concentrate on two contributions to the\ntask: (1) we propose Retrieval Augmented Prompt Tuning (RAPT) as a\nparameter-efficient method to adapt large pre-trained language models for\nparaphrase generation; (2) we propose Novelty Conditioned RAPT (NC-RAPT) as a\nsimple model-agnostic method of using specialized prompt tokens for controlled\nparaphrase generation with varying levels of lexical novelty. By conducting\nextensive experiments on four datasets, we demonstrate the effectiveness of the\nproposed approaches for retaining the semantic content of the original text\nwhile inducing lexical novelty in the generation.",
    "descriptor": "\nComments: Accepted by AAAI 2022\n",
    "authors": [
      "Jishnu Ray Chowdhury",
      "Yong Zhuang",
      "Shuyi Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.00535"
  },
  {
    "id": "arXiv:2202.00537",
    "title": "Maximum Batch Frobenius Norm for Multi-Domain Text Classification",
    "abstract": "Multi-domain text classification (MDTC) has obtained remarkable achievements\ndue to the advent of deep learning. Recently, many endeavors are devoted to\napplying adversarial learning to extract domain-invariant features to yield\nstate-of-the-art results. However, these methods still face one challenge:\ntransforming original features to be domain-invariant distorts the\ndistributions of the original features, degrading the discriminability of the\nlearned features. To address this issue, we first investigate the structure of\nthe batch classification output matrix and theoretically justify that the\ndiscriminability of the learned features has a positive correlation with the\nFrobenius norm of the batch output matrix. Based on this finding, we propose a\nmaximum batch Frobenius norm (MBF) method to boost the feature discriminability\nfor MDTC. Experiments on two MDTC benchmarks show that our MBF approach can\neffectively advance the performance of the state-of-the-art.",
    "descriptor": "\nComments: 5 pages, ICASSP 2022\n",
    "authors": [
      "Yuan Wu",
      "Diana Inkpen",
      "Ahmed El-Roby"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.00537"
  },
  {
    "id": "arXiv:2202.00538",
    "title": "The impact of removing head movements on audio-visual speech enhancement",
    "abstract": "This paper investigates the impact of head movements on audio-visual speech\nenhancement (AVSE). Although being a common conversational feature, head\nmovements have been ignored by past and recent studies: they challenge today's\nlearning-based methods as they often degrade the performance of models that are\ntrained on clean, frontal, and steady face images. To alleviate this problem,\nwe propose to use robust face frontalization (RFF) in combination with an AVSE\nmethod based on a variational auto-encoder (VAE) model. We briefly describe the\nbasic ingredients of the proposed pipeline and we perform experiments with a\nrecently released audio-visual dataset. In the light of these experiments, and\nbased on three standard metrics, namely STOI, PESQ and SI-SDR, we conclude that\nRFF improves the performance of AVSE by a considerable margin.",
    "descriptor": "",
    "authors": [
      "Zhiqi Kang",
      "Mostafa Sadeghi",
      "Radu Horaud",
      "Xavier Alameda-Pineda",
      "Jacob Donley",
      "Anurag Kumar"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2202.00538"
  },
  {
    "id": "arXiv:2202.00540",
    "title": "Dominant Set-based Active Learning for Text Classification and its  Application to Online Social Media",
    "abstract": "Recent advances in natural language processing (NLP) in online social media\nare evidently owed to large-scale datasets. However, labeling, storing, and\nprocessing a large number of textual data points, e.g., tweets, has remained\nchallenging. On top of that, in applications such as hate speech detection,\nlabeling a sufficiently large dataset containing offensive content can be\nmentally and emotionally taxing for human annotators. Thus, NLP methods that\ncan make the best use of significantly less labeled data points are of great\ninterest. In this paper, we present a novel pool-based active learning method\nthat can be used for the training of large unlabeled corpus with minimum\nannotation cost. For that, we propose to find the dominant sets of local\nclusters in the feature space. These sets represent maximally cohesive\nstructures in the data. Then, the samples that do not belong to any of the\ndominant sets are selected to be used to train the model, as they represent the\nboundaries of the local clusters and are more challenging to classify. Our\nproposed method does not have any parameters to be tuned, making it\ndataset-independent, and it can approximately achieve the same classification\naccuracy as full training data, with significantly fewer data points.\nAdditionally, our method achieves a higher performance in comparison to the\nstate-of-the-art active learning strategies. Furthermore, our proposed\nalgorithm is able to incorporate conventional active learning scores, such as\nuncertainty-based scores, into its selection criteria. We show the\neffectiveness of our method on different datasets and using different neural\nnetwork architectures.",
    "descriptor": "\nComments: 11 pages, 5 tables, 1 figure\n",
    "authors": [
      "Toktam A. Oghaz",
      "Ivan Garibay"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.00540"
  },
  {
    "id": "arXiv:2202.00543",
    "title": "Testability and local certification of monotone properties in  minor-closed classes",
    "abstract": "The main problem in the area of property testing is to understand which graph\nproperties are \\emph{testable}, which means that with constantly many queries\nto any input graph $G$, a tester can decide with good probability whether $G$\nsatisfies the property, or is far from satisfying the property. Testable\nproperties are well understood in the dense model and in the bounded degree\nmodel, but little is known in sparse graph classes when graphs are allowed to\nhave unbounded degree. This is the setting of the \\emph{sparse model}. We prove\nthat for any proper minor-closed class $\\mathcal{G}$, any monotone property\n(i.e., any property that is closed under taking subgraphs) is testable for\ngraphs from $\\mathcal{G}$ in the sparse model. This extends a result of Czumaj\nand Sohler (FOCS'19), who proved it for monotone properties with finitely many\nobstructions. Our result implies for instance that for any integers $k$ and\n$t$, $k$-colorability of $K_t$-minor free graphs is testable in the sparse\nmodel.\nElek recently proved that planarity of bounded degree graphs is almost\nlocally checkable in constant time. We show again that the assumption of\nbounded degree can be omitted in his result.",
    "descriptor": "\nComments: 12 pages\n",
    "authors": [
      "Louis Esperet",
      "Sergey Norin"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2202.00543"
  },
  {
    "id": "arXiv:2202.00553",
    "title": "Neural Tangent Kernel Beyond the Infinite-Width Limit: Effects of Depth  and Initialization",
    "abstract": "Neural Tangent Kernel (NTK) is widely used to analyze overparametrized neural\nnetworks due to the famous result by (Jacot et al., 2018): in the\ninfinite-width limit, the NTK is deterministic and constant during training.\nHowever, this result cannot explain the behavior of deep networks, since it\ngenerally does not hold if depth and width tend to infinity simultaneously. In\nthis paper, we study the NTK of fully-connected ReLU networks with depth\ncomparable to width. We prove that the NTK properties depend significantly on\nthe depth-to-width ratio and the distribution of parameters at initialization.\nIn fact, our results indicate the importance of the three phases in the\nhyperparameter space identified in (Poole et al., 2016): ordered, chaotic and\nthe edge of chaos (EOC). We derive exact expressions for the NTK dispersion in\nthe infinite-depth-and-width limit in all three phases and conclude that the\nNTK variability grows exponentially with depth at the EOC and in the chaotic\nphase but not in the ordered phase. We also show that the NTK of deep networks\nmay stay constant during training only in the ordered phase and discuss how the\nstructure of the NTK matrix changes during training.",
    "descriptor": "",
    "authors": [
      "Mariia Seleznova",
      "Gitta Kutyniok"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.00553"
  },
  {
    "id": "arXiv:2202.00557",
    "title": "Finding the optimal human strategy for Wordle using maximum correct  letter probabilities and reinforcement learning",
    "abstract": "Wordle is an online word puzzle game that gained viral popularity in January\n2022. The goal is to guess a hidden five letter word. After each guess, the\nplayer gains information about whether the letters they guessed are present in\nthe word, and whether they are in the correct position. Numerous blogs have\nsuggested guessing strategies and starting word lists that improve the chance\nof winning. Optimized algorithms can win 100% of games within five of the six\nallowed trials. However, it is infeasible for human players to use these\nalgorithms due to an inability to perfectly recall all known 5-letter words and\nperform complex calculations that optimize information gain. Here, we present\ntwo different methods for choosing starting words along with a framework for\ndiscovering the optimal human strategy based on reinforcement learning. Human\nWordle players can use the rules we discover to optimize their chance of\nwinning.",
    "descriptor": "",
    "authors": [
      "Benton J. Anderson",
      "Jesse G. Meyer"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.00557"
  },
  {
    "id": "arXiv:2202.00561",
    "title": "Blockchain scalability for smart contract systems using eUTXO model",
    "abstract": "This research critically analyses blockchain scaling solutions based on their\nability to realistically balance the properties of the blockchain trilemma. We\nhave concluded this research by outlining a gap in the current body of\nliterature and implementation of scalability solutions. An extended UTXO\ntransaction model is proposed to overcome challenges associated with\nimplementing both layer one and layer two scaling solutions in a blockchain\nsystem. The examination of industry approaches is used to justify this\ndirection and puts forth a basis for future work.",
    "descriptor": "\nComments: 9 Pages\n",
    "authors": [
      "Frazer Chard",
      "Cayo Fletcher-Smith"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.00561"
  },
  {
    "id": "arXiv:2202.00573",
    "title": "Development of a neural network to recognize standards and features from  3D CAD models",
    "abstract": "Focus of this work is to recognize standards and further features directly\nfrom 3D CAD models. For this reason, a neural network was trained to recognize\nnine classes of machine elements. After the system identified a part as a\nstandard, like a hexagon head screw after the DIN EN ISO 8676, it accesses the\ngeometrical information of the CAD system via the Application Programming\nInterface (API). In the API, the system searches for necessary information to\ndescribe the part appropriately. Based on this information standardized parts\ncan be recognized in detail and supplemented with further information.",
    "descriptor": "",
    "authors": [
      "Alexander Neb",
      "Iyed Briki",
      "Raoul Schoenhof"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.00573"
  },
  {
    "id": "arXiv:2202.00576",
    "title": "Subcell limiting strategies for discontinuous Galerkin spectral element  methods",
    "abstract": "We present a general family of subcell limiting strategies to construct\nrobust high-order accurate nodal discontinuous Galerkin (DG) schemes. The main\nstrategy is to construct compatible low order finite volume (FV) type\ndiscretizations that allow for convex blending with the high-order variant with\nthe goal of guaranteeing additional properties, such as bounds on physical\nquantities and/or guaranteed entropy dissipation. For an implementation of this\nmain strategy, four main ingredients are identified that may be combined in a\nflexible manner: (i) a nodal high-order DG method on Legendre-Gauss-Lobatto\nnodes, (ii) a compatible robust subcell FV scheme, (iii) a convex combination\nstrategy for the two schemes, which can be element-wise or subcell-wise, and\n(iv) a strategy to compute the convex blending factors, which can be either\nbased on heuristic troubled-cell indicators, or using ideas from flux-corrected\ntransport methods.\nBy carefully designing the metric terms of the subcell FV method, the\nresulting methods can be used on unstructured curvilinear meshes, are locally\nconservative, can handle strong shocks efficiently while directly guaranteeing\nphysical bounds on quantities such as density, pressure or entropy. We further\nshow that it is possible to choose the four ingredients to recover existing\nmethods such as a provably entropy dissipative subcell shock-capturing approach\nor a sparse invariant domain preserving approach.\nWe test the versatility of the presented strategies and mix and match the\nfour ingredients to solve challenging simulation setups, such as the KPP\nproblem (a hyperbolic conservation law with non-convex flux function),\nturbulent and hypersonic Euler simulations, and MHD problems featuring shocks\nand turbulence.",
    "descriptor": "\nComments: 26 pages, 11 figures\n",
    "authors": [
      "Andr\u00e9s M. Rueda-Ram\u00edrez",
      "Will Pazner",
      "Gregor J. Gassner"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2202.00576"
  },
  {
    "id": "arXiv:2202.00577",
    "title": "Families of point sets with identical 1D persistence",
    "abstract": "Persistent homology is a popular and useful tool for analysing point sets,\nrevealing features of a point set that can be used to highlight key\ninformation, distinguish point sets and as an input into machine learning\npipelines. The famous stability theorem of persistent homology provides an\nupper bound for the change in persistence under perturbations, but it does not\nprovide a lower bound. This paper clarifies the possible limitations persistent\nhomology may have in distinguishing point sets, which is clearly evident for\npoint sets that have trivial persistence. We describe large families of point\nsets that have identical or even trivial one-dimensional persistence. The\nresults motivate stronger invariants to distinguish point sets up to isometry.",
    "descriptor": "\nComments: 8 pages, 5 figures, the latest version is at this http URL\n",
    "authors": [
      "Philip Smith",
      "Vitaliy Kurlin"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2202.00577"
  },
  {
    "id": "arXiv:2202.00580",
    "title": "Fishing for User Data in Large-Batch Federated Learning via Gradient  Magnification",
    "abstract": "Federated learning (FL) has rapidly risen in popularity due to its promise of\nprivacy and efficiency. Previous works have exposed privacy vulnerabilities in\nthe FL pipeline by recovering user data from gradient updates. However,\nexisting attacks fail to address realistic settings because they either 1)\nrequire a `toy' settings with very small batch sizes, or 2) require unrealistic\nand conspicuous architecture modifications. We introduce a new strategy that\ndramatically elevates existing attacks to operate on batches of arbitrarily\nlarge size, and without architectural modifications. Our model-agnostic\nstrategy only requires modifications to the model parameters sent to the user,\nwhich is a realistic threat model in many scenarios. We demonstrate the\nstrategy in challenging large-scale settings, obtaining high-fidelity data\nextraction in both cross-device and cross-silo federated learning.",
    "descriptor": "\nComments: First three authors contributed equally, order chosen randomly. 21 pages, 9 figures\n",
    "authors": [
      "Yuxin Wen",
      "Jonas Geiping",
      "Liam Fowl",
      "Micah Goldblum",
      "Tom Goldstein"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.00580"
  },
  {
    "id": "arXiv:2202.00582",
    "title": "Security Analysis of Mobile Banking Application in Qatar",
    "abstract": "This paper discusses the security posture of Android m-banking applications\nin Qatar. Since technology has developed over the years and more security\nmethods are provided, banking is now heavily reliant on mobile applications for\nprompt service delivery to clients, thus enabling a seamless and remote\ntransaction. However, such mobile banking applications have access to sensitive\ndata for each bank customer which presents a potential attack vector for\nclients, and the banks. The banks, therefore, have the responsibility to\nprotect the information of the client by providing a high-security layer to\ntheir mobile application. This research discusses m-banking applications for\nAndroid OS, its security, vulnerability, threats, and solutions. Two m-banking\napplications were analyzed and benchmarked against standardized best practices,\nusing the combination of two mobile testing frameworks. The security weaknesses\nobserved during the experimental evaluation suggest the need for a more robust\nsecurity evaluation of a mobile banking application in the state of Qatar. Such\nan approach would further ensure the confidence of the end-users. Consequently,\nunderstanding the security posture would provide a veritable measure towards\nmbanking security and user awareness.",
    "descriptor": "\nComments: 8 pages, 1 figure\n",
    "authors": [
      "Shaymaa Abdulla Al-Delayel"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.00582"
  },
  {
    "id": "arXiv:2202.00586",
    "title": "On the Capacity Achieving Input of Amplitude Constrained Vector Gaussian  Wiretap Channel",
    "abstract": "This paper studies secrecy-capacity of an $n$-dimensional Gaussian wiretap\nchannel under the peak-power constraint. This work determines the largest\npeak-power constraint $\\bar{\\mathsf{R}}_n$ such that an input distribution\nuniformly distributed on a single sphere is optimal; this regime is termed the\nsmall-amplitude regime. The asymptotic of $\\bar{\\mathsf{R}}_n$ as $n$ goes to\ninfinity is completely characterized as a function of noise variance at both\nreceivers. Moreover, the secrecy-capacity is also characterized in a form\namenable for computation. Furthermore, several numerical examples are provided,\nsuch as the example of the secrecy-capacity achieving distribution outside of\nthe small amplitude regime.",
    "descriptor": "\nComments: Extended version of a manuscript submitted to IEEE ISIT 2022\n",
    "authors": [
      "Antonino Favano",
      "Luca Barletta",
      "Alex Dytso"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.00586"
  },
  {
    "id": "arXiv:2202.00596",
    "title": "Machine learning based modelling and optimization in hard turning of  AISI D6 steel with newly developed AlTiSiN coated carbide tool",
    "abstract": "In recent times Mechanical and Production industries are facing increasing\nchallenges related to the shift toward sustainable manufacturing. In this\narticle, machining was performed in dry cutting condition with a newly\ndeveloped coated insert called AlTiSiN coated carbides coated through scalable\npulsed power plasma technique in dry cutting condition and a dataset was\ngenerated for different machining parameters and output responses. The\nmachining parameters are speed, feed, depth of cut and the output responses are\nsurface roughness, cutting force, crater wear length, crater wear width, and\nflank wear. The data collected from the machining operation is used for the\ndevelopment of machine learning (ML) based surrogate models to test, evaluate\nand optimize various input machining parameters. Different ML approaches such\nas polynomial regression (PR), random forest (RF) regression, gradient boosted\n(GB) trees, and adaptive boosting (AB) based regression are used to model\ndifferent output responses in the hard machining of AISI D6 steel. The\nsurrogate models for different output responses are used to prepare a complex\nobjective function for the germinal center algorithm-based optimization of the\nmachining parameters of the hard turning operation.",
    "descriptor": "",
    "authors": [
      "A Das",
      "S R Das",
      "J P Panda",
      "A Dey",
      "K K Gajrani",
      "N Somani",
      "N Gupta"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ],
    "url": "https://arxiv.org/abs/2202.00596"
  },
  {
    "id": "arXiv:2202.00598",
    "title": "Combined Pruning for Nested Cross-Validation to Accelerate Automated  Hyperparameter Optimization for Embedded Feature Selection in  High-Dimensional Data with Very Small Sample Sizes",
    "abstract": "Applying tree-based embedded feature selection to exclude irrelevant features\nin high-dimensional data with very small sample sizes requires optimized\nhyperparameters for the model building process. In addition, nested\ncross-validation must be applied for this type of data to avoid biased model\nperformance. The resulting long computation time can be accelerated with\npruning. However, standard pruning algorithms must prune late or risk aborting\ncalculations of promising hyperparameter sets due to high variance in the\nperformance evaluation metric. To address this, we adapt the usage of a\nstate-of-the-art successive halving pruner and combine it with two new pruning\nstrategies based on domain or prior knowledge. One additional pruning strategy\nimmediately stops the computation of trials with semantically meaningless\nresults for the selected hyperparameter combinations. The other is an\nextrapolating threshold pruning strategy suitable for nested-cross-validation\nwith high variance. Our proposed combined three-layer pruner keeps promising\ntrials while reducing the number of models to be built by up to 81,3% compared\nto using a state-of-the-art asynchronous successive halving pruner alone. Our\nthree-layer pruner implementation(available at\nhttps://github.com/sigrun-may/cv-pruner) speeds up data analysis or enables\ndeeper hyperparameter search within the same computation time. It consequently\nsaves time, money and energy, reducing the CO2 footprint.",
    "descriptor": "",
    "authors": [
      "Sigrun May",
      "Sven Hartmann",
      "Frank Klawonn"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.00598"
  },
  {
    "id": "arXiv:2202.00605",
    "title": "Bayesian Persuasion Meets Mechanism Design: Going Beyond Intractability  with Type Reporting",
    "abstract": "Bayesian persuasion studies how an informed sender should partially disclose\ninformation so as to influence the behavior of self-interested receivers. In\nthe last years, a growing attention has been devoted to relaxing the assumption\nthat the sender perfectly knows receiver's payoffs. The first crucial step\ntowards such an achievement is to study settings where each receiver's payoffs\ndepend on their unknown type, which is randomly determined by a known\nfinite-supported probability distribution. This begets considerable\ncomputational challenges, as computing a sender-optimal signaling scheme is\ninapproximable up to within any constant factor. In this work, we circumvent\nthis issue by leveraging ideas from mechanism design. In particular, we\nintroduce a type reporting step in which the receiver is asked to report their\ntype to the sender, after the latter has committed to a menu defining a\nsignaling scheme for each possible receiver's type. We prove that, with a\nsingle receiver, the addition of this type reporting stage makes the sender's\ncomputational problem tractable. Then, we extend our framework to settings with\nmultiple receivers, focusing on the case of no inter-agent externalities and\nbinary actions. We show that it is possible to find a sender-optimal solution\nin polynomial-time by means of the ellipsoid method, given access to a suitable\npolynomial-time separation oracle. This can be implemented for supermodular and\nanonymous sender's utility functions. As for the case of submodular sender's\nutility functions, we first approximately cast the sender's problem into a\nlinearly-constrained mathematical program whose objective function is the\nmulti-linear extension of the sender's utility. Then, we show how to find in\npolynomial-time an approximate solution to the program by means of a continuous\ngreedy algorithm. This provides a (1 -1/e)-approximation to the problem.",
    "descriptor": "",
    "authors": [
      "Matteo Castiglioni",
      "Alberto Marchesi",
      "Nicola Gatti"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2202.00605"
  },
  {
    "id": "arXiv:2202.00609",
    "title": "Semantic of Cloud Computing services for Time Series workflows",
    "abstract": "Time series (TS) are present in many fields of knowledge, research, and\nengineering. The processing and analysis of TS are essential in order to\nextract knowledge from the data and to tackle forecasting or predictive\nmaintenance tasks among others The modeling of TS is a challenging task,\nrequiring high statistical expertise as well as outstanding knowledge about the\napplication of Data Mining(DM) and Machine Learning (ML) methods. The overall\nwork with TS is not limited to the linear application of several techniques,\nbut is composed of an open workflow of methods and tests. These workflow,\ndeveloped mainly on programming languages, are complicated to execute and run\neffectively on different systems, including Cloud Computing (CC) environments.\nThe adoption of CC can facilitate the integration and portability of services\nallowing to adopt solutions towards services Internet Technologies (IT)\nindustrialization. The definition and description of workflow services for TS\nopen up a new set of possibilities regarding the reduction of complexity in the\ndeployment of this type of issues in CC environments. In this sense, we have\ndesigned an effective proposal based on semantic modeling (or vocabulary) that\nprovides the full description of workflow for Time Series modeling as a CC\nservice. Our proposal includes a broad spectrum of the most extended\noperations, accommodating any workflow applied to classification, regression,\nor clustering problems for Time Series, as well as including evaluation\nmeasures, information, tests, or machine learning algorithms among others.",
    "descriptor": "\nComments: 11 pages, 12 figures\n",
    "authors": [
      "Manuel Parra-Roy\u00f3n",
      "Francisco Baldan",
      "Ghislain Atemezing",
      "J.M. Benitez"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.00609"
  },
  {
    "id": "arXiv:2202.00610",
    "title": "First-order Temporal Logic on Finite Traces: Semantic Properties,  Decidable Fragments, and Applications",
    "abstract": "Formalisms based on temporal logics interpreted over finite strict linear\norders, known in the literature as finite traces, have been used for temporal\nspecification in automated planning, process modelling, (runtime) verification\nand synthesis of programs, as well as in knowledge representation and\nreasoning. In this paper, we focus on first-order temporal logic on finite\ntraces. We first investigate preservation of equivalences and satisfiability of\nformulas between finite and infinite traces, by providing a set of semantic and\nsyntactic conditions to guarantee when the distinction between reasoning in the\ntwo cases can be blurred. Moreover, we show that the satisfiability problem on\nfinite traces for several decidable fragments of first-order temporal logic is\nExpSpace-complete, as in the infinite trace case, while it decreases to\nNExpTime when finite traces bounded in the number of instants are considered.\nThis leads also to new complexity results for temporal description logics over\nfinite traces. Finally, we investigate applications to planning and\nverification, in particular by establishing connections with the notions of\ninsensitivity to infiniteness and safety from the literature.",
    "descriptor": "",
    "authors": [
      "Alessandro Artale",
      "Andrea Mazzullo",
      "Ana Ozaki"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2202.00610"
  },
  {
    "id": "arXiv:2202.00617",
    "title": "A General, Evolution-Inspired Reward Function for Social Robotics",
    "abstract": "The field of social robotics will likely need to depart from a paradigm of\ndesigned behaviours and imitation learning and adopt modern reinforcement\nlearning (RL) methods to enable robots to interact fluidly and efficaciously\nwith humans. In this paper, we present the Social Reward Function as a\nmechanism to provide (1) a real-time, dense reward function necessary for the\ndeployment of RL agents in social robotics, and (2) a standardised objective\nmetric for comparing the efficacy of different social robots. The Social Reward\nFunction is designed to closely mimic those genetically endowed social\nperception capabilities of humans in an effort to provide a simple, stable and\nculture-agnostic reward function. Presently, datasets used in social robotics\nare either small or significantly out-of-domain with respect to social\nrobotics. The use of the Social Reward Function will allow larger in-domain\ndatasets to be collected close to the behaviour policy of social robots, which\nwill allow both further improvements to reward functions and to the behaviour\npolicies of social robots. We believe this will be the key enabler to\ndeveloping efficacious social robots in the future.",
    "descriptor": "",
    "authors": [
      "Thomas Kingsford"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.00617"
  },
  {
    "id": "arXiv:2202.00619",
    "title": "Insights into the Core of the Assignment Game via Complementarity",
    "abstract": "The classic paper of Shapley and Shubik \\cite{Shapley1971assignment} showed\nthat the set of imputations in the core of the assignment game is precisely the\nset of optimal solutions to the dual of the LP-relaxation of this game. Since\nthe worth of this game is given by an optimal solution to the primal LP, this\nnaturally raises the question of studying core imputations through the lens of\ncomplementarity. Our exploration yields new insights: we obtain a relationship\nbetween the competitiveness of individuals and teams of agents and the amount\nof profit they accrue. This also sheds light on the phenomenon of degeneracy in\nassignment games, i.e., when the optimal assignment is not unique. The core is\na quintessential solution concept in cooperative game theory. It contains all\nways of distributing the total worth of a game among agents in such a way that\nno sub-coalition has incentive to secede from the grand coalition.",
    "descriptor": "\nComments: 10 pages\n",
    "authors": [
      "Vijay V. Vazirani"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Data Structures and Algorithms (cs.DS)",
      "Theoretical Economics (econ.TH)"
    ],
    "url": "https://arxiv.org/abs/2202.00619"
  },
  {
    "id": "arXiv:2202.00628",
    "title": "Regret Minimization with Performative Feedback",
    "abstract": "In performative prediction, the deployment of a predictive model triggers a\nshift in the data distribution. As these shifts are typically unknown ahead of\ntime, the learner needs to deploy a model to get feedback about the\ndistribution it induces. We study the problem of finding near-optimal models\nunder performativity while maintaining low regret. On the surface, this problem\nmight seem equivalent to a bandit problem. However, it exhibits a fundamentally\nricher feedback structure that we refer to as performative feedback: after\nevery deployment, the learner receives samples from the shifted distribution\nrather than only bandit feedback about the reward. Our main contribution is\nregret bounds that scale only with the complexity of the distribution shifts\nand not that of the reward function. The key algorithmic idea is careful\nexploration of the distribution shifts that informs a novel construction of\nconfidence bounds on the risk of unexplored models. The construction only\nrelies on smoothness of the shifts and does not assume convexity. More broadly,\nour work establishes a conceptual approach for leveraging tools from the\nbandits literature for the purpose of regret minimization with performative\nfeedback.",
    "descriptor": "",
    "authors": [
      "Meena Jagadeesan",
      "Tijana Zrnic",
      "Celestine Mendler-D\u00fcnner"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.00628"
  },
  {
    "id": "arXiv:2202.00632",
    "title": "Reducing the Amount of Real World Data for Object Detector Training with  Synthetic Data",
    "abstract": "A number of studies have investigated the training of neural networks with\nsynthetic data for applications in the real world. The aim of this study is to\nquantify how much real world data can be saved when using a mixed dataset of\nsynthetic and real world data. By modeling the relationship between the number\nof training examples and detection performance by a simple power law, we find\nthat the need for real world data can be reduced by up to 70% without\nsacrificing detection performance. The training of object detection networks is\nespecially enhanced by enriching the mixed dataset with classes\nunderrepresented in the real world dataset. The results indicate that mixed\ndatasets with real world data ratios between 5% and 20% reduce the need for\nreal world data the most without reducing the detection performance.",
    "descriptor": "\nComments: 6 pages, 4 figures submitted to 33rd IEEE Intelligent Vehicles Symposium (IV 22)\n",
    "authors": [
      "Sven Burdorf",
      "Karoline Plum",
      "Daniel Hasenklever"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.00632"
  },
  {
    "id": "arXiv:2202.00633",
    "title": "Efficient Policy Space Response Oracles",
    "abstract": "Policy Space Response Oracle method (PSRO) provides a general solution to\nNash equilibrium in two-player zero-sum games but suffers from two problems:\n(1) the computation inefficiency due to consistently evaluating current\npopulations by simulations; and (2) the exploration inefficiency due to\nlearning best responses against a fixed meta-strategy at each iteration. In\nthis work, we propose Efficient PSRO (EPSRO) that largely improves the\nefficiency of the above two steps. Central to our development is the\nnewly-introduced subroutine of minimax optimization on unrestricted-restricted\n(URR) games. By solving URR at each step, one can evaluate the current game and\ncompute the best response in one forward pass with no need for game\nsimulations. Theoretically, we prove that the solution procedures of EPSRO\noffer a monotonic improvement on exploitability. Moreover, a desirable property\nof EPSRO is that it is parallelizable, this allows for efficient exploration in\nthe policy space that induces behavioral diversity. We test EPSRO on three\nclasses of games and report a 50x speedup in wall-time, 10x data efficiency,\nand similar exploitability as existing PSRO methods on Kuhn and Leduc Poker\ngames.",
    "descriptor": "\nComments: 14 pages, 8 figures\n",
    "authors": [
      "Ming Zhou",
      "Jingxiao Chen",
      "Ying Wen",
      "Weinan Zhang",
      "Yaodong Yang",
      "Yong Yu"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2202.00633"
  },
  {
    "id": "arXiv:2202.00636",
    "title": "Differentially Private Community Detection for Stochastic Block Models",
    "abstract": "The goal of community detection over graphs is to recover underlying\nlabels/attributes of users (e.g., political affiliation) given the connectivity\nbetween users (represented by adjacency matrix of a graph). There has been\nsignificant recent progress on understanding the fundamental limits of\ncommunity detection when the graph is generated from a stochastic block model\n(SBM). Specifically, sharp information theoretic limits and efficient\nalgorithms have been obtained for SBMs as a function of $p$ and $q$, which\nrepresent the intra-community and inter-community connection probabilities. In\nthis paper, we study the community detection problem while preserving the\nprivacy of the individual connections (edges) between the vertices. Focusing on\nthe notion of $(\\epsilon, \\delta)$-edge differential privacy (DP), we seek to\nunderstand the fundamental tradeoffs between $(p, q)$, DP budget $(\\epsilon,\n\\delta)$, and computational efficiency for exact recovery of the community\nlabels.\nTo this end, we present and analyze the associated information-theoretic\ntradeoffs for three broad classes of differentially private community recovery\nmechanisms: a) stability based mechanism; b) sampling based mechanisms; and c)\ngraph perturbation mechanisms. Our main findings are that stability and\nsampling based mechanisms lead to a superior tradeoff between $(p,q)$ and the\nprivacy budget $(\\epsilon, \\delta)$; however this comes at the expense of\nhigher computational complexity. On the other hand, albeit low complexity,\ngraph perturbation mechanisms require the privacy budget $\\epsilon$ to scale as\n$\\Omega(\\log(n))$ for exact recovery. To the best of our knowledge, this is the\nfirst work to study the impact of privacy constraints on the fundamental limits\nfor community detection.",
    "descriptor": "\nComments: Under review\n",
    "authors": [
      "Mohamed Seif",
      "Dung Nguyen",
      "Anil Vullikanti",
      "Ravi Tandon"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Cryptography and Security (cs.CR)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.00636"
  },
  {
    "id": "arXiv:2202.00640",
    "title": "Rewiring What-to-Watch-Next Recommendations to Reduce Radicalization  Pathways",
    "abstract": "Recommender systems typically suggest to users content similar to what they\nconsumed in the past. If a user happens to be exposed to strongly polarized\ncontent, she might subsequently receive recommendations which may steer her\ntowards more and more radicalized content, eventually being trapped in what we\ncall a \"radicalization pathway\". In this paper, we study the problem of\nmitigating radicalization pathways using a graph-based approach. Specifically,\nwe model the set of recommendations of a \"what-to-watch-next\" recommender as a\nd-regular directed graph where nodes correspond to content items, links to\nrecommendations, and paths to possible user sessions. We measure the\n\"segregation\" score of a node representing radicalized content as the expected\nlength of a random walk from that node to any node representing non-radicalized\ncontent. High segregation scores are associated to larger chances to get users\ntrapped in radicalization pathways. Hence, we define the problem of reducing\nthe prevalence of radicalization pathways by selecting a small number of edges\nto \"rewire\", so to minimize the maximum of segregation scores among all\nradicalized nodes, while maintaining the relevance of the recommendations. We\nprove that the problem of finding the optimal set of recommendations to rewire\nis NP-hard and NP-hard to approximate within any factor. Therefore, we turn our\nattention to heuristics, and propose an efficient yet effective greedy\nalgorithm based on the absorbing random walk theory. Our experiments on\nreal-world datasets in the context of video and news recommendations confirm\nthe effectiveness of our proposal.",
    "descriptor": "\nComments: To appear in the Web conference 2022 (WWW '22)\n",
    "authors": [
      "Francesco Fabbri",
      "Yanhao Wang",
      "Francesco Bonchi",
      "Carlos Castillo",
      "Michael Mathioudakis"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2202.00640"
  },
  {
    "id": "arXiv:2202.00643",
    "title": "Topological invariants for words of linear factor complexity",
    "abstract": "Given a finite alphabet $\\Sigma$ and a right-infinite word $w$ over the\nalphabet $\\Sigma$, we construct a topological space ${\\rm Rec}(w)$ consisting\nof all right-infinite recurrent words whose factors are all factors of $w$,\nwhere we work up to an equivalence in which two words are equivalent if they\nhave the exact same set of factors (finite contiguous subwords). We show that\n${\\rm Rec}(w)$ can be endowed with a natural topology and we show that if $w$\nis word of linear factor complexity then ${\\rm Rec}(w)$ is a finite topological\nspace. In addition, we note that there are examples which show that if\n$f:\\mathbb{N}\\to \\mathbb{N}$ is a function that tends to infinity as $n\\to\n\\infty$ then there is a word whose factor complexity function is ${\\rm\nO}(nf(n))$ such that ${\\rm Rec}(w)$ is an infinite set. Finally, we pose a\nrealization problem: which finite topological spaces can arise as ${\\rm\nRec}(w)$ for a word of linear factor complexity?",
    "descriptor": "\nComments: 14 pages\n",
    "authors": [
      "Jason Bell"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2202.00643"
  },
  {
    "id": "arXiv:2202.00645",
    "title": "Stability and Generalization Capabilities of Message Passing Graph  Neural Networks",
    "abstract": "Message passing neural networks (MPNN) have seen a steep rise in popularity\nsince their introduction as generalizations of convolutional neural networks to\ngraph structured data, and are now considered state-of-the-art tools for\nsolving a large variety of graph-focused problems. We study the generalization\ncapabilities of MPNNs in graph classification. We assume that graphs of\ndifferent classes are sampled from different random graph models. Based on this\ndata distribution, we derive a non-asymptotic bound on the generalization gap\nbetween the empirical and statistical loss, that decreases to zero as the\ngraphs become larger. This is proven by showing that a MPNN, applied on a\ngraph, approximates the MPNN applied on the geometric model that the graph\ndiscretizes.",
    "descriptor": "\nComments: 8 pages main body, 35 pages with references and appendix, 2 figures, 1 table\n",
    "authors": [
      "Sohir Maskey",
      "Yunseok Lee",
      "Ron Levie",
      "Gitta Kutyniok"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Numerical Analysis (math.NA)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2202.00645"
  },
  {
    "id": "arXiv:2202.00649",
    "title": "Timely Gossiping with File Slicing and Network Coding",
    "abstract": "We consider a system consisting of a large network of $n$ users and a library\nof files, wherein inter-user communication is established based upon gossip\nmechanisms. Each file is initially present at exactly one node, which is\ndesignated as the file \\emph{source}. The source gets updated with newer\nversions of the file according to an arbitrary distribution in real time, and\nthe other users in the network wish to acquire the latest possible version of\nthe file. We present a class of gossip protocols that achieve $O(1)$ age at a\ntypical node in a single-file system and $O(n)$ age at a typical node for a\ngiven file in an $n$-file system. We show that file slicing and network coding\nbased protocols fall under the presented class of protocols. Numerical\nevaluation results are presented to confirm the aforementioned bounds.",
    "descriptor": "",
    "authors": [
      "Priyanka Kaswan",
      "Sennur Ulukus"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.00649"
  },
  {
    "id": "arXiv:2202.00658",
    "title": "Scalable Fragment-Based 3D Molecular Design with Reinforcement Learning",
    "abstract": "Machine learning has the potential to automate molecular design and\ndrastically accelerate the discovery of new functional compounds. Towards this\ngoal, generative models and reinforcement learning (RL) using string and graph\nrepresentations have been successfully used to search for novel molecules.\nHowever, these approaches are limited since their representations ignore the\nthree-dimensional (3D) structure of molecules. In fact, geometry plays an\nimportant role in many applications in inverse molecular design, especially in\ndrug discovery. Thus, it is important to build models that can generate\nmolecular structures in 3D space based on property-oriented geometric\nconstraints. To address this, one approach is to generate molecules as 3D point\nclouds by sequentially placing atoms at locations in space -- this allows the\nprocess to be guided by physical quantities such as energy or other properties.\nHowever, this approach is inefficient as placing individual atoms makes the\nexploration unnecessarily deep, limiting the complexity of molecules that can\nbe generated. Moreover, when optimizing a molecule, organic and medicinal\nchemists use known fragments and functional groups, not single atoms. We\nintroduce a novel RL framework for scalable 3D design that uses a hierarchical\nagent to build molecules by placing molecular substructures sequentially in 3D\nspace, thus attempting to build on the existing human knowledge in the field of\nmolecular design. In a variety of experiments with different substructures, we\nshow that our agent, guided only by energy considerations, can efficiently\nlearn to produce molecules with over 100 atoms from many distributions\nincluding drug-like molecules, organic LED molecules, and biomolecules.",
    "descriptor": "",
    "authors": [
      "Daniel Flam-Shepherd",
      "Alexander Zhigalin",
      "Al\u00e1n Aspuru-Guzik"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.00658"
  },
  {
    "id": "arXiv:2202.00659",
    "title": "Stay Positive: Non-Negative Image Synthesis for Augmented Reality",
    "abstract": "In applications such as optical see-through and projector augmented reality,\nproducing images amounts to solving non-negative image generation, where one\ncan only add light to an existing image. Most image generation methods,\nhowever, are ill-suited to this problem setting, as they make the assumption\nthat one can assign arbitrary color to each pixel. In fact, naive application\nof existing methods fails even in simple domains such as MNIST digits, since\none cannot create darker pixels by adding light. We know, however, that the\nhuman visual system can be fooled by optical illusions involving certain\nspatial configurations of brightness and contrast. Our key insight is that one\ncan leverage this behavior to produce high quality images with negligible\nartifacts. For example, we can create the illusion of darker patches by\nbrightening surrounding pixels. We propose a novel optimization procedure to\nproduce images that satisfy both semantic and non-negativity constraints. Our\napproach can incorporate existing state-of-the-art methods, and exhibits strong\nperformance in a variety of tasks including image-to-image translation and\nstyle transfer.",
    "descriptor": "",
    "authors": [
      "Katie Luo",
      "Guandao Yang",
      "Wenqi Xian",
      "Harald Haraldsson",
      "Bharath Hariharan",
      "Serge Belongie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2202.00659"
  },
  {
    "id": "arXiv:2202.00660",
    "title": "Interactron: Embodied Adaptive Object Detection",
    "abstract": "Over the years various methods have been proposed for the problem of object\ndetection. Recently, we have witnessed great strides in this domain owing to\nthe emergence of powerful deep neural networks. However, there are typically\ntwo main assumptions common among these approaches. First, the model is trained\non a fixed training set and is evaluated on a pre-recorded test set. Second,\nthe model is kept frozen after the training phase, so no further updates are\nperformed after the training is finished. These two assumptions limit the\napplicability of these methods to real-world settings. In this paper, we\npropose Interactron, a method for adaptive object detection in an interactive\nsetting, where the goal is to perform object detection in images observed by an\nembodied agent navigating in different environments. Our idea is to continue\ntraining during inference and adapt the model at test time without any explicit\nsupervision via interacting with the environment. Our adaptive object detection\nmodel provides a 11.8 point improvement in AP (and 19.1 points in AP50) over\nDETR, a recent, high-performance object detector. Moreover, we show that our\nobject detection model adapts to environments with completely different\nappearance characteristics, and its performance is on par with a model trained\nwith full supervision for those environments.",
    "descriptor": "",
    "authors": [
      "Klemen Kotar",
      "Roozbeh Mottaghi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.00660"
  },
  {
    "id": "arXiv:2202.00661",
    "title": "Questions for Flat-Minima Optimization of Modern Neural Networks",
    "abstract": "For training neural networks, flat-minima optimizers that seek to find\nparameters in neighborhoods having uniformly low loss (flat minima) have been\nshown to improve upon stochastic and adaptive gradient-based methods. Two\nmethods for finding flat minima stand out: 1. Averaging methods (i.e.,\nStochastic Weight Averaging, SWA), and 2. Minimax methods (i.e., Sharpness\nAware Minimization, SAM). However, despite similar motivations, there has been\nlimited investigation into their properties and no comprehensive comparison\nbetween them. In this work, we investigate the loss surfaces from a systematic\nbenchmarking of these approaches across computer vision, natural language\nprocessing, and graph learning tasks. This leads us to a hypothesis: since both\napproaches find flat solutions in orthogonal ways, combining them should\nimprove generalization even further. We verify this improves over either\nflat-minima approach in 39 out of 42 cases. When it does not, we provide\npotential explanations. We hope our results across image, graph, and text data\nwill help researchers to improve deep learning optimizers, and practitioners to\npinpoint the optimizer for the problem at hand.",
    "descriptor": "",
    "authors": [
      "Jean Kaddour",
      "Linqing Liu",
      "Ricardo Silva",
      "Matt J. Kusner"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.00661"
  },
  {
    "id": "arXiv:2202.00663",
    "title": "Measuring the Accessibility of Domain Name Encryption and Its Impact on  Internet Filtering",
    "abstract": "Most online communications rely on DNS to map domain names to their hosting\nIP address(es). Previous work has shown that DNS-based network interference is\nwidespread due to the unencrypted and unauthenticated nature of the original\nDNS protocol. In addition to DNS, accessed domain names can also be monitored\nby on-path observers during the TLS handshake when the SNI extension is used.\nThese lingering issues with exposed plaintext domain names have led to the\ndevelopment of a new generation of protocols that keep accessed domain names\nhidden. DNS-over-TLS (DoT) and DNS-over-HTTPS (DoH) hide the domain names of\nDNS queries, while Encrypted Server Name Indication (ESNI) encrypts the domain\nname in the SNI extension.\nWe present DNEye, a measurement system built on top of a network of\ndistributed vantage points, which we used to study the accessibility of DoT/DoH\nand ESNI, and to investigate whether these protocols are tampered with by\nnetwork providers (e.g., for censorship). Moreover, we evaluate the efficacy of\nthese protocols in circumventing network interference when accessing content\nblocked by traditional DNS manipulation. We find evidence of blocking efforts\nagainst domain name encryption technologies in several countries, including\nChina, Russia, and Saudi Arabia. At the same time, we discover that domain name\nencryption can help with unblocking more than 55% and 95% of censored domains\nin China and other countries where DNS-based filtering is heavily employed.",
    "descriptor": "\nComments: To appear in Proceedings of the Passive and Active Measurement Conference 2022\n",
    "authors": [
      "Nguyen Phong Hoang",
      "Michalis Polychronakis",
      "Phillipa Gill"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Cryptography and Security (cs.CR)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2202.00663"
  },
  {
    "id": "arXiv:2202.00665",
    "title": "Tutorial on amortized optimization for learning to optimize over  continuous domains",
    "abstract": "Optimization is a ubiquitous modeling tool that is often deployed in settings\nthat repeatedly solve similar instances of the same problem. Amortized\noptimization methods use learning to predict the solutions to problems in these\nsettings. This leverages the shared structure between similar problem\ninstances. In this tutorial, we will discuss the key design choices behind\namortized optimization, roughly categorizing 1) models into fully-amortized and\nsemi-amortized approaches, and 2) learning methods into regression-based and\nobjective-based. We then view existing applications through these foundations\nto draw connections between them, including for manifold optimization,\nvariational inference, sparse coding, meta-learning, control, reinforcement\nlearning, convex optimization, and deep equilibrium networks. This framing\nenables us easily see, for example, that the amortized inference in variational\nautoencoders is conceptually identical to value gradients in control and\nreinforcement learning as they both use fully-amortized models with a\nobjective-based loss. The source code for this tutorial is available at\nhttps://www.github.com/facebookresearch/amortized-optimization-tutorial",
    "descriptor": "",
    "authors": [
      "Brandon Amos"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2202.00665"
  },
  {
    "id": "arXiv:2202.00666",
    "title": "Typical Decoding for Natural Language Generation",
    "abstract": "Despite achieving incredibly low perplexities on myriad natural language\ncorpora, today's language models still often underperform when used to generate\ntext. This dichotomy has puzzled the language generation community for the last\nfew years. In this work, we posit that the abstraction of natural language as a\ncommunication channel (\\`a la Shannon, 1948) can provide new insights into the\nbehaviors of probabilistic language generators, e.g., why high-probability\ntexts can be dull or repetitive. Humans use language as a means of\ncommunicating information, and do so in an efficient yet error-minimizing\nmanner, choosing each word in a string with this (perhaps subconscious) goal in\nmind. We propose that generation from probabilistic models should mimic this\nbehavior. Rather than always choosing words from the high-probability region of\nthe distribution--which have a low Shannon information content--we sample from\nthe set of words with an information content close to its expected value, i.e.,\nclose to the conditional entropy of our model. This decision criterion can be\nrealized through a simple and efficient implementation, which we call typical\nsampling. Automatic and human evaluations show that, in comparison to nucleus\nand top-k sampling, typical sampling offers competitive performance in terms of\nquality while consistently reducing the number of degenerate repetitions.",
    "descriptor": "",
    "authors": [
      "Clara Meister",
      "Tiago Pimentel",
      "Gian Wiher",
      "Ryan Cotterell"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.00666"
  },
  {
    "id": "arXiv:2202.00667",
    "title": "Deep Kernelized Dense Geometric Matching",
    "abstract": "Dense geometric matching is a challenging computer vision task, requiring\naccurate correspondences under extreme variations in viewpoint and\nillumination, even for low-texture regions. In this task, finding accurate\nglobal correspondences is essential for later refinement stages. The current\nlearning based paradigm is to perform global fixed-size correlation, followed\nby flattening and convolution to predict correspondences. In this work, we\nconsider the problem from a different perspective and propose to formulate\nglobal correspondence estimation as a continuous probabilistic regression task\nusing deep kernels, yielding a novel approach to learning dense\ncorrespondences. Our full approach, \\textbf{D}eep \\textbf{K}ernelized\n\\textbf{M}atching, achieves significant improvements compared to the\nstate-of-the-art on the competitive HPatches and YFCC100m benchmarks, and we\ndissect the gains of our contributions in a thorough ablation study.",
    "descriptor": "",
    "authors": [
      "Johan Edstedt",
      "M\u00e5rten Wadenb\u00e4ck",
      "Michael Felsberg"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.00667"
  },
  {
    "id": "arXiv:2202.00001",
    "title": "Insights into performance evaluation of com-pound-protein interaction  prediction methods",
    "abstract": "Motivation: Machine learning based prediction of compound-protein\ninteractions (CPIs) is important for drug design, screening and repurposing\nstudies and can improve the efficiency and cost-effectiveness of wet lab\nassays. Despite the publication of many research papers reporting CPI\npredictors in the recent years, we have observed a number of fundamental issues\nin experiment design that lead to over optimistic estimates of model\nperformance. Results: In this paper, we analyze the impact of several important\nfactors affecting generalization perfor-mance of CPI predictors that are\noverlooked in existing work: 1. Similarity between training and test examples\nin cross-validation 2. The strategy for generating negative examples, in the\nabsence of experimentally verified negative examples. 3. Choice of evaluation\nprotocols and performance metrics and their alignment with real-world use of\nCPI predictors in screening large compound libraries. Using both an existing\nstate-of-the-art method (CPI-NN) and a proposed kernel based approach, we have\nfound that assessment of predictive performance of CPI predictors requires\ncareful con-trol over similarity between training and test examples. We also\nshow that random pairing for gen-erating synthetic negative examples for\ntraining and performance evaluation results in models with better\ngeneralization performance in comparison to more sophisticated strategies used\nin existing studies. Furthermore, we have found that our kernel based approach,\ndespite its simple design, exceeds the prediction performance of CPI-NN. We\nhave used the proposed model for compound screening of several proteins\nincluding SARS-CoV-2 Spike and Human ACE2 proteins and found strong evidence in\nsupport of its top hits. Availability: Code and raw experimental results\navailable at https://github.com/adibayaseen/HKRCPI Contact:\nFayyaz.minhas@warwick.ac.uk",
    "descriptor": "\nComments: Supplementary information: Supplementary data files are available as part of the GitHub repository\n",
    "authors": [
      "Adiba Yaseen",
      "Imran Amin",
      "Naeem Akhter",
      "Asa Ben-Hur",
      "Fayyaz Minhas"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.00001"
  },
  {
    "id": "arXiv:2202.00002",
    "title": "BREAK: Bronchi Reconstruction by gEodesic transformation And sKeleton  embedding",
    "abstract": "Airway segmentation is critical for virtual bronchoscopy and computer-aided\npulmonary disease analysis. In recent years, convolutional neural networks\n(CNNs) have been widely used to delineate the bronchial tree. However, the\nsegmentation results of the CNN-based methods usually include many\ndiscontinuous branches, which need manual repair in clinical use. A major\nreason for the breakages is that the appearance of the airway wall can be\naffected by the lung disease as well as the adjacency of the vessels, while the\nnetwork tends to overfit to these special patterns in the training set. To\nlearn robust features for these areas, we design a multi-branch framework that\nadopts the geodesic distance transform to capture the intensity changes between\nairway lumen and wall. Another reason for the breakages is the intra-class\nimbalance. Since the volume of the peripheral bronchi may be much smaller than\nthe large branches in an input patch, the common segmentation loss is not\nsensitive to the breakages among the distal branches. Therefore, in this paper,\na breakage-sensitive regularization term is designed and can be easily combined\nwith other loss functions. Extensive experiments are conducted on publicly\navailable datasets. Compared with state-of-the-art methods, our framework can\ndetect more branches while maintaining competitive segmentation performance.",
    "descriptor": "\nComments: Accept as IEEE ISBI 2022 oral\n",
    "authors": [
      "Weihao Yu",
      "Hao Zheng",
      "Minghui Zhang",
      "Hanxiao Zhang",
      "Jiayuan Sun",
      "Jie Yang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.00002"
  },
  {
    "id": "arXiv:2202.00011",
    "title": "Leveraging Bitstream Metadata for Fast and Accurate Video Compression  Correction",
    "abstract": "Video compression is a central feature of the modern internet powering\ntechnologies from social media to video conferencing. While video compression\ncontinues to mature, for many, and particularly for extreme, compression\nsettings, quality loss is still noticeable. These extreme settings nevertheless\nhave important applications to the efficient transmission of videos over\nbandwidth constrained or otherwise unstable connections. In this work, we\ndevelop a deep learning architecture capable of restoring detail to compressed\nvideos which leverages the underlying structure and motion information embedded\nin the video bitstream. We show that this improves restoration accuracy\ncompared to prior compression correction methods and is competitive when\ncompared with recent deep-learning-based video compression methods on\nrate-distortion while achieving higher throughput.",
    "descriptor": "\nComments: We are preparing to add more comparisons to newer papers in Table 1\n",
    "authors": [
      "Max Ehrlich",
      "Jon Barker",
      "Namitha Padmanabhan",
      "Larry Davis",
      "Andrew Tao",
      "Bryan Catanzaro",
      "Abhinav Shrivastava"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.00011"
  },
  {
    "id": "arXiv:2202.00027",
    "title": "Exoplanet Characterization using Conditional Invertible Neural Networks",
    "abstract": "The characterization of an exoplanet's interior is an inverse problem, which\nrequires statistical methods such as Bayesian inference in order to be solved.\nCurrent methods employ Markov Chain Monte Carlo (MCMC) sampling to infer the\nposterior probability of planetary structure parameters for a given exoplanet.\nThese methods are time consuming since they require the calculation of a large\nnumber of planetary structure models. To speed up the inference process when\ncharacterizing an exoplanet, we propose to use conditional invertible neural\nnetworks (cINNs) to calculate the posterior probability of the internal\nstructure parameters. cINNs are a special type of neural network which excel in\nsolving inverse problems. We constructed a cINN using FrEIA, which was then\ntrained on a database of $5.6\\cdot 10^6$ internal structure models to recover\nthe inverse mapping between internal structure parameters and observable\nfeatures (i.e., planetary mass, planetary radius and composition of the host\nstar). The cINN method was compared to a Metropolis-Hastings MCMC. For that we\nrepeated the characterization of the exoplanet K2-111 b, using both the MCMC\nmethod and the trained cINN. We show that the inferred posterior probability of\nthe internal structure parameters from both methods are very similar, with the\nbiggest differences seen in the exoplanet's water content. Thus cINNs are a\npossible alternative to the standard time-consuming sampling methods. Indeed,\nusing cINNs allows for orders of magnitude faster inference of an exoplanet's\ncomposition than what is possible using an MCMC method, however, it still\nrequires the computation of a large database of internal structures to train\nthe cINN. Since this database is only computed once, we found that using a cINN\nis more efficient than an MCMC, when more than 10 exoplanets are characterized\nusing the same cINN.",
    "descriptor": "\nComments: 15 pages, 13 figures, submitted to Astronomy & Astrophysics\n",
    "authors": [
      "Jonas Haldemann",
      "Victor Ksoll",
      "Daniel Walter",
      "Yann Alibert",
      "Ralf S. Klessen",
      "Willy Benz",
      "Ullrich Koethe",
      "Lynton Ardizzone",
      "Carsten Rother"
    ],
    "subjectives": [
      "Earth and Planetary Astrophysics (astro-ph.EP)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.00027"
  },
  {
    "id": "arXiv:2202.00031",
    "title": "YOUNG Star detrending for Transiting Exoplanet Recovery (YOUNGSTER) II:  Using Self-Organising Maps to explore young star variability in Sectors 1-13  of TESS data",
    "abstract": "Young exoplanets and their corresponding host stars are fascinating\nlaboratories for constraining the timescale of planetary evolution and\nplanet-star interactions. However, because young stars are typically much more\nactive than the older population, in order to discover more young exoplanets,\ngreater knowledge of the wide array of young star variability is needed. Here\nKohonen Self Organising Maps (SOMs) are used to explore young star variability\npresent in the first year of observations from the Transiting Exoplanet Survey\nSatellite (TESS), with such knowledge valuable to perform targeted detrending\nof young stars in the future. This technique was found to be particularly\neffective at separating the signals of young eclipsing binaries and potential\ntransiting objects from stellar variability, a list of which are provided in\nthis paper. The effect of pre-training the Self-Organising Maps on known\nvariability classes was tested, but found to be challenging without a\nsignificant training set from TESS. SOMs were also found to provide an\nintuitive and informative overview of leftover systematics in the TESS data,\nproviding an important new way to characterise troublesome systematics in\nphotometric data-sets. This paper represents the first stage of the wider\nYOUNGSTER program, which will use a machine-learning-based approach to\nclassification and targeted detrending of young stars in order to improve the\nrecovery of smaller young exoplanets.",
    "descriptor": "\nComments: 21 pages, 33 figures, accepted for publication at MNRAS\n",
    "authors": [
      "Matthew P. Battley",
      "David J. Armstrong",
      "Don Pollacco"
    ],
    "subjectives": [
      "Earth and Planetary Astrophysics (astro-ph.EP)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Solar and Stellar Astrophysics (astro-ph.SR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.00031"
  },
  {
    "id": "arXiv:2202.00048",
    "title": "Single Time-scale Actor-critic Method to Solve the Linear Quadratic  Regulator with Convergence Guarantees",
    "abstract": "We propose a single time-scale actor-critic algorithm to solve the linear\nquadratic regulator (LQR) problem. A least squares temporal difference (LSTD)\nmethod is applied to the critic and a natural policy gradient method is used\nfor the actor. We give a proof of convergence with sample complexity\n$\\mO(\\ve^{-1} \\log(\\ve^{-1})^2)$. The method in the proof is applicable to\ngeneral single time-scale bilevel optimization problem. We also numerically\nvalidate our theoretical results on the convergence.",
    "descriptor": "\nComments: 4 figures\n",
    "authors": [
      "Mo Zhou",
      "Jianfeng Lu"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.00048"
  },
  {
    "id": "arXiv:2202.00054",
    "title": "Quantum machine learning with subspace states",
    "abstract": "We introduce a new approach for quantum linear algebra based on quantum\nsubspace states and present three new quantum machine learning algorithms. The\nfirst is a quantum determinant sampling algorithm that samples from the\ndistribution $\\Pr[S]= det(X_{S}X_{S}^{T})$ for $|S|=d$ using $O(nd)$ gates and\nwith circuit depth $O(d\\log n)$. The state of art classical algorithm for the\ntask requires $O(d^{3})$ operations \\cite{derezinski2019minimax}. The second is\na quantum singular value estimation algorithm for compound matrices\n$\\mathcal{A}^{k}$, the speedup for this algorithm is potentially exponential.\nIt decomposes a $\\binom{n}{k}$ dimensional vector of order-$k$ correlations\ninto a linear combination of subspace states corresponding to $k$-tuples of\nsingular vectors of $A$. The third algorithm reduces exponentially the depth of\ncircuits used in quantum topological data analysis from $O(n)$ to $O(\\log n)$.\nOur basic tool is the quantum subspace state, defined as $|Col(X)\\langle =\n\\sum_{S\\subset [n], |S|=d} det(X_{S}) |ket{S}\\langle$ for matrices $X \\in\n\\mathbb{R}^{n \\times d}$ s]uch that $X^{T} X = I_{d}$, that encodes\n$d$-dimensional subspaces of $\\mathbb{R}^{n}$ and for which we develop two\nefficient state preparation techniques. The first using Givens circuits uses\nthe representation of a subspace as a sequence of Givens rotations, while the\nsecond uses efficient implementations of unitaries $\\Gamma(x) = \\sum_{i} x_{i}\nZ^{\\otimes (i-1)} \\otimes X \\otimes I^{n-i}$ with $O(\\log n)$ depth circuits\nthat we term Clifford loaders.",
    "descriptor": "",
    "authors": [
      "Iordanis Kerenidis",
      "Anupam Prakash"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2202.00054"
  },
  {
    "id": "arXiv:2202.00067",
    "title": "AutoGeoLabel: Automated Label Generation for Geospatial Machine Learning",
    "abstract": "A key challenge of supervised learning is the availability of human-labeled\ndata. We evaluate a big data processing pipeline to auto-generate labels for\nremote sensing data. It is based on rasterized statistical features extracted\nfrom surveys such as e.g. LiDAR measurements. Using simple combinations of the\nrasterized statistical layers, it is demonstrated that multiple classes can be\ngenerated at accuracies of ~0.9. As proof of concept, we utilize the big\ngeo-data platform IBM PAIRS to dynamically generate such labels in dense urban\nareas with multiple land cover classes. The general method proposed here is\nplatform independent, and it can be adapted to generate labels for other\nsatellite modalities in order to enable machine learning on overhead imagery\nfor land use classification and object detection.",
    "descriptor": "",
    "authors": [
      "Conrad M Albrecht",
      "Fernando Marianno",
      "Levente J Klein"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.00067"
  },
  {
    "id": "arXiv:2202.00076",
    "title": "Optimal Estimation of Off-Policy Policy Gradient via Double Fitted  Iteration",
    "abstract": "Policy gradient (PG) estimation becomes a challenge when we are not allowed\nto sample with the target policy but only have access to a dataset generated by\nsome unknown behavior policy. Conventional methods for off-policy PG estimation\noften suffer from either significant bias or exponentially large variance. In\nthis paper, we propose the double Fitted PG estimation (FPG) algorithm. FPG can\nwork with an arbitrary policy parameterization, assuming access to a\nBellman-complete value function class. In the case of linear value function\napproximation, we provide a tight finite-sample upper bound on policy gradient\nestimation error, that is governed by the amount of distribution mismatch\nmeasured in feature space. We also establish the asymptotic normality of FPG\nestimation error with a precise covariance characterization, which is further\nshown to be statistically optimal with a matching Cramer-Rao lower bound.\nEmpirically, we evaluate the performance of FPG on both policy gradient\nestimation and policy optimization, using either softmax tabular or ReLU policy\nnetworks. Under various metrics, our results show that FPG significantly\noutperforms existing off-policy PG estimation methods based on importance\nsampling and variance reduction techniques.",
    "descriptor": "",
    "authors": [
      "Chengzhuo Ni",
      "Ruiqi Zhang",
      "Xiang Ji",
      "Xuezhou Zhang",
      "Mengdi Wang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.00076"
  },
  {
    "id": "arXiv:2202.00078",
    "title": "A heteroencoder architecture for prediction of failure locations in  porous metals using variational inference",
    "abstract": "In this work we employ an encoder-decoder convolutional neural network to\npredict the failure locations of porous metal tension specimens based only on\ntheir initial porosities. The process we model is complex, with a progression\nfrom initial void nucleation, to saturation, and ultimately failure. The\nobjective of predicting failure locations presents an extreme case of class\nimbalance since most of the material in the specimens do not fail. In response\nto this challenge, we develop and demonstrate the effectiveness of data- and\nloss-based regularization methods. Since there is considerable sensitivity of\nthe failure location to the particular configuration of voids, we also use\nvariational inference to provide uncertainties for the neural network\npredictions. We connect the deterministic and Bayesian convolutional neural\nnetworks at a theoretical level to explain how variational inference\nregularizes the training and predictions. We demonstrate that the resulting\npredicted variances are effective in ranking the locations that are most likely\nto fail in any given specimen.",
    "descriptor": "\nComments: 40 pages, 12 figures\n",
    "authors": [
      "Wyatt Bridgman",
      "Xiaoxuan Zhang",
      "Greg Teichert",
      "Mohammad Khalil",
      "Krishna Garikipati",
      "Reese Jones"
    ],
    "subjectives": [
      "Applied Physics (physics.app-ph)",
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.00078"
  },
  {
    "id": "arXiv:2202.00081",
    "title": "On solutions of the distributional Bellman equation",
    "abstract": "In distributional reinforcement learning not only expected returns but the\ncomplete return distributions of a policy is taken into account. The return\ndistribution for a fixed policy is given as the fixed point of an associated\ndistributional Bellman operator. In this note we consider general\ndistributional Bellman operators and study existence and uniqueness of its\nfixed points as well as their tail properties. We give necessary and sufficient\nconditions for existence and uniqueness of return distributions and identify\ncases of regular variation. We link distributional Bellman equations to\nmultivariate distributional equations of the form $\\textbf{X} =_d\n\\textbf{A}\\textbf{X} + \\textbf{B}$, where $\\textbf{X}$ and $\\textbf{B}$ are\n$d$-dimensional random vectors, $\\textbf{A}$ a random $d\\times d$ matrix and\n$\\textbf{X}$ and $(\\textbf{A},\\textbf{B})$ are independent. We show that any\nfixed-point of a distributional Bellman operator can be obtained as the vector\nof marginal laws of a solution to such a multivariate distributional equation.\nThis makes the general theory of such equations applicable to the\ndistributional reinforcement learning setting.",
    "descriptor": "",
    "authors": [
      "Julian Gerstenberg",
      "Ralph Neininger",
      "Denis Spiegel"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2202.00081"
  },
  {
    "id": "arXiv:2202.00087",
    "title": "Holistic Fine-grained GGS Characterization: From Detection to Unbalanced  Classification",
    "abstract": "Recent studies have demonstrated the diagnostic and prognostic values of\nglobal glomerulosclerosis (GGS) in IgA nephropathy, aging, and end-stage renal\ndisease. However, the fine-grained quantitative analysis of multiple GGS\nsubtypes (e.g., obsolescent, solidified, and disappearing glomerulosclerosis)\nis typically a resource extensive manual process. Very few automatic methods,\nif any, have been developed to bridge this gap for such analytics. In this\npaper, we present a holistic pipeline to quantify GGS (with both detection and\nclassification) from a whole slide image in a fully automatic manner. In\naddition, we conduct the fine-grained classification for the sub-types of GGS.\nOur study releases the open-source quantitative analytical tool for\nfine-grained GGS characterization while tackling the technical challenges in\nunbalanced classification and integrating detection and classification.",
    "descriptor": "",
    "authors": [
      "Yuzhe Lu",
      "Haichun Yang",
      "Zuhayr Asad",
      "Zheyu Zhu",
      "Tianyuan Yao",
      "Jiachen Xu",
      "Agnes B. Fogo",
      "Yuankai Huo"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2202.00087"
  },
  {
    "id": "arXiv:2202.00095",
    "title": "Deconfounded Representation Similarity for Comparison of Neural Networks",
    "abstract": "Similarity metrics such as representational similarity analysis (RSA) and\ncentered kernel alignment (CKA) have been used to compare layer-wise\nrepresentations between neural networks. However, these metrics are confounded\nby the population structure of data items in the input space, leading to\nspuriously high similarity for even completely random neural networks and\ninconsistent domain relations in transfer learning. We introduce a simple and\ngenerally applicable fix to adjust for the confounder with covariate adjustment\nregression, which retains the intuitive invariance properties of the original\nsimilarity measures. We show that deconfounding the similarity metrics\nincreases the resolution of detecting semantically similar neural networks.\nMoreover, in real-world applications, deconfounding improves the consistency of\nrepresentation similarities with domain similarities in transfer learning, and\nincreases correlation with out-of-distribution accuracy.",
    "descriptor": "",
    "authors": [
      "Tianyu Cui",
      "Yogesh Kumar",
      "Pekka Marttinen",
      "Samuel Kaski"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.00095"
  },
  {
    "id": "arXiv:2202.00099",
    "title": "Dynamic Origin-Destination Matrix Estimation in Urban Traffic Networks",
    "abstract": "Given the counters of vehicles that traverse the roads of a traffic network,\nwe aim at reconstructing the travel demand that generated them expressed in\nterms of the number of origin-destination trips made by users. We model the\nproblem as a bi-level optimization problem. In the inner level, given a\ntentative travel demand, we solve a dynamic traffic assignment problem to\ndecide the routing of the users between their origins and destinations. In the\nouter level, we adjust the number of trips and their origins and destinations,\naiming at minimizing the discrepancy between the consequent counters generated\nin the inner level and the given vehicle counts measured by sensors in the\ntraffic network. We solve the dynamic traffic assignment problem employing a\nmesoscopic model implemented by the traffic simulator SUMO. Thus, the outer\nproblem becomes an optimization problem that minimizes a black-box objective\nfunction determined by the results of the simulation, which is a costly\ncomputation. We study different approaches to the outer level problem\ncategorized as gradient-based and derivative-free approaches. Among the\ngradient-based approaches, we study an assignment matrix-based approach and an\nassignment matrix-free approach that uses the Simultaneous Perturbation\nStochastic Approximation (SPSA) algorithm. Among the derivative-free\napproaches, we study machine learning algorithms to learn a model of the\nsimulator that can then be used as a surrogated objective function in the\noptimization problem. We compare these approaches computationally on an\nartificial network. The gradient-based approaches perform the best in terms of\narchived solution quality and computational requirements, while the results\nobtained by the machine learning approach are currently less satisfactory but\nprovide an interesting avenue of future research.",
    "descriptor": "",
    "authors": [
      "Nicklas Sindlev Andersen",
      "Marco Chiarandini",
      "Kristian Debrabant"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.00099"
  },
  {
    "id": "arXiv:2202.00100",
    "title": "Calibration of P-values for calibration and for deviation of a  subpopulation from the full population",
    "abstract": "The author's recent research papers, \"Cumulative deviation of a subpopulation\nfrom the full population\" and \"A graphical method of cumulative differences\nbetween two subpopulations\" (both published in volume 8 of Springer's\nopen-access \"Journal of Big Data\" during 2021), propose graphical methods and\nsummary statistics, without extensively calibrating formal significance tests.\nThe summary metrics and methods can measure the calibration of probabilistic\npredictions and can assess differences in responses between a subpopulation and\nthe full population while controlling for a covariate or score via conditioning\non it. These recently published papers construct significance tests based on\nthe scalar summary statistics, but only sketch how to calibrate the attained\nsignificance levels (also known as \"P-values\") for the tests. The present\narticle reviews and synthesizes work spanning many decades in order to detail\nhow to calibrate the P-values. The present paper presents computationally\nefficient, easily implemented numerical methods for evaluating properly\ncalibrated P-values, together with rigorous mathematical proofs guaranteeing\ntheir accuracy, and illustrates and validates the methods with open-source\nsoftware and numerical examples.",
    "descriptor": "\nComments: 21 pages, 8 figures\n",
    "authors": [
      "Mark Tygert"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2202.00100"
  },
  {
    "id": "arXiv:2202.00109",
    "title": "Using satellites and artificial intelligence to measure health and  material-living standards in India",
    "abstract": "The application of deep learning methods to survey human development in\nremote areas with satellite imagery at high temporal frequency can\nsignificantly enhance our understanding of spatial and temporal patterns in\nhuman development. Current applications have focused their efforts in\npredicting a narrow set of asset-based measurements of human well-being within\na limited group of African countries. Here, we leverage georeferenced\nvillage-level census data from across 30 percent of the landmass of India to\ntrain a deep-neural network that predicts 16 variables representing material\nconditions from annual composites of Landsat 7 imagery. The census-based model\nis used as a feature extractor to train another network that predicts an even\nlarger set of developmental variables (over 90 variables) included in two\nrounds of the National Family Health Survey (NFHS) survey. The census-based\nmodel outperforms the current standard in the literature,\nnight-time-luminosity-based models, as a feature extractor for several of these\nlarge set of variables. To extend the temporal scope of the models, we suggest\na distribution-transformation procedure to estimate outcomes over time and\nspace in India. Our procedure achieves levels of accuracy in the R-square of\n0.92 to 0.60 for 21 development outcomes, 0.59 to 0.30 for 25 outcomes, and\n0.29 to 0.00 for 28 outcomes, and 19 outcomes had negative R-square. Overall,\nthe results show that combining satellite data with Indian Census data unlocks\nrich information for training deep learning models that track human development\nat an unprecedented geographical and temporal definition.",
    "descriptor": "",
    "authors": [
      "Adel Daoud",
      "Felipe Jordan",
      "Makkunda Sharma",
      "Fredrik Johansson",
      "Devdatt Dubhashi",
      "Sourabh Paul",
      "Subhashis Banerjee"
    ],
    "subjectives": [
      "General Economics (econ.GN)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2202.00109"
  },
  {
    "id": "arXiv:2202.00119",
    "title": "A lower bound on the space overhead of fault-tolerant quantum  computation",
    "abstract": "The threshold theorem is a fundamental result in the theory of fault-tolerant\nquantum computation stating that arbitrarily long quantum computations can be\nperformed with a polylogarithmic overhead provided the noise level is below a\nconstant level. A recent work by Fawzi, Grospellier and Leverrier (FOCS 2018)\nbuilding on a result by Gottesman (QIC 2013) has shown that the space overhead\ncan be asymptotically reduced to a constant independent of the circuit provided\nwe only consider circuits with a length bounded by a polynomial in the width.\nIn this work, using a minimal model for quantum fault tolerance, we establish a\ngeneral lower bound on the space overhead required to achieve fault tolerance.\nFor any non-unitary qubit channel $\\mathcal{N}$ and any quantum fault\ntolerance schemes against $\\mathrm{i.i.d.}$ noise modeled by $\\mathcal{N}$, we\nprove a lower bound of\n$\\max\\left\\{\\mathrm{Q}(\\mathcal{N})^{-1}n,\\alpha_\\mathcal{N} \\log T\\right\\}$ on\nthe number of physical qubits, for circuits of length $T$ and width $n$. Here,\n$\\mathrm{Q}(\\mathcal{N})$ denotes the quantum capacity of $\\mathcal{N}$ and\n$\\alpha_\\mathcal{N}>0$ is a constant only depending on the channel\n$\\mathcal{N}$. In our model, we allow for qubits to be replaced by fresh ones\nduring the execution of the circuit and we allow classical computation to be\nfree and perfect. This improves upon results that assumed classical\ncomputations to be also affected by noise, and that sometimes did not allow for\nfresh qubits to be added. Along the way, we prove an exponential upper bound on\nthe maximal length of fault-tolerant quantum computation with amplitude damping\nnoise resolving a conjecture by Ben-Or, Gottesman, and Hassidim (2013).",
    "descriptor": "\nComments: 23 pages, 2 figures, an earlier version of this paper appeared in proceedings of ITCS 2022. In the current version, we have extended our results to the model with noiseless classical computation for all non-unitary qubit noise channels\n",
    "authors": [
      "Omar Fawzi",
      "Alexander M\u00fcller-Hermes",
      "Ala Shayeghi"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.00119"
  },
  {
    "id": "arXiv:2202.00147",
    "title": "Distributed Quantum Vote Based on Quantum Logical Operators, a New  Battlefield of the Second Quantum Revolution",
    "abstract": "We designed two rules of binary quantum computed vote: Quantum Logical Veto\n(QLV) and Quantum Logical Nomination (QLN). The conjunction and disjunction\nfrom quantum computational logic are used to define QLV and QLN, respectively.\nCompared to classical vote, quantum computed vote is fairer, more democratic\nand has stronger expressive power. Since the advantage of quantum computed vote\nis neither the speed of computing nor the security of communication, we believe\nit opens a new battlefield in the second quantum revolution. Compared to other\nrules of quantum computed vote, QLV and QLN have better scalability. Both QLV\nand QLN can be implemented by the current technology and the difficulty of\nimplementation does not grow with the increase of the number of voters.",
    "descriptor": "\nComments: 9 pages\n",
    "authors": [
      "Xin Sun",
      "Feifei He",
      "Daowen Qiu",
      "Piotr Kulicki",
      "Mirek Sopek",
      "Meiyun Guo"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.00147"
  },
  {
    "id": "arXiv:2202.00157",
    "title": "Teaching Predictive Control Using Specification-based Summative  Assessments",
    "abstract": "Including Model Predictive Control (MPC) in the undergraduate/graduate\ncontrol curriculum is becoming vitally important due to the growing adoption of\nMPC in many industrial areas. In this paper, we present an overview of the\npredictive control course taught by the authors at Imperial College London\nbetween 2018 and 2021. We discuss how the course evolved from focusing solely\non the linear MPC formulation to covering nonlinear MPC and some of its\nextensions. We also present a novel specification-based summative assessment\nframework, written in MATLAB, that was developed to assess the knowledge and\nunderstanding of the students in the course by tasking them with designing a\ncontroller for a real-world problem. The MATLAB assessment framework was\ndesigned to provide the students with the freedom to design and implement any\nMPC controller they wanted. The submitted controllers were then assessed\nagainst over 30 variations of the real-world problem to gauge student\nunderstanding of design robustness and the MPC topics from the course.",
    "descriptor": "",
    "authors": [
      "Ian McInerney",
      "Eric C. Kerrigan"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.00157"
  },
  {
    "id": "arXiv:2202.00172",
    "title": "Fractional Motion Estimation for Point Cloud Compression",
    "abstract": "Motivated by the success of fractional pixel motion in video coding, we\nexplore the design of motion estimation with fractional-voxel resolution for\ncompression of color attributes of dynamic 3D point clouds. Our proposed\nblock-based fractional-voxel motion estimation scheme takes into account the\nfundamental differences between point clouds and videos, i.e., the irregularity\nof the distribution of voxels within a frame and across frames. We show that\nmotion compensation can benefit from the higher resolution reference and more\naccurate displacements provided by fractional precision. Our proposed scheme\nsignificantly outperforms comparable methods that only use integer motion. The\nproposed scheme can be combined with and add sizeable gains to state-of-the-art\nsystems that use transforms such as Region Adaptive Graph Fourier Transform and\nRegion Adaptive Haar Transform.",
    "descriptor": "\nComments: ACCPTED by DCC2022\n",
    "authors": [
      "Haoran Hong",
      "Eduardo Pavez",
      "Antonio Ortega",
      "Ryosuke Watanabe",
      "Keisuke Nonaka"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.00172"
  },
  {
    "id": "arXiv:2202.00179",
    "title": "Blind Image Deconvolution Using Variational Deep Image Prior",
    "abstract": "Conventional deconvolution methods utilize hand-crafted image priors to\nconstrain the optimization. While deep-learning-based methods have simplified\nthe optimization by end-to-end training, they fail to generalize well to blurs\nunseen in the training dataset. Thus, training image-specific models is\nimportant for higher generalization. Deep image prior (DIP) provides an\napproach to optimize the weights of a randomly initialized network with a\nsingle degraded image by maximum a posteriori (MAP), which shows that the\narchitecture of a network can serve as the hand-crafted image prior. Different\nfrom the conventional hand-crafted image priors that are statistically\nobtained, it is hard to find a proper network architecture because the\nrelationship between images and their corresponding network architectures is\nunclear. As a result, the network architecture cannot provide enough constraint\nfor the latent sharp image. This paper proposes a new variational deep image\nprior (VDIP) for blind image deconvolution, which exploits additive\nhand-crafted image priors on latent sharp images and approximates a\ndistribution for each pixel to avoid suboptimal solutions. Our mathematical\nanalysis shows that the proposed method can better constrain the optimization.\nThe experimental results further demonstrate that the generated images have\nbetter quality than that of the original DIP on benchmark datasets. The source\ncode of our VDIP is available at\nhttps://github.com/Dong-Huo/VDIP-Deconvolution.",
    "descriptor": "",
    "authors": [
      "Dong Huo",
      "Abbas Masoumzadeh",
      "Rafsanjany Kushol",
      "Yee-Hong Yang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.00179"
  },
  {
    "id": "arXiv:2202.00187",
    "title": "Deep Reference Priors: What is the best way to pretrain a model?",
    "abstract": "What is the best way to exploit extra data -- be it unlabeled data from the\nsame task, or labeled data from a related task -- to learn a given task? This\npaper formalizes the question using the theory of reference priors. Reference\npriors are objective, uninformative Bayesian priors that maximize the mutual\ninformation between the task and the weights of the model. Such priors enable\nthe task to maximally affect the Bayesian posterior, e.g., reference priors\ndepend upon the number of samples available for learning the task and for very\nsmall sample sizes, the prior puts more probability mass on low-complexity\nmodels in the hypothesis space. This paper presents the first demonstration of\nreference priors for medium-scale deep networks and image-based data. We\ndevelop generalizations of reference priors and demonstrate applications to two\nproblems. First, by using unlabeled data to compute the reference prior, we\ndevelop new Bayesian semi-supervised learning methods that remain effective\neven with very few samples per class. Second, by using labeled data from the\nsource task to compute the reference prior, we develop a new pretraining method\nfor transfer learning that allows data from the target task to maximally affect\nthe Bayesian posterior. Empirical validation of these methods is conducted on\nimage classification datasets.",
    "descriptor": "\nComments: 23 pages\n",
    "authors": [
      "Yansong Gao",
      "Rahul Ramesh",
      "Pratik Chaudhari"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.00187"
  },
  {
    "id": "arXiv:2202.00188",
    "title": "Rethinking the notion of oracle: A link between synthetic descriptive  set theory and effective topos theory",
    "abstract": "We present three different perspectives of oracle. First, an oracle is a\nblackbox; second, an oracle is an endofunctor on the category of represented\nspaces; and third, an oracle is an operation on the object of truth-values.\nThese three perspectives create a link between the three fields, computability\ntheory, synthetic descriptive set theory, and effective topos theory.",
    "descriptor": "",
    "authors": [
      "Takayuki Kihara"
    ],
    "subjectives": [
      "Logic (math.LO)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2202.00188"
  },
  {
    "id": "arXiv:2202.00192",
    "title": "Tight Cuts in Biartite Grafts I: Capital Distance Components",
    "abstract": "This paper is the first from a series of papers that provide a\ncharacterization of maximum packings of $T$-cuts in bipartite graphs. Given a\nconnected graph, a set $T$ of an even number of vertices, and a minimum\n$T$-join, an edge weighting can be defined, from which distances between\nvertices can be defined. Furthermore, given a specified vertex called root,\nvertices can be classified according to their distances from the root, and this\nclassification of vertices can be used to define a family of subgraphs called\n{\\em distance components}. Seb\\\"o provided a theorem that revealed a\nrelationship between distance components, minimum $T$-joins, and $T$-cuts. In\nthis paper, we further investigate the structure of distance components in\nbipartite graphs. Particularly, we focus on {\\em capital} distance components,\nthat is, those that include the root. We reveal the structure of capital\ndistance components in terms of the $T$-join analogue of the general\nKotzig-Lov\\'asz canonical decomposition.",
    "descriptor": "",
    "authors": [
      "Nanao Kita"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2202.00192"
  },
  {
    "id": "arXiv:2202.00198",
    "title": "Recognition-Aware Learned Image Compression",
    "abstract": "Learned image compression methods generally optimize a rate-distortion loss,\ntrading off improvements in visual distortion for added bitrate. Increasingly,\nhowever, compressed imagery is used as an input to deep learning networks for\nvarious tasks such as classification, object detection, and superresolution. We\npropose a recognition-aware learned compression method, which optimizes a\nrate-distortion loss alongside a task-specific loss, jointly learning\ncompression and recognition networks. We augment a hierarchical\nautoencoder-based compression network with an EfficientNet recognition model\nand use two hyperparameters to trade off between distortion, bitrate, and\nrecognition performance. We characterize the classification accuracy of our\nproposed method as a function of bitrate and find that for low bitrates our\nmethod achieves as much as 26% higher recognition accuracy at equivalent\nbitrates compared to traditional methods such as Better Portable Graphics\n(BPG).",
    "descriptor": "\nComments: Electronic Imaging Symposium, Computational Imaging XX Conference, January 2022\n",
    "authors": [
      "Maxime Kawawa-Beaudan",
      "Ryan Roggenkemper",
      "Avideh Zakhor"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.00198"
  },
  {
    "id": "arXiv:2202.00204",
    "title": "Disentangling multiple scattering with deep learning: application to  strain mapping from electron diffraction patterns",
    "abstract": "Implementation of a fast, robust, and fully-automated pipeline for crystal\nstructure determination and underlying strain mapping for crystalline materials\nis important for many technological applications. Scanning electron\nnanodiffraction offers a procedure for identifying and collecting strain maps\nwith good accuracy and high spatial resolutions. However, the application of\nthis technique is limited, particularly in thick samples where the electron\nbeam can undergo multiple scattering, which introduces signal nonlinearities.\nDeep learning methods have the potential to invert these complex signals, but\nprevious implementations are often trained only on specific crystal systems or\na small subset of the crystal structure and microscope parameter phase space.\nIn this study, we implement a Fourier space, complex-valued deep neural network\ncalled FCU-Net, to invert highly nonlinear electron diffraction patterns into\nthe corresponding quantitative structure factor images. We trained the FCU-Net\nusing over 200,000 unique simulated dynamical diffraction patterns which\ninclude many different combinations of crystal structures, orientations,\nthicknesses, microscope parameters, and common experimental artifacts. We\nevaluated the trained FCU-Net model against simulated and experimental 4D-STEM\ndiffraction datasets, where it substantially out-performs conventional analysis\nmethods. Our simulated diffraction pattern library, implementation of FCU-Net,\nand trained model weights are freely available in open source repositories, and\ncan be adapted to many different diffraction measurement problems.",
    "descriptor": "\nComments: 17 pages, 7 figures\n",
    "authors": [
      "Joydeep Munshi",
      "Alexander Rakowski",
      "Benjamin H Savitzky",
      "Steven E Zeltmann",
      "Jim Ciston",
      "Matthew Henderson",
      "Shreyas Cholia",
      "Andrew M Minor",
      "Maria KY Chan",
      "Colin Ophus"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Applied Physics (physics.app-ph)"
    ],
    "url": "https://arxiv.org/abs/2202.00204"
  },
  {
    "id": "arXiv:2202.00232",
    "title": "ISNet: Costless and Implicit Image Segmentation for Deep Classifiers,  with Application in COVID-19 Detection",
    "abstract": "In this work we propose a novel deep neural network (DNN) architecture,\nISNet, to solve the task of image segmentation followed by classification,\nsubstituting the common pipeline of two networks by a single model. We designed\nthe ISNet for high flexibility and performance: it allows virtually any\nclassification neural network architecture to analyze a common image as if it\nhad been previously segmented. Furthermore, in relation to the original\nclassifier, the ISNet does not cause any increment in computational cost or\narchitectural changes at run-time. To accomplish this, we introduce the concept\nof optimizing DNNs for relevance segmentation in heatmaps created by Layer-wise\nRelevance Propagation (LRP), which proves to be equivalent to the\nclassification of previously segmented images. We apply an ISNet based on a\nDenseNet121 classifier to solve the task of COVID-19 detection in chest X-rays.\nWe compare the model to a U-net (performing lung segmentation) followed by a\nDenseNet121, and to a standalone DenseNet121. Due to the implicit segmentation,\nthe ISNet precisely ignored the X-ray regions outside of the lungs; it achieved\n94.5 +/-4.1% mean accuracy with an external database, showing strong\ngeneralization capability and surpassing the other models' performances by 6 to\n7.9%. ISNet presents a fast and light methodology to perform classification\npreceded by segmentation, while also being more accurate than standard\npipelines.",
    "descriptor": "",
    "authors": [
      "Pedro R.A.S. Bassi"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.00232"
  },
  {
    "id": "arXiv:2202.00235",
    "title": "A Network Map of The Witcher",
    "abstract": "The Witcher, a fantasy novel series by Andrzej Sapkowski, has inspired\nmultiple computer games and was even launched on Netflix in 2019, with the\nlatest season airing in December 2021. Fictional storylines such as The\nWitcher, can be well summarized and simplified by network science, extracting\nthe backbone of a complex series of events. In other words, network mapping and\ndata science can transform thousands of pages into one simple, visual, social\nmap. This exemplary visualization also highlights the power of network science\nby uncovering hidden patterns, such as influencers, hubs, and cliques in the\ninterplay of hundreds of people and their countless encounters. As these\nmethods can be applied to novels and their adaptations as well, they also allow\nus to compare the original and the adapted pieces, from the cast to the plots.\nTherefore, in this article, I provide a social network analysis about the\nsocietal characteristics of The Witcher, comparing the novels and the TV show.",
    "descriptor": "\nComments: 10 pages, 5 figures\n",
    "authors": [
      "Milan Janosov"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2202.00235"
  },
  {
    "id": "arXiv:2202.00293",
    "title": "Phase diagram of Stochastic Gradient Descent in high-dimensional  two-layer neural networks",
    "abstract": "Despite the non-convex optimization landscape, over-parametrized shallow\nnetworks are able to achieve global convergence under gradient descent. The\npicture can be radically different for narrow networks, which tend to get stuck\nin badly-generalizing local minima. Here we investigate the cross-over between\nthese two regimes in the high-dimensional setting, and in particular\ninvestigate the connection between the so-called mean-field/hydrodynamic regime\nand the seminal approach of Saad & Solla. Focusing on the case of Gaussian\ndata, we study the interplay between the learning rate, the time scale, and the\nnumber of hidden units in the high-dimensional dynamics of stochastic gradient\ndescent (SGD). Our work builds on a deterministic description of SGD in\nhigh-dimensions from statistical physics, which we extend and for which we\nprovide rigorous convergence rates.",
    "descriptor": "\nComments: 14 pages + Appendix\n",
    "authors": [
      "Rodrigo Veiga",
      "Ludovic Stephan",
      "Bruno Loureiro",
      "Florent Krzakala",
      "Lenka Zdeborov\u00e1"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.00293"
  },
  {
    "id": "arXiv:2202.00347",
    "title": "Finite-time enclosing control for multiple moving targets: a continuous  estimator approach",
    "abstract": "This work addresses the finite-time enclosing control problem where a set of\nfollowers are deployed to encircle and rotate around multiple moving targets\nwith a predefined spacing pattern in finite time. A novel distributed and\ncontinuous estimator is firstly proposed to track the geometric center of\ntargets in finite time using only local information for every follower. Then a\npair of decentralized control laws for both the relative distance and included\nangle, respectively, are designed to achieve the desired spacing pattern in\nfinite time based on the output of the proposed estimator. Through both\ntheoretical analysis and simulation validation, we show that the proposed\nestimator is continuous and therefore can avoid dithering control output while\nstill inheriting the merit of finite-time convergence. The steady errors of the\nestimator and the enclosing controller are guaranteed to converge to some\nbounded and adjustable regions around zero.",
    "descriptor": "",
    "authors": [
      "Liang Zhang"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.00347"
  },
  {
    "id": "arXiv:2202.00348",
    "title": "Learning entanglement breakdown as a phase transition by confusion",
    "abstract": "Quantum technologies require methods for preparing and manipulating entangled\nmultiparticle states. However, the problem of determining whether a given\nquantum state is entangled or separable is known to be an NP-hard problem in\ngeneral, and even the task of detecting entanglement breakdown for a given\nclass of quantum states is difficult. In this work, we develop an approach for\nrevealing entanglement breakdown using a machine learning technique, which is\nknown as 'learning by confusion'. We consider a family of quantum states, which\nis parameterized such that there is a single critical value dividing states\nwithin this family on separate and entangled. We demonstrate the 'learning by\nconfusion' scheme allows determining the critical value. Specifically, we study\nthe performance of the method for the two-qubit, two-qutrit, and two-ququart\nentangled state, where the standard entanglement measures do not work\nefficiently. In addition, we investigate the properties of the local\ndepolarization and the generalized amplitude damping channel in the framework\nof the confusion scheme. Within our approach and setting the parameterization\nof special trajectories to construct W shapes, we obtain an\nentanglement-breakdown 'phase diagram' of a quantum channel, which indicates\nregions of entangled (separable) states and the entanglement-breakdown region.\nThen we extend the way of using the 'learning by confusion' scheme for\nrecognizing whether an arbitrary given state is entangled or separable. We show\nthat the developed method provides correct answers for a variety of states,\nincluding entangled states with positive partial transpose (PPT). We also\npresent a more practical version of the method, which is suitable for studying\nentanglement breakdown in noisy intermediate-scale quantum (NISQ) devices. We\ndemonstrate its performance using an available cloud-based IBM quantum\nprocessor.",
    "descriptor": "\nComments: 13 pages, 10 figures, 4 tables\n",
    "authors": [
      "M.A. Gavreev",
      "A.S. Mastiukova",
      "E.O. Kiktenko",
      "A.K. Fedorov"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.00348"
  },
  {
    "id": "arXiv:2202.00380",
    "title": "Machine-learning-enhanced quantum sensors for accurate magnetic field  imaging",
    "abstract": "Local detection of magnetic fields is crucial for characterizing nano- and\nmicro-materials and has been implemented using various scanning techniques or\neven diamond quantum sensors. Diamond nanoparticles (nanodiamonds) offer an\nattractive opportunity to chieve high spatial resolution because they can\neasily be close to the target within a few 10 nm simply by attaching them to\nits surface. A physical model for such a randomly oriented nanodiamond ensemble\n(NDE) is available, but the complexity of actual experimental conditions still\nlimits the accuracy of deducing magnetic fields. Here, we demonstrate magnetic\nfield imaging with high accuracy of 1.8 $\\mu$T combining NDE and machine\nlearning without any physical models. We also discover the field direction\ndependence of the NDE signal, suggesting the potential application for vector\nmagnetometry and improvement of the existing model. Our method further enriches\nthe performance of NDE to achieve the accuracy to visualize mesoscopic current\nand magnetism in atomic-layer materials and to expand the applicability in\narbitrarily shaped materials, including living organisms. This achievement will\nbridge machine learning and quantum sensing for accurate measurements.",
    "descriptor": "\nComments: 29 pages, 10 figures\n",
    "authors": [
      "Moeta Tsukamoto",
      "Shuji Ito",
      "Kensuke Ogawa",
      "Yuto Ashida",
      "Kento Sasaki",
      "Kensuke Kobayashi"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.00380"
  },
  {
    "id": "arXiv:2202.00382",
    "title": "A Privacy-Preserving Image Retrieval Scheme with a Mixture of Plain and  EtC Images",
    "abstract": "In this paper, we propose a novel content-based image-retrieval scheme that\nallows us to use a mixture of plain images and compressible encrypted ones\ncalled \"encryption-then-compression (EtC) images.\" In the proposed scheme,\nextended SIMPLE descriptors are extracted from EtC images as well as from plain\nones, so the mixed use of plain and encrypted images is available for image\nretrieval. In an experiment, the proposed scheme was demonstrated to have\nalmost the same retrieval performance as that for plain images, even with a\nmixture of plain and encrypted images.",
    "descriptor": "\nComments: This paper will be presented at IEEE LifeTech 2022. arXiv admin note: text overlap with arXiv:2011.00270\n",
    "authors": [
      "Kenta Iida",
      "Hitoshi Kiya"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2202.00382"
  },
  {
    "id": "arXiv:2202.00414",
    "title": "A physics-driven study of dominance space in soccer",
    "abstract": "In arXiv:2107.05714 the concept of the Voronoi diagram was investigated\nclosely from a theoretical point of view. Then, a physics-driven kinematical\nmethod was introduced to produce an improved model for dominance space in\nsoccer. Remaining faithful to the deterministic approach, we extend the\noriginal work by the introduction of (a) an asymmetric influence of the players\nin their surrounding area, (b) the frictional forces to the players' motion,\nand (c) the simultaneous combination of both effects. The asymmetric influence\nis fairly intuitive; players have more control in the direction they are\nrunning than any other direction. The sharper the turn they must make to reach\na point on the pitch, the weaker their control of that point will be. From\nsimple kinematical laws, this effect can be quantified explicitly. For the\nfrictional force, a portion comes from air resistance, and so will be\nproportional to the square of the player's speed, as is well known from fluid\ndynamics. There are no other external frictional forces, but, at the suggestion\nof biokinematics, there is an internal frictional force, relating to the\nconsumption of energy by the muscles, which is proportional to the player's\nspeed.\nAlthough these additions are intuitively understood, mathematically they\nintroduce many analytical complexities. We establish exact analytical solutions\nof the dominance areas of the pitch by introducing a few reasonable simplifying\nassumptions. Given these solutions the new Voronoi diagrams are drawn for the\npublicly available data by Metrica Sports. In general, it is not necessary\nanymore for the dominance regions to be convex, they might contain holes, and\nmay be disconnected. The fastest player may dominate points far away from the\nrest of the players.",
    "descriptor": "\nComments: The article contains many computer-generated Voronoi diagrams. We have reduced the file size of the diagrams but there might be a few seconds delay to load some pages\n",
    "authors": [
      "Costas J. Efthimiou",
      "Gregory DeCamillis",
      "Indranil Ghosh"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Computers and Society (cs.CY)",
      "Popular Physics (physics.pop-ph)"
    ],
    "url": "https://arxiv.org/abs/2202.00414"
  },
  {
    "id": "arXiv:2202.00416",
    "title": "CAESR: Conditional Autoencoder and Super-Resolution for Learned Spatial  Scalability",
    "abstract": "In this paper, we present CAESR, an hybrid learning-based coding approach for\nspatial scalability based on the versatile video coding (VVC) standard. Our\nframework considers a low-resolution signal encoded with VVC intra-mode as a\nbase-layer (BL), and a deep conditional autoencoder with hyperprior (AE-HP) as\nan enhancement-layer (EL) model. The EL encoder takes as inputs both the\nupscaled BL reconstruction and the original image. Our approach relies on\nconditional coding that learns the optimal mixture of the source and the\nupscaled BL image, enabling better performance than residual coding. On the\ndecoder side, a super-resolution (SR) module is used to recover high-resolution\ndetails and invert the conditional coding process. Experimental results have\nshown that our solution is competitive with the VVC full-resolution intra\ncoding while being scalable.",
    "descriptor": "",
    "authors": [
      "Charles Bonnineau",
      "Wassim Hamidouche",
      "Jean-Fran\u00e7ois Travers",
      "Naty Sidaty",
      "Jean-Yves Aubi\u00e9",
      "Olivier Deforges"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.00416"
  },
  {
    "id": "arXiv:2202.00419",
    "title": "Sinogram Enhancement with Generative Adversarial Networks using Shape  Priors",
    "abstract": "Compensating scarce measurements by inferring them from computational models\nis a way to address ill-posed inverse problems. We tackle Limited Angle\nTomography by completing the set of acquisitions using a generative model and\nprior-knowledge about the scanned object. Using a Generative Adversarial\nNetwork as model and Computer-Assisted Design data as shape prior, we\ndemonstrate a quantitative and qualitative advantage of our technique over\nother state-of-the-art methods. Inferring a substantial number of consecutive\nmissing measurements, we offer an alternative to other image inpainting\ntechniques that fall short of providing a satisfying answer to our research\nquestion: can X-Ray exposition be reduced by using generative models to infer\nlacking measurements?",
    "descriptor": "\nComments: 9 pages, 8 figures\n",
    "authors": [
      "Emilien Valat",
      "Katayoun Farrahi",
      "Thomas Blumensath"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.00419"
  },
  {
    "id": "arXiv:2202.00424",
    "title": "Improving Parametric Neural Networks for High-Energy Physics (and  Beyond)",
    "abstract": "Signal-background classification is a central problem in High-Energy Physics,\nthat plays a major role for the discovery of new fundamental particles. A\nrecent method -- the Parametric Neural Network (pNN) -- leverages multiple\nsignal mass hypotheses as an additional input feature to effectively replace a\nwhole set of individual classifier, each providing (in principle) the best\nresponse for a single mass hypothesis. In this work we aim at deepening the\nunderstanding of pNNs in light of real-world usage. We discovered several\npeculiarities of parametric networks, providing intuition, metrics, and\nguidelines to them. We further propose an alternative parametrization scheme,\nresulting in a new parametrized neural network architecture: the AffinePNN;\nalong with many other generally applicable improvements. Finally, we\nextensively evaluate our models on the HEPMASS dataset, along its imbalanced\nversion (called HEPMASS-IMB) we provide here for the first time to further\nvalidate our approach. Provided results are in terms of the impact of the\nproposed design decisions, classification performance, and interpolation\ncapability as well.",
    "descriptor": "\nComments: 18 pages, 13 figures, 5 tables\n",
    "authors": [
      "Luca Anzalone",
      "Tommaso Diotalevi",
      "Daniele Bonacorsi"
    ],
    "subjectives": [
      "High Energy Physics - Experiment (hep-ex)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.00424"
  },
  {
    "id": "arXiv:2202.00437",
    "title": "Combinatorial properties of lazy expansions in Cantor real bases",
    "abstract": "The lazy algorithm for a real base $\\beta$ is generalized to the setting of\nCantor bases $\\boldsymbol{\\beta}=(\\beta_n)_{n\\in \\mathbb{N}}$ introduced\nrecently by Charlier and the author. To do so, let $x_{\\boldsymbol{\\beta}}$ be\nthe greatest real number that has a $\\boldsymbol{\\beta}$-representation\n$a_0a_1a_2\\cdots$ such that each letter $a_n$ belongs to $\\{0,\\ldots,\\lceil\n\\beta_n \\rceil -1\\}$. This paper is concerned with the combinatorial properties\nof the lazy $\\boldsymbol{\\beta}$-expansions, which are defined when\n$x_{\\boldsymbol{\\beta}}<+\\infty$. As an illustration, Cantor bases following\nthe Thue-Morse sequence are studied and a formula giving their corresponding\nvalue of $x_{\\boldsymbol{\\beta}}$ is proved. First, it is shown that the lazy\n$\\boldsymbol{\\beta}$-expansions are obtained by \"flipping\" the digits of the\ngreedy $\\boldsymbol{\\beta}$-expansions. Next, a Parry-like criterion\ncharacterizing the sequences of non-negative integers that are the lazy\n$\\boldsymbol{\\beta}$-expansions of some real number in\n$(x_{\\boldsymbol{\\beta}}-1,x_{\\boldsymbol{\\beta}}]$ is proved. Moreover, the\nlazy $\\boldsymbol{\\beta}$-shift is studied and in the particular case of\nalternate bases, that is the periodic Cantor bases, an analogue of\nBertrand-Mathis' theorem in the lazy framework is proved: the lazy\n$\\boldsymbol{\\beta}$-shift is sofic if and only if all quasi-lazy\n$\\boldsymbol{\\beta}^{(i)}$-expansions of $x_{\\boldsymbol{\\beta}^{(i)}}-1$ are\nultimately periodic, where $\\boldsymbol{\\beta}^{(i)}$ is the $i$-th shift of\nthe alternate base $\\boldsymbol{\\beta}$.",
    "descriptor": "",
    "authors": [
      "C\u00e9lia Cisternino"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2202.00437"
  },
  {
    "id": "arXiv:2202.00451",
    "title": "GENEOnet: A new machine learning paradigm based on Group Equivariant  Non-Expansive Operators. An application to protein pocket detection",
    "abstract": "Nowadays there is a big spotlight cast on the development of techniques of\nexplainable machine learning. Here we introduce a new computational paradigm\nbased on Group Equivariant Non-Expansive Operators, that can be regarded as the\nproduct of a rising mathematical theory of information-processing observers.\nThis approach, that can be adjusted to different situations, may have many\nadvantages over other common tools, like Neural Networks, such as: knowledge\ninjection and information engineering, selection of relevant features, small\nnumber of parameters and higher transparency. We chose to test our method,\ncalled GENEOnet, on a key problem in drug design: detecting pockets on the\nsurface of proteins that can host ligands. Experimental results confirmed that\nour method works well even with a quite small training set, providing thus a\ngreat computational advantage, while the final comparison with other\nstate-of-the-art methods shows that GENEOnet provides better or comparable\nresults in terms of accuracy.",
    "descriptor": "",
    "authors": [
      "Giovanni Bocchi",
      "Patrizio Frosini",
      "Alessandra Micheletti",
      "Alessandro Pedretti",
      "Carmen Gratteri",
      "Filippo Lunghini",
      "Andrea Rosario Beccari",
      "Carmine Talarico"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2202.00451"
  },
  {
    "id": "arXiv:2202.00465",
    "title": "A generalizable approach based on U-Net model for automatic Intra  retinal cyst segmentation in SD-OCT images",
    "abstract": "Intra retinal fluids or Cysts are one of the important symptoms of macular\npathologies that are efficiently visualized in OCT images. Automatic\nsegmentation of these abnormalities has been widely investigated in medical\nimage processing studies. In this paper, we propose a new U-Net-based approach\nfor Intra retinal cyst segmentation across different vendors that improves some\nof the challenges faced by previous deep-based techniques. The proposed method\nhas two main steps: 1- prior information embedding and input data adjustment,\nand 2- IRC segmentation model. In the first step, we inject the information\ninto the network in a way that overcomes some of the network limitations in\nreceiving data and learning important contextual knowledge. And in the next\nstep, we introduced a connection module between encoder and decoder parts of\nthe standard U-Net architecture that transfers information more effectively\nfrom the encoder to the decoder part. Two public datasets namely OPTIMA and\nKERMANY were employed to evaluate the proposed method. Results showed that the\nproposed method is an efficient vendor-independent approach for IRC\nsegmentation with mean Dice values of 0.78 and 0.81 on the OPTIMA and KERMANY\ndatasets, respectively.",
    "descriptor": "\nComments: 22pages, 7 figures, 4 tables\n",
    "authors": [
      "Razieh Ganjee",
      "Mohsen Ebrahimi Moghaddam",
      "Ramin Nourinia"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.00465"
  },
  {
    "id": "arXiv:2202.00467",
    "title": "Safe Screening for Logistic Regression with $\\ell_0$-$\\ell_2$  Regularization",
    "abstract": "In logistic regression, it is often desirable to utilize regularization to\npromote sparse solutions, particularly for problems with a large number of\nfeatures compared to available labels. In this paper, we present screening\nrules that safely remove features from logistic regression with $\\ell_0-\\ell_2$\nregularization before solving the problem. The proposed safe screening rules\nare based on lower bounds from the Fenchel dual of strong conic relaxations of\nthe logistic regression problem. Numerical experiments with real and synthetic\ndata suggest that a high percentage of the features can be effectively and\nsafely removed apriori, leading to substantial speed-up in the computations.",
    "descriptor": "",
    "authors": [
      "Anna Deza",
      "Alper Atamturk"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2202.00467"
  },
  {
    "id": "arXiv:2202.00495",
    "title": "Machine Intelligence-Driven Classification of Cancer Patients-Derived  Extracellular Vesicles using Fluorescence Correlation Spectroscopy: Results  from a Pilot Study",
    "abstract": "Patient-derived extracellular vesicles (EVs) that contains a complex\nbiological cargo is a valuable source of liquid biopsy diagnostics to aid in\nearly detection, cancer screening, and precision nanotherapeutics. In this\nstudy, we predicted that coupling cancer patient blood-derived EVs to\ntime-resolved spectroscopy and artificial intelligence (AI) could provide a\nrobust cancer screening and follow-up tools. Methods: Fluorescence correlation\nspectroscopy (FCS) measurements were performed on 24 blood samples-derived EVs.\nBlood samples were obtained from 15 cancer patients (presenting 5 different\ntypes of cancers), and 9 healthy controls (including patients with benign\nlesions). The obtained FCS autocorrelation spectra were processed into power\nspectra using the Fast-Fourier Transform algorithm and subjected to various\nmachine learning algorithms to distinguish cancer spectra from healthy control\nspectra. Results and Applications: The performance of AdaBoost Random Forest\n(RF) classifier, support vector machine, and multilayer perceptron, were tested\non selected frequencies in the N=118 power spectra. The RF classifier exhibited\na 90% classification accuracy and high sensitivity and specificity in\ndistinguishing the FCS power spectra of cancer patients from those of healthy\ncontrols. Further, an image convolutional neural network (CNN), ResNet network,\nand a quantum CNN were assessed on the power spectral images as additional\nvalidation tools. All image-based CNNs exhibited a nearly equal classification\nperformance with an accuracy of roughly 82% and reasonably high sensitivity and\nspecificity scores. Our pilot study demonstrates that AI-algorithms coupled to\ntime-resolved FCS power spectra can accurately and differentially classify the\ncomplex patient-derived EVs from different cancer samples of distinct tissue\nsubtypes.",
    "descriptor": "\nComments: 23 pages, 6 figures\n",
    "authors": [
      "Abicumaran Uthamacumaran",
      "Mohamed Abdouh",
      "Kinshuk Sengupta",
      "Zu-hua Gao",
      "Stefano Forte",
      "Thupten Tsering",
      "Julia V Burnier",
      "Goffredo Arena"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)",
      "Biomolecules (q-bio.BM)"
    ],
    "url": "https://arxiv.org/abs/2202.00495"
  },
  {
    "id": "arXiv:2202.00509",
    "title": "Decentralized Stochastic Variance Reduced Extragradient Method",
    "abstract": "This paper studies decentralized convex-concave minimax optimization problems\nof the form $\\min_x\\max_y f(x,y) \\triangleq\\frac{1}{m}\\sum_{i=1}^m f_i(x,y)$,\nwhere $m$ is the number of agents and each local function can be written as\n$f_i(x,y)=\\frac{1}{n}\\sum_{j=1}^n f_{i,j}(x,y)$. We propose a novel\ndecentralized optimization algorithm, called multi-consensus stochastic\nvariance reduced extragradient, which achieves the best known stochastic\nfirst-order oracle (SFO) complexity for this problem. Specifically, each agent\nrequires $\\mathcal O((n+\\kappa\\sqrt{n})\\log(1/\\varepsilon))$ SFO calls for\nstrongly-convex-strongly-concave problem and $\\mathcal\nO((n+\\sqrt{n}L/\\varepsilon)\\log(1/\\varepsilon))$ SFO call for general\nconvex-concave problem to achieve $\\varepsilon$-accurate solution in\nexpectation, where $\\kappa$ is the condition number and $L$ is the smoothness\nparameter. The numerical experiments show the proposed method performs better\nthan baselines.",
    "descriptor": "",
    "authors": [
      "Luo Luo",
      "Haishan Ye"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.00509"
  },
  {
    "id": "arXiv:2202.00552",
    "title": "Intelligent Reflecting Surface Assisted Integrated Sensing and  Communications for mmWave Channels",
    "abstract": "This paper proposes an intelligent reflecting surface (IRS) assisted\nintegrated sensing and communication (ISAC) system operating at the\nmillimeter-wave (mmWave) band. Specifically, the ISAC system combines\ncommunication and radar operations and performs, detecting and communicating\nsimultaneously with multiple targets and users. The IRS dynamically controls\nthe amplitude or phase of the radio signal via reflecting elements to\nreconfigure the radio propagation environment and enhance the transmission rate\nof the ISAC system. By jointly designing the radar signal covariance (RSC)\nmatrix, the beamforming vector of the communication system, and the IRS phase\nshift, the ISAC system transmission rate can be improved while matching the\ndesired waveform for radar. The problem is non-convex due to multivariate\ncoupling, and thus we decompose it into two separate subproblems. First, a\nclosed-form solution of the RSC matrix is derived from the desired radar\nwaveform. Next, the quadratic transformation (QT) technique is applied to the\nsubproblem, and then alternating optimization (AO) is employed to determine the\ncommunication beamforming vector and the IRS phase shift. For computing the IRS\nphase shift, we adopt both the majorization minimization (MM) and the manifold\noptimization (MO). Also, we derive a closed-form solution for the formulated\nproblem, effectively decreasing computational complexity. Furthermore, a\ntrade-off factor is introduced to balance the performance of communication and\nsensing. Finally, the simulations verify the effectiveness of the algorithm and\ndemonstrate that the IRS can improve the performance of the ISAC system.",
    "descriptor": "\nComments: 10 pages, 8 figures\n",
    "authors": [
      "Zhengyu Zhu",
      "Zheng Li",
      "Zheng Chu",
      "Gangcan Sun",
      "Wanming Hao",
      "Pei Xiao",
      "Inkyu Lee"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.00552"
  },
  {
    "id": "arXiv:2202.00559",
    "title": "Runtime Monitoring and Statistical Approaches for Correlation Analysis  of ECG and PPG",
    "abstract": "Biophysical signals such as Electrocardiogram (ECG) and Photoplethysmogram\n(PPG) are key to the sensing of vital parameters for wellbeing. Coincidentally,\nECG and PPG are signals, which provide a \"different window\" into the same\nphenomena, namely the cardiac cycle. While they are used separately, there are\nno studies regarding the exact correction of the different ECG and PPG events.\nSuch correlation would be helpful in many fronts such as sensor fusion for\nimproved accuracy using cheaper sensors and attack detection and mitigation\nmethods using multiple signals to enhance the robustness, for example.\nConsidering this, we present the first approach in formally establishing the\nkey relationships between ECG and PPG signals. We combine formal run-time\nmonitoring with statistical analysis and regression analysis for our results.",
    "descriptor": "\nComments: 5pages, 6 figures\n",
    "authors": [
      "Abhinandan Panda",
      "Srinivas Pinisetty",
      "Partha Roop"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Formal Languages and Automata Theory (cs.FL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.00559"
  },
  {
    "id": "arXiv:2202.00560",
    "title": "Study of filtered-x logarithmic recursive least $p$-power algorithm",
    "abstract": "For active impulsive noise control, a filtered-x recursive least $p$-power\n(FxRLP) algorithm is proposed by minimizing the weighted summation of the\n$p$-power of the \\emph{a posteriori} errors. Since the characteristic of the\ntarget noise is investigated, the FxRLP algorithm achieves good performance and\nrobustness. To obtain a better performance, we develop a filtered-x logarithmic\nrecursive least $p$-power (FxlogRLP) algorithm which integrates the $p$-order\nmoment with the logarithmic-order moment. Simulation results demonstrate that\nthe FxlogRLP algorithm is superior to the existing algorithms in terms of\nconvergence rate and noise reduction.",
    "descriptor": "\nComments: 7 pages, 3 figures\n",
    "authors": [
      "Z. Zheng",
      "L. Lu",
      "Y. Yu",
      "R. C. de Lamare",
      "Z. Liu"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.00560"
  },
  {
    "id": "arXiv:2202.00563",
    "title": "Finding lost DG: Explaining domain generalization via model complexity",
    "abstract": "The domain generalization (DG) problem setting challenges a model trained on\nmultiple known data distributions to generalise well on unseen data\ndistributions. Due to its practical importance, a large number of methods have\nbeen proposed to address this challenge. However much of the work in general\npurpose DG is heuristically motivated, as the DG problem is hard to model\nformally; and recent evaluations have cast doubt on existing methods' practical\nefficacy -- in particular compared to a well tuned empirical risk minimisation\nbaseline. We present a novel learning-theoretic generalisation bound for DG\nthat bounds unseen domain generalisation performance in terms of the model's\nRademacher complexity. Based on this, we conjecture that existing methods'\nefficacy or lack thereof is largely determined by an empirical risk vs\npredictor complexity trade-off, and demonstrate that their performance\nvariability can be explained in these terms. Algorithmically, this analysis\nsuggests that domain generalisation should be achieved by simply performing\nregularised ERM with a leave-one-domain-out cross-validation objective.\nEmpirical results on the DomainBed benchmark corroborate this.",
    "descriptor": "",
    "authors": [
      "Da Li",
      "Henry Gouk",
      "Timothy Hospedales"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.00563"
  },
  {
    "id": "arXiv:2202.00567",
    "title": "Optimal Transport based Data Augmentation for Heart Disease Diagnosis  and Prediction",
    "abstract": "In this paper, we focus on a new method of data augmentation to solve the\ndata imbalance problem within imbalanced ECG datasets to improve the robustness\nand accuracy of heart disease detection. By using Optimal Transport, we augment\nthe ECG disease data from normal ECG beats to balance the data among different\ncategories. We build a Multi-Feature Transformer (MF-Transformer) as our\nclassification model, where different features are extracted from both time and\nfrequency domains to diagnose various heart conditions. Learning from 12-lead\nECG signals, our model is able to distinguish five categories of cardiac\nconditions. Our results demonstrate 1) the classification models' ability to\nmake competitive predictions on five ECG categories; 2) improvements in\naccuracy and robustness reflecting the effectiveness of our data augmentation\nmethod.",
    "descriptor": "",
    "authors": [
      "Jielin Qiu",
      "Jiacheng Zhu",
      "Michael Rosenberg",
      "Emerson Liu",
      "Ding Zhao"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.00567"
  },
  {
    "id": "arXiv:2202.00568",
    "title": "Stochastic 2D Signal Generative Model with Wavelet Packets Basis  Regarded as a Random Variable and Bayes Optimal Processing",
    "abstract": "This study deals with two-dimensional (2D) signal processing using the\nwavelet packet transform. When the basis is unknown the candidate of basis\nincreases in exponential order with respect to the signal size. Previous\nstudies do not consider the basis as a random vaiables. Therefore, the cost\nfunction needs to be used to select a basis. However, this method is often a\nheuristic and a greedy search because it is impossible to search all the\ncandidates for a huge number of bases. Therefore, it is difficult to evaluate\nthe entire signal processing under a criterion and also it does not always\ngurantee the optimality of the entire signal processing. In this study, we\npropose a stochastic generative model in which the basis is regarded as a\nrandom variable. This makes it possible to evaluate entire signal processing\nunder a unified criterion i.e. Bayes criterion. Moreover we can derive an\noptimal signal processing scheme that achieves the theoretical limit. This\nderived scheme shows that all the bases should be combined according to the\nposterior in stead of selecting a single basis. Although exponential order\ncalculations is required for this scheme, we have derived a recursive algorithm\nfor this scheme, which successfully reduces the computational complexity from\nthe exponential order to the polynomial order.",
    "descriptor": "",
    "authors": [
      "Ryohei Oka",
      "Yuta Nakahara",
      "Toshiyasu Matsushima"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.00568"
  },
  {
    "id": "arXiv:2202.00569",
    "title": "Arrhythmia Classification using CGAN-augmented ECG Signals",
    "abstract": "One of the easiest ways to diagnose cardiovascular conditions is\nElectrocardiogram (ECG) analysis. ECG databases usually have highly imbalanced\ndistributions due to the abundance of Normal ECG and scarcity of abnormal cases\nwhich are equally, if not more, important for arrhythmia detection. As such, DL\nclassifiers trained on these datasets usually perform poorly, especially on\nminor classes. One solution to address the imbalance is to generate realistic\nsynthetic ECG signals mostly using Generative Adversarial Networks (GAN) to\naugment and the datasets. In this study, we designed an experiment to\ninvestigate the impact of data augmentation on arrhythmia classification. Using\nthe MIT-BIH Arrhythmia dataset, we employed two ways for ECG beats generation:\n(i) an unconditional GAN, i.e., Wasserstein GAN with gradient penalty (WGAN-GP)\nis trained on each class individually; (ii) a conditional GAN model, i.e.,\nAuxiliary Classifier Wasserstein GAN with gradient penalty (AC-WGAN-GP) is\ntrained on all the available classes to train one single generator. Two\nscenarios are defined for each case: i) unscreened where all the generated\nsynthetic beats were used directly without any post-processing, and ii)\nscreened where a portion of generated beats are selected based on their Dynamic\nTime Warping (DTW) distance with a designated template. A ResNet classifier is\ntrained on each of the four augmented datasets and the performance metrics of\nprecision, recall and F1-Score as well as the confusion matrices were compared\nwith the reference case, i.e., when the classifier is trained on the imbalanced\noriginal dataset. The results show that in all four cases augmentation achieves\nimpressive improvements in metrics particularly on minor classes (typically\nfrom 0 or 0.27 to 0.99). The quality of the generated beats is also evaluated\nusing DTW distance function compared with real data.",
    "descriptor": "",
    "authors": [
      "Edmond Adib",
      "Fatemeh Afghah",
      "John J. Prevost"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.00569"
  },
  {
    "id": "arXiv:2202.00570",
    "title": "Closing the sim-to-real gap in guided wave damage detection with  adversarial training of variational auto-encoders",
    "abstract": "Guided wave testing is a popular approach for monitoring the structural\nintegrity of infrastructures. We focus on the primary task of damage detection,\nwhere signal processing techniques are commonly employed. The detection\nperformance is affected by a mismatch between the wave propagation model and\nexperimental wave data. External variations, such as temperature, which are\ndifficult to model, also affect the performance. While deep learning models can\nbe an alternative detection method, there is often a lack of real-world\ntraining datasets. In this work, we counter this challenge by training an\nensemble of variational autoencoders only on simulation data with a wave\nphysics-guided adversarial component. We set up an experiment with non-uniform\ntemperature variations to test the robustness of the methods. We compare our\nscheme with existing deep learning detection schemes and observe superior\nperformance on experimental data.",
    "descriptor": "\nComments: Accepted for presentation at IEEE ICASSP 2022. Copyright: 2022 IEEE\n",
    "authors": [
      "Ishan D. Khurjekar",
      "Joel B. Harley"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2202.00570"
  },
  {
    "id": "arXiv:2202.00574",
    "title": "Identifying Pauli spin blockade using deep learning",
    "abstract": "Pauli spin blockade (PSB) can be employed as a great resource for spin qubit\ninitialisation and readout even at elevated temperatures but it can be\ndifficult to identify. We present a machine learning algorithm capable of\nautomatically identifying PSB using charge transport measurements. The scarcity\nof PSB data is circumvented by training the algorithm with simulated data and\nby using cross-device validation. We demonstrate our approach on a silicon\nfield-effect transistor device and report an accuracy of 96% on different test\ndevices, giving evidence that the approach is robust to device variability. The\napproach is expected to be employable across all types of quantum dot devices.",
    "descriptor": "",
    "authors": [
      "Jonas Schuff",
      "Dominic T. Lennon",
      "Simon Geyer",
      "David L. Craig",
      "Federico Fedele",
      "Florian Vigneau",
      "Leon C. Camenzind",
      "Andreas V. Kuhlmann",
      "G. Andrew D. Briggs",
      "Dominik M. Zumb\u00fchl",
      "Dino Sejdinovic",
      "Natalia Ares"
    ],
    "subjectives": [
      "Mesoscale and Nanoscale Physics (cond-mat.mes-hall)",
      "Machine Learning (cs.LG)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2202.00574"
  },
  {
    "id": "arXiv:2202.00589",
    "title": "Blind ECG Restoration by Operational Cycle-GANs",
    "abstract": "Continuous long-term monitoring of electrocardiography (ECG) signals is\ncrucial for the early detection of cardiac abnormalities such as arrhythmia.\nNon-clinical ECG recordings acquired by Holter and wearable ECG sensors often\nsuffer from severe artifacts such as baseline wander, signal cuts, motion\nartifacts, variations on QRS amplitude, noise, and other interferences.\nUsually, a set of such artifacts occur on the same ECG signal with varying\nseverity and duration, and this makes an accurate diagnosis by machines or\nmedical doctors extremely difficult. Despite numerous studies that have\nattempted ECG denoising, they naturally fail to restore the actual ECG signal\ncorrupted with such artifacts due to their simple and naive noise model. In\nthis study, we propose a novel approach for blind ECG restoration using\ncycle-consistent generative adversarial networks (Cycle-GANs) where the quality\nof the signal can be improved to a clinical level ECG regardless of the type\nand severity of the artifacts corrupting the signal. To further boost the\nrestoration performance, we propose 1D operational Cycle-GANs with the\ngenerative neuron model. The proposed approach has been evaluated extensively\nusing one of the largest benchmark ECG datasets from the China Physiological\nSignal Challenge (CPSC-2020) with more than one million beats. Besides the\nquantitative and qualitative evaluations, a group of cardiologists performed\nmedical evaluations to validate the quality and usability of the restored ECG,\nespecially for an accurate arrhythmia diagnosis.",
    "descriptor": "\nComments: 16 pages, 10 figures, journal article submission\n",
    "authors": [
      "Serkan Kiranyaz",
      "Ozer Can Devecioglu",
      "Turker Ince",
      "Junaid Malik",
      "Muhammad Chowdhury",
      "Tahir Hamid",
      "Rashid Mazhar",
      "Amith Khandakar",
      "Anas Tahir",
      "Tawsifur Rahman",
      "Moncef Gabbouj"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.00589"
  },
  {
    "id": "arXiv:2202.00595",
    "title": "A least squares support vector regression for anisotropic diffusion  filtering",
    "abstract": "Anisotropic diffusion filtering for signal smoothing as a low-pass filter has\nthe advantage of the edge-preserving, i.e., it does not affect the edges that\ncontain more critical data than the other parts of the signal. In this paper,\nwe present a numerical algorithm based on least squares support vector\nregression by using Legendre orthogonal kernel with the discretization of the\nnonlinear diffusion problem in time by the Crank-Nicolson method. This method\ntransforms the signal smoothing process into solving an optimization problem\nthat can be solved by efficient numerical algorithms. In the final analysis, we\nhave reported some numerical experiments to show the effectiveness of the\nproposed machine learning based approach for signal smoothing.",
    "descriptor": "",
    "authors": [
      "Arsham Gholamzadeh Khoee",
      "Kimia Mohammadi Mohammadi",
      "Mostafa Jani",
      "Kourosh Parand"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.00595"
  },
  {
    "id": "arXiv:2202.00601",
    "title": "BEA-Base: A Benchmark for ASR of Spontaneous Hungarian",
    "abstract": "Hungarian is spoken by 15 million people, still, easily accessible Automatic\nSpeech Recognition (ASR) benchmark datasets - especially for spontaneous speech\n- have been practically unavailable. In this paper, we introduce BEA-Base, a\nsubset of the BEA spoken Hungarian database comprising mostly spontaneous\nspeech of 140 speakers. It is built specifically to assess ASR, primarily for\nconversational AI applications. After defining the speech recognition subsets\nand task, several baselines - including classic HMM-DNN hybrid and end-to-end\napproaches augmented by cross-language transfer learning - are developed using\nopen-source toolkits. The best results obtained are based on multilingual\nself-supervised pretraining, achieving a 45% recognition error rate reduction\nas compared to the classical approach - without the application of an external\nlanguage model or additional supervised data. The results show the feasibility\nof using BEA-Base for training and evaluation of Hungarian speech recognition\nsystems.",
    "descriptor": "\nComments: Submitted to LREC 2022\n",
    "authors": [
      "P. Mihajlik",
      "A. Balog",
      "T. E. Gr\u00e1czi",
      "A. Koh\u00e1ri",
      "B. Tarj\u00e1n",
      "K. M\u00e1dy"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2202.00601"
  },
  {
    "id": "arXiv:2202.00602",
    "title": "Meta-Learning Hypothesis Spaces for Sequential Decision-making",
    "abstract": "Obtaining reliable, adaptive confidence sets for prediction functions\n(hypotheses) is a central challenge in sequential decision-making tasks, such\nas bandits and model-based reinforcement learning. These confidence sets\ntypically rely on prior assumptions on the hypothesis space, e.g., the known\nkernel of a Reproducing Kernel Hilbert Space (RKHS). Hand-designing such\nkernels is error prone, and misspecification may lead to poor or unsafe\nperformance. In this work, we propose to meta-learn a kernel from offline data\n(Meta-KeL). For the case where the unknown kernel is a combination of known\nbase kernels, we develop an estimator based on structured sparsity. Under mild\nconditions, we guarantee that our estimated RKHS yields valid confidence sets\nthat, with increasing amounts of offline data, become as tight as those given\nthe true unknown kernel. We demonstrate our approach on the kernelized bandit\nproblem (a.k.a.~Bayesian optimization), where we establish regret bounds\ncompetitive with those given the true kernel. We also empirically evaluate the\neffectiveness of our approach on a Bayesian optimization task.",
    "descriptor": "\nComments: 21 pages, 9 figures\n",
    "authors": [
      "Parnian Kassraie",
      "Jonas Rothfuss",
      "Andreas Krause"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.00602"
  },
  {
    "id": "arXiv:2202.00606",
    "title": "Signal Quality Assessment of Photoplethysmogram Signals using Quantum  Pattern Recognition and lightweight CNN Architecture",
    "abstract": "Photoplethysmography (PPG) signal comprises physiological information related\nto cardiorespiratory health. However, while recording, these PPG signals are\neasily corrupted by motion artifacts and body movements, leading to noise\nenriched, poor quality signals. Therefore ensuring high-quality signals is\nnecessary to extract cardiorespiratory information accurately. Although there\nexists several rule-based and Machine-Learning (ML) - based approaches for PPG\nsignal quality estimation, those algorithms' efficacy is questionable. Thus,\nthis work proposes a lightweight CNN architecture for signal quality assessment\nemploying a novel Quantum pattern recognition (QPR) technique. The proposed\nalgorithm is validated on manually annotated data obtained from the University\nof Queensland database. A total of 28366, 5s signal segments are preprocessed\nand transformed into image files of 20 x 500 pixels. The image files are\ntreated as an input to the 2D CNN architecture. The developed model classifies\nthe PPG signal as `good' or `bad' with an accuracy of 98.3% with 99.3%\nsensitivity, 94.5% specificity and 98.9% F1-score. Finally, the performance of\nthe proposed framework is validated against the noisy `Welltory app' collected\nPPG database. Even in a noisy environment, the proposed architecture proved its\ncompetence. Experimental analysis concludes that a slim architecture along with\na novel Spatio-temporal pattern recognition technique improve the system's\nperformance. Hence, the proposed approach can be useful to classify good and\nbad PPG signals for a resource-constrained wearable implementation.",
    "descriptor": "\nComments: 7 pages, 6 figures, submitted to IEEE EMBC 2022\n",
    "authors": [
      "Tamaghno Chatterjee",
      "Aayushman Ghosh",
      "Sayan Sarkar"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.00606"
  },
  {
    "id": "arXiv:2202.00612",
    "title": "Similarity Learning based Few Shot Learning for ECG Time Series  Classification",
    "abstract": "Using deep learning models to classify time series data generated from the\nInternet of Things (IoT) devices requires a large amount of labeled data.\nHowever, due to constrained resources available in IoT devices, it is often\ndifficult to accommodate training using large data sets. This paper proposes\nand demonstrates a Similarity Learning-based Few Shot Learning for ECG\narrhythmia classification using Siamese Convolutional Neural Networks. Few shot\nlearning resolves the data scarcity issue by identifying novel classes from\nvery few labeled examples. Few Shot Learning relies first on pretraining the\nmodel on a related relatively large database, and then the learning is used for\nfurther adaptation towards few examples available per class. Our experiments\nevaluate the performance accuracy with respect to K (number of instances per\nclass) for ECG time series data classification. The accuracy with 5- shot\nlearning is 92.25% which marginally improves with further increase in K. We\nalso compare the performance of our method against other well-established\nsimilarity learning techniques such as Dynamic Time Warping (DTW), Euclidean\nDistance (ED), and a deep learning model - Long Short Term Memory Fully\nConvolutional Network (LSTM-FCN) with the same amount of data and conclude that\nour method outperforms them for a limited dataset size. For K=5, the accuracies\nobtained are 57%, 54%, 33%, and 92% approximately for ED, DTW, LSTM-FCN, and\nSCNN, respectively.",
    "descriptor": "\nComments: 7 pages, 4 figures. Published as part of the DICTA 2021 conference proceedings\n",
    "authors": [
      "Priyanka Gupta",
      "Sathvik Bhaskarpandit",
      "Manik Gupta"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.00612"
  },
  {
    "id": "arXiv:2202.00622",
    "title": "Datamodels: Predicting Predictions from Training Data",
    "abstract": "We present a conceptual framework, datamodeling, for analyzing the behavior\nof a model class in terms of the training data. For any fixed \"target\" example\n$x$, training set $S$, and learning algorithm, a datamodel is a parameterized\nfunction $2^S \\to \\mathbb{R}$ that for any subset of $S' \\subset S$ -- using\nonly information about which examples of $S$ are contained in $S'$ -- predicts\nthe outcome of training a model on $S'$ and evaluating on $x$. Despite the\npotential complexity of the underlying process being approximated (e.g.,\nend-to-end training and evaluation of deep neural networks), we show that even\nsimple linear datamodels can successfully predict model outputs. We then\ndemonstrate that datamodels give rise to a variety of applications, such as:\naccurately predicting the effect of dataset counterfactuals; identifying\nbrittle predictions; finding semantically similar examples; quantifying\ntrain-test leakage; and embedding data into a well-behaved and feature-rich\nrepresentation space. Data for this paper (including pre-computed datamodels as\nwell as raw predictions from four million trained deep neural networks) is\navailable at https://github.com/MadryLab/datamodels-data .",
    "descriptor": "",
    "authors": [
      "Andrew Ilyas",
      "Sung Min Park",
      "Logan Engstrom",
      "Guillaume Leclerc",
      "Aleksander Madry"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.00622"
  },
  {
    "id": "arXiv:2202.00625",
    "title": "Black-box Bayesian inference for economic agent-based models",
    "abstract": "Simulation models, in particular agent-based models, are gaining popularity\nin economics. The considerable flexibility they offer, as well as their\ncapacity to reproduce a variety of empirically observed behaviours of complex\nsystems, give them broad appeal, and the increasing availability of cheap\ncomputing power has made their use feasible. Yet a widespread adoption in\nreal-world modelling and decision-making scenarios has been hindered by the\ndifficulty of performing parameter estimation for such models. In general,\nsimulation models lack a tractable likelihood function, which precludes a\nstraightforward application of standard statistical inference techniques.\nSeveral recent works have sought to address this problem through the\napplication of likelihood-free inference techniques, in which parameter\nestimates are determined by performing some form of comparison between the\nobserved data and simulation output. However, these approaches are (a) founded\non restrictive assumptions, and/or (b) typically require many hundreds of\nthousands of simulations. These qualities make them unsuitable for large-scale\nsimulations in economics and can cast doubt on the validity of these inference\nmethods in such scenarios. In this paper, we investigate the efficacy of two\nclasses of black-box approximate Bayesian inference methods that have recently\ndrawn significant attention within the probabilistic machine learning\ncommunity: neural posterior estimation and neural density ratio estimation. We\npresent benchmarking experiments in which we demonstrate that neural network\nbased black-box methods provide state of the art parameter inference for\neconomic simulation models, and crucially are compatible with generic\nmultivariate time-series data. In addition, we suggest appropriate assessment\ncriteria for future benchmarking of approximate Bayesian inference procedures\nfor economic simulation models.",
    "descriptor": "",
    "authors": [
      "Joel Dyer",
      "Patrick Cannon",
      "J. Doyne Farmer",
      "Sebastian Schmon"
    ],
    "subjectives": [
      "Econometrics (econ.EM)",
      "Multiagent Systems (cs.MA)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.00625"
  },
  {
    "id": "arXiv:2202.00630",
    "title": "Covid-19 vaccine hesitancy and mega-influencers",
    "abstract": "Covid-19 vaccines are widely available in the United States, yet our Covid-19\nvaccination rates have remained far below 100%. Not only that, but CDC data\nshows that even in places where vaccine acceptance was proportionally high at\nthe outset of the Covid-19 vaccination effort, that willingness has not\nnecessarily translated into high rates of vaccination over the subsequent\nmonths. We model how such a shift could have arisen, using parameters in\nagreement with data from the state of Alabama. The simulations suggest that in\nAlabama, local interactions would have favored the emergence of tight consensus\naround the initial majority view, which was to accept the Covid-19 vaccine. Yet\nthis is not what happened. We therefore add to our model the impact of\nmega-influencers such as mass media, the governor of the state, etc. Our\nsimulations show that a single vaccine-hesitant mega-influencer, reaching a\nlarge fraction of the population, can indeed cause the consensus to shift\nradically, from acceptance to hesitancy. Surprisingly this is true even when\nthe mega-influencer only reaches individuals who are already somewhat inclined\nto agree with them, and under the conservative assumption that individuals give\nno more weight to the mega-influencer than they would give to a single one of\ntheir friends or neighbors. Our simulations also suggest that a competing\nmega-influencer with the opposite view can shift the mean population opinion\nback, but cannot restore the tightness of consensus around that view. Our code\nand data are distributed in the ODyN (Opinion Dynamic Networks) library\navailable at https://github.com/annahaensch/ODyN.",
    "descriptor": "",
    "authors": [
      "Anna Haensch",
      "Natasa Dragovic",
      "Christoph B\u00f6rgers",
      "Bruce Boghosian"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)",
      "Populations and Evolution (q-bio.PE)"
    ],
    "url": "https://arxiv.org/abs/2202.00630"
  },
  {
    "id": "arXiv:2202.00631",
    "title": "FiNCAT: Financial Numeral Claim Analysis Tool",
    "abstract": "While making investment decisions by reading financial documents, investors\nneed to differentiate between in-claim and outof-claim numerals. In this paper,\nwe present a tool which does it automatically. It extracts context embeddings\nof the numerals using one of the transformer based pre-trained language model\ncalled BERT. After this, it uses a Logistic Regression based model to detect\nwhether the numerals is in-claim or out-of-claim. We use FinNum-3 (English)\ndataset to train our model. After conducting rigorous experiments we achieve a\nMacro F1 score of 0.8223 on the validation set. We have open-sourced this tool\nand it can be accessed from\nhttps://github.com/sohomghosh/FiNCAT_Financial_Numeral_Claim_Analysis_Tool",
    "descriptor": "\nComments: 3 pages, 2 figures, 1 table\n",
    "authors": [
      "Sohom Ghosh",
      "Sudip Kumar Naskar"
    ],
    "subjectives": [
      "General Finance (q-fin.GN)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.00631"
  },
  {
    "id": "arXiv:2202.00648",
    "title": "Evidence for Super-Polynomial Advantage of QAOA over Unstructured Search",
    "abstract": "We compare the performance of several variations of the Quantum Alternating\nOperator Ansatz (QAOA) on constrained optimization problems. Specifically, we\nstudy the Clique, Ring, and Grover mixers as well as the traditional objective\nvalue and recently introduced threshold-based phase separators. These are\nstudied through numerical simulation on k-Densest Subgraph, Maximum k-Vertex\nCover, and Maximum Bisection problems of size up to n=18 on Erd\\\"os-Renyi\ngraphs. We show that only one of these QAOA variations, the Clique mixer with\nobjective value phase separator, outperforms Grover-style unstructured search,\nwith a potentially super-polynomial advantage.",
    "descriptor": "",
    "authors": [
      "John Golden",
      "Andreas B\u00e4rtschi",
      "Stephan Eidenbenz",
      "Daniel O'Malley"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2202.00648"
  },
  {
    "id": "arXiv:2202.00650",
    "title": "AI-based Medical e-Diagnosis for Fast and Automatic Ventricular Volume  Measurement in the Patients with Normal Pressure Hydrocephalus",
    "abstract": "Based on CT and MRI images acquired from normal pressure hydrocephalus (NPH)\npatients, using machine learning methods, we aim to establish a multi-modal and\nhigh-performance automatic ventricle segmentation method to achieve efficient\nand accurate automatic measurement of the ventricular volume. First, we extract\nthe brain CT and MRI images of 143 definite NPH patients. Second, we manually\nlabel the ventricular volume (VV) and intracranial volume (ICV). Then, we use\nmachine learning method to extract features and establish automatic ventricle\nsegmentation model. Finally, we verify the reliability of the model and\nachieved automatic measurement of VV and ICV. In CT images, the Dice similarity\ncoefficient (DSC), Intraclass Correlation Coefficient (ICC), Pearson\ncorrelation, and Bland-Altman analysis of the automatic and manual segmentation\nresult of the VV were 0.95, 0.99, 0.99, and 4.2$\\pm$2.6 respectively. The\nresults of ICV were 0.96, 0.99, 0.99, and 6.0$\\pm$3.8 respectively. The whole\nprocess takes 3.4$\\pm$0.3 seconds. In MRI images, the DSC, ICC, Pearson\ncorrelation, and Bland-Altman analysis of the automatic and manual segmentation\nresult of the VV were 0.94, 0.99, 0.99, and 2.0$\\pm$0.6 respectively. The\nresults of ICV were 0.93, 0.99, 0.99, and 7.9$\\pm$3.8 respectively. The whole\nprocess took 1.9$\\pm$0.1 seconds. We have established a multi-modal and\nhigh-performance automatic ventricle segmentation method to achieve efficient\nand accurate automatic measurement of the ventricular volume of NPH patients.\nThis can help clinicians quickly and accurately understand the situation of NPH\npatient's ventricles.",
    "descriptor": "\nComments: 26 pages, 4 figure, accepted by Neural Computing and Applications journal\n",
    "authors": [
      "Xi Zhou",
      "Qinghao Ye",
      "Xiaolin Yang",
      "Jiakuan Chen",
      "Haiqin Ma",
      "Jun Xia",
      "Javier Del Ser",
      "Guang Yang"
    ],
    "subjectives": [
      "Medical Physics (physics.med-ph)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.00650"
  },
  {
    "id": "arXiv:1301.0999",
    "title": "Transporting continuity properties from a poset to its subposets",
    "abstract": "Comments: 42 pages. Changes: updated Sections 4 and 8, many improvements",
    "descriptor": "\nComments: 42 pages. Changes: updated Sections 4 and 8, many improvements\n",
    "authors": [
      "Paul Poncet"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/1301.0999"
  },
  {
    "id": "arXiv:1506.05068",
    "title": "Extract an essential skeleton of a character as a graph from a character  image",
    "abstract": "Extract an essential skeleton of a character as a graph from a character  image",
    "descriptor": "",
    "authors": [
      "Kazuhisa Fujita"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/1506.05068"
  },
  {
    "id": "arXiv:1705.01240",
    "title": "Consistency of orthology and paralogy constraints in the presence of  gene transfers",
    "abstract": "Consistency of orthology and paralogy constraints in the presence of  gene transfers",
    "descriptor": "",
    "authors": [
      "Mark Jones",
      "Manuel Lafond",
      "Celine Scornavacca"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/1705.01240"
  },
  {
    "id": "arXiv:1707.05852",
    "title": "Double-Opportunity Estimation via Altruism",
    "abstract": "Comments: 20 pages, 5 figures. This is a revised version",
    "descriptor": "\nComments: 20 pages, 5 figures. This is a revised version\n",
    "authors": [
      "Nitai Stein",
      "Yaakov Oshman"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/1707.05852"
  },
  {
    "id": "arXiv:1811.03435",
    "title": "Data Science as Political Action: Grounding Data Science in a Politics  of Justice",
    "abstract": "Data Science as Political Action: Grounding Data Science in a Politics  of Justice",
    "descriptor": "",
    "authors": [
      "Ben Green"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/1811.03435"
  },
  {
    "id": "arXiv:1902.11186",
    "title": "Fault detection and diagnosis: computational issues and tools",
    "abstract": "Comments: 12 pages. A shorter version of this article appeared in the Encyclopedia of Systems and Control (2019)",
    "descriptor": "\nComments: 12 pages. A shorter version of this article appeared in the Encyclopedia of Systems and Control (2019)\n",
    "authors": [
      "Andreas Varga"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/1902.11186"
  },
  {
    "id": "arXiv:1907.06688",
    "title": "Matrices of optimal tree-depth and a row-invariant parameterized  algorithm for integer programming",
    "abstract": "Comments: Full version. 48 pages, 7 figures",
    "descriptor": "\nComments: Full version. 48 pages, 7 figures\n",
    "authors": [
      "Timothy F. N. Chan",
      "Jacob W. Cooper",
      "Martin Koutecky",
      "Daniel Kral",
      "Kristyna Pekarkova"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/1907.06688"
  },
  {
    "id": "arXiv:1910.07373",
    "title": "Iterative Augmentation of Visual Evidence for Weakly-Supervised Lesion  Localization in Deep Interpretability Frameworks: Application to Color Fundus  Images",
    "abstract": "Iterative Augmentation of Visual Evidence for Weakly-Supervised Lesion  Localization in Deep Interpretability Frameworks: Application to Color Fundus  Images",
    "descriptor": "",
    "authors": [
      "Cristina Gonz\u00e1lez-Gonzalo",
      "Bart Liefers",
      "Bram van Ginneken",
      "Clara I. S\u00e1nchez"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/1910.07373"
  },
  {
    "id": "arXiv:2001.02600",
    "title": "Deep Learning for Free-Hand Sketch: A Survey",
    "abstract": "Comments: This paper is accepted by IEEE TPAMI",
    "descriptor": "\nComments: This paper is accepted by IEEE TPAMI\n",
    "authors": [
      "Peng Xu",
      "Timothy M. Hospedales",
      "Qiyue Yin",
      "Yi-Zhe Song",
      "Tao Xiang",
      "Liang Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2001.02600"
  },
  {
    "id": "arXiv:2001.11825",
    "title": "Recursion, evolution and conscious self",
    "abstract": "Recursion, evolution and conscious self",
    "descriptor": "",
    "authors": [
      "A.D. Arvanitakis"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Machine Learning (cs.LG)",
      "Logic (math.LO)",
      "Neurons and Cognition (q-bio.NC)",
      "Populations and Evolution (q-bio.PE)"
    ],
    "url": "https://arxiv.org/abs/2001.11825"
  },
  {
    "id": "arXiv:2004.02020",
    "title": "Building secure distributed applications the DECENT way",
    "abstract": "Comments: 17 pages, 21 figures. V3: Added a section to introduce a distributed revoker design; Added details on Decent Handshake protocol; Revised the description on data sealing mechanism; Added a discussion of future research directions related to automatic component verification; Added and replaced 11 figures; V2: Added formal verification result for the protocols; clarified verifiers and revokers",
    "descriptor": "\nComments: 17 pages, 21 figures. V3: Added a section to introduce a distributed revoker design; Added details on Decent Handshake protocol; Revised the description on data sealing mechanism; Added a discussion of future research directions related to automatic component verification; Added and replaced 11 figures; V2: Added formal verification result for the protocols; clarified verifiers and revokers\n",
    "authors": [
      "Haofan Zheng",
      "Owen Arden"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2004.02020"
  },
  {
    "id": "arXiv:2004.04552",
    "title": "Interactions in information spread: quantification and interpretation  using stochastic block models",
    "abstract": "Comments: 17 pages, 3 figures, RecSys'21",
    "descriptor": "\nComments: 17 pages, 3 figures, RecSys'21\n",
    "authors": [
      "Ga\u00ebl Poux-M\u00e9dard",
      "Julien Velcin",
      "Sabine Loudcher"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2004.04552"
  },
  {
    "id": "arXiv:2005.09507",
    "title": "Decidability and k-Regular Sequences",
    "abstract": "Decidability and k-Regular Sequences",
    "descriptor": "",
    "authors": [
      "Daniel Krenn",
      "Jeffrey Shallit"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Computational Complexity (cs.CC)",
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2005.09507"
  },
  {
    "id": "arXiv:2006.13309",
    "title": "Ultra-fast Deep Mixtures of Gaussian Process Experts",
    "abstract": "Comments: 17 pages, 4 figures",
    "descriptor": "\nComments: 17 pages, 4 figures\n",
    "authors": [
      "Clement Etienam",
      "Kody Law",
      "Sara Wade",
      "Vitaly Zankin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.13309"
  },
  {
    "id": "arXiv:2007.13153",
    "title": "Rank-adaptive structure-preserving model order reduction of Hamiltonian  systems",
    "abstract": "Rank-adaptive structure-preserving model order reduction of Hamiltonian  systems",
    "descriptor": "",
    "authors": [
      "Jan S. Hesthaven",
      "Cecilia Pagliantini",
      "Nicol\u00f2 Ripamonti"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2007.13153"
  },
  {
    "id": "arXiv:2008.01627",
    "title": "SL1-Simplex: Safe Velocity Regulation of Self-Driving Vehicles in  Dynamic and Unforeseen Environments",
    "abstract": "Comments: Submitted to ACM Transactions on Cyber-Physical Systems",
    "descriptor": "\nComments: Submitted to ACM Transactions on Cyber-Physical Systems\n",
    "authors": [
      "Yanbing Mao",
      "Yuliang Gu",
      "Naira Hovakimyan",
      "Lui Sha",
      "Petros Voulgaris"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2008.01627"
  },
  {
    "id": "arXiv:2008.06971",
    "title": "Physical Action Categorization using Signal Analysis and Machine  Learning",
    "abstract": "Physical Action Categorization using Signal Analysis and Machine  Learning",
    "descriptor": "",
    "authors": [
      "Asad Mansoor Khan",
      "Ayesha Sadiq",
      "Sajid Gul Khawaja",
      "Norah Saleh Alghamdi",
      "Muhammad Usman Akram",
      "Ali Saeed"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2008.06971"
  },
  {
    "id": "arXiv:2008.13222",
    "title": "Improved Lite Audio-Visual Speech Enhancement",
    "abstract": "Improved Lite Audio-Visual Speech Enhancement",
    "descriptor": "",
    "authors": [
      "Shang-Yi Chuang",
      "Hsin-Min Wang",
      "Yu Tsao"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2008.13222"
  },
  {
    "id": "arXiv:2009.13065",
    "title": "Fixed Points Theorems for Non-Transitive Relations",
    "abstract": "Fixed Points Theorems for Non-Transitive Relations",
    "descriptor": "",
    "authors": [
      "J\u00e9r\u00e9my Dubut",
      "Akihisa Yamada"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2009.13065"
  },
  {
    "id": "arXiv:2009.13865",
    "title": "Quantum copy-protection of compute-and-compare programs in the quantum  random oracle model",
    "abstract": "Comments: 53 pages. Minor fixes and new section on multi-bit point functions",
    "descriptor": "\nComments: 53 pages. Minor fixes and new section on multi-bit point functions\n",
    "authors": [
      "Andrea Coladangelo",
      "Christian Majenz",
      "Alexander Poremba"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2009.13865"
  },
  {
    "id": "arXiv:2010.10242",
    "title": "Ulixes: Facial Recognition Privacy with Adversarial Machine Learning",
    "abstract": "Ulixes: Facial Recognition Privacy with Adversarial Machine Learning",
    "descriptor": "",
    "authors": [
      "Thomas Cilloni",
      "Wei Wang",
      "Charles Walter",
      "Charles Fleming"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2010.10242"
  },
  {
    "id": "arXiv:2010.14877",
    "title": "Hierarchical Gaussian Processes with Wasserstein-2 Kernels",
    "abstract": "Hierarchical Gaussian Processes with Wasserstein-2 Kernels",
    "descriptor": "",
    "authors": [
      "Sebastian Popescu",
      "David Sharp",
      "James Cole",
      "Ben Glocker"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2010.14877"
  },
  {
    "id": "arXiv:2010.15153",
    "title": "On the Optimality and Convergence Properties of the Iterative Learning  Model Predictive Controller",
    "abstract": "Comments: technical note",
    "descriptor": "\nComments: technical note\n",
    "authors": [
      "Ugo Rosolia",
      "Yingzhao Lian",
      "Emilio T. Maddalena",
      "Giancarlo Ferrari-Trecate",
      "Colin N. Jones"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2010.15153"
  },
  {
    "id": "arXiv:2012.04477",
    "title": "Analyzing Finite Neural Networks: Can We Trust Neural Tangent Kernel  Theory?",
    "abstract": "Analyzing Finite Neural Networks: Can We Trust Neural Tangent Kernel  Theory?",
    "descriptor": "",
    "authors": [
      "Mariia Seleznova",
      "Gitta Kutyniok"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2012.04477"
  },
  {
    "id": "arXiv:2012.08909",
    "title": "Maximum 0-1 Timed Matching on Temporal Graphs",
    "abstract": "Maximum 0-1 Timed Matching on Temporal Graphs",
    "descriptor": "",
    "authors": [
      "Subhrangsu Mandal",
      "Arobinda Gupta"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2012.08909"
  },
  {
    "id": "arXiv:2012.14521",
    "title": "Minoration via Mixed Volumes and Cover's Problem for General Channels",
    "abstract": "Comments: Some materials in Section 3 from the previous version are removed, replaced by appropriate references to [Pajor 1984] and [Mendelson, Milman, Paouris 2019]. The paper has been published online on Probability Theory and Related Fields",
    "descriptor": "\nComments: Some materials in Section 3 from the previous version are removed, replaced by appropriate references to [Pajor 1984] and [Mendelson, Milman, Paouris 2019]. The paper has been published online on Probability Theory and Related Fields\n",
    "authors": [
      "Jingbo Liu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Probability (math.PR)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2012.14521"
  },
  {
    "id": "arXiv:2012.15582",
    "title": "Isogeometric discretizations of the Stokes problem on trimmed geometries",
    "abstract": "Isogeometric discretizations of the Stokes problem on trimmed geometries",
    "descriptor": "",
    "authors": [
      "Riccardo Puppi"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2012.15582"
  },
  {
    "id": "arXiv:2101.08611",
    "title": "General Decidability Results for Asynchronous Shared-Memory Programs:  Higher-Order and Beyond",
    "abstract": "General Decidability Results for Asynchronous Shared-Memory Programs:  Higher-Order and Beyond",
    "descriptor": "",
    "authors": [
      "Rupak Majumdar",
      "Ramanathan S. Thinniyam",
      "Georg Zetzsche"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2101.08611"
  },
  {
    "id": "arXiv:2101.11796",
    "title": "DOC2PPT: Automatic Presentation Slides Generation from Scientific  Documents",
    "abstract": "Comments: AAAI'22",
    "descriptor": "\nComments: AAAI'22\n",
    "authors": [
      "Tsu-Jui Fu",
      "William Yang Wang",
      "Daniel McDuff",
      "Yale Song"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2101.11796"
  },
  {
    "id": "arXiv:2102.07876",
    "title": "Approximating viscosity solutions of the Euler system",
    "abstract": "Comments: 42 pages",
    "descriptor": "\nComments: 42 pages\n",
    "authors": [
      "Eduard Feireisl",
      "M\u00e1ria Luk\u00e1\u010dov\u00e1-Medvi\u010fov\u00e1",
      "Simon Schneider",
      "Bangwei She"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2102.07876"
  },
  {
    "id": "arXiv:2102.09030",
    "title": "Bringing Differential Private SGD to Practice: On the Independence of  Gaussian Noise and the Number of Training Rounds",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:2007.09208",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2007.09208\n",
    "authors": [
      "Marten van Dijk",
      "Nhuong V. Nguyen",
      "Toan N. Nguyen",
      "Lam M. Nguyen",
      "Phuong Ha Nguyen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2102.09030"
  },
  {
    "id": "arXiv:2102.09700",
    "title": "AI-SARAH: Adaptive and Implicit Stochastic Recursive Gradient Methods",
    "abstract": "AI-SARAH: Adaptive and Implicit Stochastic Recursive Gradient Methods",
    "descriptor": "",
    "authors": [
      "Zheng Shi",
      "Abdurakhmon Sadiev",
      "Nicolas Loizou",
      "Peter Richt\u00e1rik",
      "Martin Tak\u00e1\u010d"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2102.09700"
  },
  {
    "id": "arXiv:2102.10869",
    "title": "Introducing a Novel Data over Voice Technique for Secure Voice  Communication",
    "abstract": "Comments: 22 pages, 43 figures; submitted to Wireless Personal Communications, Springer on 17 Jul. 2020; initially accepted on 13 Apr. 2021; revised on 27 Apr. 2021; finally accepted on 6 Jan. 2022; published on 25 Jan. 2022; this work is supported by grant DGA Cifre-Defense program No 01D17022178 DGA/DS/MRIS and AID program No SED0456JE75",
    "descriptor": "\nComments: 22 pages, 43 figures; submitted to Wireless Personal Communications, Springer on 17 Jul. 2020; initially accepted on 13 Apr. 2021; revised on 27 Apr. 2021; finally accepted on 6 Jan. 2022; published on 25 Jan. 2022; this work is supported by grant DGA Cifre-Defense program No 01D17022178 DGA/DS/MRIS and AID program No SED0456JE75\n",
    "authors": [
      "Piotr Krasnowski",
      "Jerome Lebrun",
      "Bruno Martin"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2102.10869"
  },
  {
    "id": "arXiv:2103.12443",
    "title": "Deep KKL: Data-driven Output Prediction for Non-Linear Systems",
    "abstract": "Comments: Conference on Decision and Control (CDC 2021)",
    "descriptor": "\nComments: Conference on Decision and Control (CDC 2021)\n",
    "authors": [
      "Steeven Janny",
      "Vincent Andrieu",
      "Madiha Nadri",
      "Christian Wolf"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2103.12443"
  },
  {
    "id": "arXiv:2103.16523",
    "title": "Local output feedback stabilization of a Reaction-Diffusion equation  with saturated actuation",
    "abstract": "Comments: in press",
    "descriptor": "\nComments: in press\n",
    "authors": [
      "Hugo Lhachemi",
      "Christophe Prieur"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2103.16523"
  },
  {
    "id": "arXiv:2104.08245",
    "title": "Towards Electronic Structure-Based Ab-Initio Molecular Dynamics  Simulations with Hundreds of Millions of Atoms",
    "abstract": "Comments: 12 pages, 11 figures",
    "descriptor": "\nComments: 12 pages, 11 figures\n",
    "authors": [
      "Robert Schade",
      "Tobias Kenter",
      "Hossam Elgabarty",
      "Michael Lass",
      "Ole Sch\u00fctt",
      "Alfio Lazzaro",
      "Hans Pabst",
      "Stephan Mohr",
      "J\u00fcrg Hutter",
      "Thomas D. K\u00fchne",
      "Christian Plessl"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2104.08245"
  },
  {
    "id": "arXiv:2104.10003",
    "title": "An Exact Hypergraph Matching Algorithm for Nuclear Identification in  Embryonic Caenorhabditis elegans",
    "abstract": "Comments: 20 pages, 11 figures",
    "descriptor": "\nComments: 20 pages, 11 figures\n",
    "authors": [
      "Andrew Lauziere",
      "Ryan Christensen",
      "Hari Shroff",
      "Radu Balan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2104.10003"
  },
  {
    "id": "arXiv:2104.10127",
    "title": "Generative Transformer for Accurate and Reliable Salient Object  Detection",
    "abstract": "Comments: Technical report, 18 pages, 17 figures",
    "descriptor": "\nComments: Technical report, 18 pages, 17 figures\n",
    "authors": [
      "Yuxin Mao",
      "Jing Zhang",
      "Zhexiong Wan",
      "Yuchao Dai",
      "Aixuan Li",
      "Yunqiu Lv",
      "Xinyu Tian",
      "Deng-Ping Fan",
      "Nick Barnes"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2104.10127"
  },
  {
    "id": "arXiv:2104.13695",
    "title": "Information Interaction Profile of Choice Adoption",
    "abstract": "Comments: 18 pages, 4 figures",
    "descriptor": "\nComments: 18 pages, 4 figures\n",
    "authors": [
      "Ga\u00ebl Poux-M\u00e9dard",
      "Julien Velcin",
      "Sabine Loudcher"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Human-Computer Interaction (cs.HC)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2104.13695"
  },
  {
    "id": "arXiv:2104.13718",
    "title": "Graph Decoupling Attention Markov Networks for Semi-supervised Graph  Node Classification",
    "abstract": "Graph Decoupling Attention Markov Networks for Semi-supervised Graph  Node Classification",
    "descriptor": "",
    "authors": [
      "Jie Chen",
      "Shouzhen Chen",
      "Mingyuan Bai",
      "Jian Pu",
      "Junping Zhang",
      "Junbin Gao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2104.13718"
  },
  {
    "id": "arXiv:2105.00321",
    "title": "Regret and Cumulative Constraint Violation Analysis for Distributed  Online Constrained Convex Optimization",
    "abstract": "Regret and Cumulative Constraint Violation Analysis for Distributed  Online Constrained Convex Optimization",
    "descriptor": "",
    "authors": [
      "Xinlei Yi",
      "Xiuxian Li",
      "Tao Yang",
      "Lihua Xie",
      "Tianyou Chai",
      "Karl H. Johansson"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.00321"
  },
  {
    "id": "arXiv:2105.00794",
    "title": "Robust 3D Cell Segmentation: Extending the View of Cellpose",
    "abstract": "Robust 3D Cell Segmentation: Extending the View of Cellpose",
    "descriptor": "",
    "authors": [
      "Dennis Eschweiler",
      "Richard S. Smith",
      "Johannes Stegmaier"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.00794"
  },
  {
    "id": "arXiv:2105.08291",
    "title": "A Network Embedding Based Method for Cascade Prediction on Social  Networks",
    "abstract": "A Network Embedding Based Method for Cascade Prediction on Social  Networks",
    "descriptor": "",
    "authors": [
      "Wenjin Xie",
      "Xiaomeng Wang",
      "Tao Jia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2105.08291"
  },
  {
    "id": "arXiv:2105.08743",
    "title": "Coverage Path Planning for Spraying Drones",
    "abstract": "Comments: Submitted to Computers and Industrial Engineering",
    "descriptor": "\nComments: Submitted to Computers and Industrial Engineering\n",
    "authors": [
      "E. Viridiana Vazquez-Carmona",
      "Juan Irving Vasquez",
      "Juan Carlos Herrera Lozada",
      "Mayra Antonio-Cruz"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2105.08743"
  },
  {
    "id": "arXiv:2105.08832",
    "title": "A Contraction Theory Approach to Optimization Algorithms from  Acceleration Flows",
    "abstract": "A Contraction Theory Approach to Optimization Algorithms from  Acceleration Flows",
    "descriptor": "",
    "authors": [
      "Pedro Cisneros-Velarde",
      "Francesco Bullo"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2105.08832"
  },
  {
    "id": "arXiv:2105.10897",
    "title": "Asynchronous wreath product and cascade decompositions for concurrent  behaviours",
    "abstract": "Comments: The results in this paper are an elaboration and an extension of our CONCUR 2020 paper(doi={10.4230/LIPIcs.CONCUR.2020.19}, see this https URL ), and its extended version at arxiv:2007.07940 . It includes new significant technical results, simplified notations, and is a considerable improvement and reorganization of both",
    "descriptor": "\nComments: The results in this paper are an elaboration and an extension of our CONCUR 2020 paper(doi={10.4230/LIPIcs.CONCUR.2020.19}, see this https URL ), and its extended version at arxiv:2007.07940 . It includes new significant technical results, simplified notations, and is a considerable improvement and reorganization of both\n",
    "authors": [
      "Bharat Adsul",
      "Paul Gastin",
      "Saptarshi Sarkar",
      "Pascal Weil"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2105.10897"
  },
  {
    "id": "arXiv:2105.12152",
    "title": "Density estimation on low-dimensional manifolds: an inflation-deflation  approach",
    "abstract": "Density estimation on low-dimensional manifolds: an inflation-deflation  approach",
    "descriptor": "",
    "authors": [
      "Christian Horvat",
      "Jean-Pascal Pfister"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.12152"
  },
  {
    "id": "arXiv:2105.12842",
    "title": "A Full-Stack Search Technique for Domain Optimized Deep Learning  Accelerators",
    "abstract": "Comments: Fixed typo",
    "descriptor": "\nComments: Fixed typo\n",
    "authors": [
      "Dan Zhang",
      "Safeen Huda",
      "Ebrahim Songhori",
      "Kartik Prabhu",
      "Quoc Le",
      "Anna Goldie",
      "Azalia Mirhoseini"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Hardware Architecture (cs.AR)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2105.12842"
  },
  {
    "id": "arXiv:2106.00050",
    "title": "Continual 3D Convolutional Neural Networks for Real-time Processing of  Videos",
    "abstract": "Comments: 13 pages, 10 figures, 7 tables",
    "descriptor": "\nComments: 13 pages, 10 figures, 7 tables\n",
    "authors": [
      "Lukas Hedegaard",
      "Alexandros Iosifidis"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.00050"
  },
  {
    "id": "arXiv:2106.00477",
    "title": "Tight Accounting in the Shuffle Model of Differential Privacy",
    "abstract": "Comments: 21 pages, 5 figures",
    "descriptor": "\nComments: 21 pages, 5 figures\n",
    "authors": [
      "Antti Koskela",
      "Mikko A. Heikkil\u00e4",
      "Antti Honkela"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.00477"
  },
  {
    "id": "arXiv:2106.01680",
    "title": "Convergent Graph Solvers",
    "abstract": "Comments: 24 pages, 8 figures",
    "descriptor": "\nComments: 24 pages, 8 figures\n",
    "authors": [
      "Junyoung Park",
      "Jinhyun Choo",
      "Jinkyoo Park"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.01680"
  },
  {
    "id": "arXiv:2106.01784",
    "title": "The Contestation of Tech Ethics: A Sociotechnical Approach to Technology  Ethics in Practice",
    "abstract": "The Contestation of Tech Ethics: A Sociotechnical Approach to Technology  Ethics in Practice",
    "descriptor": "",
    "authors": [
      "Ben Green"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.01784"
  },
  {
    "id": "arXiv:2106.02584",
    "title": "Self-Attention Between Datapoints: Going Beyond Individual Input-Output  Pairs in Deep Learning",
    "abstract": "Comments: Accepted for publication at NeurIPS 2021. First two authors contributed equally",
    "descriptor": "\nComments: Accepted for publication at NeurIPS 2021. First two authors contributed equally\n",
    "authors": [
      "Jannik Kossen",
      "Neil Band",
      "Clare Lyle",
      "Aidan N. Gomez",
      "Tom Rainforth",
      "Yarin Gal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.02584"
  },
  {
    "id": "arXiv:2106.03157",
    "title": "Self-Supervision is All You Need for Solving Rubik's Cube",
    "abstract": "Comments: 7 pages, 6 figures. This update (v3) includes a comparison to existing methods, with slight modifications to theoretical explanation, paper structure, and visual representation. Newly added a demonstration with 15 puzzle in Appendix",
    "descriptor": "\nComments: 7 pages, 6 figures. This update (v3) includes a comparison to existing methods, with slight modifications to theoretical explanation, paper structure, and visual representation. Newly added a demonstration with 15 puzzle in Appendix\n",
    "authors": [
      "Kyo Takano"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.03157"
  },
  {
    "id": "arXiv:2106.03170",
    "title": "FlexParser -- the adaptive log file parser for continuous results in a  changing world",
    "abstract": "Comments: 17 pages, 9 figures, 3 tables",
    "descriptor": "\nComments: 17 pages, 9 figures, 3 tables\n",
    "authors": [
      "Nadine Ruecker",
      "Andreas Maier"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.03170"
  },
  {
    "id": "arXiv:2106.06313",
    "title": "Topology-Preserved Human Reconstruction with Details",
    "abstract": "Topology-Preserved Human Reconstruction with Details",
    "descriptor": "",
    "authors": [
      "Lixiang Lin",
      "Jianke Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.06313"
  },
  {
    "id": "arXiv:2106.06385",
    "title": "Deep Conditional Gaussian Mixture Model for Constrained Clustering",
    "abstract": "Deep Conditional Gaussian Mixture Model for Constrained Clustering",
    "descriptor": "",
    "authors": [
      "Laura Manduchi",
      "Kieran Chin-Cheong",
      "Holger Michel",
      "Sven Wellmann",
      "Julia E. Vogt"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.06385"
  },
  {
    "id": "arXiv:2106.06685",
    "title": "Adversarial Robustness via Fisher-Rao Regularization",
    "abstract": "Adversarial Robustness via Fisher-Rao Regularization",
    "descriptor": "",
    "authors": [
      "Marine Picot",
      "Francisco Messina",
      "Malik Boudiaf",
      "Fabrice Labeau",
      "Ismail Ben Ayed",
      "Pablo Piantanida"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.06685"
  },
  {
    "id": "arXiv:2106.07289",
    "title": "Decentralized Personalized Federated Min-Max Problems",
    "abstract": "Comments: New in v4: non-monotone analysis",
    "descriptor": "\nComments: New in v4: non-monotone analysis\n",
    "authors": [
      "Ekaterina Borodich",
      "Aleksandr Beznosikov",
      "Abdurakhmon Sadiev",
      "Vadim Sushko",
      "Nikolay Savelyev",
      "Martin Tak\u00e1\u010d",
      "Alexander Gasnikov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2106.07289"
  },
  {
    "id": "arXiv:2106.07831",
    "title": "Efficient Asynchronous Byzantine Agreement without Private Setups",
    "abstract": "Efficient Asynchronous Byzantine Agreement without Private Setups",
    "descriptor": "",
    "authors": [
      "Yingzi Gao",
      "Yuan Lu",
      "Zhenliang Lu",
      "Qiang Tang",
      "Jing Xu",
      "Zhenfeng Zhang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2106.07831"
  },
  {
    "id": "arXiv:2106.09920",
    "title": "Being Properly Improper",
    "abstract": "Comments: New theoretical and experimental results and new treatment",
    "descriptor": "\nComments: New theoretical and experimental results and new treatment\n",
    "authors": [
      "Tyler Sypherd",
      "Richard Nock",
      "Lalitha Sankar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2106.09920"
  },
  {
    "id": "arXiv:2106.11796",
    "title": "End-to-End Task-Oriented Dialog Modeling with Semi-Structured Knowledge  Management",
    "abstract": "Comments: IEEE/ACM TASLP, regular paper. arXiv admin note: text overlap with arXiv:2105.06041",
    "descriptor": "\nComments: IEEE/ACM TASLP, regular paper. arXiv admin note: text overlap with arXiv:2105.06041\n",
    "authors": [
      "Silin Gao",
      "Ryuichi Takanobu",
      "Antoine Bosselut",
      "Minlie Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.11796"
  },
  {
    "id": "arXiv:2106.15499",
    "title": "Self-Contrastive Learning: An Efficient Supervised Contrastive Framework  with Single-view and Sub-network",
    "abstract": "Self-Contrastive Learning: An Efficient Supervised Contrastive Framework  with Single-view and Sub-network",
    "descriptor": "",
    "authors": [
      "Sangmin Bae",
      "Sungnyun Kim",
      "Jongwoo Ko",
      "Gihun Lee",
      "Seungjong Noh",
      "Se-Young Yun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.15499"
  },
  {
    "id": "arXiv:2107.00243",
    "title": "Preconditioning for Scalable Gaussian Process Hyperparameter  Optimization",
    "abstract": "Preconditioning for Scalable Gaussian Process Hyperparameter  Optimization",
    "descriptor": "",
    "authors": [
      "Jonathan Wenger",
      "Geoff Pleiss",
      "Philipp Hennig",
      "John P. Cunningham",
      "Jacob R. Gardner"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2107.00243"
  },
  {
    "id": "arXiv:2107.07061",
    "title": "Distributed Dual Subgradient Methods with Averaging and Applications to  Grid Optimization",
    "abstract": "Distributed Dual Subgradient Methods with Averaging and Applications to  Grid Optimization",
    "descriptor": "",
    "authors": [
      "Subhonmesh Bose",
      "Hoa Dinh Nguyen",
      "Haitian Liu",
      "Ye Guo",
      "Thinh T. Doan",
      "Carolyn L. Beck"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2107.07061"
  },
  {
    "id": "arXiv:2107.07999",
    "title": "From block-Toeplitz matrices to differential equations on graphs:  towards a general theory for scalable masked Transformers",
    "abstract": "Comments: 20 pages, 11 figures",
    "descriptor": "\nComments: 20 pages, 11 figures\n",
    "authors": [
      "Krzysztof Choromanski",
      "Han Lin",
      "Haoxian Chen",
      "Tianyi Zhang",
      "Arijit Sehanobish",
      "Valerii Likhosherstov",
      "Jack Parker-Holder",
      "Tamas Sarlos",
      "Adrian Weller",
      "Thomas Weingarten"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.07999"
  },
  {
    "id": "arXiv:2107.10950",
    "title": "Pre-Clustering Point Clouds of Crop Fields Using Scalable Methods",
    "abstract": "Pre-Clustering Point Clouds of Crop Fields Using Scalable Methods",
    "descriptor": "",
    "authors": [
      "Henry J. Nelson",
      "Nikolaos Papanikolopoulos"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.10950"
  },
  {
    "id": "arXiv:2107.12824",
    "title": "A Low-Cost Neural ODE with Depthwise Separable Convolution for Edge  Domain Adaptation on FPGAs",
    "abstract": "A Low-Cost Neural ODE with Depthwise Separable Convolution for Edge  Domain Adaptation on FPGAs",
    "descriptor": "",
    "authors": [
      "Hiroki Kawakami",
      "Hirohisa Watanabe",
      "Keisuke Sugiura",
      "Hiroki Matsutani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2107.12824"
  },
  {
    "id": "arXiv:2107.13463",
    "title": "Learning the shape of female breasts: an open-access 3D statistical  shape model of the female breast built from 110 breast scans",
    "abstract": "Comments: 16 pages, 14 figures, accepted for publication in The Visual Computer",
    "descriptor": "\nComments: 16 pages, 14 figures, accepted for publication in The Visual Computer\n",
    "authors": [
      "Maximilian Weiherer",
      "Andreas Eigenberger",
      "Bernhard Egger",
      "Vanessa Br\u00e9bant",
      "Lukas Prantl",
      "Christoph Palm"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.13463"
  },
  {
    "id": "arXiv:2108.00925",
    "title": "Control Design of Dynamic Virtual Power Plants: An Adaptive  Divide-and-Conquer Approach",
    "abstract": "Comments: 13 pages, 16 figures",
    "descriptor": "\nComments: 13 pages, 16 figures\n",
    "authors": [
      "Verena H\u00e4berle",
      "Michael W. Fisher",
      "Eduardo Prieto-Araujo",
      "Florian D\u00f6rfler"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2108.00925"
  },
  {
    "id": "arXiv:2108.06084",
    "title": "Curriculum Learning: A Regularization Method for Efficient and Stable  Billion-Scale GPT Model Pre-Training",
    "abstract": "Curriculum Learning: A Regularization Method for Efficient and Stable  Billion-Scale GPT Model Pre-Training",
    "descriptor": "",
    "authors": [
      "Conglong Li",
      "Minjia Zhang",
      "Yuxiong He"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2108.06084"
  },
  {
    "id": "arXiv:2108.06655",
    "title": "Policy Evaluation and Temporal-Difference Learning in Continuous Time  and Space: A Martingale Approach",
    "abstract": "Comments: 58 pages, 12 figures",
    "descriptor": "\nComments: 58 pages, 12 figures\n",
    "authors": [
      "Yanwei Jia",
      "Xun Yu Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Mathematical Finance (q-fin.MF)"
    ],
    "url": "https://arxiv.org/abs/2108.06655"
  },
  {
    "id": "arXiv:2108.13643",
    "title": "Learning to Synthesize Programs as Interpretable and Generalizable  Policies",
    "abstract": "Comments: NeurIPS 2021. 53 pages, 16 figures, 12 tables. Website at this https URL",
    "descriptor": "\nComments: NeurIPS 2021. 53 pages, 16 figures, 12 tables. Website at this https URL\n",
    "authors": [
      "Dweep Trivedi",
      "Jesse Zhang",
      "Shao-Hua Sun",
      "Joseph J. Lim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2108.13643"
  },
  {
    "id": "arXiv:2108.13995",
    "title": "RealisticHands: A Hybrid Model for 3D Hand Reconstruction",
    "abstract": "Comments: International Conference on 3D Vision (3DV) 2021",
    "descriptor": "\nComments: International Conference on 3D Vision (3DV) 2021\n",
    "authors": [
      "Michael Seeber",
      "Roi Poranne",
      "Marc Polleyfeys",
      "Martin R. Oswald"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.13995"
  },
  {
    "id": "arXiv:2109.00919",
    "title": "Reiterative Domain Aware Multi-Target Adaptation",
    "abstract": "Reiterative Domain Aware Multi-Target Adaptation",
    "descriptor": "",
    "authors": [
      "Sudipan Saha",
      "Shan Zhao",
      "Nasrullah Sheikh",
      "Xiao Xiang Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.00919"
  },
  {
    "id": "arXiv:2109.03890",
    "title": "Model Explanations via the Axiomatic Causal Lens",
    "abstract": "Model Explanations via the Axiomatic Causal Lens",
    "descriptor": "",
    "authors": [
      "Gagan Biradar",
      "Vignesh Viswanathan",
      "Yair Zick"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.03890"
  },
  {
    "id": "arXiv:2109.05225",
    "title": "Space Meets Time: Local Spacetime Neural Network For Traffic Flow  Forecasting",
    "abstract": "Space Meets Time: Local Spacetime Neural Network For Traffic Flow  Forecasting",
    "descriptor": "",
    "authors": [
      "Song Yang",
      "Jiamou Liu",
      "Kaiqi Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2109.05225"
  },
  {
    "id": "arXiv:2109.05679",
    "title": "Reinforcement Learning for Load-balanced Parallel Particle Tracing",
    "abstract": "Comments: Accepted by IEEE Transactions on Visualization and Computer Graphics",
    "descriptor": "\nComments: Accepted by IEEE Transactions on Visualization and Computer Graphics\n",
    "authors": [
      "Jiayi Xu",
      "Hanqi Guo",
      "Han-Wei Shen",
      "Mukund Raj",
      "Skylar W. Wurster",
      "Tom Peterka"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.05679"
  },
  {
    "id": "arXiv:2109.05714",
    "title": "Vision-Aided Autonomous Navigation of Underactuated Bipedal Robots in  Height-Constrained Environments",
    "abstract": "Comments: submitted to International Journal of Robotics Research (IJRR)",
    "descriptor": "\nComments: submitted to International Journal of Robotics Research (IJRR)\n",
    "authors": [
      "Zhongyu Li",
      "Jun Zeng",
      "Shuxiao Chen",
      "Koushil Sreenath"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2109.05714"
  },
  {
    "id": "arXiv:2109.10252",
    "title": "Audiomer: A Convolutional Transformer For Keyword Spotting",
    "abstract": "Comments: The results and claims made are incorrect due to data leakage and an erroneous split of datasets",
    "descriptor": "\nComments: The results and claims made are incorrect due to data leakage and an erroneous split of datasets\n",
    "authors": [
      "Surya Kant Sahu",
      "Sai Mitheran",
      "Juhi Kamdar",
      "Meet Gandhi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2109.10252"
  },
  {
    "id": "arXiv:2109.10935",
    "title": "Robust Generalization of Quadratic Neural Networks via Function  Identification",
    "abstract": "Robust Generalization of Quadratic Neural Networks via Function  Identification",
    "descriptor": "",
    "authors": [
      "Kan Xu",
      "Hamsa Bastani",
      "Osbert Bastani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2109.10935"
  },
  {
    "id": "arXiv:2109.13132",
    "title": "Optimization Landscape of Gradient Descent for Discrete-time Static  Output Feedback",
    "abstract": "Optimization Landscape of Gradient Descent for Discrete-time Static  Output Feedback",
    "descriptor": "",
    "authors": [
      "Jingliang Duan",
      "Jie Li",
      "Lin Zhao"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2109.13132"
  },
  {
    "id": "arXiv:2109.14236",
    "title": "LightSecAgg: Rethinking Secure Aggregation in Federated Learning",
    "abstract": "LightSecAgg: Rethinking Secure Aggregation in Federated Learning",
    "descriptor": "",
    "authors": [
      "Jinhyun So",
      "Chaoyang He",
      "Chien-Sheng Yang",
      "Songze Li",
      "Qian Yu",
      "Ramy E. Ali",
      "Basak Guler",
      "Salman Avestimehr"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Information Theory (cs.IT)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2109.14236"
  },
  {
    "id": "arXiv:2109.15089",
    "title": "Biologically Plausible Training Mechanisms for Self-Supervised Learning  in Deep Networks",
    "abstract": "Comments: To be published in Frontiers in Computational Neuroscience",
    "descriptor": "\nComments: To be published in Frontiers in Computational Neuroscience\n",
    "authors": [
      "Mufeng Tang",
      "Yibo Yang",
      "Yali Amit"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2109.15089"
  },
  {
    "id": "arXiv:2110.00494",
    "title": "Probabilistic Robust Autoencoders for Anomaly Detection",
    "abstract": "Probabilistic Robust Autoencoders for Anomaly Detection",
    "descriptor": "",
    "authors": [
      "Yariv Aizenbud",
      "Ofir Lindenbaum",
      "Yuval Kluger"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.00494"
  },
  {
    "id": "arXiv:2110.01292",
    "title": "A Survey on Channel Estimation and Practical Passive Beamforming Design  for Intelligent Reflecting Surface Aided Wireless Communications",
    "abstract": "Comments: Accepted by IEEE Communications Surveys and Tutorials (76 pages, 17 figures, and 10 tables). In this paper, we provide a comprehensive survey on the up-to-date research in IRS-aided wireless communications, with an emphasis on the promising solutions to tackle practical design issues",
    "descriptor": "\nComments: Accepted by IEEE Communications Surveys and Tutorials (76 pages, 17 figures, and 10 tables). In this paper, we provide a comprehensive survey on the up-to-date research in IRS-aided wireless communications, with an emphasis on the promising solutions to tackle practical design issues\n",
    "authors": [
      "Beixiong Zheng",
      "Changsheng You",
      "Weidong Mei",
      "Rui Zhang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Emerging Technologies (cs.ET)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.01292"
  },
  {
    "id": "arXiv:2110.02281",
    "title": "A Rate Splitting Strategy for Uplink CR-NOMA Systems",
    "abstract": "Comments: 5 pages, 5 figures, submitted to IEEE Journal",
    "descriptor": "\nComments: 5 pages, 5 figures, submitted to IEEE Journal\n",
    "authors": [
      "Hongwu Liu",
      "Zhiquan Bai",
      "Hongjiang Lei",
      "Gaofeng Pan",
      "Kyeong Jin Kim",
      "Theodoros A. Tsiftsis"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2110.02281"
  },
  {
    "id": "arXiv:2110.02423",
    "title": "Geometric Transformers for Protein Interface Contact Prediction",
    "abstract": "Comments: 18 pages, 5 figures, and 9 tables. Camera-ready version for ICLR 2022",
    "descriptor": "\nComments: 18 pages, 5 figures, and 9 tables. Camera-ready version for ICLR 2022\n",
    "authors": [
      "Alex Morehead",
      "Chen Chen",
      "Jianlin Cheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Biomolecules (q-bio.BM)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2110.02423"
  },
  {
    "id": "arXiv:2110.02870",
    "title": "Capturing Structural Locality in Non-parametric Language Models",
    "abstract": "Comments: ICLR 2022",
    "descriptor": "\nComments: ICLR 2022\n",
    "authors": [
      "Frank F. Xu",
      "Junxian He",
      "Graham Neubig",
      "Vincent J. Hellendoorn"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2110.02870"
  },
  {
    "id": "arXiv:2110.03331",
    "title": "CLEVA-Compass: A Continual Learning EValuation Assessment Compass to  Promote Research Transparency and Comparability",
    "abstract": "Comments: International Conference on Learning Representations (ICLR) 2022",
    "descriptor": "\nComments: International Conference on Learning Representations (ICLR) 2022\n",
    "authors": [
      "Martin Mundt",
      "Steven Lang",
      "Quentin Delfosse",
      "Kristian Kersting"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.03331"
  },
  {
    "id": "arXiv:2110.03757",
    "title": "Predictive Maintenance for General Aviation Using Convolutional  Transformers",
    "abstract": "Comments: Accepted in IAAI-22 this https URL",
    "descriptor": "\nComments: Accepted in IAAI-22 this https URL\n",
    "authors": [
      "Hong Yang",
      "Aidan LaBella",
      "Travis Desell"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.03757"
  },
  {
    "id": "arXiv:2110.04629",
    "title": "The Neural Testbed: Evaluating Predictive Distributions",
    "abstract": "The Neural Testbed: Evaluating Predictive Distributions",
    "descriptor": "",
    "authors": [
      "Ian Osband",
      "Zheng Wen",
      "Seyed Mohammad Asghari",
      "Vikranth Dwaracherla",
      "Botao Hao",
      "Morteza Ibrahimi",
      "Dieterich Lawson",
      "Xiuyuan Lu",
      "Brendan O'Donoghue",
      "Benjamin Van Roy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.04629"
  },
  {
    "id": "arXiv:2110.04775",
    "title": "Estimating the confidence of speech spoofing countermeasure",
    "abstract": "Comments: Work in progress. Comments are welcome. Accepted by ICASSP2022. Code is available this https URL Not all the comments from anonymous reviewers can be addressed within 4 pages, apologize for that",
    "descriptor": "\nComments: Work in progress. Comments are welcome. Accepted by ICASSP2022. Code is available this https URL Not all the comments from anonymous reviewers can be addressed within 4 pages, apologize for that\n",
    "authors": [
      "Xin Wang",
      "Junichi Yamagishi"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Cryptography and Security (cs.CR)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2110.04775"
  },
  {
    "id": "arXiv:2110.04814",
    "title": "Finding Second-Order Stationary Point for Nonconvex-Strongly-Concave  Minimax Problem",
    "abstract": "Finding Second-Order Stationary Point for Nonconvex-Strongly-Concave  Minimax Problem",
    "descriptor": "",
    "authors": [
      "Luo Luo",
      "Yujun Li",
      "Cheng Chen"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.04814"
  },
  {
    "id": "arXiv:2110.05329",
    "title": "Addressing the Stability-Plasticity Dilemma via Knowledge-Aware  Continual Learning",
    "abstract": "Comments: Preprint",
    "descriptor": "\nComments: Preprint\n",
    "authors": [
      "Ghada Sokar",
      "Decebal Constantin Mocanu",
      "Mykola Pechenizkiy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.05329"
  },
  {
    "id": "arXiv:2110.05588",
    "title": "DeepFilterNet: A Low Complexity Speech Enhancement Framework for  Full-Band Audio based on Deep Filtering",
    "abstract": "Comments: Accepted to ICASSP 2022",
    "descriptor": "\nComments: Accepted to ICASSP 2022\n",
    "authors": [
      "Hendrik Schr\u00f6ter",
      "Alberto N. Escalante-B.",
      "Tobias Rosenkranz",
      "Andreas Maier"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.05588"
  },
  {
    "id": "arXiv:2110.06726",
    "title": "Scalable Anytime Algorithms for Learning Fragments of Linear Temporal  Logic",
    "abstract": "Scalable Anytime Algorithms for Learning Fragments of Linear Temporal  Logic",
    "descriptor": "",
    "authors": [
      "Ritam Raha",
      "Rajarshi Roy",
      "Nathana\u00ebl Fijalkow",
      "Daniel Neider"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Formal Languages and Automata Theory (cs.FL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.06726"
  },
  {
    "id": "arXiv:2110.06983",
    "title": "Bundle Networks: Fiber Bundles, Local Trivializations, and a Generative  Approach to Exploring Many-to-one Maps",
    "abstract": "Comments: Accepted for publication at ICLR 2022; 19 pages",
    "descriptor": "\nComments: Accepted for publication at ICLR 2022; 19 pages\n",
    "authors": [
      "Nico Courts",
      "Henry Kvinge"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Geometric Topology (math.GT)"
    ],
    "url": "https://arxiv.org/abs/2110.06983"
  },
  {
    "id": "arXiv:2110.07098",
    "title": "Finding Local Minimax Points via (Stochastic) Cubic-Regularized GDA:  Global Convergence and Complexity",
    "abstract": "Comments: 23 pages, no figures. arXiv admin note: text overlap with arXiv:2102.04653. The original title is \"Escaping Saddle Points in Nonconvex Minimax Optimization via Cubic-Regularized Gradient Descent-Ascent\"",
    "descriptor": "\nComments: 23 pages, no figures. arXiv admin note: text overlap with arXiv:2102.04653. The original title is \"Escaping Saddle Points in Nonconvex Minimax Optimization via Cubic-Regularized Gradient Descent-Ascent\"\n",
    "authors": [
      "Ziyi Chen",
      "Qunwei Li",
      "Yi Zhou"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.07098"
  },
  {
    "id": "arXiv:2110.07317",
    "title": "ReGVD: Revisiting Graph Neural Networks for Vulnerability Detection",
    "abstract": "Comments: Accepted to ICSE 2022 (Demonstrations). The first two authors contributed equally to this work",
    "descriptor": "\nComments: Accepted to ICSE 2022 (Demonstrations). The first two authors contributed equally to this work\n",
    "authors": [
      "Van-Anh Nguyen",
      "Dai Quoc Nguyen",
      "Van Nguyen",
      "Trung Le",
      "Quan Hung Tran",
      "Dinh Phung"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.07317"
  },
  {
    "id": "arXiv:2110.08340",
    "title": "Return migration of German-affiliated researchers: Analyzing departure  and return by gender, cohort, and discipline using Scopus bibliometric data  1996-2020",
    "abstract": "Comments: 27 pages, 6 figures, 1 table",
    "descriptor": "\nComments: 27 pages, 6 figures, 1 table\n",
    "authors": [
      "Xinyi Zhao",
      "Samin Aref",
      "Emilio Zagheni",
      "Guy Stecklov"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.08340"
  },
  {
    "id": "arXiv:2110.08741",
    "title": "Minimal Conditions for Beneficial Local Search",
    "abstract": "Comments: 36 pages plus 19 pages of appendix",
    "descriptor": "\nComments: 36 pages plus 19 pages of appendix\n",
    "authors": [
      "Mark G Wallace"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2110.08741"
  },
  {
    "id": "arXiv:2110.09170",
    "title": "Continuation of Famous Art with AI: A Conditional Adversarial Network  Inpainting Approach",
    "abstract": "Continuation of Famous Art with AI: A Conditional Adversarial Network  Inpainting Approach",
    "descriptor": "",
    "authors": [
      "Jordan J. Bird"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2110.09170"
  },
  {
    "id": "arXiv:2110.11446",
    "title": "ML with HE: Privacy Preserving Machine Learning Inferences for Genome  Studies",
    "abstract": "ML with HE: Privacy Preserving Machine Learning Inferences for Genome  Studies",
    "descriptor": "",
    "authors": [
      "\u015e. S. Ma\u011fara",
      "C. Y\u0131ld\u0131r\u0131m",
      "F. Yaman",
      "B. Dileko\u011flu",
      "F. R. Tuta\u015f",
      "E. \u00d6zt\u00fcrk",
      "K. Kaya",
      "\u00d6. Ta\u015ftan",
      "E. Sava\u015f"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Genomics (q-bio.GN)"
    ],
    "url": "https://arxiv.org/abs/2110.11446"
  },
  {
    "id": "arXiv:2110.11526",
    "title": "Wide Neural Networks Forget Less Catastrophically",
    "abstract": "Comments: preprint",
    "descriptor": "\nComments: preprint\n",
    "authors": [
      "Seyed Iman Mirzadeh",
      "Arslan Chaudhry",
      "Dong Yin",
      "Huiyi Hu",
      "Razvan Pascanu",
      "Dilan Gorur",
      "Mehrdad Farajtabar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.11526"
  },
  {
    "id": "arXiv:2110.11772",
    "title": "Grounding force-directed network layouts with latent space models",
    "abstract": "Grounding force-directed network layouts with latent space models",
    "descriptor": "",
    "authors": [
      "Felix Gaisbauer",
      "Armin Pournaki",
      "Sven Banisch",
      "Eckehard Olbrich"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2110.11772"
  },
  {
    "id": "arXiv:2110.12690",
    "title": "A Dynamical System Perspective for Lipschitz Neural Networks",
    "abstract": "A Dynamical System Perspective for Lipschitz Neural Networks",
    "descriptor": "",
    "authors": [
      "Laurent Meunier",
      "Blaise Delattre",
      "Alexandre Araujo",
      "Alexandre Allauzen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.12690"
  },
  {
    "id": "arXiv:2110.12879",
    "title": "Information efficient learning of complexly structured preferences:  Elicitation procedures and their application to decision making under  uncertainty",
    "abstract": "Information efficient learning of complexly structured preferences:  Elicitation procedures and their application to decision making under  uncertainty",
    "descriptor": "",
    "authors": [
      "Christoph Jansen",
      "Hannah Blocher",
      "Thomas Augustin",
      "Georg Schollmeyer"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2110.12879"
  },
  {
    "id": "arXiv:2110.13799",
    "title": "Hinge Policy Optimization: Rethinking Policy Improvement and  Reinterpreting PPO",
    "abstract": "Comments: 25 pages, 3 figures",
    "descriptor": "\nComments: 25 pages, 3 figures\n",
    "authors": [
      "Hsuan-Yu Yao",
      "Ping-Chun Hsieh",
      "Kuo-Hao Ho",
      "Kai-Chun Hu",
      "Liang-Chun Ouyang",
      "I-Chen Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.13799"
  },
  {
    "id": "arXiv:2111.00328",
    "title": "Multi-Task Learning based Convolutional Models with Curriculum Learning  for the Anisotropic Reynolds Stress Tensor in Turbulent Duct Flow",
    "abstract": "Multi-Task Learning based Convolutional Models with Curriculum Learning  for the Anisotropic Reynolds Stress Tensor in Turbulent Duct Flow",
    "descriptor": "",
    "authors": [
      "Haitz S\u00e1ez de Oc\u00e1riz Borde",
      "David Sondak",
      "Pavlos Protopapas"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.00328"
  },
  {
    "id": "arXiv:2111.02275",
    "title": "Causal-BALD: Deep Bayesian Active Learning of Outcomes to Infer  Treatment-Effects from Observational Data",
    "abstract": "Comments: 24 pages, 8 Figures, 5 tables, NeurIPS 2021",
    "descriptor": "\nComments: 24 pages, 8 Figures, 5 tables, NeurIPS 2021\n",
    "authors": [
      "Andrew Jesson",
      "Panagiotis Tigas",
      "Joost van Amersfoort",
      "Andreas Kirsch",
      "Uri Shalit",
      "Yarin Gal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.02275"
  },
  {
    "id": "arXiv:2111.02708",
    "title": "Quasi-Newton Methods for Saddle Point Problems and Beyond",
    "abstract": "Quasi-Newton Methods for Saddle Point Problems and Beyond",
    "descriptor": "",
    "authors": [
      "Chengchang Liu",
      "Luo Luo"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.02708"
  },
  {
    "id": "arXiv:2111.03664",
    "title": "Oracle Teacher: Towards Better Knowledge Distillation",
    "abstract": "Comments: Under review",
    "descriptor": "\nComments: Under review\n",
    "authors": [
      "Ji Won Yoon",
      "Hyung Yong Kim",
      "Hyeonseung Lee",
      "Sunghwan Ahn",
      "Nam Soo Kim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2111.03664"
  },
  {
    "id": "arXiv:2111.04096",
    "title": "Online Mutual Adaptation of Deep Depth Prediction and Visual SLAM",
    "abstract": "Comments: 11 pages, 6 figures",
    "descriptor": "\nComments: 11 pages, 6 figures\n",
    "authors": [
      "Shing Yan Loo",
      "Moein Shakeri",
      "Sai Hong Tang",
      "Syamsiah Mashohor",
      "Hong Zhang"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.04096"
  },
  {
    "id": "arXiv:2111.04357",
    "title": "Can semi-supervised learning reduce the amount of manual labelling  required for effective radio galaxy morphology classification?",
    "abstract": "Comments: Accepted in: Fourth Workshop on Machine Learning and the Physical Sciences (35th Conference on Neural Information Processing Systems; NeurIPS2021); final version",
    "descriptor": "\nComments: Accepted in: Fourth Workshop on Machine Learning and the Physical Sciences (35th Conference on Neural Information Processing Systems; NeurIPS2021); final version\n",
    "authors": [
      "Inigo V. Slijepcevic",
      "Anna M. M. Scaife"
    ],
    "subjectives": [
      "Astrophysics of Galaxies (astro-ph.GA)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.04357"
  },
  {
    "id": "arXiv:2111.04809",
    "title": "Absence of zeros implies strong spatial mixing",
    "abstract": "Comments: v3: An unfortunate typo in the statement of Theorem 2 has been fixed",
    "descriptor": "\nComments: v3: An unfortunate typo in the statement of Theorem 2 has been fixed\n",
    "authors": [
      "Guus Regts"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2111.04809"
  },
  {
    "id": "arXiv:2112.00847",
    "title": "CLAWS: Contrastive Learning with hard Attention and Weak Supervision",
    "abstract": "CLAWS: Contrastive Learning with hard Attention and Weak Supervision",
    "descriptor": "",
    "authors": [
      "Jansel Herrera-Gerena",
      "Ramakrishnan Sundareswaran",
      "John Just",
      "Matthew Darr",
      "Ali Jannesari"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.00847"
  },
  {
    "id": "arXiv:2112.03534",
    "title": "Deep Surrogate Assisted MAP-Elites for Automated Hearthstone  Deckbuilding",
    "abstract": "Deep Surrogate Assisted MAP-Elites for Automated Hearthstone  Deckbuilding",
    "descriptor": "",
    "authors": [
      "Yulun Zhang",
      "Matthew C. Fontaine",
      "Amy K. Hoover",
      "Stefanos Nikolaidis"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2112.03534"
  },
  {
    "id": "arXiv:2112.03609",
    "title": "Predict and Optimize: Through the Lens of Learning to Rank",
    "abstract": "Comments: Working paper",
    "descriptor": "\nComments: Working paper\n",
    "authors": [
      "Jayanta Mandi",
      "V\u00edctor Bucarey",
      "Maxime Mulamba",
      "Tias Guns"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.03609"
  },
  {
    "id": "arXiv:2112.04939",
    "title": "A Training Framework for Stereo-Aware Speech Enhancement using Deep  Neural Networks",
    "abstract": "Comments: Accepted to the IEEE 47th International Conference on Acoustics, Speech, and Signal Processing (ICASSP)",
    "descriptor": "\nComments: Accepted to the IEEE 47th International Conference on Acoustics, Speech, and Signal Processing (ICASSP)\n",
    "authors": [
      "Bahareh Tolooshams",
      "Kazuhito Koishida"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2112.04939"
  },
  {
    "id": "arXiv:2112.06300",
    "title": "Scalable and Conservative Continuous Collision Detection for GPU",
    "abstract": "Scalable and Conservative Continuous Collision Detection for GPU",
    "descriptor": "",
    "authors": [
      "David Belgrod",
      "Bolun Wang",
      "Zachary Ferguson",
      "Marco Attene",
      "Daniele Panozzo",
      "Teseo Schneider"
    ],
    "subjectives": [
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2112.06300"
  },
  {
    "id": "arXiv:2112.09202",
    "title": "3D-TSV: The 3D Trajectory-based Stress Visualizer",
    "abstract": "Comments: 13 pages",
    "descriptor": "\nComments: 13 pages\n",
    "authors": [
      "Junpeng Wang",
      "Christoph Neuhauser",
      "Jun Wu",
      "Xifeng Gao",
      "R\u00fcdiger Westermann"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2112.09202"
  },
  {
    "id": "arXiv:2112.09654",
    "title": "FastSurferVINN: Building Resolution-Independence into Deep Learning  Segmentation Methods -- A Solution for HighRes Brain MRI",
    "abstract": "Comments: accepted at NeuroImage",
    "descriptor": "\nComments: accepted at NeuroImage\n",
    "authors": [
      "Leonie Henschel",
      "David K\u00fcgler",
      "Martin Reuter"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.09654"
  },
  {
    "id": "arXiv:2112.10699",
    "title": "Mind-proofing Your Phone: Navigating the Digital Minefield with  GreaseTerminator",
    "abstract": "Comments: Accepted in ACM IUI 2022",
    "descriptor": "\nComments: Accepted in ACM IUI 2022\n",
    "authors": [
      "Siddhartha Datta",
      "Konrad Kollnig",
      "Nigel Shadbolt"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.10699"
  },
  {
    "id": "arXiv:2112.11325",
    "title": "iSegFormer: Interactive Image Segmentation with Transformers",
    "abstract": "iSegFormer: Interactive Image Segmentation with Transformers",
    "descriptor": "",
    "authors": [
      "Qin Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.11325"
  },
  {
    "id": "arXiv:2112.13650",
    "title": "Multiagent Transition Systems: Protocol-Stack Mathematics for  Distributed Computing",
    "abstract": "Multiagent Transition Systems: Protocol-Stack Mathematics for  Distributed Computing",
    "descriptor": "",
    "authors": [
      "Ehud Shapiro"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Formal Languages and Automata Theory (cs.FL)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2112.13650"
  },
  {
    "id": "arXiv:2112.13744",
    "title": "Improving the Performance of Backward Chained Behavior Trees using  Reinforcement Learning",
    "abstract": "Improving the Performance of Backward Chained Behavior Trees using  Reinforcement Learning",
    "descriptor": "",
    "authors": [
      "Mart Karta\u0161ev",
      "Justin Saler",
      "Petter \u00d6gren"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.13744"
  },
  {
    "id": "arXiv:2112.14531",
    "title": "Designing the Topology of Graph Neural Networks: A Novel Feature Fusion  Perspective",
    "abstract": "Designing the Topology of Graph Neural Networks: A Novel Feature Fusion  Perspective",
    "descriptor": "",
    "authors": [
      "Lanning Wei",
      "Huan Zhao",
      "Zhiqiang He"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.14531"
  },
  {
    "id": "arXiv:2112.15360",
    "title": "Making AI 'Smart': Bridging AI and Cognitive Science",
    "abstract": "Making AI 'Smart': Bridging AI and Cognitive Science",
    "descriptor": "",
    "authors": [
      "Madhav Agarwal",
      "Siddhant Bansal"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.15360"
  },
  {
    "id": "arXiv:2201.04098",
    "title": "Creation of a Modular Soft Robotic Fish Testing Platform",
    "abstract": "Comments: Video supplement at this https URL",
    "descriptor": "\nComments: Video supplement at this https URL\n",
    "authors": [
      "Yu Zhang",
      "Robert K. Katzschmann"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2201.04098"
  },
  {
    "id": "arXiv:2201.05610",
    "title": "When less is more: Simplifying inputs aids neural network understanding",
    "abstract": "When less is more: Simplifying inputs aids neural network understanding",
    "descriptor": "",
    "authors": [
      "Robin Tibor Schirrmeister",
      "Rosanne Liu",
      "Sara Hooker",
      "Tonio Ball"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.05610"
  },
  {
    "id": "arXiv:2201.06083",
    "title": "An Analytical Latency Model and Evaluation of the Capacity of 5G NR to  Support V2X Services using V2N2V Communications",
    "abstract": "Comments: 14 pages, 15 figures, 2 tables",
    "descriptor": "\nComments: 14 pages, 15 figures, 2 tables\n",
    "authors": [
      "M.C. Lucas-Esta\u00f1",
      "B. Coll-Perales",
      "T. Shimizu",
      "J. Gozalvez",
      "T. Higuchi",
      "S. Avedisov",
      "O. Altintas",
      "M. Sepulcre"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2201.06083"
  },
  {
    "id": "arXiv:2201.07284",
    "title": "TranAD: Deep Transformer Networks for Anomaly Detection in Multivariate  Time Series Data",
    "abstract": "Comments: Accepted in VLDB 2022",
    "descriptor": "\nComments: Accepted in VLDB 2022\n",
    "authors": [
      "Shreshth Tuli",
      "Giuliano Casale",
      "Nicholas R. Jennings"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.07284"
  },
  {
    "id": "arXiv:2201.07391",
    "title": "TAFA: Task-Agnostic Model Fingerprinting for Deep Neural Networks",
    "abstract": "Comments: Work in Progress; Updated on the technical parts",
    "descriptor": "\nComments: Work in Progress; Updated on the technical parts\n",
    "authors": [
      "Xudong Pan",
      "Mi Zhang",
      "Yifan Lu",
      "Yifan Yan",
      "Min Yang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2201.07391"
  },
  {
    "id": "arXiv:2201.08802",
    "title": "Deconfounding to Explanation Evaluation in Graph Neural Networks",
    "abstract": "Comments: 18 pages",
    "descriptor": "\nComments: 18 pages\n",
    "authors": [
      "Ying-Xin Wu",
      "Xiang Wang",
      "An Zhang",
      "Xia Hu",
      "Fuli Feng",
      "Xiangnan He",
      "Tat-Seng Chua"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.08802"
  },
  {
    "id": "arXiv:2201.09702",
    "title": "Correlated Equilibria and Fairness in Concurrent Stochastic Games",
    "abstract": "Correlated Equilibria and Fairness in Concurrent Stochastic Games",
    "descriptor": "",
    "authors": [
      "Marta Kwiatkowska",
      "Gethin Norman",
      "David Parker",
      "Gabriel Santos"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2201.09702"
  },
  {
    "id": "arXiv:2201.09751",
    "title": "Adversarial Classification under Gaussian Mechanism: Calibrating the  Attack to Sensitivity",
    "abstract": "Adversarial Classification under Gaussian Mechanism: Calibrating the  Attack to Sensitivity",
    "descriptor": "",
    "authors": [
      "Ayse Unsal",
      "Melek Onen"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2201.09751"
  },
  {
    "id": "arXiv:2201.10022",
    "title": "Affine Body Dynamics: Fast, Stable & Intersection-free Simulation of  Stiff Materials",
    "abstract": "Affine Body Dynamics: Fast, Stable & Intersection-free Simulation of  Stiff Materials",
    "descriptor": "",
    "authors": [
      "Lei Lan",
      "Danny M. Kaufman",
      "Minchen Li",
      "Chenfanfu Jiang",
      "Yin Yang"
    ],
    "subjectives": [
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2201.10022"
  },
  {
    "id": "arXiv:2201.10082",
    "title": "Polar Coded Computing: The Role of the Scaling Exponent",
    "abstract": "Polar Coded Computing: The Role of the Scaling Exponent",
    "descriptor": "",
    "authors": [
      "Dorsa Fathollahi",
      "Marco Mondelli"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2201.10082"
  },
  {
    "id": "arXiv:2201.10936",
    "title": "FIGARO: Generating Symbolic Music with Fine-Grained Artistic Control",
    "abstract": "Comments: 14 pages, 9 figures",
    "descriptor": "\nComments: 14 pages, 9 figures\n",
    "authors": [
      "Dimitri von R\u00fctte",
      "Luca Biggio",
      "Yannic Kilcher",
      "Thomas Hofmann"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2201.10936"
  },
  {
    "id": "arXiv:2201.11115",
    "title": "CsFEVER and CTKFacts: Czech Datasets for Fact Verification",
    "abstract": "Comments: submitted to LREV journal for review",
    "descriptor": "\nComments: submitted to LREV journal for review\n",
    "authors": [
      "Jan Drchal",
      "Herbert Ullrich",
      "Martin R\u00fdpar",
      "Hana Vincourov\u00e1",
      "V\u00e1clav Moravec"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.11115"
  },
  {
    "id": "arXiv:2201.11195",
    "title": "Explaining Preferences by Multiple Patterns in Voters' Behavior",
    "abstract": "Comments: The previous version claimed that prior to our work 2-Voter Partition for single-peaked preferences was open. In fact, as we learned after posting the previous version, this problem was resolved by Yang(ECAI'20, extended abstract in AAMAS'18) using a technique that was very similar to ours. The current version fixes this attribution error",
    "descriptor": "\nComments: The previous version claimed that prior to our work 2-Voter Partition for single-peaked preferences was open. In fact, as we learned after posting the previous version, this problem was resolved by Yang(ECAI'20, extended abstract in AAMAS'18) using a technique that was very similar to ours. The current version fixes this attribution error\n",
    "authors": [
      "Sonja Kraiczy",
      "Edith Elkind"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2201.11195"
  },
  {
    "id": "arXiv:2201.11643",
    "title": "From the Ravine method to the Nesterov method and vice versa: a  dynamical system perspective",
    "abstract": "From the Ravine method to the Nesterov method and vice versa: a  dynamical system perspective",
    "descriptor": "",
    "authors": [
      "H. Attouch",
      "J. Fadili"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2201.11643"
  },
  {
    "id": "arXiv:2201.12231",
    "title": "Overcoming Exploration: Deep Reinforcement Learning in Complex  Environments from Temporal Logic Specifications",
    "abstract": "Overcoming Exploration: Deep Reinforcement Learning in Complex  Environments from Temporal Logic Specifications",
    "descriptor": "",
    "authors": [
      "Mingyu Cai",
      "Erfan Aasi",
      "Calin Belta",
      "Cristian-Ioan Vasile"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.12231"
  },
  {
    "id": "arXiv:2201.12266",
    "title": "Six Questions about 6G",
    "abstract": "Comments: 6 pages, 3 figures, document also available in German, document available in a more attractive format, here: www.thinknet-6g.de",
    "descriptor": "\nComments: 6 pages, 3 figures, document also available in German, document available in a more attractive format, here: www.thinknet-6g.de\n",
    "authors": [
      "Kimberley Parsons Trommler",
      "Matthias Hafner",
      "Prof. Dr. Wolfgang Kellerer",
      "Peter Merz",
      "Sigurd Schuster",
      "Josef Urban",
      "Uwe Baeder",
      "Dr. Bertram Gunzelmann",
      "Andreas Kornbichler"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2201.12266"
  },
  {
    "id": "arXiv:2201.12345",
    "title": "On Stability and Convergence of a Three-layer Semi-discrete Scheme for  an Abstract Analogue of the Ball Integro-differential Equation",
    "abstract": "Comments: 24 pages",
    "descriptor": "\nComments: 24 pages\n",
    "authors": [
      "Jemal Rogava",
      "Mikheil Tsiklauri",
      "Zurab Vashakidze"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Mathematical Physics (math-ph)",
      "Analysis of PDEs (math.AP)",
      "Functional Analysis (math.FA)"
    ],
    "url": "https://arxiv.org/abs/2201.12345"
  },
  {
    "id": "arXiv:2201.12362",
    "title": "Physics-informed neural networks to learn cardiac fiber orientation from  multiple electroanatomical maps",
    "abstract": "Comments: 28 pages, 11 figures",
    "descriptor": "\nComments: 28 pages, 11 figures\n",
    "authors": [
      "Carlos Ruiz Herrera",
      "Thomas Grandits",
      "Gernot Plank",
      "Paris Perdikaris",
      "Francisco Sahli Costabal",
      "Simone Pezzuto"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Machine Learning (cs.LG)",
      "Medical Physics (physics.med-ph)",
      "Tissues and Organs (q-bio.TO)"
    ],
    "url": "https://arxiv.org/abs/2201.12362"
  },
  {
    "id": "arXiv:2201.12550",
    "title": "Recommender System Expedited Quantum Control Optimization",
    "abstract": "Comments: 7 pages, 4 figures, 2 tables",
    "descriptor": "\nComments: 7 pages, 4 figures, 2 tables\n",
    "authors": [
      "Priya Batra",
      "M. Harshanth Ram",
      "T. S. Mahesh"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2201.12550"
  },
  {
    "id": "arXiv:2201.12558",
    "title": "The KFIoU Loss for Rotated Object Detection",
    "abstract": "Comments: 19 pages, 5 figures, 11 tables, tensorflow code: this https URL, pytorch code: this https URL",
    "descriptor": "\nComments: 19 pages, 5 figures, 11 tables, tensorflow code: this https URL, pytorch code: this https URL\n",
    "authors": [
      "Xue Yang",
      "Yue Zhou",
      "Gefan Zhang",
      "Jirui Yang",
      "Wentao Wang",
      "Junchi Yan",
      "Xiaopeng Zhang",
      "Qi Tian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.12558"
  },
  {
    "id": "arXiv:2201.12612",
    "title": "On Non-Cooperative Perfect Information Semi-Markov Games",
    "abstract": "Comments: arXiv admin note: substantial text overlap with arXiv:2201.00179",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2201.00179\n",
    "authors": [
      "K. G. Bakshi",
      "S. Sinha"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2201.12612"
  },
  {
    "id": "arXiv:2201.12646",
    "title": "Self Semi Supervised Neural Architecture Search for Semantic  Segmentation",
    "abstract": "Comments: 21 pages, 5 figures",
    "descriptor": "\nComments: 21 pages, 5 figures\n",
    "authors": [
      "Lo\u00efc Pauletto",
      "Massih-Reza Amini",
      "Nicolas Winckler"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.12646"
  },
  {
    "id": "arXiv:2201.12741",
    "title": "GARNET: Reduced-Rank Topology Learning for Robust and Scalable Graph  Neural Networks",
    "abstract": "GARNET: Reduced-Rank Topology Learning for Robust and Scalable Graph  Neural Networks",
    "descriptor": "",
    "authors": [
      "Chenhui Deng",
      "Xiuyu Li",
      "Zhuo Feng",
      "Zhiru Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.12741"
  },
  {
    "id": "arXiv:2201.12830",
    "title": "Over-smoothing Effect of Graph Convolutional Networks",
    "abstract": "Comments: 8 pages, 2 figures",
    "descriptor": "\nComments: 8 pages, 2 figures\n",
    "authors": [
      "Fang Sun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.12830"
  },
  {
    "id": "arXiv:2201.12898",
    "title": "Clearing Payments in Dynamic Financial Networks",
    "abstract": "Clearing Payments in Dynamic Financial Networks",
    "descriptor": "",
    "authors": [
      "Giuseppe C. Calafiore",
      "Giulia Fracastoro",
      "Anton V. Proskurnikov"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Systems and Control (eess.SY)",
      "Mathematical Finance (q-fin.MF)",
      "Risk Management (q-fin.RM)"
    ],
    "url": "https://arxiv.org/abs/2201.12898"
  },
  {
    "id": "arXiv:2201.12981",
    "title": "G$ \\mathbf{^2} $VD Planner: An Efficient Motion Planning Approach With  Grid-based Generalized Voronoi Diagrams",
    "abstract": "Comments: Submitted to IEEE RA-L with 2022 IEEE/RSJ IROS, under review",
    "descriptor": "\nComments: Submitted to IEEE RA-L with 2022 IEEE/RSJ IROS, under review\n",
    "authors": [
      "Jian Wen",
      "Xuebo Zhang",
      "Hui Liu",
      "Haoyue Liu",
      "Jing Yuan",
      "Yongchun Fang"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2201.12981"
  },
  {
    "id": "arXiv:2201.13195",
    "title": "Memory-Efficient Backpropagation through Large Linear Layers",
    "abstract": "Comments: Submitted",
    "descriptor": "\nComments: Submitted\n",
    "authors": [
      "Daniel Bershatsky",
      "Aleksandr Mikhalev",
      "Alexandr Katrutsa",
      "Julia Gusak",
      "Daniil Merkulov",
      "Ivan Oseledets"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2201.13195"
  },
  {
    "id": "arXiv:2201.13288",
    "title": "A Regret Minimization Approach to Multi-Agent Control",
    "abstract": "A Regret Minimization Approach to Multi-Agent Control",
    "descriptor": "",
    "authors": [
      "Udaya Ghai",
      "Udari Madhushani",
      "Naomi Leonard",
      "Elad Hazan"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2201.13288"
  }
]
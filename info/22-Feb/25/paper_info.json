[
  {
    "id": "arXiv:2202.11742",
    "title": "Think Global, Act Local: Dual-scale Graph Transformer for  Vision-and-Language Navigation",
    "abstract": "Following language instructions to navigate in unseen environments is a\nchallenging problem for autonomous embodied agents. The agent not only needs to\nground languages in visual scenes, but also should explore the environment to\nreach its target. In this work, we propose a dual-scale graph transformer\n(DUET) for joint long-term action planning and fine-grained cross-modal\nunderstanding. We build a topological map on-the-fly to enable efficient\nexploration in global action space. To balance the complexity of large action\nspace reasoning and fine-grained language grounding, we dynamically combine a\nfine-scale encoding over local observations and a coarse-scale encoding on a\nglobal map via graph transformers. The proposed approach, DUET, significantly\noutperforms state-of-the-art methods on goal-oriented vision-and-language\nnavigation (VLN) benchmarks REVERIE and SOON. It also improves the success rate\non the fine-grained VLN benchmark R2R.",
    "descriptor": "",
    "authors": [
      "Shizhe Chen",
      "Pierre-Louis Guhur",
      "Makarand Tapaswi",
      "Cordelia Schmid",
      "Ivan Laptev"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.11742"
  },
  {
    "id": "arXiv:2202.11748",
    "title": "The Need for Interpretable Features: Motivation and Taxonomy",
    "abstract": "Through extensive experience developing and explaining machine learning (ML)\napplications for real-world domains, we have learned that ML models are only as\ninterpretable as their features. Even simple, highly interpretable model types\nsuch as regression models can be difficult or impossible to understand if they\nuse uninterpretable features. Different users, especially those using ML models\nfor decision-making in their domains, may require different levels and types of\nfeature interpretability. Furthermore, based on our experiences, we claim that\nthe term \"interpretable feature\" is not specific nor detailed enough to capture\nthe full extent to which features impact the usefulness of ML explanations. In\nthis paper, we motivate and discuss three key lessons: 1) more attention should\nbe given to what we refer to as the interpretable feature space, or the state\nof features that are useful to domain experts taking real-world actions, 2) a\nformal taxonomy is needed of the feature properties that may be required by\nthese domain experts (we propose a partial taxonomy in this paper), and 3)\ntransforms that take data from the model-ready state to an interpretable form\nare just as essential as traditional ML transforms that prepare features for\nthe model.",
    "descriptor": "\nComments: 11 pages, 4 figures, 2 tables\n",
    "authors": [
      "Alexandra Zytek",
      "Ignacio Arnaldo",
      "Dongyu Liu",
      "Laure Berti-Equille",
      "Kalyan Veeramachaneni"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.11748"
  },
  {
    "id": "arXiv:2202.11749",
    "title": "Are All Linear Regions Created Equal?",
    "abstract": "The number of linear regions has been studied as a proxy of complexity for\nReLU networks. However, the empirical success of network compression techniques\nlike pruning and knowledge distillation, suggest that in the overparameterized\nsetting, linear regions density might fail to capture the effective\nnonlinearity. In this work, we propose an efficient algorithm for discovering\nlinear regions and use it to investigate the effectiveness of density in\ncapturing the nonlinearity of trained VGGs and ResNets on CIFAR-10 and\nCIFAR-100. We contrast the results with a more principled nonlinearity measure\nbased on function variation, highlighting the shortcomings of linear regions\ndensity. Furthermore, interestingly, our measure of nonlinearity clearly\ncorrelates with model-wise deep double descent, connecting reduced test error\nwith reduced nonlinearity, and increased local similarity of linear regions.",
    "descriptor": "",
    "authors": [
      "Matteo Gamba",
      "Adrian Chmielewski-Anders",
      "Josephine Sullivan",
      "Hossein Azizpour",
      "M\u00e5rten Bj\u00f6rkman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.11749"
  },
  {
    "id": "arXiv:2202.11756",
    "title": "ML-based Anomaly Detection in Optical Fiber Monitoring",
    "abstract": "Secure and reliable data communication in optical networks is critical for\nhigh-speed internet. We propose a data driven approach for the anomaly\ndetection and faults identification in optical networks to diagnose physical\nattacks such as fiber breaks and optical tapping. The proposed methods include\nan autoencoder-based anomaly detection and an attention-based bidirectional\ngated recurrent unit algorithm for the fiber fault identification and\nlocalization. We verify the efficiency of our methods by experiments under\nvarious attack scenarios using real operational data.",
    "descriptor": "\nComments: The AAAI-22 Workshop on Artificial Intelligence for Cyber Security (AICS)\n",
    "authors": [
      "Khouloud Abdelli",
      "Joo Yeon Cho",
      "Carsten Tropschug"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2202.11756"
  },
  {
    "id": "arXiv:2202.11757",
    "title": "Degradation-Reducing Control for Dynamically Reconfigurable Batteries",
    "abstract": "Cascaded circuits such as modular multilevel con-verters (MMC) offer\nattractive qualities in reconfigurable battery applications. In contrast to\nconventional hard-wired dc battery packs, the MMC topology loads modules with\nac current, which may lead to additional ageing of batteries. As recent studies\nreveal, such ageing of batteries occurs at low-frequency load ripple, and\nalmost vanishes at high frequencies. State of the art in MMC bat-tery control\nfocuses on state of charge and temperature balancing of individual modules.\nPrevious methods to suppress ripple rely on slow feedback loops and low\ndynamics, which tends to form low-frequency patterns in the module load that\nnegatively contribute to their ageing. This paper presents a novel\nmodule-current-oriented high-bandwidth control technique which minimizes\nlow-frequency components in the module load spectrum. The control method\nrespects limitations related to module data acquisition and enhanc-es the\nfeedback bandwidth using observation techniques. We verify the proposed method\nexperimentally on a laboratory setup and estimate the influence on the battery\ncells.",
    "descriptor": "\nComments: 9 pages, 11 figures\n",
    "authors": [
      "Tomas Kacetl",
      "Jan Kacetl",
      "Jinyang Fang",
      "Malte Jaensch",
      "Stefan Goetz"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.11757"
  },
  {
    "id": "arXiv:2202.11760",
    "title": "Googling for Abortion: Search Engine Mediation of Abortion Accessibility  in the United States",
    "abstract": "Among the myriad barriers to abortion access, crisis pregnancy centers (CPCs)\npose an additional difficulty by targeting women with unexpected or \"crisis\"\npregnancies in order to dissuade them from the procedure. Web search engines\nmay prove to be another barrier, being in a powerful position to direct their\nusers to health information, and above all, health services. In this study we\nask, to what degree does Google Search provide quality responses to users\nsearching for an abortion provider, specifically in terms of directing them to\nabortion clinics (ACs) or CPCs. To answer this question, we considered the\nscenario of a woman searching for abortion services online, and conducted 10\nabortion-related queries from 467 locations across the United States once a\nweek for 14 weeks. Overall, among Google's location results that feature\nbusinesses alongside a map, 79.4% were ACs, and 6.9% were CPCs. When an AC was\nreturned, it was the closest known AC location 86.9% of the time. However, when\na CPC appeared in a result set, it was the closest one to the search location\n75.9% of the time. Examining correlates of AC results, we found that fewer AC\nresults were returned for searches from poorer and rural areas, and those with\nTRAP laws governing AC facility and clinician requirements. We also observed\nthat Google's performance on our queries significantly improved following a\nmajor algorithm update. These results have important implications concerning\nhealth access quality and equity, both for individual users and public health\npolicy.",
    "descriptor": "",
    "authors": [
      "Yelena Mejova",
      "Tatiana Gracyk",
      "Ronald E. Robertson"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2202.11760"
  },
  {
    "id": "arXiv:2202.11762",
    "title": "Safe Control with Learned Certificates: A Survey of Neural Lyapunov,  Barrier, and Contraction methods",
    "abstract": "Learning-enabled control systems have demonstrated impressive empirical\nperformance on challenging control problems in robotics, but this performance\ncomes at the cost of reduced transparency and lack of guarantees on the safety\nor stability of the learned controllers. In recent years, new techniques have\nemerged to provide these guarantees by learning certificates alongside control\npolicies -- these certificates provide concise, data-driven proofs that\nguarantee the safety and stability of the learned control system. These methods\nnot only allow the user to verify the safety of a learned controller but also\nprovide supervision during training, allowing safety and stability requirements\nto influence the training process itself. In this paper, we provide a\ncomprehensive survey of this rapidly developing field of certificate learning.\nWe hope that this paper will serve as an accessible introduction to the theory\nand practice of certificate learning, both to those who wish to apply these\ntools to practical robotics problems and to those who wish to dive more deeply\ninto the theory of learning for control.",
    "descriptor": "\nComments: Supplementary code available at this https URL\n",
    "authors": [
      "Charles Dawson",
      "Sicun Gao",
      "Chuchu Fan"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.11762"
  },
  {
    "id": "arXiv:2202.11765",
    "title": "When do GANs replicate? On the choice of dataset size",
    "abstract": "Do GANs replicate training images? Previous studies have shown that GANs do\nnot seem to replicate training data without significant change in the training\nprocedure. This leads to a series of research on the exact condition needed for\nGANs to overfit to the training data. Although a number of factors has been\ntheoretically or empirically identified, the effect of dataset size and\ncomplexity on GANs replication is still unknown. With empirical evidence from\nBigGAN and StyleGAN2, on datasets CelebA, Flower and LSUN-bedroom, we show that\ndataset size and its complexity play an important role in GANs replication and\nperceptual quality of the generated images. We further quantify this\nrelationship, discovering that replication percentage decays exponentially with\nrespect to dataset size and complexity, with a shared decaying factor across\nGAN-dataset combinations. Meanwhile, the perceptual image quality follows a\nU-shape trend w.r.t dataset size. This finding leads to a practical tool for\none-shot estimation on minimal dataset size to prevent GAN replication which\ncan be used to guide datasets construction and selection.",
    "descriptor": "",
    "authors": [
      "Qianli Feng",
      "Chenqi Guo",
      "Fabian Benitez-Quiroz",
      "Aleix Martinez"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.11765"
  },
  {
    "id": "arXiv:2202.11766",
    "title": "A gentle introduction to Quantum Natural Language Processing",
    "abstract": "The main goal of this master's thesis is to introduce Quantum Natural\nLanguage Processing (QNLP) in a way understandable by both the NLP engineer and\nthe quantum computing practitioner. QNLP is a recent application of quantum\ncomputing that aims at representing sentences' meaning as vectors encoded into\nquantum computers. To achieve this, the distributional meaning of words is\nextended by the compositional meaning of sentences (DisCoCat model) : the\nvectors representing words' meanings are composed through the syntactic\nstructure of the sentence. This is done using an algorithm based on tensor\nproducts. We see that this algorithm is inefficient on classical computers but\nscales well using quantum circuits. After exposing the practical details of its\nimplementation, we go through three use-cases.",
    "descriptor": "",
    "authors": [
      "Shervin Le Du",
      "Senaida Hern\u00e1ndez Santana",
      "Giannicola Scarpa"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.11766"
  },
  {
    "id": "arXiv:2202.11768",
    "title": "From Unstructured Text to Causal Knowledge Graphs: A Transformer-Based  Approach",
    "abstract": "Qualitative causal relationships compactly express the direction, dependency,\ntemporal constraints, and monotonicity constraints of discrete or continuous\ninteractions in the world. In everyday or academic language, we may express\ninteractions between quantities (e.g., sleep decreases stress), between\ndiscrete events or entities (e.g., a protein inhibits another protein's\ntranscription), or between intentional or functional factors (e.g., hospital\npatients pray to relieve their pain). Extracting and representing these diverse\ncausal relations are critical for cognitive systems that operate in domains\nspanning from scientific discovery to social science. This paper presents a\ntransformer-based NLP architecture that jointly extracts knowledge graphs\nincluding (1) variables or factors described in language, (2) qualitative\ncausal relationships over these variables, (3) qualifiers and magnitudes that\nconstrain these causal relationships, and (4) word senses to localize each\nextracted node within a large ontology. We do not claim that our\ntransformer-based architecture is itself a cognitive system; however, we\nprovide evidence of its accurate knowledge graph extraction in real-world\ndomains and the practicality of its resulting knowledge graphs for cognitive\nsystems that perform graph-based reasoning. We demonstrate this approach and\ninclude promising results in two use cases, processing textual inputs from\nacademic publications, news articles, and social media.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2108.13304\n",
    "authors": [
      "Scott Friedman",
      "Ian Magnusson",
      "Vasanth Sarathy",
      "Sonja Schmer-Galunder"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.11768"
  },
  {
    "id": "arXiv:2202.11770",
    "title": "Development and performance of a HemeLB GPU code for human-scale blood  flow simulation",
    "abstract": "In recent years, it has become increasingly common for high performance\ncomputers (HPC) to possess some level of heterogeneous architecture - typically\nin the form of GPU accelerators. In some machines these are isolated within a\ndedicated partition, whilst in others they are integral to all compute nodes -\noften with multiple GPUs per node - and provide the majority of a machine's\ncompute performance. In light of this trend, it is becoming essential that\ncodes deployed on HPC are updated to execute on accelerator hardware. In this\npaper we introduce a GPU implementation of the 3D blood flow simulation code\nHemeLB that has been developed using CUDA C++. We demonstrate how taking\nadvantage of NVIDIA GPU hardware can achieve significant performance\nimprovements compared to the equivalent CPU only code on which it has been\nbuilt whilst retaining the excellent strong scaling characteristics that have\nbeen repeatedly demonstrated by the CPU version. With HPC positioned on the\nbrink of the exascale era, we use HemeLB as a motivation to provide a\ndiscussion on some of the challenges that many users will face when deploying\ntheir own applications on upcoming exascale machines.",
    "descriptor": "",
    "authors": [
      "I. Zacharoudiou",
      "J.W.S. McCullough",
      "P.V. Coveney"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2202.11770"
  },
  {
    "id": "arXiv:2202.11772",
    "title": "Discovering Multiple and Diverse Directions for Cognitive Image  Properties",
    "abstract": "Recent research has shown that it is possible to find interpretable\ndirections in the latent spaces of pre-trained GANs. These directions enable\ncontrollable generation and support a variety of semantic editing operations.\nWhile previous work has focused on discovering a single direction that performs\na desired editing operation such as zoom-in, limited work has been done on the\ndiscovery of multiple and diverse directions that can achieve the desired edit.\nIn this work, we propose a novel framework that discovers multiple and diverse\ndirections for a given property of interest. In particular, we focus on the\nmanipulation of cognitive properties such as Memorability, Emotional Valence\nand Aesthetics. We show with extensive experiments that our method successfully\nmanipulates these properties while producing diverse outputs. Our project page\nand source code can be found at this http URL",
    "descriptor": "",
    "authors": [
      "Umut Kocasari",
      "Alperen Bag",
      "Oguz Kaan Yuksel",
      "Pinar Yanardag"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.11772"
  },
  {
    "id": "arXiv:2202.11776",
    "title": "The Challenge of Understanding What Users Want: Inconsistent Preferences  and Engagement Optimization",
    "abstract": "Online platforms have a wealth of data, run countless experiments and use\nindustrial-scale algorithms to optimize user experience. Despite this, many\nusers seem to regret the time they spend on these platforms. One possible\nexplanation is that incentives are misaligned: platforms are not optimizing for\nuser happiness. We suggest the problem runs deeper, transcending the specific\nincentives of any particular platform, and instead stems from a mistaken\nfoundational assumption. To understand what users want, platforms look at what\nusers do. This is a kind of revealed-preference assumption that is ubiquitous\nin user models. Yet research has demonstrated, and personal experience affirms,\nthat we often make choices in the moment that are inconsistent with what we\nactually want: we can choose mindlessly or myopically, behaviors that feel\nentirely familiar on online platforms.\nIn this work, we develop a model of media consumption where users have\ninconsistent preferences. We consider what happens when a platform that simply\nwants to maximize user utility is only able to observe behavioral data in the\nform of user engagement. Our model produces phenomena related to\noverconsumption that are familiar from everyday experience, but difficult to\ncapture in traditional user interaction models. A key ingredient is a\nformulation for how platforms determine what to show users: they optimize over\na large set of potential content (the content manifold) parametrized by\nunderlying features of the content. We show how the relationship between\nengagement and utility depends on the structure of the content manifold,\ncharacterizing when engagement optimization leads to good utility outcomes. By\nlinking these effects to abstractions of platform design choices, our model\nthus creates a theoretical framework and vocabulary in which to explore\ninteractions between design, behavioral science, and social media.",
    "descriptor": "",
    "authors": [
      "Jon Kleinberg",
      "Sendhil Mullainathan",
      "Manish Raghavan"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2202.11776"
  },
  {
    "id": "arXiv:2202.11777",
    "title": "Art Creation with Multi-Conditional StyleGANs",
    "abstract": "Creating meaningful art is often viewed as a uniquely human endeavor. A human\nartist needs a combination of unique skills, understanding, and genuine\nintention to create artworks that evoke deep feelings and emotions. In this\npaper, we introduce a multi-conditional Generative Adversarial Network (GAN)\napproach trained on large amounts of human paintings to synthesize\nrealistic-looking paintings that emulate human art. Our approach is based on\nthe StyleGAN neural network architecture, but incorporates a custom\nmulti-conditional control mechanism that provides fine-granular control over\ncharacteristics of the generated paintings, e.g., with regard to the perceived\nemotion evoked in a spectator. For better control, we introduce the conditional\ntruncation trick, which adapts the standard truncation trick for the\nconditional setting and diverse datasets. Finally, we develop a diverse set of\nevaluation techniques tailored to multi-conditional generation.",
    "descriptor": "",
    "authors": [
      "Konstantin Dobler",
      "Florian H\u00fcbscher",
      "Jan Westphal",
      "Alejandro Sierra-M\u00fanera",
      "Gerard de Melo",
      "Ralf Krestel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.11777"
  },
  {
    "id": "arXiv:2202.11781",
    "title": "RadioTransformer: A Cascaded Global-Focal Transformer for Visual  Attention-guided Disease Classification",
    "abstract": "In this work, we present RadioTransformer, a novel visual attention-driven\ntransformer framework, that leverages radiologists' gaze patterns and models\ntheir visuo-cognitive behavior for disease diagnosis on chest radiographs.\nDomain experts, such as radiologists, rely on visual information for medical\nimage interpretation. On the other hand, deep neural networks have demonstrated\nsignificant promise in similar tasks even where visual interpretation is\nchallenging. Eye-gaze tracking has been used to capture the viewing behavior of\ndomain experts, lending insights into the complexity of visual search. However,\ndeep learning frameworks, even those that rely on attention mechanisms, do not\nleverage this rich domain information. RadioTransformer fills this critical gap\nby learning from radiologists' visual search patterns, encoded as 'human visual\nattention regions' in a cascaded global-focal transformer framework. The\noverall 'global' image characteristics and the more detailed 'local' features\nare captured by the proposed global and focal modules, respectively. We\nexperimentally validate the efficacy of our student-teacher approach for 8\ndatasets involving different disease classification tasks where eye-gaze data\nis not available during the inference phase.",
    "descriptor": "",
    "authors": [
      "Moinak Bhattacharya",
      "Shubham Jain",
      "Prateek Prasanna"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.11781"
  },
  {
    "id": "arXiv:2202.11782",
    "title": "Prune and Tune Ensembles: Low-Cost Ensemble Learning With Sparse  Independent Subnetworks",
    "abstract": "Ensemble Learning is an effective method for improving generalization in\nmachine learning. However, as state-of-the-art neural networks grow larger, the\ncomputational cost associated with training several independent networks\nbecomes expensive. We introduce a fast, low-cost method for creating diverse\nensembles of neural networks without needing to train multiple models from\nscratch. We do this by first training a single parent network. We then create\nchild networks by cloning the parent and dramatically pruning the parameters of\neach child to create an ensemble of members with unique and diverse topologies.\nWe then briefly train each child network for a small number of epochs, which\nnow converge significantly faster when compared to training from scratch. We\nexplore various ways to maximize diversity in the child networks, including the\nuse of anti-random pruning and one-cycle tuning. This diversity enables \"Prune\nand Tune\" ensembles to achieve results that are competitive with traditional\nensembles at a fraction of the training cost. We benchmark our approach against\nstate of the art low-cost ensemble methods and display marked improvement in\nboth accuracy and uncertainty estimation on CIFAR-10 and CIFAR-100.",
    "descriptor": "\nComments: 9 pages, 3 figures, Accepted to AAAI-22\n",
    "authors": [
      "Tim Whitaker",
      "Darrell Whitley"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.11782"
  },
  {
    "id": "arXiv:2202.11783",
    "title": "Adversarially-regularized mixed effects deep learning (ARMED) models for  improved interpretability, performance, and generalization on clustered data",
    "abstract": "Data in the natural sciences frequently violate assumptions of independence.\nSuch datasets have samples with inherent clustering (e.g. by study site,\nsubject, experimental batch), which may lead to spurious associations, poor\nmodel fitting, and confounded analyses. While largely unaddressed in deep\nlearning, mixed effects models have been used in traditional statistics for\nclustered data. Mixed effects models separate cluster-invariant,\npopulation-level fixed effects from cluster-specific random effects. We propose\na general-purpose framework for building Adversarially-Regularized Mixed\nEffects Deep learning (ARMED) models through 3 non-intrusive additions to\nexisting networks: 1) a domain adversarial classifier constraining the original\nmodel to learn only cluster-invariant features, 2) a random effects subnetwork\ncapturing cluster-specific features, and 3) a cluster-inferencing approach to\npredict on clusters unseen during training. We apply this framework to dense\nfeedforward neural networks (DFNNs), convolutional neural networks, and\nautoencoders on 4 applications including simulations, dementia prognosis and\ndiagnosis, and cell microscopy. We compare to conventional models, domain\nadversarial-only models, and the naive inclusion of cluster membership as a\ncovariate. Our models better distinguish confounded from true associations in\nsimulations and emphasize more biologically plausible features in clinical\napplications. ARMED DFNNs quantify inter-cluster variance in clinical data\nwhile ARMED autoencoders visualize batch effects in cell images. Finally, ARMED\nimproves accuracy on data from clusters seen during training (up to 28% vs.\nconventional models) and generalizes better to unseen clusters (up to 9% vs.\nconventional models). By incorporating powerful mixed effects modeling into\ndeep learning, ARMED increases performance, interpretability, and\ngeneralization on clustered data.",
    "descriptor": "\nComments: 19 pages, 6 figures\n",
    "authors": [
      "Kevin P. Nguyen",
      "Albert Montillo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.11783"
  },
  {
    "id": "arXiv:2202.11784",
    "title": "Design and experimental investigation of a vibro-impact self-propelled  capsule robot with orientation control",
    "abstract": "This paper presents a novel design and experimental investigation for a\nself-propelled capsule robot that can be used for painless colonoscopy during a\nretrograde progression from the patient's rectum. The steerable robot is driven\nforward and backward via its internal vibration and impact with orientation\ncontrol by using an electromagnetic actuator. The actuator contains four sets\nof coils and a shaft made by permanent magnet. The shaft can be excited\nlinearly in a controllable and tilted angle, so guide the progression\norientation of the robot. Two control strategies are studied in this work and\ncompared via simulation and experiment. Extensive results are presented to\ndemonstrate the progression efficiency of the robot and its potential for\nrobotic colonoscopy.",
    "descriptor": "\nComments: ICRA 2022 Conference paper\n",
    "authors": [
      "Jiajia Zhang",
      "Jiyuan Tian",
      "Yang Liu",
      "Shyam Prasad"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.11784"
  },
  {
    "id": "arXiv:2202.11788",
    "title": "Generative modeling via tensor train sketching",
    "abstract": "In this paper we introduce a sketching algorithm for constructing a tensor\ntrain representation of a probability density from its samples. Our method\ndeviates from the standard recursive SVD-based procedure for constructing a\ntensor train. Instead we formulate and solve a sequence of small linear systems\nfor the individual tensor train cores. This approach can avoid the curse of\ndimensionality that threatens both the algorithmic and sample complexities of\nthe recovery problem. Specifically, for Markov models, we prove that the tensor\ncores can be recovered with a sample complexity that is constant with respect\nto the dimension. Finally, we illustrate the performance of the method with\nseveral numerical experiments.",
    "descriptor": "",
    "authors": [
      "Y. Hur",
      "J. G. Hoskins",
      "M. Lindsey",
      "E.M. Stoudenmire",
      "Y. Khoo"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.11788"
  },
  {
    "id": "arXiv:2202.11789",
    "title": "Investigating the effect of binning on causal discovery",
    "abstract": "Binning (a.k.a. discretization) of numerically continuous measurements is a\nwide-spread but controversial practice in data collection, analysis, and\npresentation. The consequences of binning have been evaluated for many\ndifferent kinds of data analysis methods, however so far the effect of binning\non causal discovery algorithms has not been directly investigated. This paper\nreports the results of a simulation study that examined the effect of binning\non the Greedy Equivalence Search (GES) causal discovery algorithm. Our findings\nsuggest that unbinned continuous data often result in the highest search\nperformance, but some exceptions are identified. We also found that binned data\nare more sensitive to changes in sample size and tuning parameters, and\nidentified some interactive effects between sample size, binning, and tuning\nparameter on performance.",
    "descriptor": "",
    "authors": [
      "Andrew Colt Deckert",
      "Erich Kummerfeld"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.11789"
  },
  {
    "id": "arXiv:2202.11792",
    "title": "Let's Handle It: Generalizable Manipulation of Articulated Objects",
    "abstract": "In this project we present a framework for building generalizable\nmanipulation controller policies that map from raw input point clouds and\nsegmentation masks to joint velocities. We took a traditional robotics\napproach, using point cloud processing, end-effector trajectory calculation,\ninverse kinematics, closed-loop position controllers, and behavior trees. We\ndemonstrate our framework on four manipulation skills on common household\nobjects that comprise the SAPIEN ManiSkill Manipulation challenge.",
    "descriptor": "",
    "authors": [
      "Zhutian Yang",
      "Aidan Curtis"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.11792"
  },
  {
    "id": "arXiv:2202.11795",
    "title": "Exploiting Correlation to Achieve Faster Learning Rates in Low-Rank  Preference Bandits",
    "abstract": "We introduce the \\emph{Correlated Preference Bandits} problem with random\nutility-based choice models (RUMs), where the goal is to identify the best item\nfrom a given pool of $n$ items through online subsetwise preference feedback.\nWe investigate whether models with a simple correlation structure, e.g. low\nrank, can result in faster learning rates. While we show that the problem can\nbe impossible to solve for the general `low rank' choice models, faster\nlearning rates can be attained assuming more structured item correlations. In\nparticular, we introduce a new class of \\emph{Block-Rank} based RUM model,\nwhere the best item is shown to be $(\\epsilon,\\delta)$-PAC learnable with only\n$O(r \\epsilon^{-2} \\log(n/\\delta))$ samples. This improves on the standard\nsample complexity bound of $\\tilde{O}(n\\epsilon^{-2} \\log(1/\\delta))$ known for\nthe usual learning algorithms which might not exploit the item-correlations ($r\n\\ll n$). We complement the above sample complexity with a matching lower bound\n(up to logarithmic factors), justifying the tightness of our analysis.\nSurprisingly, we also show a lower bound of\n$\\Omega(n\\epsilon^{-2}\\log(1/\\delta))$ when the learner is forced to play just\nduels instead of larger subsetwise queries. Further, we extend the results to a\nmore general `\\emph{noisy Block-Rank}' model, which ensures robustness of our\ntechniques. Overall, our results justify the advantage of playing subsetwise\nqueries over pairwise preferences $(k=2)$, we show the latter provably fails to\nexploit correlation.",
    "descriptor": "\nComments: In International Conference on Artificial Intelligence and Statistics, AIStats 2022\n",
    "authors": [
      "Suprovat Ghoshal",
      "Aadirupa Saha"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.11795"
  },
  {
    "id": "arXiv:2202.11797",
    "title": "Training Characteristic Functions with Reinforcement Learning:  XAI-methods play Connect Four",
    "abstract": "One of the goals of Explainable AI (XAI) is to determine which input\ncomponents were relevant for a classifier decision. This is commonly know as\nsaliency attribution. Characteristic functions (from cooperative game theory)\nare able to evaluate partial inputs and form the basis for theoretically \"fair\"\nattribution methods like Shapley values. Given only a standard classifier\nfunction, it is unclear how partial input should be realised. Instead, most\nXAI-methods for black-box classifiers like neural networks consider\ncounterfactual inputs that generally lie off-manifold. This makes them hard to\nevaluate and easy to manipulate.\nWe propose a setup to directly train characteristic functions in the form of\nneural networks to play simple two-player games. We apply this to the game of\nConnect Four by randomly hiding colour information from our agents during\ntraining. This has three advantages for comparing XAI-methods: It alleviates\nthe ambiguity about how to realise partial input, makes off-manifold evaluation\nunnecessary and allows us to compare the methods by letting them play against\neach other.",
    "descriptor": "\nComments: 18 pages, 9 figures, 1 table\n",
    "authors": [
      "Stephan W\u00e4ldchen",
      "Felix Huber",
      "Sebastian Pokutta"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.11797"
  },
  {
    "id": "arXiv:2202.11798",
    "title": "Drawing Inductor Layout with a Reinforcement Learning Agent: Method and  Application for VCO Inductors",
    "abstract": "Design of Voltage-Controlled Oscillator (VCO) inductors is a laborious and\ntime-consuming task that is conventionally done manually by human experts. In\nthis paper, we propose a framework for automating the design of VCO inductors,\nusing Reinforcement Learning (RL). We formulate the problem as a sequential\nprocedure, where wire segments are drawn one after another, until a complete\ninductor is created. We then employ an RL agent to learn to draw inductors that\nmeet certain target specifications. In light of the need to tweak the target\nspecifications throughout the circuit design cycle, we also develop a variant\nin which the agent can learn to quickly adapt to draw new inductors for\nmoderately different target specifications. Our empirical results show that the\nproposed framework is successful at automatically generating VCO inductors that\nmeet or exceed the target specification.",
    "descriptor": "",
    "authors": [
      "Cameron Haigh",
      "Zichen Zhang",
      "Negar Hassanpour",
      "Khurram Javed",
      "Yingying Fu",
      "Shayan Shahramian",
      "Shawn Zhang",
      "Jun Luo"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.11798"
  },
  {
    "id": "arXiv:2202.11811",
    "title": "NeuroView-RNN: It's About Time",
    "abstract": "Recurrent Neural Networks (RNNs) are important tools for processing\nsequential data such as time-series or video. Interpretability is defined as\nthe ability to be understood by a person and is different from explainability,\nwhich is the ability to be explained in a mathematical formulation. A key\ninterpretability issue with RNNs is that it is not clear how each hidden state\nper time step contributes to the decision-making process in a quantitative\nmanner. We propose NeuroView-RNN as a family of new RNN architectures that\nexplains how all the time steps are used for the decision-making process. Each\nmember of the family is derived from a standard RNN architecture by\nconcatenation of the hidden steps into a global linear classifier. The global\nlinear classifier has all the hidden states as the input, so the weights of the\nclassifier have a linear mapping to the hidden states. Hence, from the weights,\nNeuroView-RNN can quantify how important each time step is to a particular\ndecision. As a bonus, NeuroView-RNN also offers higher accuracy in many cases\ncompared to the RNNs and their variants. We showcase the benefits of\nNeuroView-RNN by evaluating on a multitude of diverse time-series datasets.",
    "descriptor": "\nComments: 21 pages, 13 figures, 9 tables\n",
    "authors": [
      "CJ Barberan",
      "Sina Alemohammad",
      "Naiming Liu",
      "Randall Balestriero",
      "Richard G. Baraniuk"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.11811"
  },
  {
    "id": "arXiv:2202.11812",
    "title": "Investigations of Performance and Bias in Human-AI Teamwork in Hiring",
    "abstract": "In AI-assisted decision-making, effective hybrid (human-AI) teamwork is not\nsolely dependent on AI performance alone, but also on its impact on human\ndecision-making. While prior work studies the effects of model accuracy on\nhumans, we endeavour here to investigate the complex dynamics of how both a\nmodel's predictive performance and bias may transfer to humans in a\nrecommendation-aided decision task. We consider the domain of ML-assisted\nhiring, where humans -- operating in a constrained selection setting -- can\nchoose whether they wish to utilize a trained model's inferences to help select\ncandidates from written biographies. We conduct a large-scale user study\nleveraging a re-created dataset of real bios from prior work, where humans\npredict the ground truth occupation of given candidates with and without the\nhelp of three different NLP classifiers (random, bag-of-words, and deep neural\nnetwork). Our results demonstrate that while high-performance models\nsignificantly improve human performance in a hybrid setting, some models\nmitigate hybrid bias while others accentuate it. We examine these findings\nthrough the lens of decision conformity and observe that our model architecture\nchoices have an impact on human-AI conformity and bias, motivating the explicit\nneed to assess these complex dynamics prior to deployment.",
    "descriptor": "\nComments: Accepted at AAAI 2022\n",
    "authors": [
      "Andi Peng",
      "Besmira Nushi",
      "Emre Kiciman",
      "Kori Inkpen",
      "Ece Kamar"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.11812"
  },
  {
    "id": "arXiv:2202.11813",
    "title": "AirGuard -- Protecting Android Users From Stalking Attacks By Apple Find  My Devices",
    "abstract": "Finder networks in general, and Apple's Find My network in particular, can\npose a grave threat to users' privacy and even health if these networks are\nabused for stalking. Apple's release of the AirTag, a very affordable tracker\ncovered by the nearly ubiquitous Find My network, amplified this issue. While\nApple provides a stalking detection feature within its ecosystem, billions of\nAndroid users are still left in the dark. Apple recently released the Android\napp \"Tracker Detect,\" which does not deliver a convincing feature set for\nstalking protection. We reverse engineer Apple's tracking protection in iOS and\ndiscuss its features regarding stalking detection. We design \"AirGuard\" and\nrelease it as an Android app to protect against abuse by Apple tracking\ndevices. We compare the performance of our solution with the Apple-provided one\nin iOS and study the use of AirGuard in the wild over multiple weeks using data\ncontributed by tens of thousands of active users.",
    "descriptor": "",
    "authors": [
      "Alexander Heinrich",
      "Niklas Bittner",
      "Matthias Hollick"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2202.11813"
  },
  {
    "id": "arXiv:2202.11818",
    "title": "Consistent Dropout for Policy Gradient Reinforcement Learning",
    "abstract": "Dropout has long been a staple of supervised learning, but is rarely used in\nreinforcement learning. We analyze why naive application of dropout is\nproblematic for policy-gradient learning algorithms and introduce consistent\ndropout, a simple technique to address this instability. We demonstrate\nconsistent dropout enables stable training with A2C and PPO in both continuous\nand discrete action environments across a wide range of dropout probabilities.\nFinally, we show that consistent dropout enables the online training of complex\narchitectures such as GPT without needing to disable the model's native\ndropout.",
    "descriptor": "",
    "authors": [
      "Matthew Hausknecht",
      "Nolan Wagener"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.11818"
  },
  {
    "id": "arXiv:2202.11819",
    "title": "Improving Scalability with GPU-Aware Asynchronous Tasks",
    "abstract": "Asynchronous tasks, when created with overdecomposition, enable automatic\ncomputation-communication overlap which can substantially improve performance\nand scalability. This is not only applicable to traditional CPU-based systems,\nbut also to modern GPU-accelerated platforms. While the ability to hide\ncommunication behind computation can be highly effective in weak scaling\nscenarios, performance begins to suffer with smaller problem sizes or in strong\nscaling due to fine-grained overheads and reduced room for overlap. In this\nwork, we integrate GPU-aware communication into asynchronous tasks in addition\nto computation-communication overlap, with the goal of reducing time spent in\ncommunication and further increasing GPU utilization. We demonstrate the\nperformance impact of our approach using a proxy application that performs the\nJacobi iterative method on GPUs, Jacobi3D. In addition to optimizations for\nminimizing host-device synchronization and increasing the concurrency of GPU\noperations, we explore techniques such as kernel fusion and CUDA Graphs to\ncombat fine-grained overheads at scale.",
    "descriptor": "\nComments: 10 pages, 9 figures, submitted to HIPS 2022 workshop\n",
    "authors": [
      "Jaemin Choi",
      "David F. Richards",
      "Laxmikant V. Kale"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2202.11819"
  },
  {
    "id": "arXiv:2202.11820",
    "title": "Nowcasting the Financial Time Series with Streaming Data Analytics under  Apache Spark",
    "abstract": "This paper proposes nowcasting of high-frequency financial datasets in\nreal-time with a 5-minute interval using the streaming analytics feature of\nApache Spark. The proposed 2 stage method consists of modelling chaos in the\nfirst stage and then using a sliding window approach for training with machine\nlearning algorithms namely Lasso Regression, Ridge Regression, Generalised\nLinear Model, Gradient Boosting Tree and Random Forest available in the MLLib\nof Apache Spark in the second stage. For testing the effectiveness of the\nproposed methodology, 3 different datasets, of which two are stock markets\nnamely National Stock Exchange & Bombay Stock Exchange, and finally One\nBitcoin-INR conversion dataset. For evaluating the proposed methodology, we\nused metrics such as Symmetric Mean Absolute Percentage Error, Directional\nSymmetry, and Theil U Coefficient. We tested the significance of each pair of\nmodels using the Diebold Mariano (DM) test.",
    "descriptor": "\nComments: 26 pages; 7 Tables and 11 Figures\n",
    "authors": [
      "Mohammad Arafat Ali Khan",
      "Chandra Bhushan",
      "Vadlamani Ravi",
      "Vangala Sarveswara Rao",
      "Shiva Shankar Orsu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2202.11820"
  },
  {
    "id": "arXiv:2202.11821",
    "title": "Physics-informed neural networks for inverse problems in supersonic  flows",
    "abstract": "Accurate solutions to inverse supersonic compressible flow problems are often\nrequired for designing specialized aerospace vehicles. In particular, we\nconsider the problem where we have data available for density gradients from\nSchlieren photography as well as data at the inflow and part of wall\nboundaries. These inverse problems are notoriously difficult and traditional\nmethods may not be adequate to solve such ill-posed inverse problems. To this\nend, we employ the physics-informed neural networks (PINNs) and its extended\nversion, extended PINNs (XPINNs), where domain decomposition allows deploying\nlocally powerful neural networks in each subdomain, which can provide\nadditional expressivity in subdomains, where a complex solution is expected.\nApart from the governing compressible Euler equations, we also enforce the\nentropy conditions in order to obtain viscosity solutions. Moreover, we enforce\npositivity conditions on density and pressure. We consider inverse problems\ninvolving two-dimensional expansion waves, two-dimensional oblique and bow\nshock waves. We compare solutions obtained by PINNs and XPINNs and invoke some\ntheoretical results that can be used to decide on the generalization errors of\nthe two methods.",
    "descriptor": "\nComments: 19 pages, 20 figures\n",
    "authors": [
      "Ameya D. Jagtap",
      "Zhiping Mao",
      "Nikolaus Adams",
      "George Em Karniadakis"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.11821"
  },
  {
    "id": "arXiv:2202.11822",
    "title": "Using natural language prompts for machine translation",
    "abstract": "We explore the use of natural language prompts for controlling various\naspects of the outputs generated by machine translation models. We demonstrate\nthat natural language prompts allow us to influence properties like formality\nor specific dialect of the output. We show that using language names to control\nthe output language of multilingual translation models enables positive\ntransfer for unseen language pairs. This unlocks the ability to translate into\nlanguages not seen during fine-tuning by using their English names. We\ninvestigate how scale, number of pre-training steps, number of languages in\nfine-tuning, and language similarity affect this phenomenon.",
    "descriptor": "",
    "authors": [
      "Xavier Garcia",
      "Orhan Firat"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.11822"
  },
  {
    "id": "arXiv:2202.11823",
    "title": "Differentially Private Speaker Anonymization",
    "abstract": "Sharing real-world speech utterances is key to the training and deployment of\nvoice-based services. However, it also raises privacy risks as speech contains\na wealth of personal data. Speaker anonymization aims to remove speaker\ninformation from a speech utterance while leaving its linguistic and prosodic\nattributes intact. State-of-the-art techniques operate by disentangling the\nspeaker information (represented via a speaker embedding) from these attributes\nand re-synthesizing speech based on the speaker embedding of another speaker.\nPrior research in the privacy community has shown that anonymization often\nprovides brittle privacy protection, even less so any provable guarantee. In\nthis work, we show that disentanglement is indeed not perfect: linguistic and\nprosodic attributes still contain speaker information. We remove speaker\ninformation from these attributes by introducing differentially private feature\nextractors based on an autoencoder and an automatic speech recognizer,\nrespectively, trained using noise layers. We plug these extractors in the\nstate-of-the-art anonymization pipeline and generate, for the first time,\ndifferentially private utterances with a provable upper bound on the speaker\ninformation they contain. We evaluate empirically the privacy and utility\nresulting from our differentially private speaker anonymization approach on the\nLibriSpeech data set. Experimental results show that the generated utterances\nretain very high utility for automatic speech recognition training and\ninference, while being much better protected against strong adversaries who\nleverage the full knowledge of the anonymization process to try to infer the\nspeaker identity.",
    "descriptor": "",
    "authors": [
      "Ali Shahin Shamsabadi",
      "Brij Mohan Lal Srivastava",
      "Aur\u00e9lien Bellet",
      "Nathalie Vauquier",
      "Emmanuel Vincent",
      "Mohamed Maouche",
      "Marc Tommasi",
      "Nicolas Papernot"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2202.11823"
  },
  {
    "id": "arXiv:2202.11824",
    "title": "Using Deep Learning to Detect Digitally Encoded DNA Trigger for Trojan  Malware in Bio-Cyber Attacks",
    "abstract": "This article uses Deep Learning technologies to safeguard DNA sequencing\nagainst Bio-Cyber attacks. We consider a hybrid attack scenario where the\npayload is encoded into a DNA sequence to activate a Trojan malware implanted\nin a software tool used in the sequencing pipeline in order to allow the\nperpetrators to gain control over the resources used in that pipeline during\nsequence analysis. The scenario considered in the paper is based on\nperpetrators submitting synthetically engineered DNA samples that contain\ndigitally encoded IP address and port number of the perpetrators machine in the\nDNA. Genetic analysis of the samples DNA will decode the address that is used\nby the software trojan malware to activate and trigger a remote connection.\nThis approach can open up to multiple perpetrators to create connections to\nhijack the DNA sequencing pipeline. As a way of hiding the data, the\nperpetrators can avoid detection by encoding the address to maximise similarity\nwith genuine DNAs, which we showed previously. However, in this paper we show\nhow Deep Learning can be used to successfully detect and identify the trigger\nencoded data, in order to protect a DNA sequencing pipeline from trojan\nattacks. The result shows nearly up to 100% accuracy in detection in such a\nnovel Trojan attack scenario even after applying fragmentation encryption and\nsteganography on the encoded trigger data. In addition, feasibility of\ndesigning and synthesizing encoded DNA for such Trojan payloads is validated by\na wet lab experiment.",
    "descriptor": "",
    "authors": [
      "Mohd Siblee Islam",
      "Stepan Ivanov",
      "Hamdan Awan",
      "Jennifer Drohan",
      "Sasitharan Balasubramaniam",
      "Lee Coffey",
      "Srivatsan Kidambi",
      "Witty Sri-saan"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.11824"
  },
  {
    "id": "arXiv:2202.11827",
    "title": "TARexp: A Python Framework for Technology-Assisted Review Experiments",
    "abstract": "Technology-assisted review (TAR) is an important industrial application of\ninformation retrieval (IR) and machine learning (ML). While a small TAR\nresearch community exists, the complexity of TAR software and workflows is a\nmajor barrier to entry. Drawing on past open source TAR efforts, as well as\ndesign patterns from the IR and ML open source software, we present an open\nsource Python framework for conducting experiments on TAR algorithms. Key\ncharacteristics of this framework are declarative representations of workflows\nand experiment plans, the ability for components to play variable numbers of\nworkflow roles, and state maintenance and restart capabilities. Users can draw\non reference implementations of standard TAR algorithms while incorporating\nnovel components to explore their research interests. The framework is\navailable at https://github.com/eugene-yang/tarexp.",
    "descriptor": "\nComments: 5 pages, 2 figures, submitted to SIGIR 2022 demo paper\n",
    "authors": [
      "Eugene Yang",
      "David D. Lewis"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2202.11827"
  },
  {
    "id": "arXiv:2202.11831",
    "title": "A modification of the conjugate direction method for motion estimation",
    "abstract": "A comparative study of different block matching alternatives for motion\nestimation is presented. The study is focused on computational burden and\nobjective measures on the accuracy of prediction. Together with existing\nalgorithms several new variations have been tested. An interesting modification\nof the conjugate direction method previously related in literature is reported.\nThis new algorithm shows a good trade-off between computational complexity and\naccuracy of motion vector estimation. Computational complexity is evaluated\nusing a sequence of artificial images designed to incorporate a great variety\nof motion vectors. The performance of block matching methods has been measured\nin terms of the entropy in the error signal between the motion compensated and\nthe original frames.",
    "descriptor": "\nComments: 4 pages\n",
    "authors": [
      "Marcos Faundez-Zanuy",
      "Francesc Tarres-Ruiz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.11831"
  },
  {
    "id": "arXiv:2202.11833",
    "title": "Near Perfect GAN Inversion",
    "abstract": "To edit a real photo using Generative Adversarial Networks (GANs), we need a\nGAN inversion algorithm to identify the latent vector that perfectly reproduces\nit. Unfortunately, whereas existing inversion algorithms can synthesize images\nsimilar to real photos, they cannot generate the identical clones needed in\nmost applications. Here, we derive an algorithm that achieves near perfect\nreconstructions of photos. Rather than relying on encoder- or\noptimization-based methods to find an inverse mapping on a fixed generator\n$G(\\cdot)$, we derive an approach to locally adjust $G(\\cdot)$ to more\noptimally represent the photos we wish to synthesize. This is done by locally\ntweaking the learned mapping $G(\\cdot)$ s.t. $\\| {\\bf x} - G({\\bf z})\n\\|<\\epsilon$, with ${\\bf x}$ the photo we wish to reproduce, ${\\bf z}$ the\nlatent vector, $\\|\\cdot\\|$ an appropriate metric, and $\\epsilon > 0$ a small\nscalar. We show that this approach can not only produce synthetic images that\nare indistinguishable from the real photos we wish to replicate, but that these\nimages are readily editable. We demonstrate the effectiveness of the derived\nalgorithm on a variety of datasets including human faces, animals, and cars,\nand discuss its importance for diversity and inclusion.",
    "descriptor": "",
    "authors": [
      "Qianli Feng",
      "Viraj Shah",
      "Raghudeep Gadde",
      "Pietro Perona",
      "Aleix Martinez"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.11833"
  },
  {
    "id": "arXiv:2202.11836",
    "title": "Sky Computing: Accelerating Geo-distributed Computing in Federated  Learning",
    "abstract": "Federated learning is proposed by Google to safeguard data privacy through\ntraining models locally on users' devices. However, with deep learning models\ngrowing in size to achieve better results, it becomes increasingly difficult to\naccommodate the whole model on one single device. Thus, model parallelism is\nthen used to divide the model weights among several devices. With this logic,\nthe approach currently used evenly allocates weights among devices. However, in\nreality, a computation bottleneck may occur resulting from variant computing\npower of different users' devices. To address this problem, load balancing is\nneeded to allocate the model weights based on the computational capability of\nthe device. In this paper, we proposed Sky Computing, a load-balanced model\nparallelism framework to adaptively allocate the weights to devices. Sky\nComputing outperforms the baseline method by 55% in training time when training\n160-layer BERT with 64 nodes. The source code can be found at\nhttps://github.com/hpcaitech/SkyComputing.",
    "descriptor": "",
    "authors": [
      "Jie Zhu",
      "Shenggui Li",
      "Yang You"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2202.11836"
  },
  {
    "id": "arXiv:2202.11838",
    "title": "Explanatory Paradigms in Neural Networks",
    "abstract": "In this article, we present a leap-forward expansion to the study of\nexplainability in neural networks by considering explanations as answers to\nabstract reasoning-based questions. With $P$ as the prediction from a neural\nnetwork, these questions are `Why P?', `What if not P?', and `Why P, rather\nthan Q?' for a given contrast prediction $Q$. The answers to these questions\nare observed correlations, observed counterfactuals, and observed contrastive\nexplanations respectively. Together, these explanations constitute the\nabductive reasoning scheme. We term the three explanatory schemes as observed\nexplanatory paradigms. The term observed refers to the specific case of\npost-hoc explainability, when an explanatory technique explains the decision\n$P$ after a trained neural network has made the decision $P$. The primary\nadvantage of viewing explanations through the lens of abductive reasoning-based\nquestions is that explanations can be used as reasons while making decisions.\nThe post-hoc field of explainability, that previously only justified decisions,\nbecomes active by being involved in the decision making process and providing\nlimited, but relevant and contextual interventions. The contributions of this\narticle are: ($i$) realizing explanations as reasoning paradigms, ($ii$)\nproviding a probabilistic definition of observed explanations and their\ncompleteness, ($iii$) creating a taxonomy for evaluation of explanations, and\n($iv$) positioning gradient-based complete explanainability's replicability and\nreproducibility across multiple applications and data modalities, ($v$) code\nrepositories, publicly available at\nhttps://github.com/olivesgatech/Explanatory-Paradigms.",
    "descriptor": "\nComments: To be published in Signal Processing Magazine\n",
    "authors": [
      "Ghassan AlRegib",
      "Mohit Prabhushankar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.11838"
  },
  {
    "id": "arXiv:2202.11840",
    "title": "Scalpel: The Python Static Analysis Framework",
    "abstract": "Despite being the most popular programming language, Python has not yet\nreceived enough attention from the community. To the best of our knowledge,\nthere is no general static analysis framework proposed to facilitate the\nimplementation of dedicated Python static analyzers. To fill this gap, we\ndesign and implement such a framework (named Scalpel) and make it publicly\navailable as an open-source project. The Scalpel framework has already\nintegrated a number of fundamental static analysis functions (e.g., call graph\nconstructions, control-flow graph constructions, alias analysis, etc.) that are\nready to be reused by developers to implement client applications focusing on\nstatically resolving dedicated Python problems such as detecting bugs or fixing\nvulnerabilities.",
    "descriptor": "",
    "authors": [
      "Li Li",
      "Jiawei Wang",
      "Haowei Quan"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2202.11840"
  },
  {
    "id": "arXiv:2202.11841",
    "title": "DC and SA: Robust and Efficient Hyperparameter Optimization of  Multi-subnetwork Deep Learning Models",
    "abstract": "We present two novel hyperparameter optimization strategies for optimization\nof deep learning models with a modular architecture constructed of multiple\nsubnetworks. As complex networks with multiple subnetworks become more\nfrequently applied in machine learning, hyperparameter optimization methods are\nrequired to efficiently optimize their hyperparameters. Existing hyperparameter\nsearches are general, and can be used to optimize such networks, however, by\nexploiting the multi-subnetwork architecture, these searches can be sped up\nsubstantially. The proposed methods offer faster convergence to a\nbetter-performing final model. To demonstrate this, we propose 2 independent\napproaches to enhance these prior algorithms: 1) a divide-and-conquer approach,\nin which the best subnetworks of top-performing models are combined, allowing\nfor more rapid sampling of the hyperparameter search space. 2) A subnetwork\nadaptive approach that distributes computational resources based on the\nimportance of each subnetwork, allowing more intelligent resource allocation.\nThese approaches can be flexibily applied to many hyperparameter optimization\nalgorithms. To illustrate this, we combine our approaches with the\ncommonly-used Bayesian optimization method. Our approaches are then tested\nagainst both synthetic examples and real-world examples and applied to multiple\nnetwork types including convolutional neural networks and dense feed forward\nneural networks. Our approaches show an increased optimization efficiency of up\nto 23.62x, and a final performance boost of up to 3.5% accuracy for\nclassification and 4.4 MSE for regression, when compared to comparable BO\napproach.",
    "descriptor": "",
    "authors": [
      "Alex H. Treacher",
      "Albert Montillo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.11841"
  },
  {
    "id": "arXiv:2202.11844",
    "title": "First is Better Than Last for Training Data Influence",
    "abstract": "The ability to identify influential training examples enables us to debug\ntraining data and explain model behavior. Existing techniques are based on the\nflow of influence through the model parameters. For large models in NLP\napplications, it is often computationally infeasible to study this flow through\nall model parameters, therefore techniques usually pick the last layer of\nweights. Our first observation is that for classification problems, the last\nlayer is reductive and does not encode sufficient input level information.\nDeleting influential examples, according to this measure, typically does not\nchange the model's behavior much. We propose a technique called TracIn-WE that\nmodifies a method called TracIn to operate on the word embedding layer instead\nof the last layer. This could potentially have the opposite concern, that the\nword embedding layer does not encode sufficient high level information.\nHowever, we find that gradients (unlike embeddings) do not suffer from this,\npossibly because they chain through higher layers. We show that TracIn-WE\nsignificantly outperforms other data influence methods applied on the last\nlayer by 4-10 times on the case deletion evaluation on three language\nclassification tasks. In addition, TracIn-WE can produce scores not just at the\ntraining data level, but at the word training data level, a further aid in\ndebugging.",
    "descriptor": "",
    "authors": [
      "Chih-Kuan Yeh",
      "Ankur Taly",
      "Mukund Sundararajan",
      "Frederick Liu",
      "Pradeep Ravikumar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2202.11844"
  },
  {
    "id": "arXiv:2202.11847",
    "title": "CAISE: Conversational Agent for Image Search and Editing",
    "abstract": "Demand for image editing has been increasing as users' desire for expression\nis also increasing. However, for most users, image editing tools are not easy\nto use since the tools require certain expertise in photo effects and have\ncomplex interfaces. Hence, users might need someone to help edit their images,\nbut having a personal dedicated human assistant for every user is impossible to\nscale. For that reason, an automated assistant system for image editing is\ndesirable. Additionally, users want more image sources for diverse image\nediting works, and integrating an image search functionality into the editing\ntool is a potential remedy for this demand. Thus, we propose a dataset of an\nautomated Conversational Agent for Image Search and Editing (CAISE). To our\nknowledge, this is the first dataset that provides conversational image search\nand editing annotations, where the agent holds a grounded conversation with\nusers and helps them to search and edit images according to their requests. To\nbuild such a system, we first collect image search and editing conversations\nbetween pairs of annotators. The assistant-annotators are equipped with a\ncustomized image search and editing tool to address the requests from the\nuser-annotators. The functions that the assistant-annotators conduct with the\ntool are recorded as executable commands, allowing the trained system to be\nuseful for real-world application execution. We also introduce a\ngenerator-extractor baseline model for this task, which can adaptively select\nthe source of the next token (i.e., from the vocabulary or from textual/visual\ncontexts) for the executable command. This serves as a strong starting point\nwhile still leaving a large human-machine performance gap for useful future\nwork. Our code and dataset are publicly available at:\nhttps://github.com/hyounghk/CAISE",
    "descriptor": "\nComments: AAAI 2022 (11 pages)\n",
    "authors": [
      "Hyounghun Kim",
      "Doo Soon Kim",
      "Seunghyun Yoon",
      "Franck Dernoncourt",
      "Trung Bui",
      "Mohit Bansal"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.11847"
  },
  {
    "id": "arXiv:2202.11850",
    "title": "Robust Federated Learning with Connectivity Failures: A  Semi-Decentralized Framework with Collaborative Relaying",
    "abstract": "Intermittent client connectivity is one of the major challenges in\ncentralized federated edge learning frameworks. Intermittently failing uplinks\nto the central parameter server (PS) can induce a large generalization gap in\nperformance especially when the data distribution among the clients exhibits\nheterogeneity. In this work, to mitigate communication blockages between\nclients and the central PS, we introduce the concept of knowledge relaying\nwherein the successfully participating clients collaborate in relaying their\nneighbors' local updates to a central parameter server (PS) in order to boost\nthe participation of clients with intermittently failing connectivity. We\npropose a collaborative relaying based semi-decentralized federated edge\nlearning framework where at every communication round each client first\ncomputes a local consensus of the updates from its neighboring clients and\neventually transmits a weighted average of its own update and those of its\nneighbors to the PS. We appropriately optimize these averaging weights to\nreduce the variance of the global update at the PS while ensuring that the\nglobal update is unbiased, consequently improving the convergence rate.\nFinally, by conducting experiments on CIFAR-10 dataset we validate our\ntheoretical results and demonstrate that our proposed scheme is superior to\nFederated averaging benchmark especially when data distribution among clients\nis non-iid.",
    "descriptor": "\nComments: 29 pages, 6 figures\n",
    "authors": [
      "Michal Yemini",
      "Rajarshi Saha",
      "Emre Ozfatura",
      "Deniz G\u00fcnd\u00fcz",
      "Andrea J. Goldsmith"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2202.11850"
  },
  {
    "id": "arXiv:2202.11853",
    "title": "Attainability and Optimality: The Equalized Odds Fairness Revisited",
    "abstract": "Fairness of machine learning algorithms has been of increasing interest. In\norder to suppress or eliminate discrimination in prediction, various notions as\nwell as approaches have been proposed to impose fairness. Given a notion of\nfairness, an essential problem is then whether or not it can always be\nattained, even if with an unlimited amount of data. This issue is, however, not\nwell addressed yet. In this paper, focusing on the Equalized Odds notion of\nfairness, we consider the attainability of this criterion and, furthermore, if\nit is attainable, the optimality of the prediction performance under various\nsettings. In particular, for prediction performed by a deterministic function\nof input features, we give conditions under which Equalized Odds can hold true;\nif the stochastic prediction is acceptable, we show that under mild\nassumptions, fair predictors can always be derived. For classification, we\nfurther prove that compared to enforcing fairness by post-processing, one can\nalways benefit from exploiting all available features during training and get\npotentially better prediction performance while remaining fair. Moreover, while\nstochastic prediction can attain Equalized Odds with theoretical guarantees, we\nalso discuss its limitation and potential negative social impacts.",
    "descriptor": "",
    "authors": [
      "Zeyu Tang",
      "Kun Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.11853"
  },
  {
    "id": "arXiv:2202.11855",
    "title": "Learning Multi-Object Dynamics with Compositional Neural Radiance Fields",
    "abstract": "We present a method to learn compositional predictive models from image\nobservations based on implicit object encoders, Neural Radiance Fields (NeRFs),\nand graph neural networks. A central question in learning dynamic models from\nsensor observations is on which representations predictions should be\nperformed. NeRFs have become a popular choice for representing scenes due to\ntheir strong 3D prior. However, most NeRF approaches are trained on a single\nscene, representing the whole scene with a global model, making generalization\nto novel scenes, containing different numbers of objects, challenging. Instead,\nwe present a compositional, object-centric auto-encoder framework that maps\nmultiple views of the scene to a \\emph{set} of latent vectors representing each\nobject separately. The latent vectors parameterize individual NeRF models from\nwhich the scene can be reconstructed and rendered from novel viewpoints. We\ntrain a graph neural network dynamics model in the latent space to achieve\ncompositionality for dynamics prediction. A key feature of our approach is that\nthe learned 3D information of the scene through the NeRF model enables us to\nincorporate structural priors in learning the dynamics models, making long-term\npredictions more stable. The model can further be used to synthesize new scenes\nfrom individual object observations. For planning, we utilize RRTs in the\nlearned latent space, where we can exploit our model and the implicit object\nencoder to make sampling the latent space informative and more efficient. In\nthe experiments, we show that the model outperforms several baselines on a\npushing task containing many objects. Video:\nhttps://dannydriess.github.io/compnerfdyn/",
    "descriptor": "",
    "authors": [
      "Danny Driess",
      "Zhiao Huang",
      "Yunzhu Li",
      "Russ Tedrake",
      "Marc Toussaint"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.11855"
  },
  {
    "id": "arXiv:2202.11857",
    "title": "Complexity Results on Untangling Planar Rectilinear Red-Blue Matchings",
    "abstract": "Given a rectilinear matching between n red points and n blue points in the\nplane, we consider the problem of obtaining a crossing-free matching through\nflip operations that replace two crossing segments by two non-crossing ones. We\nfirst show that (i) it is NP-hard to alpha-approximate the shortest flip\nsequence, for any constant alpha. Second, we show that when the red points are\ncolinear, (ii) given a matching, a flip sequence of length at most n(n-1)/2\nalways exists and (iii) the number of flips in any sequence never exceeds\n(n(n-1)/2) (n+4)/6. Finally, we present (iv) a lower bounding flip sequence\nwith roughly 1.5 n(n-1)/2 flips, which disproves the conjecture that n(n-1)/2,\nreached in the convex case, is the maximum. The last three results, based on\nnovel analyses, improve the constants of state-of-the-art bounds.",
    "descriptor": "\nComments: 24 pages, 27 figures, accepted at EuroCG 2022\n",
    "authors": [
      "Arun Kumar Das",
      "Sandip Das",
      "Guilherme D. da Fonseca",
      "Yan Gerard",
      "Bastien Rivier"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2202.11857"
  },
  {
    "id": "arXiv:2202.11860",
    "title": "Robust Transmission Design for RIS-assisted Secure Multiuser  Communication Systems in the Presence of Hardware Impairments",
    "abstract": "This paper investigates reconfigurable intelligent surface (RIS)-assisted\nsecure multiuser communication systems subject to hardware impairments (HIs).\nWe jointly optimize the beamforming vectors at the base station (BS) and the\nphase shifts of the reflecting elements at the RIS so as to maximize the\nweighted minimum secrecy rate (WMSR), subject to both transmission power\nconstraints at the BS and unit-modulus constraints at the RIS. To address the\nformulated optimization problem, we first decouple it into two tractable\nsubproblems and then use the block coordinate descent (BCD) method to\nalternately optimize the subproblems. Two different methods are proposed to\nsolve the two obtained subproblems. The first method transforms each subproblem\ninto a second order cone programming (SOCP) problem, which can be directly\nsolved using CVX. The second method leverages the Minorization- Maximization\n(MM) algorithm. Specifically, we first derive a concave approximation function,\nwhich is a lower bound of the original objective function, and then the two\nsubproblems are transformed into two simple surrogate problems with closedform\nsolutions. Simulation results verify the performance gains of the proposed\nrobust transmission method over existing nonrobust designs. In addition, the MM\nalgorithm is shown to have much lower complexity than the SOCP-based algorithm.",
    "descriptor": "\nComments: Submitted to IEEE journal. Keywords: Reconfigurable intelligent surface (RIS), intelligent reflecting surface (IRS)\n",
    "authors": [
      "Zhangjie Peng",
      "Ruisong Weng",
      "Cunhua Pan",
      "Gui Zhou",
      "Marco Di Renzo",
      "A. Lee Swindlehurst"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.11860"
  },
  {
    "id": "arXiv:2202.11861",
    "title": "Deploying Static Analysis",
    "abstract": "Static source code analysis is a powerful tool for finding and fixing bugs\nwhen deployed properly; it is, however, all too easy to deploy it in a way that\nlooks good superficially, but which misses important defects, shows many false\npositives, and brings the tool into disrepute. This article is a guide to the\nprocess of deploying a static analysis tool in a large organization while\navoiding the worst organizational and technical pitfalls. My main point is the\nimportance of concentrating on the main goal of getting bugs fixed, against all\nthe competing lesser goals which will arise during the process.",
    "descriptor": "\nComments: The original unabridged version (with footnotes) of the Dr Dobb's Journal August 2012 cover story\n",
    "authors": [
      "Flash Sheridan"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2202.11861"
  },
  {
    "id": "arXiv:2202.11862",
    "title": "Loss as the Inconsistency of a Probabilistic Dependency Graph: Choose  Your Model, Not Your Loss Function",
    "abstract": "In a world blessed with a great diversity of loss functions, we argue that\nthat choice between them is not a matter of taste or pragmatics, but of model.\nProbabilistic depencency graphs (PDGs) are probabilistic models that come\nequipped with a measure of \"inconsistency\". We prove that many standard loss\nfunctions arise as the inconsistency of a natural PDG describing the\nappropriate scenario, and use the same approach to justify a well-known\nconnection between regularizers and priors. We also show that the PDG\ninconsistency captures a large class of statistical divergences, and detail\nbenefits of thinking of them in this way, including an intuitive visual\nlanguage for deriving inequalities between them. In variational inference, we\nfind that the ELBO, a somewhat opaque objective for latent variable models, and\nvariants of it arise for free out of uncontroversial modeling assumptions -- as\ndo simple graphical proofs of their corresponding bounds. Finally, we observe\nthat inconsistency becomes the log partition function (free energy) in the\nsetting where PDGs are factor graphs.",
    "descriptor": "\nComments: to appear in AISTATS22\n",
    "authors": [
      "Oliver E Richardson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.11862"
  },
  {
    "id": "arXiv:2202.11864",
    "title": "Some Stylometric Remarks on Ovid's Heroides and the Epistula Sapphus",
    "abstract": "This article aims to contribute to two well-worn areas of debate in classical\nLatin philology, relating to Ovid's Heroides. The first is the question of the\nauthenticity (and, to a lesser extent the correct position) of the letter\nplaced fifteenth by almost every editor -- the so-called Epistula Sapphus\n(henceforth ES). The secondary question, although perhaps now less fervently\ndebated, is the authenticity of the 'Double Heroides', placed by those who\naccept them as letters 16-21. I employ a variety of methods drawn from the\ndomain of computational stylometry to consider the poetics and the\nlexico-grammatical features of these elegiac poems in the broader context of a\ncorpus of 'shorter' (from 20 to 546 lines) elegiac works from five authors (266\npoems in all) comprising more or less all of the non-fragmentary classical\ncorpus. Based on a variety of techniques, every measure gives clear indication\nthat the poetic style of the Heroides is Ovidian, but distinctive; they can be\naccurately isolated from Ovid more broadly. The Single and Double Heroides\nsplit into two clear groups, with the ES grouped consistently with the single\nletters. Furthermore, by comparing the style of the letters with the 'early'\n(although there are complications in this label) works of the Amores and the\nlate works of the Ex Ponto, the evidence supports sequential composition --\nmeaning that the ES is correctly placed -- and, further, supports the growing\nconsensus that the double letters were composed significantly later, in exile.",
    "descriptor": "",
    "authors": [
      "Ben Nagy"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.11864"
  },
  {
    "id": "arXiv:2202.11865",
    "title": "Using calibrator to improve robustness in Machine Reading Comprehension",
    "abstract": "Machine Reading Comprehension(MRC) has achieved a remarkable result since\nsome powerful models, such as BERT, are proposed. However, these models are not\nrobust enough and vulnerable to adversarial input perturbation and\ngeneralization examples. Some works tried to improve the performance on\nspecific types of data by adding some related examples into training data while\nit leads to degradation on the original dataset, because the shift of data\ndistribution makes the answer ranking based on the softmax probability of model\nunreliable. In this paper, we propose a method to improve the robustness by\nusing a calibrator as the post-hoc reranker, which is implemented based on\nXGBoost model. The calibrator combines both manual features and representation\nlearning features to rerank candidate results. Experimental results on\nadversarial datasets show that our model can achieve performance improvement by\nmore than 10\\% and also make improvement on the original and generalization\ndatasets.",
    "descriptor": "",
    "authors": [
      "Jing Jin",
      "Houfeng Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.11865"
  },
  {
    "id": "arXiv:2202.11867",
    "title": "Joint Program Partitioning and Resource Allocation for Completion Time  Minimization in Multi-MEC Systems",
    "abstract": "This paper considers a practical mobile edge computing (MEC) system, where\nedge server does not pre-install the program required to perform user offloaded\ncomputing tasks. A partial program offloading (PPO) scheme is proposed, which\ncan divide a user program into two parts, where the first part is executed by\nthe user itself and the second part is transferred to an edge server for remote\nexecution. However, the execution of the latter part requires the results of\nthe previous part (called intermediate result) as the input. We aim to minimize\nthe overall time consumption of a multi-server MEC system to complete all user\noffloaded tasks. It is modeled as a mixed integer nonlinear programming (MINLP)\nproblem which considers user-and-server association, program partitioning, and\ncommunication resource allocation in a joint manner. An effective algorithm is\ndeveloped to solve the problem by exploiting its structural features. First,\nthe task completion time of a single server is minimized given the computing\nworkload and available resource. Then, the working time of the edge servers are\nbalanced by updating user-and-server association and communication resource\nallocation. Numerical results show that significant performance improvement can\nbe achieved by the proposed scheme.",
    "descriptor": "",
    "authors": [
      "Taizhou Yi",
      "Guopeng Zhang",
      "Kezhi Wang",
      "Kun Yang"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2202.11867"
  },
  {
    "id": "arXiv:2202.11868",
    "title": "CG-SSD: Corner Guided Single Stage 3D Object Detection from LiDAR Point  Cloud",
    "abstract": "At present, the anchor-based or anchor-free models that use LiDAR point\nclouds for 3D object detection use the center assigner strategy to infer the 3D\nbounding boxes. However, in a real world scene, the LiDAR can only acquire a\nlimited object surface point clouds, but the center point of the object does\nnot exist. Obtaining the object by aggregating the incomplete surface point\nclouds will bring a loss of accuracy in direction and dimension estimation. To\naddress this problem, we propose a corner-guided anchor-free single-stage 3D\nobject detection model (CG-SSD ).Firstly, 3D sparse convolution backbone\nnetwork composed of residual layers and sub-manifold sparse convolutional\nlayers are used to construct bird's eye view (BEV) features for further deeper\nfeature mining by a lite U-shaped network; Secondly, a novel corner-guided\nauxiliary module (CGAM) is proposed to incorporate corner supervision signals\ninto the neural network. CGAM is explicitly designed and trained to detect\npartially visible and invisible corners to obtains a more accurate object\nfeature representation, especially for small or partial occluded objects;\nFinally, the deep features from both the backbone networks and CGAM module are\nconcatenated and fed into the head module to predict the classification and 3D\nbounding boxes of the objects in the scene. The experiments demonstrate CG-SSD\nachieves the state-of-art performance on the ONCE benchmark for supervised 3D\nobject detection using single frame point cloud data, with 62.77%mAP.\nAdditionally, the experiments on ONCE and Waymo Open Dataset show that CGAM can\nbe extended to most anchor-based models which use the BEV feature to detect\nobjects, as a plug-in and bring +1.17%-+14.27%AP improvement.",
    "descriptor": "\nComments: 27 pages\n",
    "authors": [
      "Ruiqi Ma",
      "Chi Chen",
      "Bisheng Yang",
      "Deren Li",
      "Haiping Wang",
      "Yangzi Cong",
      "Zongtian Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.11868"
  },
  {
    "id": "arXiv:2202.11871",
    "title": "No-Regret Learning in Games is Turing Complete",
    "abstract": "Games are natural models for multi-agent machine learning settings, such as\ngenerative adversarial networks (GANs). The desirable outcomes from algorithmic\ninteractions in these games are encoded as game theoretic equilibrium concepts,\ne.g. Nash and coarse correlated equilibria. As directly computing an\nequilibrium is typically impractical, one often aims to design learning\nalgorithms that iteratively converge to equilibria. A growing body of negative\nresults casts doubt on this goal, from non-convergence to chaotic and even\narbitrary behaviour. In this paper we add a strong negative result to this\nlist: learning in games is Turing complete. Specifically, we prove Turing\ncompleteness of the replicator dynamic on matrix games, one of the simplest\npossible settings. Our results imply the undecicability of reachability\nproblems for learning algorithms in games, a special case of which is\ndetermining equilibrium convergence.",
    "descriptor": "\nComments: 18 pages, 1 figure\n",
    "authors": [
      "Gabriel P. Andrade",
      "Rafael Frongillo",
      "Georgios Piliouras"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2202.11871"
  },
  {
    "id": "arXiv:2202.11877",
    "title": "A Unified Framework for Campaign Performance Forecasting in Online  Display Advertising",
    "abstract": "Advertisers usually enjoy the flexibility to choose criteria like target\naudience, geographic area and bid price when planning an campaign for online\ndisplay advertising, while they lack forecast information on campaign\nperformance to optimize delivery strategies in advance, resulting in a waste of\nlabour and budget for feedback adjustments. In this paper, we aim to forecast\nkey performance indicators for new campaigns given any certain criteria.\nInterpretable and accurate results could enable advertisers to manage and\noptimize their campaign criteria. There are several challenges for this very\ntask. First, platforms usually offer advertisers various criteria when they\nplan an advertising campaign, it is difficult to estimate campaign performance\nunifiedly because of the great difference among bidding types. Furthermore,\ncomplex strategies applied in bidding system bring great fluctuation on\ncampaign performance, making estimation accuracy an extremely tough problem. To\naddress above challenges, we propose a novel Campaign Performance Forecasting\nframework, which firstly reproduces campaign performance on historical logs\nunder various bidding types with a unified replay algorithm, in which essential\nauction processes like match and rank are replayed, ensuring the\ninterpretability on forecast results. Then, we innovatively introduce a\nmulti-task learning method to calibrate the deviation of estimation brought by\nhard-to-reproduce bidding strategies in replay. The method captures mixture\ncalibration patterns among related forecast indicators to map the estimated\nresults to the true ones, improving both accuracy and efficiency significantly.\nExperiment results on a dataset from Taobao.com demonstrate that the proposed\nframework significantly outperforms other baselines by a large margin, and an\nonline A/B test verifies its effectiveness in the real world.",
    "descriptor": "",
    "authors": [
      "Jun Chen",
      "Cheng Chen",
      "Huayue Zhang",
      "Qing Tan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.11877"
  },
  {
    "id": "arXiv:2202.11878",
    "title": "New Benchmark for Household Garbage Image Recognition",
    "abstract": "Household garbage images are usually faced with complex backgrounds, variable\nilluminations, diverse angles, and changeable shapes, which bring a great\ndifficulty in garbage image classification. Due to the ability to discover\nproblem-specific features, deep learning and especially convolutional neural\nnetworks (CNNs) have been successfully and widely used for image representation\nlearning. However, available and stable household garbage datasets are\ninsufficient, which seriously limits the development of research and\napplication. Besides, the state of the art in the field of garbage image\nclassification is not entirely clear. To solve this problem, in this study, we\nbuilt a new open benchmark dataset for household garbage image classification\nby simulating different lightings, backgrounds, angles, and shapes. This\ndataset is named 30 Classes of Household Garbage Images (HGI-30), which\ncontains 18,000 images of 30 household garbage classes. The publicly available\nHGI-30 dataset allows researchers to develop accurate and robust methods for\nhousehold garbage recognition. We also conducted experiments and performance\nanalysis of the state-of-the-art deep CNN methods on HGI-30, which serves as\nbaseline results on this benchmark.",
    "descriptor": "",
    "authors": [
      "Zhize Wu",
      "Huanyi Li",
      "Xiaofeng Wang",
      "Zijun Wu",
      "Le Zou",
      "Lixiang Xu",
      "Ming Tan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.11878"
  },
  {
    "id": "arXiv:2202.11879",
    "title": "Positive Trigonometric Polynomials on the Stability of Spatially  Interconnected Systems",
    "abstract": "This paper is devoted to the stability analysis of spatially interconnected\nsystems (SISs) via the sum-of-squares (SOS) decomposition of positive\ntrigonometric polynomials. For each spatial direction of SISs, three types of\ninterconnected structures are considered. Inspired by the idea of rational\nparameterization and robust stabilizability function, necessary and sufficient\nconditions are derived for establishing the stability of SISs with two\ndifferent combined topologies respectively. For these results, the primary\nissue concerns the global or local positivity of trigonometric polynomials. SOS\ndecomposition and generalized trace parameterization of positive trigonometric\npolynomials are utilized so that the addressed problems can be quantified by\ntwo semidefinite programs (SDPs). The proposed methods are applicable to all\npossible interconnected structures due to the assumption of spatial\nreversibility. Numerical examples are given to illustrate the efficiency of the\nderived theoretical results.",
    "descriptor": "",
    "authors": [
      "Xiaokai Zhai"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.11879"
  },
  {
    "id": "arXiv:2202.11880",
    "title": "On Nash-Stackelberg-Nash Games under Decision-Dependent Uncertainties:  Model and Equilibrium",
    "abstract": "In this paper, we discuss a class of two-stage hierarchical games with\nmultiple leaders and followers, which is called Nash-Stackelberg-Nash (N-S-N)\ngames. Particularly, we consider N-S-N games under decision-dependent\nuncertainties (DDUs). DDUs refer to the uncertainties that are affected by the\nstrategies of decision-makers and have been rarely addressed in game\nequilibrium analysis. In this paper, we first formulate the N-S-N games with\nDDUs of complete ignorance, where the interactions between the players and DDUs\nare characterized by uncertainty sets that depend parametrically on the\nplayers' strategies. Then, a rigorous definition for the equilibrium of the\ngame is established by consolidating generalized Nash equilibrium and\nPareto-Nash equilibrium. Afterward, we prove the existence of the equilibrium\nof N-S-N games under DDUs by applying Kakutani's fixed-point theorem. Finally,\nan illustrative example is provided to show the impact of DDUs on the\nequilibrium of N-S-N games.",
    "descriptor": "",
    "authors": [
      "Yunfan Zhang",
      "Feng Liu",
      "Zhaojian Wang",
      "Yue Chen",
      "Shuanglei Feng",
      "Qiuwei Wu",
      "Yunhe Hou"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.11880"
  },
  {
    "id": "arXiv:2202.11884",
    "title": "M2I: From Factored Marginal Trajectory Prediction to Interactive  Prediction",
    "abstract": "Predicting future motions of road participants is an important task for\ndriving autonomously in urban scenes. Existing models excel at predicting\nmarginal trajectories for single agents, yet it remains an open question to\njointly predict scene compliant trajectories over multiple agents. The\nchallenge is due to exponentially increasing prediction space as a function of\nthe number of agents. In this work, we exploit the underlying relations between\ninteracting agents and decouple the joint prediction problem into marginal\nprediction problems. Our proposed approach M2I first classifies interacting\nagents as pairs of influencers and reactors, and then leverages a marginal\nprediction model and a conditional prediction model to predict trajectories for\nthe influencers and reactors, respectively. The predictions from interacting\nagents are combined and selected according to their joint likelihoods.\nExperiments show that our simple but effective approach achieves\nstate-of-the-art performance on the Waymo Open Motion Dataset interactive\nprediction benchmark.",
    "descriptor": "\nComments: 14 pages, 7 figures, 3 tables. Code available soon\n",
    "authors": [
      "Qiao Sun",
      "Xin Huang",
      "Junru Gu",
      "Brian C. Williams",
      "Hang Zhao"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.11884"
  },
  {
    "id": "arXiv:2202.11885",
    "title": "A Partition-and-Merge Algorithm for Solving the Steiner Tree Problem in  Large Graphs",
    "abstract": "The Steiner tree problem, which asks for a minimum weighted tree spanning a\ngiven set of terminal vertices in a given graph, is a classic problem arising\nin numerous practical applications. Many algorithms about this problem emerged\nin the past decade, especially presented in the 11th DIMACS Challenge in 2014\nand the 3rd PACE Competition in 2018. In this paper, we present a novel\npartition-and-merge algorithm for effectively solving this NP-hard problem in\nlarge graphs. The algorithm first breaks the input graph into small fragments\nand then gradually builds up the graph in a level-by-level manner. Intuitively,\nthe method aggregates information that is found by local search at each level\ninto the final graph. We assess the algorithm on a wide range of benchmark\ninstances, showing that the algorithm outperforms the winners of DIMACS and\nPACE challenges on large instances and competes favorably with them on small or\nmiddle-sized instances.",
    "descriptor": "",
    "authors": [
      "Xinyu Wu",
      "Yi Zhou",
      "Jin-Kao Hao",
      "Zhang-Hua Fu"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2202.11885"
  },
  {
    "id": "arXiv:2202.11890",
    "title": "Multirate Partitioned Runge-Kutta Methods for Coupled Navier-Stokes  Equations",
    "abstract": "Earth system models are complex integrated models of atmosphere, ocean, sea\nice, and land surface. Coupling the components can be a significant challenge\ndue to the difference in physics, temporal, and spatial scales. This study\nexplores new coupling strategies for the fluid-fluid interaction problem based\non multirate partitioned Runge-Kutta methods. We consider compressible\nNavier-Stokes equations with gravity coupled through a rigid-lid interface. Our\nlarge-scale numerical experiments reveal that multirate partitioned Runge-Kutta\ncoupling schemes (1) can conserve total mass; (2) have second-order accuracy in\ntime; and (3) provide favorable strong- and weak-scaling performance on modern\ncomputing architectures. We also show that the speedup factors of multirate\npartitioned Runge-Kutta methods match theoretical expectations over their base\n(single-rate) method.",
    "descriptor": "\nComments: 11 figures, 9 tables, 23 pages\n",
    "authors": [
      "Shinhoo Kang",
      "Alp Dener",
      "Aidan Hamilton",
      "Hong Zhang",
      "Emil M. Constantinescu",
      "Robert L. Jacob"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2202.11890"
  },
  {
    "id": "arXiv:2202.11891",
    "title": "HMD-EgoPose: Head-Mounted Display-Based Egocentric Marker-Less Tool and  Hand Pose Estimation for Augmented Surgical Guidance",
    "abstract": "The success or failure of modern computer-assisted surgery procedures hinges\non the precise six-degree-of-freedom (6DoF) position and orientation (pose)\nestimation of tracked instruments and tissue. In this paper, we present\nHMD-EgoPose, a single-shot learning-based approach to hand and object pose\nestimation and demonstrate state-of-the-art performance on a benchmark dataset\nfor monocular red-green-blue (RGB) 6DoF marker-less hand and surgical\ninstrument pose tracking. Further, we reveal the capacity of our HMD-EgoPose\nframework for 6DoF near real-time pose estimation on a commercially available\noptical see-through head-mounted display (OST-HMD) through a low-latency\nstreaming approach. Our framework utilized an efficient convolutional neural\nnetwork (CNN) backbone for multi-scale feature extraction and a set of\nsubnetworks to jointly learn the 6DoF pose representation of the rigid surgical\ndrill instrument and the grasping orientation of the hand of a user. To make\nour approach accessible to a commercially available OST-HMD, the Microsoft\nHoloLens 2, we created a pipeline for low-latency video and data communication\nwith a high-performance computing workstation capable of optimized network\ninference. HMD-EgoPose outperformed current state-of-the-art approaches on a\nbenchmark dataset for surgical tool pose estimation, achieving an average tool\n3D vertex error of 11.0 mm on real data and furthering the progress towards a\nclinically viable marker-free tracking strategy. Through our low-latency\nstreaming approach, we achieved a round trip latency of 202.5 ms for pose\nestimation and augmented visualization of the tracked model when integrated\nwith the OST-HMD. Our single-shot learned approach was robust to occlusion and\ncomplex surfaces and improved on current state-of-the-art approaches to\nmarker-less tool and hand pose estimation.",
    "descriptor": "\nComments: 21 pages, 6 figures, 2 tables\n",
    "authors": [
      "Mitchell Doughty",
      "Nilesh R. Ghugre"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.11891"
  },
  {
    "id": "arXiv:2202.11896",
    "title": "Controlling Memorability of Face Images",
    "abstract": "Everyday, we are bombarded with many photographs of faces, whether on social\nmedia, television, or smartphones. From an evolutionary perspective, faces are\nintended to be remembered, mainly due to survival and personal relevance.\nHowever, all these faces do not have the equal opportunity to stick in our\nminds. It has been shown that memorability is an intrinsic feature of an image\nbut yet, it is largely unknown what attributes make an image more memorable. In\nthis work, we aimed to address this question by proposing a fast approach to\nmodify and control the memorability of face images. In our proposed method, we\nfirst found a hyperplane in the latent space of StyleGAN to separate high and\nlow memorable images. We then modified the image memorability (while\nmaintaining the identity and other facial features such as age, emotion, etc.)\nby moving in the positive or negative direction of this hyperplane normal\nvector. We further analyzed how different layers of the StyleGAN augmented\nlatent space contribute to face memorability. These analyses showed how each\nindividual face attribute makes an image more or less memorable. Most\nimportantly, we evaluated our proposed method for both real and synthesized\nface images. The proposed method successfully modifies and controls the\nmemorability of real human faces as well as unreal synthesized faces. Our\nproposed method can be employed in photograph editing applications for social\nmedia, learning aids, or advertisement purposes.",
    "descriptor": "",
    "authors": [
      "Mohammad Younesi",
      "Yalda Mohsenzadeh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.11896"
  },
  {
    "id": "arXiv:2202.11898",
    "title": "Improving Robustness of Convolutional Neural Networks Using Element-Wise  Activation Scaling",
    "abstract": "Recent works reveal that re-calibrating the intermediate activation of\nadversarial examples can improve the adversarial robustness of a CNN model. The\nstate of the arts [Baiet al., 2021] and [Yanet al., 2021] explores this feature\nat the channel level, i.e. the activation of a channel is uniformly scaled by a\nfactor. In this paper, we investigate the intermediate activation manipulation\nat a more fine-grained level. Instead of uniformly scaling the activation, we\nindividually adjust each element within an activation and thus propose\nElement-Wise Activation Scaling, dubbed EWAS, to improve CNNs' adversarial\nrobustness. Experimental results on ResNet-18 and WideResNet with CIFAR10 and\nSVHN show that EWAS significantly improves the robustness accuracy. Especially\nfor ResNet18 on CIFAR10, EWAS increases the adversarial accuracy by 37.65% to\n82.35% against C&W attack. EWAS is simple yet very effective in terms of\nimproving robustness. The codes are anonymously available at\nhttps://anonymous.4open.science/r/EWAS-DD64.",
    "descriptor": "",
    "authors": [
      "Zhi-Yuan Zhang",
      "Di Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.11898"
  },
  {
    "id": "arXiv:2202.11899",
    "title": "An Efficient Binary Harris Hawks Optimization based on Quantum SVM for  Cancer Classification Tasks",
    "abstract": "Cancer classification based on gene expression increases early diagnosis and\nrecovery, but high-dimensional genes with a small number of samples are a major\nchallenge. This work introduces a new hybrid quantum kernel support vector\nmachine (QKSVM) combined with a Binary Harris hawk optimization (BHHO) based\ngene selection for cancer classification on a quantum simulator. This study\naims to improve the microarray cancer prediction performance with the quantum\nkernel estimation based on the informative genes by BHHO. The feature selection\nis a critical step in large-dimensional features, and BHHO is used to select\nimportant features. The BHHO mimics the behavior of the cooperative action of\nHarris hawks in nature. The principal component analysis (PCA) is applied to\nreduce the selected genes to match the qubit numbers. After which, the quantum\ncomputer is used to estimate the kernel with the training data of the reduced\ngenes and generate the quantum kernel matrix. Moreover, the classical computer\nis used to draw the support vectors based on the quantum kernel matrix. Also,\nthe prediction stage is performed with the classical device. Finally, the\nproposed approach is applied to colon and breast microarray datasets and\nevaluated with all genes and the selected genes by BHHO. The proposed approach\nis found to enhance the overall performance with two datasets. Also, the\nproposed approach is evaluated with different quantum feature maps (kernels)\nand classical kernel (RBF).",
    "descriptor": "",
    "authors": [
      "Essam H. Houssein",
      "Zainab Abohashima",
      "Mohamed Elhoseny",
      "Waleed M. Mohamed"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.11899"
  },
  {
    "id": "arXiv:2202.11900",
    "title": "SLRNet: Semi-Supervised Semantic Segmentation Via Label Reuse for Human  Decomposition Images",
    "abstract": "Semantic segmentation is a challenging computer vision task demanding a\nsignificant amount of pixel-level annotated data. Producing such data is a\ntime-consuming and costly process, especially for domains with a scarcity of\nexperts, such as medicine or forensic anthropology. While numerous\nsemi-supervised approaches have been developed to make the most from the\nlimited labeled data and ample amount of unlabeled data, domain-specific\nreal-world datasets often have characteristics that both reduce the\neffectiveness of off-the-shelf state-of-the-art methods and also provide\nopportunities to create new methods that exploit these characteristics. We\npropose and evaluate a semi-supervised method that reuses available labels for\nunlabeled images of a dataset by exploiting existing similarities, while\ndynamically weighting the impact of these reused labels in the training\nprocess. We evaluate our method on a large dataset of human decomposition\nimages and find that our method, while conceptually simple, outperforms\nstate-of-the-art consistency and pseudo-labeling-based methods for the\nsegmentation of this dataset. This paper includes graphic content of human\ndecomposition.",
    "descriptor": "",
    "authors": [
      "Sara Mousavi",
      "Zhenning Yang",
      "Kelley Cross",
      "Dawnie Steadman",
      "Audris Mockus"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.11900"
  },
  {
    "id": "arXiv:2202.11902",
    "title": "A PTAS for Packing Hypercubes into a Knapsack",
    "abstract": "We study the d-dimensional hypercube knapsack problem where we are given a\nset of d-dimensional hypercubes with associated profits, and a knapsack which\nis a unit d-dimensional hypercube. The goal is to find an axis-aligned\nnon-overlapping packing of a subset of hypercubes such that the profit of the\npacked hypercubes is maximized. For this problem, Harren (ICALP'06) gave an\nalgorithm with an approximation ratio of (1+1/2^d+epsilon). For d=2, Jansen and\nSolis-Oba (IPCO'08) showed that the problem admits a polynomial-time\napproximation scheme (PTAS); Heydrich and Wiese (SODA'17) further improved the\nrunning time and gave an efficient polynomial-time approximation scheme\n(EPTAS). Both the results use structural properties of 2-D packing, which do\nnot generalize to higher dimensions. For d>2, it remains open to obtain a PTAS,\nand in fact, there has been no improvement since Harren's result.\nWe settle the problem by providing a PTAS. Our main technical contribution is\na structural lemma which shows that any packing of hypercubes can be converted\ninto another structured packing such that a high profitable subset of\nhypercubes is packed into a constant number of special hypercuboids, called\nV-Boxes and N-Boxes. As a side result, we give an almost optimal algorithm for\na variant of the strip packing problem in higher dimensions. This might have\napplications for other multidimensional geometric packing problems.",
    "descriptor": "",
    "authors": [
      "Klaus Jansen",
      "Arindam Khan",
      "Marvin Lira",
      "K. V. N. Sreenivas"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2202.11902"
  },
  {
    "id": "arXiv:2202.11907",
    "title": "Uncertainty-driven Planner for Exploration and Navigation",
    "abstract": "We consider the problems of exploration and point-goal navigation in\npreviously unseen environments, where the spatial complexity of indoor scenes\nand partial observability constitute these tasks challenging. We argue that\nlearning occupancy priors over indoor maps provides significant advantages\ntowards addressing these problems. To this end, we present a novel planning\nframework that first learns to generate occupancy maps beyond the field-of-view\nof the agent, and second leverages the model uncertainty over the generated\nareas to formulate path selection policies for each task of interest. For\npoint-goal navigation the policy chooses paths with an upper confidence bound\npolicy for efficient and traversable paths, while for exploration the policy\nmaximizes model uncertainty over candidate paths. We perform experiments in the\nvisually realistic environments of Matterport3D using the Habitat simulator and\ndemonstrate: 1) Improved results on exploration and map quality metrics over\ncompetitive methods, and 2) The effectiveness of our planning module when\npaired with the state-of-the-art DD-PPO method for the point-goal navigation\ntask.",
    "descriptor": "",
    "authors": [
      "Georgios Georgakis",
      "Bernadette Bucher",
      "Anton Arapin",
      "Karl Schmeckpeper",
      "Nikolai Matni",
      "Kostas Daniilidis"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.11907"
  },
  {
    "id": "arXiv:2202.11908",
    "title": "Program Synthesis for the OEIS",
    "abstract": "We present a self-learning approach to synthesize programs for integer\nsequences. Our method relies on a tree search equipped with a semantic quotient\nguided by a learned policy. Through self-learning, our implementation discovers\nin one week programs that generate the first 16 numbers of 43516 OEIS sequences\nwith sequences identical up to the 16th number counted only once.",
    "descriptor": "",
    "authors": [
      "Thibault Gauthier"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Symbolic Computation (cs.SC)"
    ],
    "url": "https://arxiv.org/abs/2202.11908"
  },
  {
    "id": "arXiv:2202.11910",
    "title": "Robust Probabilistic Time Series Forecasting",
    "abstract": "Probabilistic time series forecasting has played critical role in\ndecision-making processes due to its capability to quantify uncertainties. Deep\nforecasting models, however, could be prone to input perturbations, and the\nnotion of such perturbations, together with that of robustness, has not even\nbeen completely established in the regime of probabilistic forecasting. In this\nwork, we propose a framework for robust probabilistic time series forecasting.\nFirst, we generalize the concept of adversarial input perturbations, based on\nwhich we formulate the concept of robustness in terms of bounded Wasserstein\ndeviation. Then we extend the randomized smoothing technique to attain robust\nprobabilistic forecasters with theoretical robustness certificates against\ncertain classes of adversarial perturbations. Lastly, extensive experiments\ndemonstrate that our methods are empirically effective in enhancing the\nforecast quality under additive adversarial attacks and forecast consistency\nunder supplement of noisy observations.",
    "descriptor": "\nComments: AISTATS 2022 camera ready version\n",
    "authors": [
      "TaeHo Yoon",
      "Youngsuk Park",
      "Ernest K. Ryu",
      "Yuyang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.11910"
  },
  {
    "id": "arXiv:2202.11911",
    "title": "When Transformer Meets Robotic Grasping: Exploits Context for Efficient  Grasp Detection",
    "abstract": "In this paper, we present a transformer-based architecture, namely TF-Grasp,\nfor robotic grasp detection. The developed TF-Grasp framework has two elaborate\ndesigns making it well suitable for visual grasping tasks. The first key design\nis that we adopt the local window attention to capture local contextual\ninformation and detailed features of graspable objects. Then, we apply the\ncross window attention to model the long-term dependencies between distant\npixels. Object knowledge, environmental configuration, and relationships\nbetween different visual entities are aggregated for subsequent grasp\ndetection. The second key design is that we build a hierarchical\nencoder-decoder architecture with skip-connections, delivering shallow features\nfrom encoder to decoder to enable a multi-scale feature fusion. Due to the\npowerful attention mechanism, the TF-Grasp can simultaneously obtain the local\ninformation (i.e., the contours of objects), and model long-term connections\nsuch as the relationships between distinct visual concepts in clutter.\nExtensive computational experiments demonstrate that the TF-Grasp achieves\nsuperior results versus state-of-art grasping convolutional models and attain a\nhigher accuracy of 97.99% and 94.6% on Cornell and Jacquard grasping datasets,\nrespectively. Real-world experiments using a 7DoF Franka Emika Panda robot also\ndemonstrate its capability of grasping unseen objects in a variety of\nscenarios. The code and pre-trained models will be available at\nhttps://github.com/WangShaoSUN/grasp-transformer",
    "descriptor": "\nComments: 8 pages, 8 figures\n",
    "authors": [
      "Shaochen Wang",
      "Zhangli Zhou",
      "Zhen Kan"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.11911"
  },
  {
    "id": "arXiv:2202.11912",
    "title": "A Rigorous Study of Integrated Gradients Method and Extensions to  Internal Neuron Attributions",
    "abstract": "As the efficacy of deep learning (DL) grows, so do concerns about the lack of\ntransparency of these black-box models. Attribution methods aim to improve\ntransparency of DL models by quantifying an input feature's importance to a\nmodel's prediction. The method of Integrated gradients (IG) sets itself apart\nby claiming other methods failed to satisfy desirable axioms, while IG and\nmethods like it uniquely satisfied said axioms. This paper comments on\nfundamental aspects of IG and its applications/extensions: 1) We identify key\nunaddressed differences between DL-attribution function spaces and the\nsupporting literature's function spaces which problematize previous claims of\nIG uniqueness. We show that with the introduction of an additional axiom,\n$\\textit{non-decreasing positivity}$, the uniqueness claim can be established.\n2) We address the question of input sensitivity by identifying function spaces\nwhere the IG is/is not Lipschitz continuous in the attributed input. 3) We show\nhow axioms for single-baseline methods in IG impart analogous properties for\nmethods where the baseline is a probability distribution over the input sample\nspace. 4) We introduce a means of decomposing the IG map with respect to a\nlayer of internal neurons while simultaneously gaining internal-neuron\nattributions. Finally, we present experimental results validating the\ndecomposition and internal neuron attributions.",
    "descriptor": "",
    "authors": [
      "Daniel Lundstrom",
      "Tianjian Huang",
      "Meisam Razaviyayn"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.11912"
  },
  {
    "id": "arXiv:2202.11914",
    "title": "An Efficient Adaptive Finite Element Method for Eigenvalue Problems",
    "abstract": "The aim of this paper is to propose an efficient adaptive finite element\nmethod for eigenvalue problems based on the multilevel correction scheme and\ninverse power method. This method involves solving associated boundary value\nproblems on each adaptive partitions and very low dimensional eigenvalue\nproblems on some special meshes which are controlled by the proposed algorithm.\nSince we Hence the efficiency of solving eigenvalue problems can be improved to\nbe similar to the adaptive finite element method for the associated boundary\nvalue problems. The convergence and optimal complexity is theoretically\nverified and numerically demonstrated.",
    "descriptor": "\nComments: 33 pages, 37 figures. arXiv admin note: text overlap with arXiv:1201.2308\n",
    "authors": [
      "Qichen Hong",
      "Hehu Xie",
      "Fei Xu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.11914"
  },
  {
    "id": "arXiv:2202.11915",
    "title": "Interpolation-based Contrastive Learning for Few-Label Semi-Supervised  Learning",
    "abstract": "Semi-supervised learning (SSL) has long been proved to be an effective\ntechnique to construct powerful models with limited labels. In the existing\nliterature, consistency regularization-based methods, which force the perturbed\nsamples to have similar predictions with the original ones have attracted much\nattention for their promising accuracy. However, we observe that, the\nperformance of such methods decreases drastically when the labels get extremely\nlimited, e.g., 2 or 3 labels for each category. Our empirical study finds that\nthe main problem lies with the drifting of semantic information in the\nprocedure of data augmentation. The problem can be alleviated when enough\nsupervision is provided. However, when little guidance is available, the\nincorrect regularization would mislead the network and undermine the\nperformance of the algorithm. To tackle the problem, we (1) propose an\ninterpolation-based method to construct more reliable positive sample pairs;\n(2) design a novel contrastive loss to guide the embedding of the learned\nnetwork to change linearly between samples so as to improve the discriminative\ncapability of the network by enlarging the margin decision boundaries. Since no\ndestructive regularization is introduced, the performance of our proposed\nalgorithm is largely improved. Specifically, the proposed algorithm outperforms\nthe second best algorithm (Comatch) with 5.3% by achieving 88.73%\nclassification accuracy when only two labels are available for each class on\nthe CIFAR-10 dataset. Moreover, we further prove the generality of the proposed\nmethod by improving the performance of the existing state-of-the-art algorithms\nconsiderably with our proposed strategy.",
    "descriptor": "",
    "authors": [
      "Xihong Yang",
      "Xiaochang Hu",
      "Sihang Zhou",
      "Xinwang Liu",
      "En Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.11915"
  },
  {
    "id": "arXiv:2202.11917",
    "title": "Machine Learning for Intrusion Detection in Industrial Control Systems:  Applications, Challenges, and Recommendations",
    "abstract": "Methods from machine learning are being applied to design Industrial Control\nSystems resilient to cyber-attacks. Such methods focus on two major areas: the\ndetection of intrusions at the network-level using the information acquired\nthrough network packets, and detection of anomalies at the physical process\nlevel using data that represents the physical behavior of the system. This\nsurvey focuses on four types of methods from machine learning in use for\nintrusion and anomaly detection, namely, supervised, semi-supervised,\nunsupervised, and reinforcement learning. Literature available in the public\ndomain was carefully selected, analyzed, and placed in a 7-dimensional space\nfor ease of comparison. The survey is targeted at researchers, students, and\npractitioners. Challenges associated in using the methods and research gaps are\nidentified and recommendations are made to fill the gaps.",
    "descriptor": "",
    "authors": [
      "Muhammad Azmi Umer",
      "Khurum Nazir Junejo",
      "Muhammad Taha Jilani",
      "Aditya P. Mathur"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.11917"
  },
  {
    "id": "arXiv:2202.11918",
    "title": "Phase Continuity: Learning Derivatives of Phase Spectrum for Speech  Enhancement",
    "abstract": "Modern neural speech enhancement models usually include various forms of\nphase information in their training loss terms, either explicitly or\nimplicitly. However, these loss terms are typically designed to reduce the\ndistortion of phase spectrum values at specific frequencies, which ensures they\ndo not significantly affect the quality of the enhanced speech. In this paper,\nwe propose an effective phase reconstruction strategy for neural speech\nenhancement that can operate in noisy environments. Specifically, we introduce\na phase continuity loss that considers relative phase variations across the\ntime and frequency axes. By including this phase continuity loss in a\nstate-of-the-art neural speech enhancement system trained with reconstruction\nloss and a number of magnitude spectral losses, we show that our proposed\nmethod further improves the quality of enhanced speech signals over the\nbaseline, especially when training is done jointly with a magnitude spectrum\nloss.",
    "descriptor": "\nComments: Accepted by ICASSP 2022\n",
    "authors": [
      "Doyeon Kim",
      "Hyewon Han",
      "Hyeon-Kyeong Shin",
      "Soo-Whan Chung",
      "Hong-Goo Kang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2202.11918"
  },
  {
    "id": "arXiv:2202.11919",
    "title": "Threading the Needle of On and Off-Manifold Value Functions for Shapley  Explanations",
    "abstract": "A popular explainable AI (XAI) approach to quantify feature importance of a\ngiven model is via Shapley values. These Shapley values arose in cooperative\ngames, and hence a critical ingredient to compute these in an XAI context is a\nso-called value function, that computes the \"value\" of a subset of features,\nand which connects machine learning models to cooperative games. There are many\npossible choices for such value functions, which broadly fall into two\ncategories: on-manifold and off-manifold value functions, which take an\nobservational and an interventional viewpoint respectively. Both these classes\nhowever have their respective flaws, where on-manifold value functions violate\nkey axiomatic properties and are computationally expensive, while off-manifold\nvalue functions pay less heed to the data manifold and evaluate the model on\nregions for which it wasn't trained. Thus, there is no consensus on which class\nof value functions to use. In this paper, we show that in addition to these\nexisting issues, both classes of value functions are prone to adversarial\nmanipulations on low density regions. We formalize the desiderata of value\nfunctions that respect both the model and the data manifold in a set of axioms\nand are robust to perturbation on off-manifold regions, and show that there\nexists a unique value function that satisfies these axioms, which we term the\nJoint Baseline value function, and the resulting Shapley value the Joint\nBaseline Shapley (JBshap), and validate the effectiveness of JBshap in\nexperiments.",
    "descriptor": "\nComments: AISTATS 2022\n",
    "authors": [
      "Chih-Kuan Yeh",
      "Kuan-Yun Lee",
      "Frederick Liu",
      "Pradeep Ravikumar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2202.11919"
  },
  {
    "id": "arXiv:2202.11921",
    "title": "Auto-scaling Vision Transformers without Training",
    "abstract": "This work targets automated designing and scaling of Vision Transformers\n(ViTs). The motivation comes from two pain spots: 1) the lack of efficient and\nprincipled methods for designing and scaling ViTs; 2) the tremendous\ncomputational cost of training ViT that is much heavier than its convolution\ncounterpart. To tackle these issues, we propose As-ViT, an auto-scaling\nframework for ViTs without training, which automatically discovers and scales\nup ViTs in an efficient and principled manner. Specifically, we first design a\n\"seed\" ViT topology by leveraging a training-free search process. This\nextremely fast search is fulfilled by a comprehensive study of ViT's network\ncomplexity, yielding a strong Kendall-tau correlation with ground-truth\naccuracies. Second, starting from the \"seed\" topology, we automate the scaling\nrule for ViTs by growing widths/depths to different ViT layers. This results in\na series of architectures with different numbers of parameters in a single run.\nFinally, based on the observation that ViTs can tolerate coarse tokenization in\nearly training stages, we propose a progressive tokenization strategy to train\nViTs faster and cheaper. As a unified framework, As-ViT achieves strong\nperformance on classification (83.5% top1 on ImageNet-1k) and detection (52.7%\nmAP on COCO) without any manual crafting nor scaling of ViT architectures: the\nend-to-end model design and scaling process cost only 12 hours on one V100 GPU.\nOur code is available at https://github.com/VITA-Group/AsViT.",
    "descriptor": "\nComments: ICLR 2022 accepted\n",
    "authors": [
      "Wuyang Chen",
      "Wei Huang",
      "Xianzhi Du",
      "Xiaodan Song",
      "Zhangyang Wang",
      "Denny Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.11921"
  },
  {
    "id": "arXiv:2202.11923",
    "title": "Welcome to the Modern World of Pronouns: Identity-Inclusive Natural  Language Processing beyond Gender",
    "abstract": "The world of pronouns is changing. From a closed class of words with few\nmembers to a much more open set of terms to reflect identities. However,\nNatural Language Processing (NLP) is barely reflecting this linguistic shift,\neven though recent work outlined the harms of gender-exclusive language\ntechnology. Particularly problematic is the current modeling 3rd person\npronouns, as it largely ignores various phenomena like neopronouns, i.e.,\npronoun sets that are novel and not (yet) widely established. This omission\ncontributes to the discrimination of marginalized and underrepresented groups,\ne.g., non-binary individuals. However, other identity-expression phenomena\nbeyond gender are also ignored by current NLP technology. In this paper, we\nprovide an overview of 3rd person pronoun issues for NLP. Based on our\nobservations and ethical considerations, we define a series of desiderata for\nmodeling pronouns in language technology. We evaluate existing and novel\nmodeling approaches w.r.t. these desiderata qualitatively, and quantify the\nimpact of a more discrimination-free approach on established benchmark data.",
    "descriptor": "",
    "authors": [
      "Anne Lauscher",
      "Archie Crowley",
      "Dirk Hovy"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.11923"
  },
  {
    "id": "arXiv:2202.11927",
    "title": "Polynomial Kernels for Tracking Shortest Paths",
    "abstract": "Given an undirected graph $G=(V,E)$, vertices $s,t\\in V$, and an integer $k$,\nTracking Shortest Paths requires deciding whether there exists a set of $k$\nvertices $T\\subseteq V$ such that for any two distinct shortest paths between\n$s$ and $t$, say $P_1$ and $P_2$, we have $T\\cap V(P_1)\\neq T\\cap V(P_2)$. In\nthis paper, we give the first polynomial size kernel for the problem.\nSpecifically we show the existence of a kernel with $\\mathcal{O}(k^2)$ vertices\nand edges in general graphs and a kernel with $\\mathcal{O}(k)$ vertices and\nedges in planar graphs for the Tracking Paths in DAG problem. This problem\nadmits a polynomial parameter transformation to Tracking Shortest Paths, and\nthis implies a kernel with $\\mathcal{O}(k^4)$ vertices and edges for Tracking\nShortest Paths in general graphs and a kernel with $\\mathcal{O}(k^2)$ vertices\nand edges in planar graphs. Based on the above we also give a single\nexponential algorithm for Tracking Shortest Paths in planar graphs.",
    "descriptor": "",
    "authors": [
      "V\u00e1clav Bla\u017eej",
      "Pratibha Choudhary",
      "Du\u0161an Knop",
      "Jan Maty\u00e1\u0161 K\u0159i\u0161\u0165an",
      "Ond\u0159ej Such\u00fd",
      "Tom\u00e1\u0161 Valla"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2202.11927"
  },
  {
    "id": "arXiv:2202.11928",
    "title": "AutoCl : A Visual Interactive System for Automatic Deep Learning  Classifier Recommendation Based on Models Performance",
    "abstract": "Nowadays, deep learning (DL) models being increasingly applied to various\nfields, people without technical expertise and domain knowledge struggle to\nfind an appropriate model for their task. In this paper, we introduce AutoCl a\nvisual interactive recommender system aimed at helping non-experts to adopt an\nappropriate DL classifier. Our system enables users to compare the performance\nand behavior of multiple classifiers trained with various hyperparameter setups\nas well as automatically recommends a best classifier with appropriate\nhyperparameter. We compare features of AutoCl against several recent AutoML\nsystems and show that it helps non-experts better in choosing DL classifier.\nFinally, we demonstrate use cases for image classification using publicly\navailable dataset to show the capability of our system.",
    "descriptor": "\nComments: This research paper has accepted and presented in The 28th International Workshop on Frontiers of Computer Vision (IW-FCV). IW-FCV held fully virtual on February 21-22, 2022. See this https URL for details\n",
    "authors": [
      "Fuad Ahmed",
      "Rubayea Ferdows",
      "Md Rafiqul Islam",
      "Abu Raihan M. Kamal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.11928"
  },
  {
    "id": "arXiv:2202.11929",
    "title": "Word Segmentation on Discovered Phone Units with Dynamic Programming and  Self-Supervised Scoring",
    "abstract": "Recent work on unsupervised speech segmentation has used self-supervised\nmodels with a phone segmentation module and a word segmentation module that are\ntrained jointly. This paper compares this joint methodology with an older idea:\nbottom-up phone-like unit discovery is performed first, and symbolic word\nsegmentation is then performed on top of the discovered units (without\ninfluencing the lower level). I specifically describe a duration-penalized\ndynamic programming (DPDP) procedure that can be used for either phone or word\nsegmentation by changing the self-supervised scoring network that gives segment\ncosts. For phone discovery, DPDP is applied with a contrastive predictive\ncoding clustering model, while for word segmentation it is used with an\nautoencoding recurrent neural network. The two models are chained in order to\nsegment speech. This approach gives comparable word segmentation results to\nstate-of-the-art joint self-supervised models on an English benchmark. On\nFrench and Mandarin data, it outperforms previous systems on the ZeroSpeech\nbenchmarks. Analysis shows that the chained DPDP system segments shorter filler\nwords well, but longer words might require an external top-down signal.",
    "descriptor": "\nComments: 10 pages, 5 figures, 5 tables\n",
    "authors": [
      "Herman Kamper"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2202.11929"
  },
  {
    "id": "arXiv:2202.11931",
    "title": "Explore-Bench: Data Sets, Metrics and Evaluations for Frontier-based and  Deep-reinforcement-learning-based Autonomous Exploration",
    "abstract": "Autonomous exploration and mapping of unknown terrains employing single or\nmultiple robots is an essential task in mobile robotics and has therefore been\nwidely investigated. Nevertheless, given the lack of unified data sets,\nmetrics, and platforms to evaluate the exploration approaches, we develop an\nautonomous robot exploration benchmark entitled Explore-Bench. The benchmark\ninvolves various exploration scenarios and presents two types of quantitative\nmetrics to evaluate exploration efficiency and multi-robot cooperation.\nExplore-Bench is extremely useful as, recently, deep reinforcement learning\n(DRL) has been widely used for robot exploration tasks and achieved promising\nresults. However, training DRL-based approaches requires large data sets, and\nadditionally, current benchmarks rely on realistic simulators with a slow\nsimulation speed, which is not appropriate for training exploration strategies.\nHence, to support efficient DRL training and comprehensive evaluation, the\nsuggested Explore-Bench designs a 3-level platform with a unified data flow and\n$12 \\times$ speed-up that includes a grid-based simulator for fast evaluation\nand efficient training, a realistic Gazebo simulator, and a remotely accessible\nrobot testbed for high-accuracy tests in physical environments. The\npracticality of the proposed benchmark is highlighted with the application of\none DRL-based and three frontier-based exploration approaches. Furthermore, we\nanalyze the performance differences and provide some insights about the\nselection and design of exploration methods. Our benchmark is available at\nhttps://github.com/efc-robot/Explore-Bench.",
    "descriptor": "\nComments: To be published in IEEE International Conference on Robotics and Automation (ICRA), May 23-27, 2022\n",
    "authors": [
      "Yuanfan Xu",
      "Jincheng Yu",
      "Jiahao Tang",
      "Jiantao Qiu",
      "Jian Wang",
      "Yuan Shen",
      "Yu Wang",
      "Huazhong Yang"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.11931"
  },
  {
    "id": "arXiv:2202.11932",
    "title": "Collective Conditioned Reflex: A Bio-Inspired Fast Emergency Reaction  Mechanism for Designing Safe Multi-Robot Systems",
    "abstract": "A multi-robot system (MRS) is a group of coordinated robots designed to\ncooperate with each other and accomplish set tasks. Due to the uncertainties in\noperating environments, the system may encounter unexpected emergencies, such\nas unobserved obstacles, unexpectedly moving vehicles, explosions, and fires.\nAnimal groups such as bee colonies initiate collective emergency reaction\nbehaviors such as bypassing the front trees and avoiding back predators,\nsimilar to muscle conditioned reflex which organizes local muscles to avoid\nhazards in the first response without delaying passage through the central\nbrain. Inspired by this, we develop a similar collective conditioned reflex\nmechanism for multi-robot systems to respond to emergencies. In this study,\nCollective Conditioned Reflex (CCR), a bio-inspired emergency reaction\nmechanism, is developed based on animal collective behavior analysis and\nmulti-agent reinforcement learning. The algorithm uses a physical model to\ndetermine if the robots are experiencing an emergency; then, rewards for robots\ninvolved in the emergency are augmented with corresponding heuristic rewards,\nwhich evaluate emergency magnitudes and consequences and decide local robots'\nparticipation. CCR is validated on three typical emergency scenarios:\nunexpected turbulence, strong wind, and uncertain obstacle. Experimental\nresults demonstrate that CCR improves robot teams' emergency reaction\ncapability with faster reaction speed and safer trajectory adjustment compared\nwith traditional methods.",
    "descriptor": "",
    "authors": [
      "Zhenting Zhao",
      "Bowei He",
      "Wenhao Luo",
      "Rui Liu"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.11932"
  },
  {
    "id": "arXiv:2202.11937",
    "title": "Compositional Generalization Requires Compositional Parsers",
    "abstract": "A rapidly growing body of research on compositional generalization\ninvestigates the ability of a semantic parser to dynamically recombine\nlinguistic elements seen in training into unseen sequences. We present a\nsystematic comparison of sequence-to-sequence models and models guided by\ncompositional principles on the recent COGS corpus (Kim and Linzen, 2020).\nThough seq2seq models can perform well on lexical tasks, they perform with\nnear-zero accuracy on structural generalization tasks that require novel\nsyntactic structures; this holds true even when they are trained to predict\nsyntax instead of semantics. In contrast, compositional models achieve\nnear-perfect accuracy on structural generalization; we present new results\nconfirming this from the AM parser (Groschwitz et al., 2021). Our findings show\nstructural generalization is a key measure of compositional generalization and\nrequires models that are aware of complex structure.",
    "descriptor": "",
    "authors": [
      "Pia Wei\u00dfenhorn",
      "Yuekun Yao",
      "Lucia Donatelli",
      "Alexander Koller"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.11937"
  },
  {
    "id": "arXiv:2202.11940",
    "title": "On Learning Mixture Models with Sparse Parameters",
    "abstract": "Mixture models are widely used to fit complex and multimodal datasets. In\nthis paper we study mixtures with high dimensional sparse latent parameter\nvectors and consider the problem of support recovery of those vectors. While\nparameter learning in mixture models is well-studied, the sparsity constraint\nremains relatively unexplored. Sparsity of parameter vectors is a natural\nconstraint in variety of settings, and support recovery is a major step towards\nparameter estimation. We provide efficient algorithms for support recovery that\nhave a logarithmic sample complexity dependence on the dimensionality of the\nlatent space. Our algorithms are quite general, namely they are applicable to\n1) mixtures of many different canonical distributions including Uniform,\nPoisson, Laplace, Gaussians, etc. 2) Mixtures of linear regressions and linear\nclassifiers with Gaussian covariates under different assumptions on the unknown\nparameters. In most of these settings, our results are the first guarantees on\nthe problem while in the rest, our results provide improvements on existing\nworks.",
    "descriptor": "\nComments: 41 pages, Accepted at AISTATS 2022\n",
    "authors": [
      "Arya Mazumdar",
      "Soumyabrata Pal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.11940"
  },
  {
    "id": "arXiv:2202.11941",
    "title": "A Timing Yield Model for SRAM Cells in Sub/Near-threshold Voltages Based  on A Compact Drain Current Model",
    "abstract": "Sub/Near-threshold static random-access memory (SRAM) design is crucial for\naddressing the memory bottleneck in energy-constrained applications. However,\nthe high integration density and reliability under process variations demand an\naccurate estimation of extremely small failure probabilities. To capture such a\nrare event in memory circuits, the time and storage overhead of conventional\nMonte Carlo (MC) simulations cannot be tolerated. On the other hand, classic\nanalytical methods predicting failure probabilities from a physical expression\nbecome inaccurate in the sub/near-threshold region due to the assumed\ndistribution or the oversimplified drain current model for nanoscale devices.\nThis work first proposes a simple but efficient drain current model to describe\nthe drain-induced barrier lowering effect at low voltages. Based on that, the\nprobability density functions of the interest metrics in SRAM are derived. Two\nanalytical models are then put forward to evaluate SRAM dynamic stabilities\nincluding access and write-time failures. The proposed models can be extended\neasily to different types of SRAM with different read/write assist circuits.\nThe models are validated against MC simulations across different operating\nvoltages and temperatures. The average relative errors at 0.5V VDD are only\n8.8% and 10.4% for the access-time and write failure models respectively. The\nsize of required data samples is 43.6X smaller than that of the\nstate-of-the-art method.",
    "descriptor": "\nComments: This manuscript has been submitted to TCAD\n",
    "authors": [
      "Shan Shen",
      "Peng Cao",
      "Ming Ling",
      "Longxing Shi"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2202.11941"
  },
  {
    "id": "arXiv:2202.11944",
    "title": "Computer Aided Diagnosis and Out-of-Distribution Detection in Glaucoma  Screening Using Color Fundus Photography",
    "abstract": "Artificial Intelligence for RObust Glaucoma Screening (AIROGS) Challenge is\nheld for developing solutions for glaucoma screening from color fundus\nphotography that are robust to real-world scenarios. This report describes our\nmethod submitted to the AIROGS challenge. Our method employs convolutional\nneural networks to classify input images to \"referable glaucoma\" or \"no\nreferable glaucoma\". In addition, we introduce an inference-time\nout-of-distribution (OOD) detection method to identify ungradable images. Our\nOOD detection is based on an energy-based method combined with activation\nrectification.",
    "descriptor": "",
    "authors": [
      "Satoshi Kondo",
      "Satoshi Kasai",
      "Kosuke Hirasawa"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.11944"
  },
  {
    "id": "arXiv:2202.11946",
    "title": "Temporal Efficient Training of Spiking Neural Network via Gradient  Re-weighting",
    "abstract": "Recently, brain-inspired spiking neuron networks (SNNs) have attracted\nwidespread research interest because of their event-driven and energy-efficient\ncharacteristics. Still, it is difficult to efficiently train deep SNNs due to\nthe non-differentiability of its activation function, which disables the\ntypically used gradient descent approaches for traditional artificial neural\nnetworks (ANNs). Although the adoption of surrogate gradient (SG) formally\nallows for the back-propagation of losses, the discrete spiking mechanism\nactually differentiates the loss landscape of SNNs from that of ANNs, failing\nthe surrogate gradient methods to achieve comparable accuracy as for ANNs. In\nthis paper, we first analyze why the current direct training approach with\nsurrogate gradient results in SNNs with poor generalizability. Then we\nintroduce the temporal efficient training (TET) approach to compensate for the\nloss of momentum in the gradient descent with SG so that the training process\ncan converge into flatter minima with better generalizability. Meanwhile, we\ndemonstrate that TET improves the temporal scalability of SNN and induces a\ntemporal inheritable training for acceleration. Our method consistently\noutperforms the SOTA on all reported mainstream datasets, including\nCIFAR-10/100 and ImageNet. Remarkably on DVS-CIFAR10, we obtained 83$\\%$ top-1\naccuracy, over 10$\\%$ improvement compared to existing state of the art. Codes\nare available at \\url{https://github.com/Gus-Lab/temporal_efficient_training}.",
    "descriptor": "\nComments: Published as a conference paper at ICLR 2022\n",
    "authors": [
      "Shikuang Deng",
      "Yuhang Li",
      "Shanghang Zhang",
      "Shi Gu"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.11946"
  },
  {
    "id": "arXiv:2202.11948",
    "title": "Domain Disentangled Generative Adversarial Network for Zero-Shot  Sketch-Based 3D Shape Retrieval",
    "abstract": "Sketch-based 3D shape retrieval is a challenging task due to the large domain\ndiscrepancy between sketches and 3D shapes. Since existing methods are trained\nand evaluated on the same categories, they cannot effectively recognize the\ncategories that have not been used during training. In this paper, we propose a\nnovel domain disentangled generative adversarial network (DD-GAN) for zero-shot\nsketch-based 3D retrieval, which can retrieve the unseen categories that are\nnot accessed during training. Specifically, we first generate domain-invariant\nfeatures and domain-specific features by disentangling the learned features of\nsketches and 3D shapes, where the domain-invariant features are used to align\nwith the corresponding word embeddings. Then, we develop a generative\nadversarial network that combines the domainspecific features of the seen\ncategories with the aligned domain-invariant features to synthesize samples,\nwhere the synthesized samples of the unseen categories are generated by using\nthe corresponding word embeddings. Finally, we use the synthesized samples of\nthe unseen categories combined with the real samples of the seen categories to\ntrain the network for retrieval, so that the unseen categories can be\nrecognized. In order to reduce the domain shift between the synthesized domain\nand the real domain, we adopt the transductive setting to reduce the gap\nbetween the distributions of the synthesized unseen categories and real unseen\ncategories. Extensive experiments on the SHREC'13 and SHREC'14 datasets show\nthat our method significantly improves the retrieval performance of the unseen\ncategories.",
    "descriptor": "\nComments: Accepted by AAAI 2022\n",
    "authors": [
      "Rui Xu",
      "Zongyan Han",
      "Le Hui",
      "Jianjun Qian",
      "Jin Xie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.11948"
  },
  {
    "id": "arXiv:2202.11949",
    "title": "SMILE: Sequence-to-Sequence Domain Adaption with Minimizing Latent  Entropy for Text Image Recognition",
    "abstract": "Training recognition models with synthetic images have achieved remarkable\nresults in text recognition. However, recognizing text from real-world images\nstill faces challenges due to the domain shift between synthetic and real-world\ntext images. One of the strategies to eliminate the domain difference without\nmanual annotation is unsupervised domain adaptation (UDA). Due to the\ncharacteristic of sequential labeling tasks, most popular UDA methods cannot be\ndirectly applied to text recognition. To tackle this problem, we proposed a UDA\nmethod with minimizing latent entropy on sequence-to-sequence attention-based\nmodels with classbalanced self-paced learning. Our experiments show that our\nproposed framework achieves better recognition results than the existing\nmethods on most UDA text recognition benchmarks. All codes are publicly\navailable.",
    "descriptor": "",
    "authors": [
      "Yen-Cheng Chang",
      "Yi-Chang Chen",
      "Yu-Chuan Chang",
      "Yi-Ren Yeh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.11949"
  },
  {
    "id": "arXiv:2202.11950",
    "title": "An efficient combined local and global search strategy for optimization  of parallel kinematic mechanisms with joint limits and collision constraints",
    "abstract": "The optimization of parallel kinematic manipulators (PKM) involve several\nconstraints that are difficult to formalize, thus making optimal synthesis\nproblem highly challenging. The presence of passive joint limits as well as the\nsingularities and self-collisions lead to a complicated relation between the\ninput and output parameters. In this article, a novel optimization methodology\nis proposed by combining a local search, Nelder-Mead algorithm, with global\nsearch methodologies such as low discrepancy distribution for faster and more\nefficient exploration of the optimization space. The effect of the dimension of\nthe optimization problem and the different constraints are discussed to\nhighlight the complexities of closed-loop kinematic chain optimization. The\nwork also presents the approaches used to consider constraints for passive\njoint boundaries as well as singularities to avoid internal collisions in such\nmechanisms. The proposed algorithm can also optimize the length of the\nprismatic actuators and the constraints can be added in modular fashion,\nallowing to understand the impact of given criteria on the final result. The\napplication of the presented approach is used to optimize two PKMs of different\ndegrees of freedom.",
    "descriptor": "",
    "authors": [
      "Haribhau Durgesh",
      "Guillaume Michel",
      "Shivesh Kumar",
      "Marcello Sanguineti",
      "Damien Chablat"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.11950"
  },
  {
    "id": "arXiv:2202.11954",
    "title": "XAutoML: A Visual Analytics Tool for Establishing Trust in Automated  Machine Learning",
    "abstract": "In the last ten years, various automated machine learning (AutoML) systems\nhave been proposed to build end-to-end machine learning (ML) pipelines with\nminimal human interaction. Even though such automatically synthesized ML\npipelines are able to achieve a competitive performance, recent studies have\nshown that users do not trust models constructed by AutoML due to missing\ntransparency of AutoML systems and missing explanations for the constructed ML\npipelines. In a requirements analysis study with 26 domain experts, data\nscientists, and AutoML researchers from different professions with vastly\ndifferent expertise in ML, we collect detailed informational needs to establish\ntrust in AutoML. We propose XAutoML, an interactive visual analytics tool for\nexplaining arbitrary AutoML optimization procedures and ML pipelines\nconstructed by AutoML. XAutoML combines interactive visualizations with\nestablished techniques from explainable artificial intelligence (XAI) to make\nthe complete AutoML procedure transparent and explainable. By integrating\nXAutoML with JupyterLab, experienced users can extend the visual analytics with\nad-hoc visualizations based on information extracted from XAutoML. We validate\nour approach in a user study with the same diverse user group from the\nrequirements analysis. All participants were able to extract useful information\nfrom XAutoML, leading to a significantly increased trust in ML pipelines\nproduced by AutoML and the AutoML optimization itself.",
    "descriptor": "\nComments: Submitted for review to ACM TiiS Special Issue on Human-centered Explainable AI\n",
    "authors": [
      "Marc-Andr\u00e9 Z\u00f6ller",
      "Waldemar Titov",
      "Thomas Schlegel",
      "Marco F. Huber"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2202.11954"
  },
  {
    "id": "arXiv:2202.11955",
    "title": "NP$^{\\#P}$ = $\\exists$PP and other remarks about maximized counting",
    "abstract": "We consider the following decision problem DMAX#SAT, and generalizations\nthereof: given a quantifier-free propositional formula\n$F(\\mathbf{x},\\mathbf{y})$, where $\\mathbf{x},\\mathbf{y}$ are tuples of\nvariables, and a bound $B$, determine if there is $\\vec{x}$ such that\n$\\#\\{\\mathbf{y} \\mid F(\\mathbf{x},\\mathbf{y})\\} \\geq B$. This is the decision\nversion of the problem of MAX#SAT: finding $\\mathbf{x}$ and $B$ for maximal\n$B$.",
    "descriptor": "",
    "authors": [
      "David Monniaux"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2202.11955"
  },
  {
    "id": "arXiv:2202.11958",
    "title": "Cognitive Semantic Communication Systems Driven by Knowledge Graph",
    "abstract": "Semantic communication is envisioned as a promising technique to break\nthrough the Shannon limit. However, the existing semantic communication\nframeworks do not involve inference and error correction, which limits the\nachievable performance. In this paper, in order to tackle this issue, a\ncognitive semantic communication framework is proposed by exploiting knowledge\ngraph. Moreover, a simple, general and interpretable solution for semantic\ninformation detection is developed by exploiting triples as semantic symbols.\nIt also allows the receiver to correct errors occurring at the symbolic level.\nFurthermore, the pre-trained model is fine-tuned to recover semantic\ninformation, which overcomes the drawback that a fixed bit length coding is\nused to encode sentences of different lengths. Simulation results on the public\nWebNLG corpus show that our proposed system is superior to other benchmark\nsystems in terms of the data compression rate and the reliability of\ncommunication.",
    "descriptor": "",
    "authors": [
      "Fuhui Zhou",
      "Yihao Li",
      "Xinyuan Zhang",
      "Qihui Wu",
      "Xianfu Lei",
      "Rose Qingyang Hu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.11958"
  },
  {
    "id": "arXiv:2202.11960",
    "title": "All You Need Is Supervised Learning: From Imitation Learning to Meta-RL  With Upside Down RL",
    "abstract": "Upside down reinforcement learning (UDRL) flips the conventional use of the\nreturn in the objective function in RL upside down, by taking returns as input\nand predicting actions. UDRL is based purely on supervised learning, and\nbypasses some prominent issues in RL: bootstrapping, off-policy corrections,\nand discount factors. While previous work with UDRL demonstrated it in a\ntraditional online RL setting, here we show that this single algorithm can also\nwork in the imitation learning and offline RL settings, be extended to the\ngoal-conditioned RL setting, and even the meta-RL setting. With a general agent\narchitecture, a single UDRL agent can learn across all paradigms.",
    "descriptor": "",
    "authors": [
      "Kai Arulkumaran",
      "Dylan R. Ashley",
      "J\u00fcrgen Schmidhuber",
      "Rupesh K. Srivastava"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.11960"
  },
  {
    "id": "arXiv:2202.11961",
    "title": "\"Is not the truth the truth?\": Analyzing the Impact of User Validations  for Bus In/Out Detection in Smartphone-based Surveys",
    "abstract": "Passenger flow allows the study of users' behavior through the public network\nand assists in designing new facilities and services. This flow is observed\nthrough interactions between passengers and infrastructure. For this task,\nBluetooth technology and smartphones represent the ideal solution. The latter\ncomponent allows users' identification, authentication, and billing, while the\nformer allows short-range implicit interactions, device-to-device. To assess\nthe potential of such a use case, we need to verify how robust Bluetooth signal\nand related machine learning (ML) classifiers are against the noise of\nrealistic contexts. Therefore, we model binary passenger states with respect to\na public vehicle, where one can either be-in or be-out (BIBO). The BIBO label\nidentifies a fundamental building block of continuously-valued passenger flow.\nThis paper describes the Human-Computer interaction experimental setting in a\nsemi-controlled environment, which involves: two autonomous vehicles operating\non two routes, serving three bus stops and eighteen users, as well as a\nproprietary smartphone-Bluetooth sensing platform. The resulting dataset\nincludes multiple sensors' measurements of the same event and two ground-truth\nlevels, the first being validation by participants, the second by three\nvideo-cameras surveilling buses and track. We performed a Monte-Carlo\nsimulation of labels-flip to emulate human errors in the labeling process, as\nis known to happen in smartphone surveys; next we used such flipped labels for\nsupervised training of ML classifiers. The impact of errors on model\nperformance bias can be large. Results show ML tolerance to label flips caused\nby human or machine errors up to 30%.",
    "descriptor": "\nComments: 22 pages, 11 figures, 4 tables, 3 algorithms\n",
    "authors": [
      "Valentino Servizi.",
      "Dan R. Persson",
      "Francisco C. Pereira",
      "Hannah Villadsen",
      "Per B\u00e6kgaard",
      "Inon Peled",
      "Otto A. Nielsen"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.11961"
  },
  {
    "id": "arXiv:2202.11962",
    "title": "Large Scale Passenger Detection with Smartphone/Bus Implicit Interaction  and Multisensory Unsupervised Cause-effect Learning",
    "abstract": "Intelligent Transportation Systems (ITS) underpin the concept of Mobility as\na Service (MaaS), which requires universal and seamless users' access across\nmultiple public and private transportation systems while allowing operators'\nproportional revenue sharing. Current user sensing technologies such as\nWalk-in/Walk-out (WIWO) and Check-in/Check-out (CICO) have limited scalability\nfor large-scale deployments. These limitations prevent ITS from supporting\nanalysis, optimization, calculation of revenue sharing, and control of MaaS\ncomfort, safety, and efficiency. We focus on the concept of implicit\nBe-in/Be-out (BIBO) smartphone-sensing and classification.\nTo close the gap and enhance smartphones towards MaaS, we developed a\nproprietary smartphone-sensing platform collecting contemporary Bluetooth Low\nEnergy (BLE) signals from BLE devices installed on buses and Global Positioning\nSystem (GPS) locations of both buses and smartphones. To enable the training of\na model based on GPS features against the BLE pseudo-label, we propose the\nCause-Effect Multitask Wasserstein Autoencoder (CEMWA). CEMWA combines and\nextends several frameworks around Wasserstein autoencoders and neural networks.\nAs a dimensionality reduction tool, CEMWA obtains an auto-validated\nrepresentation of a latent space describing users' smartphones within the\ntransport system. This representation allows BIBO clustering via DBSCAN.\nWe perform an ablation study of CEMWA's alternative architectures and\nbenchmark against the best available supervised methods. We analyze\nperformance's sensitivity to label quality. Under the na\\\"ive assumption of\naccurate ground truth, XGBoost outperforms CEMWA. Although XGBoost and Random\nForest prove to be tolerant to label noise, CEMWA is agnostic to label noise by\ndesign and provides the best performance with an 88\\% F1 score.",
    "descriptor": "\nComments: 20 pages, 13 figures, 3 tables\n",
    "authors": [
      "Valentino Servizi",
      "Dan R. Persson",
      "Francisco C. Pereira",
      "Hannah Villadsen",
      "Per B\u00e6kgaard",
      "Jeppe Rich",
      "Otto A. Nielsen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2202.11962"
  },
  {
    "id": "arXiv:2202.11963",
    "title": "A general framework for adaptive two-index fusion attribute weighted  naive Bayes",
    "abstract": "Naive Bayes(NB) is one of the essential algorithms in data mining. However,\nit is rarely used in reality because of the attribute independent assumption.\nResearchers have proposed many improved NB methods to alleviate this\nassumption. Among these methods, due to high efficiency and easy\nimplementation, the filter attribute weighted NB methods receive great\nattentions. However, there still exists several challenges, such as the poor\nrepresentation ability for single index and the fusion problem of two indexes.\nTo overcome above challenges, we propose a general framework for Adaptive\nTwo-index Fusion attribute weighted NB(ATFNB). Two types of data description\ncategory are used to represent the correlation between classes and attributes,\nintercorrelation between attributes and attributes, respectively. ATFNB can\nselect any one index from each category. Then, we introduce a switching factor\n\\{beta} to fuse two indexes, which can adaptively adjust the optimal ratio of\nthe two index on various datasets. And a quick algorithm is proposed to infer\nthe optimal interval of switching factor \\{beta}. Finally, the weight of each\nattribute is calculated using the optimal value \\{beta} and is integrated into\nNB classifier to improve the accuracy. The experimental results on 50 benchmark\ndatasets and a Flavia dataset show that ATFNB outperforms the basic NB and\nstate-of-the-art filter weighted NB models. In addition, the ATFNB framework\ncan improve the existing two-index NB model by introducing the adaptive\nswitching factor \\{beta}. Auxiliary experimental results demonstrate the\nimproved model significantly increases the accuracy compared to the original\nmodel without the adaptive switching factor \\{beta}.",
    "descriptor": "",
    "authors": [
      "Xiaoliang Zhou",
      "Dongyang Wu",
      "Zitong You",
      "Li Zhang",
      "Ning Ye"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.11963"
  },
  {
    "id": "arXiv:2202.11965",
    "title": "A Holistic View on Data Protection for Sharing, Communicating, and  Computing Environments: Taxonomy and Future Directions",
    "abstract": "The data is an important asset of an organization and it is essential to keep\nthis asset secure. It requires security in whatever state is it i.e. data at\nrest, data in use, and data in transit. There is a need to pay more attention\nto it when the third party is included i.e. when the data is stored in the\ncloud then it requires more security. Since confidential data can reside on a\nvariety of computing devices (physical servers, virtual servers, databases,\nfile servers, PCs, point-of-sale devices, flash drives, and mobile devices) and\nmove through a variety of network access points (wireline, wireless, VPNs,\netc.), there is a need of solutions or mechanism that can tackle the problem of\ndata loss, data recovery and data leaks. In this context, the paper presents a\nholistic view of data protection for sharing and communicating environments for\nany type of organization. A taxonomy of data leakage protection systems and\nmajor challenges faced while protecting confidential data are discussed. Data\nprotection solutions, Data Leakage Protection System's analysis techniques,\nand, a thorough analysis of existing state-of-the-art contributions empowering\nmachine learning-based approaches are entailed. Finally, the paper explores and\nconcludes various critical emerging challenges and future research directions\nconcerning data protection.",
    "descriptor": "",
    "authors": [
      "Ishu Gupta",
      "Ashutosh Kumar Singh"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.11965"
  },
  {
    "id": "arXiv:2202.11966",
    "title": "A Fair Empirical Risk Minimization with Generalized Entropy",
    "abstract": "Recently a parametric family of fairness metrics to quantify algorithmic\nfairness has been proposed based on generalized entropy which have been\noriginally used in economics and public welfare. Since these metrics have\nseveral advantages such as quantifying unfairness at the individual-level and\ngroup-level, and unfold trade-off between the individual fairness and\ngroup-level fairness, algorithmic fairness requirement may be given in terms of\ngeneralized entropy for a fair classification problem. We consider a fair\nempirical risk minimization with a fairness constraint specified by generalized\nentropy. We theoretically investigate if the fair empirical fair classification\nproblem is learnable and how to find an approximate optimal classifier of it.",
    "descriptor": "\nComments: 28 pages and 1 figure\n",
    "authors": [
      "Youngmi Jin",
      "Tae-Jin Lee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.11966"
  },
  {
    "id": "arXiv:2202.11969",
    "title": "Should I Get Involved? On the Privacy Perils of Mining Software  Repositories for Research Participants",
    "abstract": "Mining Software Repositories (MSRs) is an evidence-based methodology that\ncross-links data to uncover actionable information about software systems.\nEmpirical studies in software engineering often leverage MSR techniques as they\nallow researchers to unveil issues and flaws in software development so as to\nanalyse the different factors contributing to them. Hence, counting on\nfine-grained information about the repositories and sources being mined (e.g.,\nserver names, and contributors' identities) is essential for the\nreproducibility and transparency of MSR studies. However, this can also\nintroduce threats to participants' privacy as their identities may be linked to\nflawed/sub-optimal programming practices (e.g., code smells, improper\ndocumentation), or vice-versa. Moreover, this can be extensible to close\ncollaborators and community members resulting \"guilty by association\". This\nposition paper aims to start a discussion about indirect participation in MSRs\ninvestigations, the dichotomy of 'privacy vs. utility' regarding sharing\nnon-aggregated data, and its effects on privacy restrictions and ethical\nconsiderations for participant involvement.",
    "descriptor": "\nComments: Accepted at ROPES'22: 1st International Workshop on Recruiting Participants for Empirical Software Engineering (co-located with ICSE 2022)\n",
    "authors": [
      "Melina Vidoni",
      "Nicol\u00e1s E. D\u00edaz Ferreyra"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2202.11969"
  },
  {
    "id": "arXiv:2202.11981",
    "title": "Fully Self-Supervised Learning for Semantic Segmentation",
    "abstract": "In this work, we present a fully self-supervised framework for semantic\nsegmentation(FS^4). A fully bootstrapped strategy for semantic segmentation,\nwhich saves efforts for the huge amount of annotation, is crucial for building\ncustomized models from end-to-end for open-world domains. This application is\neagerly needed in realistic scenarios. Even though recent self-supervised\nsemantic segmentation methods have gained great progress, these works however\nheavily depend on the fully-supervised pretrained model and make it impossible\na fully self-supervised pipeline. To solve this problem, we proposed a\nbootstrapped training scheme for semantic segmentation, which fully leveraged\nthe global semantic knowledge for self-supervision with our proposed PGG\nstrategy and CAE module. In particular, we perform pixel clustering and\nassignments for segmentation supervision. Preventing it from clustering a mess,\nwe proposed 1) a pyramid-global-guided (PGG) training strategy to supervise the\nlearning with pyramid image/patch-level pseudo labels, which are generated by\ngrouping the unsupervised features. The stable global and pyramid semantic\npseudo labels can prevent the segmentation from learning too many clutter\nregions or degrading to one background region; 2) in addition, we proposed\ncontext-aware embedding (CAE) module to generate global feature embedding in\nview of its neighbors close both in space and appearance in a non-trivial way.\nWe evaluate our method on the large-scale COCO-Stuff dataset and achieved 7.19\nmIoU improvements on both things and stuff objects",
    "descriptor": "",
    "authors": [
      "Yuan Wang",
      "Wei Zhuo",
      "Yucong Li",
      "Zhi Wang",
      "Qi Ju",
      "Wenwu Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.11981"
  },
  {
    "id": "arXiv:2202.11982",
    "title": "N-QGN: Navigation Map from a Monocular Camera using Quadtree Generating  Networks",
    "abstract": "Monocular depth estimation has been a popular area of research for several\nyears, especially since self-supervised networks have shown increasingly good\nresults in bridging the gap with supervised and stereo methods. However, these\napproaches focus their interest on dense 3D reconstruction and sometimes on\ntiny details that are superfluous for autonomous navigation. In this paper, we\npropose to address this issue by estimating the navigation map under a quadtree\nrepresentation. The objective is to create an adaptive depth map prediction\nthat only extract details that are essential for the obstacle avoidance. Other\n3D space which leaves large room for navigation will be provided with\napproximate distance. Experiment on KITTI dataset shows that our method can\nsignificantly reduce the number of output information without major loss of\naccuracy.",
    "descriptor": "\nComments: 6 pages + references, accepted to ICRA 2022\n",
    "authors": [
      "Daniel Braun",
      "Olivier Morel",
      "Pascal Vasseur",
      "C\u00e9dric Demonceaux"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.11982"
  },
  {
    "id": "arXiv:2202.11983",
    "title": "GIAOTracker: A comprehensive framework for MCMOT with global information  and optimizing strategies in VisDrone 2021",
    "abstract": "In recent years, algorithms for multiple object tracking tasks have benefited\nfrom great progresses in deep models and video quality. However, in challenging\nscenarios like drone videos, they still suffer from problems, such as small\nobjects, camera movements and view changes. In this paper, we propose a new\nmultiple object tracker, which employs Global Information And some Optimizing\nstrategies, named GIAOTracker. It consists of three stages, i.e., online\ntracking, global link and post-processing. Given detections in every frame, the\nfirst stage generates reliable tracklets using information of camera motion,\nobject motion and object appearance. Then they are associated into trajectories\nby exploiting global clues and refined through four post-processing methods.\nWith the effectiveness of the three stages, GIAOTracker achieves\nstate-of-the-art performance on the VisDrone MOT dataset and wins the 3rd place\nin the VisDrone2021 MOT Challenge.",
    "descriptor": "\nComments: ICCV 2021 Workshop\n",
    "authors": [
      "Yunhao Du",
      "Junfeng Wan",
      "Yanyun Zhao",
      "Binyu Zhang",
      "Zhihang Tong",
      "Junhao Dong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.11983"
  },
  {
    "id": "arXiv:2202.11984",
    "title": "Fine-grained TLS Services Classification with Reject Option",
    "abstract": "The recent success and proliferation of machine learning and deep learning\nhave provided powerful tools, which are also utilized for encrypted traffic\nanalysis, classification, and threat detection. These methods, neural networks\nin particular, are often complex and require a huge corpus of training data.\nTherefore, this paper focuses on collecting a large up-to-date dataset with\nalmost 200 fine-grained service labels and 140 million network flows extended\nwith packet-level metadata. The number of flows is three orders of magnitude\nhigher than in other existing public labeled datasets of encrypted traffic. The\nnumber of service labels, which is important to make the problem hard and\nrealistic, is four times higher than in the public dataset with the most class\nlabels. The published dataset is intended as a benchmark for identifying\nservices in encrypted traffic. Service identification can be further extended\nwith the task of \"rejecting\" unknown services, i.e., the traffic not seen\nduring the training phase. Neural networks offer superior performance for\ntackling this more challenging problem. To showcase the dataset's usefulness,\nwe implemented a neural network with a multi-modal architecture, which is the\nstate-of-the-art approach, and achieved 97.04% classification accuracy and\ndetected 91.94% of unknown services with 5% false positive rate.",
    "descriptor": "",
    "authors": [
      "Jan Luxemburk",
      "Tom\u00e1\u0161 \u010cejka"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2202.11984"
  },
  {
    "id": "arXiv:2202.11985",
    "title": "Can deep neural networks learn process model structure? An assessment  framework and analysis",
    "abstract": "Predictive process monitoring concerns itself with the prediction of ongoing\ncases in (business) processes. Prediction tasks typically focus on remaining\ntime, outcome, next event or full case suffix prediction. Various methods using\nmachine and deep learning havebeen proposed for these tasks in recent years.\nEspecially recurrent neural networks (RNNs) such as long short-term memory nets\n(LSTMs) have gained in popularity. However, no research focuses on whether such\nneural network-based models can truly learn the structure of underlying process\nmodels. For instance, can such neural networks effectively learn parallel\nbehaviour or loops? Therefore, in this work, we propose an evaluation scheme\ncomplemented with new fitness, precision, and generalisation metrics,\nspecifically tailored towards measuring the capacity of deep learning models to\nlearn process model structure. We apply this framework to several process\nmodels with simple control-flow behaviour, on the task of next-event\nprediction. Our results show that, even for such simplistic models, careful\ntuning of overfitting countermeasures is required to allow these models to\nlearn process model structure.",
    "descriptor": "\nComments: Second International Workshop on Leveraging Machine Learning in Process Mining\n",
    "authors": [
      "Jari Peeperkorn",
      "Seppe vanden Broucke",
      "Jochen De Weerdt"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.11985"
  },
  {
    "id": "arXiv:2202.11987",
    "title": "Predicting the impact of treatments over time with uncertainty aware  neural differential equations",
    "abstract": "Predicting the impact of treatments from observational data only still\nrepresents a majorchallenge despite recent significant advances in time series\nmodeling. Treatment assignments are usually correlated with the predictors of\nthe response, resulting in a lack of data support for counterfactual\npredictions and therefore in poor quality estimates. Developments in causal\ninference have lead to methods addressing this confounding by requiring a\nminimum level of overlap. However,overlap is difficult to assess and usually\nnotsatisfied in practice. In this work, we propose Counterfactual ODE (CF-ODE),\na novel method to predict the impact of treatments continuously over time using\nNeural Ordinary Differential Equations equipped with uncertainty estimates.\nThis allows to specifically assess which treatment outcomes can be reliably\npredicted. We demonstrate over several longitudinal data sets that CF-ODE\nprovides more accurate predictions and more reliable uncertainty estimates than\npreviously available methods.",
    "descriptor": "",
    "authors": [
      "Edward De Brouwer",
      "Javier Gonz\u00e1lez Hern\u00e1ndez",
      "Stephanie Hyland"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.11987"
  },
  {
    "id": "arXiv:2202.11988",
    "title": "Exact Matching in Graphs of Bounded Independence Number",
    "abstract": "In the \\emph{Exact Matching Problem} (EM), we are given a graph equipped with\na fixed coloring of its edges with two colors (red and blue), as well as a\npositive integer $k$. The task is then to decide whether the given graph\ncontains a perfect matching exactly $k$ of whose edges have color red. EM\ngeneralizes several important algorithmic problems such as \\emph{perfect\nmatching} and restricted minimum weight spanning tree problems.\nWhen introducing the problem in 1982, Papadimitriou and Yannakakis\nconjectured EM to be \\textbf{NP}-complete. Later however, Mulmuley et\nal.~presented a randomized polynomial time algorithm for EM, which puts EM in\n\\textbf{RP}. Given that to decide whether or not \\textbf{RP}$=$\\textbf{P}\nrepresents a big open challenge in complexity theory, this makes it unlikely\nfor EM to be \\textbf{NP}-complete, and in fact indicates the possibility of a\n\\emph{deterministic} polynomial time algorithm. EM remains one of the few\nnatural combinatorial problems in \\textbf{RP} which are not known to be\ncontained in \\textbf{P}, making it an interesting instance for testing the\nhypothesis \\textbf{RP}$=$\\textbf{P}.\nDespite EM being quite well-known, attempts to devise deterministic\npolynomial algorithms have remained illusive during the last 40 years and\nprogress has been lacking even for very restrictive classes of input graphs. In\nthis paper we finally push the frontier of positive results forward by proving\nthat EM can be solved in deterministic polynomial time for input graphs of\nbounded independence number, and for bipartite input graphs of bounded\nbipartite independence number. This generalizes previous positive results for\ncomplete (bipartite) graphs which were the only known results for EM on dense\ngraphs.",
    "descriptor": "",
    "authors": [
      "Nicolas El Maalouly",
      "Raphael Steiner"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2202.11988"
  },
  {
    "id": "arXiv:2202.11998",
    "title": "Effective Actor-centric Human-object Interaction Detection",
    "abstract": "While Human-Object Interaction(HOI) Detection has achieved tremendous\nadvances in recent, it still remains challenging due to complex interactions\nwith multiple humans and objects occurring in images, which would inevitably\nlead to ambiguities. Most existing methods either generate all human-object\npair candidates and infer their relationships by cropped local features\nsuccessively in a two-stage manner, or directly predict interaction points in a\none-stage procedure. However, the lack of spatial configurations or reasoning\nsteps of two- or one- stage methods respectively limits their performance in\nsuch complex scenes. To avoid this ambiguity, we propose a novel actor-centric\nframework. The main ideas are that when inferring interactions: 1) the\nnon-local features of the entire image guided by actor position are obtained to\nmodel the relationship between the actor and context, and then 2) we use an\nobject branch to generate pixel-wise interaction area prediction, where the\ninteraction area denotes the object central area. Moreover, we also use an\nactor branch to get interaction prediction of the actor and propose a novel\ncomposition strategy based on center-point indexing to generate the final HOI\nprediction. Thanks to the usage of the non-local features and the\npartly-coupled property of the human-objects composition strategy, our proposed\nframework can detect HOI more accurately especially for complex images.\nExtensive experimental results show that our method achieves the\nstate-of-the-art on the challenging V-COCO and HICO-DET benchmarks and is more\nrobust especially in multiple persons and/or objects scenes.",
    "descriptor": "\nComments: 11 pages\n",
    "authors": [
      "Kunlun Xu",
      "Zhimin Li",
      "Zhijun Zhang",
      "Leizhen Dong",
      "Wenhui Xu",
      "Luxin Yan",
      "Sheng Zhong",
      "Xu Zou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.11998"
  },
  {
    "id": "arXiv:2202.11999",
    "title": "Proactive Libraries: Enforcing Correct Behaviors in Android Apps",
    "abstract": "The Android framework provides a rich set of APIs that can be exploited by\ndevelopers to build their apps. However, the rapid evolution of these APIs\njointly with the specific characteristics of the lifecycle of the Android\ncomponents challenge developers, who may release apps that use APIs\nincorrectly. In this demo, we present Proactive Libraries, a tool that can be\nused to decorate regular libraries with the capability of proactively detecting\nand healing API misuses at runtime. Proactive Libraries blend libraries with\nmultiple proactive modules that collect data, check the compliance of API\nusages with correctness policies, and heal executions as soon as the possible\nviolation of a policy is detected. The results of our evaluation with 27\npossible API misuses show the effectiveness of Proactive Libraries in\ncorrecting API misuses with negligible runtime overhead.",
    "descriptor": "\nComments: Accepted for publication in the Proceedings of the 44th International Conference on Software Engineering (ICSE 2022). arXiv admin note: substantial text overlap with arXiv:1911.09357, arXiv:1703.08005\n",
    "authors": [
      "Oliviero Riganelli",
      "Ionut Daniel Fagadau",
      "Daniela Micucci",
      "Leonardo Mariani"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2202.11999"
  },
  {
    "id": "arXiv:2202.12002",
    "title": "Rare Gems: Finding Lottery Tickets at Initialization",
    "abstract": "It has been widely observed that large neural networks can be pruned to a\nsmall fraction of their original size, with little loss in accuracy, by\ntypically following a time-consuming \"train, prune, re-train\" approach. Frankle\n& Carbin (2018) conjecture that we can avoid this by training lottery tickets,\ni.e., special sparse subnetworks found at initialization, that can be trained\nto high accuracy. However, a subsequent line of work presents concrete evidence\nthat current algorithms for finding trainable networks at initialization, fail\nsimple baseline comparisons, e.g., against training random sparse subnetworks.\nFinding lottery tickets that train to better accuracy compared to simple\nbaselines remains an open problem. In this work, we partially resolve this open\nproblem by discovering rare gems: subnetworks at initialization that attain\nconsiderable accuracy, even before training. Refining these rare gems - \"by\nmeans of fine-tuning\" - beats current baselines and leads to accuracy\ncompetitive or better than magnitude pruning methods.",
    "descriptor": "",
    "authors": [
      "Kartik Sreenivasan",
      "Jy-yong Sohn",
      "Liu Yang",
      "Matthew Grinde",
      "Alliot Nagle",
      "Hongyi Wang",
      "Kangwook Lee",
      "Dimitris Papailiopoulos"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.12002"
  },
  {
    "id": "arXiv:2202.12003",
    "title": "IBIA: Bayesian Inference via Incremental Build-Infer-Approximate  operations on Clique Trees",
    "abstract": "Exact inference in Bayesian networks is intractable and has an exponential\ndependence on the size of the largest clique in the corresponding clique tree,\nnecessitating approximations. Techniques for approximate inference typically\nuse iterative BP in graphs with bounded cluster sizes. We propose an\nalternative approach for approximate inference based on an incremental\nbuild-infer-approximate (IBIA) paradigm. In the build stage of this approach,\nbounded-clique size partitions are obtained by building the clique tree (CT)\nincrementally. Nodes are added to the CT as long as the sizes are within a\nuser-specified clique size constraint. Once the clique size constraint is\nreached, the infer and approximate part of the algorithm finds an approximate\nCT with lower clique sizes to which new nodes can be added. This step involves\nexact inference to calibrate the CT and a combination of exact and approximate\nmarginalization for approximation. The approximate CT serves as a starting\npoint for the construction of CT for the next partition. The algorithm returns\na forest of calibrated clique trees corresponding to all partitions. We show\nthat our algorithm for incremental construction of clique trees always\ngenerates a valid CT and our approximation technique automatically maintains\nconsistency of within-clique beliefs. The queries of interest are prior and\nposterior singleton marginals and the partition function. More than 500\nbenchmarks were used to test the method and the results show a significant\nreduction in error when compared to other approximate methods, with competitive\nruntimes.",
    "descriptor": "",
    "authors": [
      "Shivani Bathla",
      "Vinita Vasudevan"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.12003"
  },
  {
    "id": "arXiv:2202.12006",
    "title": "Parameterized Intractability for Multi-Winner Election under the  Chamberlin-Courant Rule and the Monroe Rule",
    "abstract": "Answering an open question by Betzler et al. [Betzler et al., JAIR'13], we\nresolve the parameterized complexity of the multi-winner determination problem\nunder two famous representation voting rules: the Chamberlin-Courant (in short\nCC) rule [Chamberlin and Courant, APSR'83] and the Monroe rule [Monroe,\nAPSR'95]. We show that under both rules, the problem is W[1]-hard with respect\nto the sum $\\beta$ of misrepresentations, thereby precluding the existence of\nany $f(\\beta) \\cdot |I|^{O(1)}$ -time algorithm, where $|I|$ denotes the size\nof the input instance.",
    "descriptor": "",
    "authors": [
      "Jiehua Chen",
      "Sanjukta Roy"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Artificial Intelligence (cs.AI)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2202.12006"
  },
  {
    "id": "arXiv:2202.12014",
    "title": "TriggerCit: Early Flood Alerting using Twitter and Geolocation -- a  comparison with alternative sources",
    "abstract": "Rapid impact assessment in the immediate aftermath of a natural disaster is\nessential to provide adequate information to international organisations, local\nauthorities, and first responders. Social media can support emergency response\nwith evidence-based content posted by citizens and organisations during ongoing\nevents. In the paper, we propose TriggerCit: an early flood alerting tool with\na multilanguage approach focused on timeliness and geolocation. The paper\nfocuses on assessing the reliability of the approach as a triggering system,\ncomparing it with alternative sources for alerts, and evaluating the quality\nand amount of complementary information gathered. Geolocated visual evidence\nextracted from Twitter by TriggerCit was analysed in two case studies on floods\nin Thailand and Nepal in 2021.",
    "descriptor": "\nComments: 12 pages Keywords Social Media, Disaster management, Early Alerting\n",
    "authors": [
      "Carlo Bono",
      "Barbara Pernici",
      "Jose Luis Fernandez-Marquez",
      "Amudha Ravi Shankar",
      "Mehmet O\u011fuz M\u00fcl\u00e2yim",
      "Edoardo Nemni"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2202.12014"
  },
  {
    "id": "arXiv:2202.12015",
    "title": "Learning to Merge Tokens in Vision Transformers",
    "abstract": "Transformers are widely applied to solve natural language understanding and\ncomputer vision tasks. While scaling up these architectures leads to improved\nperformance, it often comes at the expense of much higher computational costs.\nIn order for large-scale models to remain practical in real-world systems,\nthere is a need for reducing their computational overhead. In this work, we\npresent the PatchMerger, a simple module that reduces the number of patches or\ntokens the network has to process by merging them between two consecutive\nintermediate layers. We show that the PatchMerger achieves a significant\nspeedup across various model sizes while matching the original performance both\nupstream and downstream after fine-tuning.",
    "descriptor": "\nComments: 11 pages, 9 figures\n",
    "authors": [
      "Cedric Renggli",
      "Andr\u00e9 Susano Pinto",
      "Neil Houlsby",
      "Basil Mustafa",
      "Joan Puigcerver",
      "Carlos Riquelme"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.12015"
  },
  {
    "id": "arXiv:2202.12016",
    "title": "Practical Abstraction for Model Checking of Multi-Agent Systems",
    "abstract": "Model checking of multi-agent systems (MAS) is known to be hard, both\ntheoretically and in practice. A smart abstraction of the state space may\nsignificantly reduce the model, and facilitate the verification. In this paper,\nwe propose and study an intuitive agent-based abstraction scheme, based on the\nremoval of variables in the representation of a MAS. This allows to do the\nreduction without generating the global model of the system. Moreover, the\nprocess is easy to understand and control even for domain experts with little\nknowledge of computer science. We formally prove the correctness of the\napproach, and evaluate the gains experimentally on models of a postal voting\nprocedure.",
    "descriptor": "",
    "authors": [
      "Wojciech Jamroga",
      "Yan Kim"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2202.12016"
  },
  {
    "id": "arXiv:2202.12018",
    "title": "Counterfactual Explanations for Predictive Business Process Monitoring",
    "abstract": "Predictive business process monitoring increasingly leverages sophisticated\nprediction models. Although sophisticated models achieve consistently higher\nprediction accuracy than simple models, one major drawback is their lack of\ninterpretability, which limits their adoption in practice. We thus see growing\ninterest in explainable predictive business process monitoring, which aims to\nincrease the interpretability of prediction models. Existing solutions focus on\ngiving factual explanations.While factual explanations can be helpful, humans\ntypically do not ask why a particular prediction was made, but rather why it\nwas made instead of another prediction, i.e., humans are interested in\ncounterfactual explanations. While research in explainable AI produced several\npromising techniques to generate counterfactual explanations, directly applying\nthem to predictive process monitoring may deliver unrealistic explanations,\nbecause they ignore the underlying process constraints. We propose LORELEY, a\ncounterfactual explanation technique for predictive process monitoring, which\nextends LORE, a recent explainable AI technique. We impose control flow\nconstraints to the explanation generation process to ensure realistic\ncounterfactual explanations. Moreover, we extend LORE to enable explaining\nmulti-class classification models. Experimental results using a real, public\ndataset indicate that LORELEY can approximate the prediction models with an\naverage fidelity of 97.69\\% and generate realistic counterfactual explanations.",
    "descriptor": "",
    "authors": [
      "Tsung-Hao Huang",
      "Andreas Metzger",
      "Klaus Pohl"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.12018"
  },
  {
    "id": "arXiv:2202.12020",
    "title": "Point Containment Queries on Ray Tracing Cores for AMR Flow  Visualization",
    "abstract": "Modern GPUs come with dedicated hardware to perform ray/triangle\nintersections and bounding volume hierarchy (BVH) traversal. While the primary\nuse case for this hardware is photorealistic 3D computer graphics, with careful\nalgorithm design scientists can also use this special-purpose hardware to\naccelerate general-purpose computations such as point containment queries. This\narticle explains the principles behind these techniques and their application\nto vector field visualization of large simulation data using particle tracing.",
    "descriptor": "",
    "authors": [
      "Stefan Zellmann",
      "Daniel Seifried",
      "Nate Morrical",
      "Ingo Wald",
      "Will Usher",
      "Jamie A.P. Law-Smith",
      "Stefanie Walch-Gassner",
      "Andr\u00e9 Hinkenjann"
    ],
    "subjectives": [
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2202.12020"
  },
  {
    "id": "arXiv:2202.12023",
    "title": "Validating an SVM-based neonatal seizure detection algorithm for  generalizability, non-inferiority and clinical efficacy",
    "abstract": "Neonatal seizure detection algorithms (SDA) are approaching the benchmark of\nhuman expert annotation. Measures of algorithm generalizability and\nnon-inferiority as well as measures of clinical efficacy are needed to assess\nthe full scope of neonatal SDA performance. We validated our neonatal SDA on an\nindependent data set of 28 neonates. Generalizability was tested by comparing\nthe performance of the original training set (cross-validation) to its\nperformance on the validation set. Non-inferiority was tested by assessing\ninter-observer agreement between combinations of SDA and two human expert\nannotations. Clinical efficacy was tested by comparing how the SDA and human\nexperts quantified seizure burden and identified clinically significant periods\nof seizure activity in the EEG. Algorithm performance was consistent between\ntraining and validation sets with no significant worsening in AUC (p>0.05, n\n=28). SDA output was inferior to the annotation of the human expert, however,\nre-training with an increased diversity of data resulted in non-inferior\nperformance ($\\Delta\\kappa$=0.077, 95% CI: -0.002-0.232, n=18). The SDA\nassessment of seizure burden had an accuracy ranging from 89-93%, and 87% for\nidentifying periods of clinical interest. The proposed SDA is approaching human\nequivalence and provides a clinically relevant interpretation of the EEG.",
    "descriptor": "",
    "authors": [
      "Karoliina T. Tapani",
      "P\u00e4ivi Nevalainen",
      "Sampsa Vanhatalo",
      "Nathan J. Stevenson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.12023"
  },
  {
    "id": "arXiv:2202.12024",
    "title": "NoisyTune: A Little Noise Can Help You Finetune Pretrained Language  Models Better",
    "abstract": "Effectively finetuning pretrained language models (PLMs) is critical for\ntheir success in downstream tasks. However, PLMs may have risks in overfitting\npretraining signals, and there are some gaps between downstream tasks and the\npretraining tasks. It can be difficult for vanilla finetuning methods to\novercome the barrier between pretraining and downstream tasks, which leads to\nsuboptimal performance. In this paper, we propose a very simple yet effective\nmethod named NoisyTune which can help better finetune PLMs in downstream tasks\nby adding some noise to the parameters of PLMs before finetuning. More\nspecifically, we propose a matrix-wise perturbing method by adding different\nuniform noises according to the standard deviations of different parameter\nmatrices, which can consider the varied characteristics of different types of\nparameters in PLMs. Extensive experiments on the GLUE English benchmark and the\nXTREME multilingual benchmark show that NoisyTune can consistently improve the\nperformance of different PLMs in many downstream tasks.",
    "descriptor": "\nComments: ACL 2022\n",
    "authors": [
      "Chuhan Wu",
      "Fangzhao Wu",
      "Tao Qi",
      "Yongfeng Huang",
      "Xing Xie"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.12024"
  },
  {
    "id": "arXiv:2202.12025",
    "title": "Scenario Parameter Generation Method and Scenario Representativeness  Metric for Scenario-Based Assessment of Automated Vehicles",
    "abstract": "The development of assessment methods for the performance of Automated\nVehicles (AVs) is essential to enable the deployment of automated driving\ntechnologies, due to the complex operational domain of AVs. One candidate is\nscenario-based assessment, in which test cases are derived from real-world road\ntraffic scenarios obtained from driving data. Because of the high variety of\nthe possible scenarios, using only observed scenarios for the assessment is not\nsufficient. Therefore, methods for generating additional scenarios are\nnecessary.\nOur contribution is twofold. First, we propose a method to determine the\nparameters that describe the scenarios to a sufficient degree without relying\non strong assumptions on the parameters that characterize the scenarios. By\nestimating the probability density function (pdf) of these parameters,\nrealistic parameter values can be generated. Second, we present the Scenario\nRepresentativeness (SR) metric based on the Wasserstein distance, which\nquantifies to what extent the scenarios with the generated parameter values are\nrepresentative of real-world scenarios while covering the actual variety found\nin the real-world scenarios.\nA comparison of our proposed method with methods relying on assumptions of\nthe scenario parametrization and pdf estimation shows that the proposed method\ncan automatically determine the optimal scenario parametrization and pdf\nestimation. Furthermore, we demonstrate that our SR metric can be used to\nchoose the (number of) parameters that best describe a scenario. The presented\nmethod is promising, because the parameterization and pdf estimation can\ndirectly be applied to already available importance sampling strategies for\naccelerating the evaluation of AVs.",
    "descriptor": "\nComments: 14 pages, 11 figures, 4 tables, accepted for publication in IEEE Transactions on Intelligent Transportation Systems\n",
    "authors": [
      "Erwin de Gelder",
      "Jasper Hof",
      "Eric Cator",
      "Jan-Pieter Paardekooper",
      "Olaf Op den Camp",
      "Jeroen Ploeg",
      "Bart De Schutter"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.12025"
  },
  {
    "id": "arXiv:2202.12029",
    "title": "Systematic Prevention of On-Core Timing Channels by Full Temporal  Partitioning",
    "abstract": "Microarchitectural timing channels enable unwanted information flow across\nsecurity boundaries, violating fundamental security assumptions. They leverage\ntiming variations of several state-holding microarchitectural components and\nhave been demonstrated across instruction set architectures and hardware\nimplementations. Analogously to memory protection, Ge et al. have proposed time\nprotection for preventing information leakage via timing channels. They also\nshowed that time protection calls for hardware support. This work leverages the\nopen and extensible RISC-V instruction set architecture (ISA) to introduce the\ntemporal fence instruction fence.t, which provides the required mechanisms by\nclearing vulnerable microarchitectural state and guaranteeing a\nhistory-independent context-switch latency. We propose and discuss three\ndifferent implementations of fence.t and implement them on an experimental\nversion of the seL4 microkernel and CVA6, an open-source, in-order, application\nclass, 64-bit RISC-V core. We find that a complete, systematic, ISA-supported\nerasure of all non-architectural core components is the most effective\nimplementation while featuring a low implementation effort, a minimal\nperformance overhead of approximately 2%, and negligible hardware costs.",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible. arXiv admin note: text overlap with arXiv:2005.02193\n",
    "authors": [
      "Nils Wistoff",
      "Moritz Schneider",
      "Frank K. G\u00fcrkaynak",
      "Gernot Heiser",
      "Luca Benini"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2202.12029"
  },
  {
    "id": "arXiv:2202.12031",
    "title": "Assessing generalisability of deep learning-based polyp detection and  segmentation methods through a computer vision challenge",
    "abstract": "Polyps are well-known cancer precursors identified by colonoscopy. However,\nvariability in their size, location, and surface largely affect identification,\nlocalisation, and characterisation. Moreover, colonoscopic surveillance and\nremoval of polyps (referred to as polypectomy ) are highly operator-dependent\nprocedures. There exist a high missed detection rate and incomplete removal of\ncolonic polyps due to their variable nature, the difficulties to delineate the\nabnormality, the high recurrence rates, and the anatomical topography of the\ncolon. There have been several developments in realising automated methods for\nboth detection and segmentation of these polyps using machine learning.\nHowever, the major drawback in most of these methods is their ability to\ngeneralise to out-of-sample unseen datasets that come from different centres,\nmodalities and acquisition systems. To test this hypothesis rigorously we\ncurated a multi-centre and multi-population dataset acquired from multiple\ncolonoscopy systems and challenged teams comprising machine learning experts to\ndevelop robust automated detection and segmentation methods as part of our\ncrowd-sourcing Endoscopic computer vision challenge (EndoCV) 2021. In this\npaper, we analyse the detection results of the four top (among seven) teams and\nthe segmentation results of the five top teams (among 16). Our analyses\ndemonstrate that the top-ranking teams concentrated on accuracy (i.e., accuracy\n> 80% on overall Dice score on different validation sets) over real-time\nperformance required for clinical applicability. We further dissect the methods\nand provide an experiment-based hypothesis that reveals the need for improved\ngeneralisability to tackle diversity present in multi-centre datasets.",
    "descriptor": "\nComments: 26 pages\n",
    "authors": [
      "Sharib Ali",
      "Noha Ghatwary",
      "Debesh Jha",
      "Ece Isik-Polat",
      "Gorkem Polat",
      "Chen Yang",
      "Wuyang Li",
      "Adrian Galdran",
      "Miguel-\u00c1ngel Gonz\u00e1lez Ballester",
      "Vajira Thambawita",
      "Steven Hicks",
      "Sahadev Poudel",
      "Sang-Woong Lee",
      "Ziyi Jin",
      "Tianyuan Gan",
      "ChengHui Yu",
      "JiangPeng Yan",
      "Doyeob Yeo",
      "Hyunseok Lee",
      "Nikhil Kumar Tomar",
      "Mahmood Haithmi",
      "Amr Ahmed",
      "Michael A. Riegler",
      "Christian Daul",
      "P\u00e5l Halvorsen",
      "Jens Rittscher",
      "Osama E. Salem",
      "Dominique Lamarque",
      "Renato Cannizzaro",
      "Stefano Realdon",
      "Thomas de Lange",
      "James E. East"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.12031"
  },
  {
    "id": "arXiv:2202.12033",
    "title": "Multi-Modal Legged Locomotion Framework with Automated Residual  Reinforcement Learning",
    "abstract": "While quadruped robots usually have good stability and load capacity, bipedal\nrobots offer a higher level of flexibility / adaptability to different tasks\nand environments. A multi-modal legged robot can take the best of both worlds.\nIn this paper, we propose a multi-modal locomotion framework that is composed\nof a hand-crafted transition motion and a learning-based bipedal controller --\nlearnt by a novel algorithm called Automated Residual Reinforcement Learning.\nThis framework aims to endow arbitrary quadruped robots with the ability to\nwalk bipedally. In particular, we 1) design an additional supporting structure\nfor a quadruped robot and a sequential multi-modal transition strategy; 2)\npropose a novel class of Reinforcement Learning algorithms for bipedal control\nand evaluate their performances in both simulation and the real world.\nExperimental results show that our proposed algorithms have the best\nperformance in simulation and maintain a good performance in a real-world\nrobot. Overall, our multi-modal robot could successfully switch between biped\nand quadruped, and walk in both modes. Experiment videos and code are available\nat https://chenaah.github.io/multimodal/.",
    "descriptor": "",
    "authors": [
      "Chen Yu",
      "Andre Rosendo"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.12033"
  },
  {
    "id": "arXiv:2202.12038",
    "title": "Restivo Salemi property for $\u03b1$-power free languages with  $\u03b1\\geq 4$ and $k\\geq 3$ letters",
    "abstract": "In 2009, Shur published the following conjecture: \\emph{Let $L$ be a\npower-free language and let $e(L)\\subseteq L$ be the set of words of $L$ that\ncan be extended to a bi-infinite word respecting the given power-freeness. If\n$u, v \\in e(L)$ then $uwv \\in e(L)$ for some word $w$.} Let $L_{k,\\alpha}$\ndenote an $\\alpha$-power free language over an alphabet with $k$ letters, where\n$\\alpha$ is a positive rational number and $k$ is positive integer. If\n$\\alpha\\geq 4$ and $k\\geq 3$ then we prove that the conjecture holds for the\nlanguage $L_{k,\\alpha}$.",
    "descriptor": "",
    "authors": [
      "Josef Rukavicka"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2202.12038"
  },
  {
    "id": "arXiv:2202.12039",
    "title": "Metacognitive Agents for Ethical Decision Support: Conceptual Model and  Research Roadmap",
    "abstract": "An ethical value-action gap exists when there is a discrepancy between\nintentions and actions. This discrepancy may be caused by social and structural\nobstacles as well as cognitive biases. Computational models of cognition and\naffect can provide insights into the value-action gap and how it can be\nreduced. In particular, metacognition (\"thinking about thinking\") plays an\nimportant role in many of these models as a mechanism for self-regulation and\nreasoning about mental attitudes. This paper outlines a roadmap for translating\ncognitive-affective models into assistant agents to help make value-aligned\ndecisions.",
    "descriptor": "",
    "authors": [
      "Catriona M. Kennedy"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.12039"
  },
  {
    "id": "arXiv:2202.12040",
    "title": "Self-Training: A Survey",
    "abstract": "In recent years, semi-supervised algorithms have received a lot of interest\nin both academia and industry. Among the existing techniques, self-training\nmethods have arguably received more attention in the last few years. These\nmodels are designed to search the decision boundary on low density regions\nwithout making extra assumptions on the data distribution, and use the unsigned\noutput score of a learned classifier, or its margin, as an indicator of\nconfidence. The working principle of self-training algorithms is to learn a\nclassifier iteratively by assigning pseudo-labels to the set of unlabeled\ntraining samples with a margin greater than a certain threshold. The\npseudo-labeled examples are then used to enrich the labeled training data and\ntrain a new classifier in conjunction with the labeled training set. We present\nself-training methods for binary and multiclass classification and their\nvariants which were recently developed using Neural Networks. Finally, we\ndiscuss our ideas for future research in self-training. To the best of our\nknowledge, this is the first thorough and complete survey on this subject.",
    "descriptor": "\nComments: 16 pages\n",
    "authors": [
      "Massih-Reza Amini",
      "Vasilii Feofanov",
      "Loic Pauletto",
      "Emilie Devijver",
      "Yury Maximov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.12040"
  },
  {
    "id": "arXiv:2202.12042",
    "title": "Parameterized Complexity of Graph Partitioning into Connected Clusters",
    "abstract": "Given an undirected graph $G$ and $q$ integers $n_1,n_2,n_3, \\cdots, n_q$,\nbalanced connected $q$-partition problem ($BCP_q$) asks whether there exists a\npartition of the vertex set $V$ of $G$ into $q$ parts $V_1,V_2,V_3,\\cdots, V_q$\nsuch that for all $i\\in[1,q]$, $|V_i|=n_i$ and the graph induced on $V_i$ is\nconnected. A related problem denoted as the balanced connected $q$-edge\npartition problem ($BCEP_q$) is defined as follows. Given an undirected graph\n$G$ and $q$ integers $n_1,n_2,n_3, \\cdots, n_q$, $BCEP_q$ asks whether there\nexists a partition of the edge set of $G$ into $q$ parts $E_1,E_2,E_3,\\cdots,\nE_q$ such that for all $i\\in[1,q]$, $|E_i|=n_i$ and the graph induced on the\nedge set $E_i$ is connected. Here we study both the problems for $q=2$ and\nprove that $BCP_q$ for $q\\geq 2$ is $W[1]$-hard. We also show that $BCP_2$ is\nunlikely to have a polynomial kernel on the class of planar graphs. Coming to\nthe positive results, we show that $BCP_2$ is fixed parameter tractable (FPT)\nparameterized by treewidth of the graph, which generalizes to FPT algorithm for\nplanar graphs. We design another FPT algorithm and a polynomial kernel on the\nclass of unit disk graphs parameterized by $\\min(n_1,n_2)$. Finally, we prove\nthat unlike $BCP_2$, $BCEP_2$ is FPT parameterized by $\\min(n_1,n_2)$.",
    "descriptor": "",
    "authors": [
      "Ankit Abhinav",
      "Susobhan Bandopadhyay",
      "Aritra Banik",
      "Saket Saurabh"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2202.12042"
  },
  {
    "id": "arXiv:2202.12049",
    "title": "When is Software a Medical Device? Understanding and Determining the  'Intention' and Requirements for Software as a Medical device in EU law",
    "abstract": "The role of software in society has changed drastically since the start of\nthe 21st century. Software can now partially or fully facilitate anything from\ndiagnosis to treatment of a disease, regardless of whether it is psychological\nor pathological, with the consequence of software being comparable to any other\ntype of medical equipment, and this makes discovering when software must comply\nwith such rules vital to both manufacturers and regulators. In lieu of the\nMedical Device Regulation we expand on the idea of intention, and identify the\ncriteria software must fulfil to be considered medical devices within EU-law.",
    "descriptor": "\nComments: 13 pages, 2 figures\n",
    "authors": [
      "Kaspar Rosager Ludvigsen",
      "Shishir Nagaraja",
      "Angela Daly"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2202.12049"
  },
  {
    "id": "arXiv:2202.12050",
    "title": "Experiments as Code: A Concept for Reproducible, Auditable, Debuggable,  Reusable, & Scalable Experiments",
    "abstract": "A common concern in experimental research is the auditability and\nreproducibility of experiments. Experiments are usually designed, provisioned,\nmanaged, and analyzed by diverse teams of specialists (e.g., researchers,\ntechnicians and engineers) and may require many resources (e.g. cloud\ninfrastructure, specialized equipment). Even though researchers strive to\ndocument experiments accurately, this process is often lacking, making it hard\nto reproduce them. Moreover, when it is necessary to create a similar\nexperiment, very often we end up \"reinventing the wheel\" as it is easier to\nstart from scratch than trying to reuse existing work, thus losing valuable\nembedded best practices and previous experiences. In behavioral studies this\nhas contributed to the reproducibility crisis. To tackle this challenge, we\npropose the \"Experiments as Code\" paradigm, where the whole experiment is not\nonly documented but additionally the automation code to provision, deploy,\nmanage, and analyze it is provided. To this end we define the Experiments as\nCode concept, provide a taxonomy for the components of a practical\nimplementation, and provide a proof of concept with a simple desktop VR\nexperiment that showcases the benefits of its \"as code\" representation, i.e.,\nreproducibility, auditability, debuggability, reusability, and scalability.",
    "descriptor": "",
    "authors": [
      "Leonel Aguilar",
      "Michal Gath-Morad",
      "Jascha Gr\u00fcbel",
      "Jasper Ermatinger",
      "Hantao Zhao",
      "Stefan Wehrli",
      "Robert W. Sumner",
      "Ce Zhang",
      "Dirk Helbing",
      "Christoph H\u00f6lscher"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2202.12050"
  },
  {
    "id": "arXiv:2202.12055",
    "title": "Counting Temporal Paths",
    "abstract": "The betweenness centrality of a vertex v is an important centrality measure\nthat quantifies how many optimal paths between pairs of other vertices visit v.\nComputing betweenness centrality in a temporal graph, in which the edge set may\nchange over discrete timesteps, requires us to count temporal paths that are\noptimal with respect to some criterion. For several natural notions of\noptimality, including foremost or fastest temporal paths, this counting problem\nreduces to #Temporal Path, the problem of counting all temporal paths between a\nfixed pair of vertices; like the problems of counting foremost and fastest\ntemporal paths, #Temporal Path is #P-hard in general. Motivated by the many\napplications of this intractable problem, we initiate a systematic study of the\nprameterised and approximation complexity of #Temporal Path. We show that the\nproblem presumably does not admit an FPT-algorithm for the feedback vertex\nnumber of the static underlying graph, and that it is hard to approximate in\ngeneral. On the positive side, we proved several exact and approximate\nFPT-algorithms for special cases.",
    "descriptor": "",
    "authors": [
      "Jessica Enright",
      "Kitty Meeks",
      "Hendrik Molter"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Complexity (cs.CC)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2202.12055"
  },
  {
    "id": "arXiv:2202.12058",
    "title": "Exploring the Unfairness of DP-SGD Across Settings",
    "abstract": "End users and regulators require private and fair artificial intelligence\nmodels, but previous work suggests these objectives may be at odds. We use the\nCivilComments to evaluate the impact of applying the {\\em de facto} standard\napproach to privacy, DP-SGD, across several fairness metrics. We evaluate three\nimplementations of DP-SGD: for dimensionality reduction (PCA), linear\nclassification (logistic regression), and robust deep learning (Group-DRO). We\nestablish a negative, logarithmic correlation between privacy and fairness in\nthe case of linear classification and robust deep learning. DP-SGD had no\nsignificant impact on fairness for PCA, but upon inspection, also did not seem\nto lead to private representations.",
    "descriptor": "\nComments: 6 pages, 3 figures, this https URL\n",
    "authors": [
      "Frederik Noe",
      "Rasmus Herskind",
      "Anders S\u00f8gaard"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.12058"
  },
  {
    "id": "arXiv:2202.12059",
    "title": "AFFDEX 2.0: A Real-Time Facial Expression Analysis Toolkit",
    "abstract": "In this paper we introduce AFFDEX 2.0 - a toolkit for analyzing facial\nexpressions in the wild, that is, it is intended for users aiming to; a)\nestimate the 3D head pose, b) detect facial Action Units (AUs), c) recognize\nbasic emotions and 2 new emotional states (sentimentality and confusion), and\nd) detect high-level expressive metrics like blink and attention. AFFDEX 2.0\nmodels are mainly based on Deep Learning, and are trained using a large-scale\nnaturalistic dataset consisting of thousands of participants from different\ndemographic groups. AFFDEX 2.0 is an enhanced version of our previous toolkit\n[1], that is capable of tracking efficiently faces at more challenging\nconditions, detecting more accurately facial expressions, and recognizing new\nemotional states (sentimentality and confusion). AFFDEX 2.0 can process\nmultiple faces in real time, and is working across the Windows and Linux\nplatforms.",
    "descriptor": "\nComments: ICIP 2022\n",
    "authors": [
      "Mina Bishay",
      "Kenneth Preston",
      "Matthew Strafuss",
      "Graham Page",
      "Jay Turcot",
      "Mohammad Mavadati"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.12059"
  },
  {
    "id": "arXiv:2202.12064",
    "title": "Interfering Paths in Decision Trees: A Note on Deodata Predictors",
    "abstract": "A technique for improving the prediction accuracy of decision trees is\nproposed. It consists in evaluating the tree's branches in parallel over\nmultiple paths. The technique enables predictions that are more aligned with\nthe ones generated by the nearest neighborhood variant of the deodata\nalgorithms. The technique also enables the hybridization of the decision tree\nalgorithm with the nearest neighborhood variant.",
    "descriptor": "",
    "authors": [
      "Cristian Alb"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.12064"
  },
  {
    "id": "arXiv:2202.12065",
    "title": "Activation Functions: Dive into an optimal activation function",
    "abstract": "Activation functions have come up as one of the essential components of\nneural networks. The choice of adequate activation function can impact the\naccuracy of these methods. In this study, we experiment for finding an optimal\nactivation function by defining it as a weighted sum of existing activation\nfunctions and then further optimizing these weights while training the network.\nThe study uses three activation functions, ReLU, tanh, and sin, over three\npopular image datasets, MNIST, FashionMNIST, and KMNIST. We observe that the\nReLU activation function can easily overlook other activation functions. Also,\nwe see that initial layers prefer to have ReLU or LeakyReLU type of activation\nfunctions, but deeper layers tend to prefer more convergent activation\nfunctions.",
    "descriptor": "",
    "authors": [
      "Vipul Bansal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.12065"
  },
  {
    "id": "arXiv:2202.12069",
    "title": "Regulations Aware Motion Planning for Autonomous Surface Vessels in  Urban Canals",
    "abstract": "In unstructured urban canals, regulation-aware interactions with other\nvessels are essential for collision avoidance and social compliance. In this\npaper, we propose a regulations aware motion planning framework for Autonomous\nSurface Vessels (ASVs) that accounts for dynamic and static obstacles. Our\nmethod builds upon local model predictive contouring control (LMPCC) to\ngenerate motion plans satisfying kino-dynamic and collision constraints in\nreal-time while including regulation awareness. To incorporate regulations in\nthe planning stage, we propose a cost function encouraging compliance with\nrules describing interactions with other vessels similar to COLlision avoidance\nREGulations at sea (COLREGs). These regulations are essential to make an ASV\nbehave in a predictable and socially compliant manner with regard to other\nvessels. We compare the framework against baseline methods and show more\neffective regulation-compliance avoidance of moving obstacles with our motion\nplanner. Additionally, we present experimental results in an outdoor\nenvironment",
    "descriptor": "\nComments: Submitted at ICRA 2022\n",
    "authors": [
      "Jitske de Vries",
      "Elia Trevisan",
      "Jules van der Toorn",
      "Tuhin Das",
      "Bruno Brito",
      "Javier Alonso-Mora"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.12069"
  },
  {
    "id": "arXiv:2202.12073",
    "title": "Random primes without primality testing",
    "abstract": "Numerous algorithms call for computation over the integers modulo a\nrandomly-chosen large prime. In some cases, the quasi-cubic complexity of\nselecting a random prime can dominate the total running time. We propose a new\nvariant of the classic D5 algorithm for \"dynamic evaluation\", applied to a\nrandomly-chosen (composite) integer. Unlike the D5 principle which has been\nused in the past to compute over a direct product of fields, our method is\nsimpler as it only requires following a single path after any modulus splits.\nThe transformation we propose can apply to any algorithm in the algebraic RAM\nmodel, even allowing randomization. The resulting transformed algorithm avoids\nany primality tests and will, with constant positive probability, have the same\nresult as the original computation modulo a randomly-chosen prime. As an\napplication, we demonstrate how to compute the exact number of nonzero terms in\nan unknown integer polynomial in quasi-linear time. We also show how the same\nalgorithmic transformation technique can be used for computing modulo random\nirreducible polynomials over a finite field.",
    "descriptor": "",
    "authors": [
      "Pascal Giorgi",
      "Bruno Grenet",
      "Armelle Perret du Cray",
      "Daniel S. Roche"
    ],
    "subjectives": [
      "Symbolic Computation (cs.SC)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2202.12073"
  },
  {
    "id": "arXiv:2202.12074",
    "title": "Investigating the Use of One-Class Support Vector Machine for Software  Defect Prediction",
    "abstract": "Early software defect identification is considered an important step towards\nsoftware quality assurance. Software defect prediction aims at identifying\nsoftware components that are likely to cause faults before a software is made\navailable to the end-user. To date, this task has been modeled as a two-class\nclassification problem, however its nature also allows it to be formulated as a\none-class classification task.\nPreliminary results obtained in prior work show that One-Class Support Vector\nMachine (OCSVM) can outperform two-class classifiers for defect prediction. If\nconfirmed, these results would overcome the data imbalance problem researchers\nhave for long attempted to tackle in this field.\nIn this paper, we further investigate whether learning from one class only is\nsufficient to produce effective defect prediction models by conducting a\nthorough large-scale empirical study investigating 15 real-world software\nprojects, three validation scenarios, eight classifiers, robust evaluation\nmeasures and statistical significance tests. The results reveal that OCSVM is\nmore suitable for cross-version and cross-project, rather than for\nwithin-project defect prediction, thus suggesting it performs better with\nheterogeneous data. While, we cannot conclude that OCSVM is the best classifier\n(Random Forest performs best herein), our results show interesting findings\nthat open up further research avenues for training accurate defect prediction\nclassifiers when defective instances are scarce or unavailable.",
    "descriptor": "",
    "authors": [
      "Rebecca Moussa",
      "Danielle Azar",
      "Federica Sarro"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.12074"
  },
  {
    "id": "arXiv:2202.12076",
    "title": "Phrase-Based Affordance Detection via Cyclic Bilateral Interaction",
    "abstract": "Affordance detection, which refers to perceiving objects with potential\naction possibilities in images, is a challenging task since the possible\naffordance depends on the person's purpose in real-world application scenarios.\nThe existing works mainly extract the inherent human-object dependencies from\nimage/video to accommodate affordance properties that change dynamically. In\nthis paper, we explore to perceive affordance from a vision-language\nperspective and consider the challenging phrase-based affordance detection\nproblem,i.e., given a set of phrases describing the action purposes, all the\nobject regions in a scene with the same affordance should be detected. To this\nend, we propose a cyclic bilateral consistency enhancement network (CBCE-Net)\nto align language and vision features progressively. Specifically, the\npresented CBCE-Net consists of a mutual guided vision-language module that\nupdates the common features of vision and language in a progressive manner, and\na cyclic interaction module (CIM) that facilitates the perception of possible\ninteraction with objects in a cyclic manner. In addition, we extend the public\nPurpose-driven Affordance Dataset (PAD) by annotating affordance categories\nwith short phrases. The contrastive experimental results demonstrate the\nsuperiority of our method over nine typical methods from four relevant fields\nin terms of both objective metrics and visual quality. The related code and\ndataset will be released at \\url{https://github.com/lulsheng/CBCE-Net}.",
    "descriptor": "",
    "authors": [
      "Liangsheng Lu",
      "Wei Zhai",
      "Hongchen Luo",
      "Yu Kang",
      "Yang Cao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.12076"
  },
  {
    "id": "arXiv:2202.12081",
    "title": "Community Trend Prediction on Heterogeneous Graph in E-commerce",
    "abstract": "In online shopping, ever-changing fashion trends make merchants need to\nprepare more differentiated products to meet the diversified demands, and\ne-commerce platforms need to capture the market trend with a prophetic vision.\nFor the trend prediction, the attribute tags, as the essential description of\nitems, can genuinely reflect the decision basis of consumers. However, few\nexisting works explore the attribute trend in the specific community for\ne-commerce. In this paper, we focus on the community trend prediction on the\nitem attribute and propose a unified framework that combines the dynamic\nevolution of two graph patterns to predict the attribute trend in a specific\ncommunity. Specifically, we first design a communityattribute bipartite graph\nat each time step to learn the collaboration of different communities. Next, we\ntransform the bipartite graph into a hypergraph to exploit the associations of\ndifferent attribute tags in one community. Lastly, we introduce a dynamic\nevolution component based on the recurrent neural networks to capture the\nfashion trend of attribute tags. Extensive experiments on three real-world\ndatasets in a large e-commerce platform show the superiority of the proposed\napproach over several strong alternatives and demonstrate the ability to\ndiscover the community trend in advance.",
    "descriptor": "\nComments: Published as a full paper at WSDM 2022\n",
    "authors": [
      "Jiahao Yuan",
      "Zhao Li",
      "Pengcheng Zou",
      "Xuan Gao",
      "Jinwei Pan",
      "Wendi Ji",
      "Xiaoling Wang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2202.12081"
  },
  {
    "id": "arXiv:2202.12085",
    "title": "pHGen: A pH-Based Key Generation Mechanism Using ISFETs",
    "abstract": "Digital keys are a fundamental component of many hardware- and software-based\nsecurity mechanisms. However, digital keys are limited to binary values and\neasily exploitable when stored in standard memories. In this paper, based on\nemerging technologies, we introduce pHGen, a potential-of-hydrogen (pH)-based\nkey generation mechanism that leverages chemical reactions in the form of a\npotential change in ion-sensitive field-effect transistors (ISFETs). The\nthreshold voltage of ISFETs is manipulated corresponding to a known pH buffer\nsolution (key) in which the transistors are immersed. To read the chemical\ninformation effectively via ISFETs, we designed a readout circuit for stable\noperation and detection of voltage thresholds. To demonstrate the applicability\nof the proposed key generation, we utilize pHGen for logic locking -- a\nhardware integrity protection scheme. The proposed key-generation method breaks\nthe limits of binary values and provides the first steps toward the utilization\nof multi-valued voltage thresholds of ISFETs controlled by chemical\ninformation. The pHGen approach is expected to be a turning point for using\nmore sophisticated bio-based analog keys for securing next-generation\nelectronics.",
    "descriptor": "\nComments: Accepted in HOST 2022\n",
    "authors": [
      "Elmira Moussavi",
      "Dominik Sisejkovic",
      "Fabian Brings",
      "Daniyar Kizatov",
      "Animesh Singh",
      "Xuan Thang Vu",
      "Sven Ingebrandt",
      "Rainer Leupers",
      "Vivek Pachauri",
      "Farhad Merchant"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2202.12085"
  },
  {
    "id": "arXiv:2202.12087",
    "title": "SQuadMDS: a lean Stochastic Quartet MDS improving global structure  preservation in neighbor embedding like t-SNE and UMAP",
    "abstract": "Multidimensional scaling is a statistical process that aims to embed high\ndimensional data into a lower-dimensional space; this process is often used for\nthe purpose of data visualisation. Common multidimensional scaling algorithms\ntend to have high computational complexities, making them inapplicable on large\ndata sets. This work introduces a stochastic, force directed approach to\nmultidimensional scaling with a time and space complexity of O(N), with N data\npoints. The method can be combined with force directed layouts of the family of\nneighbour embedding such as t-SNE, to produce embeddings that preserve both the\nglobal and the local structures of the data. Experiments assess the quality of\nthe embeddings produced by the standalone version and its hybrid extension both\nquantitatively and qualitatively, showing competitive results outperforming\nstate-of-the-art approaches. Codes are available at\nhttps://github.com/PierreLambert3/SQuaD-MDS-and-FItSNE-hybrid.",
    "descriptor": "",
    "authors": [
      "Pierre Lambert",
      "Cyril de Bodt",
      "Michel Verleysen",
      "John Lee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.12087"
  },
  {
    "id": "arXiv:2202.12093",
    "title": "KESA: A Knowledge Enhanced Approach For Sentiment Analysis",
    "abstract": "Though some recent works focus on injecting sentiment knowledge into\npre-trained language models, they usually design mask and reconstruction tasks\nin the post-training phase. In this paper, we aim to benefit from sentiment\nknowledge in a lighter way. To achieve this goal, we study sentence-level\nsentiment analysis and, correspondingly, propose two sentiment-aware auxiliary\ntasks named sentiment word cloze and conditional sentiment prediction. The\nfirst task learns to select the correct sentiment words within the input, given\nthe overall sentiment polarity as prior knowledge. On the contrary, the second\ntask predicts the overall sentiment polarity given the sentiment polarity of\nthe word as prior knowledge. In addition, two kinds of label combination\nmethods are investigated to unify multiple types of labels in each task. We\nargue that more information can promote the models to learn more profound\nsemantic representation. We implement it in a straightforward way to verify\nthis hypothesis. The experimental results demonstrate that our approach\nconsistently outperforms pre-trained models and is additive to existing\nknowledge-enhanced post-trained models. The code and data are released at\nhttps://github.com/lshowway/KESA.",
    "descriptor": "",
    "authors": [
      "Qinghua Zhao",
      "Shuai Ma",
      "Shuo Ren"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.12093"
  },
  {
    "id": "arXiv:2202.12098",
    "title": "Numerical reconstruction from the Fourier transform on the ball using  prolate spheroidal wave functions",
    "abstract": "We implement numerically formulas of [Isaev, Novikov, arXiv:2107.07882] for\nfinding a compactly supported function $v$ on $\\mathbb{R}^d$, $d\\geq 1$, from\nits Fourier transform $\\mathcal{F} [v]$ given within the ball $B_r$. For the\none-dimensional case, these formulas are based on the theory of prolate\nspheroidal wave functions, which arise, in particular, in the singular value\ndecomposition of the aforementioned band-limited Fourier transform for $d = 1$.\nIn multidimensions, these formulas also include inversion of the Radon\ntransform. In particular, we give numerical examples of super-resolution, that\nis, recovering details beyond the diffraction limit.",
    "descriptor": "",
    "authors": [
      "Mikhail Isaev",
      "Roman G. Novikov",
      "Grigory V. Sabinin"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Classical Analysis and ODEs (math.CA)"
    ],
    "url": "https://arxiv.org/abs/2202.12098"
  },
  {
    "id": "arXiv:2202.12100",
    "title": "DeepFusionMOT: A 3D Multi-Object Tracking Framework Based on  Camera-LiDAR Fusion with Deep Association",
    "abstract": "In the recent literature, on the one hand, many 3D multi-object tracking\n(MOT) works have focused on tracking accuracy and neglected computation speed,\ncommonly by designing rather complex cost functions and feature extractors. On\nthe other hand, some methods have focused too much on computation speed at the\nexpense of tracking accuracy. In view of these issues, this paper proposes a\nrobust and fast camera-LiDAR fusion-based MOT method that achieves a good\ntrade-off between accuracy and speed. Relying on the characteristics of camera\nand LiDAR sensors, an effective deep association mechanism is designed and\nembedded in the proposed MOT method. This association mechanism realizes\ntracking of an object in a 2D domain when the object is far away and only\ndetected by the camera, and updating of the 2D trajectory with 3D information\nobtained when the object appears in the LiDAR field of view to achieve a smooth\nfusion of 2D and 3D trajectories. Extensive experiments based on the KITTI\ndataset indicate that our proposed method presents obvious advantages over the\nstate-of-the-art MOT methods in terms of both tracking accuracy and processing\nspeed. Our code is made publicly available for the benefit of the community",
    "descriptor": "\nComments: 8 pages, 4 figures, 4 tables\n",
    "authors": [
      "Xiyang Wang",
      "Chunyun Fu",
      "Zhankun Li",
      "Ying Lai",
      "Jiawei He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.12100"
  },
  {
    "id": "arXiv:2202.12107",
    "title": "From Natural Language to Simulations: Applying GPT-3 Codex to Automate  Simulation Modeling of Logistics Systems",
    "abstract": "Our work is the first attempt to apply Natural Language Processing to\nautomate the development of simulation models of logistics systems. We\ndemonstrated that the framework built on top of the fine-tuned\nTransdormer-based language model could produce functionally valid simulations\nof queuing and inventory control systems given the verbal description. The\nproposed framework has the potential to remove the tedium of programming and\nallow experts to focus on the high-level consideration of the problem and\nholistic thinking.",
    "descriptor": "",
    "authors": [
      "Ilya Jackson",
      "Maria Jesus Saenz"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.12107"
  },
  {
    "id": "arXiv:2202.12108",
    "title": "Light Robust Monocular Depth Estimation For Outdoor Environment Via  Monochrome And Color Camera Fusion",
    "abstract": "Depth estimation plays a important role in SLAM, odometry, and autonomous\ndriving. Especially, monocular depth estimation is profitable technology\nbecause of its low cost, memory, and computation. However, it is not a\nsufficiently predicting depth map due to a camera often failing to get a clean\nimage because of light conditions. To solve this problem, various sensor fusion\nmethod has been proposed. Even though it is a powerful method, sensor fusion\nrequires expensive sensors, additional memory, and high computational\nperformance.\nIn this paper, we present color image and monochrome image pixel-level fusion\nand stereo matching with partially enhanced correlation coefficient\nmaximization. Our methods not only outperform the state-of-the-art works across\nall metrics but also efficient in terms of cost, memory, and computation. We\nalso validate the effectiveness of our design with an ablation study.",
    "descriptor": "",
    "authors": [
      "Hyeonsoo Jang",
      "Yeongmin Ko",
      "Younkwan Lee",
      "Moongu Jeon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.12108"
  },
  {
    "id": "arXiv:2202.12109",
    "title": "Prompt for Extraction? PAIE: Prompting Argument Interaction for Event  Argument Extraction",
    "abstract": "In this paper, we propose an effective yet efficient model PAIE for both\nsentence-level and document-level Event Argument Extraction (EAE), which also\ngeneralizes well when there is a lack of training data. On the one hand, PAIE\nutilizes prompt tuning for extractive objectives to take the best advantages of\nPre-trained Language Models (PLMs). It introduces two span selectors based on\nprompt to select start/end tokens among input texts for each role. On the other\nhand, we capture argument interactions via multi-role prompts, and conduct\njoint optimization with optimal span assignments via a bipartite matching loss.\nAlso, with flexible prompt design, PAIE can extract multiple arguments with the\nsame role, instead of conventional heuristic threshold tuning. We have\nconducted extensive experiments on three benchmarks, including both sentence-\nand document-level EAE. The results present a promising improvements from PAIE\n(1.1% and 3.8% F1 gains on average in sentence-level and document-level\nrespectively). Further analysis demonstrates the efficiency, generalization to\nfew-shot settings and effectiveness of different extractive prompt tuning\nstrategies. We will release our codes upon acceptance.",
    "descriptor": "\nComments: Accepted by ACL 2022 main conference\n",
    "authors": [
      "Yubo Ma",
      "Zehao Wang",
      "Yixin Cao",
      "Mukai Li",
      "Meiqi Chen",
      "Kun Wang",
      "Jing Shao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.12109"
  },
  {
    "id": "arXiv:2202.12111",
    "title": "An Algorithm for Computing the Covering Radius of a Linear Code Based on  Vilenkin-Chrestenson Transform",
    "abstract": "We present a generalization of Walsh-Hadamard transform that is suitable for\napplications in Coding Theory, especially for computation of the weight\ndistribution and the covering radius of a linear code over a finite field. The\ntransform used in our research, is a modification of Vilenkin-Chrestenson\ntransform. Instead of using all the vectors in the considered space, we take a\nmaximal set of nonproportional vectors, which reduces the computational\ncomplexity.",
    "descriptor": "",
    "authors": [
      "Paskal Piperkov",
      "Iliya Bouyukliev",
      "Stefka Bouyuklieva"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2202.12111"
  },
  {
    "id": "arXiv:2202.12116",
    "title": "Slow-Fast Visual Tempo Learning for Video-based Action Recognition",
    "abstract": "Action visual tempo characterizes the dynamics and the temporal scale of an\naction, which is helpful to distinguish human actions that share high\nsimilarities in visual dynamics and appearance. Previous methods capture the\nvisual tempo either by sampling raw videos with multiple rates, which requires\na costly multi-layer network to handle each rate, or by hierarchically sampling\nbackbone features, which relies heavily on high-level features that miss\nfine-grained temporal dynamics. In this work, we propose a Temporal Correlation\nModule (TCM), which can be easily embedded into the current action recognition\nbackbones in a plug-in-and-play manner, to extract action visual tempo from\nlow-level backbone features at single-layer remarkably. Specifically, our TCM\ncontains two main components: a Multi-scale Temporal Dynamics Module (MTDM) and\na Temporal Attention Module (TAM). MTDM applies a correlation operation to\nlearn pixel-wise fine-grained temporal dynamics for both fast-tempo and\nslow-tempo. TAM adaptively emphasizes expressive features and suppresses\ninessential ones via analyzing the global information across various tempos.\nExtensive experiments conducted on several action recognition benchmarks, e.g.\nSomething-Something V1 & V2, Kinetics-400, UCF-101, and HMDB-51, have\ndemonstrated that the proposed TCM is effective to promote the performance of\nthe existing video-based action recognition models for a large margin. The\nsource code is publicly released at https://github.com/zphyix/TCM.",
    "descriptor": "",
    "authors": [
      "Yuanzhong Liu",
      "Zhigang Tu",
      "Hongyan Li",
      "Chi Chen",
      "Baoxin Li",
      "Junsong Yuan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.12116"
  },
  {
    "id": "arXiv:2202.12119",
    "title": "Optimal Learning Rates of Deep Convolutional Neural Networks: Additive  Ridge Functions",
    "abstract": "Convolutional neural networks have shown extraordinary abilities in many\napplications, especially those related to the classification tasks. However,\nfor the regression problem, the abilities of convolutional structures have not\nbeen fully understood, and further investigation is needed. In this paper, we\nconsider the mean squared error analysis for deep convolutional neural\nnetworks. We show that, for additive ridge functions, convolutional neural\nnetworks followed by one fully connected layer with ReLU activation functions\ncan reach optimal mini-max rates (up to a log factor). The convergence rates\nare dimension independent. This work shows the statistical optimality of\nconvolutional neural networks and may shed light on why convolutional neural\nnetworks are able to behave well for high dimensional input.",
    "descriptor": "",
    "authors": [
      "Zhiying Fang",
      "Guang Cheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2202.12119"
  },
  {
    "id": "arXiv:2202.12120",
    "title": "Temporal Convolution Domain Adaptation Learning for Crops Growth  Prediction",
    "abstract": "Existing Deep Neural Nets on crops growth prediction mostly rely on\navailability of a large amount of data. In practice, it is difficult to collect\nenough high-quality data to utilize the full potential of these deep learning\nmodels. In this paper, we construct an innovative network architecture based on\ndomain adaptation learning to predict crops growth curves with limited\navailable crop data. This network architecture overcomes the challenge of data\navailability by incorporating generated data from the developed crops\nsimulation model. We are the first to use the temporal convolution filters as\nthe backbone to construct a domain adaptation network architecture which is\nsuitable for deep learning regression models with very limited training data of\nthe target domain. We conduct experiments to test the performance of the\nnetwork and compare our proposed architecture with other state-of-the-art\nmethods, including a recent LSTM-based domain adaptation network architecture.\nThe results show that the proposed temporal convolution-based network\narchitecture outperforms all benchmarks not only in accuracy but also in model\nsize and convergence rate.",
    "descriptor": "",
    "authors": [
      "Shengzhe Wang",
      "Ling Wang",
      "Zhihao Lin",
      "Xi Zheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.12120"
  },
  {
    "id": "arXiv:2202.12122",
    "title": "Demonstrating BrainScaleS 2 Inter-Chip Pulse Communication using Extoll",
    "abstract": "The BrainScaleS-2 (BSS-2) Neuromorphic Computing System currently consists of\nmultiple single-chip setups, which are connected to a compute cluster via\nGigabit-Ethernet network technology. This is convenient for small experiments,\nwhere the neural networks fit into a single chip. When modeling networks of\nlarger size, neurons have to be connected across chip boundaries. We implement\nthese connections for BSS-2 using the Extoll networking technology, which\nprovides high bandwidths and low latencies, as well as high message rates.\nHere, we describe the targeted pulse-routing implementation and required\nextensions to the BSS-2 software stack, and demonstrate feed-forward\npulse-routing on BSS-2 using a scaled-down version without temporal merging.\nThe results of this scaled-down implementation will be ready for the\nconference.",
    "descriptor": "\nComments: 3 pages, 2 figures, submitted to the Neuro Inspired Computational Elements 2022 (NICE'2022) conference, accepted and presented as a lightning-talk in March 2022\n",
    "authors": [
      "Tobias Thommes",
      "Sven Bordukat",
      "Andreas Gr\u00fcbl",
      "Vitali Karasenko",
      "Eric M\u00fcller",
      "Johannes Schemmel"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2202.12122"
  },
  {
    "id": "arXiv:2202.12123",
    "title": "An Information-theoretical Approach to Semi-supervised Learning under  Covariate-shift",
    "abstract": "A common assumption in semi-supervised learning is that the labeled,\nunlabeled, and test data are drawn from the same distribution. However, this\nassumption is not satisfied in many applications. In many scenarios, the data\nis collected sequentially (e.g., healthcare) and the distribution of the data\nmay change over time often exhibiting so-called covariate shifts. In this\npaper, we propose an approach for semi-supervised learning algorithms that is\ncapable of addressing this issue. Our framework also recovers some popular\nmethods, including entropy minimization and pseudo-labeling. We provide new\ninformation-theoretical based generalization error upper bounds inspired by our\nnovel framework. Our bounds are applicable to both general semi-supervised\nlearning and the covariate-shift scenario. Finally, we show numerically that\nour method outperforms previous approaches proposed for semi-supervised\nlearning under the covariate shift.",
    "descriptor": "\nComments: Accepted at AISTATS 2022\n",
    "authors": [
      "Gholamali Aminian",
      "Mahed Abroshan",
      "Mohammad Mahdi Khalili",
      "Laura Toni",
      "Miguel R. D. Rodrigues"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.12123"
  },
  {
    "id": "arXiv:2202.12124",
    "title": "Projected gradient-tracking in multi-cluster games and its application  to power management",
    "abstract": "We are concerned with a distributed approach to solve multi-cluster games\narising in multi-agent systems. In such games, agents are separated into\ndistinct clusters. The agents belonging to the same cluster cooperate with each\nother to achieve a common cluster goal while a non-cooperative game is played\nbetween the clusters. To be able to deal with the sparsity of information, as\neach agent only knows a specific part of the problem, we combine\ngradient-tracking and consensus methods for information distribution into an\nalgorithm that can solve both the cooperative and non-cooperative problem in a\nsingle run. The constraints of the problem are taken into account by the\ncorresponding projection operators and linear convergence is proven given an\nappropriate constant step size. The algorithm is applied to a day-ahead power\nmanagement problem, posed as a multi-cluster game, and its efficiency is\ndemonstrated by simulations.",
    "descriptor": "",
    "authors": [
      "Jan Zimmermann",
      "Tatiana Tatarenko",
      "Volker Willert",
      "J\u00fcrgen Adamy"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.12124"
  },
  {
    "id": "arXiv:2202.12131",
    "title": "The Shortest Path with Increasing Chords in a Simple Polygon",
    "abstract": "We study the problem of finding the shortest path with increasing chords in a\nsimple polygon. A path has increasing chords if and only if for any points a,\nb, c, and d that lie on the path in that order, |ad| >= |bc|. In this paper we\nshow that the shortest path with increasing chords is unique and present an\nalgorithm to construct it.",
    "descriptor": "",
    "authors": [
      "Mart Hagedoorn",
      "Irina Kostitsyna"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2202.12131"
  },
  {
    "id": "arXiv:2202.12132",
    "title": "\"splink\" is happy and \"phrouth\" is scary: Emotion Intensity Analysis for  Nonsense Words",
    "abstract": "People associate affective meanings to words -- \"death\" is scary and sad\nwhile \"party\" is connotated with surprise and joy. This raises the question if\nthe association is purely a product of the learned affective imports inherent\nto semantic meanings, or is also an effect of other features of words, e.g.,\nmorphological and phonological patterns. We approach this question with an\nannotation-based analysis leveraging nonsense words. Specifically, we conduct a\nbest-worst scaling crowdsourcing study in which participants assign intensity\nscores for joy, sadness, anger, disgust, fear, and surprise to 272 non-sense\nwords and, for comparison of the results to previous work, to 68 real words.\nBased on this resource, we develop character-level and phonology-based\nintensity regressors and evaluate them on real and nonsense words, and across\nthese categories (making use of the NRC emotion intensity lexicon of 7493\nwords). The data analysis reveals that some phonetic patterns show clear\ndifferences between emotion intensities. For instance, s as a first phoneme\ncontributes to joy, sh to surprise, p as last phoneme more to disgust than to\nanger and fear. In the modelling experiments, a regressor trained on real words\nfrom the NRC emotion intensity lexicon shows a higher performance (r = 0.17)\nthan regressors that aim at learning the emotion connotation purely from\nnonsense words. We conclude that humans do associate affective meaning to words\nbased on surface patterns, but also based on similarities to existing words\n(\"juy\" to \"joy\", or \"flike\" to \"like\").",
    "descriptor": "",
    "authors": [
      "Valentino Sabbatino",
      "Enrica Troiano",
      "Antje Schweitzer",
      "Roman Klinger"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.12132"
  },
  {
    "id": "arXiv:2202.12138",
    "title": "How reparametrization trick broke differentially-private text  representation leaning",
    "abstract": "As privacy gains traction in the NLP community, researchers have started\nadopting various approaches to privacy-preserving methods. One of the favorite\nprivacy frameworks, differential privacy (DP), is perhaps the most compelling\nthanks to its fundamental theoretical guarantees. Despite the apparent\nsimplicity of the general concept of differential privacy, it seems non-trivial\nto get it right when applying it to NLP. In this short paper, we formally\nanalyze several recent NLP papers proposing text representation learning using\nDPText (Beigi et al., 2019a,b; Alnasser et al., 2021; Beigi et al., 2021) and\nreveal their false claims of being differentially private. Furthermore, we also\nshow a simple yet general empirical sanity check to determine whether a given\nimplementation of a DP mechanism almost certainly violates the privacy loss\nguarantees. Our main goal is to raise awareness and help the community\nunderstand potential pitfalls of applying differential privacy to text\nrepresentation learning.",
    "descriptor": "\nComments: Pre-print version; Accepted at ACL 2022\n",
    "authors": [
      "Ivan Habernal"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.12138"
  },
  {
    "id": "arXiv:2202.12139",
    "title": "Testing Deep Learning Models: A First Comparative Study of Multiple  Testing Techniques",
    "abstract": "Deep Learning (DL) has revolutionized the capabilities of vision-based\nsystems (VBS) in critical applications such as autonomous driving, robotic\nsurgery, critical infrastructure surveillance, air and maritime traffic\ncontrol, etc. By analyzing images, voice, videos, or any type of complex\nsignals, DL has considerably increased the situation awareness of these\nsystems. At the same time, while relying more and more on trained DL models,\nthe reliability and robustness of VBS have been challenged and it has become\ncrucial to test thoroughly these models to assess their capabilities and\npotential errors. To discover faults in DL models, existing software testing\nmethods have been adapted and refined accordingly. In this article, we provide\nan overview of these software testing methods, namely differential,\nmetamorphic, mutation, and combinatorial testing, as well as adversarial\nperturbation testing and review some challenges in their deployment for\nboosting perception systems used in VBS. We also provide a first experimental\ncomparative study on a classical benchmark used in VBS and discuss its results.",
    "descriptor": "\nComments: Artificial Intelligence in Software Testing 2022 workshop @ ICST 2022\n",
    "authors": [
      "Mohit Kumar Ahuja",
      "Arnaud Gotlieb",
      "Helge Spieker"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.12139"
  },
  {
    "id": "arXiv:2202.12142",
    "title": "Pretraining without Wordpieces: Learning Over a Vocabulary of Millions  of Words",
    "abstract": "The standard BERT adopts subword-based tokenization, which may break a word\ninto two or more wordpieces (e.g., converting \"lossless\" to \"loss\" and \"less\").\nThis will bring inconvenience in following situations: (1) what is the best way\nto obtain the contextual vector of a word that is divided into multiple\nwordpieces? (2) how to predict a word via cloze test without knowing the number\nof wordpieces in advance? In this work, we explore the possibility of\ndeveloping BERT-style pretrained model over a vocabulary of words instead of\nwordpieces. We call such word-level BERT model as WordBERT. We train models\nwith different vocabulary sizes, initialization configurations and languages.\nResults show that, compared to standard wordpiece-based BERT, WordBERT makes\nsignificant improvements on cloze test and machine reading comprehension. On\nmany other natural language understanding tasks, including POS tagging,\nchunking and NER, WordBERT consistently performs better than BERT. Model\nanalysis indicates that the major advantage of WordBERT over BERT lies in the\nunderstanding for low-frequency words and rare words. Furthermore, since the\npipeline is language-independent, we train WordBERT for Chinese language and\nobtain significant gains on five natural language understanding datasets.\nLastly, the analyse on inference speed illustrates WordBERT has comparable time\ncost to BERT in natural language understanding tasks.",
    "descriptor": "",
    "authors": [
      "Zhangyin Feng",
      "Duyu Tang",
      "Cong Zhou",
      "Junwei Liao",
      "Shuangzhi Wu",
      "Xiaocheng Feng",
      "Bing Qin",
      "Yunbo Cao",
      "Shuming Shi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.12142"
  },
  {
    "id": "arXiv:2202.12150",
    "title": "Tighter Expected Generalization Error Bounds via Convexity of  Information Measures",
    "abstract": "Generalization error bounds are essential to understanding machine learning\nalgorithms. This paper presents novel expected generalization error upper\nbounds based on the average joint distribution between the output hypothesis\nand each input training sample. Multiple generalization error upper bounds\nbased on different information measures are provided, including Wasserstein\ndistance, total variation distance, KL divergence, and Jensen-Shannon\ndivergence. Due to the convexity of the information measures, the proposed\nbounds in terms of Wasserstein distance and total variation distance are shown\nto be tighter than their counterparts based on individual samples in the\nliterature. An example is provided to demonstrate the tightness of the proposed\ngeneralization error bounds.",
    "descriptor": "\nComments: 10 pages, 1 figure\n",
    "authors": [
      "Gholamali Aminian",
      "Yuheng Bu",
      "Gregory Wornell",
      "Miguel Rodrigues"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.12150"
  },
  {
    "id": "arXiv:2202.12152",
    "title": "Discrete approximation of the Griffith functional by adaptative finite  elements",
    "abstract": "This paper is devoted to show a discrete adaptative finite element\napproximation result for the isotropic two-dimensional Griffith energy arising\nin fracture mechanics. The problem is addressed in the geometric measure\ntheoretic framework of generalized special functions of bounded deformation\nwhich corresponds to the natural energy space for this functional. It is proved\nto be approximated in the sense of $\\Gamma$-convergence by a sequence of\ndiscrete integral functionals defined on continuous piecewise affine functions.\nThe main feature of this result is that the mesh is part of the unknown of the\nproblem, and it gives enough flexibility to recover isotropic surface energies.",
    "descriptor": "",
    "authors": [
      "Jean-Fran\u00e7ois Babadjian",
      "\u00c9lise Bonhomme"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)"
    ],
    "url": "https://arxiv.org/abs/2202.12152"
  },
  {
    "id": "arXiv:2202.12154",
    "title": "Towards Effective and Robust Neural Trojan Defenses via Input Filtering",
    "abstract": "Trojan attacks on deep neural networks are both dangerous and surreptitious.\nOver the past few years, Trojan attacks have advanced from using only a simple\ntrigger and targeting only one class to using many sophisticated triggers and\ntargeting multiple classes. However, Trojan defenses have not caught up with\nthis development. Most defense methods still make out-of-date assumptions about\nTrojan triggers and target classes, thus, can be easily circumvented by modern\nTrojan attacks. In this paper, we advocate general defenses that are effective\nand robust against various Trojan attacks and propose two novel \"filtering\"\ndefenses with these characteristics called Variational Input Filtering (VIF)\nand Adversarial Input Filtering (AIF). VIF and AIF leverage variational\ninference and adversarial training respectively to purify all potential Trojan\ntriggers in the input at run time without making any assumption about their\nnumbers and forms. We further extend \"filtering\" to\n\"filtering-then-contrasting\" - a new defense mechanism that helps avoid the\ndrop in classification accuracy on clean data caused by filtering. Extensive\nexperimental results show that our proposed defenses significantly outperform 4\nwell-known defenses in mitigating 5 different Trojan attacks including the two\nstate-of-the-art which defeat many strong defenses.",
    "descriptor": "",
    "authors": [
      "Kien Do",
      "Haripriya Harikumar",
      "Hung Le",
      "Dung Nguyen",
      "Truyen Tran",
      "Santu Rana",
      "Dang Nguyen",
      "Willy Susilo",
      "Svetha Venkatesh"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.12154"
  },
  {
    "id": "arXiv:2202.12159",
    "title": "An NLP Solution to Foster the Use of Information in Electronic Health  Records for Efficiency in Decision-Making in Hospital Care",
    "abstract": "The project aimed to define the rules and develop a technological solution to\nautomatically identify a set of attributes within free-text clinical records\nwritten in Portuguese. The first application developed and implemented on this\nbasis was a structured summary of a patient's clinical history, including\nprevious diagnoses and procedures, usual medication, and relevant\ncharacteristics or conditions for clinical decisions, such as allergies, being\nunder anticoagulant therapy, etc. The project's goal was achieved by a\nmultidisciplinary team that included clinicians, epidemiologists, computational\nlinguists, machine learning researchers and software engineers, bringing\ntogether the expertise and perspectives of a public hospital, the university\nand the private sector. Relevant benefits to users and patients are related\nwith facilitated access to the patient's history, which translates into\nexhaustiveness in apprehending the patient's clinical past and efficiency due\nto time saving.",
    "descriptor": "\nComments: 11 pages, 2 figures\n",
    "authors": [
      "Adelino Leite-Moreira",
      "Afonso Mendes",
      "Afonso Pedrosa",
      "Am\u00e2ndio Rocha-Sousa",
      "Ana Azevedo",
      "Andr\u00e9 Amaral-Gomes",
      "Cl\u00e1udia Pinto",
      "Helena Figueira",
      "Nuno Rocha Pereira",
      "Pedro Mendes",
      "Tiago Pimenta"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2202.12159"
  },
  {
    "id": "arXiv:2202.12160",
    "title": "Self-attention for incomplete utterance rewriting",
    "abstract": "Incomplete utterance rewriting (IUR) has recently become an essential task in\nNLP, aiming to complement the incomplete utterance with sufficient context\ninformation for comprehension. In this paper, we propose a novel method by\ndirectly extracting the coreference and omission relationship from the\nself-attention weight matrix of the transformer instead of word embeddings and\nedit the original text accordingly to generate the complete utterance.\nBenefiting from the rich information in the self-attention weight matrix, our\nmethod achieved competitive results on public IUR datasets.",
    "descriptor": "\nComments: 4 pages, 3 figures, Accepted by ICASSP2022\n",
    "authors": [
      "Yong Zhang",
      "Zhitao Li",
      "Jianzong Wang",
      "Ning Cheng",
      "Jing Xiao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.12160"
  },
  {
    "id": "arXiv:2202.12162",
    "title": "Measuring CLEVRness: Blackbox testing of Visual Reasoning Models",
    "abstract": "How can we measure the reasoning capabilities of intelligence systems? Visual\nquestion answering provides a convenient framework for testing the model's\nabilities by interrogating the model through questions about the scene.\nHowever, despite scores of various visual QA datasets and architectures, which\nsometimes yield even a super-human performance, the question of whether those\narchitectures can actually reason remains open to debate. To answer this, we\nextend the visual question answering framework and propose the following\nbehavioral test in the form of a two-player game. We consider black-box neural\nmodels of CLEVR. These models are trained on a diagnostic dataset benchmarking\nreasoning. Next, we train an adversarial player that re-configures the scene to\nfool the CLEVR model. We show that CLEVR models, which otherwise could perform\nat a human level, can easily be fooled by our agent. Our results put in doubt\nwhether data-driven approaches can do reasoning without exploiting the numerous\nbiases that are often present in those datasets. Finally, we also propose a\ncontrolled experiment measuring the efficiency of such models to learn and\nperform reasoning.",
    "descriptor": "\nComments: ICLR 2022\n",
    "authors": [
      "Spyridon Mouselinos",
      "Henryk Michalewski",
      "Mateusz Malinowski"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.12162"
  },
  {
    "id": "arXiv:2202.12165",
    "title": "Transformers in Medical Image Analysis: A Review",
    "abstract": "Transformers have dominated the field of natural language processing, and\nrecently impacted the computer vision area. In the field of medical image\nanalysis, Transformers have also been successfully applied to full-stack\nclinical applications, including image synthesis/reconstruction, registration,\nsegmentation, detection, and diagnosis. Our paper presents both a position\npaper and a primer, promoting awareness and application of Transformers in the\nfield of medical image analysis. Specifically, we first overview the core\nconcepts of the attention mechanism built into Transformers and other basic\ncomponents. Second, we give a new taxonomy of various Transformer architectures\ntailored for medical image applications and discuss their limitations. Within\nthis review, we investigate key challenges revolving around the use of\nTransformers in different learning paradigms, improving the model efficiency,\nand their coupling with other techniques. We hope this review can give a\ncomprehensive picture of Transformers to the readers in the field of medical\nimage analysis.",
    "descriptor": "",
    "authors": [
      "Kelei He",
      "Chen Gan",
      "Zhuoyuan Li",
      "Islem Rekik",
      "Zihao Yin",
      "Wen Ji",
      "Yang Gao",
      "Qian Wang",
      "Junfeng Zhang",
      "Dinggang Shen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.12165"
  },
  {
    "id": "arXiv:2202.12166",
    "title": "Attention Enables Zero Approximation Error",
    "abstract": "Deep learning models have been widely applied in various aspects of daily\nlife. Many variant models based on deep learning structures have achieved even\nbetter performances. Attention-based architectures have become almost\nubiquitous in deep learning structures. Especially, the transformer model has\nnow defeated the convolutional neural network in image classification tasks to\nbecome the most widely used tool. However, the theoretical properties of\nattention-based models are seldom considered. In this work, we show that with\nsuitable adaptations, the single-head self-attention transformer with a fixed\nnumber of transformer encoder blocks and free parameters is able to generate\nany desired polynomial of the input with no error. The number of transformer\nencoder blocks is the same as the degree of the target polynomial. Even more\nexciting, we find that these transformer encoder blocks in this model do not\nneed to be trained. As a direct consequence, we show that the single-head\nself-attention transformer with increasing numbers of free parameters is\nuniversal. These surprising theoretical results clearly explain the outstanding\nperformances of the transformer model and may shed light on future\nmodifications in real applications. We also provide some experiments to verify\nour theoretical result.",
    "descriptor": "",
    "authors": [
      "Zhiying Fang",
      "Yidong Ouyang",
      "Ding-Xuan Zhou",
      "Guang Cheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.12166"
  },
  {
    "id": "arXiv:2202.12172",
    "title": "Overcoming a Theoretical Limitation of Self-Attention",
    "abstract": "Although transformers are remarkably effective for many tasks, there are some\nsurprisingly easy-looking regular languages that they struggle with. Hahn shows\nthat for languages where acceptance depends on a single input symbol, a\ntransformer's classification decisions become less and less confident (that is,\nwith cross-entropy approaching 1 bit per string) as input strings get longer\nand longer. We examine this limitation using two languages: PARITY, the\nlanguage of bit strings with an odd number of 1s, and FIRST, the language of\nbit strings starting with a 1. We demonstrate three ways of overcoming the\nlimitation suggested by Hahn's lemma. First, we settle an open question by\nconstructing a transformer that recognizes PARITY with perfect accuracy, and\nsimilarly for FIRST. Second, we use layer normalization to bring the\ncross-entropy of both models arbitrarily close to zero. Third, when\ntransformers need to focus on a single position, as for FIRST, we find that\nthey can fail to generalize to longer strings; we offer a simple remedy to this\nproblem that also improves length generalization in machine translation.",
    "descriptor": "\nComments: Accepted at ACL 2022\n",
    "authors": [
      "David Chiang",
      "Peter Cholak"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.12172"
  },
  {
    "id": "arXiv:2202.12173",
    "title": "The Impact of Selfish Behavior in Load Balancing Games",
    "abstract": "To what extent does the structure of the players' strategy space influence\nthe efficiency of decentralized solutions in congestion games? In this work, we\ninvestigate whether better performance are possible when restricting to load\nbalancing games in which players can only choose among single resources. We\nconsider three different solutions concepts, namely, approximate pure Nash\nequilibria, approximate one-round walks generated by selfish players aiming at\nminimizing their personal cost and approximate one-round walks generated by\ncooperative players aiming at minimizing the marginal increase in the sum of\nthe players' personal costs. The last two concepts can be interpreted as\nsolutions of greedy online algorithms for the related resource selection\nproblem. We show that, under fairly general latency functions on the resources,\nbetter bounds cannot be achieved if players are either weighted or asymmetric.\nOn the positive side, we prove that, under mild assumptions on the latency\nfunctions, improvements on the performance of approximate pure Nash equilibria\nare possible for load balancing games with weighted and symmetric players in\nthe case of identical resources. We also design lower bounds on the performance\nof one-round walks in load balancing games with unweighted players and\nidentical resources.",
    "descriptor": "\nComments: To cite this paper, consider the preliminary version appeared in the proceedings of ESA 2017: \"Vittorio Bil\\`o, Cosimo Vinci: On the Impact of Singleton Strategies in Congestion Games. The 25th Annual European Symposium on Algorithms (ESA), 17:1-17:14 (2017)\"\n",
    "authors": [
      "Vittorio Bil\u00f2",
      "Cosimo Vinci"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2202.12173"
  },
  {
    "id": "arXiv:2202.12174",
    "title": "Collaborative Training of Heterogeneous Reinforcement Learning Agents in  Environments with Sparse Rewards: What and When to Share?",
    "abstract": "In the early stages of human life, babies develop their skills by exploring\ndifferent scenarios motivated by their inherent satisfaction rather than by\nextrinsic rewards from the environment. This behavior, referred to as intrinsic\nmotivation, has emerged as one solution to address the exploration challenge\nderived from reinforcement learning environments with sparse rewards. Diverse\nexploration approaches have been proposed to accelerate the learning process\nover single- and multi-agent problems with homogeneous agents. However, scarce\nstudies have elaborated on collaborative learning frameworks between\nheterogeneous agents deployed into the same environment, but interacting with\ndifferent instances of the latter without any prior knowledge. Beyond the\nheterogeneity, each agent's characteristics grant access only to a subset of\nthe full state space, which may hide different exploration strategies and\noptimal solutions. In this work we combine ideas from intrinsic motivation and\ntransfer learning. Specifically, we focus on sharing parameters in actor-critic\nmodel architectures and on combining information obtained through intrinsic\nmotivation with the aim of having a more efficient exploration and faster\nlearning. We test our strategies through experiments performed over a modified\nViZDooM's My Way Home scenario, which is more challenging than its original\nversion and allows evaluating the heterogeneity between agents. Our results\nreveal different ways in which a collaborative framework with little additional\ncomputational cost can outperform an independent learning process without\nknowledge sharing. Additionally, we depict the need for modulating correctly\nthe importance between the extrinsic and intrinsic rewards to avoid undesired\nagent behaviors.",
    "descriptor": "\nComments: 27 pages, 16 figures, 3 tables, under review\n",
    "authors": [
      "Alain Andres",
      "Esther Villar-Rodriguez",
      "Javier Del Ser"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.12174"
  },
  {
    "id": "arXiv:2202.12175",
    "title": "Removing Popular Faces in Curve Arrangements",
    "abstract": "A face in a curve arrangement is called popular if it is bounded by the same\ncurve multiple times. Motivated by the automatic generation of curved nonogram\npuzzles, we investigate possibilities to eliminate popular faces in an\narrangement by inserting a single additional curve. This turns out to be\nalready NP-hard; however, we present a probabilistic FPT-approach in the number\nof such faces.",
    "descriptor": "\nComments: 23 Pages, 16 Figures, contains appendix\n",
    "authors": [
      "Phoebe de Nooijer",
      "Soeren Nickel",
      "Alexandra Weinberger",
      "Zuzana Mas\u00e1rov\u00e1",
      "Tamara Mchedlidze",
      "Maarten L\u00f6ffler",
      "G\u00fcnter Rote"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2202.12175"
  },
  {
    "id": "arXiv:2202.12176",
    "title": "Clarifying MCMC-based training of modern EBMs : Contrastive Divergence  versus Maximum Likelihood",
    "abstract": "The Energy-Based Model (EBM) framework is a very general approach to\ngenerative modeling that tries to learn and exploit probability distributions\nonly defined though unnormalized scores. It has risen in popularity recently\nthanks to the impressive results obtained in image generation by parameterizing\nthe distribution with Convolutional Neural Networks (CNN). However, the\nmotivation and theoretical foundations behind modern EBMs are often absent from\nrecent papers and this sometimes results in some confusion. In particular, the\ntheoretical justifications behind the popular MCMC-based learning algorithm\nContrastive Divergence (CD) are often glossed over and we find that this leads\nto theoretical errors in recent influential papers (Du & Mordatch, 2019; Du et\nal., 2020). After offering a first-principles introduction of MCMC-based\ntraining, we argue that the learning algorithm they use can in fact not be\ndescribed as CD and reinterpret theirs methods in light of a new\ninterpretation. Finally, we discuss the implications of our new interpretation\nand provide some illustrative experiments.",
    "descriptor": "\nComments: This work was done as a final project in the class IFT 6269 (Probabilistic Graphical Models) given by Simon Lacoste-Julien in Fall 2021 at Mila\n",
    "authors": [
      "L\u00e9o Gagnon",
      "Guillaume Lajoie"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.12176"
  },
  {
    "id": "arXiv:2202.12177",
    "title": "Bubble Planner: Planning High-speed Smooth Quadrotor Trajectories using  Receding Corridors",
    "abstract": "Quadrotors are agile platforms. With human experts, they can perform\nextremely high-speed flights in cluttered environments. However, fully\nautonomous flight at high speed remains a significant challenge. In this work,\nwe propose a motion planning algorithm based on the corridor-constrained\nminimum control effort trajectory optimization (MINCO) framework. Specifically,\nwe use a series of overlapping spheres to represent the free space of the\nenvironment and propose two novel designs that enable the algorithm to plan\nhigh-speed quadrotor trajectories in real-time. One is a sampling-based\ncorridor generation method that generates spheres with large overlapped areas\n(hence overall corridor size) between two neighboring spheres. The second is a\nReceding Horizon Corridors (RHC) strategy, where part of the previously\ngenerated corridor is reused in each replan. Together, these two designs\nenlarge the corridor spaces in accordance with the quadrotor's current state\nand hence allow the quadrotor to maneuver at high speeds. We benchmark our\nalgorithm against other state-of-the-art planning methods to show its\nsuperiority in simulation. Comprehensive ablation studies are also conducted to\nshow the necessity of the two designs. The proposed method is finally evaluated\non an autonomous LiDAR-navigated quadrotor UAV in woods environments, achieving\nflight speeds over 13.7 m/s without any prior map of the environment or\nexternal localization facility.",
    "descriptor": "",
    "authors": [
      "Yunfan Ren",
      "Fangcheng Zhu",
      "Wenyi Liu",
      "Zhepei Wang",
      "Yi Lin",
      "Fei Gao",
      "Fu Zhang"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.12177"
  },
  {
    "id": "arXiv:2202.12179",
    "title": "Cybersecurity Challenges in the Offshore Oil and Gas Industry: An  Industrial Cyber-Physical Systems (ICPS) Perspective",
    "abstract": "The offshore oil and gas industry has recently been going through a\ndigitalisation drive, with use of `smart' equipment using technologies like the\nIndustrial Internet of Things (IIoT) and Industrial Cyber-Physical Systems\n(ICPS). There has also been a corresponding increase in cyber attacks targeted\nat oil and gas companies. Oil production offshore is usually in remote\nlocations, requiring remote access and control. This is achieved by integrating\nICPS, Supervisory, Control and Data Acquisition (SCADA) systems, and IIoT\ntechnologies. A successful cyber attack against an oil and gas offshore asset\ncould have a devastating impact on the environment, marine ecosystem and safety\nof personnel. Any disruption to the world's supply of oil and gas (O\\&G) can\nalso have an effect on oil prices and in turn, the global economy. This makes\nit important to secure the industry against cyber threats. We describe the\npotential cyberattack surface within the oil and gas industry, discussing\nemerging trends in the offshore sub-sector, and provide a timeline of known\ncyberattacks. We also present a case study of a subsea control system\narchitecture typically used in offshore oil and gas operations and highlight\npotential vulnerabilities affecting the components of the system. This study is\nthe first to provide a detailed analysis on the attack vectors in a subsea\ncontrol system and is crucial to understanding key vulnerabilities, primarily\nto implement efficient mitigation methods that safeguard the safety of\npersonnel and the environment when using such systems.",
    "descriptor": "\nComments: 19 pages, 8 figures\n",
    "authors": [
      "Abubakar Sadiq Mohammed",
      "Philipp Reinecke",
      "Pete Burnap",
      "Omer Rana",
      "Eirini Anthi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.12179"
  },
  {
    "id": "arXiv:2202.12180",
    "title": "Quantum Deep Reinforcement Learning for Robot Navigation Tasks",
    "abstract": "In this work, we utilize Quantum Deep Reinforcement Learning as method to\nlearn navigation tasks for a simple, wheeled robot in three simulated\nenvironments of increasing complexity. We show similar performance of a\nparameterized quantum circuit trained with well established deep reinforcement\nlearning techniques in a hybrid quantum-classical setup compared to a classical\nbaseline. To our knowledge this is the first demonstration of quantum machine\nlearning (QML) for robotic behaviors. Thus, we establish robotics as a viable\nfield of study for QML algorithms and henceforth quantum computing and quantum\nmachine learning as potential techniques for future advancements in autonomous\nrobotics. Beyond that, we discuss current limitations of the presented approach\nas well as future research directions in the field of quantum machine learning\nfor autonomous robots.",
    "descriptor": "\nComments: 8 pages, 5 figures; This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Dirk Heimann",
      "Hans Hohenfeld",
      "Felix Wiebe",
      "Frank Kirchner"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2202.12180"
  },
  {
    "id": "arXiv:2202.12181",
    "title": "FreeSOLO: Learning to Segment Objects without Annotations",
    "abstract": "Instance segmentation is a fundamental vision task that aims to recognize and\nsegment each object in an image. However, it requires costly annotations such\nas bounding boxes and segmentation masks for learning. In this work, we propose\na fully unsupervised learning method that learns class-agnostic instance\nsegmentation without any annotations. We present FreeSOLO, a self-supervised\ninstance segmentation framework built on top of the simple instance\nsegmentation method SOLO. Our method also presents a novel localization-aware\npre-training framework, where objects can be discovered from complicated scenes\nin an unsupervised manner. FreeSOLO achieves 9.8% AP_{50} on the challenging\nCOCO dataset, which even outperforms several segmentation proposal methods that\nuse manual annotations. For the first time, we demonstrate unsupervised\nclass-agnostic instance segmentation successfully. FreeSOLO's box localization\nsignificantly outperforms state-of-the-art unsupervised object\ndetection/discovery methods, with about 100% relative improvements in COCO AP.\nFreeSOLO further demonstrates superiority as a strong pre-training method,\noutperforming state-of-the-art self-supervised pre-training methods by +9.8% AP\nwhen fine-tuning instance segmentation with only 5% COCO masks.",
    "descriptor": "\nComments: 13 pages\n",
    "authors": [
      "Xinlong Wang",
      "Zhiding Yu",
      "Shalini De Mello",
      "Jan Kautz",
      "Anima Anandkumar",
      "Chunhua Shen",
      "Jose M. Alvarez"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.12181"
  },
  {
    "id": "arXiv:2202.12183",
    "title": "Large-scale Stochastic Optimization of NDCG Surrogates for Deep Learning  with Provable Convergence",
    "abstract": "NDCG, namely Normalized Discounted Cumulative Gain, is a widely used ranking\nmetric in information retrieval and machine learning. However, efficient and\nprovable stochastic methods for maximizing NDCG are still lacking, especially\nfor deep models. In this paper, we propose a principled approach to optimize\nNDCG and its top-$K$ variant. First, we formulate a novel compositional\noptimization problem for optimizing the NDCG surrogate, and a novel bilevel\ncompositional optimization problem for optimizing the top-$K$ NDCG surrogate.\nThen, we develop efficient stochastic algorithms with provable convergence\nguarantees for the non-convex objectives. Different from existing NDCG\noptimization methods, the per-iteration complexity of our algorithms scales\nwith the mini-batch size instead of the number of total items. To improve the\neffectiveness for deep learning, we further propose practical strategies by\nusing initial warm-up and stop gradient operator. Experimental results on\nmultiple datasets demonstrate that our methods outperform prior ranking\napproaches in terms of NDCG. To the best of our knowledge, this is the first\ntime that stochastic algorithms are proposed to optimize NDCG with a provable\nconvergence guarantee.",
    "descriptor": "\nComments: 33 pages, 7 figures\n",
    "authors": [
      "Zi-Hao Qiu",
      "Quanqi Hu",
      "Yongjian Zhong",
      "Lijun Zhang",
      "Tianbao Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2202.12183"
  },
  {
    "id": "arXiv:2202.12184",
    "title": "Consistent data fusion with Parker",
    "abstract": "When combining data from multiple sources, inconsistent data complicates the\nproduction of a coherent result. In this paper, we introduce a new type of\nconstraints called edit rules under a partial key (EPKs). These constraints can\nmodel inconsistencies both within and between sources, but in a loosely-coupled\nmatter. We show that we can adapt the well-known set cover methodology to the\nsetting of EPKs and this yields an efficient algorithm to find minimal cost\nrepairs of sources. This algorithm is implemented in a repair engine called\nParker. Empirical results show that Parker is several orders of magnitude\nfaster than state-of-the-art repair tools. At the same time, the quality of the\nrepairs in terms of $F_1$-score ranges from comparable to better compared to\nthese tools.",
    "descriptor": "",
    "authors": [
      "Antoon Bronselaer",
      "Maribel Acosta"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2202.12184"
  },
  {
    "id": "arXiv:2202.12186",
    "title": "Sequential Asset Ranking within Nonstationary Time Series",
    "abstract": "Financial time series are both autocorrelated and nonstationary, presenting\nmodelling challenges that violate the independent and identically distributed\nrandom variables assumption of most regression and classification models. The\nprediction with expert advice framework makes no assumptions on the\ndata-generating mechanism yet generates predictions that work well for all\nsequences, with performance nearly as good as the best expert with hindsight.\nWe conduct research using S&P 250 daily sampled data, extending the academic\nresearch into cross-sectional momentum trading strategies. We introduce a novel\nranking algorithm from the prediction with expert advice framework, the naive\nBayes asset ranker, to select subsets of assets to hold in either long-only or\nlong/short portfolios. Our algorithm generates the best total returns and\nrisk-adjusted returns, net of transaction costs, outperforming the long-only\nholding of the S&P 250 with hindsight. Furthermore, our ranking algorithm\noutperforms a proxy for the regress-then-rank cross-sectional momentum trader,\na sequentially fitted curds and whey multivariate regression procedure.",
    "descriptor": "",
    "authors": [
      "Gabriel Borrageiro",
      "Nick Firoozye",
      "Paolo Barucca"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Machine Learning (cs.LG)",
      "Trading and Market Microstructure (q-fin.TR)"
    ],
    "url": "https://arxiv.org/abs/2202.12186"
  },
  {
    "id": "arXiv:2202.12187",
    "title": "SonOpt: Sonifying Bi-objective Population-Based Optimization Algorithms",
    "abstract": "We propose SonOpt, the first (open source) data sonification application for\nmonitoring the progress of bi-objective population-based optimization\nalgorithms during search, to facilitate algorithm understanding. SonOpt\nprovides insights into convergence/stagnation of search, the evolution of the\napproximation set shape, location of recurring points in the approximation set,\nand population diversity. The benefits of data sonification have been shown for\nvarious non-optimization related monitoring tasks. However, very few attempts\nhave been made in the context of optimization and their focus has been\nexclusively on single-objective problems. In comparison, SonOpt is designed for\nbi-objective optimization problems, relies on objective function values of\nnon-dominated solutions only, and is designed with the user (listener) in mind;\navoiding convolution of multiple sounds and prioritising ease of familiarizing\nwith the system. This is achieved using two sonification paths relying on the\nconcepts of wavetable and additive synthesis. This paper motivates and\ndescribes the architecture of SonOpt, and then validates SonOpt for two popular\nmulti-objective optimization algorithms (NSGA-II and MOEA/D). Experience SonOpt\nyourself via https://github.com/tasos-a/SonOpt-1.0 .",
    "descriptor": "",
    "authors": [
      "Tasos Asonitis",
      "Richard Allmendinger",
      "Matt Benatan",
      "Ricardo Climent"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2202.12187"
  },
  {
    "id": "arXiv:2202.12191",
    "title": "Finding Inverse Document Frequency Information in BERT",
    "abstract": "For many decades, BM25 and its variants have been the dominant document\nretrieval approach, where their two underlying features are Term Frequency (TF)\nand Inverse Document Frequency (IDF). The traditional approach, however, is\nbeing rapidly replaced by Neural Ranking Models (NRMs) that can exploit\nsemantic features. In this work, we consider BERT-based NRMs and study if IDF\ninformation is present in the NRMs. This simple question is interesting because\nIDF has been indispensable for the traditional lexical matching, but global\nfeatures like IDF are not explicitly learned by neural language models\nincluding BERT. We adopt linear probing as the main analysis tool because\ntypical BERT based NRMs utilize linear or inner-product based score\naggregators. We analyze input embeddings, representations of all BERT layers,\nand the self-attention weights of CLS. By studying MS-MARCO dataset with three\nBERT-based models, we show that all of them contain information that is\nstrongly dependent on IDF.",
    "descriptor": "\nComments: 5 pages\n",
    "authors": [
      "Jaekeol Choi",
      "Euna Jung",
      "Sungjun Lim",
      "Wonjong Rhee"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2202.12191"
  },
  {
    "id": "arXiv:2202.12192",
    "title": "A decreasing upper bound of energy for time-fractional phase-field  equations",
    "abstract": "In this article, we study the energy dissipation property of time-fractional\nAllen-Cahn equation. We propose a decreasing upper bound of energy that\ndecreases with respect to time and coincides with the original energy at $t =\n0$ and as $t$ tends to $\\infty$. This upper bound can also be viewed as a\nnonlocal-in-time modified energy, the summation of the original energy and an\naccumulation term due to the memory effect of time fractional derivative. In\nparticular, this indicates that the original energy indeed decays w.r.t. time\nin a small neighborhood at $t=0$. We illustrate the theory mainly with the\ntime-fractional Allen-Cahn equation, but it could be applied to other\ntime-fractional phase-field models such as the Cahn-Hilliard equation.\nOn the discrete level, the first-order L1 and second-order L2 schemes for\ntime-fractional Allen-Cahn equation have similar decreasing modified energies,\nso that the stability can be established. Some numerical results are provided\nto illustrate the behavior of this modified energy and to verify our\ntheoretical results.",
    "descriptor": "",
    "authors": [
      "Chaoyu Quan",
      "Tao Tang",
      "Boyi Wang",
      "Jiang Yang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.12192"
  },
  {
    "id": "arXiv:2202.12193",
    "title": "Black-Box Algorithm Synthesis -- Divide-and-Conquer and More",
    "abstract": "Algorithm synthesis is a newly emerging branch of program synthesis,\ntargeting to automatically apply a predefined class of algorithms to a\nuser-provided program. In algorithm synthesis, one popular topic is to\nsynthesize divide-and-conquer-style parallel programs. Existing approaches on\nthis topic rely on the syntax of the user-provided program and require it to\nfollow a specific format, namely single-pass.\nIn many cases, implementing such a program is still difficult for the user.\nTherefore, in this paper, we study the black-box synthesis for\ndivide-and-conquer which removes the requirement on the syntax and propose a\nnovel algorithm synthesizer AutoLifter. Besides, we show that AutoLifter can be\ngeneralized to other algorithms beyond divide-and-conquer. We propose a novel\ntype of synthesis tasks, namely lifting problems, and show that AutoLifter can\nbe applied to those algorithms where the synthesis task is an instance of\nlifting problems. To our knowledge, AutoLifter is the first algorithm\nsynthesizer that generalizes across algorithm types. We evaluate AutoLifter on\ntwo datasets containing 57 tasks covering five different algorithms. The\nresults demonstrate the effectiveness of AutoLifter for solving lifting\nproblems and show that though AutoLifter does not access the syntax of the\nuser-provided program, it still achieves competitive performance compared with\nwhite-box approaches for divide-and-conquer.",
    "descriptor": "",
    "authors": [
      "Ruyi Ji",
      "Yingfei Xiong",
      "Zhenjiang Hu"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2202.12193"
  },
  {
    "id": "arXiv:2202.12194",
    "title": "Towards a Heterogeneous Smart Electromagnetic Environment for  Millimeter-Wave Communications: An Industrial Viewpoint",
    "abstract": "Fifth generation (5G) and beyond communication systems open the door to\nmillimeter Wave (mmWave) frequency bands to leverage the extremely large\noperating bandwidths and deliver unprecedented network capacity. These\nfrequency bands are affected by high propagation losses that severely limit the\nachievable coverage. The simplest way to address this problem would be to\nincrease the number of installed mmWave base stations (BSs), at the same time\naugmenting the overall network cost, power consumption and ElectroMagnetic\nField (EMF) levels. As alternative direction, here we propose to complement the\nmacro-layer of mmWave BSs with a heterogeneous deployment of Smart\nElectromagnetic (Smart EM) Entities - namely IAB nodes, Smart Repeaters,\nReconfigurable Intelligent Surfaces (RISs) and passive surfaces - that is\njudiciously planned to minimize the total installation costs while at the same\ntime optimizing the network spectral efficiency. Initial network planning\nresults underline the effectiveness of the proposed approach. The available\ntechnologies and the key research directions for achieving this view are\nthoroughly discussed by accounting for issues ranging from system-level design\nto the development of new materials.",
    "descriptor": "",
    "authors": [
      "Roberto Flamini",
      "Danilo De Donno",
      "Jonathan Gambini",
      "Francesco Giuppi",
      "Christian Mazzucco",
      "Angelo Milani",
      "Laura Resteghini"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2202.12194"
  },
  {
    "id": "arXiv:2202.12195",
    "title": "LAGC Semantics of Concurrent Programming Languages",
    "abstract": "Formal, mathematically rigorous programming language semantics are the\nessential prerequisite for the design of logics and calculi that permit\nautomated reasoning about concurrent programs. We propose a novel modular\nsemantics designed to align smoothly with program logics used in deductive\nverification and formal specification of concurrent programs. Our semantics\nseparates local evaluation of expressions and statements performed in an\nabstract, symbolic environment from their composition into global computations,\nat which point they are concretised. This makes incremental addition of new\nlanguage concepts possible, without the need to revise the framework. The basis\nis a generalisation of the notion of a program trace as a sequence of evolving\nstates that we enrich with event descriptors and trailing continuation markers.\nThis allows to postpone scheduling constraints from the level of local\nevaluation to the global composition stage, where well-formedness predicates\nover the event structure declaratively characterise a wide range of concurrency\nmodels. We also illustrate how a sound program logic and calculus can be\ndefined for this semantics.",
    "descriptor": "",
    "authors": [
      "Crystal Chang Din",
      "Reiner H\u00e4hnle",
      "Ludovic Henrio",
      "Einar Broch Johnsen",
      "Violet Ka I Pun",
      "Silvia Lizeth Tapia Tarifa"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2202.12195"
  },
  {
    "id": "arXiv:2202.12197",
    "title": "Situational Graphs for Robot Navigation in Structured Indoor  Environments",
    "abstract": "Autonomous mobile robots should be aware of their situation, understood as a\ncomprehensive understanding of the environment along with the estimation of its\nown state, to successfully make decisions and execute tasks in natural\nenvironments. 3D scene graphs are an emerging field of research with great\npotential to represent these situations in a joint model comprising geometric,\nsemantic and relational/topological dimensions. Although 3D scene graphs have\nalready been utilized for this, further research is still required to\neffectively deploy them on-board mobile robots.\nTo this end, we present in this paper a real-time online built Situational\nGraphs (S-Graphs), composed of a single graph representing the environment,\nwhile simultaneously improving the robot pose estimation. Our method utilizes\nodometry readings and planar surfaces extracted from 3D LiDAR scans, to\nconstruct and optimize in real-time a three layered S-Graph that includes a\nrobot tracking layer where the robot poses are registered, a metric-semantic\nlayer with features such as planar walls and our novel topological layer\nconstraining higher-level features such as corridors and rooms. Our proposal\ndoes not only demonstrate state-of-the-art results for pose estimation of the\nrobot, but also contributes with a metric-semantic-topological model of the\nenvironment",
    "descriptor": "\nComments: 8 pages, 6 figures, IROS 2022\n",
    "authors": [
      "Hriday Bavle",
      "Jose Luis Sanchez-Lopez",
      "Muhammad Shaheer",
      "Javier Civera",
      "Holger Voos"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.12197"
  },
  {
    "id": "arXiv:2202.12201",
    "title": "Energy-Efficient Transmission Range and Duration for Cognitive Radio  Sensor Networks",
    "abstract": "Cognitive Radio (CR) promises an efficient utilization of radio spectrum\nresources by enabling dynamic spectrum access to overcome the spectrum scarcity\nproblem. Cognitive Radio Sensor Networks (CRSNs) are one type of Wireless\nSensor Networks (WSNs) equipped with CR capabilities. CRSN nodes need to\noperate energy-efficiently to extend network lifetime due to their limited\nbattery capacity. In this paper, for the first time in literature, we formulate\nthe problem of finding a common energy-efficient transmission range and\ntransmission duration for all CRSN nodes and network deployment that would\nminimize the energy consumed per goodput per meter toward the sink in a greedy\nforwarding scenario. Results reveal non-trivial relations for energy-efficient\nCRSN transmission range and duration as a function of nine critical network\nparameters such as primary user activity levels. These relations provide\nvaluable insights for detailed CRSN designs prior to deployment.",
    "descriptor": "\nComments: 12 pages, 8 figures\n",
    "authors": [
      "Mustafa Ozger",
      "Ecehan B. Pehlivanoglu",
      "Ozgur B. Akan"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.12201"
  },
  {
    "id": "arXiv:2202.12205",
    "title": "Is Neuro-Symbolic AI Meeting its Promise in Natural Language Processing?  A Structured Review",
    "abstract": "Advocates for Neuro-Symbolic AI (NeSy) assert that combining deep learning\nwith symbolic reasoning will lead to stronger AI than either paradigm on its\nown. As successful as deep learning has been, it is generally accepted that\neven our best deep learning systems are not very good at abstract reasoning.\nAnd since reasoning is inextricably linked to language, it makes intuitive\nsense that Natural Language Processing (NLP), would be a particularly\nwell-suited candidate for NeSy. We conduct a structured review of studies\nimplementing NeSy for NLP, challenges and future directions, and aim to answer\nthe question of whether NeSy is indeed meeting its promises: reasoning,\nout-of-distribution generalization, interpretability, learning and reasoning\nfrom small data, and transferability to new domains. We examine the impact of\nknowledge representation, such as rules and semantic networks, language\nstructure and relational structure, and whether implicit or explicit reasoning\ncontributes to higher promise scores. We find that knowledge encoded in\nrelational structures and explicit reasoning tend to lead to more NeSy goals\nbeing satisfied. We also advocate for a more methodical approach to the\napplication of theories of reasoning, which we hope can reduce some of the\nfriction between the symbolic and sub-symbolic schools of AI.",
    "descriptor": "\nComments: Survey\n",
    "authors": [
      "Kyle Hamilton",
      "Aparna Nayak",
      "Bojan Bo\u017ei\u0107",
      "Luca Longo"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.12205"
  },
  {
    "id": "arXiv:2202.12208",
    "title": "Synthesizing Efficient Dynamic Programming Algorithms",
    "abstract": "Dynamic programming is an important optimization technique, but designing\nefficient dynamic programming algorithms can be difficult even for professional\nprogrammers. Motivated by this point, we propose a synthesizer namely MetHyl,\nwhich automatically synthesizes efficient dynamic programming algorithms from a\npossibly inefficient program in the form of relational hylomorphism. MetHyl\nconsists of a transformation system and efficient synthesis algorithms, where\nthe former transforms a hylomorphism to an efficient dynamic programming\nalgorithm via four synthesis tasks, and the latter solves these tasks\nefficiently. We evaluate MetHyl on 37 tasks related to 16 optimization problems\ncollected from Introduction to Algorithm. The results show that MetHyl achieves\nexponential speed-ups on 97.3% tasks and the time complexity of the standard\nsolutions on 70.3% tasks with an average time cost of less than one minute.",
    "descriptor": "",
    "authors": [
      "Ruyi Ji",
      "Tianran Zhu",
      "Yingfei Xiong",
      "Zhenjiang Hu"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2202.12208"
  },
  {
    "id": "arXiv:2202.12210",
    "title": "BERTVision -- A Parameter-Efficient Approach for Question Answering",
    "abstract": "We present a highly parameter efficient approach for Question Answering that\nsignificantly reduces the need for extended BERT fine-tuning. Our method uses\ninformation from the hidden state activations of each BERT transformer layer,\nwhich is discarded during typical BERT inference. Our best model achieves\nmaximal BERT performance at a fraction of the training time and GPU or TPU\nexpense. Performance is further improved by ensembling our model with BERTs\npredictions. Furthermore, we find that near optimal performance can be achieved\nfor QA span annotation using less training data. Our experiments show that this\napproach works well not only for span annotation, but also for classification,\nsuggesting that it may be extensible to a wider range of tasks.",
    "descriptor": "\nComments: 7 pages, 11 with appendix\n",
    "authors": [
      "Siduo Jiang",
      "Cristopher Benge",
      "William Casey King"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.12210"
  },
  {
    "id": "arXiv:2202.12211",
    "title": "Self-Distilled StyleGAN: Towards Generation from Internet Photos",
    "abstract": "StyleGAN is known to produce high-fidelity images, while also offering\nunprecedented semantic editing. However, these fascinating abilities have been\ndemonstrated only on a limited set of datasets, which are usually structurally\naligned and well curated. In this paper, we show how StyleGAN can be adapted to\nwork on raw uncurated images collected from the Internet. Such image\ncollections impose two main challenges to StyleGAN: they contain many outlier\nimages, and are characterized by a multi-modal distribution. Training StyleGAN\non such raw image collections results in degraded image synthesis quality. To\nmeet these challenges, we proposed a StyleGAN-based self-distillation approach,\nwhich consists of two main components: (i) A generative-based self-filtering of\nthe dataset to eliminate outlier images, in order to generate an adequate\ntraining set, and (ii) Perceptual clustering of the generated images to detect\nthe inherent data modalities, which are then employed to improve StyleGAN's\n\"truncation trick\" in the image synthesis process. The presented technique\nenables the generation of high-quality images, while minimizing the loss in\ndiversity of the data. Through qualitative and quantitative evaluation, we\ndemonstrate the power of our approach to new challenging and diverse domains\ncollected from the Internet. New datasets and pre-trained models are available\nat https://self-distilled-stylegan.github.io/ .",
    "descriptor": "",
    "authors": [
      "Ron Mokady",
      "Michal Yarom",
      "Omer Tov",
      "Oran Lang",
      "Daniel Cohen-Or",
      "Tali Dekel",
      "Michal Irani",
      "Inbar Mosseri"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.12211"
  },
  {
    "id": "arXiv:2202.12219",
    "title": "Debugging Differential Privacy: A Case Study for Privacy Auditing",
    "abstract": "Differential Privacy can provide provable privacy guarantees for training\ndata in machine learning. However, the presence of proofs does not preclude the\npresence of errors. Inspired by recent advances in auditing which have been\nused for estimating lower bounds on differentially private algorithms, here we\nshow that auditing can also be used to find flaws in (purportedly)\ndifferentially private schemes. In this case study, we audit a recent open\nsource implementation of a differentially private deep learning algorithm and\nfind, with 99.99999999% confidence, that the implementation does not satisfy\nthe claimed differential privacy guarantee.",
    "descriptor": "",
    "authors": [
      "Florian Tramer",
      "Andreas Terzis",
      "Thomas Steinke",
      "Shuang Song",
      "Matthew Jagielski",
      "Nicholas Carlini"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.12219"
  },
  {
    "id": "arXiv:2202.12224",
    "title": "An optimal scheduled learning rate for a randomized Kaczmarz algorithm",
    "abstract": "We study how the learning rate affects the performance of a relaxed\nrandomized Kaczmarz algorithm for solving $A x \\approx b + \\varepsilon$, where\n$A x =b$ is a consistent linear system and $\\varepsilon$ has independent mean\nzero random entries. We derive a scheduled learning rate which optimizes a\nbound on the expected error that is sharp in certain cases; in contrast to the\nexponential convergence of the standard randomized Kaczmarz algorithm, our\noptimized bound involves the reciprocal of the Lambert-$W$ function of an\nexponential.",
    "descriptor": "\nComments: 14 pages, 4 figures\n",
    "authors": [
      "Nicholas F. Marshall",
      "Oscar Mickelin"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)",
      "Classical Analysis and ODEs (math.CA)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2202.12224"
  },
  {
    "id": "arXiv:2202.12226",
    "title": "Probing BERT's priors with serial reproduction chains",
    "abstract": "We can learn as much about language models from what they say as we learn\nfrom their performance on targeted benchmarks. Sampling is a promising\nbottom-up method for probing, but generating samples from successful models\nlike BERT remains challenging. Taking inspiration from theories of iterated\nlearning in cognitive science, we explore the use of serial reproduction chains\nto probe BERT's priors. Although the masked language modeling objective does\nnot guarantee a consistent joint distribution, we observe that a unique and\nconsistent estimator of the ground-truth joint distribution may be obtained by\na GSN sampler, which randomly selects which word to mask and reconstruct on\neach step. We compare the lexical and syntactic statistics of sentences from\nthe resulting prior distribution against those of the ground-truth corpus\ndistribution and elicit a large empirical sample of naturalness judgments to\ninvestigate how, exactly, the model deviates from human speakers. Our findings\nsuggest the need to move beyond top-down evaluation methods toward bottom-up\nprobing to capture the full richness of what has been learned about language.",
    "descriptor": "\nComments: Findings of ACL 2022\n",
    "authors": [
      "Takateru Yamakoshi",
      "Robert D. Hawkins",
      "Thomas L. Griffiths"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.12226"
  },
  {
    "id": "arXiv:2202.12229",
    "title": "The Linear Capacity of Single-Server Individually-Private Information  Retrieval with Side Information",
    "abstract": "This paper considers the problem of single-server Individually-Private\nInformation Retrieval with side information (IPIR). In this problem, there is a\nremote server that stores a dataset of $K$ messages, and there is a user that\ninitially knows $M$ of these messages, and wants to retrieve $D$ other messages\nbelonging to the dataset. The goal of the user is to retrieve the $D$ desired\nmessages by downloading the minimum amount of information from the server while\nrevealing no information about whether an individual message is one of the $D$\ndesired messages. In this work, we focus on linear IPIR schemes, i.e., the IPIR\nschemes in which the user downloads only linear combinations of the original\nmessages from the server. We prove a converse bound on the download rate of any\nlinear IPIR scheme for all $K,D,M$, and show the achievability of this bound\nfor all $K,D,M$ satisfying a certain divisibility condition. Our results\ncharacterize the linear capacity of IPIR, which is defined as the maximum\nachievable download rate over all linear IPIR schemes, for a wide range of\nvalues of $K,D,M$.",
    "descriptor": "",
    "authors": [
      "Anoosheh Heidarzadeh",
      "Alex Sprintson"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2202.12229"
  },
  {
    "id": "arXiv:2202.12230",
    "title": "Sample Efficiency of Data Augmentation Consistency Regularization",
    "abstract": "Data augmentation is popular in the training of large neural networks;\ncurrently, however, there is no clear theoretical comparison between different\nalgorithmic choices on how to use augmented data. In this paper, we take a step\nin this direction - we first present a simple and novel analysis for linear\nregression, demonstrating that data augmentation consistency (DAC) is\nintrinsically more efficient than empirical risk minimization on augmented data\n(DA-ERM). We then propose a new theoretical framework for analyzing DAC, which\nreframes DAC as a way to reduce function class complexity. The new framework\ncharacterizes the sample efficiency of DAC for various non-linear models (e.g.,\nneural networks). Further, we perform experiments that make a clean and\napples-to-apples comparison (i.e., with no extra modeling or data tweaks)\nbetween ERM and consistency regularization using CIFAR-100 and WideResNet;\nthese together demonstrate the superior efficacy of DAC.",
    "descriptor": "",
    "authors": [
      "Shuo Yang",
      "Yijun Dong",
      "Rachel Ward",
      "Inderjit S. Dhillon",
      "Sujay Sanghavi",
      "Qi Lei"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.12230"
  },
  {
    "id": "arXiv:2202.12232",
    "title": "Bounding Membership Inference",
    "abstract": "Differential Privacy (DP) is the de facto standard for reasoning about the\nprivacy guarantees of a training algorithm. Despite the empirical observation\nthat DP reduces the vulnerability of models to existing membership inference\n(MI) attacks, a theoretical underpinning as to why this is the case is largely\nmissing in the literature. In practice, this means that models need to be\ntrained with DP guarantees that greatly decrease their accuracy. In this paper,\nwe provide a tighter bound on the accuracy of any MI adversary when a training\nalgorithm provides $\\epsilon$-DP. Our bound informs the design of a novel\nprivacy amplification scheme, where an effective training set is sub-sampled\nfrom a larger set prior to the beginning of training, to greatly reduce the\nbound on MI accuracy. As a result, our scheme enables $\\epsilon$-DP users to\nemploy looser DP guarantees when training their model to limit the success of\nany MI adversary; this ensures that the model's accuracy is less impacted by\nthe privacy guarantee. Finally, we discuss implications of our MI bound on the\nfield of machine unlearning.",
    "descriptor": "",
    "authors": [
      "Anvith Thudi",
      "Ilia Shumailov",
      "Franziska Boenisch",
      "Nicolas Papernot"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.12232"
  },
  {
    "id": "arXiv:2202.12237",
    "title": "A comparative study of in-air trajectories at short and long distances  in online handwriting",
    "abstract": "Introduction Existing literature about online handwriting analysis to support\npathology diagnosis has taken advantage of in-air trajectories. A similar\nsituation occurred in biometric security applications where the goal is to\nidentify or verify an individual using his signature or handwriting. These\nstudies do not consider the distance of the pen tip to the writing surface.\nThis is due to the fact that current acquisition devices do not provide height\nformation. However, it is quite straightforward to differentiate movements at\ntwo different heights: a) short distance: height lower or equal to 1 cm above a\nsurface of digitizer, the digitizer provides x and y coordinates. b) long\ndistance: height exceeding 1 cm, the only information available is a time stamp\nthat indicates the time that a specific stroke has spent at long distance.\nAlthough short distance has been used in several papers, long distances have\nbeen ignored and will be investigated in this paper. Methods In this paper, we\nwill analyze a large set of databases (BIOSECURID, EMOTHAW, PaHaW,\nOxygen-Therapy and SALT), which contain a total amount of 663 users and 17951\nfiles. We have specifically studied: a) the percentage of time spent\non-surface, in-air at short distance, and in-air at long distance for different\nuser profiles (pathological and healthy users) and different tasks; b) The\npotential use of these signals to improve classification rates. Results and\nconclusions Our experimental results reveal that long-distance movements\nrepresent a very small portion of the total execution time (0.5 % in the case\nof signatures and 10.4% for uppercase words of BIOSECUR-ID, which is the\nlargest database). In addition, significant differences have been found in the\ncomparison of pathological versus control group for letter l in PaHaW database\n(p=0.0157) and crossed pentagons in SALT database (p=0.0122)",
    "descriptor": "\nComments: 11 pages\n",
    "authors": [
      "Carlos Alonso-Martinez",
      "Marcos Faundez-Zanuy",
      "Jiri Mekyska"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.12237"
  },
  {
    "id": "arXiv:2202.12242",
    "title": "On-line signature verification system with failure to enroll managing",
    "abstract": "In this paper we simulate a real biometric verification system based on\non-line signatures. For this purpose we have split the MCYT signature database\nin three subsets: one for classifier training, another for system adjustment\nand a third one for system testing simulating enrollment and verification. This\ncontext corresponds to a real operation, where a new user tries to enroll an\nexisting system and must be automatically guided by the system in order to\ndetect the failure to enroll situations. The main contribution of this work is\nthe management of failure to enroll situations by means of a new proposal,\ncalled intelligent enrollment, which consists of consistency checking in order\nto automatically reject low quality samples. This strategy lets to enhance the\nverification errors up to 22% when leaving out 8% of the users. In this\nsituation 8% of the people cannot be enrolled in the system and must be\nverified by other biometrics or by human abilities. These people are identified\nwith intelligent enrollment and the situation can be thus managed. In addition\nwe also propose a DCT-based feature extractor with threshold coding and\ndiscriminability criteria.",
    "descriptor": "\nComments: 35 pages\n",
    "authors": [
      "Joan Fabregas",
      "Marcos Faundez-Zanuy"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.12242"
  },
  {
    "id": "arXiv:2202.12243",
    "title": "Flat latent manifolds for music improvisation between human and machine",
    "abstract": "The use of machine learning in artistic music generation leads to\ncontroversial discussions of the quality of art, for which objective\nquantification is nonsensical. We therefore consider a music-generating\nalgorithm as a counterpart to a human musician, in a setting where reciprocal\nimprovisation is to lead to new experiences, both for the musician and the\naudience. To obtain this behaviour, we resort to the framework of recurrent\nVariational Auto-Encoders (VAE) and learn to generate music, seeded by a human\nmusician. In the learned model, we generate novel musical sequences by\ninterpolation in latent space. Standard VAEs however do not guarantee any form\nof smoothness in their latent representation. This translates into abrupt\nchanges in the generated music sequences. To overcome these limitations, we\nregularise the decoder and endow the latent space with a flat Riemannian\nmanifold, i.e., a manifold that is isometric to the Euclidean space. As a\nresult, linearly interpolating in the latent space yields realistic and smooth\nmusical changes that fit the type of machine--musician interactions we aim for.\nWe provide empirical evidence for our method via a set of experiments on music\ndatasets and we deploy our model for an interactive jam session with a\nprofessional drummer. The live performance provides qualitative evidence that\nthe latent representation can be intuitively interpreted and exploited by the\ndrummer to drive the interplay. Beyond the musical application, our approach\nshowcases an instance of human-centred design of machine-learning models,\ndriven by interpretability and the interaction with the end user.",
    "descriptor": "\nComments: 17 pages\n",
    "authors": [
      "Nutan Chen",
      "Djalel Benbouzid",
      "Francesco Ferroni",
      "Mathis Nitschke",
      "Luciano Pinna",
      "Patrick van der Smagt"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2202.12243"
  },
  {
    "id": "arXiv:2202.12245",
    "title": "EMOTHAW: A novel database for emotional state recognition from  handwriting",
    "abstract": "The detection of negative emotions through daily activities such as\nhandwriting is useful for promoting well-being. The spread of human-machine\ninterfaces such as tablets makes the collection of handwriting samples easier.\nIn this context, we present a first publicly available handwriting database\nwhich relates emotional states to handwriting, that we call EMOTHAW. This\ndatabase includes samples of 129 participants whose emotional states, namely\nanxiety, depression and stress, are assessed by the Depression Anxiety Stress\nScales (DASS) questionnaire. Seven tasks are recorded through a digitizing\ntablet: pentagons and house drawing, words copied in handprint, circles and\nclock drawing, and one sentence copied in cursive writing. Records consist in\npen positions, on-paper and in-air, time stamp, pressure, pen azimuth and\naltitude. We report our analysis on this database. From collected data, we\nfirst compute measurements related to timing and ductus. We compute separate\nmeasurements according to the position of the writing device: on paper or\nin-air. We analyse and classify this set of measurements (referred to as\nfeatures) using a random forest approach. This latter is a machine learning\nmethod [2], based on an ensemble of decision trees, which includes a feature\nranking process. We use this ranking process to identify the features which\nbest reveal a targeted emotional state.\nWe then build random forest classifiers associated to each emotional state.\nOur results, obtained from cross-validation experiments, show that the targeted\nemotional states can be identified with accuracies ranging from 60% to 71%.",
    "descriptor": "\nComments: 31 pages\n",
    "authors": [
      "Laurence Likforman-Sulem",
      "Anna Esposito",
      "Marcos Faundez-Zanuy",
      "Stephan Clemen\u00e7on",
      "Gennaro Cordasco"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.12245"
  },
  {
    "id": "arXiv:2202.12246",
    "title": "Neural reality of argument structure constructions",
    "abstract": "In lexicalist linguistic theories, argument structure is assumed to be\npredictable from the meaning of verbs. As a result, the verb is the primary\ndeterminant of the meaning of a clause. In contrast, construction grammarians\npropose that argument structure is encoded in constructions (or form-meaning\npairs) that are distinct from verbs. Decades of psycholinguistic research have\nproduced substantial empirical evidence in favor of the construction view. Here\nwe adapt several psycholinguistic studies to probe for the existence of\nargument structure constructions (ASCs) in Transformer-based language models\n(LMs). First, using a sentence sorting experiment, we find that sentences\nsharing the same construction are closer in embedding space than sentences\nsharing the same verb. Furthermore, LMs increasingly prefer grouping by\nconstruction with more input data, mirroring the behaviour of non-native\nlanguage learners. Second, in a \"Jabberwocky\" priming-based experiment, we find\nthat LMs associate ASCs with meaning, even in semantically nonsensical\nsentences. Our work offers the first evidence for ASCs in LMs and highlights\nthe potential to devise novel probing methods grounded in psycholinguistic\nresearch.",
    "descriptor": "\nComments: ACL 2022 (Long Paper)\n",
    "authors": [
      "Bai Li",
      "Zining Zhu",
      "Guillaume Thomas",
      "Frank Rudzicz",
      "Yang Xu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.12246"
  },
  {
    "id": "arXiv:2202.12250",
    "title": "BLPnet: A new DNN model and Bengali OCR engine for Automatic License  Plate Recognition",
    "abstract": "The development of the Automatic License Plate Recognition (ALPR) system has\nreceived much attention for the English license plate. However, despite being\nthe sixth largest population around the world, no significant progress can be\ntracked in the Bengali language countries or states for the ALPR system\naddressing their more alarming traffic management with inadequate road-safety\nmeasures. This paper reports a computationally efficient and reasonably\naccurate Automatic License Plate Recognition (ALPR) system for Bengali\ncharacters with a new end-to-end DNN model that we call Bengali License Plate\nNetwork(BLPnet). The cascaded architecture for detecting vehicle regions prior\nto vehicle license plate (VLP) in the model is proposed to eliminate false\npositives resulting in higher detection accuracy of VLP. Besides, a lower set\nof trainable parameters is considered for reducing the computational cost\nmaking the system faster and more compatible for a real-time application. With\na Computational Neural Network (CNN)based new Bengali OCR engine and\nword-mapping process, the model is characters rotation invariant, and can\nreadily extract, detect and output the complete license plate number of a\nvehicle. The model feeding with17 frames per second (fps) on real-time video\nfootage can detect a vehicle with the Mean Squared Error (MSE) of 0.0152, and\nthe mean license plate character recognition accuracy of 95%. While compared to\nthe other models, an improvement of 5% and 20% were recorded for the BLPnetover\nthe prominent YOLO-based ALPR model and the Tesseract model for the\nnumber-plate detection accuracy and time requirement, respectively.",
    "descriptor": "\nComments: Submitted to Neurocomputing (this https URL)\n",
    "authors": [
      "Md. Saif Hassan Onim",
      "Hussain Nyeem",
      "Koushik Roy",
      "Mahmudul Hasan",
      "Abtahi Ishmam",
      "Md. Akiful Hoque Akif",
      "Tareque Bashar Ovi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2202.12250"
  },
  {
    "id": "arXiv:2202.12251",
    "title": "ISDA: Position-Aware Instance Segmentation with Deformable Attention",
    "abstract": "Most instance segmentation models are not end-to-end trainable due to either\nthe incorporation of proposal estimation (RPN) as a pre-processing or\nnon-maximum suppression (NMS) as a post-processing. Here we propose a novel\nend-to-end instance segmentation method termed ISDA. It reshapes the task into\npredicting a set of object masks, which are generated via traditional\nconvolution operation with learned position-aware kernels and features of\nobjects. Such kernels and features are learned by leveraging a deformable\nattention network with multi-scale representation. Thanks to the introduced\nset-prediction mechanism, the proposed method is NMS-free. Empirically, ISDA\noutperforms Mask R-CNN (the strong baseline) by 2.6 points on MS-COCO, and\nachieves leading performance compared with recent models. Code will be\navailable soon.",
    "descriptor": "\nComments: Accepted to ICASSP 2022\n",
    "authors": [
      "Kaining Ying",
      "Zhenhua Wang",
      "Cong Bai",
      "Pengfei Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.12251"
  },
  {
    "id": "arXiv:2202.12255",
    "title": "Exact Community Recovery over Signed Graphs",
    "abstract": "Signed graphs encode similarity and dissimilarity relationships among\ndifferent entities with positive and negative edges. In this paper, we study\nthe problem of community recovery over signed graphs generated by the signed\nstochastic block model (SSBM) with two equal-sized communities. Our approach is\nbased on the maximum likelihood estimation (MLE) of the SSBM. Unlike many\nexisting approaches, our formulation reveals that the positive and negative\nedges of a signed graph should be treated unequally. We then propose a simple\ntwo-stage iterative algorithm for solving the regularized MLE. It is shown that\nin the logarithmic degree regime, the proposed algorithm can exactly recover\nthe underlying communities in nearly-linear time at the information-theoretic\nlimit. Numerical results on both synthetic and real data are reported to\nvalidate and complement our theoretical developments and demonstrate the\nefficacy of the proposed method.",
    "descriptor": "",
    "authors": [
      "Xiaolu Wang",
      "Peng Wang",
      "Anthony Man-Cho So"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2202.12255"
  },
  {
    "id": "arXiv:2202.12256",
    "title": "Integration of neural network and fuzzy logic decision making compared  with bilayered neural network in the simulation of daily dew point  temperature",
    "abstract": "In this research, dew point temperature (DPT) is simulated using the\ndata-driven approach. Adaptive Neuro-Fuzzy Inference System (ANFIS) is utilized\nas a data-driven technique to forecast this parameter at Tabriz in East\nAzerbaijan. Various input patterns, namely T min, T max, and T mean, are\nutilized for training the architecture whilst DPT is the model's output. The\nfindings indicate that, in general, ANFIS method is capable of identifying data\npatterns with a high degree of accuracy. However, the approach demonstrates\nthat processing time and computer resources may substantially increase by\nadding additional functions. Based on the results, the number of iterations and\ncomputing resources might change dramatically if new functionalities are\nincluded. As a result, tuning parameters have to be optimized inside the method\nframework. The findings demonstrate a high agreement between results by the\ndata-driven technique (machine learning method) and the observed data. Using\nthis prediction toolkit, DPT can be adequately forecasted solely based on the\ntemperature distribution of Tabriz. This kind of modeling is extremely\npromising for predicting DPT at various sites. Besides, this study thoroughly\ncompares the Bilayered Neural Network (BNN) and ANFIS models on various scales.\nWhilst the ANFIS model is extremely stable for almost all numbers of membership\nfunctions, the BNN model is highly sensitive to this scale factor to predict\nDPT.",
    "descriptor": "\nComments: 18 pages, 15 figures\n",
    "authors": [
      "Guodao Zhang",
      "Shahab S. Band",
      "Sina Ardabili",
      "Kwok-Wing Chau",
      "Amir Mosavi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.12256"
  },
  {
    "id": "arXiv:2202.12257",
    "title": "A Perceptual Measure for Evaluating the Resynthesis of Automatic Music  Transcriptions",
    "abstract": "This study focuses on the perception of music performances when contextual\nfactors, such as room acoustics and instrument, change. We propose to\ndistinguish the concept of \"performance\" from the one of \"interpretation\",\nwhich expresses the \"artistic intention\". Towards assessing this distinction,\nwe carried out an experimental evaluation where 91 subjects were invited to\nlisten to various audio recordings created by resynthesizing MIDI data obtained\nthrough Automatic Music Transcription (AMT) systems and a sensorized acoustic\npiano. During the resynthesis, we simulated different contexts and asked\nlisteners to evaluate how much the interpretation changes when the context\nchanges. Results show that: (1) MIDI format alone is not able to completely\ngrasp the artistic intention of a music performance; (2) usual objective\nevaluation measures based on MIDI data present low correlations with the\naverage subjective evaluation. To bridge this gap, we propose a novel measure\nwhich is meaningfully correlated with the outcome of the tests. In addition, we\ninvestigate multimodal machine learning by providing a new score-informed AMT\nmethod and propose an approximation algorithm for the $p$-dispersion problem.",
    "descriptor": "\nComments: Accepted by Multimedia Tools and Applications; supplementary materials are in the latex sources\n",
    "authors": [
      "Federico Simonetta",
      "Federico Avanzini",
      "Stavros Ntalampiras"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2202.12257"
  },
  {
    "id": "arXiv:2202.12258",
    "title": "A Method for Waste Segregation using Convolutional Neural Networks",
    "abstract": "Segregation of garbage is a primary concern in many nations across the world.\nEven though we are in the modern era, many people still do not know how to\ndistinguish between organic and recyclable waste. It is because of this that\nthe world is facing a major crisis of waste disposal. In this paper, we try to\nuse deep learning algorithms to help solve this problem of waste\nclassification. The waste is classified into two categories like organic and\nrecyclable. Our proposed model achieves an accuracy of 94.9%. Although the\nother two models also show promising results, the Proposed Model stands out\nwith the greatest accuracy. With the help of deep learning, one of the greatest\nobstacles to efficient waste management can finally be removed.",
    "descriptor": "",
    "authors": [
      "Jash Shah",
      "Sagar Kamat"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2202.12258"
  },
  {
    "id": "arXiv:2202.12259",
    "title": "Learning from the Pros: Extracting Professional Goalkeeper Technique  from Broadcast Footage",
    "abstract": "As an amateur goalkeeper playing grassroots soccer, who better to learn from\nthan top professional goalkeepers? In this paper, we harness computer vision\nand machine learning models to appraise the save technique of professionals in\na way those at lower levels can learn from. We train an unsupervised machine\nlearning model using 3D body pose data extracted from broadcast footage to\nlearn professional goalkeeper technique. Then, an \"expected saves\" model is\ndeveloped, from which we can identify the optimal goalkeeper technique in\ndifferent match contexts.",
    "descriptor": "\nComments: 17 pages, 15 figures, MIT Sloan Sports Analytics Conference, March 4-5 2022, Boston, USA\n",
    "authors": [
      "Matthew Wear",
      "Ryan Beal",
      "Tim Matthews",
      "Tim Norman",
      "Sarvapali Ramchurn"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.12259"
  },
  {
    "id": "arXiv:2202.12260",
    "title": "Self-organising Urban Traffic control on micro-level using Reinforcement  Learning and Agent-based Modelling",
    "abstract": "Most traffic flow control algorithms address switching cycle adaptation of\ntraffic signals and lights. This work addresses traffic flow optimisation by\nself-organising micro-level control combining Reinforcement Learning and\nrule-based agents for action selection performing long-range navigation in\nurban environments. I.e., vehicles represented by agents adapt their decision\nmaking for re-routing based on local environmental sensors. Agent-based\nmodelling and simulation is used to study emergence effects on urban city\ntraffic flows. An unified agent programming model enables simulation and\ndistributed data processing with possible incorporation of crowd sensing tasks\nused as an additional sensor data base. Results from an agent-based simulation\nof an artificial urban area show that the deployment of micro-level vehicle\nnavigation control just by learned individual decision making and re-routing\nbased on local environmental sensors can increase the efficiency of mobility in\nterms of path length and travelling time.",
    "descriptor": "",
    "authors": [
      "Stefan Bosse"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.12260"
  },
  {
    "id": "arXiv:2202.12262",
    "title": "On the Omnipresence of Spurious Local Minima in Certain Neural Network  Training Problems",
    "abstract": "We study the loss landscape of training problems for deep artificial neural\nnetworks with a one-dimensional real output whose activation functions contain\nan affine segment and whose hidden layers have width at least two. It is shown\nthat such problems possess a continuum of spurious (i.e., not globally optimal)\nlocal minima for all target functions that are not affine. In contrast to\nprevious works, our analysis covers all sampling and parameterization regimes,\ngeneral differentiable loss functions, arbitrary continuous nonpolynomial\nactivation functions, and both the finite- and infinite-dimensional setting. It\nis further shown that the appearance of the spurious local minima in the\nconsidered training problems is a direct consequence of the universal\napproximation theorem and that the underlying mechanisms also cause, e.g.,\nLp-best approximation problems to be ill-posed in the sense of Hadamard for all\nnetworks that do not have a dense image. The latter result also holds without\nthe assumption of local affine linearity and without any conditions on the\nhidden layers. The paper concludes with a numerical experiment which\ndemonstrates that spurious local minima can indeed affect the convergence\nbehavior of gradient-based solution algorithms in practice.",
    "descriptor": "",
    "authors": [
      "Constantin Christof",
      "Julia Kowalczyk"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2202.12262"
  },
  {
    "id": "arXiv:2202.12265",
    "title": "Clustering Edges in Directed Graphs",
    "abstract": "How do vertices exert influence in graph data? We develop a framework for\nedge clustering, a new method for exploratory data analysis that reveals how\nboth vertices and edges collaboratively accomplish directed influence in\ngraphs, especially for directed graphs. In contrast to the ubiquitous vertex\nclustering which groups vertices, edge clustering groups edges. Edges sharing a\nfunctional affinity are assigned to the same group and form an influence\nsubgraph cluster. With a complexity comparable to that of vertex clustering,\nthis framework presents three different methods for edge spectral clustering\nthat reveal important influence subgraphs in graph data, with each method\nproviding different insight into directed influence processes. We present\nseveral diverse examples demonstrating the potential for widespread application\nof edge clustering in scientific research.",
    "descriptor": "",
    "authors": [
      "Manohar Murthi",
      "Kamal Premaratne"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.12265"
  },
  {
    "id": "arXiv:2202.12269",
    "title": "Systematic review of deep learning and machine learning for building  energy",
    "abstract": "The building energy (BE) management has an essential role in urban\nsustainability and smart cities. Recently, the novel data science and\ndata-driven technologies have shown significant progress in analyzing the\nenergy consumption and energy demand data sets for a smarter energy management.\nThe machine learning (ML) and deep learning (DL) methods and applications, in\nparticular, have been promising for the advancement of the accurate and\nhigh-performance energy models. The present study provides a comprehensive\nreview of ML and DL-based techniques applied for handling BE systems, and it\nfurther evaluates the performance of these techniques. Through a systematic\nreview and a comprehensive taxonomy, the advances of ML and DL-based techniques\nare carefully investigated, and the promising models are introduced. According\nto the results obtained for energy demand forecasting, the hybrid and ensemble\nmethods are located in high robustness range, SVM-based methods are located in\ngood robustness limitation, ANN-based methods are located in medium robustness\nlimitation and linear regression models are located in low robustness\nlimitations. On the other hand, for energy consumption forecasting, DL-based,\nhybrid, and ensemble-based models provided the highest robustness score. ANN,\nSVM, and single ML models provided good and medium robustness and LR-based\nmodels provided the lower robustness score. In addition, for energy load\nforecasting, LR-based models provided the lower robustness score. The hybrid\nand ensemble-based models provided a higher robustness score. The DL-based and\nSVM-based techniques provided a good robustness score and ANN-based techniques\nprovided a medium robustness score.",
    "descriptor": "\nComments: 14 figures, 10 tables, accepted Frontiers in Energy Research: this https URL\n",
    "authors": [
      "Ardabili Sina",
      "Leila Abdolalizadeh",
      "Csaba Mako",
      "Bernat Torok",
      "Mosavi Amir"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.12269"
  },
  {
    "id": "arXiv:2202.12270",
    "title": "Evaluating Feature Attribution Methods in the Image Domain",
    "abstract": "Feature attribution maps are a popular approach to highlight the most\nimportant pixels in an image for a given prediction of a model. Despite a\nrecent growth in popularity and available methods, little attention is given to\nthe objective evaluation of such attribution maps. Building on previous work in\nthis domain, we investigate existing metrics and propose new variants of\nmetrics for the evaluation of attribution maps. We confirm a recent finding\nthat different attribution metrics seem to measure different underlying\nconcepts of attribution maps, and extend this finding to a larger selection of\nattribution metrics. We also find that metric results on one dataset do not\nnecessarily generalize to other datasets, and methods with desirable\ntheoretical properties such as DeepSHAP do not necessarily outperform\ncomputationally cheaper alternatives. Based on these findings, we propose a\ngeneral benchmarking approach to identify the ideal feature attribution method\nfor a given use case. Implementations of attribution metrics and our\nexperiments are available online.",
    "descriptor": "",
    "authors": [
      "Arne Gevaert",
      "Axel-Jan Rousseau",
      "Thijs Becker",
      "Dirk Valkenborg",
      "Tijl De Bie",
      "Yvan Saeys"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.12270"
  },
  {
    "id": "arXiv:2202.12273",
    "title": "Matching Papers and Reviewers at Large Conferences",
    "abstract": "This paper studies a novel reviewer-paper matching approach that was recently\ndeployed in the 35th AAAI Conference on Artificial Intelligence (AAAI 2021),\nand has since been adopted by other conferences including AAAI 2022 and ICML\n2022. This approach has three main elements: (1) collecting and processing\ninput data to identify problematic matches and generate reviewer-paper scores;\n(2) formulating and solving an optimization problem to find good reviewer-paper\nmatchings; and (3) the introduction of a novel, two-phase reviewing process\nthat shifted reviewing resources away from papers likely to be rejected and\ntowards papers closer to the decision boundary. This paper also describes an\nevaluation of these innovations based on an extensive post-hoc analysis on real\ndata -- including a comparison with the matching algorithm used in AAAI's\nprevious (2020) iteration -- and supplements this with additional numerical\nexperimentation.",
    "descriptor": "",
    "authors": [
      "Kevin Leyton-Brown",
      "Mausam",
      "Yatin Nandwani",
      "Hedayat Zarkoob",
      "Chris Cameron",
      "Neil Newman",
      "Dinesh Raghu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2202.12273"
  },
  {
    "id": "arXiv:2202.12276",
    "title": "On the influence of roundoff errors on the convergence of the gradient  descent method with low-precision floating-point computation",
    "abstract": "The employment of stochastic rounding schemes helps prevent stagnation of\nconvergence, due to vanishing gradient effect when implementing the gradient\ndescent method in low precision. Conventional stochastic rounding achieves zero\nbias by preserving small updates with probabilities proportional to their\nrelative magnitudes. In this study, we propose a new stochastic rounding scheme\nthat trades the zero bias property with a larger probability to preserve small\ngradients. Our method yields a constant rounding bias that, at each iteration,\nlies in a descent direction. For convex problems, we prove that the proposed\nrounding method has a beneficial effect on the convergence rate of gradient\ndescent. We validate our theoretical analysis by comparing the performances of\nvarious rounding schemes when optimizing a multinomial logistic regression\nmodel and when training a simple neural network with 8-bit floating-point\nformat.",
    "descriptor": "",
    "authors": [
      "Lu Xia",
      "Stefano Massei",
      "Michiel Hochstenbach",
      "Barry Koren"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.12276"
  },
  {
    "id": "arXiv:2202.12278",
    "title": "Learning Stochastic Dynamics with Statistics-Informed Neural Network",
    "abstract": "We introduce a machine-learning framework named statistics-informed neural\nnetwork (SINN) for learning stochastic dynamics from data. This new\narchitecture was theoretically inspired by a universal approximation theorem\nfor stochastic systems introduced in this paper and the projection-operator\nformalism for stochastic modeling. We devise mechanisms for training the neural\nnetwork model to reproduce the correct \\emph{statistical} behavior of a target\nstochastic process. Numerical simulation results demonstrate that a\nwell-trained SINN can reliably approximate both Markovian and non-Markovian\nstochastic dynamics. We demonstrate the applicability of SINN to model\ntransition dynamics. Furthermore, we show that the obtained reduced-order model\ncan be trained on temporally coarse-grained data and hence is well suited for\nrare-event simulations.",
    "descriptor": "",
    "authors": [
      "Yuanran Zhu",
      "Yu-Hang Tang",
      "Changho Kim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Artificial Intelligence (cs.AI)",
      "Dynamical Systems (math.DS)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2202.12278"
  },
  {
    "id": "arXiv:2202.12280",
    "title": "Tactile Materials in Practice: Understanding the Experiences of Teachers  of the Visually Impaired",
    "abstract": "Teachers of the visually impaired (TVIs) regularly present tactile materials\n(tactile graphics, 3D models, and real objects) to students with vision\nimpairments. Researchers have been increasingly interested in designing tools\nto support the use of tactile materials, but we still lack an in-depth\nunderstanding of how tactile materials are created and used in practice today.\nTo address this gap, we conducted interviews with 21 TVIs and a 3-week diary\nstudy with eight of them. We found that tactile materials were regularly used\nfor academic as well as non-academic concepts like tactile literacy, motor\nability, and spatial awareness. Real objects and 3D models served as \"stepping\nstones\" to tactile graphics and our participants preferred to teach with 3D\nmodels, despite finding them difficult to create, obtain, and modify. Use of\ncertain materials also carried social implications; participants selected\nmaterials that fostered student independence and allow classroom inclusion. We\ncontribute design considerations, encouraging future work on tactile materials\nto enable student and TVI co-creation, facilitate rapid prototyping, and\npromote movement and spatial awareness. To support future research in this\narea, our paper provides a fundamental understanding of current practices. We\nbridge these practices to established pedagogical approaches and highlight\nopportunities for growth regarding this important genre of educational\nmaterials.",
    "descriptor": "\nComments: 35 pages, 6 figures, 3 tables, to be published in TACCESS\n",
    "authors": [
      "Mahika Phutane",
      "Julie Wright",
      "Brenda Veronica Castro",
      "Lei Shi",
      "Simone R. Stern",
      "Holly M. Lawson",
      "Shiri Azenkot"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2202.12280"
  },
  {
    "id": "arXiv:2202.12284",
    "title": "Noisy Group Testing with Side Information",
    "abstract": "Group testing has recently attracted significant attention from the research\ncommunity due to its applications in diagnostic virology. An instance of the\ngroup testing problem includes a ground set of individuals which includes a\nsmall subset of infected individuals. The group testing procedure consists of a\nnumber of tests, such that each test indicates whether or not a given subset of\nindividuals includes one or more infected individuals. The goal of the group\ntesting procedure is to identify the subset of infected individuals with the\nminimum number of tests. Motivated by practical scenarios, such as testing for\nviral diseases, this paper focuses on the following group testing settings: (i)\nthe group testing procedure is noisy, i.e., the outcome of the group testing\nprocedure can be flipped with a certain probability; (ii) there is a certain\namount of side information on the distribution of the infected individuals\navailable to the group testing algorithm. The paper makes the following\ncontributions. First, we propose a probabilistic model, referred to as an\ninteraction model, that captures the side information about the probability\ndistribution of the infected individuals. Next, we present a decoding scheme,\nbased on the belief propagation, that leverages the interaction model to\nimprove the decoding accuracy. Our results indicate that the proposed algorithm\nachieves higher success probability and lower false-negative and false-positive\nrates when compared to the traditional belief propagation especially in the\nhigh noise regime.",
    "descriptor": "",
    "authors": [
      "Esmaeil Karimi",
      "Anoosheh Heidarzadeh",
      "Krishna R. Narayanan",
      "Alex Sprintson"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.12284"
  },
  {
    "id": "arXiv:2202.12288",
    "title": "Toward More Meaningful Resources for Lower-resourced Languages",
    "abstract": "In this position paper, we describe our perspective on how meaningful\nresources for lower-resourced languages should be developed in connection with\nthe speakers of those languages. We first examine two massively multilingual\nresources in detail. We explore the contents of the names stored in Wikidata\nfor a few lower-resourced languages and find that many of them are not in fact\nin the languages they claim to be and require non-trivial effort to correct. We\ndiscuss quality issues present in WikiAnn and evaluate whether it is a useful\nsupplement to hand annotated data. We then discuss the importance of creating\nannotation for lower-resourced languages in a thoughtful and ethical way that\nincludes the languages' speakers as part of the development process. We\nconclude with recommended guidelines for resource development.",
    "descriptor": "\nComments: Submitted to the ACL 2022 theme track \"Language Diversity: from Low-Resource to Endangered Languages\" and accepted to Findings of the ACL for ACL 2022\n",
    "authors": [
      "Constantine Lignos",
      "Nolan Holley",
      "Chester Palen-Michel",
      "Jonne S\u00e4lev\u00e4"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.12288"
  },
  {
    "id": "arXiv:2202.12293",
    "title": "Planarizing Graphs and their Drawings by Vertex Splitting",
    "abstract": "The splitting number of a graph $G=(V,E)$ is the minimum number of vertex\nsplits required to turn $G$ into a planar graph, where a vertex split removes a\nvertex $v \\in V$, introduces two new vertices $v_1, v_2$, and distributes the\nedges formerly incident to $v$ among its two split copies $v_1, v_2$. The\nsplitting number problem is known to be NP-complete. In this paper we shift\nfocus to the splitting number of graph drawings in $\\mathbb R^2$, where the new\nvertices resulting from vertex splits can be re-embedded into the existing\ndrawing of the remaining graph. We first provide a non-uniform fixed-parameter\ntractable (FPT) algorithm for the splitting number problem (without drawings).\nThen we show the NP-completeness of the splitting number problem for graph\ndrawings, even for its two subproblems of (1) selecting a minimum subset of\nvertices to split and (2) for re-embedding a minimum number of copies of a\ngiven set of vertices. For the latter problem we present an FPT algorithm\nparameterized by the number of vertex splits. This algorithm reduces to a\nbounded outerplanarity case and uses an intricate dynamic program on a\nsphere-cut decomposition.",
    "descriptor": "",
    "authors": [
      "Soeren Nickel",
      "Martin N\u00f6llenburg",
      "Manuel Sorge",
      "Ana\u00efs Villedieu",
      "Hsiang-Yun Wu",
      "Jules Wulms"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2202.12293"
  },
  {
    "id": "arXiv:2202.12299",
    "title": "Capturing Failures of Large Language Models via Human Cognitive Biases",
    "abstract": "Large language models generate complex, open-ended outputs: instead of\noutputting a single class, they can write summaries, generate dialogue, and\nproduce working code. In order to study the reliability of these open-ended\nsystems, we must understand not just when they fail, but also how they fail. To\napproach this, we draw inspiration from human cognitive biases -- systematic\npatterns of deviation from rational judgement. Specifically, we use cognitive\nbiases to (i) identify inputs that models are likely to err on, and (ii)\ndevelop tests to qualitatively characterize their errors on these inputs. Using\ncode generation as a case study, we find that OpenAI's Codex errs predictably\nbased on how the input prompt is framed, adjusts outputs towards anchors, and\nis biased towards outputs that mimic frequent training examples. We then use\nour framework to uncover high-impact errors such as incorrectly deleting files.\nOur experiments suggest that cognitive science can be a useful jumping-off\npoint to better understand how contemporary machine learning systems behave.",
    "descriptor": "",
    "authors": [
      "Erik Jones",
      "Jacob Steinhardt"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.12299"
  },
  {
    "id": "arXiv:2202.11712",
    "title": "Flow-based sampling in the lattice Schwinger model at criticality",
    "abstract": "Recent results suggest that flow-based algorithms may provide efficient\nsampling of field distributions for lattice field theory applications, such as\nstudies of quantum chromodynamics and the Schwinger model. In this work, we\nprovide a numerical demonstration of robust flow-based sampling in the\nSchwinger model at the critical value of the fermion mass. In contrast, at the\nsame parameters, conventional methods fail to sample all parts of configuration\nspace, leading to severely underestimated uncertainties.",
    "descriptor": "\nComments: 5 pages main text, 3 pages supplementary material. 4 figures\n",
    "authors": [
      "Michael S. Albergo",
      "Denis Boyda",
      "Kyle Cranmer",
      "Daniel C. Hackett",
      "Gurtej Kanwar",
      "S\u00e9bastien Racani\u00e8re",
      "Danilo J. Rezende",
      "Fernando Romero-L\u00f3pez",
      "Phiala E. Shanahan",
      "Julian M. Urban"
    ],
    "subjectives": [
      "High Energy Physics - Lattice (hep-lat)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.11712"
  },
  {
    "id": "arXiv:2202.11727",
    "title": "Completely Quantum Neural Networks",
    "abstract": "Artificial neural networks are at the heart of modern deep learning\nalgorithms. We describe how to embed and train a general neural network in a\nquantum annealer without introducing any classical element in training. To\nimplement the network on a state-of-the-art quantum annealer, we develop three\ncrucial ingredients: binary encoding the free parameters of the network,\npolynomial approximation of the activation function, and reduction of binary\nhigher-order polynomials into quadratic ones. Together, these ideas allow\nencoding the loss function as an Ising model Hamiltonian. The quantum annealer\nthen trains the network by finding the ground state. We implement this for an\nelementary network and illustrate the advantages of quantum training: its\nconsistency in finding the global minimum of the loss function and the fact\nthat the network training converges in a single annealing step, which leads to\nshort training times while maintaining a high classification performance. Our\napproach opens a novel avenue for the quantum training of general machine\nlearning models.",
    "descriptor": "\nComments: 12 pages, 6 figures\n",
    "authors": [
      "Steve Abel",
      "Juan C. Criado",
      "Michael Spannowsky"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)",
      "High Energy Physics - Phenomenology (hep-ph)",
      "High Energy Physics - Theory (hep-th)"
    ],
    "url": "https://arxiv.org/abs/2202.11727"
  },
  {
    "id": "arXiv:2202.11730",
    "title": "Using Bayesian Deep Learning to infer Planet Mass from Gaps in  Protoplanetary Disks",
    "abstract": "Planet induced sub-structures, like annular gaps, observed in dust emission\nfrom protoplanetary disks provide a unique probe to characterize unseen young\nplanets. While deep learning based model has an edge in characterizing the\nplanet's properties over traditional methods, like customized simulations and\nempirical relations, it lacks in its ability to quantify the uncertainty\nassociated with its predictions. In this paper, we introduce a Bayesian deep\nlearning network \"DPNNet-Bayesian\" that can predict planet mass from disk gaps\nand provides uncertainties associated with the prediction. A unique feature of\nour approach is that it can distinguish between the uncertainty associated with\nthe deep learning architecture and uncertainty inherent in the input data due\nto measurement noise. The model is trained on a data set generated from\ndisk-planet simulations using the \\textsc{fargo3d} hydrodynamics code with a\nnewly implemented fixed grain size module and improved initial conditions. The\nBayesian framework enables estimating a gauge/confidence interval over the\nvalidity of the prediction when applied to unknown observations. As a\nproof-of-concept, we apply DPNNet-Bayesian to dust gaps observed in HL Tau. The\nnetwork predicts masses of $ 86.0 \\pm 5.5 M_{\\Earth} $, $ 43.8 \\pm 3.3\nM_{\\Earth} $, and $ 92.2 \\pm 5.1 M_{\\Earth} $ respectively, which are\ncomparable to other studies based on specialized simulations.",
    "descriptor": "\nComments: 14 pages, 6 figures, submitted to ApJ\n",
    "authors": [
      "Sayantan Auddy",
      "Ramit Dey",
      "Min-Kai Lin",
      "Daniel Carrera",
      "Jacob B. Simon"
    ],
    "subjectives": [
      "Earth and Planetary Astrophysics (astro-ph.EP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.11730"
  },
  {
    "id": "arXiv:2202.11735",
    "title": "Truncated LinUCB for Stochastic Linear Bandits",
    "abstract": "This paper considers contextual bandits with a finite number of arms, where\nthe contexts are independent and identically distributed $d$-dimensional random\nvectors, and the expected rewards are linear in both the arm parameters and\ncontexts. The LinUCB algorithm, which is near minimax optimal for related\nlinear bandits, is shown to have a cumulative regret that is suboptimal in both\nthe dimension $d$ and time horizon $T$, due to its over-exploration. A\ntruncated version of LinUCB is proposed and termed \"Tr-LinUCB\", which follows\nLinUCB up to a truncation time $S$ and performs pure exploitation afterwards.\nThe Tr-LinUCB algorithm is shown to achieve $O(d\\log(T))$ regret if $S =\nCd\\log(T)$ for a sufficiently large constant $C$, and a matching lower bound is\nestablished, which shows the rate optimality of Tr-LinUCB in both $d$ and $T$\nunder a low dimensional regime. Further, if $S = d\\log^{\\kappa}(T)$ for some\n$\\kappa>1$, the loss compared to the optimal is a multiplicative $\\log\\log(T)$\nfactor, which does not depend on $d$. This insensitivity to overshooting in\nchoosing the truncation time of Tr-LinUCB is of practical importance.",
    "descriptor": "",
    "authors": [
      "Yanglei Song",
      "Meng zhou"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2202.11735"
  },
  {
    "id": "arXiv:2202.11752",
    "title": "Analysis of Coronavirus Envelope Protein with Cellular Automata (CA)  Model",
    "abstract": "The reason of significantly higher transmissibility of SARS Covid (2019\nCoV-2) compared to SARS Covid (2003 CoV) and MERS Covid (2012 MERS) can be\nattributed to mutations reported in structural proteins, and the role played by\nnon-structural proteins (nsps) and accessory proteins (ORFs) for viral\nreplication, assembly, and shedding. Envelope protein E is one of the four\nstructural proteins of minimum length. Recent studies have confirmed critical\nrole played by the envelope protein in the viral life cycle including assembly\nof virion exported from infected cell for its transmission. However, the\ndeterminants of the highly complex viral - host interactions of envelope\nprotein, particularly with host Golgi complex, have not been adequately\ncharacterized. CoV-2 and CoV Envelope proteins of length 75 and 76 amino acids\ndiffer in four amino acid locations. The additional amino acid Gly (G) at\nlocation 70 makes CoV length 76. The amino acid pair EG at location 69-70 of\nCoV in place of amino acid R in location 69 of CoV-2, has been identified as a\nmajor determining factor in the current investigation. This paper concentrates\non the design of computational model to compare the structure/function of wild\nand mutants of CoV-2 with wild and mutants of CoV in the functionally important\nregion of the protein chain pair. We hypothesize that differences of CAML model\nparameter of CoV-2 and CoV characterize the deviation in structure and function\nof envelope proteins in respect of interaction of virus with host Golgi\ncomplex; and this difference gets reflected in the difference of their\ntransmissibility. The hypothesis has been validated from single point\nmutational study on- (i) human HBB beta-globin hemoglobin protein associated\nwith sickle cell anemia, (ii) mutants of envelope protein of Covid-2 infected\npatients reported in recent publications.",
    "descriptor": "",
    "authors": [
      "Raju Hazari",
      "P Pal Chaudhuri"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.11752"
  },
  {
    "id": "arXiv:2202.11763",
    "title": "Single Image Super-Resolution Methods: A Survey",
    "abstract": "Super-resolution (SR), the process of obtaining high-resolution images from\none or more low-resolution observations of the same scene, has been a very\npopular topic of research in the last few decades in both signal processing and\nimage processing areas. Due to the recent developments in Convolutional Neural\nNetworks, the popularity of SR algorithms has skyrocketed as the barrier of\nentry has been lowered significantly. Recently, this popularity has spread into\nvideo processing areas to the lengths of developing SR models that work in\nreal-time. In this paper, we compare different SR models that specialize in\nsingle image processing and will take a glance at how they evolved to take on\nmany different objectives and shapes over the years.",
    "descriptor": "\nComments: 7 pages, 5 figures\n",
    "authors": [
      "Bahattin Can Maral"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.11763"
  },
  {
    "id": "arXiv:2202.11790",
    "title": "Blind Reverberation Time Estimation in Dynamic Acoustic Conditions",
    "abstract": "The estimation of reverberation time from real-world signals plays a central\nrole in a wide range of applications. In many scenarios, acoustic conditions\nchange over time which in turn requires the estimate to be updated\ncontinuously. Previously proposed methods involving deep neural networks were\nmostly designed and tested under the assumption of static acoustic conditions.\nIn this work, we show that these approaches can perform poorly in dynamically\nevolving acoustic environments. Motivated by a recent trend towards\ndata-centric approaches in machine learning, we propose a novel way of\ngenerating training data and demonstrate, using an existing deep neural network\narchitecture, the considerable improvement in the ability to follow temporal\nchanges in reverberation time.",
    "descriptor": "\nComments: accepted for publication in ICASSP 2022\n",
    "authors": [
      "Philipp G\u00f6tz",
      "Cagdas Tuna",
      "Andreas Walther",
      "Emanu\u00ebl A. P. Habets"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2202.11790"
  },
  {
    "id": "arXiv:2202.11801",
    "title": "Optimizing semilinear representations for State-dependent Riccati  Equation-based feedback control",
    "abstract": "An optimized variant of the State Dependent Riccati Equations (SDREs)\napproach for nonlinear optimal feedback stabilization is presented. The\nproposed method is based on the construction of equivalent semilinear\nrepresentations associated to the dynamics and their affine combination. The\noptimal combination is chosen to minimize the discrepancy between the SDRE\ncontrol and the optimal feedback law stemming from the solution of the\ncorresponding Hamilton Jacobi Bellman (HJB) equation. Numerical experiments\nassess effectiveness of the method in terms of stability of the closed-loop\nwith near-to-optimal performance.",
    "descriptor": "",
    "authors": [
      "Sergey Dolgov",
      "Dante Kalise",
      "Luca Saluzzi"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.11801"
  },
  {
    "id": "arXiv:2202.11804",
    "title": "Nuclei panoptic segmentation and composition regression with multi-task  deep neural networks",
    "abstract": "Nuclear segmentation, classification and quantification within Haematoxylin &\nEosin stained histology images enables the extraction of interpretable\ncell-based features that can be used in downstream explainable models in\ncomputational pathology. The Colon Nuclei Identification and Counting (CoNIC)\nChallenge is held to help drive forward research and innovation for automatic\nnuclei recognition in computational pathology. This report describes our\nproposed method submitted to the CoNIC challenge. Our method employs a\nmulti-task learning framework, which performs a panoptic segmentation task and\na regression task. For the panoptic segmentation task, we use encoder-decoder\ntype deep neural networks predicting a direction map in addition to a\nsegmentation map in order to separate neighboring nuclei into different\ninstances",
    "descriptor": "",
    "authors": [
      "Satoshi Kondo",
      "Satoshi Kasai"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.11804"
  },
  {
    "id": "arXiv:2202.11817",
    "title": "Benefit of Interpolation in Nearest Neighbor Algorithms",
    "abstract": "In some studies \\citep[e.g.,][]{zhang2016understanding} of deep learning, it\nis observed that over-parametrized deep neural networks achieve a small testing\nerror even when the training error is almost zero. Despite numerous works\ntowards understanding this so-called \"double descent\" phenomenon\n\\citep[e.g.,][]{belkin2018reconciling,belkin2019two}, in this paper, we turn\ninto another way to enforce zero training error (without over-parametrization)\nthrough a data interpolation mechanism. Specifically, we consider a class of\ninterpolated weighting schemes in the nearest neighbors (NN) algorithms. By\ncarefully characterizing the multiplicative constant in the statistical risk,\nwe reveal a U-shaped performance curve for the level of data interpolation in\nboth classification and regression setups. This sharpens the existing result\n\\citep{belkin2018does} that zero training error does not necessarily jeopardize\npredictive performances and claims a counter-intuitive result that a mild\ndegree of data interpolation actually {\\em strictly} improve the prediction\nperformance and statistical stability over those of the (un-interpolated)\n$k$-NN algorithm. In the end, the universality of our results, such as change\nof distance measure and corrupted testing data, will also be discussed.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:1909.11720\n",
    "authors": [
      "Yue Xing",
      "Qifan Song",
      "Guang Cheng"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.11817"
  },
  {
    "id": "arXiv:2202.11858",
    "title": "Reduced bandwidth: a qualitative strengthening of twin-width in  minor-closed classes (and beyond)",
    "abstract": "In a reduction sequence of a graph, vertices are successively identified\nuntil the graph has one vertex. At each step, when identifying $u$ and $v$,\neach edge incident to exactly one of $u$ and $v$ is coloured red. Bonnet, Kim,\nThomass\\'e and Watrigant [J. ACM 2022] defined the twin-width of a graph $G$ to\nbe the minimum integer $k$ such that there is a reduction sequence of $G$ in\nwhich every red graph has maximum degree at most $k$. For any graph parameter\n$f$, we define the reduced $f$ of a graph $G$ to be the minimum integer $k$\nsuch that there is a reduction sequence of $G$ in which every red graph has $f$\nat most $k$. Our focus is on graph classes with bounded reduced bandwidth,\nwhich implies and is stronger than bounded twin-width (reduced maximum degree).\nWe show that every proper minor-closed class has bounded reduced bandwidth,\nwhich is qualitatively stronger than an analogous result of Bonnet et al.\\ for\nbounded twin-width. In many instances, we also make quantitative improvements.\nFor example, all previous upper bounds on the twin-width of planar graphs were\nat least $2^{1000}$. We show that planar graphs have reduced bandwidth at most\n$466$ and twin-width at most $583$. Our bounds for graphs of Euler genus\n$\\gamma$ are $O(\\gamma)$. Lastly, we show that fixed powers of graphs in a\nproper minor-closed class have bounded reduced bandwidth (irrespective of the\ndegree of the vertices). In particular, we show that map graphs of Euler genus\n$\\gamma$ have reduced bandwidth $O(\\gamma^4)$. Lastly, we separate twin-width\nand reduced bandwidth by showing that any infinite class of expanders excluding\na fixed complete bipartite subgraph has unbounded reduced bandwidth, while\nthere are bounded-degree expanders with twin-width at most 6.",
    "descriptor": "\nComments: 35 pages, 4 figures\n",
    "authors": [
      "\u00c9douard Bonnet",
      "O-joung Kwon",
      "David R. Wood"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2202.11858"
  },
  {
    "id": "arXiv:2202.11883",
    "title": "A Note on Machine Learning Approach for Computational Imaging",
    "abstract": "Computational imaging has been playing a vital role in the development of\nnatural sciences. Advances in sensory, information, and computer technologies\nhave further extended the scope of influence of imaging, making digital images\nan essential component of our daily lives. For the past three decades, we have\nwitnessed phenomenal developments of mathematical and machine learning methods\nin computational imaging. In this note, we will review some of the recent\ndevelopments of the machine learning approach for computational imaging and\ndiscuss its differences and relations to the mathematical approach. We will\ndemonstrate how we may combine the wisdom from both approaches, discuss the\nmerits and potentials of such a combination and present some of the new\ncomputational and theoretical challenges it brings about.",
    "descriptor": "",
    "authors": [
      "Bin Dong"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Medical Physics (physics.med-ph)"
    ],
    "url": "https://arxiv.org/abs/2202.11883"
  },
  {
    "id": "arXiv:2202.11889",
    "title": "A spectral-spatial fusion anomaly detection method for hyperspectral  imagery",
    "abstract": "In hyperspectral, high-quality spectral signals convey subtle spectral\ndifferences to distinguish similar materials, thereby providing unique\nadvantage for anomaly detection. Hence fine spectra of anomalous pixels can be\neffectively screened out from heterogeneous background pixels. Since the same\nmaterials have similar characteristics in spatial and spectral dimension,\ndetection performance can be significantly enhanced by jointing spatial and\nspectral information. In this paper, a spectralspatial fusion anomaly detection\n(SSFAD) method is proposed for hyperspectral imagery. First, original spectral\nsignals are mapped to a local linear background space composed of median and\nmean with high confidence, where saliency weight and feature enhancement\nstrategies are implemented to obtain an initial detection map in spectral\ndomain. Futhermore, to make full use of similarity information of local\nbackground around testing pixel, a new detector is designed to extract the\nlocal similarity spatial features of patch images in spatial domain. Finally,\nanomalies are detected by adaptively combining the spectral and spatial\ndetection maps. The experimental results demonstrate that our proposed method\nhas superior detection performance than traditional methods.",
    "descriptor": "",
    "authors": [
      "Zengfu Hou",
      "Siyuan Cheng",
      "Ting Hu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.11889"
  },
  {
    "id": "arXiv:2202.11945",
    "title": "Performance of an iterative wavelet reconstructor for the  Multi-conjugate Adaptive Optics RelaY of ESO's ELT",
    "abstract": "The Multi-conjugate Adaptive Optics RelaY (MAORY) is one of the key Adaptive\nOptics (AO) systems on the European Southern Observatory's Extremely Large\nTelescope. MAORY aims to achieve a good wavefront correction over a large field\nof view, which involves a tomographic estimation of the 3D atmospheric\nwavefront disturbance. Mathematically, the reconstruction of turbulent layers\nin the atmosphere is severely ill-posed, hence, limits the achievable\nreconstruction accuracy. Moreover, the reconstruction has to be performed in\nreal-time at a few hundred to one thousand Hertz frame rates. Huge amounts of\ndata have to be processed and thousands of actuators of the deformable mirrors\nhave to be controlled by elaborated algorithms. Even with extensive\nparallelization and pipelining, direct solvers, such as the Matrix Vector\nMultiplication (MVM) method, are extremely demanding. Thus, research in the\nlast years shifted into the direction of iterative methods. In this paper we\nfocus on the iterative Finite Element Wavelet Hybrid Algorithm (FEWHA). The key\nfeature of FEWHA is a matrix-free representation of all operators involved,\nwhich makes the algorithm fast and enables on the fly system updates whenever\nparameters at the telescope or in the atmosphere change. We provide a\nperformance analysis of the method regarding quality and run-time for the MAORY\ninstrument using the AO software package COMPASS.",
    "descriptor": "",
    "authors": [
      "Bernadett Stadler",
      "Ronny Ramlau"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.11945"
  },
  {
    "id": "arXiv:2202.11959",
    "title": "Entropic trust region for densest crystallographic symmetry group  packings",
    "abstract": "Molecular crystal structure prediction (CSP) seeks the most stable periodic\nstructure given a chemical composition of a molecule and pressure-temperature\nconditions. Modern CSP solvers use global optimization methods to search for\nstructures with minimal free energy within a complex energy landscape induced\nby intermolecular potentials. A major caveat of these methods is that initial\nconfigurations are random, making thus the search susceptible to the\nconvergence at local minima. Providing initial configurations that are densely\npacked with respect to the geometric representation of a molecule can\nsignificantly accelerate CSP. Motivated by these observations we define a class\nof periodic packings restricted to crystallographic symmetry groups (CSG) and\ndesign a search method for densest CSG packings in an information geometric\nframework. Since the CSG induce a toroidal topology on the configuration space,\na non-euclidean trust region method is performed on a statistical manifold\nconsisting of probability distributions defined on an $n$-dimensional flat unit\ntorus by extending the multivariate von Mises distribution. By introducing an\nadaptive quantile reformulation of the fitness function into the optimization\nschedule we provide the algorithm a geometric characterization through local\ndual geodesic flows. Moreover, we examine the geometry of the adaptive\nselection quantile defined trust region and show that the algorithm performs a\nmaximization of stochastic dependence among elements of the extended\nmultivariate von Mises distributed random vector. We experimentally evaluate\nits behavior and performance on various densest packings of convex polygons in\n$2$-dimensional CSG for which optimal solutions are known.",
    "descriptor": "",
    "authors": [
      "Miloslav Torda",
      "John Y. Goulermas",
      "Roland P\u00fa\u010dek",
      "Vitaliy Kurlin"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Materials Science (cond-mat.mtrl-sci)",
      "Information Theory (cs.IT)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Metric Geometry (math.MG)"
    ],
    "url": "https://arxiv.org/abs/2202.11959"
  },
  {
    "id": "arXiv:2202.12008",
    "title": "A fair pricing model via adversarial learning",
    "abstract": "At the core of insurance business lies classification between risky and\nnon-risky insureds, actuarial fairness meaning that risky insureds should\ncontribute more and pay a higher premium than non-risky or less-risky ones.\nActuaries, therefore, use econometric or machine learning techniques to\nclassify, but the distinction between a fair actuarial classification and\n\"discrimination\" is subtle. For this reason, there is a growing interest about\nfairness and discrimination in the actuarial community Lindholm, Richman,\nTsanakas, and Wuthrich (2022). Presumably, non-sensitive characteristics can\nserve as substitutes or proxies for protected attributes. For example, the\ncolor and model of a car, combined with the driver's occupation, may lead to an\nundesirable gender bias in the prediction of car insurance prices.\nSurprisingly, we will show that debiasing the predictor alone may be\ninsufficient to maintain adequate accuracy (1). Indeed, the traditional pricing\nmodel is currently built in a two-stage structure that considers many\npotentially biased components such as car or geographic risks. We will show\nthat this traditional structure has significant limitations in achieving\nfairness. For this reason, we have developed a novel pricing model approach.\nRecently some approaches have Blier-Wong, Cossette, Lamontagne, and Marceau\n(2021); Wuthrich and Merz (2021) shown the value of autoencoders in pricing. In\nthis paper, we will show that (2) this can be generalized to multiple pricing\nfactors (geographic, car type), (3) it perfectly adapted for a fairness context\n(since it allows to debias the set of pricing components): We extend this main\nidea to a general framework in which a single whole pricing model is trained by\ngenerating the geographic and car pricing components needed to predict the pure\npremium while mitigating the unwanted bias according to the desired metric.",
    "descriptor": "\nComments: 20 pages, 12 figures\n",
    "authors": [
      "Grari Vincent",
      "Charpentier Arthur",
      "Lamprier Sylvain",
      "Detyniecki Marcin"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2202.12008"
  },
  {
    "id": "arXiv:2202.12012",
    "title": "Strict universes for Grothendieck topoi",
    "abstract": "Hofmann and Streicher famously showed how to lift Grothendieck universes into\npresheaf topoi, and Streicher has extended their result to the case of sheaf\ntopoi by sheafification. In parallel, van den Berg and Moerdijk have shown in\nthe context of algebraic set theory that similar constructions continue to\napply even in weaker metatheories. Unfortunately, sheafification seems not to\npreserve an important realignment property enjoyed by the presheaf universes\nthat plays a critical role in models of univalent type theory as well as\nsynthetic Tait computability, a recent technique to establish syntactic\nproperties of type theories and programming languages. In the context of\nmultiple universes, the realignment property also implies a coherent choice of\ncodes for connectives at each universe level, thereby interpreting the\ncumulativity laws present in popular formulations of Martin-L\\\"of type theory.\nWe observe that a slight adjustment to an argument of Shulman constructs a\ncumulative universe hierarchy satisfying the realignment property at every\nlevel in any Grothendieck topos. Hence one has direct-style interpretations of\nMartin-L\\\"of type theory with cumulative universes into all Grothendieck topoi.\nA further implication is to extend the reach of recent synthetic methods in the\nsemantics of cubical type theory and the syntactic metatheory of type theory\nand programming languages to all Grothendieck topoi.",
    "descriptor": "",
    "authors": [
      "Daniel Gratzer",
      "Michael Shulman",
      "Jonathan Sterling"
    ],
    "subjectives": [
      "Category Theory (math.CT)",
      "Logic in Computer Science (cs.LO)",
      "Logic (math.LO)"
    ],
    "url": "https://arxiv.org/abs/2202.12012"
  },
  {
    "id": "arXiv:2202.12028",
    "title": "Evolutionary Multi-Objective Reinforcement Learning Based Trajectory  Control and Task Offloading in UAV-Assisted Mobile Edge Computing",
    "abstract": "This paper studies the trajectory control and task offloading (TCTO) problem\nin an unmanned aerial vehicle (UAV)-assisted mobile edge computing system,\nwhere a UAV flies along a planned trajectory to collect computation tasks from\nsmart devices (SDs). We consider a scenario that SDs are not directly connected\nby the base station (BS) and the UAV has two roles to play: MEC server or\nwireless relay. The UAV makes task offloading decisions online, in which the\ncollected tasks can be executed locally on the UAV or offloaded to the BS for\nremote processing. The TCTO problem involves multi-objective optimization as\nits objectives are to minimize the task delay and the UAV's energy consumption,\nand maximize the number of tasks collected by the UAV, simultaneously. This\nproblem is challenging because the three objectives conflict with each other.\nThe existing reinforcement learning (RL) algorithms, either single-objective\nRLs or single-policy multi-objective RLs, cannot well address the problem since\nthey cannot output multiple policies for various preferences (i.e. weights)\nacross objectives in a single run. This paper adapts the evolutionary\nmulti-objective RL (EMORL), a multi-policy multi-objective RL, to the TCTO\nproblem. This algorithm can output multiple optimal policies in just one run,\neach optimizing a certain preference. The simulation results demonstrate that\nthe proposed algorithm can obtain more excellent nondominated policies by\nstriking a balance between the three objectives regarding policy quality,\ncompared with two evolutionary and two multi-policy RL algorithms.",
    "descriptor": "",
    "authors": [
      "Fuhong Song",
      "Huanlai Xing",
      "Xinhan Wang",
      "Shouxi Luo",
      "Penglin Dai",
      "Zhiwen Xiao",
      "Bowen Zhao"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.12028"
  },
  {
    "id": "arXiv:2202.12045",
    "title": "Pushing Blocks by Sweeping Lines",
    "abstract": "We investigate the reconfiguration of $n$ blocks, or \"tokens\", in the square\ngrid using \"line pushes\". A line push is performed from one of the four\ncardinal directions and pushes all tokens that are maximum in that direction to\nthe opposite direction. Tokens that are in the way of other tokens are\ndisplaced in the same direction, as well. Since we consider configurations\nequivalent under translation, this model is equivalent to having a line barrier\ntouching one of the sides of the bounding box of the configuration and trying\nto move all tokens toward the barrier by one unit.\nSimilar models of manipulating objects using uniform external forces match\nthe mechanics of existing games and puzzles, such as Mega Maze, 2048 and\nLabyrinth, and have also been investigated in the context of self-assembly,\nprogrammable matter and robotic motion planning. The problem of obtaining a\ngiven shape from a starting configuration is know to be NP-complete.\nWe show that, for every $n$, there are \"sparse\" initial configurations of $n$\ntokens (i.e., where no two tokens are in the same row or column) that can be\ncompacted into any $a\\times b$ box such that $ab=n$. However, only $1\\times k$,\n$2\\times k$ and $3\\times 3$ boxes are obtainable from any arbitrary sparse\nconfiguration with a matching number of tokens. We also study the problem of\nrearranging labeled tokens into a configuration of the same shape, but with\npermuted tokens. For every initial configuration of the tokens, we provide a\ncomplete characterization of what other configurations can be obtained by means\nof line pushes.",
    "descriptor": "\nComments: 26 pages, 23 figures\n",
    "authors": [
      "Hugo A. Akitaya",
      "Maarten L\u00f6ffler",
      "Giovanni Viglietta"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2202.12045"
  },
  {
    "id": "arXiv:2202.12088",
    "title": "The adoption of non-pharmaceutical interventions and the role of digital  infrastructure during the COVID-19 Pandemic in Colombia, Ecuador, and El  Salvador",
    "abstract": "Adherence to the non-pharmaceutical interventions (NPIs) put in place to\nmitigate the spreading of infectious diseases is a multifaceted problem.\nSocio-demographic, socio-economic, and epidemiological factors can influence\nthe perceived susceptibility and risk which are known to affect behavior.\nFurthermore, the adoption of NPIs is dependent upon the barriers, real or\nperceived, associated with their implementation. We study the determinants of\nNPIs adherence during the first wave of the COVID-19 Pandemic in Colombia,\nEcuador, and El Salvador. Analyses are performed at the level of municipalities\nand include socio-economic, socio-demographic, and epidemiological indicators.\nFurthermore, by leveraging a unique dataset comprising tens of millions of\ninternet Speedtest measurements from Ookla, we investigate the quality of the\ndigital infrastructure as a possible barrier to adoption. We use publicly\navailable data provided by Meta capturing aggregated mobility changes as a\nproxy of adherence to NPIs. Across the three countries considered, we find a\nsignificant correlation between mobility drops and digital infrastructure\nquality. The relationship remains significant after controlling for several\nfactors including socio-economic status, population size, and reported COVID-19\ncases. This finding suggests that municipalities with better connectivity were\nable to afford higher mobility reductions. The link between mobility drops and\ndigital infrastructure quality is stronger at the peak of NPIs stringency. We\nalso find that mobility reductions were more pronounced in larger, denser, and\nwealthier municipalities. Our work provides new insights on the significance of\naccess to digital tools as an additional factor influencing the ability to\nfollow social distancing guidelines during a health emergency",
    "descriptor": "",
    "authors": [
      "Nicol\u00f2 Gozzi",
      "Niccol\u00f2 Comini",
      "Nicola Perra"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2202.12088"
  },
  {
    "id": "arXiv:2202.12099",
    "title": "Data variation-aware medical image segmentation",
    "abstract": "Deep learning algorithms have become the golden standard for segmentation of\nmedical imaging data. In most works, the variability and heterogeneity of real\nclinical data is acknowledged to still be a problem. One way to automatically\novercome this is to capture and exploit this variation explicitly. Here, we\npropose an approach that improves on our previous work in this area and explain\nhow it potentially can improve clinical acceptance of (semi-)automatic\nsegmentation methods. In contrast to a standard neural network that produces\none segmentation, we propose to use a multi-pathUnet network that produces\nmultiple segmentation variants, presumably corresponding to the variations that\nreside in the dataset. Different paths of the network are trained on disjoint\ndata subsets. Because a priori it may be unclear what variations exist in the\ndata, the subsets should be automatically determined. This is achieved by\nsearching for the best data partitioning with an evolutionary optimization\nalgorithm. Because each network path can become more specialized when trained\non a more homogeneous data subset, better segmentation quality can be achieved.\nIn practical usage, various automatically produced segmentations can be\npresented to a medical expert, from which the preferred segmentation can be\nselected. In experiments with a real clinical dataset of CT scans with prostate\nsegmentations, our approach provides an improvement of several percentage\npoints in terms of Dice and surface Dice coefficients compared to when all\nnetwork paths are trained on all training data. Noticeably, the largest\nimprovement occurs in the upper part of the prostate that is known to be most\nprone to inter-observer segmentation variation.",
    "descriptor": "",
    "authors": [
      "Arkadiy Dushatskiy",
      "Gerry Lowe",
      "Peter A. N. Bosman",
      "Tanja Alderliesten"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2202.12099"
  },
  {
    "id": "arXiv:2202.12104",
    "title": "A Transformer-based Network for Deformable Medical Image Registration",
    "abstract": "Deformable medical image registration plays an important role in clinical\ndiagnosis and treatment. Recently, the deep learning (DL) based image\nregistration methods have been widely investigated and showed excellent\nperformance in computational speed. However, these methods cannot provide\nenough registration accuracy because of insufficient ability in representing\nboth the global and local features of the moving and fixed images. To address\nthis issue, this paper has proposed the transformer based image registration\nmethod. This method uses the distinctive transformer to extract the global and\nlocal image features for generating the deformation fields, based on which the\nregistered image is produced in an unsupervised way. Our method can improve the\nregistration accuracy effectively by means of self-attention mechanism and\nbi-level information flow. Experimental results on such brain MR image datasets\nas LPBA40 and OASIS-1 demonstrate that compared with several traditional and DL\nbased registration methods, our method provides higher registration accuracy in\nterms of dice values.",
    "descriptor": "\nComments: 5 pages, 4 figures, 18 conferences\n",
    "authors": [
      "Yibo Wang",
      "Wen Qian",
      "Xuming Zhang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.12104"
  },
  {
    "id": "arXiv:2202.12106",
    "title": "Classification of preordered spaces in terms of monotones -- Filling in  the gaps",
    "abstract": "Following the recent introduction of new classes of monotones, like injective\nmonotones or strict monotone multi-utilities, we present the classification of\npreordered spaces in terms of both the existence and cardinality of real-valued\nmonotones and the cardinality of the quotient space. In particular, we take\nadvantage of a characterization of real-valued monotones in terms of separating\nfamilies of increasing sets in order to obtain a more complete classification\nconsisting of classes that are strictly different from each other.",
    "descriptor": "",
    "authors": [
      "Pedro Hack",
      "Daniel A. Braun",
      "Sebastian Gottwald"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Information Theory (cs.IT)",
      "Theoretical Economics (econ.TH)",
      "Functional Analysis (math.FA)"
    ],
    "url": "https://arxiv.org/abs/2202.12106"
  },
  {
    "id": "arXiv:2202.12127",
    "title": "Robust random walk-like Metropolis-Hastings algorithms for concentrating  posteriors",
    "abstract": "Motivated by Bayesian inference with highly informative data we analyze the\nperformance of random walk-like Metropolis-Hastings algorithms for approximate\nsampling of increasingly concentrating target distributions. We focus on\nGaussian proposals which use a Hessian-based approximation of the target\ncovariance. By means of pushforward transition kernels we show that for\nGaussian target measures the spectral gap of the corresponding\nMetropolis-Hastings algorithm is independent of the concentration of the\nposterior, i.e., the noise level in the observational data that is used for\nBayesian inference. Moreover, by exploiting the convergence of the\nconcentrating posteriors to their Laplace approximation we extend the analysis\nto non-Gaussian target measures which either concentrate around a single point\nor along a linear manifold. In particular, in that setting we show that the\naverage acceptance rate as well as the expected squared jump distance of\nsuitable Metropolis-Hastings Markov chains do not deteriorate as the target\nconcentrates.",
    "descriptor": "\nComments: 27 pages\n",
    "authors": [
      "Daniel Rudolf",
      "Bj\u00f6rn Sprungk"
    ],
    "subjectives": [
      "Computation (stat.CO)",
      "Numerical Analysis (math.NA)",
      "Probability (math.PR)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2202.12127"
  },
  {
    "id": "arXiv:2202.12148",
    "title": "A novel unsupervised covid lung lesion segmentation based on the lung  tissue identification",
    "abstract": "This study aimed to evaluate the performance of a novel unsupervised deep\nlearning-based framework for automated infections lesion segmentation from CT\nimages of Covid patients. In the first step, two residual networks were\nindependently trained to identify the lung tissue for normal and Covid patients\nin a supervised manner. These two models, referred to as DL-Covid and DL-Norm\nfor Covid-19 and normal patients, respectively, generate the voxel-wise\nprobability maps for lung tissue identification. To detect Covid lesions, the\nCT image of the Covid patient is processed by the DL-Covid and DL-Norm models\nto obtain two lung probability maps. Since the DL-Norm model is not familiar\nwith Covid infections within the lung, this model would assign lower\nprobabilities to the lesions than the DL-Covid. Hence, the probability maps of\nthe Covid infections could be generated through the subtraction of the two lung\nprobability maps obtained from the DL-Covid and DL-Norm models. Manual lesion\nsegmentation of 50 Covid-19 CT images was used to assess the accuracy of the\nunsupervised lesion segmentation approach. The Dice coefficients of 0.985 and\n0.978 were achieved for the lung segmentation of normal and Covid patients in\nthe external validation dataset, respectively. Quantitative results of\ninfection segmentation by the proposed unsupervised method showed the Dice\ncoefficient and Jaccard index of 0.67 and 0.60, respectively. Quantitative\nevaluation of the proposed unsupervised approach for Covid-19 infectious lesion\nsegmentation showed relatively satisfactory results. Since this framework does\nnot require any annotated dataset, it could be used to generate very large\ntraining samples for the supervised machine learning algorithms dedicated to\nnoisy and/or weakly annotated datasets.",
    "descriptor": "",
    "authors": [
      "Faeze Gholamian Khah",
      "Samaneh Mostafapour",
      "Seyedjafar Shojaerazavi",
      "Nouraddin Abdi-Goushbolagh",
      "Hossein Arabi"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Medical Physics (physics.med-ph)"
    ],
    "url": "https://arxiv.org/abs/2202.12148"
  },
  {
    "id": "arXiv:2202.12158",
    "title": "Tube Stochastic Optimal Control for Nonlinear Constrained Trajectory  Optimization Problems",
    "abstract": "Recent low-thrust space missions have highlighted the importance of designing\ntrajectories that are robust against uncertainties. In its complete form, this\nprocess is formulated as a nonlinear constrained stochastic optimal control\nproblem. This problem is among the most complex in control theory, and no\npractically applicable method to low-thrust trajectory optimization problems\nhas been proposed to date. This paper presents a new algorithm to solve\nstochastic optimal control problems with nonlinear systems and constraints. The\nproposed algorithm uses the unscented transform to convert a stochastic optimal\ncontrol problem into a deterministic problem, which is then solved by\ntrajectory optimization methods such as differential dynamic programming. Two\nnumerical examples, one of which applies the proposed method to low-thrust\ntrajectory design, illustrate that it automatically introduces margins that\nimprove robustness. Finally, Monte Carlo simulations are used to evaluate the\nrobustness and optimality of the solution.",
    "descriptor": "",
    "authors": [
      "Naoya Ozaki",
      "Stefano Campagnola",
      "Ryu Funase"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.12158"
  },
  {
    "id": "arXiv:2202.12163",
    "title": "Attentive Temporal Pooling for Conformer-based Streaming Language  Identification in Long-form Speech",
    "abstract": "In this paper, we introduce a novel language identification system based on\nconformer layers. We propose an attentive temporal pooling mechanism to allow\nthe model to carry information in long-form audio via a recurrent form, such\nthat the inference can be performed in a streaming fashion. Additionally, a\nsimple domain adaptation mechanism is introduced to allow adapting an existing\nlanguage identification model to a new domain where the prior language\ndistribution is different. We perform a comparative study of different model\ntopologies under different constraints of model size, and find that\nconformer-base models outperform LSTM and transformer based models. Our\nexperiments also show that attentive temporal pooling and domain adaptation\nsignificantly improve the model accuracy.",
    "descriptor": "",
    "authors": [
      "Quan Wang",
      "Yang Yu",
      "Jason Pelecanos",
      "Yiling Huang",
      "Ignacio Lopez Moreno"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.12163"
  },
  {
    "id": "arXiv:2202.12169",
    "title": "Closing the Gap between Single-User and Multi-User VoiceFilter-Lite",
    "abstract": "VoiceFilter-Lite is a speaker-conditioned voice separation model that plays a\ncrucial role in improving speech recognition and speaker verification by\nsuppressing overlapping speech from non-target speakers. However, one\nlimitation of VoiceFilter-Lite, and other speaker-conditioned speech models in\ngeneral, is that these models are usually limited to a single target speaker.\nThis is undesirable as most smart home devices now support multiple enrolled\nusers. In order to extend the benefits of personalization to multiple users, we\npreviously developed an attention-based speaker selection mechanism and applied\nit to VoiceFilter-Lite. However, the original multi-user VoiceFilter-Lite model\nsuffers from significant performance degradation compared with single-user\nmodels. In this paper, we devised a series of experiments to improve the\nmulti-user VoiceFilter-Lite model. By incorporating a dual learning rate\nschedule and by using feature-wise linear modulation (FiLM) to condition the\nmodel with the attended speaker embedding, we successfully closed the\nperformance gap between multi-user and single-user VoiceFilter-Lite models on\nsingle-speaker evaluations. At the same time, the new model can also be easily\nextended to support any number of users, and significantly outperforms our\npreviously published model on multi-speaker evaluations.",
    "descriptor": "",
    "authors": [
      "Rajeev Rikhye",
      "Quan Wang",
      "Qiao Liang",
      "Yanzhang He",
      "Ian McGraw"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.12169"
  },
  {
    "id": "arXiv:2202.12233",
    "title": "Automatic speaker verification spoofing and deepfake detection using  wav2vec 2.0 and data augmentation",
    "abstract": "The performance of spoofing countermeasure systems depends fundamentally upon\nthe use of sufficiently representative training data. With this usually being\nlimited, current solutions typically lack generalisation to attacks encountered\nin the wild. Strategies to improve reliability in the face of uncontrolled,\nunpredictable attacks are hence needed. We report in this paper our efforts to\nuse self-supervised learning in the form of a wav2vec 2.0 front-end with fine\ntuning. Despite initial base representations being learned using only bona fide\ndata and no spoofed data, we obtain the lowest equal error rates reported in\nthe literature for both the ASVspoof 2021 Logical Access and Deepfake\ndatabases. When combined with data augmentation, these results correspond to an\nimprovement of almost 90 % relative to our baseline system.",
    "descriptor": "\nComments: Submitted to Speaker Odyssey Workshop 2022\n",
    "authors": [
      "Hemlata Tak",
      "Massimiliano Todisco",
      "Xin Wang",
      "Jee-weon Jung",
      "Junichi Yamagishi",
      "Nicholas Evans"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2202.12233"
  },
  {
    "id": "arXiv:2202.12263",
    "title": "Effect Identification in Cluster Causal Diagrams",
    "abstract": "One pervasive task found throughout the empirical sciences is to determine\nthe effect of interventions from non-experimental data. It is well-understood\nthat assumptions are necessary to perform causal inferences, which are commonly\narticulated through causal diagrams (Pearl, 2000). Despite the power of this\napproach, there are settings where the knowledge necessary to specify a causal\ndiagram over all observed variables may not be available, particularly in\ncomplex, high-dimensional domains. In this paper, we introduce a new type of\ngraphical model called cluster causal diagrams (for short, C-DAGs) that allows\nfor the partial specification of relationships among variables based on limited\nprior knowledge, alleviating the stringent requirement of specifying a full\ncausal diagram. A C-DAG specifies relationships between clusters of variables,\nwhile the relationships between the variables within a cluster are left\nunspecified. We develop the foundations and machinery for valid causal\ninferences over C-DAGs. In particular, we first define a new version of the\nd-separation criterion and prove its soundness and completeness. Secondly, we\nextend these new separation rules and prove the validity of the corresponding\ndo-calculus. Lastly, we show that a standard identification algorithm is sound\nand complete to systematically compute causal effects from observational data\ngiven a C-DAG.",
    "descriptor": "",
    "authors": [
      "Tara V. Anand",
      "Ad\u00e8le H. Ribeiro",
      "Jin Tian",
      "Elias Bareinboim"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.12263"
  },
  {
    "id": "arXiv:2202.12264",
    "title": "Understanding the Impact of the COVID-19 Pandemic on  Transportation-related Behaviors with Human Mobility Data",
    "abstract": "The constrained outbreak of COVID-19 in Mainland China has recently been\nregarded as a successful example of fighting this highly contagious virus. Both\nthe short period (in about three months) of transmission and the\nsub-exponential increase of confirmed cases in Mainland China have proved that\nthe Chinese authorities took effective epidemic prevention measures, such as\ncase isolation, travel restrictions, closing recreational venues, and banning\npublic gatherings. These measures can, of course, effectively control the\nspread of the COVID-19 pandemic. Meanwhile, they may dramatically change the\nhuman mobility patterns, such as the daily transportation-related behaviors of\nthe public. To better understand the impact of COVID-19 on\ntransportation-related behaviors and to provide more targeted anti-epidemic\nmeasures, we use the huge amount of human mobility data collected from Baidu\nMaps, a widely-used Web mapping service in China, to look into the detail\nreaction of the people there during the pandemic. To be specific, we conduct\ndata-driven analysis on transportation-related behaviors during the pandemic\nfrom the perspectives of 1) means of transportation, 2) type of visited venues,\n3) check-in time of venues, 4) preference on \"origin-destination\" distance, and\n5) \"origin-transportation-destination\" patterns. For each topic, we also give\nour specific insights and policy-making suggestions. Given that the COVID-19\npandemic is still spreading in more than 200 countries and territories\nworldwide, infecting millions of people, the insights and suggestions provided\nhere may help fight COVID-19.",
    "descriptor": "\nComments: KDD 2020\n",
    "authors": [
      "Huang Jizhou",
      "Wang Haifeng",
      "Fan Miao",
      "Zhuo An",
      "Sun Yibo",
      "Li Ying"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2202.12264"
  },
  {
    "id": "arXiv:2202.12267",
    "title": "Inflation of test accuracy due to data leakage in deep learning-based  classification of OCT images",
    "abstract": "In the application of deep learning on optical coherence tomography (OCT)\ndata, it is common to train classification networks using 2D images originating\nfrom volumetric data. Given the micrometer resolution of OCT systems,\nconsecutive images are often very similar in both visible structures and noise.\nThus, an inappropriate data split can result in overlap between the training\nand testing sets, with a large portion of the literature overlooking this\naspect. In this study, the effect of improper dataset splitting on model\nevaluation is demonstrated for two classification tasks using two OCT\nopen-access datasets extensively used in the literature, Kermany's\nophthalmology dataset and AIIMS breast tissue dataset. Our results show that\nthe classification accuracy is inflated by 3.9 to 26 percentage units for\nmodels tested on a dataset with improper splitting, highlighting the\nconsiderable effect of dataset handling on model evaluation. This study intends\nto raise awareness on the importance of dataset splitting for research on deep\nlearning using OCT data and volumetric data in general.",
    "descriptor": "\nComments: 8 pages, 2 figures\n",
    "authors": [
      "Iulian Emil Tampu",
      "Anders Eklund",
      "Neda Haj-Hosseini"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.12267"
  },
  {
    "id": "arXiv:2202.12275",
    "title": "Partitioned Variational Inference: A framework for probabilistic  federated learning",
    "abstract": "The proliferation of computing devices has brought about an opportunity to\ndeploy machine learning models on new problem domains using previously\ninaccessible data. Traditional algorithms for training such models often\nrequire data to be stored on a single machine with compute performed by a\nsingle node, making them unsuitable for decentralised training on multiple\ndevices. This deficiency has motivated the development of federated learning\nalgorithms, which allow multiple data owners to train collaboratively and use a\nshared model whilst keeping local data private. However, many of these\nalgorithms focus on obtaining point estimates of model parameters, rather than\nprobabilistic estimates capable of capturing model uncertainty, which is\nessential in many applications. Variational inference (VI) has become the\nmethod of choice for fitting many modern probabilistic models. In this paper we\nintroduce partitioned variational inference (PVI), a general framework for\nperforming VI in the federated setting. We develop new supporting theory for\nPVI, demonstrating a number of properties that make it an attractive choice for\npractitioners; use PVI to unify a wealth of fragmented, yet related literature;\nand provide empirical results that showcase the effectiveness of PVI in a\nvariety of federated settings.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:1811.11206\n",
    "authors": [
      "Matthew Ashman",
      "Thang D. Bui",
      "Cuong V. Nguyen",
      "Efstratios Markou",
      "Adrian Weller",
      "Siddharth Swaroop",
      "Richard E. Turner"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.12275"
  },
  {
    "id": "arXiv:2202.12277",
    "title": "Solving optimization problems with Blackwell approachability",
    "abstract": "We introduce the Conic Blackwell Algorithm$^+$ (CBA$^+$) regret minimizer, a\nnew parameter- and scale-free regret minimizer for general convex sets. CBA$^+$\nis based on Blackwell approachability and attains $O(\\sqrt{T})$ regret. We show\nhow to efficiently instantiate CBA$^+$ for many decision sets of interest,\nincluding the simplex, $\\ell_{p}$ norm balls, and ellipsoidal confidence\nregions in the simplex. Based on CBA$^+$, we introduce SP-CBA$^+$, a new\nparameter-free algorithm for solving convex-concave saddle-point problems,\nwhich achieves a $O(1/\\sqrt{T})$ ergodic rate of convergence. In our\nsimulations, we demonstrate the wide applicability of SP-CBA$^+$ on several\nstandard saddle-point problems, including matrix games, extensive-form games,\ndistributionally robust logistic regression, and Markov decision processes. In\neach setting, SP-CBA$^+$ achieves state-of-the-art numerical performance, and\noutperforms classical methods, without the need for any choice of step sizes or\nother algorithmic parameters.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2105.13203\n",
    "authors": [
      "Julien Grand-Cl\u00e9ment",
      "Christian Kroer"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.12277"
  },
  {
    "id": "arXiv:2202.12292",
    "title": "Bridging Level-K to Nash Equilibrium",
    "abstract": "We introduce NLK, a model that connects the Nash equilibrium (NE) and\nLevel-K. It allows a player in a game to believe that her opponent may be\neither less or as sophisticated as, she is, a view supported in psychology. We\napply NLK to data from five published papers on static, dynamic, and auction\ngames. NLK provides different predictions than those of the NE and Level-K;\nmoreover, a simple version of NLK explains the experimental data better in many\ncases, with the same or lower number of parameters. We discuss extensions to\ngames with more than two players and heterogeneous beliefs.",
    "descriptor": "",
    "authors": [
      "Dan Levin",
      "Luyao Zhang"
    ],
    "subjectives": [
      "General Economics (econ.GN)",
      "Computer Science and Game Theory (cs.GT)",
      "Applications (stat.AP)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2202.12292"
  },
  {
    "id": "arXiv:2202.12295",
    "title": "Factorizer: A Scalable Interpretable Approach to Context Modeling for  Medical Image Segmentation",
    "abstract": "Convolutional Neural Networks (CNNs) with U-shaped architectures have\ndominated medical image segmentation, which is crucial for various clinical\npurposes. However, the inherent locality of convolution makes CNNs fail to\nfully exploit global context, essential for better recognition of some\nstructures, e.g., brain lesions. Transformers have recently proved promising\nperformance on vision tasks, including semantic segmentation, mainly due to\ntheir capability of modeling long-range dependencies. Nevertheless, the\nquadratic complexity of attention makes existing Transformer-based models use\nself-attention layers only after somehow reducing the image resolution, which\nlimits the ability to capture global contexts present at higher resolutions.\nTherefore, this work introduces a family of models, dubbed Factorizer, which\nleverages the power of low-rank matrix factorization for constructing an\nend-to-end segmentation model. Specifically, we propose a linearly scalable\napproach to context modeling, formulating Nonnegative Matrix Factorization\n(NMF) as a differentiable layer integrated into a U-shaped architecture. The\nshifted window technique is also utilized in combination with NMF to\neffectively aggregate local information. Factorizers compete favorably with\nCNNs and Transformers in terms of accuracy, scalability, and interpretability,\nachieving state-of-the-art results on the BraTS dataset for brain tumor\nsegmentation, with Dice scores of 79.33%, 83.14%, and 90.16% for enhancing\ntumor, tumor core, and whole tumor, respectively. Highly meaningful NMF\ncomponents give an additional interpretability advantage to Factorizers over\nCNNs and Transformers. Moreover, our ablation studies reveal a distinctive\nfeature of Factorizers that enables a significant speed-up in inference for a\ntrained Factorizer without any extra steps and without sacrificing much\naccuracy.",
    "descriptor": "\nComments: 27 pages, 7 figures, 3 tables\n",
    "authors": [
      "Pooya Ashtari",
      "Diana Sima",
      "Lieven De Lathauwer",
      "Dominique Sappey-Marinierd",
      "Frederik Maes",
      "Sabine Van Huffel"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.12295"
  },
  {
    "id": "arXiv:2202.12297",
    "title": "Embedded Ensembles: Infinite Width Limit and Operating Regimes",
    "abstract": "A memory efficient approach to ensembling neural networks is to share most\nweights among the ensembled models by means of a single reference network. We\nrefer to this strategy as Embedded Ensembling (EE); its particular examples are\nBatchEnsembles and Monte-Carlo dropout ensembles. In this paper we perform a\nsystematic theoretical and empirical analysis of embedded ensembles with\ndifferent number of models. Theoretically, we use a Neural-Tangent-Kernel-based\napproach to derive the wide network limit of the gradient descent dynamics. In\nthis limit, we identify two ensemble regimes - independent and collective -\ndepending on the architecture and initialization strategy of ensemble models.\nWe prove that in the independent regime the embedded ensemble behaves as an\nensemble of independent models. We confirm our theoretical prediction with a\nwide range of experiments with finite networks, and further study empirically\nvarious effects such as transition between the two regimes, scaling of ensemble\nperformance with the network width and number of models, and dependence of\nperformance on a number of architecture and hyperparameter choices.",
    "descriptor": "",
    "authors": [
      "Maksim Velikanov",
      "Roman Kail",
      "Ivan Anokhin",
      "Roman Vashurin",
      "Maxim Panov",
      "Alexey Zaytsev",
      "Dmitry Yarotsky"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.12297"
  },
  {
    "id": "arXiv:2202.12298",
    "title": "Towards Low-distortion Multi-channel Speech Enhancement: The ESPNet-SE  Submission to The L3DAS22 Challenge",
    "abstract": "This paper describes our submission to the L3DAS22 Challenge Task 1, which\nconsists of speech enhancement with 3D Ambisonic microphones. The core of our\napproach combines Deep Neural Network (DNN) driven complex spectral mapping\nwith linear beamformers such as the multi-frame multi-channel Wiener filter.\nOur proposed system has two DNNs and a linear beamformer in between. Both DNNs\nare trained to perform complex spectral mapping, using a combination of\nwaveform and magnitude spectrum losses. The estimated signal from the first DNN\nis used to drive a linear beamformer, and the beamforming result, together with\nthis enhanced signal, are used as extra inputs for the second DNN which refines\nthe estimation. Then, from this new estimated signal, the linear beamformer and\nsecond DNN are run iteratively. The proposed method was ranked first in the\nchallenge, achieving, on the evaluation set, a ranking metric of 0.984, versus\n0.833 of the challenge baseline.",
    "descriptor": "\nComments: to be published in IEEE ICASSP 2022\n",
    "authors": [
      "Yen-Ju Lu",
      "Samuele Cornell",
      "Xuankai Chang",
      "Wangyou Zhang",
      "Chenda Li",
      "Zhaoheng Ni",
      "Zhong-Qiu Wang",
      "Shinji Watanabe"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2202.12298"
  },
  {
    "id": "arXiv:1507.07045",
    "title": "The Square Root Agreement Rule for Incentivizing Truthful Feedback on  Online Platforms",
    "abstract": "Comments: To appear in Management Science (2022)",
    "descriptor": "\nComments: To appear in Management Science (2022)\n",
    "authors": [
      "Vijay Kamble",
      "Nihar Shah",
      "David Marn",
      "Abhay Parekh",
      "Kannan Ramachandran"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/1507.07045"
  },
  {
    "id": "arXiv:1811.01908",
    "title": "Fast Non-Bayesian Poisson Factorization for Implicit-Feedback  Recommendations",
    "abstract": "Fast Non-Bayesian Poisson Factorization for Implicit-Feedback  Recommendations",
    "descriptor": "",
    "authors": [
      "David Cortes"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1811.01908"
  },
  {
    "id": "arXiv:1909.03618",
    "title": "Bias-Variance Games",
    "abstract": "Bias-Variance Games",
    "descriptor": "",
    "authors": [
      "Yiding Feng",
      "Ronen Gradwohl",
      "Jason Hartline",
      "Aleck Johnsen",
      "Denis Nekipelov"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/1909.03618"
  },
  {
    "id": "arXiv:1911.13136",
    "title": "A Multilayered Block Network Model to Forecast Large Dynamic  Transportation Graphs: an Application to US Air Transport",
    "abstract": "A Multilayered Block Network Model to Forecast Large Dynamic  Transportation Graphs: an Application to US Air Transport",
    "descriptor": "",
    "authors": [
      "Hector Rodriguez-Deniz",
      "Mattias Villani",
      "Augusto Voltes-Dorta"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/1911.13136"
  },
  {
    "id": "arXiv:2005.09649",
    "title": "Embeddings-Based Clustering for Target Specific Stances: The Case of a  Polarized Turkey",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:1909.10213",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:1909.10213\n",
    "authors": [
      "Ammar Rashed",
      "Mucahid Kutlu",
      "Kareem Darwish",
      "Tamer Elsayed",
      "Cans\u0131n Bayrak"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2005.09649"
  },
  {
    "id": "arXiv:2006.00987",
    "title": "Quantum circuit design for universal distribution using a superposition  of classical automata",
    "abstract": "Comments: 27 pages, pre-print",
    "descriptor": "\nComments: 27 pages, pre-print\n",
    "authors": [
      "Aritra Sarkar",
      "Zaid Al-Ars",
      "Koen Bertels"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computation and Language (cs.CL)",
      "Emerging Technologies (cs.ET)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2006.00987"
  },
  {
    "id": "arXiv:2006.09327",
    "title": "Submodular Maximization in Clean Linear Time",
    "abstract": "Submodular Maximization in Clean Linear Time",
    "descriptor": "",
    "authors": [
      "Wenxin Li",
      "Moran Feldman",
      "Ehsan Kazemi",
      "Amin Karbasi"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2006.09327"
  },
  {
    "id": "arXiv:2007.15030",
    "title": "Dynamic Defense Against Byzantine Poisoning Attacks in Federated  Learning",
    "abstract": "Comments: 10 pages",
    "descriptor": "\nComments: 10 pages\n",
    "authors": [
      "Nuria Rodr\u00edguez-Barroso",
      "Eugenio Mart\u00ednez-C\u00e1mara",
      "M. Victoria Luz\u00f3n",
      "Francisco Herrera"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2007.15030"
  },
  {
    "id": "arXiv:2010.06786",
    "title": "A Self-supervised Representation Learning of Sentence Structure for  Authorship Attribution",
    "abstract": "A Self-supervised Representation Learning of Sentence Structure for  Authorship Attribution",
    "descriptor": "",
    "authors": [
      "Fereshteh Jafariakinabad",
      "Kien A. Hua"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2010.06786"
  },
  {
    "id": "arXiv:2010.13096",
    "title": "Deductive Stability Proofs for Ordinary Differential Equations",
    "abstract": "Comments: Long version of paper at TACAS 2021 (27th International Conference on Tools and Algorithms for the Construction and Analysis of Systems, 27 Mar - 1 Apr 2021)",
    "descriptor": "\nComments: Long version of paper at TACAS 2021 (27th International Conference on Tools and Algorithms for the Construction and Analysis of Systems, 27 Mar - 1 Apr 2021)\n",
    "authors": [
      "Yong Kiam Tan",
      "Andr\u00e9 Platzer"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2010.13096"
  },
  {
    "id": "arXiv:2010.13933",
    "title": "Memorizing without overfitting: Bias, variance, and interpolation in  over-parameterized models",
    "abstract": "Comments: 21 pages (double column), 6 figures, 32 pages of supplemental material (single column)",
    "descriptor": "\nComments: 21 pages (double column), 6 figures, 32 pages of supplemental material (single column)\n",
    "authors": [
      "Jason W. Rocks",
      "Pankaj Mehta"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2010.13933"
  },
  {
    "id": "arXiv:2010.14006",
    "title": "Continuous Operator Authentication for Teleoperated Systems Using Hidden  Markov Models",
    "abstract": "Continuous Operator Authentication for Teleoperated Systems Using Hidden  Markov Models",
    "descriptor": "",
    "authors": [
      "Junjie Yan",
      "Kevin Huang",
      "Kyle Lindgren",
      "Tamara Bonaci",
      "Howard Jay Chizeck"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2010.14006"
  },
  {
    "id": "arXiv:2011.08485",
    "title": "Probing Predictions on OOD Images via Nearest Categories",
    "abstract": "Probing Predictions on OOD Images via Nearest Categories",
    "descriptor": "",
    "authors": [
      "Yao-Yuan Yang",
      "Cyrus Rashtchian",
      "Ruslan Salakhutdinov",
      "Kamalika Chaudhuri"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2011.08485"
  },
  {
    "id": "arXiv:2011.11710",
    "title": "Natural-gradient learning for spiking neurons",
    "abstract": "Comments: Joint senior authorship: Walter M. Senn and Mihai A. Petrovici",
    "descriptor": "\nComments: Joint senior authorship: Walter M. Senn and Mihai A. Petrovici\n",
    "authors": [
      "Elena Kreutzer",
      "Walter M. Senn",
      "Mihai A. Petrovici"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Differential Geometry (math.DG)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2011.11710"
  },
  {
    "id": "arXiv:2012.00968",
    "title": "Reconfigurable Intelligent Surfaces in Action for Non-Terrestrial  Networks",
    "abstract": "Comments: 8 pages, 6 figures",
    "descriptor": "\nComments: 8 pages, 6 figures\n",
    "authors": [
      "K\u00fcr\u015fat Tekb\u0131y\u0131k",
      "G\u00fcne\u015f Karabulut Kurt",
      "Ali R\u0131za Ekti",
      "Halim Yanikomeroglu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2012.00968"
  },
  {
    "id": "arXiv:2012.03597",
    "title": "PSGCNet: A Pyramidal Scale and Global Context Guided Network for Dense  Object Counting in Remote Sensing Images",
    "abstract": "Comments: Accepted by TGRS",
    "descriptor": "\nComments: Accepted by TGRS\n",
    "authors": [
      "Guangshuai Gao",
      "Qingjie Liu",
      "Zhenghui Hu",
      "Lu Li",
      "Qi Wen",
      "Yunhong Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2012.03597"
  },
  {
    "id": "arXiv:2012.08512",
    "title": "FLAVR: Flow-Agnostic Video Representations for Fast Frame Interpolation",
    "abstract": "Comments: Project webpage: this https URL",
    "descriptor": "\nComments: Project webpage: this https URL\n",
    "authors": [
      "Tarun Kalluri",
      "Deepak Pathak",
      "Manmohan Chandraker",
      "Du Tran"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2012.08512"
  },
  {
    "id": "arXiv:2101.09646",
    "title": "An Improved Level Set Method for Reachability Problems in Differential  Games",
    "abstract": "Comments: 9 pages, 13 figures",
    "descriptor": "\nComments: 9 pages, 13 figures\n",
    "authors": [
      "Wei Liao",
      "Taotao Liang",
      "Pengwen Xiong",
      "Chen Wang",
      "Aiguo Song",
      "Peter X. Liu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2101.09646"
  },
  {
    "id": "arXiv:2102.01649",
    "title": "Heterogeneous Graph based Deep Learning for Biomedical Network Link  Prediction",
    "abstract": "Heterogeneous Graph based Deep Learning for Biomedical Network Link  Prediction",
    "descriptor": "",
    "authors": [
      "Jinjiang Guo",
      "Jie Li",
      "Dawei Leng",
      "Lurong Pan"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.01649"
  },
  {
    "id": "arXiv:2102.06186",
    "title": "Quadric Hypersurface Intersection for Manifold Learning in Feature Space",
    "abstract": "Quadric Hypersurface Intersection for Manifold Learning in Feature Space",
    "descriptor": "",
    "authors": [
      "Fedor Pavutnitskiy",
      "Sergei O. Ivanov",
      "Evgeny Abramov",
      "Viacheslav Borovitskiy",
      "Artem Klochkov",
      "Viktor Vialov",
      "Anatolii Zaikovskii",
      "Aleksandr Petiushko"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2102.06186"
  },
  {
    "id": "arXiv:2102.06249",
    "title": "A Survey on Ransomware: Evolution, Taxonomy, and Defense Solutions",
    "abstract": "Comments: Accepted to ACM Computing Surveys",
    "descriptor": "\nComments: Accepted to ACM Computing Surveys\n",
    "authors": [
      "Harun Oz",
      "Ahmet Aris",
      "Albert Levi",
      "A. Selcuk Uluagac"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2102.06249"
  },
  {
    "id": "arXiv:2102.12238",
    "title": "Inductive Bias of Multi-Channel Linear Convolutional Networks with  Bounded Weight Norm",
    "abstract": "Comments: Updated version with revised and expanded content",
    "descriptor": "\nComments: Updated version with revised and expanded content\n",
    "authors": [
      "Meena Jagadeesan",
      "Ilya Razenshteyn",
      "Suriya Gunasekar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2102.12238"
  },
  {
    "id": "arXiv:2102.12592",
    "title": "Documentation Matters: Human-Centered AI System to Assist Data Science  Code Documentation in Computational Notebooks",
    "abstract": "Documentation Matters: Human-Centered AI System to Assist Data Science  Code Documentation in Computational Notebooks",
    "descriptor": "",
    "authors": [
      "April Yi Wang",
      "Dakuo Wang",
      "Jaimie Drozdal",
      "Michael Muller",
      "Soya Park",
      "Justin D. Weisz",
      "Xuye Liu",
      "Lingfei Wu",
      "Casey Dugan"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2102.12592"
  },
  {
    "id": "arXiv:2103.02958",
    "title": "Serverless Model Serving for Data Science",
    "abstract": "Comments: Accepted by ACM SIGMOD 2022, 10 pages",
    "descriptor": "\nComments: Accepted by ACM SIGMOD 2022, 10 pages\n",
    "authors": [
      "Yuncheng Wu",
      "Tien Tuan Anh Dinh",
      "Guoyu Hu",
      "Meihui Zhang",
      "Yeow Meng Chee",
      "Beng Chin Ooi"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.02958"
  },
  {
    "id": "arXiv:2103.09716",
    "title": "Quantitative Performance Assessment of CNN Units via Topological Entropy  Calculation",
    "abstract": "Comments: Conference paper at ICLR 2022",
    "descriptor": "\nComments: Conference paper at ICLR 2022\n",
    "authors": [
      "Yang Zhao",
      "Hao Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.09716"
  },
  {
    "id": "arXiv:2104.01358",
    "title": "Intersection Types for a Computational Lambda-Calculus with Global State",
    "abstract": "Intersection Types for a Computational Lambda-Calculus with Global State",
    "descriptor": "",
    "authors": [
      "Ugo de'Liguoro",
      "Riccardo Treglia"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2104.01358"
  },
  {
    "id": "arXiv:2104.01374",
    "title": "Interpretable Unsupervised Diversity Denoising and Artefact Removal",
    "abstract": "Interpretable Unsupervised Diversity Denoising and Artefact Removal",
    "descriptor": "",
    "authors": [
      "Mangal Prakash",
      "Mauricio Delbracio",
      "Peyman Milanfar",
      "Florian Jug"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2104.01374"
  },
  {
    "id": "arXiv:2104.06135",
    "title": "Multivariate Deep Evidential Regression",
    "abstract": "Comments: 20 pages, 13 figures",
    "descriptor": "\nComments: 20 pages, 13 figures\n",
    "authors": [
      "Nis Meinert",
      "Alexander Lavin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2104.06135"
  },
  {
    "id": "arXiv:2104.08133",
    "title": "Inverse linear problems on Hilbert space and their Krylov solvability",
    "abstract": "Inverse linear problems on Hilbert space and their Krylov solvability",
    "descriptor": "",
    "authors": [
      "Noe Angelo Caruso",
      "Alessandro Michelangeli"
    ],
    "subjectives": [
      "Functional Analysis (math.FA)",
      "Numerical Analysis (math.NA)",
      "Spectral Theory (math.SP)"
    ],
    "url": "https://arxiv.org/abs/2104.08133"
  },
  {
    "id": "arXiv:2104.11294",
    "title": "Operator Shifting for General Noisy Matrix Systems",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:2010.09656",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2010.09656\n",
    "authors": [
      "Philip Etter",
      "Lexing Ying"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2104.11294"
  },
  {
    "id": "arXiv:2104.13621",
    "title": "MLDemon: Deployment Monitoring for Machine Learning Systems",
    "abstract": "Comments: Accepted to AISTATS 2022. Significant changes to algorithm, theory, and experiments since previous versions",
    "descriptor": "\nComments: Accepted to AISTATS 2022. Significant changes to algorithm, theory, and experiments since previous versions\n",
    "authors": [
      "Antonio Ginart",
      "Martin Zhang",
      "James Zou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2104.13621"
  },
  {
    "id": "arXiv:2104.14976",
    "title": "Comparing Power Processing System Approaches in Second-Use Battery  Energy Buffering for Electric Vehicle Charging",
    "abstract": "Comments: typos corrected, references added, several sections from the previous version were omitted because it is out of scope for the journal submission, title, abstract and introduction revised, results unchanged",
    "descriptor": "\nComments: typos corrected, references added, several sections from the previous version were omitted because it is out of scope for the journal submission, title, abstract and introduction revised, results unchanged\n",
    "authors": [
      "Xiaofan Cui",
      "Alireza Ramyar",
      "Jason Siegel",
      "Peyman Mohtat",
      "Anna Stefanopoulou",
      "Al-Thaddeus Avestruz"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2104.14976"
  },
  {
    "id": "arXiv:2105.01478",
    "title": "Intelligent Zero Trust Architecture for 5G/6G Networks: Principles,  Challenges, and the Role of Machine Learning in the context of O-RAN",
    "abstract": "Comments: Submitted for possible publication. For non-commercial use only. Please contact Dr. Jithin Jagannath for any other use case",
    "descriptor": "\nComments: Submitted for possible publication. For non-commercial use only. Please contact Dr. Jithin Jagannath for any other use case\n",
    "authors": [
      "Keyvan Ramezanpour",
      "Jithin Jagannath"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.01478"
  },
  {
    "id": "arXiv:2105.06597",
    "title": "RetGen: A Joint framework for Retrieval and Grounded Text Generation  Modeling",
    "abstract": "Comments: accepted by AAAI-22, camera ready version",
    "descriptor": "\nComments: accepted by AAAI-22, camera ready version\n",
    "authors": [
      "Yizhe Zhang",
      "Siqi Sun",
      "Xiang Gao",
      "Yuwei Fang",
      "Chris Brockett",
      "Michel Galley",
      "Jianfeng Gao",
      "Bill Dolan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.06597"
  },
  {
    "id": "arXiv:2105.07446",
    "title": "Sobolev Norm Learning Rates for Conditional Mean Embeddings",
    "abstract": "Comments: Appears in AISTATS 2022",
    "descriptor": "\nComments: Appears in AISTATS 2022\n",
    "authors": [
      "Prem Talwai",
      "Ali Shameli",
      "David Simchi-Levi"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.07446"
  },
  {
    "id": "arXiv:2105.13343",
    "title": "Drawing Multiple Augmentation Samples Per Image During Training  Efficiently Decreases Test Error",
    "abstract": "Drawing Multiple Augmentation Samples Per Image During Training  Efficiently Decreases Test Error",
    "descriptor": "",
    "authors": [
      "Stanislav Fort",
      "Andrew Brock",
      "Razvan Pascanu",
      "Soham De",
      "Samuel L. Smith"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.13343"
  },
  {
    "id": "arXiv:2105.14428",
    "title": "DAGNN: Demand-aware Graph Neural Networks for Session-based  Recommendation",
    "abstract": "Comments: There were errors in the experimental analysis",
    "descriptor": "\nComments: There were errors in the experimental analysis\n",
    "authors": [
      "Liqi Yang",
      "Linhan Luo",
      "Lifeng Xin",
      "Xiaofeng Zhang",
      "Xinni Zhang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2105.14428"
  },
  {
    "id": "arXiv:2105.15197",
    "title": "A Simple and General Debiased Machine Learning Theorem with Finite  Sample Guarantees",
    "abstract": "Comments: 34 pages",
    "descriptor": "\nComments: 34 pages\n",
    "authors": [
      "Victor Chernozhukov",
      "Whitney K. Newey",
      "Rahul Singh"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Econometrics (econ.EM)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2105.15197"
  },
  {
    "id": "arXiv:2106.02697",
    "title": "Enterprise-Scale Search: Accelerating Inference for Sparse Extreme  Multi-Label Ranking Trees",
    "abstract": "Enterprise-Scale Search: Accelerating Inference for Sparse Extreme  Multi-Label Ranking Trees",
    "descriptor": "",
    "authors": [
      "Philip A. Etter",
      "Kai Zhong",
      "Hsiang-Fu Yu",
      "Lexing Ying",
      "Inderjit Dhillon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.02697"
  },
  {
    "id": "arXiv:2106.03947",
    "title": "TENGraD: Time-Efficient Natural Gradient Descent with Exact Fisher-Block  Inversion",
    "abstract": "TENGraD: Time-Efficient Natural Gradient Descent with Exact Fisher-Block  Inversion",
    "descriptor": "",
    "authors": [
      "Saeed Soori",
      "Bugra Can",
      "Baourun Mu",
      "Mert G\u00fcrb\u00fczbalaban",
      "Maryam Mehri Dehnavi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.03947"
  },
  {
    "id": "arXiv:2106.04420",
    "title": "Back2Future: Leveraging Backfill Dynamics for Improving Real-time  Predictions in Future",
    "abstract": "Comments: 15 pages, 8 figures, To appear in ICLR 2022",
    "descriptor": "\nComments: 15 pages, 8 figures, To appear in ICLR 2022\n",
    "authors": [
      "Harshavardhan Kamarthi",
      "Alexander Rodr\u00edguez",
      "B. Aditya Prakash"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2106.04420"
  },
  {
    "id": "arXiv:2106.07856",
    "title": "A Hybrid mmWave and Camera System for Long-Range Depth Imaging",
    "abstract": "A Hybrid mmWave and Camera System for Long-Range Depth Imaging",
    "descriptor": "",
    "authors": [
      "Akarsh Prabhakara",
      "Diana Zhang",
      "Chao Li",
      "Sirajum Munir",
      "Aswin Sankanaryanan",
      "Anthony Rowe",
      "Swarun Kumar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Networking and Internet Architecture (cs.NI)",
      "Robotics (cs.RO)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2106.07856"
  },
  {
    "id": "arXiv:2106.08934",
    "title": "Personalized News Recommendation: Methods and Challenges",
    "abstract": "Personalized News Recommendation: Methods and Challenges",
    "descriptor": "",
    "authors": [
      "Chuhan Wu",
      "Fangzhao Wu",
      "Yongfeng Huang",
      "Xing Xie"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2106.08934"
  },
  {
    "id": "arXiv:2106.09659",
    "title": "Robustness and Consistency in Linear Quadratic Control with Untrusted  Predictions",
    "abstract": "Comments: 34 pages, 8 figures, ACM SIGMETRICS 2022",
    "descriptor": "\nComments: 34 pages, 8 figures, ACM SIGMETRICS 2022\n",
    "authors": [
      "Tongxin Li",
      "Ruixiao Yang",
      "Guannan Qu",
      "Guanya Shi",
      "Chenkai Yu",
      "Adam Wierman",
      "Steven H. Low"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2106.09659"
  },
  {
    "id": "arXiv:2106.11424",
    "title": "HODA: Hardness-Oriented Detection of Model Extraction Attacks",
    "abstract": "Comments: 15 pages, 12 figures, 7 tables, 2 Alg",
    "descriptor": "\nComments: 15 pages, 12 figures, 7 tables, 2 Alg\n",
    "authors": [
      "Amir Mahdi Sadeghzadeh",
      "Amir Mohammad Sobhanian",
      "Faezeh Dehghan",
      "Rasool Jalili"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2106.11424"
  },
  {
    "id": "arXiv:2106.13301",
    "title": "Physics perception in sloshing scenes with guaranteed thermodynamic  consistency",
    "abstract": "Comments: 21 pages, 12 figures",
    "descriptor": "\nComments: 21 pages, 12 figures\n",
    "authors": [
      "Beatriz Moya",
      "Alberto Badias",
      "David Gonzalez",
      "Francisco Chinesta",
      "Elias Cueto"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.13301"
  },
  {
    "id": "arXiv:2107.10098",
    "title": "Disentanglement via Mechanism Sparsity Regularization: A New Principle  for Nonlinear ICA",
    "abstract": "Comments: Appears in: 1st Conference on Causal Learning and Reasoning (CLeaR 2022). 57 pages",
    "descriptor": "\nComments: Appears in: 1st Conference on Causal Learning and Reasoning (CLeaR 2022). 57 pages\n",
    "authors": [
      "S\u00e9bastien Lachapelle",
      "Pau Rodr\u00edguez L\u00f3pez",
      "Yash Sharma",
      "Katie Everett",
      "R\u00e9mi Le Priol",
      "Alexandre Lacoste",
      "Simon Lacoste-Julien"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.10098"
  },
  {
    "id": "arXiv:2107.12765",
    "title": "Resource Optimization with Interference Coupling in Multi-RIS-assisted  Multi-cell Systems",
    "abstract": "Resource Optimization with Interference Coupling in Multi-RIS-assisted  Multi-cell Systems",
    "descriptor": "",
    "authors": [
      "Zhanwei Yu",
      "Di Yuan"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2107.12765"
  },
  {
    "id": "arXiv:2107.14185",
    "title": "Feature Importance-aware Transferable Adversarial Attacks",
    "abstract": "Comments: Accepted to ICCV 2021",
    "descriptor": "\nComments: Accepted to ICCV 2021\n",
    "authors": [
      "Zhibo Wang",
      "Hengchang Guo",
      "Zhifei Zhang",
      "Wenxin Liu",
      "Zhan Qin",
      "Kui Ren"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.14185"
  },
  {
    "id": "arXiv:2108.01430",
    "title": "Constant Factor Approximation for Tracking Paths and Fault Tolerant  Feedback Vertex Set",
    "abstract": "Constant Factor Approximation for Tracking Paths and Fault Tolerant  Feedback Vertex Set",
    "descriptor": "",
    "authors": [
      "V\u00e1clav Bla\u017eej",
      "Pratibha Choudhary",
      "Du\u0161an Knop",
      "Jan Maty\u00e1\u0161 K\u0159i\u0161\u0165an",
      "Ond\u0159ej Such\u00fd",
      "Tom\u00e1\u0161 Valla"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2108.01430"
  },
  {
    "id": "arXiv:2108.07992",
    "title": "On Multimarginal Partial Optimal Transport: Equivalent Forms and  Computational Complexity",
    "abstract": "Comments: Accepted at AISTATS, 2022. Khang Le and Huy Nguyen contributed equally to this work",
    "descriptor": "\nComments: Accepted at AISTATS, 2022. Khang Le and Huy Nguyen contributed equally to this work\n",
    "authors": [
      "Khang Le",
      "Huy Nguyen",
      "Tung Pham",
      "Nhat Ho"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2108.07992"
  },
  {
    "id": "arXiv:2108.10961",
    "title": "Entropic Gromov-Wasserstein between Gaussian Distributions",
    "abstract": "Comments: 52 pages, 3 figures. Khang Le, Dung Le, Huy Nguyen contributed equally to this work",
    "descriptor": "\nComments: 52 pages, 3 figures. Khang Le, Dung Le, Huy Nguyen contributed equally to this work\n",
    "authors": [
      "Khang Le",
      "Dung Le",
      "Huy Nguyen",
      "Dat Do",
      "Tung Pham",
      "Nhat Ho"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Information Theory (cs.IT)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2108.10961"
  },
  {
    "id": "arXiv:2109.01690",
    "title": "High-quality Thermal Gibbs Sampling with Quantum Annealing Hardware",
    "abstract": "High-quality Thermal Gibbs Sampling with Quantum Annealing Hardware",
    "descriptor": "",
    "authors": [
      "Jon Nelson",
      "Marc Vuffray",
      "Andrey Y. Lokhov",
      "Tameem Albash",
      "Carleton Coffrin"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.01690"
  },
  {
    "id": "arXiv:2109.05539",
    "title": "BioLCNet: Reward-modulated Locally Connected Spiking Neural Networks",
    "abstract": "Comments: 9 pages, 6 figures",
    "descriptor": "\nComments: 9 pages, 6 figures\n",
    "authors": [
      "Hafez Ghaemi",
      "Erfan Mirzaei",
      "Mahbod Nouri",
      "Saeed Reza Kheradpisheh"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2109.05539"
  },
  {
    "id": "arXiv:2109.05664",
    "title": "Unsupervised domain adaptation for cross-modality liver segmentation via  joint adversarial learning and self-learning",
    "abstract": "Unsupervised domain adaptation for cross-modality liver segmentation via  joint adversarial learning and self-learning",
    "descriptor": "",
    "authors": [
      "Jin Hong",
      "Simon Chun-Ho Yu",
      "Weitian Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2109.05664"
  },
  {
    "id": "arXiv:2109.07082",
    "title": "Efficient and Probabilistic Adaptive Voxel Mapping for Accurate Online  3D SLAM",
    "abstract": "Comments: 8 pages, 10 figures",
    "descriptor": "\nComments: 8 pages, 10 figures\n",
    "authors": [
      "Chongjian Yuan",
      "Wei xu",
      "Xiyuan Liu",
      "Xiaoping Hong",
      "Fu Zhang"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.07082"
  },
  {
    "id": "arXiv:2109.11115",
    "title": "Unet-TTS: Improving Unseen Speaker and Style Transfer in One-shot Voice  Cloning",
    "abstract": "Comments: 6 pages, 5 figures, Accepted to IEEE ICASSP 2022",
    "descriptor": "\nComments: 6 pages, 5 figures, Accepted to IEEE ICASSP 2022\n",
    "authors": [
      "Rui Li",
      "Dong Pu",
      "Minnie Huang",
      "Bill Huang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2109.11115"
  },
  {
    "id": "arXiv:2109.12355",
    "title": "Suboptimal nonlinear model predictive control with input move-blocking",
    "abstract": "Comments: Refined equation (17); Refined Proof of Proposition 7; Added equation (21); Refined inequality in Remark 8; Corrected typos; Added reference [39]",
    "descriptor": "\nComments: Refined equation (17); Refined Proof of Proposition 7; Added equation (21); Refined inequality in Remark 8; Corrected typos; Added reference [39]\n",
    "authors": [
      "Artemi Makarow",
      "Christoph R\u00f6smann",
      "Torsten Bertram"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2109.12355"
  },
  {
    "id": "arXiv:2109.12979",
    "title": "CT-ICP: Real-time Elastic LiDAR Odometry with Loop Closure",
    "abstract": "Comments: 7 pages",
    "descriptor": "\nComments: 7 pages\n",
    "authors": [
      "Pierre Dellenbach",
      "Jean-Emmanuel Deschaud",
      "Bastien Jacquet",
      "Fran\u00e7ois Goulette"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.12979"
  },
  {
    "id": "arXiv:2109.13986",
    "title": "Symbolic Brittleness in Sequence Models: on Systematic Generalization in  Symbolic Mathematics",
    "abstract": "Comments: AAAI 2022",
    "descriptor": "\nComments: AAAI 2022\n",
    "authors": [
      "Sean Welleck",
      "Peter West",
      "Jize Cao",
      "Yejin Choi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.13986"
  },
  {
    "id": "arXiv:2109.14035",
    "title": "Formalizing the Generalization-Forgetting Trade-off in Continual  Learning",
    "abstract": "Formalizing the Generalization-Forgetting Trade-off in Continual  Learning",
    "descriptor": "",
    "authors": [
      "Krishnan Raghavan",
      "Prasanna Balaprakash"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Dynamical Systems (math.DS)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2109.14035"
  },
  {
    "id": "arXiv:2110.01123",
    "title": "Hybrid Event Shaping to Stabilize Periodic Hybrid Orbits",
    "abstract": "Comments: To appear in IEEE ICRA 2022",
    "descriptor": "\nComments: To appear in IEEE ICRA 2022\n",
    "authors": [
      "James Zhu",
      "Nathan J. Kong",
      "George Council",
      "Aaron M. Jonhson"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.01123"
  },
  {
    "id": "arXiv:2110.03460",
    "title": "Finding popular branchings in vertex-weighted digraphs",
    "abstract": "Comments: 17 pages, 3 figures",
    "descriptor": "\nComments: 17 pages, 3 figures\n",
    "authors": [
      "Kei Natsui",
      "Kenjiro Takazawa"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2110.03460"
  },
  {
    "id": "arXiv:2110.05023",
    "title": "Online Graph Learning in Dynamic Environments",
    "abstract": "Online Graph Learning in Dynamic Environments",
    "descriptor": "",
    "authors": [
      "Xiang Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.05023"
  },
  {
    "id": "arXiv:2110.05243",
    "title": "Score-based diffusion models for accelerated MRI",
    "abstract": "Score-based diffusion models for accelerated MRI",
    "descriptor": "",
    "authors": [
      "Hyungjin Chung",
      "Jong Chul Ye"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.05243"
  },
  {
    "id": "arXiv:2110.05809",
    "title": "Couple Learning for semi-supervised sound event detection",
    "abstract": "Comments: Interspeech 2022",
    "descriptor": "\nComments: Interspeech 2022\n",
    "authors": [
      "Rui Tao",
      "Long Yan",
      "Kazushige Ouchi",
      "Xiangdong Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2110.05809"
  },
  {
    "id": "arXiv:2110.07205",
    "title": "SpeechT5: Unified-Modal Encoder-Decoder Pre-Training for Spoken Language  Processing",
    "abstract": "Comments: Accepted by ACL 2022 main conference",
    "descriptor": "\nComments: Accepted by ACL 2022 main conference\n",
    "authors": [
      "Junyi Ao",
      "Rui Wang",
      "Long Zhou",
      "Chengyi Wang",
      "Shuo Ren",
      "Yu Wu",
      "Shujie Liu",
      "Tom Ko",
      "Qing Li",
      "Yu Zhang",
      "Zhihua Wei",
      "Yao Qian",
      "Jinyu Li",
      "Furu Wei"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2110.07205"
  },
  {
    "id": "arXiv:2110.07689",
    "title": "First-Order Modal $\u03be$-Calculus: on Applicative Aspect and Model Theory",
    "abstract": "First-Order Modal $\u03be$-Calculus: on Applicative Aspect and Model Theory",
    "descriptor": "",
    "authors": [
      "Xinyu Wang"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Logic (math.LO)"
    ],
    "url": "https://arxiv.org/abs/2110.07689"
  },
  {
    "id": "arXiv:2110.08126",
    "title": "Learning Multi-agent Action Coordination via Electing First-move Agent",
    "abstract": "Comments: Accepted by ICAPS 2022",
    "descriptor": "\nComments: Accepted by ICAPS 2022\n",
    "authors": [
      "Jingqing Ruan",
      "Linghui Meng",
      "Xuantang Xiong",
      "Dengpeng Xing",
      "Bo Xu"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2110.08126"
  },
  {
    "id": "arXiv:2110.08223",
    "title": "Simultaneous Missing Value Imputation and Structure Learning with Groups",
    "abstract": "Simultaneous Missing Value Imputation and Structure Learning with Groups",
    "descriptor": "",
    "authors": [
      "Pablo Morales-Alvarez",
      "Wenbo Gong",
      "Angus Lamb",
      "Simon Woodhead",
      "Simon Peyton Jones",
      "Nick Pawlowski",
      "Miltiadis Allamanis",
      "Cheng Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.08223"
  },
  {
    "id": "arXiv:2110.08813",
    "title": "VISinger: Variational Inference with Adversarial Learning for End-to-End  Singing Voice Synthesis",
    "abstract": "Comments: 5 pages, ICASSP 2022",
    "descriptor": "\nComments: 5 pages, ICASSP 2022\n",
    "authors": [
      "Yongmao Zhang",
      "Jian Cong",
      "Heyang Xue",
      "Lei Xie",
      "Pengcheng Zhu",
      "Mengxiao Bi"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2110.08813"
  },
  {
    "id": "arXiv:2110.09461",
    "title": "In a Nutshell, the Human Asked for This: Latent Goals for Following  Temporal Specifications",
    "abstract": "In a Nutshell, the Human Asked for This: Latent Goals for Following  Temporal Specifications",
    "descriptor": "",
    "authors": [
      "Borja G. Le\u00f3n",
      "Murray Shanahan",
      "Francesco Belardinelli"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.09461"
  },
  {
    "id": "arXiv:2110.10965",
    "title": "2020 CATARACTS Semantic Segmentation Challenge",
    "abstract": "2020 CATARACTS Semantic Segmentation Challenge",
    "descriptor": "",
    "authors": [
      "Imanol Luengo",
      "Maria Grammatikopoulou",
      "Rahim Mohammadi",
      "Chris Walsh",
      "Chinedu Innocent Nwoye",
      "Deepak Alapatt",
      "Nicolas Padoy",
      "Zhen-Liang Ni",
      "Chen-Chen Fan",
      "Gui-Bin Bian",
      "Zeng-Guang Hou",
      "Heonjin Ha",
      "Jiacheng Wang",
      "Haojie Wang",
      "Dong Guo",
      "Lu Wang",
      "Guotai Wang",
      "Mobarakol Islam",
      "Bharat Giddwani",
      "Ren Hongliang",
      "Theodoros Pissas",
      "Claudio Ravasio",
      "Martin Huber",
      "Jeremy Birch",
      "Joan M.Nunez Do Rio",
      "Lyndon da Cruz",
      "Christos Bergeles",
      "Hongyu Chen",
      "Fucang Jia",
      "Nikhil KumarTomar",
      "Debesh Jha",
      "Michael A. Riegler",
      "Pal Halvorsen",
      "Sophia Bano",
      "Uddhav Vaghela",
      "Jianyuan Hong",
      "Haili Ye",
      "Feihong Huang",
      "Da-Han Wang",
      "Danail Stoyanov"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.10965"
  },
  {
    "id": "arXiv:2110.11819",
    "title": "A Last Switch Dependent Analysis of Satiation and Seasonality in Bandits",
    "abstract": "A Last Switch Dependent Analysis of Satiation and Seasonality in Bandits",
    "descriptor": "",
    "authors": [
      "Pierre Laforgue",
      "Giulia Clerici",
      "Nicol\u00f2 Cesa-Bianchi",
      "Ran Gilad-Bachrach"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.11819"
  },
  {
    "id": "arXiv:2110.11886",
    "title": "Conditionally Gaussian PAC-Bayes",
    "abstract": "Conditionally Gaussian PAC-Bayes",
    "descriptor": "",
    "authors": [
      "Eugenio Clerico",
      "George Deligiannidis",
      "Arnaud Doucet"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.11886"
  },
  {
    "id": "arXiv:2110.13194",
    "title": "Covariance-Generalized Matching Component Analysis for Data Fusion and  Transfer Learning",
    "abstract": "Comments: v2: All scientific content and results unchanged; author formatting changed; acknowledgments added",
    "descriptor": "\nComments: v2: All scientific content and results unchanged; author formatting changed; acknowledgments added\n",
    "authors": [
      "Nick Lorenzo",
      "Sean O'Rourke",
      "Theresa Scarnati"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.13194"
  },
  {
    "id": "arXiv:2110.15828",
    "title": "Resampling Base Distributions of Normalizing Flows",
    "abstract": "Resampling Base Distributions of Normalizing Flows",
    "descriptor": "",
    "authors": [
      "Vincent Stimper",
      "Bernhard Sch\u00f6lkopf",
      "Jos\u00e9 Miguel Hern\u00e1ndez-Lobato"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.15828"
  },
  {
    "id": "arXiv:2111.00705",
    "title": "Communication-Compressed Adaptive Gradient Method for Distributed  Nonconvex Optimization",
    "abstract": "Comments: Accepted by AISTATS 2022 (29 pages, 11 figures, 2 tables)",
    "descriptor": "\nComments: Accepted by AISTATS 2022 (29 pages, 11 figures, 2 tables)\n",
    "authors": [
      "Yujia Wang",
      "Lu Lin",
      "Jinghui Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.00705"
  },
  {
    "id": "arXiv:2111.00734",
    "title": "Robust Deep Learning from Crowds with Belief Propagation",
    "abstract": "Robust Deep Learning from Crowds with Belief Propagation",
    "descriptor": "",
    "authors": [
      "Hoyoung Kim",
      "Seunghyuk Cho",
      "Dongwoo Kim",
      "Jungseul Ok"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.00734"
  },
  {
    "id": "arXiv:2111.01225",
    "title": "Identifying causal relations in tweets using deep learning: Use case on  diabetes-related tweets from 2017-2021",
    "abstract": "Comments: 6 Figures, 4 Tables",
    "descriptor": "\nComments: 6 Figures, 4 Tables\n",
    "authors": [
      "Adrian Ahne",
      "Vivek Khetan",
      "Xavier Tannier",
      "Md Imbessat Hassan Rizvi",
      "Thomas Czernichow",
      "Francisco Orchard",
      "Charline Bour",
      "Andrew Fano",
      "Guy Fagherazzi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.01225"
  },
  {
    "id": "arXiv:2111.01892",
    "title": "Equivariant Deep Dynamical Model for Motion Prediction",
    "abstract": "Equivariant Deep Dynamical Model for Motion Prediction",
    "descriptor": "",
    "authors": [
      "Bahar Azari",
      "Deniz Erdo\u011fmu\u015f"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.01892"
  },
  {
    "id": "arXiv:2111.02887",
    "title": "Self-Supervised Radio-Visual Representation Learning for 6G Sensing",
    "abstract": "Comments: To appear in IEEE ICC '22",
    "descriptor": "\nComments: To appear in IEEE ICC '22\n",
    "authors": [
      "Mohammed Alloulah",
      "Akash Deep Singh",
      "Maximilian Arnold"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.02887"
  },
  {
    "id": "arXiv:2111.04558",
    "title": "Fast and Scalable Spike and Slab Variable Selection in High-Dimensional  Gaussian Processes",
    "abstract": "Comments: Accepted at the 25th International Conference on Artificial Intelligence and Statistics (AISTATS 2022)",
    "descriptor": "\nComments: Accepted at the 25th International Conference on Artificial Intelligence and Statistics (AISTATS 2022)\n",
    "authors": [
      "Hugh Dance",
      "Brooks Paige"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.04558"
  },
  {
    "id": "arXiv:2111.05300",
    "title": "Double Control Variates for Gradient Estimation in Discrete Latent  Variable Models",
    "abstract": "Comments: AISTATS 2022. Source code: this https URL",
    "descriptor": "\nComments: AISTATS 2022. Source code: this https URL\n",
    "authors": [
      "Michalis K. Titsias",
      "Jiaxin Shi"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.05300"
  },
  {
    "id": "arXiv:2111.07443",
    "title": "Unified stability criteria for perturbed LTV systems with unstable  instantaneous dynamics",
    "abstract": "Comments: Submitted to Automatica",
    "descriptor": "\nComments: Submitted to Automatica\n",
    "authors": [
      "Shenyu Liu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2111.07443"
  },
  {
    "id": "arXiv:2111.08102",
    "title": "The Partially Observable History Process",
    "abstract": "Comments: 8 pages, 2 figures",
    "descriptor": "\nComments: 8 pages, 2 figures\n",
    "authors": [
      "Dustin Morrill",
      "Amy R. Greenwald",
      "Michael Bowling"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2111.08102"
  },
  {
    "id": "arXiv:2111.08687",
    "title": "INTERN: A New Learning Paradigm Towards General Vision",
    "abstract": "INTERN: A New Learning Paradigm Towards General Vision",
    "descriptor": "",
    "authors": [
      "Jing Shao",
      "Siyu Chen",
      "Yangguang Li",
      "Kun Wang",
      "Zhenfei Yin",
      "Yinan He",
      "Jianing Teng",
      "Qinghong Sun",
      "Mengya Gao",
      "Jihao Liu",
      "Gengshi Huang",
      "Guanglu Song",
      "Yichao Wu",
      "Yuming Huang",
      "Fenggang Liu",
      "Huan Peng",
      "Shuo Qin",
      "Chengyu Wang",
      "Yujie Wang",
      "Conghui He",
      "Ding Liang",
      "Yu Liu",
      "Fengwei Yu",
      "Junjie Yan",
      "Dahua Lin",
      "Xiaogang Wang",
      "Yu Qiao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.08687"
  },
  {
    "id": "arXiv:2111.09005",
    "title": "A Neural Solver for Variational Problems on CAD Geometries with  Application to Electric Machine Simulation",
    "abstract": "Comments: 27 pages, 9 figures",
    "descriptor": "\nComments: 27 pages, 9 figures\n",
    "authors": [
      "Moritz von Tresckow",
      "Stefan Kurz",
      "Herbert De Gersem",
      "Dimitrios Loukrezis"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2111.09005"
  },
  {
    "id": "arXiv:2111.09151",
    "title": "Barrier Forming: Separating Polygonal Sets with Minimum Number of Lines",
    "abstract": "Comments: Accepted to ICRA 2022",
    "descriptor": "\nComments: Accepted to ICRA 2022\n",
    "authors": [
      "Si Wei Feng",
      "Jingjin Yu"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2111.09151"
  },
  {
    "id": "arXiv:2111.09449",
    "title": "Local Mutual Exclusion for Dynamic, Anonymous, Bounded Memory Message  Passing Systems",
    "abstract": "Comments: 19 pages, 1 figure, 1 table",
    "descriptor": "\nComments: 19 pages, 1 figure, 1 table\n",
    "authors": [
      "Joshua J. Daymude",
      "Andr\u00e9a W. Richa",
      "Christian Scheideler"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2111.09449"
  },
  {
    "id": "arXiv:2111.10574",
    "title": "Switching Independent Vector Analysis and Its Extension to Blind and  Spatially Guided Convolutional Beamforming Algorithms",
    "abstract": "Comments: Submitted to IEEE/ACM Trans. Audio, Speech, and Language Processing on 27 July 2021, accepted on 22 Feb. 2022",
    "descriptor": "\nComments: Submitted to IEEE/ACM Trans. Audio, Speech, and Language Processing on 27 July 2021, accepted on 22 Feb. 2022\n",
    "authors": [
      "Tomohiro Nakatani",
      "Rintaro Ikeshita",
      "Keisuke Kinoshita",
      "Hiroshi Sawada",
      "Naoyuki Kamo",
      "Shoko Araki"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2111.10574"
  },
  {
    "id": "arXiv:2111.11305",
    "title": "Universal Efficient Variable-rate Neural Image Compression",
    "abstract": "Comments: 5 pages, 5 figures; Accepted by ICASSP 2022",
    "descriptor": "\nComments: 5 pages, 5 figures; Accepted by ICASSP 2022\n",
    "authors": [
      "Shanzhi Yin",
      "Chao Li",
      "Youneng Bao",
      "Yongsheng Liang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.11305"
  },
  {
    "id": "arXiv:2111.11397",
    "title": "Lebanon Solar Rooftop Potential Assessment using Buildings Segmentation  from Aerial Images",
    "abstract": "Lebanon Solar Rooftop Potential Assessment using Buildings Segmentation  from Aerial Images",
    "descriptor": "",
    "authors": [
      "Hasan Nasrallah",
      "Abed Ellatif Samhat",
      "Ghaleb Faour",
      "Ali J. Ghandour"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.11397"
  },
  {
    "id": "arXiv:2111.12045",
    "title": "Adaptive Multi-Goal Exploration",
    "abstract": "Comments: AISTATS 2022",
    "descriptor": "\nComments: AISTATS 2022\n",
    "authors": [
      "Jean Tarbouriech",
      "Omar Darwiche Domingues",
      "Pierre M\u00e9nard",
      "Matteo Pirotta",
      "Michal Valko",
      "Alessandro Lazaric"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.12045"
  },
  {
    "id": "arXiv:2112.01521",
    "title": "Object-aware Monocular Depth Prediction with Instance Convolutions",
    "abstract": "Object-aware Monocular Depth Prediction with Instance Convolutions",
    "descriptor": "",
    "authors": [
      "Enis Simsar",
      "Evin P\u0131nar \u00d6rnek",
      "Fabian Manhardt",
      "Helisa Dhamo",
      "Nassir Navab",
      "Federico Tombari"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.01521"
  },
  {
    "id": "arXiv:2112.01914",
    "title": "SGM3D: Stereo Guided Monocular 3D Object Detection",
    "abstract": "Comments: 8 pages, 5 figures",
    "descriptor": "\nComments: 8 pages, 5 figures\n",
    "authors": [
      "Zheyuan Zhou",
      "Liang Du",
      "Xiaoqing Ye",
      "Zhikang Zou",
      "Xiao Tan",
      "Li Zhang",
      "Xiangyang Xue",
      "Jianfeng Feng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.01914"
  },
  {
    "id": "arXiv:2112.06127",
    "title": "Real-world challenges for multi-agent reinforcement learning in  grid-interactive buildings",
    "abstract": "Comments: under review",
    "descriptor": "\nComments: under review\n",
    "authors": [
      "Kingsley Nweye",
      "Bo Liu",
      "Peter Stone",
      "Zoltan Nagy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.06127"
  },
  {
    "id": "arXiv:2112.06749",
    "title": "Step-unrolled Denoising Autoencoders for Text Generation",
    "abstract": "Comments: Accepted to ICLR 2022",
    "descriptor": "\nComments: Accepted to ICLR 2022\n",
    "authors": [
      "Nikolay Savinov",
      "Junyoung Chung",
      "Mikolaj Binkowski",
      "Erich Elsen",
      "Aaron van den Oord"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.06749"
  },
  {
    "id": "arXiv:2112.09988",
    "title": "Smooth Model Predictive Path Integral Control without Smoothing",
    "abstract": "Comments: Our video can be found at this https URL",
    "descriptor": "\nComments: Our video can be found at this https URL\n",
    "authors": [
      "Taekyung Kim",
      "Gyuhyun Park",
      "Jihwan Bae",
      "Wonsuk Lee"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2112.09988"
  },
  {
    "id": "arXiv:2112.10614",
    "title": "Omni-Roach: A legged robot capable of traversing multiple types of large  obstacles and self-righting",
    "abstract": "Omni-Roach: A legged robot capable of traversing multiple types of large  obstacles and self-righting",
    "descriptor": "",
    "authors": [
      "Jonathan Mi",
      "Yaqing Wang",
      "Chen Li"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2112.10614"
  },
  {
    "id": "arXiv:2112.11622",
    "title": "An Alternate Policy Gradient Estimator for Softmax Policies",
    "abstract": "Comments: Accepted to AISTATS 2022. 60 pages, 50 figures. This updated version has an additional experiment and minor corrections",
    "descriptor": "\nComments: Accepted to AISTATS 2022. 60 pages, 50 figures. This updated version has an additional experiment and minor corrections\n",
    "authors": [
      "Shivam Garg",
      "Samuele Tosatto",
      "Yangchen Pan",
      "Martha White",
      "A. Rupam Mahmood"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.11622"
  },
  {
    "id": "arXiv:2112.13112",
    "title": "A Survey on Interpretable Reinforcement Learning",
    "abstract": "A Survey on Interpretable Reinforcement Learning",
    "descriptor": "",
    "authors": [
      "Claire Glanois",
      "Paul Weng",
      "Matthieu Zimmer",
      "Dong Li",
      "Tianpei Yang",
      "Jianye Hao",
      "Wulong Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.13112"
  },
  {
    "id": "arXiv:2112.15383",
    "title": "Separation of Scales and a Thermodynamic Description of Feature Learning  in Some CNNs",
    "abstract": "Separation of Scales and a Thermodynamic Description of Feature Learning  in Some CNNs",
    "descriptor": "",
    "authors": [
      "Inbar Seroussi",
      "Gadi Naveh",
      "Zohar Ringel"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ],
    "url": "https://arxiv.org/abs/2112.15383"
  },
  {
    "id": "arXiv:2201.00707",
    "title": "Data Driven Safe Gain-Scheduling Control",
    "abstract": "Data Driven Safe Gain-Scheduling Control",
    "descriptor": "",
    "authors": [
      "Amir Modares",
      "Nasser Sadati",
      "Hamidreza Modares"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2201.00707"
  },
  {
    "id": "arXiv:2201.01163",
    "title": "Analyzing Micro-Founded General Equilibrium Models with Many Agents  using Deep Reinforcement Learning",
    "abstract": "Analyzing Micro-Founded General Equilibrium Models with Many Agents  using Deep Reinforcement Learning",
    "descriptor": "",
    "authors": [
      "Michael Curry",
      "Alexander Trott",
      "Soham Phade",
      "Yu Bai",
      "Stephan Zheng"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "General Economics (econ.GN)"
    ],
    "url": "https://arxiv.org/abs/2201.01163"
  },
  {
    "id": "arXiv:2201.02707",
    "title": "ALPHA: Audit that Learns from Previously Hand-Audited Ballots",
    "abstract": "ALPHA: Audit that Learns from Previously Hand-Audited Ballots",
    "descriptor": "",
    "authors": [
      "Philip B. Stark"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Cryptography and Security (cs.CR)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2201.02707"
  },
  {
    "id": "arXiv:2201.05756",
    "title": "Block Policy Mirror Descent",
    "abstract": "Block Policy Mirror Descent",
    "descriptor": "",
    "authors": [
      "Guanghui Lan",
      "Yan Li",
      "Tuo Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2201.05756"
  },
  {
    "id": "arXiv:2201.06064",
    "title": "Neighborhood Region Smoothing Regularization for Finding Flat Minima In  Deep Neural Networks",
    "abstract": "Neighborhood Region Smoothing Regularization for Finding Flat Minima In  Deep Neural Networks",
    "descriptor": "",
    "authors": [
      "Yang Zhao",
      "Hao Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2201.06064"
  },
  {
    "id": "arXiv:2201.07006",
    "title": "Time Series Generation with Masked Autoencoder",
    "abstract": "Time Series Generation with Masked Autoencoder",
    "descriptor": "",
    "authors": [
      "Mengyue Zha",
      "SiuTim Wong",
      "Mengqi Liu",
      "Tong Zhang",
      "Kani Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.07006"
  },
  {
    "id": "arXiv:2201.07119",
    "title": "A Survey on Code-Based Cryptography",
    "abstract": "Comments: This book chapter is considered to be part of the Springer Lecture Notes in Mathematics: Coding Theory and Applications V, Applications of Coding Theory in Quantum Computing and Cryptography",
    "descriptor": "\nComments: This book chapter is considered to be part of the Springer Lecture Notes in Mathematics: Coding Theory and Applications V, Applications of Coding Theory in Quantum Computing and Cryptography\n",
    "authors": [
      "Violetta Weger",
      "Niklas Gassner",
      "Joachim Rosenthal"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2201.07119"
  },
  {
    "id": "arXiv:2201.07798",
    "title": "Cognitive Explainers of Graph Neural Networks Based on Medical Concepts",
    "abstract": "Comments: 9 pages, 8 figures",
    "descriptor": "\nComments: 9 pages, 8 figures\n",
    "authors": [
      "Yingni Wang",
      "Huabin Zhang",
      "Lichong Dong",
      "Xiaobo Zhou",
      "Kehong Yuan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2201.07798"
  },
  {
    "id": "arXiv:2201.08894",
    "title": "Reinforcement Learning for Personalized Drug Discovery and Design for  Complex Diseases: A Systems Pharmacology Perspective",
    "abstract": "Comments: 26 pages, 3 figure",
    "descriptor": "\nComments: 26 pages, 3 figure\n",
    "authors": [
      "Ryan K. Tan",
      "Yang Liu",
      "Lei Xie"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.08894"
  },
  {
    "id": "arXiv:2201.09414",
    "title": "Generalized Spatially-Coupled Parallel Concatenated Codes With Partial  Repetition",
    "abstract": "Comments: Revised version, 36 pages, 10 figures, 4 tables. arXiv admin note: text overlap with arXiv:2105.00698",
    "descriptor": "\nComments: Revised version, 36 pages, 10 figures, 4 tables. arXiv admin note: text overlap with arXiv:2105.00698\n",
    "authors": [
      "Min Qiu",
      "Xiaowei Wu",
      "Jinhong Yuan",
      "Alexandre Graell i Amat"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2201.09414"
  },
  {
    "id": "arXiv:2201.09644",
    "title": "Multiscale Generative Models: Improving Performance of a Generative  Model Using Feedback from Other Dependent Generative Models",
    "abstract": "Multiscale Generative Models: Improving Performance of a Generative  Model Using Feedback from Other Dependent Generative Models",
    "descriptor": "",
    "authors": [
      "Changyu Chen",
      "Avinandan Bose",
      "Shih-Fen Cheng",
      "Arunesh Sinha"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2201.09644"
  },
  {
    "id": "arXiv:2201.10502",
    "title": "Positivity-Preserving Entropy-Based Adaptive Filtering for Discontinuous  Spectral Element Methods",
    "abstract": "Comments: 19 pages, 10 figures",
    "descriptor": "\nComments: 19 pages, 10 figures\n",
    "authors": [
      "Tarik Dzanic",
      "Freddie D. Witherden"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2201.10502"
  },
  {
    "id": "arXiv:2201.10574",
    "title": "Basic Quantum Algorithms",
    "abstract": "Comments: 106 pages",
    "descriptor": "\nComments: 106 pages\n",
    "authors": [
      "Renato Portugal"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2201.10574"
  },
  {
    "id": "arXiv:2201.13256",
    "title": "Proximal denoiser for convergent plug-and-play optimization with  nonconvex regularization",
    "abstract": "Comments: 21 pages. arXiv admin note: text overlap with arXiv:2110.03220",
    "descriptor": "\nComments: 21 pages. arXiv admin note: text overlap with arXiv:2110.03220\n",
    "authors": [
      "Samuel Hurault",
      "Arthur Leclaire",
      "Nicolas Papadakis"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.13256"
  },
  {
    "id": "arXiv:2202.00232",
    "title": "ISNet: Costless and Implicit Image Segmentation for Deep Classifiers,  with Application in COVID-19 Detection",
    "abstract": "Comments: Text revised",
    "descriptor": "\nComments: Text revised\n",
    "authors": [
      "Pedro R.A.S. Bassi",
      "Andrea Cavalli"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.00232"
  },
  {
    "id": "arXiv:2202.01614",
    "title": "The RoyalFlush System of Speech Recognition for M2MeT Challenge",
    "abstract": "The RoyalFlush System of Speech Recognition for M2MeT Challenge",
    "descriptor": "",
    "authors": [
      "Shuaishuai Ye",
      "Peiyao Wang",
      "Shunfei Chen",
      "Xinhui Hu",
      "Xinkang Xu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.01614"
  },
  {
    "id": "arXiv:2202.02404",
    "title": "Model-Free Reinforcement Learning for Symbolic Automata-encoded  Objectives",
    "abstract": "Model-Free Reinforcement Learning for Symbolic Automata-encoded  Objectives",
    "descriptor": "",
    "authors": [
      "Anand Balakrishnan",
      "Stefan Jak\u0161i\u0107",
      "Edgar A. Aguilar",
      "Dejan Ni\u010dkovi\u0107",
      "Jyotirmoy V. Deshmukh"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.02404"
  },
  {
    "id": "arXiv:2202.03712",
    "title": "Fourier Representations for Black-Box Optimization over Categorical  Variables",
    "abstract": "Fourier Representations for Black-Box Optimization over Categorical  Variables",
    "descriptor": "",
    "authors": [
      "Hamid Dadkhahi",
      "Jesus Rios",
      "Karthikeyan Shanmugam",
      "Payel Das"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.03712"
  },
  {
    "id": "arXiv:2202.04595",
    "title": "Exploring Structural Sparsity in Neural Image Compression",
    "abstract": "Comments: 5 pages, 5 figures, submitted to ICIP 2022",
    "descriptor": "\nComments: 5 pages, 5 figures, submitted to ICIP 2022\n",
    "authors": [
      "Shanzhi Yin",
      "Chao Li",
      "Wen Tan",
      "Youneng Bao",
      "Yongsheng Liang",
      "Wei Liu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.04595"
  },
  {
    "id": "arXiv:2202.04744",
    "title": "Robust Bayesian Inference for Simulator-based Models via the MMD  Posterior Bootstrap",
    "abstract": "Comments: Accepted for publication (with an oral presentation) at AISTATS 2022. A preliminary version of this paper was accepted in the NeurIPS 2021 workshop \"Your Model is Wrong: Robustness and misspecification in probabilistic modeling\". v2: added some references",
    "descriptor": "\nComments: Accepted for publication (with an oral presentation) at AISTATS 2022. A preliminary version of this paper was accepted in the NeurIPS 2021 workshop \"Your Model is Wrong: Robustness and misspecification in probabilistic modeling\". v2: added some references\n",
    "authors": [
      "Charita Dellaporta",
      "Jeremias Knoblauch",
      "Theodoros Damoulas",
      "Fran\u00e7ois-Xavier Briol"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.04744"
  },
  {
    "id": "arXiv:2202.04828",
    "title": "Learning Latent Causal Dynamics",
    "abstract": "Learning Latent Causal Dynamics",
    "descriptor": "",
    "authors": [
      "Weiran Yao",
      "Guangyi Chen",
      "Kun Zhang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.04828"
  },
  {
    "id": "arXiv:2202.05139",
    "title": "Game of Privacy: Towards Better Federated Platform Collaboration under  Privacy Restriction",
    "abstract": "Comments: Submitted to KDD 2022",
    "descriptor": "\nComments: Submitted to KDD 2022\n",
    "authors": [
      "Chuhan Wu",
      "Fangzhao Wu",
      "Tao Qi",
      "Yanlin Wang",
      "Yuqing Yang",
      "Yongfeng Huang",
      "Xing Xie"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.05139"
  },
  {
    "id": "arXiv:2202.05338",
    "title": "Accountability in an Algorithmic Society: Relationality, Responsibility,  and Robustness in Machine Learning",
    "abstract": "Comments: Preprint",
    "descriptor": "\nComments: Preprint\n",
    "authors": [
      "A. Feder Cooper",
      "Benjamin Laufer",
      "Emanuel Moss",
      "Helen Nissenbaum"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.05338"
  },
  {
    "id": "arXiv:2202.05917",
    "title": "Group-based Cryptography in the Quantum Era",
    "abstract": "Comments: This paper has been accepted by the Notices of the American Mathematical Society",
    "descriptor": "\nComments: This paper has been accepted by the Notices of the American Mathematical Society\n",
    "authors": [
      "Delaram Kahrobaei",
      "Ram\u00f3n Flores",
      "Marialaura Noce"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Group Theory (math.GR)"
    ],
    "url": "https://arxiv.org/abs/2202.05917"
  },
  {
    "id": "arXiv:2202.05933",
    "title": "Increasing FPGA Accelerators Memory Bandwidth with a Burst-Friendly  Memory Layout",
    "abstract": "Comments: 16 pages; 17 figures",
    "descriptor": "\nComments: 16 pages; 17 figures\n",
    "authors": [
      "Corentin Ferry",
      "Tomofumi Yuki",
      "Steven Derrien",
      "Sanjay Rajopadhye"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2202.05933"
  },
  {
    "id": "arXiv:2202.06819",
    "title": "Learning from distinctive candidates to optimize reduced-precision  convolution program on tensor cores",
    "abstract": "Comments: 10 pages, 16 figures, preliminary work",
    "descriptor": "\nComments: 10 pages, 16 figures, preliminary work\n",
    "authors": [
      "Junkyeong Choi",
      "Hyucksung Kwon",
      "Woongkyu Lee",
      "Jungwook Choi",
      "Jieun Lim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.06819"
  },
  {
    "id": "arXiv:2202.07646",
    "title": "Quantifying Memorization Across Neural Language Models",
    "abstract": "Quantifying Memorization Across Neural Language Models",
    "descriptor": "",
    "authors": [
      "Nicholas Carlini",
      "Daphne Ippolito",
      "Matthew Jagielski",
      "Katherine Lee",
      "Florian Tramer",
      "Chiyuan Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.07646"
  },
  {
    "id": "arXiv:2202.08548",
    "title": "The Political Economy of Privacy Enhancing Technologies",
    "abstract": "Comments: 16 Pages, 1 Figure",
    "descriptor": "\nComments: 16 Pages, 1 Figure\n",
    "authors": [
      "Partha Das Chowdhury",
      "Andres Dominguez",
      "Kopo M. Ramkapane",
      "Awais Rashid"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2202.08548"
  },
  {
    "id": "arXiv:2202.08994",
    "title": "REFUGE2 Challenge: Treasure for Multi-Domain Learning in Glaucoma  Assessment",
    "abstract": "Comments: 28 pages, 20 figures",
    "descriptor": "\nComments: 28 pages, 20 figures\n",
    "authors": [
      "Huihui Fang",
      "Fei Li",
      "Huazhu Fu",
      "Xu Sun",
      "Xingxing Cao",
      "Jaemin Son",
      "Shuang Yu",
      "Menglu Zhang",
      "Chenglang Yuan",
      "Cheng Bian",
      "Baiying Lei",
      "Benjian Zhao",
      "Xinxing Xu",
      "Shaohua Li",
      "Francisco Fumero",
      "Jose Sigut",
      "Haidar Almubarak",
      "Yakoub Bazi",
      "Yuanhao Guo",
      "Yating Zhou",
      "Ujjwal Baid",
      "Shubham Innani",
      "Tianjiao Guo",
      "Jie Yang",
      "Jos\u00e9 Ignacio Orlando",
      "Hrvoje Bogunovi\u0107",
      "Xiulan Zhang",
      "Yanwu Xu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.08994"
  },
  {
    "id": "arXiv:2202.09400",
    "title": "Equivariant Transporter Network",
    "abstract": "Equivariant Transporter Network",
    "descriptor": "",
    "authors": [
      "Haojie Huang",
      "Dian Wang",
      "Robin Walter",
      "Robert Platt"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.09400"
  },
  {
    "id": "arXiv:2202.09464",
    "title": "Geometric Algebra based Embeddings for Static and Temporal Knowledge  Graph Completion",
    "abstract": "Comments: Accepted by IEEE Transactions on Knowledge and Data Engineering",
    "descriptor": "\nComments: Accepted by IEEE Transactions on Knowledge and Data Engineering\n",
    "authors": [
      "Chengjin Xu",
      "Mojtaba Nayyeri",
      "Yung-Yu Chen",
      "Jens Lehmann"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.09464"
  },
  {
    "id": "arXiv:2202.09662",
    "title": "Reward Modeling for Mitigating Toxicity in Transformer-based Language  Models",
    "abstract": "Reward Modeling for Mitigating Toxicity in Transformer-based Language  Models",
    "descriptor": "",
    "authors": [
      "Farshid Faal",
      "Ketra Schmitt"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.09662"
  },
  {
    "id": "arXiv:2202.09885",
    "title": "On Optimal Early Stopping: Over-informative versus Under-informative  Parametrization",
    "abstract": "Comments: 30 pages, 15 figures",
    "descriptor": "\nComments: 30 pages, 15 figures\n",
    "authors": [
      "Ruoqi Shen",
      "Liyao Gao",
      "Yi-An Ma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.09885"
  },
  {
    "id": "arXiv:2202.09953",
    "title": "LiDAR-guided Stereo Matching with a Spatial Consistency Constraint",
    "abstract": "Comments: we replace an article because of the addition of journal reference, DOI, and report number information",
    "descriptor": "\nComments: we replace an article because of the addition of journal reference, DOI, and report number information\n",
    "authors": [
      "Yongjun Zhang",
      "Siyuan Zou",
      "Xinyi Liu",
      "Xu Huang",
      "Yi Wan",
      "Yongxiang Yao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2202.09953"
  },
  {
    "id": "arXiv:2202.10163",
    "title": "DeepShovel: An Online Collaborative Platform for Data Extraction in  Geoscience Literature with AI Assistance",
    "abstract": "Comments: 26 pages, 16 figures, 5 tables, manuscript submitted to CSCW2022",
    "descriptor": "\nComments: 26 pages, 16 figures, 5 tables, manuscript submitted to CSCW2022\n",
    "authors": [
      "Shao Zhang",
      "Yuting Jia",
      "Hui Xu",
      "Ying Wen",
      "Dakuo Wang",
      "Xinbing Wang"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.10163"
  },
  {
    "id": "arXiv:2202.10517",
    "title": "Personalized PATE: Differential Privacy for Machine Learning with  Individual Privacy Guarantees",
    "abstract": "Personalized PATE: Differential Privacy for Machine Learning with  Individual Privacy Guarantees",
    "descriptor": "",
    "authors": [
      "Christopher M\u00fchl",
      "Franziska Boenisch"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.10517"
  },
  {
    "id": "arXiv:2202.10667",
    "title": "Visually Grounded Task and Motion Planning for Mobile Manipulation",
    "abstract": "Comments: To be published in IEEE International Conference on Robotics and Automation (ICRA), May 23-27, 2022",
    "descriptor": "\nComments: To be published in IEEE International Conference on Robotics and Automation (ICRA), May 23-27, 2022\n",
    "authors": [
      "Xiaohan Zhang",
      "Yifeng Zhu",
      "Yan Ding",
      "Yuke Zhu",
      "Peter Stone",
      "Shiqi Zhang"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.10667"
  },
  {
    "id": "arXiv:2202.10752",
    "title": "Event-Triggered Tracking Control of Networked Multi-Agent Systems",
    "abstract": "Comments: 16 pages, 8 figures, 1 table, Conditionally accepted in the IEEE Transactions on Automatic Control. arXiv admin note: substantial text overlap with arXiv:2110.09786",
    "descriptor": "\nComments: 16 pages, 8 figures, 1 table, Conditionally accepted in the IEEE Transactions on Automatic Control. arXiv admin note: substantial text overlap with arXiv:2110.09786\n",
    "authors": [
      "Wei Ren",
      "Dimos V. Dimarogonas"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2202.10752"
  },
  {
    "id": "arXiv:2202.10873",
    "title": "Ligandformer: A Graph Neural Network for Predicting Compound Property  with Robust Interpretation",
    "abstract": "Comments: 7 pages, 4 figures",
    "descriptor": "\nComments: 7 pages, 4 figures\n",
    "authors": [
      "Jinjiang Guo",
      "Qi Liu",
      "Han Guo",
      "Xi Lu"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.10873"
  },
  {
    "id": "arXiv:2202.11076",
    "title": "Topological Universality of the Art Gallery Problem",
    "abstract": "Topological Universality of the Art Gallery Problem",
    "descriptor": "",
    "authors": [
      "Jack Stade",
      "Jamie Tucker-Foltz"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2202.11076"
  },
  {
    "id": "arXiv:2202.11204",
    "title": "Study of Feature Importance for Quantum Machine Learning Models",
    "abstract": "Comments: 21 pages, 15 figures, 1 Table",
    "descriptor": "\nComments: 21 pages, 15 figures, 1 Table\n",
    "authors": [
      "Aaron Baughman",
      "Kavitha Yogaraj",
      "Raja Hebbar",
      "Sudeep Ghosh",
      "Rukhsan Ul Haq",
      "Yoshika Chhabra"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.11204"
  },
  {
    "id": "arXiv:2202.11384",
    "title": "Multi-Teacher Knowledge Distillation for Incremental Implicitly-Refined  Classification",
    "abstract": "Multi-Teacher Knowledge Distillation for Incremental Implicitly-Refined  Classification",
    "descriptor": "",
    "authors": [
      "Longhui Yu",
      "Zhenyu Weng",
      "Yuqing Wang",
      "Yuesheng Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.11384"
  },
  {
    "id": "arXiv:2202.11409",
    "title": "ScrawlD: A Dataset of Real World Ethereum Smart Contracts Labelled with  Vulnerabilities",
    "abstract": "Comments: 5 pages, 2 figures, submitted to Data and Tool Showcase Track MSR 2022 (this https URL)",
    "descriptor": "\nComments: 5 pages, 2 figures, submitted to Data and Tool Showcase Track MSR 2022 (this https URL)\n",
    "authors": [
      "Chavhan Sujeet Yashavant",
      "Saurabh Kumar",
      "Amey Karkare"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.11409"
  },
  {
    "id": "arXiv:2202.11483",
    "title": "High-precision Hardware Oscillators Ensemble for GNSS Attack Detection",
    "abstract": "High-precision Hardware Oscillators Ensemble for GNSS Attack Detection",
    "descriptor": "",
    "authors": [
      "M. Spanghero",
      "P. Papadimitratos"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.11483"
  },
  {
    "id": "arXiv:2202.11604",
    "title": "The Segment Number: Algorithms and Universal Lower Bounds for Some  Classes of Planar Graphs",
    "abstract": "The Segment Number: Algorithms and Universal Lower Bounds for Some  Classes of Planar Graphs",
    "descriptor": "",
    "authors": [
      "Ina Goe\u00dfmann",
      "Jonathan Klawitter",
      "Boris Klemz",
      "Felix Klesen",
      "Stephen Kobourov",
      "Myroslav Kryven",
      "Alexander Wolff",
      "Johannes Zink"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2202.11604"
  },
  {
    "id": "arXiv:2202.11694",
    "title": "An information-theoretic proof of the Erd\u0151s-Kac theorem",
    "abstract": "Comments: 4 pages",
    "descriptor": "\nComments: 4 pages\n",
    "authors": [
      "Aidan Rocke"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.11694"
  }
]
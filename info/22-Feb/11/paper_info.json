[
  {
    "id": "arXiv:2202.04643",
    "title": "Dimensionally Consistent Learning with Buckingham Pi",
    "abstract": "In the absence of governing equations, dimensional analysis is a robust\ntechnique for extracting insights and finding symmetries in physical systems.\nGiven measurement variables and parameters, the Buckingham Pi theorem provides\na procedure for finding a set of dimensionless groups that spans the solution\nspace, although this set is not unique. We propose an automated approach using\nthe symmetric and self-similar structure of available measurement data to\ndiscover the dimensionless groups that best collapse this data to a lower\ndimensional space according to an optimal fit. We develop three data-driven\ntechniques that use the Buckingham Pi theorem as a constraint: (i) a\nconstrained optimization problem with a non-parametric input-output fitting\nfunction, (ii) a deep learning algorithm (BuckiNet) that projects the input\nparameter space to a lower dimension in the first layer, and (iii) a technique\nbased on sparse identification of nonlinear dynamics (SINDy) to discover\ndimensionless equations whose coefficients parameterize the dynamics. We\nexplore the accuracy, robustness and computational complexity of these methods\nas applied to three example problems: a bead on a rotating hoop, a laminar\nboundary layer, and Rayleigh-B\\'enard convection.",
    "descriptor": "",
    "authors": [
      "Joseph Bakarji",
      "Jared Callaham",
      "Steven L. Brunton",
      "J. Nathan Kutz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2202.04643"
  },
  {
    "id": "arXiv:2202.04648",
    "title": "A survey of unsupervised learning methods for high-dimensional  uncertainty quantification in black-box-type problems",
    "abstract": "Constructing surrogate models for uncertainty quantification (UQ) on complex\npartial differential equations (PDEs) having inherently high-dimensional\n$\\mathcal{O}(10^{\\ge 2})$ stochastic inputs (e.g., forcing terms, boundary\nconditions, initial conditions) poses tremendous challenges. The curse of\ndimensionality can be addressed with suitable unsupervised learning techniques\nused as a pre-processing tool to encode inputs onto lower-dimensional subspaces\nwhile retaining its structural information and meaningful properties. In this\nwork, we review and investigate thirteen dimension reduction methods including\nlinear and nonlinear, spectral, blind source separation, convex and non-convex\nmethods and utilize the resulting embeddings to construct a mapping to\nquantities of interest via polynomial chaos expansions (PCE). We refer to the\ngeneral proposed approach as manifold PCE (m-PCE), where manifold corresponds\nto the latent space resulting from any of the studied dimension reduction\nmethods. To investigate the capabilities and limitations of these methods we\nconduct numerical tests for three physics-based systems (treated as\nblack-boxes) having high-dimensional stochastic inputs of varying complexity\nmodeled as both Gaussian and non-Gaussian random fields to investigate the\neffect of the intrinsic dimensionality of input data. We demonstrate both the\nadvantages and limitations of the unsupervised learning methods and we conclude\nthat a suitable m-PCE model provides a cost-effective approach compared to\nalternative algorithms proposed in the literature, including recently proposed\nexpensive deep neural network-based surrogates and can be readily applied for\nhigh-dimensional UQ in stochastic PDEs.",
    "descriptor": "\nComments: 42 pages, 14 figures\n",
    "authors": [
      "Katiana Kontolati",
      "Dimitrios Loukrezis",
      "Dimitrios D. Giovanis",
      "Lohit Vandanapu",
      "Michael D. Shields"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.04648"
  },
  {
    "id": "arXiv:2202.04670",
    "title": "Can Humans Do Less-Than-One-Shot Learning?",
    "abstract": "Being able to learn from small amounts of data is a key characteristic of\nhuman intelligence, but exactly {\\em how} small? In this paper, we introduce a\nnovel experimental paradigm that allows us to examine classification in an\nextremely data-scarce setting, asking whether humans can learn more categories\nthan they have exemplars (i.e., can humans do \"less-than-one shot\" learning?).\nAn experiment conducted using this paradigm reveals that people are capable of\nlearning in such settings, and provides several insights into underlying\nmechanisms. First, people can accurately infer and represent high-dimensional\nfeature spaces from very little data. Second, having inferred the relevant\nspaces, people use a form of prototype-based categorization (as opposed to\nexemplar-based) to make categorical inferences. Finally, systematic,\nmachine-learnable patterns in responses indicate that people may have efficient\ninductive biases for dealing with this class of data-scarce problems.",
    "descriptor": "\nComments: 7 pages, 7 figures\n",
    "authors": [
      "Maya Malaviya",
      "Ilia Sucholutsky",
      "Kerem Oktar",
      "Thomas L. Griffiths"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.04670"
  },
  {
    "id": "arXiv:2202.04675",
    "title": "Bayesian Nonparametrics for Offline Skill Discovery",
    "abstract": "Skills or low-level policies in reinforcement learning are temporally\nextended actions that can speed up learning and enable complex behaviours.\nRecent work in offline reinforcement learning and imitation learning has\nproposed several techniques for skill discovery from a set of expert\ntrajectories. While these methods are promising, the number K of skills to\ndiscover is always a fixed hyperparameter, which requires either prior\nknowledge about the environment or an additional parameter search to tune it.\nWe first propose a method for offline learning of options (a particular skill\nframework) exploiting advances in variational inference and continuous\nrelaxations. We then highlight an unexplored connection between Bayesian\nnonparametrics and offline skill discovery, and show how to obtain a\nnonparametric version of our model. This version is tractable thanks to a\ncarefully structured approximate posterior with a dynamically-changing number\nof options, removing the need to specify K. We also show how our nonparametric\nextension can be applied in other skill frameworks, and empirically demonstrate\nthat our method can outperform state-of-the-art offline skill learning\nalgorithms across a variety of environments. Our code is available at\nhttps://github.com/layer6ai-labs/BNPO .",
    "descriptor": "",
    "authors": [
      "Valentin Villecroze",
      "Harry J. Braviner",
      "Panteha Naderian",
      "Chris J. Maddison",
      "Gabriel Loaiza-Ganem"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.04675"
  },
  {
    "id": "arXiv:2202.04678",
    "title": "Non-Linear Spectral Dimensionality Reduction Under Uncertainty",
    "abstract": "In this paper, we consider the problem of non-linear dimensionality reduction\nunder uncertainty, both from a theoretical and algorithmic perspectives. Since\nreal-world data usually contain measurements with uncertainties and artifacts,\nthe input space in the proposed framework consists of probability distributions\nto model the uncertainties associated with each sample. We propose a new\ndimensionality reduction framework, called NGEU, which leverages uncertainty\ninformation and directly extends several traditional approaches, e.g., KPCA,\nMDA/KMFA, to receive as inputs the probability distributions instead of the\noriginal data. We show that the proposed NGEU formulation exhibits a global\nclosed-form solution, and we analyze, based on the Rademacher complexity, how\nthe underlying uncertainties theoretically affect the generalization ability of\nthe framework. Empirical results on different datasets show the effectiveness\nof the proposed framework.",
    "descriptor": "\nComments: 10 pages, 3 figures\n",
    "authors": [
      "Firas Laakom",
      "Jenni Raitoharju",
      "Nikolaos Passalis",
      "Alexandros Iosifidis",
      "Moncef Gabbouj"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Spectral Theory (math.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.04678"
  },
  {
    "id": "arXiv:2202.04679",
    "title": "A degenerating convection-diffusion system modelling froth flotation  with drainage",
    "abstract": "Froth flotation is a common unit operation used in mineral processing. It\nserves to separate valuable mineral particles from worthless gangue particles\nin finely ground ores. The valuable mineral particles are hydrophobic and\nattach to bubbles of air injected into the pulp. This creates bubble-particle\naggregates that rise to the top of the flotation column where they accumulate\nto a froth or foam layer that is removed through a launder for further\nprocessing. At the same time, the hydrophilic gangue particles settle and are\nremoved continuously. The drainage of liquid due to capillarity is essential\nfor the formation of a stable froth layer. This effect is included into a\npreviously formulated hyperbolic system of partial differential equations that\nmodels the volume fractions of floating aggregates and settling hydrophilic\nsolids [R. B\\\"{u}rger, S. Diehl and M.C. Mart\\'i, {\\it IMA J. Appl. Math.} {\\bf\n84} (2019) 930--973]. The construction of desired steady-state solutions with a\nfroth layer is detailed and feasibility conditions on the feed volume fractions\nand the volumetric flows of feed, underflow and wash water are visualized in\nso-called operating charts. A monotone numerical scheme is derived and employed\nto simulate the dynamic behaviour of a flotation column. It is also proven\nthat, under a suitable Courant-Friedrichs-Lewy (CFL) condition, the approximate\nvolume fractions are bounded between zero and one when the initial data are.",
    "descriptor": "",
    "authors": [
      "Raimund B\u00fcrger",
      "Stefan Diehl",
      "M. Carmen Mart\u00ed",
      "Yolanda V\u00e1squez"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2202.04679"
  },
  {
    "id": "arXiv:2202.04680",
    "title": "A Joint Variational Multichannel Multiphase Segmentation Framework",
    "abstract": "In this paper, we propose a variational image segmentation framework for\nmultichannel multiphase image segmentation based on the Chan-Vese active\ncontour model. The core of our method lies in finding a variable u encoding the\nsegmentation, by minimizing a multichannel energy functional that combines the\ninformation of multiple images. We create a decomposition of the input, either\nby multichannel filtering, or simply by using plain natural RGB, or medical\nimages, which already consist of several channels. Subsequently we minimize the\nproposed functional for each of the channels simultaneously. Our model meets\nthe necessary assumptions such that it can be solved efficiently by\noptimization techniques like the Chambolle-Pock method. We prove that the\nproposed energy functional has global minimizers, and show its stability and\nconvergence with respect to noisy inputs. Experimental results show that the\nproposed method performs well in single- and multichannel segmentation tasks,\nand can be employed to the segmentation of various types of images, such as\nnatural and texture images as well as medical images.",
    "descriptor": "",
    "authors": [
      "Nadja Gruber",
      "Johannes Schwab",
      "Sebastien Court",
      "Elke Gizewski",
      "Markus Haltmeier"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Functional Analysis (math.FA)"
    ],
    "url": "https://arxiv.org/abs/2202.04680"
  },
  {
    "id": "arXiv:2202.04682",
    "title": "\"I feel invaded, annoyed, anxious and I may protect myself\":  Individuals' Feelings about Online Tracking and their Protective Behaviour  across Gender and Country",
    "abstract": "Online tracking is a primary concern for Internet users, yet previous\nresearch has not found a clear link between the cognitive understanding of\ntracking and protective actions. We postulate that protective behaviour follows\naffective evaluation of tracking. We conducted an online study, with N=614\nparticipants, across the UK, Germany and France, to investigate how users feel\nabout third-party tracking and what protective actions they take. We found that\nmost participants' feelings about tracking were negative, described as deeply\nintrusive - beyond the informational sphere, including feelings of annoyance\nand anxiety, that predict protective actions. We also observed indications of a\n`privacy gender gap', where women feel more negatively about tracking, yet are\nless likely to take protective actions, compared to men. And less UK\nindividuals report negative feelings and protective actions, compared to those\nfrom Germany and France. This paper contributes insights into the affective\nevaluation of privacy threats and how it predicts protective behaviour. It also\nprovides a discussion on the implications of these findings for various\nstakeholders, make recommendations and outline avenues for future work.",
    "descriptor": "",
    "authors": [
      "Kovila P.L. Coopamootoo",
      "Maryam Mehrnezhad",
      "Ehsan Toreini"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2202.04682"
  },
  {
    "id": "arXiv:2202.04696",
    "title": "Distributed Attribute-based Private Access Control",
    "abstract": "In attribute-based access control, users with certain verified attributes\nwill gain access to some particular data. Concerning with privacy of the users'\nattributes, we study the problem of distributed attribute-based private access\ncontrol (DAPAC) with multiple authorities, where each authority will learn and\nverify only one of the attributes.\nTo investigate its fundamental limits, we introduce an information theoretic\nDAPAC framework, with $N \\in \\mathbb{N}$, $N\\geq 2$, replicated non-colluding\nservers (authorities) and some users. Each user has an attribute vector\n$\\mathbf{v^*}=(v_1^*, ..., v_N^*)$ of dimension $N$ and is eligible to retrieve\na message $W^{\\mathbf{v}^*}$, available in all servers. Each server $n\\in [N]$\nis able to only observe and verify the $n$'th attribute of a user. In response,\nit sends a function of its data to the user. The system must satisfy the\nfollowing conditions: (1) Correctness: the user with attribute vector\n$\\mathbf{v^*}$ is able to retrieve his intended message $W^{\\mathbf{v}^*}$ from\nthe servers' response, (2) Data Secrecy: the user will not learn anything about\nthe other messages, (3) Attribute Privacy: each Server~$n$ learns nothing\nbeyond attribute $n$ of the user. The capacity of the DAPAC is defined as the\nratio of the file size and the aggregated size of the responses, maximized over\nall feasible schemes. We obtain a lower bound on the capacity of this problem\nby proposing an achievable algorithm with rate $\\frac{1}{2K}$, where $K$ is the\nsize of the alphabet of each attribute.",
    "descriptor": "",
    "authors": [
      "Amir Masoud Jafarpisheh",
      "Mahtab Mirmohseni",
      "Mohammad Ali Maddah-Ali"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.04696"
  },
  {
    "id": "arXiv:2202.04703",
    "title": "Improving Content-Aware Video Streaming in Congested Networks with  In-Network Computing",
    "abstract": "Network congestion and packet loss pose an ever-increasing challenge to video\nstreaming. Despite the research efforts toward making video encoding schemes\nresilient to lossy network conditions, forwarding devices have not considered\nmonitoring packet content to prioritize packets and minimize the impact of\npacket loss on video transmission. In this work, we advocate in favor of\nin-network computing employing a packet drop algorithm and an in-network\nhardware module to devise a solution for improving content-aware video\nstreaming in congested network. Results show that our approach can reduce\nintra-predicted packet loss by over 80% at negligible resource usage and\nperformance costs.",
    "descriptor": "",
    "authors": [
      "Leonardo Gobatto",
      "Mateus Saquetti",
      "Claudio Diniz",
      "Bruno Zatt",
      "Weverton Cordeiro",
      "Jose Rodrigo Azambuja"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Hardware Architecture (cs.AR)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2202.04703"
  },
  {
    "id": "arXiv:2202.04705",
    "title": "Deploying Vaccine Distribution Sites for Improved Accessibility and  Equity to Support Pandemic Response",
    "abstract": "In response to COVID-19, many countries have mandated social distancing and\nbanned large group gatherings in order to slow down the spread of SARS-CoV-2.\nThese social interventions along with vaccines remain the best way forward to\nreduce the spread of SARS CoV-2. In order to increase vaccine accessibility,\nstates such as Virginia have deployed mobile vaccination centers to distribute\nvaccines across the state. When choosing where to place these sites, there are\ntwo important factors to take into account: accessibility and equity. We\nformulate a combinatorial problem that captures these factors and then develop\nefficient algorithms with theoretical guarantees on both of these aspects.\nFurthermore, we study the inherent hardness of the problem, and demonstrate\nstrong impossibility results. Finally, we run computational experiments on\nreal-world data to show the efficacy of our methods.",
    "descriptor": "\nComments: 14 pages, 4 figures, to appear at AAMAS 2022\n",
    "authors": [
      "George Li",
      "Ann Li",
      "Madhav Marathe",
      "Aravind Srinivasan",
      "Leonidas Tsepenekas",
      "Anil Vullikanti"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Data Structures and Algorithms (cs.DS)",
      "Multiagent Systems (cs.MA)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2202.04705"
  },
  {
    "id": "arXiv:2202.04708",
    "title": "Active Learning Improves Performance on Symbolic RegressionTasks in  StackGP",
    "abstract": "In this paper we introduce an active learning method for symbolic regression\nusing StackGP. The approach begins with a small number of data points for\nStackGP to model. To improve the model the system incrementally adds a data\npoint such that the new point maximizes prediction uncertainty as measured by\nthe model ensemble. Symbolic regression is re-run with the larger data set.\nThis cycle continues until the system satisfies a termination criterion. We use\nthe Feynman AI benchmark set of equations to examine the ability of our method\nto find appropriate models using fewer data points. The approach was found to\nsuccessfully rediscover 72 of the 100 Feynman equations using as few data\npoints as possible, and without use of domain expertise or data translation.",
    "descriptor": "\nComments: 8 page, 1 figure. Submitted to GECCO-2022\n",
    "authors": [
      "Nathan Haut",
      "Wolfgang Banzhaf",
      "Bill Punch"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.04708"
  },
  {
    "id": "arXiv:2202.04709",
    "title": "Transferred Q-learning",
    "abstract": "We consider $Q$-learning with knowledge transfer, using samples from a target\nreinforcement learning (RL) task as well as source samples from different but\nrelated RL tasks. We propose transfer learning algorithms for both batch and\nonline $Q$-learning with offline source studies. The proposed transferred\n$Q$-learning algorithm contains a novel re-targeting step that enables vertical\ninformation-cascading along multiple steps in an RL task, besides the usual\nhorizontal information-gathering as transfer learning (TL) for supervised\nlearning. We establish the first theoretical justifications of TL in RL tasks\nby showing a faster rate of convergence of the $Q$ function estimation in the\noffline RL transfer, and a lower regret bound in the offline-to-online RL\ntransfer under certain similarity assumptions. Empirical evidences from both\nsynthetic and real datasets are presented to back up the proposed algorithm and\nour theoretical results.",
    "descriptor": "",
    "authors": [
      "Elynn Y. Chen",
      "Michael I. Jordan",
      "Sai Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2202.04709"
  },
  {
    "id": "arXiv:2202.04713",
    "title": "PINs: Progressive Implicit Networks for Multi-Scale Neural  Representations",
    "abstract": "Multi-layer perceptrons (MLP) have proven to be effective scene encoders when\ncombined with higher-dimensional projections of the input, commonly referred to\nas \\textit{positional encoding}. However, scenes with a wide frequency spectrum\nremain a challenge: choosing high frequencies for positional encoding\nintroduces noise in low structure areas, while low frequencies result in poor\nfitting of detailed regions. To address this, we propose a progressive\npositional encoding, exposing a hierarchical MLP structure to incremental sets\nof frequency encodings. Our model accurately reconstructs scenes with wide\nfrequency bands and learns a scene representation at progressive level of\ndetail \\textit{without explicit per-level supervision}. The architecture is\nmodular: each level encodes a continuous implicit representation that can be\nleveraged separately for its respective resolution, meaning a smaller network\nfor coarser reconstructions. Experiments on several 2D and 3D datasets show\nimprovements in reconstruction accuracy, representational capacity and training\nspeed compared to baselines.",
    "descriptor": "",
    "authors": [
      "Zoe Landgraf",
      "Alexander Sorkine Hornung",
      "Ricardo Silveira Cabral"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.04713"
  },
  {
    "id": "arXiv:2202.04718",
    "title": "Designing Closed Human-in-the-loop Deferral Pipelines",
    "abstract": "In hybrid human-machine deferral frameworks, a classifier can defer uncertain\ncases to human decision-makers (who are often themselves fallible). Prior work\non simultaneous training of such classifier and deferral models has typically\nassumed access to an oracle during training to obtain true class labels for\ntraining samples, but in practice there often is no such oracle. In contrast,\nwe consider a \"closed\" decision-making pipeline in which the same fallible\nhuman decision-makers used in deferral also provide training labels. How can\nimperfect and biased human expert labels be used to train a fair and accurate\ndeferral framework? Our key insight is that by exploiting weak prior\ninformation, we can match experts to input examples to ensure fairness and\naccuracy of the resulting deferral framework, even when imperfect and biased\nexperts are used in place of ground truth labels. The efficacy of our approach\nis shown both by theoretical analysis and by evaluation on two tasks.",
    "descriptor": "\nComments: A shorter version of this paper appeared in BHCC 2021\n",
    "authors": [
      "Vijay Keswani",
      "Matthew Lease",
      "Krishnaram Kenthapadi"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.04718"
  },
  {
    "id": "arXiv:2202.04721",
    "title": "New Projection-free Algorithms for Online Convex Optimization with  Adaptive Regret Guarantees",
    "abstract": "We present new efficient \\textit{projection-free} algorithms for online\nconvex optimization (OCO), where by projection-free we refer to algorithms that\navoid computing orthogonal projections onto the feasible set, and instead relay\non different and potentially much more efficient oracles. While most\nstate-of-the-art projection-free algorithms are based on the\n\\textit{follow-the-leader} framework, our algorithms are fundamentally\ndifferent and are based on the \\textit{online gradient descent} algorithm with\na novel and efficient approach to computing so-called \\textit{infeasible\nprojections}. As a consequence, we obtain the first projection-free algorithms\nwhich naturally yield \\textit{adaptive regret} guarantees, i.e., regret bounds\nthat hold w.r.t. any sub-interval of the sequence. Concretely, when assuming\nthe availability of a linear optimization oracle (LOO) for the feasible set, on\na sequence of length $T$, our algorithms guarantee $O(T^{3/4})$ adaptive regret\nand $O(T^{3/4})$ adaptive expected regret, for the full-information and bandit\nsettings, respectively, using only $O(T)$ calls to the LOO. These bounds match\nthe current state-of-the-art regret bounds for LOO-based projection-free OCO,\nwhich are \\textit{not adaptive}. We also consider a new natural setting in\nwhich the feasible set is accessible through a separation oracle. We present\nalgorithms which, using overall $O(T)$ calls to the separation oracle,\nguarantee $O(\\sqrt{T})$ adaptive regret and $O(T^{3/4})$ adaptive expected\nregret for the full-information and bandit settings, respectively.",
    "descriptor": "",
    "authors": [
      "Dan Garber",
      "Ben Kretzu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2202.04721"
  },
  {
    "id": "arXiv:2202.04722",
    "title": "On the stability of unevenly spaced samples for interpolation and  quadrature",
    "abstract": "Unevenly spaced samples from a periodic function are common in signal\nprocessing and can often be viewed as a perturbed equally spaced grid. In this\npaper, we analyze how the uneven distribution of the samples impacts the\nquality of interpolation and quadrature. Starting with equally spaced nodes on\n$[-\\pi,\\pi)$ with grid spacing $h$, suppose the unevenly spaced nodes are\nobtained by perturbing each uniform node by an arbitrary amount $\\leq \\alpha\nh$, where $0 \\leq \\alpha < 1/2$ is a fixed constant. We prove a discrete\nversion of the Kadec-1/4 theorem, which states that the nonuniform discrete\nFourier transform associated with perturbed nodes has a bounded condition\nnumber independent of $h$, for any $\\alpha < 1/4$. We go on to show that\nunevenly spaced quadrature rules converge for all continuous functions and\ninterpolants converge uniformly for all differentiable functions whose\nderivative has bounded variation when $0 \\leq \\alpha < 1/4$. Though, quadrature\nrules at perturbed nodes can have negative weights for any $\\alpha > 0$, we\nprovide a bound on the absolute sum of the quadrature weights. Therefore, we\nshow that perturbed equally spaced grids with small $\\alpha$ can be used\nwithout numerical woes. While our proof techniques work primarily when $0 \\leq\n\\alpha < 1/4$, we show that a small amount of oversampling extends our results\nto the case when $1/4 \\leq \\alpha < 1/2$.",
    "descriptor": "",
    "authors": [
      "Annan Yu",
      "Alex Townsend"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.04722"
  },
  {
    "id": "arXiv:2202.04724",
    "title": "The Landscape of Distributed Complexities on Trees and Beyond",
    "abstract": "We study the local complexity landscape of locally checkable labeling (LCL)\nproblems on constant-degree graphs with a focus on complexities below $\\log^*\nn$.\nOur contribution is threefold:\nOur main contribution is that we complete the classification of the\ncomplexity landscape of LCL problems on trees in the LOCAL model, by proving\nthat every LCL problem with local complexity $o(\\log^* n)$ has actually\ncomplexity $O(1)$. This result improves upon the previous speedup result from\n$o(\\log \\log^* n)$ to $O(1)$ by [Chang, Pettie, FOCS 2017].\nIn the related LCA and Volume models [Alon, Rubinfeld, Vardi, Xie, SODA 2012,\nRubinfeld, Tamir, Vardi, Xie, 2011, Rosenbaum, Suomela, PODC 2020], we prove\nthe same speedup from $o(\\log^* n)$ to $O(1)$ for all bounded degree graphs.\nSimilarly, we complete the classification of the LOCAL complexity landscape\nof oriented $d$-dimensional grids by proving that any LCL problem with local\ncomplexity $o(\\log^* n)$ has actually complexity $O(1)$. This improves upon the\nprevious speed-up from $o(\\sqrt[d]{\\log^* n})$ by Suomela in [Chang, Pettie,\nFOCS 2017].",
    "descriptor": "",
    "authors": [
      "Christoph Grunau",
      "Vaclav Rozhon",
      "Sebastian Brandt"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2202.04724"
  },
  {
    "id": "arXiv:2202.04725",
    "title": "TamilEmo: Finegrained Emotion Detection Dataset for Tamil",
    "abstract": "Emotional Analysis from textual input has been considered both a challenging\nand interesting task in Natural Language Processing. However, due to the lack\nof datasets in low-resource languages (i.e. Tamil), it is difficult to conduct\nresearch of high standard in this area. Therefore we introduce this labelled\ndataset (a largest manually annotated dataset of more than 42k Tamil YouTube\ncomments, labelled for 31 emotions including neutral) for emotion recognition.\nThe goal of this dataset is to improve emotion detection in multiple downstream\ntasks in Tamil. We have also created three different groupings of our emotions\n(3-class, 7-class and 31-class) and evaluated the model's performance on each\ncategory of the grouping. Our MURIL-base model has achieved a 0.60 macro\naverage F1-score across our 3-class group dataset. With 7-class and 31-class\ngroups, the Random Forest model performed well with a macro average F1-scores\nof 0.42 and 0.29 respectively.",
    "descriptor": "\nComments: 11 pages, 4 figures\n",
    "authors": [
      "Charangan Vasantharajan",
      "Sean Benhur",
      "Prasanna Kumar Kumarasen",
      "Rahul Ponnusamy",
      "Sathiyaraj Thangasamy",
      "Ruba Priyadharshini",
      "Thenmozhi Durairaj",
      "Kanchana Sivanraju",
      "Anbukkarasi Sampath",
      "Bharathi Raja Chakravarthi",
      "John Phillip McCrae"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.04725"
  },
  {
    "id": "arXiv:2202.04727",
    "title": "Terrain parameter estimation from proprioceptive sensing of the  suspension dynamics in offroad vehicles",
    "abstract": "Offroad vehicle movement has to contend with uneven and uncertain terrain\nwhich present challenges to path planning and motion control for both manned\nand unmanned ground vehicles. Knowledge of terrain properties can allow a\nvehicle to adapt its control and motion planning algorithms. Terrain\nproperties, however, can change on time scales of days or even hours,\nnecessitating their online estimation. The kinematics and, in particular the\noscillations experienced by an offroad vehicle carry a signature of the terrain\nproperties. These terrain properties can thus be estimated from proprioceptive\nsensing of the vehicle dynamics with an appropriate model and estimation\nalgorithm. In this paper, we show that knowledge of the vertical dynamics of a\nvehicle due to its suspension can enable faster and more accurate estimation of\nterrain parameters. The paper considers a five degree of freedom model that\ncombines the well known half-car and bicycle models. We show through simulation\nthat the sinkage exponent, a parameter that can significantly influence the\nwheel forces from the terrain and thus greatly impact the vehicle trajectory,\ncan be estimated from measurements of the vehicle's linear acceleration and\nrotational velocity, which can be readily obtained from an onboard IMU. We show\nthat modelling the vertical vehicle dynamics can lead to significant\nimprovement in both the estimation of terrain parameters and the prediction of\nthe vehicle trajectory.",
    "descriptor": "",
    "authors": [
      "Jake Buzhardt",
      "Phanindra Tallapragada"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.04727"
  },
  {
    "id": "arXiv:2202.04728",
    "title": "Predicting Human Similarity Judgments Using Large Language Models",
    "abstract": "Similarity judgments provide a well-established method for accessing mental\nrepresentations, with applications in psychology, neuroscience and machine\nlearning. However, collecting similarity judgments can be prohibitively\nexpensive for naturalistic datasets as the number of comparisons grows\nquadratically in the number of stimuli. One way to tackle this problem is to\nconstruct approximation procedures that rely on more accessible proxies for\npredicting similarity. Here we leverage recent advances in language models and\nonline recruitment, proposing an efficient domain-general procedure for\npredicting human similarity judgments based on text descriptions. Intuitively,\nsimilar stimuli are likely to evoke similar descriptions, allowing us to use\ndescription similarity to predict pairwise similarity judgments. Crucially, the\nnumber of descriptions required grows only linearly with the number of stimuli,\ndrastically reducing the amount of data required. We test this procedure on six\ndatasets of naturalistic images and show that our models outperform previous\napproaches based on visual information.",
    "descriptor": "\nComments: 7 pages, 6 figures\n",
    "authors": [
      "Raja Marjieh",
      "Ilia Sucholutsky",
      "Theodore R. Sumers",
      "Nori Jacoby",
      "Thomas L. Griffiths"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.04728"
  },
  {
    "id": "arXiv:2202.04731",
    "title": "Graph Neural Network for Cell Tracking in Microscopy Videos",
    "abstract": "We present a novel graph neural network (GNN) approach for cell tracking in\nhigh-throughput microscopy videos. By modeling the entire time-lapse sequence\nas a direct graph where cell instances are represented by its nodes and their\nassociations by its edges, we extract the entire set of cell trajectories by\nlooking for the maximal paths in the graph. This is accomplished by several key\ncontributions incorporated into an end-to-end deep learning framework. We\nexploit a deep metric learning algorithm to extract cell feature vectors that\ndistinguish between instances of different biological cells and assemble same\ncell instances. We introduce a new GNN block type which enables a mutual update\nof node and edge feature vectors, thus facilitating the underlying message\npassing process. The message passing concept, whose extent is determined by the\nnumber of GNN blocks, is of fundamental importance as it enables the `flow' of\ninformation between nodes and edges much behind their neighbors in consecutive\nframes. Finally, we solve an edge classification problem and use the identified\nactive edges to construct the cells' tracks and lineage trees. We demonstrate\nthe strengths of the proposed cell tracking approach by applying it to 2D and\n3D datasets of different cell types, imaging setups, and experimental\nconditions. We show that our framework outperforms most of the current\nstate-of-the-art methods.",
    "descriptor": "",
    "authors": [
      "Tal Ben-Haim",
      "Tammy Riklin-Raviv"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.04731"
  },
  {
    "id": "arXiv:2202.04732",
    "title": "Online Learning to Transport via the Minimal Selection Principle",
    "abstract": "Motivated by robust dynamic resource allocation in operations research, we\nstudy the Online Learning to Transport (OLT) problem where the decision\nvariable is a probability measure, an infinite-dimensional object. We draw\nconnections between online learning, optimal transport, and partial\ndifferential equations through an insight called the minimal selection\nprinciple, originally studied in the Wasserstein gradient flow setting by\nAmbrosio et al. (2005). This allows us to extend the standard online learning\nframework to the infinite-dimensional setting seamlessly. Based on our\nframework, we derive a novel method called the minimal selection or exploration\n(MSoE) algorithm to solve OLT problems using mean-field approximation and\ndiscretization techniques. In the displacement convex setting, the main\ntheoretical message underpinning our approach is that minimizing transport cost\nover time (via the minimal selection principle) ensures optimal cumulative\nregret upper bounds. On the algorithmic side, our MSoE algorithm applies beyond\nthe displacement convex setting, making the mathematical theory of optimal\ntransport practically relevant to non-convex settings common in dynamic\nresource allocation.",
    "descriptor": "\nComments: 20 pages\n",
    "authors": [
      "Wenxuan Guo",
      "YoonHaeng Hur",
      "Tengyuan Liang",
      "Christopher Ryan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.04732"
  },
  {
    "id": "arXiv:2202.04736",
    "title": "Coarsening the Granularity: Towards Structurally Sparse Lottery Tickets",
    "abstract": "The lottery ticket hypothesis (LTH) has shown that dense models contain\nhighly sparse subnetworks (i.e., winning tickets) that can be trained in\nisolation to match full accuracy. Despite many exciting efforts being made,\nthere is one \"commonsense\" seldomly challenged: a winning ticket is found by\niterative magnitude pruning (IMP) and hence the resultant pruned subnetworks\nhave only unstructured sparsity. That gap limits the appeal of winning tickets\nin practice, since the highly irregular sparse patterns are challenging to\naccelerate on hardware. Meanwhile, directly substituting structured pruning for\nunstructured pruning in IMP damages performance more severely and is usually\nunable to locate winning tickets.\nIn this paper, we demonstrate the first positive result that a structurally\nsparse winning ticket can be effectively found in general. The core idea is to\nappend \"post-processing techniques\" after each round of (unstructured) IMP, to\nenforce the formation of structural sparsity. Specifically, we first \"re-fill\"\npruned elements back in some channels deemed to be important, and then\n\"re-group\" non-zero elements to create flexible group-wise structural patterns.\nBoth our identified channel- and group-wise structural subnetworks win the\nlottery, with substantial inference speedups readily supported by existing\nhardware. Extensive experiments, conducted on diverse datasets across multiple\nnetwork backbones, consistently validate our proposal, showing that the\nhardware acceleration roadblock of LTH is now removed. Specifically, the\nstructural winning tickets obtain up to {64.93%, 64.84%, 64.84%} running time\nsavings at {36% ~ 80%, 74%, 58%} sparsity on {CIFAR, Tiny-ImageNet, ImageNet},\nwhile maintaining comparable accuracy. Codes are available in\nhttps://github.com/VITA-Group/Structure-LTH.",
    "descriptor": "",
    "authors": [
      "Tianlong Chen",
      "Xuxi Chen",
      "Xiaolong Ma",
      "Yanzhi Wang",
      "Zhangyang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.04736"
  },
  {
    "id": "arXiv:2202.04737",
    "title": "Telegram Monitor: Monitoring Brazilian Political Groups and Channels on  Telegram",
    "abstract": "Instant messaging platforms such as Telegram became one of the main means of\ncommunication used by people all over the world. Most of them are home of\nseveral groups and channels that connect thousands of people focused on\npolitical topics. However, they have suffered with misinformation campaigns\nwith a direct impact on electoral processes around the world. While some\nplatforms, such as WhatsApp, took restrictive policies and measures to\nattenuate the issues arising from the abuse of their systems, others have\nemerged as alternatives, presenting little or no restrictions on content\nmoderation or actions in combating misinformation. Telegram is one of those\nsystems, which has been attracting more users and gaining popularity. In this\nwork, we present the \"Telegram Monitor\", a web-based system that monitors the\npolitical debate in this environment and enables the analysis of the most\nshared content in multiple channels and public groups. Our system aims to allow\njournalists, researchers, and fact-checking agencies to identify trending\nconspiracy theories, misinformation campaigns, or simply to monitor the\npolitical debate in this space along the 2022 Brazilian elections. We hope our\nsystem can assist the combat of misinformation spreading through Telegram in\nBrazil.",
    "descriptor": "\nComments: 4 pages, TheWebConf 2022\n",
    "authors": [
      "Manoel J\u00fanior",
      "Philipe Melo",
      "Daniel Kansaon",
      "Vitor Mafra",
      "Kaio S\u00e1",
      "Fabr\u00edcio Benevenuto"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2202.04737"
  },
  {
    "id": "arXiv:2202.04742",
    "title": "FedQAS: Privacy-aware machine reading comprehension with federated  learning",
    "abstract": "Machine reading comprehension (MRC) of text data is one important task in\nNatural Language Understanding. It is a complex NLP problem with a lot of\nongoing research fueled by the release of the Stanford Question Answering\nDataset (SQuAD) and Conversational Question Answering (CoQA). It is considered\nto be an effort to teach computers how to \"understand\" a text, and then to be\nable to answer questions about it using deep learning. However, until now\nlarge-scale training on private text data and knowledge sharing has been\nmissing for this NLP task. Hence, we present FedQAS, a privacy-preserving\nmachine reading system capable of leveraging large-scale private data without\nthe need to pool those datasets in a central location. The proposed approach\ncombines transformer models and federated learning technologies. The system is\ndeveloped using the FEDn framework and deployed as a proof-of-concept alliance\ninitiative. FedQAS is flexible, language-agnostic, and allows intuitive\nparticipation and execution of local model training. In addition, we present\nthe architecture and implementation of the system, as well as provide a\nreference evaluation based on the SQUAD dataset, to showcase how it overcomes\ndata privacy issues and enables knowledge sharing between alliance members in a\nFederated learning setting.",
    "descriptor": "",
    "authors": [
      "Addi Ait-Mlouk",
      "Sadi Alawadi",
      "Salman Toor",
      "Andreas Hellander"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.04742"
  },
  {
    "id": "arXiv:2202.04743",
    "title": "Auditory Feedback for Standing Balance Improvement in Virtual Reality",
    "abstract": "Virtual Reality (VR) users often experience postural instability, i.e.,\nbalance problems, which could be a major barrier to universal usability and\naccessibility for all, especially for persons with balance impairments. Prior\nresearch has confirmed the imbalance effect, but minimal research has been\nconducted to reduce this effect. We recruited 42 participants (with balance\nimpairments: 21, without balance impairments: 21) to investigate the impact of\nseveral auditory techniques on balance in VR, specifically spatial audio,\nstatic rest frame audio, rhythmic audio, and audio mapped to the center of\npressure (CoP). Participants performed two types of tasks - standing visual\nexploration and standing reach and grasp. Within-subject results showed that\neach auditory technique improved balance in VR for both persons with and\nwithout balance impairments. Spatial and CoP audio improved balance\nsignificantly more than other auditory conditions. The techniques presented in\nthis research could be used in future virtual environments to improve standing\nbalance and help push VR closer to universal usability.",
    "descriptor": "\nComments: 10 pages\n",
    "authors": [
      "M. Rasel Mahmud",
      "Michael Stewart",
      "Alberto Cordova",
      "John Quarles"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2202.04743"
  },
  {
    "id": "arXiv:2202.04746",
    "title": "Weighted Connected Matchings",
    "abstract": "A matching $M$ is a $\\mathscr{P}$-matching if the subgraph induced by the\nendpoints of the edges of $M$ satisfies property $\\mathscr{P}$. As examples,\nfor appropriate choices of $\\mathscr{P}$, the problems Induced Matching,\nUniquely Restricted Matching, Connected Matching and Disconnected Matching\narise. For many of these problems, finding a maximum $\\mathscr{P}$-matching is\na knowingly NP-Hard problem, with few exceptions, such as connected matchings,\nwhich has the same time complexity as usual Maximum Matching problem. The\nweighted variant of Maximum Matching has been studied for decades, with many\napplications, including the well-known Assignment problem. Motivated by this\nfact, in addition to some recent researches in weighted versions of acyclic and\ninduced matchings, we study the Maximum Weight Connected Matching. In this\nproblem, we want to find a matching $M$ such that the endpoint vertices of its\nedges induce a connected subgraph and the sum of the edge weights of $M$ is\nmaximum. Unlike the unweighted Connected Matching problem, which is in P for\ngeneral graphs, we show that Maximum Weight Connected Matching is NP-Hard even\nfor bounded diameter bipartite graphs, starlike graphs, planar bipartite, and\nbounded degree planar graphs, while solvable in linear time for trees and\nsubcubic graphs. When we restrict edge weights to be non negative only, we show\nthat the problem turns to be polynomially solvable for chordal graphs, while it\nremains NP-Hard for most of the cases when weights can be negative. Our final\ncontributions are on parameterized complexity. On the positive side, we present\na single exponential time algorithm when parameterized by treewidth. In terms\nof kernelization, we show that, even when restricted to binary weights,\nWeighted Connected Matching does not admit a polynomial kernel when\nparameterized by vertex cover under standard complexity-theoretical hypotheses.",
    "descriptor": "",
    "authors": [
      "Guilherme C. M. Gomes",
      "Bruno P. Masquio",
      "Paulo E. D. Pinto",
      "Vinicius F. dos Santos",
      "Jayme L. Szwarcfiter"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2202.04746"
  },
  {
    "id": "arXiv:2202.04748",
    "title": "Estimation of Clinical Workload and Patient Activity using Deep Learning  and Optical Flow",
    "abstract": "Contactless monitoring using thermal imaging has become increasingly proposed\nto monitor patient deterioration in hospital, most recently to detect fevers\nand infections during the COVID-19 pandemic. In this letter, we propose a novel\nmethod to estimate patient motion and observe clinical workload using a similar\ntechnical setup but combined with open source object detection algorithms\n(YOLOv4) and optical flow. Patient motion estimation was used to approximate\npatient agitation and sedation, while worker motion was used as a surrogate for\ncaregiver workload. Performance was illustrated by comparing over 32000 frames\nfrom videos of patients recorded in an Intensive Care Unit, to clinical\nagitation scores recorded by clinical workers.",
    "descriptor": "",
    "authors": [
      "Thanh Nguyen-Duc",
      "Peter Y Chan",
      "Andrew Tay",
      "David Chen",
      "John Tan Nguyen",
      "Jessica Lyall",
      "Maria De Freitas"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.04748"
  },
  {
    "id": "arXiv:2202.04752",
    "title": "\"This is Fake! Shared it by Mistake\": Assessing the Intent of Fake News  Spreaders",
    "abstract": "Individuals can be misled by fake news and spread it unintentionally without\nknowing it is false. This phenomenon has been frequently observed but has not\nbeen investigated. Our aim in this work is to assess the intent of fake news\nspreaders. To distinguish between intentional versus unintentional spreading,\nwe study the psychological explanations of unintentional spreading. With this\nfoundation, we then propose an influence graph, using which we assess the\nintent of fake news spreaders. Our extensive experiments show that the assessed\nintent can help significantly differentiate between intentional and\nunintentional fake news spreaders. Furthermore, the estimated intent can\nsignificantly improve the current techniques that detect fake news. To our best\nknowledge, this is the first work to model individuals' intent in fake news\nspreading.",
    "descriptor": "\nComments: Accepted to The ACM Web Conference (WWW) 2022\n",
    "authors": [
      "Xinyi Zhou",
      "Kai Shu",
      "Vir V. Phoha",
      "Huan Liu",
      "Reza Zafarani"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.04752"
  },
  {
    "id": "arXiv:2202.04753",
    "title": "Discovering Concepts in Learned Representations using Statistical  Inference and Interactive Visualization",
    "abstract": "Concept discovery is one of the open problems in the interpretability\nliterature that is important for bridging the gap between non-deep learning\nexperts and model end-users. Among current formulations, concepts defines them\nby as a direction in a learned representation space. This definition makes it\npossible to evaluate whether a particular concept significantly influences\nclassification decisions for classes of interest. However, finding relevant\nconcepts is tedious, as representation spaces are high-dimensional and hard to\nnavigate. Current approaches include hand-crafting concept datasets and then\nconverting them to latent space directions; alternatively, the process can be\nautomated by clustering the latent space. In this study, we offer another two\napproaches to guide user discovery of meaningful concepts, one based on\nmultiple hypothesis testing, and another on interactive visualization. We\nexplore the potential value and limitations of these approaches through\nsimulation experiments and an demo visual interface to real data. Overall, we\nfind that these techniques offer a promising strategy for discovering relevant\nconcepts in settings where users do not have predefined descriptions of them,\nbut without completely automating the process.",
    "descriptor": "\nComments: KDD'19, Workshop Explainable AI/ML (XAI) for Accountability, Fairness, and Transparency, August 04-08, 2019, Anchorage, AK, USA\n",
    "authors": [
      "Adrianna Janik",
      "Kris Sankaran"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.04753"
  },
  {
    "id": "arXiv:2202.04755",
    "title": "DeepSSN: a deep convolutional neural network to assess spatial scene  similarity",
    "abstract": "Spatial-query-by-sketch is an intuitive tool to explore human spatial\nknowledge about geographic environments and to support communication with scene\ndatabase queries. However, traditional sketch-based spatial search methods\nperform insufficiently due to their inability to find hidden multi-scale map\nfeatures from mental sketches. In this research, we propose a deep\nconvolutional neural network, namely Deep Spatial Scene Network (DeepSSN), to\nbetter assess the spatial scene similarity. In DeepSSN, a triplet loss function\nis designed as a comprehensive distance metric to support the similarity\nassessment. A positive and negative example mining strategy using qualitative\nconstraint networks in spatial reasoning is designed to ensure a consistently\nincreasing distinction of triplets during the training process. Moreover, we\ndevelop a prototype spatial scene search system using the proposed DeepSSN, in\nwhich the users input spatial query via sketch maps and the system can\nautomatically augment the sketch training data. The proposed model is validated\nusing multi-source conflated map data including 131,300 labeled scene samples\nafter data augmentation. The empirical results demonstrate that the DeepSSN\noutperforms baseline methods including k-nearest-neighbors, multilayer\nperceptron, AlexNet, DenseNet, and ResNet using mean reciprocal rank and\nprecision metrics. This research advances geographic information retrieval\nstudies by introducing a novel deep learning method tailored to spatial scene\nqueries.",
    "descriptor": "\nComments: 28 pages, 10 figures, 8 tables\n",
    "authors": [
      "Danhuai Guo",
      "Shiyin Ge",
      "Shu Zhang",
      "Song Gao",
      "Ran Tao",
      "Yangang Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.04755"
  },
  {
    "id": "arXiv:2202.04757",
    "title": "A Novel Encoder-Decoder Network with Guided Transmission Map for Single  Image Dehazing",
    "abstract": "A novel Encoder-Decoder Network with Guided Transmission Map (EDN-GTM) for\nsingle image dehazing scheme is proposed in this paper. The proposed EDN-GTM\ntakes conventional RGB hazy image in conjunction with its transmission map\nestimated by adopting dark channel prior as the inputs of the network. The\nproposed EDN-GTM utilizes U-Net for image segmentation as the core network and\nutilizes various modifications including spatial pyramid pooling module and\nSwish activation to achieve state-of-the-art dehazing performance. Experiments\non benchmark datasets show that the proposed EDN-GTM outperforms most of\ntraditional and deep learning-based image dehazing schemes in terms of PSNR and\nSSIM metrics. The proposed EDN-GTM furthermore proves its applicability to\nobject detection problems. Specifically, when applied to an image preprocessing\ntool for driving object detection, the proposed EDN-GTM can efficiently remove\nhaze and significantly improve detection accuracy by 4.73% in terms of mAP\nmeasure. The code is available at: https://github.com/tranleanh/edn-gtm.",
    "descriptor": "\nComments: 8 pages, 5 figures, iSCSi'22\n",
    "authors": [
      "Le-Anh Tran",
      "Seokyong Moon",
      "Dong-Chul Park"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.04757"
  },
  {
    "id": "arXiv:2202.04762",
    "title": "Providing Real-time Assistance for Repairing Runtime Exceptions using  Stack Overflow Posts",
    "abstract": "Runtime Exceptions (REs) are an important class of bugs that occur frequently\nduring code development. Traditional Automatic Program Repair (APR) tools are\nof limited use in this \"in-development\" use case, since they require a\ntest-suite to be available as a patching oracle. Thus, developers typically\ntend to manually resolve their in-development REs, often by referring to\ntechnical forums, such as Stack Overflow (SO). To automate this manual process\nwe extend our previous work, MAESTRO, to provide real-time assistance to\ndevelopers for repairing Java REs by recommending a relevant patch-suggesting\nSO post and synthesizing a repair patch from this post to fix the RE in the\ndeveloper's code. MAESTRO exploits a library of Runtime Exception Patterns\n(REPs) semi-automatically mined from SO posts, through a relatively\ninexpensive, one-time, incremental process. An REP is an abstracted sequence of\nstatements that triggers a given RE. REPs are used to index SO posts, retrieve\na post most relevant to the RE instance exhibited by a developer's code and\nthen mediate the process of extracting a concrete repair from the SO post,\nabstracting out post-specific details, and concretizing the repair to the\ndeveloper's buggy code. We evaluate MAESTRO on a published RE benchmark\ncomprised of 78 instances. MAESTRO is able to generate a correct repair patch\nat the top position in 27% of the cases, within the top-3 in 40% of the cases\nand overall return a useful artifact in 81% of the cases. Further, the use of\nREPs proves instrumental to all aspects of MAESTRO's performance, from ranking\nand searching of SO posts to synthesizing patches from a given post. In\nparticular, 45% of correct patches generated by MAESTRO could not be produced\nby a baseline technique not using REPs, even when provided with MAESTRO's\nSO-post ranking. MAESTRO is also fast, needing around 1 second, on average, to\ngenerate its output.",
    "descriptor": "",
    "authors": [
      "Sonal Mahajan",
      "Mukul R. Prasad"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2202.04762"
  },
  {
    "id": "arXiv:2202.04766",
    "title": "Sampling Strategy for Fine-Tuning Segmentation Models to Crisis Area  under Scarcity of Data",
    "abstract": "The use of remote sensing in humanitarian crisis response missions is\nwell-established and has proven relevant repeatedly. One of the problems is\nobtaining gold annotations as it is costly and time consuming which makes it\nalmost impossible to fine-tune models to new regions affected by the crisis.\nWhere time is critical, resources are limited and environment is constantly\nchanging, models has to evolve and provide flexible ways to adapt to a new\nsituation. The question that we want to answer is if prioritization of samples\nprovide better results in fine-tuning vs other classical sampling methods under\nannotated data scarcity? We propose a method to guide data collection during\nfine-tuning, based on estimated model and sample properties, like predicted IOU\nscore. We propose two formulas for calculating sample priority. Our approach\nblends techniques from interpretability, representation learning and active\nlearning. We have applied our method to a deep learning model for semantic\nsegmentation, U-Net, in a remote sensing application of building detection -\none of the core use cases of remote sensing in humanitarian applications.\nPreliminary results shows utility in prioritization of samples for tuning\nsemantic segmentation models under scarcity of data condition.",
    "descriptor": "",
    "authors": [
      "Adrianna Janik",
      "Kris Sankaran"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.04766"
  },
  {
    "id": "arXiv:2202.04768",
    "title": "Boosting Graph Neural Networks by Injecting Pooling in Message Passing",
    "abstract": "There has been tremendous success in the field of graph neural networks\n(GNNs) as a result of the development of the message-passing (MP) layer, which\nupdates the representation of a node by combining it with its neighbors to\naddress variable-size and unordered graphs. Despite the fruitful progress of MP\nGNNs, their performance can suffer from over-smoothing, when node\nrepresentations become too similar and even indistinguishable from one another.\nFurthermore, it has been reported that intrinsic graph structures are smoothed\nout as the GNN layer increases. Inspired by the edge-preserving bilateral\nfilters used in image processing, we propose a new, adaptable, and powerful MP\nframework to prevent over-smoothing. Our bilateral-MP estimates a pairwise\nmodular gradient by utilizing the class information of nodes, and further\npreserves the global graph structure by using the gradient when the aggregating\nfunction is applied. Our proposed scheme can be generalized to all ordinary MP\nGNNs. Experiments on five medium-size benchmark datasets using four\nstate-of-the-art MP GNNs indicate that the bilateral-MP improves performance by\nalleviating over-smoothing. By inspecting quantitative measurements, we\nadditionally validate the effectiveness of the proposed mechanism in preventing\nthe over-smoothing issue.",
    "descriptor": "\nComments: 12 pages, 2 figures\n",
    "authors": [
      "Hyeokjin Kwon",
      "Jong-Min Lee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.04768"
  },
  {
    "id": "arXiv:2202.04769",
    "title": "Spectral Propagation Graph Network for Few-shot Time Series  Classification",
    "abstract": "Few-shot Time Series Classification (few-shot TSC) is a challenging problem\nin time series analysis. It is more difficult to classify when time series of\nthe same class are not completely consistent in spectral domain or time series\nof different classes are partly consistent in spectral domain. To address this\nproblem, we propose a novel method named Spectral Propagation Graph Network\n(SPGN) to explicitly model and propagate the spectrum-wise relations between\ndifferent time series with graph network. To the best of our knowledge, SPGN is\nthe first to utilize spectral comparisons in different intervals and involve\nspectral propagation across all time series with graph networks for few-shot\nTSC. SPGN first uses bandpass filter to expand time series in spectral domain\nfor calculating spectrum-wise relations between time series. Equipped with\ngraph networks, SPGN then integrates spectral relations with label information\nto make spectral propagation. The further study conveys the bi-directional\neffect between spectral relations acquisition and spectral propagation. We\nconduct extensive experiments on few-shot TSC benchmarks. SPGN outperforms\nstate-of-the-art results by a large margin in $4\\% \\sim 13\\%$. Moreover, SPGN\nsurpasses them by around $12\\%$ and $9\\%$ under cross-domain and cross-way\nsettings respectively.",
    "descriptor": "",
    "authors": [
      "Ling Yang",
      "Shenda Hong",
      "Luxia Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.04769"
  },
  {
    "id": "arXiv:2202.04770",
    "title": "Unsupervised Time-Series Representation Learning with Iterative Bilinear  Temporal-Spectral Fusion",
    "abstract": "Unsupervised/self-supervised time series representation learning is a\nchallenging problem because of its complex dynamics and sparse annotations.\nExisting works mainly adopt the framework of contrastive learning with the\ntime-based augmentation techniques to sample positives and negatives for\ncontrastive training. Nevertheless, they mostly use segment-level augmentation\nderived from time slicing, which may bring about sampling bias and incorrect\noptimization with false negatives due to the loss of global context. Besides,\nthey all pay no attention to incorporate the spectral information in feature\nrepresentation. In this paper, we propose a unified framework, namely Bilinear\nTemporal-Spectral Fusion (BTSF). Specifically, we firstly utilize the\ninstance-level augmentation with a simple dropout on the entire time series for\nmaximally capturing long-term dependencies. We devise a novel iterative\nbilinear temporal-spectral fusion to explicitly encode the affinities of\nabundant time-frequency pairs, and iteratively refines representations in a\nfusion-and-squeeze manner with Spectrum-to-Time (S2T) and Time-to-Spectrum\n(T2S) Aggregation modules. We firstly conducts downstream evaluations on three\nmajor tasks for time series including classification, forecasting and anomaly\ndetection. Experimental results shows that our BTSF consistently significantly\noutperforms the state-of-the-art methods.",
    "descriptor": "",
    "authors": [
      "Ling Yang",
      "Shenda Hong",
      "Luxia Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.04770"
  },
  {
    "id": "arXiv:2202.04771",
    "title": "Orthogonal Matrices for MBAT Vector Symbolic Architectures, and a \"Soft\"  VSA Representation for JSON",
    "abstract": "Vector Symbolic Architectures (VSAs) give a way to represent a complex object\nas a single fixed-length vector, so that similar objects have similar vector\nrepresentations. These vector representations then become easy to use for\nmachine learning or nearest-neighbor search. We review a previously proposed\nVSA method, MBAT (Matrix Binding of Additive Terms), which uses multiplication\nby random matrices for binding related terms. However, multiplying by such\nmatrices introduces instabilities which can harm performance. Making the random\nmatrices be orthogonal matrices provably fixes this problem. With respect to\nlarger scale applications, we see how to apply MBAT vector representations for\nany data expressed in JSON. JSON is used in numerous programming languages to\nexpress complex data, but its native format appears highly unsuited for machine\nlearning. Expressing JSON as a fixed-length vector makes it readily usable for\nmachine learning and nearest-neighbor search. Creating such JSON vectors also\nshows that a VSA needs to employ binding operations that are non-commutative.\nVSAs are now ready to try with full-scale practical applications, including\nhealthcare, pharmaceuticals, and genomics.\nKeywords: MBAT (Matrix Binding of Additive Terms), VSA (Vector Symbolic\nArchitecture), HDC (Hyperdimensional Computing), Distributed Representations,\nBinding, Orthogonal Matrices, Recurrent Connections, Machine Learning, Search,\nJSON, VSA Applications",
    "descriptor": "\nComments: 8 pages\n",
    "authors": [
      "Stephen I. Gallant"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2202.04771"
  },
  {
    "id": "arXiv:2202.04772",
    "title": "GrASP: Gradient-Based Affordance Selection for Planning",
    "abstract": "Planning with a learned model is arguably a key component of intelligence.\nThere are several challenges in realizing such a component in large-scale\nreinforcement learning (RL) problems. One such challenge is dealing effectively\nwith continuous action spaces when using tree-search planning (e.g., it is not\nfeasible to consider every action even at just the root node of the tree). In\nthis paper we present a method for selecting affordances useful for planning --\nfor learning which small number of actions/options from a continuous space of\nactions/options to consider in the tree-expansion process during planning. We\nconsider affordances that are goal-and-state-conditional mappings to\nactions/options as well as unconditional affordances that simply select\nactions/options available in all states. Our selection method is gradient\nbased: we compute gradients through the planning procedure to update the\nparameters of the function that represents affordances. Our empirical work\nshows that it is feasible to learn to select both primitive-action and option\naffordances, and that simultaneously learning to select affordances and\nplanning with a learned value-equivalent model can outperform model-free RL.",
    "descriptor": "",
    "authors": [
      "Vivek Veeriah",
      "Zeyu Zheng",
      "Richard Lewis",
      "Satinder Singh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.04772"
  },
  {
    "id": "arXiv:2202.04774",
    "title": "SHAS: Approaching optimal Segmentation for End-to-End Speech Translation",
    "abstract": "Speech translation models are unable to directly process long audios, like\nTED talks, which have to be split into shorter segments. Speech translation\ndatasets provide manual segmentations of the audios, which are not available in\nreal-world scenarios, and existing segmentation methods usually significantly\nreduce translation quality at inference time. To bridge the gap between the\nmanual segmentation of training and the automatic one at inference, we propose\nSupervised Hybrid Audio Segmentation (SHAS), a method that can effectively\nlearn the optimal segmentation from any manually segmented speech corpus.\nFirst, we train a classifier to identify the included frames in a segmentation,\nusing speech representations from a pre-trained wav2vec 2.0. The optimal\nsplitting points are then found by a probabilistic Divide-and-Conquer algorithm\nthat progressively splits at the frame of lowest probability until all segments\nare below a pre-specified length. Experiments on MuST-C and mTEDx show that the\ntranslation of the segments produced by our method approaches the quality of\nthe manual segmentation on 5 languages pairs. Namely, SHAS retains 95-98% of\nthe manual segmentation's BLEU score, compared to the 87-93% of the best\nexisting methods. Our method is additionally generalizable to different domains\nand achieves high zero-shot performance in unseen languages.",
    "descriptor": "\nComments: 7 pages including appendix\n",
    "authors": [
      "Ioannis Tsiamas",
      "Gerard I. G\u00e1llego",
      "Jos\u00e9 A. R. Fonollosa",
      "Marta R. Costa-juss\u00e0"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2202.04774"
  },
  {
    "id": "arXiv:2202.04781",
    "title": "Adversarial Attack and Defense of YOLO Detectors in Autonomous Driving  Scenarios",
    "abstract": "Visual detection is a key task in autonomous driving, and it serves as one\nfoundation for self-driving planning and control. Deep neural networks have\nachieved promising results in various computer vision tasks, but they are known\nto be vulnerable to adversarial attacks. A comprehensive understanding of deep\nvisual detectors' vulnerability is required before people can improve their\nrobustness. However, only a few adversarial attack/defense works have focused\non object detection, and most of them employed only classification and/or\nlocalization losses, ignoring the objectness aspect. In this paper, we identify\na serious objectness-related adversarial vulnerability in YOLO detectors and\npresent an effective attack strategy aiming the objectness aspect of visual\ndetection in autonomous vehicles. Furthermore, to address such vulnerability,\nwe propose a new objectness-aware adversarial training approach for visual\ndetection. Experiments show that the proposed attack targeting the objectness\naspect is 45.17% and 43.50% more effective than those generated from\nclassification and/or localization losses on the KITTI and COCO_traffic\ndatasets, respectively. Also, the proposed adversarial defense approach can\nimprove the detectors' robustness against objectness-oriented attacks by up to\n21% and 12% mAP on KITTI and COCO_traffic, respectively.",
    "descriptor": "\nComments: 7 pages, 3 figures\n",
    "authors": [
      "Jung Im Choi",
      "Qing Tian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.04781"
  },
  {
    "id": "arXiv:2202.04786",
    "title": "No-Regret Learning in Dynamic Stackelberg Games",
    "abstract": "In a Stackelberg game, a leader commits to a randomized strategy, and a\nfollower chooses their best strategy in response. We consider an extension of a\nstandard Stackelberg game, called a discrete-time dynamic Stackelberg game,\nthat has an underlying state space that affects the leader's rewards and\navailable strategies and evolves in a Markovian manner depending on both the\nleader and follower's selected strategies. Although standard Stackelberg games\nhave been utilized to improve scheduling in security domains, their deployment\nis often limited by requiring complete information of the follower's utility\nfunction. In contrast, we consider scenarios where the follower's utility\nfunction is unknown to the leader; however, it can be linearly parameterized.\nOur objective then is to provide an algorithm that prescribes a randomized\nstrategy to the leader at each step of the game based on observations of how\nthe follower responded in previous steps. We design a no-regret learning\nalgorithm that, with high probability, achieves a regret bound (when compared\nto the best policy in hindsight) which is sublinear in the number of time\nsteps; the degree of sublinearity depends on the number of features\nrepresenting the follower's utility function. The regret of the proposed\nlearning algorithm is independent of the size of the state space and polynomial\nin the rest of the parameters of the game. We show that the proposed learning\nalgorithm outperforms existing model-free reinforcement learning approaches.",
    "descriptor": "\nComments: Preprint, under review\n",
    "authors": [
      "Niklas Lauffer",
      "Mahsa Ghasemi",
      "Abolfazl Hashemi",
      "Yagiz Savas",
      "Ufuk Topcu"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.04786"
  },
  {
    "id": "arXiv:2202.04787",
    "title": "Proceedings of the Robust Artificial Intelligence System Assurance  (RAISA) Workshop 2022",
    "abstract": "The Robust Artificial Intelligence System Assurance (RAISA) workshop will\nfocus on research, development and application of robust artificial\nintelligence (AI) and machine learning (ML) systems. Rather than studying\nrobustness with respect to particular ML algorithms, our approach will be to\nexplore robustness assurance at the system architecture level, during both\ndevelopment and deployment, and within the human-machine teaming context. While\nthe research community is converging on robust solutions for individual AI\nmodels in specific scenarios, the problem of evaluating and assuring the\nrobustness of an AI system across its entire life cycle is much more complex.\nMoreover, the operational context in which AI systems are deployed necessitates\nconsideration of robustness and its relation to principles of fairness,\nprivacy, and explainability.",
    "descriptor": "",
    "authors": [
      "Olivia Brown",
      "Brad Dillman"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.04787"
  },
  {
    "id": "arXiv:2202.04789",
    "title": "HW/SW Co-design for Reliable In-memory Brain-inspired Hyperdimensional  Computing",
    "abstract": "Brain-inspired hyperdimensional computing (HDC) is continuously gaining\nremarkable attention. It is a promising alternative to traditional\nmachine-learning approaches due to its ability to learn from little data,\nlightweight implementation, and resiliency against errors. However, HDC is\noverwhelmingly data-centric similar to traditional machine-learning algorithms.\nIn-memory computing is rapidly emerging to overcome the von Neumann bottleneck\nby eliminating data movements between compute and storage units. In this work,\nwe investigate and model the impact of imprecise in-memory computing hardware\non the inference accuracy of HDC. Our modeling is based on 14nm FinFET\ntechnology fully calibrated with Intel measurement data. We accurately model,\nfor the first time, the voltage-dependent error probability in SRAM-based and\nFeFET-based in-memory computing. Thanks to HDC's resiliency against errors, the\ncomplexity of the underlying hardware can be reduced, providing large energy\nsavings of up to 6x. Experimental results for SRAM reveal that\nvariability-induced errors have a probability of up to 39 percent. Despite such\na high error probability, the inference accuracy is only marginally impacted.\nThis opens doors to explore new tradeoffs. We also demonstrate that the\nresiliency against errors is application-dependent. In addition, we investigate\nthe robustness of HDC against errors when the underlying in-memory hardware is\nrealized using emerging non-volatile FeFET devices instead of mature CMOS-based\nSRAMs. We demonstrate that inference accuracy does remain high despite the\nlarger error probability, while large area and power savings can be obtained.\nAll in all, HW/SW co-design is the key for efficient yet reliable in-memory\nhyperdimensional computing for both conventional CMOS technology and upcoming\nemerging technologies.",
    "descriptor": "\nComments: 12 pages, 16 figures\n",
    "authors": [
      "Simon Thomann",
      "Paul R. Genssler",
      "Hussam Amrouch"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2202.04789"
  },
  {
    "id": "arXiv:2202.04793",
    "title": "Low Ambiguity Zone: Theoretical Bounds and Doppler-Resilient Sequence  Design in Integrated Sensing and Communication Systems",
    "abstract": "In radar sensing and communications, designing Doppler resilient sequences\n(DRSs) with low ambiguity function for delay over the entire signal duration\nand Doppler shift over the entire signal bandwidth is an extremely difficult\ntask. However, in practice, the Doppler frequency range is normally much\nsmaller than the bandwidth of the transmitted signal, and it is relatively easy\nto attain quasi-synchronization for delays far less than the entire signal\nduration. Motivated by this observation, we propose a new concept called low\nambiguity zone (LAZ) which is a small area of the corresponding ambiguity\nfunction of interest defined by the certain Doppler frequency and delay. Such\nan LAZ will reduce to a zero ambiguity zone (ZAZ) if the maximum ambiguity\nvalues of interest are zero. In this paper, we derive a set of theoretical\nbounds on periodic LAZ/ZAZ of unimodular DRSs with and without spectral\nconstraints, which include the existing bounds on periodic global ambiguity\nfunction as special cases. These bounds may be used as theoretical design\nguidelines to measure the optimality of sequences against Doppler effect. We\nthen introduce four optimal constructions of DRSs with respect to the derived\nambiguity lower bounds based on some algebraic tools such as characters over\nfinite field and cyclic difference sets.",
    "descriptor": "\nComments: To apeear in IEEE JSAC, 2022\n",
    "authors": [
      "Zhifan Ye",
      "Zhengchun Zhou",
      "Pingzhi Fan",
      "Zilong Liu",
      "Xianfu Lei",
      "Xiaohu Tang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.04793"
  },
  {
    "id": "arXiv:2202.04798",
    "title": "Augmenting Neural Networks with Priors on Function Values",
    "abstract": "The need for function estimation in label-limited settings is common in the\nnatural sciences. At the same time, prior knowledge of function values is often\navailable in these domains. For example, data-free biophysics-based models can\nbe informative on protein properties, while quantum-based computations can be\ninformative on small molecule properties. How can we coherently leverage such\nprior knowledge to help improve a neural network model that is quite accurate\nin some regions of input space -- typically near the training data -- but\nwildly wrong in other regions? Bayesian neural networks (BNN) enable the user\nto specify prior information only on the neural network weights, not directly\non the function values. Moreover, there is in general no clear mapping between\nthese. Herein, we tackle this problem by developing an approach to augment BNNs\nwith prior information on the function values themselves. Our probabilistic\napproach yields predictions that rely more heavily on the prior information\nwhen the epistemic uncertainty is large, and more heavily on the neural network\nwhen the epistemic uncertainty is small.",
    "descriptor": "",
    "authors": [
      "Hunter Nisonoff",
      "Yixin Wang",
      "Jennifer Listgarten"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.04798"
  },
  {
    "id": "arXiv:2202.04800",
    "title": "The Abduction of Sherlock Holmes: A Dataset for Visual Abductive  Reasoning",
    "abstract": "Humans have remarkable capacity to reason abductively and hypothesize about\nwhat lies beyond the literal content of an image. By identifying concrete\nvisual clues scattered throughout a scene, we almost can't help but draw\nprobable inferences beyond the literal scene based on our everyday experience\nand knowledge about the world. For example, if we see a \"20 mph\" sign alongside\na road, we might assume the street sits in a residential area (rather than on a\nhighway), even if no houses are pictured. Can machines perform similar visual\nreasoning?\nWe present Sherlock, an annotated corpus of 103K images for testing machine\ncapacity for abductive reasoning beyond literal image contents. We adopt a\nfree-viewing paradigm: participants first observe and identify salient clues\nwithin images (e.g., objects, actions) and then provide a plausible inference\nabout the scene, given the clue. In total, we collect 363K (clue, inference)\npairs, which form a first-of-its-kind abductive visual reasoning dataset. Using\nour corpus, we test three complementary axes of abductive reasoning. We\nevaluate the capacity of models to: i) retrieve relevant inferences from a\nlarge candidate corpus; ii) localize evidence for inferences via bounding\nboxes, and iii) compare plausible inferences to match human judgments on a\nnewly-collected diagnostic corpus of 19K Likert-scale judgments. While we find\nthat fine-tuning CLIP-RN50x64 with a multitask objective outperforms strong\nbaselines, significant headroom exists between model performance and human\nagreement. We provide analysis that points towards future work.",
    "descriptor": "\nComments: code, data, models will be shared at this http URL\n",
    "authors": [
      "Jack Hessel",
      "Jena D. Hwang",
      "Jae Sung Park",
      "Rowan Zellers",
      "Chandra Bhagavatula",
      "Anna Rohrbach",
      "Kate Saenko",
      "Yejin Choi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.04800"
  },
  {
    "id": "arXiv:2202.04801",
    "title": "The leap to ordinal: functional prognosis after traumatic brain injury  using artificial intelligence",
    "abstract": "When a patient is admitted to the intensive care unit (ICU) after a traumatic\nbrain injury (TBI), an early prognosis is essential for baseline risk\nadjustment and shared decision making. TBI outcomes are commonly categorised by\nthe Glasgow Outcome Scale-Extended (GOSE) into 8, ordered levels of functional\nrecovery at 6 months after injury. Existing ICU prognostic models predict\nbinary outcomes at a certain threshold of GOSE (e.g., prediction of survival\n[GOSE>1] or functional independence [GOSE>4]). We aimed to develop ordinal\nprediction models that concurrently predict probabilities of each GOSE score.\nFrom a prospective cohort (n=1,550, 65 centres) in the ICU stratum of the\nCollaborative European NeuroTrauma Effectiveness Research in TBI (CENTER-TBI)\npatient dataset, we extracted all clinical information within 24 hours of ICU\nadmission (1,151 predictors) and 6-month GOSE scores. We analysed the effect of\n2 design elements on ordinal model performance: (1) the baseline predictor set,\nranging from a concise set of 10 validated predictors to a token-embedded\nrepresentation of all possible predictors, and (2) the modelling strategy, from\nordinal logistic regression to multinomial deep learning. With repeated k-fold\ncross-validation, we found that expanding the baseline predictor set\nsignificantly improved ordinal prediction performance while increasing\nanalytical complexity did not. Half of these gains could be achieved with the\naddition of 8 high-impact predictors (2 demographic variables, 4 protein\nbiomarkers, and 2 severity assessments) to the concise set. At best, ordinal\nmodels achieved 0.76 (95% CI: 0.74-0.77) ordinal discrimination ability\n(ordinal c-index) and 57% (95% CI: 54%-60%) explanation of ordinal variation in\n6-month GOSE (Somers' D). Our results motivate the search for informative\npredictors for higher GOSE and the development of ordinal dynamic prediction\nmodels.",
    "descriptor": "\nComments: 72 pages, 4 figures, 4 tables, 1 appendix, 5 supplementary figures, 4 supplementary tables, 3 supplementary methods, 1 supplementary result\n",
    "authors": [
      "Shubhayu Bhattacharyay",
      "Ioan Milosevic",
      "Lindsay Wilson",
      "David K. Menon",
      "Robert D. Stevens",
      "Ewout W. Steyerberg",
      "David W. Nelson",
      "Ari Ercole",
      "CENTER-TBI investigators",
      "participants"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.04801"
  },
  {
    "id": "arXiv:2202.04802",
    "title": "Should Storage-Centric Tariffs be Extended to Commercial Flexible  Demand?",
    "abstract": "Further electrification of the economy is expected to sharpen ramp rates and\nincrease peak loads. Flexibility from the demand side, which new technologies\nmight facilitate, can help these operational challenges. Electric utilities\nhave begun implementing new tariffs and other mechanisms to encourage the\ndeployment of energy storage. This paper examines whether making these new\ntariffs technology agnostic and extending them to flexible demand would\nsignificantly improve the procurement of operational flexibility. In\nparticular, we consider how a commercial consumer might adjust its flexible\ndemand when subject to Pacific Gas and Electric Company's storage-centric\nelectric tariff. We show that extending this tariff to consumers with flexible\ndemand would reduce the utility's net demand ramp rates during peak hours. If\nconsumers have a high level of demand flexibility, this tariff also reduces the\nnet demand during peak hours and decreases total electric bills when compared\nto the base tariff.",
    "descriptor": "\nComments: Accepted to the 2022 IEEE Power and Energy Society (PES) General Meeting. arXiv admin note: text overlap with arXiv:2105.07106\n",
    "authors": [
      "Lane D. Smith",
      "Daniel S. Kirschen"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.04802"
  },
  {
    "id": "arXiv:2202.04805",
    "title": "Understanding Hyperdimensional Computing for Parallel Single-Pass  Learning",
    "abstract": "Hyperdimensional computing (HDC) is an emerging learning paradigm that\ncomputes with high dimensional binary vectors. It is attractive because of its\nenergy efficiency and low latency, especially on emerging hardware -- but HDC\nsuffers from low model accuracy, with little theoretical understanding of what\nlimits its performance. We propose a new theoretical analysis of the limits of\nHDC via a consideration of what similarity matrices can be \"expressed\" by\nbinary vectors, and we show how the limits of HDC can be approached using\nrandom Fourier features (RFF). We extend our analysis to the more general class\nof vector symbolic architectures (VSA), which compute with high-dimensional\nvectors (hypervectors) that are not necessarily binary. We propose a new class\nof VSAs, finite group VSAs, which surpass the limits of HDC. Using\nrepresentation theory, we characterize which similarity matrices can be\n\"expressed\" by finite group VSA hypervectors, and we show how these VSAs can be\nconstructed. Experimental results show that our RFF method and group VSA can\nboth outperform the state-of-the-art HDC model by up to 7.6\\% while maintaining\nhardware efficiency.",
    "descriptor": "",
    "authors": [
      "Tao Yu",
      "Yichi Zhang",
      "Zhiru Zhang",
      "Christopher De Sa"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2202.04805"
  },
  {
    "id": "arXiv:2202.04812",
    "title": "Weakly-Supervised Semantic Segmentation with Visual Words Learning and  Hybrid Pooling",
    "abstract": "Weakly-Supervised Semantic Segmentation (WSSS) methods with image-level\nlabels generally train a classification network to generate the Class\nActivation Maps (CAMs) as the initial coarse segmentation labels. However,\ncurrent WSSS methods still perform far from satisfactorily because their\nadopted CAMs 1) typically focus on partial discriminative object regions and 2)\nusually contain useless background regions. These two problems are attributed\nto the sole image-level supervision and aggregation of global information when\ntraining the classification networks. In this work, we propose the visual words\nlearning module and hybrid pooling approach, and incorporate them in the\nclassification network to mitigate the above problems. In the visual words\nlearning module, we counter the first problem by enforcing the classification\nnetwork to learn fine-grained visual word labels so that more object extents\ncould be discovered. Specifically, the visual words are learned with a\ncodebook, which could be updated via two proposed strategies, i.e.\nlearning-based strategy and memory-bank strategy. The second drawback of CAMs\nis alleviated with the proposed hybrid pooling, which incorporates the global\naverage and local discriminative information to simultaneously ensure object\ncompleteness and reduce background regions. We evaluated our methods on PASCAL\nVOC 2012 and MS COCO 2014 datasets. Without any extra saliency prior, our\nmethod achieved 70.6% and 70.7% mIoU on the $val$ and $test$ set of PASCAL VOC\ndataset, respectively, and 36.2% mIoU on the $val$ set of MS COCO dataset,\nwhich significantly surpassed the performance of state-of-the-art WSSS methods.",
    "descriptor": "\nComments: Accepted to IJCV\n",
    "authors": [
      "Lixiang Ru",
      "Bo Du",
      "Yibing Zhan",
      "Chen Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.04812"
  },
  {
    "id": "arXiv:2202.04814",
    "title": "Royalflush Speaker Diarization System for ICASSP 2022 Multi-channel  Multi-party Meeting Transcription Challenge",
    "abstract": "This paper describes the Royalflush speaker diarization system submitted to\nthe Multi-channel Multi-party Meeting Transcription Challenge. Our system\ncomprises speech enhancement, overlapped speech detection, speaker embedding\nextraction, speaker clustering, speech separation and system fusion. In this\nsystem, we made three contributions. First, we propose an architecture of\ncombining the multi-channel and U-Net-based models, aiming at utilizing the\nbenefits of these two individual architectures, for far-field overlapped speech\ndetection. Second, in order to use overlapped speech detection model to help\nspeaker diarization, a speech separation based overlapped speech handling\napproach, in which the speaker verification technique is further applied, is\nproposed. Third, we explore three speaker embedding methods, and obtained the\nstate-of-the-art performance on the CNCeleb-E test set. With these proposals,\nour best individual system significantly reduces DER from 15.25% to 6.40%, and\nthe fusion of four systems finally achieves a DER of 6.30% on the far-field\nAlimeeting evaluation set.",
    "descriptor": "",
    "authors": [
      "Jingguang Tian",
      "Xinhui Hu",
      "Xinkang Xu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2202.04814"
  },
  {
    "id": "arXiv:2202.04816",
    "title": "Scale Estimation with Dual Quadrics for Monocular Object SLAM",
    "abstract": "The scale ambiguity problem is inherently unsolvable to monocular SLAM\nwithout the metric baseline between moving cameras. In this paper, we present a\nnovel scale estimation approach based on an object-level SLAM system. To obtain\nthe absolute scale of the reconstructed map, we derive a nonlinear optimization\nmethod to make the scaled dimensions of objects conforming to the distribution\nof their sizes in the physical world, without relying on any prior information\nof gravity direction. We adopt the dual quadric to represent objects for its\nability to fit objects compactly and accurately. In the proposed monocular\nobject-level SLAM system, dual quadrics are fastly initialized based on\nconstraints of 2-D detections and fitted oriented bounding box and are further\noptimized to provide reliable dimensions for scale estimation.",
    "descriptor": "",
    "authors": [
      "Shuangfu Song",
      "Junqiao Zhao",
      "Tiantian Feng",
      "Chen Ye",
      "Lu Xiong"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.04816"
  },
  {
    "id": "arXiv:2202.04820",
    "title": "L0Learn: A Scalable Package for Sparse Learning using L0 Regularization",
    "abstract": "We introduce L0Learn: an open-source package for sparse regression and\nclassification using L0 regularization. L0Learn implements scalable,\napproximate algorithms, based on coordinate descent and local combinatorial\noptimization. The package is built using C++ and has a user-friendly R\ninterface. Our experiments indicate that L0Learn can scale to problems with\nmillions of features, achieving competitive run times with state-of-the-art\nsparse learning packages. L0Learn is available on both CRAN and GitHub.",
    "descriptor": "",
    "authors": [
      "Hussein Hazimeh",
      "Rahul Mazumder",
      "Tim Nonet"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Mathematical Software (cs.MS)",
      "Computation (stat.CO)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.04820"
  },
  {
    "id": "arXiv:2202.04821",
    "title": "Measuring disentangled generative spatio-temporal representation",
    "abstract": "Disentangled representation learning offers useful properties such as\ndimension reduction and interpretability, which are essential to modern deep\nlearning approaches. Although deep learning techniques have been widely applied\nto spatio-temporal data mining, there has been little attention to further\ndisentangle the latent features and understanding their contribution to the\nmodel performance, particularly their mutual information and correlation across\nfeatures. In this study, we adopt two state-of-the-art disentangled\nrepresentation learning methods and apply them to three large-scale public\nspatio-temporal datasets. To evaluate their performance, we propose an internal\nevaluation metric focusing on the degree of correlations among latent variables\nof the learned representations and the prediction performance of the downstream\ntasks. Empirical results show that our modified method can learn disentangled\nrepresentations that achieve the same level of performance as existing\nstate-of-the-art ST deep learning methods in a spatio-temporal sequence\nforecasting problem. Additionally, we find that our methods can be used to\ndiscover real-world spatial-temporal semantics to describe the variables in the\nlearned representation.",
    "descriptor": "",
    "authors": [
      "Sichen Zhao",
      "Wei Shao",
      "Jeffrey Chan",
      "Flora D. Salim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.04821"
  },
  {
    "id": "arXiv:2202.04822",
    "title": "Survey on Graph Neural Network Acceleration: An Algorithmic Perspective",
    "abstract": "Graph neural networks (GNNs) have been a hot spot of recent research and are\nwidely utilized in diverse applications. However, with the use of huger data\nand deeper models, an urgent demand is unsurprisingly made to accelerate GNNs\nfor more efficient execution. In this paper, we provide a comprehensive survey\non acceleration methods for GNNs from an algorithmic perspective. We first\npresent a new taxonomy to classify existing acceleration methods into five\ncategories. Based on the classification, we systematically discuss these\nmethods and highlight their correlations. Next, we provide comparisons from\naspects of the efficiency and characteristics of these methods. Finally, we\nsuggest some promising prospects for future research.",
    "descriptor": "\nComments: 8 pages\n",
    "authors": [
      "Xin Liu",
      "Mingyu Yan",
      "Lei Deng",
      "Guoqi Li",
      "Xiaochun Ye",
      "Dongrui Fan",
      "Shirui Pan",
      "Yuan Xie"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.04822"
  },
  {
    "id": "arXiv:2202.04824",
    "title": "AdaPrompt: Adaptive Model Training for Prompt-based NLP",
    "abstract": "Prompt-based learning, with its capability to tackle zero-shot and few-shot\nNLP tasks, has gained much attention in community. The main idea is to bridge\nthe gap between NLP downstream tasks and language modeling (LM), by mapping\nthese tasks into natural language prompts, which are then filled by pre-trained\nlanguage models (PLMs). However, for prompt learning, there are still two\nsalient gaps between NLP tasks and pretraining. First, prompt information is\nnot necessarily sufficiently present during LM pretraining. Second,\ntask-specific data are not necessarily well represented during pretraining. We\naddress these two issues by proposing AdaPrompt, adaptively retrieving external\ndata for continual pretraining of PLMs by making use of both task and prompt\ncharacteristics. In addition, we make use of knowledge in Natural Language\nInference models for deriving adaptive verbalizers. Experimental results on\nfive NLP benchmarks show that AdaPrompt can improve over standard PLMs in\nfew-shot settings. In addition, in zero-shot settings, our method outperforms\nstandard prompt-based methods by up to 26.35\\% relative error reduction.",
    "descriptor": "",
    "authors": [
      "Yulong Chen",
      "Yang Liu",
      "Li Dong",
      "Shuohang Wang",
      "Chenguang Zhu",
      "Michael Zeng",
      "Yue Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.04824"
  },
  {
    "id": "arXiv:2202.04827",
    "title": "Bias-Eliminated Semantic Refinement for Any-Shot Learning",
    "abstract": "When training samples are scarce, the semantic embedding technique, ie,\ndescribing class labels with attributes, provides a condition to generate\nvisual features for unseen objects by transferring the knowledge from seen\nobjects. However, semantic descriptions are usually obtained in an external\nparadigm, such as manual annotation, resulting in weak consistency between\ndescriptions and visual features. In this paper, we refine the coarse-grained\nsemantic description for any-shot learning tasks, ie, zero-shot learning (ZSL),\ngeneralized zero-shot learning (GZSL), and few-shot learning (FSL). A new\nmodel, namely, the semantic refinement Wasserstein generative adversarial\nnetwork (SRWGAN) model, is designed with the proposed multihead representation\nand hierarchical alignment techniques. Unlike conventional methods, semantic\nrefinement is performed with the aim of identifying a bias-eliminated condition\nfor disjoint-class feature generation and is applicable in both inductive and\ntransductive settings. We extensively evaluate model performance on six\nbenchmark datasets and observe state-of-the-art results for any-shot learning;\neg, we obtain 70.2% harmonic accuracy for the Caltech UCSD Birds (CUB) dataset\nand 82.2% harmonic accuracy for the Oxford Flowers (FLO) dataset in the\nstandard GZSL setting. Various visualizations are also provided to show the\nbias-eliminated generation of SRWGAN. Our code is available.",
    "descriptor": "",
    "authors": [
      "Liangjun Feng",
      "Chunhui Zhao",
      "Xi Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.04827"
  },
  {
    "id": "arXiv:2202.04829",
    "title": "Target-aware Molecular Graph Generation",
    "abstract": "Generating molecules with desired biological activities has attracted growing\nattention in drug discovery. Previous molecular generation models are designed\nas chemocentric methods that hardly consider the drug-target interaction,\nlimiting their practical applications. In this paper, we aim to generate\nmolecular drugs in a target-aware manner that bridges biological activity and\nmolecular design. To solve this problem, we compile a benchmark dataset from\nseveral publicly available datasets and build baselines in a unified framework.\nBuilding on the recent advantages of flow-based molecular generation models, we\npropose SiamFlow, which forces the flow to fit the distribution of target\nsequence embeddings in latent space. Specifically, we employ an alignment loss\nand a uniform loss to bring target sequence embeddings and drug graph\nembeddings into agreements while avoiding collapse. Furthermore, we formulate\nthe alignment into a one-to-many problem by learning spaces of target sequence\nembeddings. Experiments quantitatively show that our proposed method learns\nmeaningful representations in the latent space toward the target-aware\nmolecular graph generation and provides an alternative approach to bridge\nbiology and chemistry in drug discovery.",
    "descriptor": "",
    "authors": [
      "Cheng Tan",
      "Zhangyang Gao",
      "Stan Z. Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.04829"
  },
  {
    "id": "arXiv:2202.04830",
    "title": "Impact of Device Thermal Performance on 5G mmWave Communication Systems",
    "abstract": "5G millimeter wave (mmWave) cellular networks have been deployed by carriers\nmostly in dense urban areas of the US, and have been reported to deliver a\nthroughput of around 1 - 2 Gbps per device. These throughput numbers are\ncaptured via speed-testing applications which run for only a few seconds at a\ntime and are not indicative of the sustained throughput obtained while\ndownloading a large volume of data that can take several minutes to complete.\nIn this paper we report the first detailed measurements in three cities, Miami,\nChicago, and San Francisco that study the impact of skin temperature, as\nmeasured by the device, on the throughput that the device is able to sustain\nover many minutes. We report results from experiments conducted on deployed 5G\nmmWave networks that show the effect of thermal throttling on a 5G mmWave\ncommunication link when a large file download is initiated that saturates the\nlink, i.e., the device is connected to 4 mmWave downlink channels each 100 MHz\nwide. We observe a gradual increase of skin temperature within 1-2 minutes\nwhich correlates to a decrease in the data rate due to the number of aggregated\nmmWave channels reducing from 4 to 1 before finally switching to 4G LTE.\nFinally, we identify messaging in the Radio Resource Control (RRC) layer\nconfirming that the reduction in throughput was due to throttling due to the\nskin temperature rise and further demonstrate that cooling the device restores\nthroughput performance. These results are extremely important since they\nindicate that the Gbps throughput deliverable by 5G mmWave to an end-user 5G\ndevice will be limited not by network characteristics but by device thermal\nmanagement.",
    "descriptor": "",
    "authors": [
      "Muhammad Iqbal Rochman",
      "Damian Fernandez",
      "Norlen Nunez",
      "Vanlin Sathya",
      "Ahmed S. Ibrahim",
      "Monisha Ghosh",
      "William Payne"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2202.04830"
  },
  {
    "id": "arXiv:2202.04834",
    "title": "Geometric Digital Twinning of Industrial Facilities: Retrieval of  Industrial Shapes",
    "abstract": "This paper devises, implements and benchmarks a novel shape retrieval method\nthat can accurately match individual labelled point clusters (instances) of\nexisting industrial facilities with their respective CAD models. It employs a\ncombination of image and point cloud deep learning networks to classify and\nmatch instances to their geometrically similar CAD model. It extends our\nprevious research on geometric digital twin generation from point cloud data,\nwhich currently is a tedious, manual process. Experiments with our joint\nnetwork reveal that it can reliably retrieve CAD models at 85.2\\% accuracy. The\nproposed research is a fundamental framework to enable the geometric Digital\nTwin (gDT) pipeline and incorporate the real geometric configuration into the\nDigital Twin.",
    "descriptor": "",
    "authors": [
      "Eva Agapaki",
      "Ioannis Brilakis"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.04834"
  },
  {
    "id": "arXiv:2202.04836",
    "title": "Deconstructing The Inductive Biases Of Hamiltonian Neural Networks",
    "abstract": "Physics-inspired neural networks (NNs), such as Hamiltonian or Lagrangian\nNNs, dramatically outperform other learned dynamics models by leveraging strong\ninductive biases. These models, however, are challenging to apply to many real\nworld systems, such as those that don't conserve energy or contain contacts, a\ncommon setting for robotics and reinforcement learning. In this paper, we\nexamine the inductive biases that make physics-inspired models successful in\npractice. We show that, contrary to conventional wisdom, the improved\ngeneralization of HNNs is the result of modeling acceleration directly and\navoiding artificial complexity from the coordinate system, rather than\nsymplectic structure or energy conservation. We show that by relaxing the\ninductive biases of these models, we can match or exceed performance on\nenergy-conserving systems while dramatically improving performance on\npractical, non-conservative systems. We extend this approach to constructing\ntransition models for common Mujoco environments, showing that our model can\nappropriately balance inductive biases with the flexibility required for\nmodel-based control.",
    "descriptor": "\nComments: ICLR 2022. Code available at this https URL\n",
    "authors": [
      "Nate Gruver",
      "Marc Finzi",
      "Samuel Stanton",
      "Andrew Gordon Wilson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)",
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.04836"
  },
  {
    "id": "arXiv:2202.04841",
    "title": "Collaborative analysis of genomic data: vision and challenges",
    "abstract": "The cost of DNA sequencing has resulted in a surge of genetic data being\nutilised to improve scientific research, clinical procedures, and healthcare\ndelivery in recent years. Since the human genome can uniquely identify an\nindividual, this characteristic also raises security and privacy concerns. In\norder to balance the risks and benefits, governance mechanisms including\nregulatory and ethical controls have been established, which are prone to human\nerrors and create hindrance for collaboration. Over the past decade,\ntechnological methods are also catching up that can support critical\ndiscoveries responsibly. In this paper, we explore regulations and ethical\nguidelines and propose our visions of secure/private genomic data\nstorage/processing/sharing platforms. Then, we present some available\ntechniques and a conceptual system model that can support our visions. Finally,\nwe highlight the open issues that need further investigation.",
    "descriptor": "\nComments: This is an accepted paper and it is going to appear in the Proceedings of the 2021 IEEE International Conference on Collaboration and Internet Computing (CIC 2021)\n",
    "authors": [
      "Sara Jafarbeiki",
      "Raj Gaire",
      "Amin Sakzad",
      "Shabnam Kasra Kermanshahi",
      "Ron Steinfeld"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2202.04841"
  },
  {
    "id": "arXiv:2202.04842",
    "title": "Networks and Identity Drive Geographic Properties of the Diffusion of  Linguistic Innovation",
    "abstract": "Adoption of cultural innovation (e.g., music, beliefs, language) is often\ngeographically correlated, with adopters largely residing within the boundaries\nof relatively few well-studied, socially significant areas. These cultural\nregions are often hypothesized to be the result of either (i) identity\nperformance driving the adoption of cultural innovation, or (ii) homophily in\nthe networks underlying diffusion. In this study, we show that demographic\nidentity and network topology are both required to model the diffusion of\ninnovation, as they play complementary roles in producing its spatial\nproperties. We develop an agent-based model of cultural adoption, and validate\ngeographic patterns of transmission in our model against a novel dataset of\ninnovative words that we identify from a 10% sample of Twitter. Using our\nmodel, we are able to directly compare a combined network + identity model of\ndiffusion to simulated network-only and identity-only counterfactuals --\nallowing us to test the separate and combined roles of network and identity.\nWhile social scientists often treat either network or identity as the core\nsocial structure in modeling culture change, we show that key geographic\nproperties of diffusion actually depend on both factors as each one influences\ndifferent mechanisms of diffusion. Specifically, the network principally drives\nspread among urban counties via weak-tie diffusion, while identity plays a\ndisproportionate role in transmission among rural counties via strong-tie\ndiffusion. Diffusion between urban and rural areas, a key component in\ninnovation diffusing nationally, requires both network and identity. Our work\nsuggests that models must integrate both factors in order to understand and\nreproduce the adoption of innovation.",
    "descriptor": "",
    "authors": [
      "Aparna Ananthasubramaniam",
      "David Jurgens",
      "Daniel M. Romero"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2202.04842"
  },
  {
    "id": "arXiv:2202.04843",
    "title": "A Stieltjes algorithm for generating multivariate orthogonal polynomials",
    "abstract": "Orthogonal polynomials of several variables have a vector-valued three-term\nrecurrence relation, much like the corresponding one-dimensional relation. This\nrelation requires only knowledge of certain recurrence matrices, and allows\nsimple and stable evaluation of multivariate orthogonal polynomials. In the\nunivariate case, various algorithms can evaluate the recurrence coefficients\ngiven the ability to compute polynomial moments, but such a procedure is absent\nin multiple dimensions. We present a new Multivariate Stieltjes (MS) algorithm\nthat fills this gap in the multivariate case, allowing computation of\nrecurrence matrices assuming moments are available. The algorithm is\nessentially explicit in two and three dimensions, but requires the numerical\nsolution to a non-convex problem in more than three dimensions. Compared to\ndirect Gram-Schmidt-type orthogonalization, we demonstrate on several examples\nin up to three dimensions that the MS algorithm is far more stable, and allows\naccurate computation of orthogonal bases in the multivariate setting, in\ncontrast to direct orthogonalization approaches.",
    "descriptor": "\nComments: 24 pages, 8 figures\n",
    "authors": [
      "Zexin Liu",
      "Akil Narayan"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.04843"
  },
  {
    "id": "arXiv:2202.04844",
    "title": "Multi-relation Message Passing for Multi-label Text Classification",
    "abstract": "A well-known challenge associated with the multi-label classification problem\nis modelling dependencies between labels. Most attempts at modelling label\ndependencies focus on co-occurrences, ignoring the valuable information that\ncan be extracted by detecting label subsets that rarely occur together. For\nexample, consider customer product reviews; a product probably would not\nsimultaneously be tagged by both \"recommended\" (i.e., reviewer is happy and\nrecommends the product) and \"urgent\" (i.e., the review suggests immediate\naction to remedy an unsatisfactory experience). Aside from the consideration of\npositive and negative dependencies, the direction of a relationship should also\nbe considered. For a multi-label image classification problem, the \"ship\" and\n\"sea\" labels have an obvious dependency, but the presence of the former implies\nthe latter much more strongly than the other way around. These examples\nmotivate the modelling of multiple types of bi-directional relationships\nbetween labels. In this paper, we propose a novel method, entitled\nMulti-relation Message Passing (MrMP), for the multi-label classification\nproblem. Experiments on benchmark multi-label text classification datasets show\nthat the MrMP module yields similar or superior performance compared to\nstate-of-the-art methods. The approach imposes only minor additional\ncomputational and memory overheads.",
    "descriptor": "",
    "authors": [
      "Muberra Ozmen",
      "Hao Zhang",
      "Pengyun Wang",
      "Mark Coates"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.04844"
  },
  {
    "id": "arXiv:2202.04847",
    "title": "A Survey on Artificial Intelligence for Source Code: A Dialogue Systems  Perspective",
    "abstract": "In this survey paper, we overview major deep learning methods used in Natural\nLanguage Processing (NLP) and source code over the last 35 years. Next, we\npresent a survey of the applications of Artificial Intelligence (AI) for source\ncode, also known as Code Intelligence (CI) and Programming Language Processing\n(PLP). We survey over 287 publications and present a software-engineering\ncentered taxonomy for CI placing each of the works into one category describing\nhow it best assists the software development cycle. Then, we overview the field\nof conversational assistants and their applications in software engineering and\neducation. Lastly, we highlight research opportunities at the intersection of\nAI for code and conversational assistants and provide future directions for\nresearching conversational assistants with CI capabilities.",
    "descriptor": "\nComments: 55 pages, 16 Figures, 4 Tables\n",
    "authors": [
      "Erfan Al-Hossami",
      "Samira Shaikh"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2202.04847"
  },
  {
    "id": "arXiv:2202.04849",
    "title": "SAFER: Data-Efficient and Safe Reinforcement Learning via Skill  Acquisition",
    "abstract": "Though many reinforcement learning (RL) problems involve learning policies in\nsettings with difficult-to-specify safety constraints and sparse rewards,\ncurrent methods struggle to acquire successful and safe policies. Methods that\nextract useful policy primitives from offline datasets using generative\nmodeling have recently shown promise at accelerating RL in these more complex\nsettings. However, we discover that current primitive-learning methods may not\nbe well-equipped for safe policy learning and may promote unsafe behavior due\nto their tendency to ignore data from undesirable behaviors. To overcome these\nissues, we propose SAFEty skill pRiors (SAFER), an algorithm that accelerates\npolicy learning on complex control tasks under safety constraints. Through\nprincipled training on an offline dataset, SAFER learns to extract safe\nprimitive skills. In the inference stage, policies trained with SAFER learn to\ncompose safe skills into successful policies. We theoretically characterize why\nSAFER can enforce safe policy learning and demonstrate its effectiveness on\nseveral complex safety-critical robotic grasping tasks inspired by the game\nOperation, in which SAFER outperforms baseline methods in learning successful\npolicies and enforcing safety.",
    "descriptor": "",
    "authors": [
      "Dylan Slack",
      "Yinlam Chow",
      "Bo Dai",
      "Nevan Wichers"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.04849"
  },
  {
    "id": "arXiv:2202.04856",
    "title": "PPA: Preference Profiling Attack Against Federated Learning",
    "abstract": "Federated learning (FL) trains a global model across a number of\ndecentralized participants, each with a local dataset. Compared to traditional\ncentralized learning, FL does not require direct local datasets access and thus\nmitigates data security and privacy concerns. However, data privacy concerns\nfor FL still exist due to inference attacks, including known membership\ninference, property inference, and data inversion.\nIn this work, we reveal a new type of privacy inference attack, coined\nPreference Profiling Attack (PPA), that accurately profiles private preferences\nof a local user. In general, the PPA can profile top-k, especially for top-1,\npreferences contingent on the local user's characteristics. Our key insight is\nthat the gradient variation of a local user's model has a distinguishable\nsensitivity to the sample proportion of a given class, especially the\nmajority/minority class. By observing a user model's gradient sensitivity to a\nclass, the PPA can profile the sample proportion of the class in the user's\nlocal dataset and thus the user's preference of the class is exposed. The\ninherent statistical heterogeneity of FL further facilitates the PPA. We have\nextensively evaluated the PPA's effectiveness using four datasets from the\nimage domains of MNIST, CIFAR10, Products-10K and RAF-DB. Our results show that\nthe PPA achieves 90% and 98% top-1 attack accuracy to the MNIST and CIFAR10,\nrespectively. More importantly, in the real-world commercial scenarios of\nshopping (i.e., Products-10K) and the social network (i.e., RAF-DB), the PPA\ngains a top-1 attack accuracy of 78% in the former case to infer the most\nordered items, and 88% in the latter case to infer a victim user's emotions.\nAlthough existing countermeasures such as dropout and differential privacy\nprotection can lower the PPA's accuracy to some extent, they unavoidably incur\nnotable global model deterioration.",
    "descriptor": "",
    "authors": [
      "Chunyi Zhou",
      "Yansong Gao",
      "Anmin Fu",
      "Kai Chen",
      "Zhiyang Dai",
      "Zhi Zhang",
      "Minhui Xue",
      "Yuqing Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.04856"
  },
  {
    "id": "arXiv:2202.04861",
    "title": "Consistency and Diversity induced Human Motion Segmentation",
    "abstract": "Subspace clustering is a classical technique that has been widely used for\nhuman motion segmentation and other related tasks. However, existing\nsegmentation methods often cluster data without guidance from prior knowledge,\nresulting in unsatisfactory segmentation results. To this end, we propose a\nnovel Consistency and Diversity induced human Motion Segmentation (CDMS)\nalgorithm. Specifically, our model factorizes the source and target data into\ndistinct multi-layer feature spaces, in which transfer subspace learning is\nconducted on different layers to capture multi-level information. A\nmulti-mutual consistency learning strategy is carried out to reduce the domain\ngap between the source and target data. In this way, the domain-specific\nknowledge and domain-invariant properties can be explored simultaneously.\nBesides, a novel constraint based on the Hilbert Schmidt Independence Criterion\n(HSIC) is introduced to ensure the diversity of multi-level subspace\nrepresentations, which enables the complementarity of multi-level\nrepresentations to be explored to boost the transfer learning performance.\nMoreover, to preserve the temporal correlations, an enhanced graph regularizer\nis imposed on the learned representation coefficients and the multi-level\nrepresentations of the source data. The proposed model can be efficiently\nsolved using the Alternating Direction Method of Multipliers (ADMM) algorithm.\nExtensive experimental results on public human motion datasets demonstrate the\neffectiveness of our method against several state-of-the-art approaches.",
    "descriptor": "\nComments: This paper has been accepted by IEEE TPAMI\n",
    "authors": [
      "Tao Zhou",
      "Huazhu Fu",
      "Chen Gong",
      "Ling Shao",
      "Fatih Porikli",
      "Haibin Ling",
      "Jianbing Shen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.04861"
  },
  {
    "id": "arXiv:2202.04868",
    "title": "Understanding Value Decomposition Algorithms in Deep Cooperative  Multi-Agent Reinforcement Learning",
    "abstract": "Value function decomposition is becoming a popular rule of thumb for scaling\nup multi-agent reinforcement learning (MARL) in cooperative games. For such a\ndecomposition rule to hold, the assumption of the individual-global max (IGM)\nprinciple must be made; that is, the local maxima on the decomposed value\nfunction per every agent must amount to the global maximum on the joint value\nfunction. This principle, however, does not have to hold in general. As a\nresult, the applicability of value decomposition algorithms is concealed and\ntheir corresponding convergence properties remain unknown. In this paper, we\nmake the first effort to answer these questions. Specifically, we introduce the\nset of cooperative games in which the value decomposition methods find their\nvalidity, which is referred as decomposable games. In decomposable games, we\ntheoretically prove that applying the multi-agent fitted Q-Iteration algorithm\n(MA-FQI) will lead to an optimal Q-function. In non-decomposable games, the\nestimated Q-function by MA-FQI can still converge to the optimum under the\ncircumstance that the Q-function needs projecting into the decomposable\nfunction space at each iteration. In both settings, we consider value function\nrepresentations by practical deep neural networks and derive their\ncorresponding convergence rates. To summarize, our results, for the first time,\noffer theoretical insights for MARL practitioners in terms of when value\ndecomposition algorithms converge and why they perform well.",
    "descriptor": "",
    "authors": [
      "Zehao Dou",
      "Jakub Grudzien Kuba",
      "Yaodong Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.04868"
  },
  {
    "id": "arXiv:2202.04870",
    "title": "Online Learning for Min Sum Set Cover and Pandora's Box",
    "abstract": "Two central problems in Stochastic Optimization are Min Sum Set Cover and\nPandora's Box. In Pandora's Box, we are presented with n boxes, each containing\nan unknown value and the goal is to open the boxes in some order to minimize\nthe sum of the search cost and the smallest value found. Given a distribution\nof value vectors, we are asked to identify a near-optimal search order. Min Sum\nSet Cover corresponds to the case where values are either 0 or infinity. In\nthis work, we study the case where the value vectors are not drawn from a\ndistribution but are presented to a learner in an online fashion. We present a\ncomputationally efficient algorithm that is constant-competitive against the\ncost of the optimal search order. We extend our results to a bandit setting\nwhere only the values of the boxes opened are revealed to the learner after\nevery round. We also generalize our results to other commonly studied variants\nof Pandora's Box and Min Sum Set Cover that involve selecting more than a\nsingle value subject to a matroid constraint.",
    "descriptor": "",
    "authors": [
      "Evangelia Gergatsouli",
      "Christos Tzamos"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.04870"
  },
  {
    "id": "arXiv:2202.04872",
    "title": "A Note on the Misinterpretation of the US Census Re-identification  Attack",
    "abstract": "In 2018, the US Census Bureau designed a new data reconstruction and\nre-identification attack and tested it against their 2010 data release. The\nspecific attack executed by the Bureau allows an attacker to infer the race and\nethnicity of respondents with average 75% precision for 85% of the respondents,\nassuming that the attacker knows the correct age, sex, and address of the\nrespondents. They interpreted the attack as exceeding the Bureau's privacy\nstandards, and so introduced stronger privacy protections for the 2020 Census\nin the form of the TopDown Algorithm (TDA).\nThis paper demonstrates that race and ethnicity can be inferred from the\nTDA-protected census data with substantially better precision and recall, using\nless prior knowledge: only the respondents' address. Race and ethnicity can be\ninferred with average 75% precision for 98% of the respondents, and can be\ninferred with 100% precision for 11% of the respondents. The inference is done\nby simply assuming that the race/ethnicity of the respondent is that of the\nmajority race/ethnicity for the respondent's census block.\nThe conclusion to draw from this simple demonstration is NOT that the\nBureau's data releases lack adequate privacy protections. Indeed it is the\npurpose of the data releases to allow this kind of inference. The problem,\nrather, is that the Bureau's criteria for measuring privacy is flawed and\noverly pessimistic.",
    "descriptor": "",
    "authors": [
      "Paul Francis"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.04872"
  },
  {
    "id": "arXiv:2202.04876",
    "title": "Distilling Hypernymy Relations from Language Models: On the  Effectiveness of Zero-Shot Taxonomy Induction",
    "abstract": "In this paper, we analyze zero-shot taxonomy learning methods which are based\non distilling knowledge from language models via prompting and sentence\nscoring. We show that, despite their simplicity, these methods outperform some\nsupervised strategies and are competitive with the current state-of-the-art\nunder adequate conditions. We also show that statistical and linguistic\nproperties of prompts dictate downstream performance.",
    "descriptor": "",
    "authors": [
      "Devansh Jain",
      "Luis Espinosa Anke"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.04876"
  },
  {
    "id": "arXiv:2202.04877",
    "title": "Memory-based gaze prediction in deep imitation learning for robot  manipulation",
    "abstract": "Deep imitation learning is a promising approach that does not require\nhard-coded control rules in autonomous robot manipulation. The current\napplications of deep imitation learning to robot manipulation have been limited\nto reactive control based on the states at the current time step. However,\nfuture robots will also be required to solve tasks utilizing their memory\nobtained by experience in complicated environments (e.g., when the robot is\nasked to find a previously used object on a shelf). In such a situation, simple\ndeep imitation learning may fail because of distractions caused by complicated\nenvironments. We propose that gaze prediction from sequential visual input\nenables the robot to perform a manipulation task that requires memory. The\nproposed algorithm uses a Transformer-based self-attention architecture for the\ngaze estimation based on sequential data to implement memory. The proposed\nmethod was evaluated with a real robot multi-object manipulation task that\nrequires memory of the previous states.",
    "descriptor": "\nComments: 7 pages. Accepted in 2022 IEEE/RSJ International Conference on Robotics and Automation (ICRA)\n",
    "authors": [
      "Heecheol Kim",
      "Yoshiyuki Ohmura",
      "Yasuo Kuniyoshi"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.04877"
  },
  {
    "id": "arXiv:2202.04878",
    "title": "Space-Time Adaptive Processing Using Random Matrix Theory Under Limited  Training Samples",
    "abstract": "Space-time adaptive processing (STAP) is one of the most effective approaches\nto suppressing ground clutters in airborne radar systems. It basically takes\ntwo forms, i.e., full-dimension STAP (FD-STAP) and reduced-dimension STAP\n(RD-STAP). When the numbers of clutter training samples are less than two times\ntheir respective system degrees-of-freedom (DOF), the performances of both\nFD-STAP and RD-STAP degrade severely due to inaccurate clutter estimation. To\nenhance STAP performance under the limited training samples, this paper\ndevelops a STAP theory with random matrix theory (RMT). By minimizing the\noutput clutter-plus-noise power, the estimate of the inversion of clutter plus\nnoise covariance matrix (CNCM) can be obtained through optimally manipulating\nits eigenvalues, and thus producing the optimal STAP weight vector. Two STAP\nalgorithms, FD-STAP using RMT (RMT-FD-STAP) and RD-STAP using RMT\n(RMT-RD-STAP), are proposed. It is found that both RMT-FD-STAP and RMT-RD-STAP\ngreatly outperform other-related STAP algorithms when the numbers of training\nsamples are larger than their respective clutter DOFs, which are much less than\nthe corresponding system DOFs. Theoretical analyses and simulation demonstrate\nthe effectiveness and the performance advantages of the proposed STAP\nalgorithms.",
    "descriptor": "\nComments: 24 pages, 5 figures\n",
    "authors": [
      "Di Song",
      "Shengyao Chen",
      "Feng Xi",
      "Zhong Liu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.04878"
  },
  {
    "id": "arXiv:2202.04879",
    "title": "PVSeRF: Joint Pixel-, Voxel- and Surface-Aligned Radiance Field for  Single-Image Novel View Synthesis",
    "abstract": "We present PVSeRF, a learning framework that reconstructs neural radiance\nfields from single-view RGB images, for novel view synthesis. Previous\nsolutions, such as pixelNeRF, rely only on pixel-aligned features and suffer\nfrom feature ambiguity issues. As a result, they struggle with the\ndisentanglement of geometry and appearance, leading to implausible geometries\nand blurry results. To address this challenge, we propose to incorporate\nexplicit geometry reasoning and combine it with pixel-aligned features for\nradiance field prediction. Specifically, in addition to pixel-aligned features,\nwe further constrain the radiance field learning to be conditioned on i)\nvoxel-aligned features learned from a coarse volumetric grid and ii) fine\nsurface-aligned features extracted from a regressed point cloud. We show that\nthe introduction of such geometry-aware features helps to achieve a better\ndisentanglement between appearance and geometry, i.e. recovering more accurate\ngeometries and synthesizing higher quality images of novel views. Extensive\nexperiments against state-of-the-art methods on ShapeNet benchmarks demonstrate\nthe superiority of our approach for single-image novel view synthesis.",
    "descriptor": "",
    "authors": [
      "Xianggang Yu",
      "Jiapeng Tang",
      "Yipeng Qin",
      "Chenghong Li",
      "Linchao Bao",
      "Xiaoguang Han",
      "Shuguang Cui"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.04879"
  },
  {
    "id": "arXiv:2202.04882",
    "title": "Auditory Model based Phase-Aware Bayesian Spectral Amplitude Estimator  for Single-Channel Speech Enhancement",
    "abstract": "Bayesian estimation of short-time spectral amplitude is one of the most\npredominant approaches for the enhancement of the noise corrupted speech. The\nperformance of these estimators are usually significantly improved when any\nperceptually relevant cost function is considered. On the other hand, the\nrecent progress in the phase-based speech signal processing have shown that the\nphase-only enhancement based on spectral phase estimation methods can also\nprovide joint improvement in the perceived speech quality and intelligibility,\neven in low SNR conditions. In this paper, to take advantage of both the\nperceptually motivated cost function involving STSAs of estimated and true\nclean speech and utilizing the prior spectral phase information, we have\nderived a phase-aware Bayesian STSA estimator. The parameters of the cost\nfunction are chosen based on the characteristics of the human auditory system,\nnamely, the dynamic compressive nonlinearity of the cochlea, the perceived\nloudness theory and the simultaneous masking properties of the ear. This type\nof parameter selection scheme results in more noise reduction while limiting\nthe speech distortion. The derived STSA estimator is optimal in the MMSE sense\nif the prior phase information is available. In practice, however, typically\nonly an estimate of the clean speech phase can be obtained via employing\ndifferent types of spectral phase estimation techniques which have been\ndeveloped throughout the last few years. In a blind setup, we have evaluated\nthe proposed Bayesian STSA estimator with different types of standard phase\nestimation methods available in the literature. Experimental results have shown\nthat the proposed estimator can achieve substantial improvement in performance\nthan the traditional phase-blind approaches.",
    "descriptor": "\nComments: Submitted to IEEE\n",
    "authors": [
      "Suman Samui",
      "Indrajit Chakrabarti",
      "Soumya K. Ghosh"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2202.04882"
  },
  {
    "id": "arXiv:2202.04883",
    "title": "Towards the automated large-scale reconstruction of past road networks  from historical maps",
    "abstract": "Transportation infrastructure, such as road or railroad networks, represent a\nfundamental component of our civilization. For sustainable planning and\ninformed decision making, a thorough understanding of the long-term evolution\nof transportation infrastructure such as road networks is crucial. However,\nspatially explicit, multi-temporal road network data covering large spatial\nextents are scarce and rarely available prior to the 2000s. Herein, we propose\na framework that employs increasingly available scanned and georeferenced\nhistorical map series to reconstruct past road networks, by integrating\nabundant, contemporary road network data and color information extracted from\nhistorical maps. Specifically, our method uses contemporary road segments as\nanalytical units and extracts historical roads by inferring their existence in\nhistorical map series based on image processing and clustering techniques. We\ntested our method on over 300,000 road segments representing more than 50,000\nkm of the road network in the United States, extending across three study areas\nthat cover 53 historical topographic map sheets dated between 1890 and 1950. We\nevaluated our approach by comparison to other historical datasets and against\nmanually created reference data, achieving F-1 scores of up to 0.95, and showed\nthat the extracted road network statistics are highly plausible over time,\ni.e., following general growth patterns. We demonstrated that contemporary\ngeospatial data integrated with information extracted from historical map\nseries open up new avenues for the quantitative analysis of long-term\nurbanization processes and landscape changes far beyond the era of operational\nremote sensing and digital cartography.",
    "descriptor": "",
    "authors": [
      "Johannes H. Uhl",
      "Stefan Leyk",
      "Yao-Yi Chiang",
      "Craig A. Knoblock"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2202.04883"
  },
  {
    "id": "arXiv:2202.04887",
    "title": "TaxoEnrich: Self-Supervised Taxonomy Completion via Structure-Semantic  Representations",
    "abstract": "Taxonomies are fundamental to many real-world applications in various\ndomains, serving as structural representations of knowledge. To deal with the\nincreasing volume of new concepts needed to be organized as taxonomies,\nresearchers turn to automatically completion of an existing taxonomy with new\nconcepts. In this paper, we propose TaxoEnrich, a new taxonomy completion\nframework, which effectively leverages both semantic features and structural\ninformation in the existing taxonomy and offers a better representation of\ncandidate position to boost the performance of taxonomy completion.\nSpecifically, TaxoEnrich consists of four components: (1)\ntaxonomy-contextualized embedding which incorporates both semantic meanings of\nconcept and taxonomic relations based on powerful pretrained language models;\n(2) a taxonomy-aware sequential encoder which learns candidate position\nrepresentations by encoding the structural information of taxonomy; (3) a\nquery-aware sibling encoder which adaptively aggregates candidate siblings to\naugment candidate position representations based on their importance to the\nquery-position matching; (4) a query-position matching model which extends\nexisting work with our new candidate position representations. Extensive\nexperiments on four large real-world datasets from different domains show that\n\\TaxoEnrich achieves the best performance among all evaluation metrics and\noutperforms previous state-of-the-art methods by a large margin.",
    "descriptor": "\nComments: WWW 2022\n",
    "authors": [
      "Minhao Jiang",
      "Xiangchen Song",
      "Jieyu Zhang",
      "Jiawei Han"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2202.04887"
  },
  {
    "id": "arXiv:2202.04890",
    "title": "Improving performance of aircraft detection in satellite imagery while  limiting the labelling effort: Hybrid active learning",
    "abstract": "The earth observation industry provides satellite imagery with high spatial\nresolution and short revisit time. To allow efficient operational employment of\nthese images, automating certain tasks has become necessary. In the defense\ndomain, aircraft detection on satellite imagery is a valuable tool for\nanalysts. Obtaining high performance detectors on such a task can only be\nachieved by leveraging deep learning and thus us-ing a large amount of labeled\ndata. To obtain labels of a high enough quality, the knowledge of military\nexperts is needed.We propose a hybrid clustering active learning method to\nselect the most relevant data to label, thus limiting the amount of data\nrequired and further improving the performances. It combines diversity- and\nuncertainty-based active learning selection methods. For aircraft detection by\nsegmentation, we show that this method can provide better or competitive\nresults compared to other active learning methods.",
    "descriptor": "",
    "authors": [
      "Julie Imbert",
      "Gohar Dashyan",
      "Alex Goupilleau",
      "Tugdual Ceillier",
      "Marie-Caroline Corbineau"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2202.04890"
  },
  {
    "id": "arXiv:2202.04891",
    "title": "Case-based reasoning for rare events prediction on strategic sites",
    "abstract": "Satellite imagery is now widely used in the defense sector for monitoring\nlocations of interest. Although the increasing amount of data enables pattern\nidentification and therefore prediction, carrying this task manually is hardly\nfeasible. We hereby propose a cased-based reasoning approach for automatic\nprediction of rare events on strategic sites. This method allows direct\nincorporation of expert knowledge, and is adapted to irregular time series and\nsmall-size datasets. Experiments are carried out on two use-cases using real\nsatellite images: the prediction of submarines arrivals and departures from a\nnaval base, and the forecasting of imminent rocket launches on two space bases.\nThe proposed method significantly outperforms a random selection of reference\ncases on these challenging applications, showing its strong potential.",
    "descriptor": "",
    "authors": [
      "Vincent Vidal",
      "Marie-Caroline Corbineau",
      "Tugdual Ceillier"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.04891"
  },
  {
    "id": "arXiv:2202.04893",
    "title": "Differential Private Knowledge Transfer for Privacy-Preserving  Cross-Domain Recommendation",
    "abstract": "Cross Domain Recommendation (CDR) has been popularly studied to alleviate the\ncold-start and data sparsity problem commonly existed in recommender systems.\nCDR models can improve the recommendation performance of a target domain by\nleveraging the data of other source domains. However, most existing CDR models\nassume information can directly 'transfer across the bridge', ignoring the\nprivacy issues. To solve the privacy concern in CDR, in this paper, we propose\na novel two stage based privacy-preserving CDR framework (PriCDR). In the first\nstage, we propose two methods, i.e., Johnson-Lindenstrauss Transform (JLT)\nbased and Sparse-awareJLT (SJLT) based, to publish the rating matrix of the\nsource domain using differential privacy. We theoretically analyze the privacy\nand utility of our proposed differential privacy based rating publishing\nmethods. In the second stage, we propose a novel heterogeneous CDR model\n(HeteroCDR), which uses deep auto-encoder and deep neural network to model the\npublished source rating matrix and target rating matrix respectively. To this\nend, PriCDR can not only protect the data privacy of the source domain, but\nalso alleviate the data sparsity of the source domain. We conduct experiments\non two benchmark datasets and the results demonstrate the effectiveness of our\nproposed PriCDR and HeteroCDR.",
    "descriptor": "\nComments: Accepted by TheWebConf'22 (WWW'22)\n",
    "authors": [
      "Chaochao Chen",
      "Huiwen Wu",
      "Jiajie Su",
      "Lingjuan Lyu",
      "Xiaolin Zheng",
      "Li Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.04893"
  },
  {
    "id": "arXiv:2202.04894",
    "title": "A Directional Equispaced interpolation-based Fast Multipole Method for  oscillatory kernels",
    "abstract": "Fast Multipole Methods (FMMs) based on the oscillatory Helmholtz kernel can\nreduce the cost of solving N-body problems arising from Boundary Integral\nEquations (BIEs) in acoustic or electromagnetics. However, their cost strongly\nincreases in the high-frequency regime. This paper introduces a new directional\nFMM for oscillatory kernels (defmm - directional equispaced interpolation-based\nfmm), whose precomputation and application are FFT-accelerated due to\npolynomial interpolations on equispaced grids. We demonstrate the consistency\nof our FFT approach, and show how symmetries can be exploited in the Fourier\ndomain. We also describe the algorithmic design of defmm, well-suited for the\nBIE non-uniform particle distributions, and present performance optimizations\non one CPU core. Finally, we exhibit important performance gains on all test\ncases for defmm over a state-of-the-art FMM library for oscillatory kernels.",
    "descriptor": "",
    "authors": [
      "Igor Chollet",
      "Xavier Claeys",
      "Pierre Fortin",
      "Laura Grigori"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.04894"
  },
  {
    "id": "arXiv:2202.04897",
    "title": "InterHT: Knowledge Graph Embeddings by Interaction between Head and Tail  Entities",
    "abstract": "Knowledge graph embedding (KGE) models learn the representation of entities\nand relations in knowledge graphs. Distance-based methods show promising\nperformance on link prediction task, which predicts the result by the distance\nbetween two entity representations. However, most of these methods represent\nthe head entity and tail entity separately, which limits the model capacity. We\npropose a novel distance-based method named InterHT that allows the head and\ntail entities to interact better and get better entity representation.\nExperimental results show that our proposed method achieves the best results on\nogbl-wikikg2 dataset.",
    "descriptor": "",
    "authors": [
      "Baoxin Wang",
      "Qingye Meng",
      "Ziyue Wang",
      "Dayong Wu",
      "Wanxiang Che",
      "Shijin Wang",
      "Zhigang Chen",
      "Cong Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.04897"
  },
  {
    "id": "arXiv:2202.04901",
    "title": "FILM: Frame Interpolation for Large Motion",
    "abstract": "We present a frame interpolation algorithm that synthesizes multiple\nintermediate frames from two input images with large in-between motion. Recent\nmethods use multiple networks to estimate optical flow or depth and a separate\nnetwork dedicated to frame synthesis. This is often complex and requires scarce\noptical flow or depth ground-truth. In this work, we present a single unified\nnetwork, distinguished by a multi-scale feature extractor that shares weights\nat all scales, and is trainable from frames alone. To synthesize crisp and\npleasing frames, we propose to optimize our network with the Gram matrix loss\nthat measures the correlation difference between feature maps. Our approach\noutperforms state-of-the-art methods on the Xiph large motion benchmark. We\nalso achieve higher scores on Vimeo-90K, Middlebury and UCF101, when comparing\nto methods that use perceptual losses. We study the effect of weight sharing\nand of training with datasets of increasing motion range. Finally, we\ndemonstrate our model's effectiveness in synthesizing high quality and\ntemporally coherent videos on a challenging near-duplicate photos dataset.\nCodes and pre-trained models are available at\nhttps://github.com/google-research/frame-interpolation.",
    "descriptor": "\nComments: Codes and pre-trained models can be found at this https URL\n",
    "authors": [
      "Fitsum Reda",
      "Janne Kontkanen",
      "Eric Tabellion",
      "Deqing Sun",
      "Caroline Pantofaru",
      "Brian Curless"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.04901"
  },
  {
    "id": "arXiv:2202.04903",
    "title": "Investigating Explainability of Generative AI for Code through  Scenario-based Design",
    "abstract": "What does it mean for a generative AI model to be explainable? The emergent\ndiscipline of explainable AI (XAI) has made great strides in helping people\nunderstand discriminative models. Less attention has been paid to generative\nmodels that produce artifacts, rather than decisions, as output. Meanwhile,\ngenerative AI (GenAI) technologies are maturing and being applied to\napplication domains such as software engineering. Using scenario-based design\nand question-driven XAI design approaches, we explore users' explainability\nneeds for GenAI in three software engineering use cases: natural language to\ncode, code translation, and code auto-completion. We conducted 9 workshops with\n43 software engineers in which real examples from state-of-the-art generative\nAI models were used to elicit users' explainability needs. Drawing from prior\nwork, we also propose 4 types of XAI features for GenAI for code and gathered\nadditional design ideas from participants. Our work explores explainability\nneeds for GenAI for code and demonstrates how human-centered approaches can\ndrive the technical development of XAI in novel domains.",
    "descriptor": "",
    "authors": [
      "Jiao Sun",
      "Q. Vera Liao",
      "Michael Muller",
      "Mayank Agarwal",
      "Stephanie Houde",
      "Kartik Talamadupula",
      "Justin D. Weisz"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2202.04903"
  },
  {
    "id": "arXiv:2202.04910",
    "title": "Instance-wise algorithm configuration with graph neural networks",
    "abstract": "We present our submission for the configuration task of the Machine Learning\nfor Combinatorial Optimization (ML4CO) NeurIPS 2021 competition. The\nconfiguration task is to predict a good configuration of the open-source solver\nSCIP to solve a mixed integer linear program (MILP) efficiently. We pose this\ntask as a supervised learning problem: First, we compile a large dataset of the\nsolver performance for various configurations and all provided MILP instances.\nSecond, we use this data to train a graph neural network that learns to predict\na good configuration for a specific instance. The submission was tested on the\nthree problem benchmarks of the competition and improved solver performance\nover the default by 12% and 35% and 8% across the hidden test instances. We\nranked 3rd out of 15 on the global leaderboard and won the student leaderboard.\nWe make our code publicly available at\n\\url{https://github.com/RomeoV/ml4co-competition} .",
    "descriptor": "\nComments: 5 pages, 3 figures\n",
    "authors": [
      "Romeo Valentin",
      "Claudio Ferrari",
      "J\u00e9r\u00e9my Scheurer",
      "Andisheh Amrollahi",
      "Chris Wendler",
      "Max B. Paulus"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2202.04910"
  },
  {
    "id": "arXiv:2202.04916",
    "title": "Discovering plasticity models without stress data",
    "abstract": "We propose a new approach for data-driven automated discovery of material\nlaws, which we call EUCLID (Efficient Unsupervised Constitutive Law\nIdentification and Discovery), and we apply it here to the discovery of\nplasticity models, including arbitrarily shaped yield surfaces and isotropic\nand/or kinematic hardening laws. The approach is unsupervised, i.e., it\nrequires no stress data but only full-field displacement and global force data;\nit delivers interpretable models, i.e., models that are embodied by\nparsimonious mathematical expressions discovered through sparse regression of a\npotentially large catalogue of candidate functions; it is one-shot, i.e.,\ndiscovery only needs one experiment. The material model library is constructed\nby expanding the yield function with a Fourier series, whereas isotropic and\nkinematic hardening are introduced by assuming a yield function dependency on\ninternal history variables that evolve with the plastic deformation. For\nselecting the most relevant Fourier modes and identifying the hardening\nbehavior, EUCLID employs physics knowledge, i.e., the optimization problem that\ngoverns the discovery enforces the equilibrium constraints in the bulk and at\nthe loaded boundary of the domain. Sparsity promoting regularization is\ndeployed to generate a set of solutions out of which a solution with low cost\nand high parsimony is automatically selected. Through virtual experiments, we\ndemonstrate the ability of EUCLID to accurately discover several plastic yield\nsurfaces and hardening mechanisms of different complexity.",
    "descriptor": "",
    "authors": [
      "Moritz Flaschel",
      "Siddhant Kumar",
      "Laura De Lorenzis"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2202.04916"
  },
  {
    "id": "arXiv:2202.04920",
    "title": "Collaborative Filtering with Attribution Alignment for Review-based  Non-overlapped Cross Domain Recommendation",
    "abstract": "Cross-Domain Recommendation (CDR) has been popularly studied to utilize\ndifferent domain knowledge to solve the data sparsity and cold-start problem in\nrecommender systems. In this paper, we focus on the Review-based Non-overlapped\nRecommendation (RNCDR) problem. The problem is commonly-existed and challenging\ndue to two main aspects, i.e, there are only positive user-item ratings on the\ntarget domain and there is no overlapped user across different domains. Most\nprevious CDR approaches cannot solve the RNCDR problem well, since (1) they\ncannot effectively combine review with other information (e.g., ID or ratings)\nto obtain expressive user or item embedding, (2) they cannot reduce the domain\ndiscrepancy on users and items. To fill this gap, we propose Collaborative\nFiltering with Attribution Alignment model (CFAA), a cross-domain\nrecommendation framework for the RNCDR problem. CFAA includes two main modules,\ni.e., rating prediction module and embedding attribution alignment module. The\nformer aims to jointly mine review, one-hot ID, and multi-hot historical\nratings to generate expressive user and item embeddings. The later includes\nvertical attribution alignment and horizontal attribution alignment, tending to\nreduce the discrepancy based on multiple perspectives. Our empirical study on\nDouban and Amazon datasets demonstrates that CFAA significantly outperforms the\nstate-of-the-art models under the RNCDR setting.",
    "descriptor": "",
    "authors": [
      "Weiming Liu",
      "Xiaolin Zheng",
      "Mengling Hu",
      "Chaochao Chen"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.04920"
  },
  {
    "id": "arXiv:2202.04927",
    "title": "A non-local gradient based approach of infinity Laplacian with  $\u0393$-convergence",
    "abstract": "We propose an infinity Laplacian method to address the problem of\ninterpolation on an unstructured point cloud. In doing so, we find the labeling\nfunction with the smallest infinity norm of its gradient. By introducing the\nnon-local gradient, the continuous functional is approximated with a discrete\nform. The discrete problem is convex and can be solved efficiently with the\nsplit Bregman method. Experimental results indicate that our approach provides\nconsistent interpolations and the labeling functions obtained are globally\nsmooth, even in the case of extreme low sampling rate. More importantly,\nconvergence of the discrete minimizer to the optimal continuous labeling\nfunction is proved using $\\Gamma$-convergence and compactness, which guarantees\nthe reliability of the infinity Laplacian method in various potential\napplications.",
    "descriptor": "\nComments: 44 pages, 4 figures\n",
    "authors": [
      "Weiye Gan",
      "Xintong Liu",
      "Yicheng Li",
      "Zuoqiang Shi"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.04927"
  },
  {
    "id": "arXiv:2202.04932",
    "title": "Robust Sylvester-Gallai type theorem for quadratic polynomials",
    "abstract": "In this work, we extend the robust version of the Sylvester-Gallai theorem,\nobtained by Barak, Dvir, Wigderson and Yehudayoff, and by Dvir, Saraf and\nWigderson, to the case of quadratic polynomials. Specifically, we prove that if\n$\\mathcal{Q}\\subset \\mathbb{C}[x_1.\\ldots,x_n]$ is a finite set,\n$|\\mathcal{Q}|=m$, of irreducible quadratic polynomials that satisfy the\nfollowing condition:\nThere is $\\delta>0$ such that for every $Q\\in\\mathcal{Q}$ there are at least\n$\\delta m$ polynomials $P\\in \\mathcal{Q}$ such that whenever $Q$ and $P$ vanish\nthen so does a third polynomial in $\\mathcal{Q}\\setminus\\{Q,P\\}$, then\n$\\dim(\\text{span}({\\mathcal{Q}}))=\\text{poly}(1/\\delta)$.\nThe work of Barak et al. and Dvir et al. studied the case of linear\npolynomials and proved an upper bound of $O(1/\\delta)$ on the dimension (in the\nfirst work an upper bound of $O(1/\\delta^2)$ was given, which was improved to\n$O(1/\\delta)$ in the second work).",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2006.08263\n",
    "authors": [
      "Shir Peleg",
      "Amir Shpilka"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2202.04932"
  },
  {
    "id": "arXiv:2202.04933",
    "title": "Energy-Based Contrastive Learning of Visual Representations",
    "abstract": "Contrastive learning is a method of learning visual representations by\ntraining Deep Neural Networks (DNNs) to increase the similarity between\nrepresentations of positive pairs and reduce the similarity between\nrepresentations of negative pairs. However, contrastive methods usually require\nlarge datasets with significant number of negative pairs per iteration to\nachieve reasonable performance on downstream tasks. To address this problem,\nhere we propose Energy-Based Contrastive Learning (EBCLR) that combines\ncontrastive learning with Energy-Based Models (EBMs) and can be theoretically\ninterpreted as learning the joint distribution of positive pairs. Using a novel\nvariant of Stochastic Gradient Langevin Dynamics (SGLD) to accelerate the\ntraining of EBCLR, we show that EBCLR is far more sample-efficient than\nprevious self-supervised learning methods. Specifically, EBCLR shows from X4 up\nto X20 acceleration compared to SimCLR and MoCo v2 in terms of training epochs.\nFurthermore, in contrast to SimCLR, EBCLR achieves nearly the same performance\nwith 254 negative pairs (batch size 128) and 30 negative pairs (batch size 16)\nper positive pair, demonstrating the robustness of EBCLR to small number of\nnegative pairs.",
    "descriptor": "",
    "authors": [
      "Beomsu Kim",
      "Jong Chul Ye"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.04933"
  },
  {
    "id": "arXiv:2202.04936",
    "title": "Graph Neural Network for Local Corruption Recovery",
    "abstract": "Graph neural networks (GNNs) have seen a surge of development for exploiting\nthe relational information of input graphs. Nevertheless, messages propagating\nthrough a graph contain both interpretable patterns and small perturbations.\nDespite global noise could be distributed over the entire graph data, it is not\nuncommon that corruptions appear well-concealed and merely pollute local\nregions while still having a vital influence on the GNN learning and prediction\nperformance. This work tackles the graph recovery problem from local poisons by\na robustness representation learning. Our developed strategy identifies\nregional graph perturbations and formulates a robust hidden feature\nrepresentation for GNNs. A mask function pinpointed the anomalies without prior\nknowledge, and an $\\ell_{p,q}$ regularizer defends local poisonings through\npursuing sparsity in the framelet domain while maintaining a conditional\ncloseness between the observation and new representation. The proposed robust\ncomputational unit alleviates the inertial alternating direction method of\nmultipliers to achieve an efficient solution. Extensive experiments show that\nour new model recovers graph representations from local pollution and achieves\nexcellent performance.",
    "descriptor": "",
    "authors": [
      "Bingxin Zhou",
      "Yuanhong Jiang",
      "Yu Guang Wang",
      "Jingwei Liang",
      "Junbin Gao",
      "Shirui Pan",
      "Xiaoqun Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.04936"
  },
  {
    "id": "arXiv:2202.04942",
    "title": "Spherical Transformer",
    "abstract": "Using convolutional neural networks for 360images can induce sub-optimal\nperformance due to distortions entailed by a planar projection. The distortion\ngets deteriorated when a rotation is applied to the 360image. Thus, many\nresearches based on convolutions attempt to reduce the distortions to learn\naccurate representation. In contrast, we leverage the transformer architecture\nto solve image classification problems for 360images. Using the proposed\ntransformer for 360images has two advantages. First, our method does not\nrequire the erroneous planar projection process by sampling pixels from the\nsphere surface. Second, our sampling method based on regular polyhedrons makes\nlow rotation equivariance errors, because specific rotations can be reduced to\npermutations of faces. In experiments, we validate our network on two aspects,\nas follows. First, we show that using a transformer with highly uniform\nsampling methods can help reduce the distortion. Second, we demonstrate that\nthe transformer architecture can achieve rotation equivariance on specific\nrotations. We compare our method to other state-of-the-art algorithms using the\nSPH-MNIST, SPH-CIFAR, and SUN360 datasets and show that our method is\ncompetitive with other methods.",
    "descriptor": "\nComments: 9 pages with 10 figures\n",
    "authors": [
      "Sungmin Cho",
      "Raehyuk Jung",
      "Junseok Kwon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.04942"
  },
  {
    "id": "arXiv:2202.04943",
    "title": "Interpretable pipelines with evolutionarily optimized modules for RL  tasks with visual inputs",
    "abstract": "The importance of explainability in AI has become a pressing concern, for\nwhich several explainable AI (XAI) approaches have been recently proposed.\nHowever, most of the available XAI techniques are post-hoc methods, which\nhowever may be only partially reliable, as they do not reflect exactly the\nstate of the original models. Thus, a more direct way for achieving XAI is\nthrough interpretable (also called glass-box) models. These models have been\nshown to obtain comparable (and, in some cases, better) performance with\nrespect to black-boxes models in various tasks such as classification and\nreinforcement learning. However, they struggle when working with raw data,\nespecially when the input dimensionality increases and the raw inputs alone do\nnot give valuable insights on the decision-making process. Here, we propose to\nuse end-to-end pipelines composed of multiple interpretable models co-optimized\nby means of evolutionary algorithms, that allows us to decompose the\ndecision-making process into two parts: computing high-level features from raw\ndata, and reasoning on the extracted high-level features. We test our approach\nin reinforcement learning environments from the Atari benchmark, where we\nobtain comparable results (with respect to black-box approaches) in settings\nwithout stochastic frame-skipping, while performance degrades in frame-skipping\nsettings.",
    "descriptor": "\nComments: 9 pages, 6 figures, submitted to GECCO 2022\n",
    "authors": [
      "Leonardo Lucio Custode",
      "Giovanni Iacca"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.04943"
  },
  {
    "id": "arXiv:2202.04947",
    "title": "OWL (Observe, Watch, Listen): Localizing Actions in Egocentric Video via  Audiovisual Temporal Context",
    "abstract": "Temporal action localization (TAL) is an important task extensively explored\nand improved for third-person videos in recent years. Recent efforts have been\nmade to perform fine-grained temporal localization on first-person videos.\nHowever, current TAL methods only use visual signals, neglecting the audio\nmodality that exists in most videos and that shows meaningful action\ninformation in egocentric videos. In this work, we take a deep look into the\neffectiveness of audio in detecting actions in egocentric videos and introduce\na simple-yet-effective approach via Observing, Watching, and Listening (OWL) to\nleverage audio-visual information and context for egocentric TAL. For doing\nthat, we: 1) compare and study different strategies for where and how to fuse\nthe two modalities; 2) propose a transformer-based model to incorporate\ntemporal audio-visual context. Our experiments show that our approach achieves\nstate-of-the-art performance on EPIC-KITCHENS-100.",
    "descriptor": "",
    "authors": [
      "Merey Ramazanova",
      "Victor Escorcia",
      "Fabian Caba Heilbron",
      "Chen Zhao",
      "Bernard Ghanem"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2202.04947"
  },
  {
    "id": "arXiv:2202.04950",
    "title": "Work-from-home and its implication for project management, resilience  and innovation -- a global survey on software companies",
    "abstract": "[Context] The COVID-19 pandemic has had a disruptive impact on how people\nwork and collaborate across all global economic sectors, including the software\nbusiness. While remote working is not new for software engineers, forced\nWork-from-home situations to come with both constraints, limitations, and\nopportunities for individuals, software teams and software companies. As the\n\"new normal\" for working might be based on the current state of Work From Home\n(WFH), it is useful to understand what has happened and learn from that.\n[Objective] The goal of this study is to gain insights on how their WFH\nenvironment impacts software projects and software companies. We are also\ninterested in understanding if the impact differs between software startups and\nestablished companies. [Method] We conducted a global-scale, cross-sectional\nsurvey during spring and summer 2021. Our results are based on quantitative and\nqualitative analysis of 297 valid responses. [Results] We observed a mixed\nperception of the impact of WFH on software project management, resilience, and\ninnovation. Certain patterns on WFH, control and coordination mechanisms and\ncollaborative tools are observed globally. We find that team, agility and\nleadership are the three most important factors for achieving resilience during\nthe pandemic. Although startups do not perceive the impact of WFH differently,\nthere is a difference between engineers who work in a small team context and\nthose who work in a large team context. [Conclusion] The result suggests a\ncontingency approach in studying and improving WFH practices and environment in\nthe future software industry.",
    "descriptor": "",
    "authors": [
      "Anh Nguyen-Duc",
      "Dron Khanna",
      "Des Greer",
      "Xiaofeng Wang",
      "Luciana Martinez Zaina",
      "Gerardo Matturro",
      "Jorge Melegati",
      "Eduardo Guerra",
      "Giang Huong Le",
      "Petri Kettunen",
      "Sami Hyrynsalmi",
      "Henry Edison",
      "Afonso Sales",
      "Didzis Rutitis",
      "Kai-Kristian Kemell",
      "Abdullah Aldaeej",
      "Tommi Mikkonen",
      "Juan Garbajosa",
      "Pekka Abrahamsson"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2202.04950"
  },
  {
    "id": "arXiv:2202.04954",
    "title": "D2A-BSP: Distilled Data Association Belief Space Planning with  Performance Guarantees Under Budget Constraints",
    "abstract": "Unresolved data association in ambiguous and perceptually aliased\nenvironments leads to multi-modal hypotheses on both the robot's and the\nenvironment state. To avoid catastrophic results, when operating in such\nambiguous environments, it is crucial to reason about data association within\nBelief Space Planning (BSP). However, explicitly considering all possible data\nassociations, the number of hypotheses grows exponentially with the planning\nhorizon and determining the optimal action sequence quickly becomes\nintractable. Moreover, with hard budget constraints where some non-negligible\nhypotheses must be pruned, achieving performance guarantees is crucial. In this\nwork we present a computationally efficient novel approach that utilizes only a\ndistilled subset of hypotheses to solve BSP problems while reasoning about data\nassociation. Furthermore, to provide performance guarantees, we derive error\nbounds with respect to the optimal solution. We then demonstrate our approach\nin an extremely aliased environment, where we manage to significantly reduce\ncomputation time without compromising on the quality of the solution.",
    "descriptor": "\nComments: 8 pages, 2 figures, submitted to IEEE International Conference on Robotics and Automation (ICRA) 2022\n",
    "authors": [
      "Moshe Shienman",
      "Vadim Indelman"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.04954"
  },
  {
    "id": "arXiv:2202.04956",
    "title": "Loss-guided Stability Selection",
    "abstract": "In modern data analysis, sparse model selection becomes inevitable once the\nnumber of predictors variables is very high. It is well-known that model\nselection procedures like the Lasso or Boosting tend to overfit on real data.\nThe celebrated Stability Selection overcomes these weaknesses by aggregating\nmodels, based on subsamples of the training data, followed by choosing a stable\npredictor set which is usually much sparser than the predictor sets from the\nraw models. The standard Stability Selection is based on a global criterion,\nnamely the per-family error rate, while additionally requiring expert knowledge\nto suitably configure the hyperparameters. Since model selection depends on the\nloss function, i.e., predictor sets selected w.r.t. some particular loss\nfunction differ from those selected w.r.t. some other loss function, we propose\na Stability Selection variant which respects the chosen loss function via an\nadditional validation step based on out-of-sample validation data, optionally\nenhanced with an exhaustive search strategy. Our Stability Selection variants\nare widely applicable and user-friendly. Moreover, our Stability Selection\nvariants can avoid the issue of severe underfitting which affects the original\nStability Selection for noisy high-dimensional data, so our priority is not to\navoid false positives at all costs but to result in a sparse stable model with\nwhich one can make predictions. Experiments where we consider both regression\nand binary classification and where we use Boosting as model selection\nalgorithm reveal a significant precision improvement compared to raw Boosting\nmodels while not suffering from any of the mentioned issues of the original\nStability Selection.",
    "descriptor": "",
    "authors": [
      "Tino Werner"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.04956"
  },
  {
    "id": "arXiv:2202.04958",
    "title": "Sound masking degrades perception of self-location during stepping: A  case for sound-transparent spacesuits for Mars",
    "abstract": "Most efforts to improve spacesuits have been directed towards adding haptic\nfeedback. However, sound transparency can also improve situational awareness at\na relatively low cost. The extent of the improvement is unknown. We use the\nFukuda-Unterberger stepping test to measure the accuracy of one's perception of\nself-location. We compare accuracy outcomes in two scenarios: one where hearing\nis impaired with sound masking with white noise and one where it is not. These\nscenarios are acoustic proxies for a sound muffling space suit and a sound\ntransparent space suit respectively. The results show that when sound masking\nis applied, the error in self-location increases by 14.5cm, 95% CI [4.04\n28.22]. Suggestions to apply the findings to Mars spacesuit designs are\ndiscussed. A cost-benefit analysis is also provided.",
    "descriptor": "",
    "authors": [
      "Jose Berengueres",
      "Maryam Al Kuwaiti",
      "Ahmed Yasir",
      "Kenjiro Tadakuma"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2202.04958"
  },
  {
    "id": "arXiv:2202.04964",
    "title": "Forecasting large-scale circulation regimes using deformable  convolutional neural networks and global spatiotemporal climate data",
    "abstract": "Classifying the state of the atmosphere into a finite number of large-scale\ncirculation regimes is a popular way of investigating teleconnections, the\npredictability of severe weather events, and climate change. Here, we\ninvestigate a supervised machine learning approach based on deformable\nconvolutional neural networks (deCNNs) and transfer learning to forecast the\nNorth Atlantic-European weather regimes during extended boreal winter for 1 to\n15 days into the future. We apply state-of-the-art interpretation techniques\nfrom the machine learning literature to attribute particular regions of\ninterest or potential teleconnections relevant for any given weather cluster\nprediction or regime transition. We demonstrate superior forecasting\nperformance relative to several classical meteorological benchmarks, as well as\nlogistic regression and random forests. Due to its wider field of view, we also\nobserve deCNN achieving considerably better performance than regular\nconvolutional neural networks at lead times beyond 5-6 days. Finally, we find\ntransfer learning to be of paramount importance, similar to previous\ndata-driven atmospheric forecasting studies.",
    "descriptor": "\nComments: Submitted to Nature - Scientific Reports\n",
    "authors": [
      "Andreas Holm Nielsen",
      "Alexandros Iosifidis",
      "Henrik Karstoft"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.04964"
  },
  {
    "id": "arXiv:2202.04966",
    "title": "Real-Time Siamese Multiple Object Tracker with Enhanced Proposals",
    "abstract": "Maintaining the identity of multiple objects in real-time video is a\nchallenging task, as it is not always possible to run a detector on every\nframe. Thus, motion estimation systems are often employed, which either do not\nscale well with the number of targets or produce features with limited semantic\ninformation. To solve the aforementioned problems and allow the tracking of\ndozens of arbitrary objects in real-time, we propose SiamMOTION. SiamMOTION\nincludes a novel proposal engine that produces quality features through an\nattention mechanism and a region-of-interest extractor fed by an inertia module\nand powered by a feature pyramid network. Finally, the extracted tensors enter\na comparison head that efficiently matches pairs of exemplars and search areas,\ngenerating quality predictions via a pairwise depthwise region proposal network\nand a multi-object penalization module. SiamMOTION has been validated on five\npublic benchmarks, achieving leading performance against current\nstate-of-the-art trackers.",
    "descriptor": "",
    "authors": [
      "Lorenzo Vaquero",
      "V\u00edctor M. Brea",
      "Manuel Mucientes"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.04966"
  },
  {
    "id": "arXiv:2202.04971",
    "title": "ASRPU: A Programmable Accelerator for Low-Power Automatic Speech  Recognition",
    "abstract": "The outstanding accuracy achieved by modern Automatic Speech Recognition\n(ASR) systems is enabling them to quickly become a mainstream technology. ASR\nis essential for many applications, such as speech-based assistants, dictation\nsystems and real-time language translation. However, highly accurate ASR\nsystems are computationally expensive, requiring on the order of billions of\narithmetic operations to decode each second of audio, which conflicts with a\ngrowing interest in deploying ASR on edge devices. On these devices, hardware\nacceleration is key for achieving acceptable performance. However, ASR is a\nrich and fast-changing field, and thus, any overly specialized hardware\naccelerator may quickly become obsolete.\nIn this paper, we tackle those challenges by proposing ASRPU, a programmable\naccelerator for on-edge ASR. ASRPU contains a pool of general-purpose cores\nthat execute small pieces of parallel code. Each of these programs computes one\npart of the overall decoder (e.g. a layer in a neural network). The accelerator\nautomates some carefully chosen parts of the decoder to simplify the\nprogramming without sacrificing generality. We provide an analysis of a modern\nASR system implemented on ASRPU and show that this architecture can achieve\nreal-time decoding with a very low power budget.",
    "descriptor": "\nComments: 11 pages, 11 figures\n",
    "authors": [
      "Dennis Pinto",
      "Jose-Mar\u00eda Arnau",
      "Antonio Gonz\u00e1lez"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2202.04971"
  },
  {
    "id": "arXiv:2202.04972",
    "title": "IHGNN: Interactive Hypergraph Neural Network for Personalized Product  Search",
    "abstract": "A good personalized product search (PPS) system should not only focus on\nretrieving relevant products, but also consider user personalized preference.\nRecent work on PPS mainly adopts the representation learning paradigm, e.g.,\nlearning representations for each entity (including user, product and query)\nfrom historical user behaviors (aka. user-product-query interactions). However,\nwe argue that existing methods do not sufficiently exploit the crucial\ncollaborative signal, which is latent in historical interactions to reveal the\naffinity between the entities. Collaborative signal is quite helpful for\ngenerating high-quality representation, exploiting which would benefit the\nrepresentation learning of one node from its connected nodes.\nTo tackle this limitation, in this work, we propose a new model IHGNN for\npersonalized product search. IHGNN resorts to a hypergraph constructed from the\nhistorical user-product-query interactions, which could completely preserve\nternary relations and express collaborative signal based on the topological\nstructure. On this basis, we develop a specific interactive hypergraph neural\nnetwork to explicitly encode the structure information (i.e., collaborative\nsignal) into the embedding process. It collects the information from the\nhypergraph neighbors and explicitly models neighbor feature interaction to\nenhance the representation of the target entity. Extensive experiments on three\nreal-world datasets validate the superiority of our proposal over the\nstate-of-the-arts.",
    "descriptor": "\nComments: Presented at Proceedings of the ACM Web Conference 2022 (WWW '22)\n",
    "authors": [
      "Dian Cheng",
      "Jiawei Chen",
      "Wenjun Peng",
      "Wenqin Ye",
      "Fuyu Lv",
      "Tao Zhuang",
      "Xiaoyi Zeng",
      "Xiangnan He"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2202.04972"
  },
  {
    "id": "arXiv:2202.04975",
    "title": "FedAttack: Effective and Covert Poisoning Attack on Federated  Recommendation via Hard Sampling",
    "abstract": "Federated learning (FL) is a feasible technique to learn personalized\nrecommendation models from decentralized user data. Unfortunately, federated\nrecommender systems are vulnerable to poisoning attacks by malicious clients.\nExisting recommender system poisoning methods mainly focus on promoting the\nrecommendation chances of target items due to financial incentives. In fact, in\nreal-world scenarios, the attacker may also attempt to degrade the overall\nperformance of recommender systems. However, existing general FL poisoning\nmethods for degrading model performance are either ineffective or not concealed\nin poisoning federated recommender systems. In this paper, we propose a simple\nyet effective and covert poisoning attack method on federated recommendation,\nnamed FedAttack. Its core idea is using globally hardest samples to subvert\nmodel training. More specifically, the malicious clients first infer user\nembeddings based on local user profiles. Next, they choose the candidate items\nthat are most relevant to the user embeddings as hardest negative samples, and\nfind the candidates farthest from the user embeddings as hardest positive\nsamples. The model gradients inferred from these poisoned samples are then\nuploaded to the server for aggregation and model update. Since the behaviors of\nmalicious clients are somewhat similar to users with diverse interests, they\ncannot be effectively distinguished from normal clients by the server.\nExtensive experiments on two benchmark datasets show that FedAttack can\neffectively degrade the performance of various federated recommender systems,\nmeanwhile cannot be effectively detected nor defended by many existing methods.",
    "descriptor": "\nComments: Submitted to KDD 2022\n",
    "authors": [
      "Chuhan Wu",
      "Fangzhao Wu",
      "Tao Qi",
      "Yongfeng Huang",
      "Xing Xie"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2202.04975"
  },
  {
    "id": "arXiv:2202.04977",
    "title": "Needs-aware Artificial Intelligence: AI that 'serves [human] needs'",
    "abstract": "Many boundaries are, and will continue to, shape the future of Artificial\nIntelligence (AI). We push on these boundaries in order to make progress, but\nthey are both pliable and resilient--always creating new boundaries of what AI\ncan (or should) achieve. Among these are technical boundaries (such as\nprocessing capacity), psychological boundaries (such as human trust in AI\nsystems), ethical boundaries (such as with AI weapons), and conceptual\nboundaries (such as the AI people can imagine). It is within this final\ncategory while it can play a fundamental role in all other boundaries} that we\nfind the construct of needs and the limitations that our current concept of\nneed places on the future AI.",
    "descriptor": "",
    "authors": [
      "Ryan Watkins",
      "Soheil Human"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.04977"
  },
  {
    "id": "arXiv:2202.04978",
    "title": "Towards Assessing and Characterizing the Semantic Robustness of Face  Recognition",
    "abstract": "Deep Neural Networks (DNNs) lack robustness against imperceptible\nperturbations to their input. Face Recognition Models (FRMs) based on DNNs\ninherit this vulnerability. We propose a methodology for assessing and\ncharacterizing the robustness of FRMs against semantic perturbations to their\ninput. Our methodology causes FRMs to malfunction by designing adversarial\nattacks that search for identity-preserving modifications to faces. In\nparticular, given a face, our attacks find identity-preserving variants of the\nface such that an FRM fails to recognize the images belonging to the same\nidentity. We model these identity-preserving semantic modifications via\ndirection- and magnitude-constrained perturbations in the latent space of\nStyleGAN. We further propose to characterize the semantic robustness of an FRM\nby statistically describing the perturbations that induce the FRM to\nmalfunction. Finally, we combine our methodology with a certification\ntechnique, thus providing (i) theoretical guarantees on the performance of an\nFRM, and (ii) a formal description of how an FRM may model the notion of face\nidentity.",
    "descriptor": "\nComments: 26 pages, 18 figures\n",
    "authors": [
      "Juan C. P\u00e9rez",
      "Motasem Alfarra",
      "Ali Thabet",
      "Pablo Arbel\u00e1ez",
      "Bernard Ghanem"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.04978"
  },
  {
    "id": "arXiv:2202.04981",
    "title": "Barwise Compression Schemes for Audio-Based Music Structure Analysis",
    "abstract": "Music Structure Analysis (MSA) consists in segmenting a music piece in\nseveral distinct sections. We approach MSA within a compression framework,\nunder the hypothesis that the structure is more easily revealed by a simplified\nrepresentation of the original content of the song.\nMore specifically, under the hypothesis that MSA is correlated with\nsimilarities occurring at the bar scale, linear and non-linear compression\nschemes can be applied to barwise audio signals. Compressed representations\ncapture the most salient components of the different bars in the song and are\nthen used to infer the song structure using a dynamic programming algorithm.\nThis work explores both low-rank approximation models such as Principal\nComponent Analysis or Nonnegative Matrix Factorization and \"piece-specific\"\nAuto-Encoding Neural Networks, with the objective to learn latent\nrepresentations specific to a given song. Such approaches do not rely on\nsupervision nor annotations, which are well-known to be tedious to collect and\npossibly ambiguous in MSA description.\nIn our experiments, several unsupervised compression schemes achieve a level\nof performance comparable to that of state-of-the-art supervised methods (for\n3s tolerance) on the RWC-Pop dataset, showcasing the importance of the barwise\ncompression processing for MSA.",
    "descriptor": "\nComments: Submitted at the 2022 Sound and Music Computing (SMC) conference, 8 pages, 6 figures, 1 table, code available at this https URL arXiv admin note: substantial text overlap with arXiv:2110.14437\n",
    "authors": [
      "Axel Marmoret",
      "J\u00e9r\u00e9my E. Cohen",
      "Fr\u00e9d\u00e9ric Bimbot"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2202.04981"
  },
  {
    "id": "arXiv:2202.04982",
    "title": "A Robust Version of Heged\u0171s's Lemma, with Applications",
    "abstract": "Heged\\H{u}s's lemma is the following combinatorial statement regarding\npolynomials over finite fields. Over a field $\\F$ of characteristic $p > 0$ and\nfor $q$ a power of $p$, the lemma says that any multilinear polynomial $P\\in\n\\F[x_1,\\ldots,x_n]$ of degree less than $q$ that vanishes at all points in\n$\\{0,1\\}^n$ of Hamming weight $k\\in [q,n-q]$ must also vanish at all points in\n$\\{0,1\\}^n$ of weight $k + q$. This lemma was used by Heged\\H{u}s (2009) to\ngive a solution to \\emph{Galvin's problem}, an extremal problem about set\nsystems; by Alon, Kumar and Volk (2018) to improve the best-known multilinear\ncircuit lower bounds; and by Hrube\\v{s}, Ramamoorthy, Rao and Yehudayoff (2019)\nto prove optimal lower bounds against depth-$2$ threshold circuits for\ncomputing some symmetric functions.\nIn this paper, we formulate a robust version of Heged\\H{u}s's lemma.\nInformally, this version says that if a polynomial of degree $o(q)$ vanishes at\nmost points of weight $k$, then it vanishes at many points of weight $k+q$. We\nprove this lemma and give three different applications.",
    "descriptor": "\nComments: Published in STOC 2020\n",
    "authors": [
      "Srikanth Srinivasan"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2202.04982"
  },
  {
    "id": "arXiv:2202.04986",
    "title": "Enhanced Digital Halftoning via Weighted Sigma-Delta Modulation",
    "abstract": "In this paper, we study error diffusion techniques for digital halftoning\nfrom the perspective of 1-bit Sigma-Delta quantization. We introduce a method\nto generate Sigma-Delta schemes for two-dimensional signals as a weighted\ncombination of its one-dimensional counterparts and show that various error\ndiffusion schemes proposed in the literature can be represented in this\nframework via Sigma-Delta schemes of first order. Under the model of\ntwo-dimensional bandlimited signals, which is motivated by a mathematical model\nof human visual perception, we derive quantitative error bounds for such\nweighted Sigma-Delta schemes. We see these bounds as a step towards a\nmathematical understanding of the good empirical performance of error\ndiffusion, even though they are formulated in the supremum norm, which is known\nto not fully capture the visual similarity of images.\nMotivated by the correspondence between existing error diffusion algorithms\nand first-order Sigma-Delta schemes, we study the performance of the analogous\nweighted combinations of second-order Sigma-Delta schemes and show that they\nexhibit a superior performance in terms of guaranteed error decay for\ntwo-dimensional bandlimited signals. In extensive numerical simulations for\nreal world images, we demonstrate that with some modifications to enhance\nstability this superior performance also translates to the problem of digital\nhalftoning.\nMore concretely, we find that certain second-order weighted Sigma-Delta\nschemes exhibit competitive performance for digital halftoning of real world\nimages in terms of the Feature Similarity Index (FSIM), a state-of-the-art\nmeasure for image quality assessment.",
    "descriptor": "",
    "authors": [
      "Felix Krahmer",
      "Anna Veselovska"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.04986"
  },
  {
    "id": "arXiv:2202.04988",
    "title": "Group Testing on General Set-Systems",
    "abstract": "Group testing is one of the fundamental problems in coding theory and\ncombinatorics in which one is to identify a subset of contaminated items from a\ngiven ground set. There has been renewed interest in group testing recently due\nto its applications in diagnostic virology, including pool testing for the\nnovel coronavirus. The majority of existing works on group testing focus on the\n\\emph{uniform} setting in which any subset of size $d$ from a ground set $V$ of\nsize $n$ is potentially contaminated. In this work, we consider a {\\em\ngeneralized} version of group testing with an arbitrary set-system of\npotentially contaminated sets. The generalized problem is characterized by a\nhypergraph $H=(V,E)$, where $V$ represents the ground set and edges $e\\in E$\nrepresent potentially contaminated sets. The problem of generalized group\ntesting is motivated by practical settings in which not all subsets of a given\nsize $d$ may be potentially contaminated, rather, due to social dynamics,\ngeographical limitations, or other considerations, there exist subsets that can\nbe readily ruled out. For example, in the context of pool testing, the edge set\n$E$ may consist of families, work teams, or students in a classroom, i.e.,\nsubsets likely to be mutually contaminated. The goal in studying the\ngeneralized setting is to leverage the additional knowledge characterized by\n$H=(V,E)$ to significantly reduce the number of required tests. The paper\nconsiders both adaptive and non-adaptive group testing and makes the following\ncontributions. First, for the non-adaptive setting, we show that finding an\noptimal solution for the generalized version of group testing is NP-hard. For\nthis setting, we present a solution that requires $O(d\\log{|E|})$ tests, where\n$d$ is the maximum size of a set $e \\in E$. Our solutions generalize those\ngiven for the traditional setting and are shown to be of order-optimal size\n$O(\\log{|E|})$ for hypergraphs with edges that have ``large'' symmetric\ndifferences. For the adaptive setting, when edges in $E$ are of size exactly\n$d$, we present a solution of size $O(\\log{|E|}+d\\log^2{d})$ that comes close\nto the lower bound of $\\Omega(\\log{|E|} + d)$.",
    "descriptor": "\nComments: 7 pages, 1 figure\n",
    "authors": [
      "Mira Gonen",
      "Michael Langberg",
      "Alex Sprintson"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.04988"
  },
  {
    "id": "arXiv:2202.04989",
    "title": "Semi-Supervised Convolutive NMF for Automatic Music Transcription",
    "abstract": "Automatic Music Transcription, which consists in transforming an audio\nrecording of a musical performance into symbolic format, remains a difficult\nMusic Information Retrieval task. In this work, we propose a semi-supervised\napproach using low-rank matrix factorization techniques, in particular\nConvolutive Nonnegative Matrix Factorization. In the semi-supervised setting,\nonly a single recording of each individual notes is required.\nWe show on the MAPS dataset that the proposed semi-supervised CNMF method\nperforms better than state-of-the-art low-rank factorization techniques and a\nlittle worse than supervised deep learning state-of-the-art methods, while\nhowever suffering from generalization issues.",
    "descriptor": "\nComments: Submitted to 2022 Sound and Music Computing (SMC) conference, 7 pages, 5 figures, 3 tables, coda available at this https URL\n",
    "authors": [
      "Haoran Wu",
      "Axel Marmoret",
      "J\u00e9r\u00e9my E. Cohen"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2202.04989"
  },
  {
    "id": "arXiv:2202.04990",
    "title": "Mixture-of-Rookies: Saving DNN Computations by Predicting ReLU Outputs",
    "abstract": "Deep Neural Networks (DNNs) are widely used in many applications domains.\nHowever, they require a vast amount of computations and memory accesses to\ndeliver outstanding accuracy. In this paper, we propose a scheme to predict\nwhether the output of each ReLu activated neuron will be a zero or a positive\nnumber in order to skip the computation of those neurons that will likely\noutput a zero. Our predictor, named Mixture-of-Rookies, combines two\ninexpensive components. The first one exploits the high linear correlation\nbetween binarized (1-bit) and full-precision (8-bit) dot products, whereas the\nsecond component clusters together neurons that tend to output zero at the same\ntime. We propose a novel clustering scheme based on the analysis of angles, as\nthe sign of the dot product of two vectors depends on the cosine of the angle\nbetween them. We implement our hybrid zero output predictor on top of a\nstate-of-the-art DNN accelerator. Experimental results show that our scheme\nintroduces a small area overhead of 5.3% while achieving a speedup of 1.2x and\nreducing energy consumption by 16.5% on average for a set of diverse DNNs.",
    "descriptor": "\nComments: 13 pages, 14 figures\n",
    "authors": [
      "Dennis Pinto",
      "Jose-Mar\u00eda Arnau",
      "Antonio Gonz\u00e1lez"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2202.04990"
  },
  {
    "id": "arXiv:2202.04994",
    "title": "Slovene SuperGLUE Benchmark: Translation and Evaluation",
    "abstract": "We present a Slovene combined machine-human translated SuperGLUE benchmark.\nWe describe the translation process and problems arising due to differences in\nmorphology and grammar. We evaluate the translated datasets in several modes:\nmonolingual, cross-lingual, and multilingual, taking into account differences\nbetween machine and human translated training sets. The results show that the\nmonolingual Slovene SloBERTa model is superior to massively multilingual and\ntrilingual BERT models, but these also show a good cross-lingual performance on\ncertain tasks. The performance of Slovene models still lags behind the best\nEnglish models.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2107.10614\n",
    "authors": [
      "Ale\u0161 \u017dagar",
      "Marko Robnik-\u0160ikonja"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.04994"
  },
  {
    "id": "arXiv:2202.04996",
    "title": "AA-TransUNet: Attention Augmented TransUNet For Nowcasting Tasks",
    "abstract": "Data driven modeling based approaches have recently gained a lot of attention\nin many challenging meteorological applications including weather element\nforecasting. This paper introduces a novel data-driven predictive model based\non TransUNet for precipitation nowcasting task. The TransUNet model which\ncombines the Transformer and U-Net models has been previously successfully\napplied in medical segmentation tasks. Here, TransUNet is used as a core model\nand is further equipped with Convolutional Block Attention Modules (CBAM) and\nDepthwise-separable Convolution (DSC). The proposed Attention Augmented\nTransUNet (AA-TransUNet) model is evaluated on two distinct datasets: the Dutch\nprecipitation map dataset and the French cloud cover dataset. The obtained\nresults show that the proposed model outperforms other examined models on both\ntested datasets. Furthermore, the uncertainty analysis of the proposed\nAA-TransUNet is provided to give additional insights on its predictions.",
    "descriptor": "\nComments: 8 pages, 8 figures\n",
    "authors": [
      "Yimin Yang",
      "Siamak Mehrkanoon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.04996"
  },
  {
    "id": "arXiv:2202.05002",
    "title": "Achievable Information-Energy Region in the Finite Block-Length Regime  with Finite Constellations",
    "abstract": "This paper characterizes an achievable information-energy region of\nsimultaneous information and energy transmission over an additive white\nGaussian noise channel. This analysis is performed in the finite block-length\nregime with finite constellations. More specifically, a method for constructing\na family of codes is proposed and the set of achievable tuples of information\nrate, energy rate, decoding error probability (DEP) and energy outage\nprobability (EOP) is characterized. Using existing converse results, it is\nshown that the construction is information rate, energy rate, and EOP optimal.\nThe achieved DEP is, however, sub-optimal.",
    "descriptor": "",
    "authors": [
      "Sadaf ul Zuhra",
      "Samir M. Perlaza",
      "H. Vincent Poor",
      "Eitan Altman"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.05002"
  },
  {
    "id": "arXiv:2202.05008",
    "title": "EvoJAX: Hardware-Accelerated Neuroevolution",
    "abstract": "Evolutionary computation has been shown to be a highly effective method for\ntraining neural networks, particularly when employed at scale on CPU clusters.\nRecent work have also showcased their effectiveness on hardware accelerators,\nsuch as GPUs, but so far such demonstrations are tailored for very specific\ntasks, limiting applicability to other domains. We present EvoJAX, a scalable,\ngeneral purpose, hardware-accelerated neuroevolution toolkit. Building on top\nof the JAX library, our toolkit enables neuroevolution algorithms to work with\nneural networks running in parallel across multiple TPU/GPUs. EvoJAX achieves\nvery high performance by implementing the evolution algorithm, neural network\nand task all in NumPy, which is compiled just-in-time to run on accelerators.\nWe provide extensible examples of EvoJAX for a wide range of tasks, including\nsupervised learning, reinforcement learning and generative art. Since EvoJAX\ncan find solutions to most of these tasks within minutes on a single\naccelerator, compared to hours or days when using CPUs, we believe our toolkit\ncan significantly shorten the iteration time of conducting experiments for\nresearchers working with evolutionary computation. Our project is available at\nhttps://github.com/google/evojax",
    "descriptor": "\nComments: this https URL\n",
    "authors": [
      "Yujin Tang",
      "Yingtao Tian",
      "David Ha"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2202.05008"
  },
  {
    "id": "arXiv:2202.05009",
    "title": "N\u00dcWA-LIP: Language Guided Image Inpainting with Defect-free VQGAN",
    "abstract": "Language guided image inpainting aims to fill in the defective regions of an\nimage under the guidance of text while keeping non-defective regions unchanged.\nHowever, the encoding process of existing models suffers from either receptive\nspreading of defective regions or information loss of non-defective regions,\ngiving rise to visually unappealing inpainting results. To address the above\nissues, this paper proposes N\\\"UWA-LIP by incorporating defect-free VQGAN\n(DF-VQGAN) with multi-perspective sequence to sequence (MP-S2S). In particular,\nDF-VQGAN introduces relative estimation to control receptive spreading and\nadopts symmetrical connections to protect information. MP-S2S further enhances\nvisual information from complementary perspectives, including both low-level\npixels and high-level tokens. Experiments show that DF-VQGAN performs more\nrobustness than VQGAN. To evaluate the inpainting performance of our model, we\nbuilt up 3 open-domain benchmarks, where N\\\"UWA-LIP is also superior to recent\nstrong baselines.",
    "descriptor": "\nComments: 10 pages, 6 figures\n",
    "authors": [
      "Minheng Ni",
      "Chenfei Wu",
      "Haoyang Huang",
      "Daxin Jiang",
      "Wangmeng Zuo",
      "Nan Duan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.05009"
  },
  {
    "id": "arXiv:2202.05011",
    "title": "Hardness Results for Laplacians of Simplicial Complexes via  Sparse-Linear Equation Complete Gadgets",
    "abstract": "We study linear equations in combinatorial Laplacians of $k$-dimensional\nsimplicial complexes ($k$-complexes), a natural generalization of graph\nLaplacians. Combinatorial Laplacians play a crucial role in homology and are a\ncentral tool in topology. Beyond this, they have various applications in data\nanalysis and physical modeling problems. It is known that nearly-linear time\nsolvers exist for graph Laplacians. However, nearly-linear time solvers for\ncombinatorial Laplacians are only known for restricted classes of complexes.\nThis paper shows that linear equations in combinatorial Laplacians of\n2-complexes are as hard to solve as general linear equations. More precisely,\nfor any constant $c \\geq 1$, if we can solve linear equations in combinatorial\nLaplacians of 2-complexes up to high accuracy in time $\\tilde{O}((\\# \\text{ of\nnonzero coefficients})^c)$, then we can solve general linear equations with\npolynomially bounded integer coefficients and condition numbers up to high\naccuracy in time $\\tilde{O}((\\# \\text{ of nonzero coefficients})^c)$. We prove\nthis by a nearly-linear time reduction from general linear equations to\ncombinatorial Laplacians of 2-complexes. Our reduction preserves the sparsity\nof the problem instances up to poly-logarithmic factors.",
    "descriptor": "",
    "authors": [
      "Ming Ding",
      "Rasmus Kyng",
      "Maximilian Probst Gutenberg",
      "Peng Zhang"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Data Structures and Algorithms (cs.DS)",
      "Algebraic Topology (math.AT)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.05011"
  },
  {
    "id": "arXiv:2202.05014",
    "title": "Coverage Probability and Spectral Efficiency Analysis of Multi-Gateway  Downlink LoRa Networks",
    "abstract": "The system-level performance of multi-gateway downlink long-range (LoRa)\nnetworks is investigated in the present paper.\nSpecifically, we first compute the active probability of a channel and the\nselection probability of an active end-device (ED) in the closed-form\nexpressions. We then derive the coverage probability (Pcov) and the area\nspectral efficiency (ASE) under the impact of the capture effects and different\nspreading factor (SF) allocation schemes.\nOur findings show that both the Pcov and the ASE of the considered networks\ncan be enhanced significantly by increasing both the duty cycle and the\ntransmit power.\nFinally, Monte-Carlo simulations are provided to verify the accuracy of the\nproposed mathematical frameworks.",
    "descriptor": "",
    "authors": [
      "Lam-Thanh Tu",
      "Abbas Bradai",
      "Yannis Pousset"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.05014"
  },
  {
    "id": "arXiv:2202.05017",
    "title": "Intelligent Resource Allocations for IRS-Assisted OFDM Communications: A  Hybrid MDQN-DDPG Approach",
    "abstract": "In this paper, we study the resource allocation problem for an intelligent\nreflecting surface (IRS)-assisted OFDM system. The system sum rate maximization\nframework is formulated by jointly optimizing subcarrier allocation, base\nstation transmit beamforming and IRS phase shift. Considering the continuous\nand discrete hybrid action space characteristics of the optimization variables,\nwe propose an efficient resource allocation algorithm combining multiple deep Q\nnetworks (MDQN) and deep deterministic policy-gradient (DDPG) to deal with this\nissue. In our algorithm, MDQN are employed to solve the problem of large\ndiscrete action space, while DDPG is introduced to tackle the continuous action\nallocation. Compared with the traditional approaches, our proposed MDQN-DDPG\nbased algorithm has the advantage of continuous behavior improvement through\nlearning from the environment. Simulation results demonstrate superior\nperformance of our design in terms of system sum rate compared with the\nbenchmark schemes.",
    "descriptor": "\nComments: 6 pages, 6 figures, accept by ICC 2022\n",
    "authors": [
      "Wei Wu",
      "Fengchun Yang",
      "Fuhui Zhou",
      "Han Hu",
      "Qihui Wu",
      "Rose Qingyang Hu"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.05017"
  },
  {
    "id": "arXiv:2202.05022",
    "title": "CMOS Circuits for Shape-Based Analog Machine Learning",
    "abstract": "While analog computing is attractive for implementing machine learning (ML)\nprocessors, the paradigm requires chip-in-the-loop training for every processor\nto alleviate artifacts due to device mismatch and device non-linearity.\nSpeeding up chip-in-the-loop training requires re-biasing the circuits in a\nmanner that the analog functions remain invariant across training and\ninference. In this paper, we present an analog computational paradigm and\ncircuits using \"shape\" functions that remain invariant to transistor biasing\n(weak, moderate, and strong inversion) and ambient temperature variation. We\nshow that a core Shape-based Analog Compute (S-AC) circuit could be re-biased\nand reused to implement: (a) non-linear functions; (b) inner-product building\nblocks; and (c) a mixed-signal logarithmic memory, all of which are integral\ntowards designing an ML inference processor. Measured results using a prototype\nfabricated in a 180nm standard CMOS process demonstrate bias invariance and\nhence the resulting analog designs can be scaled for power and speed like\ndigital logic circuits. We also demonstrate a regression task using these CMOS\nbuilding blocks.",
    "descriptor": "\nComments: 9 pages , 12 figures\n",
    "authors": [
      "Pratik Kumar",
      "Ankita Nandi",
      "Shantanu Chakrabartty",
      "Chetan Singh Thakur"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.05022"
  },
  {
    "id": "arXiv:2202.05023",
    "title": "Cybersecurity Challenges Of IoT-enabled Smart Cities: A Survey",
    "abstract": "The new era of the Internet of Things (IoT) is changing our urban lives in\nevery way. With the support of recent IoT technologies, IoT-enabled smart\ncities are capable of building extensive data networks incorporating a large\nnumber of heterogeneous devices participating in the data collection and\ndecision-making process. This massive data backbone formed by IoT devices\nallows systems to perform real-time environmental monitoring and actuating.\nCoupled with high flexibility and ease of deployment, IoT-based solutions can\nbe easily adopted for different application scenarios. However, there are many\nchallenges that system designers would need to consider before employing\nlarge-scale IoT deployment. Our current infrastructure will have to quickly\nadapt to handle the big data in our systems, supply interoperability for\ncross-functional performance, and provide the cognitive capabilities for system\nintelligence. Most importantly, we must consider a new spectrum of security\nchallenges arising from the new context. In this paper, we aim to provide\ngeneral security guidelines for IoT-enabled smart city developments by 1)\npresenting some of the latest innovations in IoT-enabled smart cities, and\nhighlighting common security challenges and research opportunities; 2)\nreviewing recent cryptographic security implementations for IoT-enabled smart\ncities; 3) using the Activity-Network-Things architecture to analyze major\nsecurity challenges in IoT deployments and proposing a set of specialized\nsecurity requirements for IoT-enabled smart cities; 4) providing a discussion\non the potential prospect for IoT and IoT security.",
    "descriptor": "\nComments: Submitted to IEEE IoT Journal\n",
    "authors": [
      "Jiani Fan",
      "Wenzhuo Yang",
      "Kwok-Yan Lam"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.05023"
  },
  {
    "id": "arXiv:2202.05040",
    "title": "Lebesgue Induction and Tonelli's Theorem in Coq",
    "abstract": "Lebesgue integration is a well-known mathematical tool, used for instance in\nprobability theory, real analysis, and numerical mathematics. Thus its\nformalization in a proof assistant is to be designed to fit different goals and\nprojects. Once Lebesgue integral is formally defined and the first lemmas are\nproved, the question of the convenience of the formalization naturally arises.\nTo check it, a useful extension is the Tonelli theorem, stating that the\n(double) integral of a nonnegative measurable function of two variables can be\ncomputed by iterated integrals, and allowing to switch the order of\nintegration. Therefore, we need to define and prove results on product spaces,\nhoping that they can easily derive from the existing ones on a single space.\nThis article describes the formal definition and proof in Coq of product\n$\\sigma$-algebras, product measures and their uniqueness, the construction of\niterated integrals, up to the Tonelli theorem. We also advertise the\n\\emph{Lebesgue induction principle} provided by an inductive type for\n{\\nonnegative} measurable functions.",
    "descriptor": "",
    "authors": [
      "Sylvie Boldo",
      "Fran\u00e7ois Cl\u00e9ment",
      "Vincent Martin",
      "Micaela Mayero",
      "Houda Mouhcine"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Functional Analysis (math.FA)"
    ],
    "url": "https://arxiv.org/abs/2202.05040"
  },
  {
    "id": "arXiv:2202.05041",
    "title": "On characterizations of learnability with computable learners",
    "abstract": "We study computable PAC (CPAC) learning as introduced by Agarwal et al.\n(2020). First, we consider the main open question of finding characterizations\nof proper and improper CPAC learning. We give a characterization of a closely\nrelated notion of strong CPAC learning, and we provide a negative answer to the\nopen problem posed by Agarwal et al. (2021) whether all decidable PAC learnable\nclasses are improperly CPAC learnable. Second, we consider undecidability of\n(computable) PAC learnability. We give a simple and general argument to exhibit\nsuch undecidability, and we initiate a study of the arithmetical complexity of\nlearnability. We briefly discuss the relation to the undecidability result of\nBen-David et al. (2019), that motivated the work of Agarwal et al.",
    "descriptor": "",
    "authors": [
      "Tom F. Sterkenburg"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.05041"
  },
  {
    "id": "arXiv:2202.05048",
    "title": "Quantune: Post-training Quantization of Convolutional Neural Networks  using Extreme Gradient Boosting for Fast Deployment",
    "abstract": "To adopt convolutional neural networks (CNN) for a range of\nresource-constrained targets, it is necessary to compress the CNN models by\nperforming quantization, whereby precision representation is converted to a\nlower bit representation. To overcome problems such as sensitivity of the\ntraining dataset, high computational requirements, and large time consumption,\npost-training quantization methods that do not require retraining have been\nproposed. In addition, to compensate for the accuracy drop without retraining,\nprevious studies on post-training quantization have proposed several\ncomplementary methods: calibration, schemes, clipping, granularity, and\nmixed-precision. To generate a quantized model with minimal error, it is\nnecessary to study all possible combinations of the methods because each of\nthem is complementary and the CNN models have different characteristics.\nHowever, an exhaustive or a heuristic search is either too time-consuming or\nsuboptimal. To overcome this challenge, we propose an auto-tuner known as\nQuantune, which builds a gradient tree boosting model to accelerate the search\nfor the configurations of quantization and reduce the quantization error. We\nevaluate and compare Quantune with the random, grid, and genetic algorithms.\nThe experimental results show that Quantune reduces the search time for\nquantization by approximately 36.5x with an accuracy loss of 0.07 ~ 0.65%\nacross six CNN models, including the fragile ones (MobileNet, SqueezeNet, and\nShuffleNet). To support multiple targets and adopt continuously evolving\nquantization works, Quantune is implemented on a full-fledged compiler for deep\nlearning as an open-sourced project.",
    "descriptor": "\nComments: 13 page, 9 figures, Accepted in Future Generation Computer Systems\n",
    "authors": [
      "Jemin Lee",
      "Misun Yu",
      "Yongin Kwon",
      "Teaho Kim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.05048"
  },
  {
    "id": "arXiv:2202.05053",
    "title": "Leveraging Multi-Connectivity for Multicast Video Streaming",
    "abstract": "Multi-connectivity has emerged as a key enabler for providing seamless\nconnectivity in cellular mobile networks. However, its potential for improving\nthe quality of multicast transmissions has remained unexplored. In this paper,\nwe investigate the use of multi-connectivity in wireless multicast streaming.\nMulti-connectivity can significantly improve the performance of multicast\nservices. It especially benefits the cell edge users who often suffer from poor\nchannel conditions. In this work, we assess the impact of multi-connectivity on\nthe performance of multicast streaming. We propose procedures for establishing\nmulti-connectivity in a multicast system and address the associated resource\nallocation problem. We prove that the optimal resource allocation problem is\nNP-hard. We propose a greedy approximation algorithm for this problem and prove\nthat no other polynomial-time algorithm can provide a better approximation.\nSince video streaming is the primary use case under consideration here, we use\ntraces from actual videos to generate realistic video traffic patterns in our\nsimulations. Our simulation results clearly establish that multi-connectivity\nresults in considerable performance improvement in multicast streaming.",
    "descriptor": "",
    "authors": [
      "Sadaf ul Zuhra",
      "Prasanna Chaporkar",
      "Abhay Karandikar",
      "Pranav Jha"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2202.05053"
  },
  {
    "id": "arXiv:2202.05054",
    "title": "Exploiting Spatial Sparsity for Event Cameras with Visual Transformers",
    "abstract": "Event cameras report local changes of brightness through an asynchronous\nstream of output events. Events are spatially sparse at pixel locations with\nlittle brightness variation. We propose using a visual transformer (ViT)\narchitecture to leverage its ability to process a variable-length input. The\ninput to the ViT consists of events that are accumulated into time bins and\nspatially separated into non-overlapping sub-regions called patches. Patches\nare selected when the number of nonzero pixel locations within a sub-region is\nabove a threshold. We show that by fine-tuning a ViT model on the selected\nactive patches, we can reduce the average number of patches fed into the\nbackbone during the inference by at least 50% with only a minor drop (0.34%) of\nthe classification accuracy on the N-Caltech101 dataset. This reduction\ntranslates into a decrease of 51% in Multiply-Accumulate (MAC) operations and\nan increase of 46% in the inference speed using a server CPU.",
    "descriptor": "",
    "authors": [
      "Zuowen Wang",
      "Yuhuang Hu",
      "Shih-Chii Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.05054"
  },
  {
    "id": "arXiv:2202.05057",
    "title": "A VM/Containerized Approach for Scaling TinyML Applications",
    "abstract": "Although deep neural networks are typically computationally expensive to use,\ntechnological advances in both the design of hardware platforms and of neural\nnetwork architectures, have made it possible to use powerful models on edge\ndevices. To enable widespread adoption of edge based machine learning, we\nintroduce a set of open-source tools that make it easy to deploy, update and\nmonitor machine learning models on a wide variety of edge devices. Our tools\nbring the concept of containerization to the TinyML world. We propose to\npackage ML and application logic as containers called Runes to deploy onto edge\ndevices. The containerization allows us to target a fragmented\nInternet-of-Things (IoT) ecosystem by providing a common platform for Runes to\nrun across devices.",
    "descriptor": "\nComments: Presented at the tinyML 2021 Research Symposium\n",
    "authors": [
      "Meelis Lootus",
      "Kartik Thakore",
      "Sam Leroux",
      "Geert Trooskens",
      "Akshay Sharma",
      "Holly Ly"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2202.05057"
  },
  {
    "id": "arXiv:2202.05063",
    "title": "PCENet: High Dimensional Deep Surrogate Modeling",
    "abstract": "Learning data representations under uncertainty is an important task that\nemerges in numerous machine learning applications. However, uncertainty\nquantification (UQ) techniques are computationally intensive and become\nprohibitively expensive for high-dimensional data. In this paper, we present a\nnovel surrogate model for representation learning and uncertainty\nquantification, which aims to deal with data of moderate to high dimensions.\nThe proposed model combines a neural network approach for dimensionality\nreduction of the (potentially high-dimensional) data, with a surrogate model\nmethod for learning the data distribution. We first employ a variational\nautoencoder (VAE) to learn a low-dimensional representation of the data\ndistribution. We then propose to harness polynomial chaos expansion (PCE)\nformulation to map this distribution to the output target. The coefficients of\nPCE are learned from the distribution representation of the training data using\na maximum mean discrepancy (MMD) approach. Our model enables us to (a) learn a\nrepresentation of the data, (b) estimate uncertainty in the high-dimensional\ndata system, and (c) match high order moments of the output distribution;\nwithout any prior statistical assumptions on the data. Numerical experimental\nresults are presented to illustrate the performance of the proposed method.",
    "descriptor": "",
    "authors": [
      "Paz Fink Shustin",
      "Shashanka Ubaru",
      "Vasileios Kalantzis",
      "Lior Horesh",
      "Haim Avron"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.05063"
  },
  {
    "id": "arXiv:2202.05065",
    "title": "Natural Language in Requirements Engineering for Structure Inference --  An Integrative Review",
    "abstract": "The automatic extraction of structure from text can be difficult for\nmachines. Yet, the elicitation of this information can provide many benefits\nand opportunities for various applications. Benefits have also been identified\nfor the area of Requirements Engineering. To evaluate what work has been done\nand is currently available, the paper at hand provides an integrative review\nregarding Natural Language Processing (NLP) tools for Requirements Engineering.\nThis assessment was conducted to provide a foundation for future work as well\nas deduce insights from the stats quo. To conduct the review, the history of\nRequirements Engineering and NLP are described as well as an evaluation of over\n136 NLP tools. To assess these tools, a set of criteria was defined. The\nresults are that currently no open source approach exists that allows for the\ndirect/primary extraction of information structure and even closed source\nsolutions show limitations such as supervision or input limitations, which\neliminates the possibility for fully automatic and universal application. As a\nresults, the authors deduce that the current approaches are not applicable and\na different methodology is necessary. An approach that allows for individual\nmanagement of the algorithm, knowledge base, and text corpus is a possibility\nbeing pursued.",
    "descriptor": "\nComments: 16 pages, 6 figures\n",
    "authors": [
      "Maximilian Vierlboeck",
      "Carlo Lipizzi",
      "Roshanak Nilchiani"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.05065"
  },
  {
    "id": "arXiv:2202.05068",
    "title": "Controlling the Complexity and Lipschitz Constant improves polynomial  nets",
    "abstract": "While the class of Polynomial Nets demonstrates comparable performance to\nneural networks (NN), it currently has neither theoretical generalization\ncharacterization nor robustness guarantees. To this end, we derive new\ncomplexity bounds for the set of Coupled CP-Decomposition (CCP) and Nested\nCoupled CP-decomposition (NCP) models of Polynomial Nets in terms of the\n$\\ell_\\infty$-operator-norm and the $\\ell_2$-operator norm. In addition, we\nderive bounds on the Lipschitz constant for both models to establish a\ntheoretical certificate for their robustness. The theoretical results enable us\nto propose a principled regularization scheme that we also evaluate\nexperimentally in six datasets and show that it improves the accuracy as well\nas the robustness of the models to adversarial perturbations. We showcase how\nthis regularization can be combined with adversarial training, resulting in\nfurther improvements.",
    "descriptor": "",
    "authors": [
      "Zhenyu Zhu",
      "Fabian Latorre",
      "Grigorios G Chrysos",
      "Volkan Cevher"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.05068"
  },
  {
    "id": "arXiv:2202.05072",
    "title": "Optimised operation of low-emission offshore oil and gas platform  integrated energy systems",
    "abstract": "This paper considers the operation of offshore oil and gas platform energy\nsystems with energy supply from wind turbines to reduce local CO2 emissions. A\nnew integrated energy system model for operational planning and simulation has\nbeen developed and implemented in an open-source software tool (Oogeso). This\nmodel and tool is first presented, and then applied on a relevant North Sea\ncase with different energy supply alternatives to quantify and compare CO2\nemission reductions and other key indicators.",
    "descriptor": "",
    "authors": [
      "Harald G Svendsen"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.05072"
  },
  {
    "id": "arXiv:2202.05074",
    "title": "Leveraging Google's Publisher-specific IDs to Detect Website  Administration",
    "abstract": "Digital advertising is the most popular way for content monetization on the\nInternet. Publishers spawn new websites, and older ones change hands with the\nsole purpose of monetizing user traffic. In this ever-evolving ecosystem, it is\nchallenging to effectively answer questions such as: Which entities monetize\nwhat websites? What categories of websites does an average entity typically\nmonetize on and how diverse are these websites? How has this website\nadministration ecosystem changed across time?\nIn this paper, we propose a novel, graph-based methodology to detect\nadministration of websites on the Web, by exploiting the ad-related\npublisher-specific IDs. We apply our methodology across the top 1 million\nwebsites and study the characteristics of the created graphs of website\nadministration. Our findings show that approximately 90% of the websites are\nassociated each with a single publisher, and that small publishers tend to\nmanage less popular websites. We perform a historical analysis of up to 8\nmillion websites, and find a new, constantly rising number of (intermediary)\npublishers that control and monetize traffic from hundreds of websites, seeking\na share of the ad-market pie. We also observe that over time, websites tend to\nmove from big to smaller administrators.",
    "descriptor": "\nComments: 10 pages, To be published at The Web Conference 2022 (WWW 2022). Please cite the WWW version\n",
    "authors": [
      "Emmanouil Papadogiannakis",
      "Panagiotis Papadopoulos",
      "Evangelos P. Markatos",
      "Nicolas Kourtellis"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2202.05074"
  },
  {
    "id": "arXiv:2202.05079",
    "title": "Who Funds Misinformation? A Systematic Analysis of the Ad-related Profit  Routines of Fake News sites",
    "abstract": "Fake news is an age-old phenomenon, widely assumed to be associated with\npolitical propaganda published to sway public opinion. Yet, with the growth of\nsocial media it has become a lucrative business for web publishers. Despite\nmany studies performed and countermeasures deployed from researchers and\nstakeholders, unreliable news sites have increased their share of engagement\namong the top performing news sources in last years. Indeed, stifling fake news\nimpact depends on the efforts from the society, and the market, in limiting the\n(economic) incentives of fake news producers.\nIn this paper, we aim at enhancing the transparency around these exact\nincentives and explore the following main questions: Who supports the existence\nof fake news websites via paid ads, either as an advertiser or an ad seller?\nWho owns these websites and what other Web business are they into? What\ntracking activity do they perform in these websites?\nAiming to answer these questions, we are the first to systematize the\nauditing process of fake news revenue flows. We develop a novel ad detection\nmethodology to identify the companies that advertise in fake news websites and\nthe intermediary companies responsible for facilitating those ad revenues. We\nstudy more than 2400 popular fake and real news websites and show that\nwell-known legitimate ad networks, such as of Google, IndexExchange, and\nAppNexus, have a direct advertising relation with more than 40% of these fake\nnews websites, and a re-seller advertising relation with more than 60% of them.\nUsing a graph clustering approach on an extended set of 114.5K sites connected\nwith 443K edges, we show that entities who own fake news websites, also own (or\noperate) other types of websites for entertainment, business, and politics,\npointing to the fact that owning a fake news website is part of a broader\nbusiness operation.",
    "descriptor": "\nComments: 18 pages\n",
    "authors": [
      "Emmanouil Papadogiannakis",
      "Panagiotis Papadopoulos",
      "Evangelos P. Markatos",
      "Nicolas Kourtellis"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2202.05079"
  },
  {
    "id": "arXiv:2202.05085",
    "title": "MONI can find k-MEMs",
    "abstract": "Maximal exact matches (MEMs) have been widely used in bioinformatics at least\nsince Li (2013) presented BWA-MEM. Building on work by Bannai, Gagie and I\n(2018), Rossi et al.\\ (2022) recently built an index called MONI, based on the\nrun-length compressed Burrows-Wheeler Transform, that can find MEMs efficiently\nwith respect to pangenomes. In this paper we define $k$-MEMs to be maximal\nsubstrings of a pattern that each occur exactly at $k$ times in a text (so a\nMEM is a 1-MEM) and show that, when $k$ is given at construction time, MONI can\nfind $k$-MEMs efficiently as well.",
    "descriptor": "",
    "authors": [
      "Travis Gagie"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2202.05085"
  },
  {
    "id": "arXiv:2202.05086",
    "title": "Complexity of Arithmetic in Warded Datalog+-",
    "abstract": "Warded Datalog+- extends the logic-based language Datalog with existential\nquantifiers in rule heads. Existential rules are needed for advanced reasoning\ntasks, e.g., ontological reasoning. The theoretical efficiency guarantees of\nWarded Datalog+- do not cover extensions crucial for data analytics, such as\narithmetic. Moreover, despite the significance of arithmetic for common data\nanalytic scenarios, no decidable fragment of any Datalog+- language extended\nwith arithmetic has been identified. We close this gap by defining a new\nlanguage that extends Warded Datalog+- with arithmetic and prove its\nP-completeness. Furthermore, we present an efficient reasoning algorithm for\nour newly defined language and prove descriptive complexity results for a\nrecently introduced Datalog fragment with integer arithmetic, thereby closing\nan open question. We lay the theoretical foundation for highly expressive\nDatalog+- languages that combine the power of advanced recursive rules and\narithmetic while guaranteeing efficient reasoning algorithms for applications\nin modern AI systems, such as Knowledge Graphs.",
    "descriptor": "",
    "authors": [
      "Lucas Berent",
      "Markus Nissl",
      "Emanuel Sallinger"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2202.05086"
  },
  {
    "id": "arXiv:2202.05089",
    "title": "Backpropagation Clipping for Deep Learning with Differential Privacy",
    "abstract": "We present backpropagation clipping, a novel variant of differentially\nprivate stochastic gradient descent (DP-SGD) for privacy-preserving deep\nlearning. Our approach clips each trainable layer's inputs (during the forward\npass) and its upstream gradients (during the backward pass) to ensure bounded\nglobal sensitivity for the layer's gradient; this combination replaces the\ngradient clipping step in existing DP-SGD variants. Our approach is simple to\nimplement in existing deep learning frameworks. The results of our empirical\nevaluation demonstrate that backpropagation clipping provides higher accuracy\nat lower values for the privacy parameter $\\epsilon$ compared to previous work.\nWe achieve 98.7% accuracy for MNIST with $\\epsilon = 0.07$ and 74% accuracy for\nCIFAR-10 with $\\epsilon = 3.64$.",
    "descriptor": "\nComments: 11 Pages, 6 figures and tables\n",
    "authors": [
      "Timothy Stevens",
      "Ivoline C. Ngong",
      "David Darais",
      "Calvin Hirsch",
      "David Slater",
      "Joseph P. Near"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.05089"
  },
  {
    "id": "arXiv:2202.05093",
    "title": "Two-Stage Deep Anomaly Detection with Heterogeneous Time Series Data",
    "abstract": "We introduce a data-driven anomaly detection framework using a manufacturing\ndataset collected from a factory assembly line. Given heterogeneous time series\ndata consisting of operation cycle signals and sensor signals, we aim at\ndiscovering abnormal events. Motivated by our empirical findings that\nconventional single-stage benchmark approaches may not exhibit satisfactory\nperformance under our challenging circumstances, we propose a two-stage deep\nanomaly detection (TDAD) framework in which two different unsupervised learning\nmodels are adopted depending on types of signals. In Stage I, we select anomaly\ncandidates by using a model trained by operation cycle signals; in Stage II, we\nfinally detect abnormal events out of the candidates by using another model,\nwhich is suitable for taking advantage of temporal continuity, trained by\nsensor signals. A distinguishable feature of our framework is that operation\ncycle signals are exploited first to find likely anomalous points, whereas\nsensor signals are leveraged to filter out unlikely anomalous points afterward.\nOur experiments comprehensively demonstrate the superiority over single-stage\nbenchmark approaches, the model-agnostic property, and the robustness to\ndifficult situations.",
    "descriptor": "\nComments: 10 pages, 4 figures, 4 tables; published in the IEEE Access (Please cite our journal version.)\n",
    "authors": [
      "Kyeong-Joong Jeong",
      "Jin-Duk Park",
      "Kyusoon Hwang",
      "Seong-Lyun Kim",
      "Won-Yong Shin"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.05093"
  },
  {
    "id": "arXiv:2202.05094",
    "title": "Hardware calibrated learning to compensate heterogeneity in analog  RRAM-based Spiking Neural Networks",
    "abstract": "Spiking Neural Networks (SNNs) can unleash the full power of analog Resistive\nRandom Access Memories (RRAMs) based circuits for low power signal processing.\nTheir inherent computational sparsity naturally results in energy efficiency\nbenefits. The main challenge implementing robust SNNs is the intrinsic\nvariability (heterogeneity) of both analog CMOS circuits and RRAM technology.\nIn this work, we assessed the performance and variability of RRAM-based\nneuromorphic circuits that were designed and fabricated using a 130\\,nm\ntechnology node. Based on these results, we propose a Neuromorphic Hardware\nCalibrated (NHC) SNN, where the learning circuits are calibrated on the\nmeasured data. We show that by taking into account the measured heterogeneity\ncharacteristics in the off-chip learning phase, the NHC SNN self-corrects its\nhardware non-idealities and learns to solve benchmark tasks with high accuracy.\nThis work demonstrates how to cope with the heterogeneity of neurons and\nsynapses for increasing classification accuracy in temporal tasks.",
    "descriptor": "\nComments: Preprint for ISCAS2022\n",
    "authors": [
      "Filippo Moro",
      "E. Esmanhotto",
      "T. Hirtzlin",
      "N. Castellani",
      "A. Trabelsi",
      "T. Dalgaty",
      "G. Molas",
      "F. Andrieu",
      "S. Brivio",
      "S. Spiga",
      "G. Indiveri",
      "M. Payvand",
      "E. Vianello"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.05094"
  },
  {
    "id": "arXiv:2202.05096",
    "title": "Near-Optimal Statistical Query Lower Bounds for Agnostically Learning  Intersections of Halfspaces with Gaussian Marginals",
    "abstract": "We consider the well-studied problem of learning intersections of halfspaces\nunder the Gaussian distribution in the challenging \\emph{agnostic learning}\nmodel. Recent work of Diakonikolas et al. (2021) shows that any Statistical\nQuery (SQ) algorithm for agnostically learning the class of intersections of\n$k$ halfspaces over $\\mathbb{R}^n$ to constant excess error either must make\nqueries of tolerance at most $n^{-\\tilde{\\Omega}(\\sqrt{\\log k})}$ or must make\n$2^{n^{\\Omega(1)}}$ queries. We strengthen this result by improving the\ntolerance requirement to $n^{-\\tilde{\\Omega}(\\log k)}$. This lower bound is\nessentially best possible since an SQ algorithm of Klivans et al. (2008)\nagnostically learns this class to any constant excess error using $n^{O(\\log\nk)}$ queries of tolerance $n^{-O(\\log k)}$. We prove two variants of our lower\nbound, each of which combines ingredients from Diakonikolas et al. (2021) with\n(an extension of) a different earlier approach for agnostic SQ lower bounds for\nthe Boolean setting due to Dachman-Soled et al. (2014). Our approach also\nyields lower bounds for agnostically SQ learning the class of \"convex subspace\njuntas\" (studied by Vempala, 2010) and the class of sets with bounded Gaussian\nsurface area; all of these lower bounds are nearly optimal since they\nessentially match known upper bounds from Klivans et al. (2008).",
    "descriptor": "\nComments: 19 pages\n",
    "authors": [
      "Daniel Hsu",
      "Clayton Sanford",
      "Rocco Servedio",
      "Emmanouil-Vasileios Vlatakis-Gkaragkounis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.05096"
  },
  {
    "id": "arXiv:2202.05101",
    "title": "Characterizations of Adjoint Sobolev Embedding Operators for Inverse  Problems",
    "abstract": "We consider the Sobolev embedding operator $E_s : H^s(\\Omega) \\to\nL_2(\\Omega)$ and its role in the solution of inverse problems. In particular,\nwe collect various properties and representations of its adjoint operator\n$E_s^*$, which is a common component in both iterative and variational\nregularization methods. These include e.g. variational representations and\nconnections to boundary value problems, Fourier and wavelet representations, as\nwell as connections to spatial filters. While many of these results are already\nknown to researchers from different fields, an overview or reference work is\nstill missing. Hence, in this paper we aim to fill this gap, providing a\ncollection of representations of $E_s^*$ which can serve both as a reference as\nwell as a useful guide for its efficient numerical implementation in practice.",
    "descriptor": "\nComments: 32 pages\n",
    "authors": [
      "Simon Hubmer",
      "Ekaterina Sherina"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.05101"
  },
  {
    "id": "arXiv:2202.05107",
    "title": "Machine Learning-based Urban Canyon Path Loss Prediction using 28 GHz  Manhattan Measurements",
    "abstract": "Large bandwidth at mm-wave is crucial for 5G and beyond but the high path\nloss (PL) requires highly accurate PL prediction for network planning and\noptimization. Statistical models with slope-intercept fit fall short in\ncapturing large variations seen in urban canyons, whereas ray-tracing, capable\nof characterizing site-specific features, faces challenges in describing\nfoliage and street clutter and associated reflection/diffraction ray\ncalculation. Machine learning (ML) is promising but faces three key challenges\nin PL prediction: 1) insufficient measurement data; 2) lack of extrapolation to\nnew streets; 3) overwhelmingly complex features/models. We propose an ML-based\nurban canyon PL prediction model based on extensive 28 GHz measurements from\nManhattan where street clutters are modeled via a LiDAR point cloud dataset and\nbuildings by a mesh-grid building dataset. We extract expert knowledge-driven\nstreet clutter features from the point cloud and aggressively compress\n3D-building information using convolutional-autoencoder. Using a new\nstreet-by-street training and testing procedure to improve generalizability,\nthe proposed model using both clutter and building features achieves a\nprediction error (RMSE) of $4.8 \\pm 1.1$ dB compared to $10.6 \\pm 4.4$ dB and\n$6.5 \\pm 2.0$ dB for 3GPP LOS and slope-intercept prediction, respectively,\nwhere the standard deviation indicates street-by-street variation. By only\nusing four most influential clutter features, RMSE of $5.5\\pm 1.1$ dB is\nachieved.",
    "descriptor": "\nComments: Accepted for publication at IEEE Transactions on Antennas and Propagation\n",
    "authors": [
      "Ankit Gupta",
      "Jinfeng Du",
      "Dmitry Chizhik",
      "Reinaldo A. Valenzuela",
      "Mathini Sellathurai"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.05107"
  },
  {
    "id": "arXiv:2202.05115",
    "title": "Spoiler Susceptibility in Multi-District Party Elections",
    "abstract": "Electoral spoilers are such agents that there exists a coalition of agents\nwhose total gain when a putative spoiler is eliminated exceeds that spoiler's\nshare in the election outcome. So far spoiler effects have been analyzed\nprimarily in the context of single-winner electoral systems. We consider this\nproblem in the context of multi-district party elections. We introduce a formal\nmeasure of a party's excess electoral impact, treating \"spoilership\" as a\nmanner of degree. This approach allows us to compare multi-winner social choice\nrules according to their degree of spoiler susceptibility. We present\nexperimental results, as well as analytical results for toy models, for seven\nclassical rules ($k$-Borda, Chamberlin--Courant, Harmonic-Borda,\nJefferson--D'Hondt, PAV, SNTV, and STV). Since the probabilistic models\ncommonly used in computational social choice have been developed for non-party\nelections, we extend them to be able to generate multi-district party\nelections.",
    "descriptor": "\nComments: 19 pages, 3 figures\n",
    "authors": [
      "Daria Boratyn",
      "Wojciech S\u0142omczy\u0144ski",
      "Dariusz Stolicki",
      "Stanis\u0142aw Szufa"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2202.05115"
  },
  {
    "id": "arXiv:2202.05118",
    "title": "Reinforcement Learning in the Wild: Scalable RL Dispatching Algorithm  Deployed in Ridehailing Marketplace",
    "abstract": "In this study, a real-time dispatching algorithm based on reinforcement\nlearning is proposed and for the first time, is deployed in large scale.\nCurrent dispatching methods in ridehailing platforms are dominantly based on\nmyopic or rule-based non-myopic approaches. Reinforcement learning enables\ndispatching policies that are informed of historical data and able to employ\nthe learned information to optimize returns of expected future trajectories.\nPrevious studies in this field yielded promising results, yet have left room\nfor further improvements in terms of performance gain, self-dependency,\ntransferability, and scalable deployment mechanisms. The present study proposes\na standalone RL-based dispatching solution that is equipped with multiple\nmechanisms to ensure robust and efficient on-policy learning and inference\nwhile being adaptable for full-scale deployment. A new form of value updating\nbased on temporal difference is proposed that is more adapted to the inherent\nuncertainty of the problem. For the driver-order assignment, a customized\nutility function is proposed that when tuned based on the statistics of the\nmarket, results in remarkable performance improvement and interpretability. In\naddition, for reducing the risk of cancellation after drivers' assignment, an\nadaptive graph pruning strategy based on the multi-arm bandit problem is\nintroduced. The method is evaluated using offline simulation with real data and\nyields notable performance improvement. In addition, the algorithm is deployed\nonline in multiple cities under DiDi's operation for A/B testing and is\nlaunched in one of the major international markets as the primary mode of\ndispatch. The deployed algorithm shows over 1.3% improvement in total driver\nincome from A/B testing. In addition, by causal inference analysis, as much as\n5.3% improvement in major performance metrics is detected after full-scale\ndeployment.",
    "descriptor": "\nComments: submitted to KDD'22\n",
    "authors": [
      "Soheil Sadeghi Eshkevari",
      "Xiaocheng Tang",
      "Zhiwei Qin",
      "Jinhan Mei",
      "Cheng Zhang",
      "Qianying Meng",
      "Jia Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2202.05118"
  },
  {
    "id": "arXiv:2202.05120",
    "title": "Low-Rank Approximation with $1/\u03b5^{1/3}$ Matrix-Vector Products",
    "abstract": "We study iterative methods based on Krylov subspaces for low-rank\napproximation under any Schatten-$p$ norm. Here, given access to a matrix $A$\nthrough matrix-vector products, an accuracy parameter $\\epsilon$, and a target\nrank $k$, the goal is to find a rank-$k$ matrix $Z$ with orthonormal columns\nsuch that $\\| A(I -ZZ^\\top)\\|_{S_p} \\leq (1+\\epsilon)\\min_{U^\\top U = I_k}\n\\|A(I - U U^\\top)\\|_{S_p}$, where $\\|M\\|_{S_p}$ denotes the $\\ell_p$ norm of\nthe the singular values of $M$. For the special cases of $p=2$ (Frobenius norm)\nand $p = \\infty$ (Spectral norm), Musco and Musco (NeurIPS 2015) obtained an\nalgorithm based on Krylov methods that uses $\\tilde{O}(k/\\sqrt{\\epsilon})$\nmatrix-vector products, improving on the na\\\"ive $\\tilde{O}(k/\\epsilon)$\ndependence obtainable by the power method, where $\\tilde{O}$ suppresses\npoly$(\\log(dk/\\epsilon))$ factors.\nOur main result is an algorithm that uses only\n$\\tilde{O}(kp^{1/6}/\\epsilon^{1/3})$ matrix-vector products, and works for all\n$p \\geq 1$. For $p = 2$ our bound improves the previous\n$\\tilde{O}(k/\\epsilon^{1/2})$ bound to $\\tilde{O}(k/\\epsilon^{1/3})$. Since the\nSchatten-$p$ and Schatten-$\\infty$ norms are the same up to a $1+ \\epsilon$\nfactor when $p \\geq (\\log d)/\\epsilon$, our bound recovers the result of Musco\nand Musco for $p = \\infty$. Further, we prove a matrix-vector query lower bound\nof $\\Omega(1/\\epsilon^{1/3})$ for any fixed constant $p \\geq 1$, showing that\nsurprisingly $\\tilde{\\Theta}(1/\\epsilon^{1/3})$ is the optimal complexity for\nconstant~$k$.\nTo obtain our results, we introduce several new techniques, including\noptimizing over multiple Krylov subspaces simultaneously, and pinching\ninequalities for partitioned operators. Our lower bound for $p \\in [1,2]$ uses\nthe Araki-Lieb-Thirring trace inequality, whereas for $p>2$, we appeal to a\nnorm-compression inequality for aligned partitioned operators.",
    "descriptor": "",
    "authors": [
      "Ainesh Bakshi",
      "Kenneth L. Clarkson",
      "David P. Woodruff"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.05120"
  },
  {
    "id": "arXiv:2202.05123",
    "title": "Unaligned but Safe -- Formally Compensating Performance Limitations for  Imprecise 2D Object Detection",
    "abstract": "In this paper, we consider the imperfection within machine learning-based 2D\nobject detection and its impact on safety. We address a special sub-type of\nperformance limitations: the prediction bounding box cannot be perfectly\naligned with the ground truth, but the computed Intersection-over-Union metric\nis always larger than a given threshold. Under such type of performance\nlimitation, we formally prove the minimum required bounding box enlargement\nfactor to cover the ground truth. We then demonstrate that the factor can be\nmathematically adjusted to a smaller value, provided that the motion planner\ntakes a fixed-length buffer in making its decisions. Finally, observing the\ndifference between an empirically measured enlargement factor and our formally\nderived worst-case enlargement factor offers an interesting connection between\nthe quantitative evidence (demonstrated by statistics) and the qualitative\nevidence (demonstrated by worst-case analysis).",
    "descriptor": "",
    "authors": [
      "Tobias Schuster",
      "Emmanouil Seferis",
      "Simon Burton",
      "Chih-Hong Cheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.05123"
  },
  {
    "id": "arXiv:2202.05127",
    "title": "Improved Compression of the Okamura-Seymour Metric",
    "abstract": "Let $G=(V,E)$ be an undirected unweighted planar graph. Consider a vector\nstoring the distances from an arbitrary vertex $v$ to all vertices $S = \\{ s_1\n, s_2 , \\ldots , s_k \\}$ of a single face in their cyclic order. The pattern of\n$v$ is obtained by taking the difference between every pair of consecutive\nvalues of this vector. In STOC'19, Li and Parter used a VC-dimension argument\nto show that in planar graphs, the number of distinct patterns, denoted $x$, is\nonly $O(k^3)$. This resulted in a simple compression scheme requiring $\\tilde\nO(\\min \\{ k^4+|T|, k\\cdot |T|\\})$ space to encode the distances between $S$ and\na subset of terminal vertices $T \\subseteq V$. This is known as the\nOkamura-Seymour metric compression problem.\nWe give an alternative proof of the $x=O(k^3)$ bound that exploits planarity\nbeyond the VC-dimension argument. Namely, our proof relies on cut-cycle\nduality, as well as on the fact that distances among vertices of $S$ are\nbounded by $k$. Our method implies the following:\n(1) An $\\tilde{O}(x+k+|T|)$ space compression of the Okamura-Seymour metric,\nthus improving the compression of Li and Parter to $\\tilde O(\\min \\{k^3+|T|,k\n\\cdot |T| \\})$.\n(2) An optimal $\\tilde{O}(k+|T|)$ space compression of the Okamura-Seymour\nmetric, in the case where the vertices of $T$ induce a connected component in\n$G$.\n(3) A tight bound of $x = \\Theta(k^2)$ for the family of Halin graphs,\nwhereas the VC-dimension argument is limited to showing $x=O(k^3)$.",
    "descriptor": "",
    "authors": [
      "Shay Mozes",
      "Nathan Wallheimer",
      "Oren Weimann"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2202.05127"
  },
  {
    "id": "arXiv:2202.05129",
    "title": "Help Me Explore: Minimal Social Interventions for Graph-Based Autotelic  Agents",
    "abstract": "In the quest for autonomous agents learning open-ended repertoires of skills,\nmost works take a Piagetian perspective: learning trajectories are the results\nof interactions between developmental agents and their physical environment.\nThe Vygotskian perspective, on the other hand, emphasizes the centrality of the\nsocio-cultural environment: higher cognitive functions emerge from\ntransmissions of socio-cultural processes internalized by the agent. This paper\nargues that both perspectives could be coupled within the learning of autotelic\nagents to foster their skill acquisition. To this end, we make two\ncontributions: 1) a novel social interaction protocol called Help Me Explore\n(HME), where autotelic agents can benefit from both individual and socially\nguided exploration. In social episodes, a social partner suggests goals at the\nfrontier of the learning agent knowledge. In autotelic episodes, agents can\neither learn to master their own discovered goals or autonomously rehearse\nfailed social goals; 2) GANGSTR, a graph-based autotelic agent for manipulation\ndomains capable of decomposing goals into sequences of intermediate sub-goals.\nWe show that when learning within HME, GANGSTR overcomes its individual\nlearning limits by mastering the most complex configurations (e.g. stacks of 5\nblocks) with only few social interventions.",
    "descriptor": "\nComments: 18 pages, 11 figures\n",
    "authors": [
      "Ahmed Akakzia",
      "Olivier Serris",
      "Olivier Sigaud",
      "C\u00e9dric Colas"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2202.05129"
  },
  {
    "id": "arXiv:2202.05134",
    "title": "Understanding Twitters behavior during the pandemic: Fake News and Fear",
    "abstract": "The outbreak of the SARS-CoV-2 novel coronavirus (COVID-19) has been\naccompanied by a large amount of misleading and false information about the\nvirus, especially on social media. During the pandemic social media gained\nspecial interest as it went on to become an important medium of communication.\nThis made the information being relayed on these platforms especially critical.\nIn our work, we aim to explore the percentage of fake news being spread on\nTwitter as well as measure the sentiment of the public at the same time. We\nfurther study how the sentiment of fear is present among the public. In\naddition to that we compare the rate of spread of the virus per day with the\nrate of spread of fake news on Twitter. Our study is useful in establishing the\nrole of Twitter, and social media, during a crisis, and more specifically\nduring crisis management.",
    "descriptor": "\nComments: 21 pages, 5 figures\n",
    "authors": [
      "Guillermo Romera Rodriguez",
      "Sanjana Gautam",
      "Andrea Tapia"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2202.05134"
  },
  {
    "id": "arXiv:2202.05135",
    "title": "DDA3C: Cooperative Distributed Deep Reinforcement Learning in A  Group-Agent System",
    "abstract": "It can largely benefit the reinforcement learning process of each agent if\nmultiple agents perform their separate reinforcement learning tasks\ncooperatively. These tasks can be not exactly the same but still benefit from\nthe communication behaviour between agents due to task similarities. In fact,\nthis learning scenario is not well understood yet and not well formulated. As\nthe first effort, we provide a detailed discussion of this scenario, and\npropose group-agent reinforcement learning as a formulation of the\nreinforcement learning problem under this scenario and a third type of\nreinforcement learning problem with respect to single-agent and multi-agent\nreinforcement learning. We propose that it can be solved with the help of\nmodern deep reinforcement learning techniques and provide a distributed deep\nreinforcement learning algorithm called DDA3C (Decentralised Distributed\nAsynchronous Advantage Actor-Critic) that is the first framework designed for\ngroup-agent reinforcement learning. We show through experiments in the\nCartPole-v0 game environment that DDA3C achieved desirable performance and has\ngood scalability.",
    "descriptor": "",
    "authors": [
      "Kaiyue Wu",
      "Xiao-Jun Zeng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.05135"
  },
  {
    "id": "arXiv:2202.05137",
    "title": "Quantization in Layer's Input is Matter",
    "abstract": "In this paper, we will show that the quantization in layer's input is more\nimportant than parameters' quantization for loss function. And the algorithm\nwhich is based on the layer's input quantization error is better than\nhessian-based mixed precision layout algorithm.",
    "descriptor": "",
    "authors": [
      "Daning Cheng",
      "WenGuang Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.05137"
  },
  {
    "id": "arXiv:2202.05139",
    "title": "Game of Privacy: Towards Better Federated Platform Collaboration under  Privacy Restriction",
    "abstract": "Vertical federated learning (VFL) aims to train models from cross-silo data\nwith different feature spaces stored on different platforms. Existing VFL\nmethods usually assume all data on each platform can be used for model\ntraining. However, due to the intrinsic privacy risks of federated learning,\nthe total amount of involved data may be constrained. In addition, existing VFL\nstudies usually assume only one platform has task labels and can benefit from\nthe collaboration, making it difficult to attract other platforms to join in\nthe collaborative learning. In this paper, we study the platform collaboration\nproblem in VFL under privacy constraint. We propose to incent different\nplatforms through a reciprocal collaboration, where all platforms can exploit\nmulti-platform information in the VFL framework to benefit their own tasks.\nWith limited privacy budgets, each platform needs to wisely allocate its data\nquotas for collaboration with other platforms. Thereby, they naturally form a\nmulti-party game. There are two core problems in this game, i.e., how to\nappraise other platforms' data value to compute game rewards and how to\noptimize policies to solve the game. To evaluate the contributions of other\nplatforms' data, each platform offers a small amount of \"deposit\" data to\nparticipate in the VFL. We propose a performance estimation method to predict\nthe expected model performance when involving different amount combinations of\ninter-platform data. To solve the game, we propose a platform negotiation\nmethod that simulates the bargaining among platforms and locally optimizes\ntheir policies via gradient descent. Extensive experiments on two real-world\ndatasets show that our approach can effectively facilitate the collaborative\nexploitation of multi-platform data in VFL under privacy restrictions.",
    "descriptor": "\nComments: Submitted to KDD 2022\n",
    "authors": [
      "Chuhan Wu",
      "Fangzhao Wu",
      "Tao Qi",
      "Yanlin Wang",
      "Yongfeng Huang",
      "Xing Xie"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.05139"
  },
  {
    "id": "arXiv:2202.05140",
    "title": "Transferable and Adaptable Driving Behavior Prediction",
    "abstract": "While autonomous vehicles still struggle to solve challenging situations\nduring on-road driving, humans have long mastered the essence of driving with\nefficient, transferable, and adaptable driving capability. By mimicking humans'\ncognition model and semantic understanding during driving, we propose HATN, a\nhierarchical framework to generate high-quality, transferable, and adaptable\npredictions for driving behaviors in multi-agent dense-traffic environments.\nOur hierarchical method consists of a high-level intention identification\npolicy and a low-level trajectory generation policy. We introduce a novel\nsemantic sub-task definition and generic state representation for each\nsub-task. With these techniques, the hierarchical framework is transferable\nacross different driving scenarios. Besides, our model is able to capture\nvariations of driving behaviors among individuals and scenarios by an online\nadaptation module. We demonstrate our algorithms in the task of trajectory\nprediction for real traffic data at intersections and roundabouts from the\nINTERACTION dataset. Through extensive numerical studies, it is evident that\nour method significantly outperformed other methods in terms of prediction\naccuracy, transferability, and adaptability. Pushing the state-of-the-art\nperformance by a considerable margin, we also provide a cognitive view of\nunderstanding the driving behavior behind such improvement. We highlight that\nin the future, more research attention and effort are deserved for\ntransferability and adaptability. It is not only due to the promising\nperformance elevation of prediction and planning algorithms, but more\nfundamentally, they are crucial for the scalable and general deployment of\nautonomous vehicles.",
    "descriptor": "\nComments: 22 pages, 12 figure. arXiv admin note: substantial text overlap with arXiv:2111.00788\n",
    "authors": [
      "Letian Wang",
      "Yeping Hu",
      "Liting Sun",
      "Wei Zhan",
      "Masayoshi Tomizuka",
      "Changliu Liu"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.05140"
  },
  {
    "id": "arXiv:2202.05143",
    "title": "On the Acquisition of Stationary Signals Using Uniform ADCs",
    "abstract": "In this work, we consider the acquisition of stationary signals using uniform\nanalog-to-digital converters (ADCs), i.e., employing uniform sampling and\nscalar uniform quantization. We jointly optimize the pre-sampling and\nreconstruction filters to minimize the time-averaged mean-squared error (TMSE)\nin recovering the continuous-time input signal for a fixed sampling rate and\nquantizer resolution and obtain closed-form expressions for the minimal\nachievable TMSE. We show that the TMSE-minimizing pre-sampling filter omits\naliasing and discards weak frequency components to resolve the remaining ones\nwith higher resolution when the rate budget is small. In our numerical study,\nwe validate our results and show that sub-Nyquist sampling often minimizes the\nTMSE under tight rate budgets at the output of the ADC.",
    "descriptor": "\nComments: Accepted for presentation at the 2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), Singapore, Singapore\n",
    "authors": [
      "Peter Neuhaus",
      "Nir Shlezinger",
      "Meik D\u00f6rpinghaus",
      "Yonina C. Eldar",
      "Gerhard Fettweis"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.05143"
  },
  {
    "id": "arXiv:2202.05144",
    "title": "InPars: Data Augmentation for Information Retrieval using Large Language  Models",
    "abstract": "The information retrieval community has recently witnessed a revolution due\nto large pretrained transformer models. Another key ingredient for this\nrevolution was the MS MARCO dataset, whose scale and diversity has enabled\nzero-shot transfer learning to various tasks. However, not all IR tasks and\ndomains can benefit from one single dataset equally. Extensive research in\nvarious NLP tasks has shown that using domain-specific training data, as\nopposed to a general-purpose one, improves the performance of neural models. In\nthis work, we harness the few-shot capabilities of large pretrained language\nmodels as synthetic data generators for IR tasks. We show that models finetuned\nsolely on our unsupervised dataset outperform strong baselines such as BM25 as\nwell as recently proposed self-supervised dense retrieval methods. Furthermore,\nretrievers finetuned on both supervised and our synthetic data achieve better\nzero-shot transfer than models finetuned only on supervised data. Code, models,\nand data are available at https://github.com/zetaalphavector/inpars .",
    "descriptor": "",
    "authors": [
      "Luiz Bonifacio",
      "Hugo Abonizio",
      "Marzieh Fadaee",
      "Rodrigo Nogueira"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.05144"
  },
  {
    "id": "arXiv:2202.05148",
    "title": "Identifying Weaknesses in Machine Translation Metrics Through Minimum  Bayes Risk Decoding: A Case Study for COMET",
    "abstract": "Neural metrics have achieved impressive correlation with human judgements in\nthe evaluation of machine translation systems, but before we can safely\noptimise towards such metrics, we should be aware of (and ideally eliminate)\nbiases towards bad translations that receive high scores. Our experiments show\nthat sample-based Minimum Bayes Risk decoding can be used to explore and\nquantify such weaknesses. When applying this strategy to COMET for en-de and\nde-en, we find that COMET models are not sensitive enough to discrepancies in\nnumbers and named entities. We further show that these biases cannot be fully\nremoved by simply training on additional synthetic data.",
    "descriptor": "",
    "authors": [
      "Chantal Amrhein",
      "Rico Sennrich"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.05148"
  },
  {
    "id": "arXiv:2202.05152",
    "title": "Feature-level augmentation to improve robustness of deep neural networks  to affine transformations",
    "abstract": "Recent studies revealed that convolutional neural networks do not generalize\nwell to small image transformations, e.g. rotations by a few degrees or\ntranslations of a few pixels. To improve the robustness to such\ntransformations, we propose to introduce data augmentation at intermediate\nlayers of the neural architecture, in addition to the common data augmentation\napplied on the input images. By introducing small perturbations to activation\nmaps (features) at various levels, we develop the capacity of the neural\nnetwork to cope with such transformations. We conduct experiments on three\nimage classification benchmarks (Tiny ImageNet, Caltech-256 and Food-101),\nconsidering two different convolutional architectures (ResNet-18 and\nDenseNet-121). When compared with two state-of-the-art methods, the empirical\nresults show that our approach consistently attains the best trade-off between\naccuracy and mean flip rate.",
    "descriptor": "",
    "authors": [
      "Adrian Sandru",
      "Mariana-Iuliana Georgescu",
      "Radu Tudor Ionescu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.05152"
  },
  {
    "id": "arXiv:2202.05155",
    "title": "DeepCENT: Prediction of Censored Event Time via Deep Learning",
    "abstract": "With the rapid advances of deep learning, many computational methods have\nbeen developed to analyze nonlinear and complex right censored data via deep\nlearning approaches. However, the majority of the methods focus on predicting\nsurvival function or hazard function rather than predicting a single valued\ntime to an event. In this paper, we propose a novel method, DeepCENT, to\ndirectly predict the individual time to an event. It utilizes the deep learning\nframework with an innovative loss function that combines the mean square error\nand the concordance index. Most importantly, DeepCENT can handle competing\nrisks, where one type of event precludes the other types of events from being\nobserved. The validity and advantage of DeepCENT were evaluated using\nsimulation studies and illustrated with three publicly available cancer data\nsets.",
    "descriptor": "",
    "authors": [
      "Jong-Hyeon Jeong",
      "Yichen Jia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.05155"
  },
  {
    "id": "arXiv:2202.05159",
    "title": "Optimal reservoir computers for forecasting systems of nonlinear  dynamics",
    "abstract": "Prediction and analysis of systems of nonlinear dynamics is crucial in many\napplications. Here, we study characteristics and optimization of reservoir\ncomputing, a machine learning technique that has gained attention as a suitable\nmethod for this task. By systematically applying Bayesian optimization on\nreservoirs we show that reservoirs of low connectivity perform better than or\nas well as those of high connectivity in forecasting noiseless Lorenz and\ncoupled Wilson-Cowan systems. We also show that, unexpectedly, computationally\neffective reservoirs of unconnected nodes (RUN) outperform reservoirs of linked\nnetwork topologies in predicting these systems. In the presence of noise,\nreservoirs of linked nodes perform only slightly better than RUNs. In contrast\nto previously reported results, we find that the topology of linked reservoirs\nhas no significance in the performance of system prediction. Based on our\nfindings, we give a procedure for designing optimal reservoir computers (RC)\nfor forecasting dynamical systems. This work paves way for computationally\neffective RCs applicable to real-time prediction of signals measured on systems\nof nonlinear dynamics such as EEG or MEG signals measured on a brain.",
    "descriptor": "\nComments: 15 pages, 9 figures\n",
    "authors": [
      "Pauliina K\u00e4rkk\u00e4inen",
      "Riku Linna"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Chaotic Dynamics (nlin.CD)"
    ],
    "url": "https://arxiv.org/abs/2202.05159"
  },
  {
    "id": "arXiv:2202.05163",
    "title": "Machine Learning and Data Science: Foundations, Concepts, Algorithms,  and Tools",
    "abstract": "Today, data is a tool and fuel for businesses to gain important insights and\nimprove their performance. Data science has dominated almost every industry in\nthe world. There is no industry in the world today that does not use data. But\nwho will get this insight? Who processes all the raw data? Everything is done\nby a data analyst or a data scientist.",
    "descriptor": "\nComments: in Persian language\n",
    "authors": [
      "Milad Vazan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.05163"
  },
  {
    "id": "arXiv:2202.05165",
    "title": "Deterministic Non-cooperative Binding in Two-Dimensional Tile Assembly  Systems Must Have Ultimately Periodic Paths",
    "abstract": "We consider non-cooperative binding, so-called 'temperature 1', in\ndeterministic or directed (called here confluent) tile self-assembly systems in\ntwo dimensions and show a necessary and sufficient condition for such system to\nhave an ultimately periodic assembly path. We prove that an infinite maximal\nassembly has an ultimately periodic assembly path if and only if it contains an\ninfinite assembly path that does not intersect a periodic path in the Z2 grid.\nMoreover we show that every infinite assembly must satisfy this condition, and\ntherefore, contains an ultimately periodic path. This result is obtained\nthrough a super-position and a combination of two paths that produce a new path\nwith desired properties, a technique that we call co-grow of two paths. The\npaper is an updated and improved version of the first part of arXiv 1901.08575.",
    "descriptor": "\nComments: 16 pages, 11 pictures. arXiv admin note: substantial text overlap with arXiv:1901.08575\n",
    "authors": [
      "J\u00e9r\u00f4me Durand-Lose",
      "Hendrik Jan Hoogeboom",
      "Nata\u0161a Jonoska"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Computational Geometry (cs.CG)",
      "Discrete Mathematics (cs.DM)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2202.05165"
  },
  {
    "id": "arXiv:2202.05171",
    "title": "Image classification using collective optical modes of an array of  nanolasers",
    "abstract": "Recent advancements in nanolaser design and manufacturing open up\nunprecedented perspectives in terms of high integration densities and ultra-low\npower consumption, making these devices ideal for high-performance optical\ncomputing systems. In this work we exploit the symmetry properties of the\ncollective modes of a nanolaser array for binary image classification. The\nimplementation is based on a 8x8 array, and relies on the activation of a\ncollective optical mode of the array, the so-called \"zero mode\", under\nspatially modulated pump patterns. We demonstrate that a simple training\nstrategy allows us to achieve an overall success rate of 98% in binary image\nrecognition.",
    "descriptor": "",
    "authors": [
      "Giulio Tirabassi",
      "Ji Kaiwen",
      "Cristina Masoller",
      "Alejandro M. Yacomotti"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Image and Video Processing (eess.IV)",
      "Optics (physics.optics)"
    ],
    "url": "https://arxiv.org/abs/2202.05171"
  },
  {
    "id": "arXiv:2202.05175",
    "title": "Application of the Affinity Propagation Clustering Technique to obtain  traffic accident clusters at macro, meso, and micro levels",
    "abstract": "Accident grouping is a crucial step in identifying accident-prone locations.\nAmong the different accident grouping modes, clustering methods present\nexcellent performance for discovering different distributions of accidents in\nspace. This work introduces the Affinity Propagation Clustering (APC) approach\nfor grouping traffic accidents based on criteria of similarity and\ndissimilarity between distributions of data points in space. The APC provides\nmore realistic representations of the distribution of events from similarity\nmatrices between instances. The results showed that when representative data\nsamples obtain, the preference parameter of similarity provides the necessary\nperformance to calibrate the model and generate clusters according to the\ndesired characteristics. In addition, the study demonstrates that the\npreference parameter as a continuous parameter facilitates the calibration and\ncontrol of the model's convergence, allowing the discovery of clustering\npatterns with less effort and greater control of the results",
    "descriptor": "\nComments: 24 pages, 1 figure, 3 tables\n",
    "authors": [
      "Fagner Sutel de Moura",
      "Christine Tessele Nodari"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2202.05175"
  },
  {
    "id": "arXiv:2202.05178",
    "title": "Semidirect Product Key Exchange: the State of Play",
    "abstract": "In this report we survey the various proposals of the key exchange protocol\nknown as semidirect product key exchange (SDPKE). We discuss the various\nplatforms proposed and give an overview of the main cryptanalytic ideas\nrelevant to each scheme.",
    "descriptor": "",
    "authors": [
      "Christopher Battarbee",
      "Delaram Kahrobaei",
      "Siamak F. Shahandashti"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.05178"
  },
  {
    "id": "arXiv:2202.05182",
    "title": "Remote Contextual Bandits",
    "abstract": "We consider a remote contextual multi-armed bandit (CMAB) problem, in which\nthe decision-maker observes the context and the reward, but must communicate\nthe actions to be taken by the agents over a rate-limited communication\nchannel. This can model, for example, a personalized ad placement application,\nwhere the content owner observes the individual visitors to its website, and\nhence has the context information, but must convey the ads that must be shown\nto each visitor to a separate entity that manages the marketing content. In\nthis remote CMAB (R-CMAB) problem, the constraint on the communication rate\nbetween the decision-maker and the agents imposes a trade-off between the\nnumber of bits sent per agent and the acquired average reward. We are\nparticularly interested in characterizing the rate required to achieve\nsub-linear regret. Consequently, this can be considered as a policy compression\nproblem, where the distortion metric is induced by the learning objectives. We\nfirst study the fundamental information theoretic limits of this problem by\nletting the number of agents go to infinity, and study the regret achieved when\nThompson sampling strategy is adopted. In particular, we identify two distinct\nrate regions resulting in linear and sub-linear regret behavior, respectively.\nThen, we provide upper bounds on the achievable regret when the decision-maker\ncan reliably transmit the policy without distortion.",
    "descriptor": "",
    "authors": [
      "Francesco Pase",
      "Deniz Gunduz",
      "Michele Zorzi"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.05182"
  },
  {
    "id": "arXiv:2202.05185",
    "title": "Pok\u00e9mon GO to Pok\u00e9mon STAY: How Covid-19 Affected Pok\u00e9mon GO  Players",
    "abstract": "Since its creation, the Location-Based Game (LBG), Pok\\'emon GO, has been\nembraced by a community of fans across the world. Due to its recency, the\nimpact of COVID-19 on the community of Pok\\'emon GO players is underexplored.\nWe address how COVID-19 has impacted the players of Pok\\'emon GO by building\nupon existing work focusing on player gratifications and impacts in Pok\\'emon\nGO. Through semi-structured interviews, we provide a snapshot of the state of\nLBG play during unprecedented times. These player testimonies demonstrate (1)\nthe importance of in-person socialization to LBG, (2) additional ways players\nuse the game as a coping mechanism, and (3) how intentionality mediates player\nperceptions of people-place relationships. In demonstrating these behaviors, we\nprovide a glimpse of how a game that forces players to explore the world around\nthem changed when going outside with friends became a source of danger.",
    "descriptor": "\nComments: 2 tables, 26 pages, 2 figures, TOCHI Submission\n",
    "authors": [
      "John Dunham",
      "Konstantinos Papangelis",
      "Samuli Laato",
      "Nicolas LaLone",
      "Jin Ha Lee",
      "Michael Saker"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2202.05185"
  },
  {
    "id": "arXiv:2202.05186",
    "title": "Fair allocation of a multiset of indivisible items",
    "abstract": "We study the problem of allocating a set $M$ of $m$ ${indivisible}$ items\namong $n$ agents in a fair manner. We consider two well-studied notions of\nfairness: envy-freeness (EF), and envy-freeness up to any good (EFX). While it\nis known that complete EF allocations do not always exist, it is not known if\ncomplete EFX allocations exist besides a few cases. In this work, we\nreformulate the problem to allow $M$ to be a multiset. Specifically, we\nintroduce a parameter $t$ for the number of distinct ${types}$ of items, and\nstudy allocations of multisets that contain items of these $t$ types. We show\nthe following:\n1. For arbitrary $n$, $t$, a complete EF allocation exists when agents have\ndistinct additive valuations, and there are ${enough}$ items of each type.\n2. For arbitrary $n$, $m$, $t$, a complete EFX allocation exists when agents\nhave additive valuations with identical ${preferences}$.\n3. For arbitrary $n$, $m$, and $t\\le2$, a complete EFX allocation exists when\nagents have additive valuations.\nFor 2 and 3, our approach is constructive; we give a polynomial-time\nalgorithm to find a complete EFX allocation.",
    "descriptor": "\nComments: 29 pages, 5 figures, 1 table\n",
    "authors": [
      "Pranay Gorantla",
      "Kunal Marwaha",
      "Santhoshini Velusamy"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Theoretical Economics (econ.TH)"
    ],
    "url": "https://arxiv.org/abs/2202.05186"
  },
  {
    "id": "arXiv:2202.05187",
    "title": "Adults as Augmentations for Children in Facial Emotion Recognition with  Contrastive Learning",
    "abstract": "Emotion recognition in children can help the early identification of, and\nintervention on, psychological complications that arise in stressful situations\nsuch as cancer treatment. Though deep learning models are increasingly being\nadopted, data scarcity is often an issue in pediatric medicine, including for\nfacial emotion recognition in children. In this paper, we study the application\nof data augmentation-based contrastive learning to overcome data scarcity in\nfacial emotion recognition for children. We explore the idea of ignoring\ngenerational gaps, by adding abundantly available adult data to pediatric data,\nto learn better representations. We investigate different ways by which adult\nfacial expression images can be used alongside those of children. In\nparticular, we propose to explicitly incorporate within each mini-batch adult\nimages as augmentations for children's. Out of $84$ combinations of learning\napproaches and training set sizes, we find that supervised contrastive learning\nwith the proposed training scheme performs best, reaching a test accuracy that\ntypically surpasses the one of the second-best approach by 2% to 3%. Our\nresults indicate that adult data can be considered to be a meaningful\naugmentation of pediatric data for the recognition of emotional facial\nexpression in children, and open up the possibility for other applications of\ncontrastive learning to improve pediatric care by complementing data of\nchildren with that of adults.",
    "descriptor": "",
    "authors": [
      "Marco Virgolin",
      "Andrea De Lorenzo",
      "Tanja Alderliesten",
      "Peter A. N. Bosman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2202.05187"
  },
  {
    "id": "arXiv:2202.05189",
    "title": "Understanding Rare Spurious Correlations in Neural Networks",
    "abstract": "Neural networks are known to use spurious correlations for classification;\nfor example, they commonly use background information to classify objects. But\nhow many examples does it take for a network to pick up these correlations?\nThis is the question that we empirically investigate in this work. We introduce\nspurious patterns correlated with a specific class to a few examples and find\nthat it takes only a handful of such examples for the network to pick up on the\nspurious correlation. Through extensive experiments, we show that (1) spurious\npatterns with a larger $\\ell_2$ norm are learnt to correlate with the specified\nclass more easily; (2) network architectures that are more sensitive to the\ninput are more susceptible to learning these rare spurious correlations; (3)\nstandard data deletion methods, including incremental retraining and influence\nfunctions, are unable to forget these rare spurious correlations through\ndeleting the examples that cause these spurious correlations to be learnt. Code\navailable at https://github.com/yangarbiter/rare-spurious-correlation.",
    "descriptor": "",
    "authors": [
      "Yao-Yuan Yang",
      "Kamalika Chaudhuri"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.05189"
  },
  {
    "id": "arXiv:2202.05194",
    "title": "Robust and fair work allocation",
    "abstract": "In today's digital world, interaction with online platforms is ubiquitous,\nand thus content moderation is important for protecting users from content that\ndo not comply with pre-established community guidelines. Having a robust\ncontent moderation system throughout every stage of planning is particularly\nimportant. We study the short-term planning problem of allocating human content\nreviewers to different harmful content categories. We use tools from fair\ndivision and study the application of competitive equilibrium and leximin\nallocation rules. Furthermore, we incorporate, to the traditional Fisher market\nsetup, novel aspects that are of practical importance. The first aspect is the\nforecasted workload of different content categories. We show how a formulation\nthat is inspired by the celebrated Eisenberg-Gale program allows us to find an\nallocation that not only satisfies the forecasted workload, but also fairly\nallocates the remaining reviewing hours among all content categories. The\nresulting allocation is also robust as the additional allocation provides a\nguardrail in cases where the actual workload deviates from the predicted\nworkload. The second practical consideration is time dependent allocation that\nis motivated by the fact that partners need scheduling guidance for the\nreviewers across days to achieve efficiency.\nTo address the time component, we introduce new extensions of the various\nfair allocation approaches for the single-time period setting, and we show that\nmany properties extend in essence, albeit with some modifications. Related to\nthe time component, we additionally investigate how to satisfy markets' desire\nfor smooth allocation (e.g., partners for content reviewers prefer an\nallocation that does not vary much from time to time, to minimize staffing\nswitch). We demonstrate the performance of our proposed approaches through\nreal-world data obtained from Meta.",
    "descriptor": "",
    "authors": [
      "Amine Allouah",
      "Christian Kroer",
      "Xuan Zhang",
      "Vashist Avadhanula",
      "Anil Dania",
      "Caner Gocmen",
      "Sergey Pupyrev",
      "Parikshit Shah",
      "Nicolas Stier"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2202.05194"
  },
  {
    "id": "arXiv:2202.05199",
    "title": "A Human-Centered Machine-Learning Approach for Muscle-Tendon Junction  Tracking in Ultrasound Images",
    "abstract": "Biomechanical and clinical gait research observes muscles and tendons in\nlimbs to study their functions and behaviour. Therefore, movements of distinct\nanatomical landmarks, such as muscle-tendon junctions, are frequently measured.\nWe propose a reliable and time efficient machine-learning approach to track\nthese junctions in ultrasound videos and support clinical biomechanists in gait\nanalysis. In order to facilitate this process, a method based on deep-learning\nwas introduced. We gathered an extensive dataset, covering 3 functional\nmovements, 2 muscles, collected on 123 healthy and 38 impaired subjects with 3\ndifferent ultrasound systems, and providing a total of 66864 annotated\nultrasound images in our network training. Furthermore, we used data collected\nacross independent laboratories and curated by researchers with varying levels\nof experience. For the evaluation of our method a diverse test-set was selected\nthat is independently verified by four specialists. We show that our model\nachieves similar performance scores to the four human specialists in\nidentifying the muscle-tendon junction position. Our method provides\ntime-efficient tracking of muscle-tendon junctions, with prediction times of up\nto 0.078 seconds per frame (approx. 100 times faster than manual labeling). All\nour codes, trained models and test-set were made publicly available and our\nmodel is provided as a free-to-use online service on https://deepmtj.org/.",
    "descriptor": "\nComments: in IEEE Transactions on Biomedical Engineering\n",
    "authors": [
      "Christoph Leitner",
      "Robert Jarolim",
      "Bernhard Englmair",
      "Annika Kruse",
      "Karen Andrea Lara Hernandez",
      "Andreas Konrad",
      "Eric Su",
      "J\u00f6rg Schr\u00f6ttner",
      "Luke A. Kelly",
      "Glen A. Lichtwark",
      "Markus Tilp",
      "Christian Baumgartner"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2202.05199"
  },
  {
    "id": "arXiv:2202.05200",
    "title": "Visual Servoing for Pose Control of Soft Continuum Arm in a Structured  Environment",
    "abstract": "For soft continuum arms, visual servoing is a popular control strategy that\nrelies on visual feedback to close the control loop. However, robust visual\nservoing is challenging as it requires reliable feature extraction from the\nimage, accurate control models and sensors to perceive the shape of the arm,\nboth of which can be hard to implement in a soft robot. This letter circumvents\nthese challenges by presenting a deep neural network-based method to perform\nsmooth and robust 3D positioning tasks on a soft arm by visual servoing using a\ncamera mounted at the distal end of the arm. A convolutional neural network is\ntrained to predict the actuations required to achieve the desired pose in a\nstructured environment. Integrated and modular approaches for estimating the\nactuations from the image are proposed and are experimentally compared. A\nproportional control law is implemented to reduce the error between the desired\nand current image as seen by the camera. The model together with the\nproportional feedback control makes the described approach robust to several\nvariations such as new targets, lighting, loads, and diminution of the soft\narm. Furthermore, the model lends itself to be transferred to a new environment\nwith minimal effort.",
    "descriptor": "\nComments: 9 pages, 5 figures, RA-L + RoboSoft\n",
    "authors": [
      "Shivani Kamtikar",
      "Samhita Marri",
      "Benjamin Walt",
      "Naveen Kumar Uppalapati",
      "Girish Krishnan",
      "Girish Chowdhary"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.05200"
  },
  {
    "id": "arXiv:2202.05204",
    "title": "Towards Predicting Fine Finger Motions from Ultrasound Images via  Kinematic Representation",
    "abstract": "A central challenge in building robotic prostheses is the creation of a\nsensor-based system able to read physiological signals from the lower limb and\ninstruct a robotic hand to perform various tasks. Existing systems typically\nperform discrete gestures such as pointing or grasping, by employing\nelectromyography (EMG) or ultrasound (US) technologies to analyze the state of\nthe muscles. In this work, we study the inference problem of identifying the\nactivation of specific fingers from a sequence of US images when performing\ndexterous tasks such as keyboard typing or playing the piano. While estimating\nfinger gestures has been done in the past by detecting prominent gestures, we\nare interested in classification done in the context of fine motions that\nevolve over time. We consider this task as an important step towards higher\nadoption rates of robotic prostheses among arm amputees, as it has the\npotential to dramatically increase functionality in performing daily tasks. Our\nkey observation, motivating this work, is that modeling the hand as a robotic\nmanipulator allows to encode an intermediate representation wherein US images\nare mapped to said configurations. Given a sequence of such learned\nconfigurations, coupled with a neural-network architecture that exploits\ntemporal coherence, we are able to infer fine finger motions. We evaluated our\nmethod by collecting data from a group of subjects and demonstrating how our\nframework can be used to replay music played or text typed. To the best of our\nknowledge, this is the first study demonstrating these downstream tasks within\nan end-to-end system.",
    "descriptor": "",
    "authors": [
      "Dean Zadok",
      "Oren Salzman",
      "Alon Wolf",
      "Alex M. Bronstein"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.05204"
  },
  {
    "id": "arXiv:2202.05206",
    "title": "Zero Shot Learning for Predicting Energy Usage of Buildings in  Sustainable Design",
    "abstract": "The 2030 Challenge is aimed at making all new buildings and major renovations\ncarbon neutral by 2030. One of the potential solutions to meet this challenge\nis through innovative sustainable design strategies. For developing such\nstrategies it is important to understand how the various building factors\ncontribute to energy usage of a building, right at design time. The growth of\nartificial intelligence (AI) in recent years provides an unprecedented\nopportunity to advance sustainable design by learning complex relationships\nbetween building factors from available data. However, rich training datasets\nare needed for AI-based solutions to achieve good prediction accuracy.\nUnfortunately, obtaining training datasets are time consuming and expensive in\nmany real-world applications. Motivated by these reasons, we address the\nproblem of accurately predicting the energy usage of new or unknown building\ntypes, i.e., those building types that do not have any training data. We\npropose a novel approach based on zero-shot learning (ZSL) to solve this\nproblem. Our approach uses side information from building energy modeling\nexperts to predict the closest building types for a given new/unknown building\ntype. We then obtain the predicted energy usage for the k-closest building\ntypes using the models learned during training and combine the predicted values\nusing a weighted averaging function. We evaluated our approach on a dataset\ncontaining five building types generated using BuildSimHub, a popular platform\nfor building energy modeling. Our approach achieved better average accuracy\nthan a regression model (based on XGBoost) trained on the entire dataset of\nknown building types.",
    "descriptor": "\nComments: To appear in 1st Annual AAAI Workshop on AI to Accelerate Science and Engineering (AI2ASE) @ AAAI 2022\n",
    "authors": [
      "Arun Zachariah",
      "Praveen Rao",
      "Brian Corn",
      "Dominique Davison"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.05206"
  },
  {
    "id": "arXiv:2202.05207",
    "title": "Vehicle: Interfacing Neural Network Verifiers with Interactive Theorem  Provers",
    "abstract": "Verification of neural networks is currently a hot topic in automated theorem\nproving. Progress has been rapid and there are now a wide range of tools\navailable that can verify properties of networks with hundreds of thousands of\nnodes. In theory this opens the door to the verification of larger control\nsystems that make use of neural network components. However, although work has\nmanaged to incorporate the results of these verifiers to prove larger\nproperties of individual systems, there is currently no general methodology for\nbridging the gap between verifiers and interactive theorem provers (ITPs).\nIn this paper we present Vehicle, our solution to this problem. Vehicle is\nequipped with an expressive domain specific language for stating neural network\nspecifications which can be compiled to both verifiers and ITPs. It overcomes\nprevious issues with maintainability and scalability in similar ITP\nformalisations by using a standard ONNX file as the single canonical\nrepresentation of the network. We demonstrate its utility by using it to\nconnect the neural network verifier Marabou to Agda and then formally verifying\nthat a car steered by a neural network never leaves the road, even in the face\nof an unpredictable cross wind and imperfect sensors. The network has over\n20,000 nodes, and therefore this proof represents an improvement of 3 orders of\nmagnitude over prior proofs about neural network enhanced systems in ITPs.",
    "descriptor": "",
    "authors": [
      "Matthew L. Daggitt",
      "Wen Kokke",
      "Robert Atkey",
      "Luca Arnaboldi",
      "Ekaterina Komendantskya"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Logic in Computer Science (cs.LO)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2202.05207"
  },
  {
    "id": "arXiv:2202.05209",
    "title": "Improving Automatic Speech Recognition for Non-Native English with  Transfer Learning and Language Model Decoding",
    "abstract": "ASR systems designed for native English (L1) usually underperform on\nnon-native English (L2). To address this performance gap, \\textbf{(i)} we\nextend our previous work to investigate fine-tuning of a pre-trained wav2vec\n2.0 model \\cite{baevski2020wav2vec,xu2021self} under a rich set of L1 and L2\ntraining conditions. We further \\textbf{(ii)} incorporate language model\ndecoding in the ASR system, along with the fine-tuning method. Quantifying\ngains acquired from each of these two approaches separately and an error\nanalysis allows us to identify different sources of improvement within our\nmodels. We find that while the large self-trained wav2vec 2.0 may be\ninternalizing sufficient decoding knowledge for clean L1 speech\n\\cite{xu2021self}, this does not hold for L2 speech and accounts for the\nutility of employing language model decoding on L2 data.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2110.00678\n",
    "authors": [
      "Peter Sullivan",
      "Toshiko Shibano",
      "Muhammad Abdul-Mageed"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2202.05209"
  },
  {
    "id": "arXiv:2202.05211",
    "title": "Behavior-Semantic Scenery Description (BSSD) of Road Networks for  Automated Driving",
    "abstract": "The safety approval of Highly Automated Vehicles (HAV) is economically\ninfeasible with current approaches. For verification and validation, it is\nessential to describe the intended behavior of an HAV in the development\nprocess in order to prove safety. The demand for this behavior comes from the\ntraffic rules which are instantiated by the present scenery around the vehicle\n(e.g. traffic signs or road markings). The Operational Design Domain (ODD)\nspecifies the scenery in which an HAV may operate, but current descriptions\nfail to explicitly represent the associated behavioral demand of the scenery.\nWe propose a new approach for a Behavior-Semantic Scenery Description (BSSD) in\norder to describe the behavior space of a present scenery. A behavior space\nrepresents the delimitation of the legally possible behavior. The BSSD\nexplicitly links the scenery with the behavioral demand for HAV. Based on\nidentified goals and challenges for such an approach, we derive requirements\nfor a generic structure of the description for complete road networks. All\nrequired elements to represent the behavior space of the scenery are\nidentified. Within real world examples, we present an instance of the BSSD\nintegrated into the HD-map framework Lanelet2 to prove the applicability of the\ndescription. The presented approach supports development, test and operation of\nHAV by closing the knowledge gap of where a vehicle has to behave in which\nlimits within an ODD.",
    "descriptor": "\nComments: 12 pages, 3 figures, 3 tables, submitted to IEEE Transactions on Intelligent Transportation Systems (T-ITS)\n",
    "authors": [
      "Moritz Lippert",
      "Felix Glatzki",
      "Hermann Winner"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.05211"
  },
  {
    "id": "arXiv:2202.05218",
    "title": "Pynguin: Automated Unit Test Generation for Python",
    "abstract": "Automated unit test generation is a well-known methodology aiming to reduce\nthe developers' effort of writing tests manually. Prior research focused mainly\non statically typed programming languages like Java. In practice, however,\ndynamically typed languages have received a huge gain in popularity over the\nlast decade. This introduces the need for tools and research on test generation\nfor these languages, too. We introduce Pynguin, an extendable test-generation\nframework for Python, which generates regression tests with high code coverage.\nPynguin is designed to be easily usable by practitioners; it is also extensible\nto allow researchers to adapt it for their needs and to enable future research.\nWe provide a demo of Pynguin at https://youtu.be/UiGrG25Vts0; further\ninformation, documentation, the tool, and its source code are available at\nhttps://www.pynguin.eu.",
    "descriptor": "\nComments: 5 pages\n",
    "authors": [
      "Stephan Lukasczyk",
      "Gordon Fraser"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2202.05218"
  },
  {
    "id": "arXiv:2202.05223",
    "title": "Reliabuild: Searching for High-Fidelity Builds Using Active Learning",
    "abstract": "Modern software is incredibly complex. A typical application may comprise\nhundreds or thousands of reusable components. Automated package managers can\nhelp to maintain a consistent set of dependency versions, but ultimately the\nsolvers in these systems rely on constraints generated by humans. At scale,\nsmall errors add up, and it becomes increasingly difficult to find\nhigh-fidelity configurations. We cannot test all configurations, because the\nspace is combinatorial, so exhaustive exploration is infeasible.\nIn this paper, we present Reliabuild, an auto-tuning framework that\nefficiently explores the build configuration space and learns which package\nversions are likely to result in a successful configuration. We implement two\nmodels in Reliabuild to rank the different configurations and use adaptive\nsampling to select good configurations with fewer samples. We demonstrate\nReliabuild's effectiveness by evaluating 31,186 build configurations of 61\npackages from the Extreme-scale Scientific Software Stack(E4S). Reliabuild\nselects good configurations efficiently. For example, Reliabuild selects 3X the\nnumber of good configurations in comparison to random sampling for several\npackages including Abyss, Bolt, libnrm, OpenMPI. Our framework is also able to\nselect all the high-fidelity builds in half the number of samples required by\nrandom sampling for packages such as Chai, OpenMPI, py-petsc4py, and slepc. We\nfurther use the model to learn statistics about the compatibility of different\npackages, which will enable package solvers to better select high-fidelity\nbuild configurations automatically.",
    "descriptor": "",
    "authors": [
      "Harshitha Menon",
      "Konstantinos Parasyris",
      "Tom Scogland",
      "Todd Gamblin"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2202.05223"
  },
  {
    "id": "arXiv:2202.05225",
    "title": "On the Identity Problem for Unitriangular Matrices of Dimension Four",
    "abstract": "We show that the Identity Problem is decidable for finitely generated\nsub-semigroups of the group $\\operatorname{UT}(4, \\mathbb{Z})$ of $4 \\times 4$\nunitriangular integer matrices. As a byproduct of our proof, we have also shown\nthe decidability of several subset reachability problems in\n$\\operatorname{UT}(4, \\mathbb{Z})$.",
    "descriptor": "\nComments: 25 pages, 2 figures\n",
    "authors": [
      "Ruiwen Dong"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Symbolic Computation (cs.SC)"
    ],
    "url": "https://arxiv.org/abs/2202.05225"
  },
  {
    "id": "arXiv:2202.05226",
    "title": "Deadwooding: Robust Global Pruning for Deep Neural Networks",
    "abstract": "The ability of Deep Neural Networks to approximate highly complex functions\nis the key to their success. This benefit, however, often comes at the cost of\na large model size, which challenges their deployment in resource-constrained\nenvironments. To limit this issue, pruning techniques can introduce sparsity in\nthe models, but at the cost of accuracy and adversarial robustness. This paper\naddresses these critical issues and introduces Deadwooding, a novel pruning\ntechnique that exploits a Lagrangian Dual method to encourage model sparsity\nwhile retaining accuracy and ensuring robustness. The resulting model is shown\nto significantly outperform the state-of-the-art studies in measures of\nrobustness and accuracy.",
    "descriptor": "\nComments: 11 pages, 5 figures\n",
    "authors": [
      "Sawinder Kaur",
      "Ferdinando Fioretto",
      "Asif Salekin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.05226"
  },
  {
    "id": "arXiv:2202.05227",
    "title": "A Novel Four-DOF Lagrangian Approach to Attitude Tracking for Rigid  Spacecraft",
    "abstract": "This paper presents a novel Lagrangian approach to attitude tracking for\nrigid spacecraft using unit quaternions, where the motion equations of a\nspacecraft are described by a four degrees of freedom Lagrangian dynamics\nsubject to a holonomic constraint imposed by the norm of a unit quaternion. The\nbasic energy-conservation property as well as some additional useful properties\nof the Lagrangian dynamics are explored, enabling to develop quaternion-based\nattitude tracking controllers by taking full advantage of a broad class of\ntracking control designs for mechanical systems based on energy-shaping\nmethodology. Global tracking of a desired attitude on the unit sphere is\nachieved by designing control laws that render the tracking error on the\nfour-dimensional Euclidean space to converge to the origin. The topological\nconstraints for globally exponentially tracking by a quaternion-based\ncontinuous controller and singularities in controller designs based on any\nthree-parameter representation of the attitude are then avoided. Using this\napproach, a full-state feedback controller is first developed, and then several\nimportant issues, such as robustness to noise in quaternion measurements,\nunknown on-orbit torque disturbances, uncertainty in the inertial matrix, and\nlack of angular-velocity measurements are addressed progressively, by designing\na hybrid state-feedback controller, an adaptive hybrid state-feedback\ncontroller, and an adaptive hybrid attitude-feedback controller. Global\nasymptotic stability is established for each controller. Simulations are\nincluded to illustrate the theoretical results.",
    "descriptor": "",
    "authors": [
      "Eduardo Esp\u00edndola",
      "Yu Tang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.05227"
  },
  {
    "id": "arXiv:2202.05233",
    "title": "Game Theoretic Analysis of an Adversarial Status Updating System",
    "abstract": "We investigate the game theoretic equilibrium points of a status updating\nsystem with an adversary that jams the updates in the downlink. We consider the\nsystem models with and without diversity. The adversary can jam up to $\\alpha$\nproportion of the entire communication window. In the model without diversity,\nin each time slot, the base station schedules a user from $N$ users according\nto a stationary distribution. The adversary blocks (jams) $\\alpha T$ time slots\nof its choosing out of the total $T$ time slots. For this system, we show that\na Nash equilibrium does not exist, however, a Stackelberg equilibrium exists\nwhen the scheduling algorithm of the base station acts as the leader and the\nadversary acts as the follower. In the model with diversity, in each time slot,\nthe base station schedules a user from $N$ users and chooses a sub-carrier from\n$N_{sub}$ sub-carriers to transmit update packets to the scheduled user\naccording to a stationary distribution. The adversary blocks $\\alpha T$ time\nslots of its choosing out of $T$ time slots at the sub-carriers of its\nchoosing. For this system, we show that a Nash equilibrium exists and identify\nthe Nash equilibrium.",
    "descriptor": "",
    "authors": [
      "Subhankar Banerjee",
      "Sennur Ulukus"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.05233"
  },
  {
    "id": "arXiv:2202.05236",
    "title": "Learnable Nonlinear Compression for Robust Speaker Verification",
    "abstract": "In this study, we focus on nonlinear compression methods in spectral features\nfor speaker verification based on deep neural network. We consider different\nkinds of channel-dependent (CD) nonlinear compression methods optimized in a\ndata-driven manner. Our methods are based on power nonlinearities and dynamic\nrange compression (DRC). We also propose multi-regime (MR) design on the\nnonlinearities, at improving robustness. Results on VoxCeleb1 and VoxMovies\ndata demonstrate improvements brought by proposed compression methods over both\nthe commonly-used logarithm and their static counterparts, especially for ones\nbased on power function. While CD generalization improves performance on\nVoxCeleb1, MR provides more robustness on VoxMovies, with a maximum relative\nequal error rate reduction of 21.6%.",
    "descriptor": "\nComments: Accepted by ICASSP2022\n",
    "authors": [
      "Xuechen Liu",
      "Md Sahidullah",
      "Tomi Kinnunen"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2202.05236"
  },
  {
    "id": "arXiv:2202.05239",
    "title": "F8Net: Fixed-Point 8-bit Only Multiplication for Network Quantization",
    "abstract": "Neural network quantization is a promising compression technique to reduce\nmemory footprint and save energy consumption, potentially leading to real-time\ninference. However, there is a performance gap between quantized and\nfull-precision models. To reduce it, existing quantization approaches require\nhigh-precision INT32 or full-precision multiplication during inference for\nscaling or dequantization. This introduces a noticeable cost in terms of\nmemory, speed, and required energy. To tackle these issues, we present F8Net, a\nnovel quantization framework consisting of only fixed-point 8-bit\nmultiplication. To derive our method, we first discuss the advantages of\nfixed-point multiplication with different formats of fixed-point numbers and\nstudy the statistical behavior of the associated fixed-point numbers. Second,\nbased on the statistical and algorithmic analysis, we apply different\nfixed-point formats for weights and activations of different layers. We\nintroduce a novel algorithm to automatically determine the right format for\neach layer during training. Third, we analyze a previous quantization algorithm\n-- parameterized clipping activation (PACT) -- and reformulate it using\nfixed-point arithmetic. Finally, we unify the recently proposed method for\nquantization fine-tuning and our fixed-point approach to show the potential of\nour method. We verify F8Net on ImageNet for MobileNet V1/V2 and ResNet18/50.\nOur approach achieves comparable and better performance, when compared not only\nto existing quantization techniques with INT32 multiplication or floating-point\narithmetic, but also to the full-precision counterparts, achieving\nstate-of-the-art performance.",
    "descriptor": "\nComments: ICLR 2022 (Oral)\n",
    "authors": [
      "Qing Jin",
      "Jian Ren",
      "Richard Zhuang",
      "Sumant Hanumante",
      "Zhengang Li",
      "Zhiyu Chen",
      "Yanzhi Wang",
      "Kaiyuan Yang",
      "Sergey Tulyakov"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Hardware Architecture (cs.AR)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2202.05239"
  },
  {
    "id": "arXiv:2202.05240",
    "title": "ChemicalX: A Deep Learning Library for Drug Pair Scoring",
    "abstract": "In this paper, we introduce ChemicalX, a PyTorch-based deep learning library\ndesigned for providing a range of state of the art models to solve the drug\npair scoring task. The primary objective of the library is to make deep drug\npair scoring models accessible to machine learning researchers and\npractitioners in a streamlined framework.The design of ChemicalX reuses\nexisting high level model training utilities, geometric deep learning, and deep\nchemistry layers from the PyTorch ecosystem. Our system provides neural network\nlayers, custom pair scoring architectures, data loaders, and batch iterators\nfor end users. We showcase these features with example code snippets and case\nstudies to highlight the characteristics of ChemicalX. A range of experiments\non real world drug-drug interaction, polypharmacy side effect, and combination\nsynergy prediction tasks demonstrate that the models available in ChemicalX are\neffective at solving the pair scoring task. Finally, we show that ChemicalX\ncould be used to train and score machine learning models on large drug pair\ndatasets with hundreds of thousands of compounds on commodity hardware.",
    "descriptor": "\nComments: this https URL\n",
    "authors": [
      "Benedek Rozemberczki",
      "Charles Tapley Hoyt",
      "Anna Gogleva",
      "Piotr Grabowski",
      "Klas Karis",
      "Andrej Lamov",
      "Andriy Nikolov",
      "Sebastian Nilsson",
      "Michael Ughetto",
      "Yu Wang",
      "Tyler Derr",
      "Benjamin M Gyori"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.05240"
  },
  {
    "id": "arXiv:2202.05244",
    "title": "REvolveR: Continuous Evolutionary Models for Robot-to-robot Policy  Transfer",
    "abstract": "A popular paradigm in robotic learning is to train a policy from scratch for\nevery new robot. This is not only inefficient but also often impractical for\ncomplex robots. In this work, we consider the problem of transferring a policy\nacross two different robots with significantly different parameters such as\nkinematics and morphology. Existing approaches that train a new policy by\nmatching the action or state transition distribution, including imitation\nlearning methods, fail due to optimal action and/or state distribution being\nmismatched in different robots. In this paper, we propose a novel method named\n$REvolveR$ of using continuous evolutionary models for robotic policy transfer\nimplemented in a physics simulator. We interpolate between the source robot and\nthe target robot by finding a continuous evolutionary change of robot\nparameters. An expert policy on the source robot is transferred through\ntraining on a sequence of intermediate robots that gradually evolve into the\ntarget robot. Experiments show that the proposed continuous evolutionary model\ncan effectively transfer the policy across robots and achieve superior sample\nefficiency on new robots using a physics simulator. The proposed method is\nespecially advantageous in sparse reward settings where exploration can be\nsignificantly reduced.",
    "descriptor": "",
    "authors": [
      "Xingyu Liu",
      "Deepak Pathak",
      "Kris M. Kitani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.05244"
  },
  {
    "id": "arXiv:2202.05246",
    "title": "Monotone Learning",
    "abstract": "The amount of training-data is one of the key factors which determines the\ngeneralization capacity of learning algorithms. Intuitively, one expects the\nerror rate to decrease as the amount of training-data increases. Perhaps\nsurprisingly, natural attempts to formalize this intuition give rise to\ninteresting and challenging mathematical questions. For example, in their\nclassical book on pattern recognition, Devroye, Gyorfi, and Lugosi (1996) ask\nwhether there exists a {monotone} Bayes-consistent algorithm. This question\nremained open for over 25 years, until recently Pestov (2021) resolved it for\nbinary classification, using an intricate construction of a monotone\nBayes-consistent algorithm.\nWe derive a general result in multiclass classification, showing that every\nlearning algorithm A can be transformed to a monotone one with similar\nperformance. Further, the transformation is efficient and only uses a black-box\noracle access to A. This demonstrates that one can provably avoid non-monotonic\nbehaviour without compromising performance, thus answering questions asked by\nDevroye et al (1996), Viering, Mey, and Loog (2019), Viering and Loog (2021),\nand by Mhammedi (2021).\nOur transformation readily implies monotone learners in a variety of\ncontexts: for example it extends Pestov's result to classification tasks with\nan arbitrary number of labels. This is in contrast with Pestov's work which is\ntailored to binary classification.\nIn addition, we provide uniform bounds on the error of the monotone\nalgorithm. This makes our transformation applicable in distribution-free\nsettings. For example, in PAC learning it implies that every learnable class\nadmits a monotone PAC learner. This resolves questions by Viering, Mey, and\nLoog (2019); Viering and Loog (2021); Mhammedi (2021).",
    "descriptor": "\nComments: 19 pages\n",
    "authors": [
      "Olivier Bousquet",
      "Amit Daniely",
      "Haim Kaplan",
      "Yishay Mansour",
      "Shay Moran",
      "Uri Stemmer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2202.05246"
  },
  {
    "id": "arXiv:2202.05252",
    "title": "SA-HMTS: A Secure and Adaptive Hierarchical Multi-timescale Framework  for Resilient Load Restoration Using A Community Microgrid",
    "abstract": "Distribution system integrated community microgrids (CMGs) can partake in\nrestoring loads during extended duration outages. At such times, the CMG is\nchallenged with limited resource availability, absence of robust grid support,\nand heightened demand-supply uncertainty. This paper proposes a secure and\nadaptive three-stage hierarchical multi-timescale framework for scheduling and\nreal-time (RT) dispatch of CMGs with hybrid PV systems to address these\nchallenges. The framework enables the CMG to dynamically expand its boundary to\nsupport the neighboring grid sections and is adaptive to the changing forecast\nerror impacts. The first stage solves a stochastic extended duration scheduling\n(EDS) problem to obtain referral plans for optimal resource rationing. The\nintermediate near-real-time (NRT) scheduling stage updates the EDS schedule\ncloser to the dispatch time using newly obtained forecasts, followed by the RT\ndispatch stage. To make the dispatch decisions more secure and robust against\nforecast errors, a novel concept called delayed recourse is proposed. The\nmethodology is evaluated via numerical simulations on a modified IEEE 123-bus\nsystem and validated using OpenDSS/hardware-in-loop simulations. The results\nshow superior performance in maximizing load supply and continuous secure CMG\noperation under numerous operating scenarios.",
    "descriptor": "",
    "authors": [
      "Ashwin Shirsat",
      "Valliappan Muthukaruppan",
      "Rongxing Hu",
      "Victor Paduani",
      "Bei Xu",
      "Lidong Song",
      "Yiyan Li",
      "Ning Lu",
      "Mesut Baran",
      "David Lubkeman",
      "Wenyuan Tang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2202.05252"
  },
  {
    "id": "arXiv:2202.05254",
    "title": "Deep Learning in Random Neural Fields: Numerical Experiments via Neural  Tangent Kernel",
    "abstract": "A biological neural network in the cortex forms a neural field. Neurons in\nthe field have their own receptive fields, and connection weights between two\nneurons are random but highly correlated when they are in close proximity in\nreceptive fields. In this paper, we investigate such neural fields in a\nmultilayer architecture to investigate the supervised learning of the fields.\nWe empirically compare the performances of our field model with those of\nrandomly connected deep networks. The behavior of a randomly connected network\nis investigated on the basis of the key idea of the neural tangent kernel\nregime, a recent development in the machine learning theory of\nover-parameterized networks; for most randomly connected neural networks, it is\nshown that global minima always exist in their small neighborhoods. We\nnumerically show that this claim also holds for our neural fields. In more\ndetail, our model has two structures: i) each neuron in a field has a\ncontinuously distributed receptive field, and ii) the initial connection\nweights are random but not independent, having correlations when the positions\nof neurons are close in each layer. We show that such a multilayer neural field\nis more robust than conventional models when input patterns are deformed by\nnoise disturbances. Moreover, its generalization ability can be slightly\nsuperior to that of conventional models.",
    "descriptor": "",
    "authors": [
      "Kaito Watanabe",
      "Kotaro Sakamoto",
      "Ryo Karakida",
      "Sho Sonoda",
      "Shun-ichi Amari"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.05254"
  },
  {
    "id": "arXiv:2202.05257",
    "title": "Characterizing, Detecting, and Predicting Online Ban Evasion",
    "abstract": "Moderators and automated methods enforce bans on malicious users who engage\nin disruptive behavior. However, malicious users can easily create a new\naccount to evade such bans. Previous research has focused on other forms of\nonline deception, like the simultaneous operation of multiple accounts by the\nsame entities (sockpuppetry), impersonation of other individuals, and studying\nthe effects of de-platforming individuals and communities. Here we conduct the\nfirst data-driven study of ban evasion, i.e., the act of circumventing bans on\nan online platform, leading to temporally disjoint operation of accounts by the\nsame user.\nWe curate a novel dataset of 8,551 ban evasion pairs (parent, child)\nidentified on Wikipedia and contrast their behavior with benign users and\nnon-evading malicious users. We find that evasion child accounts demonstrate\nsimilarities with respect to their banned parent accounts on several behavioral\naxes - from similarity in usernames and edited pages to similarity in content\nadded to the platform and its psycholinguistic attributes. We reveal key\nbehavioral attributes of accounts that are likely to evade bans. Based on the\ninsights from the analyses, we train logistic regression classifiers to detect\nand predict ban evasion at three different points in the ban evasion lifecycle.\nResults demonstrate the effectiveness of our methods in predicting future\nevaders (AUC = 0.78), early detection of ban evasion (AUC = 0.85), and matching\nchild accounts with parent accounts (MRR = 0.97). Our work can aid moderators\nby reducing their workload and identifying evasion pairs faster and more\nefficiently than current manual and heuristic-based approaches. Dataset is\navailable $\\href{https://github.com/srijankr/ban_evasion}{\\text{here}}$.",
    "descriptor": "\nComments: Accepted full paper at The ACM WebConf 2022\n",
    "authors": [
      "Manoj Niverthi",
      "Gaurav Verma",
      "Srijan Kumar"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.05257"
  },
  {
    "id": "arXiv:2202.05258",
    "title": "Hardness of Noise-Free Learning for Two-Hidden-Layer Neural Networks",
    "abstract": "We give exponential statistical query (SQ) lower bounds for learning\ntwo-hidden-layer ReLU networks with respect to Gaussian inputs in the standard\n(noise-free) model. No general SQ lower bounds were known for learning ReLU\nnetworks of any depth in this setting: previous SQ lower bounds held only for\nadversarial noise models (agnostic learning) or restricted models such as\ncorrelational SQ.\nPrior work hinted at the impossibility of our result: Vempala and Wilmes\nshowed that general SQ lower bounds cannot apply to any real-valued family of\nfunctions that satisfies a simple non-degeneracy condition.\nTo circumvent their result, we refine a lifting procedure due to Daniely and\nVardi that reduces Boolean PAC learning problems to Gaussian ones. We show how\nto extend their technique to other learning models and, in many well-studied\ncases, obtain a more efficient reduction. As such, we also prove new\ncryptographic hardness results for PAC learning two-hidden-layer ReLU networks,\nas well as new lower bounds for learning constant-depth ReLU networks from\nmembership queries.",
    "descriptor": "\nComments: 24 pages, 1 figure, comments welcome\n",
    "authors": [
      "Sitan Chen",
      "Aravind Gollakota",
      "Adam R. Klivans",
      "Raghu Meka"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Complexity (cs.CC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.05258"
  },
  {
    "id": "arXiv:2202.05262",
    "title": "Locating and Editing Factual Knowledge in GPT",
    "abstract": "We investigate the mechanisms underlying factual knowledge recall in\nautoregressive transformer language models. First, we develop a causal\nintervention for identifying neuron activations capable of altering a model's\nfactual predictions. Within large GPT-style models, this reveals two distinct\nsets of neurons that we hypothesize correspond to knowing an abstract fact and\nsaying a concrete word, respectively. This insight inspires the development of\nROME, a novel method for editing facts stored in model weights. For evaluation,\nwe assemble CounterFact, a dataset of over twenty thousand counterfactuals and\ntools to facilitate sensitive measurements of knowledge editing. Using\nCounterFact, we confirm the distinction between saying and knowing neurons, and\nwe find that ROME achieves state-of-the-art performance in knowledge editing\ncompared to other methods. An interactive demo notebook, full code\nimplementation, and the dataset are available at https://rome.baulab.info/.",
    "descriptor": "\nComments: 21 pages, 21 figures. Code and data at this https URL\n",
    "authors": [
      "Kevin Meng",
      "David Bau",
      "Alex Andonian",
      "Yonatan Belinkov"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.05262"
  },
  {
    "id": "arXiv:2202.05263",
    "title": "Block-NeRF: Scalable Large Scene Neural View Synthesis",
    "abstract": "We present Block-NeRF, a variant of Neural Radiance Fields that can represent\nlarge-scale environments. Specifically, we demonstrate that when scaling NeRF\nto render city-scale scenes spanning multiple blocks, it is vital to decompose\nthe scene into individually trained NeRFs. This decomposition decouples\nrendering time from scene size, enables rendering to scale to arbitrarily large\nenvironments, and allows per-block updates of the environment. We adopt several\narchitectural changes to make NeRF robust to data captured over months under\ndifferent environmental conditions. We add appearance embeddings, learned pose\nrefinement, and controllable exposure to each individual NeRF, and introduce a\nprocedure for aligning appearance between adjacent NeRFs so that they can be\nseamlessly combined. We build a grid of Block-NeRFs from 2.8 million images to\ncreate the largest neural scene representation to date, capable of rendering an\nentire neighborhood of San Francisco.",
    "descriptor": "\nComments: Project page: this https URL\n",
    "authors": [
      "Matthew Tancik",
      "Vincent Casser",
      "Xinchen Yan",
      "Sabeek Pradhan",
      "Ben Mildenhall",
      "Pratul P. Srinivasan",
      "Jonathan T. Barron",
      "Henrik Kretzschmar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2202.05263"
  },
  {
    "id": "arXiv:2202.05265",
    "title": "Image-to-Image Regression with Distribution-Free Uncertainty  Quantification and Applications in Imaging",
    "abstract": "Image-to-image regression is an important learning task, used frequently in\nbiological imaging. Current algorithms, however, do not generally offer\nstatistical guarantees that protect against a model's mistakes and\nhallucinations. To address this, we develop uncertainty quantification\ntechniques with rigorous statistical guarantees for image-to-image regression\nproblems. In particular, we show how to derive uncertainty intervals around\neach pixel that are guaranteed to contain the true value with a user-specified\nconfidence probability. Our methods work in conjunction with any base machine\nlearning model, such as a neural network, and endow it with formal mathematical\nguarantees -- regardless of the true unknown data distribution or choice of\nmodel. Furthermore, they are simple to implement and computationally\ninexpensive. We evaluate our procedure on three image-to-image regression\ntasks: quantitative phase microscopy, accelerated magnetic resonance imaging,\nand super-resolution transmission electron microscopy of a Drosophila\nmelanogaster brain.",
    "descriptor": "\nComments: Code available at this https URL\n",
    "authors": [
      "Anastasios N Angelopoulos",
      "Amit P Kohli",
      "Stephen Bates",
      "Michael I Jordan",
      "Jitendra Malik",
      "Thayer Alshaabi",
      "Srigokul Upadhyayula",
      "Yaniv Romano"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)",
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.05265"
  },
  {
    "id": "arXiv:2202.04644",
    "title": "On-the-fly 3D metrology of volumetric additive manufacturing",
    "abstract": "Additive manufacturing techniques are revolutionizing product development by\nenabling fast turnaround from design to fabrication. However, the throughput of\nthe rapid prototyping pipeline remains constrained by print optimization,\nrequiring multiple iterations of fabrication and ex-situ metrology. Despite the\nneed for a suitable technology, robust in-situ shape measurement of an entire\nprint is not currently available with any additive manufacturing modality.\nHere, we address this shortcoming by demonstrating fully simultaneous 3D\nmetrology and printing. We exploit the dramatic increase in light scattering by\na photoresin during gelation for real-time 3D imaging of prints during\ntomographic volumetric additive manufacturing. Tomographic imaging of the light\nscattering density in the build volume yields quantitative, artifact-free 3D +\ntime models of cured objects that are accurate to below 1% of the size of the\nprint. By integrating shape measurement into the printing process, our work\npaves the way for next-generation rapid prototyping with real-time defect\ndetection and correction.",
    "descriptor": "",
    "authors": [
      "Antony Orth",
      "Kathleen L. Sampson",
      "Yujie Zhang",
      "Kayley Ting",
      "Derek Aranguren van Egmond",
      "Kurtis Laqua",
      "Thomas Lacelle",
      "Daniel Webber",
      "Dorothy Fathi",
      "Jonathan Boisvert",
      "Chantal Paquet"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Graphics (cs.GR)",
      "Optics (physics.optics)"
    ],
    "url": "https://arxiv.org/abs/2202.04644"
  },
  {
    "id": "arXiv:2202.04645",
    "title": "FCM-DNN: diagnosing coronary artery disease by deep accuracy Fuzzy  C-Means clustering model",
    "abstract": "Cardiovascular disease is one of the most challenging diseases in middle-aged\nand older people, which causes high mortality. Coronary artery disease (CAD) is\nknown as a common cardiovascular disease. A standard clinical tool for\ndiagnosing CAD is angiography. The main challenges are dangerous side effects\nand high angiography costs. Today, the development of artificial\nintelligence-based methods is a valuable achievement for diagnosing disease.\nHence, in this paper, artificial intelligence methods such as neural network\n(NN), deep neural network (DNN), and Fuzzy C-Means clustering combined with\ndeep neural network (FCM-DNN) are developed for diagnosing CAD on a cardiac\nmagnetic resonance imaging (CMRI) dataset. The original dataset is used in two\ndifferent approaches. First, the labeled dataset is applied to the NN and DNN\nto create the NN and DNN models. Second, the labels are removed, and the\nunlabeled dataset is clustered via the FCM method, and then, the clustered\ndataset is fed to the DNN to create the FCM-DNN model. By utilizing the second\nclustering and modeling, the training process is improved, and consequently,\nthe accuracy is increased. As a result, the proposed FCM-DNN model achieves the\nbest performance with a 99.91% accuracy specifying 10 clusters, i.e., 5\nclusters for healthy subjects and 5 clusters for sick subjects, through the\n10-fold cross-validation technique compared to the NN and DNN models reaching\nthe accuracies of 92.18% and 99.63%, respectively. To the best of our\nknowledge, no study has been conducted for CAD diagnosis on the CMRI dataset\nusing artificial intelligence methods. The results confirm that the proposed\nFCM-DNN model can be helpful for scientific and research centers.",
    "descriptor": "\nComments: 27 pages, 13 figures\n",
    "authors": [
      "Javad Hassannataj Joloudari",
      "Hamid Saadatfar",
      "Mohammad GhasemiGol",
      "Roohallah Alizadehsani",
      "Zahra Alizadeh Sani",
      "Fereshteh Hasanzadeh",
      "Edris Hassannataj",
      "Danial Sharifrazi",
      "Zulkefli Mansor"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.04645"
  },
  {
    "id": "arXiv:2202.04647",
    "title": "Multi-modal unsupervised brain image registration using edge maps",
    "abstract": "Diffeomorphic deformable multi-modal image registration is a challenging task\nwhich aims to bring images acquired by different modalities to the same\ncoordinate space and at the same time to preserve the topology and the\ninvertibility of the transformation. Recent research has focused on leveraging\ndeep learning approaches for this task as these have been shown to achieve\ncompetitive registration accuracy while being computationally more efficient\nthan traditional iterative registration methods. In this work, we propose a\nsimple yet effective unsupervised deep learning-based {\\em multi-modal} image\nregistration approach that benefits from auxiliary information coming from the\ngradient magnitude of the image, i.e. the image edges, during the training. The\nintuition behind this is that image locations with a strong gradient are\nassumed to denote a transition of tissues, which are locations of high\ninformation value able to act as a geometry constraint. The task is similar to\nusing segmentation maps to drive the training, but the edge maps are easier and\nfaster to acquire and do not require annotations. We evaluate our approach in\nthe context of registering multi-modal (T1w to T2w) magnetic resonance (MR)\nbrain images of different subjects using three different loss functions that\nare said to assist multi-modal registration, showing that in all cases the\nauxiliary information leads to better results without compromising the runtime.",
    "descriptor": "\nComments: Accepted to IEEE International Symposium on Biomedical Imaging (ISBI) 2022\n",
    "authors": [
      "Vasiliki Sideri-Lampretsa",
      "Georgios Kaissis",
      "Daniel Rueckert"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.04647"
  },
  {
    "id": "arXiv:2202.04650",
    "title": "Semantic Segmentation of Anaemic RBCs Using Multilevel Deep  Convolutional Encoder-Decoder Network",
    "abstract": "Pixel-level analysis of blood images plays a pivotal role in diagnosing\nblood-related diseases, especially Anaemia. These analyses mainly rely on an\naccurate diagnosis of morphological deformities like shape, size, and precise\npixel counting. In traditional segmentation approaches, instance or\nobject-based approaches have been adopted that are not feasible for pixel-level\nanalysis. The convolutional neural network (CNN) model required a large dataset\nwith detailed pixel-level information for the semantic segmentation of red\nblood cells in the deep learning domain. In current research work, we address\nthese problems by proposing a multi-level deep convolutional encoder-decoder\nnetwork along with two state-of-the-art healthy and Anaemic-RBC datasets. The\nproposed multi-level CNN model preserved pixel-level semantic information\nextracted in one layer and then passed to the next layer to choose relevant\nfeatures. This phenomenon helps to precise pixel-level counting of healthy and\nanaemic-RBC elements along with morphological analysis. For experimental\npurposes, we proposed two state-of-the-art RBC datasets, i.e., Healthy-RBCs and\nAnaemic-RBCs dataset. Each dataset contains 1000 images, ground truth masks,\nrelevant, complete blood count (CBC), and morphology reports for performance\nevaluation. The proposed model results were evaluated using crossmatch analysis\nwith ground truth mask by finding IoU, individual training, validation, testing\naccuracies, and global accuracies using a 05-fold training procedure. This\nmodel got training, validation, and testing accuracies as 0.9856, 0.9760, and\n0.9720 on the Healthy-RBC dataset and 0.9736, 0.9696, and 0.9591 on an\nAnaemic-RBC dataset. The IoU and BFScore of the proposed model were 0.9311,\n0.9138, and 0.9032, 0.8978 on healthy and anaemic datasets, respectively.",
    "descriptor": "",
    "authors": [
      "Muhammad Shahzad",
      "Arif Iqbal Umar",
      "Syed Hamad Shirazi",
      "Israr Ahmed Shaikh"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.04650"
  },
  {
    "id": "arXiv:2202.04683",
    "title": "Saturation and vanishing ideals",
    "abstract": "We consider an homogeneous ideal $I$ in the polynomial ring $S=K[x_1,\\dots,$\n$x_m]$ over a finite field $K=\\mathbb{F}_q$ and the finite set of projective\nrational points $\\mathbb{X}$ that it defines in the projective space\n$\\mathbb{P}^{m-1}$. We concern ourselves with the problem of computing the\nvanishing ideal $I(\\mathbb{X})$. This is usually done by adding the equations\nof the projective space $I(\\mathbb{P}^{m-1})$ to $I$ and computing the radical.\nWe give an alternative and more efficient way using the saturation with respect\nto the homogeneous maximal ideal.",
    "descriptor": "",
    "authors": [
      "Philippe Gimenez",
      "Diego Ruano",
      "Rodrigo San-Jos\u00e9"
    ],
    "subjectives": [
      "Commutative Algebra (math.AC)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.04683"
  },
  {
    "id": "arXiv:2202.04690",
    "title": "Smoothed Online Learning is as Easy as Statistical Learning",
    "abstract": "Much of modern learning theory has been split between two regimes: the\nclassical \\emph{offline} setting, where data arrive independently, and the\n\\emph{online} setting, where data arrive adversarially. While the former model\nis often both computationally and statistically tractable, the latter requires\nno distributional assumptions. In an attempt to achieve the best of both\nworlds, previous work proposed the smooth online setting where each sample is\ndrawn from an adversarially chosen distribution, which is smooth, i.e., it has\na bounded density with respect to a fixed dominating measure. We provide tight\nbounds on the minimax regret of learning a nonparametric function class, with\nnearly optimal dependence on both the horizon and smoothness parameters.\nFurthermore, we provide the first oracle-efficient, no-regret algorithms in\nthis setting. In particular, we propose an oracle-efficient improper algorithm\nwhose regret achieves optimal dependence on the horizon and a proper algorithm\nrequiring only a single oracle call per round whose regret has the optimal\nhorizon dependence in the classification setting and is sublinear in general.\nBoth algorithms have exponentially worse dependence on the smoothness parameter\nof the adversary than the minimax rate. We then prove a lower bound on the\noracle complexity of any proper learning algorithm, which matches the\noracle-efficient upper bounds up to a polynomial factor, thus demonstrating the\nexistence of a statistical-computational gap in smooth online learning.\nFinally, we apply our results to the contextual bandit setting to show that if\na function class is learnable in the classical setting, then there is an\noracle-efficient, no-regret algorithm for contextual bandits in the case that\ncontexts arrive in a smooth manner.",
    "descriptor": "",
    "authors": [
      "Adam Block",
      "Yuval Dagan",
      "Noah Golowich",
      "Alexander Rakhlin"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.04690"
  },
  {
    "id": "arXiv:2202.04719",
    "title": "A Coupled CP Decomposition for Principal Components Analysis of  Symmetric Networks",
    "abstract": "In a number of application domains, one observes a sequence of network data;\nfor example, repeated measurements between users interactions in social media\nplatforms, financial correlation networks over time, or across subjects, as in\nmulti-subject studies of brain connectivity. One way to analyze such data is by\nstacking networks into a third-order array or tensor. We propose a principal\ncomponents analysis (PCA) framework for sequence network data, based on a novel\ndecomposition for semi-symmetric tensors. We derive efficient algorithms for\ncomputing our proposed \"Coupled CP\" decomposition and establish estimation\nconsistency of our approach under an analogue of the spiked covariance model\nwith rates the same as the matrix case up to a logarithmic term. Our framework\ninherits many of the strengths of classical PCA and is suitable for a wide\nrange of unsupervised learning tasks, including identifying principal networks,\nisolating meaningful changepoints or outliers across observations, and for\ncharacterizing the \"variability network\" of the most varying edges. Finally, we\ndemonstrate the effectiveness of our proposal on simulated data and on examples\nfrom political science and financial economics. The proof techniques used to\nestablish our main consistency results are surprisingly straight-forward and\nmay find use in a variety of other matrix and tensor decomposition problems.",
    "descriptor": "",
    "authors": [
      "Michael Weylandt",
      "George Michailidis"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2202.04719"
  },
  {
    "id": "arXiv:2202.04744",
    "title": "Robust Bayesian Inference for Simulator-based Models via the MMD  Posterior Bootstrap",
    "abstract": "Simulator-based models are models for which the likelihood is intractable but\nsimulation of synthetic data is possible. They are often used to describe\ncomplex real-world phenomena, and as such can often be misspecified in\npractice. Unfortunately, existing Bayesian approaches for simulators are known\nto perform poorly in those cases. In this paper, we propose a novel algorithm\nbased on the posterior bootstrap and maximum mean discrepancy estimators. This\nleads to a highly-parallelisable Bayesian inference algorithm with strong\nrobustness properties. This is demonstrated through an in-depth theoretical\nstudy which includes generalisation bounds and proofs of frequentist\nconsistency and robustness of our posterior. The approach is then assessed on a\nrange of examples including a g-and-k distribution and a toggle-switch model.",
    "descriptor": "\nComments: Accepted for publication (with an oral presentation) at AISTATS 2022. A preliminary version of this paper was accepted in the NeurIPS 2021 workshop \"Your Model is Wrong: Robustness and misspecification in probabilistic modeling\"\n",
    "authors": [
      "Charita Dellaporta",
      "Jeremias Knoblauch",
      "Theodoros Damoulas",
      "Fran\u00e7ois-Xavier Briol"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.04744"
  },
  {
    "id": "arXiv:2202.04754",
    "title": "Wireless Transmission of Images With The Assistance of Multi-level  Semantic Information",
    "abstract": "Semantic-oriented communication has been considered as a promising to boost\nthe bandwidth efficiency by only transmitting the semantics of the data. In\nthis paper, we propose a multi-level semantic aware communication system for\nwireless image transmission, named MLSC-image, which is based on the deep\nlearning techniques and trained in an end to end manner. In particular, the\nproposed model includes a multilevel semantic feature extractor, that extracts\nboth the highlevel semantic information, such as the text semantics and the\nsegmentation semantics, and the low-level semantic information, such as local\nspatial details of the images. We employ a pretrained image caption to capture\nthe text semantics and a pretrained image segmentation model to obtain the\nsegmentation semantics. These high-level and low-level semantic features are\nthen combined and encoded by a joint semantic and channel encoder into symbols\nto transmit over the physical channel. The numerical results validate the\neffectiveness and efficiency of the proposed semantic communication system,\nespecially under the limited bandwidth condition, which indicates the\nadvantages of the high-level semantics in the compression of images.",
    "descriptor": "",
    "authors": [
      "Zhenguo Zhang",
      "Qianqian Yang",
      "Shibo He",
      "Mingyang Sun",
      "Jiming Chen"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.04754"
  },
  {
    "id": "arXiv:2202.04773",
    "title": "A Neural Network Model of Continual Learning with Cognitive Control",
    "abstract": "Neural networks struggle in continual learning settings from catastrophic\nforgetting: when trials are blocked, new learning can overwrite the learning\nfrom previous blocks. Humans learn effectively in these settings, in some cases\neven showing an advantage of blocking, suggesting the brain contains mechanisms\nto overcome this problem. Here, we build on previous work and show that neural\nnetworks equipped with a mechanism for cognitive control do not exhibit\ncatastrophic forgetting when trials are blocked. We further show an advantage\nof blocking over interleaving when there is a bias for active maintenance in\nthe control signal, implying a tradeoff between maintenance and the strength of\ncontrol. Analyses of map-like representations learned by the networks provided\nadditional insights into these mechanisms. Our work highlights the potential of\ncognitive control to aid continual learning in neural networks, and offers an\nexplanation for the advantage of blocking that has been observed in humans.",
    "descriptor": "\nComments: 7 pages, 5 figures, submitted to CogSci 2022\n",
    "authors": [
      "Jacob Russin",
      "Maryam Zolfaghar",
      "Seongmin A. Park",
      "Erie Boorman",
      "Randall C. O'Reilly"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2202.04773"
  },
  {
    "id": "arXiv:2202.04777",
    "title": "Exact Solutions of a Deep Linear Network",
    "abstract": "This work finds the exact solutions to a deep linear network with weight\ndecay and stochastic neurons, a fundamental model for understanding the\nlandscape of neural networks. Our result implies that weight decay strongly\ninteracts with the model architecture and can create bad minima in a network\nwith more than $1$ hidden layer, qualitatively different for a network with\nonly $1$ hidden layer. As an application, we also analyze stochastic nets and\nshow that their prediction variance vanishes to zero as the stochasticity, the\nwidth, or the depth tends to infinity.",
    "descriptor": "\nComments: Preprint\n",
    "authors": [
      "Liu Ziyin",
      "Botao Li",
      "Xiangming Meng"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.04777"
  },
  {
    "id": "arXiv:2202.04785",
    "title": "Multiclass histogram-based thresholding using kernel density estimation  and scale-space representations",
    "abstract": "We present a new method for multiclass thresholding of a histogram which is\nbased on the nonparametric Kernel Density (KD) estimation, where the unknown\nparameters of the KD estimate are defined using the Expectation-Maximization\n(EM) iterations. The method compares the number of extracted minima of the KD\nestimate with the number of the requested clusters minus one. If these numbers\nmatch, the algorithm returns positions of the minima as the threshold values,\notherwise, the method gradually decreases/increases the kernel bandwidth until\nthe numbers match. We verify the method using synthetic histograms with known\nthreshold values and using the histogram of real X-ray computed tomography\nimages. After thresholding of the real histogram, we estimated the porosity of\nthe sample and compare it with the direct experimental measurements. The\ncomparison shows the meaningfulness of the thresholding.",
    "descriptor": "",
    "authors": [
      "S. Korneev",
      "J. Gilles",
      "I. Battiato"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.04785"
  },
  {
    "id": "arXiv:2202.04807",
    "title": "Spatial active noise control based on individual kernel interpolation of  primary and secondary sound fields",
    "abstract": "A spatial active noise control (ANC) method based on the individual kernel\ninterpolation of primary and secondary sound fields is proposed. Spatial ANC is\naimed at cancelling unwanted primary noise within a continuous region by using\nmultiple secondary sources and microphones. A method based on the kernel\ninterpolation of a sound field makes it possible to attenuate noise over the\ntarget region with flexible array geometry. Furthermore, by using the kernel\nfunction with directional weighting, prior information on primary noise source\ndirections can be taken into consideration. However, whereas the sound field to\nbe interpolated is a superposition of primary and secondary sound fields, the\ndirectional weight for the primary noise source was applied to the total sound\nfield in previous work; therefore, the performance improvement was limited. We\npropose a method of individually interpolating the primary and secondary sound\nfields and formulate a normalized least-mean-square algorithm based on this\ninterpolation method. Experimental results indicate that the proposed method\noutperforms the method based on total kernel interpolation.",
    "descriptor": "\nComments: Accepted to International Conference on Acoustics, Speech and Signal Processing (ICASSP) 2022\n",
    "authors": [
      "Kazuyuki Arikawa",
      "Shoichi Koyama",
      "Hiroshi Saruwatari"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2202.04807"
  },
  {
    "id": "arXiv:2202.04823",
    "title": "Decreasing Annotation Burden of Pairwise Comparisons with  Human-in-the-Loop Sorting: Application in Medical Image Artifact Rating",
    "abstract": "Ranking by pairwise comparisons has shown improved reliability over ordinal\nclassification. However, as the annotations of pairwise comparisons scale\nquadratically, this becomes less practical when the dataset is large. We\npropose a method for reducing the number of pairwise comparisons required to\nrank by a quantitative metric, demonstrating the effectiveness of the approach\nin ranking medical images by image quality in this proof of concept study.\nUsing the medical image annotation software that we developed, we actively\nsubsample pairwise comparisons using a sorting algorithm with a human rater in\nthe loop. We find that this method substantially reduces the number of\ncomparisons required for a full ordinal ranking without compromising\ninter-rater reliability when compared to pairwise comparisons without sorting.",
    "descriptor": "\nComments: 5 pages, 2 figures, NeurIPS Data-Centric AI Workshop 2021\n",
    "authors": [
      "Ikbeom Jang",
      "Garrison Danley",
      "Ken Chang",
      "Jayashree Kalpathy-Cramer"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2202.04823"
  },
  {
    "id": "arXiv:2202.04828",
    "title": "Learning Latent Causal Dynamics",
    "abstract": "One critical challenge of time-series modeling is how to learn and quickly\ncorrect the model under unknown distribution shifts. In this work, we propose a\nprincipled framework, called LiLY, to first recover time-delayed latent causal\nvariables and identify their relations from measured temporal data under\ndifferent distribution shifts. The correction step is then formulated as\nlearning the low-dimensional change factors with a few samples from the new\nenvironment, leveraging the identified causal structure. Specifically, the\nframework factorizes unknown distribution shifts into transition distribution\nchanges caused by fixed dynamics and time-varying latent causal relations, and\nby global changes in observation. We establish the identifiability theories of\nnonparametric latent causal dynamics from their nonlinear mixtures under fixed\ndynamics and under changes. Through experiments, we show that time-delayed\nlatent causal influences are reliably identified from observed variables under\ndifferent distribution changes. By exploiting this modular representation of\nchanges, we can efficiently learn to correct the model under unknown\ndistribution shifts with only a few samples.",
    "descriptor": "",
    "authors": [
      "Weiran Yao",
      "Guangyi Chen",
      "Kun Zhang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.04828"
  },
  {
    "id": "arXiv:2202.04832",
    "title": "Bayesian Optimisation for Mixed-Variable Inputs using Value Proposals",
    "abstract": "Many real-world optimisation problems are defined over both categorical and\ncontinuous variables, yet efficient optimisation methods such asBayesian\nOptimisation (BO) are not designed tohandle such mixed-variable search spaces.\nRe-cent approaches to this problem cast the selection of the categorical\nvariables as a bandit problem, operating independently alongside a BO component\nwhich optimises the continuous variables. In this paper, we adopt a holistic\nview and aim to consolidate optimisation of the categorical and continuous\nsub-spaces under a single acquisition metric. We derive candidates from the\nExpectedImprovement criterion, which we call value proposals, and use these\nproposals to make selections on both the categorical and continuous components\nof the input. We show that this unified approach significantly outperforms\nexisting mixed-variable optimisation approaches across several mixed-variable\nblack-box optimisation tasks.",
    "descriptor": "",
    "authors": [
      "Yan Zuo",
      "Amir Dezfouli",
      "Iadine Chades",
      "David Alexander",
      "Benjamin Ward Muir"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.04832"
  },
  {
    "id": "arXiv:2202.04835",
    "title": "Robophysical modeling of spacetime dynamics",
    "abstract": "Systems consisting of spheres rolling on elastic membranes have been used as\neducational tools to introduce a core conceptual idea of General Relativity\n(GR): how curvature guides the movement of matter. However, previous studies\nhave revealed that such schemes cannot accurately represent relativistic\ndynamics in the laboratory. Dissipative forces cause the initially GR-like\ndynamics to be transient and consequently restrict experimental study to only\nthe beginnings of trajectories; dominance of Earth's gravity forbids the\ndifference between spatial and temporal spacetime curvatures. Here by\ndeveloping a mapping between dynamics of a wheeled vehicle on a spandex\nmembrane, we demonstrate that an active object that can prescribe its speed can\nnot only obtain steady-state orbits, but also use the additional parameters\nsuch as speed to tune the orbits towards relativistic dynamics. Our mapping\ndemonstrates how activity mixes space and time in a metric, shows how active\nparticles do not necessarily follow geodesics in the real space but instead\nfollow geodesics in a fiducial spacetime. The mapping further reveals how\nparameters such as the membrane elasticity and instantaneous speed allow\nprogramming a desired spacetime such as the Schwarzschild metric near a\nnon-rotating black hole. Our mapping and framework point the way to the\npossibility to create a robophysical analog gravity system in the laboratory at\nlow cost and provide insights into active matter in deformable environments and\nrobot exploration in complex landscapes.",
    "descriptor": "",
    "authors": [
      "Shengkai Li",
      "Hussain N. Gynai",
      "Steven Tarr",
      "Pablo Laguna",
      "Gongjie Li",
      "Daniel I. Goldman"
    ],
    "subjectives": [
      "General Relativity and Quantum Cosmology (gr-qc)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.04835"
  },
  {
    "id": "arXiv:2202.04837",
    "title": "Heterogeneous Calibration: A post-hoc model-agnostic framework for  improved generalization",
    "abstract": "We introduce the notion of heterogeneous calibration that applies a post-hoc\nmodel-agnostic transformation to model outputs for improving AUC performance on\nbinary classification tasks. We consider overconfident models, whose\nperformance is significantly better on training vs test data and give intuition\nonto why they might under-utilize moderately effective simple patterns in the\ndata. We refer to these simple patterns as heterogeneous partitions of the\nfeature space and show theoretically that perfectly calibrating each partition\nseparately optimizes AUC. This gives a general paradigm of heterogeneous\ncalibration as a post-hoc procedure by which heterogeneous partitions of the\nfeature space are identified through tree-based algorithms and post-hoc\ncalibration techniques are applied to each partition to improve AUC. While the\ntheoretical optimality of this framework holds for any model, we focus on deep\nneural networks (DNNs) and test the simplest instantiation of this paradigm on\na variety of open-source datasets. Experiments demonstrate the effectiveness of\nthis framework and the future potential for applying higher-performing\npartitioning schemes along with more effective calibration techniques.",
    "descriptor": "",
    "authors": [
      "David Durfee",
      "Aman Gupta",
      "Kinjal Basu"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.04837"
  },
  {
    "id": "arXiv:2202.04855",
    "title": "The USTC-Ximalaya system for the ICASSP 2022 multi-channel multi-party  meeting transcription (M2MeT) challenge",
    "abstract": "We propose two improvements to target-speaker voice activity detection\n(TS-VAD), the core component in our proposed speaker diarization system that\nwas submitted to the 2022 Multi-Channel Multi-Party Meeting Transcription\n(M2MeT) challenge. These techniques are designed to handle multi-speaker\nconversations in real-world meeting scenarios with high speaker-overlap ratios\nand under heavy reverberant and noisy condition. First, for data preparation\nand augmentation in training TS-VAD models, speech data containing both real\nmeetings and simulated indoor conversations are used. Second, in refining\nresults obtained after TS-VAD based decoding, we perform a series of\npost-processing steps to improve the VAD results needed to reduce diarization\nerror rates (DERs). Tested on the ALIMEETING corpus, the newly released\nMandarin meeting dataset used in M2MeT, we demonstrate that our proposed system\ncan decrease the DER by up to 66.55/60.59% relatively when compared with\nclassical clustering based diarization on the Eval/Test set.",
    "descriptor": "",
    "authors": [
      "Maokui He",
      "Xiang Lv",
      "Weilin Zhou",
      "JingJing Yin",
      "Xiaoqi Zhang",
      "Yuxuan Wang",
      "Shutong Niu",
      "Yuhang Cao",
      "Heng Lu",
      "Jun Du",
      "Chin-Hui Lee"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2202.04855"
  },
  {
    "id": "arXiv:2202.04862",
    "title": "Settling the Communication Complexity for Distributed Offline  Reinforcement Learning",
    "abstract": "We study a novel setting in offline reinforcement learning (RL) where a\nnumber of distributed machines jointly cooperate to solve the problem but only\none single round of communication is allowed and there is a budget constraint\non the total number of information (in terms of bits) that each machine can\nsend out. For value function prediction in contextual bandits, and both\nepisodic and non-episodic MDPs, we establish information-theoretic lower bounds\non the minimax risk for distributed statistical estimators; this reveals the\nminimum amount of communication required by any offline RL algorithms.\nSpecifically, for contextual bandits, we show that the number of bits must\nscale at least as $\\Omega(AC)$ to match the centralised minimax optimal rate,\nwhere $A$ is the number of actions and $C$ is the context dimension; meanwhile,\nwe reach similar results in the MDP settings. Furthermore, we develop learning\nalgorithms based on least-squares estimates and Monte-Carlo return estimates\nand provide a sharp analysis showing that they can achieve optimal risk up to\nlogarithmic factors. Additionally, we also show that temporal difference is\nunable to efficiently utilise information from all available devices under the\nsingle-round communication setting due to the initial bias of this method. To\nour best knowledge, this paper presents the first minimax lower bounds for\ndistributed offline RL problems.",
    "descriptor": "",
    "authors": [
      "Juliusz Krysztof Ziomek",
      "Jun Wang",
      "Yaodong Yang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.04862"
  },
  {
    "id": "arXiv:2202.04896",
    "title": "Faulty isogenies: a new kind of leakage",
    "abstract": "In SIDH and SIKE protocols, public keys are defined over quadratic extensions\nof prime fields. We present in this work a projective invariant property\ncharacterizing affine Montgomery curves defined over prime fields. We then\nforce a secret 3-isogeny chain to repeatedly pass through a curve defined over\na prime field in order to exploit the new property and inject zeros in the\nA-coefficient of an intermediate curve to successfully recover the isogeny\nchain one step at a time. Our results introduce a new kind of fault attacks\napplicable to SIDH and SIKE.",
    "descriptor": "",
    "authors": [
      "Gora Adj",
      "Jes\u00fas-Javier Chi-Dom\u00ednguez",
      "V\u00edctor Mateu",
      "Francisco Rodr\u00edguez-Henr\u00edquez"
    ],
    "subjectives": [
      "Number Theory (math.NT)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.04896"
  },
  {
    "id": "arXiv:2202.04912",
    "title": "Random Forests Weighted Local Fr\u00e9chet Regression with Theoretical  Guarantee",
    "abstract": "Statistical analysis is increasingly confronted with complex data from\ngeneral metric spaces, such as symmetric positive definite matrix-valued data\nand probability distribution functions. [47] and [17] establish a general\nparadigm of Fr\\'echet regression with complex metric space valued responses and\nEuclidean predictors. However, their proposed local Fr\\'echet regression\napproach involves nonparametric kernel smoothing and suffers from the curse of\ndimensionality. To address this issue, we in this paper propose a novel random\nforests weighted local Fr\\'echet regression paradigm. The main mechanism of our\napproach relies on the adaptive kernels generated by random forests. Our first\nmethod utilizes these weights as the local average to solve the Fr\\'echet mean,\nwhile the second method performs local linear Fr\\'echet regression, making both\nmethods locally adaptive. Our proposals significantly improve existing\nFr\\'echet regression methods. Based on the theory of infinite order U-processes\nand infinite order Mmn-estimator, we establish the consistency, rate of\nconvergence, and asymptotic normality for our proposed random forests weighted\nFr\\'echet regression estimator, which covers the current large sample theory of\nrandom forests with Euclidean responses as a special case. Numerical studies\nshow the superiority of our proposed two methods for Fr\\'echet regression with\nseveral commonly encountered types of responses such as probability\ndistribution functions, symmetric positive definite matrices, and sphere data.\nThe practical merits of our proposals are also demonstrated through the\napplication to the human mortality distribution data.",
    "descriptor": "",
    "authors": [
      "Rui Qiu",
      "Zhou Yu",
      "Ruoqing Zhu"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.04912"
  },
  {
    "id": "arXiv:2202.04917",
    "title": "Study of COVID-19 epidemiological evolution in India with a multi-wave  SIR model",
    "abstract": "The global pandemic due to the outbreak of COVID-19 ravages the whole world\nfor more than two years in which all the countries are suffering a lot since\nDecember 2019. In order to control this ongoing waves of epidemiological\ninfections, attempts have been made to understand the dynamics of this pandemic\nin deterministic approach with the help of several mathematical models. In this\narticle characteristics of a multi-wave SIR model have been studied which\nsuccessfully explains the features of this pandemic waves in India. Stability\nof this model has been studied by identifying the equilibrium points as well as\nby finding the eigen values of the corresponding Jacobian matrices. Complex\neigen values are found which ultimately give rise to the oscillatory solutions\nfor the three categories of populations, say, susceptible, infected and\nremoved. In this model, a finite probability of the recovered people for\nbecoming susceptible again is introduced which eventually lead to the\noscillatory solution in other words. The set of differential equations has been\nsolved numerically in order to obtain the variation for numbers of susceptible,\ninfected and removed people with time. In this phenomenological study, finally\nan additional modification is made in order to explain the aperiodic\noscillation which is found necessary to capture the feature of epidemiological\nwaves particularly in India.",
    "descriptor": "\nComments: Five pages, two-column, six figures\n",
    "authors": [
      "Kalpita Ghosh",
      "Asim Kumar Ghosh"
    ],
    "subjectives": [
      "Populations and Evolution (q-bio.PE)",
      "Computers and Society (cs.CY)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2202.04917"
  },
  {
    "id": "arXiv:2202.04961",
    "title": "Monotonically Convergent Regularization by Denoising",
    "abstract": "Regularization by denoising (RED) is a widely-used framework for solving\ninverse problems by leveraging image denoisers as image priors. Recent work has\nreported the state-of-the-art performance of RED in a number of imaging\napplications using pre-trained deep neural nets as denoisers. Despite the\nrecent progress, the stable convergence of RED algorithms remains an open\nproblem. The existing RED theory only guarantees stability for convex\ndata-fidelity terms and nonexpansive denoisers. This work addresses this issue\nby developing a new monotone RED (MRED) algorithm, whose convergence does not\nrequire nonexpansiveness of the deep denoising prior. Simulations on image\ndeblurring and compressive sensing recovery from random matrices show the\nstability of MRED even when the traditional RED algorithm diverges.",
    "descriptor": "",
    "authors": [
      "Yuyang Hu",
      "Jiaming Liu",
      "Xiaojian Xu",
      "Ulugbek S. Kamilov"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.04961"
  },
  {
    "id": "arXiv:2202.04962",
    "title": "Feasible Low-thrust Trajectory Identification via a Deep Neural Network  Classifier",
    "abstract": "In recent years, deep learning techniques have been introduced into the field\nof trajectory optimization to improve convergence and speed. Training such\nmodels requires large trajectory datasets. However, the convergence of low\nthrust (LT) optimizations is unpredictable before the optimization process\nends. For randomly initialized low thrust transfer data generation, most of the\ncomputation power will be wasted on optimizing infeasible low thrust transfers,\nwhich leads to an inefficient data generation process. This work proposes a\ndeep neural network (DNN) classifier to accurately identify feasible LT\ntransfer prior to the optimization process. The DNN-classifier achieves an\noverall accuracy of 97.9%, which has the best performance among the tested\nalgorithms. The accurate low-thrust trajectory feasibility identification can\navoid optimization on undesired samples, so that the majority of the optimized\nsamples are LT trajectories that converge. This technique enables efficient\ndataset generation for different mission scenarios with different spacecraft\nconfigurations.",
    "descriptor": "\nComments: 18 Pages; 10 figures; Presented at 2021 AAS/AIAA Astrodynamics Specialist Conference, Big Sky, Virtual\n",
    "authors": [
      "Ruida Xie",
      "Andrew G. Dempster"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.04962"
  },
  {
    "id": "arXiv:2202.04965",
    "title": "$\u0393$-Convergence of an Ambrosio-Tortorelli approximation scheme for  image segmentation",
    "abstract": "Given an image $u_0$, the aim of minimising the Mumford-Shah functional is to\nfind a decomposition of the image domain into sub-domains and a piecewise\nsmooth approximation $u$ of $u_0$ such that $u$ varies smoothly within each\nsub-domain. Since the Mumford-Shah functional is highly non-smooth,\nregularizations such as the Ambrosio-Tortorelli approximation can be considered\nwhich is one of the most computationally efficient approximations of the\nMumford-Shah functional for image segmentation. Our main result is the\n$\\Gamma$-convergence of the Ambrosio-Tortorelli approximation of the\nMumford-Shah functional for piecewise smooth approximations. This requires the\nintroduction of an appropriate function space. As a consequence of our\n$\\Gamma$-convergence result, we can infer the convergence of minimizers of the\nrespective functionals.",
    "descriptor": "",
    "authors": [
      "Irene Fonseca",
      "Lisa Maria Kreusser",
      "Carola-Bibiane Sch\u00f6nlieb",
      "Matthew Thorpe"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Analysis of PDEs (math.AP)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.04965"
  },
  {
    "id": "arXiv:2202.04970",
    "title": "Off-Policy Fitted Q-Evaluation with Differentiable Function  Approximators: Z-Estimation and Inference Theory",
    "abstract": "Off-Policy Evaluation (OPE) serves as one of the cornerstones in\nReinforcement Learning (RL). Fitted Q Evaluation (FQE) with various function\napproximators, especially deep neural networks, has gained practical success.\nWhile statistical analysis has proved FQE to be minimax-optimal with tabular,\nlinear and several nonparametric function families, its practical performance\nwith more general function approximator is less theoretically understood. We\nfocus on FQE with general differentiable function approximators, making our\ntheory applicable to neural function approximations. We approach this problem\nusing the Z-estimation theory and establish the following results: The FQE\nestimation error is asymptotically normal with explicit variance determined\njointly by the tangent space of the function class at the ground truth, the\nreward structure, and the distribution shift due to off-policy learning; The\nfinite-sample FQE error bound is dominated by the same variance term, and it\ncan also be bounded by function class-dependent divergence, which measures how\nthe off-policy distribution shift intertwines with the function approximator.\nIn addition, we study bootstrapping FQE estimators for error distribution\ninference and estimating confidence intervals, accompanied by a Cramer-Rao\nlower bound that matches our upper bounds. The Z-estimation analysis provides a\ngeneralizable theoretical framework for studying off-policy estimation in RL\nand provides sharp statistical theory for FQE with differentiable function\napproximators.",
    "descriptor": "\nComments: 39 pages\n",
    "authors": [
      "Ruiqi Zhang",
      "Xuezhou Zhang",
      "Chengzhuo Ni",
      "Mengdi Wang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.04970"
  },
  {
    "id": "arXiv:2202.04985",
    "title": "Generalization Bounds via Convex Analysis",
    "abstract": "Since the celebrated works of Russo and Zou (2016,2019) and Xu and Raginsky\n(2017), it has been well known that the generalization error of supervised\nlearning algorithms can be bounded in terms of the mutual information between\ntheir input and the output, given that the loss of any fixed hypothesis has a\nsubgaussian tail. In this work, we generalize this result beyond the standard\nchoice of Shannon's mutual information to measure the dependence between the\ninput and the output. Our main result shows that it is indeed possible to\nreplace the mutual information by any strongly convex function of the joint\ninput-output distribution, with the subgaussianity condition on the losses\nreplaced by a bound on an appropriately chosen norm capturing the geometry of\nthe dependence measure. This allows us to derive a range of generalization\nbounds that are either entirely new or strengthen previously known ones.\nExamples include bounds stated in terms of $p$-norm divergences and the\nWasserstein-2 distance, which are respectively applicable for heavy-tailed loss\ndistributions and highly smooth loss functions. Our analysis is entirely based\non elementary tools from convex analysis by tracking the growth of a potential\nfunction associated with the dependence measure and the loss function.",
    "descriptor": "",
    "authors": [
      "Gergely Neu",
      "G\u00e1bor Lugosi"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.04985"
  },
  {
    "id": "arXiv:2202.05001",
    "title": "IEC Flickermeter Measurement Results for Distorted Modulating Signal  while Supplied with Distorted Voltage",
    "abstract": "The paper presents IEC flickermeter measurement results for voltage\nfluctuations modelled by amplitude modulation of distorted supply voltage. The\nsupply voltage distortion caused by electronic and power electronic devices in\nthe \"clipped cosine\" form is assumed. This type of supply voltage distortion is\na common disturbance in low voltage networks. Several arbitrary distorted\nwaveforms of the modulating signal with different modulation depth and\nmodulating frequency up to approx. 1 kHz are selected to determine the\ndependence of severity of voltage fluctuation on their shape. The paper mainly\npresents the dependence of voltage fluctuation severity with a frequency\ngreater than 3fc, where fc is the power frequency. The voltage fluctuation\nseverity and the dependencies associated with it have been determined on the\nbasis of numerical simulation studies and experimental laboratory tests.",
    "descriptor": "\nComments: 6 pages; 8 figures; The paper submitted to 20th International Conference on Harmonics and Quality of Power (ICHQP)\n",
    "authors": [
      "Piotr Kuwa\u0142ek"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.05001"
  },
  {
    "id": "arXiv:2202.05012",
    "title": "SUPA: A Lightweight Diagnostic Simulator for Machine Learning in  Particle Physics",
    "abstract": "Deep learning methods have gained popularity in high energy physics for fast\nmodeling of particle showers in detectors. Detailed simulation frameworks such\nas the gold standard Geant4 are computationally intensive, and current deep\ngenerative architectures work on discretized, lower resolution versions of the\ndetailed simulation. The development of models that work at higher spatial\nresolutions is currently hindered by the complexity of the full simulation\ndata, and by the lack of simpler, more interpretable benchmarks. Our\ncontribution is SUPA, the SUrrogate PArticle propagation simulator, an\nalgorithm and software package for generating data by simulating simplified\nparticle propagation, scattering and shower development in matter. The\ngeneration is extremely fast and easy to use compared to Geant4, but still\nexhibits the key characteristics and challenges of the detailed simulation. We\nsupport this claim experimentally by showing that performance of generative\nmodels on data from our simulator reflects the performance on a dataset\ngenerated with Geant4. The proposed simulator generates thousands of particle\nshowers per second on a desktop machine, a speed up of up to 6 orders of\nmagnitudes over Geant4, and stores detailed geometric information about the\nshower propagation. SUPA provides much greater flexibility for setting initial\nconditions and defining multiple benchmarks for the development of models.\nMoreover, interpreting particle showers as point clouds creates a connection to\ngeometric machine learning and provides challenging and fundamentally new\ndatasets for the field.\nThe code for SUPA is available at https://github.com/itsdaniele/SUPA.",
    "descriptor": "",
    "authors": [
      "Atul Kumar Sinha",
      "Daniele Paliotta",
      "B\u00e1lint M\u00e1t\u00e9",
      "Sebastian Pina-Otey",
      "John A. Raine",
      "Tobias Golling",
      "Fran\u00e7ois Fleuret"
    ],
    "subjectives": [
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Machine Learning (cs.LG)",
      "High Energy Physics - Experiment (hep-ex)",
      "Accelerator Physics (physics.acc-ph)"
    ],
    "url": "https://arxiv.org/abs/2202.05012"
  },
  {
    "id": "arXiv:2202.05020",
    "title": "Decomposition Problem in Process of Selective Identification and  Localization of Voltage Fluctuations Sources in Power Grids",
    "abstract": "Voltage fluctuations are common disturbances in power grids, therefore the\neffective and selective process of identification and localization of\nindividual voltage fluctuations sources is necessary for the minimization of\nsuch disturbances. Selectivity in the process of identification and\nlocalization disturbing loads is possible by the use cascade of blocks:\ndemodulation, decomposition and propagation assessment. The effectiveness of\nthis approach is closely related to the used method of decomposition. The paper\npresents the problem of decomposition process for the selected method of\nselective identification and localization of voltage fluctuation sources, in\nwhich the algorithm of enhanced empirical wavelet transform (EEWT) is used as\nthe decomposition method. The paper presents selected research results from the\nreal power grid, for which the result of selected approach causes mistakes in\nthe process of identification and localization of voltage fluctuations sources.\nThe potential causes of such mistakes related to the decomposition process are\ndiscussed on the basis of obtained research results.",
    "descriptor": "\nComments: 6 pages; 10 figures; The paper submitted to 20th International Conference on Harmonics and Quality of Power (ICHQP)\n",
    "authors": [
      "Piotr Kuwa\u0142ek"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.05020"
  },
  {
    "id": "arXiv:2202.05034",
    "title": "Sharp $L_p$-error estimates for sampling operators",
    "abstract": "We study approximation properties of linear sampling operators in the spaces\n$L_p$ for $1\\le p<\\infty$. By means of the Steklov averages, we introduce a new\nmeasure of smoothness that simultaneously contains information on the\nsmoothness of a function in $L_p$ and discrete information on the behaviour of\na function at sampling points. The new measure of smoothness enables us to\nimprove and extend several classical results of approximation theory to the\ncase of linear sampling operators. In particular, we obtain matching direct and\ninverse approximation inequalities for sampling operators in $L_p$, find the\nexact order of decay of the corresponding $L_p$-errors for particular classes\nof functions, and introduce a special $K$-functional and its realization\nsuitable for studying smoothness properties of sampling operators.",
    "descriptor": "",
    "authors": [
      "Yurii Kolomoitsev",
      "Tetiana Lomako"
    ],
    "subjectives": [
      "Classical Analysis and ODEs (math.CA)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.05034"
  },
  {
    "id": "arXiv:2202.05049",
    "title": "Fair When Trained, Unfair When Deployed: Observable Fairness Measures  are Unstable in Performative Prediction Settings",
    "abstract": "Many popular algorithmic fairness measures depend on the joint distribution\nof predictions, outcomes, and a sensitive feature like race or gender. These\nmeasures are sensitive to distribution shift: a predictor which is trained to\nsatisfy one of these fairness definitions may become unfair if the distribution\nchanges. In performative prediction settings, however, predictors are precisely\nintended to induce distribution shift. For example, in many applications in\ncriminal justice, healthcare, and consumer finance, the purpose of building a\npredictor is to reduce the rate of adverse outcomes such as recidivism,\nhospitalization, or default on a loan. We formalize the effect of such\npredictors as a type of concept shift-a particular variety of distribution\nshift-and show both theoretically and via simulated examples how this causes\npredictors which are fair when they are trained to become unfair when they are\ndeployed. We further show how many of these issues can be avoided by using\nfairness definitions that depend on counterfactual rather than observable\noutcomes.",
    "descriptor": "\nComments: 11 pages, 3 figures. Presented at the workshop on Algorithmic Fairness through the Lens of Causality and Robustness, NeurIPS 2021\n",
    "authors": [
      "Alan Mishler",
      "Niccol\u00f2 Dalmasso"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.05049"
  },
  {
    "id": "arXiv:2202.05062",
    "title": "Equivariance Regularization for Image Reconstruction",
    "abstract": "In this work, we propose Regularization-by-Equivariance (REV), a novel\nstructure-adaptive regularization scheme for solving imaging inverse problems\nunder incomplete measurements. Our regularization scheme utilizes the\nequivariant structure in the physics of the measurements -- which is prevalent\nin many inverse problems such as tomographic image reconstruction -- to\nmitigate the ill-poseness of the inverse problem. Our proposed scheme can be\napplied in a plug-and-play manner alongside with any classic first-order\noptimization algorithm such as the accelerated gradient descent/FISTA for\nsimplicity and fast convergence. Our numerical experiments in sparse-view X-ray\nCT image reconstruction tasks demonstrate the effectiveness of our approach.",
    "descriptor": "",
    "authors": [
      "Junqi Tang"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2202.05062"
  },
  {
    "id": "arXiv:2202.05069",
    "title": "Transfer-Learning Across Datasets with Different Input Dimensions: An  Algorithm and Analysis for the Linear Regression Case",
    "abstract": "With the development of new sensors and monitoring devices, more sources of\ndata become available to be used as inputs for machine learning models. These\ncan on the one hand help to improve the accuracy of a model. On the other hand\nhowever, combining these new inputs with historical data remains a challenge\nthat has not yet been studied in enough detail. In this work, we propose a\ntransfer-learning algorithm that combines the new and the historical data, that\nis especially beneficial when the new data is scarce. We focus the approach on\nthe linear regression case, which allows us to conduct a rigorous theoretical\nstudy on the benefits of the approach. We show that our approach is robust\nagainst negative transfer-learning, and we confirm this result empirically with\nreal and simulated data.",
    "descriptor": "",
    "authors": [
      "Luis Pedro Silvestrin",
      "Harry van Zanten",
      "Mark Hoogendoorn",
      "Ger Koole"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.05069"
  },
  {
    "id": "arXiv:2202.05073",
    "title": "Computer Validation of Neural Network Dynamics: A First Case Study",
    "abstract": "A large number of current machine learning methods rely upon deep neural\nnetworks. Yet, viewing neural networks as nonlinear dynamical systems, it\nbecomes quickly apparent that mathematically rigorously establishing certain\npatterns generated by the nodes in the network is extremely difficult. Indeed,\nit is well-understood in the nonlinear dynamics of complex systems that, even\nin low-dimensional models, analytical techniques rooted in pencil-and-paper\napproaches reach their limits quickly. In this work, we propose a completely\ndifferent perspective via the paradigm of rigorous numerical methods of\nnonlinear dynamics. The idea is to use computer-assisted proofs to validate\nmathematically the existence of nonlinear patterns in neural networks. As a\ncase study, we consider a class of recurrent neural networks, where we prove\nvia computer assistance the existence of several hundred Hopf bifurcation\npoints, their non-degeneracy, and hence also the existence of several hundred\nperiodic orbits. Our paradigm has the capability to rigorously verify complex\nnonlinear behaviour of neural networks, which provides a first step to explain\nthe full abilities, as well as potential sensitivities, of machine learning\nmethods via computer-assisted proofs.",
    "descriptor": "",
    "authors": [
      "Christian Kuehn",
      "Elena Queirolo"
    ],
    "subjectives": [
      "Dynamical Systems (math.DS)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.05073"
  },
  {
    "id": "arXiv:2202.05083",
    "title": "Cross-speaker style transfer for text-to-speech using data augmentation",
    "abstract": "We address the problem of cross-speaker style transfer for text-to-speech\n(TTS) using data augmentation via voice conversion. We assume to have a corpus\nof neutral non-expressive data from a target speaker and supporting\nconversational expressive data from different speakers. Our goal is to build a\nTTS system that is expressive, while retaining the target speaker's identity.\nThe proposed approach relies on voice conversion to first generate high-quality\ndata from the set of supporting expressive speakers. The voice converted data\nis then pooled with natural data from the target speaker and used to train a\nsingle-speaker multi-style TTS system. We provide evidence that this approach\nis efficient, flexible, and scalable. The method is evaluated using one or more\nsupporting speakers, as well as a variable amount of supporting data. We\nfurther provide evidence that this approach allows some controllability of\nspeaking style, when using multiple supporting speakers. We conclude by scaling\nour proposed technology to a set of 14 speakers across 7 languages. Results\nindicate that our technology consistently improves synthetic samples in terms\nof style similarity, while retaining the target speaker's identity.",
    "descriptor": "\nComments: 5 pages, 3 figures, 4 tables. ICASSP 2022\n",
    "authors": [
      "Manuel Sam Ribeiro",
      "Julian Roth",
      "Giulia Comini",
      "Goeric Huybrechts",
      "Adam Gabrys",
      "Jaime Lorenzo-Trueba"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2202.05083"
  },
  {
    "id": "arXiv:2202.05098",
    "title": "AD-NEGF: An End-to-End Differentiable Quantum Transport Simulator for  Sensitivity Analysis and Inverse Problems",
    "abstract": "Since proposed in the 70s, the Non-Equilibrium Green Function (NEGF) method\nhas been recognized as a standard approach to quantum transport simulations.\nAlthough it achieves superiority in simulation accuracy, the tremendous\ncomputational cost makes it unbearable for high-throughput simulation tasks\nsuch as sensitivity analysis, inverse design, etc. In this work, we propose\nAD-NEGF, to our best knowledge the first end-to-end differentiable NEGF model\nfor quantum transport simulations. We implement the entire numerical process in\nPyTorch, and design customized backward pass with implicit layer techniques,\nwhich provides gradient information at an affordable cost while guaranteeing\nthe correctness of the forward simulation. The proposed model is validated with\napplications in calculating differential physical quantities, empirical\nparameter fitting, and doping optimization, which demonstrates its capacity to\naccelerate the material design process by conducting gradient-based parameter\noptimization.",
    "descriptor": "\nComments: 13 pages including references\n",
    "authors": [
      "Yingzhanghao Zhou",
      "Xiang Chen",
      "Peng Zhang",
      "Jun Wang",
      "Lei Wang",
      "Hong Guo"
    ],
    "subjectives": [
      "Mesoscale and Nanoscale Physics (cond-mat.mes-hall)",
      "Machine Learning (cs.LG)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2202.05098"
  },
  {
    "id": "arXiv:2202.05099",
    "title": "Social interactions affect discovery processes",
    "abstract": "Our network of acquaintances determines how we get exposed to ideas,\nproducts, or cultural artworks (books, music, movies, etc.). Though this\nprinciple is part of our common sense, little is known about the specific\npathways through which our peers influence our discovery processes and our\nexperience of the new. Here, we fill this gap by investigating a data set\ncontaining the whole listening histories of a large, socially connected sample\nof users from the online music platform \\emph{Last.fm}. We demonstrate that\nusers exhibit highly heterogeneous discovery rates of new songs and artists and\nthat their social neighborhood significantly influences their behavior. More\nexplorative users tend to interact with peers more prone to explore new\ncontent. We capture this phenomenology in a modeling scheme where users are\nrepresented by random walkers exploring a graph of songs or artists and\ninteracting with each other through their social links. Even starting from a\nuniform population of agents (no natural differences among the individuals),\nour model predicts the emergence of strong heterogeneous exploration patterns,\nwith users clustered according to their musical tastes and propensity to\nexplore. We contend our approach can pave the way to a quantitative approach to\ncollective discovery processes.",
    "descriptor": "",
    "authors": [
      "Gabriele Di Bona",
      "Enrico Ubaldi",
      "Iacopo Iacopini",
      "Bernardo Monechi",
      "Vito Latora",
      "Vittorio Loreto"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2202.05099"
  },
  {
    "id": "arXiv:2202.05100",
    "title": "Adaptively Exploiting d-Separators with Causal Bandits",
    "abstract": "Multi-armed bandit problems provide a framework to identify the optimal\nintervention over a sequence of repeated experiments. Without additional\nassumptions, minimax optimal performance (measured by cumulative regret) is\nwell-understood. With access to additional observed variables that d-separate\nthe intervention from the outcome (i.e., they are a d-separator), recent causal\nbandit algorithms provably incur less regret. However, in practice it is\ndesirable to be agnostic to whether observed variables are a d-separator.\nIdeally, an algorithm should be adaptive; that is, perform nearly as well as an\nalgorithm with oracle knowledge of the presence or absence of a d-separator. In\nthis work, we formalize and study this notion of adaptivity, and provide a\nnovel algorithm that simultaneously achieves (a) optimal regret when a\nd-separator is observed, improving on classical minimax algorithms, and (b)\nsignificantly smaller regret than recent causal bandit algorithms when the\nobserved variables are not a d-separator. Crucially, our algorithm does not\nrequire any oracle knowledge of whether a d-separator is observed. We also\ngeneralize this adaptivity to other conditions, such as the front-door\ncriterion.",
    "descriptor": "\nComments: 32 pages, 3 figures\n",
    "authors": [
      "Blair Bilodeau",
      "Linbo Wang",
      "Daniel M. Roy"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.05100"
  },
  {
    "id": "arXiv:2202.05112",
    "title": "Probabilistic learning inference of boundary value problem with  uncertainties based on Kullback-Leibler divergence under implicit constraints",
    "abstract": "In a first part, we present a mathematical analysis of a general methodology\nof a probabilistic learning inference that allows for estimating a posterior\nprobability model for a stochastic boundary value problem from a prior\nprobability model. The given targets are statistical moments for which the\nunderlying realizations are not available. Under these conditions, the\nKullback-Leibler divergence minimum principle is used for estimating the\nposterior probability measure. A statistical surrogate model of the implicit\nmapping, which represents the constraints, is introduced. The MCMC generator\nand the necessary numerical elements are given to facilitate the implementation\nof the methodology in a parallel computing framework. In a second part, an\napplication is presented to illustrate the proposed theory and is also, as\nsuch, a contribution to the three-dimensional stochastic homogenization of\nheterogeneous linear elastic media in the case of a non-separation of the\nmicroscale and macroscale. For the construction of the posterior probability\nmeasure by using the probabilistic learning inference, in addition to the\nconstraints defined by given statistical moments of the random effective\nelasticity tensor, the second-order moment of the random normalized residue of\nthe stochastic partial differential equation has been added as a constraint.\nThis constraint guarantees that the algorithm seeks to bring the statistical\nmoments closer to their targets while preserving a small residue.",
    "descriptor": "\nComments: 30 pages, 6 figures\n",
    "authors": [
      "Christian Soize"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2202.05112"
  },
  {
    "id": "arXiv:2202.05126",
    "title": "Deep Learning for Computational Cytology: A Survey",
    "abstract": "Computational cytology is a critical, rapid-developing, yet challenging topic\nin the field of medical image computing which analyzes the digitized cytology\nimage by computer-aided technologies for cancer screening. Recently, an\nincreasing number of deep learning (DL) algorithms have made significant\nprogress in medical image analysis, leading to the boosting publications of\ncytological studies. To investigate the advanced methods and comprehensive\napplications, we survey more than 120 publications of DL-based cytology image\nanalysis in this article. We first introduce various deep learning methods,\nincluding fully supervised, weakly supervised, unsupervised, and transfer\nlearning. Then, we systematically summarize the public datasets, evaluation\nmetrics, versatile cytology image analysis applications including\nclassification, detection, segmentation, and other related tasks. Finally, we\ndiscuss current challenges and potential research directions of computational\ncytology.",
    "descriptor": "",
    "authors": [
      "Hao Jiang",
      "Yanning Zhou",
      "Yi Lin",
      "Ronald CK Chan",
      "Jiang Liu",
      "Hao Chen"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.05126"
  },
  {
    "id": "arXiv:2202.05128",
    "title": "Load Balancing and Resource Allocation in Fog-Assisted 5G Networks: An  Incentive-based Game Theoretic Approach",
    "abstract": "Fog-assisted 5G Networks allow the users within the networks to execute their\ntasks and processes through fog nodes and cooperation among the fog nodes. As a\nresult, the delay in task execution reduces as compared to that in case of\nindependent task execution, where the Base Station (BS) or server is directly\ninvolved. In the practical scenario, the ability to cooperate clearly depends\non the willingness of fog nodes to cooperate. Hence, in this paper, we propose\nan incentive-based bargaining approach which encourages the fog nodes to\ncooperate among themselves by receiving incentives from the end users\nbenefitting from the cooperation. Considering the heterogenous nature of users\nand fog nodes based on their storage capacity, energy efficiency etc., we aim\nto emphasise a fair incentive mechanism which fairly and uniformly distributes\nthe incentives from user to the participating fog nodes. The proposed\nincentive-based cooperative approach reduces the cost of end users as well as\nbalances the energy consumption of fog nodes. The proposed system model\naddresses and models the above approaches and mathematically formulate cost\nmodels for both fog nodes and the end users in a fog-assisted 5G network.",
    "descriptor": "\nComments: Paper contains 5 authors, 17 references, 8 figures, 5 keywords; it is a research-based paper relating to optimisation of task offloading cost in fog-assisted networks\n",
    "authors": [
      "Snigdha Kashyap",
      "Saahil Kumar Singh",
      "Abhishek Rouniyar",
      "Rajsi Saxena",
      "Avinash Kumar"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2202.05128"
  },
  {
    "id": "arXiv:2202.05145",
    "title": "Deep learning for drug repurposing: methods, databases, and applications",
    "abstract": "Drug development is time-consuming and expensive. Repurposing existing drugs\nfor new therapies is an attractive solution that accelerates drug development\nat reduced experimental costs, specifically for Coronavirus Disease 2019\n(COVID-19), an infectious disease caused by severe acute respiratory syndrome\ncoronavirus 2 (SARS-CoV-2). However, comprehensively obtaining and productively\nintegrating available knowledge and big biomedical data to effectively advance\ndeep learning models is still challenging for drug repurposing in other complex\ndiseases. In this review, we introduce guidelines on how to utilize deep\nlearning methodologies and tools for drug repurposing. We first summarized the\ncommonly used bioinformatics and pharmacogenomics databases for drug\nrepurposing. Next, we discuss recently developed sequence-based and graph-based\nrepresentation approaches as well as state-of-the-art deep learning-based\nmethods. Finally, we present applications of drug repurposing to fight the\nCOVID-19 pandemic, and outline its future challenges.",
    "descriptor": "\nComments: Accepted by WIREs Computational Molecular Science\n",
    "authors": [
      "Xiaoqin Pan",
      "Xuan Lin",
      "Dongsheng Cao",
      "Xiangxiang Zeng",
      "Philip S. Yu",
      "Lifang He",
      "Ruth Nussinov",
      "Feixiong Cheng"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.05145"
  },
  {
    "id": "arXiv:2202.05146",
    "title": "EquiBind: Geometric Deep Learning for Drug Binding Structure Prediction",
    "abstract": "Predicting how a drug-like molecule binds to a specific protein target is a\ncore problem in drug discovery. An extremely fast computational binding method\nwould enable key applications such as fast virtual screening or drug\nengineering. Existing methods are computationally expensive as they rely on\nheavy candidate sampling coupled with scoring, ranking, and fine-tuning steps.\nWe challenge this paradigm with EquiBind, an SE(3)-equivariant geometric deep\nlearning model performing direct-shot prediction of both i) the receptor\nbinding location (blind docking) and ii) the ligand's bound pose and\norientation. EquiBind achieves significant speed-ups and better quality\ncompared to traditional and recent baselines. Further, we show extra\nimprovements when coupling it with existing fine-tuning techniques at the cost\nof increased running time. Finally, we propose a novel and fast fine-tuning\nmodel that adjusts torsion angles of a ligand's rotatable bonds based on\nclosed-form global minima of the von Mises angular distance to a given input\natomic point cloud, avoiding previous expensive differential evolution\nstrategies for energy minimization.",
    "descriptor": "\nComments: Under review. 18 pages, 15 figures\n",
    "authors": [
      "Hannes St\u00e4rk",
      "Octavian-Eugen Ganea",
      "Lagnajit Pattanaik",
      "Regina Barzilay",
      "Tommi Jaakkola"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.05146"
  },
  {
    "id": "arXiv:2202.05154",
    "title": "Effective classification of ecg signals using enhanced convolutional  neural network in iot",
    "abstract": "In this paper, a novel ECG monitoring approach based on IoT technology is\nsuggested. This paper proposes a routing system for IoT healthcare platforms\nbased on Dynamic Source Routing (DSR) and Routing by Energy and Link Quality\n(REL). In addition, the Artificial Neural Network (ANN), Support Vector Machine\n(SVM), and Convolution Neural Networks (CNNs)-based approaches for ECG signal\ncategorization were tested in this study. Deep-ECG will employ a deep CNN to\nextract important characteristics, which will then be compared using simple and\nfast distance functions in order to classify cardiac problems efficiently. This\nwork has suggested algorithms for the categorization of ECG data acquired from\nmobile watch users in order to identify aberrant data. The Massachusetts\nInstitute of Technology (MIT) and Beth Israel Hospital (MIT/BIH) Arrhythmia\nDatabase have been used for experimental verification of the suggested\napproaches. The results show that the proposed strategy outperforms others in\nterms of classification accuracy.",
    "descriptor": "",
    "authors": [
      "Ahmad M. Karim"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.05154"
  },
  {
    "id": "arXiv:2202.05158",
    "title": "SUMO: Advanced sleep spindle identification with neural networks",
    "abstract": "Sleep spindles are neurophysiological phenomena that appear to be linked to\nmemory formation and other functions of the central nervous system, and that\ncan be observed in electroencephalographic recordings (EEG) during sleep.\nManually identified spindle annotations in EEG recordings suffer from\nsubstantial intra- and inter-rater variability, even if raters have been highly\ntrained, which reduces the reliability of spindle measures as a research and\ndiagnostic tool. The Massive Online Data Annotation (MODA) project has recently\naddressed this problem by forming a consensus from multiple such rating\nexperts, thus providing a corpus of spindle annotations of enhanced quality.\nBased on this dataset, we present a U-Net-type deep neural network model to\nautomatically detect sleep spindles. Our model's performance exceeds that of\nthe state-of-the-art detector and of most experts in the MODA dataset. We\nobserved improved detection accuracy in subjects of all ages, including older\nindividuals whose spindles are particularly challenging to detect reliably. Our\nresults underline the potential of automated methods to do repetitive\ncumbersome tasks with super-human performance.",
    "descriptor": "\nComments: 11 pages, 4 figures\n",
    "authors": [
      "Lars Kaulen",
      "Justus T. C. Schwabedal",
      "Jules Schneider",
      "Philipp Ritter",
      "Stephan Bialonski"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2202.05158"
  },
  {
    "id": "arXiv:2202.05166",
    "title": "Design of Flexible Meander Line Antenna for Healthcare for Wireless  Medical Body Area Networks",
    "abstract": "A flexible meander line monopole antenna (MMA) is presented in this paper.\nThe antenna can be worn for on-and off-body applications. The overall dimension\nof the MMA is 37 mm x 50 mm x2.37 mm3. The MMA was manufactured and measured,\nand the results matched with simulation results. The MMA design shows a\nbandwidth of up to 1282.4 (450.5) MHz and provides gains of 3.03 (4.85) dBi in\nthe lower and upper operating bands, respectively, showing omnidirectional\nradiation patterns in free space. While worn on the chest or arm, bandwidths as\nhigh as 688.9 (500.9) MHz and 1261.7 (524.2) MHz, and the gains of 3.80 (4.67)\ndBi and 3.00 (4.55) dBi were observed. The experimental measurements of the\nread range confirmed the results of the coverage range of up to 11 meters.",
    "descriptor": "\nComments: 4 pages, 10 figures\n",
    "authors": [
      "Shahid M Ali",
      "Cheab Sovuthy",
      "Sima Noghanian",
      "Qammer H. Abbasi",
      "Tatjana Asenova",
      "Peter Derleth",
      "Alex Casson",
      "Tughrul Arslan",
      "Amir Hussain"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)",
      "Medical Physics (physics.med-ph)"
    ],
    "url": "https://arxiv.org/abs/2202.05166"
  },
  {
    "id": "arXiv:2202.05167",
    "title": "Class Distance Weighted Cross-Entropy Loss for Ulcerative Colitis  Severity Estimation",
    "abstract": "Endoscopic Mayo score and Ulcerative Colitis Endoscopic Index of Severity are\ncommonly used scoring systems for the assessment of endoscopic severity of\nulcerative colitis. They are based on assigning a score in relation to the\ndisease activity, which creates a rank among the levels, making it an ordinal\nregression problem. On the other hand, most studies use categorical\ncross-entropy loss function, which is not optimal for the ordinal regression\nproblem, to train the deep learning models. In this study, we propose a novel\nloss function called class distance weighted cross-entropy (CDW-CE) that\nrespects the order of the classes and takes the distance of the classes into\naccount in calculation of cost. Experimental evaluations show that CDW-CE\noutperforms the conventional categorical cross-entropy and CORN framework,\nwhich is designed for the ordinal regression problems. In addition, CDW-CE does\nnot require any modifications at the output layer and is compatible with the\nclass activation map visualization techniques.",
    "descriptor": "\nComments: 11 pages, 2 figures\n",
    "authors": [
      "Gorkem Polat",
      "Ilkay Ergenc",
      "Haluk Tarik Kani",
      "Yesim Ozen Alahdab",
      "Ozlen Atug",
      "Alptekin Temizel"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.05167"
  },
  {
    "id": "arXiv:2202.05169",
    "title": "Radar-based Materials Classification Using Deep Wavelet Scattering  Transform: A Comparison of Centimeter vs. Millimeter Wave Units",
    "abstract": "Radar-based materials detection received significant attention in recent\nyears for its potential inclusion in consumer and industrial applications like\nobject recognition for grasping and manufacturing quality assurance and\ncontrol. Several radar publications were developed for material classification\nunder controlled settings with specific materials' properties and shapes.\nRecent literature has challenged the earlier findings on radars-based materials\nclassification claiming that earlier solutions are not easily scaled to\nindustrial applications due to a variety of real-world issues. Published\nexperiments on the impact of these factors on the robustness of the extracted\nradar-based traditional features have already demonstrated that the application\nof deep neural networks can mitigate, to some extent, the impact to produce a\nviable solution. However, previous studies lacked an investigation of the\nusefulness of lower frequency radar units, specifically <10GHz, against the\nhigher range units around and above 60GHz. This research considers two radar\nunits with different frequency ranges: Walabot-3D (6.3-8 GHz) cm-wave and\nIMAGEVK-74 (62-69 GHz) mm-wave imaging units by Vayyar Imaging. A comparison is\npresented on the applicability of each unit for material classification. This\nwork extends upon previous efforts, by applying deep wavelet scattering\ntransform for the identification of different materials based on the reflected\nsignals. In the wavelet scattering feature extractor, data is propagated\nthrough a series of wavelet transforms, nonlinearities, and averaging to\nproduce low-variance representations of the reflected radar signals. This work\nis unique in comparison of the radar units and algorithms in material\nclassification and includes real-time demonstrations that show strong\nperformance by both units, with increased robustness offered by the cm-wave\nradar unit.",
    "descriptor": "\nComments: 6 pages, 8 figures, accepted IEEE in Robotics and Automation Letters c. January 2022 associated video: this https URL\n",
    "authors": [
      "Rami N. Khushaba",
      "Andrew J. Hill"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.05169"
  },
  {
    "id": "arXiv:2202.05170",
    "title": "Efficacy of Transformer Networks for Classification of Raw EEG Data",
    "abstract": "With the unprecedented success of transformer networks in natural language\nprocessing (NLP), recently, they have been successfully adapted to areas like\ncomputer vision, generative adversarial networks (GAN), and reinforcement\nlearning. Classifying electroencephalogram (EEG) data has been challenging and\nresearchers have been overly dependent on pre-processing and hand-crafted\nfeature extraction. Despite having achieved automated feature extraction in\nseveral other domains, deep learning has not yet been accomplished for EEG. In\nthis paper, the efficacy of the transformer network for the classification of\nraw EEG data (cleaned and pre-processed) is explored. The performance of\ntransformer networks was evaluated on a local (age and gender data) and a\npublic dataset (STEW). First, a classifier using a transformer network is built\nto classify the age and gender of a person with raw resting-state EEG data.\nSecond, the classifier is tuned for mental workload classification with open\naccess raw multi-tasking mental workload EEG data (STEW). The network achieves\nan accuracy comparable to state-of-the-art accuracy on both the local (Age and\nGender dataset; 94.53% (gender) and 87.79% (age)) and the public (STEW dataset;\n95.28% (two workload levels) and 88.72% (three workload levels)) dataset. The\naccuracy values have been achieved using raw EEG data without feature\nextraction. Results indicate that the transformer-based deep learning models\ncan successfully abate the need for heavy feature-extraction of EEG data for\nsuccessful classification.",
    "descriptor": "",
    "authors": [
      "Gourav Siddhad",
      "Anmol Gupta",
      "Debi Prosad Dogra",
      "Partha Pratim Roy"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.05170"
  },
  {
    "id": "arXiv:2202.05177",
    "title": "Automated Atrial Fibrillation Classification Based on Denoising Stacked  Autoencoder and Optimized Deep Network",
    "abstract": "The incidences of atrial fibrillation (AFib) are increasing at a daunting\nrate worldwide. For the early detection of the risk of AFib, we have developed\nan automatic detection system based on deep neural networks. For achieving\nbetter classification, it is mandatory to have good pre-processing of\nphysiological signals. Keeping this in mind, we have proposed a two-fold study.\nFirst, an end-to-end model is proposed to denoise the electrocardiogram signals\nusing denoising autoencoders (DAE). To achieve denoising, we have used three\nnetworks including, convolutional neural network (CNN), dense neural network\n(DNN), and recurrent neural networks (RNN). Compared the three models and CNN\nbased DAE performance is found to be better than the other two. Therefore, the\nsignals denoised by the CNN based DAE were used to train the deep neural\nnetworks for classification. Three neural networks' performance has been\nevaluated using accuracy, specificity, sensitivity, and signal to noise ratio\n(SNR) as the evaluation criteria.\nThe proposed end-to-end deep learning model for detecting atrial fibrillation\nin this study has achieved an accuracy rate of 99.20%, a specificity of 99.50%,\na sensitivity of 99.50%, and a true positive rate of 99.00%. The average\naccuracy of the algorithms we compared is 96.26%, and our algorithm's accuracy\nis 3.2% higher than this average of the other algorithms. The CNN\nclassification network performed better as compared to the other two.\nAdditionally, the model is computationally efficient for real-time\napplications, and it takes approx 1.3 seconds to process 24 hours ECG signal.\nThe proposed model was also tested on unseen dataset with different proportions\nof arrhythmias to examine the model's robustness, which resulted in 99.10% of\nrecall and 98.50% of precision.",
    "descriptor": "",
    "authors": [
      "Prateek Singh",
      "Ambalika Sharma",
      "Shreesha Maiya"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2202.05177"
  },
  {
    "id": "arXiv:2202.05193",
    "title": "Bayes Optimal Algorithm is Suboptimal in Frequentist Best Arm  Identification",
    "abstract": "We consider the fixed-budget best arm identification problem with Normal\nrewards. In this problem, the forecaster is given $K$ arms (treatments) and $T$\ntime steps. The forecaster attempts to find the best arm in terms of the\nlargest mean via an adaptive experiment conducted with an algorithm. The\nperformance of the algorithm is measured by the simple regret, or the quality\nof the estimated best arm. It is known that the frequentist simple regret can\nbe exponentially small to $T$ for any fixed parameters, whereas the Bayesian\nsimple regret is $\\Theta(T^{-1})$ over a continuous prior distribution. This\npaper shows that Bayes optimal algorithm, which minimizes the Bayesian simple\nregret, does not have an exponential simple regret for some parameters. This\nfinding contrasts with the many results indicating the asymptotic equivalence\nof Bayesian and frequentist algorithms in fixed sampling regimes. While the\nBayes optimal algorithm is described in terms of a recursive equation that is\nvirtually impossible to compute exactly, we pave the way to an analysis by\nintroducing a key quantity that we call the expected Bellman improvement.",
    "descriptor": "",
    "authors": [
      "Junpei Komiyama"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2202.05193"
  },
  {
    "id": "arXiv:2202.05195",
    "title": "Uncovering Instabilities in Variational-Quantum Deep Q-Networks",
    "abstract": "Deep Reinforcement Learning (RL) has considerably advanced over the past\ndecade. At the same time, state-of-the-art RL algorithms require a large\ncomputational budget in terms of training time to converge. Recent work has\nstarted to approach this problem through the lens of quantum computing, which\npromises theoretical speed-ups for several traditionally hard tasks. In this\nwork, we examine a class of hybrid quantumclassical RL algorithms that we\ncollectively refer to as variational quantum deep Q-networks (VQ-DQN). We show\nthat VQ-DQN approaches are subject to instabilities that cause the learned\npolicy to diverge, study the extent to which this afflicts reproduciblity of\nestablished results based on classical simulation, and perform systematic\nexperiments to identify potential explanations for the observed instabilities.\nAdditionally, and in contrast to most existing work on quantum reinforcement\nlearning, we execute RL algorithms on an actual quantum processing unit (an IBM\nQuantum Device) and investigate differences in behaviour between simulated and\nphysical quantum systems that suffer from implementation deficiencies. Our\nexperiments show that, contrary to opposite claims in the literature, it cannot\nbe conclusively decided if known quantum approaches, even if simulated without\nphysical imperfections, can provide an advantage as compared to classical\napproaches. Finally, we provide a robust, universal and well-tested\nimplementation of VQ-DQN as a reproducible testbed for future experiments.",
    "descriptor": "\nComments: Authors Maja Franz, Lucas Wolf, Maniraman Periyasamy contributed equally (name order randomised)\n",
    "authors": [
      "Maja Franz",
      "Lucas Wolf",
      "Maniraman Periyasamy",
      "Christian Ufrecht",
      "Daniel D. Scherer",
      "Axel Plinge",
      "Christopher Mutschler",
      "Wolfgang Mauerer"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.05195"
  },
  {
    "id": "arXiv:2202.05198",
    "title": "P-split formulations: A class of intermediate formulations between big-M  and convex hull for disjunctive constraints",
    "abstract": "We develop a class of mixed-integer formulations for disjunctive constraints\nintermediate to the big-M and convex hull formulations in terms of relaxation\nstrength. The main idea is to capture the best of both the big-M and convex\nhull formulations: a computationally light formulation with a tight relaxation.\nThe \"$P$-split\" formulations are based on a lifted transformation that splits\nconvex additively separable constraints into $P$ partitions and forms the\nconvex hull of the linearized and partitioned disjunction. We analyze the\ncontinuous relaxation of the $P$-split formulations and show that, under\ncertain assumptions, the formulations form a hierarchy starting from a big-M\nequivalent and converging to the convex hull. The goal of the $P$-split\nformulations is to form a strong approximation of the convex hull through a\ncomputationally simpler formulation. We computationally compare the $P$-split\nformulations against big-M and convex hull formulations on 320 test instances.\nThe test problems include K-means clustering, P_ball problems, and optimization\nover trained ReLU neural networks. The computational results show promising\npotential of the $P$-split formulations. For many of the test problems,\n$P$-split formulations are solved with a similar number of explored nodes as\nthe convex hull formulation, while reducing the solution time by an order of\nmagnitude and outperforming big-M both in time and number of explored nodes.",
    "descriptor": "\nComments: 24 pages, 5 figures\n",
    "authors": [
      "Jan Kronqvist",
      "Ruth Misener",
      "Calvin Tsay"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.05198"
  },
  {
    "id": "arXiv:2202.05232",
    "title": "Matching with Transfers under Distributional Constraints",
    "abstract": "We study two-sided many-to-one matching markets with transferable utilities,\ne.g., labor and rental housing markets, in which money can exchange hands\nbetween agents, subject to distributional constraints on the set of feasible\nallocations. In such markets, we establish the efficiency of equilibrium\narrangements, specified by an assignment and transfers between agents on the\ntwo sides of the market, and study the conditions on the distributional\nconstraints and agent preferences under which equilibria exist. To this end, we\nfirst consider the setting when the number of institutions (e.g., firms in a\nlabor market) is one and show that equilibrium arrangements exist irrespective\nof the nature of the constraint structure or the agents' preferences. However,\nequilibrium arrangements may not exist in markets with multiple institutions\neven when agents on each side have linear (or additively separable) preferences\nover agents on the other side. Thus, for markets with linear preferences, we\nstudy sufficient conditions on the constraint structure that guarantee the\nexistence of equilibria using linear programming duality. Our linear\nprogramming approach not only generalizes that of Shapley and Shubik (1971) in\nthe one-to-one matching setting to the many-to-one matching setting under\ndistributional constraints but also provides a method to compute market\nequilibria efficiently.",
    "descriptor": "",
    "authors": [
      "Devansh Jalota"
    ],
    "subjectives": [
      "Theoretical Economics (econ.TH)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2202.05232"
  },
  {
    "id": "arXiv:2202.05245",
    "title": "Benign-Overfitting in Conditional Average Treatment Effect Prediction  with Linear Regression",
    "abstract": "We study the benign overfitting theory in the prediction of the conditional\naverage treatment effect (CATE), with linear regression models. As the\ndevelopment of machine learning for causal inference, a wide range of\nlarge-scale models for causality are gaining attention. One problem is that\nsuspicions have been raised that the large-scale models are prone to\noverfitting to observations with sample selection, hence the large models may\nnot be suitable for causal prediction. In this study, to resolve the\nsuspicious, we investigate on the validity of causal inference methods for\noverparameterized models, by applying the recent theory of benign overfitting\n(Bartlett et al., 2020). Specifically, we consider samples whose distribution\nswitches depending on an assignment rule, and study the prediction of CATE with\nlinear models whose dimension diverges to infinity. We focus on two methods:\nthe T-learner, which based on a difference between separately constructed\nestimators with each treatment group, and the inverse probability weight\n(IPW)-learner, which solves another regression problem approximated by a\npropensity score. In both methods, the estimator consists of interpolators that\nfit the samples perfectly. As a result, we show that the T-learner fails to\nachieve the consistency except the random assignment, while the IPW-learner\nconverges the risk to zero if the propensity score is known. This difference\nstems from that the T-learner is unable to preserve eigenspaces of the\ncovariances, which is necessary for benign overfitting in the overparameterized\nsetting. Our result provides new insights into the usage of causal inference\nmethods in the overparameterizated setting, in particular, doubly robust\nestimators.",
    "descriptor": "",
    "authors": [
      "Masahiro Kato",
      "Masaaki Imaizumi"
    ],
    "subjectives": [
      "Econometrics (econ.EM)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.05245"
  },
  {
    "id": "arXiv:2202.05250",
    "title": "Adaptive and Robust Multi-task Learning",
    "abstract": "We study the multi-task learning problem that aims to simultaneously analyze\nmultiple datasets collected from different sources and learn one model for each\nof them. We propose a family of adaptive methods that automatically utilize\npossible similarities among those tasks while carefully handling their\ndifferences. We derive sharp statistical guarantees for the methods and prove\ntheir robustness against outlier tasks. Numerical experiments on synthetic and\nreal datasets demonstrate the efficacy of our new methods.",
    "descriptor": "\nComments: 60 pages, 2 figures\n",
    "authors": [
      "Yaqi Duan",
      "Kaizheng Wang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2202.05250"
  },
  {
    "id": "arXiv:2202.05253",
    "title": "A New Fusion Strategy for Spoofing Aware Speaker Verification",
    "abstract": "The performance of automatic speaker verification (ASV) systems could be\ndegraded by voice spoofing attacks. Most existing works aimed to develop\nstandalone spoofing countermeasure (CM) systems. Relatively little work aimed\nto develop an integrated spoofing aware speaker verification (SASV) system.\nWith the recent SASV challenge aiming to encourage the development of such\nintegration, official protocols and baselines have been released by the\norganizers. Building on these baselines, we propose a score scaling and\nmultiplication strategy for inference and an SASV training strategy.\nSurprisingly, these strategies significantly improve the SASV equal error rate\n(EER) from 19.31\\% of the best baseline to 1.58\\% on the official evaluation\ntrials of the SASV challenge. We verify the effectiveness of our proposed\ncomponents through ablation studies and provide insights with score\ndistribution analyses.",
    "descriptor": "\nComments: Work in Progress\n",
    "authors": [
      "You Zhang",
      "Ge Zhu",
      "Zhiyao Duan"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2202.05253"
  },
  {
    "id": "arXiv:2202.05255",
    "title": "Topogivity: A Machine-Learned Chemical Rule for Discovering Topological  Materials",
    "abstract": "Topological materials present unconventional electronic properties that make\nthem attractive for both basic science and next-generation technological\napplications. The majority of currently-known topological materials have been\ndiscovered using methods that involve symmetry-based analysis of the quantum\nwavefunction. Here we use machine learning to develop a simple-to-use heuristic\nchemical rule that diagnoses with a high accuracy whether a material is\ntopological using only its chemical formula. This heuristic rule is based on a\nnotion that we term topogivity, a machine-learned numerical value for each\nelement that loosely captures its tendency to form topological materials. We\nnext implement a high-throughput strategy for discovering topological materials\nbased on the heuristic topogivity-rule prediction followed by ab initio\nvalidation. This way, we discover new topological materials that are not\ndiagnosable using symmetry indicators, including several that may be promising\nfor experimental observation.",
    "descriptor": "\nComments: 6 pages, 3 figures\n",
    "authors": [
      "Andrew Ma",
      "Yang Zhang",
      "Thomas Christensen",
      "Hoi Chun Po",
      "Li Jing",
      "Liang Fu",
      "Marin Solja\u010di\u0107"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Mesoscale and Nanoscale Physics (cond-mat.mes-hall)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.05255"
  },
  {
    "id": "arXiv:2202.05256",
    "title": "Conditional Diffusion Probabilistic Model for Speech Enhancement",
    "abstract": "Speech enhancement is a critical component of many user-oriented audio\napplications, yet current systems still suffer from distorted and unnatural\noutputs. While generative models have shown strong potential in speech\nsynthesis, they are still lagging behind in speech enhancement. This work\nleverages recent advances in diffusion probabilistic models, and proposes a\nnovel speech enhancement algorithm that incorporates characteristics of the\nobserved noisy speech signal into the diffusion and reverse processes. More\nspecifically, we propose a generalized formulation of the diffusion\nprobabilistic model named conditional diffusion probabilistic model that, in\nits reverse process, can adapt to non-Gaussian real noises in the estimated\nspeech signal. In our experiments, we demonstrate strong performance of the\nproposed approach compared to representative generative models, and investigate\nthe generalization capability of our models to other datasets with noise\ncharacteristics unseen during training.",
    "descriptor": "",
    "authors": [
      "Yen-Ju Lu",
      "Zhong-Qiu Wang",
      "Shinji Watanabe",
      "Alexander Richard",
      "Cheng Yu",
      "Yu Tsao"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2202.05256"
  },
  {
    "id": "arXiv:2001.04216",
    "title": "Cycles in synchronous iterative voting: general robustness and examples  in Approval Voting",
    "abstract": "Comments: v2: added a numerical study of rarity of bad cycles and equilibriums, and a case of chaotic Continuous Polling Dynamics. Many other improvements throughout the text. v3: reorganization and change of order. The robustness result is generalized to all voting systems. v4 Added a simple example to the stability Theorem, various other small modifications",
    "descriptor": "\nComments: v2: added a numerical study of rarity of bad cycles and equilibriums, and a case of chaotic Continuous Polling Dynamics. Many other improvements throughout the text. v3: reorganization and change of order. The robustness result is generalized to all voting systems. v4 Added a simple example to the stability Theorem, various other small modifications\n",
    "authors": [
      "Beno\u00eet Kloeckner"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2001.04216"
  },
  {
    "id": "arXiv:2006.05531",
    "title": "GEOM: Energy-annotated molecular conformations for property prediction  and molecular generation",
    "abstract": "GEOM: Energy-annotated molecular conformations for property prediction  and molecular generation",
    "descriptor": "",
    "authors": [
      "Simon Axelrod",
      "Rafael Gomez-Bombarelli"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2006.05531"
  },
  {
    "id": "arXiv:2006.10728",
    "title": "Diverse Image Generation via Self-Conditioned GANs",
    "abstract": "Comments: CVPR 2020. Code: this https URL Webpage: this http URL",
    "descriptor": "\nComments: CVPR 2020. Code: this https URL Webpage: this http URL\n",
    "authors": [
      "Steven Liu",
      "Tongzhou Wang",
      "David Bau",
      "Jun-Yan Zhu",
      "Antonio Torralba"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2006.10728"
  },
  {
    "id": "arXiv:2009.10868",
    "title": "A Real-Time Predictive Pedestrian Collision Warning Service for  Cooperative Intelligent Transportation Systems Using 3D Pose Estimation",
    "abstract": "Comments: 12 pages, 8 figures, 4 tables",
    "descriptor": "\nComments: 12 pages, 8 figures, 4 tables\n",
    "authors": [
      "Ue-Hwan Kim",
      "Dongho Ka",
      "Hwasoo Yeo",
      "Jong-Hwan Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2009.10868"
  },
  {
    "id": "arXiv:2011.11198",
    "title": "Complex-valued Iris Recognition Network",
    "abstract": "Complex-valued Iris Recognition Network",
    "descriptor": "",
    "authors": [
      "Kien Nguyen",
      "Clinton Fookes",
      "Sridha Sridharan",
      "Arun Ross"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2011.11198"
  },
  {
    "id": "arXiv:2011.14860",
    "title": "Infinite Probabilistic Databases",
    "abstract": "Comments: This is the full version of the paper \"Infinite Probabilistic Databases\" presented at ICDT 2020 (arXiv:1904.06766)",
    "descriptor": "\nComments: This is the full version of the paper \"Infinite Probabilistic Databases\" presented at ICDT 2020 (arXiv:1904.06766)\n",
    "authors": [
      "Martin Grohe",
      "Peter Lindner"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2011.14860"
  },
  {
    "id": "arXiv:2012.02097",
    "title": "Recursive Tree Grammar Autoencoders",
    "abstract": "Comments: Submitted to the ECML/PKDD Journal Track",
    "descriptor": "\nComments: Submitted to the ECML/PKDD Journal Track\n",
    "authors": [
      "Benjamin Paassen",
      "Irena Koprinska",
      "Kalina Yacef"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2012.02097"
  },
  {
    "id": "arXiv:2012.06568",
    "title": "Analyzing and Improving Adversarial Training for Generative Modeling",
    "abstract": "Analyzing and Improving Adversarial Training for Generative Modeling",
    "descriptor": "",
    "authors": [
      "Xuwang Yin",
      "Shiying Li",
      "Gustavo K. Rohde"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2012.06568"
  },
  {
    "id": "arXiv:2012.11913",
    "title": "On rich points and incidences with restricted sets of lines in 3-space",
    "abstract": "Comments: 21 pages, one figure",
    "descriptor": "\nComments: 21 pages, one figure\n",
    "authors": [
      "Micha Sharir",
      "Noam Solomon"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2012.11913"
  },
  {
    "id": "arXiv:2012.12607",
    "title": "PTAS for Sparse General-Valued CSPs",
    "abstract": "PTAS for Sparse General-Valued CSPs",
    "descriptor": "",
    "authors": [
      "Bal\u00e1zs F. Mezei",
      "Marcin Wrochna",
      "Stanislav \u017divn\u00fd"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2012.12607"
  },
  {
    "id": "arXiv:2101.10892",
    "title": "Online Body Schema Adaptation through Cost-Sensitive Active Learning",
    "abstract": "Comments: 6 pages, 7 figures",
    "descriptor": "\nComments: 6 pages, 7 figures\n",
    "authors": [
      "Gon\u00e7alo Cunha",
      "Pedro Vicente",
      "Alexandre Bernardino",
      "Ricardo Ribeiro",
      "Pl\u00ednio Moreno"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2101.10892"
  },
  {
    "id": "arXiv:2102.08329",
    "title": "An Information-Theoretic Justification for Model Pruning",
    "abstract": "Comments: Published in the International Conference on Artificial Intelligence and Statistics (AISTATS) 2022. Previous titles: 1) Rate-Distortion Theoretic Model Compression: Successive Refinement for Pruning, 2) Successive pruning for model compression via rate distortion theory",
    "descriptor": "\nComments: Published in the International Conference on Artificial Intelligence and Statistics (AISTATS) 2022. Previous titles: 1) Rate-Distortion Theoretic Model Compression: Successive Refinement for Pruning, 2) Successive pruning for model compression via rate distortion theory\n",
    "authors": [
      "Berivan Isik",
      "Tsachy Weissman",
      "Albert No"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2102.08329"
  },
  {
    "id": "arXiv:2102.08779",
    "title": "User Tracking in the Post-cookie Era: How Websites Bypass GDPR Consent  to Track Users",
    "abstract": "Comments: 12 pages, Published at The Web Conference 2021 (WWW 2021). Please cite the WWW version; Made source code publicly available",
    "descriptor": "\nComments: 12 pages, Published at The Web Conference 2021 (WWW 2021). Please cite the WWW version; Made source code publicly available\n",
    "authors": [
      "Emmanouil Papadogiannakis",
      "Panagiotis Papadopoulos",
      "Nicolas Kourtellis",
      "Evangelos P. Markatos"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2102.08779"
  },
  {
    "id": "arXiv:2102.10616",
    "title": "Dealing with Non-Stationarity in MARL via Trust-Region Decomposition",
    "abstract": "Comments: 39 pages, 23 figures, ICLR 2022 Camera Ready",
    "descriptor": "\nComments: 39 pages, 23 figures, ICLR 2022 Camera Ready\n",
    "authors": [
      "Wenhao Li",
      "Xiangfeng Wang",
      "Bo Jin",
      "Junjie Sheng",
      "Hongyuan Zha"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Science and Game Theory (cs.GT)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2102.10616"
  },
  {
    "id": "arXiv:2103.01028",
    "title": "Information Discrepancy in Strategic Learning",
    "abstract": "Information Discrepancy in Strategic Learning",
    "descriptor": "",
    "authors": [
      "Yahav Bechavod",
      "Chara Podimata",
      "Zhiwei Steven Wu",
      "Juba Ziani"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.01028"
  },
  {
    "id": "arXiv:2103.04909",
    "title": "Latent Imagination Facilitates Zero-Shot Transfer in Autonomous Racing",
    "abstract": "Latent Imagination Facilitates Zero-Shot Transfer in Autonomous Racing",
    "descriptor": "",
    "authors": [
      "Axel Brunnbauer",
      "Luigi Berducci",
      "Andreas Brandst\u00e4tter",
      "Mathias Lechner",
      "Ramin Hasani",
      "Daniela Rus",
      "Radu Grosu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2103.04909"
  },
  {
    "id": "arXiv:2103.05621",
    "title": "The Common Intuition to Transfer Learning Can Win or Lose: Case Studies  for Linear Regression",
    "abstract": "The Common Intuition to Transfer Learning Can Win or Lose: Case Studies  for Linear Regression",
    "descriptor": "",
    "authors": [
      "Yehuda Dar",
      "Daniel LeJeune",
      "Richard G. Baraniuk"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.05621"
  },
  {
    "id": "arXiv:2103.10453",
    "title": "A massively parallel evolutionary algorithm for the partial Latin square  extension problem",
    "abstract": "A massively parallel evolutionary algorithm for the partial Latin square  extension problem",
    "descriptor": "",
    "authors": [
      "Olivier Goudet",
      "Jin-Kao Hao"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2103.10453"
  },
  {
    "id": "arXiv:2103.13650",
    "title": "A General Approach to Robust Controller Analysis and Synthesis",
    "abstract": "A General Approach to Robust Controller Analysis and Synthesis",
    "descriptor": "",
    "authors": [
      "Shih-Hao Tseng"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2103.13650"
  },
  {
    "id": "arXiv:2103.14077",
    "title": "Nearly Horizon-Free Offline Reinforcement Learning",
    "abstract": "Comments: NeurIPS 2021",
    "descriptor": "\nComments: NeurIPS 2021\n",
    "authors": [
      "Tongzheng Ren",
      "Jialian Li",
      "Bo Dai",
      "Simon S. Du",
      "Sujay Sanghavi"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.14077"
  },
  {
    "id": "arXiv:2103.16833",
    "title": "A categorical framework for congruence of applicative bisimilarity in  higher-order languages",
    "abstract": "A categorical framework for congruence of applicative bisimilarity in  higher-order languages",
    "descriptor": "",
    "authors": [
      "Tom Hirschowitz",
      "Ambroise Lafont"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2103.16833"
  },
  {
    "id": "arXiv:2104.05634",
    "title": "The Undecidability of Conditional Affine Information Inequalities and  Conditional Independence Implication with a Binary Constraint",
    "abstract": "Comments: 19 pages, 7 figures, presented in part at the 2021 IEEE Information Theory Workshop",
    "descriptor": "\nComments: 19 pages, 7 figures, presented in part at the 2021 IEEE Information Theory Workshop\n",
    "authors": [
      "Cheuk Ting Li"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2104.05634"
  },
  {
    "id": "arXiv:2104.12425",
    "title": "Separating Data via Block Invalidation Time Inference for Write  Amplification Reduction in Log-Structured Storage",
    "abstract": "Comments: 19 pages. Accepted by the 20th USENIX Conference on File and Storage Technologies (FAST '22)",
    "descriptor": "\nComments: 19 pages. Accepted by the 20th USENIX Conference on File and Storage Technologies (FAST '22)\n",
    "authors": [
      "Qiuping Wang",
      "Jinhong Li",
      "Patrick P. C. Lee",
      "Tao Ouyang",
      "Chao Shi",
      "Lilong Huang"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2104.12425"
  },
  {
    "id": "arXiv:2105.10731",
    "title": "A systematic review of physical-digital play technology and  developmentally relevant child behaviour",
    "abstract": "Comments: 11 Tables, 1 Figure, 4 Appendices; Keywords: Systematic review, digital play, child development, child behaviour, child-computer interactions *Corresponding author info: Faculty of Education, University of Cambridge. Email: pelt2@cam.ac.uk; torresp.uk@gmail.com",
    "descriptor": "\nComments: 11 Tables, 1 Figure, 4 Appendices; Keywords: Systematic review, digital play, child development, child behaviour, child-computer interactions *Corresponding author info: Faculty of Education, University of Cambridge. Email: pelt2@cam.ac.uk; torresp.uk@gmail.com\n",
    "authors": [
      "Pablo E. Torres",
      "Philip I. N. Ulrich",
      "Veronica Cucuiat",
      "Mutlu Cukurova",
      "Maria Fercovic De la Presa",
      "Rose Luckin",
      "Amanda Carr",
      "Thomas Dylan",
      "Abigail Durrant",
      "John Vines",
      "Shaun Lawson"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2105.10731"
  },
  {
    "id": "arXiv:2105.13637",
    "title": "Lower Bounds for Differentially Private ERM: Unconstrained and  Non-Euclidean",
    "abstract": "Comments: Fixed an error in the proof of pure DP lower bound in the previous version. Added a reduction approach. Submitted to ICML2022",
    "descriptor": "\nComments: Fixed an error in the proof of pure DP lower bound in the previous version. Added a reduction approach. Submitted to ICML2022\n",
    "authors": [
      "Daogao Liu",
      "Zhou Lu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2105.13637"
  },
  {
    "id": "arXiv:2105.14301",
    "title": "A Theory of Neural Tangent Kernel Alignment and Its Influence on  Training",
    "abstract": "A Theory of Neural Tangent Kernel Alignment and Its Influence on  Training",
    "descriptor": "",
    "authors": [
      "Haozhe Shan",
      "Blake Bordelon"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.14301"
  },
  {
    "id": "arXiv:2106.02624",
    "title": "ViViT: Curvature access through the generalized Gauss-Newton's low-rank  structure",
    "abstract": "Comments: Main text: 10 pages, 6 figures; Supplements: 26 pages, 27 figures, 5 tables",
    "descriptor": "\nComments: Main text: 10 pages, 6 figures; Supplements: 26 pages, 27 figures, 5 tables\n",
    "authors": [
      "Felix Dangel",
      "Lukas Tatzel",
      "Philipp Hennig"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.02624"
  },
  {
    "id": "arXiv:2106.03214",
    "title": "Lower Bounds on Stabilizer Rank",
    "abstract": "Lower Bounds on Stabilizer Rank",
    "descriptor": "",
    "authors": [
      "Shir Peleg",
      "Amir Shpilka",
      "Ben Lee Volk"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2106.03214"
  },
  {
    "id": "arXiv:2106.03741",
    "title": "Training Strategies for Deep Learning Gravitational-Wave Searches",
    "abstract": "Comments: 18 pages, 12 figures, 3 tables, supplemental materials at this https URL",
    "descriptor": "\nComments: 18 pages, 12 figures, 3 tables, supplemental materials at this https URL\n",
    "authors": [
      "Marlin B. Sch\u00e4fer",
      "Ond\u0159ej Zelenka",
      "Alexander H. Nitz",
      "Frank Ohme",
      "Bernd Br\u00fcgmann"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Machine Learning (cs.LG)",
      "General Relativity and Quantum Cosmology (gr-qc)"
    ],
    "url": "https://arxiv.org/abs/2106.03741"
  },
  {
    "id": "arXiv:2106.04982",
    "title": "Cooperative Online Learning with Feedback Graphs",
    "abstract": "Cooperative Online Learning with Feedback Graphs",
    "descriptor": "",
    "authors": [
      "Nicol\u00f2 Cesa-Bianchi",
      "Tommaso R. Cesari",
      "Riccardo Della Vecchia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.04982"
  },
  {
    "id": "arXiv:2106.05209",
    "title": "Distilling Image Classifiers in Object Detectors",
    "abstract": "Distilling Image Classifiers in Object Detectors",
    "descriptor": "",
    "authors": [
      "Shuxuan Guo",
      "Jose M. Alvarez",
      "Mathieu Salzmann"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.05209"
  },
  {
    "id": "arXiv:2106.10050",
    "title": "A note on augmented unprojected Krylov subspace methods",
    "abstract": "Comments: 14 pages, 4 figures",
    "descriptor": "\nComments: 14 pages, 4 figures\n",
    "authors": [
      "Kirk M. Soodhalter"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.10050"
  },
  {
    "id": "arXiv:2106.10717",
    "title": "Optimal potentials for hedging algorithms",
    "abstract": "Optimal potentials for hedging algorithms",
    "descriptor": "",
    "authors": [
      "Yoav Freund"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.10717"
  },
  {
    "id": "arXiv:2106.14350",
    "title": "Deep Learning Image Recognition for Non-images",
    "abstract": "Comments: 33 pages, 17 figures, 18 tables",
    "descriptor": "\nComments: 33 pages, 17 figures, 18 tables\n",
    "authors": [
      "Boris Kovalerchuk",
      "Divya Chandrika Kalla",
      "Bedant Agarwal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.14350"
  },
  {
    "id": "arXiv:2107.02692",
    "title": "ML-Quadrat & DriotData: A Model-Driven Engineering Tool and a Low-Code  Platform for Smart IoT Services",
    "abstract": "Comments: ICSE'22 Tool Demo",
    "descriptor": "\nComments: ICSE'22 Tool Demo\n",
    "authors": [
      "Armin Moin",
      "Andrei Mituca",
      "Moharram Challenger",
      "Atta Badii",
      "Stephan G\u00fcnnemann"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.02692"
  },
  {
    "id": "arXiv:2107.02755",
    "title": "FedFog: Network-Aware Optimization of Federated Learning over Wireless  Fog-Cloud Systems",
    "abstract": "Comments: IEEE Transactions on Wireless Communications. Copyright may be transferred without notice, after which this version may no longer be accessible",
    "descriptor": "\nComments: IEEE Transactions on Wireless Communications. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Van-Dinh Nguyen",
      "Symeon Chatzinotas",
      "Bjorn Ottersten",
      "Trung Q. Duong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2107.02755"
  },
  {
    "id": "arXiv:2107.06243",
    "title": "Fairness-aware Summarization for Justified Decision-Making",
    "abstract": "Comments: 22 pages, 9 figures",
    "descriptor": "\nComments: 22 pages, 9 figures\n",
    "authors": [
      "Moniba Keymanesh",
      "Tanya Berger-Wolf",
      "Micha Elsner",
      "Srinivasan Parthasarathy"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2107.06243"
  },
  {
    "id": "arXiv:2107.07438",
    "title": "Convolutional Neural Bandit for Visual-aware Recommendation",
    "abstract": "Comments: In submission",
    "descriptor": "\nComments: In submission\n",
    "authors": [
      "Yikun Ban",
      "Jingrui He"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.07438"
  },
  {
    "id": "arXiv:2107.09008",
    "title": "Harmonizing the Cacophony with MIC: An Affordance-aware Framework for  Platform Moderation",
    "abstract": "Comments: 20 pages, 5 figures",
    "descriptor": "\nComments: 20 pages, 5 figures\n",
    "authors": [
      "Tanvi Bajpai",
      "Drshika Asher",
      "Anwesa Goswami",
      "Eshwar Chandrasekharan"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2107.09008"
  },
  {
    "id": "arXiv:2107.09232",
    "title": "Using reinforcement learning to autonomously identify the source of  errors for agents in a group mission",
    "abstract": "Comments: 7 pages, 2 figure. References added. It has been edited in English",
    "descriptor": "\nComments: 7 pages, 2 figure. References added. It has been edited in English\n",
    "authors": [
      "Keishu Utimula",
      "Ken-taro Hayaschi",
      "Trevor J. Bihl",
      "Kousuke Nakano",
      "Kenta Hongo",
      "Ryo Maezono"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2107.09232"
  },
  {
    "id": "arXiv:2107.11357",
    "title": "Joint Shapley values: a measure of joint feature importance",
    "abstract": "Comments: Source code available at this https URL",
    "descriptor": "\nComments: Source code available at this https URL\n",
    "authors": [
      "Chris Harris",
      "Richard Pymar",
      "Colin Rowat"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.11357"
  },
  {
    "id": "arXiv:2108.00298",
    "title": "Filling the G_ap_s: Multivariate Time Series Imputation by Graph Neural  Networks",
    "abstract": "Comments: Accepted at ICLR 2022",
    "descriptor": "\nComments: Accepted at ICLR 2022\n",
    "authors": [
      "Andrea Cini",
      "Ivan Marisca",
      "Cesare Alippi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2108.00298"
  },
  {
    "id": "arXiv:2108.00807",
    "title": "Smart HealthCare System",
    "abstract": "Smart HealthCare System",
    "descriptor": "",
    "authors": [
      "Debendranath Das",
      "Amudhan Muthaiah",
      "Sushmita Ruj"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2108.00807"
  },
  {
    "id": "arXiv:2108.02423",
    "title": "Automatic Rail Component Detection Based on AttnConv-Net",
    "abstract": "Automatic Rail Component Detection Based on AttnConv-Net",
    "descriptor": "",
    "authors": [
      "Tiange Wang",
      "Zijun Zhang",
      "Fangfang Yang",
      "Kwok-Leung Tsui"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.02423"
  },
  {
    "id": "arXiv:2108.05251",
    "title": "Improving Single-Image Defocus Deblurring: How Dual-Pixel Images Help  Through Multi-Task Learning",
    "abstract": "Comments: Published in the Winter Conference on Applications of Computer Vision 2022 (WACV'22)",
    "descriptor": "\nComments: Published in the Winter Conference on Applications of Computer Vision 2022 (WACV'22)\n",
    "authors": [
      "Abdullah Abuolaim",
      "Mahmoud Afifi",
      "Michael S. Brown"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.05251"
  },
  {
    "id": "arXiv:2108.07636",
    "title": "Accounting for shared covariates in semi-parametric Bayesian additive  regression trees",
    "abstract": "Accounting for shared covariates in semi-parametric Bayesian additive  regression trees",
    "descriptor": "",
    "authors": [
      "Estev\u00e3o B. Prado",
      "Andrew C. Parnell",
      "Keefe Murphy",
      "Nathan McJames",
      "Ann O'Shea",
      "Rafael A. Moral"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.07636"
  },
  {
    "id": "arXiv:2108.10715",
    "title": "From One to Many: A Deep Learning Coincident Gravitational-Wave Search",
    "abstract": "Comments: 11 pages, 4 figures, 2 tables",
    "descriptor": "\nComments: 11 pages, 4 figures, 2 tables\n",
    "authors": [
      "Marlin B. Sch\u00e4fer",
      "Alexander H. Nitz"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Machine Learning (cs.LG)",
      "General Relativity and Quantum Cosmology (gr-qc)"
    ],
    "url": "https://arxiv.org/abs/2108.10715"
  },
  {
    "id": "arXiv:2108.11157",
    "title": "Cob: a Leaderless Protocol for Parallel Byzantine Agreement in  Incomplete Networks",
    "abstract": "Comments: 40 pages, 2 figures, 2 tables",
    "descriptor": "\nComments: 40 pages, 2 figures, 2 tables\n",
    "authors": [
      "Andrea Flamini",
      "Riccardo Longo",
      "Alessio Meneghetti"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2108.11157"
  },
  {
    "id": "arXiv:2108.13714",
    "title": "Competing control scenarios in probabilistic SIR epidemics on  social-contact networks",
    "abstract": "Comments: preprint submitted to journal \\ competing control scenarios \\ compounded payoff matrices",
    "descriptor": "\nComments: preprint submitted to journal \\ competing control scenarios \\ compounded payoff matrices\n",
    "authors": [
      "Jan B. Broekaert",
      "Davide La Torre",
      "Faizal Hafiz"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Populations and Evolution (q-bio.PE)"
    ],
    "url": "https://arxiv.org/abs/2108.13714"
  },
  {
    "id": "arXiv:2108.13753",
    "title": "Disentanglement Analysis with Partial Information Decomposition",
    "abstract": "Comments: ICLR 2022",
    "descriptor": "\nComments: ICLR 2022\n",
    "authors": [
      "Seiya Tokui",
      "Issei Sato"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.13753"
  },
  {
    "id": "arXiv:2109.00574",
    "title": "Active label cleaning for improved dataset quality under resource  constraints",
    "abstract": "Comments: Accepted for publication in Nature Communications",
    "descriptor": "\nComments: Accepted for publication in Nature Communications\n",
    "authors": [
      "Melanie Bernhardt",
      "Daniel C. Castro",
      "Ryutaro Tanno",
      "Anton Schwaighofer",
      "Kerem C. Tezcan",
      "Miguel Monteiro",
      "Shruthi Bannur",
      "Matthew Lungren",
      "Aditya Nori",
      "Ben Glocker",
      "Javier Alvarez-Valle",
      "Ozan Oktay"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.00574"
  },
  {
    "id": "arXiv:2109.01411",
    "title": "An Exploratory Study on Utilising the Web of Linked Data for Product  Data Mining",
    "abstract": "Comments: Currently under review at LRE journal",
    "descriptor": "\nComments: Currently under review at LRE journal\n",
    "authors": [
      "Ziqi Zhang",
      "Xingyi Song"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.01411"
  },
  {
    "id": "arXiv:2109.05693",
    "title": "On Shallow Packings and Tusn\u00e1dy's Problem",
    "abstract": "Comments: The proof of the main theorem in the paper has an unfixable flaw, in Claim 4.7. The claimed result is therefore no longer correct",
    "descriptor": "\nComments: The proof of the main theorem in the paper has an unfixable flaw, in Claim 4.7. The claimed result is therefore no longer correct\n",
    "authors": [
      "Kunal Dutta"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2109.05693"
  },
  {
    "id": "arXiv:2109.05952",
    "title": "Tamizhi-Net OCR: Creating A Quality Large Scale Tamil-Sinhala-English  Parallel Corpus Using Deep Learning Based Printed Character Recognition (PCR)",
    "abstract": "Comments: 8 Pages",
    "descriptor": "\nComments: 8 Pages\n",
    "authors": [
      "Charangan Vasantharajan",
      "Uthayasanker Thayasivam"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.05952"
  },
  {
    "id": "arXiv:2109.06452",
    "title": "Spiking Neural Networks for Visual Place Recognition via Weighted  Neuronal Assignments",
    "abstract": "Comments: 8 pages, 6 figures, IEEE Robotics and Automation Letters (RA-L), also accepted to IEEE International Conference on Robotics and Automation (ICRA 2022)",
    "descriptor": "\nComments: 8 pages, 6 figures, IEEE Robotics and Automation Letters (RA-L), also accepted to IEEE International Conference on Robotics and Automation (ICRA 2022)\n",
    "authors": [
      "Somayeh Hussaini",
      "Michael Milford",
      "Tobias Fischer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.06452"
  },
  {
    "id": "arXiv:2109.08266",
    "title": "Hard to Forget: Poisoning Attacks on Certified Machine Unlearning",
    "abstract": "Comments: Align with camera-ready submission to AAAI-22. Changes include: switched to row-wise normalization in Algorithm 3, added link to GitHub repository, added Appendix C with additional results on long-term effectiveness",
    "descriptor": "\nComments: Align with camera-ready submission to AAAI-22. Changes include: switched to row-wise normalization in Algorithm 3, added link to GitHub repository, added Appendix C with additional results on long-term effectiveness\n",
    "authors": [
      "Neil G. Marchant",
      "Benjamin I. P. Rubinstein",
      "Scott Alfeld"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2109.08266"
  },
  {
    "id": "arXiv:2109.08991",
    "title": "The Undecidability of Network Coding with some Fixed-Size Messages and  Edges",
    "abstract": "Comments: 12 pages, 8 figures",
    "descriptor": "\nComments: 12 pages, 8 figures\n",
    "authors": [
      "Cheuk Ting Li"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2109.08991"
  },
  {
    "id": "arXiv:2109.10888",
    "title": "A Functional Operator for Model Uncertainty Quantification in the RKHS",
    "abstract": "Comments: Paper modified for clarity and new results added. Updated version of arXiv:2103.01374",
    "descriptor": "\nComments: Paper modified for clarity and new results added. Updated version of arXiv:2103.01374\n",
    "authors": [
      "Rishabh Singh",
      "Jose C. Principe"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2109.10888"
  },
  {
    "id": "arXiv:2109.12886",
    "title": "Nonlinear MPC for Quadrotor Fault-Tolerant Control",
    "abstract": "Comments: 9 pages, 13 figures",
    "descriptor": "\nComments: 9 pages, 13 figures\n",
    "authors": [
      "Fang Nan",
      "Sihao Sun",
      "Philipp Foehn",
      "Davide Scaramuzza"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.12886"
  },
  {
    "id": "arXiv:2109.13479",
    "title": "Knowledge Transfer based Evolutionary Deep Neural Network for  Intelligent Fault Diagnosis",
    "abstract": "Knowledge Transfer based Evolutionary Deep Neural Network for  Intelligent Fault Diagnosis",
    "descriptor": "",
    "authors": [
      "Arun K. Sharma",
      "Nishchal K. Verma"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2109.13479"
  },
  {
    "id": "arXiv:2109.14290",
    "title": "Residual-based adaptivity for two-phase flow simulation in porous media  using Physics-informed Neural Networks",
    "abstract": "Residual-based adaptivity for two-phase flow simulation in porous media  using Physics-informed Neural Networks",
    "descriptor": "",
    "authors": [
      "John Hanna",
      "Jose V. Aguado",
      "Sebastien Comas-Cardona",
      "Ramzi Askri",
      "Domenico Borzacchiello"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2109.14290"
  },
  {
    "id": "arXiv:2110.02291",
    "title": "FedDQ: Communication-Efficient Federated Learning with Descending  Quantization",
    "abstract": "FedDQ: Communication-Efficient Federated Learning with Descending  Quantization",
    "descriptor": "",
    "authors": [
      "Linping Qu",
      "Shenghui Song",
      "Chi-Ying Tsui"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.02291"
  },
  {
    "id": "arXiv:2110.02424",
    "title": "Spectral Bias in Practice: The Role of Function Frequency in  Generalization",
    "abstract": "Spectral Bias in Practice: The Role of Function Frequency in  Generalization",
    "descriptor": "",
    "authors": [
      "Sara Fridovich-Keil",
      "Raphael Gontijo-Lopes",
      "Rebecca Roelofs"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.02424"
  },
  {
    "id": "arXiv:2110.02793",
    "title": "Multi-Agent Constrained Policy Optimisation",
    "abstract": "Multi-Agent Constrained Policy Optimisation",
    "descriptor": "",
    "authors": [
      "Shangding Gu",
      "Jakub Grudzien Kuba",
      "Munning Wen",
      "Ruiqing Chen",
      "Ziyan Wang",
      "Zheng Tian",
      "Jun Wang",
      "Alois Knoll",
      "Yaodong Yang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2110.02793"
  },
  {
    "id": "arXiv:2110.02898",
    "title": "Coresets for Kernel Clustering",
    "abstract": "Coresets for Kernel Clustering",
    "descriptor": "",
    "authors": [
      "Shaofeng H.-C. Jiang",
      "Robert Krauthgamer",
      "Jianing Lou",
      "Yubo Zhang"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2110.02898"
  },
  {
    "id": "arXiv:2110.03095",
    "title": "Which Shortcut Cues Will DNNs Choose? A Study from the Parameter-Space  Perspective",
    "abstract": "Comments: To be published in \"The International Conference on Learning Representations\" (ICLR 2022)(Accepted) First two authors have contributed equally",
    "descriptor": "\nComments: To be published in \"The International Conference on Learning Representations\" (ICLR 2022)(Accepted) First two authors have contributed equally\n",
    "authors": [
      "Luca Scimeca",
      "Seong Joon Oh",
      "Sanghyuk Chun",
      "Michael Poli",
      "Sangdoo Yun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.03095"
  },
  {
    "id": "arXiv:2110.03576",
    "title": "Training Stable Graph Neural Networks Through Constrained Learning",
    "abstract": "Training Stable Graph Neural Networks Through Constrained Learning",
    "descriptor": "",
    "authors": [
      "Juan Cervino",
      "Luana Ruiz",
      "Alejandro Ribeiro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.03576"
  },
  {
    "id": "arXiv:2110.04597",
    "title": "A Proximal Algorithm for Sampling from Non-smooth Potentials",
    "abstract": "Comments: 20 pages",
    "descriptor": "\nComments: 20 pages\n",
    "authors": [
      "Jiaming Liang",
      "Yongxin Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2110.04597"
  },
  {
    "id": "arXiv:2110.04621",
    "title": "Universal Paralinguistic Speech Representations Using Self-Supervised  Conformers",
    "abstract": "Universal Paralinguistic Speech Representations Using Self-Supervised  Conformers",
    "descriptor": "",
    "authors": [
      "Joel Shor",
      "Aren Jansen",
      "Wei Han",
      "Daniel Park",
      "Yu Zhang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.04621"
  },
  {
    "id": "arXiv:2110.05093",
    "title": "Consistency of the Full and Reduced Order Models for Evolve-Filter-Relax  Regularization of Convection-Dominated, Marginally-Resolved Flows",
    "abstract": "Consistency of the Full and Reduced Order Models for Evolve-Filter-Relax  Regularization of Convection-Dominated, Marginally-Resolved Flows",
    "descriptor": "",
    "authors": [
      "Maria Strazzullo",
      "Michele Girfoglio",
      "Francesco Ballarin",
      "Traian Iliescu",
      "Gianluigi Rozza"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.05093"
  },
  {
    "id": "arXiv:2110.07788",
    "title": "Gaussian Process Bandit Optimization with Few Batches",
    "abstract": "Comments: AISTATS 2022",
    "descriptor": "\nComments: AISTATS 2022\n",
    "authors": [
      "Zihan Li",
      "Jonathan Scarlett"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2110.07788"
  },
  {
    "id": "arXiv:2110.07875",
    "title": "Graph Neural Networks with Learnable Structural and Positional  Representations",
    "abstract": "Comments: Code at this https URL",
    "descriptor": "\nComments: Code at this https URL\n",
    "authors": [
      "Vijay Prakash Dwivedi",
      "Anh Tuan Luu",
      "Thomas Laurent",
      "Yoshua Bengio",
      "Xavier Bresson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.07875"
  },
  {
    "id": "arXiv:2110.08802",
    "title": "Coordinated Multi-Agent Pathfinding for Drones and Trucks over Road  Networks",
    "abstract": "Comments: Accepted to Autonomous Agents and Multiagent Systems, 2022",
    "descriptor": "\nComments: Accepted to Autonomous Agents and Multiagent Systems, 2022\n",
    "authors": [
      "Shushman Choudhury",
      "Kiril Solovey",
      "Mykel Kochenderfer",
      "Marco Pavone"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2110.08802"
  },
  {
    "id": "arXiv:2110.09660",
    "title": "BEV-SGD: Best Effort Voting SGD for Analog Aggregation Based Federated  Learning against Byzantine Attackers",
    "abstract": "Comments: Version 2:Revised some proofs, some typos, and some expressions of sentences",
    "descriptor": "\nComments: Version 2:Revised some proofs, some typos, and some expressions of sentences\n",
    "authors": [
      "Xin Fan",
      "Yue Wang",
      "Yan Huo",
      "Zhi Tian"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2110.09660"
  },
  {
    "id": "arXiv:2110.10996",
    "title": "Mean Nystr\u00f6m Embeddings for Adaptive Compressive Learning",
    "abstract": "Comments: Accepted to AISTATS 2022. 21 pages, 4 figures",
    "descriptor": "\nComments: Accepted to AISTATS 2022. 21 pages, 4 figures\n",
    "authors": [
      "Antoine Chatalic",
      "Luigi Carratino",
      "Ernesto De Vito",
      "Lorenzo Rosasco"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.10996"
  },
  {
    "id": "arXiv:2110.13162",
    "title": "Quantum machine learning beyond kernel methods",
    "abstract": "Comments: 16 pages, 13 figures; added new results on learning separations",
    "descriptor": "\nComments: 16 pages, 13 figures; added new results on learning separations\n",
    "authors": [
      "Sofiene Jerbi",
      "Lukas J. Fiderer",
      "Hendrik Poulsen Nautrup",
      "Jonas M. K\u00fcbler",
      "Hans J. Briegel",
      "Vedran Dunjko"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.13162"
  },
  {
    "id": "arXiv:2110.13340",
    "title": "Privacy-Preserving Multi-Target Multi-Domain Recommender Systems with  Assisted AutoEncoders",
    "abstract": "Privacy-Preserving Multi-Target Multi-Domain Recommender Systems with  Assisted AutoEncoders",
    "descriptor": "",
    "authors": [
      "Enmao Diao",
      "Vahid Tarokh",
      "Jie Ding"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.13340"
  },
  {
    "id": "arXiv:2111.00344",
    "title": "Convergence and Semi-convergence of a class of constrained block  iterative methods",
    "abstract": "Convergence and Semi-convergence of a class of constrained block  iterative methods",
    "descriptor": "",
    "authors": [
      "Mahdi Mirzapour",
      "Andrzej Cegielski",
      "Tommy Elfving"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2111.00344"
  },
  {
    "id": "arXiv:2111.02580",
    "title": "Deep Direct Visual Servoing of Tendon-Driven Continuum Robots",
    "abstract": "Comments: 7 pages, 10 figures, 1 table",
    "descriptor": "\nComments: 7 pages, 10 figures, 1 table\n",
    "authors": [
      "Ibrahim Abdulhafiz",
      "Ali A. Nazari",
      "Taha Abbasi-Hashemi",
      "Amir Jalali",
      "Kourosh Zareinia",
      "Sajad Saeedi",
      "Farrokh Janabi-Sharifi"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2111.02580"
  },
  {
    "id": "arXiv:2111.02749",
    "title": "Label Ranking through Nonparametric Regression",
    "abstract": "Label Ranking through Nonparametric Regression",
    "descriptor": "",
    "authors": [
      "Dimitris Fotakis",
      "Alkis Kalavasis",
      "Eleni Psaroudaki"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.02749"
  },
  {
    "id": "arXiv:2111.02763",
    "title": "Understanding Riemannian Acceleration via a Proximal Extragradient  Framework",
    "abstract": "Understanding Riemannian Acceleration via a Proximal Extragradient  Framework",
    "descriptor": "",
    "authors": [
      "Jikai Jin",
      "Suvrit Sra"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.02763"
  },
  {
    "id": "arXiv:2111.05649",
    "title": "Towards Practical Evaluation of Android ICC Resolution Techniques",
    "abstract": "Towards Practical Evaluation of Android ICC Resolution Techniques",
    "descriptor": "",
    "authors": [
      "Jiwei Yan",
      "ShiXin Zhang",
      "YePang Liu",
      "Jun Yan",
      "Jian Zhang"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2111.05649"
  },
  {
    "id": "arXiv:2111.09372",
    "title": "BLOOM-Net: Blockwise Optimization for Masking Networks Toward Scalable  and Efficient Speech Enhancement",
    "abstract": "Comments: 5 pages, 3 figures, ICASSP 2022",
    "descriptor": "\nComments: 5 pages, 3 figures, ICASSP 2022\n",
    "authors": [
      "Sunwoo Kim",
      "Minje Kim"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2111.09372"
  },
  {
    "id": "arXiv:2111.10003",
    "title": "Differentiable Wavetable Synthesis",
    "abstract": "Comments: Accepted by ICASSP 2022, Demo: this https URL Codes: this https URL",
    "descriptor": "\nComments: Accepted by ICASSP 2022, Demo: this https URL Codes: this https URL\n",
    "authors": [
      "Siyuan Shan",
      "Lamtharn Hantrakul",
      "Jitong Chen",
      "Matt Avent",
      "David Trevelyan"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2111.10003"
  },
  {
    "id": "arXiv:2111.13176",
    "title": "Using Color To Identify Insider Threats",
    "abstract": "Using Color To Identify Insider Threats",
    "descriptor": "",
    "authors": [
      "Sameer Khanna"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.13176"
  },
  {
    "id": "arXiv:2111.13646",
    "title": "Dimension Reduction with Prior Information for Knowledge Discovery",
    "abstract": "Comments: 24 pages, 6 figures",
    "descriptor": "\nComments: 24 pages, 6 figures\n",
    "authors": [
      "Anh Tuan Bui"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.13646"
  },
  {
    "id": "arXiv:2112.04153",
    "title": "Model-Value Inconsistency as a Signal for Epistemic Uncertainty",
    "abstract": "Comments: The first three authors contributed equally",
    "descriptor": "\nComments: The first three authors contributed equally\n",
    "authors": [
      "Angelos Filos",
      "Eszter V\u00e9rtes",
      "Zita Marinho",
      "Gregory Farquhar",
      "Diana Borsa",
      "Abram Friesen",
      "Feryal Behbahani",
      "Tom Schaul",
      "Andr\u00e9 Barreto",
      "Simon Osindero"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.04153"
  },
  {
    "id": "arXiv:2112.06103",
    "title": "Improving Vision Transformers for Incremental Learning",
    "abstract": "Comments: Add experiments on CIFAR-100, comparison with DER",
    "descriptor": "\nComments: Add experiments on CIFAR-100, comparison with DER\n",
    "authors": [
      "Pei Yu",
      "Yinpeng Chen",
      "Ying Jin",
      "Zicheng Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.06103"
  },
  {
    "id": "arXiv:2112.07159",
    "title": "Birds Eye View Social Distancing Analysis System",
    "abstract": "Birds Eye View Social Distancing Analysis System",
    "descriptor": "",
    "authors": [
      "Zhengye Yang",
      "Mingfei Sun",
      "Hongzhe Ye",
      "Zihao Xiong",
      "Gil Zussman",
      "Zoran Kostic"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2112.07159"
  },
  {
    "id": "arXiv:2112.09484",
    "title": "Learning in Restless Bandits under Exogenous Global Markov Process",
    "abstract": "Comments: 13 pages, 6 figures. arXiv admin note: text overlap with arXiv:1906.08120",
    "descriptor": "\nComments: 13 pages, 6 figures. arXiv admin note: text overlap with arXiv:1906.08120\n",
    "authors": [
      "Tomer Gafni",
      "Michal Yemini",
      "Kobi Cohen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2112.09484"
  },
  {
    "id": "arXiv:2112.10200",
    "title": "Multi-turn RNN-T for streaming recognition of multi-party speech",
    "abstract": "Comments: Accepted by ICASSP 2022",
    "descriptor": "\nComments: Accepted by ICASSP 2022\n",
    "authors": [
      "Ilya Sklyar",
      "Anna Piunova",
      "Xianrui Zheng",
      "Yulan Liu"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2112.10200"
  },
  {
    "id": "arXiv:2112.10852",
    "title": "The effective noise of Stochastic Gradient Descent",
    "abstract": "Comments: 7 pages + appendix, 5 figures",
    "descriptor": "\nComments: 7 pages + appendix, 5 figures\n",
    "authors": [
      "Francesca Mignacco",
      "Pierfrancesco Urbani"
    ],
    "subjectives": [
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.10852"
  },
  {
    "id": "arXiv:2112.14518",
    "title": "Mutual influence between language and perception in multi-agent  communication games",
    "abstract": "Mutual influence between language and perception in multi-agent  communication games",
    "descriptor": "",
    "authors": [
      "Xenia Ohmer",
      "Michael Marino",
      "Michael Franke",
      "Peter K\u00f6nig"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2112.14518"
  },
  {
    "id": "arXiv:2112.15036",
    "title": "Dimensionality reduction for prediction: Application to Bitcoin and  Ethereum",
    "abstract": "Dimensionality reduction for prediction: Application to Bitcoin and  Ethereum",
    "descriptor": "",
    "authors": [
      "Hugo Inzirillo",
      "Benjamin Mat"
    ],
    "subjectives": [
      "Statistical Finance (q-fin.ST)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.15036"
  },
  {
    "id": "arXiv:2201.01384",
    "title": "Sparse-Dyn: Sparse Dynamic Graph Multi-representation Learning via  Event-based Sparse Temporal Attention Network",
    "abstract": "Sparse-Dyn: Sparse Dynamic Graph Multi-representation Learning via  Event-based Sparse Temporal Attention Network",
    "descriptor": "",
    "authors": [
      "Yan Pang",
      "Chao Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.01384"
  },
  {
    "id": "arXiv:2201.01549",
    "title": "SPT-Code: Sequence-to-Sequence Pre-Training for Learning Source Code  Representations",
    "abstract": "Comments: Accepted by ICSE 2022, not the final version",
    "descriptor": "\nComments: Accepted by ICSE 2022, not the final version\n",
    "authors": [
      "Changan Niu",
      "Chuanyi Li",
      "Vincent Ng",
      "Jidong Ge",
      "Liguo Huang",
      "Bin Luo"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2201.01549"
  },
  {
    "id": "arXiv:2201.02447",
    "title": "Bregman divergence based em algorithm and its application to classical  and quantum rate distortion theory",
    "abstract": "Bregman divergence based em algorithm and its application to classical  and quantum rate distortion theory",
    "descriptor": "",
    "authors": [
      "Masahito Hayashi"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2201.02447"
  },
  {
    "id": "arXiv:2201.02707",
    "title": "ALPHA: Audit that Learns from Previously Hand-Audited Ballots",
    "abstract": "ALPHA: Audit that Learns from Previously Hand-Audited Ballots",
    "descriptor": "",
    "authors": [
      "Philip B. Stark"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Cryptography and Security (cs.CR)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2201.02707"
  },
  {
    "id": "arXiv:2201.03242",
    "title": "A Coq Formalization of the Bochner integral",
    "abstract": "A Coq Formalization of the Bochner integral",
    "descriptor": "",
    "authors": [
      "Sylvie Boldo",
      "Fran\u00e7ois Cl\u00e9ment",
      "Louise Leclerc"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Functional Analysis (math.FA)"
    ],
    "url": "https://arxiv.org/abs/2201.03242"
  },
  {
    "id": "arXiv:2201.03749",
    "title": "Utilizing Parallelism in Smart Contracts on Decentralized Blockchains by  Taming Application-Inherent Conflicts",
    "abstract": "Utilizing Parallelism in Smart Contracts on Decentralized Blockchains by  Taming Application-Inherent Conflicts",
    "descriptor": "",
    "authors": [
      "P\u00e9ter Garamv\u00f6lgyi",
      "Yuxi Liu",
      "Dong Zhou",
      "Fan Long",
      "Ming Wu"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2201.03749"
  },
  {
    "id": "arXiv:2201.04234",
    "title": "Leveraging Unlabeled Data to Predict Out-of-Distribution Performance",
    "abstract": "Comments: Accepted at ICLR 2022",
    "descriptor": "\nComments: Accepted at ICLR 2022\n",
    "authors": [
      "Saurabh Garg",
      "Sivaraman Balakrishnan",
      "Zachary C. Lipton",
      "Behnam Neyshabur",
      "Hanie Sedghi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2201.04234"
  },
  {
    "id": "arXiv:2201.04462",
    "title": "Chaos and order in event-triggered control",
    "abstract": "Chaos and order in event-triggered control",
    "descriptor": "",
    "authors": [
      "Gabriel de Albuquerque Gleizer",
      "Manuel Mazo Jr"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2201.04462"
  },
  {
    "id": "arXiv:2201.04469",
    "title": "Best Arm Identification with a Fixed Budget under a Small Gap",
    "abstract": "Best Arm Identification with a Fixed Budget under a Small Gap",
    "descriptor": "",
    "authors": [
      "Masahiro Kato",
      "Kaito Ariu",
      "Masaaki Imaizumi",
      "Masatoshi Uehara",
      "Masahiro Nomura",
      "Chao Qin"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Econometrics (econ.EM)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2201.04469"
  },
  {
    "id": "arXiv:2201.05613",
    "title": "The Dark Side of the Language: Pre-trained Transformers in the DarkNet",
    "abstract": "The Dark Side of the Language: Pre-trained Transformers in the DarkNet",
    "descriptor": "",
    "authors": [
      "Leonardo Ranaldi",
      "Aria Nourbakhsh",
      "Arianna Patrizi",
      "Elena Sofia Ruzzetti",
      "Dario Onorati",
      "Francesca Fallucchi",
      "Fabio Massimo Zanzotto"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.05613"
  },
  {
    "id": "arXiv:2201.06628",
    "title": "Learning Wave Propagation with Attention-Based Convolutional Recurrent  Autoencoder Net",
    "abstract": "Comments: 23 pages",
    "descriptor": "\nComments: 23 pages\n",
    "authors": [
      "Indu Kant Deo",
      "Rajeev Jaiman"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.06628"
  },
  {
    "id": "arXiv:2201.06778",
    "title": "Data-Driven Deep Learning Based Hybrid Beamforming for Aerial Massive  MIMO-OFDM Systems with Implicit CSI",
    "abstract": "Data-Driven Deep Learning Based Hybrid Beamforming for Aerial Massive  MIMO-OFDM Systems with Implicit CSI",
    "descriptor": "",
    "authors": [
      "Zhen Gao",
      "Minghui Wu",
      "Chun Hu",
      "Feifei Gao",
      "Guanghui Wen",
      "Dezhi Zheng",
      "Jun Zhang"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.06778"
  },
  {
    "id": "arXiv:2201.07322",
    "title": "Interpretable Single-Cell Set Classification with Kernel Mean Embeddings",
    "abstract": "Comments: Codes are avialbe at this https URL",
    "descriptor": "\nComments: Codes are avialbe at this https URL\n",
    "authors": [
      "Siyuan Shan",
      "Vishal Baskaran",
      "Haidong Yi",
      "Jolene Ranek",
      "Natalie Stanley",
      "Junier Oliva"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2201.07322"
  },
  {
    "id": "arXiv:2201.08239",
    "title": "LaMDA: Language Models for Dialog Applications",
    "abstract": "LaMDA: Language Models for Dialog Applications",
    "descriptor": "",
    "authors": [
      "Romal Thoppilan",
      "Daniel De Freitas",
      "Jamie Hall",
      "Noam Shazeer",
      "Apoorv Kulshreshtha",
      "Heng-Tze Cheng",
      "Alicia Jin",
      "Taylor Bos",
      "Leslie Baker",
      "Yu Du",
      "YaGuang Li",
      "Hongrae Lee",
      "Huaixiu Steven Zheng",
      "Amin Ghafouri",
      "Marcelo Menegali",
      "Yanping Huang",
      "Maxim Krikun",
      "Dmitry Lepikhin",
      "James Qin",
      "Dehao Chen",
      "Yuanzhong Xu",
      "Zhifeng Chen",
      "Adam Roberts",
      "Maarten Bosma",
      "Vincent Zhao",
      "Yanqi Zhou",
      "Chung-Ching Chang",
      "Igor Krivokon",
      "Will Rusch",
      "Marc Pickett",
      "Pranesh Srinivasan",
      "Laichee Man",
      "Kathleen Meier-Hellstern",
      "Meredith Ringel Morris",
      "Tulsee Doshi",
      "Renelito Delos Santos",
      "Toju Duke",
      "Johnny Soraker",
      "Ben Zevenbergen",
      "Vinodkumar Prabhakaran",
      "Mark Diaz",
      "Ben Hutchinson",
      "Kristen Olson",
      "Alejandra Molina",
      "Erin Hoffman-John",
      "Josh Lee",
      "Lora Aroyo",
      "Ravi Rajakumar",
      "Alena Butryna",
      "Matthew Lamm",
      "Viktoriya Kuzmina",
      "Joe Fenton"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2201.08239"
  },
  {
    "id": "arXiv:2201.08355",
    "title": "Sim-to-Lab-to-Real: Safe Reinforcement Learning with Shielding and  Generalization Guarantees",
    "abstract": "Comments: Preprint submitted to Special Issue on Risk-aware Autonomous Systems: Theory and Practice, Artificial Intelligence Journal",
    "descriptor": "\nComments: Preprint submitted to Special Issue on Risk-aware Autonomous Systems: Theory and Practice, Artificial Intelligence Journal\n",
    "authors": [
      "Kai-Chieh Hsu",
      "Allen Z. Ren",
      "Duy Phuong Nguyen",
      "Anirudha Majumdar",
      "Jaime F. Fisac"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.08355"
  },
  {
    "id": "arXiv:2201.10758",
    "title": "An Efficient Approximation Algorithm for the Colonel Blotto Game",
    "abstract": "An Efficient Approximation Algorithm for the Colonel Blotto Game",
    "descriptor": "",
    "authors": [
      "Daniel Beaglehole"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2201.10758"
  },
  {
    "id": "arXiv:2201.10800",
    "title": "SkiM: Skipping Memory LSTM for Low-Latency Real-Time Continuous Speech  Separation",
    "abstract": "Comments: Accepted by ICASSP 2022",
    "descriptor": "\nComments: Accepted by ICASSP 2022\n",
    "authors": [
      "Chenda Li",
      "Lei Yang",
      "Weiqin Wang",
      "Yanmin Qian"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2201.10800"
  },
  {
    "id": "arXiv:2201.11412",
    "title": "Reduction of Two-Dimensional Data for Speeding Up Convex Hull  Computation",
    "abstract": "Comments: 12 pages, 6 figures",
    "descriptor": "\nComments: 12 pages, 6 figures\n",
    "authors": [
      "Debashis Mukherjee"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2201.11412"
  },
  {
    "id": "arXiv:2201.11481",
    "title": "Multi-Access Cache-Aided Multi-User Private Information Retrieval",
    "abstract": "Comments: 15 pages, 11 figures, 2 tables. Fixed minor errors in the previous version and the presentation improved",
    "descriptor": "\nComments: 15 pages, 11 figures, 2 tables. Fixed minor errors in the previous version and the presentation improved\n",
    "authors": [
      "Kanishak Vaidya",
      "B Sundar Rajan"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2201.11481"
  },
  {
    "id": "arXiv:2201.11528",
    "title": "Beyond ImageNet Attack: Towards Crafting Adversarial Examples for  Black-box Domains",
    "abstract": "Comments: Accepted by ICLR 2022",
    "descriptor": "\nComments: Accepted by ICLR 2022\n",
    "authors": [
      "Qilong Zhang",
      "Xiaodan Li",
      "Yuefeng Chen",
      "Jingkuan Song",
      "Lianli Gao",
      "Yuan He",
      "Hui Xue"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.11528"
  },
  {
    "id": "arXiv:2201.12038",
    "title": "A survey on flexible/restricted skyline and their applicability",
    "abstract": "A survey on flexible/restricted skyline and their applicability",
    "descriptor": "",
    "authors": [
      "Davide Canali"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2201.12038"
  },
  {
    "id": "arXiv:2201.12702",
    "title": "Robotic Wireless Energy Transfer in Dynamic Environments: System Design  and Experimental Validation",
    "abstract": "Comments: single column, 18 pages, 6 figures, to appear in IEEE Communications Magazine",
    "descriptor": "\nComments: single column, 18 pages, 6 figures, to appear in IEEE Communications Magazine\n",
    "authors": [
      "Shuai Wang",
      "Ruihua Han",
      "Yuncong Hong",
      "Qi Hao",
      "Miaowen Wen",
      "Leila Musavian",
      "Shahid Mumtaz",
      "Derrick Wing Kwan Ng"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Information Theory (cs.IT)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2201.12702"
  },
  {
    "id": "arXiv:2201.13189",
    "title": "Resultant Tools for Parametric Polynomial Systems with Application to  Population Models",
    "abstract": "Comments: 10 pages; typo from v1 fixed",
    "descriptor": "\nComments: 10 pages; typo from v1 fixed\n",
    "authors": [
      "AmirHosein Sadeghimanesh",
      "Matthew England"
    ],
    "subjectives": [
      "Symbolic Computation (cs.SC)",
      "Populations and Evolution (q-bio.PE)"
    ],
    "url": "https://arxiv.org/abs/2201.13189"
  },
  {
    "id": "arXiv:2202.00666",
    "title": "Typical Decoding for Natural Language Generation",
    "abstract": "Typical Decoding for Natural Language Generation",
    "descriptor": "",
    "authors": [
      "Clara Meister",
      "Tiago Pimentel",
      "Gian Wiher",
      "Ryan Cotterell"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.00666"
  },
  {
    "id": "arXiv:2202.00794",
    "title": "Learning to pronounce as measuring cross-lingual joint  orthography-phonology complexity",
    "abstract": "Comments: Submitted and Accepted to NLPML 2022",
    "descriptor": "\nComments: Submitted and Accepted to NLPML 2022\n",
    "authors": [
      "Domenic Rosati"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.00794"
  },
  {
    "id": "arXiv:2202.00898",
    "title": "Quantification and aggregation over concepts of the ontology",
    "abstract": "Comments: Submitted to KR 2022",
    "descriptor": "\nComments: Submitted to KR 2022\n",
    "authors": [
      "Pierre Carbonnelle",
      "Matthias Van der Hallen",
      "Marc Denecker"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.00898"
  },
  {
    "id": "arXiv:2202.01389",
    "title": "An Empirical Review of Optimization Techniques for Quantum Variational  Circuits",
    "abstract": "Comments: 14 pages, 1 figure",
    "descriptor": "\nComments: 14 pages, 1 figure\n",
    "authors": [
      "Owen Lockwood"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.01389"
  },
  {
    "id": "arXiv:2202.01477",
    "title": "Unsourced Random Access with a Massive MIMO Receiver Using Multiple  Stages of Orthogonal Pilots",
    "abstract": "Comments: I need to improve it",
    "descriptor": "\nComments: I need to improve it\n",
    "authors": [
      "Mohammad Javad Ahmadi",
      "Tolga M. Duman"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.01477"
  },
  {
    "id": "arXiv:2202.01478",
    "title": "Trajectory Forecasting from Detection with Uncertainty-Aware Motion  Encoding",
    "abstract": "Comments: 11 pages, 4 figures",
    "descriptor": "\nComments: 11 pages, 4 figures\n",
    "authors": [
      "Pu Zhang",
      "Lei Bai",
      "Jianru Xue",
      "Jianwu Fang",
      "Nanning Zheng",
      "Wanli Ouyang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.01478"
  },
  {
    "id": "arXiv:2202.01498",
    "title": "Towards Understanding First-Party Cookie Tracking in the Field",
    "abstract": "Towards Understanding First-Party Cookie Tracking in the Field",
    "descriptor": "",
    "authors": [
      "Nurullah Demir",
      "Daniel Theis",
      "Tobias Urban",
      "Norbert Pohlmann"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.01498"
  },
  {
    "id": "arXiv:2202.01802",
    "title": "Cross-Platform Difference in Facebook and Text Messages Language Use:  Illustrated by Depression Diagnosis",
    "abstract": "Comments: 5 pages, 1 figure",
    "descriptor": "\nComments: 5 pages, 1 figure\n",
    "authors": [
      "Tingting Liu",
      "Salvatore Giorgi",
      "Xiangyu Tao",
      "Douglas Bellew",
      "Brenda Curtis",
      "Lyle Ungar"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.01802"
  },
  {
    "id": "arXiv:2202.02031",
    "title": "Complex-to-Real Random Features for Polynomial Kernels",
    "abstract": "Comments: 26 pages",
    "descriptor": "\nComments: 26 pages\n",
    "authors": [
      "Jonas Wacker",
      "Ruben Ohana",
      "Maurizio Filippone"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2202.02031"
  },
  {
    "id": "arXiv:2202.02585",
    "title": "GhostTalk: Interactive Attack on Smartphone Voice System Through Power  Line",
    "abstract": "GhostTalk: Interactive Attack on Smartphone Voice System Through Power  Line",
    "descriptor": "",
    "authors": [
      "Yuanda Wang",
      "Hanqing Guo",
      "Qiben Yan"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.02585"
  },
  {
    "id": "arXiv:2202.02626",
    "title": "Layer-wise Regularized Adversarial Training using Layers Sustainability  Analysis (LSA) framework",
    "abstract": "Comments: Layers Sustainability Analysis (LSA) framework",
    "descriptor": "\nComments: Layers Sustainability Analysis (LSA) framework\n",
    "authors": [
      "Mohammad Khalooei",
      "Mohammad Mehdi Homayounpour",
      "Maryam Amirmazlaghani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.02626"
  },
  {
    "id": "arXiv:2202.02671",
    "title": "Stable factorization for phase factors of quantum signal processing",
    "abstract": "Stable factorization for phase factors of quantum signal processing",
    "descriptor": "",
    "authors": [
      "Lexing Ying"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.02671"
  },
  {
    "id": "arXiv:2202.02928",
    "title": "ABG: A Multi-Party Mixed Protocol Framework for Privacy-Preserving  Cooperative Learning",
    "abstract": "Comments: The authors have just discovered an existing paper [1], which has substantial overlap in contributions, therefore we decide to withdraw this paper. [1] Lennart Braun, Daniel Demmler, Thomas Schneider, and Oleksandr Tkachenko. MOTION - A framework for mixed-protocol multi-party computation. this https URL",
    "descriptor": "\nComments: The authors have just discovered an existing paper [1], which has substantial overlap in contributions, therefore we decide to withdraw this paper. [1] Lennart Braun, Daniel Demmler, Thomas Schneider, and Oleksandr Tkachenko. MOTION - A framework for mixed-protocol multi-party computation. this https URL\n",
    "authors": [
      "Hao Wang",
      "Zhi Li",
      "Chunpeng Ge",
      "Willy Susilo"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.02928"
  },
  {
    "id": "arXiv:2202.02947",
    "title": "Parallel Successive Learning for Dynamic Distributed Model Training over  Heterogeneous Wireless Networks",
    "abstract": "Parallel Successive Learning for Dynamic Distributed Model Training over  Heterogeneous Wireless Networks",
    "descriptor": "",
    "authors": [
      "Seyyedali Hosseinalipour",
      "Su Wang",
      "Nicolo Michelusi",
      "Vaneet Aggarwal",
      "Christopher G. Brinton",
      "David J. Love",
      "Mung Chiang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Networking and Internet Architecture (cs.NI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.02947"
  },
  {
    "id": "arXiv:2202.03152",
    "title": "Optimizing Age of Information in Wireless Uplink Networks with Partial  Observations",
    "abstract": "Comments: Submitted for possible IEEE publication",
    "descriptor": "\nComments: Submitted for possible IEEE publication\n",
    "authors": [
      "Jingwei Liu",
      "Rui Zhang",
      "Aoyu Gong",
      "He Chen"
    ],
    "subjectives": [
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2202.03152"
  },
  {
    "id": "arXiv:2202.03384",
    "title": "Hybrid Contrastive Quantization for Efficient Cross-View Video Retrieval",
    "abstract": "Comments: Accepted to The Web Conference 2022 (WWW'22). 11 pages, 5 tables, 6 figures",
    "descriptor": "\nComments: Accepted to The Web Conference 2022 (WWW'22). 11 pages, 5 tables, 6 figures\n",
    "authors": [
      "Jinpeng Wang",
      "Bin Chen",
      "Dongliang Liao",
      "Ziyun Zeng",
      "Gongfu Li",
      "Shu-Tao Xia",
      "Jin Xu"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2202.03384"
  },
  {
    "id": "arXiv:2202.03613",
    "title": "Conformal prediction for the design problem",
    "abstract": "Comments: 30 pages, 7 figures",
    "descriptor": "\nComments: 30 pages, 7 figures\n",
    "authors": [
      "Clara Fannjiang",
      "Stephen Bates",
      "Anastasios Angelopoulos",
      "Jennifer Listgarten",
      "Michael I. Jordan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2202.03613"
  },
  {
    "id": "arXiv:2202.03634",
    "title": "Multi-Agent Path Finding with Prioritized Communication Learning",
    "abstract": "Comments: 7 pages, 5 figures, 3 tables, ICRA 2022 Camera Ready",
    "descriptor": "\nComments: 7 pages, 5 figures, 3 tables, ICRA 2022 Camera Ready\n",
    "authors": [
      "Wenhao Li",
      "Hongjun Chen",
      "Bo Jin",
      "Wenzhe Tan",
      "Hongyuan Zha",
      "Xiangfeng Wang"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2202.03634"
  },
  {
    "id": "arXiv:2202.03652",
    "title": "Real-time disease prediction with local differential privacy in Internet  of Medical Things",
    "abstract": "Real-time disease prediction with local differential privacy in Internet  of Medical Things",
    "descriptor": "",
    "authors": [
      "Guanhong Miao",
      "A. Adam Ding",
      "Samuel S. Wu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Other Statistics (stat.OT)"
    ],
    "url": "https://arxiv.org/abs/2202.03652"
  },
  {
    "id": "arXiv:2202.03799",
    "title": "What are the best systems? New perspectives on NLP Benchmarking",
    "abstract": "What are the best systems? New perspectives on NLP Benchmarking",
    "descriptor": "",
    "authors": [
      "Pierre Colombo",
      "Nathan Noiry",
      "Ekhine Irurozki",
      "Stephan Clemencon"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.03799"
  },
  {
    "id": "arXiv:2202.03861",
    "title": "Targeted Trojan-Horse Attacks on Language-based Image Retrieval",
    "abstract": "Targeted Trojan-Horse Attacks on Language-based Image Retrieval",
    "descriptor": "",
    "authors": [
      "Fan Hu",
      "Aozhu Chen",
      "Xirong Li"
    ],
    "subjectives": [
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2202.03861"
  },
  {
    "id": "arXiv:2202.03986",
    "title": "Analysis of Voltage Stability in Terms of Interactions of  Q(U)-Characteristic Control in Distribution Grids",
    "abstract": "Comments: Submitted to 5th International Conference on Smart Energy Systems and Technologies (SEST); Keywords: voltage stability, converter-driven stability, voltage control, Q(V)-characteristic, distribution grid; 7 pages",
    "descriptor": "\nComments: Submitted to 5th International Conference on Smart Energy Systems and Technologies (SEST); Keywords: voltage stability, converter-driven stability, voltage control, Q(V)-characteristic, distribution grid; 7 pages\n",
    "authors": [
      "Sebastian Krahmer",
      "Stefan Ecklebe",
      "Peter Schegner",
      "Klaus R\u00f6benack"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.03986"
  },
  {
    "id": "arXiv:2202.04000",
    "title": "Learning Sinkhorn divergences for supervised change point detection",
    "abstract": "Comments: 19 pages, 13 figures. Reorganized figures and text for improved readability",
    "descriptor": "\nComments: 19 pages, 13 figures. Reorganized figures and text for improved readability\n",
    "authors": [
      "Nauman Ahad",
      "Eva L. Dyer",
      "Keith B. Hengen",
      "Yao Xie",
      "Mark A. Davenport"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.04000"
  },
  {
    "id": "arXiv:2202.04003",
    "title": "Differentiable N-gram Objective on Abstractive Summarization",
    "abstract": "Differentiable N-gram Objective on Abstractive Summarization",
    "descriptor": "",
    "authors": [
      "Yunqi Zhu",
      "Wensheng Zhang",
      "Mingjin Zhu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.04003"
  },
  {
    "id": "arXiv:2202.04167",
    "title": "Understanding the bias-variance tradeoff of Bregman divergences",
    "abstract": "Understanding the bias-variance tradeoff of Bregman divergences",
    "descriptor": "",
    "authors": [
      "Ben Adlam",
      "Neha Gupta",
      "Zelda Mariet",
      "Jamie Smith"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2202.04167"
  },
  {
    "id": "arXiv:2202.04208",
    "title": "Evaluating Causal Inference Methods",
    "abstract": "Comments: 5 figures, 13 pages",
    "descriptor": "\nComments: 5 figures, 13 pages\n",
    "authors": [
      "Harsh Parikh",
      "Carlos Varjao",
      "Louise Xu",
      "Eric Tchetgen Tchetgen"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)",
      "Econometrics (econ.EM)"
    ],
    "url": "https://arxiv.org/abs/2202.04208"
  },
  {
    "id": "arXiv:2202.04219",
    "title": "Improving Computational Complexity in Statistical Models with  Second-Order Information",
    "abstract": "Comments: 26 pages, 2 figures. Considerably shortening the proofs to improve the readability",
    "descriptor": "\nComments: 26 pages, 2 figures. Considerably shortening the proofs to improve the readability\n",
    "authors": [
      "Tongzheng Ren",
      "Jiacheng Zhuo",
      "Sujay Sanghavi",
      "Nhat Ho"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2202.04219"
  },
  {
    "id": "arXiv:2202.04243",
    "title": "Motion-Aware Transformer For Occluded Person Re-identification",
    "abstract": "Comments: 10 pages, 3 figures",
    "descriptor": "\nComments: 10 pages, 3 figures\n",
    "authors": [
      "Mi Zhou",
      "Hongye Liu",
      "Zhekun Lv",
      "Wei Hong",
      "Xiai Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.04243"
  },
  {
    "id": "arXiv:2202.04261",
    "title": "The Volcspeech system for the ICASSP 2022 multi-channel multi-party  meeting transcription challenge",
    "abstract": "The Volcspeech system for the ICASSP 2022 multi-channel multi-party  meeting transcription challenge",
    "descriptor": "",
    "authors": [
      "Chen Shen",
      "Yi Liu",
      "Wenzhi Fan",
      "Bin Wang",
      "Shixue Wen",
      "Yao Tian",
      "Jun Zhang",
      "Jingsheng Yang",
      "Zejun Ma"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2202.04261"
  },
  {
    "id": "arXiv:2202.04488",
    "title": "CRAT-Pred: Vehicle Trajectory Prediction with Crystal Graph  Convolutional Neural Networks and Multi-Head Self-Attention",
    "abstract": "Comments: To appear in the proceedings of 2022 IEEE International Conference on Robotics and Automation (ICRA)",
    "descriptor": "\nComments: To appear in the proceedings of 2022 IEEE International Conference on Robotics and Automation (ICRA)\n",
    "authors": [
      "Julian Schmidt",
      "Julian Jordan",
      "Franz Gritschneder",
      "Klaus Dietmayer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.04488"
  },
  {
    "id": "arXiv:2202.04514",
    "title": "A Model-Agnostic Causal Learning Framework for Recommendation using  Search Data",
    "abstract": "Comments: 9 pages, 7 figures, accepted by The Web Conference 2022",
    "descriptor": "\nComments: 9 pages, 7 figures, accepted by The Web Conference 2022\n",
    "authors": [
      "Zihua Si",
      "Xueran Han",
      "Xiao Zhang",
      "Jun Xu",
      "Yue Yin",
      "Yang Song",
      "Ji-Rong Wen"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2202.04514"
  },
  {
    "id": "arXiv:2202.04518",
    "title": "Protocol Insecurity with Assertions",
    "abstract": "Protocol Insecurity with Assertions",
    "descriptor": "",
    "authors": [
      "R Ramanujam",
      "Vaishnavi Sundararajan",
      "S P Suresh"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2202.04518"
  },
  {
    "id": "arXiv:2202.04567",
    "title": "Optimal Hyperparameters and Structure Setting of Multi-Objective Robust  CNN Systems via Generalized Taguchi Method and Objective Vector Norm",
    "abstract": "Comments: 10 pages. Corresponding Author: Sheng-Guo Wang, swang@uncc.edu. To add the arXiv stamp to the first page",
    "descriptor": "\nComments: 10 pages. Corresponding Author: Sheng-Guo Wang, swang@uncc.edu. To add the arXiv stamp to the first page\n",
    "authors": [
      "Sheng-Guo Wang",
      "Shanshan Jiang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2202.04567"
  },
  {
    "id": "arXiv:2202.04595",
    "title": "Exploring Structural Sparsity in Neural Image Compression",
    "abstract": "Comments: 5 pages, 5 figures, submitted to ICIP 2022",
    "descriptor": "\nComments: 5 pages, 5 figures, submitted to ICIP 2022\n",
    "authors": [
      "Shanzhi Yin",
      "Fanyang Meng",
      "Wen Tan",
      "Chao Li",
      "Youneng Bao",
      "Yongsheng Liang",
      "Wei Liu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.04595"
  },
  {
    "id": "arXiv:2202.04632",
    "title": "A Local Geometric Interpretation of Feature Extraction in Deep  Feedforward Neural Networks",
    "abstract": "A Local Geometric Interpretation of Feature Extraction in Deep  Feedforward Neural Networks",
    "descriptor": "",
    "authors": [
      "Md Kamran Chowdhury Shisher",
      "Tasmeen Zaman Ornee",
      "Yin Sun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.04632"
  },
  {
    "id": "arXiv:2202.04641",
    "title": "Unconditionally secure digital signatures implemented in an 8-user  quantum network",
    "abstract": "Comments: Preprint, 9 pages, 7 figures, 1 table",
    "descriptor": "\nComments: Preprint, 9 pages, 7 figures, 1 table\n",
    "authors": [
      "Yoann Pelet",
      "Ittoop Vergheese Puthoor",
      "Natarajan Venkatachalam",
      "S\u00f6ren Wengerowsky",
      "Martin Lon\u010dari\u0107",
      "Sebastian Philipp Neumann",
      "Bo Liu",
      "\u017deljko Samec",
      "Mario Stip\u010devi\u0107",
      "Rupert Ursin",
      "Erika Andersson",
      "John G. Rarity",
      "Djeylan Aktas",
      "Siddarth Koduru Joshi"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.04641"
  }
]
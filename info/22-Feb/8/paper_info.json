[
  {
    "id": "arXiv:2202.02319",
    "title": "An integrated heterogeneous computing framework for ensemble simulations  of laser-induced ignition",
    "abstract": "An integrated computational framework is introduced to study complex\nengineering systems through physics-based ensemble simulations on heterogeneous\nsupercomputers. The framework is primarily designed for the quantitative\nassessment of laser-induced ignition in rocket engines. We develop and combine\nan implicit programming system, a compressible reacting flow solver, and a data\ngeneration/management strategy on a robust and portable platform. We\nsystematically present this framework using test problems on a hybrid CPU/GPU\nmachine. Efficiency, scalability, and accuracy of the solver are\ncomprehensively assessed with canonical unit problems. Ensemble data management\nand autoencoding are demonstrated using a canonical diffusion flame case.\nSensitivity analysis of the ignition of a turbulent, gaseous fuel jet is\nperformed using a simplified, three-dimensional model combustor. Our approach\nunifies computer science, physics and engineering, and data science to realize\na cross-disciplinary workflow. The framework is exascale-oriented and can be\nconsidered a benchmark for future computational science studies of real-world\nsystems.",
    "descriptor": "\nComments: 28 pages, 12 figures\n",
    "authors": [
      "Kazuki Maeda",
      "Thiago Teixeira",
      "Jonathan M. Wang",
      "Jeffrey M. Hokanson",
      "Caetano Melone",
      "Mario Di Renzo",
      "Steve Jones",
      "Javier Urzay",
      "Gianluca Iaccarino"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2202.02319"
  },
  {
    "id": "arXiv:2202.02320",
    "title": "A dynamic program to achieve capacity of multiple access channel with  noiseless feedback",
    "abstract": "In this paper, we consider the problem of evaluating capacity expression of a\nmultiple access channel (MAC) with noiseless feedback. So far, the capacity\nexpression for this channel is known through a multi letter directed\ninformation by Kramer [1]. Recently, it was shown in [2] that one can pose it\nas a dynamic optimization problem, however, no dynamic program was provided as\nthe authors claimed there is no notion of state that is observed by both the\nsenders. In this paper, we build upon [2] to show that there indeed exists a\nstate and therefore a dynamic program (DP) that decomposes this dynamic\noptimization problem, and equivalently a Bellman fixed-point equation to\nevaluate capacity of this channel. We do so by defining a common belief on\nprivate messages and private beliefs of the two senders, and using this common\nbelief as state of the system. We further show that this DP can be further\nreduced to a DP with state as the common belief on just the messages. This\nprovides a single letter characterization of the capacity of this channel.",
    "descriptor": "\nComments: 5 pages. arXiv admin note: text overlap with arXiv:2001.03807 by other authors\n",
    "authors": [
      "Deepanshu Vasal"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.02320"
  },
  {
    "id": "arXiv:2202.02326",
    "title": "Towards Training Reproducible Deep Learning Models",
    "abstract": "Reproducibility is an increasing concern in Artificial Intelligence (AI),\nparticularly in the area of Deep Learning (DL). Being able to reproduce DL\nmodels is crucial for AI-based systems, as it is closely tied to various tasks\nlike training, testing, debugging, and auditing. However, DL models are\nchallenging to be reproduced due to issues like randomness in the software\n(e.g., DL algorithms) and non-determinism in the hardware (e.g., GPU). There\nare various practices to mitigate some of the aforementioned issues. However,\nmany of them are either too intrusive or can only work for a specific usage\ncontext. In this paper, we propose a systematic approach to training\nreproducible DL models. Our approach includes three main parts: (1) a set of\ngeneral criteria to thoroughly evaluate the reproducibility of DL models for\ntwo different domains, (2) a unified framework which leverages a\nrecord-and-replay technique to mitigate software-related randomness and a\nprofile-and-patch technique to control hardware-related non-determinism, and\n(3) a reproducibility guideline which explains the rationales and the\nmitigation strategies on conducting a reproducible training process for DL\nmodels. Case study results show our approach can successfully reproduce six\nopen source and one commercial DL models.",
    "descriptor": "",
    "authors": [
      "Boyuan Chen",
      "Mingzhi Wen",
      "Yong Shi",
      "Dayi Lin",
      "Gopi Krishnan Rajbahadur",
      "Zhen Ming",
      "Jiang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2202.02326"
  },
  {
    "id": "arXiv:2202.02339",
    "title": "Discovering Distribution Shifts using Latent Space Representations",
    "abstract": "Rapid progress in representation learning has led to a proliferation of\nembedding models, and to associated challenges of model selection and practical\napplication. It is non-trivial to assess a model's generalizability to new,\ncandidate datasets and failure to generalize may lead to poor performance on\ndownstream tasks. Distribution shifts are one cause of reduced\ngeneralizability, and are often difficult to detect in practice. In this paper,\nwe use the embedding space geometry to propose a non-parametric framework for\ndetecting distribution shifts, and specify two tests. The first test detects\nshifts by establishing a robustness boundary, determined by an intelligible\nperformance criterion, for comparing reference and candidate datasets. The\nsecond test detects shifts by featurizing and classifying multiple subsamples\nof two datasets as in-distribution and out-of-distribution. In evaluation, both\ntests detect model-impacting distribution shifts, in various shift scenarios,\nfor both synthetic and real-world datasets.",
    "descriptor": "\nComments: 10 pages, 5 figures, 3 tables, 2 algorithms\n",
    "authors": [
      "Leo Betthauser",
      "Urszula Chajewska",
      "Maurice Diesendruck",
      "Rohith Pesala"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.02339"
  },
  {
    "id": "arXiv:2202.02340",
    "title": "Selective Network Linearization for Efficient Private Inference",
    "abstract": "Private inference (PI) enables inference directly on cryptographically secure\ndata. While promising to address many privacy issues, it has seen limited use\ndue to extreme runtimes. Unlike plaintext inference, where latency is dominated\nby FLOPs, in PI non-linear functions (namely ReLU) are the bottleneck. Thus,\npractical PI demands novel ReLU-aware optimizations. To reduce PI latency we\npropose a gradient-based algorithm that selectively linearizes ReLUs while\nmaintaining prediction accuracy. We evaluate our algorithm on several standard\nPI benchmarks. The results demonstrate up to $4.25\\%$ more accuracy (iso-ReLU\ncount at 50K) or $2.2\\times$ less latency (iso-accuracy at 70\\%) than the\ncurrent state of the art and advance the Pareto frontier across the\nlatency-accuracy space. To complement empirical results, we present a \"no free\nlunch\" theorem that sheds light on how and when network linearization is\npossible while maintaining prediction accuracy.",
    "descriptor": "",
    "authors": [
      "Minsu Cho",
      "Ameya Joshi",
      "Siddharth Garg",
      "Brandon Reagen",
      "Chinmay Hegde"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.02340"
  },
  {
    "id": "arXiv:2202.02344",
    "title": "Differentiable Simulation of Inertial Musculotendons",
    "abstract": "We propose a simple and practical approach for incorporating the effects of\nmuscle inertia, which has been ignored by previous musculoskeletal simulators\nin both graphics and biomechanics. In our approach, we express the motion of\nthe musculotendons in terms of the motion of the skeletal joints using a chain\nof Jacobians, so that at the top level, only the reduced degrees of freedom of\nthe skeleton are used to completely drive both bones and musculotendons. Our\napproach can handle all commonly used musculotendon path types, including those\nwith multiple path points and wrapping surfaces. For muscle paths involving\nwrapping surfaces, we use neural networks to model the Jacobians, trained using\nexisting wrapping surface libraries, which allows us to effectively handle the\ndiscontinuities that occur when musculotendon paths collide with wrapping\nsurfaces. We demonstrate support for higher-order time integrators, complex\njoints, inverse dynamics, Hill-type muscle models, and differentiability. We\nalso show that in the limit, as the muscle mass is reduced to zero, our\napproach gracefully degrades to existing simulators in graphics and\nbiomechanics without support for muscle inertia.",
    "descriptor": "",
    "authors": [
      "Ying Wang",
      "Nima Khademi Kalantari",
      "Shinjiro Sueda"
    ],
    "subjectives": [
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2202.02344"
  },
  {
    "id": "arXiv:2202.02349",
    "title": "Analysis of Independent Learning in Network Agents: A Packet Forwarding  Use Case",
    "abstract": "Multi-Agent Reinforcement Learning (MARL) is nowadays widely used to solve\nreal-world and complex decisions in various domains. While MARL can be\ncategorized into independent and cooperative approaches, we consider the\nindependent approach as a simple, more scalable, and less costly method for\nlarge-scale distributed systems, such as network packet forwarding. In this\npaper, we quantitatively and qualitatively assess the benefits of leveraging\nsuch independent agents learning approach, in particular IQL-based algorithm,\nfor packet forwarding in computer networking, using the Named Data Networking\n(NDN) architecture as a driving example. We put multiple IQL-based forwarding\nstrategies (IDQF) to the test and compare their performances against very basic\nforwarding schemes and simple topologies/traffic models to highlight major\nchallenges and issues. We discuss the main issues related to the poor\nperformance of IDQF and quantify the impact of these issues on isolation when\ntraining and testing the IDQF models under different model tuning parameters\nand network topologies/characteristics.",
    "descriptor": "\nComments: 6 pages, 4 figures\n",
    "authors": [
      "Abu Saleh Md Tayeen",
      "Milan Biswal",
      "Abderrahmen Mtibaa",
      "Satyajayant Misra"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2202.02349"
  },
  {
    "id": "arXiv:2202.02352",
    "title": "Learning Interpretable, High-Performing Policies for Continuous Control  Problems",
    "abstract": "Gradient-based approaches in reinforcement learning (RL) have achieved\ntremendous success in learning policies for continuous control problems. While\nthe performance of these approaches warrants real-world adoption in domains,\nsuch as in autonomous driving and robotics, these policies lack\ninterpretability, limiting deployability in safety-critical and\nlegally-regulated domains. Such domains require interpretable and verifiable\ncontrol policies that maintain high performance. We propose Interpretable\nContinuous Control Trees (ICCTs), a tree-based model that can be optimized via\nmodern, gradient-based, RL approaches to produce high-performing, interpretable\npolicies. The key to our approach is a procedure for allowing direct\noptimization in a sparse decision-tree-like representation. We validate ICCTs\nagainst baselines across six domains, showing that ICCTs are capable of\nlearning interpretable policy representations that parity or outperform\nbaselines by up to 33$\\%$ in autonomous driving scenarios while achieving a\n$300$x-$600$x reduction in the number of policy parameters against deep\nlearning baselines.",
    "descriptor": "",
    "authors": [
      "Rohan Paleja",
      "Yaru Niu",
      "Andrew Silva",
      "Chace Ritchie",
      "Sugju Choi",
      "Matthew Gombolay"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.02352"
  },
  {
    "id": "arXiv:2202.02354",
    "title": "A note on the complex and bicomplex valued neural networks",
    "abstract": "In this paper we first write a proof of the perceptron convergence algorithm\nfor the complex multivalued neural networks (CMVNNs). Our primary goal is to\nformulate and prove the perceptron convergence algorithm for the bicomplex\nmultivalued neural networks (BMVNNs) and other important results in the theory\nof neural networks based on a bicomplex algebra.",
    "descriptor": "",
    "authors": [
      "Daniel Alpay",
      "Kamal Diki",
      "Mihaela Vajiac"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2202.02354"
  },
  {
    "id": "arXiv:2202.02357",
    "title": "Strong convergence of an fractional exponential integrator scheme for  the finite element discretization of time-fractional SPDE driven by standard  and fractional Brownian motions",
    "abstract": "The aim of this work is to provide the first strong convergence result of\nnumerical approximation of a general time-fractional second order stochastic\npartial differential equation involving a Caputo derivative in time of order\n$\\alpha\\in(\\frac 12; 1)$ and driven simultaneously by a multiplicative standard\nBrownian motion and additive fBm with Hurst parameter $H\\in(\\frac 12, 1)$, more\nrealistic to model the random effects on transport of particles in medium with\nthermal memory. We prove the existence and uniqueness results and perform the\nspatial discretization using the finite element and the temporal discretization\nusing a fractional exponential integrator scheme. We provide the temporal and\nspatial convergence proofs for our fully discrete scheme and the result shows\nthat the convergence orders depend on the regularity of the initial data, the\npower of the fractional derivative, and the Hurst parameter $H$.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2011.03862, arXiv:1912.12751\n",
    "authors": [
      "Aurelien Junior Noupelah",
      "Antoine Tambue",
      "Jean Louis Woukeng"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.02357"
  },
  {
    "id": "arXiv:2202.02359",
    "title": "Performance Evaluation of Structured and Semi-Structured Bioinformatics  Tools: A Comparative Study",
    "abstract": "There is a wide range of available biological databases developed by\nbioinformatics experts, employing different methods to extract biological data.\nIn this paper, we investigate and evaluate the performance of some of these\nmethods in terms of their ability to efficiently access bioinformatics\ndatabases using web-based interfaces. These methods retrieve bioinformatics\ninformation using structured and semi-structured data tools, which are able to\nretrieve data from remote database servers. This study distinguishes each of\nthese approaches and contrasts these tools. We used Sequence Retrieval System\n(SRS) and Entrez search tools for structured data, while Perl and BioPerl\nsearch programs were used for semi-structured data to retrieve complex queries\nincluding a combination of text and numeric information. The study concludes\nthat the use of semi-structured data tools for accessing bioinformatics\ndatabases is a viable alternative to the structured tools, though each method\nis shown to have certain inherent advantages and disadvantages.",
    "descriptor": "\nComments: 16 pages\n",
    "authors": [
      "Raja A. Moftah",
      "Abdelsalam M. Maatuk",
      "Richard White"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2202.02359"
  },
  {
    "id": "arXiv:2202.02360",
    "title": "Towards optimal sampling for learning sparse approximation in high  dimensions",
    "abstract": "In this chapter, we discuss recent work on learning sparse approximations to\nhigh-dimensional functions on data, where the target functions may be scalar-,\nvector- or even Hilbert space-valued. Our main objective is to study how the\nsampling strategy affects the sample complexity -- that is, the number of\nsamples that suffice for accurate and stable recovery -- and to use this\ninsight to obtain optimal or near-optimal sampling procedures. We consider two\nsettings. First, when a target sparse representation is known, in which case we\npresent a near-complete answer based on drawing independent random samples from\ncarefully-designed probability measures. Second, we consider the more\nchallenging scenario when such representation is unknown. In this case, while\nnot giving a full answer, we describe a general construction of sampling\nmeasures that improves over standard Monte Carlo sampling. We present examples\nusing algebraic and trigonometric polynomials, and for the former, we also\nintroduce a new procedure for function approximation on irregular (i.e.,\nnontensorial) domains. The effectiveness of this procedure is shown through\nnumerical examples. Finally, we discuss a number of structured sparsity models,\nand how they may lead to better approximations.",
    "descriptor": "",
    "authors": [
      "Ben Adcock",
      "Juan M. Cardenas",
      "Nick Dexter",
      "Sebastian Moraga"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.02360"
  },
  {
    "id": "arXiv:2202.02361",
    "title": "A Fast Network Exploration Strategy to Profile Low Energy Consumption  for Keyword Spotting",
    "abstract": "Keyword Spotting nowadays is an integral part of speech-oriented user\ninteraction targeted for smart devices. To this extent, neural networks are\nextensively used for their flexibility and high accuracy. However, coming up\nwith a suitable configuration for both accuracy requirements and hardware\ndeployment is a challenge. We propose a regression-based network exploration\ntechnique that considers the scaling of the network filters ($s$) and\nquantization ($q$) of the network layers, leading to a friendly and\nenergy-efficient configuration for FPGA hardware implementation. We experiment\nwith different combinations of $\\mathcal{NN}\\scriptstyle\\langle q,\\,s\\rangle\n\\displaystyle$ on the FPGA to profile the energy consumption of the deployed\nnetwork so that the user can choose the most energy-efficient network\nconfiguration promptly. Our accelerator design is deployed on the Xilinx AC 701\nplatform and has at least 2.1$\\times$ and 4$\\times$ improvements on energy and\nenergy efficiency results, respectively, compared to recent hardware\nimplementations for keyword spotting.",
    "descriptor": "\nComments: accepted in tinyML Research Symposium 2022\n",
    "authors": [
      "Arnab Neelim Mazumder",
      "Tinoosh Mohsenin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.02361"
  },
  {
    "id": "arXiv:2202.02363",
    "title": "A Discourse on MetODS: Meta-Optimized Dynamical Synapses for  Meta-Reinforcement Learning",
    "abstract": "Recent meta-reinforcement learning work has emphasized the importance of\nmnemonic control for agents to quickly assimilate relevant experience in new\ncontexts and suitably adapt their policy. However, what computational\nmechanisms support flexible behavioral adaptation from past experience remains\nan open question. Inspired by neuroscience, we propose MetODS (for\nMeta-Optimized Dynamical Synapses), a broadly applicable model of\nmeta-reinforcement learning which leverages fast synaptic dynamics influenced\nby action-reward feedback. We develop a theoretical interpretation of MetODS as\na model learning powerful control rules in the policy space and demonstrate\nempirically that robust reinforcement learning programs emerge spontaneously\nfrom them. We further propose a formalism which efficiently optimizes the\nmeta-parameters governing MetODS synaptic processes. In multiple experiments\nand domains, MetODS outperforms or compares favorably with previous\nmeta-reinforcement learning approaches. Our agents can perform one-shot\nlearning, approaches optimal exploration/exploitation strategies, generalize\nnavigation principles to unseen environments and demonstrate a strong ability\nto learn adaptive motor policies.",
    "descriptor": "",
    "authors": [
      "Mathieu Chalvidal",
      "Thomas Serre",
      "Rufin VanRullen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2202.02363"
  },
  {
    "id": "arXiv:2202.02365",
    "title": "Marius++: Large-Scale Training of Graph Neural Networks on a Single  Machine",
    "abstract": "Graph Neural Networks (GNNs) have emerged as a powerful model for ML over\ngraph-structured data. Yet, scalability remains a major challenge for using\nGNNs over billion-edge inputs. The creation of mini-batches used for training\nincurs computational and data movement costs that grow exponentially with the\nnumber of GNN layers as state-of-the-art models aggregate information from the\nmulti-hop neighborhood of each input node. In this paper, we focus on scalable\ntraining of GNNs with emphasis on resource efficiency. We show that out-of-core\npipelined mini-batch training in a single machine outperforms resource-hungry\nmulti-GPU solutions. We introduce Marius++, a system for training GNNs over\nbillion-scale graphs. Marius++ provides disk-optimized training for GNNs and\nintroduces a series of data organization and algorithmic contributions that 1)\nminimize the memory-footprint and end-to-end time required for training and 2)\nensure that models learned with disk-based training exhibit accuracy similar to\nthose fully trained in mixed CPU/GPU settings. We evaluate Marius++ against\nPyTorch Geometric and Deep Graph Library using seven benchmark (model, data\nset) settings and find that Marius++ with one GPU can achieve the same level of\nmodel accuracy up to 8$\\times$ faster than these systems when they are using up\nto eight GPUs. For these experiments, disk-based training allows Marius++\ndeployments to be up to 64$\\times$ cheaper in monetary cost than those of the\ncompeting systems.",
    "descriptor": "",
    "authors": [
      "Roger Waleffe",
      "Jason Mohoney",
      "Theodoros Rekatsinas",
      "Shivaram Venkataraman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2202.02365"
  },
  {
    "id": "arXiv:2202.02368",
    "title": "Convergence Analysis of Virtual Element Method for Nonlinear Nonlocal  Dynamic Plate Equation",
    "abstract": "In this article, we have considered a nonlinear nonlocal time dependent\nfourth order equation demonstrating the deformation of a thin and narrow\nrectangular plate. We propose $C^1$ conforming virtual element method (VEM) of\narbitrary order, $k\\ge2$, to approximate the model problem numerically. We\nemploy VEM to discretize the space variable and fully implicit scheme for\ntemporal variable. Well-posedness of the fully discrete scheme is proved under\ncertain conditions on the physical parameters, and we derive optimal order of\nconvergence in both space and time variable. Finally, numerical experiments are\npresented to illustrate the behaviour of the proposed numerical scheme.",
    "descriptor": "",
    "authors": [
      "D. Adak",
      "D. Mora",
      "S. Natarajan"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)"
    ],
    "url": "https://arxiv.org/abs/2202.02368"
  },
  {
    "id": "arXiv:2202.02385",
    "title": "Using Large-scale Heterogeneous Graph Representation Learning for Code  Review Recommendations",
    "abstract": "Code review is an integral part of any mature software development process,\nand identifying the best reviewer for a code change is a well accepted problem\nwithin the software engineering community. Selecting a reviewer who lacks\nexpertise and understanding can slow development or result in more defects. To\ndate, most reviewer recommendation systems rely primarily on historical file\nchange and review information; those who changed or reviewed a file in the past\nare the best positioned to review in the future. We posit that while these\napproaches are able to identify and suggest qualified reviewers, they may be\nblind to reviewers who have the needed expertise and have simply never\ninteracted with the changed files before. To address this, we present CORAL, a\nnovel approach to reviewer recommendation that leverages a socio-technical\ngraph built from the rich set of entities (developers, repositories, files,\npull requests, work-items, etc.) and their relationships in modern source code\nmanagement systems. We employ a graph convolutional neural network on this\ngraph and train it on two and a half years of history on 332 repositories. We\nshow that CORAL is able to model the manual history of reviewer selection\nremarkably well. Further, based on an extensive user study, we demonstrate that\nthis approach identifies relevant and qualified reviewers who traditional\nreviewer recommenders miss, and that these developers desire to be included in\nthe review process. Finally, we find that \"classical\" reviewer recommendation\nsystems perform better on smaller (in terms of developers) software projects\nwhile CORAL excels on larger projects, suggesting that there is \"no one model\nto rule them all.\"",
    "descriptor": "",
    "authors": [
      "Jiyang Zhang",
      "Chandra Maddila",
      "Ram Bairi",
      "Christian Bird",
      "Ujjwal Raizada",
      "Apoorva Agrawal",
      "Yamini Jhawar",
      "Kim Herzig",
      "Arie van Deursen"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.02385"
  },
  {
    "id": "arXiv:2202.02387",
    "title": "Automatic Identification of Self-Admitted Technical Debt from Different  Sources",
    "abstract": "Technical debt is a metaphor describing the situation that long-term benefits\n(e.g., maintainability and evolvability of software) are traded for short-term\ngoals. When technical debt is admitted explicitly by developers in software\nartifacts (e.g., code comments or issue tracking systems), it is termed as\nSelf-Admitted Technical Debt or SATD. Technical debt could be admitted in\ndifferent sources, such as source code comments, issue tracking systems, pull\nrequests, and commit messages. However, there is no approach proposed for\nidentifying SATD from different sources. Thus, in this paper, we propose an\napproach for automatically identifying SATD from different sources (i.e.,\nsource code comments, issue trackers, commit messages, and pull requests).",
    "descriptor": "",
    "authors": [
      "Yikun Li",
      "Mohamed Soliman",
      "Paris Avgeriou"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.02387"
  },
  {
    "id": "arXiv:2202.02389",
    "title": "The impact of feature importance methods on the interpretation of defect  classifiers",
    "abstract": "Classifier specific (CS) and classifier agnostic (CA) feature importance\nmethods are widely used (often interchangeably) by prior studies to derive\nfeature importance ranks from a defect classifier. However, different feature\nimportance methods are likely to compute different feature importance ranks\neven for the same dataset and classifier. Hence such interchangeable use of\nfeature importance methods can lead to conclusion instabilities unless there is\na strong agreement among different methods. Therefore, in this paper, we\nevaluate the agreement between the feature importance ranks associated with the\nstudied classifiers through a case study of 18 software projects and six\ncommonly used classifiers. We find that: 1) The computed feature importance\nranks by CA and CS methods do not always strongly agree with each other. 2) The\ncomputed feature importance ranks by the studied CA methods exhibit a strong\nagreement including the features reported at top-1 and top-3 ranks for a given\ndataset and classifier, while even the commonly used CS methods yield vastly\ndifferent feature importance ranks. Such findings raise concerns about the\nstability of conclusions across replicated studies. We further observe that the\ncommonly used defect datasets are rife with feature interactions and these\nfeature interactions impact the computed feature importance ranks of the CS\nmethods (not the CA methods). We demonstrate that removing these feature\ninteractions, even with simple methods like CFS improves agreement between the\ncomputed feature importance ranks of CA and CS methods. In light of our\nfindings, we provide guidelines for stakeholders and practitioners when\nperforming model interpretation and directions for future research, e.g.,\nfuture research is needed to investigate the impact of advanced feature\ninteraction removal methods on computed feature importance ranks of different\nCS methods.",
    "descriptor": "",
    "authors": [
      "Gopi Krishnan Rajbahadur",
      "Shaowei Wang",
      "Yasutaka Kamei",
      "Ahmed E. Hassan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2202.02389"
  },
  {
    "id": "arXiv:2202.02390",
    "title": "Condensation Jacobian with Adaptivity",
    "abstract": "We present a new approach that allows large time steps in dynamic\nsimulations. Our approach, ConJac, is based on condensation, a technique for\neliminating many degrees of freedom (DOFs) by expressing them in terms of the\nremaining degrees of freedom. In this work, we choose a subset of nodes to be\ndynamic nodes, and apply condensation at the velocity level by defining a\nlinear mapping from the velocities of these chosen dynamic DOFs to the\nvelocities of the remaining quasistatic DOFs. We then use this mapping to\nderive reduced equations of motion involving only the dynamic DOFs. We also\nderive a novel stabilization term that enables us to use complex nonlinear\nmaterial models. ConJac remains stable at large time steps, exhibits highly\ndynamic motion, and displays minimal numerical damping. In marked contrast to\nsubspace approaches, ConJac gives exactly the same configuration as the full\nspace approach once the static state is reached. Furthermore, ConJac can\nautomatically choose which parts of the object are to be simulated dynamically\nor quasistatically. Finally, ConJac works with a wide range of moderate to\nstiff materials, supports anisotropy and heterogeneity, handles topology\nchanges, and can be combined with existing solvers including rigid body\ndynamics.",
    "descriptor": "",
    "authors": [
      "Nicholas J. Weidner",
      "Theodore Kim",
      "Shinjiro Sueda"
    ],
    "subjectives": [
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2202.02390"
  },
  {
    "id": "arXiv:2202.02392",
    "title": "Fractional-Order Shell Theory: Formulation and Application to the  Analysis of Nonlocal Cylindrical Panels",
    "abstract": "We present a theoretical and computational framework based on fractional\ncalculus for the analysis of the nonlocal static response of cylindrical shell\npanels. The differ-integral nature of fractional derivatives allows an\nefficient and accurate methodology to account for the effect of long-range\n(nonlocal) interactions in curved structures. More specifically, the use of\nframe-invariant fractional-order kinematic relations enables a physically,\nmathematically, and thermodynamically consistent formulation to model the\nnonlocal elastic interactions. In order to evaluate the response of these\nnonlocal shells under practical scenarios involving generalized loads and\nboundary conditions, the fractional-Finite Element Method (f-FEM) is extended\nto incorporate shell elements based on the first-order shear-deformable\ndisplacement theory. Finally, numerical studies are performed exploring both\nthe linear and the geometrically nonlinear static response of nonlocal\ncylindrical shell panels. This study is intended to provide a general\nfoundation to investigate the nonlocal behavior of curved structures by means\nof fractional order models.",
    "descriptor": "",
    "authors": [
      "Sai Sidhardh",
      "Sansit Patnaik",
      "Fabio Semperlotti"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2202.02392"
  },
  {
    "id": "arXiv:2202.02393",
    "title": "Deep Dynamic Effective Connectivity Estimation from Multivariate Time  Series",
    "abstract": "Recently, methods that represent data as a graph, such as graph neural\nnetworks (GNNs) have been successfully used to learn data representations and\nstructures to solve classification and link prediction problems. The\napplications of such methods are vast and diverse, but most of the current work\nrelies on the assumption of a static graph. This assumption does not hold for\nmany highly dynamic systems, where the underlying connectivity structure is\nnon-stationary and is mostly unobserved. Using a static model in these\nsituations may result in sub-optimal performance. In contrast, modeling changes\nin graph structure with time can provide information about the system whose\napplications go beyond classification. Most work of this type does not learn\neffective connectivity and focuses on cross-correlation between nodes to\ngenerate undirected graphs. An undirected graph is unable to capture direction\nof an interaction which is vital in many fields, including neuroscience. To\nbridge this gap, we developed dynamic effective connectivity estimation via\nneural network training (DECENNT), a novel model to learn an interpretable\ndirected and dynamic graph induced by the downstream classification/prediction\ntask. DECENNT outperforms state-of-the-art (SOTA) methods on five different\ntasks and infers interpretable task-specific dynamic graphs. The dynamic graphs\ninferred from functional neuroimaging data align well with the existing\nliterature and provide additional information. Additionally, the temporal\nattention module of DECENNT identifies time-intervals crucial for predictive\ndownstream task from multivariate time series data.",
    "descriptor": "\nComments: In review at IJCNN 2022\n",
    "authors": [
      "Usman Mahmood",
      "Zening Fu",
      "Vince Calhoun",
      "Sergey Plis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.02393"
  },
  {
    "id": "arXiv:2202.02394",
    "title": "JARVix at SemEval-2022 Task 2: It Takes One to Know One? Idiomaticity  Detection using Zero and One Shot Learning",
    "abstract": "Large Language Models have been successful in a wide variety of Natural\nLanguage Processing tasks by capturing the compositionality of the text\nrepresentations. In spite of their great success, these vector representations\nfail to capture meaning of idiomatic multi-word expressions (MWEs). In this\npaper, we focus on the detection of idiomatic expressions by using binary\nclassification. We use a dataset consisting of the literal and idiomatic usage\nof MWEs in English and Portuguese. Thereafter, we perform the classification in\ntwo different settings: zero shot and one shot, to determine if a given\nsentence contains an idiom or not. N shot classification for this task is\ndefined by N number of common idioms between the training and testing sets. In\nthis paper, we train multiple Large Language Models in both the settings and\nachieve an F1 score (macro) of 0.73 for the zero shot setting and an F1 score\n(macro) of 0.85 for the one shot setting. An implementation of our work can be\nfound at\nhttps://github.com/ashwinpathak20/Idiomaticity_Detection_Using_Few_Shot_Learning .",
    "descriptor": "\nComments: Best Project Award for Georgia Tech CS 7650. Code available at this https URL\n",
    "authors": [
      "Ashwin Pathak",
      "Raj Shah",
      "Vaibhav Kumar",
      "Yash Jakhotiya"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.02394"
  },
  {
    "id": "arXiv:2202.02395",
    "title": "Malleable Agents for Re-Configurable Robotic Manipulators",
    "abstract": "Re-configurable robots potentially have more utility and flexibility for many\nreal-world tasks. Designing a learning agent to operate such robots requires\nadapting to different configurations. While deep reinforcement learning has had\nimmense success in robotic manipulation, domain adaptation is a significant\nproblem that limits its applicability to real-world robotics. We focus on\nrobotic arms with multiple rigid links connected by joints. Recent attempts\nhave performed domain adaptation and Sim2Real transfer to provide robustness to\nrobotic arm dynamics and sensor/camera variations. However, there have been no\nprevious attempts to adapt to robotic arms with a varying number of links. We\npropose an RL agent with sequence neural networks embedded in the deep neural\nnetwork to adapt to robotic arms that have a varying number of links. Further,\nwith the additional tool of domain randomization, this agent adapts to\ndifferent configurations with varying number/length of links and dynamics\nnoise. We perform simulations on a 2D N-link arm to show the ability of our\nnetwork to transfer and generalize efficiently.",
    "descriptor": "\nComments: 8 pages, 8 figures, 2 tables\n",
    "authors": [
      "Athindran Ramesh Kumar",
      "Gurudutt Hosangadi"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.02395"
  },
  {
    "id": "arXiv:2202.02396",
    "title": "A Temporal-Difference Approach to Policy Gradient Estimation",
    "abstract": "The policy gradient theorem (Sutton et al., 2000) prescribes the usage of a\ncumulative discounted state distribution under the target policy to approximate\nthe gradient. Most algorithms based on this theorem, in practice, break this\nassumption, introducing a distribution shift that can cause the convergence to\npoor solutions. In this paper, we propose a new approach of reconstructing the\npolicy gradient from the start state without requiring a particular sampling\nstrategy. The policy gradient calculation in this form can be simplified in\nterms of a gradient critic, which can be recursively estimated due to a new\nBellman equation of gradients. By using temporal-difference updates of the\ngradient critic from an off-policy data stream, we develop the first estimator\nthat sidesteps the distribution shift issue in a model-free way. We prove that,\nunder certain realizability conditions, our estimator is unbiased regardless of\nthe sampling strategy. We empirically show that our technique achieves a\nsuperior bias-variance trade-off and performance in presence of off-policy\nsamples.",
    "descriptor": "",
    "authors": [
      "Samuele Tosatto",
      "Andrew Patterson",
      "Martha White",
      "A. Rupam Mahmood"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.02396"
  },
  {
    "id": "arXiv:2202.02397",
    "title": "Textured Mesh Quality Assessment: Large-Scale Dataset and Deep  Learning-based Quality metric",
    "abstract": "Over the past decade, 3D graphics have become highly detailed to mimic the\nreal world, exploding their size and complexity and making them subject to\nlossy processing operations that may degrade their visual quality. Thus, to\nensure the best Quality of Experience (QoE), it is important to evaluate the\nvisual quality to accurately drive the processing operation to find the right\ncompromise between visual quality and data size. In this work, we evaluate the\nquality of textured 3D meshes. We first establish a large-scale quality\nassessment dataset, which includes 55 source models and over 343k distorted\nstimuli. Each model was characterized in terms of geometric, color, and\nsemantic complexity, and corrupted by combinations of 5 types of distortions\napplied on the geometry and texture of the meshes. We then propose an approach\nto select a subset of challenging stimuli from our (large-scale) dataset that\nwe annotate in a subjective experiment conducted in crowdsourcing. Leveraging\nour dataset, a learning-based quality metric for 3D graphics was proposed. Our\nmetric demonstrates state-of-the-art results on our dataset of textured meshes\nand on a dataset of distorted meshes with vertex colors. Finally, we present an\napplication of our metric to explore the influence of distortion interactions\non the perceived quality of 3D graphics.",
    "descriptor": "",
    "authors": [
      "Yana Nehm\u00e9",
      "Florent Dupont",
      "Jean-Philippe Farrugia",
      "Patrick Le Callet",
      "Guillaume Lavou\u00e9"
    ],
    "subjectives": [
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2202.02397"
  },
  {
    "id": "arXiv:2202.02398",
    "title": "Pir\u00e1: A Bilingual Portuguese-English Dataset for Question-Answering  about the Ocean",
    "abstract": "Current research in natural language processing is highly dependent on\ncarefully produced corpora. Most existing resources focus on English; some\nresources focus on languages such as Chinese and French; few resources deal\nwith more than one language. This paper presents the Pir\\'a dataset, a large\nset of questions and answers about the ocean and the Brazilian coast both in\nPortuguese and English. Pir\\'a is, to the best of our knowledge, the first QA\ndataset with supporting texts in Portuguese, and, perhaps more importantly, the\nfirst bilingual QA dataset that includes this language. The Pir\\'a dataset\nconsists of 2261 properly curated question/answer (QA) sets in both languages.\nThe QA sets were manually created based on two corpora: abstracts related to\nthe Brazilian coast and excerpts of United Nation reports about the ocean. The\nQA sets were validated in a peer-review process with the dataset contributors.\nWe discuss some of the advantages as well as limitations of Pir\\'a, as this new\nresource can support a set of tasks in NLP such as question-answering,\ninformation retrieval, and machine translation.",
    "descriptor": "\nComments: this https URL\n",
    "authors": [
      "Andr\u00e9 F. A. Paschoal",
      "Paulo Pirozelli",
      "Valdinei Freire",
      "Karina V. Delgado",
      "Sarajane M. Peres",
      "Marcos M. Jos\u00e9",
      "Fl\u00e1vio Nakasato",
      "Andr\u00e9 S. Oliveira",
      "Anarosa A. F. Brand\u00e3o",
      "Anna H. R. Costa",
      "Fabio G. Cozman"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.02398"
  },
  {
    "id": "arXiv:2202.02403",
    "title": "Self-Adaptive Forecasting for Improved Deep Learning on Non-Stationary  Time-Series",
    "abstract": "Real-world time-series datasets often violate the assumptions of standard\nsupervised learning for forecasting -- their distributions evolve over time,\nrendering the conventional training and model selection procedures suboptimal.\nIn this paper, we propose a novel method, Self-Adaptive Forecasting (SAF), to\nmodify the training of time-series forecasting models to improve their\nperformance on forecasting tasks with such non-stationary time-series data. SAF\nintegrates a self-adaptation stage prior to forecasting based on `backcasting',\ni.e. predicting masked inputs backward in time. This is a form of test-time\ntraining that creates a self-supervised learning problem on test samples before\nperforming the prediction task. In this way, our method enables efficient\nadaptation of encoded representations to evolving distributions, leading to\nsuperior generalization. SAF can be integrated with any canonical\nencoder-decoder based time-series architecture such as recurrent neural\nnetworks or attention-based architectures. On synthetic and real-world datasets\nin domains where time-series data are known to be notoriously non-stationary,\nsuch as healthcare and finance, we demonstrate a significant benefit of SAF in\nimproving forecasting accuracy.",
    "descriptor": "",
    "authors": [
      "Sercan O. Arik",
      "Nathanael C. Yoder",
      "Tomas Pfister"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.02403"
  },
  {
    "id": "arXiv:2202.02404",
    "title": "Model-Free Reinforcement Learning for Symbolic Automata-encoded  Objectives",
    "abstract": "Reinforcement learning (RL) is a popular approach for robotic path planning\nin uncertain environments. However, the control policies trained for an RL\nagent crucially depend on user-defined, state-based reward functions. Poorly\ndesigned rewards can lead to policies that do get maximal rewards but fail to\nsatisfy desired task objectives or are unsafe. There are several examples of\nthe use of formal languages such as temporal logics and automata to specify\nhigh-level task specifications for robots (in lieu of Markovian rewards).\nRecent efforts have focused on inferring state-based rewards from formal\nspecifications; here, the goal is to provide (probabilistic) guarantees that\nthe policy learned using RL (with the inferred rewards) satisfies the\nhigh-level formal specification. A key drawback of several of these techniques\nis that the rewards that they infer are sparse: the agent receives positive\nrewards only upon completion of the task and no rewards otherwise. This\nnaturally leads to poor convergence properties and high variance during RL. In\nthis work, we propose using formal specifications in the form of symbolic\nautomata: these serve as a generalization of both bounded-time temporal\nlogic-based specifications as well as automata. Furthermore, our use of\nsymbolic automata allows us to define non-sparse potential-based rewards which\nempirically shape the reward surface, leading to better convergence during RL.\nWe also show that our potential-based rewarding strategy still allows us to\nobtain the policy that maximizes the satisfaction of the given specification.",
    "descriptor": "",
    "authors": [
      "Anand Balakrishnan",
      "Stefan Jaksic",
      "Edgar Aguilar Lozano",
      "Dejan Nickovic",
      "Jyotirmoy Deshmukh"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.02404"
  },
  {
    "id": "arXiv:2202.02405",
    "title": "BAM: Bayes with Adaptive Memory",
    "abstract": "Online learning via Bayes' theorem allows new data to be continuously\nintegrated into an agent's current beliefs. However, a naive application of\nBayesian methods in non-stationary environments leads to slow adaptation and\nresults in state estimates that may converge confidently to the wrong parameter\nvalue. A common solution when learning in changing environments is to\ndiscard/downweight past data; however, this simple mechanism of \"forgetting\"\nfails to account for the fact that many real-world environments involve\nrevisiting similar states. We propose a new framework, Bayes with Adaptive\nMemory (BAM), that takes advantage of past experience by allowing the agent to\nchoose which past observations to remember and which to forget. We demonstrate\nthat BAM generalizes many popular Bayesian update rules for non-stationary\nenvironments. Through a variety of experiments, we demonstrate the ability of\nBAM to continuously adapt in an ever-changing world.",
    "descriptor": "\nComments: International Conference on Learning Representations (ICLR), 2022\n",
    "authors": [
      "Josue Nassar",
      "Jennifer Brennan",
      "Ben Evans",
      "Kendall Lowrey"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.02405"
  },
  {
    "id": "arXiv:2202.02406",
    "title": "Parameter-free Online Linear Optimization with Side Information via  Universal Coin Betting",
    "abstract": "A class of parameter-free online linear optimization algorithms is proposed\nthat harnesses the structure of an adversarial sequence by adapting to some\nside information. These algorithms combine the reduction technique of Orabona\nand P{\\'a}l (2016) for adapting coin betting algorithms for online linear\noptimization with universal compression techniques in information theory for\nincorporating sequential side information to coin betting. Concrete examples\nare studied in which the side information has a tree structure and consists of\nquantized values of the previous symbols of the adversarial sequence, including\nfixed-order and variable-order Markov cases. By modifying the context-tree\nweighting technique of Willems, Shtarkov, and Tjalkens (1995), the proposed\nalgorithm is further refined to achieve the best performance over all adaptive\nalgorithms with tree-structured side information of a given maximum order in a\ncomputationally efficient manner.",
    "descriptor": "\nComments: 23 pages, 5 figures, to appear at AISTATS 2022\n",
    "authors": [
      "J. Jon Ryu",
      "Alankrita Bhatt",
      "Young-Han Kim"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2202.02406"
  },
  {
    "id": "arXiv:2202.02411",
    "title": "A Novel Service Deployment Policy in Fog Computing Considering The  Degree of Availability and Fog Landscape Utilization Using Multiobjective  Evolutionary Algorithms",
    "abstract": "Fog computing is a promising paradigm for real-time and mission-critical\nInternet of Things (IoT) applications. Regarding the high distribution,\nheterogeneity, and limitation of fog resources, applications should be placed\nin a distributed manner to fully utilize these resources. In this paper, we\npropose a linear formulation for assuring the different availability\nrequirements of application services while maximizing the utilization of fog\nresources. We also compare three multiobjective evolutionary algorithms, namely\nMOPSO, NSGA-II, and MOEA/D for a trade-off between the mentioned optimization\ngoals. The evaluation results in the iFogSim simulator demonstrate the\nefficiency of all three algorithms and a generally better behavior of MOPSO\nalgorithm in terms of obtained objective values, application deadline\nsatisfaction, and execution time.",
    "descriptor": "",
    "authors": [
      "Maryam Eslami",
      "Mehdi Sakhaei"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2202.02411"
  },
  {
    "id": "arXiv:2202.02415",
    "title": "On the Efficiency and Quality of Protection of Preprovisioning in  Elastic Optical Networks",
    "abstract": "The study of protection techniques, such as pre-provisioning (off-line) and\nprovisioning (on-line), has been explored in several ways in the optical\nnetwork literature. In the new Elastic Optical Network (EON) paradigm, the\npre-provisioning techniques were still little explored. Preprovisioning implies\nthe prior allocation of resources in the network for the transport and\nprotection of future connection demands, while the provisioning implies the\nallocation of resources when the demand arrives in the network. Applying\npreprovisioning reduces the downtime experienced by a connection after a\nfailure, which will reduce unavailability and potentially avoid penalties for\nviolation of Service Level Agreements (SLA) established with client networks.\nThis work aims to explore the main protection techniques and evaluate their\nefficient in the EON scenario. The performance evaluation show that the use of\npreprovisioning techniques are more efficient, significantly reducing the\nnetwork unavailability and bandwidth usage in EON networks. Our solution has an\nunavailability 40 times lower than shared solutions being only 4% above the\noptimum.",
    "descriptor": "",
    "authors": [
      "Paulo Jos\u00e9 S. J\u00fanior",
      "Lucas R. Costa",
      "Andr\u00e9 C. Drummond"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2202.02415"
  },
  {
    "id": "arXiv:2202.02418",
    "title": "StandardSim: A Synthetic Dataset For Retail Environments",
    "abstract": "Autonomous checkout systems rely on visual and sensory inputs to carry out\nfine-grained scene understanding in retail environments. Retail environments\npresent unique challenges compared to typical indoor scenes owing to the vast\nnumber of densely packed, unique yet similar objects. The problem becomes even\nmore difficult when only RGB input is available, especially for data-hungry\ntasks such as instance segmentation. To address the lack of datasets for\nretail, we present StandardSim, a large-scale photorealistic synthetic dataset\nfeaturing annotations for semantic segmentation, instance segmentation, depth\nestimation, and object detection. Our dataset provides multiple views per\nscene, enabling multi-view representation learning. Further, we introduce a\nnovel task central to autonomous checkout called change detection, requiring\npixel-level classification of takes, puts and shifts in objects over time. We\nbenchmark widely-used models for segmentation and depth estimation on our\ndataset, show that our test set constitutes a difficult benchmark compared to\ncurrent smaller-scale datasets and that our training set provides models with\ncrucial information for autonomous checkout tasks.",
    "descriptor": "\nComments: ICIAP 2022\n",
    "authors": [
      "Cristina Mata",
      "Nick Locascio",
      "Mohammed Azeem Sheikh",
      "Kenny Kihara",
      "Dan Fischetti"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.02418"
  },
  {
    "id": "arXiv:2202.02419",
    "title": "Learning a Discrete Set of Optimal Allocation Rules in Queueing Systems  with Unknown Service Rates",
    "abstract": "We study learning-based admission control for a classical Erlang-B blocking\nsystem with unknown service rate, i.e., an $M/M/k/k$ queueing system. At every\njob arrival, a dispatcher decides to assign the job to an available server or\nto block it. Every served job yields a fixed reward for the dispatcher, but it\nalso results in a cost per unit time of service. Our goal is to design a\ndispatching policy that maximizes the long-term average reward for the\ndispatcher based on observing the arrival times and the state of the system at\neach arrival; critically, the dispatcher observes neither the service times nor\ndeparture times.\nWe develop our learning-based dispatch scheme as a parametric learning\nproblem a'la self-tuning adaptive control. In our problem, certainty equivalent\ncontrol switches between an always admit policy (always explore) and a never\nadmit policy (immediately terminate learning), which is distinct from the\nadaptive control literature. Our learning scheme then uses maximum likelihood\nestimation followed by certainty equivalent control but with judicious use of\nthe always admit policy so that learning doesn't stall. We prove that for all\nservice rates, the proposed policy asymptotically learns to take the optimal\naction. Further, we also present finite-time regret guarantees for our scheme.\nThe extreme contrast in the certainty equivalent optimal control policies leads\nto difficulties in learning that show up in our regret bounds for different\nparameter regimes. We explore this aspect in our simulations and also follow-up\nsampling related questions for our continuous-time system.",
    "descriptor": "",
    "authors": [
      "Saghar Adler",
      "Mehrdad Moharrami",
      "Vijay Subramanian"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.02419"
  },
  {
    "id": "arXiv:2202.02423",
    "title": "Improved Information Theoretic Generalization Bounds for Distributed and  Federated Learning",
    "abstract": "We consider information-theoretic bounds on expected generalization error for\nstatistical learning problems in a networked setting. In this setting, there\nare $K$ nodes, each with its own independent dataset, and the models from each\nnode have to be aggregated into a final centralized model. We consider both\nsimple averaging of the models as well as more complicated multi-round\nalgorithms. We give upper bounds on the expected generalization error for a\nvariety of problems, such as those with Bregman divergence or Lipschitz\ncontinuous losses, that demonstrate an improved dependence of $1/K$ on the\nnumber of nodes. These \"per node\" bounds are in terms of the mutual information\nbetween the training dataset and the trained weights at each node, and are\ntherefore useful in describing the generalization properties inherent to having\ncommunication or privacy constraints at each node.",
    "descriptor": "",
    "authors": [
      "L. P. Barnes",
      "Alex Dytso",
      "H. V. Poor"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.02423"
  },
  {
    "id": "arXiv:2202.02426",
    "title": "The influence of labeling techniques in classifying human manipulation  movement of different speed",
    "abstract": "In this work, we investigate the influence of labeling methods on the\nclassification of human movements on data recorded using a marker-based motion\ncapture system. The dataset is labeled using two different approaches, one\nbased on video data of the movements, the other based on the movement\ntrajectories recorded using the motion capture system. The dataset is labeled\nusing two different approaches, one based on video data of the movements, the\nother based on the movement trajectories recorded using the motion capture\nsystem. The data was recorded from one participant performing a stacking\nscenario comprising simple arm movements at three different speeds (slow,\nnormal, fast). Machine learning algorithms that include k-Nearest Neighbor,\nRandom Forest, Extreme Gradient Boosting classifier, Convolutional Neural\nnetworks (CNN), Long Short-Term Memory networks (LSTM), and a combination of\nCNN-LSTM networks are compared on their performance in recognition of these arm\nmovements. The models were trained on actions performed on slow and normal\nspeed movements segments and generalized on actions consisting of fast-paced\nhuman movement. It was observed that all the models trained on normal-paced\ndata labeled using trajectories have almost 20% improvement in accuracy on test\ndata in comparison to the models trained on data labeled using videos of the\nperformed experiments.",
    "descriptor": "",
    "authors": [
      "Sadique Adnan Siddiqui",
      "Lisa Gutzeit",
      "Frank Kirchner"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.02426"
  },
  {
    "id": "arXiv:2202.02427",
    "title": "Lightweight Compositional Embeddings for Incremental Streaming  Recommendation",
    "abstract": "Most work in graph-based recommender systems considers a {\\em static} setting\nwhere all information about test nodes (i.e., users and items) is available\nupfront at training time. However, this static setting makes little sense for\nmany real-world applications where data comes in continuously as a stream of\nnew edges and nodes, and one has to update model predictions incrementally to\nreflect the latest state. To fully capitalize on the newly available data in\nthe stream, recent graph-based recommendation models would need to be\nrepeatedly retrained, which is infeasible in practice.\nIn this paper, we study the graph-based streaming recommendation setting and\npropose a compositional recommendation model -- Lightweight Compositional\nEmbedding (LCE) -- that supports incremental updates under low computational\ncost. Instead of learning explicit embeddings for the full set of nodes, LCE\nlearns explicit embeddings for only a subset of nodes and represents the other\nnodes {\\em implicitly}, through a composition function based on their\ninteractions in the graph. This provides an effective, yet efficient, means to\nleverage streaming graph data when one node type (e.g., items) is more amenable\nto static representation. We conduct an extensive empirical study to compare\nLCE to a set of competitive baselines on three large-scale user-item\nrecommendation datasets with interactions under a streaming setting. The\nresults demonstrate the superior performance of LCE, showing that it achieves\nnearly skyline performance with significantly fewer parameters than alternative\ngraph-based models.",
    "descriptor": "",
    "authors": [
      "Mengyue Hang",
      "Tobias Schnabel",
      "Longqi Yang",
      "Jennifer Neville"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.02427"
  },
  {
    "id": "arXiv:2202.02429",
    "title": "Verifying Inverse Model Neural Networks",
    "abstract": "Inverse problems exist in a wide variety of physical domains from aerospace\nengineering to medical imaging. The goal is to infer the underlying state from\na set of observations. When the forward model that produced the observations is\nnonlinear and stochastic, solving the inverse problem is very challenging.\nNeural networks are an appealing solution for solving inverse problems as they\ncan be trained from noisy data and once trained are computationally efficient\nto run. However, inverse model neural networks do not have guarantees of\ncorrectness built-in, which makes them unreliable for use in safety and\naccuracy-critical contexts. In this work we introduce a method for verifying\nthe correctness of inverse model neural networks. Our approach is to\noverapproximate a nonlinear, stochastic forward model with piecewise linear\nconstraints and encode both the overapproximate forward model and the neural\nnetwork inverse model as a mixed-integer program. We demonstrate this\nverification procedure on a real-world airplane fuel gauge case study. The\nability to verify and consequently trust inverse model neural networks allows\ntheir use in a wide variety of contexts, from aerospace to medicine.",
    "descriptor": "",
    "authors": [
      "Chelsea Sidrane",
      "Sydney Katz",
      "Anthony Corso",
      "Mykel J. Kochenderfer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2202.02429"
  },
  {
    "id": "arXiv:2202.02430",
    "title": "HENRI: High Efficiency Negotiation-based Robust Interface for  Multi-party Multi-issue Negotiation over the Internet",
    "abstract": "This paper proposes a framework for a full fledged negotiation system that\nallows multi party multi issue negotiation. It focuses on the negotiation\nprotocol to be observed and provides a platform for concurrent and independent\nnegotiation on individual issues using the concept of multi threading. It\ndepicts the architecture of an agent detailing its components. The paper sets\nforth a hierarchical pattern for the multiple issues concerning every party.\nThe system also provides enhancements such as the time-to-live counters for\nevery advertisement, refinement of utility considering non-functional\nattributes, prioritization of issues, by assigning weights to issues.",
    "descriptor": "\nComments: CUBE '12: Proceedings of the CUBE International Information Technology Conference. arXiv admin note: substantial text overlap with arXiv:1206.5884\n",
    "authors": [
      "Saurabh Deochake",
      "Shashank Kanth",
      "Subhadip Chakraborty",
      "Suresh Sarode",
      "Vidyasagar Potdar",
      "Debajyoti Mukhopadhyay"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2202.02430"
  },
  {
    "id": "arXiv:2202.02431",
    "title": "On Universal Portfolios with Continuous Side Information",
    "abstract": "A new portfolio selection strategy that adapts to a continuous\nside-information sequence is presented, with a universal wealth guarantee\nagainst a class of state-constant rebalanced portfolios with respect to a state\nfunction that maps each side-information symbol to a finite set of states. In\nparticular, given that a state function belongs to a collection of functions of\nfinite Natarajan dimension, the proposed strategy is shown to achieve,\nasymptotically to first order in the exponent, the same wealth as the best\nstate-constant rebalanced portfolio with respect to the best state function,\nchosen in hindsight from observed market. This result can be viewed as an\nextension of the seminal work of Cover and Ordentlich (1996) that assumes a\nsingle state function.",
    "descriptor": "",
    "authors": [
      "Alankrita Bhatt",
      "J. Jon Ryu",
      "Young-Han Kim"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.02431"
  },
  {
    "id": "arXiv:2202.02432",
    "title": "Transformers and the representation of biomedical background knowledge",
    "abstract": "BioBERT and BioMegatron are Transformers models adapted for the biomedical\ndomain based on publicly available biomedical corpora. As such, they have the\npotential to encode large-scale biological knowledge. We investigate the\nencoding and representation of biological knowledge in these models, and its\npotential utility to support inference in cancer precision medicine - namely,\nthe interpretation of the clinical significance of genomic alterations. We\ncompare the performance of different transformer baselines; we use probing to\ndetermine the consistency of encodings for distinct entities; and we use\nclustering methods to compare and contrast the internal properties of the\nembeddings for genes, variants, drugs and diseases. We show that these models\ndo indeed encode biological knowledge, although some of this is lost in\nfine-tuning for specific tasks. Finally, we analyse how the models behave with\nregard to biases and imbalances in the dataset.",
    "descriptor": "\nComments: 22 pages, 12 figures, supplementary methods, tables and figures at the end of the manuscript\n",
    "authors": [
      "Oskar Wysocki",
      "Zili Zhou",
      "Paul O'Regan",
      "Deborah Ferreira",
      "Magdalena Wysocka",
      "D\u00f3nal Landers",
      "Andr\u00e9 Freitas"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.02432"
  },
  {
    "id": "arXiv:2202.02433",
    "title": "SMODICE: Versatile Offline Imitation Learning via State Occupancy  Matching",
    "abstract": "We propose State Matching Offline DIstribution Correction Estimation\n(SMODICE), a novel and versatile algorithm for offline imitation learning (IL)\nvia state-occupancy matching. We show that the SMODICE objective admits a\nsimple optimization procedure through an application of Fenchel duality and an\nanalytic solution in tabular MDPs. Without requiring access to expert actions,\nSMODICE can be effectively applied to three offline IL settings: (i) imitation\nfrom observations (IfO), (ii) IfO with dynamics or morphologically mismatched\nexpert, and (iii) example-based reinforcement learning, which we show can be\nformulated as a state-occupancy matching problem. We extensively evaluate\nSMODICE on both gridworld environments as well as on high-dimensional offline\nbenchmarks. Our results demonstrate that SMODICE is effective for all three\nproblem settings and significantly outperforms prior state-of-art.",
    "descriptor": "\nComments: Project website: this https URL\n",
    "authors": [
      "Yecheng Jason Ma",
      "Andrew Shen",
      "Dinesh Jayaraman",
      "Osbert Bastani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.02433"
  },
  {
    "id": "arXiv:2202.02435",
    "title": "On Neural Differential Equations",
    "abstract": "The conjoining of dynamical systems and deep learning has become a topic of\ngreat interest. In particular, neural differential equations (NDEs) demonstrate\nthat neural networks and differential equation are two sides of the same coin.\nTraditional parameterised differential equations are a special case. Many\npopular neural network architectures, such as residual networks and recurrent\nnetworks, are discretisations.\nNDEs are suitable for tackling generative problems, dynamical systems, and\ntime series (particularly in physics, finance, ...) and are thus of interest to\nboth modern machine learning and traditional mathematical modelling. NDEs offer\nhigh-capacity function approximation, strong priors on model space, the ability\nto handle irregular data, memory efficiency, and a wealth of available theory\non both sides.\nThis doctoral thesis provides an in-depth survey of the field.\nTopics include: neural ordinary differential equations (e.g. for hybrid\nneural/mechanistic modelling of physical systems); neural controlled\ndifferential equations (e.g. for learning functions of irregular time series);\nand neural stochastic differential equations (e.g. to produce generative models\ncapable of representing complex stochastic dynamics, or sampling from complex\nhigh-dimensional distributions).\nFurther topics include: numerical methods for NDEs (e.g. reversible\ndifferential equations solvers, backpropagation through differential equations,\nBrownian reconstruction); symbolic regression for dynamical systems (e.g. via\nregularised evolution); and deep implicit models (e.g. deep equilibrium models,\ndifferentiable optimisation).\nWe anticipate this thesis will be of interest to anyone interested in the\nmarriage of deep learning with dynamical systems, and hope it will provide a\nuseful reference for the current state of the art.",
    "descriptor": "\nComments: Doctoral thesis, Mathematical Institute, University of Oxford. 231 pages\n",
    "authors": [
      "Patrick Kidger"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Classical Analysis and ODEs (math.CA)",
      "Dynamical Systems (math.DS)",
      "Numerical Analysis (math.NA)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.02435"
  },
  {
    "id": "arXiv:2202.02436",
    "title": "Neural Logic Analogy Learning",
    "abstract": "Letter-string analogy is an important analogy learning task which seems to be\neasy for humans but very challenging for machines. The main idea behind current\napproaches to solving letter-string analogies is to design heuristic rules for\nextracting analogy structures and constructing analogy mappings. However, one\nkey problem is that it is difficult to build a comprehensive and exhaustive set\nof analogy structures which can fully describe the subtlety of analogies. This\nproblem makes current approaches unable to handle complicated letter-string\nanalogy problems. In this paper, we propose Neural logic analogy learning\n(Noan), which is a dynamic neural architecture driven by differentiable logic\nreasoning to solve analogy problems. Each analogy problem is converted into\nlogical expressions consisting of logical variables and basic logical\noperations (AND, OR, and NOT). More specifically, Noan learns the logical\nvariables as vector embeddings and learns each logical operation as a neural\nmodule. In this way, the model builds computational graph integrating neural\nnetwork with logical reasoning to capture the internal logical structure of the\ninput letter strings. The analogy learning problem then becomes a True/False\nevaluation problem of the logical expressions. Experiments show that our\nmachine learning-based Noan approach outperforms state-of-the-art approaches on\nstandard letter-string analogy benchmark datasets.",
    "descriptor": "\nComments: 11 pages, 1 figure, 3 tables\n",
    "authors": [
      "Yujia Fan",
      "Yongfeng Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2202.02436"
  },
  {
    "id": "arXiv:2202.02440",
    "title": "Zero Experience Required: Plug & Play Modular Transfer Learning for  Semantic Visual Navigation",
    "abstract": "In reinforcement learning for visual navigation, it is common to develop a\nmodel for each new task, and train that model from scratch with task-specific\ninteractions in 3D environments. However, this process is expensive; massive\namounts of interactions are needed for the model to generalize well. Moreover,\nthis process is repeated whenever there is a change in the task type or the\ngoal modality. We present a unified approach to visual navigation using a novel\nmodular transfer learning model. Our model can effectively leverage its\nexperience from one source task and apply it to multiple target tasks (e.g.,\nObjectNav, RoomNav, ViewNav) with various goal modalities (e.g., image, sketch,\naudio, label). Furthermore, our model enables zero-shot experience learning,\nwhereby it can solve the target tasks without receiving any task-specific\ninteractive training. Our experiments on multiple photorealistic datasets and\nchallenging tasks show that our approach learns faster, generalizes better, and\noutperforms SoTA models by a significant margin.",
    "descriptor": "",
    "authors": [
      "Ziad Al-Halah",
      "Santhosh K. Ramakrishnan",
      "Kristen Grauman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.02440"
  },
  {
    "id": "arXiv:2202.02441",
    "title": "SEED: Sound Event Early Detection via Evidential Uncertainty",
    "abstract": "Sound Event Early Detection (SEED) is an essential task in recognizing the\nacoustic environments and soundscapes. However, most of the existing methods\nfocus on the offline sound event detection, which suffers from the\nover-confidence issue of early-stage event detection and usually yield\nunreliable results. To solve the problem, we propose a novel Polyphonic\nEvidential Neural Network (PENet) to model the evidential uncertainty of the\nclass probability with Beta distribution. Specifically, we use a Beta\ndistribution to model the distribution of class probabilities, and the\nevidential uncertainty enriches uncertainty representation with evidence\ninformation, which plays a central role in reliable prediction. To further\nimprove the event detection performance, we design the backtrack inference\nmethod that utilizes both the forward and backward audio features of an ongoing\nevent. Experiments on the DESED database show that the proposed method can\nsimultaneously improve 13.0\\% and 3.8\\% in time delay and detection F1 score\ncompared to the state-of-the-art methods.",
    "descriptor": "\nComments: ICASSP 2022\n",
    "authors": [
      "Xujiang Zhao",
      "Xuchao Zhang",
      "Wei Cheng",
      "Wenchao Yu",
      "Yuncong Chen",
      "Haifeng Chen",
      "Feng Chen"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2202.02441"
  },
  {
    "id": "arXiv:2202.02442",
    "title": "Transfer Reinforcement Learning for Differing Action Spaces via  Q-Network Representations",
    "abstract": "Transfer learning approaches in reinforcement learning aim to assist agents\nin learning their target domains by leveraging the knowledge learned from other\nagents that have been trained on similar source domains. For example, recent\nresearch focus within this space has been placed on knowledge transfer between\ntasks that have different transition dynamics and reward functions; however,\nlittle focus has been placed on knowledge transfer between tasks that have\ndifferent action spaces. In this paper, we approach the task of transfer\nlearning between domains that differ in action spaces. We present a reward\nshaping method based on source embedding similarity that is applicable to\ndomains with both discrete and continuous action spaces. The efficacy of our\napproach is evaluated on transfer to restricted action spaces in the Acrobot-v1\nand Pendulum-v0 domains (Brockman et al. 2016). A comparison with two baselines\nshows that our method does not outperform these baselines in these continuous\naction spaces but does show an improvement in these discrete action spaces. We\nconclude our analysis with future directions for this work.",
    "descriptor": "\nComments: 5 pages, 2 figures, 1 table\n",
    "authors": [
      "Nathan Beck",
      "Abhiramon Rajasekharan",
      "Trung Hieu Tran"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.02442"
  },
  {
    "id": "arXiv:2202.02444",
    "title": "Spelunking the Deep: Guaranteed Queries for General Neural Implicit  Surfaces",
    "abstract": "Neural implicit representations, which encode a surface as the level set of a\nneural network applied to spatial coordinates, have proven to be remarkably\neffective for optimizing, compressing, and generating 3D geometry. Although\nthese representations are easy to fit, it is not clear how to best evaluate\ngeometric queries on the shape, such as intersecting against a ray or finding a\nclosest point. The predominant approach is to encourage the network to have a\nsigned distance property. However, this property typically holds only\napproximately, leading to robustness issues, and holds only at the conclusion\nof training, inhibiting the use of queries in loss functions. Instead, this\nwork presents a new approach to perform queries directly on general neural\nimplicit functions for a wide range of existing architectures. Our key tool is\nthe application of range analysis to neural networks, using automatic\narithmetic rules to bound the output of a network over a region; we conduct a\nstudy of range analysis on neural networks, and identify variants of affine\narithmetic which are highly effective. We use the resulting bounds to develop\ngeometric queries including ray casting, intersection testing, constructing\nspatial hierarchies, fast mesh extraction, closest-point evaluation, evaluating\nbulk properties, and more. Our queries can be efficiently evaluated on GPUs,\nand offer concrete accuracy guarantees even on randomly-initialized networks,\nenabling their use in training objectives and beyond. We also show a\npreliminary application to inverse rendering.",
    "descriptor": "",
    "authors": [
      "Nicholas Sharp",
      "Alec Jacobson"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.02444"
  },
  {
    "id": "arXiv:2202.02446",
    "title": "Adversarially Trained Actor Critic for Offline Reinforcement Learning",
    "abstract": "We propose Adversarially Trained Actor Critic (ATAC), a new model-free\nalgorithm for offline reinforcement learning under insufficient data coverage,\nbased on a two-player Stackelberg game framing of offline RL: A policy actor\ncompetes against an adversarially trained value critic, who finds\ndata-consistent scenarios where the actor is inferior to the data-collection\nbehavior policy. We prove that, when the actor attains no regret in the\ntwo-player game, running ATAC produces a policy that provably 1) outperforms\nthe behavior policy over a wide range of hyperparameters, and 2) competes with\nthe best policy covered by data with appropriately chosen hyperparameters.\nCompared with existing works, notably our framework offers both theoretical\nguarantees for general function approximation and a deep RL implementation\nscalable to complex environments and large datasets. In the D4RL benchmark,\nATAC consistently outperforms state-of-the-art offline RL algorithms on a range\nof continuous control tasks",
    "descriptor": "",
    "authors": [
      "Ching-An Cheng",
      "Tengyang Xie",
      "Nan Jiang",
      "Alekh Agarwal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.02446"
  },
  {
    "id": "arXiv:2202.02448",
    "title": "Linear Model with Local Differential Privacy",
    "abstract": "Scientific collaborations benefit from collaborative learning of distributed\nsources, but remain difficult to achieve when data are sensitive. In recent\nyears, privacy preserving techniques have been widely studied to analyze\ndistributed data across different agencies while protecting sensitive\ninformation. Secure multiparty computation has been widely studied for privacy\nprotection with high privacy level but intense computation cost. There are also\nother security techniques sacrificing partial data utility to reduce disclosure\nrisk. A major challenge is to balance data utility and disclosure risk while\nmaintaining high computation efficiency. In this paper, matrix masking\ntechnique is applied to encrypt data such that the secure schemes are against\nmalicious adversaries while achieving local differential privacy. The proposed\nschemes are designed for linear models and can be implemented for both vertical\nand horizontal partitioning scenarios. Moreover, cross validation is studied to\nprevent overfitting and select optimal parameters without additional\ncommunication cost. Simulation results present the efficiency of proposed\nschemes to analyze dataset with millions of records and high-dimensional data\n(n << p).",
    "descriptor": "",
    "authors": [
      "Guanhong Miao",
      "A. Adam Ding",
      "Samuel S. Wu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.02448"
  },
  {
    "id": "arXiv:2202.02451",
    "title": "Age of Information-based Scheduling for Wireless D2D Systems with a Deep  Learning Approach",
    "abstract": "Device-to-device (D2D) links scheduling for avoiding excessive interference\nis critical to the success of wireless D2D communications. Most of the\ntraditional scheduling schemes only consider the maximum throughput or fairness\nof the system and do not consider the freshness of information. In this paper,\nwe propose a novel D2D links scheduling scheme to optimize an age of\ninformation (AoI) and throughput jointly scheduling problem when D2D links\ntransmit packets under the last-come-first-serve policy with packet-replacement\n(LCFS-PR). It is motivated by the fact that the maximum throughput scheduling\nmay reduce the activation probability of links with poor channel conditions,\nwhich results in terrible AoI performance. Specifically, We derive the\nexpression of the overall average AoI and throughput of the network under the\nspatio-temporal interfering queue dynamics with the mean-field assumption.\nMoreover, a neural network structure is proposed to learn the mapping from the\ngeographic location to the optimal scheduling parameters under a stationary\nrandomized policy, where the scheduling decision can be made without estimating\nthe channel state information(CSI) after the neural network is well-trained. To\novercome the problem that implicit loss functions cannot be back-propagated, we\nderive a numerical solution of the gradient. Finally, numerical results reveal\nthat the performance of the deep learning approach is close to that of a local\noptimal algorithm which has a higher computational complexity. The trade-off\ncurve of AoI and throughput is also obtained, where the AoI tends to infinity\nwhen throughput is maximized.",
    "descriptor": "\nComments: to appear in IEEE Transactions on Green Communications and Networking\n",
    "authors": [
      "Ling Luo",
      "Zhenyu Liu",
      "Zhiyong Chen",
      "Min Hua",
      "Wenqing Li",
      "Bin Xia"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.02451"
  },
  {
    "id": "arXiv:2202.02452",
    "title": "Security-Aware Virtual Network Embedding Algorithm based on  Reinforcement Learning",
    "abstract": "Virtual network embedding (VNE) algorithm is always the key problem in\nnetwork virtualization (NV) technology. At present, the research in this field\nstill has the following problems. The traditional way to solve VNE problem is\nto use heuristic algorithm. However, this method relies on manual embedding\nrules, which does not accord with the actual situation of VNE. In addition, as\nthe use of intelligent learning algorithm to solve the problem of VNE has\nbecome a trend, this method is gradually outdated. At the same time, there are\nsome security problems in VNE. However, there is no intelligent algorithm to\nsolve the security problem of VNE. For this reason, this paper proposes a\nsecurity-aware VNE algorithm based on reinforcement learning (RL). In the\ntraining phase, we use a policy network as a learning agent and take the\nextracted attributes of the substrate nodes to form a feature matrix as input.\nThe learning agent is trained in this environment to get the mapping\nprobability of each substrate node. In the test phase, we map nodes according\nto the mapping probability and use the breadth-first strategy (BFS) to map\nlinks. For the security problem, we add security requirements level constraint\nfor each virtual node and security level constraint for each substrate node.\nVirtual nodes can only be embedded on substrate nodes that are not lower than\nthe level of security requirements. Experimental results show that the proposed\nalgorithm is superior to other typical algorithms in terms of long-term average\nreturn, long-term revenue consumption ratio and virtual network request (VNR)\nacceptance rate.",
    "descriptor": "",
    "authors": [
      "Peiying Zhang",
      "Chao Wang",
      "Chunxiao Jiang",
      "Abderrahim Benslimane"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.02452"
  },
  {
    "id": "arXiv:2202.02453",
    "title": "Vehicular Visible Light Communications for Automated Valet Parking",
    "abstract": "Visible light communication (VLC) is a promising Optical Wireless\nCommunications (OWC) scheme that is demonstrated to provide secure,\nline-of-sight (LoS), and short-distance vehicle-to-vehicle (V2V) and\nvehicle-to-infrastructure(V2I) communications. Recently, automated driving\napplications, supported by V2I links are proposed to increase the reliability\nof the autonomous vehicles. To this regard, we propose a VLCbased V2I scheme to\nincrease the V2I communication redundancy of autonomous valet parking (AVP)\napplications, through jam-free and location-based characteristics of VLC. In\nthis paper, we demonstrate a novel architecture to support indoor\nparking-garage online-map update with vehicle on-board data transmissions and\nlocation-based map update dissemination through bidirectional VLC\ncommunications. The proposed system yields error-free LoS transmissions with\nDirect Current Biased Optical OFDM (DCO-OFDM) up to 33 m transmitter-receiver\ndistance enabling vehicle CAN Bus data, infrastructure camera video, and LIDAR\npoint cloud data sharing in an indoor parking garage.",
    "descriptor": "\nComments: 2 pages, 2 figures, 1 table\n",
    "authors": [
      "Bugra Turan",
      "Ali Uyrus",
      "Osman Nuri Koc",
      "Emrah Kar",
      "Sinem Coleri"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2202.02453"
  },
  {
    "id": "arXiv:2202.02454",
    "title": "Supervised Learning based QoE Prediction of Video Streaming in Future  Networks: A Tutorial with Comparative Study",
    "abstract": "The Quality of Experience (QoE) based service management remains key for\nsuccessful provisioning of multimedia services in next-generation networks such\nas 5G/6G, which requires proper tools for quality monitoring, prediction and\nresource management where machine learning (ML) can play a crucial role. In\nthis paper, we provide a tutorial on the development and deployment of the QoE\nmeasurement and prediction solutions for video streaming services based on\nsupervised learning ML models. Firstly, we provide a detailed pipeline for\ndeveloping and deploying supervised learning-based video streaming QoE\nprediction models which covers several stages including data collection,\nfeature engineering, model optimization and training, testing and prediction\nand evaluation. Secondly, we discuss the deployment of the ML model for the QoE\nprediction/measurement in the next generation networks (5G/6G) using network\nenabling technologies such as Software-Defined Networking (SDN), Network\nFunction Virtualization (NFV) and Mobile Edge Computing (MEC) by proposing\nreference architecture. Thirdly, we present a comparative study of the\nstate-of-the-art supervised learning ML models for QoE prediction of video\nstreaming applications based on multiple performance metrics.",
    "descriptor": "",
    "authors": [
      "Arslan Ahmad",
      "Atif Bin Mansoor",
      "Alcardo Alex Barakabitze",
      "Andrew Hines",
      "Luigi Atzori",
      "Ray Walshe"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2202.02454"
  },
  {
    "id": "arXiv:2202.02455",
    "title": "Using Stochastic local search in designing microstrip antenna for 5G  communication",
    "abstract": "Well this paper defines methods to explore what is known as the local search\nproblem, this local search is what we are going to use in antenna to antenna\nand antenna to device communication. The local search algorithm searches for\nbest next for search this is in turn used by us in antenna pairing. This is\nprominently known as stochastic local search, We are going to design 5G\nmicrostrip antenna operating between 2.4GHz to 24 Ghz of operation. This speaks\nof a very novel idea which though was used in late sixties when microstrip was\nin operation but the idea is having potential.",
    "descriptor": "",
    "authors": [
      "Sunit Shantanu DIgamber Fulari",
      "Harbinder Singh"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2202.02455"
  },
  {
    "id": "arXiv:2202.02456",
    "title": "Application of Machine Learning-Based Pattern Recognition in IoT  Devices: Review",
    "abstract": "The Internet of things (IoT) is a rapidly advancing area of technology that\nhas quickly become more widespread in recent years. With greater numbers of\neveryday objects being connected to the Internet, many different innovations\nhave been presented to make our everyday lives more straightforward. Pattern\nrecognition is extremely prevalent in IoT devices because of the many\napplications and benefits that can come from it. A multitude of studies has\nbeen conducted with the intention of improving speed and accuracy, decreasing\ncomplexity, and reducing the overall required processing power of pattern\nrecognition algorithms in IoT devices. After reviewing the applications of\ndifferent machine learning algorithms, results vary from case to case, but a\ngeneral conclusion can be drawn that the optimal machine learning-based pattern\nrecognition algorithms to be used with IoT devices are support vector machine,\nk-nearest neighbor, and random forest.",
    "descriptor": "",
    "authors": [
      "Zachary Menter",
      "Wei Tee",
      "Rushit Dave"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.02456"
  },
  {
    "id": "arXiv:2202.02457",
    "title": "Path Planning for the Dynamic UAV-Aided Wireless Systems using Monte  Carlo Tree Search",
    "abstract": "For UAV-aided wireless systems, online path planning attracts much attention\nrecently. To better adapt to the real-time dynamic environment, we, for the\nfirst time, propose a Monte Carlo Tree Search (MCTS)-based path planning\nscheme. In details, we consider a single UAV acts as a mobile server to provide\ncomputation tasks offloading services for a set of mobile users on the ground,\nwhere the movement of ground users follows a Random Way Point model. Our model\naims at maximizing the average throughput under energy consumption and user\nfairness constraints, and the proposed timesaving MCTS algorithm can further\nimprove the performance. Simulation results show that the proposed algorithm\nachieves a larger average throughput and a faster convergence performance\ncompared with the baseline algorithms of Q-learning and Deep Q-Network.",
    "descriptor": "",
    "authors": [
      "Yuwen Qian",
      "Kexin Sheng",
      "Chuan Ma",
      "Jun Li",
      "Ming Ding",
      "Mahbub Hassan"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.02457"
  },
  {
    "id": "arXiv:2202.02458",
    "title": "Advanced service data provisioning in ROF-based mobile  backhauls/fronthauls",
    "abstract": "A new cost-efficient concept to realize a real-time monitoring of\nquality-of-service metrics and other service data in 5G and beyond access\nnetwork using a separate return channel based on a vertical cavity surface\nemitting laser in the optical injection locked mode that simultaneously\noperates as an optical transmitter and as a resonant cavity enhanced\nphotodetector, is proposed and discussed. The feasibility and efficiency of the\nproposed approach are confirmed by a proof-of-concept experiment when optically\ntransceiving high-speed digital signal with multi-position quadrature amplitude\nmodulation of a radio-frequency carrier.",
    "descriptor": "\nComments: 9 pages, 4 figures, 6th International Conference on Networks and Communications (NET 2022) January 29~30, 2022, Copenhagen, Denmark\n",
    "authors": [
      "Mikhail E. Belkin",
      "Leonid Zhukov",
      "Alexander S. Sigov"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.02458"
  },
  {
    "id": "arXiv:2202.02459",
    "title": "Space-Air-Ground Integrated Multi-domain Network Resource Orchestration  based on Virtual Network Architecture: a DRL Method",
    "abstract": "Traditional ground wireless communication networks cannot provide\nhigh-quality services for artificial intelligence (AI) applications such as\nintelligent transportation systems (ITS) due to deployment, coverage and\ncapacity issues. The space-air-ground integrated network (SAGIN) has become a\nresearch focus in the industry. Compared with traditional wireless\ncommunication networks, SAGIN is more flexible and reliable, and it has wider\ncoverage and higher quality of seamless connection. However, due to its\ninherent heterogeneity, time-varying and self-organizing characteristics, the\ndeployment and use of SAGIN still faces huge challenges, among which the\norchestration of heterogeneous resources is a key issue. Based on virtual\nnetwork architecture and deep reinforcement learning (DRL), we model SAGIN's\nheterogeneous resource orchestration as a multi-domain virtual network\nembedding (VNE) problem, and propose a SAGIN cross-domain VNE algorithm. We\nmodel the different network segments of SAGIN, and set the network attributes\naccording to the actual situation of SAGIN and user needs. In DRL, the agent is\nacted by a five-layer policy network. We build a feature matrix based on\nnetwork attributes extracted from SAGIN and use it as the agent training\nenvironment. Through training, the probability of each underlying node being\nembedded can be derived. In test phase, we complete the embedding process of\nvirtual nodes and links in turn based on this probability. Finally, we verify\nthe effectiveness of the algorithm from both training and testing.",
    "descriptor": "",
    "authors": [
      "Peiying Zhang",
      "Chao Wang",
      "Neeraj Kumar",
      "Lei Liu"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.02459"
  },
  {
    "id": "arXiv:2202.02465",
    "title": "ASHA: Assistive Teleoperation via Human-in-the-Loop Reinforcement  Learning",
    "abstract": "Building assistive interfaces for controlling robots through arbitrary,\nhigh-dimensional, noisy inputs (e.g., webcam images of eye gaze) can be\nchallenging, especially when it involves inferring the user's desired action in\nthe absence of a natural 'default' interface. Reinforcement learning from\nonline user feedback on the system's performance presents a natural solution to\nthis problem, and enables the interface to adapt to individual users. However,\nthis approach tends to require a large amount of human-in-the-loop training\ndata, especially when feedback is sparse. We propose a hierarchical solution\nthat learns efficiently from sparse user feedback: we use offline pre-training\nto acquire a latent embedding space of useful, high-level robot behaviors,\nwhich, in turn, enables the system to focus on using online user feedback to\nlearn a mapping from user inputs to desired high-level behaviors. The key\ninsight is that access to a pre-trained policy enables the system to learn more\nfrom sparse rewards than a na\\\"ive RL algorithm: using the pre-trained policy,\nthe system can make use of successful task executions to relabel, in hindsight,\nwhat the user actually meant to do during unsuccessful executions. We evaluate\nour method primarily through a user study with 12 participants who perform\ntasks in three simulated robotic manipulation domains using a webcam and their\neye gaze: flipping light switches, opening a shelf door to reach objects\ninside, and rotating a valve. The results show that our method successfully\nlearns to map 128-dimensional gaze features to 7-dimensional joint torques from\nsparse rewards in under 10 minutes of online training, and seamlessly helps\nusers who employ different gaze strategies, while adapting to distributional\nshift in webcam inputs, tasks, and environments.",
    "descriptor": "\nComments: Accepted to IEEE Conference on Robotics and Automation (ICRA) 2022\n",
    "authors": [
      "Sean Chen",
      "Jensen Gao",
      "Siddharth Reddy",
      "Glen Berseth",
      "Anca D. Dragan",
      "Sergey Levine"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.02465"
  },
  {
    "id": "arXiv:2202.02466",
    "title": "Handling Distribution Shifts on Graphs: An Invariance Perspective",
    "abstract": "There is increasing evidence suggesting neural networks' sensitivity to\ndistribution shifts, so that research on out-of-distribution (OOD)\ngeneralization comes into the spotlight. Nonetheless, current endeavors mostly\nfocus on Euclidean data, and its formulation for graph-structured data is not\nclear and remains under-explored, given the two-fold fundamental challenges: 1)\nthe inter-connection among nodes in one graph, which induces non-IID generation\nof data points even under the same environment, and 2) the structural\ninformation in the input graph, which is also informative for prediction. In\nthis paper, we formulate the OOD problem for node-level prediction on graphs\nand develop a new domain-invariant learning approach, named\nExplore-to-Extrapolate Risk Minimization, that facilitates GNNs to leverage\ninvariant graph features for prediction. The key difference to existing\ninvariant models is that we design multiple context explorers (specified as\ngraph editers in our case) that are adversarially trained to maximize the\nvariance of risks from multiple virtual environments. Such a design enables the\nmodel to extrapolate from a single observed environment which is the common\ncase for node-level prediction. We prove the validity of our method by\ntheoretically showing its guarantee of a valid OOD solution and further\ndemonstrate its power on various real-world datasets for handling distribution\nshifts from artificial spurious features, cross-domain transfers and dynamic\ngraph evolution.",
    "descriptor": "\nComments: ICLR2022, 31 pages\n",
    "authors": [
      "Qitian Wu",
      "Hengrui Zhang",
      "Junchi Yan",
      "David Wipf"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.02466"
  },
  {
    "id": "arXiv:2202.02467",
    "title": "Group Testing with Correlation under Edge-Faulty Graphs",
    "abstract": "In applications of group testing in networks, e.g. identifying individuals\nwho are infected by a disease spread over a network, exploiting correlation\namong network nodes provides fundamental opportunities in reducing the number\nof tests needed. We model and analyze group testing on $n$ correlated nodes\nwhose interactions are specified by a graph $G$. We model correlation through\nan edge-faulty random graph formed from $G$ in which each edge is dropped with\nprobability $1-r$, and all nodes in the same component have the same state. We\nconsider three classes of graphs: cycles and trees, $d$-regular graphs and\nstochastic block models or SBM, and obtain lower and upper bounds on the number\nof tests needed to identify the defective nodes. Our results are expressed in\nterms of the number of tests needed when the nodes are independent and they are\nin terms of $n$, $r$, and the target error. In particular, we quantify the\nfundamental improvements that exploiting correlation offers by the ratio\nbetween the total number of nodes $n$ and the equivalent number of independent\nnodes in a classic group testing algorithm. The lower bounds are derived by\nillustrating a strong dependence of the number of tests needed on the expected\nnumber of components. In this regard, we establish a new approximation for the\ndistribution of component sizes in \"$d$-regular trees\" which may be of\nindependent interest and leads to a lower bound on the expected number of\ncomponents in $d$-regular graphs. The upper bounds are found by forming dense\nsubgraphs in which nodes are more likely to be in the same state. When $G$ is a\ncycle or tree, we show an improvement by a factor of $log(1/r)$. For grid, a\ngraph with almost $2n$ edges, the improvement is by a factor of ${(1-r)\n\\log(1/r)}$, indicating drastic improvement compared to trees. When $G$ has a\nlarger number of edges, as in SBM, the improvement can scale in $n$.",
    "descriptor": "",
    "authors": [
      "Hesam Nikpey",
      "Jungyeol Kim",
      "Xingran Chen",
      "Saswati Sarkar",
      "Shirin Saeedi Bidokhti"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.02467"
  },
  {
    "id": "arXiv:2202.02468",
    "title": "Rethinking ValueDice: Does It Really Improve Performance?",
    "abstract": "Since the introduction of GAIL, adversarial imitation learning (AIL) methods\nattract lots of research interests. Among these methods, ValueDice has achieved\nsignificant improvements: it beats the classical approach Behavioral Cloning\n(BC) under the offline setting, and it requires fewer interactions than GAIL\nunder the online setting. Are these improvements benefited from more advanced\nalgorithm designs? We answer this question with the following conclusions.\nFirst, we show that ValueDice could reduce to BC under the offline setting.\nSecond, we verify that overfitting exists and regularization matters.\nSpecifically, we demonstrate that with weight decay, BC also nearly matches the\nexpert performance as ValueDice does. The first two claims explain the superior\noffline performance of ValueDice. Third, we establish that ValueDice does not\nwork at all when the expert trajectory is subsampled. Instead, the mentioned\nsuccess holds when the expert trajectory is complete, in which ValueDice is\nclosely related to BC that performs well as mentioned. Finally, we discuss the\nimplications of our research for imitation learning studies beyond ValueDice.",
    "descriptor": "",
    "authors": [
      "Ziniu Li",
      "Tian Xu",
      "Yang Yu",
      "Zhi-Quan Luo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.02468"
  },
  {
    "id": "arXiv:2202.02470",
    "title": "MarkovGNN: Graph Neural Networks on Markov Diffusion",
    "abstract": "Most real-world networks contain well-defined community structures where\nnodes are densely connected internally within communities. To learn from these\nnetworks, we develop MarkovGNN that captures the formation and evolution of\ncommunities directly in different convolutional layers. Unlike most Graph\nNeural Networks (GNNs) that consider a static graph at every layer, MarkovGNN\ngenerates different stochastic matrices using a Markov process and then uses\nthese community-capturing matrices in different layers. MarkovGNN is a general\napproach that could be used with most existing GNNs. We experimentally show\nthat MarkovGNN outperforms other GNNs for clustering, node classification, and\nvisualization tasks. The source code of MarkovGNN is publicly available at\n\\url{https://github.com/HipGraph/MarkovGNN}.",
    "descriptor": "\nComments: total 12 pages\n",
    "authors": [
      "Md. Khaledur Rahman",
      "Abhigya Agrawal",
      "Ariful Azad"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.02470"
  },
  {
    "id": "arXiv:2202.02471",
    "title": "Few-shot Learning as Cluster-induced Voronoi Diagrams: A Geometric  Approach",
    "abstract": "Few-shot learning (FSL) is the process of rapid generalization from abundant\nbase samples to inadequate novel samples. Despite extensive research in recent\nyears, FSL is still not yet able to generate satisfactory solutions for a wide\nrange of real-world applications. To confront this challenge, we study the FSL\nproblem from a geometric point of view in this paper. One observation is that\nthe widely embraced ProtoNet model is essentially a Voronoi Diagram (VD) in the\nfeature space. We retrofit it by making use of a recent advance in\ncomputational geometry called Cluster-induced Voronoi Diagram (CIVD). Starting\nfrom the simplest nearest neighbor model, CIVD gradually incorporates\ncluster-to-point and then cluster-to-cluster relationships for space\nsubdivision, which is used to improve the accuracy and robustness at multiple\nstages of FSL. Specifically, we use CIVD (1) to integrate parametric and\nnonparametric few-shot classifiers; (2) to combine feature representation and\nsurrogate representation; (3) and to leverage feature-level,\ntransformation-level, and geometry-level heterogeneities for a better ensemble.\nOur CIVD-based workflow enables us to achieve new state-of-the-art results on\nmini-ImageNet, CUB, and tiered-ImagenNet datasets, with ${\\sim}2\\%{-}5\\%$\nimprovements upon the next best. To summarize, CIVD provides a mathematically\nelegant and geometrically interpretable framework that compensates for extreme\ndata insufficiency, prevents overfitting, and allows for fast geometric\nensemble for thousands of individual VD. These together make FSL stronger.",
    "descriptor": "\nComments: Accepted for publication in ICLR 2022; this https URL\n",
    "authors": [
      "Chunwei Ma",
      "Ziyun Huang",
      "Mingchen Gao",
      "Jinhui Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.02471"
  },
  {
    "id": "arXiv:2202.02476",
    "title": "Semantic Similarity Computing Model Based on Multi Model Fine-Grained  Nonlinear Fusion",
    "abstract": "Natural language processing (NLP) task has achieved excellent performance in\nmany fields, including semantic understanding, automatic summarization, image\nrecognition and so on. However, most of the neural network models for NLP\nextract the text in a fine-grained way, which is not conducive to grasp the\nmeaning of the text from a global perspective. To alleviate the problem, the\ncombination of the traditional statistical method and deep learning model as\nwell as a novel model based on multi model nonlinear fusion are proposed in\nthis paper. The model uses the Jaccard coefficient based on part of speech,\nTerm Frequency-Inverse Document Frequency (TF-IDF) and word2vec-CNN algorithm\nto measure the similarity of sentences respectively. According to the\ncalculation accuracy of each model, the normalized weight coefficient is\nobtained and the calculation results are compared. The weighted vector is input\ninto the fully connected neural network to give the final classification\nresults. As a result, the statistical sentence similarity evaluation algorithm\nreduces the granularity of feature extraction, so it can grasp the sentence\nfeatures globally. Experimental results show that the matching of sentence\nsimilarity calculation method based on multi model nonlinear fusion is 84%, and\nthe F1 value of the model is 75%.",
    "descriptor": "",
    "authors": [
      "Peiying Zhang",
      "Xingzhe Huang",
      "Yaqi Wang",
      "Chunxiao Jiang",
      "Shuqing He",
      "Haifeng Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.02476"
  },
  {
    "id": "arXiv:2202.02478",
    "title": "Sensing Method for Two-Target Detection in Time-Constrained Vector  Gaussian Channel",
    "abstract": "This paper considers a vector Gaussian channel of fixed identity covariance\nmatrix and binary input signalling as the mean of it. A linear transformation\nis performed on the vector input signal. The objective is to find the optimal\nscaling matrix, under the total time constraint, that would: i) maximize the\nmutual information between the input and output random vectors, ii) maximize\nthe MAP detection. It was found that the two metrics lead to different optimal\nsolutions for our experimental design problem. We have used the Monte Carlo\nmethod for our computational work.",
    "descriptor": "\nComments: 14 pages, 28 figures, journal article. arXiv admin note: text overlap with arXiv:2201.07915\n",
    "authors": [
      "Muhammad Fahad",
      "Daniel R. Fuhrmann"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.02478"
  },
  {
    "id": "arXiv:2202.02479",
    "title": "Algorithmic nudge to make better choices: Evaluating effectiveness of  XAI frameworks to reveal biases in algorithmic decision making to users",
    "abstract": "In this position paper, we propose the use of existing XAI frameworks to\ndesign interventions in scenarios where algorithms expose users to problematic\ncontent (e.g. anti vaccine videos). Our intervention design includes facts (to\nindicate algorithmic justification of what happened) accompanied with either\nfore warnings or counterfactual explanations. While fore warnings indicate\npotential risks of an action to users, the counterfactual explanations will\nindicate what actions user should perform to change the algorithmic outcome. We\nenvision the use of such interventions as `decision aids' to users which will\nhelp them make informed choices.",
    "descriptor": "",
    "authors": [
      "Prerna Juneja",
      "Tanushree Mitra"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2202.02479"
  },
  {
    "id": "arXiv:2202.02481",
    "title": "LotRec: A Recommender for Urban Vacant Lot Conversion",
    "abstract": "Vacant lots are neglected properties in a city that lead to environmental\nhazards and poor standard of living for the community. Thus, reclaiming vacant\nlots and putting them to productive use is an important consideration for many\ncities. Given a large number of vacant lots and resource constraints for\nconversion, two key questions for a city are (1) whether to convert a vacant\nlot or not; and (2) what to convert a vacant lot as. We seek to provide\ncomputational support to answer these questions. To this end, we identify the\ndeterminants of a vacant lot conversion and build a recommender based on those\ndeterminants. We evaluate our models on real-world vacant lot datasets from the\nUS cities of Philadelphia,PA and Baltimore, MD. Our results indicate that our\nrecommender yields mean F-measures of (1) 90% in predicting whether a vacant\nlot should be converted or not within a single city, (2) 91% in predicting what\na vacant lot should be converted to, within a single city and, (3) 85% in\npredicting whether a vacant lot should be converted or not across two cities.",
    "descriptor": "",
    "authors": [
      "Md Towhidul A Chowdhury",
      "Naveen Sharma"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.02481"
  },
  {
    "id": "arXiv:2202.02484",
    "title": "A \"Distance Matters\" Paradox: Facilitating Intra-Team Collaboration Can  Harm Inter-Team Collaboration",
    "abstract": "By identifying the socio-technical conditions required for teams to work\neffectively remotely, the Distance Matters framework has been influential in\nCSCW since its introduction in 2000. Advances in collaboration technology and\npractices have since brought teams increasingly closer to achieving these\nconditions. This paper presents a ten-month ethnography in a remote\norganization, where we observed that despite exhibiting excellent remote\ncollaboration, teams paradoxically struggled to collaborate across team\nboundaries. We extend the Distance Matters framework to account for inter-team\ncollaboration, arguing that challenges analogous to those in the original\nintra-team framework -- common ground, collaboration readiness, collaboration\ntechnology readiness, and coupling of work -- persist but are actualized\ndifferently at the inter-team scale. Finally, we identify a fundamental tension\nbetween the intra- and inter-team layers: the collaboration technology and\npractices that help individual teams thrive (e.g., adopting customized\ncollaboration software) can also prompt collaboration challenges in the\ninter-team layer, and conversely the technology and practices that facilitate\ninter-team collaboration (e.g., strong centralized IT organizations) can harm\npractices at the intra-team layer. The addition of the inter-team layer to the\nDistance Matters framework opens new opportunities for CSCW, where balancing\nthe tension between team and organizational collaboration needs will be a\ncritical technological, operational, and organizational challenge for remote\nwork in the coming decades.",
    "descriptor": "\nComments: Accepted at CSCW 2022 (The 25th ACM Conference on Computer-Supported Cooperative Work and Social Computing)\n",
    "authors": [
      "Xinlan Emily Hu",
      "Rebecca Hinds",
      "Melissa A. Valentine",
      "Michael S. Bernstein"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2202.02484"
  },
  {
    "id": "arXiv:2202.02489",
    "title": "Investigating the Challenges of Class Imbalance and Scale Variation in  Object Detection in Aerial Images",
    "abstract": "While object detection is a common problem in computer vision, it is even\nmore challenging when dealing with aerial satellite images. The variety in\nobject scales and orientations can make them difficult to identify. In\naddition, there can be large amounts of densely packed small objects such as\ncars. In this project, we propose a few changes to the Faster-RCNN\narchitecture. First, we experiment with different backbones to extract better\nfeatures. We also modify the data augmentations and generated anchor sizes for\nregion proposals in order to better handle small objects. Finally, we\ninvestigate the effects of different loss functions. Our proposed design\nachieves an improvement of 4.7 mAP over the baseline which used a vanilla\nFaster R-CNN with a ResNet-101 FPN backbone.",
    "descriptor": "",
    "authors": [
      "Ahmed Elhagry",
      "Mohamed Saeed"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.02489"
  },
  {
    "id": "arXiv:2202.02491",
    "title": "Distributed Learning With Sparsified Gradient Differences",
    "abstract": "A very large number of communications are typically required to solve\ndistributed learning tasks, and this critically limits scalability and\nconvergence speed in wireless communications applications. In this paper, we\ndevise a Gradient Descent method with Sparsification and Error Correction\n(GD-SEC) to improve the communications efficiency in a general worker-server\narchitecture. Motivated by a variety of wireless communications learning\nscenarios, GD-SEC reduces the number of bits per communication from worker to\nserver with no degradation in the order of the convergence rate. This enables\nlarger-scale model learning without sacrificing convergence or accuracy. At\neach iteration of GD-SEC, instead of directly transmitting the entire gradient\nvector, each worker computes the difference between its current gradient and a\nlinear combination of its previously transmitted gradients, and then transmits\nthe sparsified gradient difference to the server. A key feature of GD-SEC is\nthat any given component of the gradient difference vector will not be\ntransmitted if its magnitude is not sufficiently large. An error correction\ntechnique is used at each worker to compensate for the error resulting from\nsparsification. We prove that GD-SEC is guaranteed to converge for strongly\nconvex, convex, and nonconvex optimization problems with the same order of\nconvergence rate as GD. Furthermore, if the objective function is strongly\nconvex, GD-SEC has a fast linear convergence rate. Numerical results not only\nvalidate the convergence rate of GD-SEC but also explore the communication bit\nsavings it provides. Given a target accuracy, GD-SEC can significantly reduce\nthe communications load compared to the best existing algorithms without\nslowing down the optimization process.",
    "descriptor": "",
    "authors": [
      "Yicheng Chen",
      "Rick S. Blum",
      "Martin Takac",
      "Brian M. Sadler"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.02491"
  },
  {
    "id": "arXiv:2202.02492",
    "title": "Predicting Future CSI Feedback For Highly-Mobile Massive MIMO Systems",
    "abstract": "Massive multiple-input multiple-output (MIMO) system is promising in\nproviding unprecedentedly high data rate. To achieve its full potential, the\ntransceiver needs complete channel state information (CSI) to perform\ntransmit/receive precoding/combining. This requirement, however, is challenging\nin the practical systems due to the unavoidable processing and feedback delays,\nwhich oftentimes degrades the performance to a great extent, especially in the\nhigh mobility scenarios. In this paper, we develop a deep learning based\nchannel prediction framework that proactively predicts the downlink channel\nstate information based on the past observed channel sequence. In its core, the\nmodel adopts a 3-D convolutional neural network (CNN) based architecture to\nefficiently learn the temporal, spatial and frequency correlations of downlink\nchannel samples, based on which accurate channel prediction can be performed.\nSimulation results highlight the potential of the developed learning model in\nextracting information and predicting future downlink channels directly from\nthe observed past channel sequence, which significantly improves the\nperformance compared to the sample-and-hold approach, and mitigates the impact\nof the dynamic communication environment.",
    "descriptor": "",
    "authors": [
      "Yu Zhang",
      "Ahmed Alkhateeb",
      "Pranav Madadi",
      "Jeongho Jeon",
      "Joonyoung Cho",
      "Charlie Zhang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.02492"
  },
  {
    "id": "arXiv:2202.02495",
    "title": "Weisfeiler-Lehman meets Gromov-Wasserstein",
    "abstract": "The Weisfeiler-Lehman (WL) test is a classical procedure for graph\nisomorphism testing. The WL test has also been widely used both for designing\ngraph kernels and for analyzing graph neural networks. In this paper, we\npropose the Weisfeiler-Lehman (WL) distance, a notion of distance between\nlabeled measure Markov chains (LMMCs), of which labeled graphs are special\ncases. The WL distance is polynomial time computable and is also compatible\nwith the WL test in the sense that the former is positive if and only if the WL\ntest can distinguish the two involved graphs. The WL distance captures and\ncompares subtle structures of the underlying LMMCs and, as a consequence of\nthis, it is more discriminating than the distance between graphs used for\ndefining the state-of-the-art Wasserstein Weisfeiler-Lehman graph kernel.\nInspired by the structure of the WL distance we identify a neural network\narchitecture on LMMCs which turns out to be universal w.r.t. continuous\nfunctions defined on the space of all LMMCs (which includes all graphs) endowed\nwith the WL distance. Finally, the WL distance turns out to be stable w.r.t. a\nnatural variant of the Gromov-Wasserstein (GW) distance for comparing metric\nMarkov chains that we identify. Hence, the WL distance can also be construed as\na polynomial time lower bound for the GW distance which is in general NP-hard\nto compute.",
    "descriptor": "",
    "authors": [
      "Samantha Chen",
      "Sunhyuk Lim",
      "Facundo M\u00e9moli",
      "Zhengchao Wan",
      "Yusu Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Metric Geometry (math.MG)"
    ],
    "url": "https://arxiv.org/abs/2202.02495"
  },
  {
    "id": "arXiv:2202.02500",
    "title": "A Neural Beam Filter for Real-time Multi-channel Speech Enhancement",
    "abstract": "Most deep learning-based multi-channel speech enhancement methods focus on\ndesigning a set of beamforming coefficients to directly filter the low\nsignal-to-noise ratio signals received by microphones, which hinders the\nperformance of these approaches. To handle these problems, this paper designs a\ncausal neural beam filter that fully exploits the spatial-spectral information\nin the beam domain. Specifically, multiple beams are designed to steer towards\nall directions using a parameterized super-directive beamformer in the first\nstage. After that, the neural spatial filter is learned by simultaneously\nmodeling the spatial and spectral discriminability of the speech and the\ninterference, so as to extract the desired speech coarsely in the second stage.\nFinally, to further suppress the interference components especially at low\nfrequencies, a residual estimation module is adopted to refine the output of\nthe second stage. Experimental results demonstrate that the proposed approach\noutperforms many state-of-the-art multi-channel methods on the generated\nmulti-channel speech dataset based on the DNS-Challenge dataset.",
    "descriptor": "\nComments: 5 pages, 4 figures\n",
    "authors": [
      "Wenzhe Liu",
      "Andong Li",
      "Chengshi Zheng",
      "Xiaodong Li"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2202.02500"
  },
  {
    "id": "arXiv:2202.02501",
    "title": "GraphEye: A Novel Solution for Detecting Vulnerable Functions Based on  Graph Attention Network",
    "abstract": "With the continuous extension of the Industrial Internet, cyber incidents\ncaused by software vulnerabilities have been increasing in recent years.\nHowever, software vulnerabilities detection is still heavily relying on code\nreview done by experts, and how to automatedly detect software vulnerabilities\nis an open problem so far. In this paper, we propose a novel solution named\nGraphEye to identify whether a function of C/C++ code has vulnerabilities,\nwhich can greatly alleviate the burden of code auditors. GraphEye is originated\nfrom the observation that the code property graph of a non-vulnerable function\nnaturally differs from the code property graph of a vulnerable function with\nthe same functionality. Hence, detecting vulnerable functions is attributed to\nthe graph classification problem.GraphEye is comprised of VecCPG and GcGAT.\nVecCPG is a vectorization for the code property graph, which is proposed to\ncharacterize the key syntax and semantic features of the corresponding source\ncode. GcGAT is a deep learning model based on the graph attention graph, which\nis proposed to solve the graph classification problem according to VecCPG.\nFinally, GraphEye is verified by the SARD Stack-based Buffer Overflow,\nDivide-Zero, Null Pointer Deference, Buffer Error, and Resource Error datasets,\nthe corresponding F1 scores are 95.6%, 95.6%,96.1%,92.6%, and 96.1%\nrespectively, which validate the effectiveness of the proposed solution.",
    "descriptor": "",
    "authors": [
      "Li Zhou",
      "Minhuan Huang",
      "Yujun Li",
      "Yuanping Nie",
      "Jin Li",
      "Yiwei Liu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.02501"
  },
  {
    "id": "arXiv:2202.02502",
    "title": "A Coalition Formation Game Approach for Personalized Federated Learning",
    "abstract": "Facing the challenge of statistical diversity in client local data\ndistribution, personalized federated learning (PFL) has become a growing\nresearch hotspot. Although the state-of-the-art methods with model\nsimilarity-based pairwise collaboration have achieved promising performance,\nthey neglect the fact that model aggregation is essentially a collaboration\nprocess within the coalition, where the complex multiwise influences take place\namong clients. In this paper, we first apply Shapley value (SV) from coalition\ngame theory into the PFL scenario. To measure the multiwise collaboration among\na group of clients on the personalized learning performance, SV takes their\nmarginal contribution to the final result as a metric. We propose a novel\npersonalized algorithm: pFedSV, which can 1. identify each client's optimal\ncollaborator coalition and 2. perform personalized model aggregation based on\nSV. Extensive experiments on various datasets (MNIST, Fashion-MNIST, and\nCIFAR-10) are conducted with different Non-IID data settings (Pathological and\nDirichlet). The results show that pFedSV can achieve superior personalized\naccuracy for each client, compared to the state-of-the-art benchmarks.",
    "descriptor": "\nComments: 6 pages exclude the reference, 6 figures\n",
    "authors": [
      "Leijie Wu",
      "Song Guo",
      "Yaohong Ding",
      "Yufeng Zhan",
      "Jie Zhang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.02502"
  },
  {
    "id": "arXiv:2202.02503",
    "title": "Adversarial Detector with Robust Classifier",
    "abstract": "Deep neural network (DNN) models are wellknown to easily misclassify\nprediction results by using input images with small perturbations, called\nadversarial examples. In this paper, we propose a novel adversarial detector,\nwhich consists of a robust classifier and a plain one, to highly detect\nadversarial examples. The proposed adversarial detector is carried out in\naccordance with the logits of plain and robust classifiers. In an experiment,\nthe proposed detector is demonstrated to outperform a state-of-the-art detector\nwithout any robust classifier.",
    "descriptor": "",
    "authors": [
      "Takayuki Osakabe",
      "Maungmaung Aprilpyone",
      "Sayaka Shiota",
      "Hitoshi Kiya"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.02503"
  },
  {
    "id": "arXiv:2202.02506",
    "title": "Iota: A Framework for Analyzing System-Level Security of IoTs",
    "abstract": "Most IoT systems involve IoT devices, communication protocols, remote cloud,\nIoT applications, mobile apps, and the physical environment. However, existing\nIoT security analyses only focus on a subset of all the essential components,\nsuch as device firmware, and ignore IoT systems' interactive nature, resulting\nin limited attack detection capabilities. In this work, we propose Iota, a\nlogic programming-based framework to perform system-level security analysis for\nIoT systems. Iota generates attack graphs for IoT systems, showing all of the\nsystem resources that can be compromised and enumerating potential attack\ntraces. In building Iota, we design novel techniques to scan IoT systems for\nindividual vulnerabilities and further create generic exploit models for IoT\nvulnerabilities. We also identify and model physical dependencies between\ndifferent devices as they are unique to IoT systems and are employed by\nadversaries to launch complicated attacks. In addition, we utilize NLP\ntechniques to extract IoT app semantics based on app descriptions. To evaluate\nvulnerabilities' system-wide impact, we propose two metrics based on the attack\ngraph, which provide guidance on fortifying IoT systems. Evaluation on 127 IoT\nCVEs (Common Vulnerabilities and Exposures) shows that Iota's exploit modeling\nmodule achieves over 80% accuracy in predicting vulnerabilities' preconditions\nand effects. We apply Iota to 37 synthetic smart home IoT systems based on\nreal-world IoT apps and devices. Experimental results show that our framework\nis effective and highly efficient. Among 27 shortest attack traces revealed by\nthe attack graphs, 62.8% are not anticipated by the system administrator. It\nonly takes 1.2 seconds to generate and analyze the attack graph for an IoT\nsystem consisting of 50 devices.",
    "descriptor": "\nComments: This manuscript has been accepted by IoTDI 2022\n",
    "authors": [
      "Zheng Fang",
      "Hao Fu",
      "Tianbo Gu",
      "Pengfei Hu",
      "Jinyue Song",
      "Trent Jaeger",
      "Prasant Mohapatra"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.02506"
  },
  {
    "id": "arXiv:2202.02510",
    "title": "A Survey on Poisoning Attacks Against Supervised Machine Learning",
    "abstract": "With the rise of artificial intelligence and machine learning in modern\ncomputing, one of the major concerns regarding such techniques is to provide\nprivacy and security against adversaries. We present this survey paper to cover\nthe most representative papers in poisoning attacks against supervised machine\nlearning models. We first provide a taxonomy to categorize existing studies and\nthen present detailed summaries for selected papers. We summarize and compare\nthe methodology and limitations of existing literature. We conclude this paper\nwith potential improvements and future directions to further exploit and\nprevent poisoning attacks on supervised models. We propose several unanswered\nresearch questions to encourage and inspire researchers for future work.",
    "descriptor": "",
    "authors": [
      "Wenjun Qiu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.02510"
  },
  {
    "id": "arXiv:2202.02511",
    "title": "A simple language-agnostic yet very strong baseline system for hate  speech and offensive content identification",
    "abstract": "For automatically identifying hate speech and offensive content in tweets, a\nsystem based on a classical supervised algorithm only fed with character\nn-grams, and thus completely language-agnostic, is proposed by the SATLab team.\nAfter its optimization in terms of the feature weighting and the classifier\nparameters, it reached, in the multilingual HASOC 2021 challenge, a medium\nperformance level in English, the language for which it is easy to develop deep\nlearning approaches relying on many external linguistic resources, but a far\nbetter level for the two less resourced language, Hindi and Marathi. It ends\neven first when performances are averaged over the three tasks in these\nlanguages, outperforming many deep learning approaches. These performances\nsuggest that it is an interesting reference level to evaluate the benefits of\nusing more complex approaches such as deep learning or taking into account\ncomplementary resources.",
    "descriptor": "\nComments: A slightly modified version of the paper: \"A simple language-agnostic yet strong baseline system for hate speech and offensive content identification. In Working Notes of FIRE 2021 - Forum for Information Retrieval Evaluation (10 p.). ceur-ws.org\n",
    "authors": [
      "Yves Bestgen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.02511"
  },
  {
    "id": "arXiv:2202.02514",
    "title": "Score-based Generative Modeling of Graphs via the System of Stochastic  Differential Equations",
    "abstract": "Generating graph-structured data requires learning the underlying\ndistribution of graphs. Yet, this is a challenging problem, and the previous\ngraph generative methods either fail to capture the permutation-invariance\nproperty of graphs or cannot sufficiently model the complex dependency between\nnodes and edges, which is crucial for generating real-world graphs such as\nmolecules. To overcome such limitations, we propose a novel score-based\ngenerative model for graphs with a continuous-time framework. Specifically, we\npropose a new graph diffusion process that models the joint distribution of the\nnodes and edges through a system of stochastic differential equations (SDEs).\nThen, we derive novel score matching objectives tailored for the proposed\ndiffusion process to estimate the gradient of the joint log-density with\nrespect to each component, and introduce a new solver for the system of SDEs to\nefficiently sample from the reverse diffusion process. We validate our graph\ngeneration method on diverse datasets, on which it either achieves\nsignificantly superior or competitive performance to the baselines. Further\nanalysis shows that our method is able to generate molecules that lie close to\nthe training distribution yet do not violate the chemical valency rule,\ndemonstrating the effectiveness of the system of SDEs in modeling the node-edge\nrelationships.",
    "descriptor": "",
    "authors": [
      "Jaehyeong Jo",
      "Seul Lee",
      "Sung Ju Hwang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.02514"
  },
  {
    "id": "arXiv:2202.02516",
    "title": "A Survey on Automated Sarcasm Detection on Twitter",
    "abstract": "Automatic sarcasm detection is a growing field in computer science. Short\ntext messages are increasingly used for communication, especially over social\nmedia platforms such as Twitter. Due to insufficient or missing context,\nunidentified sarcasm in these messages can invert the meaning of a statement,\nleading to confusion and communication failures. This paper covers a variety of\ncurrent methods used for sarcasm detection, including detection by context,\nposting history and machine learning models. Additionally, a shift towards deep\nlearning methods is observable, likely due to the benefit of using a model with\ninduced instead of discrete features combined with the innovation of\ntransformers.",
    "descriptor": "\nComments: 33 pages, 14 figures\n",
    "authors": [
      "Bleau Moores",
      "Vijay Mago"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.02516"
  },
  {
    "id": "arXiv:2202.02518",
    "title": "Less is More: Reversible Steganography with Uncertainty-Aware Predictive  Analytics",
    "abstract": "Artificial neural networks have advanced the frontiers of reversible\nsteganography. The core strength of neural networks is the ability to render\naccurate predictions for a bewildering variety of data. Residual modulation is\nrecognised as the most advanced reversible steganographic algorithm for digital\nimages and the pivot of which is the predictive module. The function of this\nmodule is to predict pixel intensity given some pixel-wise contextual\ninformation. This task can be perceived as a low-level vision problem and hence\nneural networks for addressing a similar class of problems can be deployed. On\ntop of the prior art, this paper analyses the predictive uncertainty and endows\nthe predictive module with the option to abstain when encountering a high level\nof uncertainty. Uncertainty analysis can be formulated as a pixel-level binary\nclassification problem and tackled by both supervised and unsupervised\nlearning. In contrast to handcrafted statistical analytics, learning-based\nanalytics can learn to follow some general statistical principles and\nsimultaneously adapt to a specific predictor. Experimental results show that\nsteganographic performance can be remarkably improved by adaptively filtering\nout the unpredictable regions with the learning-based uncertainty analysers.",
    "descriptor": "",
    "authors": [
      "Ching-Chun Chang",
      "Xu Wang",
      "Sisheng Chen",
      "Isao Echizen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2202.02518"
  },
  {
    "id": "arXiv:2202.02519",
    "title": "Intent Contrastive Learning for Sequential Recommendation",
    "abstract": "Users' interactions with items are driven by various intents (e.g., preparing\nfor holiday gifts, shopping for fishing equipment, etc.).However, users'\nunderlying intents are often unobserved/latent, making it challenging to\nleverage such latent intents forSequentialrecommendation(SR). To investigate\nthe benefits of latent intents and leverage them effectively for\nrecommendation, we proposeIntentContrastiveLearning(ICL), a general learning\nparadigm that leverages a latent intent variable into SR. The core idea is to\nlearn users' intent distribution functions from unlabeled user behavior\nsequences and optimize SR models with contrastive self-supervised learning\n(SSL) by considering the learned intents to improve recommendation.\nSpecifically, we introduce a latent variable to represent users' intents and\nlearn the distribution function of the latent variable via clustering. We\npropose to leverage the learned intents into SR models via contrastive SSL,\nwhich maximizes the agreement between a view of sequence and its corresponding\nintent. The training is alternated between intent representation learning and\nthe SR model optimization steps within the generalized expectation-maximization\n(EM) framework. Fusing user intent information into SR also improves model\nrobustness. Experiments conducted on four real-world datasets demonstrate the\nsuperiority of the proposed learning paradigm, which improves performance, and\nrobustness against data sparsity and noisy interaction issues.",
    "descriptor": "",
    "authors": [
      "Yongjun Chen",
      "Zhiwei Liu",
      "Jia Li",
      "Julian McAuley",
      "Caiming Xiong"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.02519"
  },
  {
    "id": "arXiv:2202.02521",
    "title": "Comparative study of 3D object detection frameworks based on LiDAR data  and sensor fusion techniques",
    "abstract": "Estimating and understanding the surroundings of the vehicle precisely forms\nthe basic and crucial step for the autonomous vehicle. The perception system\nplays a significant role in providing an accurate interpretation of a vehicle's\nenvironment in real-time. Generally, the perception system involves various\nsubsystems such as localization, obstacle (static and dynamic) detection, and\navoidance, mapping systems, and others. For perceiving the environment, these\nvehicles will be equipped with various exteroceptive (both passive and active)\nsensors in particular cameras, Radars, LiDARs, and others. These systems are\nequipped with deep learning techniques that transform the huge amount of data\nfrom the sensors into semantic information on which the object detection and\nlocalization tasks are performed. For numerous driving tasks, to provide\naccurate results, the location and depth information of a particular object is\nnecessary. 3D object detection methods, by utilizing the additional pose data\nfrom the sensors such as LiDARs, stereo cameras, provides information on the\nsize and location of the object. Based on recent research, 3D object detection\nframeworks performing object detection and localization on LiDAR data and\nsensor fusion techniques show significant improvement in their performance. In\nthis work, a comparative study of the effect of using LiDAR data for object\ndetection frameworks and the performance improvement seen by using sensor\nfusion techniques are performed. Along with discussing various state-of-the-art\nmethods in both the cases, performing experimental analysis, and providing\nfuture research directions.",
    "descriptor": "\nComments: 2021 2nd International Conference on Control Theory and Applications(ICoCTA 2021)\n",
    "authors": [
      "Sreenivasa Hikkal Venugopala"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.02521"
  },
  {
    "id": "arXiv:2202.02522",
    "title": "LEAPMood: Light and Efficient Architecture to Predict Mood with Genetic  Algorithm driven Hyperparameter Tuning",
    "abstract": "Accurate and automatic detection of mood serves as a building block for use\ncases like user profiling which in turn power applications such as advertising,\nrecommendation systems, and many more. One primary source indicative of an\nindividual's mood is textual data. While there has been extensive research on\nemotion recognition, the field of mood prediction has been barely explored. In\naddition, very little work is done in the area of on-device inferencing, which\nis highly important from the user privacy point of view. In this paper, we\npropose for the first time, an on-device deep learning approach for mood\nprediction from textual data, LEAPMood. We use a novel on-device\ndeployment-focused objective function for hyperparameter tuning based on the\nGenetic Algorithm (GA) and optimize the parameters concerning both performance\nand size. LEAPMood consists of Emotion Recognition in Conversion (ERC) as the\nfirst building block followed by mood prediction using K-means clustering. We\nshow that using a combination of character embedding, phonetic hashing, and\nattention along with Conditional Random Fields (CRF), results in a performance\nclosely comparable to that of the current State-Of-the-Art with a significant\nreduction in model size (> 90%) for the task of ERC. We achieve a Micro F1\nscore of 62.05% with a memory footprint of a mere 1.67MB on the DailyDialog\ndataset. Furthermore, we curate a dataset for the task of mood prediction\nachieving a Macro F1-score of 72.12% with LEAPMood.",
    "descriptor": "\nComments: Accepted at 16th IEEE International Conference on Semantic Computing (ICSC), January 26-28, 2022\n",
    "authors": [
      "Harichandana B S S",
      "Sumit Kumar"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.02522"
  },
  {
    "id": "arXiv:2202.02524",
    "title": "PrivPAS: A real time Privacy-Preserving AI System and applied ethics",
    "abstract": "With 3.78 billion social media users worldwide in 2021 (48% of the human\npopulation), almost 3 billion images are shared daily. At the same time, a\nconsistent evolution of smartphone cameras has led to a photography explosion\nwith 85% of all new pictures being captured using smartphones. However, lately,\nthere has been an increased discussion of privacy concerns when a person being\nphotographed is unaware of the picture being taken or has reservations about\nthe same being shared. These privacy violations are amplified for people with\ndisabilities, who may find it challenging to raise dissent even if they are\naware. Such unauthorized image captures may also be misused to gain sympathy by\nthird-party organizations, leading to a privacy breach. Privacy for people with\ndisabilities has so far received comparatively less attention from the AI\ncommunity. This motivates us to work towards a solution to generate\nprivacy-conscious cues for raising awareness in smartphone users of any\nsensitivity in their viewfinder content. To this end, we introduce PrivPAS (A\nreal time Privacy-Preserving AI System) a novel framework to identify sensitive\ncontent. Additionally, we curate and annotate a dataset to identify and\nlocalize accessibility markers and classify whether an image is sensitive to a\nfeatured subject with a disability. We demonstrate that the proposed\nlightweight architecture, with a memory footprint of a mere 8.49MB, achieves a\nhigh mAP of 89.52% on resource-constrained devices. Furthermore, our pipeline,\ntrained on face anonymized data, achieves an F1-score of 73.1%.",
    "descriptor": "\nComments: Accepted at 16th IEEE International Conference on Semantic Computing (ICSC), January 26-28, 2022\n",
    "authors": [
      "Harichandana B S S",
      "Vibhav Agarwal",
      "Sourav Ghosh",
      "Gopi Ramena",
      "Sumit Kumar andd Barath Raj Kandur Raja"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.02524"
  },
  {
    "id": "arXiv:2202.02526",
    "title": "LyaNet: A Lyapunov Framework for Training Neural ODEs",
    "abstract": "We propose a method for training ordinary differential equations by using a\ncontrol-theoretic Lyapunov condition for stability. Our approach, called\nLyaNet, is based on a novel Lyapunov loss formulation that encourages the\ninference dynamics to converge quickly to the correct prediction.\nTheoretically, we show that minimizing Lyapunov loss guarantees exponential\nconvergence to the correct solution and enables a novel robustness guarantee.\nWe also provide practical algorithms, including one that avoids the cost of\nbackpropagating through a solver or using the adjoint method. Relative to\nstandard Neural ODE training, we empirically find that LyaNet can offer\nimproved prediction performance, faster convergence of inference dynamics, and\nimproved adversarial robustness. Our code available at\nhttps://github.com/ivandariojr/LyapunovLearning .",
    "descriptor": "",
    "authors": [
      "Ivan Dario Jimenez Rodriguez",
      "Aaron D. Ames",
      "Yisong Yue"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.02526"
  },
  {
    "id": "arXiv:2202.02529",
    "title": "Graph Neural Network with Curriculum Learning for Imbalanced Node  Classification",
    "abstract": "Graph Neural Network (GNN) is an emerging technique for graph-based learning\ntasks such as node classification. In this work, we reveal the vulnerability of\nGNN to the imbalance of node labels. Traditional solutions for imbalanced\nclassification (e.g. resampling) are ineffective in node classification without\nconsidering the graph structure. Worse still, they may even bring overfitting\nor underfitting results due to lack of sufficient prior knowledge. To solve\nthese problems, we propose a novel graph neural network framework with\ncurriculum learning (GNN-CL) consisting of two modules. For one thing, we hope\nto acquire certain reliable interpolation nodes and edges through the novel\ngraph-based oversampling based on smoothness and homophily. For another, we\ncombine graph classification loss and metric learning loss which adjust the\ndistance between different nodes associated with minority class in feature\nspace. Inspired by curriculum learning, we dynamically adjust the weights of\ndifferent modules during training process to achieve better ability of\ngeneralization and discrimination. The proposed framework is evaluated via\nseveral widely used graph datasets, showing that our proposed model\nconsistently outperforms the existing state-of-the-art methods.",
    "descriptor": "",
    "authors": [
      "Xiaohe Li",
      "Lijie Wen",
      "Yawen Deng",
      "Fuli Feng",
      "Xuming Hu",
      "Lei Wang",
      "Zide Fan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.02529"
  },
  {
    "id": "arXiv:2202.02530",
    "title": "Analyticity of Parametric and Stochastic Elliptic Eigenvalue Problems  with an Application to Quasi-Monte Carlo Methods",
    "abstract": "In the present paper, we study the analyticity of the leftmost eigenvalue of\nthe linear elliptic partial differential operator with random coefficient and\nanalyze the convergence rate of the quasi-Monte Carlo method for approximation\nof the expectation of this quantity. The random coefficient is assumed to be\nrepresented by an affine expansion $a_0(\\boldsymbol{x})+\\sum_{j\\in\n\\mathbb{N}}y_ja_j(\\boldsymbol{x})$, where elements of the parameter vector\n$\\boldsymbol{y}=(y_j)_{j\\in \\mathbb{N}}\\in U^\\infty$ are independent and\nidentically uniformly distributed on $U:=[-\\frac{1}{2},\\frac{1}{2}]$. Under the\nassumption $ \\|\\sum_{j\\in \\mathbb{N}}\\rho_j|a_j|\\|_{L_\\infty(D)} <\\infty$ with\nsome positive sequence $(\\rho_j)_{j\\in \\mathbb{N}}\\in \\ell_p(\\mathbb{N})$ for\n$p\\in (0,1]$ we show that for any $\\boldsymbol{y}\\in U^\\infty$, the elliptic\npartial differential operator has a countably infinite number of eigenvalues\n$(\\lambda_j(\\boldsymbol{y}))_{j\\in \\mathbb{N}}$ which can be ordered\nnon-decreasingly. Moreover, the spectral gap\n$\\lambda_2(\\boldsymbol{y})-\\lambda_1(\\boldsymbol{y})$ is uniformly positive in\n$U^\\infty$. From this, we prove the holomorphic extension property of\n$\\lambda_1(\\boldsymbol{y})$ to a complex domain in $\\mathbb{C}^\\infty$ and\nestimate mixed derivatives of $\\lambda_1(\\boldsymbol{y})$ with respect to the\nparameters $\\boldsymbol{y}$ by using Cauchy's formula for analytic functions.\nBased on these bounds we prove the dimension-independent convergence rate of\nthe quasi-Monte Carlo method to approximate the expectation of\n$\\lambda_1(\\boldsymbol{y})$. In this case, the computational cost of fast\ncomponent-by-component algorithm for generating quasi-Monte Carlo $N$-points\nscales linearly in terms of integration dimension.",
    "descriptor": "\nComments: 18 pages\n",
    "authors": [
      "Van Kien Nguyen"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.02530"
  },
  {
    "id": "arXiv:2202.02533",
    "title": "Blue Data Computation Maximization in 6G Space-Air-Sea Non-Terrestrial  Networks",
    "abstract": "Non-terrestrial networks (NTN), encompassing space and air platforms, are a\nkey component of the upcoming sixth-generation (6G) cellular network.\nMeanwhile, maritime network traffic has grown significantly in recent years due\nto sea transportation used for national defense, research, recreational\nactivities, domestic and international trade. In this paper, the seamless and\nreliable demand for communication and computation in maritime wireless networks\nis investigated. Two types of marine user equipment (UEs), i.e., low-antenna\ngain and high-antenna gain UEs, are considered. A joint task computation and\ntime allocation problem for weighted sum-rate maximization is formulated as\nmixed-integer linear programming (MILP). The goal is to design an algorithm\nthat enables the network to efficiently provide backhaul resources to an\nunmanned aerial vehicle (UAV) and offload HUEs tasks to LEO satellite for blue\ndata (i.e., marine user's data). To solve this MILP, a solution based on the\nBender and primal decomposition is proposed. The Bender decomposes MILP into\nthe master problem for binary task decision and subproblem for continuous-time\nresource allocation. Moreover, primal decomposition deals with a coupling\nconstraint in the subproblem. Finally, numerical results demonstrate that the\nproposed algorithm provides the maritime UEs coverage demand in polynomial time\ncomputational complexity and achieves a near-optimal solution.",
    "descriptor": "",
    "authors": [
      "Sheikh Salman Hassan",
      "Yan Kyaw Tun",
      "Walid Saad",
      "Zhu Han",
      "Choong Seon Hong"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.02533"
  },
  {
    "id": "arXiv:2202.02535",
    "title": "Aspect-based Sentiment Analysis through EDU-level Attentions",
    "abstract": "A sentence may express sentiments on multiple aspects. When these aspects are\nassociated with different sentiment polarities, a model's accuracy is often\nadversely affected. We observe that multiple aspects in such hard sentences are\nmostly expressed through multiple clauses, or formally known as elementary\ndiscourse units (EDUs), and one EDU tends to express a single aspect with\nunitary sentiment towards that aspect. In this paper, we propose to consider\nEDU boundaries in sentence modeling, with attentions at both word and EDU\nlevels. Specifically, we highlight sentiment-bearing words in EDU through\nword-level sparse attention. Then at EDU level, we force the model to attend to\nthe right EDU for the right aspect, by using EDU-level sparse attention and\northogonal regularization. Experiments on three benchmark datasets show that\nour simple EDU-Attention model outperforms state-of-the-art baselines. Because\nEDU can be automatically segmented with high accuracy, our model can be applied\nto sentences directly without the need of manual EDU boundary annotation.",
    "descriptor": "\nComments: Accepted in PAKDD2022\n",
    "authors": [
      "Ting Lin",
      "Aixin Sun",
      "Yequan Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.02535"
  },
  {
    "id": "arXiv:2202.02537",
    "title": "Multidimensional Cybersecurity Framework for Strategic Foresight",
    "abstract": "Cybersecurity is now at the forefront of most organisational digital\ntransformative agendas and National economic, social and political programmes.\nHence its impact to society can no longer be seen to be one dimensional. The\nrise in National cybersecurity laws and regulations is a good indicator of its\nperceived importance to nations. And the recent awakening for social and\nethical transparency in society and coupled with sustainability issues\ndemonstrate the need for a paradigm shift in how cybersecurity discourses can\nnow happen. In response to this shift, a multidimensional cybersecurity\nframework for strategic foresight underpinned on situational awareness is\nproposed. The conceptual cybersecurity framework comprising six domains such as\nPhysical, Cultural, Economic, Social, Political and Cyber, is discussed. The\nguiding principles underpinning the framework are outlined, followed by\nin-depth reflection on the Business, Operational, Technological and Human\n(BOTH) factors and their implications for strategic foresight for\ncybersecurity.",
    "descriptor": "\nComments: 31 pages, 7 figures\n",
    "authors": [
      "Cyril Onwubiko",
      "Karim Ouazzane"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2202.02537"
  },
  {
    "id": "arXiv:2202.02539",
    "title": "Event Log Generation: An Industry Perspective",
    "abstract": "This paper presents the results of an industry expert survey about event log\ngeneration in process mining. It takes academic assumptions as a starting point\nand elicits practitioner's assessments of statements about process execution,\nprocess scoping, process discovery, and process analysis. The results of the\nsurvey shed some light on challenges and perspectives around event log\ngeneration, as well as on the relationship between process models and process\nexecution and derive challenges for event log generation from it. The responses\nindicate that particularly relevant challenges exist around data integration\nand quality, and that process mining can benefit from a systematic integration\nwith more traditional and wide-spread business intelligence approaches.",
    "descriptor": "",
    "authors": [
      "Timotheus Kampik",
      "Mathias Weske"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2202.02539"
  },
  {
    "id": "arXiv:2202.02540",
    "title": "Science Facing Interoperability as a Necessary Condition of Success and  Evil",
    "abstract": "Artificial intelligence (AI) systems, such as machine learning algorithms,\nhave allowed scientists, marketers and governments to shed light on\ncorrelations that remained invisible until now. Beforehand, the dots that we\nhad to connect in order to imagine a new knowledge were either too numerous,\ntoo sparse or not even detected. Sometimes, the information was not stored in\nthe same data lake or format and was not able to communicate. But in creating\nnew bridges with AI, many problems appeared such as bias reproduction, unfair\ninferences or mass surveillance. Our aim is to show that, on one hand, the AI's\ndeep ethical problem lays essentially in these new connections made possible by\nsystems interoperability. In connecting the spheres of our life, these systems\nundermine the notion of justice particular to each of them, because the new\ninteractions create dominances of social goods from a sphere to another. These\nsystems make therefore spheres permeable to one another and, in doing so, they\nopen to progress as well as to tyranny. On another hand, however, we would like\nto emphasize that the act to connect what used to seem a priori disjoint is a\nnecessary move of knowledge and scientific progress.",
    "descriptor": "\nComments: 5 pages, The Society for Philosophy and Technology Conference 2021\n",
    "authors": [
      "Remy Demichelis"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.02540"
  },
  {
    "id": "arXiv:2202.02541",
    "title": "TorchMD-NET: Equivariant Transformers for Neural Network based Molecular  Potentials",
    "abstract": "The prediction of quantum mechanical properties is historically plagued by a\ntrade-off between accuracy and speed. Machine learning potentials have\npreviously shown great success in this domain, reaching increasingly better\naccuracy while maintaining computational efficiency comparable with classical\nforce fields. In this work we propose TorchMD-NET, a novel equivariant\ntransformer (ET) architecture, outperforming state-of-the-art on MD17, ANI-1,\nand many QM9 targets in both accuracy and computational efficiency. Through an\nextensive attention weight analysis, we gain valuable insights into the black\nbox predictor and show differences in the learned representation of conformers\nversus conformations sampled from molecular dynamics or normal modes.\nFurthermore, we highlight the importance of datasets including off-equilibrium\nconformations for the evaluation of molecular potentials.",
    "descriptor": "",
    "authors": [
      "Philipp Th\u00f6lke",
      "Gianni De Fabritiis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Chemical Physics (physics.chem-ph)"
    ],
    "url": "https://arxiv.org/abs/2202.02541"
  },
  {
    "id": "arXiv:2202.02543",
    "title": "Unsupervised Learning on 3D Point Clouds by Clustering and Contrasting",
    "abstract": "Learning from unlabeled or partially labeled data to alleviate human labeling\nremains a challenging research topic in 3D modeling. Along this line,\nunsupervised representation learning is a promising direction to auto-extract\nfeatures without human intervention. This paper proposes a general unsupervised\napproach, named \\textbf{ConClu}, to perform the learning of point-wise and\nglobal features by jointly leveraging point-level clustering and instance-level\ncontrasting. Specifically, for one thing, we design an Expectation-Maximization\n(EM) like soft clustering algorithm that provides local supervision to extract\ndiscriminating local features based on optimal transport. We show that this\ncriterion extends standard cross-entropy minimization to an optimal transport\nproblem, which we solve efficiently using a fast variant of the Sinkhorn-Knopp\nalgorithm. For another, we provide an instance-level contrasting method to\nlearn the global geometry, which is formulated by maximizing the similarity\nbetween two augmentations of one point cloud. Experimental evaluations on\ndownstream applications such as 3D object classification and semantic\nsegmentation demonstrate the effectiveness of our framework and show that it\ncan outperform state-of-the-art techniques.",
    "descriptor": "",
    "authors": [
      "Guofeng Mei",
      "Litao Yu",
      "Qiang Wu",
      "Jian Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2202.02543"
  },
  {
    "id": "arXiv:2202.02545",
    "title": "Optimization of a Real-Time Wavelet-Based Algorithm for Improving Speech  Intelligibility",
    "abstract": "The optimization of a wavelet-based algorithm to improve speech\nintelligibility is reported. The discrete-time speech signal is split into\nfrequency sub-bands via a multi-level discrete wavelet transform. Various gains\nare applied to the sub-band signals before they are recombined to form a\nmodified version of the speech. The sub-band gains are adjusted while keeping\nthe overall signal energy unchanged, and the speech intelligibility under\nvarious background interference and simulated hearing loss conditions is\nenhanced and evaluated objectively and quantitatively using Google\nSpeech-to-Text transcription. For English and Chinese noise-free speech,\noverall intelligibility is improved, and the transcription accuracy can be\nincreased by as much as 80 percentage points by reallocating the spectral\nenergy toward the mid-frequency sub-bands, effectively increasing the\nconsonant-vowel intensity ratio. This is reasonable since the consonants are\nrelatively weak and of short duration, which are therefore the most likely to\nbecome indistinguishable in the presence of background noise or high-frequency\nhearing impairment. For speech already corrupted by noise, improving\nintelligibility is challenging but still realizable. The proposed algorithm is\nimplementable for real-time signal processing and comparatively simpler than\nprevious algorithms. Potential applications include speech enhancement, hearing\naids, machine listening, and a better understanding of speech intelligibility.",
    "descriptor": "\nComments: 12 pages, 7 figures, 4 tables\n",
    "authors": [
      "Tianqu Kang",
      "Anh-Dung Dinh",
      "Binghong Wang",
      "Tianyuan Du",
      "Yijia Chen",
      "Kevin Chau"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2202.02545"
  },
  {
    "id": "arXiv:2202.02550",
    "title": "Intelligent Reflecting Surface-Aided Spectrum Sensing for Cognitive  Radio",
    "abstract": "Spectrum sensing is a key enabling technique for cognitive radio (CR), which\nprovides essential information on the spectrum availability. However, due to\nsevere wireless channel fading and path loss, the primary user (PU) signals\nreceived at the CR or secondary user (SU) can be practically too weak for\nreliable detection. To tackle this issue, we consider in this letter a new\nintelligent reflecting surface (IRS)-aided spectrum sensing scheme for CR, by\nexploiting the large aperture and passive beamforming gains of IRS to boost the\nPU signal strength received at the SU to facilitate its spectrum sensing.\nSpecifically, by dynamically changing the IRS reflection over time according to\na given codebook, its reflected signal power varies substantially at the SU,\nwhich is utilized for opportunistic signal detection. Furthermore, we propose a\nweighted energy detection method by combining the received signal power values\nover different IRS reflections, which significantly improves the detection\nperformance. Simulation results validate the performance gain of the proposed\nIRS-aided spectrum sensing scheme, as compared to different benchmark schemes.",
    "descriptor": "\nComments: Accepted by IEEE Wireless Communications Letters (5 pages, 4 figures)\n",
    "authors": [
      "Shaoe Lin",
      "Beixiong Zheng",
      "Fangjiong Chen",
      "Rui Zhang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Emerging Technologies (cs.ET)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.02550"
  },
  {
    "id": "arXiv:2202.02552",
    "title": "Multiscale Modeling of Sorption Kinetics",
    "abstract": "In this paper we propose and validate a multiscale model for the description\nof particle diffusion in presence of trapping boundaries. We start from a\ndrift-diffusion equation in which the drift term describes the effect of bubble\ntraps, and is modeled by a short range potential with an attractive term and a\nrepulsive core. The interaction of the particles attracted by the bubble\nsurface is simulated by the Lennard-Jones potential that simplifies the capture\ndue to the hydrophobic properties of the ions. In our model the effect of the\npotential is replaced by a suitable boundary condition derived by mass\nconservation and asymptotic analysis. The potential is assumed to have a range\nof small size $\\varepsilon$. An asymptotic expansion in the $\\varepsilon$ is\nconsidered, and the boundary conditions are obtained by retaining the lowest\norder terms in the expansion.\nAnother aspect we investigate is saturation effect coming from high\nconcentrations in the proximity of the bubble surface. Various studies show\nthat these reactions lead to a modification of the model, including also non\nlinear terms. The validity of the model is carefully checked with several tests\nin 1D, 2D and different geometries.",
    "descriptor": "",
    "authors": [
      "Clarissa Astuto",
      "Antonio Raudino",
      "Giovanni Russo"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.02552"
  },
  {
    "id": "arXiv:2202.02556",
    "title": "DEVO: Depth-Event Camera Visual Odometry in Challenging Conditions",
    "abstract": "We present a novel real-time visual odometry framework for a stereo setup of\na depth and high-resolution event camera. Our framework balances accuracy and\nrobustness against computational efficiency towards strong performance in\nchallenging scenarios. We extend conventional edge-based semi-dense visual\nodometry towards time-surface maps obtained from event streams. Semi-dense\ndepth maps are generated by warping the corresponding depth values of the\nextrinsically calibrated depth camera. The tracking module updates the camera\npose through efficient, geometric semi-dense 3D-2D edge alignment. Our approach\nis validated on both public and self-collected datasets captured under various\nconditions. We show that the proposed method performs comparable to\nstate-of-the-art RGB-D camera-based alternatives in regular conditions, and\neventually outperforms in challenging conditions such as high dynamics or low\nillumination.",
    "descriptor": "\nComments: accepted in the 2022 IEEE International Conference on Robotics and Automation (ICRA), Philadelphia (PA), USA\n",
    "authors": [
      "Yi-Fan Zuo",
      "Jiaqi Yang",
      "Jiaben Chen",
      "Xia Wang",
      "Yifu Wang",
      "Laurent Kneip"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.02556"
  },
  {
    "id": "arXiv:2202.02557",
    "title": "Lower-bounds on the Bayesian Risk in Estimation Procedures via  f-Divergences",
    "abstract": "We consider the problem of parameter estimation in a Bayesian setting and\npropose a general lower-bound that includes part of the family of\n$f$-Divergences. The results are then applied to specific settings of interest\nand compared to other notable results in the literature. In particular, we show\nthat the known bounds using Mutual Information can be improved by using, for\nexample, Maximal Leakage, Hellinger divergence, or generalizations of the\nHockey-Stick divergence.",
    "descriptor": "\nComments: Submitted to ISIT 2022\n",
    "authors": [
      "Adrien Vandenbroucque",
      "Amedeo Roberto Esposito",
      "Michael Gastpar"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Probability (math.PR)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2202.02557"
  },
  {
    "id": "arXiv:2202.02559",
    "title": "Digital Twin of Wireless Systems: Overview, Taxonomy, Challenges, and  Opportunities",
    "abstract": "Future wireless services must be focused on improving the quality of life by\nenabling various applications, such as extended reality, brain-computer\ninteraction, and healthcare. These applications have diverse performance\nrequirements (e.g., user-defined quality of experience metrics, latency, and\nreliability) that are challenging to be fulfilled by existing wireless systems.\nTo meet the diverse requirements of the emerging applications, the concept of a\ndigital twin has been recently proposed. A digital twin uses a virtual\nrepresentation along with security-related technologies (e.g., blockchain),\ncommunication technologies (e.g., 6G), computing technologies (e.g., edge\ncomputing), and machine learning, so as to enable the smart applications. In\nthis tutorial, we present a comprehensive overview on digital twins for\nwireless systems. First, we present an overview of fundamental concepts (i.e.,\ndesign aspects, high-level architecture, and frameworks) of digital twin of\nwireless systems. Second, a comprehensive taxonomy is devised for both\ndifferent aspects. These aspects are twins for wireless and wireless for twins.\nFor the twins for wireless aspect, we consider parameters, such as twin objects\ndesign, prototyping, deployment trends, physical devices design, interface\ndesign, incentive mechanism, twins isolation, and decoupling. On the other\nhand, for wireless for twins, parameters such as, twin objects access aspects,\nsecurity and privacy, and air interface design are considered. Finally, open\nresearch challenges and opportunities are presented along with causes and\npossible solutions.",
    "descriptor": "",
    "authors": [
      "Latif U. Khan",
      "Zhu Han",
      "Walid Saad",
      "Ekram Hossain",
      "Mohsen Guizani",
      "Choong Seon Hong"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2202.02559"
  },
  {
    "id": "arXiv:2202.02565",
    "title": "Using SEQUAL for Identifying Requirements to Ecore Editors",
    "abstract": "Software engineers who use Model-Driven Development may be using Ecore for\ntheir work. Ecore is traditionally edited in Eclipse IDE, but a recent\ntransition to Web tools allows for development of new Ecore editors. To\ninvestigate the needed functionality of such modeling tools, the model quality\nframework SEQUAL has been applied. The paper presents the current results of\nthis task, producing requirements for tool functionality as quality improving\nmeans for the following quality aspects: physical, empirical, syntactic,\nsemantic, pragmatic, social and deontic. The result is an extensive list of\ntool functionality that could be implemented by the Ecore editor developers.\nAlthough many requirements are identified, the framework should also help in\nmaking trade-offs in case not all requirements can be implemented. In this way\nthe paper both contribute to identifying modeling tool functionality, and to\nhave input to improve SEQUAL as a general model quality framework. Further work\nwill need to be done on the implementation of the tools for properly evaluating\nthis work.",
    "descriptor": "",
    "authors": [
      "Kristian Rekstad",
      "John Krogstie"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2202.02565"
  },
  {
    "id": "arXiv:2202.02566",
    "title": "LST: Lexicon-Guided Self-Training for Few-Shot Text Classification",
    "abstract": "Self-training provides an effective means of using an extremely small amount\nof labeled data to create pseudo-labels for unlabeled data. Many\nstate-of-the-art self-training approaches hinge on different regularization\nmethods to prevent overfitting and improve generalization. Yet they still rely\nheavily on predictions initially trained with the limited labeled data as\npseudo-labels and are likely to put overconfident label belief on erroneous\nclasses depending on the first prediction. To tackle this issue in text\nclassification, we introduce LST, a simple self-training method that uses a\nlexicon to guide the pseudo-labeling mechanism in a linguistically-enriched\nmanner. We consistently refine the lexicon by predicting confidence of the\nunseen data to teach pseudo-labels better in the training iterations. We\ndemonstrate that this simple yet well-crafted lexical knowledge achieves\n1.0-2.0% better performance on 30 labeled samples per class for five benchmark\ndatasets than the current state-of-the-art approaches.",
    "descriptor": "",
    "authors": [
      "Hazel Kim",
      "Jaeman Son",
      "Yo-Sub Han"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.02566"
  },
  {
    "id": "arXiv:2202.02567",
    "title": "Catch Me if You Can: A Novel Task for Detection of Covert Geo-Locations  (CGL)",
    "abstract": "Most visual scene understanding tasks in the field of computer vision involve\nidentification of the objects present in the scene. Image regions like\nhideouts, turns, & other obscured regions of the scene also contain crucial\ninformation, for specific surveillance tasks. Task proposed in this paper\ninvolves the design of an intelligent visual aid for identification of such\nlocations in an image, which has either the potential to create an imminent\nthreat from an adversary or appear as the target zones needing further\ninvestigation. Covert places (CGL) for hiding behind an occluding object are\nconcealed 3D locations, not detectable from the viewpoint (camera). Hence this\ninvolves delineating specific image regions around the projections of outer\nboundary of the occluding objects, as places to be accessed around the\npotential hideouts. CGL detection finds applications in military\ncounter-insurgency operations, surveillance with path planning for an\nexploratory robot. Given an RGB image, the goal is to identify all CGLs in the\n2D scene. Identification of such regions would require knowledge about the 3D\nboundaries of obscuring items (pillars, furniture), their spatial location with\nrespect to the neighboring regions of the scene. We propose this as a novel\ntask, termed Covert Geo-Location (CGL) Detection. Classification of any region\nof an image as a CGL (as boundary sub-segments of an occluding object that\nconceals the hideout) requires examining the 3D relation between boundaries of\noccluding objects and their neighborhoods & surroundings. Our method\nsuccessfully extracts relevant depth features from a single RGB image and\nquantitatively yields significant improvement over existing object detection\nand segmentation models adapted and trained for CGL detection. We also\nintroduce a novel hand-annotated CGL detection dataset containing 1.5K\nreal-world images for experimentation.",
    "descriptor": "\nComments: This is an updated version of our accepted paper in: fourth workshop on Computer Vision Applications (WCVA), 12th Indian Conference on Computer Vision, Graphics and Image Processing (ICVGIP 20-21), IIT Jodhpur, India, December 2021. [work sponsored under IMPRINT grant]\n",
    "authors": [
      "Binoy Saha",
      "Sukhendu Das"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.02567"
  },
  {
    "id": "arXiv:2202.02568",
    "title": "Symmetric Volume Maps",
    "abstract": "Although shape correspondence is a central problem in geometry processing,\nmost methods for this task apply only to two-dimensional surfaces. The\nneglected task of volumetric correspondence--a natural extension relevant to\nshapes extracted from simulation, medical imaging, volume rendering, and even\nimproving surface maps of boundary representations--presents unique challenges\nthat do not appear in the two-dimensional case. In this work, we propose a\nmethod for mapping between volumes represented as tetrahedral meshes. Our\nformulation minimizes a distortion energy designed to extract maps\nsymmetrically, i.e., without dependence on the ordering of the source and\ntarget domains. We accompany our method with theoretical discussion describing\nthe consequences of this symmetry assumption, leading us to select a\nsymmetrized ARAP energy that favors isometric correspondences. Our final\nformulation optimizes for near-isometry while matching the boundary. We\ndemonstrate our method on a diverse geometric dataset, producing low-distortion\nmatchings that align to the boundary.",
    "descriptor": "",
    "authors": [
      "S. Mazdak Abulnaga",
      "Oded Stein",
      "Polina Golland",
      "Justin Solomon"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.02568"
  },
  {
    "id": "arXiv:2202.02569",
    "title": "AssistMe: Policy iteration for the longitudinal control of a  non-holonomic vehicle",
    "abstract": "In this article we design a physically-inspired model-based assist-as-needed\nsemi-autonomous control (ASC) algorithm to address the problem of safely\ndriving a vehicle (a power wheelchair) in an environment with static obstacles.\nOnce implemented online, the proposed algorithm requires limited computing\npower and relies on pre-computed (offline) maps (look-up tables). These are\nreadily available by implementing policy iteration that minimizes the expected\ntime to termination (safely stopping near an obstacle), by taking into account:\n(i) the vehicle dynamics; (ii) the drivers' intention modeled as three separate\nstochastic processes. We call them the expert driver, the naughty child and the\nblind driver models. A study with healthy participants confirmed that ASC\noutperforms a baseline rule-based control (a statistically significant result).",
    "descriptor": "",
    "authors": [
      "Catalin Stefan Teodorescu",
      "Tom Carlson"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.02569"
  },
  {
    "id": "arXiv:2202.02572",
    "title": "A practical algorithm to minimize the overall error in FEM computations",
    "abstract": "Using the standard finite element method (FEM) to solve general partial\ndifferential equations, the round-off error is found to be proportional to\n$N^{\\beta_{\\rm R}}$, with $N$ the number of degrees of freedom (DoFs) and\n$\\beta_{\\rm R}$ a coefficient. A method which uses a few cheap numerical\nexperiments is proposed to determine the coefficient of proportionality and\n$\\beta_{\\rm R}$ in various space dimensions and FEM packages. Using the\ncoefficients obtained above, the strategy put forward in \\cite{liu386balancing}\nfor predicting the highest achievable accuracy $E_{\\rm min}$ and the associated\noptimal number of DoFs $N_{\\rm opt}$ for specific problems is extended to\ngeneral problems. This strategy allows predicting $E_{\\rm min}$ accurately for\ngeneral problems, with the CPU time for obtaining the solution with the highest\naccuracy $E_{\\rm min}$ typically reduced by 60\\%--90\\%.",
    "descriptor": "",
    "authors": [
      "Jie Liu",
      "Henk M. Schuttelaars",
      "Matthias M\u00f6ller"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.02572"
  },
  {
    "id": "arXiv:2202.02574",
    "title": "Governance of Autonomous Agents on the Web: Challenges and Opportunities",
    "abstract": "The study of autonomous agents has a long tradition in the Multiagent Systems\nand the Semantic Web communities, with applications ranging from automating\nbusiness processes to personal assistants. More recently, the Web of Things\n(WoT), which is an extension of the Internet of Things (IoT) with metadata\nexpressed in Web standards, and its community provide further motivation for\npushing the autonomous agents research agenda forward. Although representing\nand reasoning about norms, policies and preferences is crucial to ensuring that\nautonomous agents act in a manner that satisfies stakeholder requirements,\nnormative concepts, policies and preferences have yet to be considered as\nfirst-class abstractions in Web-based multiagent systems. Towards this end,\nthis paper motivates the need for alignment and joint research across the\nMultiagent Systems, Semantic Web, and WoT communities, introduces a conceptual\nframework for governance of autonomous agents on the Web, and identifies\nseveral research challenges and opportunities.",
    "descriptor": "\nComments: Manuscript accepted for publication in ACM Transactions on Internet Technology\n",
    "authors": [
      "Timotheus Kampik",
      "Adnane Mansour",
      "Olivier Boissier",
      "Sabrina Kirrane",
      "Julian Padget",
      "Terry R. Payne",
      "Munindar P. Singh",
      "Valentina Tamma",
      "Antoine Zimmermann"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2202.02574"
  },
  {
    "id": "arXiv:2202.02575",
    "title": "Differentially Private Graph Classification with GNNs",
    "abstract": "Graph Neural Networks (GNNs) have established themselves as the\nstate-of-the-art models for many machine learning applications such as the\nanalysis of social networks, protein interactions and molecules. Several among\nthese datasets contain privacy-sensitive data. Machine learning with\ndifferential privacy is a promising technique to allow deriving insight from\nsensitive data while offering formal guarantees of privacy protection. However,\nthe differentially private training of GNNs has so far remained under-explored\ndue to the challenges presented by the intrinsic structural connectivity of\ngraphs. In this work, we introduce differential privacy for graph-level\nclassification, one of the key applications of machine learning on graphs. Our\nmethod is applicable to deep learning on multi-graph datasets and relies on\ndifferentially private stochastic gradient descent (DP-SGD). We show results on\na variety of synthetic and public datasets and evaluate the impact of different\nGNN architectures and training hyperparameters on model performance for\ndifferentially private graph classification. Finally, we apply explainability\ntechniques to assess whether similar representations are learned in the private\nand non-private settings and establish robust baselines for future work in this\narea.",
    "descriptor": "",
    "authors": [
      "Tamara T. Mueller",
      "Johannes C. Paetzold",
      "Chinmay Prabhakar",
      "Dmitrii Usynin",
      "Daniel Rueckert",
      "Georgios Kaissis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.02575"
  },
  {
    "id": "arXiv:2202.02576",
    "title": "Causal Disentanglement for Semantics-Aware Intent Learning in  Recommendation",
    "abstract": "Traditional recommendation models trained on observational interaction data\nhave generated large impacts in a wide range of applications, it faces bias\nproblems that cover users' true intent and thus deteriorate the recommendation\neffectiveness. Existing methods tracks this problem as eliminating bias for the\nrobust recommendation, e.g., by re-weighting training samples or learning\ndisentangled representation. The disentangled representation methods as the\nstate-of-the-art eliminate bias through revealing cause-effect of the bias\ngeneration. However, how to design the semantics-aware and unbiased\nrepresentation for users true intents is largely unexplored. To bridge the gap,\nwe are the first to propose an unbiased and semantics-aware disentanglement\nlearning called CaDSI (Causal Disentanglement for Semantics-Aware Intent\nLearning) from a causal perspective. Particularly, CaDSI explicitly models the\ncausal relations underlying recommendation task, and thus produces\nsemantics-aware representations via disentangling users true intents aware of\nspecific item context. Moreover, the causal intervention mechanism is designed\nto eliminate confounding bias stemmed from context information, which further\nto align the semantics-aware representation with users true intent. Extensive\nexperiments and case studies both validate the robustness and interpretability\nof our proposed model.",
    "descriptor": "",
    "authors": [
      "Xiangmeng Wang",
      "Qian Li",
      "Dianer Yu",
      "Peng Cui",
      "Zhichao Wang",
      "Guandong Xu"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.02576"
  },
  {
    "id": "arXiv:2202.02580",
    "title": "Communication Efficient Federated Learning via Ordered ADMM in a Fully  Decentralized Setting",
    "abstract": "The challenge of communication-efficient distributed optimization has\nattracted attention in recent years. In this paper, a communication efficient\nalgorithm, called ordering-based alternating direction method of multipliers\n(OADMM) is devised in a general fully decentralized network setting where a\nworker can only exchange messages with neighbors. Compared to the classical\nADMM, a key feature of OADMM is that transmissions are ordered among workers at\neach iteration such that a worker with the most informative data broadcasts its\nlocal variable to neighbors first, and neighbors who have not transmitted yet\ncan update their local variables based on that received transmission. In OADMM,\nwe prohibit workers from transmitting if their current local variables are not\nsufficiently different from their previously transmitted value. A variant of\nOADMM, called SOADMM, is proposed where transmissions are ordered but\ntransmissions are never stopped for each node at each iteration. Numerical\nresults demonstrate that given a targeted accuracy, OADMM can significantly\nreduce the number of communications compared to existing algorithms including\nADMM. We also show numerically that SOADMM can accelerate convergence,\nresulting in communication savings compared to the classical ADMM.",
    "descriptor": "",
    "authors": [
      "Yicheng Chen",
      "Rick S. Blum",
      "Brian M. Sadler"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.02580"
  },
  {
    "id": "arXiv:2202.02582",
    "title": "Multilevel Picard approximations of high-dimensional semilinear partial  differential equations with locally monotone coefficient functions",
    "abstract": "The full history recursive multilevel Picard approximation method for\nsemilinear parabolic partial differential equations (PDEs) is the only method\nwhich provably overcomes the curse of dimensionality for general time horizons\nif the coefficient functions and the nonlinearity are globally Lipschitz\ncontinuous and the nonlinearity is gradient-independent. In this article we\nextend this result to locally monotone coefficient functions. Our results cover\na range of semilinear PDEs with polynomial coefficient functions.",
    "descriptor": "\nComments: 28 pages\n",
    "authors": [
      "Tuan Anh Nguyen",
      "Martin Hutzenthaler"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2202.02582"
  },
  {
    "id": "arXiv:2202.02583",
    "title": "Temporal Robustness of Stochastic Signals",
    "abstract": "We study the temporal robustness of stochastic signals. This topic is of\nparticular interest in interleaving processes such as multi-agent systems where\ncommunication and individual agents induce timing uncertainty. For a\ndeterministic signal and a given specification, we first introduce the\nsynchronous and the asynchronous temporal robustness to quantify the signal's\nrobustness with respect to synchronous and asynchronous time shifts in its\nsub-signals. We then define the temporal robustness risk by investigating the\ntemporal robustness of the realizations of a stochastic signal. This definition\ncan be interpreted as the risk associated with a stochastic signal to not\nsatisfy a specification robustly in time. In this definition, general forms of\nspecifications such as signal temporal logic specifications are permitted. We\nshow how the temporal robustness risk is estimated from data for the\nvalue-at-risk. The usefulness of the temporal robustness risk is underlined by\nboth theoretical and empirical evidence. In particular, we provide various\nnumerical case studies including a T-intersection scenario in autonomous\ndriving.",
    "descriptor": "\nComments: 24 pages, accepted at presentation at, and presentation in, the 25th ACM International Conference on Hybrid Systems: Computation and Control\n",
    "authors": [
      "Lars Lindemann",
      "Alena Rodionova",
      "George J. Pappas"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2202.02583"
  },
  {
    "id": "arXiv:2202.02585",
    "title": "GhostTalk: Interactive Attack on Smartphone Voice System Through Power  Line",
    "abstract": "Inaudible voice command injection is one of the most threatening attacks\ntowards voice assistants. Existing attacks aim at injecting the attack signals\nover the air, but they require the access to the authorized user's voice for\nactivating the voice assistants. Moreover, the effectiveness of the attacks can\nbe greatly deteriorated in a noisy environment. In this paper, we explore a new\ntype of channel, the power line side-channel, to launch the inaudible voice\ncommand injection. By injecting the audio signals over the power line through a\nmodified charging cable, the attack becomes more resilient against various\nenvironmental factors and liveness detection models. Meanwhile, the smartphone\naudio output can be eavesdropped through the modified cable, enabling a\nhighly-interactive attack.\nTo exploit the power line side-channel, we present GhostTalk, a new hidden\nvoice attack that is capable of injecting and eavesdropping simultaneously. Via\na quick modification of the power bank cables, the attackers could launch\ninteractive attacks by remotely making a phone call or capturing private\ninformation from the voice assistants. GhostTalk overcomes the challenge of\nbypassing the speaker verification system by stealthily triggering a switch\ncomponent to simulate the press button on the headphone. In case when the\nsmartphones are charged by an unaltered standard cable, we discover that it is\npossible to recover the audio signal from smartphone loudspeakers by monitoring\nthe charging current on the power line. To demonstrate the feasibility, we\ndesign GhostTalk-SC, an adaptive eavesdropper system targeting smartphones\ncharged in the public USB ports. To correctly recognize the private information\nin the audio, GhostTalk-SC carefully extracts audio spectra and integrates a\nneural network model to classify spoken digits in the speech.",
    "descriptor": "",
    "authors": [
      "Yuanda Wang",
      "Hanqing Guo",
      "Qiben Yan"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.02585"
  },
  {
    "id": "arXiv:2202.02587",
    "title": "VIS-iTrack: Visual Intention through Gaze Tracking using Low-Cost Webcam",
    "abstract": "Human intention is an internal, mental characterization for acquiring desired\ninformation. From interactive interfaces containing either textual or graphical\ninformation, intention to perceive desired information is subjective and\nstrongly connected with eye gaze. In this work, we determine such intention by\nanalyzing real-time eye gaze data with a low-cost regular webcam. We extracted\nunique features (e.g., Fixation Count, Eye Movement Ratio) from the eye gaze\ndata of 31 participants to generate a dataset containing 124 samples of visual\nintention for perceiving textual or graphical information, labeled as either\nTEXT or IMAGE, having 48.39% and 51.61% distribution, respectively. Using this\ndataset, we analyzed 5 classifiers, including Support Vector Machine (SVM)\n(Accuracy: 92.19%). Using the trained SVM, we investigated the variation of\nvisual intention among 30 participants, distributed in 3 age groups, and found\nout that young users were more leaned towards graphical contents whereas older\nadults felt more interested in textual ones. This finding suggests that\nreal-time eye gaze data can be a potential source of identifying visual\nintention, analyzing which intention aware interactive interfaces can be\ndesigned and developed to facilitate human cognition.",
    "descriptor": "\nComments: 15 pages, 9 figures, 4 tables\n",
    "authors": [
      "Shahed Anzarus Sabab",
      "Mohammad Ridwan Kabir",
      "Sayed Rizban Hussain",
      "Hasan Mahmud",
      "Md. Kamrul Hasan",
      "Husne Ara Rubaiyeat"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.02587"
  },
  {
    "id": "arXiv:2202.02592",
    "title": "PharmaChain: A Blockchain to Ensure Counterfeit Free Pharmaceutical  Supply Chain",
    "abstract": "Access to essential medication is a primary right of every individual in all\ndeveloped, developing and underdeveloped countries. This can be fulfilled by\npharmaceutical supply chains (PSC) in place which will eliminate the boundaries\nbetween different organizations and will equip them to work collectively to\nmake medicines reach even the remote corners of the globe. Due to multiple\nentities, which are geographically widespread, being involved and very complex\ngoods and economic flows, PSC is very difficult to audit and resolve any issues\ninvolved. This has given rise to many issues, including increased threats of\ncounterfeiting, inaccurate information propagation throughout the network\nbecause of data fragmentation, lack of customer confidence and delays in\ndistribution of medication to the place in need. Hence, there is a strong need\nfor robust PSC which is transparent to all parties involved and in which the\nwhole journey of medicine from manufacturer to consumer can be tracked and\ntraced easily. This will not only build safety for the consumers, but will also\nhelp manufacturers to build confidence among consumers and increase sales. In\nthis article, a novel Distributed Ledger Technology (DLT) based transparent\nsupply chain architecture is proposed and a proof-of-concept is implemented.\nEfficiency and scalability of the proposed architecture is evaluated and\ncompared with existing solutions.",
    "descriptor": "\nComments: 25 pages, 15 figures\n",
    "authors": [
      "Anand K. Bapatla",
      "Saraju P. Mohanty",
      "Elias Kougianos"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2202.02592"
  },
  {
    "id": "arXiv:2202.02595",
    "title": "Memory Defense: More Robust Classification via a Memory-Masking  Autoencoder",
    "abstract": "Many deep neural networks are susceptible to minute perturbations of images\nthat have been carefully crafted to cause misclassification. Ideally, a robust\nclassifier would be immune to small variations in input images, and a number of\ndefensive approaches have been created as a result. One method would be to\ndiscern a latent representation which could ignore small changes to the input.\nHowever, typical autoencoders easily mingle inter-class latent representations\nwhen there are strong similarities between classes, making it harder for a\ndecoder to accurately project the image back to the original high-dimensional\nspace. We propose a novel framework, Memory Defense, an augmented classifier\nwith a memory-masking autoencoder to counter this challenge. By masking other\nclasses, the autoencoder learns class-specific independent latent\nrepresentations. We test the model's robustness against four widely used\nattacks. Experiments on the Fashion-MNIST & CIFAR-10 datasets demonstrate the\nsuperiority of our model. We make available our source code at GitHub\nrepository: https://github.com/eashanadhikarla/MemDefense",
    "descriptor": "\nComments: 11 pages\n",
    "authors": [
      "Eashan Adhikarla",
      "Dan Luo",
      "Brian D. Davison"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.02595"
  },
  {
    "id": "arXiv:2202.02601",
    "title": "Exemplar-Based Contrastive Self-Supervised Learning with Few-Shot Class  Incremental Learning",
    "abstract": "Humans are capable of learning new concepts from only a few (labeled)\nexemplars, incrementally and continually. This happens within the context that\nwe can differentiate among the exemplars, and between the exemplars and large\namounts of other data (unlabeled and labeled). This suggests, in human\nlearning, supervised learning of concepts based on exemplars takes place within\nthe larger context of contrastive self-supervised learning (CSSL) based on\nunlabeled and labeled data. We discuss extending CSSL (1) to be based mainly on\nexemplars and only secondly on data augmentation, and (2) to apply to both\nunlabeled data (a large amount is available in general) and labeled data (a few\nexemplars can be obtained with valuable supervised knowledge). A major benefit\nof the extensions is that exemplar-based CSSL, with supervised finetuning,\nsupports few-shot class incremental learning (CIL). Specifically, we discuss\nexemplar-based CSSL including: nearest-neighbor CSSL, neighborhood CSSL with\nsupervised pretraining, and exemplar CSSL with supervised finetuning. We\nfurther discuss using exemplar-based CSSL to facilitate few-shot learning and,\nin particular, few-shot CIL.",
    "descriptor": "",
    "authors": [
      "Daniel T. Chang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.02601"
  },
  {
    "id": "arXiv:2202.02602",
    "title": "Connected and Automated Vehicle Platoon Formation Control via  Differential Games",
    "abstract": "In this study, the connected and automated vehicles (CAVs) platooning problem\nis resolved under a differential game framework. Three information topologies\nare considered here. Firstly, Predecessor-following (PF) topology is utilized\nwhere the vehicles control the distance with respect to the merely nearest\npredecessor via a sensor link-based information flow. Secondly,\nTwo-predecessor-following topology (TPF) is exploited where each vehicle\ncontrols the distance with respect to the two nearest predecessors. In this\ntopology, the second predecessor is communicated via a Vehicle-to-vehicle (V2V)\nlink. The individual trajectories of CAVs under the Nash equilibrium are\nderived in closed-form for these two information topologies. Finally, general\ninformation topology is examined and the differential game is formulated in\nthis context. In all these options, Pontryagin's principle is employed to\ninvestigate the existence and uniqueness of the Nash equilibrium and obtain its\ncorresponding trajectories. In the general topology, we suppose numerical\ncomputation of eigenvalues and eigenvectors. All these approaches represent\npromising and powerful analytical representations of the CAV platoons under the\ndifferential games. Simulation experiments have verified the efficiency of the\nproposed models and their solutions.",
    "descriptor": "\nComments: 18 pages, 7 figures, 3 tables\n",
    "authors": [
      "Hossein B. Jond",
      "Aykut Y\u0131ld\u0131z"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.02602"
  },
  {
    "id": "arXiv:2202.02607",
    "title": "Lazy Risk-Limiting Ballot Comparison Audits",
    "abstract": "Risk-limiting audits or RLAs are rigorous statistical procedures meant to\ndetect invalid election results. In general, they call for an examination of\npaper ballots cast during the election to statistically assess potential\ndisagreements between the winner determined by the ballots and the winner\nreported by tabulation. The design of an RLA must balance risk, the chance that\nthe audit fails to detect such a disagreement when one occurs, with efficiency,\nthe total effort to prepare and conduct the audit. The most efficient\napproaches-when measured in terms of the number of ballots that must be\ninspected-proceed by ballot comparison. This technique, however, requires an\nuntrusted declaration of the contents of each cast ballot, rather than a simple\ntabulation of vote totals. This cast-vote record (CVR) is then spot-checked\nagainst ballots for consistency. The cost of generating such a CVR dominates\nthe cost to conduct the audit in many practical settings which precludes\nadoption. We introduce a new RLA procedure: a lazy ballot comparison audit. In\nthis audit, a global CVR is never produced; instead, when a ballot is selected\nfor audit a three-stage procedure is followed: 1) the batch containing the\nballot is announced, 2) a CVR is produced for that batch, and 3) the ballot is\nannounced and compared with the CVR. The analysis of such an audit is\ncomplicated by the fact that the details of each CVR may depend-perhaps\nadversarially-on the prior history of the audit. We present three main\ncontributions: (1) A formal adversarial model for RLAs; (2) Definition and\nanalysis of a lazy audit procedure with rigorous risk limits and an associated\ncorrectness analysis accounting for the incidental errors arising in typical\naudits; and (3) An analysis of the relative time savings of these techniques.",
    "descriptor": "\nComments: 22 pages\n",
    "authors": [
      "Abigail Harrison",
      "Benjamin Fuller",
      "Alexander Russell"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.02607"
  },
  {
    "id": "arXiv:2202.02609",
    "title": "Logarithmic equal-letter runs for BWT of purely morphic words",
    "abstract": "In this paper we study the number $r_{bwt}$ of equal-letter runs produced by\nthe Burrows-Wheeler transform ($BWT$) when it is applied to purely morphic\nfinite words, which are words generated by iterating prolongable morphisms.\nSuch a parameter $r_{bwt}$ is very significant since it provides a measure of\nthe performances of the $BWT$, in terms of both compressibility and indexing.\nIn particular, we prove that, when $BWT$ is applied to any purely morphic\nfinite word on a binary alphabet, $r_{bwt}$ is $\\mathcal{O}(\\log n)$, where $n$\nis the length of the word. Moreover, we prove that $r_{bwt}$ is $\\Theta(\\log\nn)$ for the binary words generated by a large class of prolongable binary\nmorphisms. These bounds are proved by providing some new structural properties\nof the \\emph{bispecial circular factors} of such words.",
    "descriptor": "",
    "authors": [
      "Andrea Frosini",
      "Ilaria Mancini",
      "Simone Rinaldi",
      "Giuseppe Romana",
      "Marinella Sciortino"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2202.02609"
  },
  {
    "id": "arXiv:2202.02611",
    "title": "Privacy-preserving Speech Emotion Recognition through Semi-Supervised  Federated Learning",
    "abstract": "Speech Emotion Recognition (SER) refers to the recognition of human emotions\nfrom natural speech. If done accurately, it can offer a number of benefits in\nbuilding human-centered context-aware intelligent systems. Existing SER\napproaches are largely centralized, without considering users' privacy.\nFederated Learning (FL) is a distributed machine learning paradigm dealing with\ndecentralization of privacy-sensitive personal data. In this paper, we present\na privacy-preserving and data-efficient SER approach by utilizing the concept\nof FL. To the best of our knowledge, this is the first federated SER approach,\nwhich utilizes self-training learning in conjunction with federated learning to\nexploit both labeled and unlabeled on-device data. Our experimental evaluations\non the IEMOCAP dataset shows that our federated approach can learn\ngeneralizable SER models even under low availability of data labels and highly\nnon-i.i.d. distributions. We show that our approach with as few as 10% labeled\ndata, on average, can improve the recognition rate by 8.67% compared to the\nfully-supervised federated counterparts.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2107.06877\n",
    "authors": [
      "Vasileios Tsouvalas",
      "Tanir Ozcelebi",
      "Nirvana Meratnia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2202.02611"
  },
  {
    "id": "arXiv:2202.02613",
    "title": "On the Complexity of Coordinated Table Selective Substitution Systems",
    "abstract": "We investigate computational resources used by Turing machines (TMs) and\nalternating Turing machines (ATMs) to accept languages generated by coordinated\ntable selective substitution systems with two components. We prove that the\nclass of languages generated by real-time (RL; 0S)-systems, an alternative\ndevice to generate lambda-free labeled marked Petri nets languages, can be\naccepted by nondeterministic TMs in O(log n) space and O(nlog n) time.\nConsequently, this proper sub-class of Petri nets languages (known also as\nL-languages) is included in NSPACE(log n). The class of languages generated by\n(RL; RB)-systems for which the nonterminal alphabet of the RL-grammar is\ncomposed of only one symbol and the nonterminal alphabet of the RB-grammar is\ncomposed of two symbols, can be accepted by ATMs in O(log n) time and space.\nConsequently, this proper subclass of one-counter languages generated by\none-counter machines with only one control state is included in U_E*-uniform\nNC1, hence in SPACE(log n).",
    "descriptor": "",
    "authors": [
      "Liliana Cojocaru"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2202.02613"
  },
  {
    "id": "arXiv:2202.02617",
    "title": "Adaptive Fine-Tuning of Transformer-Based Language Models for Named  Entity Recognition",
    "abstract": "The current standard approach for fine-tuning transformer-based language\nmodels includes a fixed number of training epochs and a linear learning rate\nschedule. In order to obtain a near-optimal model for the given downstream\ntask, a search in optimization hyperparameter space is usually required. In\nparticular, the number of training epochs needs to be adjusted to the dataset\nsize. In this paper, we introduce adaptive fine-tuning, which is an alternative\napproach that uses early stopping and a custom learning rate schedule to\ndynamically adjust the number of training epochs to the dataset size. For the\nexample use case of named entity recognition, we show that our approach not\nonly makes hyperparameter search with respect to the number of training epochs\nredundant, but also leads to improved results in terms of performance,\nstability and efficiency. This holds true especially for small datasets, where\nwe outperform the state-of-the-art fine-tuning method by a large margin.",
    "descriptor": "\nComments: 28 pages, 19 figures\n",
    "authors": [
      "Felix Stollenwerk"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.02617"
  },
  {
    "id": "arXiv:2202.02619",
    "title": "A bird's eye view on Multi-Objective Optimization techniques in  Relational Databases",
    "abstract": "Multi-objective optimization is the problem of optimizing simultaneously\nmultiple objective functions and several techniques exist to deal with this\nproblem. This paper aims to present the main methods that can be used to solve\nthis issue in the context of relational databases. In particular, this work\nexamines Top-k query to get the k best result from a dataset and Skyline query\nthat provides a more general overview of the best results. We also discuss\nFlexible-skyline, a new method designed to improve upon the previous\ntechniques, mitigating their shortcomings. For each method, we describe the\nmain characteristics and present an overview of the algorithms implementing\nsuch thecniques, while comparing advantages and disadvantages.",
    "descriptor": "",
    "authors": [
      "Giuseppe Tortorelli"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2202.02619"
  },
  {
    "id": "arXiv:2202.02623",
    "title": "The case for Zero Trust Digital Forensics",
    "abstract": "It is imperative for all stakeholders that digital forensics investigations\nproduce reliable results to ensure the field delivers a positive contribution\nto the pursuit of justice across the globe. Some aspects of these\ninvestigations are inevitably contingent on trust, however this is not always\nexplicitly considered or critically evaluated. Erroneously treating features of\nthe investigation as trusted can be enormously damaging to the overall\nreliability of an investigations findings as well as the confidence that\nexternal stakeholders can have in it. As an example, digital crime scenes can\nbe manipulated by tampering with the digital artefacts left on devices, yet\nrecent studies have shown that efforts to detect occurrences of this are rare\nand argue that this leaves digital forensics investigations vulnerable to\naccusations of inaccuracy. In this paper a new approach to digital forensics is\nconsidered based on the concept of Zero Trust, an increasingly popular design\nin network security. Zero Trust describes the practitioner mindset and\nprinciples upon which the reliance on trust in network components is eliminated\nin favour of dynamic verification of network interactions. An initial\ndefinition of Zero Trust Digital Forensics will be proposed and then a specific\nexample considered showing how this strategy can be applied to digital forensic\ninvestigations to mitigate against the specific risk of evidence tampering. A\ndefinition of Zero Trust Digital Forensics is proposed, specifically that it is\na strategy adopted by investigators whereby each aspect of an investigation is\nassumed to be unreliable until verified. A new principle will be introduced,\nnamely the multifaceted verification of digital artefacts that can be used by\npractitioners who wish to adopt a Zero Trust Digital Forensics strategy during\ntheir investigations...",
    "descriptor": "",
    "authors": [
      "Christoper Neale",
      "Ian Kennedy",
      "Blain Price",
      "Bashar Nuseibeh"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2202.02623"
  },
  {
    "id": "arXiv:2202.02625",
    "title": "Training Differentially Private Models with Secure Multiparty  Computation",
    "abstract": "We address the problem of learning a machine learning model from training\ndata that originates at multiple data owners while providing formal privacy\nguarantees regarding the protection of each owner's data. Existing solutions\nbased on Differential Privacy (DP) achieve this at the cost of a drop in\naccuracy. Solutions based on Secure Multiparty Computation (MPC) do not incur\nsuch accuracy loss but leak information when the trained model is made publicly\navailable. We propose an MPC solution for training DP models. Our solution\nrelies on an MPC protocol for model training, and an MPC protocol for\nperturbing the trained model coefficients with Laplace noise in a\nprivacy-preserving manner. The resulting MPC+DP approach achieves higher\naccuracy than a pure DP approach while providing the same formal privacy\nguarantees. Our work obtained first place in the iDASH2021 Track III\ncompetition on confidential computing for secure genome analysis.",
    "descriptor": "",
    "authors": [
      "Sikha Pentyala",
      "Davis Railsback",
      "Ricardo Maia",
      "Rafael Dowsley",
      "David Melanson",
      "Anderson Nascimento",
      "Martine De Cock"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.02625"
  },
  {
    "id": "arXiv:2202.02626",
    "title": "Layer-wise Regularized Adversarial Training using Layers Sustainability  Analysis (LSA) framework",
    "abstract": "Deep neural network models are used today in various applications of\nartificial intelligence, the strengthening of which, in the face of adversarial\nattacks is of particular importance. An appropriate solution to adversarial\nattacks is adversarial training, which reaches a trade-off between robustness\nand generalization. This paper introduces a novel framework (Layer\nSustainability Analysis (LSA)) for the analysis of layer vulnerability in a\ngiven neural network in the scenario of adversarial attacks. LSA can be a\nhelpful toolkit to assess deep neural networks and to extend the adversarial\ntraining approaches towards improving the sustainability of model layers via\nlayer monitoring and analysis. The LSA framework identifies a list of Most\nVulnerable Layers (MVL list) of a given network. The relative error, as a\ncomparison measure, is used to evaluate representation sustainability of each\nlayer against adversarial attack inputs. The proposed approach for obtaining\nrobust neural networks to fend off adversarial attacks is based on a layer-wise\nregularization (LR) over LSA proposal(s) for adversarial training (AT); i.e.\nthe AT-LR procedure. AT-LR could be used with any benchmark adversarial attack\nto reduce the vulnerability of network layers and to improve conventional\nadversarial training approaches. The proposed idea performs well theoretically\nand experimentally for state-of-the-art multilayer perceptron and convolutional\nneural network architectures. Compared with the AT-LR and its corresponding\nbase adversarial training, the classification accuracy of more significant\nperturbations increased by 16.35%, 21.79%, and 10.730% on Moon, MNIST, and\nCIFAR-10 benchmark datasets in comparison with the AT-LR and its corresponding\nbase adversarial training, respectively. The LSA framework is available and\npublished at https://github.com/khalooei/LSA.",
    "descriptor": "",
    "authors": [
      "Mohammad Khalooei",
      "Mohammad Mehdi Homayounpour",
      "Maryam Amirmazlaghani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.02626"
  },
  {
    "id": "arXiv:2202.02627",
    "title": "Spatio-Temporal Failure Propagation in Cyber-Physical Power Systems",
    "abstract": "Cascading failure in power systems is triggered by a small perturbation that\nleads to a sequence of failures spread through the system. The interconnection\nbetween different components in a power system causes failures to easily\npropagate across the system. The situation gets worse by considering the\ninterconnection between cyber and physical layers in power systems. A plethora\nof work has studied the cascading failure in power systems to calculate its\nimpact on the system. Understanding how failures propagate into the system in\ntime and space can help the system operator to take preventive actions and\nupgrade the system accordingly. Due to the nonlinearity of the power flow\nequation as well as the engineering constraints in the power system, it is\nessential to understand the spatio-temporal failure propagation in\ncyber-physical power systems (CPPS). This paper proposes an asynchronous\nalgorithm for investigating failure propagation in CPPS. The physics of the\npower system is addressed by the full AC power flow equations. Various\npractical constraints including load shedding, load-generation balance, and\nisland operation are considered to address practical constraints in power\nsystem operation. The propagation of various random initial attacks of\ndifferent sizes is analyzed and visualized to elaborate on the applicability of\nthe proposed approach. Our findings shed light on the cascading failure\nevolution in CPPS.",
    "descriptor": "\nComments: 6 pages, 3 figures, 3 algorithms\n",
    "authors": [
      "Osman Boyaci",
      "M. Rasoul Narimani",
      "Katherine Davis",
      "Erchin Serpedin"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.02627"
  },
  {
    "id": "arXiv:2202.02628",
    "title": "Improved Certified Defenses against Data Poisoning with (Deterministic)  Finite Aggregation",
    "abstract": "Data poisoning attacks aim at manipulating model behaviors through distorting\ntraining data. Previously, an aggregation-based certified defense, Deep\nPartition Aggregation (DPA), was proposed to mitigate this threat. DPA predicts\nthrough an aggregation of base classifiers trained on disjoint subsets of data,\nthus restricting its sensitivity to dataset distortions. In this work, we\npropose an improved certified defense against general poisoning attacks, namely\nFinite Aggregation. In contrast to DPA, which directly splits the training set\ninto disjoint subsets, our method first splits the training set into smaller\ndisjoint subsets and then combines duplicates of them to build larger (but not\ndisjoint) subsets for training base classifiers. This reduces the worst-case\nimpacts of poison samples and thus improves certified robustness bounds. In\naddition, we offer an alternative view of our method, bridging the designs of\ndeterministic and stochastic aggregation-based certified defenses. Empirically,\nour proposed Finite Aggregation consistently improves certificates on MNIST,\nCIFAR-10, and GTSRB, boosting certified fractions by up to 3.05%, 3.87% and\n4.77%, respectively, while keeping the same clean accuracies as DPA's,\neffectively establishing a new state of the art in (pointwise) certified\nrobustness against data poisoning.",
    "descriptor": "",
    "authors": [
      "Wenxiao Wang",
      "Alexander Levine",
      "Soheil Feizi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.02628"
  },
  {
    "id": "arXiv:2202.02629",
    "title": "Improving Probabilistic Models in Text Classification via Active  Learning",
    "abstract": "When using text data, social scientists often classify documents in order to\nuse the resulting document labels as an outcome or predictor. Since it is\nprohibitively costly to label a large number of documents manually, automated\ntext classification has become a standard tool. However, current approaches for\ntext classification do not take advantage of all the data at one's disposal. We\npropose a fast new model for text classification that combines information from\nboth labeled and unlabeled data with an active learning component, where a\nhuman iteratively labels documents that the algorithm is least certain about.\nUsing text data from Wikipedia discussion pages, BBC News articles, historical\nUS Supreme Court opinions, and human rights abuse allegations, we show that by\nintroducing information about the structure of unlabeled data and iteratively\nlabeling uncertain documents, our model improves performance relative to\nclassifiers that (a) only use information from labeled data and (b) randomly\ndecide which documents to label at the cost of manually labelling a small\nnumber of documents.",
    "descriptor": "\nComments: 27 pages, 6 figures\n",
    "authors": [
      "Mitchell Bosley",
      "Saki Kuzushima",
      "Ted Enamorado",
      "Yuki Shiraito"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Applications (stat.AP)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2202.02629"
  },
  {
    "id": "arXiv:2202.02634",
    "title": "A bibliometric investigation into the literature of semantic reasoning  in Internet of Things",
    "abstract": "Nowadays, semantic interoperability is a new keyword in the Internet of\nThings (IoT) for the exchange of information between sources. The constant need\nfor interaction and cooperation has resulted in the creation of the Semantic\nWeb with the help of tools and reasoners which manage personal information.\nGiven the significance of the IoT and the increasing use of semantic techniques\nin this field, the present bibliometric investigation was conducted in the\ndomain of semantic reasoning in the IoT. Bibliometrics involves analyzing\nbibliographic data of scientific sources, and it can be employed to arrive at\nan analysis of the status quo in a scientific field. In this study, through the\nanalysis of 799 articles retrieved from the Web of Science database,\ndistribution of topic categories, prolific and influential authors, language of\narticles, publishers of articles and their geographical distribution, the most\ndebated/researched and the most frequently cited articles, and keyword trends\nwere studied. The results of this study indicate that the number of articles\npublished in the domain of semantic reasoning in the IoT has increased\nconsiderably in recent years. Of the articles analyzed, it was revealed that 10\ncountries produced 84% of the total documents, with China being in the lead.\nMoreover, as a result of keyword analysis, it can be maintained that the words\nfog computing, edge computing, Semantic Web, and wireless sensor network are\namong the most important keywords in this domain. As well, ontology has the\nhighest average number of citations among the specialized keywords.",
    "descriptor": "",
    "authors": [
      "Mohammad Javad Shayegan"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2202.02634"
  },
  {
    "id": "arXiv:2202.02635",
    "title": "Multilingual Hate Speech and Offensive Content Detection using Modified  Cross-entropy Loss",
    "abstract": "The number of increased social media users has led to a lot of people\nmisusing these platforms to spread offensive content and use hate speech.\nManual tracking the vast amount of posts is impractical so it is necessary to\ndevise automated methods to identify them quickly. Large language models are\ntrained on a lot of data and they also make use of contextual embeddings. We\nfine-tune the large language models to help in our task. The data is also quite\nunbalanced; so we used a modified cross-entropy loss to tackle the issue. We\nobserved that using a model which is fine-tuned in hindi corpora performs\nbetter. Our team (HNLP) achieved the macro F1-scores of 0.808, 0.639 in English\nSubtask A and English Subtask B respectively. For Hindi Subtask A, Hindi\nSubtask B our team achieved macro F1-scores of 0.737, 0.443 respectively in\nHASOC 2021.",
    "descriptor": "",
    "authors": [
      "Arka Mitra",
      "Priyanshu Sankhala"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.02635"
  },
  {
    "id": "arXiv:2202.02639",
    "title": "Classification on Sentence Embeddings for Legal Assistance",
    "abstract": "Legal proceedings take plenty of time and also cost a lot. The lawyers have\nto do a lot of work in order to identify the different sections of prior cases\nand statutes. The paper tries to solve the first tasks in AILA2021 (Artificial\nIntelligence for Legal Assistance) that will be held in FIRE2021 (Forum for\nInformation Retrieval Evaluation). The task is to semantically segment the\ndocument into different assigned one of the 7 predefined labels or \"rhetorical\nroles.\" The paper uses BERT to obtain the sentence embeddings from a sentence,\nand then a linear classifier is used to output the final prediction. The\nexperiments show that when more weightage is assigned to the class with the\nhighest frequency, the results are better than those when more weightage is\ngiven to the class with a lower frequency. In task 1, the team legalNLP\nobtained a F1 score of 0.22.",
    "descriptor": "",
    "authors": [
      "Arka Mitra"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.02639"
  },
  {
    "id": "arXiv:2202.02641",
    "title": "Emblaze: Illuminating Machine Learning Representations through  Interactive Comparison of Embedding Spaces",
    "abstract": "Modern machine learning techniques commonly rely on complex, high-dimensional\nembedding representations to capture underlying structure in the data and\nimprove performance. In order to characterize model flaws and choose a\ndesirable representation, model builders often need to compare across multiple\nembedding spaces, a challenging analytical task supported by few existing\ntools. We first interviewed nine embedding experts in a variety of fields to\ncharacterize the diverse challenges they face and techniques they use when\nanalyzing embedding spaces. Informed by these perspectives, we developed a\nnovel system called Emblaze that integrates embedding space comparison within a\ncomputational notebook environment. Emblaze uses an animated, interactive\nscatter plot with a novel Star Trail augmentation to enable visual comparison.\nIt also employs novel neighborhood analysis and clustering procedures to\ndynamically suggest groups of points with interesting changes between spaces.\nThrough a series of case studies with ML experts, we demonstrate how\ninteractive comparison with Emblaze can help gain new insights into embedding\nspace structure.",
    "descriptor": "\nComments: 23 pages, 5 figures, 2 tables. To be presented at IUI'22\n",
    "authors": [
      "Venkatesh Sivaraman",
      "Yiwei Wu",
      "Adam Perer"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.02641"
  },
  {
    "id": "arXiv:2202.02643",
    "title": "The Unreasonable Effectiveness of Random Pruning: Return of the Most  Naive Baseline for Sparse Training",
    "abstract": "Random pruning is arguably the most naive way to attain sparsity in neural\nnetworks, but has been deemed uncompetitive by either post-training pruning or\nsparse training. In this paper, we focus on sparse training and highlight a\nperhaps counter-intuitive finding, that random pruning at initialization can be\nquite powerful for the sparse training of modern neural networks. Without any\ndelicate pruning criteria or carefully pursued sparsity structures, we\nempirically demonstrate that sparsely training a randomly pruned network from\nscratch can match the performance of its dense equivalent. There are two key\nfactors that contribute to this revival: (i) the network sizes matter: as the\noriginal dense networks grow wider and deeper, the performance of training a\nrandomly pruned sparse network will quickly grow to matching that of its dense\nequivalent, even at high sparsity ratios; (ii) appropriate layer-wise sparsity\nratios can be pre-chosen for sparse training, which shows to be another\nimportant performance booster. Simple as it looks, a randomly pruned subnetwork\nof Wide ResNet-50 can be sparsely trained to outperforming a dense Wide\nResNet-50, on ImageNet. We also observed such randomly pruned networks\noutperform dense counterparts in other favorable aspects, such as\nout-of-distribution detection, uncertainty estimation, and adversarial\nrobustness. Overall, our results strongly suggest there is larger-than-expected\nroom for sparse training at scale, and the benefits of sparsity might be more\nuniversal beyond carefully designed pruning. Our source code can be found at\nhttps://github.com/VITA-Group/Random_Pruning.",
    "descriptor": "\nComments: Published as a conference paper at ICLR 2022. Code is available at this https URL\n",
    "authors": [
      "Shiwei Liu",
      "Tianlong Chen",
      "Xiaohan Chen",
      "Li Shen",
      "Decebal Constantin Mocanu",
      "Zhangyang Wang",
      "Mykola Pechenizkiy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.02643"
  },
  {
    "id": "arXiv:2202.02646",
    "title": "RerrFact: Reduced Evidence Retrieval Representations for Scientific  Claim Verification",
    "abstract": "Exponential growth in digital information outlets and the race to publish has\nmade scientific misinformation more prevalent than ever. However, the task to\nfact-verify a given scientific claim is not straightforward even for\nresearchers. Scientific claim verification requires in-depth knowledge and\ngreat labor from domain experts to substantiate supporting and refuting\nevidence from credible scientific sources. The SciFact dataset and\ncorresponding task provide a benchmarking leaderboard to the community to\ndevelop automatic scientific claim verification systems via extracting and\nassimilating relevant evidence rationales from source abstracts. In this work,\nwe propose a modular approach that sequentially carries out binary\nclassification for every prediction subtask as in the SciFact leaderboard. Our\nsimple classifier-based approach uses reduced abstract representations to\nretrieve relevant abstracts. These are further used to train the relevant\nrationale-selection model. Finally, we carry out two-step stance predictions\nthat first differentiate non-relevant rationales and then identify supporting\nor refuting rationales for a given claim. Experimentally, our system RerrFact\nwith no fine-tuning, simple design, and a fraction of model parameters fairs\ncompetitively on the leaderboard against large-scale, modular, and joint\nmodeling approaches. We make our codebase available at\nhttps://github.com/ashishrana160796/RerrFact.",
    "descriptor": "\nComments: Accepted in the AAAI-22 Workshop on Scientific Document Understanding at the Thirty-Sixth AAAI Conference on Artificial Intelligence (SDU@AAAI-22)\n",
    "authors": [
      "Ashish Rana",
      "Deepanshu Khanna",
      "Muskaan Singh",
      "Tirthankar Ghosal",
      "Harpreet Singh",
      "Prashant Singh Rana"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.02646"
  },
  {
    "id": "arXiv:2202.02647",
    "title": "Ethics, Rules of Engagement, and AI: Neural Narrative Mapping Using  Large Transformer Language Models",
    "abstract": "The problem of determining if a military unit has correctly understood an\norder and is properly executing on it is one that has bedeviled military\nplanners throughout history. The advent of advanced language models such as\nOpenAI's GPT-series offers new possibilities for addressing this problem. This\npaper presents a mechanism to harness the narrative output of large language\nmodels and produce diagrams or \"maps\" of the relationships that are latent in\nthe weights of such models as the GPT-3. The resulting \"Neural Narrative Maps\"\n(NNMs), are intended to provide insight into the organization of information,\nopinion, and belief in the model, which in turn provide means to understand\nintent and response in the context of physical distance. This paper discusses\nthe problem of mapping information spaces in general, and then presents a\nconcrete implementation of this concept in the context of OpenAI's GPT-3\nlanguage model for determining if a subordinate is following a commander's\nintent in a high-risk situation. The subordinate's locations within the NNM\nallow a novel capability to evaluate the intent of the subordinate with respect\nto the commander. We show that is is possible not only to determine if they are\nnearby in narrative space, but also how they are oriented, and what\n\"trajectory\" they are on. Our results show that our method is able to produce\nhigh-quality maps, and demonstrate new ways of evaluating intent more\ngenerally.",
    "descriptor": "\nComments: 18 Pages, 13 figures\n",
    "authors": [
      "Philip Feldman",
      "Aaron Dant",
      "David Rosenbluth"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.02647"
  },
  {
    "id": "arXiv:2202.02650",
    "title": "Efficient Logistic Regression with Local Differential Privacy",
    "abstract": "Internet of Things devices are expanding rapidly and generating huge amount\nof data. There is an increasing need to explore data collected from these\ndevices. Collaborative learning provides a strategic solution for the Internet\nof Things settings but also raises public concern over data privacy. In recent\nyears, large amount of privacy preserving techniques have been developed based\non differential privacy and secure multi-party computation. A major challenge\nof collaborative learning is to balance disclosure risk and data utility while\nmaintaining high computation efficiency. In this paper, we proposed privacy\npreserving logistic regression model using matrix encryption approach. The\nsecure scheme achieves local differential privacy and can be implemented for\nboth vertical and horizontal partitioning scenarios. Moreover, cross validation\nis investigated to generate robust model results without increasing the\ncommunication cost. Simulation illustrates the high efficiency of proposed\nscheme to analyze dataset with millions of records. Experimental evaluations\nfurther demonstrate high model accuracy while achieving privacy protection.",
    "descriptor": "",
    "authors": [
      "Guanhong Miao"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)",
      "Other Statistics (stat.OT)"
    ],
    "url": "https://arxiv.org/abs/2202.02650"
  },
  {
    "id": "arXiv:2202.02652",
    "title": "A Graph Neural Network Framework for Grid-Based Simulation",
    "abstract": "Reservoir simulations are computationally expensive in the well control and\nwell placement optimization. Generally, numerous simulation runs (realizations)\nare needed in order to achieve the optimal well locations. In this paper, we\npropose a graph neural network (GNN) framework to build a surrogate\nfeed-forward model which replaces simulation runs to accelerate the\noptimization process. Our GNN framework includes an encoder, a process, and a\ndecoder which takes input from the processed graph data designed and generated\nfrom the simulation raw data. We train the GNN model with 6000 samples\n(equivalent to 40 well configurations) with each containing the previous step\nstate variable and the next step state variable. We test the GNN model with\nanother 6000 samples and after model tuning, both one-step prediction and\nrollout prediction achieve a close match with the simulation results. Our GNN\nframework shows great potential in the application of well-related subsurface\noptimization including oil and gas as well as carbon capture sequestration\n(CCS).",
    "descriptor": "",
    "authors": [
      "Haoyu Tang",
      "Wennan Long"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Geophysics (physics.geo-ph)"
    ],
    "url": "https://arxiv.org/abs/2202.02652"
  },
  {
    "id": "arXiv:2202.02654",
    "title": "Doing Right by Not Doing Wrong in Human-Robot Collaboration",
    "abstract": "As robotic systems become more and more capable of assisting humans in their\neveryday lives, we must consider the opportunities for these artificial agents\nto make their human collaborators feel unsafe or to treat them unfairly. Robots\ncan exhibit antisocial behavior causing physical harm to people or reproduce\nunfair behavior replicating and even amplifying historical and societal biases\nwhich are detrimental to humans they interact with. In this paper, we discuss\nthese issues considering sociable robotic manipulation and fair robotic\ndecision making. We propose a novel approach to learning fair and sociable\nbehavior, not by reproducing positive behavior, but rather by avoiding negative\nbehavior. In this study, we highlight the importance of incorporating\nsociability in robot manipulation, as well as the need to consider fairness in\nhuman-robot interactions.",
    "descriptor": "",
    "authors": [
      "Laura Londo\u00f1o",
      "Adrian R\u00f6fer",
      "Tim Welschehold",
      "Abhinav Valada"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.02654"
  },
  {
    "id": "arXiv:2202.02656",
    "title": "A survey of top-down approaches for human pose estimation",
    "abstract": "Human pose estimation in two-dimensional images videos has been a hot topic\nin the computer vision problem recently due to its vast benefits and potential\napplications for improving human life, such as behaviors recognition, motion\ncapture and augmented reality, training robots, and movement tracking. Many\nstate-of-the-art methods implemented with Deep Learning have addressed several\nchallenges and brought tremendous remarkable results in the field of human pose\nestimation. Approaches are classified into two kinds: the two-step framework\n(top-down approach) and the part-based framework (bottom-up approach). While\nthe two-step framework first incorporates a person detector and then estimates\nthe pose within each box independently, detecting all body parts in the image\nand associating parts belonging to distinct persons is conducted in the\npart-based framework. This paper aims to provide newcomers with an extensive\nreview of deep learning methods-based 2D images for recognizing the pose of\npeople, which only focuses on top-down approaches since 2016. The discussion\nthrough this paper presents significant detectors and estimators depending on\nmathematical background, the challenges and limitations, benchmark datasets,\nevaluation metrics, and comparison between methods.",
    "descriptor": "\nComments: 16 pages\n",
    "authors": [
      "Thong Duy Nguyen",
      "Milan Kresovic"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.02656"
  },
  {
    "id": "arXiv:2202.02658",
    "title": "Deep-HyROMnet: A deep learning-based operator approximation for  hyper-reduction of nonlinear parametrized PDEs",
    "abstract": "To speed-up the solution to parametrized differential problems, reduced order\nmodels (ROMs) have been developed over the years, including projection-based\nROMs such as the reduced-basis (RB) method, deep learning-based ROMs, as well\nas surrogate models obtained via a machine learning approach. Thanks to its\nphysics-based structure, ensured by the use of a Galerkin projection of the\nfull order model (FOM) onto a linear low-dimensional subspace, RB methods yield\napproximations that fulfill the physical problem at hand. However, to make the\nassembling of a ROM independent of the FOM dimension, intrusive and expensive\nhyper-reduction stages are usually required, such as the discrete empirical\ninterpolation method (DEIM), thus making this strategy less feasible for\nproblems characterized by (high-order polynomial or nonpolynomial)\nnonlinearities. To overcome this bottleneck, we propose a novel strategy for\nlearning nonlinear ROM operators using deep neural networks (DNNs). The\nresulting hyper-reduced order model enhanced by deep neural networks, to which\nwe refer to as Deep-HyROMnet, is then a physics-based model, still relying on\nthe RB method approach, however employing a DNN architecture to approximate\nreduced residual vectors and Jacobian matrices once a Galerkin projection has\nbeen performed. Numerical results dealing with fast simulations in nonlinear\nstructural mechanics show that Deep-HyROMnets are orders of magnitude faster\nthan POD-Galerkin-DEIM ROMs, keeping the same level of accuracy.",
    "descriptor": "\nComments: 32 pages\n",
    "authors": [
      "Ludovica Cicci",
      "Stefania Fresca",
      "Andrea Manzoni"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.02658"
  },
  {
    "id": "arXiv:2202.02659",
    "title": "A Game-theoretic Understanding of Repeated Explanations in ML Models",
    "abstract": "This paper formally models the strategic repeated interactions between a\nsystem, comprising of a machine learning (ML) model and associated explanation\nmethod, and an end-user who is seeking a prediction/label and its explanation\nfor a query/input, by means of game theory. In this game, a malicious end-user\nmust strategically decide when to stop querying and attempt to compromise the\nsystem, while the system must strategically decide how much information (in the\nform of noisy explanations) it should share with the end-user and when to stop\nsharing, all without knowing the type (honest/malicious) of the end-user. This\npaper formally models this trade-off using a continuous-time stochastic\nSignaling game framework and characterizes the Markov perfect equilibrium state\nwithin such a framework.",
    "descriptor": "",
    "authors": [
      "Kavita Kumari",
      "Murtuza Jadliwala",
      "Sumit Kumar Jha",
      "Anindya Maiti"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.02659"
  },
  {
    "id": "arXiv:2202.02660",
    "title": "Leveraging the Power of Graph Algorithms: Efficient Algorithms for  Computer-Aided Verification",
    "abstract": "The goal of the thesis is to leverage fast graph algorithms and modern\nalgorithmic techniques for problems in model checking and synthesis on graphs,\nMDPs, and game graphs. The results include symbolic algorithms, a well-known\nclass of algorithms in model checking that trades limited access to the input\nmodel for an efficient representation. In particular, we present the following\nresults: Algorithms for game graphs with mean-payoff B\\\"uchi objectives and\nmean-payoff coB\\\"uchi objectives which match one of the best running time\nbounds for mean-payoff objectives. A near-linear time randomized algorithm for\nStreett objectives in graphs and MDPs. A sub-cubic time algorithm for bounded\nB\\\"uchi objectives in graphs and a cubic time algorithm for game graphs.\nConditional lower bounds for queries of reachability objectives in game graphs\nand MDPs. Linear and near-linear time algorithms for sequential reachability\nobjectives in graphs and MDPs respectively. The first quasi-polynomial time\nsymbolic algorithm for parity objectives in game graphs. We break a\nlong-standing running time bound for MEC decomposition from the '90s by\nproviding a sub-quadratic time symbolic algorithm.",
    "descriptor": "\nComments: Doctoral thesis; abstract shortened and recompiled using PDFLATEX to respect the arXiv limit\n",
    "authors": [
      "Alexander Svozil"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2202.02660"
  },
  {
    "id": "arXiv:2202.02661",
    "title": "LiDAR dataset distillation within bayesian active learning framework:  Understanding the effect of data augmentation",
    "abstract": "Autonomous driving (AD) datasets have progressively grown in size in the past\nfew years to enable better deep representation learning. Active learning (AL)\nhas re-gained attention recently to address reduction of annotation costs and\ndataset size. AL has remained relatively unexplored for AD datasets, especially\non point cloud data from LiDARs. This paper performs a principled evaluation of\nAL based dataset distillation on (1/4th) of the large Semantic-KITTI dataset.\nFurther on, the gains in model performance due to data augmentation (DA) are\ndemonstrated across different subsets of the AL loop. We also demonstrate how\nDA improves the selection of informative samples to annotate. We observe that\ndata augmentation achieves full dataset accuracy using only 60\\% of samples\nfrom the selected dataset configuration. This provides faster training time and\nsubsequent gains in annotation costs.",
    "descriptor": "\nComments: Accepted at VISAPP 2022\n",
    "authors": [
      "Ngoc Phuong Anh Duong",
      "Alexandre Almin",
      "L\u00e9o Lemari\u00e9",
      "B Ravi Kiran"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.02661"
  },
  {
    "id": "arXiv:2202.02664",
    "title": "No Parameters Left Behind: Sensitivity Guided Adaptive Learning Rate for  Training Large Transformer Models",
    "abstract": "Recent research has shown the existence of significant redundancy in large\nTransformer models. One can prune the redundant parameters without\nsignificantly sacrificing the generalization performance. However, we question\nwhether the redundant parameters could have contributed more if they were\nproperly trained. To answer this question, we propose a novel training strategy\nthat encourages all parameters to be trained sufficiently. Specifically, we\nadaptively adjust the learning rate for each parameter according to its\nsensitivity, a robust gradient-based measure reflecting this parameter's\ncontribution to the model performance. A parameter with low sensitivity is\nredundant, and we improve its fitting by increasing its learning rate. In\ncontrast, a parameter with high sensitivity is well-trained, and we regularize\nit by decreasing its learning rate to prevent further overfitting. We conduct\nextensive experiments on natural language understanding, neural machine\ntranslation, and image classification to demonstrate the effectiveness of the\nproposed schedule. Analysis shows that the proposed schedule indeed reduces the\nredundancy and improves generalization performance.",
    "descriptor": "\nComments: Proceedings of ICLR 2022\n",
    "authors": [
      "Chen Liang",
      "Haoming Jiang",
      "Simiao Zuo",
      "Pengcheng He",
      "Xiaodong Liu",
      "Jianfeng Gao",
      "Weizhu Chen",
      "Tuo Zhao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.02664"
  },
  {
    "id": "arXiv:2202.02666",
    "title": "Simulation-to-Reality domain adaptation for offline 3D object annotation  on pointclouds with correlation alignment",
    "abstract": "Annotating objects with 3D bounding boxes in LiDAR pointclouds is a costly\nhuman driven process in an autonomous driving perception system. In this paper,\nwe present a method to semi-automatically annotate real-world pointclouds\ncollected by deployment vehicles using simulated data. We train a 3D object\ndetector model on labeled simulated data from CARLA jointly with real world\npointclouds from our target vehicle. The supervised object detection loss is\naugmented with a CORAL loss term to reduce the distance between labeled\nsimulated and unlabeled real pointcloud feature representations. The goal here\nis to learn representations that are invariant to simulated (labeled) and\nreal-world (unlabeled) target domains. We also provide an updated survey on\ndomain adaptation methods for pointclouds.",
    "descriptor": "",
    "authors": [
      "Weishuang Zhang",
      "B Ravi Kiran",
      "Thomas Gauthier",
      "Yanis Mazouz",
      "Theo Steger"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.02666"
  },
  {
    "id": "arXiv:2202.02668",
    "title": "Unnormalized Measures in Information Theory",
    "abstract": "Information theory is built on probability measures and by definition a\nprobability measure has total mass 1. Probability measures are used to model\nuncertainty, and one may ask how important it is that the total mass is one. We\nclaim that the main reason to normalize measures is that probability measures\nare related to codes via Kraft's inequality. Using a minimum description length\napproach to statistics we will demonstrate with that measures that are not\nnormalized require a new interpretation that we will call the Poisson\ninterpretation. With the Poisson interpretation many problems can be\nsimplified. The focus will shift from from probabilities to mean values. We\ngive examples of improvements of test procedures, improved inequalities,\nsimplified algorithms, new projection results, and improvements in our\ndescription of quantum systems.",
    "descriptor": "\nComments: 6 pages, 3 figures\n",
    "authors": [
      "Peter Harremo\u00ebs"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2202.02668"
  },
  {
    "id": "arXiv:2202.02669",
    "title": "SRPCN: Structure Retrieval based Point Completion Network",
    "abstract": "Given partial objects and some complete ones as references, point cloud\ncompletion aims to recover authentic shapes. However, existing methods pay\nlittle attention to general shapes, which leads to the poor authenticity of\ncompletion results. Besides, the missing patterns are diverse in reality, but\nexisting methods can only handle fixed ones, which means a poor generalization\nability. Considering that a partial point cloud is a subset of the\ncorresponding complete one, we regard them as different samples of the same\ndistribution and propose Structure Retrieval based Point Completion Network\n(SRPCN). It first uses k-means clustering to extract structure points and\ndisperses them into distributions, and then KL Divergence is used as a metric\nto find the complete structure point cloud that best matches the input in a\ndatabase. Finally, a PCN-like decoder network is adopted to generate the final\nresults based on the retrieved structure point clouds. As structure plays an\nimportant role in describing the general shape of an object and the proposed\nstructure retrieval method is robust to missing patterns, experiments show that\nour method can generate more authentic results and has a stronger\ngeneralization ability.",
    "descriptor": "\nComments: 10 pages, 6 figures\n",
    "authors": [
      "Kaiyi Zhang",
      "Ximing Yang",
      "Yuan Wu",
      "Cheng Jin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.02669"
  },
  {
    "id": "arXiv:2202.02670",
    "title": "Pole recovery from noisy data on imaginary axis",
    "abstract": "This note proposes an algorithm for identifying the poles and residues of a\nmeromorphic function from its noisy values on the imaginary axis. The algorithm\nuses M\\\"{o}bius transform and Prony's method in the frequency domain. Numerical\nresults are provided to demonstrate the performance of the algorithm.",
    "descriptor": "",
    "authors": [
      "Lexing Ying"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2202.02670"
  },
  {
    "id": "arXiv:2202.02672",
    "title": "(Almost) Envy-Free, Proportional and Efficient Allocations of an  Indivisible Mixed Manna",
    "abstract": "We study the problem of finding fair and efficient allocations of a set of\nindivisible items to a set of agents, where each item may be a good (positively\nvalued) for some agents and a bad (negatively valued) for others, i.e., a mixed\nmanna. As fairness notions, we consider arguably the strongest possible\nrelaxations of envy-freeness and proportionality, namely envy-free up to any\nitem (EFX and EFX$_0$), and proportional up to the maximin good or any bad\n(PropMX and PropMX$_0$). Our efficiency notion is Pareto-optimality (PO).\nWe study two types of instances:\n(i) Separable, where the item set can be partitioned into goods and bads, and\n(ii) Restricted mixed goods (RMG), where for each item $j$, every agent has\neither a non-positive value for $j$, or values $j$ at the same $v_j>0$. We\nobtain polynomial-time algorithms for the following:\n(i) Separable instances: PropMX$_0$ allocation.\n(ii) RMG instances: Let pure bads be the set of items that everyone values\nnegatively.\n- PropMX allocation for general pure bads.\n- EFX+PropMX allocation for identically-ordered pure bads.\n- EFX+PropMX+PO allocation for identical pure bads.\nFinally, if the RMG instances are further restricted to binary mixed goods\nwhere all the $v_j$'s are the same, we strengthen the results to guarantee\nEFX$_0$ and PropMX$_0$ respectively.",
    "descriptor": "\nComments: 23 pages\n",
    "authors": [
      "Vasilis Livanos",
      "Ruta Mehta",
      "Aniket Murhekar"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.02672"
  },
  {
    "id": "arXiv:2202.02673",
    "title": "PhysFad: Physics-Based End-to-End Channel Modeling of RIS-Parametrized  Environments with Adjustable Fading",
    "abstract": "Programmable radio environments parametrized by reconfigurable intelligent\nsurfaces (RISs) are emerging as a new wireless communications paradigm, but\ncurrently used channel models for the design and analysis of signal-processing\nalgorithms cannot include fading in a manner that is faithful to the underlying\nwave physics. To overcome this roadblock, we introduce a physics-based\nend-to-end model of RIS-parametrized wireless channels with adjustable fading\n(coined PhysFad) which is based on a first-principles coupled-dipole formalism.\nPhysFad naturally incorporates the notions of space and causality, dispersion\n(i.e., frequency selectivity) and the intertwinement of each RIS element's\nphase and amplitude response, as well as any arising mutual coupling effects\nincluding long-range mesoscopic correlations. PhysFad offers the to-date\nmissing tuning knob for adjustable fading. We thoroughly characterize PhysFad\nand demonstrate its capabilities for a prototypical problem of RIS-enabled\nover-the-air channel equalization in rich-scattering wireless communications.\nWe also share a user-friendly version of our code to help the community\ntransition towards physics-based models with adjustable fading.",
    "descriptor": "\nComments: 30 pages, 7 figures, submitted to an IEEE Journal\n",
    "authors": [
      "Rashid Faqiri",
      "Chlo\u00e9 Saigre-Tardif",
      "George C. Alexandropoulos",
      "Nir Shlezinger",
      "Mohammadreza F. Imani",
      "Philipp del Hougne"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)",
      "Applied Physics (physics.app-ph)"
    ],
    "url": "https://arxiv.org/abs/2202.02673"
  },
  {
    "id": "arXiv:2202.02676",
    "title": "Autocorrelation, Wigner and Ambiguity Transforms on Polygons for  Coherent Radiation Rendering",
    "abstract": "Simulating the radar illumination of large scenes generally relies on a\ngeometric model of light transport which largely ignores prominent wave\neffects. This can be remedied through coherence ray-tracing, but this requires\nthe Wigner transform of the aperture. This diffraction function has been\nhistorically difficult to generate, and is relevant in the fields of optics,\nholography, synchrotron-radiation, quantum systems and radar. In this paper we\nprovide the Wigner transform of arbitrary polygons through geometric transforms\nand the Stokes Fourier transform; and display its use in Monte-Carlo rendering.",
    "descriptor": "",
    "authors": [
      "Jacob Mackay",
      "David Johnson",
      "Graham Brooker"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Graphics (cs.GR)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.02676"
  },
  {
    "id": "arXiv:2202.02677",
    "title": "Mitigating Coriolis Effects in Centrifuge Simulators Through Allowing  Small, Unperceived G-Vector Misalignments",
    "abstract": "When coupled with additional degrees of freedom, centrifuge-based motion\nplatforms can combine the agility of hexapod-based platforms with the ability\nto sustain higher G-levels and an extended motion space, required for\nsimulating extreme maneuvers. However, the false and often nauseating\nsensations of rotation, by Coriolis effects induced by the centrifuge rotation\nin combination with rotations of the centrifuge cabin or the pilot's head, are\na major disadvantage. This paper discusses the development of a motion filter,\nthe Coherent Alignment Method (COHAM), which aims at reducing Coriolis effects\nby allowing small mismatches in the G-vector alignment, reducing cabin\nrotations. Simulations show that as long as these mismatches remain within a\nregion where humans perceive the G-vector as 'coherent', the Coherent Alignment\nZone (CAZ), the cabin angular accelerations can indeed be reduced. COHAM was\ntested in a high G-maneuver task with a fixed CAZ threshold obtained in a\nprevious study. It was experimentally compared to an existing motion filter,\nusing metrics such as sickness, comfort and false cues. Results show that\nsickness, dizziness and discomfort are reduced, making the centrifuge sessions\nmore bearable. It is recommended to further improve the filter design and\ntuning, and test it with more fighter pilots.",
    "descriptor": "\nComments: 29 pages, 24 figures\n",
    "authors": [
      "Tigran Mkhoyan",
      "Mark Wentink",
      "Bernd de Graaf",
      "M. M.",
      "van Paassen",
      "Max Mulder"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.02677"
  },
  {
    "id": "arXiv:2202.02679",
    "title": "Featherweight Assisted Vulnerability Discovery",
    "abstract": "Predicting vulnerable source code helps to focus attention on those parts of\nthe code that need to be examined with more scrutiny. Recent work proposed the\nuse of function names as semantic cues that can be learned by a deep neural\nnetwork (DNN) to aid in the hunt for vulnerability of functions.\nCombining identifier splitting, which splits each function name into its\nconstituent words, with a novel frequency-based algorithm, we explore the\nextent to which the words that make up a function's name can predict\npotentially vulnerable functions. In contrast to *lightweight* predictions by a\nDNN that considers only function names, avoiding the use of a DNN provides\n*featherweight* predictions. The underlying idea is that function names that\ncontain certain \"dangerous\" words are more likely to accompany vulnerable\nfunctions. Of course, this assumes that the frequency-based algorithm can be\nproperly tuned to focus on truly dangerous words.\nBecause it is more transparent than a DNN, the frequency-based algorithm\nenables us to investigate the inner workings of the DNN. If successful, this\ninvestigation into what the DNN does and does not learn will help us train more\neffective future models.\nWe empirically evaluate our approach on a heterogeneous dataset containing\nover 73000 functions labeled vulnerable, and over 950000 functions labeled\nbenign. Our analysis shows that words alone account for a significant portion\nof the DNN's classification ability. We also find that words are of greatest\nvalue in the datasets with a more homogeneous vocabulary. Thus, when working\nwithin the scope of a given project, where the vocabulary is unavoidably\nhomogeneous, our approach provides a cheaper, potentially complementary,\ntechnique to aid in the hunt for source-code vulnerabilities. Finally, this\napproach has the advantage that it is viable with orders of magnitude less\ntraining data.",
    "descriptor": "\nComments: 17 pages, 6 figures, 6 tables\n",
    "authors": [
      "David Binkley",
      "Leon Moonen",
      "Sibren Isaacman"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2202.02679"
  },
  {
    "id": "arXiv:2202.02682",
    "title": "Pre-integration via Active Subspaces",
    "abstract": "Pre-integration is an extension of conditional Monte Carlo to quasi-Monte\nCarlo and randomized quasi-Monte Carlo. It can reduce but not increase the\nvariance in Monte Carlo. For quasi-Monte Carlo it can bring about improved\nregularity of the integrand with potentially greatly improved accuracy.\nPre-integration is ordinarily done by integrating out one of $d$ input\nvariables to a function. In the common case of a Gaussian integral one can also\npre-integrate over any linear combination of variables. We propose to do that\nand we choose the first eigenvector in an active subspace decomposition to be\nthe pre-integrated linear combination. We find in numerical examples that this\nactive subspace pre-integration strategy is competitive with pre-integrating\nthe first variable in the principal components construction on the Asian option\nwhere principal components are known to be very effective. It outperforms other\npre-integration methods on some basket options where there is no well\nestablished default. We show theoretically that, just as in Monte Carlo,\npre-integration can reduce but not increase the variance when one uses\nscrambled net integration. We show that the lead eigenvector in an active\nsubspace decomposition is closely related to the vector that maximizes a less\ncomputationally tractable criterion using a Sobol' index to find the most\nimportant linear combination of Gaussian variables. They optimize similar\nexpectations involving the gradient. We show that the Sobol' index criterion\nfor the leading eigenvector is invariant to the way that one chooses the\nremaining $d-1$ eigenvectors with which to sample the Gaussian vector.",
    "descriptor": "",
    "authors": [
      "Sifan Liu",
      "Art B. Owen"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2202.02682"
  },
  {
    "id": "arXiv:2202.02684",
    "title": "On the Multi-View Information Bottleneck Representation",
    "abstract": "In this work, we generalize the information bottleneck (IB) approach to the\nmulti-view learning context. The exponentially growing complexity of the\noptimal representation motivates the development of two novel formulations with\nmore favorable performance-complexity tradeoffs. The first approach is based on\nforming a stochastic consensus and is suited for scenarios with significant\n{\\em representation overlap} between the different views. The second method,\nrelying on incremental updates, is tailored for the other extreme scenario with\nminimal representation overlap. In both cases, we extend our earlier work on\nthe alternating directional methods of multiplier (ADMM) solver and establish\nits convergence and scalability. Empirically, we find that the proposed methods\noutperform state-of-the-art approaches in multi-view classification problems\nunder a broad range of modelling parameters.",
    "descriptor": "",
    "authors": [
      "Teng-Hui Huang",
      "Aly El Gamal",
      "Hesham El Gamal"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.02684"
  },
  {
    "id": "arXiv:2202.02686",
    "title": "PuzzleBots: Physical Coupling of Robot Swarms",
    "abstract": "Robot swarms have been shown to improve the ability of individual robots by\ninter-robot collaboration. In this paper, we present the PuzzleBots - a\nlow-cost robotic swarm system where robots can physically couple with each\nother to form functional structures with minimum energy consumption while\nmaintaining individual mobility to navigate within the environment. Each robot\nhas knobs and holes along the sides of its body so that the robots can couple\nby inserting the knobs into the holes. We present the characterization of knob\ndesign and the result of gap-crossing behavior with up to nine robots. We show\nwith hardware experiments that the robots are able to couple with each other to\ncross gaps and decouple to perform individual tasks. We anticipate the\nPuzzleBots will be useful in unstructured environments as individuals and\ncoupled systems in real-world applications.",
    "descriptor": "",
    "authors": [
      "Sha Yi",
      "Zeynep Temel",
      "Katia Sycara"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.02686"
  },
  {
    "id": "arXiv:2202.02688",
    "title": "Joint Pilot Optimization, Target Detection and Channel Estimation for  Integrated Sensing and Communication Systems",
    "abstract": "Radar sensing will be integrated into the 6G communication system to support\nvarious applications. In this integrated sensing and communication system, a\nradar target may also be a communication channel scatterer. In this case, the\nradar and communication channels exhibit certain joint burst sparsity. We\npropose a two-stage joint pilot optimization, target detection and channel\nestimation scheme to exploit such joint burst sparsity and pilot beamforming\ngain to enhance detection/estimation performance. In Stage 1, the base station\n(BS) sends downlink pilots (DP) for initial target search, and the user sends\nuplink pilots (UP) for channel estimation. Then the BS performs joint target\ndetection and channel estimation based on the reflected DP and received UP\nsignals. In Stage 2, the BS exploits the prior information obtained in Stage 1\nto optimize the DP signal to achieve beamforming gain and further refine the\nperformance. A Turbo Sparse Bayesian inference algorithm is proposed for joint\ntarget detection and channel estimation in both stages. The pilot optimization\nproblem in Stage 2 is a semi-definite programming with rank-1 constraints. By\nreplacing the rank-1 constraint with a tight and smooth approximation, we\npropose an efficient pilot optimization algorithm based on the\nmajorization-minimization method. Simulations verify the advantages of the\nproposed scheme.",
    "descriptor": "\nComments: 30 pages, 8 figures, submitted to IEEE Transactions on Wireless Communications\n",
    "authors": [
      "Zhe Huang",
      "Kexuan Wang",
      "An Liu",
      "Yunlong Cai",
      "Rui Du",
      "Tony Xiao Han"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.02688"
  },
  {
    "id": "arXiv:2202.02691",
    "title": "TTS-GAN: A Transformer-based Time-Series Generative Adversarial Network",
    "abstract": "Signal measurements appearing in the form of time series are one of the most\ncommon types of data used in medical machine learning applications. However,\nsuch datasets are often small, making the training of deep neural network\narchitectures ineffective. For time-series, the suite of data augmentation\ntricks we can use to expand the size of the dataset is limited by the need to\nmaintain the basic properties of the signal. Data generated by a Generative\nAdversarial Network (GAN) can be utilized as another data augmentation tool.\nRNN-based GANs suffer from the fact that they cannot effectively model long\nsequences of data points with irregular temporal relations. To tackle these\nproblems, we introduce TTS-GAN, a transformer-based GAN which can successfully\ngenerate realistic synthetic time-series data sequences of arbitrary length,\nsimilar to the real ones. Both the generator and discriminator networks of the\nGAN model are built using a pure transformer encoder architecture. We use\nvisualizations and dimensionality reduction techniques to demonstrate the\nsimilarity of real and generated time-series data. We also compare the quality\nof our generated data with the best existing alternative, which is an RNN-based\ntime-series GAN.",
    "descriptor": "\nComments: submitted to 20th International Conference on Artificial Intelligence in Medicine (AIME 2022)\n",
    "authors": [
      "Xiaomin Li",
      "Vangelis Metsis",
      "Huangyingrui Wang",
      "Anne Hee Hiong Ngu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.02691"
  },
  {
    "id": "arXiv:2202.02693",
    "title": "Exploration with Multi-Sample Target Values for Distributional  Reinforcement Learning",
    "abstract": "Distributional reinforcement learning (RL) aims to learn a value-network that\npredicts the full distribution of the returns for a given state, often modeled\nvia a quantile-based critic. This approach has been successfully integrated\ninto common RL methods for continuous control, giving rise to algorithms such\nas Distributional Soft Actor-Critic (DSAC). In this paper, we introduce\nmulti-sample target values (MTV) for distributional RL, as a principled\nreplacement for single-sample target value estimation, as commonly employed in\ncurrent practice. The improved distributional estimates further lend themselves\nto UCB-based exploration. These two ideas are combined to yield our\ndistributional RL algorithm, E2DC (Extra Exploration with Distributional\nCritics). We evaluate our approach on a range of continuous control tasks and\ndemonstrate state-of-the-art model-free performance on difficult tasks such as\nHumanoid control. We provide further insight into the method via visualization\nand analysis of the learned distributions and their evolution during training.",
    "descriptor": "\nComments: Submitted to ICML 2022\n",
    "authors": [
      "Michael Teng",
      "Michiel van de Panne",
      "Frank Wood"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.02693"
  },
  {
    "id": "arXiv:2202.02697",
    "title": "Bandwidth-Constrained Distributed Quickest Change Detection in  Heterogeneous Sensor Networks: Anonymous vs Non-Anonymous Settings",
    "abstract": "The heterogeneous distribute quickest changed detection (HetDQCD) problem\nwith 1-bit feedback is studied, in which a fusion center monitors an abrupt\nchange through a bunch of heterogeneous sensors via anonymous 1-bit feedbacks.\nTwo fusion rules, one-shot and voting rules, are considered. We analyze the\nperformance in terms of the worst-case expected detection delay and the average\nrun length to false alarm for the two fusion rules. Our analysis unveils the\nmixed impact of involving more sensors into the decision and enables us to find\nnear optimal choices of parameters in the two schemes. Notably, it is shown\nthat, in contrast to the homogeneous setting, the first alarm rule may no\nlonger lead to the best performance among one-shot schemes. The non-anonymous\nsetting is also investigated where a simple scheme that only accepts alarms\nfrom the most informative sensors is shown to outperform all the above schemes\nand the mixture CUSUM scheme for the anonymous HetDQCD, hinting at the price of\nanonymity.",
    "descriptor": "",
    "authors": [
      "Wen-Hsuan Li",
      "Yu-Chih Huang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.02697"
  },
  {
    "id": "arXiv:2202.02698",
    "title": "Triangle Graph Interest Network for Click-through Rate Prediction",
    "abstract": "Click-through rate prediction is a critical task in online advertising.\nCurrently, many existing methods attempt to extract user potential interests\nfrom historical click behavior sequences. However, it is difficult to handle\nsparse user behaviors or broaden interest exploration. Recently, some\nresearchers incorporate the item-item co-occurrence graph as an auxiliary. Due\nto the elusiveness of user interests, those works still fail to determine the\nreal motivation of user click behaviors. Besides, those works are more biased\ntowards popular or similar commodities. They lack an effective mechanism to\nbreak the diversity restrictions. In this paper, we point out two special\nproperties of triangles in the item-item graphs for recommendation systems:\nIntra-triangle homophily and Inter-triangle heterophiy. Based on this, we\npropose a novel and effective framework named Triangle Graph Interest Network\n(TGIN). For each clicked item in user behavior sequences, we introduce the\ntriangles in its neighborhood of the item-item graphs as a supplement. TGIN\nregards these triangles as the basic units of user interests, which provide the\nclues to capture the real motivation for a user clicking an item. We\ncharacterize every click behavior by aggregating the information of several\ninterest units to alleviate the elusive motivation problem. The attention\nmechanism determines users' preference for different interest units. By\nselecting diverse and relative triangles, TGIN brings in novel and\nserendipitous items to expand exploration opportunities of user interests.\nThen, we aggregate the multi-level interests of historical behavior sequences\nto improve CTR prediction. Extensive experiments on both public and industrial\ndatasets clearly verify the effectiveness of our framework.",
    "descriptor": "\nComments: This paper is accepted by WSDM 2022. Source code: this https URL\n",
    "authors": [
      "Wensen Jiang",
      "Yizhu Jiao",
      "Qingqin Wang",
      "Chuanming Liang",
      "Lijie Guo",
      "Yao Zhang",
      "Zhijun Sun",
      "Yun Xiong",
      "Yangyong Zhu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.02698"
  },
  {
    "id": "arXiv:2202.02702",
    "title": "How Effective is Incongruity? Implications for Code-mix Sarcasm  Detection",
    "abstract": "The presence of sarcasm in conversational systems and social media like\nchatbots, Facebook, Twitter, etc. poses several challenges for downstream NLP\ntasks. This is attributed to the fact that the intended meaning of a sarcastic\ntext is contrary to what is expressed. Further, the use of code-mix language to\nexpress sarcasm is increasing day by day. Current NLP techniques for code-mix\ndata have limited success due to the use of different lexicon, syntax, and\nscarcity of labeled corpora. To solve the joint problem of code-mixing and\nsarcasm detection, we propose the idea of capturing incongruity through\nsub-word level embeddings learned via fastText. Empirical results shows that\nour proposed model achieves F1-score on code-mix Hinglish dataset comparable to\npretrained multilingual models while training 10x faster and using a lower\nmemory footprint",
    "descriptor": "\nComments: Published in ICON - ACL 2021\n",
    "authors": [
      "Aditya Shah",
      "Chandresh Kumar Maurya"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.02702"
  },
  {
    "id": "arXiv:2202.02703",
    "title": "Multi-modal Sensor Fusion for Auto Driving Perception: A Survey",
    "abstract": "Multi-modal fusion is a fundamental task for the perception of an autonomous\ndriving system, which has recently intrigued many researchers. However,\nachieving a rather good performance is not an easy task due to the noisy raw\ndata, underutilized information, and the misalignment of multi-modal sensors.\nIn this paper, we provide a literature review of the existing multi-modal-based\nmethods for perception tasks in autonomous driving. Generally, we make a\ndetailed analysis including over 50 papers leveraging perception sensors\nincluding LiDAR and camera trying to solve object detection and semantic\nsegmentation tasks. Different from traditional fusion methodology for\ncategorizing fusion models, we propose an innovative way that divides them into\ntwo major classes, four minor classes by a more reasonable taxonomy in the view\nof the fusion stage. Moreover, we dive deep into the current fusion methods,\nfocusing on the remaining problems and open-up discussions on the potential\nresearch opportunities. In conclusion, what we expect to do in this paper is to\npresent a new taxonomy of multi-modal fusion methods for the autonomous driving\nperception tasks and provoke thoughts of the fusion-based techniques in the\nfuture.",
    "descriptor": "\nComments: 14 pages, 8 figures\n",
    "authors": [
      "Keli Huang",
      "Botian Shi",
      "Xiang Li",
      "Xin Li",
      "Siyuan Huang",
      "Yikang Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.02703"
  },
  {
    "id": "arXiv:2202.02704",
    "title": "\"I Shake The Package To Check If It's Mine\": A Study of Package Fetching  Practices and Challenges of Blind and Low Vision People in China",
    "abstract": "With about 230 million packages delivered per day in 2020, fetching packages\nhas become a routine for many city dwellers in China. When fetching packages,\npeople usually need to go to collection sites of their apartment complexes or a\nKuaiDiGui, an increasingly popular type of self-service package pickup machine.\nHowever, little is known whether such processes are accessible to blind and low\nvision (BLV) city dwellers. We interviewed BLV people (N=20) living in a large\nmetropolitan area in China to understand their practices and challenges of\nfetching packages. Our findings show that participants encountered difficulties\nin finding the collection site and localizing and recognizing their packages.\nWhen fetching packages from KuaiDiGuis, they had difficulty in identifying the\ncorrect KuaiDiGui, interacting with its touch screen, navigating the complex\non-screen workflow, and opening the target compartment. We discuss design\nconsiderations to make the package fetching process more accessible to the BLV\ncommunity.",
    "descriptor": "\nComments: In Proceedings of CHI Conference on Human Factors in Computing Systems (CHI '22), April 29-May 5, 2022, New Orleans, LA, USA\n",
    "authors": [
      "Wentao Lei",
      "Mingming Fan",
      "Juliann Thang"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2202.02704"
  },
  {
    "id": "arXiv:2202.02705",
    "title": "Portrait Segmentation Using Deep Learning",
    "abstract": "A portrait is a painting, drawing, photograph, or engraving of a person,\nespecially one depicting only the face or head and shoulders. In the digital\nworld the portrait of a person is captured by having the person as a subject in\nthe image and capturing the image of the person such that the background is\nblurred. DSLRs generally do it by reducing the aperture to focus on very close\nregions of interest and automatically blur the background. In this paper I have\ncome up with a novel approach to replicate the portrait mode from DSLR using\nany smartphone to generate high quality portrait images.",
    "descriptor": "",
    "authors": [
      "Sumedh Vilas Datar and",
      "Jesus Gonzales Bernal"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.02705"
  },
  {
    "id": "arXiv:2202.02709",
    "title": "From `Wow' to `Why': Guidelines for Creating the Opening of a Data Video  with Cinematic Styles",
    "abstract": "Data videos are an increasingly popular storytelling form. The opening of a\ndata video critically influences its success as the opening either attracts the\naudience to continue watching or bores them to abandon watching. However,\nlittle is known about how to create an attractive opening. We draw inspiration\nfrom the openings of famous films to facilitate designing data video openings.\nFirst, by analyzing over 200 films from several sources, we derived six primary\ncinematic opening styles adaptable to data videos. Then, we consulted eight\nexperts from the film industry to formulate 28 guidelines. To validate the\nusability and effectiveness of the guidelines, we asked participants to create\ndata video openings with and without the guidelines, which were then evaluated\nby experts and the general public. Results showed that the openings designed\nwith the guidelines were perceived to be more attractive, and the guidelines\nwere praised for clarity and inspiration.",
    "descriptor": "\nComments: In Proceedings of CHI Conference on Human Factors in Computing Systems (CHI '22), April 29-May 5, 2022, New Orleans, LA, USA\n",
    "authors": [
      "Xian Xu",
      "Leni Yang",
      "David Yip",
      "Mingming Fan",
      "Zheng Wei",
      "Huamin Qu"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2202.02709"
  },
  {
    "id": "arXiv:2202.02710",
    "title": "Spectrally Adapted Physics-Informed Neural Networks for Solving  Unbounded Domain Problems",
    "abstract": "Solving analytically intractable partial differential equations (PDEs) that\ninvolve at least one variable defined in an unbounded domain requires efficient\nnumerical methods that accurately resolve the dependence of the PDE on that\nvariable over several orders of magnitude. Unbounded domain problems arise in\nvarious application areas and solving such problems is important for\nunderstanding multi-scale biological dynamics, resolving physical processes at\nlong time scales and distances, and performing parameter inference in\nengineering problems. In this work, we combine two classes of numerical\nmethods: (i) physics-informed neural networks (PINNs) and (ii) adaptive\nspectral methods. The numerical methods that we develop take advantage of the\nability of physics-informed neural networks to easily implement high-order\nnumerical schemes to efficiently solve PDEs. We then show how recently\nintroduced adaptive techniques for spectral methods can be integrated into\nPINN-based PDE solvers to obtain numerical solutions of unbounded domain\nproblems that cannot be efficiently approximated by standard PINNs. Through a\nnumber of examples, we demonstrate the advantages of the proposed spectrally\nadapted PINNs (s-PINNs) over standard PINNs in approximating functions, solving\nPDEs, and estimating model parameters from noisy observations in unbounded\ndomains.",
    "descriptor": "\nComments: 28 pages, 8 figures\n",
    "authors": [
      "Mingtao Xia",
      "Lucas B\u00f6ttcher",
      "Tom Chou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Analysis of PDEs (math.AP)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.02710"
  },
  {
    "id": "arXiv:2202.02711",
    "title": "Hydrogen and Battery Storage Technologies for Low Cost Energy  Decarbonization in Distribution Networks",
    "abstract": "Deep energy decarbonization cannot be achieved without high penetration of\nrenewables. At higher renewable energy penetrations, the variability and\nintermittent nature of solar photovoltaic (PV) electricity can cause ramping\nissues with existing fossil fuel generation, requiring longer term energy\nstorage to increase the reliability of grid operation. A proton exchange\nmembrane electrolyzer can produce H2and serves as a utility controllable load.\nThe produced H2 can then be stored and converted back into electricity, or\nmixed with natural gas, or used as transportation fuel, or chemical feedstock.\nThis paper considers the perspective of the distribution system operator that\noperates the distributed energy resources on a standard IEEE 33-node\ndistribution network considering the technical and physical constraints with\nthe goal of minimizing total investment and operation cost. Different case\nstudies, at very high PV penetrations are considered to show the challenges and\npath to net-zero emission energy production using H2 energy. Sensitivity of\nutility PV costs and electrolyzer capital costs on producing H2 at $1/kg are\npresented showing that the distribution network could produce 100% renewable\nelectricity and H2 could be produced with the same price by 2050 with\nconservative cost estimates and by 2030 with accelerated cost declines.",
    "descriptor": "",
    "authors": [
      "Hamed Haggi",
      "Paul Brooker",
      "Wei Sun",
      "James M. Fenton"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.02711"
  },
  {
    "id": "arXiv:2202.02713",
    "title": "FEAT: Face Editing with Attention",
    "abstract": "Employing the latent space of pretrained generators has recently been shown\nto be an effective means for GAN-based face manipulation. The success of this\napproach heavily relies on the innate disentanglement of the latent space axes\nof the generator. However, face manipulation often intends to affect local\nregions only, while common generators do not tend to have the necessary spatial\ndisentanglement. In this paper, we build on the StyleGAN generator, and present\na method that explicitly encourages face manipulation to focus on the intended\nregions by incorporating learned attention maps. During the generation of the\nedited image, the attention map serves as a mask that guides a blending between\nthe original features and the modified ones. The guidance for the latent space\nedits is achieved by employing CLIP, which has recently been shown to be\neffective for text-driven edits. We perform extensive experiments and show that\nour method can perform disentangled and controllable face manipulations based\non text descriptions by attending to the relevant regions only. Both\nqualitative and quantitative experimental results demonstrate the superiority\nof our method for facial region editing over alternative methods.",
    "descriptor": "",
    "authors": [
      "Xianxu Hou",
      "Linlin Shen",
      "Or Patashnik",
      "Daniel Cohen-Or",
      "Hui Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.02713"
  },
  {
    "id": "arXiv:2202.02717",
    "title": "Learning the random variables in Monte Carlo simulations with stochastic  gradient descent: Machine learning for parametric PDEs and financial  derivative pricing",
    "abstract": "In financial engineering, prices of financial products are computed\napproximately many times each trading day with (slightly) different parameters\nin each calculation. In many financial models such prices can be approximated\nby means of Monte Carlo (MC) simulations. To obtain a good approximation the MC\nsample size usually needs to be considerably large resulting in a long\ncomputing time to obtain a single approximation. In this paper we introduce a\nnew approximation strategy for parametric approximation problems including the\nparametric financial pricing problems described above. A central aspect of the\napproximation strategy proposed in this article is to combine MC algorithms\nwith machine learning techniques to, roughly speaking, learn the random\nvariables (LRV) in MC simulations. In other words, we employ stochastic\ngradient descent (SGD) optimization methods not to train parameters of standard\nartificial neural networks (ANNs) but to learn random variables appearing in MC\napproximations. We numerically test the LRV strategy on various parametric\nproblems with convincing results when compared with standard MC simulations,\nQuasi-Monte Carlo simulations, SGD-trained shallow ANNs, and SGD-trained deep\nANNs. Our numerical simulations strongly indicate that the LRV strategy might\nbe capable to overcome the curse of dimensionality in the $L^\\infty$-norm in\nseveral cases where the standard deep learning approach has been proven not to\nbe able to do so. This is not a contradiction to lower bounds established in\nthe scientific literature because this new LRV strategy is outside of the class\nof algorithms for which lower bounds have been established in the scientific\nliterature. The proposed LRV strategy is of general nature and not only\nrestricted to the parametric financial pricing problems described above, but\napplicable to a large class of approximation problems.",
    "descriptor": "",
    "authors": [
      "Sebastian Becker",
      "Arnulf Jentzen",
      "Marvin S. M\u00fcller",
      "Philippe von Wurstemberger"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2202.02717"
  },
  {
    "id": "arXiv:2202.02721",
    "title": "Robust Anomaly Detection for Time-series Data",
    "abstract": "Time-series anomaly detection plays a vital role in monitoring complex\noperation conditions. However, the detection accuracy of existing approaches is\nheavily influenced by pattern distribution, existence of multiple normal\npatterns, dynamical features representation, and parameter settings. For the\npurpose of improving the robustness and guaranteeing the accuracy, this\nresearch combined the strengths of negative selection, unthresholded recurrence\nplots, and an extreme learning machine autoencoder and then proposed robust\nanomaly detection for time-series data (RADTD), which can automatically learn\ndynamical features in time series and recognize anomalies with low label\ndependency and high robustness. Yahoo benchmark datasets and three tunneling\nengineering simulation experiments were used to evaluate the performance of\nRADTD. The experiments showed that in benchmark datasets RADTD possessed higher\naccuracy and robustness than recurrence qualification analysis and extreme\nlearning machine autoencoder, respectively, and that RADTD accurately detected\nthe occurrence of tunneling settlement accidents, indicating its remarkable\nperformance in accuracy and robustness.",
    "descriptor": "\nComments: 18 pages, 12 figures, 6 tables\n",
    "authors": [
      "Min Hu",
      "Yi Wang",
      "Xiaowei Feng",
      "Shengchen Zhou",
      "Zhaoyu Wu",
      "Yuan Qin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.02721"
  },
  {
    "id": "arXiv:2202.02727",
    "title": "Energy-Aware Edge Association for Cluster-based Personalized Federated  Learning",
    "abstract": "Federated Learning (FL) over wireless network enables data-conscious services\nby leveraging the ubiquitous intelligence at network edge for\nprivacy-preserving model training. As the proliferation of context-aware\nservices, the diversified personal preferences causes disagreeing conditional\ndistributions among user data, which leads to poor inference performance. In\nthis sense, clustered federated learning is proposed to group user devices with\nsimilar preference and provide each cluster with a personalized model. This\ncalls for innovative design in edge association that involves user clustering\nand also resource management optimization. We formulate an accuracy-cost\ntrade-off optimization problem by jointly considering model accuracy,\ncommunication resource allocation and energy consumption. To comply with\nparameter encryption techniques in FL, we propose an iterative solution\nprocedure which employs deep reinforcement learning based approach at cloud\nserver for edge association. The reward function consists of minimized energy\nconsumption at each base station and the averaged model accuracy of all users.\nUnder our proposed solution, multiple edge base station are fully exploited to\nrealize cost efficient personalized federated learning without any prior\nknowledge on model parameters. Simulation results show that our proposed\nstrategy outperforms existing strategies in achieving accurate learning at low\nenergy cost.",
    "descriptor": "",
    "authors": [
      "Y. Li",
      "X. Qin",
      "H. Chen",
      "K. Han",
      "P. Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2202.02727"
  },
  {
    "id": "arXiv:2202.02729",
    "title": "IVeri: Privacy-Preserving Interdomain Verification",
    "abstract": "In an interdomain network, autonomous systems (ASes) often establish peering\nagreements, so that one AS (agreement consumer) can influence the routing\npolicies of the other AS (agreement provider). Peering agreements are\nimplemented in the BGP configuration of the agreement provider. It is crucial\nto verify their implementation because one error can lead to disastrous\nconsequences. However, the fundamental challenge for peering agreement\nverification is how to preserve the privacy of both ASes involved in the\nagreement. To this end, this paper presents IVeri, the first privacy-preserving\ninterdomain agreement verification system. IVeri models the interdomain\nagreement verification problem as a SAT formula, and develops a novel,\nefficient, privacy-serving SAT solver, which uses oblivious shuffling and\ngarbled circuits as the key building blocks to let the agreement consumer and\nprovider collaboratively verify the implementation of interdomain peering\nagreements without exposing their private information. A prototype of IVeri is\nimplemented and evaluated extensively. Results show that IVeri achieves\naccurate, privacy-preserving interdomain agreement verification with reasonable\noverhead.",
    "descriptor": "",
    "authors": [
      "Ning Luo",
      "Qiao Xiang",
      "Timos Antonopoulos",
      "Ruzica Piskac",
      "Y. Richard Yang",
      "Franck Le"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2202.02729"
  },
  {
    "id": "arXiv:2202.02734",
    "title": "The Self-Driving Car: Crossroads at the Bleeding Edge of Artificial  Intelligence and Law",
    "abstract": "Artificial intelligence (AI) features are increasingly being embedded in cars\nand are central to the operation of self-driving cars (SDC). There is little or\nno effort expended towards understanding and assessing the broad legal and\nregulatory impact of the decisions made by AI in cars. A comprehensive\nliterature review was conducted to determine the perceived barriers, benefits\nand facilitating factors of SDC in order to help us understand the suitability\nand limitations of existing and proposed law and regulation. (1) existing and\nproposed laws are largely based on claimed benefits of SDV that are still\nmostly speculative and untested; (2) while publicly presented as issues of\nassigning blame and identifying who pays where the SDC is involved in an\naccident, the barriers broadly intersect with almost every area of society,\nlaws and regulations; and (3) new law and regulation are most frequently\nidentified as the primary factor for enabling SDC. Research on assessing the\nimpact of AI in SDC needs to be broadened beyond negligence and liability to\nencompass barriers, benefits and facilitating factors identified in this paper.\nResults of this paper are significant in that they point to the need for deeper\ncomprehension of the broad impact of all existing law and regulations on the\nintroduction of SDC technology, with a focus on identifying only those areas\ntruly requiring ongoing legislative attention.",
    "descriptor": "",
    "authors": [
      "Scott McLachlan",
      "Evangelia Kyrimi",
      "Kudakwashe Dube",
      "Norman Fenton",
      "Burkhard Schafer"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.02734"
  },
  {
    "id": "arXiv:2202.02738",
    "title": "Enhancing variational generation through self-decomposition",
    "abstract": "In this article we introduce the notion of Split Variational Autoencoder\n(SVAE), whose output $\\hat{x}$ is obtained as a weighted sum $\\sigma \\odot\n\\hat{x_1} + (1-\\sigma) \\odot \\hat{x_2}$ of two generated images\n$\\hat{x_1},\\hat{x_2}$, and $\\sigma$ is a learned compositional map. The network\nis trained as a usual Variational Autoencoder with a negative loglikelihood\nloss between training and reconstructed images. The decomposition is\nnondeterministic, but follows two main schemes, that we may roughly categorize\nas either \"syntactic\" or \"semantic\". In the first case, the map tends to\nexploit the strong correlation between adjacent pixels, splitting the image in\ntwo complementary high frequency sub-images. In the second case, the map\ntypically focuses on the contours of objects, splitting the image in\ninteresting variations of its content, with more marked and distinctive\nfeatures. In this case, the Fr\\'echet Inception Distance (FID) of $\\hat{x_1}$\nand $\\hat{x_2}$ is usually lower (hence better) than that of $\\hat{x}$, that\nclearly suffers from being the average of the formers. In a sense, a SVAE\nforces the Variational Autoencoder to {\\em make choices}, in contrast with its\nintrinsic tendency to average between alternatives with the aim to minimize the\nreconstruction loss towards a specific sample. According to the FID metric, our\ntechnique, tested on typical datasets such as Mnist, Cifar10 and Celeba, allows\nus to outperform all previous purely variational architectures (not relying on\nnormalization flows).",
    "descriptor": "",
    "authors": [
      "Andrea Asperti",
      "Laura Bugo",
      "Daniele Filippini"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2202.02738"
  },
  {
    "id": "arXiv:2202.02748",
    "title": "Visual Behaviors and Mobile Information Acquisition",
    "abstract": "It is common for people to engage in information acquisition tasks while on\nthe move. To understand how users' visual behaviors influence microlearning, a\nform of mobile information acquisition, we conducted a shadowing study with 8\nparticipants and identified three common visual behaviors: 'glance', 'inspect',\nand 'drift'. We found that 'drift' best supports mobile information\nacquisition. We also identified four user-related factors that can influence\nthe utilization of mobile information acquisition opportunities: situational\nawareness, switching costs, ongoing cognitive processes, and awareness of\nopportunities. We further examined how these user-related factors interplay\nwith device-related factors through a technology probe with 20 participants\nusing mobile phones and optical head-mounted displays (OHMDs). Results indicate\nthat different device platforms significantly influence how mobile information\nacquisition opportunities are used: OHMDs can better support mobile information\nacquisition when visual attention is fragmented. OHMDs facilitate shorter\nvisual switch-times between the task and surroundings, which reduces the mental\nbarrier of task transition. Mobile phones, on the other hand, provide a more\nfocused experience in more stable surroundings. Based on these findings, we\ndiscuss trade-offs and design implications for supporting information\nacquisition tasks on the move.",
    "descriptor": "\nComments: 25 pages, 10 figures\n",
    "authors": [
      "Nuwan Janaka",
      "Xinke Wu",
      "Shan Zhang",
      "Shengdong Zhao",
      "Petr Slovak"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2202.02748"
  },
  {
    "id": "arXiv:2202.02749",
    "title": "Exponentially Stable Adaptive Control of MIMO Systems with Unknown  Control Matrix",
    "abstract": "The scope of this research is a problem of the direct model reference\nadaptive control of linear time-invariant multi-input multi-output (MIMO)\nplants without any a priori knowledge about system matrices. To handle it, a\nnew method is proposed, which includes three main stages. Firstly, using the\nwell-known DREM procedure, the plant parametrization is made to obtain the\nlinear regressions, in which the plant matrices and state initial conditions\nare the unknown parameters. Secondly, such regressions are substituted into the\nknown equations for the controller parameters calculation. Thirdly, the\ncontroller parameters are identified using the novel adjustment law with\nexponential rate of convergence. To the best of the authors knowledge, such a\nmethod is the first one to provide the following features simultaneously: 1) it\nis applicable for the generic completely unknown MIMO systems (e.g. without any\ninformation about state or control allocation matrices, the sign of the latter,\netc.); 2) it guarantees the exponential convergence of both the parameter and\ntracking errors under the mild requirement of the regressor finite excitation;\n3) it ensures monotonicity of the transient curves of the control law\nparameters matrices. The results of the conducted experiments with the model of\na rubber and ailerons control of a small passenger aircraft corroborate all the\ntheoretical results.",
    "descriptor": "\nComments: 6 pages, 4 figures\n",
    "authors": [
      "Anton Glushchenko",
      "Konstantin Lastochkin"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.02749"
  },
  {
    "id": "arXiv:2202.02751",
    "title": "Pipe Overflow: Smashing Voice Authentication for Fun and Profit",
    "abstract": "Recent years have seen a surge of popularity of acoustics-enabled personal\ndevices powered by machine learning. Yet, machine learning has proven to be\nvulnerable to adversarial examples. Large number of modern systems protect\nthemselves against such attacks by targeting the artificiality, i.e., they\ndeploy mechanisms to detect the lack of human involvement in generating the\nadversarial examples. However, these defenses implicitly assume that humans are\nincapable of producing meaningful and targeted adversarial examples. In this\npaper, we show that this base assumption is wrong. In particular, we\ndemonstrate that for tasks like speaker identification, a human is capable of\nproducing analog adversarial examples directly with little cost and\nsupervision: by simply speaking through a tube, an adversary reliably\nimpersonates other speakers in eyes of ML models for speaker identification.\nOur findings extend to a range of other acoustic-biometric tasks such as\nliveness, bringing into question their use in security-critical settings in\nreal life, such as phone banking.",
    "descriptor": "",
    "authors": [
      "Shimaa Ahmed",
      "Yash Wani",
      "Ali Shahin Shamsabadi",
      "Mohammad Yaghini",
      "Ilia Shumailov",
      "Nicolas Papernot",
      "Kassem Fawaz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2202.02751"
  },
  {
    "id": "arXiv:2202.02757",
    "title": "A Review of Modern Fashion Recommender Systems",
    "abstract": "The textile and apparel industries have grown tremendously over the last\nyears. Customers no longer have to visit many stores, stand in long queues, or\ntry on garments in dressing rooms as millions of products are now available in\nonline catalogs. However, given the plethora of options available, an effective\nrecommendation system is necessary to properly sort, order, and communicate\nrelevant product material or information to users. Effective fashion RS can\nhave a noticeable impact on billions of customers' shopping experiences and\nincrease sales and revenues on the provider-side.\nThe goal of this survey is to provide a review of recommender systems that\noperate in the specific vertical domain of garment and fashion products. We\nhave identified the most pressing challenges in fashion RS research and created\na taxonomy that categorizes the literature according to the objective they are\ntrying to accomplish (e.g., item or outfit recommendation, size recommendation,\nexplainability, among others) and type of side-information (users, items,\ncontext). We have also identified the most important evaluation goals and\nperspectives (outfit generation, outfit recommendation, pairing recommendation,\nand fill-in-the-blank outfit compatibility prediction) and the most commonly\nused datasets and evaluation metrics.",
    "descriptor": "\nComments: 35 pages, 2 figures\n",
    "authors": [
      "Yashar Deldjoo",
      "Fatemeh Nazary",
      "Arnau Ramisa",
      "Julian Mcauley",
      "Giovanni Pellegrini",
      "Alejandro Bellogin",
      "Tommaso Di Noia"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2202.02757"
  },
  {
    "id": "arXiv:2202.02758",
    "title": "3D Map Reconstruction of an Orchard using an Angle-Aware Covering  Control Strategy",
    "abstract": "In the last years, unmanned aerial vehicles are becoming a reality in the\ncontext of precision agriculture, mainly for monitoring, patrolling and remote\nsensing tasks, but also for 3D map reconstruction. In this paper, we present an\ninnovative approach where a fleet of unmanned aerial vehicles is exploited to\nperform remote sensing tasks over an apple orchard for reconstructing a 3D map\nof the field, formulating the covering control problem to combine the position\nof a monitoring target and the viewing angle. Moreover, the objective function\nof the controller is defined by an importance index, which has been computed\nfrom a multi-spectral map of the field, obtained by a preliminary flight, using\na semantic interpretation scheme based on a convolutional neural network. This\nobjective function is then updated according to the history of the past\ncoverage states, thus allowing the drones to take situation-adaptive actions.\nThe effectiveness of the proposed covering control strategy has been validated\nthrough simulations on a Robot Operating System.",
    "descriptor": "\nComments: 6 pages, 6 figures\n",
    "authors": [
      "Martina Mammarella",
      "Cesare Donati",
      "Takumi Shimizu",
      "Masaya Suenaga",
      "Lorenzo Comba",
      "Alessandro Biglia",
      "Kuniaki Uto",
      "Takeshi Hatanaka",
      "Paolo Gay",
      "Fabrizio Dabbene"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.02758"
  },
  {
    "id": "arXiv:2202.02759",
    "title": "Node-wise monotone barrier coupling law for central pattern generation",
    "abstract": "With the aim of providing new insights into the mechanisms behind the\nemergence of collective behaviors via nonlinear coupling, we propose a\nnode-wise monotone barrier coupling law that imitates the behavior and\nbeneficial properties of neural central pattern generators (CPGs). In\nparticular, the coupling law 1) allows us to assign multiple central patterns\non the circle and 2) allows for rapid switching between different patterns via\nsimple `kicks'. In the end, we achieve full control by partitioning the state\nspace by utilizing a barrier effect and assigning unique steady-state behaviors\nto each element of the resulting partition. We analyze the global behavior and\nstudy the viability of the design.",
    "descriptor": "\nComments: 13 pages, 8 figures\n",
    "authors": [
      "Jin Gyu Lee",
      "Cyrus Mostajeran",
      "Graham Van Goffrier"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.02759"
  },
  {
    "id": "arXiv:2202.02760",
    "title": "Optimal Correlators and Waveforms for Mismatched Detection",
    "abstract": "We consider the classical Neymann-Pearson hypothesis testing problem of\nsignal detection, where under the null hypothesis ($\\calH_0$), the received\nsignal is white Gaussian noise, and under the alternative hypothesis\n($\\calH_1$), the received signal includes also an additional non-Gaussian\nrandom signal, which in turn can be viewed as a deterministic waveform plus\nzero-mean, non-Gaussian noise. However, instead of the classical likelihood\nratio test detector, which might be difficult to implement, in general, we\nimpose a (mismatched) correlation detector, which is relatively easy to\nimplement, and we characterize the optimal correlator weights in the sense of\nthe best trade-off between the false-alarm error exponent and the\nmissed-detection error exponent. Those optimal correlator weights depend\n(non-linearly, in general) on the underlying deterministic waveform under\n$\\calH_1$. We then assume that the deterministic waveform may also be free to\nbe optimized (subject to a power constraint), jointly with the correlator, and\nshow that both the optimal waveform and the optimal correlator weights may take\non values in a small finite set of typically no more than two to four levels,\ndepending on the distribution of the non-Gaussian noise component. Finally, we\noutline an extension of the scope to a wider class of detectors that are based\non linear combinations of the correlation and the energy of the received\nsignal.",
    "descriptor": "\nComments: 29 pages, 4 figures, submitted for publication\n",
    "authors": [
      "Neri Merhav"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.02760"
  },
  {
    "id": "arXiv:2202.02763",
    "title": "Riemannian Score-Based Generative Modeling",
    "abstract": "Score-based generative models (SGMs) are a novel class of generative models\ndemonstrating remarkable empirical performance. One uses a diffusion to add\nprogressively Gaussian noise to the data, while the generative model is a\n\"denoising\" process obtained by approximating the time-reversal of this\n\"noising\" diffusion. However, current SGMs make the underlying assumption that\nthe data is supported on a Euclidean manifold with flat geometry. This prevents\nthe use of these models for applications in robotics, geoscience or protein\nmodeling which rely on distributions defined on Riemannian manifolds. To\novercome this issue, we introduce Riemannian Score-based Generative Models\n(RSGMs) which extend current SGMs to the setting of compact Riemannian\nmanifolds. We illustrate our approach with earth and climate science data and\nshow how RSGMs can be accelerated by solving a Schr\\\"odinger bridge problem on\nmanifolds.",
    "descriptor": "\nComments: 31 pages\n",
    "authors": [
      "Valentin De Bortoli",
      "Emile Mathieu",
      "Michael Hutchinson",
      "James Thornton",
      "Yee Whye Teh",
      "Arnaud Doucet"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Probability (math.PR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.02763"
  },
  {
    "id": "arXiv:2202.02765",
    "title": "Pushing the Efficiency-Regret Pareto Frontier for Online Learning of  Portfolios and Quantum States",
    "abstract": "We revisit the classical online portfolio selection problem. It is widely\nassumed that a trade-off between computational complexity and regret is\nunavoidable, with Cover's Universal Portfolios algorithm, SOFT-BAYES and\nADA-BARRONS currently constituting its state-of-the-art Pareto frontier. In\nthis paper, we present the first efficient algorithm, BISONS, that obtains\npolylogarithmic regret with memory and per-step running time requirements that\nare polynomial in the dimension, displacing ADA-BARRONS from the Pareto\nfrontier. Additionally, we resolve a COLT 2020 open problem by showing that a\ncertain Follow-The-Regularized-Leader algorithm with log-barrier regularization\nsuffers an exponentially larger dependence on the dimension than previously\nconjectured. Thus, we rule out this algorithm as a candidate for the Pareto\nfrontier. We also extend our algorithm and analysis to a more general problem\nthan online portfolio selection, viz. online learning of quantum states with\nlog loss. This algorithm, called SCHRODINGER'S BISONS, is the first efficient\nalgorithm with polylogarithmic regret for this more general problem.",
    "descriptor": "",
    "authors": [
      "Julian Zimmert",
      "Naman Agarwal",
      "Satyen Kale"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.02765"
  },
  {
    "id": "arXiv:2202.02776",
    "title": "Human rights, democracy, and the rule of law assurance framework for AI  systems: A proposal",
    "abstract": "Following on from the publication of its Feasibility Study in December 2020,\nthe Council of Europe's Ad Hoc Committee on Artificial Intelligence (CAHAI) and\nits subgroups initiated efforts to formulate and draft its Possible Elements of\na Legal Framework on Artificial Intelligence, based on the Council of Europe's\nstandards on human rights, democracy, and the rule of law. This document was\nultimately adopted by the CAHAI plenary in December 2021. To support this\neffort, The Alan Turing Institute undertook a programme of research that\nexplored the governance processes and practical tools needed to operationalise\nthe integration of human right due diligence with the assurance of trustworthy\nAI innovation practices.\nThe resulting framework was completed and submitted to the Council of Europe\nin September 2021. It presents an end-to-end approach to the assurance of AI\nproject lifecycles that integrates context-based risk analysis and appropriate\nstakeholder engagement with comprehensive impact assessment, and transparent\nrisk management, impact mitigation, and innovation assurance practices. Taken\ntogether, these interlocking processes constitute a Human Rights, Democracy and\nthe Rule of Law Assurance Framework (HUDERAF). The HUDERAF combines the\nprocedural requirements for principles-based human rights due diligence with\nthe governance mechanisms needed to set up technical and socio-technical\nguardrails for responsible and trustworthy AI innovation practices. Its purpose\nis to provide an accessible and user-friendly set of mechanisms for\nfacilitating compliance with a binding legal framework on artificial\nintelligence, based on the Council of Europe's standards on human rights,\ndemocracy, and the rule of law, and to ensure that AI innovation projects are\ncarried out with appropriate levels of public accountability, transparency, and\ndemocratic governance.",
    "descriptor": "\nComments: 341 pages\n",
    "authors": [
      "David Leslie",
      "Christopher Burr",
      "Mhairi Aitken",
      "Michael Katell",
      "Morgan Briggs",
      "Cami Rincon"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.02776"
  },
  {
    "id": "arXiv:2202.02777",
    "title": "Learning Features with Parameter-Free Layers",
    "abstract": "Trainable layers such as convolutional building blocks are the standard\nnetwork design choices by learning parameters to capture the global context\nthrough successive spatial operations. When designing an efficient network,\ntrainable layers such as the depthwise convolution is the source of efficiency\nin the number of parameters and FLOPs, but there was little improvement to the\nmodel speed in practice. This paper argues that simple built-in parameter-free\noperations can be a favorable alternative to the efficient trainable layers\nreplacing spatial operations in a network architecture. We aim to break the\nstereotype of organizing the spatial operations of building blocks into\ntrainable layers. Extensive experimental analyses based on layer-level studies\nwith fully-trained models and neural architecture searches are provided to\ninvestigate whether parameter-free operations such as the max-pool are\nfunctional. The studies eventually give us a simple yet effective idea for\nredesigning network architectures, where the parameter-free operations are\nheavily used as the main building block without sacrificing the model accuracy\nas much. Experimental results on the ImageNet dataset demonstrate that the\nnetwork architectures with parameter-free operations could enjoy the advantages\nof further efficiency in terms of model speed, the number of the parameters,\nand FLOPs. Code and ImageNet pretrained models are available at\nhttps://github.com/naver-ai/PfLayer.",
    "descriptor": "\nComments: ICLR 2022\n",
    "authors": [
      "Dongyoon Han",
      "YoungJoon Yoo",
      "Beomyoung Kim",
      "Byeongho Heo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.02777"
  },
  {
    "id": "arXiv:2202.02779",
    "title": "Multi-domain Unsupervised Image-to-Image Translation with Appearance  Adaptive Convolution",
    "abstract": "Over the past few years, image-to-image (I2I) translation methods have been\nproposed to translate a given image into diverse outputs. Despite the\nimpressive results, they mainly focus on the I2I translation between two\ndomains, so the multi-domain I2I translation still remains a challenge. To\naddress this problem, we propose a novel multi-domain unsupervised\nimage-to-image translation (MDUIT) framework that leverages the decomposed\ncontent feature and appearance adaptive convolution to translate an image into\na target appearance while preserving the given geometric content. We also\nexploit a contrast learning objective, which improves the disentanglement\nability and effectively utilizes multi-domain image data in the training\nprocess by pairing the semantically similar images. This allows our method to\nlearn the diverse mappings between multiple visual domains with only a single\nframework. We show that the proposed method produces visually diverse and\nplausible results in multiple domains compared to the state-of-the-art methods.",
    "descriptor": "\nComments: ICASSP 2022\n",
    "authors": [
      "Somi Jeong",
      "Jiyoung Lee",
      "Kwanghoon Sohn"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.02779"
  },
  {
    "id": "arXiv:2202.02782",
    "title": "The Exponential-Time Complexity of the complex weighted #CSP",
    "abstract": "In this paper, I consider a fine-grained dichotomy of Boolean counting\nconstraint satisfaction problem (#CSP), under the exponential time hypothesis\nof counting version (#ETH). Suppose $\\mathscr{F}$ is a finite set of algebraic\ncomplex-valued functions defined on Boolean domain. When $\\mathscr{F}$ is a\nsubset of either two special function sets, I prove that #CSP($\\mathscr{F}$) is\npolynomial-time solvable, otherwise it can not be computed in sub-exponential\ntime unless #ETH fails. I also improve the result by proving the same dichotomy\nholds for #CSP with bounded degree (every variable appears at most constant\nconstraints), even for #R$_3$-CSP.\nAn important preparation before proving the result is to argue that pinning\n(two special unary functions $[1,0]$ and $[0,1]$ are used to reduce arity) can\nalso keep the sub-exponential lower bound of a Boolean #CSP problem. I discuss\nthis issue by utilizing some common methods in proving #P-hardness of counting\nproblems. The proof illustrates the internal correlation among these commonly\nused methods.",
    "descriptor": "",
    "authors": [
      "Ying Liu"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2202.02782"
  },
  {
    "id": "arXiv:2202.02783",
    "title": "Energy awareness in low precision neural networks",
    "abstract": "Power consumption is a major obstacle in the deployment of deep neural\nnetworks (DNNs) on end devices. Existing approaches for reducing power\nconsumption rely on quite general principles, including avoidance of\nmultiplication operations and aggressive quantization of weights and\nactivations. However, these methods do not take into account the precise power\nconsumed by each module in the network, and are therefore not optimal. In this\npaper we develop accurate power consumption models for all arithmetic\noperations in the DNN, under various working conditions. We reveal several\nimportant factors that have been overlooked to date. Based on our analysis, we\npresent PANN (power-aware neural network), a simple approach for approximating\nany full-precision network by a low-power fixed-precision variant. Our method\ncan be applied to a pre-trained network, and can also be used during training\nto achieve improved performance. In contrast to previous methods, PANN incurs\nonly a minor degradation in accuracy w.r.t. the full-precision version of the\nnetwork, even when working at the power-budget of a 2-bit quantized variant. In\naddition, our scheme enables to seamlessly traverse the power-accuracy\ntrade-off at deployment time, which is a major advantage over existing\nquantization methods that are constrained to specific bit widths.",
    "descriptor": "",
    "authors": [
      "Nurit Spingarn Eliezer",
      "Ron Banner",
      "Elad Hoffer",
      "Hilla Ben-Yaakov",
      "Tomer Michaeli"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.02783"
  },
  {
    "id": "arXiv:2202.02786",
    "title": "Proving Information Inequalities and Identities with Symbolic  Computation",
    "abstract": "Proving linear inequalities and identities of Shannon's information measures,\npossibly with linear constraints on the information measures, is an important\nproblem in information theory. For this purpose, ITIP and other variant\nalgorithms have been developed and implemented, which are all based on solving\na linear program (LP). In particular, an identity $f = 0$ is verified by\nsolving two LPs, one for $f \\ge 0$ and one for $f \\le 0$. In this paper, we\ndevelop a set of algorithms that can be implemented by symbolic computation.\nBased on these algorithms, procedures for verifying linear information\ninequalities and identities are devised. Compared with LP-based algorithms, our\nprocedures can produce analytical proofs that are both human-verifiable and\nfree of numerical errors. Our procedures are also more efficient\ncomputationally. For constrained inequalities, by taking advantage of the\nalgebraic structure of the problem, the size of the LP that needs to be solved\ncan be significantly reduced. For identities, instead of solving two LPs, the\nidentity can be verified directly with very little computation.",
    "descriptor": "",
    "authors": [
      "Laigang Guo",
      "Raymond W. Yeung",
      "Xiao-Shan Gao"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.02786"
  },
  {
    "id": "arXiv:2202.02790",
    "title": "Learning Synthetic Environments and Reward Networks for Reinforcement  Learning",
    "abstract": "We introduce Synthetic Environments (SEs) and Reward Networks (RNs),\nrepresented by neural networks, as proxy environment models for training\nReinforcement Learning (RL) agents. We show that an agent, after being trained\nexclusively on the SE, is able to solve the corresponding real environment.\nWhile an SE acts as a full proxy to a real environment by learning about its\nstate dynamics and rewards, an RN is a partial proxy that learns to augment or\nreplace rewards. We use bi-level optimization to evolve SEs and RNs: the inner\nloop trains the RL agent, and the outer loop trains the parameters of the SE /\nRN via an evolution strategy. We evaluate our proposed new concept on a broad\nrange of RL algorithms and classic control environments. In a one-to-one\ncomparison, learning an SE proxy requires more interactions with the real\nenvironment than training agents only on the real environment. However, once\nsuch an SE has been learned, we do not need any interactions with the real\nenvironment to train new agents. Moreover, the learned SE proxies allow us to\ntrain agents with fewer interactions while maintaining the original task\nperformance. Our empirical results suggest that SEs achieve this result by\nlearning informed representations that bias the agents towards relevant states.\nMoreover, we find that these proxies are robust against hyperparameter\nvariation and can also transfer to unseen agents.",
    "descriptor": "",
    "authors": [
      "Fabio Ferreira",
      "Thomas Nierhoff",
      "Andreas Saelinger",
      "Frank Hutter"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.02790"
  },
  {
    "id": "arXiv:2202.02791",
    "title": "SFMGNet: A Physics-based Neural Network To Predict Pedestrian  Trajectories",
    "abstract": "Autonomous robots and vehicles are expected to soon become an integral part\nof our environment. Unsatisfactory issues regarding interaction with existing\nroad users, performance in mixed-traffic areas and lack of interpretable\nbehavior remain key obstacles. To address these, we present a physics-based\nneural network, based on a hybrid approach combining a social force model\nextended by group force (SFMG) with Multi-Layer Perceptron (MLP) to predict\npedestrian trajectories considering its interaction with static obstacles,\nother pedestrians and pedestrian groups. We quantitatively and qualitatively\nevaluate the model with respect to realistic prediction, prediction performance\nand prediction \"interpretability\". Initial results suggest, the model even when\nsolely trained on a synthetic dataset, can predict realistic and interpretable\ntrajectories with better than state-of-the-art accuracy.",
    "descriptor": "\nComments: 16 pages, 6 figures, AAAI-MAKE 2022: Machine Learning and Knowledge Engineering for Hybrid Intelligence\n",
    "authors": [
      "Sakif Hossain",
      "Fatema T. Johora",
      "J\u00f6rg P. M\u00fcller",
      "Sven Hartmann",
      "Andreas Reinhardt"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.02791"
  },
  {
    "id": "arXiv:2202.02794",
    "title": "Active Learning on a Budget: Opposite Strategies Suit High and Low  Budgets",
    "abstract": "Investigating active learning, we focus on the relation between the number of\nlabeled examples (budget size), and suitable corresponding querying strategies.\nOur theoretical analysis shows a behavior reminiscent of phase transition:\ntypical points should best be queried in the low budget regime, while atypical\n(or uncertain) points are best queried when the budget is large. Combined\nevidence from our theoretical and empirical studies shows that a similar\nphenomenon occurs in simple classification models. Accordingly, we propose\nTypiClust -- a deep active learning strategy suited for low budgets. In a\ncomparative empirical investigation using a variety of architectures and image\ndatasets, we report that in the low budget regime, TypiClust outperforms all\nother active learning strategies. Using TypiClust in a semi-supervised\nframework, the performance of competitive semi-supervised methods gets a\nsignificant boost, surpassing the state of the art.",
    "descriptor": "",
    "authors": [
      "Guy Hacohen",
      "Avihu Dekel",
      "Daphna Weinshall"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.02794"
  },
  {
    "id": "arXiv:2202.02796",
    "title": "GLPanoDepth: Global-to-Local Panoramic Depth Estimation",
    "abstract": "In this paper, we propose a learning-based method for predicting dense depth\nvalues of a scene from a monocular omnidirectional image. An omnidirectional\nimage has a full field-of-view, providing much more complete descriptions of\nthe scene than perspective images. However, fully-convolutional networks that\nmost current solutions rely on fail to capture rich global contexts from the\npanorama. To address this issue and also the distortion of equirectangular\nprojection in the panorama, we propose Cubemap Vision Transformers (CViT), a\nnew transformer-based architecture that can model long-range dependencies and\nextract distortion-free global features from the panorama. We show that cubemap\nvision transformers have a global receptive field at every stage and can\nprovide globally coherent predictions for spherical signals. To preserve\nimportant local features, we further design a convolution-based branch in our\npipeline (dubbed GLPanoDepth) and fuse global features from cubemap vision\ntransformers at multiple scales. This global-to-local strategy allows us to\nfully exploit useful global and local features in the panorama, achieving\nstate-of-the-art performance in panoramic depth estimation.",
    "descriptor": "\nComments: 8 pages, 9 figures\n",
    "authors": [
      "Jiayang Bai",
      "Shuichang Lai",
      "Haoyu Qin",
      "Jie Guo",
      "Yanwen Guo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.02796"
  },
  {
    "id": "arXiv:2202.02797",
    "title": "SIGMA: A Structural Inconsistency Reducing Graph Matching Algorithm",
    "abstract": "Graph matching finds the correspondence of nodes across two correlated graphs\nand lies at the core of many applications. When graph side information is not\navailable, the node correspondence is estimated on the sole basis of network\ntopologies. In this paper, we propose a novel criterion to measure the graph\nmatching accuracy, structural inconsistency (SI), which is defined based on the\nnetwork topological structure. Specifically, SI incorporates the heat diffusion\nwavelet to accommodate the multi-hop structure of the graphs. Based on SI, we\npropose a Structural Inconsistency reducing Graph Matching Algorithm (SIGMA),\nwhich improves the alignment scores of node pairs that have low SI values in\neach iteration. Under suitable assumptions, SIGMA can reduce SI values of true\ncounterparts. Furthermore, we demonstrate that SIGMA can be derived by using a\nmirror descent method to solve the Gromov-Wasserstein distance with a novel\nK-hop-structure-based matching costs. Extensive experiments show that our\nmethod outperforms state-of-the-art methods.",
    "descriptor": "",
    "authors": [
      "Weijie Liu",
      "Chao Zhang",
      "Nenggan Zheng",
      "Hui Qian"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.02797"
  },
  {
    "id": "arXiv:2202.02800",
    "title": "Learning to be a Statistician: Learned Estimator for Number of Distinct  Values",
    "abstract": "Estimating the number of distinct values (NDV) in a column is useful for many\ntasks in database systems, such as columnstore compression and data profiling.\nIn this work, we focus on how to derive accurate NDV estimations from random\n(online/offline) samples. Such efficient estimation is critical for tasks where\nit is prohibitive to scan the data even once. Existing sample-based estimators\ntypically rely on heuristics or assumptions and do not have robust performance\nacross different datasets as the assumptions on data can easily break. On the\nother hand, deriving an estimator from a principled formulation such as maximum\nlikelihood estimation is very challenging due to the complex structure of the\nformulation. We propose to formulate the NDV estimation task in a supervised\nlearning framework, and aim to learn a model as the estimator. To this end, we\nneed to answer several questions: i) how to make the learned model workload\nagnostic; ii) how to obtain training data; iii) how to perform model training.\nWe derive conditions of the learning framework under which the learned model is\nworkload agnostic, in the sense that the model/estimator can be trained with\nsynthetically generated training data, and then deployed into any data\nwarehouse simply as, e.g., user-defined functions (UDFs), to offer efficient\n(within microseconds on CPU) and accurate NDV estimations for unseen tables and\nworkloads. We compare the learned estimator with the state-of-the-art\nsample-based estimators on nine real-world datasets to demonstrate its superior\nestimation accuracy. We publish our code for training data generation, model\ntraining, and the learned estimator online for reproducibility.",
    "descriptor": "\nComments: Published at International Conference on Very Large Data Bases (VLDB) 2022\n",
    "authors": [
      "Renzhi Wu",
      "Bolin Ding",
      "Xu Chu",
      "Zhewei Wei",
      "Xiening Dai",
      "Tao Guan",
      "Jingren Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2202.02800"
  },
  {
    "id": "arXiv:2202.02802",
    "title": "Low-confidence Samples Matter for Domain Adaptation",
    "abstract": "Domain adaptation (DA) aims to transfer knowledge from a label-rich source\ndomain to a related but label-scarce target domain. The conventional DA\nstrategy is to align the feature distributions of the two domains. Recently,\nincreasing researches have focused on self-training or other semi-supervised\nalgorithms to explore the data structure of the target domain. However, the\nbulk of them depend largely on confident samples in order to build reliable\npseudo labels, prototypes or cluster centers. Representing the target data\nstructure in such a way would overlook the huge low-confidence samples,\nresulting in sub-optimal transferability that is biased towards the samples\nsimilar to the source domain. To overcome this issue, we propose a novel\ncontrastive learning method by processing low-confidence samples, which\nencourages the model to make use of the target data structure through the\ninstance discrimination process. To be specific, we create positive and\nnegative pairs only using low-confidence samples, and then re-represent the\noriginal features with the classifier weights rather than directly utilizing\nthem, which can better encode the task-specific semantic information.\nFurthermore, we combine cross-domain mixup to augment the proposed contrastive\nloss. Consequently, the domain gap can be well bridged through contrastive\nlearning of intermediate representations across domains. We evaluate the\nproposed method in both unsupervised and semi-supervised DA settings, and\nextensive experimental results on benchmarks reveal that our method is\neffective and achieves state-of-the-art performance. The code can be found in\nhttps://github.com/zhyx12/MixLRCo.",
    "descriptor": "\nComments: 11 pages, 5 figures\n",
    "authors": [
      "Yixin Zhang",
      "Junjie Li",
      "Zilei Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.02802"
  },
  {
    "id": "arXiv:2202.02805",
    "title": "Formulating Connectedness in Security-Constrained Optimal Transmission  Switching Problems",
    "abstract": "This paper focuses on the issue of network connectedness (NC) in\nsecurity-constrained optimal transmission switching problems, which is\ncomplicated by branch contingencies and corrective line switching. Two criteria\nare firstly proposed with the principle of preserving NC as much as possible\nwithin reasonable limits. By extending the electrical flow based NC\nconstraints, a proposition is derived to associate different cases of NC with\nthe optimum of a linear program, yielding the mathematical formulation of the\nNC criteria. By Karush-Kuhn-Tucker conditions, this formulation is further\ntransformed into a tractable version which can be incorporated with existing\nSCOTS models without affecting the applicability of original solution\napproaches. Finally, case studies on various networks and SCOTS models\ndemonstrate the efficacy of the proposed approach.",
    "descriptor": "",
    "authors": [
      "Tong Han",
      "David J. Hill",
      "Yue Song"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.02805"
  },
  {
    "id": "arXiv:2202.02807",
    "title": "Heart-Based Biometric Protocols: A look back over almost two decades",
    "abstract": "This article surveys the literature over the period 2003-2021 on heart-based\nbiometric protocols. In particular, we focus on how the heart signal is\ntransformed from a continuous wave to discrete values to be used afterwards in\nauthentication protocols. We explain and classify the surveyed proposals\naccording to three main parameters: i) the dataset they use for testing their\nresults; ii) the delineation algorithms they use to extract the fiducial\npoints, and; iii) the cryptographic tests they run (if any) to validate how\nrandom the extracted token is.",
    "descriptor": "",
    "authors": [
      "Lara Ortiz-Martin",
      "Pablo Picazo-Sanchez"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.02807"
  },
  {
    "id": "arXiv:2202.02811",
    "title": "Construction of polynomial preserving cochain extensions by blending",
    "abstract": "A classical technique to construct polynomial preserving extensions of scalar\nfunctions defined on the boundary of an $n$ simplex to the interior is to use\nso-called rational blending functions. The purpose of this paper is to\ngeneralize the construction by blending to the de Rham complex. More precisely,\nwe define polynomial preserving extensions which map traces of $k$ forms\ndefined on the boundary of the simplex to $k$ forms defined in the interior.\nFurthermore, the extensions are cochain maps, i.e., they commute with the\nexterior derivative.",
    "descriptor": "",
    "authors": [
      "Richard S. Falk",
      "Ragnar Winther"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.02811"
  },
  {
    "id": "arXiv:2202.02812",
    "title": "Lossy Gradient Compression: How Much Accuracy Can One Bit Buy?",
    "abstract": "In federated learning (FL), a global model is trained at a Parameter Server\n(PS) by aggregating model updates obtained from multiple remote learners.\nCritically, the communication between the remote users and the PS is limited by\nthe available power for transmission, while the transmission from the PS to the\nremote users can be considered unbounded. This gives rise to the distributed\nlearning scenario in which the updates from the remote learners have to be\ncompressed so as to meet communication rate constraints in the uplink\ntransmission toward the PS. For this problem, one would like to compress the\nmodel updates so as to minimize the resulting loss in accuracy. In this paper,\nwe take a rate-distortion approach to answer this question for the distributed\ntraining of a deep neural network (DNN). In particular, we define a measure of\nthe compression performance, the \\emph{per-bit accuracy}, which addresses the\nultimate model accuracy that a bit of communication brings to the centralized\nmodel. In order to maximize the per-bit accuracy, we consider modeling the\ngradient updates at remote learners as a generalized normal distribution. Under\nthis assumption on the model update distribution, we propose a class of\ndistortion measures for the design of quantizer for the compression of the\nmodel updates. We argue that this family of distortion measures, which we refer\nto as \"$M$-magnitude weighted $L_2$\" norm, capture the practitioner intuition\nin the choice of gradient compressor. Numerical simulations are provided to\nvalidate the proposed approach.",
    "descriptor": "",
    "authors": [
      "Sadaf Salehkalaibar",
      "Stefano Rini"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.02812"
  },
  {
    "id": "arXiv:2202.02817",
    "title": "BEAS: Blockchain Enabled Asynchronous & Secure Federated Machine  Learning",
    "abstract": "Federated Learning (FL) enables multiple parties to distributively train a ML\nmodel without revealing their private datasets. However, it assumes trust in\nthe centralized aggregator which stores and aggregates model updates. This\nmakes it prone to gradient tampering and privacy leakage by a malicious\naggregator. Malicious parties can also introduce backdoors into the joint model\nby poisoning the training data or model gradients. To address these issues, we\npresent BEAS, the first blockchain-based framework for N-party FL that provides\nstrict privacy guarantees of training data using gradient pruning (showing\nimproved differential privacy compared to existing noise and clipping based\ntechniques). Anomaly detection protocols are used to minimize the risk of\ndata-poisoning attacks, along with gradient pruning that is further used to\nlimit the efficacy of model-poisoning attacks. We also define a novel protocol\nto prevent premature convergence in heterogeneous learning environments. We\nperform extensive experiments on multiple datasets with promising results: BEAS\nsuccessfully prevents privacy leakage from dataset reconstruction attacks, and\nminimizes the efficacy of poisoning attacks. Moreover, it achieves an accuracy\nsimilar to centralized frameworks, and its communication and computation\noverheads scale linearly with the number of participants.",
    "descriptor": "\nComments: The Third AAAI Workshop on Privacy-Preserving Artificial Intelligence (PPAI-22) at the Thirty-Sixth AAAI Conference on Artificial Intelligence (AAAI-22)\n",
    "authors": [
      "Arup Mondal",
      "Harpreet Virk",
      "Debayan Gupta"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.02817"
  },
  {
    "id": "arXiv:2202.02818",
    "title": "Automated Vehicle Safety Guarantee, Verification and Certification: A  Survey",
    "abstract": "Challenges related to automated driving are no longer focused on just the\nconstruction of such automated vehicles (AVs), but in assuring the safety of\ntheir operation. Recent advances in Level 3 and Level 4 autonomous driving have\nmotivated more extensive study in safety guarantees of complicated AV\nmaneuvers, which aligns with the goal of ISO 21448 (Safety of the Intended\nFunctions, or SOTIF), i.e. minimizing unsafe scenarios both known and unknown,\nas well as Vision Zero -- eliminating highway fatalities by 2050. A majority of\napproaches used in providing safety guarantees for AV motion control originate\nfrom formal methods, especially reachability analysis (RA), which relies on\nmathematical models for the dynamic evolution of the system to provide\nguarantees. However, to the best of the authors' knowledge, there have been no\nreview papers dedicated to describing and interpreting state-of-the-art of\nformal methods in the context of AVs. In this work, we provide both an overview\nof the safety verification, validation and certification process, as well as\nreview formal safety techniques that are best suited to AV applications. We\nalso propose a unified scenario coverage framework that can provide either a\nformal or sample-based estimate of safety verification for full AVs.",
    "descriptor": "",
    "authors": [
      "Tong Zhao",
      "Ekim Yurtsever",
      "Joel Paulson",
      "Giorgio Rizzoni"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.02818"
  },
  {
    "id": "arXiv:2202.02819",
    "title": "Block shuffling learning for Deepfake Detection",
    "abstract": "Although the deepfake detection based on convolutional neural network has\nachieved good results, the detection results show that these detectors show\nobvious performance degradation when the input images undergo some common\ntransformations (like resizing, blurring), which indicates that the\ngeneralization ability of the detector is insufficient. In this paper, we\npropose a novel block shuffling learning method to solve this problem.\nSpecifically, we divide the images into blocks and then introduce the random\nshuffling to intra-block and inter-block. Intra-block shuffling increases the\nrobustness of the detector and we also propose an adversarial loss algorithm to\novercome the over-fitting problem brought by the noise introduced by shuffling.\nMoreover, we encourage the detector to focus on finding differences among the\nlocal features through inter-block shuffling, and reconstruct the spatial\nlayout of the blocks to model the semantic associations between them.\nEspecially, our method can be easily integrated with various CNN models.\nExtensive experiments show that our proposed method achieves state-of-the-art\nperformance in forgery face detection, including good generalization ability in\nthe face of common image transformations.",
    "descriptor": "",
    "authors": [
      "Sitong Liu",
      "Zhichao Lian",
      "Siqi Gu",
      "Liang Xiao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.02819"
  },
  {
    "id": "arXiv:2202.02824",
    "title": "A Summary of COVID-19 Datasets",
    "abstract": "This research presents a review of main datasets that are developed for\nCOVID-19 research. We hope this collection will continue to bring together\nmembers of the computing community, biomedical experts, and policymakers in the\npursuit of effective COVID-19 treatments and management policies. Many\norganizations, such as the World Health Organization (WHO), John Hopkins,\nNational Institute of Health (NIH), COVID-19 open science table4 and such, in\nthe world, have made numerous datasets available to the public. However, these\ndatasets originate from a variety of different sources and initiatives. The\npurpose of this research is to summarize the open COVID-19 datasets to make\nthem more accessible to the research community for health systems design and\nanalysis.",
    "descriptor": "",
    "authors": [
      "Shaina Raza",
      "Syed Raza Bashir",
      "Vidhi Thakkar",
      "Usman Naseem"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2202.02824"
  },
  {
    "id": "arXiv:2202.02826",
    "title": "Post Quantum Cryptography: Techniques, Challenges, Standardization, and  Directions for Future Research",
    "abstract": "The development of large quantum computers will have dire consequences for\ncryptography. Most of the symmetric and asymmetric cryptographic algorithms are\nvulnerable to quantum algorithms. Grover's search algorithm gives a square root\ntime boost for the searching of the key in symmetric schemes like AES and 3DES.\nThe security of asymmetric algorithms like RSA, Diffie Hellman, and ECC is\nbased on the mathematical hardness of prime factorization and discrete\nlogarithm. The best classical algorithms available take exponential time.\nShor's factoring algorithm can solve the problems in polynomial time. Major\nbreakthroughs in quantum computing will render all the present-day widely used\nasymmetric cryptosystems insecure. This paper analyzes the vulnerability of the\nclassical cryptosystems in the context of quantum computers discusses various\npost-quantum cryptosystem families, discusses the status of the NIST\npost-quantum cryptography standardization process, and finally provides a\ncouple of future research directions in this field.",
    "descriptor": "",
    "authors": [
      "Ritik Bavdekar",
      "Eashan Jayant Chopde",
      "Ashutosh Bhatia",
      "Kamlesh Tiwari",
      "Sandeep Joshua Daniel",
      "Atul"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.02826"
  },
  {
    "id": "arXiv:2202.02828",
    "title": "Consistency and Convergence of a High Order Accurate Meshless Method for  Solution of Incompressible Fluid Flows",
    "abstract": "Computations of incompressible flows with velocity boundary conditions\nrequire solution of a Poisson equation for pressure with all Neumann boundary\nconditions. Discretization of such a Poisson equation results in a\nrank-deficient matrix of coefficients. When a non-conservative discretization\nmethod such as finite difference, finite element, or spectral scheme is used,\nsuch a matrix also generates an inconsistency which makes the residuals in the\niterative solution to saturate at a threshold level that depends on the spatial\nresolution and order of the discretization scheme. In this paper, we examine\ninconsistency for a high-order meshless discretization scheme suitable for\nsolving the equations on a complex domain. The high order meshless method uses\npolyharmonic spline radial basis functions (PHS-RBF) with appended polynomials\nto interpolate scattered data and constructs the discrete equations by\ncollocation. The PHS-RBF provides the flexibility to vary the order of\ndiscretization by increasing the degree of the appended polynomial. In this\nstudy, we examine the convergence of the inconsistency for different spatial\nresolutions and for different degrees of the appended polynomials by solving\nthe Poisson equation for a manufactured solution as well as the Navier-Stokes\nequations for several fluid flows. We observe that the inconsistency decreases\nfaster than the error in the final solution, and eventually becomes vanishing\nsmall at sufficient spatial resolution. The rate of convergence of the\ninconsistency is observed to be similar or better than the rate of convergence\nof the discretization errors. This beneficial observation makes it unnecessary\nto regularize the Poisson equation by fixing either the mean pressure or\npressure at an arbitrary point. A simple point solver such as the SOR is seen\nto be well-convergent, although it can be further accelerated using multilevel\nmethods.",
    "descriptor": "",
    "authors": [
      "Shantanu Shahane",
      "Surya Pratap Vanka"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2202.02828"
  },
  {
    "id": "arXiv:2202.02829",
    "title": "BDDs Strike Back: Efficient Analysis of Static and Dynamic Fault Trees",
    "abstract": "Fault trees are a key model in reliability analysis. Classical static fault\ntrees (SFT) can best be analysed using binary decision diagrams (BDD).\nState-based techniques are favorable for the more expressive dynamic fault\ntrees (DFT). This paper combines the best of both worlds by following Dugan's\napproach: dynamic sub-trees are analysed via model checking Markov models and\nreplaced by basic events capturing the obtained failure probabilities. The\nresulting SFT is then analysed via BDDs. We implemented this approach in the\nStorm model checker. Extensive experiments (a) compare our pure BDD-based\nanalysis of SFTs to various existing SFT analysis tools, (b) indicate the\nbenefits of our efficient calculations for multiple time points and the\nassessment of the mean-time-to-failure, and (c) show that our implementation of\nDugan's approach significantly outperforms pure Markovian analysis of DFTs. Our\nimplementation Storm-dft is currently the only tool supporting efficient\nanalysis for both SFTs and DFTs.",
    "descriptor": "",
    "authors": [
      "Daniel Basg\u00f6ze",
      "Matthias Volk",
      "Joost-Pieter Katoen",
      "Shahid Khan",
      "Marielle Stoelinga"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2202.02829"
  },
  {
    "id": "arXiv:2202.02830",
    "title": "Discovering Personalized Semantics for Soft Attributes in Recommender  Systems using Concept Activation Vectors",
    "abstract": "Interactive recommender systems (RSs) allow users to express intent,\npreferences and contexts in a rich fashion, often using natural language. One\nchallenge in using such feedback is inferring a user's semantic intent from the\nopen-ended terms used to describe an item, and using it to refine\nrecommendation results. Leveraging concept activation vectors (CAVs) [21], we\ndevelop a framework to learn a representation that captures the semantics of\nsuch attributes and connects them to user preferences and behaviors in RSs. A\nnovel feature of our approach is its ability to distinguish objective and\nsubjective attributes and associate different senses with different users.\nUsing synthetic and real-world datasets, we show that our CAV representation\naccurately interprets users' subjective semantics, and can improve\nrecommendations via interactive critiquing",
    "descriptor": "",
    "authors": [
      "Christina G\u00f6pfert",
      "Yinlam Chow",
      "Chih-wei Hsu",
      "Ivan Vendrov",
      "Tyler Lu",
      "Deepak Ramachandran",
      "Craig Boutilier"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.02830"
  },
  {
    "id": "arXiv:2202.02838",
    "title": "Aligning Eyes between Humans and Deep Neural Network through Interactive  Attention Alignment",
    "abstract": "While Deep Neural Networks (DNNs) are deriving the major innovations in\nnearly every field through their powerful automation, we are also witnessing\nthe peril behind automation as a form of bias, such as automated racism, gender\nbias, and adversarial bias. As the societal impact of DNNs grows, finding an\neffective way to steer DNNs to align their behavior with the human mental model\nhas become indispensable in realizing fair and accountable models. We propose a\nnovel framework of Interactive Attention Alignment (IAA) that aims at realizing\nhuman-steerable Deep Neural Networks (DNNs). IAA leverages DNN model\nexplanation method as an interactive medium that humans can use to unveil the\ncases of biased model attention and directly adjust the attention. In improving\nthe DNN using human-generated adjusted attention, we introduce GRADIA, a novel\ncomputational pipeline that jointly maximizes attention quality and prediction\naccuracy. We evaluated IAA framework in Study 1 and GRADIA in Study 2 in a\ngender classification problem. Study 1 found applying IAA can significantly\nimprove the perceived quality of model attention from human eyes. In Study 2,\nwe found using GRADIA can (1) significantly improve the perceived quality of\nmodel attention and (2) significantly improve model performance in scenarios\nwhere the training samples are limited. We present implications for future\ninteractive user interfaces design towards human-alignable AI.",
    "descriptor": "",
    "authors": [
      "Yuyang Gao",
      "Tong Sun",
      "Liang Zhao",
      "Sungsoo Hong"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2202.02838"
  },
  {
    "id": "arXiv:2202.02842",
    "title": "Evaluating natural language processing models with generalization  metrics that do not need access to any training or testing data",
    "abstract": "The search for effective and robust generalization metrics has been the focus\nof recent theoretical and empirical work.\nIn this paper, we discuss the performance of natural language processing\n(NLP) models, and we evaluate various existing and novel generalization\nmetrics.\nCompared to prior studies, we\n(i) focus on NLP instead of computer vision (CV),\n(ii) focus on generalization metrics that predict test error instead of the\ngeneralization gap,\n(iii) focus on generalization metrics that do not need the access to data,\nand\n(iv) focus on the heavy-tail (HT) phenomenon that has received comparatively\nless attention in the study of deep neural networks (NNs).\nWe extend recent HT-based work which focuses on power law (PL) distributions,\nand we study exponential (EXP) and exponentially truncated power law (E-TPL)\nfitting to the empirical spectral densities (ESDs) of weight matrices.\nOur detailed empirical studies show that\n(i) \\emph{shape metrics}, or the metrics obtained from fitting the shape of\nthe ESDs, perform uniformly better at predicting generalization performance\nthan \\emph{scale metrics} commonly studied in the literature, as measured by\nthe \\emph{average} rank correlations with the generalization performance for\nall of our experiments;\n(ii) among forty generalization metrics studied in our paper, the\n\\RANDDISTANCE metric, a new shape metric invented in this paper that measures\nthe distance between empirical eigenvalues of weight matrices and those of\nrandomly initialized weight matrices, achieves the highest worst-case rank\ncorrelation with generalization performance under a variety of training\nsettings; and\n(iii) among the three HT distributions considered in our paper, the E-TPL\nfitting of ESDs performs the most robustly.",
    "descriptor": "",
    "authors": [
      "Yaoqing Yang",
      "Ryan Theisen",
      "Liam Hodgkinson",
      "Joseph E. Gonzalez",
      "Kannan Ramchandran",
      "Charles H. Martin",
      "Michael W. Mahoney"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.02842"
  },
  {
    "id": "arXiv:2202.02843",
    "title": "Galois LCD codes over mixed alphabets",
    "abstract": "We study (Galois) linear complementary dual codes over mixed alphabets\narising from finite chain rings. We give a characterization of when a given\ncode is of We study (Galois) linear complementary dual codes over mixed\nalphabets arising from finite chain rings. We give a characterization of when a\ngiven code is of this type and when it is Galois invariant. Finally, this leads\nto a study of the Gray image of $\\mathbb{F}_p\\mathbb{F}_p[\\theta]$-linear\ncodes, where $p\\in\\{2; 3\\}$ and $\\theta\\neq\\theta^2=0$, that provides\n$\\mathbb{F}_p$-linear complementary dual codes.",
    "descriptor": "",
    "authors": [
      "Maryam Bajalam",
      "Alexandre Fotue-Tabue",
      "Jo\u00ebl Kabore",
      "Edgar Mart\u00ednez-Moro"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.02843"
  },
  {
    "id": "arXiv:2202.02845",
    "title": "A Novel Micro-service Based Platform for Composition, Deployment and  Execution of BDA Applications",
    "abstract": "Big Data are growing at an exponential rate and it becomes necessary the use\nof tools and technologies to manage, process and visualize them in order to\nextract value. In this paper a micro-service based platform is presented for\nthe composition, deployment and execution of Big Data Analytics (BDA)\napplication workflows in several domains and scenarios is presented. ALIDA is a\nresult coming from previous research activities by ENGINEERING. It aims to\nachieve a unified platform that allows both BDA application developers and data\nanalysts to interact with it. Developers will be able to register new BDA\napplications through the exposed API and/or through the web user interface.\nData analysts will be able to use the BDA applications provided to create\nbatch/stream workflows through a dashboard user interface to manipulate and\nsubsequently visualize results from one or more sources. The platform also\nsupports the auto-tuning of Big Data frameworks deployment properties to\nimprove metrics for analytics application. ALIDA has been properly extended and\nintegrated into a software solution for the analysis of large amounts of data\nfrom the avionic industries. A use case within this context is then presented.",
    "descriptor": "\nComments: 45th Euromicro Conference on Software Engineering and Advanced Applications, SEAA 2019, Kallithea-Chalkidiki, Greece, August 28-30, 2019\n",
    "authors": [
      "Davide Profeta",
      "Nicola Masi",
      "Domenico Messina",
      "Davide Dalle Carbonare",
      "Susanna Bonura",
      "Vito Morreale"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.02845"
  },
  {
    "id": "arXiv:2202.02847",
    "title": "Solidfmm: A highly optimised library of operations on the solid  harmonics for use in fast multipole methods",
    "abstract": "We present solidfmm, a highly optimised C++ library for the solid harmonics\nas they are needed in fast multipole methods. The library provides efficient,\nvectorised implementations of the translation operations M2M, M2L, and L2L, and\nis available as free software. While asymptotically of complexity $O(P^3)$, for\nall practically relevant expansion orders, the translation operators display an\nempirical complexity of $O(P^2)$, outperforming the na\\\"ive implementation by\norders of magnitude.",
    "descriptor": "",
    "authors": [
      "Matthias Kirchhart"
    ],
    "subjectives": [
      "Mathematical Software (cs.MS)"
    ],
    "url": "https://arxiv.org/abs/2202.02847"
  },
  {
    "id": "arXiv:2202.02850",
    "title": "Stochastic Gradient Descent with Dependent Data for Offline  Reinforcement Learning",
    "abstract": "In reinforcement learning (RL), offline learning decoupled learning from data\ncollection and is useful in dealing with exploration-exploitation tradeoff and\nenables data reuse in many applications. In this work, we study two offline\nlearning tasks: policy evaluation and policy learning. For policy evaluation,\nwe formulate it as a stochastic optimization problem and show that it can be\nsolved using approximate stochastic gradient descent (aSGD) with time-dependent\ndata. We show aSGD achieves $\\tilde O(1/t)$ convergence when the loss function\nis strongly convex and the rate is independent of the discount factor $\\gamma$.\nThis result can be extended to include algorithms making approximately\ncontractive iterations such as TD(0). The policy evaluation algorithm is then\ncombined with the policy iteration algorithm to learn the optimal policy. To\nachieve an $\\epsilon$ accuracy, the complexity of the algorithm is $\\tilde\nO(\\epsilon^{-2}(1-\\gamma)^{-5})$, which matches the complexity bound for\nclassic online RL algorithms such as Q-learning.",
    "descriptor": "",
    "authors": [
      "Jing Dong",
      "Xin T. Tong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2202.02850"
  },
  {
    "id": "arXiv:2202.02851",
    "title": "Machine Learning Aided Holistic Handover Optimization for Emerging  Networks",
    "abstract": "In the wake of network densification and multi-band operation in emerging\ncellular networks, mobility and handover management is becoming a major\nbottleneck. The problem is further aggravated by the fact that holistic\nmobility management solutions for different types of handovers, namely\ninter-frequency and intra-frequency handovers, remain scarce. This paper\npresents a first mobility management solution that concurrently optimizes\ninter-frequency related A5 parameters and intra-frequency related A3\nparameters. We analyze and optimize five parameters namely A5-time to trigger\n(TTT), A5-threshold1, A5-threshold2, A3-TTT, and A3-offset to jointly maximize\nthree critical key performance indicators (KPIs): edge user reference signal\nreceived power (RSRP), handover success rate (HOSR) and load between frequency\nbands. In the absence of tractable analytical models due to system level\ncomplexity, we leverage machine learning to quantify the KPIs as a function of\nthe mobility parameters. An XGBoost based model has the best performance for\nedge RSRP and HOSR while random forest outperforms others for load prediction.\nAn analysis of the mobility parameters provides several insights: 1) there\nexists a strong coupling between A3 and A5 parameters; 2) an optimal set of\nparameters exists for each KPI; and 3) the optimal parameters vary for\ndifferent KPIs. We also perform a SHAP based sensitivity to help resolve the\nparametric conflict between the KPIs. Finally, we formulate a maximization\nproblem, show it is non-convex, and solve it utilizing simulated annealing\n(SA). Results indicate that ML-based SA-aided solution is more than 14x faster\nthan the brute force approach with a slight loss in optimality.",
    "descriptor": "\nComments: Accepted in IEEE International Conference on Communications (ICC) 2022\n",
    "authors": [
      "Muhammad Umar Bin Farooq",
      "Marvin Manalastas",
      "Syed Muhammad Asad Zaidi",
      "Adnan Abu-Dayya",
      "Ali Imran"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.02851"
  },
  {
    "id": "arXiv:2202.02860",
    "title": "MIMO Systems with One-bit ADCs: Capacity Gains using Nonlinear Analog  Operations",
    "abstract": "Analog to Digital Converters (ADCs) are a major contributor to the energy\nconsumption on the receiver side of millimeter-wave multiple-input\nmultiple-output (MIMO) systems with large antenna arrays. Consequently, there\nhas been significant interest in using low-resolution ADCs along with hybrid\nbeam-forming at MIMO receivers for energy efficiency. However, decreasing the\nADC resolution results in performance loss -- in terms of achievable rates --\ndue to increased quantization error. In this work, we study the application of\npractically implementable nonlinear analog operations, prior to sampling and\nquantization at the ADCs, as a way to mitigate the aforementioned rate-loss. A\nreceiver architecture consisting of linear analog combiners, implementable\nnonlinear analog operators, and one-bit threshold ADCs is designed. The\nfundamental information theoretic performance limits of the resulting\ncommunication system, in terms of achievable rates, are investigated under\nvarious assumptions on the set of implementable nonlinear analog functions. In\norder to justify the feasibility of the nonlinear operations in the proposed\nreceiver architecture, an analog circuit is introduced, and circuit simulations\nexhibiting the generation of the desired nonlinear analog operations are\nprovided.",
    "descriptor": "",
    "authors": [
      "Farhad Shirani",
      "Hamidreza Aghasi"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.02860"
  },
  {
    "id": "arXiv:2202.02863",
    "title": "Towards Modeling Human Motor Learning Dynamics in High-Dimensional  Spaces",
    "abstract": "Designing effective rehabilitation strategies for upper extremities,\nparticularly hands and fingers, warrants the need for a computational model of\nhuman motor learning. The presence of large degrees of freedom (DoFs) available\nin these systems makes it difficult to balance the trade-off between learning\nthe full dexterity and accomplishing manipulation goals. The motor learning\nliterature argues that humans use motor synergies to reduce the dimension of\ncontrol space. Using the low-dimensional space spanned by these synergies, we\ndevelop a computational model based on the internal model theory of motor\ncontrol. We analyze the proposed model in terms of its convergence properties\nand fit it to the data collected from human experiments. We compare the\nperformance of the fitted model to the experimental data and show that it\ncaptures human motor learning behavior well.",
    "descriptor": "\nComments: accepted to \"American Control Conference 2022\"\n",
    "authors": [
      "Ankur Kamboj",
      "Rajiv Ranganathan",
      "Xiaobo Tan",
      "Vaibhav Srivastava"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Human-Computer Interaction (cs.HC)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.02863"
  },
  {
    "id": "arXiv:2202.02864",
    "title": "Alpha Blending with No Division Operations",
    "abstract": "Highly accurate alpha blending can be performed entirely with integer\noperations, and no divisions. To reduce the number of integer multiplications,\nmultiple color components can be blended in parallel in the same 32-bit or\n64-bit register. This tutorial explains how to avoid division operations when\nalpha blending with 32-bit RGBA pixels. An RGBA pixel contains four 8-bit\ncomponents (red, green, blue, and alpha), whose values range from 0 to 255.\nAlpha blending requires multiplication of the three color components by an\nalpha value, after which (for greatest accuracy) each of the three products is\ndivided by 255 and then rounded to the nearest integer. This tutorial presents\nan approximate alpha-blending equation that replaces the division operation\nwith an integer shift and add -- and also enables the number of multiplications\nto be reduced. When the same blending calculation is carried out to high\nprecision using double-precision floating-point division operations, the\nresults are found to exactly match those produced by this approximation.",
    "descriptor": "\nComments: 9 pages, 1 figure\n",
    "authors": [
      "Jerry R. Van Aken"
    ],
    "subjectives": [
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2202.02864"
  },
  {
    "id": "arXiv:2202.02868",
    "title": "Applications of Machine Learning in Healthcare and Internet of Things  (IOT): A Comprehensive Review",
    "abstract": "In recent years, smart healthcare IoT devices have become ubiquitous, but\nthey work in isolated networks due to their policy. Having these devices\nconnected in a network enables us to perform medical distributed data analysis.\nHowever, the presence of diverse IoT devices in terms of technology, structure,\nand network policy, makes it a challenging issue while applying traditional\ncentralized learning algorithms on decentralized data collected from the IoT\ndevices. In this study, we present an extensive review of the state-of-the-art\nmachine learning applications particularly in healthcare, challenging issues in\nIoT, and corresponding promising solutions. Finally, we highlight some\nopen-ended issues of IoT in healthcare that leaves further research studies and\ninvestigation for scientists.",
    "descriptor": "",
    "authors": [
      "Farid Ghareh Mohammadi",
      "Farzan Shenavarmasouleh",
      "Hamid R. Arabnia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.02868"
  },
  {
    "id": "arXiv:2202.02870",
    "title": "Generalized L-product for hight order tensors with applications using  GPU computation",
    "abstract": "In this paper, we will present a generalization of the L-tensor product\n(L-product) including generalization of the well known tensor cosine and\nT-products that were defined for third-order tensors and based on fast Fourier\ntransform and discrete cosine transform (DCT). We will give some applications\non tensor completion. To solve some optimization problems linked with the\nproblem of tensor completion, we will use the Proximal Gradient Algorithm (PGA)\nto solve some derived optimization problems. Numerical tests are given to show\nthe effectiveness of the proposed methods and also present some tests using GPU\ncomputation.",
    "descriptor": "",
    "authors": [
      "Abdeslem Hafid Ben Tbib",
      "Mouad Elalj",
      "Anas EL Hachimi",
      "Khalide Jbilou",
      "Ahmed Ratnani"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.02870"
  },
  {
    "id": "arXiv:2202.02872",
    "title": "Differentiable Economics for Randomized Affine Maximizer Auctions",
    "abstract": "A recent approach to automated mechanism design, differentiable economics,\nrepresents auctions by rich function approximators and optimizes their\nperformance by gradient descent. The ideal auction architecture for\ndifferentiable economics would be perfectly strategyproof, support multiple\nbidders and items, and be rich enough to represent the optimal (i.e.\nrevenue-maximizing) mechanism. So far, such an architecture does not exist.\nThere are single-bidder approaches (MenuNet, RochetNet) which are always\nstrategyproof and can represent optimal mechanisms. RegretNet is multi-bidder\nand can approximate any mechanism, but is only approximately strategyproof. We\npresent an architecture that supports multiple bidders and is perfectly\nstrategyproof, but cannot necessarily represent the optimal mechanism. This\narchitecture is the classic affine maximizer auction (AMA), modified to offer\nlotteries. By using the gradient-based optimization tools of differentiable\neconomics, we can now train lottery AMAs, competing with or outperforming prior\napproaches in revenue.",
    "descriptor": "",
    "authors": [
      "Michael Curry",
      "Tuomas Sandholm",
      "John Dickerson"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (cs.LG)",
      "General Economics (econ.GN)"
    ],
    "url": "https://arxiv.org/abs/2202.02872"
  },
  {
    "id": "arXiv:2202.02878",
    "title": "When to pull data from sensors for minimum Distance-based Age of  incorrect Information metric",
    "abstract": "The age of Information (AoI) has been introduced to capture the notion of\nfreshness in real-time monitoring applications. However, this metric falls\nshort in many scenarios, especially when quantifying the mismatch between the\ncurrent and the estimated states. To circumvent this issue, in this paper, we\nadopt the age of incorrect of information metric (AoII) that considers the\nquantified mismatch between the source and the knowledge at the destination. We\nconsider for that a problem where a central entity pulls the information from\nremote sources that evolve according to a Markovian Process. It selects at each\ntime slot which sources should send their updates. As the scheduler does not\nknow the real state of the remote sources, it estimates at each time the value\nof AoII based on the Markovian sources' parameters. Its goal is to keep the\ntime average of AoII function as small as possible. We develop a scheduling\nscheme based on Whittle's index policy for that purpose. To that extent, we\nproceed by using the Lagrangian Relaxation Approach and establish that the dual\nproblem has an optimal threshold policy. Building on that, we compute the\nexpressions of Whittle's indices. Finally, we provide some numerical results to\nhighlight the performance of our derived policy compared to the classical AoI\nmetric.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2102.03245\n",
    "authors": [
      "Saad Kriouile",
      "Mohamad Assaad"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.02878"
  },
  {
    "id": "arXiv:2202.02879",
    "title": "An Empirical Analysis of AI Contributions to Sustainable Cities (SDG11)",
    "abstract": "Artificial Intelligence (AI) presents opportunities to develop tools and\ntechniques for addressing some of the major global challenges and deliver\nsolutions with significant social and economic impacts. The application of AI\nhas far-reaching implications for the 17 Sustainable Development Goals (SDGs)\nin general, and sustainable urban development in particular. However, existing\nattempts to understand and use the opportunities offered by AI for SDG 11 have\nbeen explored sparsely, and the shortage of empirical evidence about the\npractical application of AI remains. In this chapter, we analyze the\ncontribution of AI to support the progress of SDG 11 (Sustainable Cities and\nCommunities). We address the knowledge gap by empirically analyzing the AI\nsystems (N = 29) from the AIxSDG database and the Community Research and\nDevelopment Information Service (CORDIS) database. Our analysis revealed that\nAI systems have indeed contributed to advancing sustainable cities in several\nways (e.g., waste management, air quality monitoring, disaster response\nmanagement, transportation management), but many projects are still working for\ncitizens and not with them. This snapshot of AI's impact on SDG11 is inherently\npartial, yet useful to advance our understanding as we move towards more mature\nsystems and research on the impact of AI systems for social good.",
    "descriptor": "\nComments: to appear in Mazzi, F. and Floridi, L. (eds) The Ethics of Artificial Intelligence for the Sustainable Development Goals\n",
    "authors": [
      "Shivam Gupta",
      "Auriol Degbelo"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.02879"
  },
  {
    "id": "arXiv:2202.02880",
    "title": "Continuous-Time Channel Gain Control for Minimum-Information Kalman-Bucy  Filtering",
    "abstract": "We consider the problem of estimating a continuous-time Gauss-Markov source\nprocess observed through a vector Gaussian channel with an adjustable channel\ngain matrix. For a given (generally time-varying) channel gain matrix, we\nprovide formulas to compute (i) the mean-square estimation error attainable by\nthe classical Kalman-Bucy filter, and (ii) the mutual information between the\nsource process and its Kalman-Bucy estimate. We then formulate a novel \"optimal\nchannel gain control problem\" where the objective is to control the channel\ngain matrix strategically to minimize the weighted sum of these two performance\nmetrics. To develop insights into the optimal solution, we first consider the\nproblem of controlling a time-varying channel gain over a finite time interval.\nA necessary optimality condition is derived based on Pontryagin's minimum\nprinciple. For a scalar system, we show that the optimal channel gain is a\npiece-wise constant signal with at most two switches. We also consider the\nproblem of designing the optimal time-invariant gain to minimize the average\ncost over an infinite time horizon. A novel semidefinite programming (SDP)\nheuristic is proposed and the exactness of the solution is discussed.",
    "descriptor": "\nComments: 12 pages. arXiv admin note: substantial text overlap with arXiv:2109.13854\n",
    "authors": [
      "Takashi Tanaka",
      "Vrushabh Zinage",
      "Valery Ugrinovskii",
      "Mikael Skoglund"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.02880"
  },
  {
    "id": "arXiv:2202.02881",
    "title": "Trusted Approximate Policy Iteration with Bisimulation Metrics",
    "abstract": "Bisimulation metrics define a distance measure between states of a Markov\ndecision process (MDP) based on a comparison of reward sequences. Due to this\nproperty they provide theoretical guarantees in value function approximation.\nIn this work we first prove that bisimulation metrics can be defined via any\n$p$-Wasserstein metric for $p\\geq 1$. Then we describe an approximate policy\niteration (API) procedure that uses $\\epsilon$-aggregation with\n$\\pi$-bisimulation and prove performance bounds for continuous state spaces. We\nbound the difference between $\\pi$-bisimulation metrics in terms of the change\nin the policies themselves. Based on these theoretical results, we design an\nAPI($\\alpha$) procedure that employs conservative policy updates and enjoys\nbetter performance bounds than the naive API approach. In addition, we propose\na novel trust region approach which circumvents the requirement to explicitly\nsolve a constrained optimization problem. Finally, we provide experimental\nevidence of improved stability compared to non-conservative alternatives in\nsimulated continuous control.",
    "descriptor": "",
    "authors": [
      "Mete Kemertas",
      "Allan Jepson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.02881"
  },
  {
    "id": "arXiv:2202.02882",
    "title": "Diversity Multiplexing Trade-off and Selection Gain in Media-Based  Modulation",
    "abstract": "The idea of Media-based Modulation (MBM) is to embed information in the\nvariations of the transmission media (channel states). Using an RF closure with\n$w$ RF walls, MBM creates a set of $2^w$ select-able states for the end-to-end\nchannel. Each state represents an index of an MBM constellation point. In each\nstate, the wave (tone) emanating from the transmit antenna experiences many\npseudo-random back-and-forth reflections within the RF closure. The RF signal,\nupon finally leaving the RF closure, further propagates in the rich scattering\nenvironment to reach the receiver. This results in an independent complex\nchannel gain to each receive antenna. As a result, coordinates of different MBM\nconstellation points (vectors of channel gains formed over received antennas)\nwill be independent of each other. This is unlike legacy transmission schemes\nwhere a fixed constellation structure used at the transmitter will be\nmultiplied by a fixed, but random, channel gain. Due to this independence\nproperty, MBM offers several advantages vs. legacy systems, including\n\"additivity of information over multiple receive antennas (regardless of the\nnumber of transmit antennas)\", and \"inherent diversity over a static fading\nchannel\". This work studies the Diversity-Multiplexing Trade-off of an MBM\nconstellation. Analytical expressions are provided that demonstrate the\nadvantages of MBM vs. legacy systems. In particular, it is shown that a\n$1\\times N_r$ SIMO-MBM constellation equipped with an MDS code (even with a\nrelatively small code length) significantly outperforms an $N_r\\times N_r$\nlegacy MIMO.",
    "descriptor": "",
    "authors": [
      "Ehsan Seifi",
      "Amir K. Khandani"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.02882"
  },
  {
    "id": "arXiv:2202.02886",
    "title": "Leveraging Approximate Symbolic Models for Reinforcement Learning via  Skill Diversity",
    "abstract": "Creating reinforcement learning (RL) agents that are capable of accepting and\nleveraging task-specific knowledge from humans has been long identified as a\npossible strategy for developing scalable approaches for solving long-horizon\nproblems. While previous works have looked at the possibility of using symbolic\nmodels along with RL approaches, they tend to assume that the high-level action\nmodels are executable at low level and the fluents can exclusively characterize\nall desirable MDP states. This need not be true and this assumption overlooks\none of the central technical challenges of incorporating symbolic task\nknowledge, namely, that these symbolic models are going to be an incomplete\nrepresentation of the underlying task. To this end, we introduce Symbolic-Model\nGuided Reinforcement Learning, wherein we will formalize the relationship\nbetween the symbolic model and the underlying MDP that will allow us to capture\nthe incompleteness of the symbolic model. We will use these models to extract\nhigh-level landmarks that will be used to decompose the task, and at the low\nlevel, we learn a set of diverse policies for each possible task sub-goal\nidentified by the landmark. We evaluate our system by testing on three\ndifferent benchmark domains and we show how even with incomplete symbolic model\ninformation, our approach is able to discover the task structure and\nefficiently guide the RL agent towards the goal.",
    "descriptor": "",
    "authors": [
      "Lin Guan",
      "Sarath Sreedharan",
      "Subbarao Kambhampati"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.02886"
  },
  {
    "id": "arXiv:2202.02887",
    "title": "Monte Carlo Methods for Estimating the Diagonal of a Real Symmetric  Matrix",
    "abstract": "For real symmetric matrices that are accessible only through matrix vector\nproducts, we present Monte Carlo estimators for computing the diagonal\nelements. Our probabilistic bounds for normwise absolute and relative errors\napply to Monte Carlo estimators based on random Rademacher, sparse Rademacher,\nnormalized and unnormalized Gaussian vectors, and to vectors with bounded\nfourth moments. The novel use of matrix concentration inequalities in our\nproofs represents a systematic model for future analyses. Our bounds mostly do\nnot depend on the matrix dimension, target different error measures than\nexisting work, and imply that the accuracy of the estimators increases with the\ndiagonal dominance of the matrix. An application to derivative-based global\nsensitivity metrics corroborates this, as do numerical experiments on synthetic\ntest matrices. We recommend against the use in practice of sparse Rademacher\nvectors, which are the basis for many randomized sketching and sampling\nalgorithms, because they tend to deliver barely a digit of accuracy even under\nlarge sampling amounts.",
    "descriptor": "",
    "authors": [
      "Eric Hallman",
      "Ilse C.F. Ipsen",
      "Arvind Saibaba"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2202.02887"
  },
  {
    "id": "arXiv:2202.02891",
    "title": "Causal Inference Using Tractable Circuits",
    "abstract": "The aim of this paper is to discuss a recent result which shows that\nprobabilistic inference in the presence of (unknown) causal mechanisms can be\ntractable for models that have traditionally been viewed as intractable. This\nresult was reported recently to facilitate model-based supervised learning but\nit can be interpreted in a causality context as follows. One can compile a\nnon-parametric causal graph into an arithmetic circuit that supports inference\nin time linear in the circuit size. The circuit is also non-parametric so it\ncan be used to estimate parameters from data and to further reason (in linear\ntime) about the causal graph parametrized by these estimates. Moreover, the\ncircuit size can sometimes be bounded even when the treewidth of the causal\ngraph is not, leading to tractable inference on models that have been deemed\nintractable previously. This has been enabled by a new technique that can\nexploit causal mechanisms computationally but without needing to know their\nidentities (the classical setup in causal inference). Our goal is to provide a\ncausality-oriented exposure to these new results and to speculate on how they\nmay potentially contribute to more scalable and versatile causal inference.",
    "descriptor": "\nComments: Appeared in Why-21 workshop of NeurIPS 2021 (Causal Inference & Machine Learning: Why now?)\n",
    "authors": [
      "Adnan Darwiche"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computational Complexity (cs.CC)",
      "Machine Learning (cs.LG)",
      "Logic in Computer Science (cs.LO)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2202.02891"
  },
  {
    "id": "arXiv:2202.02892",
    "title": "Learning under Storage and Privacy Constraints",
    "abstract": "Storage-efficient privacy-guaranteed learning is crucial due to enormous\namounts of sensitive user data required for increasingly many learning tasks.\nWe propose a framework for reducing the storage cost while at the same time\nproviding privacy guarantees, without essential loss in the utility of the data\nfor learning. Our method comprises noise injection followed by lossy\ncompression. We show that, when appropriately matching the lossy compression to\nthe distribution of the added noise, the compressed examples converge, in\ndistribution, to that of the noise-free training data. In this sense, the\nutility of the data for learning is essentially maintained, while reducing\nstorage and privacy leakage by quantifiable amounts. We present experimental\nresults on the CelebA dataset for gender classification and find that our\nsuggested pipeline delivers in practice on the promise of the theory: the\nindividuals in the images are unrecognizable (or less recognizable, depending\non the noise level), overall storage of the data is substantially reduced, with\nno essential loss of the classification accuracy. As an added bonus, our\nexperiments suggest that our method yields a substantial boost to robustness in\nthe face of adversarial test data.",
    "descriptor": "\nComments: 6 pages, 3 figures\n",
    "authors": [
      "Berivan Isik",
      "Tsachy Weissman"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.02892"
  },
  {
    "id": "arXiv:2202.02894",
    "title": "Effects of Parametric and Non-Parametric Methods on High Dimensional  Sparse Matrix Representations",
    "abstract": "The semantics are derived from textual data that provide representations for\nMachine Learning algorithms. These representations are interpretable form of\nhigh dimensional sparse matrix that are given as an input to the machine\nlearning algorithms. Since learning methods are broadly classified as\nparametric and non-parametric learning methods, in this paper we provide the\neffects of these type of algorithms on the high dimensional sparse matrix\nrepresentations. In order to derive the representations from the text data, we\nhave considered TF-IDF representation with valid reason in the paper. We have\nformed representations of 50, 100, 500, 1000 and 5000 dimensions respectively\nover which we have performed classification using Linear Discriminant Analysis\nand Naive Bayes as parametric learning method, Decision Tree and Support Vector\nMachines as non-parametric learning method. We have later provided the metrics\non every single dimension of the representation and effect of every single\nalgorithm detailed in this paper.",
    "descriptor": "\nComments: 7 pages, 6 tables, 13 equations\n",
    "authors": [
      "Sayali Tambe",
      "Raunak Joshi",
      "Abhishek Gupta",
      "Nandan Kanvinde",
      "Vidya Chitre"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.02894"
  },
  {
    "id": "arXiv:2202.02895",
    "title": "An Automated Approach for Privacy Leakage Identification in IoT Apps",
    "abstract": "This paper presents a fully automated static analysis approach and a tool,\nTaint-Things, for the identification of tainted flows in SmartThings IoT apps.\nTaint-Things accurately identifies all tainted flows reported by one of the\nstate-of-the-art tools with at least 4 times improved performance. Our approach\nreports potential vulnerable tainted flows in a form of a concise security\nslice, where the relevant parts of the code are given with the lines affecting\nthe sensitive information, which could provide security auditors with an\neffective and precise tool to pinpoint security issues in SmartThings apps\nunder test. We also present and test ways to add precision to Taint-Things by\nadding extra sensitivities; we provide different approaches for flow, path and\ncontext sensitive analyses through modules that can be added to Taint-Things.\nWe present experiments to evaluate Taint-Things by running it on a SmartThings\napp dataset as well as testing for precision and recall on a set generated by a\nmutation framework to see how much coverage is achieved without adding false\npositives. This shows an improvement in performance both in terms of speed up\nto 4 folds, as well as improving the precision avoiding false positives by\nproviding a higher level of flow and path sensitivity analysis in comparison\nwith one of state of the art tools.",
    "descriptor": "",
    "authors": [
      "Bara' Nazzal",
      "Manar H. Alalfi"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.02895"
  },
  {
    "id": "arXiv:2202.02896",
    "title": "Evaluation Methods and Measures for Causal Learning Algorithms",
    "abstract": "The convenient access to copious multi-faceted data has encouraged machine\nlearning researchers to reconsider correlation-based learning and embrace the\nopportunity of causality-based learning, i.e., causal machine learning (causal\nlearning). Recent years have therefore witnessed great effort in developing\ncausal learning algorithms aiming to help AI achieve human-level intelligence.\nDue to the lack-of ground-truth data, one of the biggest challenges in current\ncausal learning research is algorithm evaluations. This largely impedes the\ncross-pollination of AI and causal inference, and hinders the two fields to\nbenefit from the advances of the other. To bridge from conventional causal\ninference (i.e., based on statistical methods) to causal learning with big data\n(i.e., the intersection of causal inference and machine learning), in this\nsurvey, we review commonly-used datasets, evaluation methods, and measures for\ncausal learning using an evaluation pipeline similar to conventional machine\nlearning. We focus on the two fundamental causal-inference tasks and\ncausality-aware machine learning tasks. Limitations of current evaluation\nprocedures are also discussed. We then examine popular causal inference\ntools/packages and conclude with primary challenges and opportunities for\nbenchmarking causal learning algorithms in the era of big data. The survey\nseeks to bring to the forefront the urgency of developing publicly available\nbenchmarks and consensus-building standards for causal learning evaluation with\nobservational data. In doing so, we hope to broaden the discussions and\nfacilitate collaboration to advance the innovation and application of causal\nlearning.",
    "descriptor": "\nComments: 21 pages. Accepted to IEEE TAI\n",
    "authors": [
      "Lu Cheng",
      "Ruocheng Guo",
      "Raha Moraffah",
      "Paras Sheth",
      "K. Selcuk Candan",
      "Huan Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2202.02896"
  },
  {
    "id": "arXiv:2202.02898",
    "title": "Gradient boosting machines and careful pre-processing work best: ASHRAE  Great Energy Predictor III lessons learned",
    "abstract": "The ASHRAE Great Energy Predictor III (GEPIII) competition was held in late\n2019 as one of the largest machine learning competitions ever held focused on\nbuilding performance. It was hosted on the Kaggle platform and resulted in\n39,402 prediction submissions, with the top five teams splitting $25,000 in\nprize money. This paper outlines lessons learned from participants, mainly from\nteams who scored in the top 5% of the competition. Various insights were gained\nfrom their experience through an online survey, analysis of publicly shared\nsubmissions and notebooks, and the documentation of the winning teams. The\ntop-performing solutions mostly used ensembles of Gradient Boosting Machine\n(GBM) tree-based models, with the LightGBM package being the most popular. The\nsurvey participants indicated that the preprocessing and feature extraction\nphases were the most important aspects of creating the best modeling approach.\nAll the survey respondents used Python as their primary modeling tool, and it\nwas common to use Jupyter-style Notebooks as development environments. These\nconclusions are essential to help steer the research and practical\nimplementation of building energy meter prediction in the future.",
    "descriptor": "",
    "authors": [
      "Clayton Miller",
      "Liu Hao",
      "Chun Fu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.02898"
  },
  {
    "id": "arXiv:2202.02900",
    "title": "A Passivity Based Framework for Safe Physical Human Robot Interaction",
    "abstract": "In this paper, the problem of making a safe compliant contact between a human\nand an assistive robot is considered. Users with disabilities have a need to\nutilize their assistive robots for physical human-robot interaction (PHRI)\nduring certain activities of daily living (ADLs). Specifically, we propose a\nhybrid force/velocity/attitude control for a PHRI system based on measurements\nfrom a 6-axis force/torque sensor mounted on the robot wrist. While\nautomatically aligning the end-effector surface with the unknown environmental\n(human) surface, a desired commanded force is applied in the normal direction\nwhile following desired velocity commands in the tangential directions. A\nLyapunov based stability analysis is provided to prove both convergence as well\nas passivity of the interaction to ensure both performance and safety.\nSimulation as well as experimental results verify the performance and\nrobustness of the proposed hybrid controller in the presence of dynamic\nuncertainties as well as safe physical human-robot interactions for a\nkinematically redundant robotic manipulator.",
    "descriptor": "\nComments: 14 pages, 31 figures, 1 Table, Submitted to IEEE TCST for Review\n",
    "authors": [
      "Z. Ding",
      "M. Baghbahari",
      "A. Behal"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.02900"
  },
  {
    "id": "arXiv:2202.02902",
    "title": "Redactor: Targeted Disinformation Generation using Probabilistic  Decision Boundaries",
    "abstract": "Information leakage is becoming a critical problem as various information\nbecomes publicly available by mistake, and machine learning models train on\nthat data to provide services. As a result, one's private information could\neasily be memorized by such trained models. Unfortunately, deleting information\nis out of the question as the data is already exposed to the Web or third-party\nplatforms. Moreover, we cannot necessarily control the labeling process and the\nmodel trainings by other parties either. In this setting, we study the problem\nof targeted disinformation where the goal is to lower the accuracy of inference\nattacks on a specific target (e.g., a person's profile) only using data\ninsertion. While our problem is related to data privacy and defenses against\nexploratory attacks, our techniques are inspired by targeted data poisoning\nattacks with some key differences. We show that our problem is best solved by\nfinding the closest points to the target in the input space that will be\nlabeled as a different class. Since we do not control the labeling process, we\ninstead conservatively estimate the labels probabilistically by combining\ndecision boundaries of multiple classifiers using data programming techniques.\nWe also propose techniques for making the disinformation realistic. Our\nexperiments show that a probabilistic decision boundary can be a good proxy for\nlabelers, and that our approach outperforms other targeted poisoning methods\nwhen using end-to-end training on real datasets.",
    "descriptor": "\nComments: 9 pages, 7 figures\n",
    "authors": [
      "Geon Heo",
      "Steven Euijong Whang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.02902"
  },
  {
    "id": "arXiv:2202.02904",
    "title": "A Least Square Approach to Semi-supervised Local Cluster Extraction",
    "abstract": "A least square semi-supervised local clustering algorithm based on the idea\nof compressed sensing are proposed to extract clusters from a graph with known\nadjacency matrix. The algorithm is based on a two stage approaches similar to\nthe one in \\cite{LaiMckenzie2020}. However, under a weaker assumption and with\nless computational complexity than the one in \\cite{LaiMckenzie2020}, the\nalgorithm is shown to be able to find a desired cluster with high probability.\nSeveral numerical experiments including the synthetic data and real data such\nas MNIST, AT\\&T and YaleB human faces data sets are conducted to demonstrate\nthe performance of our algorithm.",
    "descriptor": "",
    "authors": [
      "Ming-Jun Lai",
      "Zhaiming Shen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.02904"
  },
  {
    "id": "arXiv:2202.02905",
    "title": "Channel Capacity for Adversaries with Computationally Bounded  Observations",
    "abstract": "We study reliable communication over point-to-point adversarial channels in\nwhich the adversary can observe the codeword via some function that takes the\n$n$-bit codeword as input and computes an $rn$-bit output. We consider the\nscenario where the $rn$-bit observation is computationally bounded -- the\nadversary is free to choose an arbitrary observation function as long as the\nfunction can be computed using a polynomial amount of computational resources.\nThis observation-based restriction differs from conventional channel-based\ncomputational limitations, where in the later case, the resource limitation\napplies to the computation of the channel error. For some number $r^* \\in\n[0,1]$ and for $r \\in [0,r^*]$, we characterize the capacity of the above\nchannel. For this range of $r$, we find that the capacity is identical to the\ncompletely obvious setting ($r=0$). This result can be viewed as a\ngeneralization of known results on myopic adversaries and channels with active\neavesdroppers for which the observation process depends on a fixed distribution\nand fixed-linear structure, respectively, that cannot be chosen arbitrarily by\nthe adversary.",
    "descriptor": "",
    "authors": [
      "Eric Ruzomberka",
      "Chih-Chun Wang",
      "David J. Love"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.02905"
  },
  {
    "id": "arXiv:2202.02906",
    "title": "Universality of parametric Coupling Flows over parametric  diffeomorphisms",
    "abstract": "Invertible neural networks based on Coupling Flows CFlows) have various\napplications such as image synthesis and data compression. The approximation\nuniversality for CFlows is of paramount importance to ensure the model\nexpressiveness. In this paper, we prove that CFlows can approximate any\ndiffeomorphism in C^k-norm if its layers can approximate certain\nsingle-coordinate transforms. Specifically, we derive that a composition of\naffine coupling layers and invertible linear transforms achieves this\nuniversality. Furthermore, in parametric cases where the diffeomorphism depends\non some extra parameters, we prove the corresponding approximation theorems for\nour proposed parametric coupling flows named Para-CFlows. In practice, we apply\nPara-CFlows as a neural surrogate model in contextual Bayesian optimization\ntasks, to demonstrate its superiority over other neural surrogate models in\nterms of optimization performance.",
    "descriptor": "\nComments: 22 pages, 6 figures\n",
    "authors": [
      "Junlong Lyu",
      "Zhitang Chen",
      "Chang Feng",
      "Wenjing Cun",
      "Shengyu Zhu",
      "Yanhui Geng",
      "Zhijie Xu",
      "Yongwei Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Differential Geometry (math.DG)",
      "Functional Analysis (math.FA)"
    ],
    "url": "https://arxiv.org/abs/2202.02906"
  },
  {
    "id": "arXiv:2202.02911",
    "title": "Traffic-aware Gateway Placement and Queue Management in Flying Networks",
    "abstract": "Unmanned Aerial Vehicles (UAVs) have emerged as adequate platforms to carry\ncommunications nodes, including Wi-Fi Access Points and cellular Base Stations.\nThis has led to the concept of flying networks composed of UAVs as a flexible\nand agile solution to provide on-demand wireless connectivity anytime,\nanywhere. However, state of the art works have been focused on optimizing the\nplacement of the access network providing connectivity to ground users,\noverlooking the backhaul network design. In order to improve the overall\nQuality of Service (QoS) offered to ground users, the placement of Flying\nGateways (FGWs) and the size of the queues configured in the UAVs need to be\ncarefully defined to meet strict performance requirements. The main\ncontribution of this article is a traffic-aware gateway placement and queue\nmanagement (GPQM) algorithm for flying networks. GPQM takes advantage of\nknowing in advance the positions of the UAVs and their traffic demand to\ndetermine the FGW position and the queue size of the UAVs, in order to maximize\nthe aggregate throughput and provide stochastic delay guarantees. GPQM is\nevaluated by means of ns-3 simulations, considering a realistic wireless\nchannel model. The results demonstrate significant gains in the QoS offered\nwhen GPQM is used.",
    "descriptor": "",
    "authors": [
      "Andr\u00e9 Coelho",
      "Rui Campos",
      "Manuel Ricardo"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2202.02911"
  },
  {
    "id": "arXiv:2202.02912",
    "title": "User Satisfaction Estimation with Sequential Dialogue Act Modeling in  Goal-oriented Conversational Systems",
    "abstract": "User Satisfaction Estimation (USE) is an important yet challenging task in\ngoal-oriented conversational systems. Whether the user is satisfied with the\nsystem largely depends on the fulfillment of the user's needs, which can be\nimplicitly reflected by users' dialogue acts. However, existing studies often\nneglect the sequential transitions of dialogue act or rely heavily on annotated\ndialogue act labels when utilizing dialogue acts to facilitate USE. In this\npaper, we propose a novel framework, namely USDA, to incorporate the sequential\ndynamics of dialogue acts for predicting user satisfaction, by jointly learning\nUser Satisfaction Estimation and Dialogue Act Recognition tasks. In specific,\nwe first employ a Hierarchical Transformer to encode the whole dialogue\ncontext, with two task-adaptive pre-training strategies to be a second-phase\nin-domain pre-training for enhancing the dialogue modeling ability. In terms of\nthe availability of dialogue act labels, we further develop two variants of\nUSDA to capture the dialogue act information in either supervised or\nunsupervised manners. Finally, USDA leverages the sequential transitions of\nboth content and act features in the dialogue to predict the user satisfaction.\nExperimental results on four benchmark goal-oriented dialogue datasets across\ndifferent applications show that the proposed method substantially and\nconsistently outperforms existing methods on USE, and validate the important\nrole of dialogue act sequences in USE.",
    "descriptor": "\nComments: Accepted by WWW 2022 (The Web Conference)\n",
    "authors": [
      "Yang Deng",
      "Wenxuan Zhang",
      "Wai Lam",
      "Hong Cheng",
      "Helen Meng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.02912"
  },
  {
    "id": "arXiv:2202.02915",
    "title": "Mobile Based Gradebook with Student Outcomes Analytics",
    "abstract": "Mobile applications and other integration of information and communication\ntechnology (ICT) have become well-known in education to monitor teaching and\nlearning activities. The analysis of student learning through evaluation is a\ngrowing area of interest for teachers in higher education aiming to enhance\nstudents learning experience. This paper describes a development of student\noutcomes monitoring tool that applies analytics to provide feedback to students\nas they progress in the ladder of achieving the intended learning outcomes. The\nstudent outcomes focus on the core elements of the curriculum; it offers\ndetailed student outcomes where the result in courses evaluations and\nrecordings are tracked and analyzed. The data revealed that the student\noutcomes monitoring and analytics tool is adequate in providing constant\nfeedback to students on the achievement of the desired learning outcomes as\nwell as support teachers in planning the teaching and learning activities,\nenhance feedback system, academic planning and improvement.",
    "descriptor": "\nComments: None\n",
    "authors": [
      "Ronel B. Dayanghirang",
      "Alexander A. Hernandez"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2202.02915"
  },
  {
    "id": "arXiv:2202.02916",
    "title": "Dataset Condensation with Contrastive Signals",
    "abstract": "Recent studies have demonstrated that gradient matching-based dataset\nsynthesis, or dataset condensation (DC), methods can achieve state-of-the-art\nperformance when applied to data-efficient learning tasks. However, in this\nstudy, we prove that the existing DC methods can perform worse than the random\nselection method when task-irrelevant information forms a significant part of\nthe training dataset. We attribute this to the lack of participation of the\ncontrastive signals between the classes resulting from the class-wise gradient\nmatching strategy. To address this problem, we propose Dataset Condensation\nwith Contrastive signals (DCC) by modifying the loss function to enable the DC\nmethods to effectively capture the differences between classes. In addition, we\nanalyze the new loss function in terms of training dynamics by tracking the\nkernel velocity. Furthermore, we introduce a bi-level warm-up strategy to\nstabilize the optimization. Our experimental results indicate that while the\nexisting methods are ineffective for fine-grained image classification tasks,\nthe proposed method can successfully generate informative synthetic datasets\nfor the same tasks. Moreover, we demonstrate that the proposed method\noutperforms the baselines even on benchmark datasets such as SVHN, CIFAR-10,\nand CIFAR-100. Finally, we demonstrate the high applicability of the proposed\nmethod by applying it to continual learning tasks.",
    "descriptor": "",
    "authors": [
      "Saehyung Lee",
      "Sanghyuk Chun",
      "Sangwon Jung",
      "Sangdoo Yun",
      "Sungroh Yoon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.02916"
  },
  {
    "id": "arXiv:2202.02918",
    "title": "Soft Actor-Critic with Inhibitory Networks for Faster Retraining",
    "abstract": "Reusing previously trained models is critical in deep reinforcement learning\nto speed up training of new agents. However, it is unclear how to acquire new\nskills when objectives and constraints are in conflict with previously learned\nskills. Moreover, when retraining, there is an intrinsic conflict between\nexploiting what has already been learned and exploring new skills. In soft\nactor-critic (SAC) methods, a temperature parameter can be dynamically adjusted\nto weight the action entropy and balance the explore $\\times$ exploit\ntrade-off. However, controlling a single coefficient can be challenging within\nthe context of retraining, even more so when goals are contradictory. In this\nwork, inspired by neuroscience research, we propose a novel approach using\ninhibitory networks to allow separate and adaptive state value evaluations, as\nwell as distinct automatic entropy tuning. Ultimately, our approach allows for\ncontrolling inhibition to handle conflict between exploiting less risky,\nacquired behaviors and exploring novel ones to overcome more challenging tasks.\nWe validate our method through experiments in OpenAI Gym environments.",
    "descriptor": "\nComments: 16 pages including Appendix\n",
    "authors": [
      "Jaime S. Ide",
      "Daria Mi\u0107ovi\u0107",
      "Michael J. Guarino",
      "Kevin Alcedo",
      "David Rosenbluth",
      "Adrian P. Pope"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2202.02918"
  },
  {
    "id": "arXiv:2202.02924",
    "title": "3TO: THz-Enabled Throughput and Trajectory Optimization of UAVs in 6G  Networks by Proximal Policy Optimization Deep Reinforcement Learning",
    "abstract": "Next-generation networks need to meet ubiquitous and high data-rate demand.\nTherefore, this paper considers the throughput and trajectory optimization of\nterahertz (THz)-enabled unmanned aerial vehicles (UAVs) in the sixth-generation\n(6G) communication networks. In the considered scenario, multiple UAVs must\nprovide on-demand terabits per second (TB/s) services to an urban area along\nwith existing terrestrial networks. However, THz-empowered UAVs pose some new\nconstraints, e.g., dynamic THz-channel conditions for ground users (GUs)\nassociation and UAV trajectory optimization to fulfill GU's throughput demands.\nThus, a framework is proposed to address these challenges, where a joint\nUAVs-GUs association, transmit power, and the trajectory optimization problem\nis studied. The formulated problem is mixed-integer non-linear programming\n(MINLP), which is NP-hard to solve. Consequently, an iterative algorithm is\nproposed to solve three sub-problems iteratively, i.e., UAVs-GUs association,\ntransmit power, and trajectory optimization. Simulation results demonstrate\nthat the proposed algorithm increased the throughput by up to 10%, 68.9%, and\n69.1% respectively compared to baseline algorithms.",
    "descriptor": "",
    "authors": [
      "Sheikh Salman Hassan",
      "Yu Min Park",
      "Yan Kyaw Tun",
      "Walid Saad",
      "Zhu Han",
      "Choong Seon Hong"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.02924"
  },
  {
    "id": "arXiv:2202.02925",
    "title": "Benchmarking Deep Models for Salient Object Detection",
    "abstract": "In recent years, deep network-based methods have continuously refreshed\nstate-of-the-art performance on Salient Object Detection (SOD) task. However,\nthe performance discrepancy caused by different implementation details may\nconceal the real progress in this task. Making an impartial comparison is\nrequired for future researches. To meet this need, we construct a general\nSALient Object Detection (SALOD) benchmark to conduct a comprehensive\ncomparison among several representative SOD methods. Specifically, we\nre-implement 14 representative SOD methods by using consistent settings for\ntraining. Moreover, two additional protocols are set up in our benchmark to\ninvestigate the robustness of existing methods in some limited conditions. In\nthe first protocol, we enlarge the difference between objectness distributions\nof train and test sets to evaluate the robustness of these SOD methods. In the\nsecond protocol, we build multiple train subsets with different scales to\nvalidate whether these methods can extract discriminative features from only a\nfew samples. In the above experiments, we find that existing loss functions\nusually specialized in some metrics but reported inferior results on the\nothers. Therefore, we propose a novel Edge-Aware (EA) loss that promotes deep\nnetworks to learn more discriminative features by integrating both pixel- and\nimage-level supervision signals. Experiments prove that our EA loss reports\nmore robust performances compared to existing losses.",
    "descriptor": "\nComments: 24 pages\n",
    "authors": [
      "Huajun Zhou",
      "Yang Lin",
      "Lingxiao Yang",
      "Jianhuang Lai",
      "Xiaohua Xie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.02925"
  },
  {
    "id": "arXiv:2202.02926",
    "title": "Feedback Linearization Based Tracking Control of A Tilt-rotor with  Cat-trot Gait Plan",
    "abstract": "With the introduction of the laterally bounded forces, the tilt-rotor gains\nmore flexibility in the controller design. Typical Feedback Linearization\nmethods of controlling this vehicle utilize all the inputs; the magnitudes as\nwell as the directions of the thrusts are maneuvered simultaneously based on a\nunified control rule. Although several promising results indicate that these\ncontrollers may track the desired complicated trajectories, the tilting angles\nare required to change relatively fast or in large scale during the flight.\nThis problem challenges the applicability of these control algorithms. The\nrecent idea in sacrifice the number of input and deem the tilt-rotor an\nunder-actuated system may solve this problem; the tilting angles are fixed or\nvary in a predetermined pattern without being maneuvered by the control\nalgorithm. By careful avoidance of the singular decoupling matrix, several\nattitudes can be tracked without changing the tilting angles unexpectedly.\nWhile the position was not directly regulated by the Feedback Linearization\nmethods in that research, which left the position-tracking still an open\nquestion. In this research, we elucidate the coupling relationship between the\nposition and the attitude. Based on this, we design the position-tracking\ncontroller adopting Feedback Linearization. We also plan the gait for the\ntilt-rotor based on the cat-trot gait. The controller is verified in Simulink,\nMATLAB. Three types of references are designed for our tracking experiments:\nsetpoint, uniform rectilinear motion, and uniform circular motion. The\nsignificant improvement with less steady state error is witnessed after\nequipping with our modified position-attitude decoupler. This steady state\nerror is also influenced by the frequency of the cat-trot gait.",
    "descriptor": "",
    "authors": [
      "Zhe Shen",
      "Yudong Ma",
      "Takeshi Tsuchiya"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.02926"
  },
  {
    "id": "arXiv:2202.02927",
    "title": "Reinforcement Learning for Shared Autonomy Drone Landings",
    "abstract": "Novice pilots find it difficult to operate and land unmanned aerial vehicles\n(UAVs), due to the complex UAV dynamics, challenges in depth perception, lack\nof expertise with the control interface and additional disturbances from the\nground effect. Therefore we propose a shared autonomy approach to assist pilots\nin safely landing a UAV under conditions where depth perception is difficult\nand safe landing zones are limited. Our approach comprises of two modules: a\nperception module that encodes information onto a compressed latent\nrepresentation using two RGB-D cameras and a policy module that is trained with\nthe reinforcement learning algorithm TD3 to discern the pilot's intent and to\nprovide control inputs that augment the user's input to safely land the UAV.\nThe policy module is trained in simulation using a population of simulated\nusers. Simulated users are sampled from a parametric model with four\nparameters, which model a pilot's tendency to conform to the assistant,\nproficiency, aggressiveness and speed. We conduct a user study (n = 28) where\nhuman participants were tasked with landing a physical UAV on one of several\nplatforms under challenging viewing conditions. The assistant, trained with\nonly simulated user data, improved task success rate from 51.4% to 98.2%\ndespite being unaware of the human participants' goal or the structure of the\nenvironment a priori. With the proposed assistant, regardless of prior piloting\nexperience, participants performed with a proficiency greater than the most\nexperienced unassisted participants.",
    "descriptor": "\nComments: 14 pages, 13 figures. Submitted to IEEE Transactions on Robotics (T-RO)\n",
    "authors": [
      "Kal Backman",
      "Dana Kuli\u0107",
      "Hoam Chung"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.02927"
  },
  {
    "id": "arXiv:2202.02928",
    "title": "ABG: A Multi-Party Mixed Protocol Framework for Privacy-Preserving  Cooperative Learning",
    "abstract": "Cooperative learning, that enables two or more data owners to jointly train a\nmodel, has been widely adopted to solve the problem of insufficient training\ndata in machine learning. Nowadays, there is an urgent need for institutions\nand organizations to train a model cooperatively while keeping each other's\ndata privately. To address the issue of privacy-preserving in collaborative\nlearning, secure outsourced computation and federated learning are two typical\nmethods. Nevertheless, there are many drawbacks for these two methods when they\nare leveraged in cooperative learning. For secure outsourced computation,\nsemi-honest servers need to be introduced. Once the outsourced servers collude\nor perform other active attacks, the privacy of data will be disclosed. For\nfederated learning, it is difficult to apply to the scenarios where vertically\npartitioned data are distributed over multiple parties. In this work, we\npropose a multi-party mixed protocol framework, ABG$^n$, which effectively\nimplements arbitrary conversion between Arithmetic sharing (A), Boolean sharing\n(B) and Garbled-Circuits sharing (G) for $n$-party scenarios. Based on ABG$^n$,\nwe design a privacy-preserving multi-party cooperative learning system, which\nallows different data owners to cooperate in machine learning in terms of data\nsecurity and privacy-preserving. Additionally, we design specific\nprivacy-preserving computation protocols for some typical machine learning\nmethods such as logistic regression and neural networks. Compared with previous\nwork, the proposed method has a wider scope of application and does not need to\nrely on additional servers. Finally, we evaluate the performance of ABG$^n$ on\nthe local setting and on the public cloud setting. The experiments indicate\nthat ABG$^n$ has excellent performance, especially in the network environment\nwith low latency.",
    "descriptor": "",
    "authors": [
      "Hao Wang",
      "Zhi Li",
      "Chunpeng Ge",
      "Willy Susilo"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.02928"
  },
  {
    "id": "arXiv:2202.02929",
    "title": "Model-Based Offline Meta-Reinforcement Learning with Regularization",
    "abstract": "Existing offline reinforcement learning (RL) methods face a few major\nchallenges, particularly the distributional shift between the learned policy\nand the behavior policy. Offline Meta-RL is emerging as a promising approach to\naddress these challenges, aiming to learn an informative meta-policy from a\ncollection of tasks. Nevertheless, as shown in our empirical studies, offline\nMeta-RL could be outperformed by offline single-task RL methods on tasks with\ngood quality of datasets, indicating that a right balance has to be delicately\ncalibrated between \"exploring\" the out-of-distribution state-actions by\nfollowing the meta-policy and \"exploiting\" the offline dataset by staying close\nto the behavior policy. Motivated by such empirical analysis, we explore\nmodel-based offline Meta-RL with regularized Policy Optimization (MerPO), which\nlearns a meta-model for efficient task structure inference and an informative\nmeta-policy for safe exploration of out-of-distribution state-actions. In\nparticular, we devise a new meta-Regularized model-based Actor-Critic (RAC)\nmethod for within-task policy optimization, as a key building block of MerPO,\nusing conservative policy evaluation and regularized policy improvement; and\nthe intrinsic tradeoff therein is achieved via striking the right balance\nbetween two regularizers, one based on the behavior policy and the other on the\nmeta-policy. We theoretically show that the learnt policy offers guaranteed\nimprovement over both the behavior policy and the meta-policy, thus ensuring\nthe performance improvement on new tasks via offline Meta-RL. Experiments\ncorroborate the superior performance of MerPO over existing offline Meta-RL\nmethods.",
    "descriptor": "\nComments: Published as a conference paper at ICLR 2022\n",
    "authors": [
      "Sen Lin",
      "Jialin Wan",
      "Tengyu Xu",
      "Yingbin Liang",
      "Junshan Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.02929"
  },
  {
    "id": "arXiv:2202.02930",
    "title": "Towards Micro-video Thumbnail Selection via a Multi-label  Visual-semantic Embedding Model",
    "abstract": "The thumbnail, as the first sight of a micro-video, plays a pivotal role in\nattracting users to click and watch. While in the real scenario, the more the\nthumbnails satisfy the users, the more likely the micro-videos will be clicked.\nIn this paper, we aim to select the thumbnail of a given micro-video that meets\nmost users` interests. Towards this end, we present a multi-label\nvisual-semantic embedding model to estimate the similarity between the pair of\neach frame and the popular topics that users are interested in. In this model,\nthe visual and textual information is embedded into a shared semantic space,\nwhereby the similarity can be measured directly, even the unseen words.\nMoreover, to compare the frame to all words from the popular topics, we devise\nan attention embedding space associated with the semantic-attention projection.\nWith the help of these two embedding spaces, the popularity score of a frame,\nwhich is defined by the sum of similarity scores over the corresponding visual\ninformation and popular topic pairs, is achieved. Ultimately, we fuse the\nvisual representation score and the popularity score of each frame to select\nthe attractive thumbnail for the given micro-video. Extensive experiments\nconducted on a real-world dataset have well-verified that our model\nsignificantly outperforms several state-of-the-art baselines.",
    "descriptor": "",
    "authors": [
      "Liu Bo"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.02930"
  },
  {
    "id": "arXiv:2202.02931",
    "title": "TRGP: Trust Region Gradient Projection for Continual Learning",
    "abstract": "Catastrophic forgetting is one of the major challenges in continual learning.\nTo address this issue, some existing methods put restrictive constraints on the\noptimization space of the new task for minimizing the interference to old\ntasks. However, this may lead to unsatisfactory performance for the new task,\nespecially when the new task is strongly correlated with old tasks. To tackle\nthis challenge, we propose Trust Region Gradient Projection (TRGP) for\ncontinual learning to facilitate the forward knowledge transfer based on an\nefficient characterization of task correlation. Particularly, we introduce a\nnotion of `trust region' to select the most related old tasks for the new task\nin a layer-wise and single-shot manner, using the norm of gradient projection\nonto the subspace spanned by task inputs. Then, a scaled weight projection is\nproposed to cleverly reuse the frozen weights of the selected old tasks in the\ntrust region through a layer-wise scaling matrix. By jointly optimizing the\nscaling matrices and the model, where the model is updated along the directions\northogonal to the subspaces of old tasks, TRGP can effectively prompt knowledge\ntransfer without forgetting. Extensive experiments show that our approach\nachieves significant improvement over related state-of-the-art methods.",
    "descriptor": "\nComments: Published as a conference paper at ICLR 2022\n",
    "authors": [
      "Sen Lin",
      "Li Yang",
      "Deliang Fan",
      "Junshan Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.02931"
  },
  {
    "id": "arXiv:2202.02932",
    "title": "On the Stability of Super-Resolution and a Beurling-Selberg Type  Extremal Problem",
    "abstract": "Super-resolution estimation is the problem of recovering a stream of spikes\n(point sources) from the noisy observation of a few number of its first\ntrigonometric moments. The performance of super-resolution is recognized to be\nintimately related to the separation between the spikes to recover. A novel\nnotion of stability of the Fisher information matrix (FIM) of the\nsuper-resolution problem is introduced, when the minimal eigenvalue of the FIM\nis not asymptotically vanishing. The regime where the minimal separation is\ninversely proportional to the number of acquired moments is considered. It is\nshown that there is a separation threshold above which the eigenvalues of the\nFIM can be bounded by a quantity that does not depend on the number of moments.\nThe proof relies on characterizing the connection between the stability of the\nFIM and a generalization of the Beurling-Selberg box approximation problem.",
    "descriptor": "",
    "authors": [
      "Maxime Ferreira Da Costa",
      "Urbashi Mitra"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.02932"
  },
  {
    "id": "arXiv:2202.02934",
    "title": "Quantized MIMO: Channel Capacity and Spectrospatial Power Distribution",
    "abstract": "Millimeter wave systems suffer from high power consumption and are\nconstrained to use low resolution quantizers --digital to analog and analog to\ndigital converters (DACs and ADCs). However, low resolution quantization leads\nto reduced data rate and increased out-of-band emission noise. In this paper, a\nmultiple-input multiple-output (MIMO) system with linear transceivers using low\nresolution DACs and ADCs is considered. An information-theoretic analysis of\nthe system to model the effect of quantization on spectrospatial power\ndistribution and capacity of the system is provided. More precisely, it is\nshown that the impact of quantization can be accurately described via a linear\nmodel with additive independent Gaussian noise. This model in turn leads to\nsimple and intuitive expressions for spectrospatial power distribution of the\ntransmitter and a lower bound on the achievable rate of the system.\nFurthermore, the derived model is validated through simulations and numerical\nevaluations, where it is shown to accurately predict both spectral and spatial\npower distributions.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2001.03870\n",
    "authors": [
      "Abbas Khalili",
      "Elza Erkip",
      "Sundeep Rangan"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.02934"
  },
  {
    "id": "arXiv:2202.02937",
    "title": "Persistent Homology for Effective Non-Prehensile Manipulation",
    "abstract": "This work explores the use of topological tools for achieving effective\nnon-prehensile manipulation in cluttered, constrained workspaces. In\nparticular, it proposes the use of persistent homology as a guiding principle\nin identifying the appropriate non-prehensile actions, such as pushing, to\nclean a cluttered space with a robotic arm so as to allow the retrieval of a\ntarget object. Persistent homology enables the automatic identification of\nconnected components of blocking objects in the space without the need for\nmanual input or tuning of parameters. The proposed algorithm uses this\ninformation to push groups of cylindrical objects together and aims to minimize\nthe number of pushing actions needed to reach to the target. Simulated\nexperiments in a physics engine using a model of the Baxter robot show that the\nproposed topology-driven solution is achieving significantly higher success\nrate in solving such constrained problems relatively to state-of-the-art\nalternatives from the literature. It manages to keep the number of pushing\nactions low, is computationally efficient and the resulting decisions and\nmotion appear natural for effectively solving such tasks.",
    "descriptor": "",
    "authors": [
      "Ewerton R. Vieira",
      "Daniel Nakhimovich",
      "Kai Gao",
      "Rui Wang",
      "Jingjin Yu",
      "Kostas E. Bekris"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.02937"
  },
  {
    "id": "arXiv:2202.02942",
    "title": "Tractable Boolean and Arithmetic Circuits",
    "abstract": "Tractable Boolean and arithmetic circuits have been studied extensively in AI\nfor over two decades now. These circuits were initially proposed as \"compiled\nobjects,\" meant to facilitate logical and probabilistic reasoning, as they\npermit various types of inference to be performed in linear-time and a\nfeed-forward fashion like neural networks. In more recent years, the role of\ntractable circuits has significantly expanded as they became a computational\nand semantical backbone for some approaches that aim to integrate knowledge,\nreasoning and learning. In this article, we review the foundations of tractable\ncircuits and some associated milestones, while focusing on their core\nproperties and techniques that make them particularly useful for the broad aims\nof neuro-symbolic AI.",
    "descriptor": "\nComments: An earlier version of this article appeared in the following edited book. Pascal Hitzler and Md Kamruzzaman Sarker, editors. Neuro-Symbolic Artificial Intelligence: The State of the Art, volume 342 of Frontiers in Artificial Intelligence and Applications. IOS Press, 2021\n",
    "authors": [
      "Adnan Darwiche"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computational Complexity (cs.CC)",
      "Machine Learning (cs.LG)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2202.02942"
  },
  {
    "id": "arXiv:2202.02944",
    "title": "Prompt-Guided Injection of Conformation to Pre-trained Protein Model",
    "abstract": "Pre-trained protein models (PTPMs) represent a protein with one fixed\nembedding and thus are not capable for diverse tasks. For example, protein\nstructures can shift, namely protein folding, between several conformations in\nvarious biological processes. To enable PTPMs to produce task-aware\nrepresentations, we propose to learn interpretable, pluggable and extensible\nprotein prompts as a way of injecting task-related knowledge into PTPMs. In\nthis regard, prior PTPM optimization with the masked language modeling task can\nbe interpreted as learning a sequence prompt (Seq prompt) that enables PTPMs to\ncapture the sequential dependency between amino acids. To incorporate\nconformational knowledge to PTPMs, we propose an interaction-conformation\nprompt (IC prompt) that is learned through back-propagation with the\nprotein-protein interaction task. As an instantiation, we present a\nconformation-aware pre-trained protein model that learns both sequence and\ninteraction-conformation prompts in a multi-task setting. We conduct\ncomprehensive experiments on nine protein datasets. Results confirm our\nexpectation that using the sequence prompt does not hurt PTPMs' performance on\nsequence-related tasks while incorporating the interaction-conformation prompt\nsignificantly improves PTPMs' performance on tasks where conformational\nknowledge counts. We also show the learned prompts can be combined and extended\nto deal with new complex tasks.",
    "descriptor": "\nComments: Work in progress\n",
    "authors": [
      "Qiang Zhang",
      "Zeyuan Wang",
      "Yuqiang Han",
      "Haoran Yu",
      "Xurui Jin",
      "Huajun Chen"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Biomolecules (q-bio.BM)"
    ],
    "url": "https://arxiv.org/abs/2202.02944"
  },
  {
    "id": "arXiv:2202.02947",
    "title": "Parallel Successive Learning for Dynamic Distributed Model Training over  Heterogeneous Wireless Networks",
    "abstract": "Federated learning (FedL) has emerged as a popular technique for distributing\nmodel training over a set of wireless devices, via iterative local updates (at\ndevices) and global aggregations (at the server). In this paper, we develop\n\\textit{parallel successive learning} (PSL), which expands the FedL\narchitecture along three dimensions: (i) Network, allowing decentralized\ncooperation among the devices via device-to-device (D2D) communications. (ii)\nHeterogeneity, interpreted at three levels: (ii-a) Learning: PSL considers\nheterogeneous number of stochastic gradient descent iterations with different\nmini-batch sizes at the devices; (ii-b) Data: PSL presumes a dynamic\nenvironment with data arrival and departure, where the distributions of local\ndatasets evolve over time, captured via a new metric for model/concept drift.\n(ii-c) Device: PSL considers devices with different computation and\ncommunication capabilities. (iii) Proximity, where devices have different\ndistances to each other and the access point. PSL considers the realistic\nscenario where global aggregations are conducted with idle times in-between\nthem for resource efficiency improvements, and incorporates data dispersion and\nmodel dispersion with local model condensation into FedL. Our analysis sheds\nlight on the notion of cold vs. warmed up models, and model inertia in\ndistributed machine learning. We then propose network-aware dynamic model\ntracking to optimize the model learning vs. resource efficiency tradeoff, which\nwe show is an NP-hard signomial programming problem. We finally solve this\nproblem through proposing a general optimization solver. Our numerical results\nreveal new findings on the interdependencies between the idle times in-between\nthe global aggregations, model/concept drift, and D2D cooperation\nconfiguration.",
    "descriptor": "",
    "authors": [
      "Seyyedali Hosseinalipour",
      "Su Wang",
      "Nicolo Michelusi",
      "Vaneet Aggarwal",
      "Christopher G. Brinton",
      "David J. Love",
      "Mung Chiang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Networking and Internet Architecture (cs.NI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.02947"
  },
  {
    "id": "arXiv:2202.02948",
    "title": "Improved Bounds for Fractional Online Matching Problems",
    "abstract": "Online bipartite matching with one-sided arrival and its variants have been\nextensively studied since the seminal work of Karp, Vazirani, and Vazirani\n(STOC 1990). Motivated by real-life applications with dynamic market\nstructures, e.g. ride-sharing, two generalizations of the classical one-sided\narrival model are proposed to allow non-bipartite graphs and to allow all\nvertices to arrive online. Namely, online matching with general vertex arrival\nis introduced by Wang and Wong (ICALP 2015), and fully online matching is\nintroduced by Huang et al. (JACM 2020).\nIn this paper, we study the fractional versions of the two models. We improve\nthree out of the four state-of-the-art upper and lower bounds of the two\nmodels. For fully online matching, we design a $0.6$-competitive algorithm and\nprove no problem can be $0.613$-competitive. For online matching with general\nvertex arrival, we prove no algorithm can be $0.584$-competitive. Moreover, we\ngive an arguably more intuitive algorithm for the general vertex arrival model,\ncompared to the algorithm of Wang and Wong, while attaining the same\ncompetitive ratio of $0.526$.",
    "descriptor": "",
    "authors": [
      "Zhihao Gavin Tang",
      "Yuhao Zhang"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2202.02948"
  },
  {
    "id": "arXiv:2202.02950",
    "title": "Jury Learning: Integrating Dissenting Voices into Machine Learning  Models",
    "abstract": "Whose labels should a machine learning (ML) algorithm learn to emulate? For\nML tasks ranging from online comment toxicity to misinformation detection to\nmedical diagnosis, different groups in society may have irreconcilable\ndisagreements about ground truth labels. Supervised ML today resolves these\nlabel disagreements implicitly using majority vote, which overrides minority\ngroups' labels. We introduce jury learning, a supervised ML approach that\nresolves these disagreements explicitly through the metaphor of a jury:\ndefining which people or groups, in what proportion, determine the classifier's\nprediction. For example, a jury learning model for online toxicity might\ncentrally feature women and Black jurors, who are commonly targets of online\nharassment. To enable jury learning, we contribute a deep learning architecture\nthat models every annotator in a dataset, samples from annotators' models to\npopulate the jury, then runs inference to classify. Our architecture enables\njuries that dynamically adapt their composition, explore counterfactuals, and\nvisualize dissent.",
    "descriptor": "\nComments: To appear at CHI 2022\n",
    "authors": [
      "Mitchell L. Gordon",
      "Michelle S. Lam",
      "Joon Sung Park",
      "Kayur Patel",
      "Jeffrey T. Hancock",
      "Tatsunori Hashimoto",
      "Michael S. Bernstein"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.02950"
  },
  {
    "id": "arXiv:2202.02959",
    "title": "A Machine Learning Approach for Material Type Logging and Chemical  Assaying from Autonomous Measure-While-Drilling (MWD) Data",
    "abstract": "Understanding the structure and mineralogical composition of a region is an\nessential step in mining, both during exploration (before mining) and in the\nmining process. During exploration, sparse but high-quality data are gathered\nto assess the overall orebody. During the mining process, boundary positions\nand material properties are refined as the mine progresses. This refinement is\nfacilitated through drilling, material logging, and chemical assaying. Material\ntype logging suffers from a high degree of variability due to factors such as\nthe diversity in mineralization and geology, the subjective nature of human\nmeasurement even by experts, and human error in manually recording results.\nWhile laboratory-based chemical assaying is much more precise, it is\ntime-consuming and costly and does not always capture or correlate boundary\npositions between all material types. This leads to significant challenges and\nfinancial implications for the industry, as the accuracy of production\nblasthole logging and assaying processes is essential for resource evaluation,\nplanning, and execution of mine plans. To overcome these challenges, this work\nreports on a pilot study to automate the process of material logging and\nchemical assaying. A machine learning approach has been trained on features\nextracted from measurement-while-drilling (MWD) data, logged from autonomous\ndrilling systems (ADS). MWD data facilitate the construction of profiles of\nphysical drilling parameters as a function of hole depth. A hypothesis is\nformed to link these drilling parameters to the underlying mineral composition.\nThe results of the pilot study discussed in this paper demonstrate the\nfeasibility of this process, with correlation coefficients of up to 0.92 for\nchemical assays and 93% accuracy for material detection, depending on the\nmaterial or assay type and their generalization across the different spatial\nregions.",
    "descriptor": "\nComments: 29 pages, 19 figures, mathematical geosciences, Rio Tinto Centre for Mine Automation\n",
    "authors": [
      "Rami N Khushaba",
      "Arman Melkumyan",
      "Andrew J Hill"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.02959"
  },
  {
    "id": "arXiv:2202.02960",
    "title": "Comprehensive Performance Analysis of Homomorphic Cryptosystems for  Practical Data Processing",
    "abstract": "Oblivious data processing has been an on and off topic for the last decade or\nso. It provides great opportunities for secure data management and processing,\nespecially in the cloud. At the same time, modern computing resources seem to\nbe affordable enough to allow for practical use of homomorphic cryptography.\nYet, the availability of products that offer practical homomorphic data\nprocessing is extremely scarce. As part of a project aimed at developing a\npractical homomorphic data management platform, we have conducted an extensive\nstudy of homomorphic cryptosystems' performance, the results of which are\npresented in this work. For this work we chose the following five\ncryptosystems: fully homomorphic HElib and SEAL, somewhat fully homomorphic\nPyAono, and partially homomorphic Paillier and ElGamal. In the discussion of\nthe aggregated results, we suggest that partially homomorphic cryptosystems\ncould be used today in certain practical applications, whereas time has not yet\ncome for the fully homomorphic ones.",
    "descriptor": "",
    "authors": [
      "Vasily Sidorov",
      "Ethan Yi Fan Wei",
      "Wee Keong Ng"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.02960"
  },
  {
    "id": "arXiv:2202.02961",
    "title": "Efficient ADMM Decoder for Non-binary LDPC Codes with  Codeword-Independent Performance",
    "abstract": "In this paper, we devote to devise a non-binary low-density parity-check\n(LDPC) decoder in Galois fields of characteristic two ($\\mathbb{F}_{2^q}$) via\nthe alternating direction method of multipliers (ADMM) technique. Through the\nproposed bit embedding technique and the decomposition technique of the\nthree-variables parity-check equation, an efficient ADMM decoding algorithm for\nnon-binary LDPC codes is proposed. The computation complexity in each ADMM\niteration is roughly $\\mathcal{O}(nq)$, which is significantly lower than the\nexisting LDPC decoders. Moreover, we prove that the proposed decoder satisfies\nthe favorable property of the codeword-independent. Simulation results\ndemonstrate the outstanding performance of the proposed decoder in contrast\nwith state-of-the-art LDPC decoders.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2201.00370\n",
    "authors": [
      "Xiaomeng Guo",
      "Yongchao Wang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.02961"
  },
  {
    "id": "arXiv:2202.02964",
    "title": "HDCoin: A Proof-of-Useful-Work Based Blockchain for Hyperdimensional  Computing",
    "abstract": "Various blockchain systems and schemes have been proposed since Bitcoin was\nfirst introduced by Nakamoto Satoshi as a distributed ledger. However,\nblockchains usually face criticisms, particularly on environmental concerns as\ntheir ``proof-of-work'' based mining process usually consumes a considerable\namount of energy which hardly makes any useful contributions to the real world.\nTherefore, the concept of ``proof-of-useful-work'' (PoUW) is proposed to\nconnect blockchain with practical application domain problems so the\ncomputation power consumed in the mining process can be spent on useful\nactivities, such as solving optimization problems or training machine learning\nmodels. This paper introduces HDCoin, a blockchain-based framework for an\nemerging machine learning scheme: the brain-inspired hyperdimensional computing\n(HDC). We formulate the model development of HDC as a problem that can be used\nin blockchain mining. Specifically, we define the PoUW under the HDC scenario\nand develop the entire mining process of HDCoin. During mining, miners are\ncompeting to obtain the highest test accuracy on a given dataset. The winner\nalso has its model recorded in the blockchain and are available for the public\nas a trustworthy HDC model. In addition, we also quantitatively examine the\nperformance of mining under different HDC configurations to illustrate the\nadaptive mining difficulty.",
    "descriptor": "",
    "authors": [
      "Dongning Ma",
      "Sizhe Zhang",
      "Xun Jiao"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2202.02964"
  },
  {
    "id": "arXiv:2202.02965",
    "title": "Energy-efficient Dynamic-subarray with Fixed True-time-delay Design for  Terahertz Wideband Hybrid Beamforming",
    "abstract": "Hybrid beamforming for Terahertz (THz) ultra-massive multiple-input\nmultiple-output (UM-MIMO) systems is a promising technology for 6G\nspace-air-ground integrated networks, which can overcome huge propagation loss\nand offer unprecedented data rates. With ultra-wide bandwidth and\nultra-large-scale antennas array in THz band, the beam squint becomes one of\nthe critical problems which could reduce the array gain and degrade the data\nrate substantially. However, the traditional phase-shifters-based hybrid\nbeamforming architectures cannot tackle this issue due to the frequency-flat\nproperty of the phase shifters. In this paper, to combat the beam squint while\nkeeping high energy efficiency, a novel dynamic-subarray with fixed\ntrue-time-delay (DS-FTTD) architecture is proposed. Compared to the existing\nstudies which use the complicated adjustable TTDs, the DS-FTTD architecture has\nlower power consumption and hardware complexity, thanks to the low-cost FTTDs.\nFurthermore, a low-complexity row-decomposition (RD) algorithm is proposed to\ndesign hybrid beamforming matrices for the DS-FTTD architecture. Extensive\nsimulation results show that, by using the RD algorithm, the DS-FTTD\narchitecture achieves near-optimal array gain and significantly higher energy\nefficiency than the existing architectures. Moreover, the spectral efficiency\nof DS-FTTD architecture with the RD algorithm is robust to the imperfect\nchannel state information.",
    "descriptor": "\nComments: 32 pages, 8 figures\n",
    "authors": [
      "Longfei Yan",
      "Chong Han",
      "Jinhong Yuan"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.02965"
  },
  {
    "id": "arXiv:2202.02967",
    "title": "Learning from Imperfect Demonstrations via Adversarial Confidence  Transfer",
    "abstract": "Existing learning from demonstration algorithms usually assume access to\nexpert demonstrations. However, this assumption is limiting in many real-world\napplications since the collected demonstrations may be suboptimal or even\nconsist of failure cases. We therefore study the problem of learning from\nimperfect demonstrations by learning a confidence predictor. Specifically, we\nrely on demonstrations along with their confidence values from a different\ncorrespondent environment (source environment) to learn a confidence predictor\nfor the environment we aim to learn a policy in (target environment -- where we\nonly have unlabeled demonstrations.) We learn a common latent space through\nadversarial distribution matching of multi-length partial trajectories to\nenable the transfer of confidence across source and target environments. The\nlearned confidence reweights the demonstrations to enable learning more from\ninformative demonstrations and discarding the irrelevant ones. Our experiments\nin three simulated environments and a real robot reaching task demonstrate that\nour approach learns a policy with the highest expected return.",
    "descriptor": "",
    "authors": [
      "Zhangjie Cao",
      "Zihan Wang",
      "Dorsa Sadigh"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.02967"
  },
  {
    "id": "arXiv:2202.02970",
    "title": "Think-Aloud Verbalizations for Identifying User Experience Problems:  Effects of Language Proficiency with Chinese Non-Native English Speakers",
    "abstract": "Subtle patterns in users' think-aloud (TA) verbalizations (i.e., utterances)\nare shown to be telltale signs of user experience (UX) problems and used to\nbuild artificial intelligence (AI) models or AI-assisted tools to help UX\nevaluators identify UX problems automatically or semi-automatically. Despite\nthe potential of such verbalization patterns, they were uncovered with native\nEnglish speakers. As most people who speak English are non-native speakers, it\nis important to investigate whether similar patterns exist in non-native\nEnglish speakers' TA verbalizations. As a first step to answer this question,\nwe conducted think-aloud usability testing with Chinese non-native English\nspeakers and native English speakers using three common TA protocols. We\ncompared their verbalizations and UX problems that they encountered to\nunderstand the effects of language and TA protocols. Our findings show that\nboth language groups had similar amounts and proportions of verbalization\ncategories, encountered similar problems, and had similar verbalization\npatterns that indicate UX problems. Furthermore, TA protocols did not\nsignificantly affect the correlations between verbalizations and problems.\nBased on the findings, we present three design implications for UX\npractitioners and the design of AI-assisted analysis tools.",
    "descriptor": "\nComments: The Ninth International Symposium of Chinese CHI (Chinese CHI 2021), October 16--17, 2021, Online, Hong Kong\n",
    "authors": [
      "Mingming Fan",
      "Lingyun Zhu"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2202.02970"
  },
  {
    "id": "arXiv:2202.02971",
    "title": "Locally Differentially Private Distributed Deep Learning via Knowledge  Distillation",
    "abstract": "Deep learning often requires a large amount of data. In real-world\napplications, e.g., healthcare applications, the data collected by a single\norganization (e.g., hospital) is often limited, and the majority of massive and\ndiverse data is often segregated across multiple organizations. As such, it\nmotivates the researchers to conduct distributed deep learning, where the data\nuser would like to build DL models using the data segregated across multiple\ndifferent data owners. However, this could lead to severe privacy concerns due\nto the sensitive nature of the data, thus the data owners would be hesitant and\nreluctant to participate. We propose LDP-DL, a privacy-preserving distributed\ndeep learning framework via local differential privacy and knowledge\ndistillation, where each data owner learns a teacher model using its own\n(local) private dataset, and the data user learns a student model to mimic the\noutput of the ensemble of the teacher models. In the experimental evaluation, a\ncomprehensive comparison has been made among our proposed approach (i.e.,\nLDP-DL), DP-SGD, PATE and DP-FL, using three popular deep learning benchmark\ndatasets (i.e., CIFAR10, MNIST and FashionMNIST). The experimental results show\nthat LDP-DL consistently outperforms the other competitors in terms of privacy\nbudget and model accuracy.",
    "descriptor": "\nComments: 10 pages, 6 figures, 1 table. Submitted to IEEE Transactions on Knowledge and Data Engineering\n",
    "authors": [
      "Di Zhuang",
      "Mingchen Li",
      "J. Morris Chang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.02971"
  },
  {
    "id": "arXiv:2202.02973",
    "title": "Empirical Analysis and Offering of Various Historical Spot Instance  Datasets",
    "abstract": "Public cloud service vendors provide a surplus of computing resources at a\ncheaper price as a spot instance. The first spot instance provider, Amazon Web\nServices(AWS), releases the history of spot price changes so that users can\nestimate the availability of spot instances, and it triggered lots of research\nwork in literature. However, a change in spot pricing policy in 2017 rendered a\nlarge portion of spot instance availability analysis work obsolete. Instead,\nAWS publishes new spot instance datasets, the spot placement score, and the\ninterruption frequency for the previous month, but the new datasets received\nfar less attention than the spot price history dataset. Furthermore, the\ndatasets only provide the current dataset without historical information, and\nthere are few restrictions when querying the dataset. In addition, the various\nspot datasets can provide contradicting information about spot instance\navailability of the same entity at the same time quite often. In this work, we\ndevelop a web-based spot instance data-archive service that provides historical\ninformation of various spot instance datasets. We describe heuristics how we\novercame limitations imposed when querying multiple spot instance datasets. We\nconducted a real-world evaluation measuring spot instance fulfillment and\ninterruption events to identify a credible spot instance dataset, especially\nwhen different datasets represent contradictory information. Based on the\nfindings of the empirical analysis, we propose SpotScore, a new spot instance\nmetric that provides a spot recommendation score based on the composition of\nspot price savings, spot placement score, and interruption frequency. The\ndata-archive service with the SpotScore is now publicly available as a web\nservice to speed up system research in the spot instance community and to\nimprove spot instance usage with a higher level of availability and cost\nsavings.",
    "descriptor": "\nComments: 13 pages, 11 figures\n",
    "authors": [
      "Sungjae Lee",
      "Kyungyong Lee"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2202.02973"
  },
  {
    "id": "arXiv:2202.02974",
    "title": "What Makes a Good Commit Message?",
    "abstract": "A key issue in collaborative software development is communication among\ndevelopers. One modality of communication is a commit message, in which\ndevelopers describe the changes they make in a repository. As such, commit\nmessages serve as an \"audit trail\" by which developers can understand how the\nsource code of a project has changed-and why. Hence, the quality of commit\nmessages affects the effectiveness of communication among developers. Commit\nmessages are often of poor quality as developers lack time and motivation to\ncraft a good message. Several automatic approaches have been proposed to\ngenerate commit messages. However, these are based on uncurated datasets\nincluding considerable proportions of poorly phrased commit messages. In this\nmulti-method study, we first define what constitutes a \"good\" commit message,\nand then establish what proportion of commit messages lack information using a\nsample of almost 1,600 messages from five highly active open source projects.\nWe find that an average of circa 44% of messages could be improved, suggesting\nthe use of uncurated datasets may be a major threat when commit message\ngenerators are trained with such data. We also observe that prior work has not\nconsidered semantics of commit messages, and there is surprisingly little\nguidance available for writing good commit messages. To that end, we develop a\ntaxonomy based on recurring patterns in commit messages' expressions. Finally,\nwe investigate whether \"good\" commit messages can be automatically identified;\nsuch automation could prompt developers to write better commit messages.",
    "descriptor": "",
    "authors": [
      "Yingchen Tian",
      "Yuxia Zhang",
      "Klaas-Jan Stol",
      "Lin Jiang",
      "Hui Liu"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2202.02974"
  },
  {
    "id": "arXiv:2202.02975",
    "title": "Competitive Online Optimization with Multiple Inventories: A  Divide-and-Conquer Approach",
    "abstract": "We study a competitive online optimization problem with multiple inventories.\nIn the problem, an online decision maker seeks to optimize the allocation of\nmultiple capacity-limited inventories over a slotted horizon, while the\nallocation constraints and revenue function come online at each slot. The\nproblem is challenging as we need to allocate limited inventories under\nadversarial revenue functions and allocation constraints, while our decisions\nare coupled among multiple inventories and different slots. We propose a\ndivide-and-conquer approach that allows us to decompose the problem into\nseveral single inventory problems and solve it in a two-step manner with almost\nno optimality loss in terms of competitive ratio (CR). Our approach provides\nnew angles, insights and results to the problem, which differs from the\nwidely-adopted primal-and-dual framework. Specifically, when the gradients of\nthe revenue functions are bounded in a positive range, we show that our\napproach can achieve a tight CR that is optimal when the number of inventories\nis small, which is better than all existing ones. For an arbitrary number of\ninventories, the CR we achieve is within an additive constant of one to a lower\nbound of the best possible CR among all online algorithms for the problem. We\nfurther characterize a general condition for generalizing our approach to\ndifferent applications. For example, for a generalized one-way trading problem\nwith price elasticity, where no previous results are available, our approach\nobtains an online algorithm that achieves the optimal CR up to a constant\nfactor.",
    "descriptor": "",
    "authors": [
      "Qiulin Lin",
      "Yanfang Mo",
      "Junyan Su",
      "Minghua Chen"
    ],
    "subjectives": [
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2202.02975"
  },
  {
    "id": "arXiv:2202.02976",
    "title": "Measuring and Reducing Model Update Regression in Structured Prediction  for NLP",
    "abstract": "Recent advance in deep learning has led to rapid adoption of machine learning\nbased NLP models in a wide range of applications. Despite the continuous gain\nin accuracy, backward compatibility is also an important aspect for industrial\napplications, yet it received little research attention. Backward compatibility\nrequires that the new model does not regress on cases that were correctly\nhandled by its predecessor. This work studies model update regression in\nstructured prediction tasks. We choose syntactic dependency parsing and\nconversational semantic parsing as representative examples of structured\nprediction tasks in NLP. First, we measure and analyze model update regression\nin different model update settings. Next, we explore and benchmark existing\ntechniques for reducing model update regression including model ensemble and\nknowledge distillation. We further propose a simple and effective method,\nBackward-Congruent Re-ranking (BCR), by taking into account the characteristics\nof structured output. Experiments show that BCR can better mitigate model\nupdate regression than model ensemble and knowledge distillation approaches.",
    "descriptor": "",
    "authors": [
      "Deng Cai",
      "Elman Mansimov",
      "Yi-An Lai",
      "Yixuan Su",
      "Lei Shu",
      "Yi Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.02976"
  },
  {
    "id": "arXiv:2202.02980",
    "title": "3D Object Detection from Images for Autonomous Driving: A Survey",
    "abstract": "3D object detection from images, one of the fundamental and challenging\nproblems in autonomous driving, has received increasing attention from both\nindustry and academia in recent years. Benefiting from the rapid development of\ndeep learning technologies, image-based 3D detection has achieved remarkable\nprogress. Particularly, more than 200 works have studied this problem from 2015\nto 2021, encompassing a broad spectrum of theories, algorithms, and\napplications. However, to date no recent survey exists to collect and organize\nthis knowledge. In this paper, we fill this gap in the literature and provide\nthe first comprehensive survey of this novel and continuously growing research\nfield, summarizing the most commonly used pipelines for image-based 3D\ndetection and deeply analyzing each of their components. Additionally, we also\npropose two new taxonomies to organize the state-of-the-art methods into\ndifferent categories, with the intent of providing a more systematic review of\nexisting methods and facilitating fair comparisons with future works. In\nretrospect of what has been achieved so far, we also analyze the current\nchallenges in the field and discuss future directions for image-based 3D\ndetection research.",
    "descriptor": "",
    "authors": [
      "Xinzhu Ma",
      "Wanli Ouyang",
      "Andrea Simonelli",
      "Elisa Ricci"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.02980"
  },
  {
    "id": "arXiv:2202.02981",
    "title": "Neural Tangent Kernel Analysis of Deep Narrow Neural Networks",
    "abstract": "The tremendous recent progress in analyzing the training dynamics of\noverparameterized neural networks has primarily focused on wide networks and\ntherefore does not sufficiently address the role of depth in deep learning. In\nthis work, we present the first trainability guarantee of infinitely deep but\nnarrow neural networks. We study the infinite-depth limit of a multilayer\nperceptron (MLP) with a specific initialization and establish a trainability\nguarantee using the NTK theory. We then extend the analysis to an infinitely\ndeep convolutional neural network (CNN) and perform brief experiments",
    "descriptor": "",
    "authors": [
      "Jongmin Lee",
      "Joo Young Choi",
      "Ernest K. Ryu",
      "Albert No"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.02981"
  },
  {
    "id": "arXiv:2202.02987",
    "title": "One to Rule them All? A First Look at DNS over QUIC",
    "abstract": "The DNS is one of the most crucial parts of the Internet. Since the original\nDNS specifications defined UDP and TCP as the underlying transport protocols,\nDNS queries are inherently unencrypted, making them vulnerable to eavesdropping\nand on-path manipulations. Consequently, concerns about DNS privacy have gained\nattention in recent years, which resulted in the introduction of the encrypted\nprotocols DNS over TLS (DoT) and DNS over HTTPS (DoH). Although these protocols\naddress the key issues of adding privacy to the DNS, they are inherently\nrestrained by their underlying transport protocols, which are at strife with,\ne.g., IP fragmentation or multi-RTT handshakes - challenges which are addressed\nby QUIC. As such, the recent addition of DNS over QUIC (DoQ) promises to\nimprove upon the established DNS protocols. However, no studies focusing on\nDoQ, its adoption, or its response times exist to this date - a gap we close\nwith our study. Our active measurements show a slowly but steadily increasing\nadoption of DoQ and reveal a high week-over-week fluctuation, which reflects\nthe ongoing development process: As DoQ is still in standardization,\nimplementations and services undergo rapid changes. Analyzing the response\ntimes of DoQ, we find that roughly 40% of measurements show considerably higher\nhandshake times than expected, which traces back to the enforcement of the\ntraffic amplification limit despite successful validation of the client's\naddress. However, DoQ already outperforms DoT as well as DoH, which makes it\nthe best choice for encrypted DNS to date.",
    "descriptor": "\nComments: To be published at PAM 2022\n",
    "authors": [
      "Mike Kosek",
      "Trinh Viet Doan",
      "Malte Granderath",
      "Vaibhav Bajpai"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2202.02987"
  },
  {
    "id": "arXiv:2202.02989",
    "title": "Graph Self-supervised Learning with Accurate Discrepancy Learning",
    "abstract": "Self-supervised learning of graph neural networks (GNNs) aims to learn an\naccurate representation of the graphs in an unsupervised manner, to obtain\ntransferable representations of them for diverse downstream tasks. Predictive\nlearning and contrastive learning are the two most prevalent approaches for\ngraph self-supervised learning. However, they have their own drawbacks. While\nthe predictive learning methods can learn the contextual relationships between\nneighboring nodes and edges, they cannot learn global graph-level similarities.\nContrastive learning, while it can learn global graph-level similarities, its\nobjective to maximize the similarity between two differently perturbed graphs\nmay result in representations that cannot discriminate two similar graphs with\ndifferent properties. To tackle such limitations, we propose a framework that\naims to learn the exact discrepancy between the original and the perturbed\ngraphs, coined as Discrepancy-based Self-supervised LeArning (D-SLA).\nSpecifically, we create multiple perturbations of the given graph with varying\ndegrees of similarity and train the model to predict whether each graph is the\noriginal graph or a perturbed one. Moreover, we further aim to accurately\ncapture the amount of discrepancy for each perturbed graph using the graph edit\ndistance. We validate our method on various graph-related downstream tasks,\nincluding molecular property prediction, protein function prediction, and link\nprediction tasks, on which our model largely outperforms relevant baselines.",
    "descriptor": "\nComments: 8 pages\n",
    "authors": [
      "Dongki Kim",
      "Jinheon Baek",
      "Sung Ju Hwang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.02989"
  },
  {
    "id": "arXiv:2202.02990",
    "title": "Comparison and Combination of Sentence Embeddings Derived from Different  Supervision Signals",
    "abstract": "We have recently seen many successful applications of sentence embedding\nmethods. It has not been well understood, however, what kind of properties are\ncaptured in the resulting sentence embeddings, depending on the supervision\nsignals. In this paper, we focus on two types of sentence embeddings obtained\nby using natural language inference (NLI) datasets and definition sentences\nfrom a word dictionary and investigate their properties by comparing their\nperformance with the semantic textual similarity (STS) task using the STS data\npartitioned by two perspectives: 1) the sources of sentences, and 2) the\nsuperficial similarity of the sentence pairs, and their performance on the\ndownstream and probing tasks. We also demonstrate that combining the two types\nof embeddings yields substantially better performances than respective models\non unsupervised STS tasks and downstream tasks.",
    "descriptor": "",
    "authors": [
      "Hayato Tsukagoshi",
      "Ryohei Sasano",
      "Koichi Takeda"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.02990"
  },
  {
    "id": "arXiv:2202.02998",
    "title": "Automatic defect segmentation by unsupervised anomaly learning",
    "abstract": "This paper addresses the problem of defect segmentation in semiconductor\nmanufacturing. The input of our segmentation is a scanning-electron-microscopy\n(SEM) image of the candidate defect region. We train a U-net shape network to\nsegment defects using a dataset of clean background images. The samples of the\ntraining phase are produced automatically such that no manual labeling is\nrequired. To enrich the dataset of clean background samples, we apply defect\nimplant augmentation. To that end, we apply a copy-and-paste of a random image\npatch in the clean specimen. To improve robustness to the unlabeled data\nscenario, we train the features of the network with unsupervised learning\nmethods and loss functions. Our experiments show that we succeed to segment\nreal defects with high quality, even though our dataset contains no defect\nexamples. Our approach performs accurately also on the problem of supervised\nand labeled defect segmentation.",
    "descriptor": "",
    "authors": [
      "Nati Ofir",
      "Ran Yacobi",
      "Omer Granoviter",
      "Boris Levant",
      "Ore Shtalrid"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.02998"
  },
  {
    "id": "arXiv:2202.03002",
    "title": "Partial Encryption after Encoding for Security and Reliability in Data  Systems",
    "abstract": "We consider the problem of secure and reliable communication over a noisy\nmultipath network. Previous work considering a noiseless version of our problem\nproposed a hybrid universal network coding cryptosystem (HUNCC). By combining\nan information-theoretically secure encoder together with partial encryption,\nHUNCC is able to obtain security guarantees, even in the presence of an\nall-observing eavesdropper. In this paper, we propose a version of HUNCC for\nnoisy channels (N-HUNCC). This modification requires four main novelties.\nFirst, we present a network coding construction which is jointly, individually\nsecure and error-correcting. Second, we introduce a new security definition\nwhich is a computational analogue of individual security, which we call\nindividual indistinguishability under chosen ciphertext attack (individual\nIND-CCA1), and show that NHUNCC satisfies it. Third, we present a noise based\ndecoder for N-HUNCC, which permits the decoding of the encoded-thenencrypted\ndata. Finally, we discuss how to select parameters for N-HUNCC and its\nerror-correcting capabilities.",
    "descriptor": "",
    "authors": [
      "Alejandro Cohen",
      "Rafael G. L. D'Oliveira",
      "Ken R. Duffy",
      "Muriel M\u00e9dard"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.03002"
  },
  {
    "id": "arXiv:2202.03004",
    "title": "Network Calculus with Flow Prolongation -- A Feedforward FIFO Analysis  enabled by ML",
    "abstract": "The derivation of upper bounds on data flows' worst-case traversal times is\nan important task in many application areas. For accurate bounds, model\nsimplifications should be avoided even in large networks. Network Calculus (NC)\nprovides a modeling framework and different analyses for delay bounding. We\ninvestigate the analysis of feedforward networks where all queues implement\nFirst-In First-Out (FIFO) service. Correctly considering the effect of data\nflows onto each other under FIFO is already a challenging task. Yet, the\nfastest available NC FIFO analysis suffers from limitations resulting in\nunnecessarily loose bounds. A feature called Flow Prolongation (FP) has been\nshown to improve delay bound accuracy significantly. Unfortunately, FP needs to\nbe executed within the NC FIFO analysis very often and each time it creates an\nexponentially growing set of alternative networks with prolongations. FP\ntherefore does not scale and has been out of reach for the exhaustive analysis\nof large networks. We introduce DeepFP, an approach to make FP scale by\npredicting prolongations using machine learning. In our evaluation, we show\nthat DeepFP can improve results in FIFO networks considerably. Compared to the\nstandard NC FIFO analysis, DeepFP reduces delay bounds by 12.1% on average at\nnegligible additional computational cost.",
    "descriptor": "",
    "authors": [
      "Fabien Geyer",
      "Alexander Scheffler",
      "Steffen Bondorf"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.03004"
  },
  {
    "id": "arXiv:2202.03005",
    "title": "B2EA: An Evolutionary Algorithm Assisted by Two Bayesian Optimization  Modules for Neural Architecture Search",
    "abstract": "The early pioneering Neural Architecture Search (NAS) works were multi-trial\nmethods applicable to any general search space. The subsequent works took\nadvantage of the early findings and developed weight-sharing methods that\nassume a structured search space typically with pre-fixed hyperparameters.\nDespite the amazing computational efficiency of the weight-sharing NAS\nalgorithms, it is becoming apparent that multi-trial NAS algorithms are also\nneeded for identifying very high-performance architectures, especially when\nexploring a general search space. In this work, we carefully review the latest\nmulti-trial NAS algorithms and identify the key strategies including\nEvolutionary Algorithm (EA), Bayesian Optimization (BO), diversification, input\nand output transformations, and lower fidelity estimation. To accommodate the\nkey strategies into a single framework, we develop B\\textsuperscript{2}EA that\nis a surrogate assisted EA with two BO surrogate models and a mutation step in\nbetween. To show that B\\textsuperscript{2}EA is robust and efficient, we\nevaluate three performance metrics over 14 benchmarks with general and\ncell-based search spaces. Comparisons with state-of-the-art multi-trial\nalgorithms reveal that B\\textsuperscript{2}EA is robust and efficient over the\n14 benchmarks for three difficulty levels of target performance. The\nB\\textsuperscript{2}EA code is publicly available at\n\\url{https://github.com/snu-adsl/BBEA}.",
    "descriptor": "\nComments: 23 pages, submitted to ICML22\n",
    "authors": [
      "Hyunghun Cho",
      "Jungwook Shin",
      "Wonjong Rhee"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.03005"
  },
  {
    "id": "arXiv:2202.03007",
    "title": "Learning Sound Localization Better From Semantically Similar Samples",
    "abstract": "The objective of this work is to localize the sound sources in visual scenes.\nExisting audio-visual works employ contrastive learning by assigning\ncorresponding audio-visual pairs from the same source as positives while\nrandomly mismatched pairs as negatives. However, these negative pairs may\ncontain semantically matched audio-visual information. Thus, these semantically\ncorrelated pairs, \"hard positives\", are mistakenly grouped as negatives. Our\nkey contribution is showing that hard positives can give similar response maps\nto the corresponding pairs. Our approach incorporates these hard positives by\nadding their response maps into a contrastive learning objective directly. We\ndemonstrate the effectiveness of our approach on VGG-SS and SoundNet-Flickr\ntest sets, showing favorable performance to the state-of-the-art methods.",
    "descriptor": "\nComments: Accepted to ICASSP 2022. SOTA performance in Audio-Visual Sound Localization. 5 Pages\n",
    "authors": [
      "Arda Senocak",
      "Hyeonggon Ryu",
      "Junsik Kim",
      "In So Kweon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2202.03007"
  },
  {
    "id": "arXiv:2202.03009",
    "title": "Encoding and Decoding of Several Optimal Rank Metric Codes",
    "abstract": "This paper presents encoding and decoding algorithms for several families of\noptimal rank metric codes whose codes are in restricted forms of symmetric,\nalternating and Hermitian matrices. First, we show the evaluation encoding is\nthe right choice for these codes and then we provide easily reversible encoding\nmethods for each family. Later unique decoding algorithms for the codes are\ndescribed. The decoding algorithms are interpolation-based and can uniquely\ncorrect errors for each code with rank up to $\\lfloor(d-1)/2\\rfloor$ in\npolynomial-time, where $d$ is the minimum distance of the code.",
    "descriptor": "",
    "authors": [
      "Wrya K. Kadir",
      "Chunlei Li",
      "Ferdinando Zullo"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.03009"
  },
  {
    "id": "arXiv:2202.03012",
    "title": "EDCHO: High Order Exact Dynamic Consensus",
    "abstract": "This article addresses the problem of average consensus in a multi-agent\nsystem when the desired consensus quantity is a time varying signal. Although\nthis problem has been addressed in existing literature by linear schemes, only\nbounded steady-state errors have been achieved. Other approaches have used\nfirst order sliding modes to achieve zero steady-state error, but suffer from\nthe chattering effect. In this work, we propose a new exact dynamic consensus\nalgorithm which leverages high order sliding modes, in the form of a\ndistributed differentiator to achieve zero steady-state error of the average of\ntime varying reference signals in a group of agents. Moreover, our proposal is\nalso able to achieve consensus to high order derivatives of the average signal,\nif desired. An in depth formal study on the stability and convergence for EDCHO\nis provided for undirected connected graphs. Finally, the effectiveness and\nadvantages of our proposal are shown with concrete simulation scenarios.",
    "descriptor": "\nComments: This is the preprint version of the accepted Manuscript: Rodrigo Aldana-Lopez, Rosario Aragues, Carlos Sagues, EDCHO: High order exact dynamic consensus, Automatica, Volume 131, 2021, ISSN 0005-1098. Please cite the publisher's version\n",
    "authors": [
      "Rodrigo Aldana-L\u00f3pez",
      "Rosario Arag\u00fc\u00e9s",
      "Carlos Sag\u00fc\u00e9s"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Multiagent Systems (cs.MA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2202.03012"
  },
  {
    "id": "arXiv:2202.03013",
    "title": "$\u03bc$AFL: Non-intrusive Feedback-driven Fuzzing for Microcontroller  Firmware",
    "abstract": "Fuzzing is one of the most effective approaches to finding software flaws.\nHowever, applying it to microcontroller firmware incurs many challenges. For\nexample, rehosting-based solutions cannot accurately model peripheral behaviors\nand thus cannot be used to fuzz the corresponding driver code. In this work, we\npresent $\\mu$AFL, a hardware-in-the-loop approach to fuzzing microcontroller\nfirmware. It leverages debugging tools in existing embedded system development\nto construct an AFL-compatible fuzzing framework. Specifically, we use the\ndebug dongle to bridge the fuzzing environment on the PC and the target\nfirmware on the microcontroller device. To collect code coverage information\nwithout costly code instrumentation, $\\mu$AFL relies on the ARM ETM hardware\ndebugging feature, which transparently collects the instruction trace and\nstreams the results to the PC. However, the raw ETM data is obscure and needs\nenormous computing resources to recover the actual instruction flow. We\ntherefore propose an alternative representation of code coverage, which retains\nthe same path sensitivity as the original AFL algorithm, but can directly work\non the raw ETM data without matching them with disassembled instructions. To\nfurther reduce the workload, we use the DWT hardware feature to selectively\ncollect runtime information of interest. We evaluated $\\mu$AFL on two real\nevaluation boards from two major vendors: NXP and STMicroelectronics. With our\nprototype, we discovered ten zero-day bugs in the driver code shipped with the\nSDK of STMicroelectronics and three zero-day bugs in the SDK of NXP. Eight CVEs\nhave been allocated for them. Considering the wide adoption of vendor SDKs in\nreal products, our results are alarming.",
    "descriptor": "\nComments: 44th International Conference on Software Engineering (ICSE 2022)\n",
    "authors": [
      "Wenqiang Li",
      "Jiameng Shi",
      "Fengjun Li",
      "Jingqiang Lin",
      "Wei Wang",
      "Le Guan"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2202.03013"
  },
  {
    "id": "arXiv:2202.03018",
    "title": "Broadcast Approach Meets Network Coding for Data Streaming",
    "abstract": "For data streaming applications, existing solutions are not yet able to close\nthe gap between high data rates and low delay. This work considers the problem\nof data streaming under mixed delay constraints over a single communication\nchannel with delayed feedback. We propose a novel layered adaptive causal\nrandom linear network coding (LAC-RLNC) approach with forward error correction.\nLAC-RLNC is a variable-to-variable coding scheme, i.e., variable recovered\ninformation data at the receiver over variable short block length and rate is\nproposed. Specifically, for data streaming with base and enhancement layers of\ncontent, we characterize a high dimensional throughput-delay trade-off managed\nby the adaptive causal layering coding scheme. The base layer is designed to\nsatisfy the strict delay constraints, as it contains the data needed to allow\nthe streaming service. Then, the sender can manage the throughput-delay\ntrade-off of the second layer by adjusting the retransmission rate a priori and\nposterior as the enhancement layer, that contains the remaining data to augment\nthe streaming service's quality, is with the relax delay constraints. We\nnumerically show that the layered network coding approach can dramatically\nincrease performance. We demonstrate that LAC-RLNC compared with the\nnon-layered approach gains a factor of three in mean and maximum delay for the\nbase layer, close to the lower bound, and factor two for the enhancement layer.",
    "descriptor": "",
    "authors": [
      "Alejandro Cohen",
      "Muriel M\u00e9dard",
      "Shlomo Shamai"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.03018"
  },
  {
    "id": "arXiv:2202.03023",
    "title": "CECILIA: Comprehensive Secure Machine Learning Framework",
    "abstract": "Since machine learning algorithms have proven their success in data mining\ntasks, the data with sensitive information enforce privacy preserving machine\nlearning algorithms to emerge. Moreover, the increase in the number of data\nsources and the high computational power required by those algorithms force\nindividuals to outsource the training and/or the inference of a machine\nlearning model to the clouds providing such services. To address this dilemma,\nwe propose a secure 3-party computation framework, CECILIA, offering privacy\npreserving building blocks to enable more complex operations privately. Among\nthose building blocks, we have two novel methods, which are the exact\nexponential of a public base raised to the power of a secret value and the\ninverse square root of a secret Gram matrix. We employ CECILIA to realize the\nprivate inference on pre-trained recurrent kernel networks, which require more\ncomplex operations than other deep neural networks such as convolutional neural\nnetworks, on the structural classification of proteins as the first study ever\naccomplishing the privacy preserving inference on recurrent kernel networks.\nThe results demonstrate that we perform the exact and fully private exponential\ncomputation, which is done by approximation in the literature so far. Moreover,\nwe can also perform the exact inverse square root of a secret Gram matrix\ncomputation up to a certain privacy level, which has not been addressed in the\nliterature at all. We also analyze the scalability of CECILIA to various\nsettings on a synthetic dataset. The framework shows a great promise to make\nother machine learning algorithms as well as further computations privately\ncomputable by the building blocks of the framework.",
    "descriptor": "\nComments: ~8 pages of the main paper, ~1 of Supplement, submitted to ICML 2022\n",
    "authors": [
      "Ali Burak \u00dcnal",
      "Mete Akg\u00fcn",
      "Nico Pfeifer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.03023"
  },
  {
    "id": "arXiv:2202.03024",
    "title": "The Input and Output Entropies of the $k$-Deletion/Insertion Channel",
    "abstract": "The channel output entropy of a transmitted word is the entropy of the\npossible channel outputs and similarly the input entropy of a received word is\nthe entropy of all possible transmitted words. The goal of this work is to\nstudy these entropy values for the $k$-deletion, $k$-insertion channel, where\nexactly $k$ symbols are deleted, inserted in the transmitted word,\nrespectively. If all possible words are transmitted with the same probability\nthen studying the input and output entropies is equivalent. For both the\n1-insertion and 1-deletion channels, it is proved that among all words with a\nfixed number of runs, the input entropy is minimized for words with a skewed\ndistribution of their run lengths and it is maximized for words with a balanced\ndistribution of their run lengths. Among our results, we establish a conjecture\nby Atashpendar et al. which claims that for the binary 1-deletion channel, the\ninput entropy is maximized for the alternating words.",
    "descriptor": "",
    "authors": [
      "Shubhransh Singhvi",
      "Omer Sabary",
      "Daniella Bar-Lev",
      "Eitan Yaakobi"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.03024"
  },
  {
    "id": "arXiv:2202.03026",
    "title": "Context Autoencoder for Self-Supervised Representation Learning",
    "abstract": "We present a novel masked image modeling (MIM) approach, context autoencoder\n(CAE), for self-supervised learning. We randomly partition the image into two\nsets: visible patches and masked patches. The CAE architecture consists of: (i)\nan encoder that takes visible patches as input and outputs their latent\nrepresentations, (ii) a latent context regressor that predicts the masked patch\nrepresentations from the visible patch representations that are not updated in\nthis regressor, (iii) a decoder that takes the estimated masked patch\nrepresentations as input and makes predictions for the masked patches, and (iv)\nan alignment module that aligns the masked patch representation estimation with\nthe masked patch representations computed from the encoder.\nIn comparison to previous MIM methods that couple the encoding and decoding\nroles, e.g., using a single module in BEiT, our approach attempts\nto~\\emph{separate the encoding role (content understanding) from the decoding\nrole (making predictions for masked patches)} using different modules,\nimproving the content understanding capability. In addition, our approach makes\npredictions from the visible patches to the masked patches in \\emph{the latent\nrepresentation space} that is expected to take on semantics. In addition, we\npresent the explanations about why contrastive pretraining and supervised\npretraining perform similarly and why MIM potentially performs better. We\ndemonstrate the effectiveness of our CAE through superior transfer performance\nin downstream tasks: semantic segmentation, and object detection and instance\nsegmentation.",
    "descriptor": "",
    "authors": [
      "Xiaokang Chen",
      "Mingyu Ding",
      "Xiaodi Wang",
      "Ying Xin",
      "Shentong Mo",
      "Yunhao Wang",
      "Shumin Han",
      "Ping Luo",
      "Gang Zeng",
      "Jingdong Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.03026"
  },
  {
    "id": "arXiv:2202.03032",
    "title": "Coded Caching Does Not Generally Benefit From Selfish Caching",
    "abstract": "In typical coded caching scenarios, the content of a central library is\nassumed to be of interest to all receiving users. However, in a realistic\nscenario the users may have diverging interests which may intersect to various\ndegrees. What happens for example if each file is of potential interest to,\nsay, $40\\,\\%$ of the users and each user has potential interest in $40\\,\\%$ of\nthe library? What if then each user caches selfishly only from content of\npotential interest? In this work, we formulate the symmetric selfish coded\ncaching problem, where each user naturally makes requests from a subset of the\nlibrary, which defines its own file demand set (FDS), and caches selfishly only\ncontents from its own FDS. For the scenario where the different FDSs\nsymmetrically overlap to some extent, we propose a novel information-theoretic\nconverse that reveals, for such general setting of symmetric FDS structures,\nthat selfish coded caching yields a load performance which is strictly worse\nthan that in standard coded caching.",
    "descriptor": "\nComments: 6 pages. Submitted to 2022 IEEE International Symposium on Information Theory (ISIT). arXiv admin note: substantial text overlap with arXiv:2109.04807\n",
    "authors": [
      "Federico Brunero",
      "Petros Elia"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.03032"
  },
  {
    "id": "arXiv:2202.03033",
    "title": "Mental Stress Detection using Data from Wearable and Non-wearable  Sensors: A Review",
    "abstract": "This paper presents a comprehensive review of methods covering significant\nsubjective and objective human stress detection techniques available in the\nliterature. The methods for measuring human stress responses could include\nsubjective questionnaires (developed by psychologists) and objective markers\nobserved using data from wearable and non-wearable sensors. In particular,\nwearable sensor-based methods commonly use data from electroencephalography,\nelectrocardiogram, galvanic skin response, electromyography, electrodermal\nactivity, heart rate, heart rate variability, and photoplethysmography both\nindividually and in multimodal fusion strategies. Whereas, methods based on\nnon-wearable sensors include strategies such as analyzing pupil dilation and\nspeech, smartphone data, eye movement, body posture, and thermal imaging.\nWhenever a stressful situation is encountered by an individual, physiological,\nphysical, or behavioral changes are induced which help in coping with the\nchallenge at hand. A wide range of studies has attempted to establish a\nrelationship between these stressful situations and the response of human\nbeings by using different kinds of psychological, physiological, physical, and\nbehavioral measures. Inspired by the lack of availability of a definitive\nverdict about the relationship of human stress with these different kinds of\nmarkers, a detailed survey about human stress detection methods is conducted in\nthis paper. In particular, we explore how stress detection methods can benefit\nfrom artificial intelligence utilizing relevant data from various sources. This\nreview will prove to be a reference document that would provide guidelines for\nfuture research enabling effective detection of human stress conditions.",
    "descriptor": "\nComments: Under Review in Artificial Intelligence Review\n",
    "authors": [
      "Aamir Arsalan",
      "Syed Muhammad Anwar",
      "Muhammad Majid"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.03033"
  },
  {
    "id": "arXiv:2202.03038",
    "title": "Deep Networks on Toroids: Removing Symmetries Reveals the Structure of  Flat Regions in the Landscape Geometry",
    "abstract": "We systematize the approach to the investigation of deep neural network\nlandscapes by basing it on the geometry of the space of implemented functions\nrather than the space of parameters. Grouping classifiers into equivalence\nclasses, we develop a standardized parameterization in which all symmetries are\nremoved, resulting in a toroidal topology. On this space, we explore the error\nlandscape rather than the loss. This lets us derive a meaningful notion of the\nflatness of minimizers and of the geodesic paths connecting them. Using\ndifferent optimization algorithms that sample minimizers with different\nflatness we study the mode connectivity and other characteristics. Testing a\nvariety of state-of-the-art architectures and benchmark datasets, we confirm\nthe correlation between flatness and generalization performance; we further\nshow that in function space flatter minima are closer to each other and that\nthe barriers along the geodesics connecting them are small. We also find that\nminimizers found by variants of gradient descent can be connected by zero-error\npaths with a single bend. We observe similar qualitative results in neural\nnetworks with binary weights and activations, providing one of the first\nresults concerning the connectivity in this setting. Our results hinge on\nsymmetry removal, and are in remarkable agreement with the rich phenomenology\ndescribed by some recent analytical studies performed on simple shallow models.",
    "descriptor": "",
    "authors": [
      "Fabrizio Pittorino",
      "Antonio Ferraro",
      "Gabriele Perugini",
      "Christoph Feinauer",
      "Carlo Baldassi",
      "Riccardo Zecchina"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)"
    ],
    "url": "https://arxiv.org/abs/2202.03038"
  },
  {
    "id": "arXiv:2202.03039",
    "title": "The Exact Load-Memory Tradeoff of Multi-Access Coded Caching With  Combinatorial Topology",
    "abstract": "Recently, Muralidhar et al. proposed a novel multi-access system model where\neach user is connected to multiple caches in a manner that follows the\nwell-known combinatorial topology of combination networks. For such\nmulti-access topology, the same authors proposed an achievable scheme, which\nstands out for the unprecedented coding gains even with very modest cache\nresources. In this paper, we identify the fundamental limits of such\nmulti-access setting with exceptional potential, providing an\ninformation-theoretic converse which establishes, together with the inner bound\nby Muralidhar et al., the exact optimal performance under uncoded prefetching.",
    "descriptor": "\nComments: 5 pages, 1 figure. Submitted to 2022 IEEE International Symposium on Information Theory (ISIT). arXiv admin note: substantial text overlap with arXiv:2110.07426\n",
    "authors": [
      "Federico Brunero",
      "Petros Elia"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.03039"
  },
  {
    "id": "arXiv:2202.03040",
    "title": "Towards Learning Through Open-Domain Dialog",
    "abstract": "The development of artificial agents able to learn through dialog without\ndomain restrictions has the potential to allow machines to learn how to perform\ntasks in a similar manner to humans and change how we relate to them. However,\nresearch in this area is practically nonexistent. In this paper, we identify\nthe modifications required for a dialog system to be able to learn from the\ndialog and propose generic approaches that can be used to implement those\nmodifications. More specifically, we discuss how knowledge can be extracted\nfrom the dialog, used to update the agent's semantic network, and grounded in\naction and observation. This way, we hope to raise awareness for this subject,\nso that it can become a focus of research in the future.",
    "descriptor": "\nComments: 6 pages, 1 figure\n",
    "authors": [
      "Eug\u00e9nio Ribeiro",
      "Ricardo Ribeiro",
      "David Martins de Matos"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.03040"
  },
  {
    "id": "arXiv:2202.03045",
    "title": "Metric-valued regression",
    "abstract": "We propose an efficient algorithm for learning mappings between two metric\nspaces, $\\X$ and $\\Y$. Our procedure is strongly Bayes-consistent whenever $\\X$\nand $\\Y$ are topologically separable and $\\Y$ is \"bounded in expectation\" (our\nterm; the separability assumption can be somewhat weakened). At this level of\ngenerality, ours is the first such learnability result for unbounded loss in\nthe agnostic setting. Our technique is based on metric medoids (a variant of\nFr\\'echet means) and presents a significant departure from existing methods,\nwhich, as we demonstrate, fail to achieve Bayes-consistency on general\ninstance- and label-space metrics. Our proofs introduce the technique of {\\em\nsemi-stable compression}, which may be of independent interest.",
    "descriptor": "",
    "authors": [
      "Dan Tsir Cohen",
      "Aryeh Kontorovich"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.03045"
  },
  {
    "id": "arXiv:2202.03046",
    "title": "A new face swap method for image and video domains: a technical report",
    "abstract": "Deep fake technology became a hot field of research in the last few years.\nResearchers investigate sophisticated Generative Adversarial Networks (GAN),\nautoencoders, and other approaches to establish precise and robust algorithms\nfor face swapping. Achieved results show that the deep fake unsupervised\nsynthesis task has problems in terms of the visual quality of generated data.\nThese problems usually lead to high fake detection accuracy when an expert\nanalyzes them. The first problem is that existing image-to-image approaches do\nnot consider video domain specificity and frame-by-frame processing leads to\nface jittering and other clearly visible distortions. Another problem is the\ngenerated data resolution, which is low for many existing methods due to high\ncomputational complexity. The third problem appears when the source face has\nlarger proportions (like bigger cheeks), and after replacement it becomes\nvisible on the face border. Our main goal was to develop such an approach that\ncould solve these problems and outperform existing solutions on a number of\nclue metrics. We introduce a new face swap pipeline that is based on\nFaceShifter architecture and fixes the problems stated above. With a new eye\nloss function, super-resolution block, and Gaussian-based face mask generation\nleads to improvements in quality which is confirmed during evaluation.",
    "descriptor": "",
    "authors": [
      "Daniil Chesakov",
      "Anastasia Maltseva",
      "Alexander Groshev",
      "Andrey Kuznetsov",
      "Denis Dimitrov"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.03046"
  },
  {
    "id": "arXiv:2202.03047",
    "title": "Data set creation and empirical analysis for detecting signs of  depression from social media postings",
    "abstract": "Depression is a common mental illness that has to be detected and treated at\nan early stage to avoid serious consequences. There are many methods and\nmodalities for detecting depression that involves physical examination of the\nindividual. However, diagnosing mental health using their social media data is\nmore effective as it avoids such physical examinations. Also, people express\ntheir emotions well in social media, it is desirable to diagnose their mental\nhealth using social media data. Though there are many existing systems that\ndetects mental illness of a person by analysing their social media data,\ndetecting the level of depression is also important for further treatment.\nThus, in this research, we developed a gold standard data set that detects the\nlevels of depression as `not depressed', `moderately depressed' and `severely\ndepressed' from the social media postings. Traditional learning algorithms were\nemployed on this data set and an empirical analysis was presented in this\npaper. Data augmentation technique was applied to overcome the data imbalance.\nAmong the several variations that are implemented, the model with Word2Vec\nvectorizer and Random Forest classifier on augmented data outperforms the other\nvariations with a score of 0.877 for both accuracy and F1 measure.",
    "descriptor": "\nComments: 12 pages\n",
    "authors": [
      "Kayalvizhi S",
      "Thenmozhi D"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.03047"
  },
  {
    "id": "arXiv:2202.03051",
    "title": "Using Partial Monotonicity in Submodular Maximization",
    "abstract": "Over the last two decades, submodular function maximization has been the\nworkhorse of many discrete optimization problems in machine learning\napplications. Traditionally, the study of submodular functions was based on\nbinary function properties. However, such properties have an inherit weakness,\nnamely, if an algorithm assumes functions that have a particular property, then\nit provides no guarantee for functions that violate this property, even when\nthe violation is very slight. Therefore, recent works began to consider\ncontinuous versions of function properties. Probably the most significant among\nthese (so far) are the submodularity ratio and the curvature, which were\nstudied extensively together and separately.\nThe monotonicity property of set functions plays a central role in submodular\nmaximization. Nevertheless, and despite all the above works, no continuous\nversion of this property has been suggested to date (as far as we know). This\nis unfortunate since submoduar functions that are almost monotone often arise\nin machine learning applications. In this work we fill this gap by defining the\nmonotonicity ratio, which is a continues version of the monotonicity property.\nWe then show that for many standard submodular maximization algorithms one can\nprove new approximation guarantees that depend on the monotonicity ratio;\nleading to improved approximation ratios for the common machine learning\napplications of movie recommendation, quadratic programming and image\nsummarization.",
    "descriptor": "\nComments: 45 pages; 7 figures\n",
    "authors": [
      "Loay Mualem",
      "Moran Feldman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.03051"
  },
  {
    "id": "arXiv:2202.03052",
    "title": "Unifying Architectures, Tasks, and Modalities Through a Simple  Sequence-to-Sequence Learning Framework",
    "abstract": "In this work, we pursue a unified paradigm for multimodal pretraining to\nbreak the scaffolds of complex task/modality-specific customization. We propose\nOFA, a unified multimodal pretrained model that unifies modalities (i.e.,\ncross-modality, vision, language) and tasks (e.g., image generation, visual\ngrounding, image captioning, image classification, text generation, etc.) to a\nsimple sequence-to-sequence learning framework based on the encoder-decoder\narchitecture. OFA performs pretraining and finetuning with task instructions\nand introduces no extra task-specific layers for finetuning. Experimental\nresults show that OFA achieves new state-of-the-arts on a series of multimodal\ntasks, including image captioning (COCO test CIDEr: 149.6), text-to-image\ngeneration (COCO test FID: 10.5), VQA (test-std acc.: 80.02), SNLI-VE (test\nacc.: 90.20), and referring expression comprehension (RefCOCO / RefCOCO+ /\nRefCOCOg test acc.: 92.93 / 90.10 / 85.20). Through extensive analyses, we\ndemonstrate that OFA reaches comparable performance with uni-modal pretrained\nmodels (e.g., BERT, MAE, MoCo v3, SimCLR v2, etc.) in uni-modal tasks,\nincluding NLU, NLG, and image classification, and it effectively transfers to\nunseen tasks and domains. Code shall be released soon at\nthis http URL",
    "descriptor": "\nComments: 23 pages, 11 figures\n",
    "authors": [
      "Peng Wang",
      "An Yang",
      "Rui Men",
      "Junyang Lin",
      "Shuai Bai",
      "Zhikang Li",
      "Jianxin Ma",
      "Chang Zhou",
      "Jingren Zhou",
      "Hongxia Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.03052"
  },
  {
    "id": "arXiv:2202.03055",
    "title": "Enabling Automatic Repair of Source Code Vulnerabilities Using  Data-Driven Methods",
    "abstract": "Users around the world rely on software-intensive systems in their day-to-day\nactivities. These systems regularly contain bugs and security vulnerabilities.\nTo facilitate bug fixing, data-driven models of automatic program repair use\npairs of buggy and fixed code to learn transformations that fix errors in code.\nHowever, automatic repair of security vulnerabilities remains under-explored.\nIn this work, we propose ways to improve code representations for vulnerability\nrepair from three perspectives: input data type, data-driven models, and\ndownstream tasks. The expected results of this work are improved code\nrepresentations for automatic program repair and, specifically, fixing security\nvulnerabilities.",
    "descriptor": "\nComments: Accepted for the ICSE '22 Doctoral Symposium\n",
    "authors": [
      "Anastasiia Grishina"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.03055"
  },
  {
    "id": "arXiv:2202.03056",
    "title": "Control of cascading failures in dynamical models of power grids",
    "abstract": "In this paper, we introduce a distributed control strategy to prevent\ndynamically-induced cascading failures in power grids. We model power grids\nusing complex networks and nonlinear dynamics to provide a coarse-grained\ndescription of the electro-mechanical phenomena taking place on them (in\nparticular, we use coupled swing equations) and restrict our analysis to\ncascades of line failures, i.e., failures due to power flows exceeding the\nmaximum capacity of a line. We formulate a distributed control protocol relying\non the same topology of the physical layer and apply it to several power grid\nmodels, including a small-size illustrative example with five nodes, the\nItalian high-voltage (380kV) power grid, and the IEEE 118-bus system. Our\nresults indicate that the approach is capable of preventing cascading failures,\neither controlling each node of the network or a suitable subset of them.",
    "descriptor": "",
    "authors": [
      "Mattia Frasca",
      "Lucia Valentina Gambuzza"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.03056"
  },
  {
    "id": "arXiv:2202.03057",
    "title": "Multi-Objective Quality Diversity Optimization",
    "abstract": "In this work, we consider the problem of Quality-Diversity (QD) optimization\nwith multiple objectives. QD algorithms have been proposed to search for a\nlarge collection of both diverse and high-performing solutions instead of a\nsingle set of local optima. Thriving for diversity was shown to be useful in\nmany industrial and robotics applications. On the other hand, most real-life\nproblems exhibit several potentially antagonist objectives to be optimized.\nHence being able to optimize for multiple objectives with an appropriate\ntechnique while thriving for diversity is important to many fields. Here, we\npropose an extension of the MAP-Elites algorithm in the multi-objective\nsetting: Multi-Objective MAP-Elites (MOME). Namely, it combines the diversity\ninherited from the MAP-Elites grid algorithm with the strength of\nmulti-objective optimizations by filling each cell with a Pareto Front. As\nsuch, it allows to extract diverse solutions in the descriptor space while\nexploring different compromises between objectives. We evaluate our method on\nseveral tasks, from standard optimization problems to robotics simulations. Our\nexperimental evaluation shows the ability of MOME to provide diverse solutions\nwhile providing global performances similar to standard multi-objective\nalgorithms.",
    "descriptor": "",
    "authors": [
      "Thomas Pierrot",
      "Guillaume Richard",
      "Karim Beguir",
      "Antoine Cully"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.03057"
  },
  {
    "id": "arXiv:2202.03058",
    "title": "Non-traditional intervals and their use. Which ones really make sense?",
    "abstract": "The paper discusses the question of why intervals, which are the main object\nof Interval Analysis, have exactly the form that we know well and habitually\nuse, and not some other. In particular, we investigate why traditional\nintervals are closed, i.\\,e. contain their endpoints, and also what is wrong\nwith an empty interval. The second question considered in the work is how\nexpedient it is to expand the set of traditional intervals by some other\nobjects. We show that improper (\"reversed\") intervals and the arithmetic of\nsuch intervals (Kaucher complete interval arithmetic) are very useful from many\ndifferent points of view.",
    "descriptor": "\nComments: 15 pages, no figures\n",
    "authors": [
      "Sergey P. Shary"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.03058"
  },
  {
    "id": "arXiv:2202.03059",
    "title": "Evaluation of Runtime Monitoring for UAV Emergency Landing",
    "abstract": "To certify UAV operations in populated areas, risk mitigation strategies --\nsuch as Emergency Landing (EL) -- must be in place to account for potential\nfailures. EL aims at reducing ground risk by finding safe landing areas using\non-board sensors. The first contribution of this paper is to present a new EL\napproach, in line with safety requirements introduced in recent research. In\nparticular, the proposed EL pipeline includes mechanisms to monitor learning\nbased components during execution. This way, another contribution is to study\nthe behavior of Machine Learning Runtime Monitoring (MLRM) approaches within\nthe context of a real-world critical system. A new evaluation methodology is\nintroduced, and applied to assess the practical safety benefits of three MLRM\nmechanisms. The proposed approach is compared to a default mitigation strategy\n(open a parachute when a failure is detected), and appears to be much safer.",
    "descriptor": "\nComments: 7 pages, 4 figures, 1 table. To appear in the proceedings of 2022 IEEE International Conference on Robotics and Automation (ICRA)\n",
    "authors": [
      "Joris Guerin",
      "Kevin Delmas",
      "J\u00e9r\u00e9mie Guiochet"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.03059"
  },
  {
    "id": "arXiv:2202.03060",
    "title": "The Importance of Non-Markovianity in Maximum State Entropy Exploration",
    "abstract": "In the maximum state entropy exploration framework, an agent interacts with a\nreward-free environment to learn a policy that maximizes the entropy of the\nexpected state visitations it is inducing. Hazan et al. (2019) noted that the\nclass of Markovian stochastic policies is sufficient for the maximum state\nentropy objective, and exploiting non-Markovianity is generally considered\npointless in this setting. In this paper, we argue that non-Markovianity is\ninstead paramount for maximum state entropy exploration in a finite-sample\nregime. Especially, we recast the objective to target the expected entropy of\nthe induced state visitations in a single trial. Then, we show that the class\nof non-Markovian deterministic policies is sufficient for the introduced\nobjective, while Markovian policies suffer non-zero regret in general. However,\nwe prove that the problem of finding an optimal non-Markovian policy is at\nleast NP-complete. Despite this negative result, we discuss avenues to address\nthe problem in a tractable way and how non-Markovian exploration could benefit\nthe sample efficiency of online reinforcement learning in future works.",
    "descriptor": "",
    "authors": [
      "Mirco Mutti",
      "Riccardo De Santi",
      "Marcello Restelli"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.03060"
  },
  {
    "id": "arXiv:2202.03061",
    "title": "Longest Cycle above Erd\u0151s-Gallai Bound",
    "abstract": "In 1959, Erd\\H{o}s and Gallai proved that every graph G with average vertex\ndegree ad(G)\\geq 2 contains a cycle of length at least ad(G). We provide an\nalgorithm that for k\\geq 0 in time 2^{O(k)} n^{O(1)} decides whether a\n2-connected n-vertex graph G contains a cycle of length at least ad(G)+k. This\nresolves an open problem explicitly mentioned in several papers. The main\ningredients of our algorithm are new graph-theoretical results interesting on\ntheir own.",
    "descriptor": "",
    "authors": [
      "Fedor V. Fomin",
      "Petr A. Golovach",
      "Danil Sagunov",
      "Kirill Simonov"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2202.03061"
  },
  {
    "id": "arXiv:2202.03068",
    "title": "Artificial Intelligence based tool wear and defect prediction for  special purpose milling machinery using low-cost acceleration sensor  retrofits",
    "abstract": "Milling machines form an integral part of many industrial processing chains.\nAs a consequence, several machine learning based approaches for tool wear\ndetection have been proposed in recent years, yet these methods mostly deal\nwith standard milling machines, while machinery designed for more specialized\ntasks has gained only limited attention so far. This paper demonstrates the\napplication of an acceleration sensor to allow for convenient condition\nmonitoring of such a special purpose machine, i.e. round seam milling machine.\nWe examine a variety of conditions including blade wear and blade breakage as\nwell as improper machine mounting or insufficient transmission belt tension. In\naddition, we presents different approaches to supervised failure recognition\nwith limited amounts of training data. Hence, aside theoretical insights, our\nanalysis is of high, practical importance, since retrofitting older machines\nwith acceleration sensors and an on-edge classification setup comes at low cost\nand effort, yet provides valuable insights into the state of the machine and\ntools in particular and the production process in general.",
    "descriptor": "",
    "authors": [
      "Mahmoud Kheir-Eddine",
      "Michael Banf",
      "Gregor Steinhagen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.03068"
  },
  {
    "id": "arXiv:2202.03070",
    "title": "Addressing modern and practical challenges in machine learning: A survey  of online federated and transfer learning",
    "abstract": "Online federated learning (OFL) and online transfer learning (OTL) are two\ncollaborative paradigms for overcoming modern machine learning challenges such\nas data silos, streaming data, and data security. This survey explored OFL and\nOTL throughout their major evolutionary routes to enhance understanding of\nonline federated and transfer learning. Besides, practical aspects of popular\ndatasets and cutting-edge applications for online federated and transfer\nlearning are highlighted in this work. Furthermore, this survey provides\ninsight into potential future research areas and aims to serve as a resource\nfor professionals developing online federated and transfer learning frameworks.",
    "descriptor": "",
    "authors": [
      "Shuang Dai",
      "Fanlin Meng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.03070"
  },
  {
    "id": "arXiv:2202.03071",
    "title": "Distributionally Robust Fair Principal Components via Geodesic Descents",
    "abstract": "Principal component analysis is a simple yet useful dimensionality reduction\ntechnique in modern machine learning pipelines. In consequential domains such\nas college admission, healthcare and credit approval, it is imperative to take\ninto account emerging criteria such as the fairness and the robustness of the\nlearned projection. In this paper, we propose a distributionally robust\noptimization problem for principal component analysis which internalizes a\nfairness criterion in the objective function. The learned projection thus\nbalances the trade-off between the total reconstruction error and the\nreconstruction error gap between subgroups, taken in the min-max sense over all\ndistributions in a moment-based ambiguity set. The resulting optimization\nproblem over the Stiefel manifold can be efficiently solved by a Riemannian\nsubgradient descent algorithm with a sub-linear convergence rate. Our\nexperimental results on real-world datasets show the merits of our proposed\nmethod over state-of-the-art baselines.",
    "descriptor": "\nComments: International Conference on Learning Representations (ICLR) 2022\n",
    "authors": [
      "Hieu Vu",
      "Toan Tran",
      "Man-Chung Yue",
      "Viet Anh Nguyen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.03071"
  },
  {
    "id": "arXiv:2202.03074",
    "title": "Imposing Temporal Consistency on Deep Monocular Body Shape and Pose  Estimation",
    "abstract": "Accurate and temporally consistent modeling of human bodies is essential for\na wide range of applications, including character animation, understanding\nhuman social behavior and AR/VR interfaces. Capturing human motion accurately\nfrom a monocular image sequence is still challenging and the modeling quality\nis strongly influenced by the temporal consistency of the captured body motion.\nOur work presents an elegant solution for the integration of temporal\nconstraints in the fitting process. This does not only increase temporal\nconsistency but also robustness during the optimization. In detail, we derive\nparameters of a sequence of body models, representing shape and motion of a\nperson, including jaw poses, facial expressions, and finger poses. We optimize\nthese parameters over the complete image sequence, fitting one consistent body\nshape while imposing temporal consistency on the body motion, assuming linear\nbody joint trajectories over a short time. Our approach enables the derivation\nof realistic 3D body models from image sequences, including facial expression\nand articulated hands. In extensive experiments, we show that our approach\nresults in accurately estimated body shape and motion, also for challenging\nmovements and poses. Further, we apply it to the special application of sign\nlanguage analysis, where accurate and temporal consistent motion modelling is\nessential, and show that the approach is well-suited for this kind of\napplication.",
    "descriptor": "",
    "authors": [
      "Alexandra Zimmer",
      "Anna Hilsmann",
      "Wieland Morgenstern",
      "Peter Eisert"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.03074"
  },
  {
    "id": "arXiv:2202.03077",
    "title": "Adversarial Attacks and Defense for Non-Parametric Two-Sample Tests",
    "abstract": "Non-parametric two-sample tests (TSTs) that judge whether two sets of samples\nare drawn from the same distribution, have been widely used in the analysis of\ncritical data. People tend to employ TSTs as trusted basic tools and rarely\nhave any doubt about their reliability. This paper systematically uncovers the\nfailure mode of non-parametric TSTs through adversarial attacks and then\nproposes corresponding defense strategies. First, we theoretically show that an\nadversary can upper-bound the distributional shift which guarantees the\nattack's invisibility. Furthermore, we theoretically find that the adversary\ncan also degrade the lower bound of a TST's test power, which enables us to\niteratively minimize the test criterion in order to search for adversarial\npairs. To enable TST-agnostic attacks, we propose an ensemble attack (EA)\nframework that jointly minimizes the different types of test criteria. Second,\nto robustify TSTs, we propose a max-min optimization that iteratively generates\nadversarial pairs to train the deep kernels. Extensive experiments on both\nsimulated and real-world datasets validate the adversarial vulnerabilities of\nnon-parametric TSTs and the effectiveness of our proposed defense.",
    "descriptor": "",
    "authors": [
      "Xilie Xu",
      "Jingfeng Zhang",
      "Feng Liu",
      "Masashi Sugiyama",
      "Mohan Kankanhalli"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.03077"
  },
  {
    "id": "arXiv:2202.03078",
    "title": "Fair Interpretable Representation Learning with Correction Vectors",
    "abstract": "Neural network architectures have been extensively employed in the fair\nrepresentation learning setting, where the objective is to learn a new\nrepresentation for a given vector which is independent of sensitive\ninformation. Various representation debiasing techniques have been proposed in\nthe literature. However, as neural networks are inherently opaque, these\nmethods are hard to comprehend, which limits their usefulness. We propose a new\nframework for fair representation learning that is centered around the learning\nof \"correction vectors\", which have the same dimensionality as the given data\nvectors. Correction vectors may be computed either explicitly via architectural\nconstraints or implicitly by training an invertible model based on Normalizing\nFlows. We show experimentally that several fair representation learning models\nconstrained in such a way do not exhibit losses in ranking or classification\nperformance. Furthermore, we demonstrate that state-of-the-art results can be\nachieved by the invertible model. Finally, we discuss the law standing of our\nmethodology in light of recent legislation in the European Union.",
    "descriptor": "",
    "authors": [
      "Mattia Cerrato",
      "Alesia Vallenas Coronel",
      "Marius K\u00f6ppel",
      "Alexander Segner",
      "Roberto Esposito",
      "Stefan Kramer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2202.03078"
  },
  {
    "id": "arXiv:2202.03079",
    "title": "Call-by-Value Solvability and Multi Types",
    "abstract": "This paper provides a characterization of call-by-value solvability using\ncall-by-value multi types. Our work is based on Accattoli and Paolini's\ncharacterization of call-by-value solvable terms as those terminating with\nrespect to the solving strategy of the value substitution calculus, a\nrefinement of Plotkin's call-by-value $\\lambda$-calculus. Here we show that the\nsolving strategy terminates on a term $t$ if and only if $t$ is typable in a\ncertain way in the multi type system induced by Ehrhard's call-by-value\nrelational semantics. Moreover, we show how to extract from the type system\nexact bounds on the length of the solving evaluation and on the size of its\nnormal form, adapting de Carvalho's technique for call-by-name.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2104.13979\n",
    "authors": [
      "Beniamino Accattoli",
      "Giulio Guerrieri"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2202.03079"
  },
  {
    "id": "arXiv:2202.03083",
    "title": "Gender stereotypes in the mediated personalization of politics:  Empirical evidence from a lexical, syntactic and sentiment analysis",
    "abstract": "The media attention to the personal sphere of famous and important\nindividuals has become a key element of the gender narrative. Here we combine\nlexical, syntactic and sentiment analysis to investigate the role of gender in\nthe personalization of a wide range of political office holders in Italy during\nthe period 2017-2020. On the basis of a score for words that is introduced to\naccount for gender unbalance in both representative and news coverage, we show\nthat the political personalization in Italy is more detrimental for women than\nmen, with the persistence of entrenched stereotypes including a masculine\nconnotation of leadership, the resulting women's unsuitability to hold\npolitical functions, and a greater deal of focus on their attractiveness and\nbody parts. In addition, women politicians are covered with a more negative\ntone than their men counterpart when personal details are reported. Further,\nthe major contribution to the observed gender differences comes from online\nnews rather than print news, suggesting that the expression of certain\nstereotypes may be better conveyed when click baiting and personal targeting\nhave a major impact.",
    "descriptor": "",
    "authors": [
      "Emanuele Brugnoli",
      "Rosaria Simone",
      "Marco Delmastro"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2202.03083"
  },
  {
    "id": "arXiv:2202.03084",
    "title": "Temporal Point Cloud Completion with Pose Disturbance",
    "abstract": "Point clouds collected by real-world sensors are always unaligned and sparse,\nwhich makes it hard to reconstruct the complete shape of object from a single\nframe of data. In this work, we manage to provide complete point clouds from\nsparse input with pose disturbance by limited translation and rotation. We also\nuse temporal information to enhance the completion model, refining the output\nwith a sequence of inputs. With the help of gated recovery units(GRU) and\nattention mechanisms as temporal units, we propose a point cloud completion\nframework that accepts a sequence of unaligned and sparse inputs, and outputs\nconsistent and aligned point clouds. Our network performs in an online manner\nand presents a refined point cloud for each frame, which enables it to be\nintegrated into any SLAM or reconstruction pipeline. As far as we know, our\nframework is the first to utilize temporal information and ensure temporal\nconsistency with limited transformation. Through experiments in ShapeNet and\nKITTI, we prove that our framework is effective in both synthetic and\nreal-world datasets.",
    "descriptor": "\nComments: 8 pages; Accepted by RAL with ICRA 2022\n",
    "authors": [
      "Jieqi Shi",
      "Lingyun Xu",
      "Peiliang Li",
      "Xiaozhi Chen",
      "Shaojie Shen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.03084"
  },
  {
    "id": "arXiv:2202.03086",
    "title": "Machine Translation from Signed to Spoken Languages: State of the Art  and Challenges",
    "abstract": "Automatic translation from signed to spoken languages is an interdisciplinary\nresearch domain, lying on the intersection of computer vision, machine\ntranslation and linguistics. Nevertheless, research in this domain is performed\nmostly by computer scientists in isolation. As the domain is becoming\nincreasingly popular - the majority of scientific papers on the topic of sign\nlanguage translation have been published in the past three years - we provide\nan overview of the state of the art as well as some required background in the\ndifferent related disciplines. We give a high-level introduction to sign\nlanguage linguistics and machine translation to illustrate the requirements of\nautomatic sign language translation. We present a systematic literature review\nto illustrate the state of the art in the domain and then, harking back to the\nrequirements, lay out several challenges for future research. We find that\nsignificant advances have been made on the shoulders of spoken language machine\ntranslation research. However, current approaches are often not linguistically\nmotivated or are not adapted to the different input modality of sign languages.\nWe explore challenges related to the representation of sign language data, the\ncollection of datasets, the need for interdisciplinary research and\nrequirements for moving beyond research, towards applications. Based on our\nfindings, we advocate for interdisciplinary research and to base future\nresearch on linguistic analysis of sign languages. Furthermore, the inclusion\nof deaf and hearing end users of sign language translation applications in use\ncase identification, data collection and evaluation is of the utmost importance\nin the creation of useful sign language translation models. We recommend\niterative, human-in-the-loop, design and development of sign language\ntranslation models.",
    "descriptor": "",
    "authors": [
      "Mathieu De Coster",
      "Dimitar Shterionov",
      "Mieke Van Herreweghe",
      "Joni Dambre"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.03086"
  },
  {
    "id": "arXiv:2202.03087",
    "title": "Unsupervised Long-Term Person Re-Identification with Clothes Change",
    "abstract": "We investigate unsupervised person re-identification (Re-ID) with clothes\nchange, a new challenging problem with more practical usability and scalability\nto real-world deployment. Most existing re-id methods artificially assume the\nclothes of every single person to be stationary across space and time. This\ncondition is mostly valid for short-term re-id scenarios since an average\nperson would often change the clothes even within a single day. To alleviate\nthis assumption, several recent works have introduced the clothes change facet\nto re-id, with a focus on supervised learning person identity discriminative\nrepresentation with invariance to clothes changes. Taking a step further\ntowards this long-term re-id direction, we further eliminate the requirement of\nperson identity labels, as they are significantly more expensive and more\ntedious to annotate in comparison to short-term person re-id datasets. Compared\nto conventional unsupervised short-term re-id, this new problem is drastically\nmore challenging as different people may have similar clothes whilst the same\nperson can wear multiple suites of clothes over different locations and times\nwith very distinct appearance. To overcome such obstacles, we introduce a novel\nCurriculum Person Clustering (CPC) method that can adaptively regulate the\nunsupervised clustering criterion according to the clustering confidence.\nExperiments on three long-term person re-id datasets show that our CPC\noutperforms SOTA unsupervised re-id methods and even closely matches the\nsupervised re-id models.",
    "descriptor": "",
    "authors": [
      "Mingkun Li",
      "Peng Xu",
      "Xiatian Zhu",
      "Jun Guo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.03087"
  },
  {
    "id": "arXiv:2202.03091",
    "title": "Auto-Lambda: Disentangling Dynamic Task Relationships",
    "abstract": "Understanding the structure of multiple related tasks allows for multi-task\nlearning to improve the generalisation ability of one or all of them. However,\nit usually requires training each pairwise combination of tasks together in\norder to capture task relationships, at an extremely high computational cost.\nIn this work, we learn task relationships via an automated weighting framework,\nnamed Auto-Lambda. Unlike previous methods where task relationships are assumed\nto be fixed, Auto-Lambda is a gradient-based meta learning framework which\nexplores continuous, dynamic task relationships via task-specific weightings,\nand can optimise any choice of combination of tasks through the formulation of\na meta-loss; where the validation loss automatically influences task weightings\nthroughout training. We apply the proposed framework to both multi-task and\nauxiliary learning problems in computer vision and robotics, and show that\nAuto-Lambda achieves state-of-the-art performance, even when compared to\noptimisation strategies designed specifically for each problem and data domain.\nFinally, we observe that Auto-Lambda can discover interesting learning\nbehaviors, leading to new insights in multi-task learning. Code is available at\nhttps://github.com/lorenmt/auto-lambda.",
    "descriptor": "\nComments: Tech Report. Project Page: this https URL Code: this https URL\n",
    "authors": [
      "Shikun Liu",
      "Stephen James",
      "Andrew J. Davison",
      "Edward Johns"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.03091"
  },
  {
    "id": "arXiv:2202.03092",
    "title": "Document-Level Event Extraction via Human-Like Reading Process",
    "abstract": "Document-level Event Extraction (DEE) is particularly tricky due to the two\nchallenges it poses: scattering-arguments and multi-events. The first challenge\nmeans that arguments of one event record could reside in different sentences in\nthe document, while the second one reflects one document may simultaneously\ncontain multiple such event records. Motivated by humans' reading cognitive to\nextract information of interests, in this paper, we propose a method called HRE\n(Human Reading inspired Extractor for Document Events), where DEE is decomposed\ninto these two iterative stages, rough reading and elaborate reading.\nSpecifically, the first stage browses the document to detect the occurrence of\nevents, and the second stage serves to extract specific event arguments. For\neach concrete event role, elaborate reading hierarchically works from sentences\nto characters to locate arguments across sentences, thus the\nscattering-arguments problem is tackled. Meanwhile, rough reading is explored\nin a multi-round manner to discover undetected events, thus the multi-events\nproblem is handled. Experiment results show the superiority of HRE over prior\ncompetitive methods.",
    "descriptor": "\nComments: To apper in ICASSP2022\n",
    "authors": [
      "Shiyao Cui",
      "Xin Cong",
      "Bowen Yu",
      "Tingwen Liu",
      "Yucheng Wang",
      "Jinqiao Shi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.03092"
  },
  {
    "id": "arXiv:2202.03093",
    "title": "Effective Variable Depth Local Search for the Budgeted Maximum Coverage  Problem",
    "abstract": "We address the Budgeted Maximum Coverage Problem (BMCP), which is a natural\nand more practical extension of the standard 0-1 knapsack problem and the set\ncover problem. Given m elements with nonnegative weights, n subsets of elements\nwith nonnegative costs, and a total budget, BMCP aims to select some subsets\nsuch that the total cost of selected subsets does not exceed the budget, and\nthe total weight of associated elements is maximized. In this paper, we propose\na variable depth local search algorithm (VDLS) for the BMCP. VDLS first\ngenerates an initial solution by a greedy algorithm, then iteratively improves\nthe solution through a partial depth-first search method, that can improve the\nsolution by simultaneously changing the states (selected or not) of multiple\nsubsets. Such method allows VDLS to explore the solution space widely and\ndeeply, and to yield high-quality solutions. We further propose a neighbour\nstructure to boost the algorithm performance, that is, both subsets have a\nneighbour relation if they have at least one common associated element. By\napplying the neighbour structure, VDLS can adjust the selected subsets while\nlosing as few covered elements as possible. Since the existing BMCP benchmarks\nonly have simple structures and small scales, we design 60 new instances with\nrelatively large scales and complex structures to enrich the diversity of the\nBMCP instances. Experimental results on 30 public instances and 60 new\ninstances we designed demonstrate that VDLS significantly outperforms the\nexisting heuristic and the general CPLEX exact solver, for the BMCP.",
    "descriptor": "",
    "authors": [
      "Jianrong Zhou",
      "Jiongzhi Zheng",
      "Kun He"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2202.03093"
  },
  {
    "id": "arXiv:2202.03097",
    "title": "Learn over Past, Evolve for Future: Search-based Time-aware  Recommendation with Sequential Behavior Data",
    "abstract": "The personalized recommendation is an essential part of modern e-commerce,\nwhere user's demands are not only conditioned by their profile but also by\ntheir recent browsing behaviors as well as periodical purchases made some time\nago. In this paper, we propose a novel framework named Search-based Time-Aware\nRecommendation (STARec), which captures the evolving demands of users over time\nthrough a unified search-based time-aware model. More concretely, we first\ndesign a search-based module to retrieve a user's relevant historical\nbehaviors, which are then mixed up with her recent records to be fed into a\ntime-aware sequential network for capturing her time-sensitive demands. Besides\nretrieving relevant information from her personal history, we also propose to\nsearch and retrieve similar user's records as an additional reference. All\nthese sequential records are further fused to make the final recommendation.\nBeyond this framework, we also develop a novel label trick that uses the\nprevious labels (i.e., user's feedbacks) as the input to better capture the\nuser's browsing pattern. We conduct extensive experiments on three real-world\ncommercial datasets on click-through-rate prediction tasks against\nstate-of-the-art methods. Experimental results demonstrate the superiority and\nefficiency of our proposed framework and techniques. Furthermore, results of\nonline experiments on a daily item recommendation platform of Company X show\nthat STARec gains average performance improvement of around 6% and 1.5% in its\ntwo main item recommendation scenarios on CTR metric respectively.",
    "descriptor": "\nComments: WWW 2022\n",
    "authors": [
      "Jiarui Jin",
      "Xianyu Chen",
      "Weinan Zhang",
      "Junjie Huang",
      "Ziming Feng",
      "Yong Yu"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2202.03097"
  },
  {
    "id": "arXiv:2202.03099",
    "title": "FL_PyTorch: optimization research simulator for federated learning",
    "abstract": "Federated Learning (FL) has emerged as a promising technique for edge devices\nto collaboratively learn a shared machine learning model while keeping training\ndata locally on the device, thereby removing the need to store and access the\nfull data in the cloud. However, FL is difficult to implement, test and deploy\nin practice considering heterogeneity in common edge device settings, making it\nfundamentally hard for researchers to efficiently prototype and test their\noptimization algorithms. In this work, our aim is to alleviate this problem by\nintroducing FL_PyTorch : a suite of open-source software written in python that\nbuilds on top of one the most popular research Deep Learning (DL) framework\nPyTorch. We built FL_PyTorch as a research simulator for FL to enable fast\ndevelopment, prototyping and experimenting with new and existing FL\noptimization algorithms. Our system supports abstractions that provide\nresearchers with a sufficient level of flexibility to experiment with existing\nand novel approaches to advance the state-of-the-art. Furthermore, FL_PyTorch\nis a simple to use console system, allows to run several clients simultaneously\nusing local CPUs or GPU(s), and even remote compute devices without the need\nfor any distributed implementation provided by the user. FL_PyTorch also offers\na Graphical User Interface. For new methods, researchers only provide the\ncentralized implementation of their algorithm. To showcase the possibilities\nand usefulness of our system, we experiment with several well-known\nstate-of-the-art FL algorithms and a few of the most common FL datasets.",
    "descriptor": "\nComments: DistributedML '21: Proceedings of the 2nd ACM International Workshop on Distributed Machine Learning\n",
    "authors": [
      "Konstantin Burlachenko",
      "Samuel Horv\u00e1th",
      "Peter Richt\u00e1rik"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Mathematical Software (cs.MS)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2202.03099"
  },
  {
    "id": "arXiv:2202.03100",
    "title": "Sequential Channel Synthesis",
    "abstract": "The channel synthesis problem has been widely investigated over the last\ndecade. In this paper, we consider the sequential version in which the encoder\nand the decoder work in a sequential way. Under a mild assumption on the target\njoint distribution we provide a complete (single-letter) characterization of\nthe solution for the point-to-point case, which shows that the canonical\nsymbol-by-symbol mapping is not optimal in general, but is indeed optimal if we\nmake some additional assumptions on the encoder and decoder. We also extend\nthis result to the broadcast scenario and the interactive communication\nscenario. We provide bounds in the broadcast setting and a complete\ncharacterization of the solution under a mild condition on the target joint\ndistribution in the interactive communication case. Our proofs are based on a\nR\\'enyi entropy method.",
    "descriptor": "\nComments: 18 pages, no figures. Short version was submitted to the ISIT 2022\n",
    "authors": [
      "Lei Yu",
      "Venkat Anantharam"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.03100"
  },
  {
    "id": "arXiv:2202.03103",
    "title": "Combining Deep Learning and Reasoning for Address Detection in  Unstructured Text Documents",
    "abstract": "Extracting information from unstructured text documents is a demanding task,\nsince these documents can have a broad variety of different layouts and a\nnon-trivial reading order, like it is the case for multi-column documents or\nnested tables. Additionally, many business documents are received in paper\nform, meaning that the textual contents need to be digitized before further\nanalysis. Nonetheless, automatic detection and capturing of crucial document\ninformation like the sender address would boost many companies' processing\nefficiency. In this work we propose a hybrid approach that combines deep\nlearning with reasoning for finding and extracting addresses from unstructured\ntext documents. We use a visual deep learning model to detect the boundaries of\npossible address regions on the scanned document images and validate these\nresults by analyzing the containing text using domain knowledge represented as\na rule based system.",
    "descriptor": "\nComments: 5 pages, 1 figure, submitted to AAAI-22 workshop CLeaR, peer reviewed\n",
    "authors": [
      "Matthias Engelbach",
      "Dennis Klau",
      "Jens Drawehn",
      "Maximilien Kintz"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.03103"
  },
  {
    "id": "arXiv:2202.03104",
    "title": "SimGRACE: A Simple Framework for Graph Contrastive Learning without Data  Augmentation",
    "abstract": "Graph contrastive learning (GCL) has emerged as a dominant technique for\ngraph representation learning which maximizes the mutual information between\npaired graph augmentations that share the same semantics. Unfortunately, it is\ndifficult to preserve semantics well during augmentations in view of the\ndiverse nature of graph data. Currently, data augmentations in GCL that are\ndesigned to preserve semantics broadly fall into three unsatisfactory ways.\nFirst, the augmentations can be manually picked per dataset by\ntrial-and-errors. Second, the augmentations can be selected via cumbersome\nsearch. Third, the augmentations can be obtained by introducing expensive\ndomain-specific knowledge as guidance. All of these limit the efficiency and\nmore general applicability of existing GCL methods. To circumvent these crucial\nissues, we propose a \\underline{Sim}ple framework for \\underline{GRA}ph\n\\underline{C}ontrastive l\\underline{E}arning, \\textbf{SimGRACE} for brevity,\nwhich does not require data augmentations. Specifically, we take original graph\nas input and GNN model with its perturbed version as two encoders to obtain two\ncorrelated views for contrast. SimGRACE is inspired by the observation that\ngraph data can preserve their semantics well during encoder perturbations while\nnot requiring manual trial-and-errors, cumbersome search or expensive domain\nknowledge for augmentations selection. Also, we explain why SimGRACE can\nsucceed. Furthermore, we devise adversarial training scheme, dubbed\n\\textbf{AT-SimGRACE}, to enhance the robustness of graph contrastive learning\nand theoretically explain the reasons. Albeit simple, we show that SimGRACE can\nyield competitive or better performance compared with state-of-the-art methods\nin terms of generalizability, transferability and robustness, while enjoying\nunprecedented degree of flexibility and efficiency.",
    "descriptor": "\nComments: Accepted by The Web Conference 2022 (WWW 2022)\n",
    "authors": [
      "Jun Xia",
      "Lirong Wu",
      "Jintao Chen",
      "Bozhen Hu",
      "Stan Z.Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2202.03104"
  },
  {
    "id": "arXiv:2202.03107",
    "title": "Bubble identification from images with machine learning methods",
    "abstract": "An automated and reliable processing of bubbly flow images is highly needed\nto analyse large data sets of comprehensive experimental series. A particular\ndifficulty arises due to overlapping bubble projections in recorded images,\nwhich highly complicates the identification of individual bubbles. Recent\napproaches focus on the use of deep learning algorithms for this task and have\nalready proven the high potential of such techniques. The main difficulties are\nthe capability to handle different image conditions, higher gas volume\nfractions and a proper reconstruction of the hidden segment of a partly\noccluded bubble. In the present work, we try to tackle these points by testing\nthree different methods based on Convolutional Neural Networks (CNNs) for the\ntwo former and two individual approaches that can be used subsequently to\naddress the latter. To validate our methodology, we created test data sets with\nsynthetic images that further demonstrate the capabilities as well as\nlimitations of our combined approach. The generated data, code and trained\nmodels are made accessible to facilitate the use as well as further\ndevelopments in the research field of bubble recognition in experimental\nimages.",
    "descriptor": "",
    "authors": [
      "Hendrik Hessenkemper",
      "Sebastian Starke",
      "Yazan Atassi",
      "Thomas Ziegenhein",
      "Dirk Lucas"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2202.03107"
  },
  {
    "id": "arXiv:2202.03119",
    "title": "Moving Other Way: Exploring Word Mover Distance Extensions",
    "abstract": "The word mover's distance (WMD) is a popular semantic similarity metric for\ntwo texts. This position paper studies several possible extensions of WMD. We\nexperiment with the frequency of words in the corpus as a weighting factor and\nthe geometry of the word vector space. We validate possible extensions of WMD\non six document classification datasets. Some proposed extensions show better\nresults in terms of the k-nearest neighbor classification error than WMD.",
    "descriptor": "",
    "authors": [
      "Ilya Smirnov",
      "Ivan P. Yamshchikov"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.03119"
  },
  {
    "id": "arXiv:2202.03120",
    "title": "To Tune or Not To Tune? Zero-shot Models for Legal Case Entailment",
    "abstract": "There has been mounting evidence that pretrained language models fine-tuned\non large and diverse supervised datasets can transfer well to a variety of\nout-of-domain tasks. In this work, we investigate this transfer ability to the\nlegal domain. For that, we participated in the legal case entailment task of\nCOLIEE 2021, in which we use such models with no adaptations to the target\ndomain. Our submissions achieved the highest scores, surpassing the second-best\nteam by more than six percentage points. Our experiments confirm a\ncounter-intuitive result in the new paradigm of pretrained language models:\ngiven limited labeled data, models with little or no adaptation to the target\ntask can be more robust to changes in the data distribution than models\nfine-tuned on it. Code is available at https://github.com/neuralmind-ai/coliee.",
    "descriptor": "",
    "authors": [
      "Guilherme Moraes Rosa",
      "Ruan Chaves Rodrigues",
      "Roberto de Alencar Lotufo",
      "Rodrigo Nogueira"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.03120"
  },
  {
    "id": "arXiv:2202.03126",
    "title": "Reasoning for Complex Data through Ensemble-based Self-Supervised  Learning",
    "abstract": "Self-supervised learning deals with problems that have little or no available\nlabeled data. Recent work has shown impressive results when underlying classes\nhave significant semantic differences. One important dataset in which this\ntechnique thrives is ImageNet, as intra-class distances are substantially lower\nthan inter-class distances. However, this is not the case for several critical\ntasks, and general self-supervised learning methods fail to learn\ndiscriminative features when classes have closer semantics, thus requiring more\nrobust strategies. We propose a strategy to tackle this problem, and to enable\nlearning from unlabeled data even when samples from different classes are not\nprominently diverse. We approach the problem by leveraging a novel\nensemble-based clustering strategy where clusters derived from different\nconfigurations are combined to generate a better grouping for the data samples\nin a fully-unsupervised way. This strategy allows clusters with different\ndensities and higher variability to emerge, which in turn reduces intra-class\ndiscrepancies, without requiring the burden of finding an optimal configuration\nper dataset. We also consider different Convolutional Neural Networks to\ncompute distances between samples. We refine these distances by performing\ncontext analysis and group them to capture complementary information. We\nconsider two applications to validate our pipeline: Person Re-Identification\nand Text Authorship Verification. These are challenging applications\nconsidering that classes are semantically close to each other and that training\nand test sets have disjoint identities. Our method is robust across different\nmodalities and outperforms state-of-the-art results with a fully-unsupervised\nsolution without any labeling or human intervention.",
    "descriptor": "\nComments: On main article: 12 pages, 7 figures and 5 tables On Supplementary material: 5 pages, 4 figures and 2 tables\n",
    "authors": [
      "Gabriel Bertocco",
      "Ant\u00f4nio The\u00f3filo",
      "Fernanda Andal\u00f3",
      "Anderson Rocha"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.03126"
  },
  {
    "id": "arXiv:2202.03129",
    "title": "Over-the-Air Ensemble Inference with Model Privacy",
    "abstract": "We consider distributed inference at the wireless edge, where multiple\nclients with an ensemble of models, each trained independently on a local\ndataset, are queried in parallel to make an accurate decision on a new sample.\nIn addition to maximizing inference accuracy, we also want to maximize the\nprivacy of local models. We exploit the superposition property of the air to\nimplement bandwidth-efficient ensemble inference methods. We introduce\ndifferent over-the-air ensemble methods and show that these schemes perform\nsignificantly better than their orthogonal counterparts, while using less\nresources and providing privacy guarantees. We also provide experimental\nresults verifying the benefits of the proposed over-the-air inference approach,\nwhose source code is shared publicly on Github.",
    "descriptor": "\nComments: 15 pages\n",
    "authors": [
      "Selim F. Yilmaz",
      "Burak Hasircioglu",
      "Deniz Gunduz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.03129"
  },
  {
    "id": "arXiv:2202.03131",
    "title": "Transformers in Self-Supervised Monocular Depth Estimation with Unknown  Camera Intrinsics",
    "abstract": "The advent of autonomous driving and advanced driver assistance systems\nnecessitates continuous developments in computer vision for 3D scene\nunderstanding. Self-supervised monocular depth estimation, a method for\npixel-wise distance estimation of objects from a single camera without the use\nof ground truth labels, is an important task in 3D scene understanding.\nHowever, existing methods for this task are limited to convolutional neural\nnetwork (CNN) architectures. In contrast with CNNs that use localized linear\noperations and lose feature resolution across the layers, vision transformers\nprocess at constant resolution with a global receptive field at every stage.\nWhile recent works have compared transformers against their CNN counterparts\nfor tasks such as image classification, no study exists that investigates the\nimpact of using transformers for self-supervised monocular depth estimation.\nHere, we first demonstrate how to adapt vision transformers for self-supervised\nmonocular depth estimation. Thereafter, we compare the transformer and\nCNN-based architectures for their performance on KITTI depth prediction\nbenchmarks, as well as their robustness to natural corruptions and adversarial\nattacks, including when the camera intrinsics are unknown. Our study\ndemonstrates how transformer-based architecture, though lower in run-time\nefficiency, achieves comparable performance while being more robust and\ngeneralizable.",
    "descriptor": "\nComments: Published in 17th International Conference on Computer Vision Theory and Applications (VISAP, 2022)\n",
    "authors": [
      "Arnav Varma",
      "Hemang Chawla",
      "Bahram Zonooz",
      "Elahe Arani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.03131"
  },
  {
    "id": "arXiv:2202.03133",
    "title": "Rate Coding or Direct Coding: Which One is Better for Accurate, Robust,  and Energy-efficient Spiking Neural Networks?",
    "abstract": "Recent Spiking Neural Networks (SNNs) works focus on an image classification\ntask, therefore various coding techniques have been proposed to convert an\nimage into temporal binary spikes. Among them, rate coding and direct coding\nare regarded as prospective candidates for building a practical SNN system as\nthey show state-of-the-art performance on large-scale datasets. Despite their\nusage, there is little attention to comparing these two coding schemes in a\nfair manner. In this paper, we conduct a comprehensive analysis of the two\ncodings from three perspectives: accuracy, adversarial robustness, and\nenergy-efficiency. First, we compare the performance of two coding techniques\nwith various architectures and datasets. Then, we measure the robustness of the\ncoding techniques on two adversarial attack methods. Finally, we compare the\nenergy-efficiency of two coding schemes on a digital hardware platform. Our\nresults show that direct coding can achieve better accuracy especially for a\nsmall number of timesteps. In contrast, rate coding shows better robustness to\nadversarial attacks owing to the non-differentiable spike generation process.\nRate coding also yields higher energy-efficiency than direct coding which\nrequires multi-bit precision for the first layer. Our study explores the\ncharacteristics of two codings, which is an important design consideration for\nbuilding SNNs. The code is made available at\nhttps://github.com/Intelligent-Computing-Lab-Yale/Rate-vs-Direct.",
    "descriptor": "\nComments: Accepted to ICASSP2022\n",
    "authors": [
      "Youngeun Kim",
      "Hyoungseob Park",
      "Abhishek Moitra",
      "Abhiroop Bhattacharjee",
      "Yeshwanth Venkatesha",
      "Priyadarshini Panda"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.03133"
  },
  {
    "id": "arXiv:2202.03134",
    "title": "Edge-computing Enabled Next Generation Wireless Networks: A Novel  Approach to Provide Secure Multicast Services",
    "abstract": "Smart grids have received much attention in recent years in order to\noptimally manage the resources, transmission and consumption of electric\npower.In these grids, one of the most important communication services is the\nmulticast service. Providing multicast services in the smart communicative grid\nposes several challenges, including the heterogeneity of different\ncommunication media and the strict requirements of reliability, security and\nlatency. Wireless technologies and PLC connections are the two most important\nmedia used in this grid, among which PLC connections are very unstable, which\nmakes it difficult to provide reliability. In this research, the problem of\ngeographically flooding of multicast data has been considered. First, this\nproblem has been modeled as an optimization problem which is used as a\nreference model in evaluating the proposed approaches. Then, two MKMB and GCBT\nmulticast tree formation algorithms have been developed based on geographical\ninformation according to the characteristics of smart grids. Comparison of\nthese two approaches shows the advantages and disadvantages of forming a\ncore-based tree compared to a source-based tree. Evaluation of these approaches\nshows a relative improvement in tree cost and the amount of end-to-end delay\ncompared to basic algorithms. In the second part, providing security and\nreliability in data transmission has been considered. Both Hybrid and Multiple\nalgorithms have been developed based on the idea of multiple transmission tree.\nIn the Hybrid algorithm, the aim is to provide higher security and reliability,\nbut in the Multiple algorithms, minimization of message transmission delay is\ntargeted. In the section of behavior evaluation, these two algorithms have been\nstudied in different working conditions, which indicates the achievement of the\ndesired goals.",
    "descriptor": "",
    "authors": [
      "Farid Sorouri"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2202.03134"
  },
  {
    "id": "arXiv:2202.03140",
    "title": "OPP-Miner: Order-preserving sequential pattern mining",
    "abstract": "A time series is a collection of measurements in chronological order.\nDiscovering patterns from time series is useful in many domains, such as stock\nanalysis, disease detection, and weather forecast. To discover patterns,\nexisting methods often convert time series data into another form, such as\nnominal/symbolic format, to reduce dimensionality, which inevitably deviates\nthe data values. Moreover, existing methods mainly neglect the order\nrelationships between time series values. To tackle these issues, inspired by\norder-preserving matching, this paper proposes an Order-Preserving sequential\nPattern (OPP) mining method, which represents patterns based on the order\nrelationships of the time series data. An inherent advantage of such\nrepresentation is that the trend of a time series can be represented by the\nrelative order of the values underneath the time series data. To obtain\nfrequent trends in time series, we propose the OPP-Miner algorithm to mine\npatterns with the same trend (sub-sequences with the same relative order).\nOPP-Miner employs the filtration and verification strategies to calculate the\nsupport and uses pattern fusion strategy to generate candidate patterns. To\ncompress the result set, we also study finding the maximal OPPs. Experiments\nvalidate that OPP-Miner is not only efficient and scalable but can also\ndiscover similar sub-sequences in time series. In addition, case studies show\nthat our algorithms have high utility in analyzing the COVID-19 epidemic by\nidentifying critical trends and improve the clustering performance.",
    "descriptor": "",
    "authors": [
      "Youxi Wu",
      "Qian Hu",
      "Yan Li",
      "Lei Guo",
      "Xingquan Zhu",
      "Xindong Wu"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.03140"
  },
  {
    "id": "arXiv:2202.03142",
    "title": "A Comprehensive Survey on the Internet of Things with the Industrial  Marketplace",
    "abstract": "There is no doubt that new technology has become one of the crucial parts of\nmost people's lives around the world. By and large, in this era, the Internet\nand the Internet of Things (IoT) have become the most indispensable parts of\nour lives. Recently, IoT technologies have been regarded as the most broadly\nused tools among other technologies. The tools and the facilities of IoT\ntech-nologies within the marketplace are part of Industry 4.0. The marketplace\nis too regarded as a new area that can be used with IoT technologies. One of\nthe main purposes of this paper is to highlight using IoT technologies in\nIndustry 4.0, and the Industrial Internet of Things (IIoT) is another feature\nrevised. This paper focuses on the value of the IoT in the industrial domain in\ngeneral; it reviews the IoT and focuses on its benefits and drawbacks, and\npresents some of the IoT applications, such as in transportation and\nhealthcare. In addition, the trends and facts that are related to the IoT\ntechnologies on the marketplace are reviewed. Finally, the role of IoT in\ntelemedicine and healthcare and the benefits of IoT technologies for COVID-19\nare presented as well.",
    "descriptor": "\nComments: 31 pages\n",
    "authors": [
      "Kazhan Othman Mohammed Salih",
      "Tarik A. Rashid",
      "Dalibor Radovanovic",
      "Nebojsa Bacanin"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2202.03142"
  },
  {
    "id": "arXiv:2202.03147",
    "title": "The development of a portable elbow exoskeleton with a Twisted Strings  Actuator to assist patients with upper limb inhabitation",
    "abstract": "Over the years, the number of exoskeleton devices utilized for upper-limb\nrehabilitation has increased dramatically, each with its own set of pros and\ncons. Most exoskeletons are not portable, limiting their utility to daily use\nfor house patients. Additionally, the huge size of some grounded exoskeletons\nconsumes space while maintaining a sophisticated structure and require more\nexpensive materials. In other words, to maintain affordability, the device's\nstructure must be simple. Thus, in this work, a portable elbow exoskeleton is\ndeveloped using SolidWorks to incorporate a Twisted Strings Actuator (TSA) to\naid in upper-limb rehabilitation and to provide an alternative for those with\ncompromised limbs to recuperate. Experiments are conducted to identify the\noptimal value for building a more flexible elbow exoskeleton prototype by\nanalyzing stress, strain conditions, torque, forces, and strings. Preliminary\ncomputational findings reveal that for the proposed intended prototype, a\nstring length of.033 m and a torque value ranging from 1.5 Nm to 3 Nm are\noptimal.",
    "descriptor": "",
    "authors": [
      "Rupal Roy",
      "MM Rashid",
      "Md Manjurul Ahsan",
      "Zahed Siddique"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.03147"
  },
  {
    "id": "arXiv:2202.03148",
    "title": "Autonomous Vehicles: Open-Source Technologies, Considerations, and  Development",
    "abstract": "Autonomous vehicles are the culmination of advances in many areas such as\nsensor technologies, artificial intelligence (AI), networking, and more. This\npaper will introduce the reader to the technologies that build autonomous\nvehicles. It will focus on open-source tools and libraries for autonomous\nvehicle development, making it cheaper and easier for developers and\nresearchers to participate in the field. The topics covered are as follows.\nFirst, we will discuss the sensors used in autonomous vehicles and summarize\ntheir performance in different environments, costs, and unique features. Then\nwe will cover Simultaneous Localization and Mapping (SLAM) and algorithms for\neach modality. Third, we will review popular open-source driving simulators, a\ncost-effective way to train machine learning models and test vehicle software\nperformance. We will then highlight embedded operating systems and the security\nand development considerations when choosing one. After that, we will discuss\nVehicle-to-Vehicle (V2V) and Internet-of-Vehicle (IoV) communication, which are\nareas that fuse networking technologies with autonomous vehicles to extend\ntheir functionality. We will then review the five levels of vehicle automation,\ncommercial and open-source Advanced Driving Assistance Systems, and their\nfeatures. Finally, we will touch on the major manufacturing and software\ncompanies involved in the field, their investments, and their partnerships.\nThese topics will give the reader an understanding of the industry, its\ntechnologies, active research, and the tools available for developers to build\nautonomous vehicles.",
    "descriptor": "\nComments: 13 pages, 7 figures\n",
    "authors": [
      "Oussama Saoudi",
      "Ishwar Singh",
      "Hamidreza Mahyar"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.03148"
  },
  {
    "id": "arXiv:2202.03150",
    "title": "Modular representation and control of floppy networks",
    "abstract": "Geometric graph models of systems as diverse as proteins, robots, and\nmechanical structures from DNA assemblies to architected materials point\ntowards a unified way to represent and control them in space and time. While\nmuch work has been done in the context of characterizing the behavior of these\nnetworks close to critical points associated with bond and rigidity\npercolation, isostaticity, etc., much less is known about floppy,\nunder-constrained networks that are far more common in nature and technology.\nHere we combine geometric rigidity and algebraic sparsity to provide a\nframework for identifying the zero-energy floppy modes via a representation\nthat illuminates the underlying hierarchy and modularity of the network, and\nthence the control of its nestedness and locality. Our framework allows us to\ndemonstrate a range of applications of this approach that include robotic\nreaching tasks with motion primitives, and predicting the linear and nonlinear\nresponse of elastic networks based solely on infinitesimal rigidity and\nsparsity, which we test using physical experiments. Our approach is thus likely\nto be of use broadly in dissecting the geometrical properties of floppy\nnetworks using algebraic sparsity to optimize their function and performance.",
    "descriptor": "",
    "authors": [
      "Siheng Chen",
      "Fabio Giardina",
      "Gary P. T. Choi",
      "L. Mahadevan"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Materials Science (cond-mat.mtrl-sci)",
      "Soft Condensed Matter (cond-mat.soft)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2202.03150"
  },
  {
    "id": "arXiv:2202.03152",
    "title": "Optimizing Age of Information in Wireless UplinkNetworks with Partial  Observations",
    "abstract": "We consider a wireless uplink network consisting of multiple end devices and\nan access point (AP). Each device monitors a physical process with stochastic\narrival of status updates and sends these updates to the AP over a shared\nchannel. The AP aims to schedule the transmissions of these devices to optimize\nthe network-wide information freshness, quantified by the Age of Information\n(AoI) metric. Due to the stochastic arrival of the status updates at the\ndevices, the AP only has partial observations of system times of the latest\nstatus updates at the devices when making scheduling decisions. We formulate\nsuch a decision-making problem as a belief Markov Decision Process\n(belief-MDP). The belief-MDP in its original form is difficult to solve as the\ndimension of its states can go to infinity and its belief space is uncountable.\nBy leveraging the properties of the status update arrival (i.e., Bernoulli)\nprocesses, we manage to simplify the feasible states of the belief-MDP to\ntwo-dimensional vectors. Built on that, we devise a low-complexity scheduling\npolicy. We derive upper bounds for the AoI performance of the low-complexity\npolicy and analyze the performance guarantee by comparing its performance with\na universal lower bound. Numerical results validate our analyses.",
    "descriptor": "\nComments: Submitted for possible IEEE publication\n",
    "authors": [
      "Jingwei Liu",
      "Rui Zhang",
      "Aoyu Gong",
      "He Chen"
    ],
    "subjectives": [
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2202.03152"
  },
  {
    "id": "arXiv:2202.03153",
    "title": "Approaches to Artificial General Intelligence: An Analysis",
    "abstract": "This paper is an analysis of the different methods proposed to achieve AGI,\nincluding Human Brain Emulation, AIXI and Integrated Cognitive Architecture.\nFirst, the definition of AGI as used in this paper has been defined, and its\nrequirements have been stated. For each proposed method mentioned, the method\nin question was summarized and its key processes were detailed, showcasing how\nit functioned. Then, each method listed was analyzed, taking various factors\ninto consideration, such as technological requirements, computational ability,\nand adequacy to the requirements. It was concluded that while there are various\nmethods to achieve AGI that could work, such as Human Brain Emulation and\nIntegrated Cognitive Architectures, the most promising method to achieve AGI is\nIntegrated Cognitive Architectures. This is because Human Brain Emulation was\nfound to require scanning technologies that will most likely not be available\nuntil the 2030s, making it unlikely to be created before then. Moreover,\nIntegrated Cognitive Architectures has reduced computational requirements and a\nsuitable functionality for General Intelligence, making it the most likely way\nto achieve AGI.",
    "descriptor": "",
    "authors": [
      "Soumil Rathi"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.03153"
  },
  {
    "id": "arXiv:2202.03155",
    "title": "Existence and perception as the basis of AGI (Artificial General  Intelligence)",
    "abstract": "As is known, AGI (Artificial General Intelligence), unlike AI, should operate\nwith meanings. And that's what distinguishes it from AI. Any successful AI\nimplementations (playing chess, unmanned driving, face recognition etc.) do not\noperate with the meanings of the processed objects in any way and do not\nrecognize the meaning. And they don't need to. But for AGI, which emulates\nhuman thinking, this ability is crucial. Numerous attempts to define the\nconcept of \"meaning\" have one very significant drawback - all such definitions\nare not strict and formalized, so they cannot be programmed. The meaning search\nprocedure should use a formalized description of its existence and possible\nforms of its perception. For the practical implementation of AGI, it is\nnecessary to develop such \"ready-to-code\" descriptions in the context of their\nuse for processing the related cognitive concepts of \"meaning\" and \"knowledge\".\nAn attempt to formalize the definition of such concepts is made in this\narticle.",
    "descriptor": "\nComments: 11 pages\n",
    "authors": [
      "Victor V. Senkevich"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2202.03155"
  },
  {
    "id": "arXiv:2202.03157",
    "title": "T-Plots: A Novel Approach to Network Design",
    "abstract": "It is accepted wisdom that changes in the traffic matrix entail capacity\nover-provisioning, but there is no simple measure of just how much\nover-provisioning can buy. In this Thesis, we aim to provide the network\ndesigner with a simple view of the network robustness to traffic matrix\nchanges. We first present the Traffic Load Distribution Plots, or T-Plots, a\nclass of plots illustrating the percentage of traffic matrices that can be\nserviced as a function of the capacity over-provisioning. For instance, from a\nsimple look at their T- Plots, network designers can guarantee that their\nnetwork services all admissible traffic matrices, or 99% of permutation traffic\nmatrices, or all traffic matrices with ingress/egress load at most half the\nmaximum. We further show that, unfortunately, in the general case plotting\nT-Plots is #P-Complete, i.e., that it is impossible to plot a T-plot in a\npolynomial time by the noon tools. However, we show that T-Plots can sometimes\nbe closely modeled as Gaussian, thus only using two values (mean and variance)\nto quantify the robustness of a capacity allocation to traffic matrix changes.\nWe further utilize these Gaussian T-Plots to provide a more robust capacity\nallocation. Finally, we demonstrate the benefits of using T-Plots by showing\nresults of extensive Monte Carlo simulations in a real backbone network. This\nThesis was submitted in 2007. Since then, the results that appeared in it were\napplied in various networking environments. In this newer version, we revisit\nthe results 13 years later and explain their relevance to state-of-the-art\nproblems in network design.",
    "descriptor": "\nComments: M.Sc. Thesis (Redux)\n",
    "authors": [
      "Itamar Cohen"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2202.03157"
  },
  {
    "id": "arXiv:2202.03163",
    "title": "Patch-Based Stochastic Attention for Image Editing",
    "abstract": "Attention mechanisms have become of crucial importance in deep learning in\nrecent years. These non-local operations, which are similar to traditional\npatch-based methods in image processing, complement local convolutions.\nHowever, computing the full attention matrix is an expensive step with a heavy\nmemory and computational load. These limitations curb network architectures and\nperformances, in particular for the case of high resolution images. We propose\nan efficient attention layer based on the stochastic algorithm PatchMatch,\nwhich is used for determining approximate nearest neighbors. We refer to our\nproposed layer as a \"Patch-based Stochastic Attention Layer\" (PSAL).\nFurthermore, we propose different approaches, based on patch aggregation, to\nensure the differentiability of PSAL, thus allowing end-to-end training of any\nnetwork containing our layer. PSAL has a small memory footprint and can\ntherefore scale to high resolution images. It maintains this footprint without\nsacrificing spatial precision and globality of the nearest neighbours, which\nmeans that it can be easily inserted in any level of a deep architecture, even\nin shallower levels. We demonstrate the usefulness of PSAL on several image\nediting tasks, such as image inpainting and image colorization.",
    "descriptor": "",
    "authors": [
      "Nicolas Cherel",
      "Andr\u00e9s Almansa",
      "Yann Gousseau",
      "Alasdair Newson"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.03163"
  },
  {
    "id": "arXiv:2202.03164",
    "title": "Conversational Agents: Theory and Applications",
    "abstract": "In this chapter, we provide a review of conversational agents (CAs),\ndiscussing chatbots, intended for casual conversation with a user, as well as\ntask-oriented agents that generally engage in discussions intended to reach one\nor several specific goals, often (but not always) within a specific domain. We\nalso consider the concept of embodied conversational agents, briefly reviewing\naspects such as character animation and speech processing. The many different\napproaches for representing dialogue in CAs are discussed in some detail, along\nwith methods for evaluating such agents, emphasizing the important topics of\naccountability and interpretability. A brief historical overview is given,\nfollowed by an extensive overview of various applications, especially in the\nfields of health and education. We end the chapter by discussing benefits and\npotential risks regarding the societal impact of current and future CA\ntechnology.",
    "descriptor": "\nComments: preprint of a chapter to appear in Handbook of Computer Learning and Intelligence - Volume 1\n",
    "authors": [
      "Mattias Wahde",
      "Marco Virgolin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.03164"
  },
  {
    "id": "arXiv:2202.03167",
    "title": "Bayesian Linear Bandits for Large-Scale Recommender Systems",
    "abstract": "Potentially, taking advantage of available side information boosts the\nperformance of recommender systems; nevertheless, with the rise of big data,\nthe side information has often several dimensions. Hence, it is imperative to\ndevelop decision-making algorithms that can cope with such a high-dimensional\ncontext in real-time. That is especially challenging when the decision-maker\nhas a variety of items to recommend. In this paper, we build upon the linear\ncontextual multi-armed bandit framework to address this problem. We develop a\ndecision-making policy for a linear bandit problem with high-dimensional\ncontext vectors and several arms. Our policy employs Thompson sampling and\nfeeds it with reduced context vectors, where the dimensionality reduction\nfollows by random projection. Our proposed recommender system follows this\npolicy to learn online the item preferences of users while keeping its runtime\nas low as possible. We prove a regret bound that scales as a factor of the\nreduced dimension instead of the original one. For numerical evaluation, we use\nour algorithm to build a recommender system and apply it to real-world\ndatasets. The theoretical and numerical results demonstrate the effectiveness\nof our proposed algorithm compared to the state-of-the-art in terms of\ncomputational complexity and regret performance.",
    "descriptor": "\nComments: 10 pages, 2 figures\n",
    "authors": [
      "Saeed Ghoorchian",
      "Setareh Maghsudi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.03167"
  },
  {
    "id": "arXiv:2202.03169",
    "title": "CITRIS: Causal Identifiability from Temporal Intervened Sequences",
    "abstract": "Understanding the latent causal factors of a dynamical system from visual\nobservations is a crucial step towards agents reasoning in complex\nenvironments. In this paper, we propose CITRIS, a variational autoencoder\nframework that learns causal representations from temporal sequences of images\nin which underlying causal factors have possibly been intervened upon. In\ncontrast to the recent literature, CITRIS exploits temporality and observing\nintervention targets to identify scalar and multidimensional causal factors,\nsuch as 3D rotation angles. Furthermore, by introducing a normalizing flow,\nCITRIS can be easily extended to leverage and disentangle representations\nobtained by already pretrained autoencoders. Extending previous results on\nscalar causal factors, we prove identifiability in a more general setting, in\nwhich only some components of a causal factor are affected by interventions. In\nexperiments on 3D rendered image sequences, CITRIS outperforms previous methods\non recovering the underlying causal variables. Moreover, using pretrained\nautoencoders, CITRIS can even generalize to unseen instantiations of causal\nfactors, opening future research areas in sim-to-real generalization for causal\nrepresentation learning.",
    "descriptor": "\nComments: 46 pages\n",
    "authors": [
      "Phillip Lippe",
      "Sara Magliacane",
      "Sindy L\u00f6we",
      "Yuki M. Asano",
      "Taco Cohen",
      "Efstratios Gavves"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2202.03169"
  },
  {
    "id": "arXiv:2202.03172",
    "title": "The 6-Ds of Creating AI-Enabled Systems",
    "abstract": "We are entering our tenth year of the current Artificial Intelligence (AI)\nspring, and, as with previous AI hype cycles, the threat of an AI winter looms.\nAI winters occurred because of ineffective approaches towards navigating the\ntechnology valley of death. The 6-D framework provides an end-to-end framework\nto successfully navigate this challenge. The 6-D framework starts with problem\ndecomposition to identify potential AI solutions, and ends with considerations\nfor deployment of AI-enabled systems. Each component of the 6-D framework and a\nprecision medicine use case is described in this paper.",
    "descriptor": "",
    "authors": [
      "John Piorkowski"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.03172"
  },
  {
    "id": "arXiv:2202.03173",
    "title": "Towards Loosely-Coupling Knowledge Graph Embeddings and Ontology-based  Reasoning",
    "abstract": "Knowledge graph completion (a.k.a.~link prediction), i.e.,~the task of\ninferring missing information from knowledge graphs, is a widely used task in\nmany applications, such as product recommendation and question answering. The\nstate-of-the-art approaches of knowledge graph embeddings and/or rule mining\nand reasoning are data-driven and, thus, solely based on the information the\ninput knowledge graph contains. This leads to unsatisfactory prediction results\nwhich make such solutions inapplicable to crucial domains such as healthcare.\nTo further enhance the accuracy of knowledge graph completion we propose to\nloosely-couple the data-driven power of knowledge graph embeddings with\ndomain-specific reasoning stemming from experts or entailment regimes (e.g.,\nOWL2). In this way, we not only enhance the prediction accuracy with domain\nknowledge that may not be included in the input knowledge graph but also allow\nusers to plugin their own knowledge graph embedding and reasoning method. Our\ninitial results show that we enhance the MRR accuracy of vanilla knowledge\ngraph embeddings by up to 3x and outperform hybrid solutions that combine\nknowledge graph embeddings with rule mining and reasoning up to 3.5x MRR.",
    "descriptor": "",
    "authors": [
      "Zoi Kaoudi",
      "Abelardo Carlos Martinez Lorenzo",
      "Volker Markl"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.03173"
  },
  {
    "id": "arXiv:2202.03176",
    "title": "Field-of-View IoU for Object Detection in 360\u00b0 Images",
    "abstract": "360{\\deg} cameras have gained popularity over the last few years. In this\npaper, we propose two fundamental techniques -- Field-of-View IoU (FoV-IoU) and\n360Augmentation for object detection in 360{\\deg} images. Although most object\ndetection neural networks designed for the perspective images are applicable to\n360{\\deg} images in equirectangular projection (ERP) format, their performance\ndeteriorates owing to the distortion in ERP images. Our method can be readily\nintegrated with existing perspective object detectors and significantly\nimproves the performance. The FoV-IoU computes the intersection-over-union of\ntwo Field-of-View bounding boxes in a spherical image which could be used for\ntraining, inference, and evaluation while 360Augmentation is a data\naugmentation technique specific to 360{\\deg} object detection task which\nrandomly rotates a spherical image and solves the bias due to the\nsphere-to-plane projection. We conduct extensive experiments on the 360indoor\ndataset with different types of perspective object detectors and show the\nconsistent effectiveness of our method.",
    "descriptor": "",
    "authors": [
      "Miao Cao",
      "Satoshi Ikehata",
      "Kiyoharu Aizawa"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.03176"
  },
  {
    "id": "arXiv:2202.03177",
    "title": "On discretization of continuous-time LPV control solutions",
    "abstract": "In recent years, the Linear Parameter-Varying (LPV) framework has become\nincreasingly useful for analysis and control of time-varying systems.\nGenerally, LPV control synthesis is performed in the continuous-time (CT)\ndomain due to significantly less complex stability and performance\nrequirements, see \\cite{zhou1998essentials}. The main complication of CT\nsynthesis approaches is implementation of the CT LPV control solutions on\nphysical hardware. In literature, several discretization methods have been\nexplored for LPV systems, see \\cite{Tothbook}. However, these approaches\nnecessitate for heavy nonlinear operations introduced by the discretization of\nthese time-varying matrices, thereby severely limiting implementation\ncapabilities of the CT LPV control solutions. Alternatively, the $w'$\ndiscretization approach illustrates to be a promising research direction for\nLPV systems, since it allows for preservation of the CT system matrices in the\nLTI case, see \\cite{whitbeck1978digital}. Moreover, this manuscript aims at\nextending the $w'$ discretization approach towards LPV systems, such that\nimplementation of CT LPV control solutions on physical hardware is simplified.",
    "descriptor": "\nComments: 1 page, 1 Figure\n",
    "authors": [
      "Yorick Broens",
      "Hans Butler",
      "Roland T\u00f3th"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.03177"
  },
  {
    "id": "arXiv:2202.03179",
    "title": "A Tensor Based Regression Approach for Human Motion Prediction",
    "abstract": "Collaborative robotic systems will be a key enabling technology for current\nand future industrial applications. The main aspect of such applications is to\nguarantee safety for humans. To detect hazardous situations, current\ncommercially available robotic systems rely on direct physical contact to the\nco-working person. To further advance this technology, there are multiple\nefforts to develop predictive capabilities for such systems. Using motion\ntracking sensors and pose estimation systems combined with adequate predictive\nmodels, potential episodes of hazardous collisions between humans and robots\ncan be predicted. Based on the provided predictive information, the robotic\nsystem can avoid physical contact by adjusting speed or position. A potential\napproach for such systems is to perform human motion prediction with machine\nlearning methods like Artificial Neural Networks. In our approach, the motion\npatterns of past seconds are used to predict future ones by applying a linear\nTensor-on-Tensor regression model, selected according to a similarity measure\nbetween motion sequences obtained by Dynamic TimeWarping. For test and\nvalidation of our proposed approach, industrial pseudo assembly tasks were\nrecorded with a motion capture system, providing unique traceable Cartesian\ncoordinates $(x, y, z)$ for each human joint. The prediction of repetitive\nhuman motions associated with assembly tasks, whose data vary significantly in\nlength and have highly correlated variables, has been achieved in real time.",
    "descriptor": "",
    "authors": [
      "Lorena Gril",
      "Philipp Wedenig",
      "Chris Torkar",
      "Ulrike Kleb"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.03179"
  },
  {
    "id": "arXiv:2202.03183",
    "title": "TransFollower: Long-Sequence Car-Following Trajectory Prediction through  Transformer",
    "abstract": "Car-following refers to a control process in which the following vehicle (FV)\ntries to keep a safe distance between itself and the lead vehicle (LV) by\nadjusting its acceleration in response to the actions of the vehicle ahead. The\ncorresponding car-following models, which describe how one vehicle follows\nanother vehicle in the traffic flow, form the cornerstone for microscopic\ntraffic simulation and intelligent vehicle development. One major motivation of\ncar-following models is to replicate human drivers' longitudinal driving\ntrajectories. To model the long-term dependency of future actions on historical\ndriving situations, we developed a long-sequence car-following trajectory\nprediction model based on the attention-based Transformer model. The model\nfollows a general format of encoder-decoder architecture. The encoder takes\nhistorical speed and spacing data as inputs and forms a mixed representation of\nhistorical driving context using multi-head self-attention. The decoder takes\nthe future LV speed profile as input and outputs the predicted future FV speed\nprofile in a generative way (instead of an auto-regressive way, avoiding\ncompounding errors). Through cross-attention between encoder and decoder, the\ndecoder learns to build a connection between historical driving and future LV\nspeed, based on which a prediction of future FV speed can be obtained. We train\nand test our model with 112,597 real-world car-following events extracted from\nthe Shanghai Naturalistic Driving Study (SH-NDS). Results show that the model\noutperforms the traditional intelligent driver model (IDM), a fully connected\nneural network model, and a long short-term memory (LSTM) based model in terms\nof long-sequence trajectory prediction accuracy. We also visualized the\nself-attention and cross-attention heatmaps to explain how the model derives\nits predictions.",
    "descriptor": "",
    "authors": [
      "Meixin Zhu",
      "Simon S. Du",
      "Xuesong Wang",
      "Yang",
      "Ziyuan Pu",
      "Yinhai Wang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.03183"
  },
  {
    "id": "arXiv:2202.03186",
    "title": "ALDER: Unlocking blockchain performance by multiplexing consensus  protocols",
    "abstract": "Most of today's online services (e.g., social networks, search engines,\nmarket places) are centralized, which is recognized as unsatisfactory by a\nmajority of users for various reasons (e.g., centralized governance,\ncensorship, loss of control over personal data). Blockchain technologies\npromise a new Web revolution (Web 3.0) through the decentralization of online\nservices. However, one of the key limitations for this revolution to happen at\na planetary scale is the poor performance of today's blockchains. We propose in\nthis paper ALDER, a solution for unlocking the performance of off-the-shelf\nleader-based blockchains by multiplexing their consensus protocol. Our solution\nleverages the existence of multiple potential leaders to alleviate the\nbottleneck that exists at different levels of consensus protocols. To\nillustrate the benefits it brings to Blockchain performance, we apply ALDER to\nthree representative blockchains, namely Algorand (Proof-of-Stake), RapidChain\n(Sharding-based) and Bitcoin (Proof-of-Work). Our evaluation, involving up to\n10,000 nodes deployed on 100 physical machines, shows that using ALDER can\nprovide up to a 300% improvement in both throughput and latency reduction.",
    "descriptor": "\nComments: 11 pages, 13 figures. arXiv admin note: text overlap with arXiv:2104.15063\n",
    "authors": [
      "Kadir Korkmaz",
      "Joachim Bruneau-Queyreix",
      "Sonia Ben Mokthar",
      "Laurent R\u00e9veill\u00e8re"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2202.03186"
  },
  {
    "id": "arXiv:2202.03187",
    "title": "Eager Functions as Processes (long version)",
    "abstract": "We study Milner's encoding of the call-by-value $\\lambda$-calculus into the\n$\\pi$-calculus. We show that, by tuning the encoding to two subcalculi of the\n$\\pi$-calculus (Internal $\\pi$ and Asynchronous Local $\\pi$), the equivalence\non $\\lambda$-terms induced by the encoding coincides with Lassen's eager\nnormalform bisimilarity, extended to handle $\\eta$-equality. As behavioural\nequivalence in the $\\pi$-calculus we consider contextual equivalence and barbed\ncongruence. We also extend the results to preorders. A crucial technical\ningredient in the proofs is the recently-introduced technique of unique\nsolutions of equations, further developed in this paper. In this respect, the\npaper also intends to be an extended case study on the applicability and\nexpressiveness of the technique.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2112.02863\n",
    "authors": [
      "Adrien Durier",
      "Daniel Hirschkoff",
      "Davide Sangiorgi"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2202.03187"
  },
  {
    "id": "arXiv:2202.03188",
    "title": "Knowledge-Integrated Informed AI for National Security",
    "abstract": "The state of artificial intelligence technology has a rich history that dates\nback decades and includes two fall-outs before the explosive resurgence of\ntoday, which is credited largely to data-driven techniques. While AI technology\nhas and continues to become increasingly mainstream with impact across domains\nand industries, it's not without several drawbacks, weaknesses, and potential\nto cause undesired effects. AI techniques are numerous with many approaches and\nvariants, but they can be classified simply based on the degree of knowledge\nthey capture and how much data they require; two broad categories emerge as\nprominent across AI to date: (1) techniques that are primarily, and often\nsolely, data-driven while leveraging little to no knowledge and (2) techniques\nthat primarily leverage knowledge and depend less on data. Now, a third\ncategory is starting to emerge that leverages both data and knowledge, that\nsome refer to as \"informed AI.\" This third category can be a game changer\nwithin the national security domain where there is ample scientific and\ndomain-specific knowledge that stands ready to be leveraged, and where purely\ndata-driven AI can lead to serious unwanted consequences.\nThis report shares findings from a thorough exploration of AI approaches that\nexploit data as well as principled and/or practical knowledge, which we refer\nto as \"knowledge-integrated informed AI.\" Specifically, we review illuminating\nexamples of knowledge integrated in deep learning and reinforcement learning\npipelines, taking note of the performance gains they provide. We also discuss\nan apparent trade space across variants of knowledge-integrated informed AI,\nalong with observed and prominent issues that suggest worthwhile future\nresearch directions. Most importantly, this report suggests how the advantages\nof knowledge-integrated informed AI stand to benefit the national security\ndomain.",
    "descriptor": "",
    "authors": [
      "Anu K. Myne",
      "Kevin J. Leahy",
      "Ryan J. Soklaski"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.03188"
  },
  {
    "id": "arXiv:2202.03189",
    "title": "Optical skin: Sensor-integration-free multimodal flexible sensing",
    "abstract": "The biological skin enables animals to sense various stimuli. Extensive\nefforts have been made recently to develop smart skin-like sensors to extend\nthe capabilities of biological skins; however, simultaneous sensing of several\ntypes of stimuli in a large area remains challenging because this requires\nlarge-scale sensor integration with numerous wire connections. We propose a\nsimple, highly sensitive, and multimodal sensing approach, which does not\nrequire integrating multiple sensors. The proposed approach is based on an\noptical interference technique, which can encode the information of various\nstimuli as a spatial pattern. In contrast to the existing approach, the\nproposed approach, combined with a deep neural network, enables us to freely\nselect the sensing mode according to our purpose. As a key example, we\ndemonstrate simultaneous sensing mode of three different physical quantities,\ncontact force, contact location, and temperature, using a single soft material\nwithout requiring complex integration. Another unique property of the proposed\napproach is spatially continuous sensing with ultrahigh resolution of few tens\nof micrometers, which enables identifying the shape of the object in contact.\nFurthermore, we present a haptic soft device for a human-machine interface. The\nproposed approach encourages the development of high-performance optical skins.",
    "descriptor": "\nComments: 13 pages, 11 figures\n",
    "authors": [
      "Sho Shimadera",
      "Kei Kitagawa",
      "Koyo Sagehashi",
      "Tomoaki Niiyama",
      "Satoshi Sunada"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)",
      "Applied Physics (physics.app-ph)",
      "Optics (physics.optics)"
    ],
    "url": "https://arxiv.org/abs/2202.03189"
  },
  {
    "id": "arXiv:2202.03190",
    "title": "Efficient Autoprecoder-based deep learning for massive MU-MIMO Downlink  under PA Non-Linearities",
    "abstract": "This paper introduces a new efficient autoprecoder (AP) based deep learning\napproach for massive multiple-input multiple-output (mMIMO) downlink systems in\nwhich the base station is equipped with a large number of antennas with\nenergy-efficient power amplifiers (PAs) and serves multiple user terminals. We\npresent AP-mMIMO, a new method that jointly eliminates the multiuser\ninterference and compensates the severe nonlinear (NL) PA distortions. Unlike\nprevious works, AP-mMIMO has a low computational complexity, making it suitable\nfor a global energy-efficient system. Specifically, we aim to design the\nPA-aware precoder and the receive decoder by leveraging the concept of\nautoprecoder, whereas the end-to-end massive multiuser (MU)-MIMO downlink is\ndesigned using a deep neural network (NN). Most importantly, the proposed\nAP-mMIMO is suited for the varying block fading channel scenario. To deal with\nsuch scenarios, we consider a two-stage precoding scheme: 1) a NN-precoder is\nused to address the PA non-linearities and 2) a linear precoder is used to\nsuppress the multiuser interference. The NN-precoder and the receive decoder\nare trained off-line and when the channel varies, only the linear precoder\nchanges on-line. This latter is designed by using the widely used zero-forcing\nprecoding scheme or its lowcomplexity version based on matrix polynomials.\nNumerical simulations show that the proposed AP-mMIMO approach achieves\ncompetitive performance with a significantly lower complexity compared to\nexisting literature. Index Terms-multiuser (MU) precoding, massive\nmultipleinput multiple-output (MIMO), energy-efficiency, hardware impairment,\npower amplifier (PA) nonlinearities, autoprecoder, deep learning, neural\nnetwork (NN)",
    "descriptor": "",
    "authors": [
      "Xinying Cheng",
      "Rafik Zayani",
      "Marin Ferecatu",
      "Nicolas Audebert"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2202.03190"
  },
  {
    "id": "arXiv:2202.03192",
    "title": "Reward is not enough: can we liberate AI from the reinforcement learning  paradigm?",
    "abstract": "I present arguments against the hypothesis put forward by Silver, Singh,\nPrecup, and Sutton (\nhttps://www.sciencedirect.com/science/article/pii/S0004370221000862 ) : reward\nmaximization is not enough to explain many activities associated with natural\nand artificial intelligence including knowledge, learning, perception, social\nintelligence, evolution, language, generalisation and imitation. I show such\nreductio ad lucrum has its intellectual origins in the political economy of\nHomo economicus and substantially overlaps with the radical version of\nbehaviourism. I show why the reinforcement learning paradigm, despite its\ndemonstrable usefulness in some practical application, is an incomplete\nframework for intelligence -- natural and artificial. Complexities of\nintelligent behaviour are not simply second-order complications on top of\nreward maximisation. This fact has profound implications for the development of\npractically usable, smart, safe and robust artificially intelligent agents.",
    "descriptor": "\nComments: 17 pages, 1 figure\n",
    "authors": [
      "Vacslav Glukhov"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.03192"
  },
  {
    "id": "arXiv:2202.03193",
    "title": "Network Resource Allocation Strategy Based on Deep Reinforcement  Learning",
    "abstract": "The traditional Internet has encountered a bottleneck in allocating network\nresources for emerging technology needs. Network virtualization (NV) technology\nas a future network architecture, the virtual network embedding (VNE) algorithm\nit supports shows great potential in solving resource allocation problems.\nCombined with the efficient machine learning (ML) algorithm, a neural network\nmodel close to the substrate network environment is constructed to train the\nreinforcement learning agent. This paper proposes a two-stage VNE algorithm\nbased on deep reinforcement learning (DRL) (TS-DRL-VNE) for the problem that\nthe mapping result of existing heuristic algorithm is easy to converge to the\nlocal optimal solution. For the problem that the existing VNE algorithm based\non ML often ignores the importance of substrate network representation and\ntraining mode, a DRL VNE algorithm based on full attribute matrix (FAM-DRL-VNE)\nis proposed. In view of the problem that the existing VNE algorithm often\nignores the underlying resource changes between virtual network requests, a DRL\nVNE algorithm based on matrix perturbation theory (MPT-DRL-VNE) is proposed.\nExperimental results show that the above algorithm is superior to other\nalgorithms.",
    "descriptor": "",
    "authors": [
      "Shidong Zhang",
      "Chao Wang",
      "Junsan Zhang",
      "Youxiang Duan",
      "Xinhong You",
      "Peiying Zhang"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2202.03193"
  },
  {
    "id": "arXiv:2202.03195",
    "title": "More is Better (Mostly): On the Backdoor Attacks in Federated Graph  Neural Networks",
    "abstract": "Graph Neural Networks (GNNs) are a class of deep learning-based methods for\nprocessing graph domain information. GNNs have recently become a widely used\ngraph analysis method due to their superior ability to learn representations\nfor complex graph data. However, due to privacy concerns and regulation\nrestrictions, centralized GNNs can be difficult to apply to data-sensitive\nscenarios. Federated learning (FL) is an emerging technology developed for\nprivacy-preserving settings when several parties need to train a shared global\nmodel collaboratively. Although many research works have applied FL to train\nGNNs (Federated GNNs), there is no research on their robustness to backdoor\nattacks.\nThis paper bridges this gap by conducting two types of backdoor attacks in\nFederated GNNs: centralized backdoor attacks (CBA) and distributed backdoor\nattacks (DBA). CBA is conducted by embedding the same global trigger during\ntraining for every malicious party, while DBA is conducted by decomposing a\nglobal trigger into separate local triggers and embedding them into the\ntraining dataset of different malicious parties, respectively. Our experiments\nshow that the DBA attack success rate is higher than CBA in almost all\nevaluated cases, while rarely, the DBA attack performance is close to CBA. For\nCBA, the attack success rate of all local triggers is similar to the global\ntrigger even if the training set of the adversarial party is embedded with the\nglobal trigger. To further explore the properties of two backdoor attacks in\nFederated GNNs, we evaluate the attack performance for different trigger sizes,\npoisoning intensities, and trigger densities, with trigger density being the\nmost influential.",
    "descriptor": "\nComments: 18 pages, 11 figures\n",
    "authors": [
      "Jing Xu",
      "Rui Wang",
      "Kaitai Liang",
      "Stjepan Picek"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.03195"
  },
  {
    "id": "arXiv:2202.03196",
    "title": "A Conditional Perspective on the Logic of Iterated Belief Contraction",
    "abstract": "In this article, we consider iteration principles for contraction, with the\ngoal of identifying properties for contractions that respect conditional\nbeliefs. Therefore, we investigate and evaluate four groups of iteration\nprinciples for contraction which consider the dynamics of conditional beliefs.\nFor all these principles, we provide semantic characterization theorems and\nprovide formulations by postulates which highlight how the change of beliefs\nand of conditional beliefs is constrained, whenever that is possible. The first\ngroup is similar to the syntactic Darwiche-Pearl postulates. As a second group,\nwe consider semantic postulates for iteration of contraction by Chopra, Ghose,\nMeyer and Wong, and by Konieczny and Pino P\\'erez, respectively, and we provide\nnovel syntactic counterparts. Third, we propose a contraction analogue of the\nindependence condition by Jin and Thielscher. For the fourth group, we consider\nnatural and moderate contraction by Nayak. Methodically, we make use of\nconditionals for contractions, so-called contractionals and furthermore, we\npropose and employ the novel notion of $ \\alpha $-equivalence for formulating\nsome of the new postulates.",
    "descriptor": "\nComments: This is a largely extended version of the following conference paper: Kai Sauerwald, Gabriele Kern-Isberner, Christoph Beierle: A Conditional Perspective for Iterated Belief Contraction. ECAI 2020: 889-896 this https URL (see also arXiv:1911.08833 )\n",
    "authors": [
      "Kai Sauerwald",
      "Gabriele Kern-Isberner",
      "Christoph Beierle"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.03196"
  },
  {
    "id": "arXiv:2202.03199",
    "title": "AI Research Associate for Early-Stage Scientific Discovery",
    "abstract": "Artificial intelligence (AI) has been increasingly applied in scientific\nactivities for decades; however, it is still far from an insightful and\ntrustworthy collaborator in the scientific process. Most existing AI methods\nare either too simplistic to be useful in real problems faced by scientists or\ntoo domain-specialized (even dogmatized), stifling transformative discoveries\nor paradigm shifts. We present an AI research associate for early-stage\nscientific discovery based on (a) a novel minimally-biased ontology for\nphysics-based modeling that is context-aware, interpretable, and generalizable\nacross classical and relativistic physics; (b) automatic search for viable and\nparsimonious hypotheses, represented at a high-level (via domain-agnostic\nconstructs) with built-in invariants, e.g., postulated forms of conservation\nprinciples implied by a presupposed spacetime topology; and (c) automatic\ncompilation of the enumerated hypotheses to domain-specific, interpretable, and\ntrainable/testable tensor-based computation graphs to learn phenomenological\nrelations, e.g., constitutive or material laws, from sparse (and possibly\nnoisy) data sets.",
    "descriptor": "\nComments: Paper #203\n",
    "authors": [
      "Morad Behandish",
      "John Maxwell III",
      "Johan de Kleer"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Symbolic Computation (cs.SC)"
    ],
    "url": "https://arxiv.org/abs/2202.03199"
  },
  {
    "id": "arXiv:2202.03202",
    "title": "One-Year In: COVID-19 Research at the International Level in CORD-19  Data",
    "abstract": "The appearance of a novel coronavirus in late 2019 radically changed the\ncommunity of researchers working on coronaviruses since the 2002 SARS epidemic.\nIn 2020, coronavirus-related publications grew by 20 times over the previous\ntwo years, with 130,000 more researchers publishing on related topics. The\nUnited States, the United Kingdom and China led dozens of nations working on\ncoronavirus prior to the pandemic, but leadership consolidated among these\nthree nations in 2020, which collectively accounted for 50% of all papers,\ngarnering well more than 60% of citations. China took an early lead on COVID-19\nresearch, but dropped rapidly in production and international participation\nthrough the year. Europe showed an opposite pattern, beginning slowly in\npublications but growing in contributions during the year. The share of\ninternationally collaborative publications dropped from pre-pandemic rates;\nsingle-authored publications grew. For all nations, including China, the number\nof publications about COVID track closely with the outbreak of COVID-19 cases.\nLower-income nations participate very little in COVID-19 research in 2020.\nTopic maps of internationally collaborative work show the rise of patient care\nand public health clusters, two topics that were largely absent from\ncoronavirus research in the two years prior to 2020. Findings are consistent\nwith global science as a self-organizing system operating on a reputation-based\ndynamic.",
    "descriptor": "\nComments: 39 pages, 8 figures, Appendix\n",
    "authors": [
      "Caroline S. Wagner",
      "Xiaojing Cai",
      "Yi Zhang",
      "Caroline V. Fry"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2202.03202"
  },
  {
    "id": "arXiv:2202.03206",
    "title": "Recent Trends in 2D Object Detection and Applications in Video Event  Recognition",
    "abstract": "Object detection serves as a significant step in improving performance of\ncomplex downstream computer vision tasks. It has been extensively studied for\nmany years now and current state-of-the-art 2D object detection techniques\nproffer superlative results even in complex images. In this chapter, we discuss\nthe geometry-based pioneering works in object detection, followed by the recent\nbreakthroughs that employ deep learning. Some of these use a monolithic\narchitecture that takes a RGB image as input and passes it to a feed-forward\nConvNet or vision Transformer. These methods, thereby predict class-probability\nand bounding-box coordinates, all in a single unified pipeline. Two-stage\narchitectures on the other hand, first generate region proposals and then feed\nit to a CNN to extract features and predict object category and bounding-box.\nWe also elaborate upon the applications of object detection in video event\nrecognition, to achieve better fine-grained video classification performance.\nFurther, we highlight recent datasets for 2D object detection both in images\nand videos, and present a comparative performance summary of various\nstate-of-the-art object detection techniques.",
    "descriptor": "\nComments: Book chapter: P Jana and PP Mohanta, Recent Trends in 2D Object Detection and Applications in Video Event Recognition, published in Advancement of Deep Learning and its Applications in Object Detection and Recognition, edited by R N Mir et al, 2022, published by River Publishers\n",
    "authors": [
      "Prithwish Jana",
      "Partha Pratim Mohanta"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.03206"
  },
  {
    "id": "arXiv:2202.03207",
    "title": "Almost Optimal Proper Learning and Testing Polynomials",
    "abstract": "We give the first almost optimal polynomial-time proper learning algorithm of\nBoolean sparse multivariate polynomial under the uniform distribution. For\n$s$-sparse polynomial over $n$ variables and $\\epsilon=1/s^\\beta$, $\\beta>1$,\nour algorithm makes $$q_U=\\left(\\frac{s}{\\epsilon}\\right)^{\\frac{\\log\n\\beta}{\\beta}+O(\\frac{1}{\\beta})}+ \\tilde\nO\\left(s\\right)\\left(\\log\\frac{1}{\\epsilon}\\right)\\log n$$ queries. Notice that\nour query complexity is sublinear in $1/\\epsilon$ and almost linear in $s$. All\nprevious algorithms have query complexity at least quadratic in $s$ and linear\nin $1/\\epsilon$.\nWe then prove the almost tight lower bound\n$$q_L=\\left(\\frac{s}{\\epsilon}\\right)^{\\frac{\\log\n\\beta}{\\beta}+\\Omega(\\frac{1}{\\beta})}+\n\\Omega\\left(s\\right)\\left(\\log\\frac{1}{\\epsilon}\\right)\\log n,$$\nApplying the reduction in~\\cite{Bshouty19b} with the above algorithm, we give\nthe first almost optimal polynomial-time tester for $s$-sparse polynomial. Our\ntester, for $\\beta>3.404$, makes $$\\tilde O\\left(\\frac{s}{\\epsilon}\\right)$$\nqueries.",
    "descriptor": "",
    "authors": [
      "Nader H. Bshouty"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.03207"
  },
  {
    "id": "arXiv:2202.03208",
    "title": "Elastic waveform inversion in the frequency domain for an application in  mechanized tunneling",
    "abstract": "The excavation process in mechanized tunneling can be improved by\nreconnaissance of the geology ahead. A nondestructive exploration can be\nachieved in means of seismic imaging. A full waveform inversion approach, which\nworks in the frequency domain, is investigated for the application in\ntunneling. The approach tries to minimize the difference of seismic records\nfrom field observations and from a discretized ground model by changing the\nground properties. The final ground model might be a representation of the\ngeology. The used elastic wave modeling approach is described as well as the\napplication of convolutional perfectly matched layers. The proposed inversion\nscheme uses the discrete adjoint gradient method, a multi-scale approach as\nwell as the L-BFGS method. Numerical parameters are identified as well as a\nvalidation of the forward wave modeling approach is performed in advance to the\ninversion of every example. Two-dimensional blind tests with two different\nground scenarios and with two different source and receiver station\nconfigurations are performed and analyzed, where only the seismic records, the\nsource functions and the ambient ground properties are provided. Finally, an\ninversion for a three-dimensional tunnel model is performed and analyzed for\nthree different source and receiver station configurations.",
    "descriptor": "",
    "authors": [
      "Christopher Riedel",
      "Khayal Musayev",
      "Matthias Baitsch",
      "Klaus Hackl"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2202.03208"
  },
  {
    "id": "arXiv:2202.03209",
    "title": "PSSNet: Planarity-sensible Semantic Segmentation of Large-scale Urban  Meshes",
    "abstract": "We introduce a novel deep learning-based framework to interpret 3D urban\nscenes represented as textured meshes. Based on the observation that object\nboundaries typically align with the boundaries of planar regions, our framework\nachieves semantic segmentation in two steps: planarity-sensible\nover-segmentation followed by semantic classification. The over-segmentation\nstep generates an initial set of mesh segments that capture the planar and\nnon-planar regions of urban scenes. In the subsequent classification step, we\nconstruct a graph that encodes geometric and photometric features of the\nsegments in its nodes and multi-scale contextual features in its edges. The\nfinal semantic segmentation is obtained by classifying the segments using a\ngraph convolutional network. Experiments and comparisons on a large semantic\nurban mesh benchmark demonstrate that our approach outperforms the\nstate-of-the-art methods in terms of boundary quality and mean IoU\n(intersection over union). Besides, we also introduce several new metrics for\nevaluating mesh over-segmentation methods dedicated for semantic segmentation,\nand our proposed over-segmentation approach outperforms state-of-the-art\nmethods on all metrics. Our source code will be released when the paper is\naccepted.",
    "descriptor": "\nComments: 8 pages,9 figures\n",
    "authors": [
      "Weixiao Gao",
      "Liangliang Nan",
      "Hugo Ledoux",
      "Bas Boom"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.03209"
  },
  {
    "id": "arXiv:2202.03212",
    "title": "Introducing explainable supervised machine learning into interactive  feedback loops for statistical production system",
    "abstract": "Statistical production systems cover multiple steps from the collection,\naggregation, and integration of data to tasks like data quality assurance and\ndissemination. While the context of data quality assurance is one of the most\npromising fields for applying machine learning, the lack of curated and labeled\ntraining data is often a limiting factor.\nThe statistical production system for the Centralised Securities Database\nfeatures an interactive feedback loop between data collected by the European\nCentral Bank and data quality assurance performed by data quality managers at\nNational Central Banks. The quality assurance feedback loop is based on a set\nof rule-based checks for raising exceptions, upon which the user either\nconfirms the data or corrects an actual error.\nIn this paper we use the information received from this feedback loop to\noptimize the exceptions presented to the National Central Banks thereby\nimproving the quality of exceptions generated and the time consumed on the\nsystem by the users authenticating those exceptions. For this approach we make\nuse of explainable supervised machine learning to (a) identify the types of\nexceptions and (b) to prioritize which exceptions are more likely to require an\nintervention or correction by the NCBs. Furthermore, we provide an explainable\nAI taxonomy aiming to identify the different explainable AI needs that arose\nduring the project.",
    "descriptor": "\nComments: Irving Fisher Committee (IFC) - Bank of Italy workshop on Data science in central banking: Applications and tools. arXiv admin note: text overlap with arXiv:2107.08045\n",
    "authors": [
      "Carlos Mougan",
      "George Kanellos",
      "Johannes Micheler",
      "Jose Martinez",
      "Thomas Gottron"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.03212"
  },
  {
    "id": "arXiv:2202.03218",
    "title": "Efficient Adapter Transfer of Self-Supervised Speech Models for  Automatic Speech Recognition",
    "abstract": "Self-supervised learning (SSL) is a powerful tool that allows learning of\nunderlying representations from unlabeled data. Transformer based models such\nas wav2vec 2.0 and HuBERT are leading the field in the speech domain. Generally\nthese models are fine-tuned on a small amount of labeled data for a downstream\ntask such as Automatic Speech Recognition (ASR). This involves re-training the\nmajority of the model for each task. Adapters are small lightweight modules\nwhich are commonly used in Natural Language Processing (NLP) to adapt\npre-trained models to new tasks. In this paper we propose applying adapters to\nwav2vec 2.0 to reduce the number of parameters required for downstream ASR\ntasks, and increase scalability of the model to multiple tasks or languages.\nUsing adapters we can perform ASR while training fewer than 10% of parameters\nper task compared to full fine-tuning with little degradation of performance.\nAblations show that applying adapters into just the top few layers of the\npre-trained network gives similar performance to full transfer, supporting the\ntheory that higher pre-trained layers encode more phonemic information, and\nfurther optimizing efficiency.",
    "descriptor": "\nComments: 5 Pages, 4 figures. Accepted to ICASSP 2022\n",
    "authors": [
      "Bethan Thomas",
      "Samuel Kessler",
      "Salah Karout"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2202.03218"
  },
  {
    "id": "arXiv:2202.03220",
    "title": "Deep Learning based Channel Estimation for Massive MIMO with Hybrid  Transceivers",
    "abstract": "Accurate and efficient estimation of the high dimensional channels is one of\nthe critical challenges for practical applications of massive multiple-input\nmultiple-output (MIMO). In the context of hybrid analog-digital (HAD)\ntransceivers, channel estimation becomes even more complicated due to\ninformation loss caused by limited radio-frequency chains. The conventional\ncompressive sensing (CS) algorithms usually suffer from unsatisfactory\nperformance and high computational complexity. In this paper, we propose a\nnovel deep learning (DL) based framework for uplink channel estimation in HAD\nmassive MIMO systems. To better exploit the sparsity structure of channels in\nthe angular domain, a novel angular space segmentation method is proposed,\nwhere the entire angular space is segmented into many small regions and a\ndedicated neural network is trained offline for each region. During online\ntesting, the most suitable network is selected based on the information from\nthe global positioning system. Inside each neural network, the region-specific\nmeasurement matrix and channel estimator are jointly optimized, which not only\nimproves the signal measurement efficiency, but also enhances the channel\nestimation capability. Simulation results show that the proposed approach\nsignificantly outperforms the state-of-the-art CS algorithms in terms of\nestimation performance and computational complexity.",
    "descriptor": "",
    "authors": [
      "Jiabao Gao",
      "Caijun Zhong",
      "Geoffrey Ye Li",
      "Zhaoyang Zhang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.03220"
  },
  {
    "id": "arXiv:2202.03229",
    "title": "Neural Models for Output-Space Invariance in Combinatorial Problems",
    "abstract": "Recently many neural models have been proposed to solve combinatorial puzzles\nby implicitly learning underlying constraints using their solved instances,\nsuch as sudoku or graph coloring (GCP). One drawback of the proposed\narchitectures, which are often based on Graph Neural Networks (GNN), is that\nthey cannot generalize across the size of the output space from which variables\nare assigned a value, for example, set of colors in a GCP, or board-size in\nsudoku. We call the output space for the variables as 'value-set'. While many\nworks have demonstrated generalization of GNNs across graph size, there has\nbeen no study on how to design a GNN for achieving value-set invariance for\nproblems that come from the same domain. For example, learning to solve 16 x 16\nsudoku after being trained on only 9 x 9 sudokus. In this work, we propose\nnovel methods to extend GNN based architectures to achieve value-set\ninvariance. Specifically, our model builds on recently proposed Recurrent\nRelational Networks. Our first approach exploits the graph-size invariance of\nGNNs by converting a multi-class node classification problem into a binary node\nclassification problem. Our second approach works directly with multiple\nclasses by adding multiple nodes corresponding to the values in the value-set,\nand then connecting variable nodes to value nodes depending on the problem\ninitialization. Our experimental evaluation on three different combinatorial\nproblems demonstrates that both our models perform well on our novel problem,\ncompared to a generic neural reasoner. Between two of our models, we observe an\ninherent trade-off: while the binarized model gives better performance when\ntrained on smaller value-sets, multi-valued model is much more memory\nefficient, resulting in improved performance when trained on larger value-sets,\nwhere binarized model fails to train.",
    "descriptor": "\nComments: Published as a conference paper at ICLR 2022\n",
    "authors": [
      "Yatin Nandwani",
      "Vidit Jain",
      "Mausam",
      "Parag Singla"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.03229"
  },
  {
    "id": "arXiv:2202.03236",
    "title": "Passive learning to address nonstationarity in virtual flow metering  applications",
    "abstract": "Steady-state process models are common in virtual flow meter applications due\nto low computational complexity, and low model development and maintenance\ncost. Nevertheless, the prediction performance of steady-state models typically\ndegrades with time due to the inherent nonstationarity of the underlying\nprocess being modeled. Few studies have investigated how learning methods can\nbe applied to sustain the prediction accuracy of steady-state virtual flow\nmeters. This paper explores passive learning, where the model is frequently\ncalibrated to new data, as a way to address nonstationarity and improve\nlong-term performance. An advantage with passive learning is that it is\ncompatible with models used in the industry. Two passive learning methods,\nperiodic batch learning and online learning, are applied with varying\ncalibration frequency to train virtual flow meters. Six different model types,\nranging from data-driven to first-principles, are trained on historical\nproduction data from 10 petroleum wells. The results are two-fold: first, in\nthe presence of frequently arriving measurements, frequent model updating\nsustains an excellent prediction performance over time; second, in the presence\nof intermittent and infrequently arriving measurements, frequent updating in\naddition to the utilization of expert knowledge is essential to increase the\nperformance accuracy. The investigation may be of interest to experts\ndeveloping soft-sensors for nonstationary processes, such as virtual flow\nmeters.",
    "descriptor": "\nComments: 35 pages, 9 figures\n",
    "authors": [
      "Mathilde Hotvedt",
      "Bjarne Grimstad",
      "Lars Imsland"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.03236"
  },
  {
    "id": "arXiv:2202.03237",
    "title": "Introducing the Expohedron for Efficient Pareto-optimal Fairness-Utility  Amortizations in Repeated Rankings",
    "abstract": "We consider the problem of computing a sequence of rankings that maximizes\nconsumer-side utility while minimizing producer-side individual unfairness of\nexposure. While prior work has addressed this problem using linear or quadratic\nprograms on bistochastic matrices, such approaches, relying on Birkhoff-von\nNeumann (BvN) decompositions, are too slow to be implemented at large scale.\nIn this paper we introduce a geometrical object, a polytope that we call\nexpohedron, whose points represent all achievable exposures of items for a\nPosition Based Model (PBM). We exhibit some of its properties and lay out a\nCarath\\'eodory decomposition algorithm with complexity $O(n^2\\log(n))$ able to\nexpress any point inside the expohedron as a convex sum of at most $n$\nvertices, where $n$ is the number of items to rank. Such a decomposition makes\nit possible to express any feasible target exposure as a distribution over at\nmost $n$ rankings. Furthermore we show that we can use this polytope to recover\nthe whole Pareto frontier of the multi-objective fairness-utility optimization\nproblem, using a simple geometrical procedure with complexity $O(n^2\\log(n))$.\nOur approach compares favorably to linear or quadratic programming baselines in\nterms of algorithmic complexity and empirical runtime and is applicable to any\nmerit that is a non-decreasing function of item relevance. Furthermore our\nsolution can be expressed as a distribution over only $n$ permutations, instead\nof the $(n-1)^2 + 1$ achieved with BvN decompositions. We perform experiments\non synthetic and real-world datasets, confirming our theoretical results.",
    "descriptor": "\nComments: 10 pages, 6 figures, accepted at WSDM'22, February 21-25, 2022, Tempe, AZ, USA\n",
    "authors": [
      "Till Kletti",
      "Jean-Michel Renders",
      "Patrick Loiseau"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.03237"
  },
  {
    "id": "arXiv:2202.03238",
    "title": "Towards an Analytical Definition of Sufficient Data",
    "abstract": "We show that, for each of five datasets of increasing complexity, certain\ntraining samples are more informative of class membership than others. These\nsamples can be identified a priori to training by analyzing their position in\nreduced dimensional space relative to the classes' centroids. Specifically, we\ndemonstrate that samples nearer the classes' centroids are less informative\nthan those that are furthest from it. For all five datasets, we show that there\nis no statistically significant difference between training on the entire\ntraining set and when excluding up to 2% of the data nearest to each class's\ncentroid.",
    "descriptor": "\nComments: 17 pages, 36 figures, 7 tables\n",
    "authors": [
      "Adam Byerly",
      "Tatiana Kalganova"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.03238"
  },
  {
    "id": "arXiv:2202.03240",
    "title": "Minimization of the Worst-Case Average Energy Consumption in  UAV-Assisted IoT Networks",
    "abstract": "The Internet of Things (IoT) brings connectivity to a massive number of\ndevices that demand energy-efficient solutions to deal with limited battery\ncapacities, uplink-dominant traffic, and channel impairments. In this work, we\nexplore the use of Unmanned Aerial Vehicles (UAVs) equipped with configurable\nantennas as a flexible solution for serving low-power IoT networks. We\nformulate an optimization problem to set the position and antenna beamwidth of\nthe UAV, and the transmit power of the IoT devices subject to\naverage-Signal-to-average-Interference-plus-Noise Ratio\n($\\bar{\\text{S}}\\overline{\\text{IN}}\\text{R}$) Quality of Service (QoS)\nconstraints. We minimize the worst-case average energy consumption of the\nlatter, thus, targeting the fairest allocation of the energy resources. The\nproblem is non-convex and highly non-linear; therefore, we re-formulate it as a\nseries of three geometric programs that can be solved iteratively. Results\nreveal the benefits of planning the network compared to a random deployment in\nterms of reducing the worst-case average energy consumption. Furthermore, we\nshow that the target $\\bar{\\text{S}}\\overline{\\text{IN}}\\text{R}$ is limited by\nthe number of IoT devices, and highlight the dominant impact of the UAV\nhovering height when serving wider areas. Our proposed algorithm outperforms\nother optimization benchmarks in terms of minimizing the average energy\nconsumption at the most energy-demanding IoT device, and convergence time.",
    "descriptor": "\nComments: 12 pages, 8 figures, Journal paper accepted for publication in the IEEE Internet of Things Journal\n",
    "authors": [
      "Osmel Mart\u00ednez Rosabal",
      "Onel Alcaraz L\u00f3pez",
      "Dian Echevarr\u00eda P\u00e9rez",
      "Mohammad Shehab",
      "Henrique Hilleshein",
      "Hirley Alves"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2202.03240"
  },
  {
    "id": "arXiv:2202.03242",
    "title": "Unsupervised physics-informed disentanglement of multimodal data for  high-throughput scientific discovery",
    "abstract": "We introduce physics-informed multimodal autoencoders (PIMA) - a variational\ninference framework for discovering shared information in multimodal scientific\ndatasets representative of high-throughput testing. Individual modalities are\nembedded into a shared latent space and fused through a product of experts\nformulation, enabling a Gaussian mixture prior to identify shared features.\nSampling from clusters allows cross-modal generative modeling, with a mixture\nof expert decoder imposing inductive biases encoding prior scientific knowledge\nand imparting structured disentanglement of the latent space. This approach\nenables discovery of fingerprints which may be detected in high-dimensional\nheterogeneous datasets, avoiding traditional bottlenecks related to\nhigh-fidelity measurement and characterization. Motivated by accelerated\nco-design and optimization of materials manufacturing processes, a dataset of\nlattice metamaterials from metal additive manufacturing demonstrates accurate\ncross modal inference between images of mesoscale topology and mechanical\nstress-strain response.",
    "descriptor": "",
    "authors": [
      "Nathaniel Trask",
      "Carianne Martinez",
      "Kookjin Lee",
      "Brad Boyce"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.03242"
  },
  {
    "id": "arXiv:2202.03243",
    "title": "Air-Releasable Soft Robots for Explosive Ordnance Disposal",
    "abstract": "The demining of landmines using drones is challenging; air-releasable\npayloads are typically non-intelligent (e.g., water balloons or explosives) and\ndeploying them at even low altitudes (~6 meter) is inherently inaccurate due to\ncomplex deployment trajectories and constrained visual awareness by the drone\npilot. Soft robotics offers a unique approach for aerial demining, namely due\nto the robust, low-cost, and lightweight designs of soft robots. Instead of\nnon-intelligent payloads, here, we propose the use of air-releasable soft\nrobots for demining. We developed a full system consisting of an unmanned\naerial vehicle retrofitted to a soft robot carrier including a custom-made\ndeployment mechanism, and an air-releasable, lightweight (296 g), untethered\nsoft hybrid robot with integrated electronics that incorporates a new type of a\nvacuum-based flasher roller actuator system. We demonstrate a deployment cycle\nin which the drone drops the soft robotic hybrid from an altitude of 4.5 m\nmeters and after which the robot approaches a dummy landmine. By deploying soft\nrobots at points of interest, we can transition soft robotic technologies from\nthe laboratory to real-world environments.",
    "descriptor": "\nComments: Accepted manuscript: IEEE Soft Robotics Conference, Edinburgh, 2022\n",
    "authors": [
      "Tyler C. Looney",
      "Nathan M. Savard",
      "Gus T. Teran",
      "Archie G. Milligan",
      "Ryley I. Wheelock",
      "Michael Scalise",
      "Daniel P. Perno",
      "Gregory C. Lewin",
      "Carlo Pinciroli",
      "Cagdas D. Onal",
      "Markus P. Nemitz"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.03243"
  },
  {
    "id": "arXiv:2202.03244",
    "title": "Online Deep Neural Network for Optimization in Wireless Communications",
    "abstract": "Recently, deep neural network (DNN) has been widely adopted in the design of\nintelligent communication systems thanks to its strong learning ability and low\ntesting complexity. However, most current offline DNN-based methods still\nsuffer from unsatisfactory performance, limited generalization ability, and\npoor interpretability. In this article, we propose an online DNN-based approach\nto solve general optimization problems in wireless communications, where a\ndedicated DNN is trained for each data sample. By treating the optimization\nvariables and the objective function as network parameters and loss function,\nrespectively, the optimization problem can be solved equivalently through\nnetwork training. Thanks to the online optimization nature and meaningful\nnetwork parameters, the proposed approach owns strong generalization ability\nand interpretability, while its superior performance is demonstrated through a\npractical example of joint beamforming in intelligent reflecting surface\n(IRS)-aided multi-user multiple-input multiple-output (MIMO) systems.\nSimulation results show that the proposed online DNN outperforms conventional\noffline DNN and state-of-the-art iterative optimization algorithm, but with low\ncomplexity.",
    "descriptor": "",
    "authors": [
      "Jiabao Gao",
      "Caijun Zhong",
      "Geoffrey Ye Li",
      "Zhaoyang Zhang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.03244"
  },
  {
    "id": "arXiv:2202.03245",
    "title": "Scalable Multi-Party Privacy-Preserving Gradient Tree Boosting over  Vertically Partitioned Dataset with Outsourced Computations",
    "abstract": "Due to privacy concerns, multi-party gradient tree boosting algorithms have\nbecome widely popular amongst machine learning researchers and practitioners.\nHowever, limited existing works have focused on vertically partitioned\ndatasets, and the few existing works are either not scalable or tend to leak\ninformation. Thus, in this work, we propose SSXGB which is a scalable and\nsecure multi-party gradient tree boosting framework for vertically partitioned\ndatasets with partially outsourced computations. Specifically, we employ an\nadditive homomorphic encryption (HE) scheme for security. We design two\nsub-protocols based on the HE scheme to perform non-linear operations\nassociated with gradient tree boosting algorithms. Next, we propose a secure\ntraining and a secure prediction algorithms under the SSXGB framework. Then we\nprovide theoretical security and communication analysis for the proposed\nframework. Finally, we evaluate the performance of the framework with\nexperiments using two real-world datasets.",
    "descriptor": "",
    "authors": [
      "Kennedy Edemacu",
      "Beakcheol Jang",
      "Jong Wook Kim"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.03245"
  },
  {
    "id": "arXiv:2202.03246",
    "title": "AI-based artistic representation of emotions from EEG signals: a  discussion on fairness, inclusion, and aesthetics",
    "abstract": "While Artificial Intelligence (AI) technologies are being progressively\ndeveloped, artists and researchers are investigating their role in artistic\npractices. In this work, we present an AI-based Brain-Computer Interface (BCI)\nin which humans and machines interact to express feelings artistically. This\nsystem and its production of images give opportunities to reflect on the\ncomplexities and range of human emotions and their expressions. In this\ndiscussion, we seek to understand the dynamics of this interaction to reach\nbetter co-existence in fairness, inclusion, and aesthetics.",
    "descriptor": "\nComments: Accepted to the Politics of the Machines conference 2021 (POM Berlin 2021)\n",
    "authors": [
      "Piera Riccio",
      "Kristin Bergaust",
      "Boel Christensen-Scheel",
      "Juan-Carlos De Martin",
      "Maria A. Zuluaga",
      "Stefano Nichele"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.03246"
  },
  {
    "id": "arXiv:2202.03250",
    "title": "ALM-KD: Knowledge Distillation with noisy labels via adaptive loss  mixing",
    "abstract": "Knowledge distillation is a technique where the outputs of a pretrained\nmodel, often known as the teacher model is used for training a student model in\na supervised setting. The teacher model outputs being a richer distribution\nover labels should improve the student model's performance as opposed to\ntraining with the usual hard labels. However, the label distribution imposed by\nthe logits of the teacher network may not be always informative and may lead to\npoor student performance. We tackle this problem via the use of an adaptive\nloss mixing scheme during KD. Specifically, our method learns an\ninstance-specific convex combination of the teacher-matching and label\nsupervision objectives, using meta learning on a validation metric signalling\nto the student `how much' of KD is to be used. Through a range of experiments\non controlled synthetic data and real-world datasets, we demonstrate\nperformance gains obtained using our approach in the standard KD setting as\nwell as in multi-teacher and self-distillation settings.",
    "descriptor": "",
    "authors": [
      "Durga Sivasubramanian",
      "Pradeep Shenoy",
      "Prathosh AP",
      "Ganesh Ramakrishnan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.03250"
  },
  {
    "id": "arXiv:2202.03255",
    "title": "OCSM : Finding Overlapping Cohesive Subgraphs with Minimum Degree",
    "abstract": "Cohesive subgraph discovery in a network is one of the fundamental problems\nand investigated for several decades. In this paper, we propose the Overlapping\nCohesive Subgraphs with Minimum degree (OCSM) problem which combines three key\nconcepts for OCSM : (i) edge-based overlapping, (ii) the minimum degree\nconstraint, and (iii) the graph density. To the best of our knowledge, this is\nthe first work to identify overlapping cohesive subgraphs with minimum degree\nby incorporating the graph density. Since the OCSM problem is NP-hard, we\npropose two algorithms: advanced peeling algorithm and seed-based expansion\nalgorithm. Finally, we show the experimental study with real-world networks to\ndemonstrate the effectiveness and efficiency of our proposed algorithms.",
    "descriptor": "",
    "authors": [
      "Junghoon Kim",
      "Sungsu Lim",
      "Jungeun Kim"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2202.03255"
  },
  {
    "id": "arXiv:2202.03257",
    "title": "Confidence Guided Depth Completion Network",
    "abstract": "The paper proposes an image-guided depth completion method to estimate\naccurate dense depth maps with fast computation time. The proposed network has\ntwo-stage structure. The first stage predicts a first depth map. Then, the\nsecond stage further refines the first depth map using the confidence maps. The\nsecond stage consists of two layers, each of which focuses on different regions\nand generates a refined depth map and a confidence map. The final depth map is\nobtained by combining two depth maps from the second stage using the\ncorresponding confidence maps. Compared with the top-ranked models on the KITTI\ndepth completion online leaderboard, the proposed model shows much faster\ncomputation time and competitive performance.",
    "descriptor": "\nComments: 6 pages, 3 figures, 2 tables\n",
    "authors": [
      "Yongjin Lee",
      "Seokjun Park",
      "Beomgu Kang",
      "Hyunwook Park"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.03257"
  },
  {
    "id": "arXiv:2202.03259",
    "title": "Theory-inspired Parameter Control Benchmarks for Dynamic Algorithm  Configuration",
    "abstract": "It has long been observed that the performance of evolutionary algorithms and\nother randomized search heuristics can benefit from a non-static choice of the\nparameters that steer their optimization behavior. Mechanisms that identify\nsuitable configurations on the fly (\"parameter control\") or via a dedicated\ntraining process (\"dynamic algorithm configuration\") are therefore an important\ncomponent of modern evolutionary computation frameworks. Several approaches to\naddress the dynamic parameter setting problem exist, but we barely understand\nwhich ones to prefer for which applications. As in classical benchmarking,\nproblem collections with a known ground truth can offer very meaningful\ninsights in this context. Unfortunately, settings with well-understood control\npolicies are very rare.\nOne of the few exceptions for which we know which parameter settings minimize\nthe expected runtime is the LeadingOnes problem. We extend this benchmark by\nanalyzing optimal control policies that can select the parameters only from a\ngiven portfolio of possible values. This also allows us to compute optimal\nparameter portfolios of a given size. We demonstrate the usefulness of our\nbenchmarks by analyzing the behavior of the DDQN reinforcement learning\napproach for dynamic algorithm configuration.",
    "descriptor": "",
    "authors": [
      "Andr\u00e9 Biedenkapp",
      "Nguyen Dang",
      "Martin S. Krejca",
      "Frank Hutter",
      "Carola Doerr"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.03259"
  },
  {
    "id": "arXiv:2202.03263",
    "title": "Asynchronous Parallel Incremental Block-Coordinate Descent for  Decentralized Machine Learning",
    "abstract": "Machine learning (ML) is a key technique for big-data-driven modelling and\nanalysis of massive Internet of Things (IoT) based intelligent and ubiquitous\ncomputing. For fast-increasing applications and data amounts, distributed\nlearning is a promising emerging paradigm since it is often impractical or\ninefficient to share/aggregate data to a centralized location from distinct\nones. This paper studies the problem of training an ML model over decentralized\nsystems, where data are distributed over many user devices and the learning\nalgorithm run on-device, with the aim of relaxing the burden at a central\nentity/server. Although gossip-based approaches have been used for this purpose\nin different use cases, they suffer from high communication costs, especially\nwhen the number of devices is large. To mitigate this, incremental-based\nmethods are proposed. We first introduce incremental block-coordinate descent\n(I-BCD) for the decentralized ML, which can reduce communication costs at the\nexpense of running time. To accelerate the convergence speed, an asynchronous\nparallel incremental BCD (API-BCD) method is proposed, where multiple\ndevices/agents are active in an asynchronous fashion. We derive convergence\nproperties for the proposed methods. Simulation results also show that our\nAPI-BCD method outperforms state of the art in terms of running time and\ncommunication costs.",
    "descriptor": "",
    "authors": [
      "Hao Chen",
      "Yu Ye",
      "Ming Xiao",
      "Mikael Skoglund"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2202.03263"
  },
  {
    "id": "arXiv:2202.03270",
    "title": "Do Developers Refactor Data Access Code? An Empirical Study",
    "abstract": "Developers often refactor code to improve the maintainability and\ncomprehension of the software. There are many studies on refactoring activities\nin traditional software systems. However, refactoring in data-intensive systems\nis not well explored. Understanding the refactoring practices of developers is\nimportant to develop efficient tool support.We conducted a longitudinal study\nof refactoring activities in data access classes using 12 data-intensive\nsubject systems. We investigated the prevalence and evolution of refactorings\nand the association of refactorings with data access smells. We also conducted\na manual analysis of over 378 samples of data access refactoring instances to\nidentify the functionalities of the code that are targeted by such\nrefactorings. Our results show that (1) data access refactorings are prevalent\nand different in type. \\textit{Rename variable} is the most prevalent data\naccess refactoring. (2) The prevalence and type of refactorings vary as systems\nevolve in time. (3) Most data access refactorings target codes that implement\ndata fetching and insertion. (4) Data access refactorings do not generally\ntouch SQL queries. Overall, the results show that data access refactorings\nfocus on improving the code quality but not the underlying data access\noperations. Hence, more work is needed from the research community on providing\nawareness and support to practitioners on the benefits of addressing data\naccess smells with refactorings.",
    "descriptor": "\nComments: 29th IEEE International Conference on Software Analysis, Evolution and Reengineering\n",
    "authors": [
      "Biruk Asmare Muse",
      "Foutse Khomh",
      "Giuliano Antoniol"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2202.03270"
  },
  {
    "id": "arXiv:2202.03276",
    "title": "Ransomware: Analysing the Impact on Windows Active Directory Domain  Services",
    "abstract": "Ransomware has become an increasingly popular type of malware across the past\ndecade and continues to rise in popularity due to its high profitability.\nOrganisations and enterprises have become prime targets for ransomware as they\nare more likely to succumb to ransom demands as part of operating expenses to\ncounter the cost incurred from downtime. Despite the prevalence of ransomware\nas a threat towards organisations, there is very little information outlining\nhow ransomware affects Windows Server environments, and particularly its\nproprietary domain services such as Active Directory. Hence, we aim to increase\nthe cyber situational awareness of organisations and corporations that utilise\nthese environments. Dynamic analysis was performed using three ransomware\nvariants to uncover how crypto-ransomware affects Windows Server-specific\nservices and processes. Our work outlines the practical investigation\nundertaken as WannaCry, TeslaCrypt, and Jigsaw were acquired and tested against\nseveral domain services. The findings showed that none of the three variants\nstopped the processes and decidedly left all domain services untouched.\nHowever, although the services remained operational, they became uniquely\ndysfunctional as ransomware encrypted the files pertaining to those services",
    "descriptor": "",
    "authors": [
      "Grant McDonald",
      "Pavlos Papadopoulos",
      "Nikolaos Pitropakis",
      "Jawad Ahmad",
      "William J. Buchanan"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.03276"
  },
  {
    "id": "arXiv:2202.03277",
    "title": "On The Empirical Effectiveness of Unrealistic Adversarial Hardening  Against Realistic Adversarial Attacks",
    "abstract": "While the literature on security attacks and defense of Machine Learning (ML)\nsystems mostly focuses on unrealistic adversarial examples, recent research has\nraised concern about the under-explored field of realistic adversarial attacks\nand their implications on the robustness of real-world systems. Our paper paves\nthe way for a better understanding of adversarial robustness against realistic\nattacks and makes two major contributions. First, we conduct a study on three\nreal-world use cases (text classification, botnet detection, malware\ndetection)) and five datasets in order to evaluate whether unrealistic\nadversarial examples can be used to protect models against realistic examples.\nOur results reveal discrepancies across the use cases, where unrealistic\nexamples can either be as effective as the realistic ones or may offer only\nlimited improvement. Second, to explain these results, we analyze the latent\nrepresentation of the adversarial examples generated with realistic and\nunrealistic attacks. We shed light on the patterns that discriminate which\nunrealistic examples can be used for effective hardening. We release our code,\ndatasets and models to support future research in exploring how to reduce the\ngap between unrealistic and realistic adversarial attacks.",
    "descriptor": "",
    "authors": [
      "Salijona Dyrmishi",
      "Salah Ghamizi",
      "Thibault Simonetto",
      "Yves Le Traon",
      "Maxime Cordy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.03277"
  },
  {
    "id": "arXiv:2202.03278",
    "title": "Crafting Better Contrastive Views for Siamese Representation Learning",
    "abstract": "Recent self-supervised contrastive learning methods greatly benefit from the\nSiamese structure that aims at minimizing distances between positive pairs. For\nhigh performance Siamese representation learning, one of the keys is to design\ngood contrastive pairs. Most previous works simply apply random sampling to\nmake different crops of the same image, which overlooks the semantic\ninformation that may degrade the quality of views. In this work, we propose\nContrastiveCrop, which could effectively generate better crops for Siamese\nrepresentation learning. Firstly, a semantic-aware object localization strategy\nis proposed within the training process in a fully unsupervised manner. This\nguides us to generate contrastive views which could avoid most false positives\n(i.e., object vs. background). Moreover, we empirically find that views with\nsimilar appearances are trivial for the Siamese model training. Thus, a\ncenter-suppressed sampling is further designed to enlarge the variance of\ncrops. Remarkably, our method takes a careful consideration of positive pairs\nfor contrastive learning with negligible extra training overhead. As a\nplug-and-play and framework-agnostic module, ContrastiveCrop consistently\nimproves SimCLR, MoCo, BYOL, SimSiam by 0.4% ~ 2.0% classification accuracy on\nCIFAR-10, CIFAR-100, Tiny ImageNet and STL-10. Superior results are also\nachieved on downstream detection and segmentation tasks when pre-trained on\nImageNet-1K.",
    "descriptor": "",
    "authors": [
      "Xiangyu Peng",
      "Kai Wang",
      "Zheng Zhu",
      "Yang You"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.03278"
  },
  {
    "id": "arXiv:2202.03279",
    "title": "On the sensitivity of implementations of a least-squares collocation  method for linear higher-index differential-algebraic equations",
    "abstract": "The present paper continues our investigation of an implementation of a\nleast-squares collocation method for higher-index differential-algebraic\nequations. In earlier papers, we were able to substantiate the choice of basis\nfunctions and collocation points for a robust implementation as well as\nalgorithms for the solution of the discrete system. The present paper is\ndevoted to an analytic estimation of condition numbers for different components\nof an implementation. We present error estimations, which show the sources for\nthe different errors.",
    "descriptor": "",
    "authors": [
      "Michael Hanke"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.03279"
  },
  {
    "id": "arXiv:2202.03281",
    "title": "Personalized Public Policy Analysis in Social Sciences using  Causal-Graphical Normalizing Flows",
    "abstract": "Structural Equation/Causal Models (SEMs/SCMs) are widely used in epidemiology\nand social sciences to identify and analyze the average treatment effect (ATE)\nand conditional ATE (CATE). Traditional causal effect estimation methods such\nas Inverse Probability Weighting (IPW) and more recently\nRegression-With-Residuals (RWR) are widely used - as they avoid the challenging\ntask of identifying the SCM parameters - to estimate ATE and CATE. However,\nmuch work remains before traditional estimation methods can be used for\ncounterfactual inference, and for the benefit of Personalized Public Policy\nAnalysis (P$^3$A) in the social sciences. While doctors rely on personalized\nmedicine to tailor treatments to patients in laboratory settings (relatively\nclosed systems), P$^3$A draws inspiration from such tailoring but adapts it for\nopen social systems. In this article, we develop a method for counterfactual\ninference that we name causal-Graphical Normalizing Flow (c-GNF), facilitating\nP$^3$A. First, we show how c-GNF captures the underlying SCM without making any\nassumption about functional forms. Second, we propose a novel dequantization\ntrick to deal with discrete variables, which is a limitation of normalizing\nflows in general. Third, we demonstrate in experiments that c-GNF performs\non-par with IPW and RWR in terms of bias and variance for estimating the ATE,\nwhen the true functional forms are known, and better when they are unknown.\nFourth and most importantly, we conduct counterfactual inference with c-GNFs,\ndemonstrating promising empirical performance. Because IPW and RWR, like other\ntraditional methods, lack the capability of counterfactual inference, c-GNFs\nwill likely play a major role in tailoring personalized treatment, facilitating\nP$^3$A, optimizing social interventions - in contrast to the current\n`one-size-fits-all' approach of existing methods.",
    "descriptor": "\nComments: 9 pages, 3 figures, AAAI-2022: AI for Social Impact track\n",
    "authors": [
      "Sourabh Balgi",
      "Jose M. Pena",
      "Adel Daoud"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.03281"
  },
  {
    "id": "arXiv:2202.03283",
    "title": "CZU-MHAD: A multimodal dataset for human action recognition utilizing a  depth camera and 10 wearable inertial sensors",
    "abstract": "Human action recognition has been widely used in many fields of life, and\nmany human action datasets have been published at the same time. However, most\nof the multi-modal databases have some shortcomings in the layout and number of\nsensors, which cannot fully represent the action features. Regarding the\nproblems, this paper proposes a freely available dataset, named CZU-MHAD\n(Changzhou University: a comprehensive multi-modal human action dataset). It\nconsists of 22 actions and three modals temporal synchronized data. These\nmodals include depth videos and skeleton positions from a kinect v2 camera, and\ninertial signals from 10 wearable sensors. Compared with single modal sensors,\nmulti-modal sensors can collect different modal data, so the use of multi-modal\nsensors can describe actions more accurately. Moreover, CZU-MHAD obtains the\n3-axis acceleration and 3-axis angular velocity of 10 main motion joints by\nbinding inertial sensors to them, and these data were captured at the same\ntime. Experimental results are provided to show that this dataset can be used\nto study structural relationships between different parts of the human body\nwhen performing actions and fusion approaches that involve multi-modal sensor\ndata.",
    "descriptor": "",
    "authors": [
      "Xin Chao",
      "Zhenjie Hou",
      "Yujian Mo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.03283"
  },
  {
    "id": "arXiv:2202.03286",
    "title": "Red Teaming Language Models with Language Models",
    "abstract": "Language Models (LMs) often cannot be deployed because of their potential to\nharm users in hard-to-predict ways. Prior work identifies harmful behaviors\nbefore deployment by using human annotators to hand-write test cases. However,\nhuman annotation is expensive, limiting the number and diversity of test cases.\nIn this work, we automatically find cases where a target LM behaves in a\nharmful way, by generating test cases (\"red teaming\") using another LM. We\nevaluate the target LM's replies to generated test questions using a classifier\ntrained to detect offensive content, uncovering tens of thousands of offensive\nreplies in a 280B parameter LM chatbot. We explore several methods, from\nzero-shot generation to reinforcement learning, for generating test cases with\nvarying levels of diversity and difficulty. Furthermore, we use prompt\nengineering to control LM-generated test cases to uncover a variety of other\nharms, automatically finding groups of people that the chatbot discusses in\noffensive ways, personal and hospital phone numbers generated as the chatbot's\nown contact info, leakage of private training data in generated text, and harms\nthat occur over the course of a conversation. Overall, LM-based red teaming is\none promising tool (among many needed) for finding and fixing diverse,\nundesirable LM behaviors before impacting users.",
    "descriptor": "",
    "authors": [
      "Ethan Perez",
      "Saffron Huang",
      "Francis Song",
      "Trevor Cai",
      "Roman Ring",
      "John Aslanides",
      "Amelia Glaese",
      "Nat McAleese",
      "Geoffrey Irving"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.03286"
  },
  {
    "id": "arXiv:2202.03287",
    "title": "Gaussian Graphical Models as an Ensemble Method for Distributed Gaussian  Processes",
    "abstract": "Distributed Gaussian process (DGP) is a popular approach to scale GP to big\ndata which divides the training data into some subsets, performs local\ninference for each partition, and aggregates the results to acquire global\nprediction. To combine the local predictions, the conditional independence\nassumption is used which basically means there is a perfect diversity between\nthe subsets. Although it keeps the aggregation tractable, it is often violated\nin practice and generally yields poor results. In this paper, we propose a\nnovel approach for aggregating the Gaussian experts' predictions by Gaussian\ngraphical model (GGM) where the target aggregation is defined as an unobserved\nlatent variable and the local predictions are the observed variables. We first\nestimate the joint distribution of latent and observed variables using the\nExpectation-Maximization (EM) algorithm. The interaction between experts can be\nencoded by the precision matrix of the joint distribution and the aggregated\npredictions are obtained based on the property of conditional Gaussian\ndistribution. Using both synthetic and real datasets, our experimental\nevaluations illustrate that our new method outperforms other state-of-the-art\nDGP approaches.",
    "descriptor": "\nComments: OPT2021: 13th Annual Workshop on Optimization for Machine Learning\n",
    "authors": [
      "Hamed Jalali",
      "Gjergji Kasneci"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.03287"
  },
  {
    "id": "arXiv:2202.03289",
    "title": "Approximation error of single hidden layer neural networks with fixed  weights",
    "abstract": "This paper provides an explicit formula for the approximation error of single\nhidden layer neural networks with two fixed weights.",
    "descriptor": "\nComments: 16 pages. arXiv admin note: text overlap with arXiv:2005.14125\n",
    "authors": [
      "Vugar Ismailov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Classical Analysis and ODEs (math.CA)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.03289"
  },
  {
    "id": "arXiv:2202.03291",
    "title": "Mental Disorders on Online Social Media Through the Lens of Language and  Behaviour: Analysis and Visualisation",
    "abstract": "Due to the worldwide accessibility to the Internet along with the continuous\nadvances in mobile technologies, physical and digital worlds have become\ncompletely blended, and the proliferation of social media platforms has taken a\nleading role over this evolution. In this paper, we undertake a thorough\nanalysis towards better visualising and understanding the factors that\ncharacterise and differentiate social media users affected by mental disorders.\nWe perform different experiments studying multiple dimensions of language,\nincluding vocabulary uniqueness, word usage, linguistic style, psychometric\nattributes, emotions' co-occurrence patterns, and online behavioural traits,\nincluding social engagement and posting trends. Our findings reveal significant\ndifferences on the use of function words, such as adverbs and verb tense, and\ntopic-specific vocabulary, such as biological processes. As for emotional\nexpression, we observe that affected users tend to share emotions more\nregularly than control individuals on average. Overall, the monthly posting\nvariance of the affected groups is higher than the control groups. Moreover, we\nfound evidence suggesting that language use on micro-blogging platforms is less\ndistinguishable for users who have a mental disorder than other less\nrestrictive platforms. In particular, we observe on Twitter less quantifiable\ndifferences between affected and control groups compared to Reddit.",
    "descriptor": "\nComments: To appear in Elsevier Information Processing & Management\n",
    "authors": [
      "Esteban A. R\u00edssola",
      "Mohammad Aliannejadi",
      "Fabio Crestani"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.03291"
  },
  {
    "id": "arXiv:2202.03293",
    "title": "Composable and Modular Code Generation in MLIR: A Structured and  Retargetable Approach to Tensor Compiler Construction",
    "abstract": "Despite significant investment in software infrastructure, machine learning\nsystems, runtimes and compilers do not compose properly. We propose a new\ndesign aiming at providing unprecedented degrees of modularity, composability\nand genericity. This paper discusses a structured approach to the construction\nof domain-specific code generators for tensor compilers, with the stated goal\nof improving the productivity of both compiler engineers and end-users. The\napproach leverages the natural structure of tensor algebra. It has been the\nmain driver for the design of progressive lowering paths in \\MLIR. The proposed\nabstractions and transformations span data structures and control flow with\nboth functional (SSA form) and imperative (side-effecting) semantics. We\ndiscuss the implications of this infrastructure on compiler construction and\npresent preliminary experimental results.",
    "descriptor": "",
    "authors": [
      "Nicolas Vasilache",
      "Oleksandr Zinenko",
      "Aart J.C. Bik",
      "Mahesh Ravishankar",
      "Thomas Raoux",
      "Alexander Belyaev",
      "Matthias Springer",
      "Tobias Gysi",
      "Diego Caballero",
      "Stephan Herhut",
      "Stella Laurenzo",
      "Albert Cohen"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2202.03293"
  },
  {
    "id": "arXiv:2202.03295",
    "title": "Theoretical characterization of uncertainty in high-dimensional linear  classification",
    "abstract": "Being able to reliably assess not only the accuracy but also the uncertainty\nof models' predictions is an important endeavour in modern machine learning.\nEven if the model generating the data and labels is known, computing the\nintrinsic uncertainty after learning the model from a limited number of samples\namounts to sampling the corresponding posterior probability measure. Such\nsampling is computationally challenging in high-dimensional problems and\ntheoretical results on heuristic uncertainty estimators in high-dimensions are\nthus scarce. In this manuscript, we characterise uncertainty for learning from\nlimited number of samples of high-dimensional Gaussian input data and labels\ngenerated by the probit model. We prove that the Bayesian uncertainty (i.e. the\nposterior marginals) can be asymptotically obtained by the approximate message\npassing algorithm, bypassing the canonical but costly Monte Carlo sampling of\nthe posterior. We then provide a closed-form formula for the joint statistics\nbetween the logistic classifier, the uncertainty of the statistically optimal\nBayesian classifier and the ground-truth probit uncertainty. The formula allows\nus to investigate calibration of the logistic classifier learning from limited\namount of samples. We discuss how over-confidence can be mitigated by\nappropriately regularising, and show that cross-validating with respect to the\nloss leads to better calibration than with the 0/1 error.",
    "descriptor": "",
    "authors": [
      "Lucas Clart\u00e9",
      "Bruno Loureiro",
      "Florent Krzakala",
      "Lenka Zdeborov\u00e1"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.03295"
  },
  {
    "id": "arXiv:2202.03296",
    "title": "Reconfigurable Intelligent Surface With Energy Harvesting Assisted  Cooperative Ambient Backscatter Communications",
    "abstract": "The performance of cooperative ambient backscatter communications (CABC) can\nbe enhanced by employing reconfigurable intelligent surface (RIS) to assist\nbackscatter transmitters. Since the RIS power consumption is a non-negligible\nissue, we consider a RIS assisted CABC system where the RIS with energy\nharvesting circuit can not only reflect signal but also harvest wireless\nenergy. We study a transmission design problem to minimize the RIS power\nconsumption with the quality of service constraints for both active and\nbackscatter transmissions. The optimization problem is a mixed-integer\nnon-convex programming problem which is NP-hard. To tackle it, an algorithm is\nproposed by employing the block coordinate descent, semidefinite relaxation and\nalternating direction method of multipliers techniques. Simulation results\ndemonstrate the effectiveness of the proposed algorithm.",
    "descriptor": "",
    "authors": [
      "Hui Ma",
      "Haijun Zhang",
      "Ning Zhang",
      "Jianquan Wang",
      "Ning Wang",
      "Victor C. M. Leung"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.03296"
  },
  {
    "id": "arXiv:2202.03299",
    "title": "Training OOD Detectors in their Natural Habitats",
    "abstract": "Out-of-distribution (OOD) detection is important for machine learning models\ndeployed in the wild. Recent methods use auxiliary outlier data to regularize\nthe model for improved OOD detection. However, these approaches make a strong\ndistributional assumption that the auxiliary outlier data is completely\nseparable from the in-distribution (ID) data. In this paper, we propose a novel\nframework that leverages wild mixture data -- that naturally consists of both\nID and OOD samples. Such wild data is abundant and arises freely upon deploying\na machine learning classifier in their \\emph{natural habitats}. Our key idea is\nto formulate a constrained optimization problem and to show how to tractably\nsolve it. Our learning objective maximizes the OOD detection rate, subject to\nconstraints on the classification error of ID data and on the OOD error rate of\nID examples. We extensively evaluate our approach on common OOD detection tasks\nand demonstrate superior performance.",
    "descriptor": "",
    "authors": [
      "Julian Katz-Samuels",
      "Julia Nakhleh",
      "Robert Nowak",
      "Yixuan Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.03299"
  },
  {
    "id": "arXiv:2202.03301",
    "title": "Some Results on the Improved Bound and Construction of Optimal  $(r,\u03b4)$ LRCs",
    "abstract": "Locally repairable codes (LRCs) with $(r,\\delta)$ locality were introduced by\nPrakash \\emph{et al.} into distributed storage systems (DSSs) due to their\nbenefit of locally repairing at least $\\delta-1$ erasures via other $r$\nsurvival nodes among the same local group. An LRC achieving the $(r,\\delta)$\nSingleton-type bound is called an optimal $(r,\\delta)$ LRC. Constructions of\noptimal $(r,\\delta)$ LRCs with longer code length and determining the maximal\ncode length have been an important research direction in coding theory in\nrecent years. In this paper, we conduct further research on the improvement of\nmaximum code length of optimal $(r,\\delta)$ LRCs. For $2\\delta+1\\leq d\\leq\n2\\delta+2$, our upper bounds largely improve the ones by Cai \\emph{et al.},\nwhich are tight in some special cases. Moreover, we generalize the results of\nChen \\emph{et al.} and obtain a complete characterization of optimal $(r=2,\n\\delta)$-LRCs in the sense of geometrical existence in the finite projective\nplane $PG(2,q)$. Within this geometrical characterization, we construct a class\nof optimal $(r,\\delta)$ LRCs based on the sunflower structure. Both the\nconstruction and upper bounds are better than previous ones.",
    "descriptor": "\nComments: Submitted to the 2022 IEEE International Symposium on Information Theory (ISIT)\n",
    "authors": [
      "Bin Chen",
      "Weijun Fang",
      "Yueqi Chen",
      "Shu-Tao Xia",
      "Fang-Wei Fu",
      "Xiangyu Chen"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.03301"
  },
  {
    "id": "arXiv:2202.03302",
    "title": "Numerical analysis for the interaction of mean curvature flow and  diffusion on closed surfaces",
    "abstract": "An evolving surface finite element discretisation is analysed for the\nevolution of a closed two-dimensional surface governed by a system coupling a\ngeneralised forced mean curvature flow and a reaction--diffusion process on the\nsurface, inspired by a gradient flow of a coupled energy. Two algorithms are\nproposed, both based on a system coupling the diffusion equation to evolution\nequations for geometric quantities in the velocity law for the surface.\nOne of the numerical methods is proved to be convergent in the $H^1$ norm\nwith optimal-order for finite elements of degree at least two.\nWe present numerical experiments illustrating the convergence behaviour and\ndemonstrating the qualitative properties of the flow: preservation of mean\nconvexity, loss of convexity, weak maximum principles, and the occurrence of\nself-intersections.",
    "descriptor": "",
    "authors": [
      "Charles M. Elliott",
      "Harald Garcke",
      "Bal\u00e1zs Kov\u00e1cs"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.03302"
  },
  {
    "id": "arXiv:2202.03310",
    "title": "Exploratory analysis of text duplication in peer-review reveals  peer-review fraud and paper mills",
    "abstract": "Comments received from referees during peer-review were analysed to determine\nthe rates of duplication and partial duplication. It is very unusual for 2\ndifferent referees to submit identical comments, so the rare cases where this\nhappens are of interest. In some cases, it appears that paper-mills create fake\nreferee accounts and use them to submit fake peer-review reports. These include\ncomments that are copied and pasted across multiple reviews. Searching for\nduplication in referee comments is therefore an effective method to search for\nmisconduct generally, since the forms of misconduct committed by paper-mills go\nbeyond peer-review fraud. These search methods allow the automatic detection of\nmisconduct candidates which may then be investigated carefully to confirm if\nmisconduct has indeed taken place. There are innocent reasons why referees\nmight share template reports, so these methods are not intended to\nautomatically diagnose misconduct.",
    "descriptor": "",
    "authors": [
      "Adam Day"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2202.03310"
  },
  {
    "id": "arXiv:2202.03314",
    "title": "A Robot Web for Distributed Many-Device Localisation",
    "abstract": "We show that a distributed network of robots or other devices which make\nmeasurements of each other can collaborate to globally localise via efficient\nad-hoc peer to peer communication. Our Robot Web solution is based on Gaussian\nBelief Propagation on the fundamental non-linear factor graph describing the\nprobabilistic structure of all of the observations robots make internally or of\neach other, and is flexible for any type of robot, motion or sensor. We define\na simple and efficient communication protocol which can be implemented by the\npublishing and reading of web pages or other asynchronous communication\ntechnologies. We show in simulations with up to 1000 robots interacting in\narbitrary patterns that our solution convergently achieves global accuracy as\naccurate as a centralised non-linear factor graph solver while operating with\nhigh distributed efficiency of computation and communication. Via the use of\nrobust factors in GBP, our method is tolerant to a high percentage of faults in\nsensor measurements or dropped communication packets.",
    "descriptor": "\nComments: 18 pages, 7 figures\n",
    "authors": [
      "Riku Murai",
      "Joseph Ortiz",
      "Sajad Saeedi",
      "Paul H.J. Kelly",
      "Andrew J. Davison"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2202.03314"
  },
  {
    "id": "arXiv:2202.03316",
    "title": "Bow-Tie Structures of Twitter Discursive Communities",
    "abstract": "Bow-tie structures were introduced to describe the World Wide Web: in the\ndirect network in which the nodes are the websites and the edges are the\nhyperlinks connecting them, the greatest number of nodes take part to a\nbow-tie, i.e. a Weakly Connected Component (WCC) composed of 3 main sectors:\nIN, OUT and SCC. SCC is the main Strongly Connected Component of WCC: it\ncontains the greatest subgraph in which each node is reachable by any other one\nin the subgraph. The IN and OUT sectors are the set of nodes not included in\nSCC that, respectively, can access and are accessible to nodes in SCC. In SCC\nthe greatest part of the websites can be found, while the search engines\nbelongs to IN, and the authorities, as Wikipedia, are in OUT. In the analysis\nof Twitter debate, the recent literature focused on discursive communities,\ni.e. clusters of accounts interacting among themselves via retweets. In the\npresent work, we studied discursive communities in 8 different thematic Twitter\ndata sets in various languages. Surprisingly, we observed that almost all\ndiscursive communities therein display a bow-tie structure during political or\nsocietal debates. Instead, they are absent when the argument of the discussion\nis different as sport events, as in the case of Euro2020 Turkish and Italian\ndata sets. We furthermore analysed the quality of the content created in the\nvarious sectors, using the domain annotation from the fact-checking website\nNewsguard: it turns out that content with the lowest quality is the ones\nproduced and shared in SCC. In this sense, in discursive communities displaying\ngreat OUT blocks, the greatest part of the accounts has access to a great\nvariety of contents, but their quality is, in general, quite low, creating the\nphenomenon known as infodemic. In the present paper, we correlate the presence\nof an infodemic to a peculiar network structure, i.e. a OUT-dominant bow-tie.",
    "descriptor": "\nComments: 46 pages, 25 figures\n",
    "authors": [
      "Mattia Mattei",
      "Manuel Pratelli",
      "Guido Caldarelli",
      "Marinella Petrocchi",
      "Fabio Saracco"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ],
    "url": "https://arxiv.org/abs/2202.03316"
  },
  {
    "id": "arXiv:2202.03322",
    "title": "Reducing the Vertex Cover Number via Edge Contractions",
    "abstract": "The CONTRACTION(vc) problem takes as input a graph $G$ on $n$ vertices and\ntwo integers $k$ and $d$, and asks whether one can contract at most $k$ edges\nto reduce the size of a minimum vertex cover of $G$ by at least $d$. Recently,\nLima et al. [JCSS 2021] proved, among other results, that unlike most of the\nso-called blocker problems, CONTRACTION(vc) admits an XP algorithm running in\ntime $f(d) \\cdot n^{O(d)}$. They left open the question of whether this problem\nis FPT under this parameterization. In this article, we continue this line of\nresearch and prove the following results:\n1. CONTRACTION(vc) is W[1]-hard parameterized by $k + d$. Moreover, unless\nthe ETH fails, the problem does not admit an algorithm running in time $f(k +\nd) \\cdot n^{o(k + d)}$ for any function $f$. In particular, this answers the\nopen question stated in Lima et al. [JCSS 2021] in the negative.\n2. It is NP-hard to decide whether an instance $(G, k, d)$ of CONTRACTION(vc)\nis a yes-instance even when $k = d$, hence enhancing our understanding of the\nclassical complexity of the problem.\n3. CONTRACTION(vc) can be solved in time $2^{O(d)} \\cdot n^{k - d + O(1)}$.\nThis XP algorithm improves the one of Lima et al. [JCSS 2021], which uses\nCourcelle's theorem as a subroutine and hence, the $f(d)$-factor in the running\ntime is non-explicit and probably very large. On the other hard, it shows that\nwhen $k=d$, the problem is FPT parameterized by $d$ (or by $k$).",
    "descriptor": "\nComments: 35 pages, 5 figures\n",
    "authors": [
      "Paloma T. Lima",
      "Vinicius F. dos Santos",
      "Ignasi Sau",
      "U\u00e9verton S. Souza",
      "Prafullkumar Tale"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Complexity (cs.CC)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2202.03322"
  },
  {
    "id": "arXiv:2202.03325",
    "title": "Differential Privacy for Symbolic Systems with Application to Markov  Chains",
    "abstract": "Data-driven systems are gathering increasing amounts of data from users, and\nsensitive user data requires privacy protections. In some cases, the data\ngathered is non-numerical or symbolic, and conventional approaches to privacy,\ne.g., adding noise, do not apply, though such systems still require privacy\nprotections. Accordingly, we present a novel differential privacy framework for\nprotecting trajectories generated by symbolic systems. These trajectories can\nbe represented as words or strings over a finite alphabet. We develop new\ndifferential privacy mechanisms that approximate a sensitive word using a\nrandom word that is likely to be near it. An offline mechanism is implemented\nefficiently using a Modified Hamming Distance Automaton to generate whole\nprivatized output words over a finite time horizon. Then, an online mechanism\nis implemented by taking in a sensitive symbol and generating a randomized\noutput symbol at each timestep. This work is extended to Markov chains to\ngenerate differentially private state sequences that a given Markov chain could\nhave produced. Statistical accuracy bounds are developed to quantify the\naccuracy of these mechanisms, and numerical results validate the accuracy of\nthese techniques for strings of English words.",
    "descriptor": "\nComments: 13 pages, 8 figures, submitted to Automatica\n",
    "authors": [
      "Bo Chen",
      "Kevin Leahy",
      "Austin Jones",
      "Matthew Hale"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Symbolic Computation (cs.SC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.03325"
  },
  {
    "id": "arXiv:2202.03327",
    "title": "Probabilistic Consensus on Feature Distribution for Multi-robot Systems  with Markovian Exploration Dynamics",
    "abstract": "In this paper, we present a consensus-based decentralized multi-robot\napproach to reconstruct a discrete distribution of features, modeled as an\noccupancy grid map, that represent information contained in a bounded planar\nenvironment, such as visual cues used for navigation or semantic labels\nassociated with object detection. The robots explore the environment according\nto a random walk modeled by a discrete-time discrete-state (DTDS) Markov chain\nand estimate the feature distribution from their own measurements and the\nestimates communicated by neighboring robots, using a distributed Chernoff\nfusion protocol. We prove that under this decentralized fusion protocol, each\nrobot's feature distribution converges to the actual distribution in an almost\nsure sense. We verify this result in numerical simulations that show that the\nHellinger distance between the estimated and actual feature distributions\nconverges to zero over time for each robot. We also validate our strategy\nthrough Software-In-The-Loop (SITL) simulations of quadrotors that search a\nbounded square grid for a set of visual features distributed on a discretized\ncircle.",
    "descriptor": "\nComments: 8 pages, 13 figures\n",
    "authors": [
      "Aniket Shirsat",
      "Shatadal Mishra",
      "Wenlong Zhang",
      "Spring Berman"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.03327"
  },
  {
    "id": "arXiv:2202.03334",
    "title": "Policy Optimization for Stochastic Shortest Path",
    "abstract": "Policy optimization is among the most popular and successful reinforcement\nlearning algorithms, and there is increasing interest in understanding its\ntheoretical guarantees. In this work, we initiate the study of policy\noptimization for the stochastic shortest path (SSP) problem, a goal-oriented\nreinforcement learning model that strictly generalizes the finite-horizon model\nand better captures many applications. We consider a wide range of settings,\nincluding stochastic and adversarial environments under full information or\nbandit feedback, and propose a policy optimization algorithm for each setting\nthat makes use of novel correction terms and/or variants of dilated bonuses\n(Luo et al., 2021). For most settings, our algorithm is shown to achieve a\nnear-optimal regret bound.\nOne key technical contribution of this work is a new approximation scheme to\ntackle SSP problems that we call \\textit{stacked discounted approximation} and\nuse in all our proposed algorithms. Unlike the finite-horizon approximation\nthat is heavily used in recent SSP algorithms, our new approximation enables us\nto learn a near-stationary policy with only logarithmic changes during an\nepisode and could lead to an exponential improvement in space complexity.",
    "descriptor": "",
    "authors": [
      "Liyu Chen",
      "Haipeng Luo",
      "Aviv Rosenberg"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.03334"
  },
  {
    "id": "arXiv:2202.03335",
    "title": "Membership Inference Attacks and Defenses in Neural Network Pruning",
    "abstract": "Neural network pruning has been an essential technique to reduce the\ncomputation and memory requirements for using deep neural networks for\nresource-constrained devices. Most existing research focuses primarily on\nbalancing the sparsity and accuracy of a pruned neural network by strategically\nremoving insignificant parameters and retraining the pruned model. Such efforts\non reusing training samples pose serious privacy risks due to increased\nmemorization, which, however, has not been investigated yet.\nIn this paper, we conduct the first analysis of privacy risks in neural\nnetwork pruning. Specifically, we investigate the impacts of neural network\npruning on training data privacy, i.e., membership inference attacks. We first\nexplore the impact of neural network pruning on prediction divergence, where\nthe pruning process disproportionately affects the pruned model's behavior for\nmembers and non-members. Meanwhile, the influence of divergence even varies\namong different classes in a fine-grained manner. Enlighten by such divergence,\nwe proposed a self-attention membership inference attack against the pruned\nneural networks. Extensive experiments are conducted to rigorously evaluate the\nprivacy impacts of different pruning approaches, sparsity levels, and adversary\nknowledge. The proposed attack shows the higher attack performance on the\npruned models when compared with eight existing membership inference attacks.\nIn addition, we propose a new defense mechanism to protect the pruning process\nby mitigating the prediction divergence based on KL-divergence distance, whose\neffectiveness has been experimentally demonstrated to effectively mitigate the\nprivacy risks while maintaining the sparsity and accuracy of the pruned models.",
    "descriptor": "\nComments: This paper has been conditionally accepted to USENIX Security Symposium 2022. This is an extended version\n",
    "authors": [
      "Xiaoyong Yuan",
      "Lan Zhang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.03335"
  },
  {
    "id": "arXiv:2202.03341",
    "title": "Neighbor2Seq: Deep Learning on Massive Graphs by Transforming Neighbors  to Sequences",
    "abstract": "Modern graph neural networks (GNNs) use a message passing scheme and have\nachieved great success in many fields. However, this recursive design\ninherently leads to excessive computation and memory requirements, making it\nnot applicable to massive real-world graphs. In this work, we propose the\nNeighbor2Seq to transform the hierarchical neighborhood of each node into a\nsequence. This novel transformation enables the subsequent mini-batch training\nfor general deep learning operations, such as convolution and attention, that\nare designed for grid-like data and are shown to be powerful in various\ndomains. Therefore, our Neighbor2Seq naturally endows GNNs with the efficiency\nand advantages of deep learning operations on grid-like data by precomputing\nthe Neighbor2Seq transformations. We evaluate our method on a massive graph,\nwith more than 111 million nodes and 1.6 billion edges, as well as several\nmedium-scale graphs. Results show that our proposed method is scalable to\nmassive graphs and achieves superior performance across massive and\nmedium-scale graphs. Our code is available at\nhttps://github.com/divelab/Neighbor2Seq.",
    "descriptor": "\nComments: Accepted by SDM2022\n",
    "authors": [
      "Meng Liu",
      "Shuiwang Ji"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.03341"
  },
  {
    "id": "arXiv:2202.03343",
    "title": "Topological Analysis of Vector-Field Guided Path Following on Manifolds",
    "abstract": "A path-following control algorithm enables a system's trajectories under its\nguidance to converge to and evolve along a given geometric desired path. There\nexist various such algorithms, but many of them can only guarantee local\nconvergence to the desired path in its neighborhood. In contrast, the control\nalgorithms using a well-designed guiding vector field can ensure almost global\nconvergence of trajectories to the desired path; here, \"almost\" means that in\nsome cases, a measure-zero set of trajectories converge to the singular set\nwhere the vector field becomes zero (with all other trajectories converging to\nthe desired path). In this paper, we first generalize the guiding vector field\nfrom the Euclidean space to a general smooth Riemannian manifold. This\ngeneralization can deal with path-following in some abstract configuration\nspace (such as robot arm joint space). Then we show several theoretical results\nfrom a topological viewpoint. Specifically, we are motivated by the observation\nthat singular points of the guiding vector field exist in many examples where\nthe desired path is homeomorphic to the unit circle, but it is unknown whether\nthe existence of singular points always holds in general (i.e., is inherent in\nthe topology of the desired path). In the $n$-dimensional Euclidean space, we\nprovide an affirmative answer, and conclude that it is not possible to\nguarantee global convergence to desired paths that are homeomorphic to the unit\ncircle. Furthermore, we show that there always exist \\emph{non-path-converging\ntrajectories} (i.e., trajectories that do not converge to the desired path)\nstarting from the boundary of a ball containing the desired path in an\n$n$-dimensional Euclidean space where $n \\ge 3$. Examples are provided to\nillustrate the theoretical results.",
    "descriptor": "\nComments: 16 pages, 8 figures, TAC\n",
    "authors": [
      "Weijia Yao",
      "Bohuan Lin",
      "Brian D. O. Anderson",
      "Ming Cao"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.03343"
  },
  {
    "id": "arXiv:2202.03347",
    "title": "FrePGAN: Robust Deepfake Detection Using Frequency-level Perturbations",
    "abstract": "Various deepfake detectors have been proposed, but challenges still exist to\ndetect images of unknown categories or GAN models outside of the training\nsettings. Such issues arise from the overfitting issue, which we discover from\nour own analysis and the previous studies to originate from the frequency-level\nartifacts in generated images. We find that ignoring the frequency-level\nartifacts can improve the detector's generalization across various GAN models,\nbut it can reduce the model's performance for the trained GAN models. Thus, we\ndesign a framework to generalize the deepfake detector for both the known and\nunseen GAN models. Our framework generates the frequency-level perturbation\nmaps to make the generated images indistinguishable from the real images. By\nupdating the deepfake detector along with the training of the perturbation\ngenerator, our model is trained to detect the frequency-level artifacts at the\ninitial iterations and consider the image-level irregularities at the last\niterations. For experiments, we design new test scenarios varying from the\ntraining settings in GAN models, color manipulations, and object categories.\nNumerous experiments validate the state-of-the-art performance of our deepfake\ndetector.",
    "descriptor": "",
    "authors": [
      "Yonghyun Jeong",
      "Doyeon Kim",
      "Youngmin Ro",
      "Jongwon Choi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2202.03347"
  },
  {
    "id": "arXiv:2202.03348",
    "title": "Failure and success of the spectral bias prediction for Kernel Ridge  Regression: the case of low-dimensional data",
    "abstract": "Recently, several theories including the replica method made predictions for\nthe generalization error of Kernel Ridge Regression. In some regimes, they\npredict that the method has a `spectral bias': decomposing the true function\n$f^*$ on the eigenbasis of the kernel, it fits well the coefficients associated\nwith the O(P) largest eigenvalues, where $P$ is the size of the training set.\nThis prediction works very well on benchmark data sets such as images, yet the\nassumptions these approaches make on the data are never satisfied in practice.\nTo clarify when the spectral bias prediction holds, we first focus on a\none-dimensional model where rigorous results are obtained and then use scaling\narguments to generalize and test our findings in higher dimensions. Our\npredictions include the classification case $f(x)=$sign$(x_1)$ with a data\ndistribution that vanishes at the decision boundary $p(x)\\sim x_1^{\\chi}$. For\n$\\chi>0$ and a Laplace kernel, we find that (i) there exists a cross-over ridge\n$\\lambda^*_{d,\\chi}(P)\\sim P^{-\\frac{1}{d+\\chi}}$ such that for $\\lambda\\gg\n\\lambda^*_{d,\\chi}(P)$, the replica method applies, but not for\n$\\lambda\\ll\\lambda^*_{d,\\chi}(P)$, (ii) in the ridge-less case, spectral bias\npredicts the correct training curve exponent only in the limit\n$d\\rightarrow\\infty$.",
    "descriptor": "\nComments: 34 pages, 11 figures\n",
    "authors": [
      "Umberto M. Tomasini",
      "Antonio Sclocchi",
      "Matthieu Wyart"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistical Mechanics (cond-mat.stat-mech)"
    ],
    "url": "https://arxiv.org/abs/2202.03348"
  },
  {
    "id": "arXiv:2202.03349",
    "title": "Conditional Gradients for the Approximately Vanishing Ideal",
    "abstract": "The vanishing ideal of a set of points $X\\subseteq \\mathbb{R}^n$ is the set\nof polynomials that evaluate to $0$ over all points $\\mathbf{x} \\in X$ and\nadmits an efficient representation by a finite set of polynomials called\ngenerators. To accommodate the noise in the data set, we introduce the\nConditional Gradients Approximately Vanishing Ideal algorithm (CGAVI) for the\nconstruction of the set of generators of the approximately vanishing ideal. The\nconstructed set of generators captures polynomial structures in data and gives\nrise to a feature map that can, for example, be used in combination with a\nlinear classifier for supervised learning. In CGAVI, we construct the set of\ngenerators by solving specific instances of (constrained) convex optimization\nproblems with the Pairwise Frank-Wolfe algorithm (PFW). Among other things, the\nconstructed generators inherit the LASSO generalization bound and not only\nvanish on the training but also on out-sample data. Moreover, CGAVI admits a\ncompact representation of the approximately vanishing ideal by constructing few\ngenerators with sparse coefficient vectors.",
    "descriptor": "\nComments: 22 pages\n",
    "authors": [
      "E. Wirth",
      "S. Pokutta"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.03349"
  },
  {
    "id": "arXiv:2202.03350",
    "title": "Optimal Gathering over Meeting Nodes in Infinite Grid",
    "abstract": "The gathering over meeting nodes problem requires the robots to gather at one\nof the pre-defined meeting nodes. This paper investigates the problem with\nrespect to the objective function that minimizes the total number of moves made\nby all the robots. In other words, the sum of the distances traveled by all the\nrobots is minimized while accomplishing the gathering task. The robots are\ndeployed on the nodes of an anonymous two-dimensional infinite grid which has a\nsubset of nodes marked as meeting nodes. The robots do not agree on a global\ncoordinate system and operate under an asynchronous scheduler. A deterministic\ndistributed algorithm has been proposed to solve the problem for all those\nsolvable configurations, and the initial configurations for which the problem\nis unsolvable have been characterized. The proposed gathering algorithm is\noptimal with respect to the total number of moves performed by all the robots\nin order to finalize the gathering.",
    "descriptor": "",
    "authors": [
      "Subhash Bhagat",
      "Abhinav Chakraborty",
      "Bibhuti Das",
      "Krishnendu Mukhopadhyaya"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2202.03350"
  },
  {
    "id": "arXiv:2202.03352",
    "title": "Analog Secure Distributed Matrix Multiplication over Complex Numbers",
    "abstract": "This work considers the problem of distributing matrix multiplication over\nthe real or complex numbers to helper servers, such that the information\nleakage to these servers is close to being information-theoretically secure.\nThese servers are assumed to be honest-but-curious, i.e., they work according\nto the protocol, but try to deduce information about the data. The problem of\nsecure distributed matrix multiplication (SDMM) has been considered in the\ncontext of matrix multiplication over finite fields, which is not always\nfeasible in real world applications. We present two schemes, which allow for\nvariable degree of security based on the use case and allow for colluding and\nstraggling servers. We analyze the security and the numerical accuracy of the\nschemes and observe a trade-off between accuracy and security.",
    "descriptor": "\nComments: 13 pages, 2 figures\n",
    "authors": [
      "Okko Makkonen",
      "Camilla Hollanti"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.03352"
  },
  {
    "id": "arXiv:2202.03354",
    "title": "Robust Dialogue State Tracking with Weak Supervision and Sparse Data",
    "abstract": "Generalising dialogue state tracking (DST) to new data is especially\nchallenging due to the strong reliance on abundant and fine-grained supervision\nduring training. Sample sparsity, distributional shift and the occurrence of\nnew concepts and topics frequently lead to severe performance degradation\nduring inference. In this paper we propose a training strategy to build\nextractive DST models without the need for fine-grained manual span labels. Two\nnovel input-level dropout methods mitigate the negative impact of sample\nsparsity. We propose a new model architecture with a unified encoder that\nsupports value as well as slot independence by leveraging the attention\nmechanism. We combine the strengths of triple copy strategy DST and value\nmatching to benefit from complementary predictions without violating the\nprinciple of ontology independence. Our experiments demonstrate that an\nextractive DST model can be trained without manual span labels. Our\narchitecture and training strategies improve robustness towards sample\nsparsity, new concepts and topics, leading to state-of-the-art performance on a\nrange of benchmarks. We further highlight our model's ability to effectively\nlearn from non-dialogue data.",
    "descriptor": "\nComments: 13 pages, 7 figures\n",
    "authors": [
      "Michael Heck",
      "Nurul Lubis",
      "Carel van Niekerk",
      "Shutong Feng",
      "Christian Geishauser",
      "Hsien-Chin Lin",
      "Milica Ga\u0161i\u0107"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.03354"
  },
  {
    "id": "arXiv:2202.03356",
    "title": "Optimal Direct-Connect Topologies for Collective Communications",
    "abstract": "We consider the problem of distilling optimal network topologies for\ncollective communications. We provide an algorithmic framework for constructing\ndirect-connect topologies optimized for the latency-bandwidth tradeoff given a\ncollective communication workload. Our algorithmic framework allows us to start\nfrom small base topologies and associated communication schedules and use a set\nof techniques that can be iteratively applied to derive much larger topologies\nand associated schedules. Our approach allows us to synthesize many different\ntopologies and schedules for a given cluster size and degree constraint, and\nthen identify the optimal topology for a given workload. We provide an\nanalytical-model-based evaluation of the derived topologies and results on a\nsmall-scale optical testbed that uses patch panels for configuring a topology\nfor the duration of an application's execution. We show that the derived\ntopologies and schedules provide significant performance benefits over existing\ncollective communications implementations.",
    "descriptor": "",
    "authors": [
      "Liangyu Zhao",
      "Siddharth Pal",
      "Tapan Chugh",
      "Weiyang Wang",
      "Prithwish Basu",
      "Joud Khoury",
      "Arvind Krishnamurthy"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.03356"
  },
  {
    "id": "arXiv:2202.03360",
    "title": "Discrete-Event Controller Synthesis for Autonomous Systems with  Deep-Learning Perception Components",
    "abstract": "We present DEEPDECS, a new method for the synthesis of\ncorrect-by-construction discrete-event controllers for autonomous systems that\nuse deep neural network (DNN) classifiers for the perception step of their\ndecision-making processes. Despite major advances in deep learning in recent\nyears, providing safety guarantees for these systems remains very challenging.\nOur controller synthesis method addresses this challenge by integrating DNN\nverification with the synthesis of verified Markov models. The synthesised\nmodels correspond to discrete-event controllers guaranteed to satisfy the\nsafety, dependability and performance requirements of the autonomous system,\nand to be Pareto optimal with respect to a set of optimisation criteria. We use\nthe method in simulation to synthesise controllers for mobile-robot collision\navoidance, and for maintaining driver attentiveness in shared-control\nautonomous driving.",
    "descriptor": "\nComments: 18 pages 6 Figures 2 Tables\n",
    "authors": [
      "Radu Calinescu",
      "Calum Imrie",
      "Ravi Mangal",
      "Corina P\u0103s\u0103reanu",
      "Misael Alpizar Santana",
      "Gricel V\u00e1zquez"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.03360"
  },
  {
    "id": "arXiv:2202.03365",
    "title": "Simple Control Baselines for Evaluating Transfer Learning",
    "abstract": "Transfer learning has witnessed remarkable progress in recent years, for\nexample, with the introduction of augmentation-based contrastive\nself-supervised learning methods. While a number of large-scale empirical\nstudies on the transfer performance of such models have been conducted, there\nis not yet an agreed-upon set of control baselines, evaluation practices, and\nmetrics to report, which often hinders a nuanced and calibrated understanding\nof the real efficacy of the methods. We share an evaluation standard that aims\nto quantify and communicate transfer learning performance in an informative and\naccessible setup. This is done by baking a number of simple yet critical\ncontrol baselines in the evaluation method, particularly the blind-guess\n(quantifying the dataset bias), scratch-model (quantifying the architectural\ncontribution), and maximal-supervision (quantifying the upper-bound). To\ndemonstrate how the evaluation standard can be employed, we provide an example\nempirical study investigating a few basic questions about self-supervised\nlearning. For example, using this standard, the study shows the effectiveness\nof existing self-supervised pre-training methods is skewed towards image\nclassification tasks versus dense pixel-wise predictions. In general, we\nencourage using/reporting the suggested control baselines in evaluating\ntransfer learning in order to gain a more meaningful and informative\nunderstanding.",
    "descriptor": "\nComments: Project website: this https URL\n",
    "authors": [
      "Andrei Atanov",
      "Shijian Xu",
      "Onur Beker",
      "Andrei Filatov",
      "Amir Zamir"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.03365"
  },
  {
    "id": "arXiv:2202.03367",
    "title": "A longitudinal case study on the effects of an evidence-based software  engineering training",
    "abstract": "Context: Evidence-based software engineering (EBSE) can be an effective\nresource to bridge the gap between academia and industry by balancing research\nof practical relevance and academic rigor. To achieve this, it seems necessary\nto investigate EBSE training and its benefits for the practice. Objective: We\nsought both to develop an EBSE training course for university students and to\ninvestigate what effects it has on the attitudes and behaviors of the trainees.\nMethod: We conducted a longitudinal case study to study our EBSE course and its\neffects. For this, we collect data at the end of each EBSE course (2017, 2018,\nand 2019), and in two follow-up surveys (one after 7 months of finishing the\nlast course, and a second after 21 months). Results: Our EBSE courses seem to\nhave taught students adequately and consistently. Half of the respondents to\nthe surveys report making use of the new skills from the course. The\nmost-reported effects in both surveys indicated that EBSE concepts increase\nawareness of the value of research and evidence and EBSE methods improve\ninformation gathering skills. Conclusions: As suggested by research in other\nareas, training appears to play a key role in the adoption of evidence-based\npractice. Our results indicate that our training method provides an\nintroduction to EBSE suitable for undergraduates. However, we believe it is\nnecessary to continue investigating EBSE training and its impact on software\nengineering practice.",
    "descriptor": "\nComments: this https URL\n",
    "authors": [
      "Sebasti\u00e1n Pizard",
      "Diego Vallespir",
      "Barbara Kitchenham"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2202.03367"
  },
  {
    "id": "arXiv:2202.03371",
    "title": "Cedille: A large autoregressive French language model",
    "abstract": "Scaling up the size and training of autoregressive language models has\nenabled novel ways of solving Natural Language Processing tasks using zero-shot\nand few-shot learning. While extreme-scale language models such as GPT-3 offer\nmultilingual capabilities, zero-shot learning for languages other than English\nremain largely unexplored. Here, we introduce Cedille, a large open source\nauto-regressive language model, specifically trained for the French language.\nOur results show that Cedille outperforms existing French language models and\nis competitive with GPT-3 on a range of French zero-shot benchmarks.\nFurthermore, we provide an in-depth comparison of the toxicity exhibited by\nthese models, showing that Cedille marks an improvement in language model\nsafety thanks to dataset filtering.",
    "descriptor": "\nComments: 8 pages, 1 figure, 7 tables\n",
    "authors": [
      "Martin M\u00fcller",
      "Florian Laurent"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.03371"
  },
  {
    "id": "arXiv:2202.03376",
    "title": "Message Passing Neural PDE Solvers",
    "abstract": "The numerical solution of partial differential equations (PDEs) is difficult,\nhaving led to a century of research so far. Recently, there have been pushes to\nbuild neural--numerical hybrid solvers, which piggy-backs the modern trend\ntowards fully end-to-end learned systems. Most works so far can only generalize\nover a subset of properties to which a generic solver would be faced,\nincluding: resolution, topology, geometry, boundary conditions, domain\ndiscretization regularity, dimensionality, etc. In this work, we build a\nsolver, satisfying these properties, where all the components are based on\nneural message passing, replacing all heuristically designed components in the\ncomputation graph with backprop-optimized neural function approximators. We\nshow that neural message passing solvers representationally contain some\nclassical methods, such as finite differences, finite volumes, and WENO\nschemes. In order to encourage stability in training autoregressive models, we\nput forward a method that is based on the principle of zero-stability, posing\nstability as a domain adaptation problem. We validate our method on various\nfluid-like flow problems, demonstrating fast, stable, and accurate performance\nacross different domain topologies, discretization, etc. in 1D and 2D. Our\nmodel outperforms state-of-the-art numerical solvers in the low resolution\nregime in terms of speed and accuracy.",
    "descriptor": "\nComments: Published at ICLR 2022\n",
    "authors": [
      "Johannes Brandstetter",
      "Daniel Worrall",
      "Max Welling"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.03376"
  },
  {
    "id": "arXiv:2202.03377",
    "title": "Benchmarking and Analyzing Point Cloud Classification under Corruptions",
    "abstract": "3D perception, especially point cloud classification, has achieved\nsubstantial progress. However, in real-world deployment, point cloud\ncorruptions are inevitable due to the scene complexity, sensor inaccuracy, and\nprocessing imprecision. In this work, we aim to rigorously benchmark and\nanalyze point cloud classification under corruptions. To conduct a systematic\ninvestigation, we first provide a taxonomy of common 3D corruptions and\nidentify the atomic corruptions. Then, we perform a comprehensive evaluation on\na wide range of representative point cloud models to understand their\nrobustness and generalizability. Our benchmark results show that although point\ncloud classification performance improves over time, the state-of-the-art\nmethods are on the verge of being less robust. Based on the obtained\nobservations, we propose several effective techniques to enhance point cloud\nclassifier robustness. We hope our comprehensive benchmark, in-depth analysis,\nand proposed techniques could spark future research in robust 3D perception.",
    "descriptor": "\nComments: Code and dataset are available at this https URL\n",
    "authors": [
      "Jiawei Ren",
      "Liang Pan",
      "Ziwei Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.03377"
  },
  {
    "id": "arXiv:2202.03382",
    "title": "Corrupted Image Modeling for Self-Supervised Visual Pre-Training",
    "abstract": "We introduce Corrupted Image Modeling (CIM) for self-supervised visual\npre-training. CIM uses an auxiliary generator with a small trainable BEiT to\ncorrupt the input image instead of using artificial mask tokens, where some\npatches are randomly selected and replaced with plausible alternatives sampled\nfrom the BEiT output distribution. Given this corrupted image, an enhancer\nnetwork learns to either recover all the original image pixels, or predict\nwhether each visual token is replaced by a generator sample or not. The\ngenerator and the enhancer are simultaneously trained and synergistically\nupdated. After pre-training, the enhancer can be used as a high-capacity visual\nencoder for downstream tasks. CIM is a general and flexible visual pre-training\nframework that is suitable for various network architectures. For the first\ntime, CIM demonstrates that both ViT and CNN can learn rich visual\nrepresentations using a unified, non-Siamese framework. Experimental results\nshow that our approach achieves compelling results in vision benchmarks, such\nas ImageNet classification and ADE20K semantic segmentation. For example,\n300-epoch CIM pre-trained vanilla ViT-Base/16 and ResNet-50 obtain 83.3 and\n80.6 Top-1 fine-tuning accuracy on ImageNet-1K image classification\nrespectively.",
    "descriptor": "\nComments: Preprint. Work in progress. Code will be released at this https URL\n",
    "authors": [
      "Yuxin Fang",
      "Li Dong",
      "Hangbo Bao",
      "Xinggang Wang",
      "Furu Wei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.03382"
  },
  {
    "id": "arXiv:2202.03384",
    "title": "Hybrid Contrastive Quantization for Efficient Cross-View Video Retrieval",
    "abstract": "With the recent boom of video-based social platforms (e.g., YouTube and\nTikTok), video retrieval using sentence queries has become an important demand\nand attracts increasing research attention. Despite the decent performance,\nexisting text-video retrieval models in vision and language communities are\nimpractical for large-scale Web search because they adopt brute-force search\nbased on high-dimensional embeddings. To improve efficiency, Web search engines\nwidely apply vector compression libraries (e.g., FAISS) to post-process the\nlearned embeddings. Unfortunately, separate compression from feature encoding\ndegrades the robustness of representations and incurs performance decay. To\npursue a better balance between performance and efficiency, we propose the\nfirst quantized representation learning method for cross-view video retrieval,\nnamely Hybrid Contrastive Quantization (HCQ). Specifically, HCQ learns both\ncoarse-grained and fine-grained quantizations with transformers, which provide\ncomplementary understandings for texts and videos and preserve comprehensive\nsemantic information. By performing Asymmetric-Quantized Contrastive Learning\n(AQ-CL) across views, HCQ aligns texts and videos at coarse-grained and\nmultiple fine-grained levels. This hybrid-grained learning strategy serves as\nstrong supervision on the cross-view video quantization model, where\ncontrastive learning at different levels can be mutually promoted. Extensive\nexperiments on three Web video benchmark datasets demonstrate that HCQ achieves\ncompetitive performance with state-of-the-art non-compressed retrieval methods\nwhile showing high efficiency in storage and computation. Code and\nconfigurations are available at https://github.com/gimpong/WWW22-HCQ.",
    "descriptor": "\nComments: Accepted to The Web Conference 2022 (WWW'22). 11 pages, 5 tables, 6 figures\n",
    "authors": [
      "Jinpeng Wang",
      "Bin Chen",
      "Dongliang Liao",
      "Ziyun Zeng",
      "Gongfu Li",
      "Shu-Tao Xia",
      "Jin Xu"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2202.03384"
  },
  {
    "id": "arXiv:2202.03385",
    "title": "Using Multiwinner Voting to Search for Movies",
    "abstract": "We show a prototype of a system that uses multiwinner voting to suggest\nresources (such as movies) related to a given query set (such as a movie that\none enjoys). Depending on the voting rule used, the system can either provide\nresources very closely related to the query set or a broader spectrum of\noptions. We show how this ability can be interpreted as a way of controlling\nthe diversity of the results. We test our system both on synthetic data and on\nthe real-life collection of movie ratings from the MovieLens dataset. We also\npresent a visual comparison of the search results corresponding to selected\ndiversity levels.",
    "descriptor": "\nComments: 20 pages, 10 figures, 2 tables\n",
    "authors": [
      "Grzegorz Gawron",
      "Piotr Faliszewski"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2202.03385"
  },
  {
    "id": "arXiv:2202.03388",
    "title": "Distributed Differentially Private Ranking Aggregation",
    "abstract": "Ranking aggregation is commonly adopted in cooperative decision-making to\nassist in combining multiple rankings into a single representative. To protect\nthe actual ranking of each individual, some privacy-preserving strategies, such\nas differential privacy, are often used. This, however, does not consider the\nscenario where the curator, who collects all rankings from individuals, is\nuntrustworthy. This paper proposed a mechanism to solve the above situation\nusing the distribute differential privacy framework. The proposed mechanism\ncollects locally differential private rankings from individuals, then randomly\npermutes pairwise rankings using a shuffle model to further amplify the privacy\nprotection. The final representative is produced by hierarchical rank\naggregation. The mechanism was theoretically analysed and experimentally\ncompared against existing methods, and demonstrated competitive results in both\nthe output accuracy and privacy protection.",
    "descriptor": "",
    "authors": [
      "Baobao Song",
      "Qiujun Lan",
      "Yang Li",
      "Gang Li"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.03388"
  },
  {
    "id": "arXiv:2202.03390",
    "title": "GMC -- Geometric Multimodal Contrastive Representation Learning",
    "abstract": "Learning representations of multimodal data that are both informative and\nrobust to missing modalities at test time remains a challenging problem due to\nthe inherent heterogeneity of data obtained from different channels. To address\nit, we present a novel Geometric Multimodal Contrastive (GMC) representation\nlearning method comprised of two main components: i) a two-level architecture\nconsisting of modality-specific base encoder, allowing to process an arbitrary\nnumber of modalities to an intermediate representation of fixed dimensionality,\nand a shared projection head, mapping the intermediate representations to a\nlatent representation space; ii) a multimodal contrastive loss function that\nencourages the geometric alignment of the learned representations. We\nexperimentally demonstrate that GMC representations are semantically rich and\nachieve state-of-the-art performance with missing modality information on three\ndifferent learning problems including prediction and reinforcement learning\ntasks.",
    "descriptor": "",
    "authors": [
      "Petra Poklukar",
      "Miguel Vasco",
      "Hang Yin",
      "Francisco S. Melo",
      "Ana Paiva",
      "Danica Kragic"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.03390"
  },
  {
    "id": "arXiv:2202.03391",
    "title": "Gradient-Based Learning of Discrete Structured Measurement Operators for  Signal Recovery",
    "abstract": "Countless signal processing applications include the reconstruction of\nsignals from few indirect linear measurements. The design of effective\nmeasurement operators is typically constrained by the underlying hardware and\nphysics, posing a challenging and often even discrete optimization task. While\nthe potential of gradient-based learning via the unrolling of iterative\nrecovery algorithms has been demonstrated, it has remained unclear how to\nleverage this technique when the set of admissible measurement operators is\nstructured and discrete. We tackle this problem by combining unrolled\noptimization with Gumbel reparametrizations, which enable the computation of\nlow-variance gradient estimates of categorical random variables. Our approach\nis formalized by GLODISMO (Gradient-based Learning of DIscrete Structured\nMeasurement Operators). This novel method is easy-to-implement, computationally\nefficient, and extendable due to its compatibility with automatic\ndifferentiation. We empirically demonstrate the performance and flexibility of\nGLODISMO in several prototypical signal recovery applications, verifying that\nthe learned measurement matrices outperform conventional designs based on\nrandomization as well as discrete optimization baselines.",
    "descriptor": "",
    "authors": [
      "Jonathan Sauder",
      "Martin Genzel",
      "Peter Jung"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.03391"
  },
  {
    "id": "arXiv:2202.03392",
    "title": "Large-scale Personalized Video Game Recommendation via Social-aware  Contextualized Graph Neural Network",
    "abstract": "Because of the large number of online games available nowadays, online game\nrecommender systems are necessary for users and online game platforms. The\nformer can discover more potential online games of their interests, and the\nlatter can attract users to dwell longer in the platform. This paper\ninvestigates the characteristics of user behaviors with respect to the online\ngames on the Steam platform. Based on the observations, we argue that a\nsatisfying recommender system for online games is able to characterize:\npersonalization, game contextualization and social connection. However,\nsimultaneously solving all is rather challenging for game recommendation.\nFirstly, personalization for game recommendation requires the incorporation of\nthe dwelling time of engaged games, which are ignored in existing methods.\nSecondly, game contextualization should reflect the complex and high-order\nproperties of those relations. Last but not least, it is problematic to use\nsocial connections directly for game recommendations due to the massive noise\nwithin social connections. To this end, we propose a Social-aware\nContextualized Graph Neural Recommender System (SCGRec), which harnesses three\nperspectives to improve game recommendation. We conduct a comprehensive\nanalysis of users' online game behaviors, which motivates the necessity of\nhandling those three characteristics in the online game recommendation.",
    "descriptor": "",
    "authors": [
      "Liangwei Yang",
      "Zhiwei Liu",
      "Yu Wang",
      "Chen Wang",
      "Ziwei Fan",
      "Philip S. Yu"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2202.03392"
  },
  {
    "id": "arXiv:2202.03393",
    "title": "Link Prediction of Artificial Intelligence Concepts using Low  Computational Power",
    "abstract": "This paper presents an approach proposed for the Science4cast 2021\ncompetition, organized by the Institute of Advanced Research in Artificial\nIntelligence, whose main goal was to predict the likelihood of future\nassociations between machine learning concepts in a semantic network. The\ndeveloped methodology corresponds to a solution for a scenario of availability\nof low computational power only, exploiting the extraction of low order\ntopological features and its incorporation in an optimized classifier to\nestimate the degree of future connections between the nodes. The reasons that\nmotivated the developed methodologies will be discussed, as well as some\nresults, limitations and suggestions of improvements.",
    "descriptor": "\nComments: Solution awarded a special prize in the Science4cast 2021 competition. Presented and published in the IEEE Big Data 2021 conference. Minor text improvements and typos corrected from the published version\n",
    "authors": [
      "Francisco Valente"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.03393"
  },
  {
    "id": "arXiv:2202.03400",
    "title": "Private Read Update Write (PRUW) with Storage Constrained Databases",
    "abstract": "We investigate the problem of private read update write (PRUW) in relation to\nfederated submodel learning (FSL) with storage constrained databases. In PRUW,\na user privately reads a submodel from a system of $N$ databases containing $M$\nsubmodels, updates it locally, and writes the update back to the databases\nwithout revealing the submodel index or the value of the update. The databases\nconsidered in this problem are only allowed to store a given amount of\ninformation specified by an arbitrary storage constraint. We provide a storage\nmechanism that determines the contents of each database prior to the\napplication of the PRUW scheme, such that the total communication cost is\nminimized. We show that the proposed storage scheme achieves a lower total cost\ncompared to what is achieved by using \\emph{coded storage} or \\emph{divided\nstorage} to meet the given storage constraint.",
    "descriptor": "",
    "authors": [
      "Sajani Vithana",
      "Sennur Ulukus"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.03400"
  },
  {
    "id": "arXiv:2202.03402",
    "title": "Preserving Privacy and Security in Federated Learning",
    "abstract": "Federated learning is known to be vulnerable to security and privacy issues.\nExisting research has focused either on preventing poisoning attacks from users\nor on protecting user privacy of model updates. However, integrating these two\nlines of research remains a crucial challenge since they often conflict with\none another with respect to the threat model.\nIn this work, we develop a framework to combine secure aggregation with\ndefense mechanisms against poisoning attacks from users, while maintaining\ntheir respective privacy guarantees. We leverage zero-knowledge proof protocol\nto let users run the defense mechanisms locally and attest the result to the\ncentral server without revealing any information about their model updates.\nFurthermore, we propose a new secure aggregation protocol for federated\nlearning using homomorphic encryption that is robust against malicious users.\nOur framework enables the central server to identify poisoned model updates\nwithout violating the privacy guarantees of secure aggregation. Finally, we\nanalyze the computation and communication complexity of our proposed solution\nand benchmark its performance.",
    "descriptor": "",
    "authors": [
      "Truc Nguyen",
      "My T. Thai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.03402"
  },
  {
    "id": "arXiv:2202.03410",
    "title": "A high order unfitted hybridizable discontinuous Galerkin method for  linear elasticity",
    "abstract": "This work analyzes a high order hybridizable discontinuous Galerkin (HDG)\nmethod for the linear elasticity problem in a domain not necessarily\npolyhedral. The domain is approximated by a polyhedral computational domain\nwhere the HDG solution can be computed. The introduction of the rotation as one\nof the unknowns allows us to use the gradient of the displacements to obtain an\nexplicit representation of the boundary data in the computational domain. The\nboundary data is transferred from the true boundary to the computational\nboundary by line integrals, where the integrand depends on the Cauchy stress\ntensor and the rotation. Under closeness assumptions between the computational\nand true boundaries, the scheme is shown to be well-posed and optimal error\nestimates are provided even in the nearly incompressible. Numerical experiments\nin two-dimensions are presented.",
    "descriptor": "",
    "authors": [
      "Juan M. Cardenas",
      "Manuel Solano"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.03410"
  },
  {
    "id": "arXiv:2202.03415",
    "title": "PopNet: Real-Time Population-Level Disease Prediction with Data Latency",
    "abstract": "Population-level disease prediction estimates the number of potential\npatients of particular diseases in some location at a future time based on\n(frequently updated) historical disease statistics. Existing approaches often\nassume the existing disease statistics are reliable and will not change.\nHowever, in practice, data collection is often time-consuming and has time\ndelays, with both historical and current disease statistics being updated\ncontinuously. In this work, we propose a real-time population-level disease\nprediction model which captures data latency (PopNet) and incorporates the\nupdated data for improved predictions. To achieve this goal, PopNet models\nreal-time data and updated data using two separate systems, each capturing\nspatial and temporal effects using hybrid graph attention networks and\nrecurrent neural networks. PopNet then fuses the two systems using both spatial\nand temporal latency-aware attentions in an end-to-end manner. We evaluate\nPopNet on real-world disease datasets and show that PopNet consistently\noutperforms all baseline disease prediction and general spatial-temporal\nprediction models, achieving up to 47% lower root mean squared error and 24%\nlower mean absolute error compared with the best baselines.",
    "descriptor": "",
    "authors": [
      "Junyi Gao",
      "Cao Xiao",
      "Lucas M. Glass",
      "Jimeng Sun"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2202.03415"
  },
  {
    "id": "arXiv:2202.03416",
    "title": "Deep Impulse Responses: Estimating and Parameterizing Filters with Deep  Networks",
    "abstract": "Impulse response estimation in high noise and in-the-wild settings, with\nminimal control of the underlying data distributions, is a challenging problem.\nWe propose a novel framework for parameterizing and estimating impulse\nresponses based on recent advances in neural representation learning. Our\nframework is driven by a carefully designed neural network that jointly\nestimates the impulse response and the (apriori unknown) spectral noise\ncharacteristics of an observed signal given the source signal. We demonstrate\nrobustness in estimation, even under low signal-to-noise ratios, and show\nstrong results when learning from spatio-temporal real-world speech data. Our\nframework provides a natural way to interpolate impulse responses on a spatial\ngrid, while also allowing for efficiently compressing and storing them for\nreal-time rendering applications in augmented and virtual reality.",
    "descriptor": "",
    "authors": [
      "Alexander Richard",
      "Peter Dodds",
      "Vamsi Krishna Ithapu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2202.03416"
  },
  {
    "id": "arXiv:2202.03418",
    "title": "Diversify and Disambiguate: Learning From Underspecified Data",
    "abstract": "Many datasets are underspecified, which means there are several equally\nviable solutions for the data. Underspecified datasets can be problematic for\nmethods that learn a single hypothesis because different functions that achieve\nlow training loss can focus on different predictive features and thus have\nwidely varying predictions on out-of-distribution data. We propose DivDis, a\nsimple two-stage framework that first learns a diverse collection of hypotheses\nfor a task by leveraging unlabeled data from the test distribution. We then\ndisambiguate by selecting one of the discovered hypotheses using minimal\nadditional supervision, in the form of additional labels or inspection of\nfunction visualization. We demonstrate the ability of DivDis to find hypotheses\nthat use robust features in image classification and natural language\nprocessing problems with underspecification.",
    "descriptor": "\nComments: Preprint\n",
    "authors": [
      "Yoonho Lee",
      "Huaxiu Yao",
      "Chelsea Finn"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.03418"
  },
  {
    "id": "arXiv:2202.02321",
    "title": "Frequency comb and machine learning-based breath analysis for COVID-19  classification",
    "abstract": "Human breath contains hundreds of volatile molecules that can provide\npowerful, non-intrusive spectral diagnosis of a diverse set of diseases and\nphysiological/metabolic states. To unleash this tremendous potential for\nmedical science, we present a robust analytical method that simultaneously\nmeasures tens of thousands of spectral features in each breath sample, followed\nby efficient and detail-specific multivariate data analysis for unambiguous\nbinary medical response classification. We combine mid-infrared cavity-enhanced\ndirect frequency comb spectroscopy (CE-DFCS), capable of real-time collection\nof tens of thousands of distinct molecular features at parts-per-trillion\nsensitivity, with supervised machine learning, capable of analysis and\nverification of extremely high-dimensional input data channels. Here, we\npresent the first application of this method to the breath detection of\nCoronavirus Disease 2019 (COVID-19). Using 170 individual samples at the\nUniversity of Colorado, we report a cross-validated area under the\nReceiver-Operating-Characteristics curve of 0.849(4), providing excellent\nprediction performance. Further, this method detected a significant difference\nbetween male and female breath as well as other variables such as smoking and\nabdominal pain. Together, these highlight the utility of CE-DFCS for rapid,\nnon-invasive detection of diverse biological conditions and disease states. The\nunique properties of frequency comb spectroscopy thus help establish precise\ndigital spectral fingerprints for building accurate databases and provide means\nfor simultaneous multi-response classifications. The predictive power can be\nfurther enhanced with readily scalable comb spectral coverage.",
    "descriptor": "",
    "authors": [
      "Qizhong Liang",
      "Ya-Chu Chan",
      "Jutta Toscano",
      "Kristen K. Bjorkman",
      "Leslie A. Leinwand",
      "Roy Parker",
      "David J. Nesbitt",
      "Jun Ye"
    ],
    "subjectives": [
      "Medical Physics (physics.med-ph)",
      "Machine Learning (cs.LG)",
      "Biological Physics (physics.bio-ph)",
      "Chemical Physics (physics.chem-ph)",
      "Optics (physics.optics)"
    ],
    "url": "https://arxiv.org/abs/2202.02321"
  },
  {
    "id": "arXiv:2202.02351",
    "title": "An explicit dual control approach for constrained reference tracking of  uncertain linear systems",
    "abstract": "A finite horizon optimal tracking problem is considered for linear dynamical\nsystems subject to parametric uncertainties in the state-space matrices and\nexogenous disturbances. A suboptimal solution is proposed using a model\npredictive control (MPC) based explicit dual control approach which enables\nactive uncertainty learning. A novel algorithm for the design of robustly\ninvariant online terminal sets and terminal controllers is presented. Set\nmembership identification is used to update the parameter uncertainty online. A\npredicted worst-case cost is used in the MPC optimization problem to model the\ndual effect of the control input. The cost-to-go is estimated using\ncontractivity of the proposed terminal set and the remaining time horizon, so\nthat the optimizer can estimate future benefits of exploration. The proposed\ndual control algorithm ensures robust constraint satisfaction and recursive\nfeasibility, and navigates the exploration-exploitation trade-off using a\nrobust performance metric.",
    "descriptor": "\nComments: Submitted to IEEE Transactions on Automatic Control\n",
    "authors": [
      "Anilkumar Parsi",
      "Andrea Iannelli",
      "Roy S. Smith"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.02351"
  },
  {
    "id": "arXiv:2202.02371",
    "title": "Boundary-aware Information Maximization for Self-supervised Medical  Image Segmentation",
    "abstract": "Unsupervised pre-training has been proven as an effective approach to boost\nvarious downstream tasks given limited labeled data. Among various methods,\ncontrastive learning learns a discriminative representation by constructing\npositive and negative pairs. However, it is not trivial to build reasonable\npairs for a segmentation task in an unsupervised way. In this work, we propose\na novel unsupervised pre-training framework that avoids the drawback of\ncontrastive learning. Our framework consists of two principles: unsupervised\nover-segmentation as a pre-train task using mutual information maximization and\nboundary-aware preserving learning. Experimental results on two benchmark\nmedical segmentation datasets reveal our method's effectiveness in improving\nsegmentation performance when few annotated images are available.",
    "descriptor": "",
    "authors": [
      "Jizong Peng",
      "Ping Wang",
      "Marco Pedersoli",
      "Christian Desrosiers"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.02371"
  },
  {
    "id": "arXiv:2202.02372",
    "title": "Direct observation of a dynamical glass transition in a nanomagnetic  artificial Hopfield network",
    "abstract": "Spin glasses, generally defined as disordered systems with randomized\ncompeting interactions, are a widely investigated complex system. Theoretical\nmodels describing spin glasses are broadly used in other complex systems, such\nas those describing brain function, error-correcting codes, or stock-market\ndynamics. This wide interest in spin glasses provides strong motivation to\ngenerate an artificial spin glass within the framework of artificial spin ice\nsystems. Here, we present the experimental realization of an artificial spin\nglass consisting of dipolar coupled single-domain Ising-type nanomagnets\narranged onto an interaction network that replicates the aspects of a Hopfield\nneural network. Using cryogenic x-ray photoemission electron microscopy\n(XPEEM), we performed temperature-dependent imaging of thermally driven moment\nfluctuations within these networks and observed characteristic features of a\ntwo-dimensional Ising spin glass. Specifically, the temperature dependence of\nthe spin glass correlation function follows a power law trend predicted from\ntheoretical models on two-dimensional spin glasses. Furthermore, we observe\nclear signatures of the hard to observe rugged spin glass free energy in the\nform of sub-aging, out of equilibrium autocorrelations and a transition from\nstable to unstable dynamics.",
    "descriptor": "\nComments: Initial submission to Nature Physics. 20 pages, 4 figures\n",
    "authors": [
      "Michael Saccone",
      "Francesco Caravelli",
      "Kevin Hofhuis",
      "Sergii Parchenko",
      "Yorick A. Birkh\u00f6lzer",
      "Scott Dhuey",
      "Armin Kleibert",
      "Sebastiaan van Dijken",
      "Cristiano Nisoli",
      "Alan Farhan"
    ],
    "subjectives": [
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Mesoscale and Nanoscale Physics (cond-mat.mes-hall)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Chaotic Dynamics (nlin.CD)"
    ],
    "url": "https://arxiv.org/abs/2202.02372"
  },
  {
    "id": "arXiv:2202.02382",
    "title": "Fully Automated Tree Topology Estimation and Artery-Vein Classification",
    "abstract": "We present a fully automatic technique for extracting the retinal vascular\ntopology, i.e., how the different vessels are connected to each other, given a\nsingle color fundus image. Determining this connectivity is very challenging\nbecause vessels cross each other in a 2D image, obscuring their true paths. We\nvalidated the usefulness of our extraction method by using it to achieve\nstate-of-the-art results in retinal artery-vein classification.\nOur proposed approach works as follows. We first segment the retinal vessels\nusing our previously developed state-of-the-art segmentation method. Then, we\nestimate an initial graph from the extracted vessels and assign the most likely\nblood flow to each edge. We then use a handful of high-level operations (HLOs)\nto fix errors in the graph. These HLOs include detaching neighboring nodes,\nshifting the endpoints of an edge, and reversing the estimated blood flow\ndirection for a branch. We use a novel cost function to find the optimal set of\nHLO operations for a given graph. Finally, we show that our extracted vascular\nstructure is correct by propagating artery/vein labels along the branches. As\nour experiments show, our topology-based artery-vein labeling achieved\nstate-of-the-art results on multiple datasets. We also performed several\nablation studies to verify the importance of the different components of our\nproposed method.",
    "descriptor": "",
    "authors": [
      "Aashis Khanal",
      "Saeid Motevali",
      "Rolando Estrada"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.02382"
  },
  {
    "id": "arXiv:2202.02388",
    "title": "Bregman Plug-and-Play Priors",
    "abstract": "The past few years have seen a surge of activity around integration of deep\nlearning networks and optimization algorithms for solving inverse problems.\nRecent work on plug-and-play priors (PnP), regularization by denoising (RED),\nand deep unfolding has shown the state-of-the-art performance of such\nintegration in a variety of applications. However, the current paradigm for\ndesigning such algorithms is inherently Euclidean, due to the usage of the\nquadratic norm within the projection and proximal operators. We propose to\nbroaden this perspective by considering a non-Euclidean setting based on the\nmore general Bregman distance. Our new Bregman Proximal Gradient Method variant\nof PnP (PnP-BPGM) and Bregman Steepest Descent variant of RED (RED-BSD) replace\nthe traditional updates in PnP and RED from the quadratic norms to more general\nBregman distance. We present a theoretical convergence result for PnP-BPGM and\ndemonstrate the effectiveness of our algorithms on Poisson linear inverse\nproblems.",
    "descriptor": "",
    "authors": [
      "Abdullah H. Al-Shabili",
      "Xiaojian Xu",
      "Ivan Selesnick",
      "Ulugbek S. Kamilov"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.02388"
  },
  {
    "id": "arXiv:2202.02407",
    "title": "An Experimental Design Approach for Regret Minimization in Logistic  Bandits",
    "abstract": "In this work we consider the problem of regret minimization for logistic\nbandits. The main challenge of logistic bandits is reducing the dependence on a\npotentially large problem dependent constant $\\kappa$ that can at worst scale\nexponentially with the norm of the unknown parameter $\\theta_{\\ast}$. Abeille\net al. (2021) have applied self-concordance of the logistic function to remove\nthis worst-case dependence providing regret guarantees like\n$O(d\\log^2(\\kappa)\\sqrt{\\dot\\mu T}\\log(|\\mathcal{X}|))$ where $d$ is the\ndimensionality, $T$ is the time horizon, and $\\dot\\mu$ is the variance of the\nbest-arm. This work improves upon this bound in the fixed arm setting by\nemploying an experimental design procedure that achieves a minimax regret of\n$O(\\sqrt{d \\dot\\mu T\\log(|\\mathcal{X}|)})$. Our regret bound in fact takes a\ntighter instance (i.e., gap) dependent regret bound for the first time in\nlogistic bandits. We also propose a new warmup sampling algorithm that can\ndramatically reduce the lower order term in the regret in general and prove\nthat it can replace the lower order term dependency on $\\kappa$ to\n$\\log^2(\\kappa)$ for some instances. Finally, we discuss the impact of the bias\nof the MLE on the logistic bandit problem, providing an example where $d^2$\nlower order regret (cf., it is $d$ for linear bandits) may not be improved as\nlong as the MLE is used and how bias-corrected estimators may be used to make\nit closer to $d$.",
    "descriptor": "",
    "authors": [
      "Blake Mason",
      "Kwang-Sung Jun",
      "Lalit Jain"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.02407"
  },
  {
    "id": "arXiv:2202.02414",
    "title": "OMLT: Optimization & Machine Learning Toolkit",
    "abstract": "The optimization and machine learning toolkit (OMLT) is an open-source\nsoftware package incorporating neural network and gradient-boosted tree\nsurrogate models, which have been trained using machine learning, into larger\noptimization problems. We discuss the advances in optimization technology that\nmade OMLT possible and show how OMLT seamlessly integrates with the algebraic\nmodeling language Pyomo. We demonstrate how to use OMLT for solving\ndecision-making problems in both computer science and engineering.",
    "descriptor": "\nComments: 7 pages, 1 figure\n",
    "authors": [
      "Francesco Ceccon",
      "Jordan Jalving",
      "Joshua Haddad",
      "Alexander Thebelt",
      "Calvin Tsay",
      "Carl D. Laird",
      "Ruth Misener"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2202.02414"
  },
  {
    "id": "arXiv:2202.02428",
    "title": "Stratification of carotid atheromatous plaque using interpretable deep  learning methods on B-mode ultrasound images",
    "abstract": "Carotid atherosclerosis is the major cause of ischemic stroke resulting in\nsignificant rates of mortality and disability annually. Early diagnosis of such\ncases is of great importance, since it enables clinicians to apply a more\neffective treatment strategy. This paper introduces an interpretable\nclassification approach of carotid ultrasound images for the risk assessment\nand stratification of patients with carotid atheromatous plaque. To address the\nhighly imbalanced distribution of patients between the symptomatic and\nasymptomatic classes (16 vs 58, respectively), an ensemble learning scheme\nbased on a sub-sampling approach was applied along with a two-phase,\ncost-sensitive strategy of learning, that uses the original and a resampled\ndata set. Convolutional Neural Networks (CNNs) were utilized for building the\nprimary models of the ensemble. A six-layer deep CNN was used to automatically\nextract features from the images, followed by a classification stage of two\nfully connected layers. The obtained results (Area Under the ROC Curve (AUC):\n73%, sensitivity: 75%, specificity: 70%) indicate that the proposed approach\nachieved acceptable discrimination performance. Finally, interpretability\nmethods were applied on the model's predictions in order to reveal insights on\nthe model's decision process as well as to enable the identification of novel\nimage biomarkers for the stratification of patients with carotid atheromatous\nplaque.Clinical Relevance-The integration of interpretability methods with deep\nlearning strategies can facilitate the identification of novel ultrasound image\nbiomarkers for the stratification of patients with carotid atheromatous plaque.",
    "descriptor": "\nComments: Accepted at 2021 43rd Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC)\n",
    "authors": [
      "Theofanis Ganitidis",
      "Maria Athanasiou",
      "Kalliopi Dalakleidi",
      "Nikos Melanitis",
      "Spyretta Golemati",
      "Konstantina S Nikita"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.02428"
  },
  {
    "id": "arXiv:2202.02439",
    "title": "Multistability and Paradoxes in Lossy Oscillator Networks",
    "abstract": "The analysis of dissipatively coupled oscillators is a challenging problem\nwith high stakes in actual applications, such as large scale physical systems.\nMany standard mathematical methods are not applicable to such systems, due to\nthe lack of symmetry of the network induced by dissipative couplings. Here we\nemphasize that the synchronization of coupled oscillators can be equivalently\ninterpreted as the problem of flow distribution over a network. Based on these\nequivalent interpretations, we demonstrate a close correspondence between\nmultiple stable synchronous states and \\emph{winding cells} in systems of\ndissipatively coupled oscillators. The recently introduced notion of winding\ncells, associated to a graph, forms a natural winding partition of the\n$n$-torus and capture essential characteristics of synchronous states in\nlossless systems. Leveraging the winding partition of the $n$-torus, we provide\nalgorithms to compute the synchronous solutions of general networks of coupled\noscillators. Furthermore, we identify three paradoxical behaviors of lossy\nnetworked systems, to be contrasted with the behavior lossless systems. Namely,\nwe show that loop flows and dissipation can increase the system's transfer\ncapacity, and that dissipation can promote multistability.",
    "descriptor": "\nComments: Main text: 14 pages, 5 figures. Supplementary information: 6 pages, 2 figures\n",
    "authors": [
      "Robin Delabays",
      "Saber Jafarpour",
      "Francesco Bullo"
    ],
    "subjectives": [
      "Adaptation and Self-Organizing Systems (nlin.AO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.02439"
  },
  {
    "id": "arXiv:2202.02443",
    "title": "Machine Learning Method for Functional Assessment of Retinal Models",
    "abstract": "Challenges in the field of retinal prostheses motivate the development of\nretinal models to accurately simulate Retinal Ganglion Cells (RGCs) responses.\nThe goal of retinal prostheses is to enable blind individuals to solve complex,\nreallife visual tasks. In this paper, we introduce the functional assessment\n(FA) of retinal models, which describes the concept of evaluating the\nperformance of retinal models on visual understanding tasks. We present a\nmachine learning method for FA: we feed traditional machine learning\nclassifiers with RGC responses generated by retinal models, to solve object and\ndigit recognition tasks (CIFAR-10, MNIST, Fashion MNIST, Imagenette). We\nexamined critical FA aspects, including how the performance of FA depends on\nthe task, how to optimally feed RGC responses to the classifiers and how the\nnumber of output neurons correlates with the model's accuracy. To increase the\nnumber of output neurons, we manipulated input images - by splitting and then\nfeeding them to the retinal model and we found that image splitting does not\nsignificantly improve the model's accuracy. We also show that differences in\nthe structure of datasets result in largely divergent performance of the\nretinal model (MNIST and Fashion MNIST exceeded 80% accuracy, while CIFAR-10\nand Imagenette achieved ~40%). Furthermore, retinal models which perform better\nin standard evaluation, i.e. more accurately predict RGC response, perform\nbetter in FA as well. However, unlike standard evaluation, FA results can be\nstraightforwardly interpreted in the context of comparing the quality of visual\nperception.",
    "descriptor": "\nComments: Accepted at 2021 43rd Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC)\n",
    "authors": [
      "Nikolas Papadopoulos",
      "Nikos Melanitis",
      "Antonio Lozano",
      "Cristina Soto-Sanchez",
      "Eduardo Fernandez",
      "Konstantina S Nikita"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.02443"
  },
  {
    "id": "arXiv:2202.02464",
    "title": "One-Nearest-Neighbor Search is All You Need for Minimax Optimal  Regression and Classification",
    "abstract": "Recently, Qiao, Duan, and Cheng~(2019) proposed a distributed\nnearest-neighbor classification method, in which a massive dataset is split\ninto smaller groups, each processed with a $k$-nearest-neighbor classifier, and\nthe final class label is predicted by a majority vote among these groupwise\nclass labels. This paper shows that the distributed algorithm with $k=1$ over a\nsufficiently large number of groups attains a minimax optimal error rate up to\na multiplicative logarithmic factor under some regularity conditions, for both\nregression and classification problems. Roughly speaking, distributed\n1-nearest-neighbor rules with $M$ groups has a performance comparable to\nstandard $\\Theta(M)$-nearest-neighbor rules. In the analysis, alternative rules\nwith a refined aggregation method are proposed and shown to attain exact\nminimax optimal rates.",
    "descriptor": "\nComments: 25 pages, 2 figures\n",
    "authors": [
      "J. Jon Ryu",
      "Young-Han Kim"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.02464"
  },
  {
    "id": "arXiv:2202.02472",
    "title": "Tensor-CSPNet: A Novel Geometric Deep Learning Framework for Motor  Imagery Classification",
    "abstract": "Deep learning (DL) has been widely investigated in a vast majority of\napplications in electroencephalography (EEG)-based brain-computer interfaces\n(BCIs), especially for motor imagery (MI) classification in the past five\nyears. The mainstream DL methodology for the MI-EEG classification exploits the\ntemporospatial patterns of EEG signals using convolutional neural networks\n(CNNs), which have been particularly successful in visual images. However,\nsince the statistical characteristics of visual images may not benefit EEG\nsignals, a natural question that arises is whether there exists an alternative\nnetwork architecture despite CNNs to extract features for the MI-EEG\nclassification. To address this question, we propose a novel geometric deep\nlearning (GDL) framework called Tensor-CSPNet to characterize EEG signals on\nsymmetric positive definite (SPD) manifolds and exploit the\ntemporo-spatio-frequential patterns using deep neural networks on SPD\nmanifolds. Meanwhile, many experiences of successful MI-EEG classifiers have\nbeen integrated into the Tensor-CSPNet framework to make it more efficient. In\nthe experiments, Tensor-CSPNet attains or slightly outperforms the current\nstate-of-the-art performance on the cross-validation and holdout scenarios of\ntwo MI-EEG datasets. The visualization and interpretability analyses also\nexhibit its validity for the MI-EEG classification. To conclude, we provide a\nfeasible answer to the question by generalizing the previous DL methodologies\non SPD manifolds, which indicates the start of a specific class from the GDL\nmethodology for the MI-EEG classification.",
    "descriptor": "\nComments: 15 pages, 10 figures, 12 tables; This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Ce Ju",
      "Cuntai Guan"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2202.02472"
  },
  {
    "id": "arXiv:2202.02474",
    "title": "Importance Weighting Approach in Kernel Bayes' Rule",
    "abstract": "We study a nonparametric approach to Bayesian computation via feature means,\nwhere the expectation of prior features is updated to yield expected posterior\nfeatures, based on regression from kernel or neural net features of the\nobservations. All quantities involved in the Bayesian update are learned from\nobserved data, making the method entirely model-free. The resulting algorithm\nis a novel instance of a kernel Bayes' rule (KBR). Our approach is based on\nimportance weighting, which results in superior numerical stability to the\nexisting approach to KBR, which requires operator inversion. We show the\nconvergence of the estimator using a novel consistency analysis on the\nimportance weighting estimator in the infinity norm. We evaluate our KBR on\nchallenging synthetic benchmarks, including a filtering problem with a\nstate-space model involving high dimensional image observations. The proposed\nmethod yields uniformly better empirical performance than the existing KBR, and\ncompetitive performance with other competing methods.",
    "descriptor": "",
    "authors": [
      "Liyuan Xu",
      "Yutian Chen",
      "Arnaud Doucet",
      "Arthur Gretton"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.02474"
  },
  {
    "id": "arXiv:2202.02509",
    "title": "Asymptotic Critical Radii in Random Geometric Graphs over 3-Dimensional  Convex regions",
    "abstract": "This article presents the precise asymptotical distribution of two types of\ncritical transmission radii, defined in terms of k-connectivity and the minimum\nvertex degree, for a random geometry graph distributed over a 3-Dimensional\nConvex region.",
    "descriptor": "",
    "authors": [
      "Jie Ding",
      "Xiaohua Xu",
      "Shuai Ma",
      "Xinshan Zhu"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2202.02509"
  },
  {
    "id": "arXiv:2202.02549",
    "title": "A Practical Vehicle Routing Problem for Monitoring Water Distribution  Networks",
    "abstract": "In this work, we introduce a generalization of the well-known Vehicle Routing\nProblem (VRP) for a specific application in the monitoring of a Water\nDistribution Network (WDN). In this problem, for each day over a planning\nperiod, multiple technicians must visit a sequence of nodes in the WDN and\nperform a series of tests to check the quality of water. Some special nodes\n(i.e., wells) require technicians to first collect a key from a key center. The\nkey must then be returned to the same key center after the test has been\nperformed, thus introducing precedence constraints and multiple visits in the\nroutes. To solve the problem, three mathematical models and an Iterated Local\nSearch have been implemented. The efficiency of the proposed methods is\ndemonstrated by means of extensive computational tests on randomly created\ninstances, as well as on instances derived from a real-world case study.",
    "descriptor": "",
    "authors": [
      "Reza Atefi",
      "Manuel Iori",
      "Majid Salari",
      "Dario Vezzali"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2202.02549"
  },
  {
    "id": "arXiv:2202.02551",
    "title": "Exploring the Dynamics of the Circumcenter Map",
    "abstract": "We study properties of an $n$-times applied \"circumcenter map\", which sends\nan $n$-gon to a scaled and rotated copy of itself. Specifically, we explore the\ngeometry of area-expanding and area-contracting regions of induced by this map.",
    "descriptor": "\nComments: 12 pages, 13 figures\n",
    "authors": [
      "Ronaldo Garcia",
      "Nicholas McDonald",
      "Dan Reznik"
    ],
    "subjectives": [
      "Dynamical Systems (math.DS)",
      "Graphics (cs.GR)",
      "Metric Geometry (math.MG)"
    ],
    "url": "https://arxiv.org/abs/2202.02551"
  },
  {
    "id": "arXiv:2202.02570",
    "title": "Proper conflict-free and unique-maximum colorings of planar graphs with  respect to neighborhoods",
    "abstract": "A {\\em conflict-free coloring} of a graph {\\em with respect to open} (resp.,\n{\\em closed}) {\\em neighborhood} is a coloring of vertices such that for every\nvertex there is a color appearing exactly once in its open (resp., closed)\nneighborhood. Similarly, a {\\em unique-maximum coloring} of a graph {\\em with\nrespect to open} (resp., {\\em closed}) {\\em neighborhood} is a coloring of\nvertices such that for every vertex the maximum color appearing in its open\n(resp., closed) neighborhood appears exactly once. There is a vast amount of\nliterature on both notions where the colorings need not be proper, i.e.,\nadjacent vertices are allowed to have the same color.\nIn this paper, we initiate a study of both colorings in the proper settings\nwith the focus given mainly to planar graphs. We establish upper bounds for the\nnumber of colors in the class of planar graphs for all considered colorings and\nprovide constructions of planar graphs attaining relatively high values of the\ncorresponding chromatic numbers. As a main result, we prove that every planar\ngraph admits a proper unique-maximum coloring with respect to open neighborhood\nwith at most 10 colors, and give examples of planar graphs needing at least $6$\ncolors for such a coloring. We also establish tight upper bounds for\nouterplanar graphs. Finally, we provide several new bounds also for the\nimproper setting of considered colorings.",
    "descriptor": "",
    "authors": [
      "Igor Fabrici",
      "Borut Lu\u017ear",
      "Simona Rindo\u0161ov\u00e1",
      "Roman Sot\u00e1k"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2202.02570"
  },
  {
    "id": "arXiv:2202.02596",
    "title": "Does elastic stress modify the equilibrium corner angle?",
    "abstract": "We consider the influence of elasticity and anisotropic surface energy on the\nenergy-minimizing shape of a two-dimensional void under biaxial loading. In\nparticular, we consider void shapes with corners for which the strain energy\ndensity is singular at the corner. The elasticity problem is formulated as a\nboundary integral equation using complex potentials. By incorporating the\nasymptotic behavior of the singular elastic fields at corners of the void, we\ndevelop a numerical spectral method for determining the stress for a class of\narbitrary void shapes and corner angles. We minimize the total energy of\nsurface energy and elastic potential energy using calculus of variations to\nobtain an Euler-Lagrange equation on the boundary that is coupled to the\nelastic field. The shape of the void boundary is determined using a numerical\nspectral method that simultaneously determines the equilibrium void shape and\nsingular elastic fields. Our results show that the precise corner angles that\nminimize the total energy are not affected by the presence of the singular\nelastic fields. However, the stress singularity on the void surface at the\ncorner must be balanced by a singularity in the curvature at the corner that\neffectively changes the macroscopic geometry of the shape and effectively\nchanges the apparent corner angle. These results reconcile the apparent\ncontradiction regarding the effect of elasticity on equilibrium corner angles\nin the results of Srolovitz and Davis (2001) and Siegel, Miksis and Voorhees\n(2004), and identify an important nontrivial singular behavior associated with\ncorners on free-boundary elasticity problems.",
    "descriptor": "\nComments: 32 pages, 11 figures\n",
    "authors": [
      "Weiqi Wang",
      "Brian J. Spencer"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Analysis of PDEs (math.AP)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.02596"
  },
  {
    "id": "arXiv:2202.02599",
    "title": "Path eccentricity of graphs",
    "abstract": "Let $G$ be a connected graph. The eccentricity of a path $P$, denoted by\necc$_G(P)$, is the maximum distance from $P$ to any vertex in $G$. In the\n\\textsc{Central path} (CP) problem our aim is to find a path of minimum\neccentricity. This problem was introduced by Cockayne et al., in 1981, in the\nstudy of different centrality measures on graphs. They showed that CP can be\nsolved in linear time in trees, but it is known to be NP-hard in many classes\nof graphs such as chordal bipartite graphs, planar 3-connected graphs, split\ngraphs, etc.\nWe investigate the path eccentricity of a connected graph~$G$ as a parameter.\nLet pe$(G)$ denote the value of ecc$_G(P)$ for a central path $P$ of $G$. We\nobtain tight upper bounds for pe$(G)$ in some graph classes. We show that\npe$(G) \\leq 1$ on biconvex graphs and that pe$(G) \\leq 2$ on bipartite convex\ngraphs. Moreover, we design algorithms that find such a path in linear time. On\nthe other hand, by investigating the longest paths of a graph, we obtain tight\nupper bounds for pe$(G)$ on general graphs and $k$-connected graphs.\nFinally, we study the relation between a central path and a longest path in a\ngraph. We show that on trees, and bipartite permutation graphs, a longest path\nis also a central path. Furthermore, for superclasses of these graphs, we\nexhibit counterexamples for this property.",
    "descriptor": "",
    "authors": [
      "Renzo G\u00f3mez",
      "Juan Guti\u00e9rrez"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2202.02599"
  },
  {
    "id": "arXiv:2202.02606",
    "title": "ROMNet: Renovate the Old Memories",
    "abstract": "Renovating the memories in old photos is an intriguing research topic in\ncomputer vision fields. These legacy images often suffer from severe and\ncommingled degradations such as cracks, noise, and color-fading, while lack of\nlarge-scale paired old photo datasets makes this restoration task very\nchallenging. In this work, we present a novel reference-based end-to-end\nlearning framework that can jointly repair and colorize the degraded legacy\npictures. Specifically, the proposed framework consists of three modules: a\nrestoration sub-network for degradation restoration, a similarity sub-network\nfor color histogram matching and transfer, and a colorization subnet that\nlearns to predict the chroma elements of the images conditioned on chromatic\nreference signals. The whole system takes advantage of the color histogram\npriors in a given reference image, which vastly reduces the dependency on\nlarge-scale training data. Apart from the proposed method, we also create, to\nour knowledge, the first public and real-world old photo dataset with paired\nground truth for evaluating old photo restoration models, wherein each old\nphoto is paired with a manually restored pristine image by PhotoShop experts.\nOur extensive experiments conducted on both synthetic and real-world datasets\ndemonstrate that our method significantly outperforms state-of-the-arts both\nquantitatively and qualitatively.",
    "descriptor": "\nComments: Submitted to TIP\n",
    "authors": [
      "Runsheng Xu",
      "Zhengzhong Tu",
      "Yuanqi Du",
      "Xiaoyu Dong",
      "Jinlong Li",
      "Zibo Meng",
      "Jiaqi Ma",
      "Hongkai YU"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.02606"
  },
  {
    "id": "arXiv:2202.02616",
    "title": "DSSIM: a structural similarity index for floating-point data",
    "abstract": "Data visualization is a critical component in terms of interacting with\nfloating-point output data from large model simulation codes. Indeed,\npostprocessing analysis workflows on simulation data often generate a large\nnumber of images from the raw data, many of which are then compared to each\nother or to specified reference images. In this image-comparison scenario,\nimage quality assessment (IQA) measures are quite useful, and the Structural\nSimilarity Index (SSIM) continues to be a popular choice. However, generating\nlarge numbers of images can be costly, and plot-specific (but data independent)\nchoices can affect the SSIM value. A natural question is whether we can apply\nthe SSIM directly to the floating-point simulation data and obtain an\nindication of whether differences in the data are likely to impact a visual\nassessment, effectively bypassing the creation of a specific set of images from\nthe data. To this end, we propose an alternative to the popular SSIM that can\nbe applied directly to the floating point data, which we refer to as the Data\nSSIM (DSSIM). While we demonstrate the usefulness of the DSSIM in the context\nof evaluating differences due to lossy compression on large volumes of\nsimulation data from a popular climate model, the DSSIM may prove useful for\nmany other applications involving simulation or image data.",
    "descriptor": "",
    "authors": [
      "Allison H. Baker",
      "Alexander Pinard",
      "Dorit M. Hammerling"
    ],
    "subjectives": [
      "Computation (stat.CO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.02616"
  },
  {
    "id": "arXiv:2202.02618",
    "title": "Solving matrix nearness problems via Hamiltonian systems, matrix  factorization, and optimization",
    "abstract": "In these lectures notes, we review our recent works addressing various\nproblems of finding the nearest stable system to an unstable one. After the\nintroduction, we provide some preliminary background, namely, defining\nPort-Hamiltonian systems and dissipative Hamiltonian systems and their\nproperties, briefly discussing matrix factorizations, and describing the\noptimization methods that we will use in these notes. In the third chapter, we\npresent our approach to tackle the distance to stability for standard\ncontinuous linear time invariant (LTI) systems. The main idea is to rely on the\ncharacterization of stable systems as dissipative Hamiltonian systems. We show\nhow this idea can be generalized to compute the nearest $\\Omega$-stable matrix,\nwhere the eigenvalues of the sought system matrix $A$ are required to belong a\nrather general set $\\Omega$. We also show how these ideas can be used to\ncompute minimal-norm static feedbacks, that is, stabilize a system by choosing\na proper input $u(t)$ that linearly depends on $x(t)$ (static-state feedback),\nor on $y(t)$ (static-output feedback). In the fourth chapter, we present our\napproach to tackle the distance to passivity. The main idea is to rely on the\ncharacterization of stable systems as port-Hamiltonian systems. We also discuss\nin more details the special case of computing the nearest stable matrix pairs.\nIn the last chapter, we focus on discrete-time LTI systems. Similarly as for\nthe continuous case, we propose a parametrization that allows efficiently\ncompute the nearest stable system (for matrices and matrix pairs), allowing to\ncompute the distance to stability. We show how this idea can be used in\ndata-driven system identification, that is, given a set of input-output pairs,\nidentify the system $A$.",
    "descriptor": "\nComments: These notes were written for the summer school on \"Recent stability issues for linear dynamical systems - Matrix nearness problems and eigenvalue optimization\" organized by Nicola Guglielmi and Christian Lubich at the Centro Internazionale Matematico Estivo (CIME) in September 2021\n",
    "authors": [
      "Nicolas Gillis",
      "Punit Sharma"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.02618"
  },
  {
    "id": "arXiv:2202.02620",
    "title": "Graphical parameters for classes of tumbling block graphs",
    "abstract": "The infinite tumbling block graph is a bipartite graph, where each vertex in\none partite set is of degree 3 and each vertex in the other partite set is of\ndegree 6. It is a 2-dimensional array of blocks of seven vertices and nine\nedges, a planar graph that has 3-D looks. This paper introduces tumbling block\ngraphs and considers various graphical parameters for different classes of\ninfinite and finite tumbling blocks.",
    "descriptor": "\nComments: 12 pages, 12 Figures\n",
    "authors": [
      "Suk J. Seo",
      "Peter J. Slater"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2202.02620"
  },
  {
    "id": "arXiv:2202.02621",
    "title": "COVID-19 and Influenza Joint Forecasts Using Internet Search Information  in the United States",
    "abstract": "As COVID-19 pandemic progresses, severe flu seasons may happen alongside an\nincrease in cases in cases and death of COVID-19, causing severe burdens on\nhealth care resources and public safety. A consequence of a twindemic may be a\nmixture of two different infections in the same person at the same time,\n\"flurona\". Admist the raising trend of \"flurona\", forecasting both influenza\noutbreaks and COVID-19 waves in a timely manner is more urgent than ever, as\naccurate joint real-time tracking of the twindemic aids health organizations\nand policymakers in adequate preparation and decision making. Under the current\npandemic, state-of-art influenza and COVID-19 forecasting models carry valuable\ndomain information but face shortcomings under current complex disease\ndynamics, such as similarities in symptoms and public healthcare seeking\npatterns of the two diseases. Inspired by the inner-connection between\ninfluenza and COVID-19 activities, we propose ARGOX-Joint-Ensemble which allows\nus to combine historical influenza and COVID-19 disease forecasting models to a\nnew ensemble framework that handles scenarios where flu and COVID co-exist. Our\nframework is able to emphasize learning from COVID-related or influenza\nsignals, through a winner-takes-all ensemble fashion. Moreover, our experiments\ndemonstrate that our approach is successful in adapting past influenza\nforecasting models to the current pandemic, while improving upon previous\nCOVID-19 forecasting models, by steadily outperforming alternative benchmark\nmethods, and remaining competitive with publicly available models.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2106.12160\n",
    "authors": [
      "Simin Ma",
      "Shaoyang Ning",
      "Shihao Yang"
    ],
    "subjectives": [
      "Applications (stat.AP)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2202.02621"
  },
  {
    "id": "arXiv:2202.02649",
    "title": "The Implicit Bias of Gradient Descent on Generalized Gated Linear  Networks",
    "abstract": "Understanding the asymptotic behavior of gradient-descent training of deep\nneural networks is essential for revealing inductive biases and improving\nnetwork performance. We derive the infinite-time training limit of a\nmathematically tractable class of deep nonlinear neural networks, gated linear\nnetworks (GLNs), and generalize these results to gated networks described by\ngeneral homogeneous polynomials. We study the implications of our results,\nfocusing first on two-layer GLNs. We then apply our theoretical predictions to\nGLNs trained on MNIST and show how architectural constraints and the implicit\nbias of gradient descent affect performance. Finally, we show that our theory\ncaptures a substantial portion of the inductive bias of ReLU networks. By\nmaking the inductive bias explicit, our framework is poised to inform the\ndevelopment of more efficient, biologically plausible, and robust learning\nalgorithms.",
    "descriptor": "\nComments: 23 pages, 5 figures\n",
    "authors": [
      "Samuel Lippl",
      "L. F. Abbott",
      "SueYeon Chung"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2202.02649"
  },
  {
    "id": "arXiv:2202.02651",
    "title": "Beyond Black Box Densities: Parameter Learning for the Deviated  Components",
    "abstract": "As we collect additional samples from a data population for which a known\ndensity function estimate may have been previously obtained by a black box\nmethod, the increased complexity of the data set may result in the true density\nbeing deviated from the known estimate by a mixture distribution. To model this\nphenomenon, we consider the \\emph{deviating mixture model} $(1-\\lambda^{*})h_0\n+ \\lambda^{*} (\\sum_{i = 1}^{k} p_{i}^{*} f(x|\\theta_{i}^{*}))$, where $h_0$ is\na known density function, while the deviated proportion $\\lambda^{*}$ and\nlatent mixing measure $G_{*} = \\sum_{i = 1}^{k} p_{i}^{*}\n\\delta_{\\theta_i^{*}}$ associated with the mixture distribution are unknown.\nVia a novel notion of distinguishability between the known density $h_{0}$ and\nthe deviated mixture distribution, we establish rates of convergence for the\nmaximum likelihood estimates of $\\lambda^{*}$ and $G^{*}$ under Wasserstein\nmetric. Simulation studies are carried out to illustrate the theory.",
    "descriptor": "\nComments: 44 pages, 3 figures. Dat Do and Nhat Ho contributed equally to this work\n",
    "authors": [
      "Dat Do",
      "Nhat Ho",
      "XuanLong Nguyen"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2202.02651"
  },
  {
    "id": "arXiv:2202.02671",
    "title": "Stable factorization for phase factors of quantum signal processing",
    "abstract": "This note proposes a new factorization algorithm for computing the phase\nfactors of quantum signal processing. The proposed algorithm avoids root\nfinding of high degree polynomials and is numerical stable in the double\nprecision arithmetics. Experimental results are reported for Hamiltonian\nsimulation, eigenstate filtering, matrix inversion, and Fermi-Dirac operator.",
    "descriptor": "",
    "authors": [
      "Lexing Ying"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.02671"
  },
  {
    "id": "arXiv:2202.02675",
    "title": "On the High Dimensional RSA Algorithm -- A Public Key Cryptosystem Based  on Lattice and Algebraic Number Theory",
    "abstract": "The most known of public key cryptosystem was introduced in 1978 by Rivest,\nShamir and Adleman [19] and now called the RSA public key cryptosystem in their\nhonor. Later, a few authors gave a simply extension of RSA over algebraic\nnumbers field( see [20]- [22]), but they require that the ring of algebraic\nintegers is Euclidean ring, this requirement is much more stronger than the\nclass number one condition. In this paper, we introduce a high dimensional form\nof RSA by making use of the ring of algebraic integers of an algebraic number\nfield and the lattice theory. We give an attainable algorithm (see Algorithm I\nbelow) of which is significant both from the theoretical and practical point of\nview. Our main purpose in this paper is to show that the high dimensional RSA\nis a lattice based on public key cryptosystem indeed, of which would be\nconsidered as a new number in the family of post-quantum cryptography(see [17]\nand [18]). On the other hand, we give a matrix expression for any algebraic\nnumber fields (see Theorem 2.7 below), which is a new result even in the sense\nof classical algebraic number theory.",
    "descriptor": "",
    "authors": [
      "Zhiyong Zheng",
      "Fengxia Liu"
    ],
    "subjectives": [
      "Number Theory (math.NT)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.02675"
  },
  {
    "id": "arXiv:2202.02687",
    "title": "Cross-Channel Attention-Based Target Speaker Voice Activity Detection:  Experimental Results for M2MeT Challenge",
    "abstract": "In this paper, we present the speaker diarization system for the\nMulti-channel Multi-party Meeting Transcription Challenge (M2MeT) from team\nDKU_DukeECE. As the highly overlapped speech exists in the dataset, we employ\nan x-vector-based target-speaker voice activity detection (TS-VAD) to find the\noverlap between speakers. For the single-channel scenario, we separately train\na model for each of the 8 channels and fuse the results. We also employ the\ncross-channel self-attention to further improve the performance, where the\nnon-linear spatial correlations between different channels are learned and\nfused. Experimental results on the evaluation set show that the single-channel\nTS-VAD reduces the DER by over 75% from 12.68\\% to 3.14%. The multi-channel\nTS-VAD further reduces the DER by 28% and achieves a DER of 2.26%. Our final\nsubmitted system achieves a DER of 2.98% on the AliMeeting test set, which\nranks 1st in the M2MET challenge.",
    "descriptor": "",
    "authors": [
      "Weiqing Wang",
      "Xiaoyi Qin",
      "Ming Li"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2202.02687"
  },
  {
    "id": "arXiv:2202.02701",
    "title": "Hyper-Convolutions via Implicit Kernels for Medical Imaging",
    "abstract": "The convolutional neural network (CNN) is one of the most commonly used\narchitectures for computer vision tasks. The key building block of a CNN is the\nconvolutional kernel that aggregates information from the pixel neighborhood\nand shares weights across all pixels. A standard CNN's capacity, and thus its\nperformance, is directly related to the number of learnable kernel weights,\nwhich is determined by the number of channels and the kernel size (support). In\nthis paper, we present the \\textit{hyper-convolution}, a novel building block\nthat implicitly encodes the convolutional kernel using spatial coordinates.\nHyper-convolutions decouple kernel size from the total number of learnable\nparameters, enabling a more flexible architecture design. We demonstrate in our\nexperiments that replacing regular convolutions with hyper-convolutions can\nimprove performance with less parameters, and increase robustness against\nnoise. We provide our code here:\n\\emph{https://github.com/tym002/Hyper-Convolution}",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2105.10559\n",
    "authors": [
      "Tianyu Ma",
      "Alan Q. Wang",
      "Adrian V. Dalca",
      "Mert R. Sabuncu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.02701"
  },
  {
    "id": "arXiv:2202.02723",
    "title": "Portfolio Optimization on NIFTY Thematic Sector Stocks Using an LSTM  Model",
    "abstract": "Portfolio optimization has been a broad and intense area of interest for\nquantitative and statistical finance researchers and financial analysts. It is\na challenging task to design a portfolio of stocks to arrive at the optimized\nvalues of the return and risk. This paper presents an algorithmic approach for\ndesigning optimum risk and eigen portfolios for five thematic sectors of the\nNSE of India. The prices of the stocks are extracted from the web from Jan 1,\n2016, to Dec 31, 2020. Optimum risk and eigen portfolios for each sector are\ndesigned based on ten critical stocks from the sector. An LSTM model is\ndesigned for predicting future stock prices. Seven months after the portfolios\nwere formed, on Aug 3, 2021, the actual returns of the portfolios are compared\nwith the LSTM-predicted returns. The predicted and the actual returns indicate\na very high-level accuracy of the LSTM model.",
    "descriptor": "\nComments: The is the preprint version of our published paper listed in the IEEE Xplore. The final paper is published in the Proceedings of the IEEE International Conference on Data Analytics for Business and Industry, pp. 364-369, Bahrain, October 25-26, 2021. The preprint consists of 6 pages and it contains 10 figures and 16 tables\n",
    "authors": [
      "Jaydip Sen",
      "Saikat Mondal",
      "Sidra Mehtab"
    ],
    "subjectives": [
      "Portfolio Management (q-fin.PM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.02723"
  },
  {
    "id": "arXiv:2202.02750",
    "title": "Estimating the Euclidean Quantum Propagator with Deep Generative  Modelling of Feynman paths",
    "abstract": "Feynman path integrals provide an elegant, classically-inspired\nrepresentation for the quantum propagator and the quantum dynamics, through\nsumming over a huge manifold of all possible paths. From computational and\nsimulational perspectives, the ergodic tracking of the whole path manifold is a\nhard problem. Machine learning can help, in an efficient manner, to identify\nthe relevant subspace and the intrinsic structure residing at a small fraction\nof the vast path manifold. In this work, we propose the concept of Feynman path\ngenerator, which efficiently generates Feynman paths with fixed endpoints from\na (low-dimensional) latent space, by targeting a desired density of paths in\nthe Euclidean space-time. With such path generators, the Euclidean propagator\nas well as the ground state wave function can be estimated efficiently for a\ngeneric potential energy. Our work leads to a fresh approach for calculating\nthe quantum propagator, paves the way toward generative modelling of Feynman\npaths, and may also provide a future new perspective to understand the\nquantum-classical correspondence through deep learning.",
    "descriptor": "\nComments: 4 figures, 6+2 pages, with supplemental information\n",
    "authors": [
      "Yanming Che",
      "Clemens Gneiting",
      "Franco Nori"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Machine Learning (cs.LG)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ],
    "url": "https://arxiv.org/abs/2202.02750"
  },
  {
    "id": "arXiv:2202.02752",
    "title": "Computing Transience Bounds of Emergency Call Centers: a Hierarchical  Timed Petri Net Approach",
    "abstract": "A fundamental issue in the analysis of emergency call centers is to estimate\nthe time needed to return to a congestion-free regime after an unusual event\nwith a massive arrival of calls. Call centers can generally be represented by\ntimed Petri nets with a hierarchical structure, in which several layers\ndescribe the successive steps of treatments of calls. We study a continuous\napproximation of the Petri net dynamics (with infinitesimal tokens). Then, we\nshow that a counter function, measuring the deviation to the stationary regime,\ncoincides with the value function of a semi-Markov decision problem. Then, we\nestablish a finite time convergence result, exploiting the hierarchical\nstructure of the Petri net. We obtain an explicit bound for the transience\ntime, as a function of the initial marking and sojourn times. This is based on\nmethods from the theory of stochastic shortest paths and non-linear\nPerron--Frobenius theory. We illustrate the bound on a case study of a medical\nemergency call center.",
    "descriptor": "",
    "authors": [
      "Xavier Allamigeon",
      "Marin Boyet",
      "Stephane Gaubert"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2202.02752"
  },
  {
    "id": "arXiv:2202.02764",
    "title": "On Smart Gaze based Annotation of Histopathology Images for Training of  Deep Convolutional Neural Networks",
    "abstract": "Unavailability of large training datasets is a bottleneck that needs to be\novercome to realize the true potential of deep learning in histopathology\napplications. Although slide digitization via whole slide imaging scanners has\nincreased the speed of data acquisition, labeling of virtual slides requires a\nsubstantial time investment from pathologists. Eye gaze annotations have the\npotential to speed up the slide labeling process. This work explores the\nviability and timing comparisons of eye gaze labeling compared to conventional\nmanual labeling for training object detectors. Challenges associated with gaze\nbased labeling and methods to refine the coarse data annotations for subsequent\nobject detection are also discussed. Results demonstrate that gaze tracking\nbased labeling can save valuable pathologist time and delivers good performance\nwhen employed for training a deep object detector. Using the task of\nlocalization of Keratin Pearls in cases of oral squamous cell carcinoma as a\ntest case, we compare the performance gap between deep object detectors trained\nusing hand-labelled and gaze-labelled data. On average, compared to\n`Bounding-box' based hand-labeling, gaze-labeling required $57.6\\%$ less time\nper label and compared to `Freehand' labeling, gaze-labeling required on\naverage $85\\%$ less time per label.",
    "descriptor": "\nComments: 12 pages, 10 figures, 2 tables, journal\n",
    "authors": [
      "Komal Mariam",
      "Osama Mohammed Afzal",
      "Wajahat Hussain",
      "Muhammad Umar Javed",
      "Amber Kiyani",
      "Nasir Rajpoot",
      "Syed Ali Khurram",
      "Hassan Aqeel Khan"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.02764"
  },
  {
    "id": "arXiv:2202.02771",
    "title": "Optimal Algorithms for Decentralized Stochastic Variational Inequalities",
    "abstract": "Variational inequalities are a formalism that includes games, minimization,\nsaddle point, and equilibrium problems as special cases. Methods for\nvariational inequalities are therefore universal approaches for many applied\ntasks, including machine learning problems. This work concentrates on the\ndecentralized setting, which is increasingly important but not well understood.\nIn particular, we consider decentralized stochastic (sum-type) variational\ninequalities over fixed and time-varying networks. We present lower complexity\nbounds for both communication and local iterations and construct optimal\nalgorithms that match these lower bounds. Our algorithms are the best among the\navailable literature not only in the decentralized stochastic case, but also in\nthe decentralized deterministic and non-distributed stochastic cases.\nExperimental results confirm the effectiveness of the presented algorithms.",
    "descriptor": "\nComments: 52 pages, 2 algorithms (with 2 modifications), 5 theorems\n",
    "authors": [
      "Dmitry Kovalev",
      "Aleksandr Beznosikov",
      "Abdurakhmon Sadiev",
      "Michael Persiianov",
      "Peter Richt\u00e1rik",
      "Alexander Gasnikov"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.02771"
  },
  {
    "id": "arXiv:2202.02813",
    "title": "Perceptual Coding for Compressed Video Understanding: A New Framework  and Benchmark",
    "abstract": "Most video understanding methods are learned on high-quality videos. However,\nin most real-world scenarios, the videos are first compressed before the\ntransportation and then decompressed for understanding. The decompressed videos\nare degraded in terms of perceptual quality, which may degenerate the\ndownstream tasks. To address this issue, we propose the first coding framework\nfor compressed video understanding, where another learnable perceptual\nbitstream is introduced and simultaneously transported with the video\nbitstream. With the sophisticatedly designed optimization target and network\narchitectures, this new stream largely boosts the perceptual quality of the\ndecoded videos yet with a small bit cost. Our framework can enjoy the best of\nboth two worlds, (1) highly efficient content-coding of industrial video codec\nand (2) flexible perceptual-coding of neural networks (NNs). Finally, we build\na rigorous benchmark for compressed video understanding over four different\ncompression levels, six large-scale datasets, and two popular tasks. The\nproposed Dual-bitstream Perceptual Video Coding framework Dual-PVC consistently\ndemonstrates significantly stronger performances than the baseline codec under\nthe same bitrate level.",
    "descriptor": "",
    "authors": [
      "Yuan Tian",
      "Guo Lu",
      "Yichao Yan",
      "Guangtao Zhai",
      "Li Chen",
      "Zhiyong Gao"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.02813"
  },
  {
    "id": "arXiv:2202.02814",
    "title": "Wave-Encoded Model-based Deep Learning for Highly Accelerated Imaging  with Joint Reconstruction",
    "abstract": "Purpose: To propose a wave-encoded model-based deep learning (wave-MoDL)\nstrategy for highly accelerated 3D imaging and joint multi-contrast image\nreconstruction, and further extend this to enable rapid quantitative imaging\nusing an interleaved look-locker acquisition sequence with T2 preparation pulse\n(3D-QALAS).\nMethod: Recently introduced MoDL technique successfully incorporates\nconvolutional neural network (CNN)-based regularizers into physics-based\nparallel imaging reconstruction using a small number of network parameters.\nWave-CAIPI is an emerging parallel imaging method that accelerates the imaging\nspeed by employing sinusoidal gradients in the phase- and slice-encoding\ndirections during the readout to take better advantage of 3D coil sensitivity\nprofiles. In wave-MoDL, we propose to combine the wave-encoding strategy with\nunrolled network constraints to accelerate the acquisition speed while\nenforcing wave-encoded data consistency. We further extend wave-MoDL to\nreconstruct multi-contrast data with controlled aliasing in parallel imaging\n(CAIPI) sampling patterns to leverage similarity between multiple images to\nimprove the reconstruction quality.\nResult: Wave-MoDL enables a 47-second MPRAGE acquisition at 1 mm resolution\nat 16-fold acceleration. For quantitative imaging, wave-MoDL permits a 2-minute\nacquisition for T1, T2, and proton density mapping at 1 mm resolution at\n12-fold acceleration, from which contrast weighted images can be synthesized as\nwell.\nConclusion: Wave-MoDL allows rapid MR acquisition and high-fidelity image\nreconstruction and may facilitate clinical and neuroscientific applications by\nincorporating unrolled neural networks into wave-CAIPI reconstruction.",
    "descriptor": "\nComments: 8 figures, 1 table\n",
    "authors": [
      "Jaejin Cho",
      "Borjan Gagoski",
      "Taehyung Kim",
      "Qiyuan Tian",
      "Stephen Robert Frost",
      "Itthi Chatnuntawech",
      "Berkin Bilgic"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.02814"
  },
  {
    "id": "arXiv:2202.02815",
    "title": "Learning Sparse Graphs via Majorization-Minimization for Smooth Node  Signals",
    "abstract": "In this letter, we propose an algorithm for learning a sparse weighted graph\nby estimating its adjacency matrix under the assumption that the observed\nsignals vary smoothly over the nodes of the graph. The proposed algorithm is\nbased on the principle of majorization-minimization (MM), wherein we first\nobtain a tight surrogate function for the graph learning objective and then\nsolve the resultant surrogate problem which has a simple closed form solution.\nThe proposed algorithm does not require tuning of any hyperparameter and it has\nthe desirable feature of eliminating the inactive variables in the course of\nthe iterations - which can help speeding up the algorithm. The numerical\nsimulations conducted using both synthetic and real world (brain-network) data\nshow that the proposed algorithm converges faster, in terms of the average\nnumber of iterations, than several existing methods in the literature.",
    "descriptor": "",
    "authors": [
      "Ghania Fatima",
      "Aakash Arora",
      "Prabhu Babu",
      "Petre Stoica"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.02815"
  },
  {
    "id": "arXiv:2202.02831",
    "title": "Anticorrelated Noise Injection for Improved Generalization",
    "abstract": "Injecting artificial noise into gradient descent (GD) is commonly employed to\nimprove the performance of machine learning models. Usually, uncorrelated noise\nis used in such perturbed gradient descent (PGD) methods. It is, however, not\nknown if this is optimal or whether other types of noise could provide better\ngeneralization performance. In this paper, we zoom in on the problem of\ncorrelating the perturbations of consecutive PGD steps. We consider a variety\nof objective functions for which we find that GD with anticorrelated\nperturbations (\"Anti-PGD\") generalizes significantly better than GD and\nstandard (uncorrelated) PGD. To support these experimental findings, we also\nderive a theoretical analysis that demonstrates that Anti-PGD moves to wider\nminima, while GD and PGD remain stuck in suboptimal regions or even diverge.\nThis new connection between anticorrelated noise and generalization opens the\nfield to novel ways to exploit noise for training machine learning models.",
    "descriptor": "\nComments: 22 pages, 16 figures\n",
    "authors": [
      "Antonio Orvieto",
      "Hans Kersting",
      "Frank Proske",
      "Francis Bach",
      "Aurelien Lucchi"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2202.02831"
  },
  {
    "id": "arXiv:2202.02832",
    "title": "Detecting Melanoma Fairly: Skin Tone Detection and Debiasing for Skin  Lesion Classification",
    "abstract": "Convolutional Neural Networks have demonstrated human-level performance in\nthe classification of melanoma and other skin lesions, but evident performance\ndisparities between differing skin tones should be addressed before widespread\ndeployment. In this work, we utilise a modified variational autoencoder to\nuncover skin tone bias in datasets commonly used as benchmarks. We propose an\nefficient yet effective algorithm for automatically labelling the skin tone of\nlesion images, and use this to annotate the benchmark ISIC dataset. We\nsubsequently use two leading bias unlearning techniques to mitigate skin tone\nbias. Our experimental results provide evidence that our skin tone detection\nalgorithm outperforms existing solutions and that unlearning skin tone improves\ngeneralisation and can reduce the performance disparity between melanoma\ndetection in lighter and darker skin tones.",
    "descriptor": "",
    "authors": [
      "Peter J. Bevan",
      "Amir Atapour-Abarghouei"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.02832"
  },
  {
    "id": "arXiv:2202.02833",
    "title": "CheXstray: Real-time Multi-Modal Data Concordance for Drift Detection in  Medical Imaging AI",
    "abstract": "Rapidly expanding Clinical AI applications worldwide have the potential to\nimpact to all areas of medical practice. Medical imaging applications\nconstitute a vast majority of approved clinical AI applications. Though\nhealthcare systems are eager to adopt AI solutions a fundamental question\nremains: \\textit{what happens after the AI model goes into production?} We use\nthe CheXpert and PadChest public datasets to build and test a medical imaging\nAI drift monitoring workflow that tracks data and model drift without\ncontemporaneous ground truth. We simulate drift in multiple experiments to\ncompare model performance with our novel multi-modal drift metric, which uses\nDICOM metadata, image appearance representation from a variational autoencoder\n(VAE), and model output probabilities as input. Through experimentation, we\ndemonstrate a strong proxy for ground truth performance using unsupervised\ndistributional shifts in relevant metadata, predicted probabilities, and VAE\nlatent representation. Our key contributions include (1) proof-of-concept for\nmedical imaging drift detection including use of VAE and domain specific\nstatistical methods (2) a multi-modal methodology for measuring and unifying\ndrift metrics (3) new insights into the challenges and solutions for observing\ndeployed medical imaging AI (4) creation of open-source tools enabling others\nto easily run their own workflows or scenarios. This work has important\nimplications for addressing the translation gap related to continuous medical\nimaging AI model monitoring in dynamic healthcare environments.",
    "descriptor": "",
    "authors": [
      "Arjun Soin",
      "Jameson Merkow",
      "Jin Long",
      "Joesph Paul Cohen",
      "Smitha Saligrama",
      "Stephen Kaiser",
      "Steven Borg",
      "Ivan Tarapov",
      "Matthew P Lungren"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.02833"
  },
  {
    "id": "arXiv:2202.02837",
    "title": "A new similarity measure for covariate shift with applications to  nonparametric regression",
    "abstract": "We study covariate shift in the context of nonparametric regression. We\nintroduce a new measure of distribution mismatch between the source and target\ndistributions that is based on the integrated ratio of probabilities of balls\nat a given radius. We use the scaling of this measure with respect to the\nradius to characterize the minimax rate of estimation over a family of H\\\"older\ncontinuous functions under covariate shift. In comparison to the recently\nproposed notion of transfer exponent, this measure leads to a sharper rate of\nconvergence and is more fine-grained. We accompany our theory with concrete\ninstances of covariate shift that illustrate this sharp difference.",
    "descriptor": "\nComments: 22 pages, 2 figures, 1 table\n",
    "authors": [
      "Reese Pathak",
      "Cong Ma",
      "Martin J. Wainwright"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.02837"
  },
  {
    "id": "arXiv:2202.02839",
    "title": "The chromatic number of triangle-free hypergraphs",
    "abstract": "A triangle in a hypergraph $\\mathcal{H}$ is a set of three distinct edges $e,\nf, g\\in\\mathcal{H}$ and three distinct vertices $u, v, w\\in V(\\mathcal{H})$\nsuch that $\\{u, v\\}\\subseteq e$, $\\{v, w\\}\\subseteq f$, $\\{w, u\\}\\subseteq g$\nand $\\{u, v, w\\}\\cap e\\cap f\\cap g=\\emptyset$. Johansson proved in 1996 that\n$\\chi(G)=\\mathcal{O}(\\Delta/\\log\\Delta)$ for any triangle-free graph $G$ with\nmaximum degree $\\Delta$. Cooper and Mubayi later generalized the Johansson's\ntheorem to all rank $3$ hypergraphs. In this paper we provide a common\ngeneralization of both these results for all hypergraphs, showing that if\n$\\mathcal{H}$ is a rank $k$, triangle-free hypergraph, then the list chromatic\nnumber \\[ \\chi_{\\ell}(\\mathcal{H})\\leq \\mathcal{O}\\left(\\max_{2\\leq \\ell \\leq\nk} \\left\\{\\left( \\frac{\\Delta_{\\ell}}{\\log \\Delta_{\\ell}}\n\\right)^{\\frac{1}{\\ell-1}} \\right\\}\\right), \\] where $\\Delta_{\\ell}$ is the\nmaximum $\\ell$-degree of $\\mathcal{H}$. The result is sharp apart from the\nconstant. Moreover, our result implies, generalizes and improves several\nearlier results on the chromatic number and also independence number of\nhypergraphs, while its proof is based on a different approach than prior works\nin hypergraphs (and therefore provides alternative proofs to them). In\nparticular, as an application, we establish a bound on chromatic number of\nsparse hypergraphs in which each vertex is contained in few triangles, and thus\nextend results of Alon, Krivelevich and Sudakov, and Cooper and Mubayi from\nhypergraphs of rank 2 and 3, respectively, to all hypergraphs.",
    "descriptor": "\nComments: 46 pages\n",
    "authors": [
      "Lina Li",
      "Luke Postle"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2202.02839"
  },
  {
    "id": "arXiv:2202.02841",
    "title": "An Asymptotically Optimal Two-Part Coding Scheme for Networked Control  under Fixed-Rate Constraints",
    "abstract": "It is known that fixed rate adaptive quantizers can be used to stabilize an\nopen-loop-unstable linear system driven by unbounded noise. These quantizers\ncan be designed so that they have near-optimal rate, and the resulting system\nwill be stable in the sense of having an invariant probability measure, or\nergodicity, as well as the boundedness of the state second moment. However,\nresults on the minimization of the state second moment for such quantizers, an\nimportant goal in practice, do not seem to be available. In this paper, we\nconstruct a two-part adaptive coding scheme that is asymptotically optimal in\nterms of the second moments. The first part, as in prior work, leads to\nergodicity (via positive Harris recurrence) and the second part attains order\noptimality of the invariant second moment, resulting in near optimal\nperformance at high rates.",
    "descriptor": "\nComments: 10 pages, 3 figures\n",
    "authors": [
      "Jonathan Keeler",
      "Tam\u00e1s Linder",
      "Serdar Y\u00fcksel"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.02841"
  },
  {
    "id": "arXiv:2202.02853",
    "title": "Covertly Controlling a Linear System",
    "abstract": "Consider the problem of covertly controlling a linear system. In this\nproblem, Alice desires to control (stabilize or change the parameters of) a\nlinear system, while keeping an observer, Willie, unable to decide if the\nsystem is indeed being controlled or not.\nWe formally define the problem, under two different models: (i) When Willie\ncan only observe the system's output (ii) When Willie can directly observe the\ncontrol signal. Focusing on AR(1) systems, we show that when Willie observes\nthe system's output through a clean channel, an inherently unstable linear\nsystem can not be covertly stabilized. However, an inherently stable linear\nsystem can be covertly controlled, in the sense of covertly changing its\nparameter. Moreover, we give direct and converse results for two important\ncontrollers: a minimal-information controller, where Alice is allowed to used\nonly $1$ bit per sample, and a maximal-information controller, where Alice is\nallowed to view the real-valued output. Unlike covert communication, where the\ntrade-off is between rate and covertness, the results reveal an interesting\n\\emph{three--fold} trade--off in covert control: the amount of information used\nby the controller, control performance and covertness. To the best of our\nknowledge, this is the first study formally defining covert control.",
    "descriptor": "",
    "authors": [
      "Barak Amihood",
      "Asaf Cohen"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.02853"
  },
  {
    "id": "arXiv:2202.02856",
    "title": "Deep Learning-Aided Spatial Multiplexing with Index Modulation",
    "abstract": "In this paper, deep learning (DL)-aided data detection of spatial\nmultiplexing (SMX) multiple-input multiple-output (MIMO) transmission with\nindex modulation (IM) (Deep-SMX-IM) has been proposed. Deep-SMX-IM has been\nconstructed by combining a zero-forcing (ZF) detector and DL technique. The\nproposed method uses the significant advantages of DL techniques to learn\ntransmission characteristics of the frequency and spatial domains. Furthermore,\nthanks to using subblockbased detection provided by IM, Deep-SMX-IM is a\nstraightforward method, which eventually reveals reduced complexity. It has\nbeen shown that Deep-SMX-IM has significant error performance gains compared to\nZF detector without increasing computational complexity for different system\nconfigurations.",
    "descriptor": "",
    "authors": [
      "Merve Turhan",
      "Ersin Ozturk",
      "Hakan Ali Cirpan"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.02856"
  },
  {
    "id": "arXiv:2202.02876",
    "title": "Deep Convolutional Learning-Aided Detector for Generalized Frequency  Division Multiplexing with Index Modulation",
    "abstract": "In this paper, a deep convolutional neural network-based symbol detection and\ndemodulation is proposed for generalized frequency division multiplexing with\nindex modulation (GFDM-IM) scheme in order to improve the error performance of\nthe system. The proposed method first pre-processes the received signal by\nusing a zero-forcing (ZF) detector and then uses a neural network consisting of\na convolutional neural network (CNN) followed by a fully-connected neural\nnetwork (FCNN). The FCNN part uses only two fully-connected layers, which can\nbe adapted to yield a trade-off between complexity and bit error rate (BER)\nperformance. This two-stage approach prevents the getting stuck of neural\nnetwork in a saddle point and enables IM blocks processing independently. It\nhas been demonstrated that the proposed deep convolutional neural network-based\ndetection and demodulation scheme provides better BER performance compared to\nZF detector with a reasonable complexity increase. We conclude that\nnon-orthogonal waveforms combined with IM schemes with the help of deep\nlearning is a promising physical layer (PHY) scheme for future wireless\nnetworks",
    "descriptor": "",
    "authors": [
      "Merve Turhan",
      "Ersin \u00d6zt\u00fcrk",
      "Hakan Ali \u00c7\u0131rpan"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.02876"
  },
  {
    "id": "arXiv:2202.02877",
    "title": "HARFE: Hard-Ridge Random Feature Expansion",
    "abstract": "We propose a random feature model for approximating high-dimensional sparse\nadditive functions called the hard-ridge random feature expansion method\n(HARFE). This method utilizes a hard-thresholding pursuit-based algorithm\napplied to the sparse ridge regression (SRR) problem to approximate the\ncoefficients with respect to the random feature matrix. The SRR formulation\nbalances between obtaining sparse models that use fewer terms in their\nrepresentation and ridge-based smoothing that tend to be robust to noise and\noutliers. In addition, we use a random sparse connectivity pattern in the\nrandom feature matrix to match the additive function assumption. We prove that\nthe HARFE method is guaranteed to converge with a given error bound depending\non the noise and the parameters of the sparse ridge regression model. Based on\nnumerical results on synthetic data as well as on real datasets, the HARFE\napproach obtains lower (or comparable) error than other state-of-the-art\nalgorithms.",
    "descriptor": "",
    "authors": [
      "Esha Saha",
      "Hayden Schaeffer",
      "Giang Tran"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2202.02877"
  },
  {
    "id": "arXiv:2202.02884",
    "title": "On Using Transformers for Speech-Separation",
    "abstract": "Transformers have enabled major improvements in deep learning. They often\noutperform recurrent and convolutional models in many tasks while taking\nadvantage of parallel processing. Recently, we have proposed SepFormer, which\nuses self-attention and obtains state-of-the art results on WSJ0-2/3 Mix\ndatasets for speech separation. In this paper, we extend our previous work by\nproviding results on more datasets including LibriMix, and WHAM!, WHAMR! which\ninclude noisy and noisy-reverberant conditions. Moreover we provide denoising,\nand denoising+dereverberation results in the context of speech enhancement,\nrespectively on WHAM! and WHAMR! datasets. We also investigate incorporating\nrecently proposed efficient self-attention mechanisms inside the SepFormer\nmodel, and show that by using efficient self-attention mechanisms it is\npossible to reduce the memory requirements significantly while performing\nbetter than the popular convtasnet model on WSJ0-2Mix dataset.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2010.13154\n",
    "authors": [
      "Cem Subakan",
      "Mirco Ravanelli",
      "Samuele Cornell",
      "Francois Grondin",
      "Mirko Bronzi"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.02884"
  },
  {
    "id": "arXiv:2202.02899",
    "title": "Deep learning of inverse water waves problems using multi-fidelity data:  Application to Serre-Green-Naghdi equations",
    "abstract": "We consider strongly-nonlinear and weakly-dispersive surface water waves\ngoverned by equations of Boussinesq type, known as the Serre-Green-Naghdi\nsystem; it describes future states of the free water surface and depth averaged\nhorizontal velocity, given their initial state. The lack of knowledge of the\nvelocity field as well as the initial states provided by measurements lead to\nan ill-posed problem that cannot be solved by traditional techniques. To this\nend, we employ physics-informed neural networks (PINNs) to generate solutions\nto such ill-posed problems using only data of the free surface elevation and\ndepth of the water. PINNs can readily incorporate the physical laws and the\nobservational data, thereby enabling inference of the physical quantities of\ninterest. In the present study, both experimental and synthetic (generated by\nnumerical methods) training data are used to train PINNs. Furthermore,\nmulti-fidelity data are used to solve the inverse water wave problem by\nleveraging both high- and low-fidelity data sets. The applicability of the PINN\nmethodology for the estimation of the impact of water waves onto solid\nobstacles is demonstrated after deriving the corresponding equations. The\npresent methodology can be employed to efficiently design offshore structures\nsuch as oil platforms, wind turbines, etc. by solving the corresponding\nill-posed inverse water waves problem.",
    "descriptor": "",
    "authors": [
      "Ameya D. Jagtap",
      "Dimitrios Mitsotakis",
      "George Em Karniadakis"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.02899"
  },
  {
    "id": "arXiv:2202.02901",
    "title": "Inter-subject Contrastive Learning for Subject Adaptive EEG-based Visual  Recognition",
    "abstract": "This paper tackles the problem of subject adaptive EEG-based visual\nrecognition. Its goal is to accurately predict the categories of visual stimuli\nbased on EEG signals with only a handful of samples for the target subject\nduring training. The key challenge is how to appropriately transfer the\nknowledge obtained from abundant data of source subjects to the subject of\ninterest. To this end, we introduce a novel method that allows for learning\nsubject-independent representation by increasing the similarity of features\nsharing the same class but coming from different subjects. With the dedicated\nsampling principle, our model effectively captures the common knowledge shared\nacross different subjects, thereby achieving promising performance for the\ntarget subject even under harsh problem settings with limited data.\nSpecifically, on the EEG-ImageNet40 benchmark, our model records the top-1 /\ntop-3 test accuracy of 72.6% / 91.6% when using only five EEG samples per class\nfor the target subject. Our code is available at\nhttps://github.com/DeepBCI/Deep-BCI/tree/master/1_Intelligent_BCI/Inter_Subject_Contrastive_Learning_for_EEG.",
    "descriptor": "\nComments: Accepted by the 10th IEEE International Winter Conference on Brain-Computer Interface (BCI 2022). Code is available at this https URL\n",
    "authors": [
      "Pilhyeon Lee",
      "Sunhee Hwang",
      "Jewook Lee",
      "Minjung Shin",
      "Seogkyu Jeon",
      "Hyeran Byun"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.02901"
  },
  {
    "id": "arXiv:2202.02914",
    "title": "Global convergence and optimality of the heavy ball method for  non-convex optimization",
    "abstract": "In this letter we revisit the famous heavy ball method and study its global\nconvergence for a class of non-convex problems. We characterize the parameters\nthat render the method globally convergent and yield the best R- convergence\nfactor. We show that for a family of functions, this convergence factor is\nsuperior to the factor obtained from the triple momentum method.",
    "descriptor": "\nComments: Submitted to CSS Letters\n",
    "authors": [
      "Valery Ugrinovskii",
      "Ian R. Petersen",
      "Iman Shames"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.02914"
  },
  {
    "id": "arXiv:2202.02943",
    "title": "Learning fair representation with a parametric integral probability  metric",
    "abstract": "As they have a vital effect on social decision-making, AI algorithms should\nbe not only accurate but also fair. Among various algorithms for fairness AI,\nlearning fair representation (LFR), whose goal is to find a fair representation\nwith respect to sensitive variables such as gender and race, has received much\nattention. For LFR, the adversarial training scheme is popularly employed as is\ndone in the generative adversarial network type algorithms. The choice of a\ndiscriminator, however, is done heuristically without justification. In this\npaper, we propose a new adversarial training scheme for LFR, where the integral\nprobability metric (IPM) with a specific parametric family of discriminators is\nused. The most notable result of the proposed LFR algorithm is its theoretical\nguarantee about the fairness of the final prediction model, which has not been\nconsidered yet. That is, we derive theoretical relations between the fairness\nof representation and the fairness of the prediction model built on the top of\nthe representation (i.e., using the representation as the input). Moreover, by\nnumerical experiments, we show that our proposed LFR algorithm is\ncomputationally lighter and more stable, and the final prediction model is\ncompetitive or superior to other LFR algorithms using more complex\ndiscriminators.",
    "descriptor": "\nComments: 24 pages, including references and appendix\n",
    "authors": [
      "Dongha Kim",
      "Kunwoong Kim",
      "Insung Kong",
      "Ilsang Ohn",
      "Yongdai Kim"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.02943"
  },
  {
    "id": "arXiv:2202.02951",
    "title": "Deep Deterministic Independent Component Analysis for Hyperspectral  Unmixing",
    "abstract": "We develop a new neural network based independent component analysis (ICA)\nmethod by directly minimizing the dependence amongst all extracted components.\nUsing the matrix-based R{\\'e}nyi's $\\alpha$-order entropy functional, our\nnetwork can be directly optimized by stochastic gradient descent (SGD), without\nany variational approximation or adversarial training. As a solid application,\nwe evaluate our ICA in the problem of hyperspectral unmixing (HU) and refute a\nstatement that \"\\emph{ICA does not play a role in unmixing hyperspectral\ndata}\", which was initially suggested by~\\cite{nascimento2005does}. Code and\nadditional remarks of our DDICA is available at\nhttps://github.com/hongmingli1995/DDICA.",
    "descriptor": "",
    "authors": [
      "Hongming Li",
      "Shujian Yu",
      "Jose C. Principe"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.02951"
  },
  {
    "id": "arXiv:2202.02952",
    "title": "SUD: Supervision by Denoising for Medical Image Segmentation",
    "abstract": "Training a fully convolutional network for semantic segmentation typically\nrequires a large, labeled dataset with little label noise if good\ngeneralization is to be guaranteed. For many segmentation problems, however,\ndata with pixel- or voxel-level labeling accuracy are scarce due to the cost of\nmanual labeling. This problem is exacerbated in domains where manual annotation\nis difficult, resulting in large amounts of variability in the labeling even\nacross domain experts. Therefore, training segmentation networks to generalize\nbetter by learning from both labeled and unlabeled images (called\nsemi-supervised learning) is problem of both practical and theoretical\ninterest. However, traditional semi-supervised learning methods for\nsegmentation often necessitate hand-crafting a differentiable regularizer\nspecific to a given segmentation problem, which can be extremely\ntime-consuming. In this work, we propose \"supervision by denoising\" (SUD), a\nframework that enables us to supervise segmentation models using their denoised\noutput as targets. SUD unifies temporal ensembling and spatial denoising\ntechniques under a spatio-temporal denoising framework and alternates denoising\nand network weight update in an optimization framework for semi-supervision. We\nvalidate SUD on three tasks-kidney and tumor (3D), and brain (3D) segmentation,\nand cortical parcellation (2D)-demonstrating a significant improvement in the\nDice overlap and the Hausdorff distance of segmentations over supervised-only\nand temporal ensemble baselines.",
    "descriptor": "\nComments: Author's manuscript for IEEE Trans. Pattern Anal. Mach. Intell\n",
    "authors": [
      "Sean I. Young",
      "Adrian V. Dalca",
      "Enzo Ferrante",
      "Polina Golland",
      "Bruce Fischl",
      "Juan Eugenio Iglesias"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.02952"
  },
  {
    "id": "arXiv:2202.02958",
    "title": "Comprehensive survey of computational learning methods for analysis of  gene expression data in genomics",
    "abstract": "Computational analysis methods including machine learning have a significant\nimpact in the fields of genomics and medicine. High-throughput gene expression\nanalysis methods such as microarray technology and RNA sequencing produce\nenormous amounts of data. Traditionally, statistical methods are used for\ncomparative analysis of the gene expression data. However, more complex\nanalysis for classification and discovery of feature genes or sample\nobservations requires sophisticated computational approaches. In this review,\nwe compile various statistical and computational tools used in analysis of\nexpression microarray data. Even though, the methods are discussed in the\ncontext of expression microarray data, they can also be applied for the\nanalysis of RNA sequencing or quantitative proteomics datasets. We specifically\ndiscuss methods for missing value (gene expression) imputation, feature gene\nscaling, selection and extraction of features for dimensionality reduction, and\nlearning and analysis of expression data. We discuss the types of missing\nvalues and the methods and approaches usually employed in their imputation. We\nalso discuss methods of data transformation and feature scaling viz.\nnormalization and standardization. Various approaches used in feature selection\nand extraction are also reviewed. Lastly, learning and analysis methods\nincluding class comparison, class prediction, and class discovery along with\ntheir evaluation parameters are described in detail. We have described the\nprocess of generation of a microarray gene expression data along with\nadvantages and limitations of the above-mentioned techniques. We believe that\nthis detailed review will help the users to select appropriate methods based on\nthe type of data and the expected outcome.",
    "descriptor": "\nComments: 51 pages, 9 figures, 5 tables\n",
    "authors": [
      "Nikita Bhandari",
      "Rahee Walambe",
      "Ketan Kotech",
      "Satyajeet Khare"
    ],
    "subjectives": [
      "Genomics (q-bio.GN)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.02958"
  },
  {
    "id": "arXiv:2202.02984",
    "title": "Deep Residual Shrinkage Networks for EMG-based Gesture Identification",
    "abstract": "This work introduces a method for high-accuracy EMG based gesture\nidentification. A newly developed deep learning method, namely, deep residual\nshrinkage network is applied to perform gesture identification. Based on the\nfeature of EMG signal resulting from gestures, optimizations are made to\nimprove the identification accuracy. Finally, three different algorithms are\napplied to compare the accuracy of EMG signal recognition with that of DRSN.\nThe result shows that DRSN excel traditional neural networks in terms of EMG\nrecognition accuracy. This paper provides a reliable way to classify EMG\nsignals, as well as exploring possible applications of DRSN.",
    "descriptor": "",
    "authors": [
      "Yueying Ma",
      "Chengbo Wang",
      "Chengbo Wang",
      "Zimo Li"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.02984"
  },
  {
    "id": "arXiv:2202.02999",
    "title": "Beyond Windability: An FPRAS for The Six-Vertex Model",
    "abstract": "The six-vertex model is an important model in statistical physics and has\ndeep connections with counting problems. There have been some fully polynomial\nrandomized approximation schemes (FPRAS) for the six-vertex model [30, 10],\nwhich all require that the constraint functions are windable. In the present\npaper, we give an FPRAS for the six-vertex model with an unwindable constraint\nfunction by Markov Chain Monte Carlo method (MCMC). Different from [10], we use\nthe Glauber dynamics to design the Markov Chain depending on a circuit\ndecomposition of the underlying graph. Moreover, we prove the rapid mixing of\nthe Markov Chain by coupling, instead of canonical paths in [10].",
    "descriptor": "\nComments: 15 pages, 2 figures, International Colloquium on Automata, Languages and Programming(ICALP)\n",
    "authors": [
      "Zhiguo Fu",
      "Junda Li",
      "Xiongxin Yang"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2202.02999"
  },
  {
    "id": "arXiv:2202.03008",
    "title": "Algorithms that get old : the case of generative algorithms",
    "abstract": "Generative IA networks, like the Variational Auto-Encoders (VAE), and\nGenerative Adversarial Networks (GANs) produce new objects each time when asked\nto do so. However, this behavior is unlike that of human artists that change\ntheir style as times go by and seldom return to the initial point. We\ninvestigate a situation where VAEs are requested to sample from a probability\nmeasure described by some empirical set. Based on recent works on Radon-Sobolev\nstatistical distances, we propose a numerical paradigm, to be used in\nconjunction with a generative algorithm, that satisfies the two following\nrequirements: the objects created do not repeat and evolve to fill the entire\ntarget probability measure.",
    "descriptor": "",
    "authors": [
      "Gabriel Turinici"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.03008"
  },
  {
    "id": "arXiv:2202.03028",
    "title": "QUARK: A Framework for Quantum Computing Application Benchmarking",
    "abstract": "Quantum computing (QC) is anticipated to provide a speedup over classical HPC\napproaches for specific problems in optimization, simulation, and machine\nlearning. With the advances in quantum computing toward practical applications,\nthe need to analyze and compare different quantum solutions increases. While\ndifferent low-level benchmarks for QC exist, these benchmarks do not provide\nsufficient insights into real-world application-level performance. We propose\nan application-centric benchmark method and the QUantum computing Application\nbenchmaRK (QUARK) framework to foster the investigation and creation of\napplication benchmarks for QC. This paper establishes three significant\ncontributions: (1) it makes a case for application-level benchmarks and\nprovides an in-depth \"pen and paper\" benchmark formulation of two reference\nproblems: robot path and vehicle option optimization from the industrial\ndomain; (2) it proposes the open-source QUARK framework for designing,\nimplementing, executing, and analyzing benchmarks; (3) it provides multiple\nreference implementations for these two reference problems based on different\nknown, and where needed, extended, classical and quantum algorithmic approaches\nand analyzes their performance on different types of infrastructures.",
    "descriptor": "",
    "authors": [
      "Jernej Rudi Fin\u017egar",
      "Philipp Ross",
      "Johannes Klepsch",
      "Andre Luckow"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2202.03028"
  },
  {
    "id": "arXiv:2202.03031",
    "title": "A comprehensive benchmark analysis for sand dust image reconstruction",
    "abstract": "Numerous sand dust image enhancement algorithms have been proposed in recent\nyears. To our best acknowledge, however, most methods evaluated their\nperformance with no-reference way using few selected real-world images from\ninternet. It is unclear how to quantitatively analysis the performance of the\nalgorithms in a supervised way and how we could gauge the progress in the\nfield. Moreover, due to the absence of large-scale benchmark datasets, there\nare no well-known reports of data-driven based method for sand dust image\nenhancement up till now. To advance the development of deep learning-based\nalgorithms for sand dust image reconstruction, while enabling supervised\nobjective evaluation of algorithm performance. In this paper, we presented a\ncomprehensive perceptual study and analysis of real-world sand dust images,\nthen constructed a Sand-dust Image Reconstruction Benchmark (SIRB) for training\nConvolutional Neural Networks (CNNs) and evaluating algorithms performance. In\naddition, we adopted the existing image transformation neural network trained\non SIRB as baseline to illustrate the generalization of SIRB for training CNNs.\nFinally, we conducted the qualitative and quantitative evaluation to\ndemonstrate the performance and limitations of the state-of-the-arts (SOTA),\nwhich shed light on future research in sand dust image reconstruction.",
    "descriptor": "\nComments: 13 pages, 12 figures\n",
    "authors": [
      "Yazhong Si",
      "Fan Yang",
      "Ya Guo",
      "Wei Zhang",
      "Yipu Yang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.03031"
  },
  {
    "id": "arXiv:2202.03036",
    "title": "Structure-Aware Transformer for Graph Representation Learning",
    "abstract": "The Transformer architecture has gained growing attention in graph\nrepresentation learning recently, as it naturally overcomes several limitations\nof graph neural networks (GNNs) by avoiding their strict structural inductive\nbiases and instead only encoding the graph structure via positional encoding.\nHere, we show that the node representations generated by the Transformer with\npositional encoding do not necessarily capture structural similarity between\nthem. To address this issue, we propose the Structure-Aware Transformer, a\nclass of simple and flexible graph transformers built upon a new self-attention\nmechanism. This new self-attention incorporates structural information into the\noriginal self-attention by extracting a subgraph representation rooted at each\nnode before computing the attention. We propose several methods for\nautomatically generating the subgraph representation and show theoretically\nthat the resulting representations are at least as expressive as the subgraph\nrepresentations. Empirically, our method achieves state-of-the-art performance\non five graph prediction benchmarks. Our structure-aware framework can leverage\nany existing GNN to extract the subgraph representation, and we show that it\nsystematically improves performance relative to the base GNN model,\nsuccessfully combining the advantages of GNNs and transformers.",
    "descriptor": "",
    "authors": [
      "Dexiong Chen",
      "Leslie O'Bray",
      "Karsten Borgwardt"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.03036"
  },
  {
    "id": "arXiv:2202.03044",
    "title": "Hybrid quantum annealing for larger-than-QPU lattice-structured problems",
    "abstract": "Quantum processing units (QPUs) executing annealing algorithms have shown\npromise in optimization and simulation applications. Hybrid algorithms are a\nnatural bridge to additional applications of larger scale. We present a\nstraightforward and effective method for solving larger-than-QPU\nlattice-structured Ising optimization problems. Performance is compared against\nsimulated annealing with promising results, and improvement is shown as a\nfunction of the generation of D-Wave QPU used.",
    "descriptor": "\nComments: 21 pages, 15 figures, supplementary code attachment\n",
    "authors": [
      "Jack Raymond",
      "Radomir Stevanovic",
      "William Bernoudy",
      "Kelly Boothby",
      "Catherine McGeoch",
      "Andrew J. Berkley",
      "Pau Farr\u00e9",
      "Andrew D. King"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2202.03044"
  },
  {
    "id": "arXiv:2202.03101",
    "title": "NUQ: Nonparametric Uncertainty Quantification for Deterministic Neural  Networks",
    "abstract": "This paper proposes a fast and scalable method for uncertainty quantification\nof machine learning models' predictions. First, we show the principled way to\nmeasure the uncertainty of predictions for a classifier based on\nNadaraya-Watson's nonparametric estimate of the conditional label distribution.\nImportantly, the approach allows to disentangle explicitly aleatoric and\nepistemic uncertainties. The resulting method works directly in the feature\nspace. However, one can apply it to any neural network by considering an\nembedding of the data induced by the network. We demonstrate the strong\nperformance of the method in uncertainty estimation tasks on a variety of\nreal-world image datasets, such as MNIST, SVHN, CIFAR-100 and several versions\nof ImageNet.",
    "descriptor": "",
    "authors": [
      "Nikita Kotelevskii",
      "Aleksandr Artemenkov",
      "Kirill Fedyanin",
      "Fedor Noskov",
      "Alexander Fishkov",
      "Aleksandr Petiushko",
      "Maxim Panov"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.03101"
  },
  {
    "id": "arXiv:2202.03125",
    "title": "Building Synthetic Speaker Profiles in Text-to-Speech Systems",
    "abstract": "The diversity of speaker profiles in multi-speaker TTS systems is a crucial\naspect of its performance, as it measures how many different speaker profiles\nTTS systems could possibly synthesize. However, this important aspect is often\noverlooked when building multi-speaker TTS systems and there is no established\nframework to evaluate this diversity. The reason behind is that most\nmulti-speaker TTS systems are limited to generate speech signals with the same\nspeaker profiles as its training data. They often use discrete speaker\nembedding vectors which have a one-to-one correspondence with individual\nspeakers. This correspondence limits TTS systems and hinders their capability\nof generating unseen speaker profiles that did not appear during training. In\nthis paper, we aim to build multi-speaker TTS systems that have a greater\nvariety of speaker profiles and can generate new synthetic speaker profiles\nthat are different from training data. To this end, we propose to use\ngenerative models with a triplet loss and a specific shuffle mechanism. In our\nexperiments, the effectiveness and advantages of the proposed method have been\ndemonstrated in terms of both the distinctiveness and intelligibility of\nsynthesized speech signals.",
    "descriptor": "",
    "authors": [
      "Jie Pu",
      "Yixiong Meng",
      "Oguz Elibol"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2202.03125"
  },
  {
    "id": "arXiv:2202.03149",
    "title": "Neural Network based Inter bi-prediction Blending",
    "abstract": "This paper presents a learning-based method to improve bi-prediction in video\ncoding. In conventional video coding solutions, the motion compensation of\nblocks from already decoded reference pictures stands out as the principal tool\nused to predict the current frame. Especially, the bi-prediction, in which a\nblock is obtained by averaging two different motion-compensated prediction\nblocks, significantly improves the final temporal prediction accuracy. In this\ncontext, we introduce a simple neural network that further improves the\nblending operation. A complexity balance, both in terms of network size and\nencoder mode selection, is carried out. Extensive tests on top of the recently\nstandardized VVC codec are performed and show a BD-rate improvement of -1.4% in\nrandom access configuration for a network size of fewer than 10k parameters. We\nalso propose a simple CPU-based implementation and direct network quantization\nto assess the complexity/gains tradeoff in a conventional codec framework.",
    "descriptor": "",
    "authors": [
      "Franck Galpin",
      "Philippe Bordes",
      "Thierry Dumas",
      "Pavel Nikitin",
      "Fabrice Le Leannec"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.03149"
  },
  {
    "id": "arXiv:2202.03156",
    "title": "Comparative Study of Machine Learning Models for Stock Price Prediction",
    "abstract": "In this work, we apply machine learning techniques to historical stock prices\nto forecast future prices. To achieve this, we use recursive approaches that\nare appropriate for handling time series data. In particular, we apply a linear\nKalman filter and different varieties of long short-term memory (LSTM)\narchitectures to historical stock prices over a 10-year range (1/1/2011 -\n1/1/2021). We quantify the results of these models by computing the error of\nthe predicted values versus the historical values of each stock. We find that\nof the algorithms we investigated, a simple linear Kalman filter can predict\nthe next-day value of stocks with low-volatility (e.g., Microsoft) surprisingly\nwell. However, in the case of high-volatility stocks (e.g., Tesla) the more\ncomplex LSTM algorithms significantly outperform the Kalman filter. Our results\nshow that we can classify different types of stocks and then train an LSTM for\neach stock type. This method could be used to automate portfolio generation for\na target return rate.",
    "descriptor": "",
    "authors": [
      "Ogulcan E. Orsel",
      "Sasha S. Yamada"
    ],
    "subjectives": [
      "Statistical Finance (q-fin.ST)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.03156"
  },
  {
    "id": "arXiv:2202.03158",
    "title": "Dual-CLVSA: a Novel Deep Learning Approach to Predict Financial Markets  with Sentiment Measurements",
    "abstract": "It is a challenging task to predict financial markets. The complexity of this\ntask is mainly due to the interaction between financial markets and market\nparticipants, who are not able to keep rational all the time, and often\naffected by emotions such as fear and ecstasy. Based on the state-of-the-art\napproach particularly for financial market predictions, a hybrid convolutional\nLSTM Based variational sequence-to-sequence model with attention (CLVSA), we\npropose a novel deep learning approach, named dual-CLVSA, to predict financial\nmarket movement with both trading data and the corresponding social sentiment\nmeasurements, each through a separate sequence-to-sequence channel. We evaluate\nthe performance of our approach with backtesting on historical trading data of\nSPDR SP 500 Trust ETF over eight years. The experiment results show that\ndual-CLVSA can effectively fuse the two types of data, and verify that\nsentiment measurements are not only informative for financial market\npredictions, but they also contain extra profitable features to boost the\nperformance of our predicting system.",
    "descriptor": "\nComments: 8 pages, 2021 20th IEEE International Conference on Machine Learning and Applications (ICMLA). IEEE, 2021\n",
    "authors": [
      "Jia Wang",
      "Hongwei Zhu",
      "Jiancheng Shen",
      "Yu Cao",
      "Benyuan Liu"
    ],
    "subjectives": [
      "Statistical Finance (q-fin.ST)",
      "Machine Learning (cs.LG)",
      "Computational Finance (q-fin.CP)",
      "Trading and Market Microstructure (q-fin.TR)"
    ],
    "url": "https://arxiv.org/abs/2202.03158"
  },
  {
    "id": "arXiv:2202.03159",
    "title": "$L^2$-Betti numbers and computability of reals",
    "abstract": "We study the computability degree of real numbers arising as $L^2$-Betti\nnumbers or $L^2$-torsion of groups, parametrised over the Turing degree of the\nword problem. Moreover, we explain how such considerations can be modelled in a\nproof assistant.",
    "descriptor": "\nComments: 35 pages; Lean implementation available at this https URL\n",
    "authors": [
      "Clara Loeh",
      "Matthias Uschold"
    ],
    "subjectives": [
      "Group Theory (math.GR)",
      "Logic in Computer Science (cs.LO)",
      "Geometric Topology (math.GT)",
      "Logic (math.LO)"
    ],
    "url": "https://arxiv.org/abs/2202.03159"
  },
  {
    "id": "arXiv:2202.03165",
    "title": "SLIDE: a surrogate fairness constraint to ensure fairness consistency",
    "abstract": "As they have a vital effect on social decision makings, AI algorithms should\nbe not only accurate and but also fair. Among various algorithms for fairness\nAI, learning a prediction model by minimizing the empirical risk (e.g.,\ncross-entropy) subject to a given fairness constraint has received much\nattention. To avoid computational difficulty, however, a given fairness\nconstraint is replaced by a surrogate fairness constraint as the 0-1 loss is\nreplaced by a convex surrogate loss for classification problems. In this paper,\nwe investigate the validity of existing surrogate fairness constraints and\npropose a new surrogate fairness constraint called SLIDE, which is\ncomputationally feasible and asymptotically valid in the sense that the learned\nmodel satisfies the fairness constraint asymptotically and achieves a fast\nconvergence rate. Numerical experiments confirm that the SLIDE works well for\nvarious benchmark datasets.",
    "descriptor": "\nComments: 41 pages including appendix\n",
    "authors": [
      "Kunwoong Kim",
      "Ilsang Ohn",
      "Sara Kim",
      "Yongdai Kim"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.03165"
  },
  {
    "id": "arXiv:2202.03181",
    "title": "On chromatic parameters of some Regular graphs",
    "abstract": "In this work, we try to enunciate the Total chromatic number of some Cayley\ngraphs like the Cayley graph on Symmetric group, Alternating group, Dihedral\ngroup with respect to some generating sets and some other regular graphs.",
    "descriptor": "\nComments: 6 pages\n",
    "authors": [
      "Prajnanaswaroopa S"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2202.03181"
  },
  {
    "id": "arXiv:2202.03204",
    "title": "T-NGA: Temporal Network Grafting Algorithm for Learning to Process  Spiking Audio Sensor Events",
    "abstract": "Spiking silicon cochlea sensors encode sound as an asynchronous stream of\nspikes from different frequency channels. The lack of labeled training datasets\nfor spiking cochleas makes it difficult to train deep neural networks on the\noutputs of these sensors. This work proposes a self-supervised method called\nTemporal Network Grafting Algorithm (T-NGA), which grafts a recurrent network\npretrained on spectrogram features so that the network works with the cochlea\nevent features. T-NGA training requires only temporally aligned audio\nspectrograms and event features. Our experiments show that the accuracy of the\ngrafted network was similar to the accuracy of a supervised network trained\nfrom scratch on a speech recognition task using events from a software spiking\ncochlea model. Despite the circuit non-idealities of the spiking silicon\ncochlea, the grafted network accuracy on the silicon cochlea spike recordings\nwas only about 5% lower than the supervised network accuracy using the\nN-TIDIGITS18 dataset. T-NGA can train networks to process spiking audio sensor\nevents in the absence of large labeled spike datasets.",
    "descriptor": "\nComments: 5 pages, 4 figures; accepted at IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), Singapore, 2022\n",
    "authors": [
      "Shu Wang",
      "Yuhuang Hu",
      "Shih-Chii Liu"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2202.03204"
  },
  {
    "id": "arXiv:2202.03211",
    "title": "Semantic-aware Speech to Text Transmission with Redundancy Removal",
    "abstract": "Deep learning (DL) based semantic communication methods have been explored\nfor the efficient transmission of images, text, and speech in recent years. In\ncontrast to traditional wireless communication methods that focus on the\ntransmission of abstract symbols, semantic communication approaches attempt to\nachieve better transmission efficiency by only sending the semantic-related\ninformation of the source data. In this paper, we consider semantic-oriented\nspeech to text transmission. We propose a novel end-to-end DL-based\ntransceiver, which includes an attention-based soft alignment module and a\nredundancy removal module to compress the transmitted data. In particular, the\nformer extracts only the text-related semantic features, and the latter further\ndrops the semantically redundant content, greatly reducing the amount of\nsemantic redundancy compared to existing methods. We also propose a two-stage\ntraining scheme, which speeds up the training of the proposed DL model. The\nsimulation results indicate that our proposed method outperforms current\nmethods in terms of the accuracy of the received text and transmission\nefficiency. Moreover, the proposed method also has a smaller model size and\nshorter end-to-end runtime.",
    "descriptor": "",
    "authors": [
      "Tianxiao Han",
      "Qianqian Yang",
      "Zhiguo Shi",
      "Shibo He",
      "Zhaoyang Zhang"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2202.03211"
  },
  {
    "id": "arXiv:2202.03223",
    "title": "SODA: Self-organizing data augmentation in deep neural networks --  Application to biomedical image segmentation tasks",
    "abstract": "In practice, data augmentation is assigned a predefined budget in terms of\nnewly created samples per epoch. When using several types of data augmentation,\nthe budget is usually uniformly distributed over the set of augmentations but\none can wonder if this budget should not be allocated to each type in a more\nefficient way. This paper leverages online learning to allocate on the fly this\nbudget as part of neural network training. This meta-algorithm can be run at\nalmost no extra cost as it exploits gradient based signals to determine which\ntype of data augmentation should be preferred. Experiments suggest that this\nstrategy can save computation time and thus goes in the way of greener machine\nlearning practices.",
    "descriptor": "",
    "authors": [
      "Arnaud Deleruyelle",
      "John Klein",
      "Cristian Versari"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2202.03223"
  },
  {
    "id": "arXiv:2202.03233",
    "title": "A Variational Edge Partition Model for Supervised Graph Representation  Learning",
    "abstract": "Graph neural networks (GNNs), which propagate the node features through the\nedges and learn how to transform the aggregated features under label\nsupervision, have achieved great success in supervised feature extraction for\nboth node-level and graph-level classification tasks. However, GNNs typically\ntreat the graph structure as given and ignore how the edges are formed. This\npaper introduces a graph generative process to model how the observed edges are\ngenerated by aggregating the node interactions over a set of overlapping node\ncommunities, each of which contributes to the edges via a logical OR mechanism.\nBased on this generative model, we partition each edge into the summation of\nmultiple community-specific weighted edges and use them to define\ncommunity-specific GNNs. A variational inference framework is proposed to\njointly learn a GNN based inference network that partitions the edges into\ndifferent communities, these community-specific GNNs, and a GNN based predictor\nthat combines community-specific GNNs for the end classification task.\nExtensive evaluations on real-world graph datasets have verified the\neffectiveness of the proposed method in learning discriminative representations\nfor both node-level and graph-level classification tasks.",
    "descriptor": "\nComments: 14 pages, 3 figures, 13 pages of appendix\n",
    "authors": [
      "Yilin He",
      "Chaojie Wang",
      "Hao Zhang",
      "Bo Chen",
      "Mingyuan Zhou"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2202.03233"
  },
  {
    "id": "arXiv:2202.03234",
    "title": "Generalised norm resolvent convergence: comparison of different concepts",
    "abstract": "In this paper, we show that the two concepts of generalised norm resolvent\nconvergence introduced by Weidmann and the first author of this paper are\nequivalent. We also focus on the convergence speed and provide conditions under\nwhich the convergence speed is the same for both concepts. We illustrate the\nabstract results by a large number of examples.",
    "descriptor": "\nComments: 36 pages, 6 figures\n",
    "authors": [
      "Olaf Post",
      "Sebastian Zimmer"
    ],
    "subjectives": [
      "Functional Analysis (math.FA)",
      "Numerical Analysis (math.NA)",
      "Spectral Theory (math.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.03234"
  },
  {
    "id": "arXiv:2202.03264",
    "title": "Short-term Multi-horizon Residential Electric Load Forecasting using  Deep Learning and Signal Decomposition Methods",
    "abstract": "With the booming growth of advanced digital technologies, it has become\npossible for users as well as distributors of energy to obtain detailed and\ntimely information about the electricity consumption of households. These\ntechnologies can also be used to forecast the household's electricity\nconsumption (a.k.a. the load). In this paper, we investigate the use of\nVariational Mode Decomposition and deep learning techniques to improve the\naccuracy of the load forecasting problem. Although this problem has been\nstudied in the literature, selecting an appropriate decomposition level and a\ndeep learning technique providing better forecasting performance have garnered\ncomparatively less attention. This study bridges this gap by studying the\neffect of six decomposition levels and five distinct deep learning networks.\nThe raw load profiles are first decomposed into intrinsic mode functions using\nthe Variational Mode Decomposition in order to mitigate their non-stationary\naspect. Then, day, hour, and past electricity consumption data are fed as a\nthree-dimensional input sequence to a four-level Wavelet Decomposition Network\nmodel. Finally, the forecast sequences related to the different intrinsic mode\nfunctions are combined to form the aggregate forecast sequence. The proposed\nmethod was assessed using load profiles of five Moroccan households from the\nMoroccan buildings' electricity consumption dataset (MORED) and was benchmarked\nagainst state-of-the-art time-series models and a baseline persistence model.",
    "descriptor": "",
    "authors": [
      "Mohamed Aymane Ahajjam",
      "Daniel Bonilla Licea",
      "Mounir Ghogho",
      "Abdellatif Kobbane"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.03264"
  },
  {
    "id": "arXiv:2202.03267",
    "title": "Team Cogitat at NeurIPS 2021: Benchmarks for EEG Transfer Learning  Competition",
    "abstract": "Building subject-independent deep learning models for EEG decoding faces the\nchallenge of strong covariate-shift across different datasets, subjects and\nrecording sessions. Our approach to address this difficulty is to explicitly\nalign feature distributions at various layers of the deep learning model, using\nboth simple statistical techniques as well as trainable methods with more\nrepresentational capacity. This follows in a similar vein as covariance-based\nalignment methods, often used in a Riemannian manifold context. The methodology\nproposed herein won first place in the 2021 Benchmarks in EEG Transfer Learning\n(BEETL) competition, hosted at the NeurIPS conference. The first task of the\ncompetition consisted of sleep stage classification, which required the\ntransfer of models trained on younger subjects to perform inference on multiple\nsubjects of older age groups without personalized calibration data, requiring\nsubject-independent models. The second task required to transfer models trained\non the subjects of one or more source motor imagery datasets to perform\ninference on two target datasets, providing a small set of personalized\ncalibration data for multiple test subjects.",
    "descriptor": "",
    "authors": [
      "Stylianos Bakas",
      "Siegfried Ludwig",
      "Konstantinos Barmpas",
      "Mehdi Bahri",
      "Yannis Panagakis",
      "Nikolaos Laskaris",
      "Dimitrios A. Adamos",
      "Stefanos Zafeiriou"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.03267"
  },
  {
    "id": "arXiv:2202.03268",
    "title": "Cyber-resilience for marine navigation by information fusion and change  detection",
    "abstract": "Cyber-resilience is an increasing concern in developing autonomous navigation\nsolutions for marine vessels. This paper scrutinizes cyber-resilience\nproperties of marine navigation through a prism with three edges: multiple\nsensor information fusion, diagnosis of not-normal behaviours, and change\ndetection. It proposes a two-stage estimator for diagnosis and mitigation of\nsensor signals used for coastal navigation. Developing a Likelihood Field\napproach, a first stage extracts shoreline features from radar and matches them\nto the electronic navigation chart. A second stage associates buoy and beacon\nfeatures from the radar with chart information. Using real data logged at sea\ntests combined with simulated spoofing, the paper verifies the ability to\ntimely diagnose and isolate an attempt to compromise position measurements. A\nnew approach is suggested for high level processing of received data to\nevaluate their consistency, that is agnostic to the underlying technology of\nthe individual sensory input. A combined parametric Gaussian modelling and\nKernel Density Estimation is suggested and compared with a generalized\nlikelihood ratio change detector that uses sliding windows. The paper shows how\ndeviations from nominal behaviour and isolation of the components is possible\nwhen under attack or when defects in sensors occur.",
    "descriptor": "\nComments: 18 pages, 21 figures\n",
    "authors": [
      "Dimitrios Dagdilelis",
      "Mogens Blanke",
      "Rasmus Hjorth Andersen",
      "Roberto Galeazzi"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2202.03268"
  },
  {
    "id": "arXiv:2202.03271",
    "title": "Spectro Temporal EEG Biomarkers For Binary Emotion Classification",
    "abstract": "Electroencephalogram (EEG) is one of the most reliable physiological signal\nfor emotion detection. Being non-stationary in nature, EEGs are better analysed\nby spectro temporal representations. Standard features like Discrete Wavelet\nTransformation (DWT) can represent temporal changes in spectral dynamics of an\nEEG, but is insufficient to extract information other way around, i.e. spectral\nchanges in temporal dynamics. On the other hand, Empirical mode decomposition\n(EMD) based features can be useful to bridge the above mentioned gap. Towards\nthis direction, we extract two novel features on top of EMD, namely, (a)\nmarginal hilbert spectrum (MHS) and (b) Holo-Hilbert spectral analysis (HHSA)\nbased on EMD, to better represent emotions in 2D arousal-valence (A-V) space.\nThe usefulness of these features for EEG emotion classification is investigated\nthrough extensive experiments using state-of-the-art classifiers. In addition,\nexperiments conducted on DEAP dataset for binary emotion classification in both\nA-V space, reveal the efficacy of the proposed features over the standard set\nof temporal and spectral features.",
    "descriptor": "",
    "authors": [
      "Upasana Tiwari",
      "Rupayan Chakraborty",
      "Sunil Kumar Kopparapu"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.03271"
  },
  {
    "id": "arXiv:2202.03273",
    "title": "Wave-Controlled Metasurface-Based Reconfigurable Intelligent Surfaces",
    "abstract": "Reconfigurable Intelligent Surfaces (RISs) are programmable metasurfaces that\ncan adaptively steer received electromagnetic energy in desired directions by\nemploying controllable phase shifting cells. Among other uses, an RIS can\nmodify the propagation environment in order to provide wireless access to user\nlocations that are not otherwise reachable by a base station. Alternatively, an\nRIS can steer the waves away from particular locations in space, to eliminate\ninterference and allow for co-existence of the wireless network with other\ntypes of fixed wireless services (e.g., radars, unlicensed radio bands, etc.).\nThe novel approach in this work is a wave-controlled architecture that properly\naccounts for the maximum possible change in the local reflection phase that can\nbe achieved by adjacent RIS elements. It obviates the need for dense wiring and\nsignal paths that would be required for individual control of every RIS\nelement, and thus offers a substantial reduction in the required hardware. We\nspecify this wave-controlled RIS architecture in detail and discuss signal\nprocessing and machine learning methods that exploit it in both point-to-point\nand multicell MIMO systems. Such implementations can lead to a dramatic\nimprovement in next-generation wireless, radar, and navigation systems where\nRIS finds wide applications. They have the potential to improve the efficiency\nof spectrum utilization and coexistence by orders of magnitude.",
    "descriptor": "\nComments: 16 pages, 5 figures\n",
    "authors": [
      "Ender Ayanoglu",
      "Filippo Capolino",
      "A. Lee Swindlehurst"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2202.03273"
  },
  {
    "id": "arXiv:2202.03274",
    "title": "Human Activity Recognition Using Tools of Convolutional Neural Networks:  A State of the Art Review, Data Sets, Challenges and Future Prospects",
    "abstract": "Human Activity Recognition (HAR) plays a significant role in the everyday\nlife of people because of its ability to learn extensive high-level information\nabout human activity from wearable or stationary devices. A substantial amount\nof research has been conducted on HAR and numerous approaches based on deep\nlearning and machine learning have been exploited by the research community to\nclassify human activities. The main goal of this review is to summarize recent\nworks based on a wide range of deep neural networks architecture, namely\nconvolutional neural networks (CNNs) for human activity recognition. The\nreviewed systems are clustered into four categories depending on the use of\ninput devices like multimodal sensing devices, smartphones, radar, and vision\ndevices. This review describes the performances, strengths, weaknesses, and the\nused hyperparameters of CNN architectures for each reviewed system with an\noverview of available public data sources. In addition, a discussion with the\ncurrent challenges to CNN-based HAR systems is presented. Finally, this review\nis concluded with some potential future directions that would be of great\nassistance for the researchers who would like to contribute to this field.",
    "descriptor": "\nComments: 32 pages, 4 figures, 4 Tables\n",
    "authors": [
      "Md. Milon Islam",
      "Sheikh Nooruddin",
      "Fakhri Karray",
      "Ghulam Muhammad"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.03274"
  },
  {
    "id": "arXiv:2202.03297",
    "title": "Grassmann Stein Variational Gradient Descent",
    "abstract": "Stein variational gradient descent (SVGD) is a deterministic particle\ninference algorithm that provides an efficient alternative to Markov chain\nMonte Carlo. However, SVGD has been found to suffer from variance\nunderestimation when the dimensionality of the target distribution is high.\nRecent developments have advocated projecting both the score function and the\ndata onto real lines to sidestep this issue, although this can severely\noverestimate the epistemic (model) uncertainty. In this work, we propose\nGrassmann Stein variational gradient descent (GSVGD) as an alternative\napproach, which permits projections onto arbitrary dimensional subspaces.\nCompared with other variants of SVGD that rely on dimensionality reduction,\nGSVGD updates the projectors simultaneously for the score function and the\ndata, and the optimal projectors are determined through a coupled\nGrassmann-valued diffusion process which explores favourable subspaces. Both\nour theoretical and experimental results suggest that GSVGD enjoys efficient\nstate-space exploration in high-dimensional problems that have an intrinsic\nlow-dimensional structure.",
    "descriptor": "\nComments: 20 pages, 13 figures, to appear in AISTATS 2022\n",
    "authors": [
      "Xing Liu",
      "Harrison Zhu",
      "Jean-Fran\u00e7ois Ton",
      "George Wynne",
      "Andrew Duncan"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2202.03297"
  },
  {
    "id": "arXiv:2202.03323",
    "title": "Motion-Plane-Adaptive Inter Prediction in 360-Degree Video Coding",
    "abstract": "Inter prediction is one of the key technologies enabling the high compression\nefficiency of modern video coding standards. 360-degree video needs to be\nmapped to the 2D image plane prior to coding in order to allow compression\nusing existing video coding standards. The distortions that inevitably occur\nwhen mapping spherical data onto the 2D image plane, however, impair the\nperformance of classical inter prediction techniques. In this paper, we propose\na motion-plane-adaptive inter prediction technique (MPA) for 360-degree video\nthat takes the spherical characteristics of 360-degree video into account.\nBased on the known projection format of the video, MPA allows to perform inter\nprediction on different motion planes in 3D space instead of having to work on\nthe - in theory arbitrarily mapped - 2D image representation directly. We\nfurthermore derive a motion-plane-adaptive motion vector prediction technique\n(MPA-MVP) that allows to translate motion information between different motion\nplanes and motion models. Our proposed integration of MPA together with MPA-MVP\ninto the state-of-the-art H.266/VVC video coding standard shows significant\nBjontegaard Delta rate savings of 1.72% with a peak of 3.97% based on PSNR and\n1.56% with a peak of 3.40% based on WS-PSNR compared to the VTM-14.2 baseline\non average.",
    "descriptor": "\nComments: 13 pages, 9 figures, 5 tables; This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Andy Regensky",
      "Christian Herglotz",
      "Andr\u00e9 Kaup"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.03323"
  },
  {
    "id": "arXiv:2202.03326",
    "title": "Optimal Ratio for Data Splitting",
    "abstract": "It is common to split a dataset into training and testing sets before fitting\na statistical or machine learning model. However, there is no clear guidance on\nhow much data should be used for training and testing. In this article we show\nthat the optimal splitting ratio is $\\sqrt{p}:1$, where $p$ is the number of\nparameters in a linear regression model that explains the data well.",
    "descriptor": "",
    "authors": [
      "V. Roshan Joseph"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.03326"
  },
  {
    "id": "arXiv:2202.03338",
    "title": "Robust Semantic Communications Against Semantic Noise",
    "abstract": "Although the semantic communications have exhibited satisfactory performance\nin a large number of tasks, the impact of semantic noise and the robustness of\nthe systems have not been well investigated. Semantic noise is a particular\nkind of noise in semantic communication systems, which refers to the misleading\nbetween the intended semantic symbols and received ones. In this paper, we\nfirst propose a framework for the robust end-to-end semantic communication\nsystems to combat the semantic noise. Particularly, we analyze the causes of\nsemantic noise and propose a practical method to generate it. To remove the\neffect of semantic noise, adversarial training is proposed to incorporate the\nsamples with semantic noise in the training dataset. Then, the masked\nautoencoder is designed as the architecture of a robust semantic communication\nsystem, where a portion of the input is masked. To further improve the\nrobustness of semantic communication systems, we design a discrete codebook\nshared by the transmitter and the receiver for encoded feature representation.\nThus, the transmitter simply needs to transmit the indices of these features in\nthe codebook. Simulation results show that our proposed method significantly\nimproves the robustness of semantic communication systems against semantic\nnoise with significant reduction on the transmission overhead.",
    "descriptor": "\nComments: 7 pages, 6 figures\n",
    "authors": [
      "Qiyu Hu",
      "Guangyi Zhang",
      "Zhijin Qin",
      "Yunlong Cai",
      "Guanding Yu"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.03338"
  },
  {
    "id": "arXiv:2202.03342",
    "title": "A Review of Landcover Classification with Very-High Resolution Remotely  Sensed Optical Images-Analysis Unit,Model Scalability and Transferability",
    "abstract": "As an important application in remote sensing, landcover classification\nremains one of the most challenging tasks in very-high-resolution (VHR) image\nanalysis. As the rapidly increasing number of Deep Learning (DL) based\nlandcover methods and training strategies are claimed to be the\nstate-of-the-art, the already fragmented technical landscape of landcover\nmapping methods has been further complicated. Although there exists a plethora\nof literature review work attempting to guide researchers in making an informed\nchoice of landcover mapping methods, the articles either focus on the review of\napplications in a specific area or revolve around general deep learning models,\nwhich lack a systematic view of the ever advancing landcover mapping methods.\nIn addition, issues related to training samples and model transferability have\nbecome more critical than ever in an era dominated by data-driven approaches,\nbut these issues were addressed to a lesser extent in previous review articles\nregarding remote sensing classification. Therefore, in this paper, we present a\nsystematic overview of existing methods by starting from learning methods and\nvarying basic analysis units for landcover mapping tasks, to challenges and\nsolutions on three aspects of scalability and transferability with a remote\nsensing classification focus including (1) sparsity and imbalance of data; (2)\ndomain gaps across different geographical regions; and (3) multi-source and\nmulti-view fusion. We discuss in detail each of these categorical methods and\ndraw concluding remarks in these developments and recommend potential\ndirections for the continued endeavor.",
    "descriptor": "\nComments: 29 pages\n",
    "authors": [
      "Rongjun Qin",
      "Tao Liu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.03342"
  },
  {
    "id": "arXiv:2202.03346",
    "title": "Variance reduced stochastic optimization over directed graphs with row  and column stochastic weights",
    "abstract": "This paper proposes AB-SAGA, a first-order distributed stochastic\noptimization method to minimize a finite-sum of smooth and strongly convex\nfunctions distributed over an arbitrary directed graph. AB-SAGA removes the\nuncertainty caused by the stochastic gradients using a node-level variance\nreduction and subsequently employs network-level gradient tracking to address\nthe data dissimilarity across the nodes. Unlike existing methods that use the\nnonlinear push-sum correction to cancel the imbalance caused by the directed\ncommunication, the consensus updates in AB-SAGA are linear and uses both row\nand column stochastic weights. We show that for a constant step-size, AB-SAGA\nconverges linearly to the global optimal. We quantify the directed nature of\nthe underlying graph using an explicit directivity constant and characterize\nthe regimes in which AB-SAGA achieves a linear speed-up over its centralized\ncounterpart. Numerical experiments illustrate the convergence of AB-SAGA for\nstrongly convex and nonconvex problems.",
    "descriptor": "",
    "authors": [
      "Muhammad I. Qureshi",
      "Ran Xin",
      "Soummya Kar",
      "Usman A. Khan"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Multiagent Systems (cs.MA)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.03346"
  },
  {
    "id": "arXiv:2202.03373",
    "title": "LEDNet: Joint Low-light Enhancement and Deblurring in the Dark",
    "abstract": "Night photography typically suffers from both low light and blurring issues\ndue to the dim environment and the common use of long exposure. While existing\nlight enhancement and deblurring methods could deal with each problem\nindividually, a cascade of such methods cannot work harmoniously to cope well\nwith joint degradation of visibility and textures. Training an end-to-end\nnetwork is also infeasible as no paired data is available to characterize the\ncoexistence of low light and blurs. We address the problem by introducing a\nnovel data synthesis pipeline that models realistic low-light blurring\ndegradations. With the pipeline, we present the first large-scale dataset for\njoint low-light enhancement and deblurring. The dataset, LOL-Blur, contains\n12,000 low-blur/normal-sharp pairs with diverse darkness and motion blurs in\ndifferent scenarios. We further present an effective network, named LEDNet, to\nperform joint low-light enhancement and deblurring. Our network is unique as it\nis specially designed to consider the synergy between the two inter-connected\ntasks. Both the proposed dataset and network provide a foundation for this\nchallenging joint task. Extensive experiments demonstrate the effectiveness of\nour method on both synthetic and real-world datasets.",
    "descriptor": "\nComments: 19 pages, 23 figures\n",
    "authors": [
      "Shangchen Zhou",
      "Chongyi Li",
      "Chen Change Loy"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.03373"
  },
  {
    "id": "arXiv:2202.03397",
    "title": "Bilevel Optimization with a Lower-level Contraction: Optimal Sample  Complexity without Warm-Start",
    "abstract": "We analyze a general class of bilevel problems, in which the upper-level\nproblem consists in the minimization of a smooth objective function and the\nlower-level problem is to find the fixed point of a smooth contraction map.\nThis type of problems include instances of meta-learning, hyperparameter\noptimization and data poisoning adversarial attacks. Several recent works have\nproposed algorithms which warm-start the lower-level problem, i.e. they use the\nprevious lower-level approximate solution as a staring point for the\nlower-level solver. This warm-start procedure allows one to improve the sample\ncomplexity in both the stochastic and deterministic settings, achieving in some\ncases the order-wise optimal sample complexity. We show that without\nwarm-start, it is still possible to achieve order-wise optimal and near-optimal\nsample complexity for the stochastic and deterministic settings, respectively.\nIn particular, we propose a simple method which uses stochastic fixed point\niterations at the lower-level and projected inexact gradient descent at the\nupper-level, that reaches an $\\epsilon$-stationary point using\n$O(\\epsilon^{-2})$ and $\\tilde{O}(\\epsilon^{-1})$ samples for the stochastic\nand the deterministic setting, respectively. Compared to methods using\nwarm-start, ours is better suited for meta-learning and yields a simpler\nanalysis that does not need to study the coupled interactions between the\nupper-level and lower-level iterates.",
    "descriptor": "\nComments: 30 pages\n",
    "authors": [
      "Riccardo Grazzi",
      "Massimiliano Pontil",
      "Saverio Salzo"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2202.03397"
  },
  {
    "id": "arXiv:2202.03406",
    "title": "Dependence model assessment and selection with DecoupleNets",
    "abstract": "Neural networks are suggested for learning a map from $d$-dimensional samples\nwith any underlying dependence structure to multivariate uniformity in $d'$\ndimensions. This map, termed DecoupleNet, is used for dependence model\nassessment and selection. If the data-generating dependence model was known,\nand if it was among the few analytically tractable ones, one such\ntransformation for $d'=d$ is Rosenblatt's transform. DecoupleNets only require\nan available sample and are applicable to $d'<d$, in particular $d'=2$. This\nallows for simpler model assessment and selection without loss of information,\nboth numerically and, because $d'=2$, graphically. Through simulation studies\nbased on data from various copulas, the feasibility and validity of this novel\napproach is demonstrated. Applications to real world data illustrate its\nusefulness for model assessment and selection.",
    "descriptor": "",
    "authors": [
      "Marius Hofert",
      "Avinash Prasad",
      "Mu Zhu"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Computational Finance (q-fin.CP)",
      "Risk Management (q-fin.RM)",
      "Applications (stat.AP)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2202.03406"
  },
  {
    "id": "arXiv:2202.03407",
    "title": "Investigating the fidelity of explainable artificial intelligence  methods for applications of convolutional neural networks in geoscience",
    "abstract": "Convolutional neural networks (CNNs) have recently attracted great attention\nin geoscience due to their ability to capture non-linear system behavior and\nextract predictive spatiotemporal patterns. Given their black-box nature\nhowever, and the importance of prediction explainability, methods of\nexplainable artificial intelligence (XAI) are gaining popularity as a means to\nexplain the CNN decision-making strategy. Here, we establish an intercomparison\nof some of the most popular XAI methods and investigate their fidelity in\nexplaining CNN decisions for geoscientific applications. Our goal is to raise\nawareness of the theoretical limitations of these methods and gain insight into\nthe relative strengths and weaknesses to help guide best practices. The\nconsidered XAI methods are first applied to an idealized attribution benchmark,\nwhere the ground truth of explanation of the network is known a priori, to help\nobjectively assess their performance. Secondly, we apply XAI to a\nclimate-related prediction setting, namely to explain a CNN that is trained to\npredict the number of atmospheric rivers in daily snapshots of climate\nsimulations. Our results highlight several important issues of XAI methods\n(e.g., gradient shattering, inability to distinguish the sign of attribution,\nignorance to zero input) that have previously been overlooked in our field and,\nif not considered cautiously, may lead to a distorted picture of the CNN\ndecision-making strategy. We envision that our analysis will motivate further\ninvestigation into XAI fidelity and will help towards a cautious implementation\nof XAI in geoscience, which can lead to further exploitation of CNNs and deep\nlearning for prediction problems.",
    "descriptor": "",
    "authors": [
      "Antonios Mamalakis",
      "Elizabeth A. Barnes",
      "Imme Ebert-Uphoff"
    ],
    "subjectives": [
      "Geophysics (physics.geo-ph)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.03407"
  },
  {
    "id": "arXiv:1706.06191",
    "title": "An adaptive rectangular mesh administration and refinement technique  with application in cancer invasion models",
    "abstract": "Comments: 31 pages, 8 figures",
    "descriptor": "\nComments: 31 pages, 8 figures\n",
    "authors": [
      "Niklas Kolbe",
      "Nikolaos Sfakianakis"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/1706.06191"
  },
  {
    "id": "arXiv:1708.01525",
    "title": "Language Design as Information Renormalization",
    "abstract": "Comments: 25 pages, 21 figures, 1 table, Final Version",
    "descriptor": "\nComments: 25 pages, 21 figures, 1 table, Final Version\n",
    "authors": [
      "Angel J. Gallego",
      "Roman Orus"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Strongly Correlated Electrons (cond-mat.str-el)",
      "History and Philosophy of Physics (physics.hist-ph)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/1708.01525"
  },
  {
    "id": "arXiv:1805.08342",
    "title": "Nearest neighbor density functional estimation from inverse Laplace  transform",
    "abstract": "Comments: 43 pages, 4 figures. IEEE Transactions on Information Theory (to appear)",
    "descriptor": "\nComments: 43 pages, 4 figures. IEEE Transactions on Information Theory (to appear)\n",
    "authors": [
      "J. Jon Ryu",
      "Shouvik Ganguly",
      "Young-Han Kim",
      "Yung-Kyun Noh",
      "Daniel D. Lee"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Information Theory (cs.IT)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1805.08342"
  },
  {
    "id": "arXiv:1807.08088",
    "title": "Learning Optimal Resource Allocations in Wireless Systems",
    "abstract": "Learning Optimal Resource Allocations in Wireless Systems",
    "descriptor": "",
    "authors": [
      "Mark Eisen",
      "Clark Zhang",
      "Luiz F. O. Chamon",
      "Daniel D. Lee",
      "Alejandro Ribeiro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1807.08088"
  },
  {
    "id": "arXiv:1810.08243",
    "title": "Fair Cake-Cutting in Practice",
    "abstract": "Fair Cake-Cutting in Practice",
    "descriptor": "",
    "authors": [
      "Maria Kyropoulou",
      "Josu\u00e9 Ortega",
      "Erel Segal-Halevi"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Theoretical Economics (econ.TH)"
    ],
    "url": "https://arxiv.org/abs/1810.08243"
  },
  {
    "id": "arXiv:1903.11394",
    "title": "Motion Deblurring with an Adaptive Network",
    "abstract": "Motion Deblurring with an Adaptive Network",
    "descriptor": "",
    "authors": [
      "Kuldeep Purohit",
      "A. N. Rajagopalan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/1903.11394"
  },
  {
    "id": "arXiv:1904.03710",
    "title": "Planar Geometry and Image Recovery from Motion-Blur",
    "abstract": "Planar Geometry and Image Recovery from Motion-Blur",
    "descriptor": "",
    "authors": [
      "Kuldeep Purohit",
      "Subeesh Vasu",
      "M. Purnachandra Rao",
      "A. N. Rajagopalan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/1904.03710"
  },
  {
    "id": "arXiv:1905.01713",
    "title": "Free Component Analysis: Theory, Algorithms & Applications",
    "abstract": "Comments: 72 pages, 16 figures",
    "descriptor": "\nComments: 72 pages, 16 figures\n",
    "authors": [
      "Hao Wu",
      "Raj Rao Nadakuditi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1905.01713"
  },
  {
    "id": "arXiv:1906.02869",
    "title": "One-Shot Neural Architecture Search via Compressive Sensing",
    "abstract": "Comments: 2nd Workshop on Neural Architecture Search at ICLR 2021",
    "descriptor": "\nComments: 2nd Workshop on Neural Architecture Search at ICLR 2021\n",
    "authors": [
      "Minsu Cho",
      "Mohammadreza Soltani",
      "Chinmay Hegde"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1906.02869"
  },
  {
    "id": "arXiv:1909.11193",
    "title": "Scaling-Translation-Equivariant Networks with Decomposed Convolutional  Filters",
    "abstract": "Scaling-Translation-Equivariant Networks with Decomposed Convolutional  Filters",
    "descriptor": "",
    "authors": [
      "Wei Zhu",
      "Qiang Qiu",
      "Robert Calderbank",
      "Guillermo Sapiro",
      "Xiuyuan Cheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1909.11193"
  },
  {
    "id": "arXiv:1909.11573",
    "title": "Deep Learning for Deepfakes Creation and Detection: A Survey",
    "abstract": "Deep Learning for Deepfakes Creation and Detection: A Survey",
    "descriptor": "",
    "authors": [
      "Thanh Thi Nguyen",
      "Quoc Viet Hung Nguyen",
      "Dung Tien Nguyen",
      "Duc Thanh Nguyen",
      "Thien Huynh-The",
      "Saeid Nahavandi",
      "Thanh Tam Nguyen",
      "Quoc-Viet Pham",
      "Cuong M. Nguyen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/1909.11573"
  },
  {
    "id": "arXiv:1911.03071",
    "title": "Balancing covariates in randomized experiments with the Gram-Schmidt  Walk design",
    "abstract": "Balancing covariates in randomized experiments with the Gram-Schmidt  Walk design",
    "descriptor": "",
    "authors": [
      "Christopher Harshaw",
      "Fredrik S\u00e4vje",
      "Daniel Spielman",
      "Peng Zhang"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Data Structures and Algorithms (cs.DS)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/1911.03071"
  },
  {
    "id": "arXiv:1912.07213",
    "title": "FISR: Deep Joint Frame Interpolation and Super-Resolution with a  Multi-scale Temporal Loss",
    "abstract": "Comments: The first two authors contributed equally to this work. Accepted to AAAI 2020 (camera-ready version)",
    "descriptor": "\nComments: The first two authors contributed equally to this work. Accepted to AAAI 2020 (camera-ready version)\n",
    "authors": [
      "Soo Ye Kim",
      "Jihyong Oh",
      "Munchurl Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/1912.07213"
  },
  {
    "id": "arXiv:1912.12257",
    "title": "Performance Analysis of TLS for Quantum Robust Cryptography on a  Constrained Device",
    "abstract": "Performance Analysis of TLS for Quantum Robust Cryptography on a  Constrained Device",
    "descriptor": "",
    "authors": [
      "Jon Barton",
      "William J Buchanan",
      "Nikolaos Pitropakis",
      "Sarwar Sayeed",
      "Will Abramson"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/1912.12257"
  },
  {
    "id": "arXiv:2001.03707",
    "title": "Superconvergence of Online Optimization for Model Predictive Control",
    "abstract": "Comments: 21 pages",
    "descriptor": "\nComments: 21 pages\n",
    "authors": [
      "Sen Na",
      "Mihai Anitescu"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)",
      "Dynamical Systems (math.DS)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2001.03707"
  },
  {
    "id": "arXiv:2003.00909",
    "title": "Holes and islands in random point sets",
    "abstract": "Holes and islands in random point sets",
    "descriptor": "",
    "authors": [
      "Martin Balko",
      "Manfred Scheucher",
      "Pavel Valtr"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Computational Geometry (cs.CG)",
      "Discrete Mathematics (cs.DM)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2003.00909"
  },
  {
    "id": "arXiv:2003.10057",
    "title": "A Toroidal Maxwell-Cremona-Delaunay Correspondence",
    "abstract": "Comments: 25 pages, 6 figures. The correct title uses en-dashes (which arXiv does not support) instead of hyphens. Accepted to the Journal of Computational Geometry. Preliminary version appeared at SoCG 2020",
    "descriptor": "\nComments: 25 pages, 6 figures. The correct title uses en-dashes (which arXiv does not support) instead of hyphens. Accepted to the Journal of Computational Geometry. Preliminary version appeared at SoCG 2020\n",
    "authors": [
      "Jeff Erickson",
      "Patrick Lin"
    ],
    "subjectives": [
      "Metric Geometry (math.MG)",
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2003.10057"
  },
  {
    "id": "arXiv:2003.13199",
    "title": "A note on Onicescu's informational energy and correlation coefficient in  exponential families",
    "abstract": "Comments: 13 pages, 2 tables",
    "descriptor": "\nComments: 13 pages, 2 tables\n",
    "authors": [
      "Frank Nielsen"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2003.13199"
  },
  {
    "id": "arXiv:2005.07574",
    "title": "CryptoMaze: Privacy-Preserving Splitting of Off-Chain Payments",
    "abstract": "Comments: 17 pages, Accepted in IEEE Transactions on Dependable and Secure Computing",
    "descriptor": "\nComments: 17 pages, Accepted in IEEE Transactions on Dependable and Secure Computing\n",
    "authors": [
      "Subhra Mazumdar",
      "Sushmita Ruj"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2005.07574"
  },
  {
    "id": "arXiv:2005.12582",
    "title": "Differentials and distances in probabilistic coherence spaces (extended  version)",
    "abstract": "Comments: extended version of arXiv:1902.04836 Improved redaction of the proof of the main result of Section 2 (expectation of computation time)",
    "descriptor": "\nComments: extended version of arXiv:1902.04836 Improved redaction of the proof of the main result of Section 2 (expectation of computation time)\n",
    "authors": [
      "Thomas Ehrhard"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2005.12582"
  },
  {
    "id": "arXiv:2006.08539",
    "title": "Deep Layer-wise Networks Have Closed-Form Weights",
    "abstract": "Comments: This version will be published in AIStats 2022",
    "descriptor": "\nComments: This version will be published in AIStats 2022\n",
    "authors": [
      "Chieh Wu",
      "Aria Masoomi",
      "Arthur Gretton",
      "Jennifer Dy"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2006.08539"
  },
  {
    "id": "arXiv:2006.15160",
    "title": "Dissecting power of intersection of two context free languages",
    "abstract": "Dissecting power of intersection of two context free languages",
    "descriptor": "",
    "authors": [
      "Josef Rukavicka"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2006.15160"
  },
  {
    "id": "arXiv:2007.01623",
    "title": "Hedging using reinforcement learning: Contextual $k$-Armed Bandit versus  $Q$-learning",
    "abstract": "Comments: 30 pages, 11 figures",
    "descriptor": "\nComments: 30 pages, 11 figures\n",
    "authors": [
      "Loris Cannelli",
      "Giuseppe Nuti",
      "Marzio Sala",
      "Oleg Szehr"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Finance (q-fin.CP)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2007.01623"
  },
  {
    "id": "arXiv:2007.10853",
    "title": "A stabilized GMRES method for singular and severely ill-conditioned  systems of linear equations",
    "abstract": "Comments: 27 pages, 13 figures, 8 tables, Fig. 9 added, Modified comment after theorem 7, other minor changes",
    "descriptor": "\nComments: 27 pages, 13 figures, 8 tables, Fig. 9 added, Modified comment after theorem 7, other minor changes\n",
    "authors": [
      "Zeyu Liao",
      "Ken Hayami",
      "Keiichi Morikuni",
      "Jun-Feng Yin"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2007.10853"
  },
  {
    "id": "arXiv:2007.11462",
    "title": "FedOCR: Communication-Efficient Federated Learning for Scene Text  Recognition",
    "abstract": "FedOCR: Communication-Efficient Federated Learning for Scene Text  Recognition",
    "descriptor": "",
    "authors": [
      "Wenqing Zhang",
      "Yang Qiu",
      "Song Bai",
      "Rui Zhang",
      "Xiaolin Wei",
      "Xiang Bai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2007.11462"
  },
  {
    "id": "arXiv:2007.14900",
    "title": "Bayesian Context Trees: Modelling and exact inference for discrete time  series",
    "abstract": "Comments: 53 pages, 22 figures, small stylistic changes. The associated R package \"BCT\" is available at CRAN.R-project.org/package=BCT",
    "descriptor": "\nComments: 53 pages, 22 figures, small stylistic changes. The associated R package \"BCT\" is available at CRAN.R-project.org/package=BCT\n",
    "authors": [
      "Ioannis Kontoyiannis",
      "Lambros Mertzanis",
      "Athina Panotopoulou",
      "Ioannis Papageorgiou",
      "Maria Skoularidou"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Information Theory (cs.IT)",
      "Applications (stat.AP)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2007.14900"
  },
  {
    "id": "arXiv:2007.15224",
    "title": "Conditions for Convergence of Dynamic Regressor Extension and Mixing  Parameter Estimator Using LTI Filters",
    "abstract": "Conditions for Convergence of Dynamic Regressor Extension and Mixing  Parameter Estimator Using LTI Filters",
    "descriptor": "",
    "authors": [
      "Bowen Yi",
      "Romeo Ortega"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2007.15224"
  },
  {
    "id": "arXiv:2008.05214",
    "title": "REMAX: Relational Representation for Multi-Agent Exploration",
    "abstract": "Comments: Accepted as a full paper at the Twenty-First International Conference on Autonomous Agents and Multiagent Systems (AAMAS-22), Virtual Conference",
    "descriptor": "\nComments: Accepted as a full paper at the Twenty-First International Conference on Autonomous Agents and Multiagent Systems (AAMAS-22), Virtual Conference\n",
    "authors": [
      "Heechang Ryu",
      "Hayong Shin",
      "Jinkyoo Park"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2008.05214"
  },
  {
    "id": "arXiv:2008.07343",
    "title": "Artificial Intelligence in the Battle against Coronavirus (COVID-19): A  Survey and Future Research Directions",
    "abstract": "Artificial Intelligence in the Battle against Coronavirus (COVID-19): A  Survey and Future Research Directions",
    "descriptor": "",
    "authors": [
      "Thanh Thi Nguyen",
      "Quoc Viet Hung Nguyen",
      "Dung Tien Nguyen",
      "Samuel Yang",
      "Peter W. Eklund",
      "Thien Huynh-The",
      "Thanh Tam Nguyen",
      "Quoc-Viet Pham",
      "Edbert B. Hsu"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2008.07343"
  },
  {
    "id": "arXiv:2008.07682",
    "title": "Residual Learning from Demonstration: Adapting DMPs for Contact-rich  Manipulation",
    "abstract": "Residual Learning from Demonstration: Adapting DMPs for Contact-rich  Manipulation",
    "descriptor": "",
    "authors": [
      "Todor Davchev",
      "Kevin Sebastian Luck",
      "Michael Burke",
      "Franziska Meier",
      "Stefan Schaal",
      "Subramanian Ramamoorthy"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2008.07682"
  },
  {
    "id": "arXiv:2008.09610",
    "title": "Implementing backjumping by throw/1 and catch/3 of Prolog",
    "abstract": "Comments: 10 pages. This version - extensions and corrections",
    "descriptor": "\nComments: 10 pages. This version - extensions and corrections\n",
    "authors": [
      "W\u0142odzimierz Drabent"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2008.09610"
  },
  {
    "id": "arXiv:2008.12052",
    "title": "Compensation Tracker: Reprocessing Lost Object for Multi-Object Tracking",
    "abstract": "Compensation Tracker: Reprocessing Lost Object for Multi-Object Tracking",
    "descriptor": "",
    "authors": [
      "Zhibo Zou",
      "Junjie Huang",
      "Ping Luo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2008.12052"
  },
  {
    "id": "arXiv:2009.00606",
    "title": "Semi-Supervised Empirical Risk Minimization: Using unlabeled data to  improve prediction",
    "abstract": "Comments: 39 pages, 4 figures",
    "descriptor": "\nComments: 39 pages, 4 figures\n",
    "authors": [
      "Oren Yuval",
      "Saharon Rosset"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2009.00606"
  },
  {
    "id": "arXiv:2009.03304",
    "title": "Conquery: an open source application to analyze high content healthcare  data",
    "abstract": "Comments: 7 pages, 5 figures, 3 supplementary codes",
    "descriptor": "\nComments: 7 pages, 5 figures, 3 supplementary codes\n",
    "authors": [
      "Fabian Kovacs",
      "Max Thonagel",
      "Marion Ludwig",
      "Alexander Albrecht",
      "Manuel Hegner",
      "Dirk Enders",
      "Lennart Hickstein",
      "Maximilian von Knobloch",
      "Anne Rothhardt",
      "Jochen Walker"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2009.03304"
  },
  {
    "id": "arXiv:2009.09612",
    "title": "Improving Ensemble Robustness by Collaboratively Promoting and Demoting  Adversarial Robustness",
    "abstract": "Improving Ensemble Robustness by Collaboratively Promoting and Demoting  Adversarial Robustness",
    "descriptor": "",
    "authors": [
      "Anh Bui",
      "Trung Le",
      "He Zhao",
      "Paul Montague",
      "Olivier deVel",
      "Tamas Abraham",
      "Dinh Phung"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2009.09612"
  },
  {
    "id": "arXiv:2009.10868",
    "title": "A Real-Time Predictive Pedestrian Collision Warning Service for  Cooperative Intelligent Transportation Systems Using 3D Pose Estimation",
    "abstract": "Comments: 12 pages, 6 figures, 4 tables",
    "descriptor": "\nComments: 12 pages, 6 figures, 4 tables\n",
    "authors": [
      "Ue-Hwan Kim",
      "Dongho Ka",
      "Hwasoo Yeo",
      "Jong-Hwan Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2009.10868"
  },
  {
    "id": "arXiv:2010.01288",
    "title": "UNISON: Unpaired Cross-lingual Image Captioning",
    "abstract": "Comments: Accepted by AAAI-2022",
    "descriptor": "\nComments: Accepted by AAAI-2022\n",
    "authors": [
      "Jiahui Gao",
      "Yi Zhou",
      "Philip L. H. Yu",
      "Shafiq Joty",
      "Jiuxiang Gu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2010.01288"
  },
  {
    "id": "arXiv:2010.06163",
    "title": "Bridging 2D and 3D Segmentation Networks for Computation Efficient  Volumetric Medical Image Segmentation: An Empirical Study of 2.5D Solutions",
    "abstract": "Comments: Computerized Medical Imaging and Graphics",
    "descriptor": "\nComments: Computerized Medical Imaging and Graphics\n",
    "authors": [
      "Yichi Zhang",
      "Qingcheng Liao",
      "Le Ding",
      "Jicong Zhang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2010.06163"
  },
  {
    "id": "arXiv:2011.14229",
    "title": "Deep Learning for Regularization Prediction in Diffeomorphic Image  Registration",
    "abstract": "Comments: 20 pages, 8 figures",
    "descriptor": "\nComments: 20 pages, 8 figures\n",
    "authors": [
      "Jian Wang",
      "Miaomiao Zhang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2011.14229"
  },
  {
    "id": "arXiv:2012.07244",
    "title": "Bayesian Neural Ordinary Differential Equations",
    "abstract": "Comments: 16 pages, 10 figures, 3 tables; added new inference methods, substantially improved MNIST accuracy, revised author affiliations",
    "descriptor": "\nComments: 16 pages, 10 figures, 3 tables; added new inference methods, substantially improved MNIST accuracy, revised author affiliations\n",
    "authors": [
      "Raj Dandekar",
      "Karen Chung",
      "Vaibhav Dixit",
      "Mohamed Tarek",
      "Aslan Garcia-Valadez",
      "Krishna Vishal Vemula",
      "Chris Rackauckas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2012.07244"
  },
  {
    "id": "arXiv:2012.09918",
    "title": "Sorting in Memristive Memory",
    "abstract": "Sorting in Memristive Memory",
    "descriptor": "",
    "authors": [
      "Mohsen Riahi Alam",
      "M. Hassan Najafi",
      "Nima TaheriNejad"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2012.09918"
  },
  {
    "id": "arXiv:2012.15675",
    "title": "Minor Sparsifiers and the Distributed Laplacian Paradigm",
    "abstract": "Comments: Accepted to FOCS 2021. Abstract shortened to respect arXiv's character limit",
    "descriptor": "\nComments: Accepted to FOCS 2021. Abstract shortened to respect arXiv's character limit\n",
    "authors": [
      "Sebastian Forster",
      "Gramoz Goranci",
      "Yang P. Liu",
      "Richard Peng",
      "Xiaorui Sun",
      "Mingquan Ye"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2012.15675"
  },
  {
    "id": "arXiv:2012.15834",
    "title": "Topological obstructions in neural networks learning",
    "abstract": "Topological obstructions in neural networks learning",
    "descriptor": "",
    "authors": [
      "Serguei Barannikov",
      "Daria Voronkova",
      "Ilya Trofimov",
      "Alexander Korotin",
      "Grigorii Sotnikov",
      "Evgeny Burnaev"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2012.15834"
  },
  {
    "id": "arXiv:2101.00078",
    "title": "Controlled Analyses of Social Biases in Wikipedia Bios",
    "abstract": "Comments: Accepted to the Web Conference 2022 (WWW '22)",
    "descriptor": "\nComments: Accepted to the Web Conference 2022 (WWW '22)\n",
    "authors": [
      "Anjalie Field",
      "Chan Young Park",
      "Kevin Z. Lin",
      "Yulia Tsvetkov"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2101.00078"
  },
  {
    "id": "arXiv:2101.01151",
    "title": "A polynomial-time construction of a hitting set for read-once branching  programs of width 3",
    "abstract": "Comments: 48 pages, 10 figures",
    "descriptor": "\nComments: 48 pages, 10 figures\n",
    "authors": [
      "Ji\u0159\u00ed \u0160\u00edma",
      "Stanislav \u017d\u00e1k"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2101.01151"
  },
  {
    "id": "arXiv:2101.05141",
    "title": "Approximation of the spectral fractional powers of the Laplace-Beltrami  Operator",
    "abstract": "Comments: 21 pages, 5 figures",
    "descriptor": "\nComments: 21 pages, 5 figures\n",
    "authors": [
      "Andrea Bonito",
      "Wenyu Lei"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2101.05141"
  },
  {
    "id": "arXiv:2101.05317",
    "title": "Learning and Fast Adaptation for Grid Emergency Control via Deep Meta  Reinforcement Learning",
    "abstract": "Learning and Fast Adaptation for Grid Emergency Control via Deep Meta  Reinforcement Learning",
    "descriptor": "",
    "authors": [
      "Renke Huang",
      "Yujiao Chen",
      "Tianzhixi Yin",
      "Qiuhua Huang",
      "Jie Tan",
      "Wenhao Yu",
      "Xinya Li",
      "Ang Li",
      "Yan Du"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2101.05317"
  },
  {
    "id": "arXiv:2101.06319",
    "title": "Old but Gold: Reconsidering the value of feedforward learners for  software analytics",
    "abstract": "Comments: v2",
    "descriptor": "\nComments: v2\n",
    "authors": [
      "Rahul Yedida",
      "Xueqi Yang",
      "Tim Menzies"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2101.06319"
  },
  {
    "id": "arXiv:2101.09193",
    "title": "Dense outlier detection and open-set recognition based on training with  noisy negative images",
    "abstract": "Dense outlier detection and open-set recognition based on training with  noisy negative images",
    "descriptor": "",
    "authors": [
      "Petra Bevandi\u0107",
      "Ivan Kre\u0161o",
      "Marin Or\u0161i\u0107",
      "Sini\u0161a \u0160egvi\u0107"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2101.09193"
  },
  {
    "id": "arXiv:2101.11490",
    "title": "Non-Asymptotic Converse Bounds Via Auxiliary Channels",
    "abstract": "Comments: Extended version of a manuscript submitted to IEEE ISIT 2022",
    "descriptor": "\nComments: Extended version of a manuscript submitted to IEEE ISIT 2022\n",
    "authors": [
      "Ioannis Papoutsidakis",
      "Robert J. Piechocki",
      "Angela Doufexi"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2101.11490"
  },
  {
    "id": "arXiv:2102.02515",
    "title": "HYDRA: Hypergradient Data Relevance Analysis for Interpreting Deep  Neural Networks",
    "abstract": "HYDRA: Hypergradient Data Relevance Analysis for Interpreting Deep  Neural Networks",
    "descriptor": "",
    "authors": [
      "Yuanyuan Chen",
      "Boyang Li",
      "Han Yu",
      "Pengcheng Wu",
      "Chunyan Miao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.02515"
  },
  {
    "id": "arXiv:2102.04360",
    "title": "Hierarchical a posteriori error estimation of Bank-Weiser type in the  FEniCS Project",
    "abstract": "Hierarchical a posteriori error estimation of Bank-Weiser type in the  FEniCS Project",
    "descriptor": "",
    "authors": [
      "Rapha\u00ebl Bulle",
      "Jack S. Hale",
      "Alexei Lozinski",
      "St\u00e9phane P. A. Bordas",
      "Franz Chouly"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2102.04360"
  },
  {
    "id": "arXiv:2102.05872",
    "title": "Onoma-to-wave: Environmental sound synthesis from onomatopoeic words",
    "abstract": "Comments: Accepted to APSIPA Transactions on Signal and Information Processing",
    "descriptor": "\nComments: Accepted to APSIPA Transactions on Signal and Information Processing\n",
    "authors": [
      "Yuki Okamoto",
      "Keisuke Imoto",
      "Shinnosuke Takamichi",
      "Ryosuke Yamanishi",
      "Takahiro Fukumori",
      "Yoichi Yamashita"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2102.05872"
  },
  {
    "id": "arXiv:2102.08797",
    "title": "Probabilistic constructions in continuous combinatorics and a bridge to  distributed algorithms",
    "abstract": "Comments: 22 pp",
    "descriptor": "\nComments: 22 pp\n",
    "authors": [
      "Anton Bernshteyn"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Dynamical Systems (math.DS)",
      "Logic (math.LO)"
    ],
    "url": "https://arxiv.org/abs/2102.08797"
  },
  {
    "id": "arXiv:2102.10256",
    "title": "Generalized Group Testing",
    "abstract": "Generalized Group Testing",
    "descriptor": "",
    "authors": [
      "Xiwei Cheng",
      "Sidharth Jaggi",
      "Qiaoqiao Zhou"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2102.10256"
  },
  {
    "id": "arXiv:2102.12416",
    "title": "Accelerating Communication for Parallel Programming Models on GPU  Systems",
    "abstract": "Comments: 12 pages, 17 figures, submitted to Journal of Parallel Computing",
    "descriptor": "\nComments: 12 pages, 17 figures, submitted to Journal of Parallel Computing\n",
    "authors": [
      "Jaemin Choi",
      "Zane Fink",
      "Sam White",
      "Nitin Bhat",
      "David F. Richards",
      "Laxmikant V. Kale"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2102.12416"
  },
  {
    "id": "arXiv:2103.00778",
    "title": "Explaining Adversarial Vulnerability with a Data Sparsity Hypothesis",
    "abstract": "Explaining Adversarial Vulnerability with a Data Sparsity Hypothesis",
    "descriptor": "",
    "authors": [
      "Mahsa Paknezhad",
      "Cuong Phuc Ngo",
      "Amadeus Aristo Winarto",
      "Alistair Cheong",
      "Chuen Yang Beh",
      "Jiayang Wu",
      "Hwee Kuan Lee"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2103.00778"
  },
  {
    "id": "arXiv:2103.03905",
    "title": "Kanerva++: extending The Kanerva Machine with differentiable, locally  block allocated latent memory",
    "abstract": "Kanerva++: extending The Kanerva Machine with differentiable, locally  block allocated latent memory",
    "descriptor": "",
    "authors": [
      "Jason Ramapuram",
      "Yan Wu",
      "Alexandros Kalousis"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2103.03905"
  },
  {
    "id": "arXiv:2103.03958",
    "title": "Simultaneous Scene Reconstruction and Whole-Body Motion Planning for  Safe Operation in Dynamic Environments",
    "abstract": "Comments: 8 pages, 4 figures, 2 tables, presented at 2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS). Copyright 2021 IEEE, this https URL",
    "descriptor": "\nComments: 8 pages, 4 figures, 2 tables, presented at 2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS). Copyright 2021 IEEE, this https URL\n",
    "authors": [
      "Mark Nicholas Finean",
      "Wolfgang Merkt",
      "Ioannis Havoutis"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2103.03958"
  },
  {
    "id": "arXiv:2103.10872",
    "title": "Optimal Clearing Payments in a Financial Contagion Model",
    "abstract": "Optimal Clearing Payments in a Financial Contagion Model",
    "descriptor": "",
    "authors": [
      "Giuseppe Calafiore",
      "Giulia Fracastoro",
      "Anton V. Proskurnikov"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Mathematical Finance (q-fin.MF)",
      "Risk Management (q-fin.RM)"
    ],
    "url": "https://arxiv.org/abs/2103.10872"
  },
  {
    "id": "arXiv:2103.11520",
    "title": "Unsupervised and self-adaptative techniques for cross-domain person  re-identification",
    "abstract": "Comments: Published on IEEE Transactions on Information Forensics and Security",
    "descriptor": "\nComments: Published on IEEE Transactions on Information Forensics and Security\n",
    "authors": [
      "Gabriel Bertocco",
      "Fernanda Andal\u00f3",
      "Anderson Rocha"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2103.11520"
  },
  {
    "id": "arXiv:2103.11616",
    "title": "A Survey on Image Aesthetic Assessment",
    "abstract": "A Survey on Image Aesthetic Assessment",
    "descriptor": "",
    "authors": [
      "Abbas Anwar",
      "Saira Kanwal",
      "Muhammad Tahir",
      "Muhammad Saqib",
      "Muhammad Uzair",
      "Mohammad Khalid Imam Rahmani",
      "Habib Ullah"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.11616"
  },
  {
    "id": "arXiv:2104.01847",
    "title": "Reddit's self-organised bull runs: Social contagion and asset prices",
    "abstract": "Comments: This paper was originally put online as a departmental pre-print on the departmental website at this https URL and on MPRA on February 2, 2021",
    "descriptor": "\nComments: This paper was originally put online as a departmental pre-print on the departmental website at this https URL and on MPRA on February 2, 2021\n",
    "authors": [
      "Valentina Semenova",
      "Julian Winkler"
    ],
    "subjectives": [
      "General Economics (econ.GN)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2104.01847"
  },
  {
    "id": "arXiv:2104.02861",
    "title": "Time-Data Tradeoffs in Structured Signals Recovery via the  Proximal-Gradient Homotopy Method",
    "abstract": "Comments: 9 pages, 6 figures",
    "descriptor": "\nComments: 9 pages, 6 figures\n",
    "authors": [
      "Xiao Lv",
      "Wei Cui",
      "Yulong Liu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2104.02861"
  },
  {
    "id": "arXiv:2104.05035",
    "title": "A Hybrid Parallelization Approach for Distributed and Scalable Deep  Learning",
    "abstract": "A Hybrid Parallelization Approach for Distributed and Scalable Deep  Learning",
    "descriptor": "",
    "authors": [
      "Samson B. Akintoye",
      "Liangxiu Han",
      "Xin Zhang",
      "Haoming Chen",
      "Daoqiang Zhang"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2104.05035"
  },
  {
    "id": "arXiv:2104.05877",
    "title": "Simpler is better: A comparative study of randomized algorithms for  computing the CUR decomposition",
    "abstract": "Comments: 33 pages, 13 figures",
    "descriptor": "\nComments: 33 pages, 13 figures\n",
    "authors": [
      "Yijun Dong",
      "Per-Gunnar Martinsson"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2104.05877"
  },
  {
    "id": "arXiv:2104.06876",
    "title": "Landmarking for Navigational Streaming of Stored High-Dimensional Media",
    "abstract": "Comments: 15 pages, 13 figures,accepted by TCSVT. With supplementary files",
    "descriptor": "\nComments: 15 pages, 13 figures,accepted by TCSVT. With supplementary files\n",
    "authors": [
      "Yuan Yuan",
      "Gene Cheung",
      "Pascal Frossard",
      "H.Vicky Zhao",
      "Jiwu Huang"
    ],
    "subjectives": [
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2104.06876"
  },
  {
    "id": "arXiv:2104.08133",
    "title": "Inverse linear problems on Hilbert space and their Krylov solvability",
    "abstract": "Inverse linear problems on Hilbert space and their Krylov solvability",
    "descriptor": "",
    "authors": [
      "Noe Angelo Caruso",
      "Alessandro Michelangeli"
    ],
    "subjectives": [
      "Functional Analysis (math.FA)",
      "Numerical Analysis (math.NA)",
      "Spectral Theory (math.SP)"
    ],
    "url": "https://arxiv.org/abs/2104.08133"
  },
  {
    "id": "arXiv:2104.08588",
    "title": "Sentence Alignment with Parallel Documents Facilitates Biomedical  Machine Translation",
    "abstract": "Comments: 16 pages, 5 figures",
    "descriptor": "\nComments: 16 pages, 5 figures\n",
    "authors": [
      "Shengxuan Luo",
      "Huaiyuan Ying",
      "Jiao Li",
      "Sheng Yu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2104.08588"
  },
  {
    "id": "arXiv:2104.11379",
    "title": "Eigenbackground Revisited: Can We Model the Background with  Eigenvectors?",
    "abstract": "Eigenbackground Revisited: Can We Model the Background with  Eigenvectors?",
    "descriptor": "",
    "authors": [
      "Mahmood Amintoosi",
      "Farzam Farbiz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2104.11379"
  },
  {
    "id": "arXiv:2104.13122",
    "title": "Why Does Propositional Quantification Make Logics on Trees Robustly  Hard?",
    "abstract": "Comments: Submitted to LMCS. Full version of our LICS 2019 paper",
    "descriptor": "\nComments: Submitted to LMCS. Full version of our LICS 2019 paper\n",
    "authors": [
      "Bartosz Bednarczyk",
      "St\u00e9phane Demri"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2104.13122"
  },
  {
    "id": "arXiv:2105.03288",
    "title": "A Hybrid Architecture for Federated and Centralized Learning",
    "abstract": "Comments: This paper introduces the first implementation of hybrid technique involving FL and CL, in which all of the clients can participate to the training regardless of their resources for model computation",
    "descriptor": "\nComments: This paper introduces the first implementation of hybrid technique involving FL and CL, in which all of the clients can participate to the training regardless of their resources for model computation\n",
    "authors": [
      "Ahmet M. Elbir",
      "Sinem Coleri",
      "Anastasios K. Papazafeiropoulos",
      "Pandelis Kourtessis",
      "Symeon Chatzinotas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2105.03288"
  },
  {
    "id": "arXiv:2105.03918",
    "title": "Opening the Blackbox: Accelerating Neural Differential Equations by  Regularizing Internal Solver Heuristics",
    "abstract": "Comments: Proceedings of the 38 th International Conference on Machine Learning, 2021",
    "descriptor": "\nComments: Proceedings of the 38 th International Conference on Machine Learning, 2021\n",
    "authors": [
      "Avik Pal",
      "Yingbo Ma",
      "Viral Shah",
      "Christopher Rackauckas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2105.03918"
  },
  {
    "id": "arXiv:2105.03949",
    "title": "High-performance symbolic-numerics via multiple dispatch",
    "abstract": "High-performance symbolic-numerics via multiple dispatch",
    "descriptor": "",
    "authors": [
      "Shashi Gowda",
      "Yingbo Ma",
      "Alessandro Cheli",
      "Maja Gwozdz",
      "Viral B. Shah",
      "Alan Edelman",
      "Christopher Rackauckas"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Mathematical Software (cs.MS)",
      "Programming Languages (cs.PL)",
      "Symbolic Computation (cs.SC)"
    ],
    "url": "https://arxiv.org/abs/2105.03949"
  },
  {
    "id": "arXiv:2105.06577",
    "title": "Online Algorithms and Policies Using Adaptive and Machine Learning  Approaches",
    "abstract": "Comments: 39 pages",
    "descriptor": "\nComments: 39 pages\n",
    "authors": [
      "Anuradha M. Annaswamy",
      "Anubhav Guha",
      "Yingnan Cui",
      "Sunbochen Tang",
      "Joseph E. Gaudio"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2105.06577"
  },
  {
    "id": "arXiv:2105.07310",
    "title": "Regret Analysis of Distributed Online LQR Control for Unknown LTI  Systems",
    "abstract": "Comments: arXiv admin note: substantial text overlap with arXiv:2009.13749",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2009.13749\n",
    "authors": [
      "Ting-Jui Chang",
      "Shahin Shahrampour"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2105.07310"
  },
  {
    "id": "arXiv:2105.07574",
    "title": "SoundFence: Securing Ultrasonic Sensors in Vehicles Using Physical-Layer  Defense",
    "abstract": "Comments: have some unresolved issues",
    "descriptor": "\nComments: have some unresolved issues\n",
    "authors": [
      "Jianzhi Lou",
      "Qiben Yan",
      "Qing Hui",
      "Huacheng Zeng"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2105.07574"
  },
  {
    "id": "arXiv:2105.07838",
    "title": "Digital Resistance during COVID-19: A Workflow Management System of  Contactless Purchasing and Its Empirical Study of Customer Acceptance",
    "abstract": "Comments: 5 figures",
    "descriptor": "\nComments: 5 figures\n",
    "authors": [
      "Yang Lu"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2105.07838"
  },
  {
    "id": "arXiv:2105.13967",
    "title": "Bridging Data Center AI Systems with Edge Computing for Actionable  Information Retrieval",
    "abstract": "Bridging Data Center AI Systems with Edge Computing for Actionable  Information Retrieval",
    "descriptor": "",
    "authors": [
      "Zhengchun Liu",
      "Ahsan Ali",
      "Peter Kenesei",
      "Antonino Miceli",
      "Hemant Sharma",
      "Nicholas Schwarz",
      "Dennis Trujillo",
      "Hyunseung Yoo",
      "Ryan Coffee",
      "Naoufal Layad",
      "Jana Thayer",
      "Ryan Herbst",
      "ChunHong Yoon",
      "Ian Foster"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.13967"
  },
  {
    "id": "arXiv:2105.15164",
    "title": "DISSECT: Disentangled Simultaneous Explanations via Concept Traversals",
    "abstract": "Comments: Accepted for publication at ICLR 2022",
    "descriptor": "\nComments: Accepted for publication at ICLR 2022\n",
    "authors": [
      "Asma Ghandeharioun",
      "Been Kim",
      "Chun-Liang Li",
      "Brendan Jou",
      "Brian Eoff",
      "Rosalind W. Picard"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.15164"
  },
  {
    "id": "arXiv:2106.01101",
    "title": "Learning a Single Neuron with Bias Using Gradient Descent",
    "abstract": "Comments: An updated version, corresponding to the NeurIPS 2021 camera-ready version",
    "descriptor": "\nComments: An updated version, corresponding to the NeurIPS 2021 camera-ready version\n",
    "authors": [
      "Gal Vardi",
      "Gilad Yehudai",
      "Ohad Shamir"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.01101"
  },
  {
    "id": "arXiv:2106.02261",
    "title": "Out-of-Distribution Generalization in Kernel Regression",
    "abstract": "Comments: Eq. (SI.1.59) corrected",
    "descriptor": "\nComments: Eq. (SI.1.59) corrected\n",
    "authors": [
      "Abdulkadir Canatar",
      "Blake Bordelon",
      "Cengiz Pehlevan"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.02261"
  },
  {
    "id": "arXiv:2106.02713",
    "title": "Learning Curves for SGD on Structured Features",
    "abstract": "Comments: Accepted at ICLR 2022: this https URL",
    "descriptor": "\nComments: Accepted at ICLR 2022: this https URL\n",
    "authors": [
      "Blake Bordelon",
      "Cengiz Pehlevan"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.02713"
  },
  {
    "id": "arXiv:2106.02894",
    "title": "MoleHD: Ultra-Low-Cost Drug Discovery using Hyperdimensional Computing",
    "abstract": "MoleHD: Ultra-Low-Cost Drug Discovery using Hyperdimensional Computing",
    "descriptor": "",
    "authors": [
      "Dongning Ma",
      "Rahul Thapa",
      "Xun Jiao"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2106.02894"
  },
  {
    "id": "arXiv:2106.02951",
    "title": "Controller Synthesis for Omega-Regular and Steady-State Specifications",
    "abstract": "Controller Synthesis for Omega-Regular and Steady-State Specifications",
    "descriptor": "",
    "authors": [
      "Alvaro Velasquez",
      "Ismail Alkhouri",
      "Andre Beckus",
      "Ashutosh Trivedi",
      "George Atia"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.02951"
  },
  {
    "id": "arXiv:2106.04477",
    "title": "MoCo-Flow: Neural Motion Consensus Flow for Dynamic Humans in Stationary  Monocular Cameras",
    "abstract": "MoCo-Flow: Neural Motion Consensus Flow for Dynamic Humans in Stationary  Monocular Cameras",
    "descriptor": "",
    "authors": [
      "Xuelin Chen",
      "Weiyu Li",
      "Daniel Cohen-Or",
      "Niloy J. Mitra",
      "Baoquan Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.04477"
  },
  {
    "id": "arXiv:2106.05027",
    "title": "Scientometric engineering: Exploring citation dynamics via arXiv eprints",
    "abstract": "Comments: [v1] 1+25 pages, 6 figures for main text; 1+24 pages, 14 figures for supplementary information. [v2] Revised version to appear in Quantitative Science Studies; 2+25 pages, 6 figures for main text; 25 pages, 14 figures for supplementary materials",
    "descriptor": "\nComments: [v1] 1+25 pages, 6 figures for main text; 1+24 pages, 14 figures for supplementary information. [v2] Revised version to appear in Quantitative Science Studies; 2+25 pages, 6 figures for main text; 25 pages, 14 figures for supplementary materials\n",
    "authors": [
      "Keisuke Okamura"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2106.05027"
  },
  {
    "id": "arXiv:2106.06046",
    "title": "Information Theoretic Evaluation of Privacy-Leakage, Interpretability,  and Transferability for a Novel Trustworthy AI Framework",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:2105.04615, arXiv:2104.07060",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2105.04615, arXiv:2104.07060\n",
    "authors": [
      "Mohit Kumar",
      "Bernhard A. Moser",
      "Lukas Fischer",
      "Bernhard Freudenthaler"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2106.06046"
  },
  {
    "id": "arXiv:2106.06528",
    "title": "Local Explanation of Dialogue Response Generation",
    "abstract": "Comments: accepted to NeurIPS 2021",
    "descriptor": "\nComments: accepted to NeurIPS 2021\n",
    "authors": [
      "Yi-Lin Tuan",
      "Connor Pryor",
      "Wenhu Chen",
      "Lise Getoor",
      "William Yang Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.06528"
  },
  {
    "id": "arXiv:2106.07080",
    "title": "Semi-verified PAC Learning from the Crowd with Pairwise Comparisons",
    "abstract": "Comments: v2 incorporates a simpler Filter algorithm, thus the technical assumption (in v1) is no longer needed. v2 also reorganizes and emphasizes new algorithm components",
    "descriptor": "\nComments: v2 incorporates a simpler Filter algorithm, thus the technical assumption (in v1) is no longer needed. v2 also reorganizes and emphasizes new algorithm components\n",
    "authors": [
      "Shiwei Zeng",
      "Jie Shen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2106.07080"
  },
  {
    "id": "arXiv:2106.07731",
    "title": "Bivariate Polynomial Codes for Secure Distributed Matrix Multiplication",
    "abstract": "Comments: To appear in IEEE Journal on Selected Areas in Communications. arXiv admin note: text overlap with arXiv:2102.08304",
    "descriptor": "\nComments: To appear in IEEE Journal on Selected Areas in Communications. arXiv admin note: text overlap with arXiv:2102.08304\n",
    "authors": [
      "Burak Hasircioglu",
      "Jesus Gomez-Vilardebo",
      "Deniz Gunduz"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2106.07731"
  },
  {
    "id": "arXiv:2106.08114",
    "title": "Leopard: Towards High Throughput-Preserving BFT for Large-scale Systems",
    "abstract": "Leopard: Towards High Throughput-Preserving BFT for Large-scale Systems",
    "descriptor": "",
    "authors": [
      "Kexin Hu",
      "Kaiwen Guo",
      "Qiang Tang",
      "Zhenfeng Zhang",
      "Hao Cheng",
      "Zhiyang Zhao"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2106.08114"
  },
  {
    "id": "arXiv:2106.08253",
    "title": "A Syntax-Guided Edit Decoder for Neural Program Repair",
    "abstract": "Comments: 10 pages",
    "descriptor": "\nComments: 10 pages\n",
    "authors": [
      "Qihao Zhu",
      "Zeyu Sun",
      "Yuan-an Xiao",
      "Wenjie Zhang",
      "Kang Yuan",
      "Yingfei Xiong",
      "Lu Zhang"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.08253"
  },
  {
    "id": "arXiv:2106.08704",
    "title": "Memorization and Generalization in Neural Code Intelligence Models",
    "abstract": "Comments: Under Review",
    "descriptor": "\nComments: Under Review\n",
    "authors": [
      "Md Rafiqul Islam Rabin",
      "Aftab Hussain",
      "Mohammad Amin Alipour",
      "Vincent J. Hellendoorn"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Programming Languages (cs.PL)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2106.08704"
  },
  {
    "id": "arXiv:2106.08811",
    "title": "Projective and Telescopic Projective Integration for Non-Linear Kinetic  Mixtures",
    "abstract": "Projective and Telescopic Projective Integration for Non-Linear Kinetic  Mixtures",
    "descriptor": "",
    "authors": [
      "Rafael Bailo",
      "Thomas Rey"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.08811"
  },
  {
    "id": "arXiv:2106.09159",
    "title": "Automatic Curricula via Expert Demonstrations",
    "abstract": "Comments: NeurIPS 2021 Deep Reinforcement Learning Workshop",
    "descriptor": "\nComments: NeurIPS 2021 Deep Reinforcement Learning Workshop\n",
    "authors": [
      "Siyu Dai",
      "Andreas Hofmann",
      "Brian Williams"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2106.09159"
  },
  {
    "id": "arXiv:2106.10404",
    "title": "Sparse Training via Boosting Pruning Plasticity with Neuroregeneration",
    "abstract": "Comments: Published on the thirty-fifth Conference on Neural Information Processing Systems (NeurIPS 2021). Code can be found this https URL",
    "descriptor": "\nComments: Published on the thirty-fifth Conference on Neural Information Processing Systems (NeurIPS 2021). Code can be found this https URL\n",
    "authors": [
      "Shiwei Liu",
      "Tianlong Chen",
      "Xiaohan Chen",
      "Zahra Atashgahi",
      "Lu Yin",
      "Huanyu Kou",
      "Li Shen",
      "Mykola Pechenizkiy",
      "Zhangyang Wang",
      "Decebal Constantin Mocanu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.10404"
  },
  {
    "id": "arXiv:2106.11156",
    "title": "Multi-Agent Curricula and Emergent Implicit Signaling",
    "abstract": "Comments: 12 pages, 11 figures",
    "descriptor": "\nComments: 12 pages, 11 figures\n",
    "authors": [
      "Niko A. Grupen",
      "Daniel D. Lee",
      "Bart Selman"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.11156"
  },
  {
    "id": "arXiv:2106.11892",
    "title": "Making Invisible Visible: Data-Driven Seismic Inversion with  Spatio-temporally Constrained Data Augmentation",
    "abstract": "Comments: 15 pages, 15 figures, accepted by IEEE Transactions on Geoscience and Remote Sensing, available as early access",
    "descriptor": "\nComments: 15 pages, 15 figures, accepted by IEEE Transactions on Geoscience and Remote Sensing, available as early access\n",
    "authors": [
      "Yuxin Yang",
      "Xitong Zhang",
      "Qiang Guan",
      "Youzuo Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.11892"
  },
  {
    "id": "arXiv:2106.12133",
    "title": "Keep them guessing: The value of randomized resource assignments in  General Lotto games",
    "abstract": "Comments: 4 figures",
    "descriptor": "\nComments: 4 figures\n",
    "authors": [
      "Keith Paarporn",
      "Rahul Chandan",
      "Mahnoosh Alizadeh",
      "Jason R. Marden"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2106.12133"
  },
  {
    "id": "arXiv:2106.12435",
    "title": "Existence of dissipative solutions to the compressible Navier-Stokes  system with potential temperature transport",
    "abstract": "Existence of dissipative solutions to the compressible Navier-Stokes  system with potential temperature transport",
    "descriptor": "",
    "authors": [
      "M\u00e1ria Luk\u00e1\u010dov\u00e1-Medvid'ov\u00e1",
      "Andreas Sch\u00f6mer"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.12435"
  },
  {
    "id": "arXiv:2106.12479",
    "title": "Classifying Textual Data with Pre-trained Vision Models through Transfer  Learning and Data Transformations",
    "abstract": "Comments: Paper contains: 7 pages, 9 figures, 1 table",
    "descriptor": "\nComments: Paper contains: 7 pages, 9 figures, 1 table\n",
    "authors": [
      "Charaf Eddine Benarab"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.12479"
  },
  {
    "id": "arXiv:2106.14568",
    "title": "Deep Ensembling with No Overhead for either Training or Testing: The  All-Round Blessings of Dynamic Sparsity",
    "abstract": "Comments: published in International Conference on Learning Representations (ICLR 2022)",
    "descriptor": "\nComments: published in International Conference on Learning Representations (ICLR 2022)\n",
    "authors": [
      "Shiwei Liu",
      "Tianlong Chen",
      "Zahra Atashgahi",
      "Xiaohan Chen",
      "Ghada Sokar",
      "Elena Mocanu",
      "Mykola Pechenizkiy",
      "Zhangyang Wang",
      "Decebal Constantin Mocanu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.14568"
  },
  {
    "id": "arXiv:2106.15728",
    "title": "Detecting Errors and Estimating Accuracy on Unlabeled Data with  Self-training Ensembles",
    "abstract": "Comments: Paper published at NeurIPS 2021",
    "descriptor": "\nComments: Paper published at NeurIPS 2021\n",
    "authors": [
      "Jiefeng Chen",
      "Frederick Liu",
      "Besim Avci",
      "Xi Wu",
      "Yingyu Liang",
      "Somesh Jha"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.15728"
  },
  {
    "id": "arXiv:2107.01131",
    "title": "Tight Mutual Information Estimation With Contrastive Fenchel-Legendre  Optimization",
    "abstract": "Tight Mutual Information Estimation With Contrastive Fenchel-Legendre  Optimization",
    "descriptor": "",
    "authors": [
      "Qing Guo",
      "Junya Chen",
      "Dong Wang",
      "Yuewei Yang",
      "Xinwei Deng",
      "Lawrence Carin",
      "Fan Li",
      "Chenyang Tao"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.01131"
  },
  {
    "id": "arXiv:2107.02371",
    "title": "Weighted Gaussian Process Bandits for Non-stationary Environments",
    "abstract": "Weighted Gaussian Process Bandits for Non-stationary Environments",
    "descriptor": "",
    "authors": [
      "Yuntian Deng",
      "Xingyu Zhou",
      "Baekjin Kim",
      "Ambuj Tewari",
      "Abhishek Gupta",
      "Ness Shroff"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.02371"
  },
  {
    "id": "arXiv:2107.03694",
    "title": "Network and Sequence-Based Prediction of Protein-Protein Interactions",
    "abstract": "Network and Sequence-Based Prediction of Protein-Protein Interactions",
    "descriptor": "",
    "authors": [
      "Leonardo Martini",
      "Adriano Fazzone",
      "Luca Becchetti"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Other Computer Science (cs.OH)"
    ],
    "url": "https://arxiv.org/abs/2107.03694"
  },
  {
    "id": "arXiv:2107.04899",
    "title": "Bounds Preserving Temporal Integration Methods for Hyperbolic  Conservation Laws",
    "abstract": "Comments: 18 pages, 8 figures",
    "descriptor": "\nComments: 18 pages, 8 figures\n",
    "authors": [
      "Tarik Dzanic",
      "Will Trojak",
      "Freddie D. Witherden"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2107.04899"
  },
  {
    "id": "arXiv:2107.06434",
    "title": "Centralized Model and Exploration Policy for Multi-Agent RL",
    "abstract": "Comments: Accepted to AAMAS 2022",
    "descriptor": "\nComments: Accepted to AAMAS 2022\n",
    "authors": [
      "Qizhen Zhang",
      "Chris Lu",
      "Animesh Garg",
      "Jakob Foerster"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.06434"
  },
  {
    "id": "arXiv:2107.06613",
    "title": "Adaptive BEM for elliptic PDE systems, part II: Isogeometric analysis  with hierarchical B-splines for weakly-singular integral equations",
    "abstract": "Adaptive BEM for elliptic PDE systems, part II: Isogeometric analysis  with hierarchical B-splines for weakly-singular integral equations",
    "descriptor": "",
    "authors": [
      "Gregor Gantner",
      "Dirk Praetorius"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2107.06613"
  },
  {
    "id": "arXiv:2107.07232",
    "title": "On the expressivity of bi-Lipschitz normalizing flows",
    "abstract": "On the expressivity of bi-Lipschitz normalizing flows",
    "descriptor": "",
    "authors": [
      "Alexandre Verine",
      "Benjamin Negrevergne",
      "Fabrice Rossi",
      "Yann Chevaleyre"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.07232"
  },
  {
    "id": "arXiv:2107.07445",
    "title": "AutoBERT-Zero: Evolving BERT Backbone from Scratch",
    "abstract": "Comments: Accepted by AAAI-2022",
    "descriptor": "\nComments: Accepted by AAAI-2022\n",
    "authors": [
      "Jiahui Gao",
      "Hang Xu",
      "Han Shi",
      "Xiaozhe Ren",
      "Philip L.H. Yu",
      "Xiaodan Liang",
      "Xin Jiang",
      "Zhenguo Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.07445"
  },
  {
    "id": "arXiv:2107.10060",
    "title": "Conditional GANs with Auxiliary Discriminative Classifier",
    "abstract": "Conditional GANs with Auxiliary Discriminative Classifier",
    "descriptor": "",
    "authors": [
      "Liang Hou",
      "Qi Cao",
      "Huawei Shen",
      "Siyuan Pan",
      "Xiaoshuang Li",
      "Xueqi Cheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.10060"
  },
  {
    "id": "arXiv:2107.12329",
    "title": "AASAE: Augmentation-Augmented Stochastic Autoencoders",
    "abstract": "Comments: 17 pages, 5 figures, 3 table",
    "descriptor": "\nComments: 17 pages, 5 figures, 3 table\n",
    "authors": [
      "William Falcon",
      "Ananya Harsh Jha",
      "Teddy Koker",
      "Kyunghyun Cho"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.12329"
  },
  {
    "id": "arXiv:2107.12773",
    "title": "Reradiation and Scattering from a Reconfigurable Intelligent Surface: A  General Macroscopic Model",
    "abstract": "Reradiation and Scattering from a Reconfigurable Intelligent Surface: A  General Macroscopic Model",
    "descriptor": "",
    "authors": [
      "V. Degli-Esposti",
      "E. M. Vitucci",
      "M. Di Renzo",
      "S. Tretyakov"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Emerging Technologies (cs.ET)",
      "Systems and Control (eess.SY)",
      "Applied Physics (physics.app-ph)",
      "Optics (physics.optics)"
    ],
    "url": "https://arxiv.org/abs/2107.12773"
  },
  {
    "id": "arXiv:2107.13530",
    "title": "An Adapter Based Pre-Training for Efficient and Scalable Self-Supervised  Speech Representation Learning",
    "abstract": "Comments: 5 pages, 6 figures. Accepted at ICASSP 2022. This version replaces an earlier version of paper accepted at an ICML 2021 workshop",
    "descriptor": "\nComments: 5 pages, 6 figures. Accepted at ICASSP 2022. This version replaces an earlier version of paper accepted at an ICML 2021 workshop\n",
    "authors": [
      "Samuel Kessler",
      "Bethan Thomas",
      "Salah Karout"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2107.13530"
  },
  {
    "id": "arXiv:2108.02113",
    "title": "Hyperparameter-free and Explainable Whole Graph Embedding",
    "abstract": "Hyperparameter-free and Explainable Whole Graph Embedding",
    "descriptor": "",
    "authors": [
      "Hao Wang",
      "Yue Deng",
      "Linyuan L\u00fc",
      "Guanrong Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2108.02113"
  },
  {
    "id": "arXiv:2108.02537",
    "title": "Redatuming physical systems using symmetric autoencoders",
    "abstract": "Redatuming physical systems using symmetric autoencoders",
    "descriptor": "",
    "authors": [
      "Pawan Bharadwaj",
      "Matthew Li",
      "Laurent Demanet"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Machine Learning (cs.LG)",
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Geophysics (physics.geo-ph)"
    ],
    "url": "https://arxiv.org/abs/2108.02537"
  },
  {
    "id": "arXiv:2108.03710",
    "title": "Online Admission Control and Resource Allocation in Network Slicing  under Demand Uncertainties",
    "abstract": "Online Admission Control and Resource Allocation in Network Slicing  under Demand Uncertainties",
    "descriptor": "",
    "authors": [
      "Sajjad Gholamipour",
      "Behzad Akbari",
      "Nader Mokari",
      "Mohammad Mahdi Tajiki",
      "Eduard Axel Jorswieck"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2108.03710"
  },
  {
    "id": "arXiv:2108.04190",
    "title": "On the Power of Differentiable Learning versus PAC and SQ Learning",
    "abstract": "On the Power of Differentiable Learning versus PAC and SQ Learning",
    "descriptor": "",
    "authors": [
      "Emmanuel Abbe",
      "Pritish Kamath",
      "Eran Malach",
      "Colin Sandon",
      "Nathan Srebro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2108.04190"
  },
  {
    "id": "arXiv:2108.04951",
    "title": "A Brief Review of Machine Learning Techniques for Protein  Phosphorylation Sites Prediction",
    "abstract": "A Brief Review of Machine Learning Techniques for Protein  Phosphorylation Sites Prediction",
    "descriptor": "",
    "authors": [
      "Farzaneh Esmaili",
      "Mahdi Pourmirzaei",
      "Shahin Ramazi",
      "Elham Yavari"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.04951"
  },
  {
    "id": "arXiv:2108.05533",
    "title": "Efficient Local Planning with Linear Function Approximation",
    "abstract": "Comments: Algorithmic Learning Theory 2022",
    "descriptor": "\nComments: Algorithmic Learning Theory 2022\n",
    "authors": [
      "Dong Yin",
      "Botao Hao",
      "Yasin Abbasi-Yadkori",
      "Nevena Lazi\u0107",
      "Csaba Szepesv\u00e1ri"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2108.05533"
  },
  {
    "id": "arXiv:2108.06443",
    "title": "Global space-time Trefftz DG schemes for the time-dependent linear wave  equation",
    "abstract": "Comments: 29 pages. arXiv admin note: text overlap with arXiv:2002.11575, arXiv:1610.08002 by other authors",
    "descriptor": "\nComments: 29 pages. arXiv admin note: text overlap with arXiv:2002.11575, arXiv:1610.08002 by other authors\n",
    "authors": [
      "Long Yuan"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2108.06443"
  },
  {
    "id": "arXiv:2108.07636",
    "title": "Accounting for shared covariates in semi-parametric Bayesian additive  regression trees",
    "abstract": "Accounting for shared covariates in semi-parametric Bayesian additive  regression trees",
    "descriptor": "",
    "authors": [
      "Estev\u00e3o B. Prado",
      "Andrew C. Parnell",
      "Keefe Murphy",
      "Nathan McJames",
      "Ann O'Shea",
      "Rafael A. Moral"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.07636"
  },
  {
    "id": "arXiv:2108.08467",
    "title": "Medical Image Segmentation using 3D Convolutional Neural Networks: A  Review",
    "abstract": "Comments: 17 pages, 4 figures",
    "descriptor": "\nComments: 17 pages, 4 figures\n",
    "authors": [
      "S Niyas",
      "S J Pawan",
      "M Anand Kumar",
      "Jeny Rajan"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.08467"
  },
  {
    "id": "arXiv:2108.08900",
    "title": "Real-time Transient Simulation and Studies of Offshore Wind Turbines",
    "abstract": "Real-time Transient Simulation and Studies of Offshore Wind Turbines",
    "descriptor": "",
    "authors": [
      "Thai-Thanh Nguyen",
      "Tuyen Vu",
      "Thomas Ortmeyer",
      "George Stefopoulos",
      "Greg Pedrick",
      "Jason MacDowell"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2108.08900"
  },
  {
    "id": "arXiv:2108.10781",
    "title": "Adaptive Explainable Continual Learning Framework for Regression  Problems with Focus on Power Forecasts",
    "abstract": "Comments: Accepted by OC-DDC 2021",
    "descriptor": "\nComments: Accepted by OC-DDC 2021\n",
    "authors": [
      "Yujiang He"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.10781"
  },
  {
    "id": "arXiv:2108.12550",
    "title": "Successive-Cancellation Decoding of Reed-Muller Codes with Fast Hadamard  Transform",
    "abstract": "Comments: Submitted to an IEEE journal for possible publication",
    "descriptor": "\nComments: Submitted to an IEEE journal for possible publication\n",
    "authors": [
      "Nghia Doan",
      "Seyyed Ali Hashemi",
      "Warren J. Gross"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2108.12550"
  },
  {
    "id": "arXiv:2108.12864",
    "title": "Well-mixing vertices and almost expanders",
    "abstract": "Comments: minor changes suggested by a reviewer",
    "descriptor": "\nComments: minor changes suggested by a reviewer\n",
    "authors": [
      "Debsoumya Chakraborti",
      "Jaehoon Kim",
      "Jinha Kim",
      "Minki Kim",
      "Hong Liu"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2108.12864"
  },
  {
    "id": "arXiv:2109.00486",
    "title": "Survey of Low-Resource Machine Translation",
    "abstract": "Survey of Low-Resource Machine Translation",
    "descriptor": "",
    "authors": [
      "Barry Haddow",
      "Rachel Bawden",
      "Antonio Valerio Miceli Barone",
      "Jind\u0159ich Helcl",
      "Alexandra Birch"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.00486"
  },
  {
    "id": "arXiv:2109.01134",
    "title": "Learning to Prompt for Vision-Language Models",
    "abstract": "Comments: Code: this https URL",
    "descriptor": "\nComments: Code: this https URL\n",
    "authors": [
      "Kaiyang Zhou",
      "Jingkang Yang",
      "Chen Change Loy",
      "Ziwei Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.01134"
  },
  {
    "id": "arXiv:2109.01892",
    "title": "Fast Succinct Retrieval and Approximate Membership using Ribbon",
    "abstract": "Fast Succinct Retrieval and Approximate Membership using Ribbon",
    "descriptor": "",
    "authors": [
      "Peter C. Dillinger",
      "Lorenz H\u00fcbschle-Schneider",
      "Peter Sanders",
      "Stefan Walzer"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2109.01892"
  },
  {
    "id": "arXiv:2109.02705",
    "title": "A Virtual Reality-based Training and Assessment System for Bridge  Inspectors with an Assistant Drone",
    "abstract": "Comments: 23 pages, 10 figures. Accepted by IEEE Transactions on Human-Machine Systems with minor revision on Jan 31, 2022",
    "descriptor": "\nComments: 23 pages, 10 figures. Accepted by IEEE Transactions on Human-Machine Systems with minor revision on Jan 31, 2022\n",
    "authors": [
      "Yu Li",
      "Muhammad Monjurul Karim",
      "Ruwen Qin"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.02705"
  },
  {
    "id": "arXiv:2109.03446",
    "title": "Hierarchical Frequency and Voltage Control using Prioritized Utilization  of Inverter Based Resources",
    "abstract": "Hierarchical Frequency and Voltage Control using Prioritized Utilization  of Inverter Based Resources",
    "descriptor": "",
    "authors": [
      "Rahul Chakraborty",
      "Aranya Chakrabortty",
      "Evangelos Farantatos",
      "Mahendra Patel",
      "Hossein Hooshyar",
      "Atena Darvishi"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2109.03446"
  },
  {
    "id": "arXiv:2109.04721",
    "title": "Where Should I Look? Optimised Gaze Control for Whole-Body Collision  Avoidance in Dynamic Environments",
    "abstract": "Comments: 8 pages, 11 figures, published in IEEE Robotics and Automation Letters (RA-L) and accepted for presentation at ICRA 2022",
    "descriptor": "\nComments: 8 pages, 11 figures, published in IEEE Robotics and Automation Letters (RA-L) and accepted for presentation at ICRA 2022\n",
    "authors": [
      "Mark Nicholas Finean",
      "Wolfgang Merkt",
      "Ioannis Havoutis"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.04721"
  },
  {
    "id": "arXiv:2109.04907",
    "title": "GPA-Teleoperation: Gaze Enhanced Perception-aware Safe Assistive Aerial  Teleoperation",
    "abstract": "Comments: 8 pages, 13 figures, RA-L with ICRA presentation option",
    "descriptor": "\nComments: 8 pages, 13 figures, RA-L with ICRA presentation option\n",
    "authors": [
      "Qianhao Wang",
      "Botao He",
      "Zhiren Xun",
      "Chao Xu",
      "Fei Gao"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.04907"
  },
  {
    "id": "arXiv:2109.05668",
    "title": "UMPNet: Universal Manipulation Policy Network for Articulated Objects",
    "abstract": "Comments: RA-L/ICRA 2022. Project page: this https URL",
    "descriptor": "\nComments: RA-L/ICRA 2022. Project page: this https URL\n",
    "authors": [
      "Zhenjia Xu",
      "Zhanpeng He",
      "Shuran Song"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.05668"
  },
  {
    "id": "arXiv:2109.06094",
    "title": "Single-stream CNN with Learnable Architecture for Multi-source Remote  Sensing Data",
    "abstract": "Single-stream CNN with Learnable Architecture for Multi-source Remote  Sensing Data",
    "descriptor": "",
    "authors": [
      "Yi Yang",
      "Daoye Zhu",
      "Tengteng Qu",
      "Qiangyu Wang",
      "Fuhu Ren",
      "Chengqi Cheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2109.06094"
  },
  {
    "id": "arXiv:2109.07437",
    "title": "Should We Be Pre-training? An Argument for End-task Aware Training as an  Alternative",
    "abstract": "Comments: 18 pages, 4 figures",
    "descriptor": "\nComments: 18 pages, 4 figures\n",
    "authors": [
      "Lucio M. Dery",
      "Paul Michel",
      "Ameet Talwalkar",
      "Graham Neubig"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.07437"
  },
  {
    "id": "arXiv:2109.07704",
    "title": "Federated Submodel Averaging",
    "abstract": "Federated Submodel Averaging",
    "descriptor": "",
    "authors": [
      "Yucheng Ding",
      "Chaoyue Niu",
      "Fan Wu",
      "Shaojie Tang",
      "Chengfei Lv",
      "Yanghe Feng",
      "Guihai Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.07704"
  },
  {
    "id": "arXiv:2109.09689",
    "title": "The Case for Claim Difficulty Assessment in Automatic Fact Checking",
    "abstract": "The Case for Claim Difficulty Assessment in Automatic Fact Checking",
    "descriptor": "",
    "authors": [
      "Prakhar Singh",
      "Anubrata Das",
      "Junyi Jessy Li",
      "Matthew Lease"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2109.09689"
  },
  {
    "id": "arXiv:2109.11192",
    "title": "Predicting the Timing of Camera Movements From the Kinematics of  Instruments in Robotic-Assisted Surgery Using Artificial Neural Networks",
    "abstract": "Predicting the Timing of Camera Movements From the Kinematics of  Instruments in Robotic-Assisted Surgery Using Artificial Neural Networks",
    "descriptor": "",
    "authors": [
      "Hanna Kossowsky",
      "Ilana Nisky"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.11192"
  },
  {
    "id": "arXiv:2109.11375",
    "title": "Stochastic Normalizing Flows for Inverse Problems: a Markov Chains  Viewpoint",
    "abstract": "Stochastic Normalizing Flows for Inverse Problems: a Markov Chains  Viewpoint",
    "descriptor": "",
    "authors": [
      "Paul Hagemann",
      "Johannes Hertrich",
      "Gabriele Steidl"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2109.11375"
  },
  {
    "id": "arXiv:2109.12449",
    "title": "AbstractDifferentiation.jl: Backend-Agnostic Differentiable Programming  in Julia",
    "abstract": "Comments: 3 figures, 2 tables 15 pages",
    "descriptor": "\nComments: 3 figures, 2 tables 15 pages\n",
    "authors": [
      "Frank Sch\u00e4fer",
      "Mohamed Tarek",
      "Lyndon White",
      "Chris Rackauckas"
    ],
    "subjectives": [
      "Mathematical Software (cs.MS)",
      "Machine Learning (cs.LG)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2109.12449"
  },
  {
    "id": "arXiv:2109.12925",
    "title": "HarrisZ$^+$: Harris Corner Selection for Next-Gen Image Matching  Pipelines",
    "abstract": "Comments: last revised manuscript",
    "descriptor": "\nComments: last revised manuscript\n",
    "authors": [
      "Fabio Bellavia",
      "Dmytro Mishkin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.12925"
  },
  {
    "id": "arXiv:2109.14128",
    "title": "Grouptron: Dynamic Multi-Scale Graph Convolutional Networks for  Group-Aware Dense Crowd Trajectory Forecasting",
    "abstract": "Comments: ICRA 2022 Accepted",
    "descriptor": "\nComments: ICRA 2022 Accepted\n",
    "authors": [
      "Rui Zhou",
      "Hongyu Zhou",
      "Masayoshi Tomizuka",
      "Jiachen Li",
      "Zhuo Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.14128"
  },
  {
    "id": "arXiv:2109.14349",
    "title": "Relational Memory: Native In-Memory Accesses on Rows and Columns",
    "abstract": "Relational Memory: Native In-Memory Accesses on Rows and Columns",
    "descriptor": "",
    "authors": [
      "Shahin Roozkhosh",
      "Denis Hoornaert",
      "Ju Hyoung Mun",
      "Tarikul Islam Papon",
      "Ahmed Sanaullah",
      "Ulrich Drepper",
      "Renato Mancuso",
      "Manos Athanassoulis"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2109.14349"
  },
  {
    "id": "arXiv:2109.14454",
    "title": "Discretizing $L_p$ norms and frame theory",
    "abstract": "Comments: 17 pages, version 2",
    "descriptor": "\nComments: 17 pages, version 2\n",
    "authors": [
      "Daniel Freeman",
      "Dorsa Ghoreishi"
    ],
    "subjectives": [
      "Functional Analysis (math.FA)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2109.14454"
  },
  {
    "id": "arXiv:2109.14509",
    "title": "PAC-Bayes Information Bottleneck",
    "abstract": "Comments: ICLR'22 (Spotlight)",
    "descriptor": "\nComments: ICLR'22 (Spotlight)\n",
    "authors": [
      "Zifeng Wang",
      "Shao-Lun Huang",
      "Ercan E. Kuruoglu",
      "Jimeng Sun",
      "Xi Chen",
      "Yefeng Zheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.14509"
  },
  {
    "id": "arXiv:2109.15258",
    "title": "Federated Dropout -- A Simple Approach for Enabling Federated Learning  on Resource Constrained Devices",
    "abstract": "Comments: This paper was accepted by IEEE Wireless Communications Letters",
    "descriptor": "\nComments: This paper was accepted by IEEE Wireless Communications Letters\n",
    "authors": [
      "Dingzhu Wen",
      "Ki-Jun Jeon",
      "Kaibin Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2109.15258"
  },
  {
    "id": "arXiv:2110.01387",
    "title": "Machine Learning with Knowledge Constraints for Process Optimization of  Open-Air Perovskite Solar Cell Manufacturing",
    "abstract": "Machine Learning with Knowledge Constraints for Process Optimization of  Open-Air Perovskite Solar Cell Manufacturing",
    "descriptor": "",
    "authors": [
      "Zhe Liu",
      "Nicholas Rolston",
      "Austin C. Flick",
      "Thomas W. Colburn",
      "Zekun Ren",
      "Reinhold H. Dauskardt",
      "Tonio Buonassisi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Applied Physics (physics.app-ph)"
    ],
    "url": "https://arxiv.org/abs/2110.01387"
  },
  {
    "id": "arXiv:2110.01439",
    "title": "SecurePtrs: Proving Secure Compilation with Data-Flow Back-Translation  and Turn-Taking Simulation",
    "abstract": "Comments: CSF 2022 submission",
    "descriptor": "\nComments: CSF 2022 submission\n",
    "authors": [
      "Akram El-Korashy",
      "Roberto Blanco",
      "J\u00e9r\u00e9my Thibault",
      "Adrien Durier",
      "Deepak Garg",
      "Catalin Hritcu"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.01439"
  },
  {
    "id": "arXiv:2110.01712",
    "title": "Feedback control of social distancing for COVID-19 via elementary  formulae",
    "abstract": "Comments: 10th Vienna International Conference on Mathematical Modelling (MATHMOD 2022) -- July 27-29, 2022 -- Vienna, Austria",
    "descriptor": "\nComments: 10th Vienna International Conference on Mathematical Modelling (MATHMOD 2022) -- July 27-29, 2022 -- Vienna, Austria\n",
    "authors": [
      "Michel Fliess",
      "C\u00e9dric Join",
      "Alberto d'Onofrio"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2110.01712"
  },
  {
    "id": "arXiv:2110.01732",
    "title": "Faster algorithm for counting of the integer points number in  $\u0394$-modular polyhedra",
    "abstract": "Faster algorithm for counting of the integer points number in  $\u0394$-modular polyhedra",
    "descriptor": "",
    "authors": [
      "D. V. Gribanov",
      "D. S. Malyshev"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Computational Geometry (cs.CG)",
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2110.01732"
  },
  {
    "id": "arXiv:2110.02423",
    "title": "Geometric Transformers for Protein Interface Contact Prediction",
    "abstract": "Comments: 18 pages, 5 figures, and 9 tables. Camera-ready version for ICLR 2022, with a minor update in the conclusion section",
    "descriptor": "\nComments: 18 pages, 5 figures, and 9 tables. Camera-ready version for ICLR 2022, with a minor update in the conclusion section\n",
    "authors": [
      "Alex Morehead",
      "Chen Chen",
      "Jianlin Cheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Biomolecules (q-bio.BM)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2110.02423"
  },
  {
    "id": "arXiv:2110.03301",
    "title": "EvadeDroid: A Practical Evasion Attack on Machine Learning for Black-box  Android Malware Detection",
    "abstract": "EvadeDroid: A Practical Evasion Attack on Machine Learning for Black-box  Android Malware Detection",
    "descriptor": "",
    "authors": [
      "Hamid Bostani",
      "Veelasha Moonsamy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.03301"
  },
  {
    "id": "arXiv:2110.03442",
    "title": "A Comparison of Neural Network Architectures for Data-Driven  Reduced-Order Modeling",
    "abstract": "A Comparison of Neural Network Architectures for Data-Driven  Reduced-Order Modeling",
    "descriptor": "",
    "authors": [
      "Anthony Gruber",
      "Max Gunzburger",
      "Lili Ju",
      "Zhu Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.03442"
  },
  {
    "id": "arXiv:2110.03536",
    "title": "Prototype Learning for Interpretable Respiratory Sound Analysis",
    "abstract": "Comments: Technical report of the paper accepted by IEEE ICASSP 2022",
    "descriptor": "\nComments: Technical report of the paper accepted by IEEE ICASSP 2022\n",
    "authors": [
      "Zhao Ren",
      "Thanh Tam Nguyen",
      "Wolfgang Nejdl"
    ],
    "subjectives": [
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2110.03536"
  },
  {
    "id": "arXiv:2110.03735",
    "title": "Adversarial Unlearning of Backdoors via Implicit Hypergradient",
    "abstract": "Comments: In proceeding of the Tenth International Conference on Learning Representations (ICLR 2022)",
    "descriptor": "\nComments: In proceeding of the Tenth International Conference on Learning Representations (ICLR 2022)\n",
    "authors": [
      "Yi Zeng",
      "Si Chen",
      "Won Park",
      "Z. Morley Mao",
      "Ming Jin",
      "Ruoxi Jia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.03735"
  },
  {
    "id": "arXiv:2110.04057",
    "title": "FAST-RIR: Fast neural diffuse room impulse response generator",
    "abstract": "Comments: Accepted to ICASSP 2022. More results and source code is available at this https URL",
    "descriptor": "\nComments: Accepted to ICASSP 2022. More results and source code is available at this https URL\n",
    "authors": [
      "Anton Ratnarajah",
      "Shi-Xiong Zhang",
      "Meng Yu",
      "Zhenyu Tang",
      "Dinesh Manocha",
      "Dong Yu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.04057"
  },
  {
    "id": "arXiv:2110.04488",
    "title": "Demystifying the Transferability of Adversarial Attacks in Computer  Networks",
    "abstract": "Comments: 15 pages",
    "descriptor": "\nComments: 15 pages\n",
    "authors": [
      "Ehsan Nowroozi",
      "Yassine Mekdad",
      "Mohammad Hajian Berenjestanaki",
      "Mauro Conti",
      "Abdeslam EL Fergougui"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2110.04488"
  },
  {
    "id": "arXiv:2110.04768",
    "title": "A Novel Negative $\\ell_1$ Penalty Approach for Multiuser One-Bit Massive  MIMO Downlink with PSK Signaling",
    "abstract": "Comments: 5 pages, 4 figures, accepted for publication in IEEE ICASSP 2022",
    "descriptor": "\nComments: 5 pages, 4 figures, accepted for publication in IEEE ICASSP 2022\n",
    "authors": [
      "Zheyu Wu",
      "Bo Jiang",
      "Ya-Feng Liu",
      "Yu-Hong Dai"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2110.04768"
  },
  {
    "id": "arXiv:2110.06986",
    "title": "ADMM-DAD net: a deep unfolding network for analysis compressed sensing",
    "abstract": "Comments: to appear in 2022 International Conference on Acoustics, Speech and Signal Processing (ICASSP)",
    "descriptor": "\nComments: to appear in 2022 International Conference on Acoustics, Speech and Signal Processing (ICASSP)\n",
    "authors": [
      "Vasiliki Kouni",
      "Georgios Paraskevopoulos",
      "Holger Rauhut",
      "George C. Alexandropoulos"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.06986"
  },
  {
    "id": "arXiv:2110.07317",
    "title": "ReGVD: Revisiting Graph Neural Networks for Vulnerability Detection",
    "abstract": "Comments: Accepted to ICSE 2022 (Demonstrations). The first two authors contributed equally to this work",
    "descriptor": "\nComments: Accepted to ICSE 2022 (Demonstrations). The first two authors contributed equally to this work\n",
    "authors": [
      "Van-Anh Nguyen",
      "Dai Quoc Nguyen",
      "Van Nguyen",
      "Trung Le",
      "Quan Hung Tran",
      "Dinh Phung"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.07317"
  },
  {
    "id": "arXiv:2110.07472",
    "title": "Capacity of Group-invariant Linear Readouts from Equivariant  Representations: How Many Objects can be Linearly Classified Under All  Possible Views?",
    "abstract": "Comments: Version accepted to ICLR 2022",
    "descriptor": "\nComments: Version accepted to ICLR 2022\n",
    "authors": [
      "Matthew Farrell",
      "Blake Bordelon",
      "Shubhendu Trivedi",
      "Cengiz Pehlevan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.07472"
  },
  {
    "id": "arXiv:2110.08429",
    "title": "TorchEsegeta: Framework for Interpretability and Explainability of  Image-based Deep Learning Models",
    "abstract": "TorchEsegeta: Framework for Interpretability and Explainability of  Image-based Deep Learning Models",
    "descriptor": "",
    "authors": [
      "Soumick Chatterjee",
      "Arnab Das",
      "Chirag Mandal",
      "Budhaditya Mukhopadhyay",
      "Manish Vipinraj",
      "Aniruddh Shukla",
      "Rajatha Nagaraja Rao",
      "Chompunuch Sarasaen",
      "Oliver Speck",
      "Andreas N\u00fcrnberger"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.08429"
  },
  {
    "id": "arXiv:2110.08741",
    "title": "Minimal Conditions for Beneficial Local Search",
    "abstract": "Comments: 36 pages plus 20 pages of appendix",
    "descriptor": "\nComments: 36 pages plus 20 pages of appendix\n",
    "authors": [
      "Mark G Wallace"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2110.08741"
  },
  {
    "id": "arXiv:2110.08980",
    "title": "Location Information Assisted Beamforming Design for Reconfigurable  Intelligent Surface Aided Communication Systems",
    "abstract": "Comments: 16 pages, 9 figures. This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible",
    "descriptor": "\nComments: 16 pages, 9 figures. This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Zhe Xing",
      "Rui Wang",
      "Xiaojun Yuan",
      "Jun Wu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.08980"
  },
  {
    "id": "arXiv:2110.09022",
    "title": "Demystifying How Self-Supervised Features Improve Training from Noisy  Labels",
    "abstract": "Demystifying How Self-Supervised Features Improve Training from Noisy  Labels",
    "descriptor": "",
    "authors": [
      "Hao Cheng",
      "Zhaowei Zhu",
      "Xing Sun",
      "Yang Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.09022"
  },
  {
    "id": "arXiv:2110.10116",
    "title": "On the Global Convergence of Momentum-based Policy Gradient",
    "abstract": "On the Global Convergence of Momentum-based Policy Gradient",
    "descriptor": "",
    "authors": [
      "Yuhao Ding",
      "Junzi Zhang",
      "Javad Lavaei"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2110.10116"
  },
  {
    "id": "arXiv:2110.10298",
    "title": "Incorporating Rich Social Interactions Into MDPs",
    "abstract": "Comments: Accepted to the 39th International Conference on Robotics and Automation (ICRA 2022)",
    "descriptor": "\nComments: Accepted to the 39th International Conference on Robotics and Automation (ICRA 2022)\n",
    "authors": [
      "Ravi Tejwani",
      "Yen-Ling Kuo",
      "Tianmin Shu",
      "Bennett Stankovits",
      "Dan Gutfreund",
      "Joshua B. Tenenbaum",
      "Boris Katz",
      "Andrei Barbu"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.10298"
  },
  {
    "id": "arXiv:2110.10721",
    "title": "Learning quantum dynamics with latent neural ODEs",
    "abstract": "Comments: 11 Pages. 8 Figures. This is a resubmission. We added more results and plots for more quantitative analysis",
    "descriptor": "\nComments: 11 Pages. 8 Figures. This is a resubmission. We added more results and plots for more quantitative analysis\n",
    "authors": [
      "Matthew Choi",
      "Daniel Flam-Shepherd",
      "Thi Ha Kyaw",
      "Al\u00e1n Aspuru-Guzik"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.10721"
  },
  {
    "id": "arXiv:2110.10863",
    "title": "Deep Generative Models in Engineering Design: A Review",
    "abstract": "Deep Generative Models in Engineering Design: A Review",
    "descriptor": "",
    "authors": [
      "Lyle Regenwetter",
      "Amin Heyrani Nobari",
      "Faez Ahmed"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.10863"
  },
  {
    "id": "arXiv:2110.11198",
    "title": "Temporal Motifs in Patent Opposition and Collaboration Networks",
    "abstract": "Temporal Motifs in Patent Opposition and Collaboration Networks",
    "descriptor": "",
    "authors": [
      "Penghang Liu",
      "Naoki Masuda",
      "Tomomi Kito",
      "A. Erdem Sar\u0131y\u00fcce"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2110.11198"
  },
  {
    "id": "arXiv:2110.11222",
    "title": "Is High Variance Unavoidable in RL? A Case Study in Continuous Control",
    "abstract": "Comments: Accepted to ICLR2022",
    "descriptor": "\nComments: Accepted to ICLR2022\n",
    "authors": [
      "Johan Bjorck",
      "Carla P. Gomes",
      "Kilian Q. Weinberger"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.11222"
  },
  {
    "id": "arXiv:2110.11291",
    "title": "Likelihood Training of Schr\u00f6dinger Bridge using Forward-Backward SDEs  Theory",
    "abstract": "Likelihood Training of Schr\u00f6dinger Bridge using Forward-Backward SDEs  Theory",
    "descriptor": "",
    "authors": [
      "Tianrong Chen",
      "Guan-Horng Liu",
      "Evangelos A. Theodorou"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Analysis of PDEs (math.AP)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2110.11291"
  },
  {
    "id": "arXiv:2110.13311",
    "title": "Physics Informed Machine Learning of SPH: Machine Learning Lagrangian  Turbulence",
    "abstract": "Physics Informed Machine Learning of SPH: Machine Learning Lagrangian  Turbulence",
    "descriptor": "",
    "authors": [
      "Michael Woodward",
      "Yifeng Tian",
      "Criston Hyett",
      "Chris Fryer",
      "Daniel Livescu",
      "Mikhail Stepanov",
      "Michael Chertkov"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.13311"
  },
  {
    "id": "arXiv:2110.13424",
    "title": "Precise URL Phishing Detection Using Neural Networks",
    "abstract": "Comments: 10 pages, 9 figures",
    "descriptor": "\nComments: 10 pages, 9 figures\n",
    "authors": [
      "Aman Rangapur",
      "Dr Ajith Jubilson"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2110.13424"
  },
  {
    "id": "arXiv:2110.14131",
    "title": "Temporal Knowledge Distillation for On-device Audio Classification",
    "abstract": "Comments: ICASSP 2022",
    "descriptor": "\nComments: ICASSP 2022\n",
    "authors": [
      "Kwanghee Choi",
      "Martin Kersner",
      "Jacob Morton",
      "Buru Chang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.14131"
  },
  {
    "id": "arXiv:2110.14953",
    "title": "Multi-Task Neural Processes",
    "abstract": "Comments: 33 pages, 13 figures",
    "descriptor": "\nComments: 33 pages, 13 figures\n",
    "authors": [
      "Donggyun Kim",
      "Seongwoong Cho",
      "Wonkwang Lee",
      "Seunghoon Hong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.14953"
  },
  {
    "id": "arXiv:2111.00083",
    "title": "A Scalable AutoML Approach Based on Graph Neural Networks",
    "abstract": "Comments: 14 pages, 9 figures",
    "descriptor": "\nComments: 14 pages, 9 figures\n",
    "authors": [
      "Mossad Helali",
      "Essam Mansour",
      "Ibrahim Abdelaziz",
      "Julian Dolby",
      "Kavitha Srinivas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.00083"
  },
  {
    "id": "arXiv:2111.00289",
    "title": "Intrusion Prevention through Optimal Stopping",
    "abstract": "Comments: Preprint; Submitted to IEEE for review. Minor text updates 17/1 2022. arXiv admin note: substantial text overlap with arXiv:2106.07160",
    "descriptor": "\nComments: Preprint; Submitted to IEEE for review. Minor text updates 17/1 2022. arXiv admin note: substantial text overlap with arXiv:2106.07160\n",
    "authors": [
      "Kim Hammar",
      "Rolf Stadler"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2111.00289"
  },
  {
    "id": "arXiv:2111.00559",
    "title": "Capacity of Noisy Permutation Channels",
    "abstract": "Comments: typos corrected",
    "descriptor": "\nComments: typos corrected\n",
    "authors": [
      "Jennifer Tang",
      "Yury Polyanskiy"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2111.00559"
  },
  {
    "id": "arXiv:2111.01842",
    "title": "Coordinate Linear Variance Reduction for Generalized Linear Programming",
    "abstract": "Comments: 39 pages, 6 figures",
    "descriptor": "\nComments: 39 pages, 6 figures\n",
    "authors": [
      "Chaobing Song",
      "Cheuk Yin Lin",
      "Stephen J. Wright",
      "Jelena Diakonikolas"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.01842"
  },
  {
    "id": "arXiv:2111.02062",
    "title": "Linking Across Data Granularity: Fitting Multivariate Hawkes Processes  to Partially Interval-Censored Data",
    "abstract": "Linking Across Data Granularity: Fitting Multivariate Hawkes Processes  to Partially Interval-Censored Data",
    "descriptor": "",
    "authors": [
      "Pio Calderon",
      "Alexander Soen",
      "Marian-Andrei Rizoiu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2111.02062"
  },
  {
    "id": "arXiv:2111.03501",
    "title": "Model Checking Temporal Properties of Recursive Probabilistic Programs",
    "abstract": "Comments: Full version including proofs, 35 pages",
    "descriptor": "\nComments: Full version including proofs, 35 pages\n",
    "authors": [
      "Tobias Winkler",
      "Christina Gehnen",
      "Joost-Pieter Katoen"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2111.03501"
  },
  {
    "id": "arXiv:2111.03627",
    "title": "Adaptive FEM for parameter-errors in elliptic linear-quadratic parameter  estimation problems",
    "abstract": "Adaptive FEM for parameter-errors in elliptic linear-quadratic parameter  estimation problems",
    "descriptor": "",
    "authors": [
      "Roland Becker",
      "Michael Innerberger",
      "Dirk Praetorius"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2111.03627"
  },
  {
    "id": "arXiv:2111.06020",
    "title": "csBoundary: City-scale Road-boundary Detection in Aerial Images for  High-definition Maps",
    "abstract": "Comments: Accepted by IEEE Robotics and Automation Letters and IEEE International Conference on Robotics and Automation (ICRA) 2022",
    "descriptor": "\nComments: Accepted by IEEE Robotics and Automation Letters and IEEE International Conference on Robotics and Automation (ICRA) 2022\n",
    "authors": [
      "Zhenhua Xu",
      "Yuxuan Liu",
      "Lu Gan",
      "Xiangcheng Hu",
      "Yuxiang Sun",
      "Ming Liu",
      "Lujia Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2111.06020"
  },
  {
    "id": "arXiv:2111.07016",
    "title": "Robust Multi-Robot Trajectory Optimization Using Alternating Direction  Method of Multiplier",
    "abstract": "Robust Multi-Robot Trajectory Optimization Using Alternating Direction  Method of Multiplier",
    "descriptor": "",
    "authors": [
      "Ruiqi Ni",
      "Zherong Pan",
      "Xifeng Gao"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2111.07016"
  },
  {
    "id": "arXiv:2111.07113",
    "title": "Novel Weight Update Scheme for Hardware Neural Network based on Synaptic  Devices Having Abrupt LTP or LTD Characteristics",
    "abstract": "Comments: 10 pages, 13 figures, 1 table",
    "descriptor": "\nComments: 10 pages, 13 figures, 1 table\n",
    "authors": [
      "Junmo Lee",
      "Joon Hwang",
      "Youngwoon Cho",
      "Sangbum Kim",
      "Jongho Lee"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2111.07113"
  },
  {
    "id": "arXiv:2111.07865",
    "title": "Achievable Rates for Short-Reach Fiber-Optic Channels with Direct  Detection",
    "abstract": "Comments: Submitted to J. Lightw. Technol. on November 15, 2021; revised January 7, 2022; accepted January 22, 2022",
    "descriptor": "\nComments: Submitted to J. Lightw. Technol. on November 15, 2021; revised January 7, 2022; accepted January 22, 2022\n",
    "authors": [
      "Daniel Plabst",
      "Tobias Prinz",
      "Thomas Wiegart",
      "Talha Rahman",
      "Neboj\u0161a Stojanovi\u0107",
      "Stefano Calabr\u00f2",
      "Norbert Hanik",
      "Gerhard Kramer"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2111.07865"
  },
  {
    "id": "arXiv:2111.07958",
    "title": "Short-Term Power Prediction for Renewable Energy Using Hybrid Graph  Convolutional Network and Long Short-Term Memory Approach",
    "abstract": "Comments: This paper was accepted the 22nd Power Systems Computation Conference (PSCC 2022)",
    "descriptor": "\nComments: This paper was accepted the 22nd Power Systems Computation Conference (PSCC 2022)\n",
    "authors": [
      "Wenlong Liao",
      "Birgitte Bak-Jensen",
      "Jayakrishnan Radhakrishna Pillai",
      "Zhe Yang",
      "Kuangpu Liu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.07958"
  },
  {
    "id": "arXiv:2111.07992",
    "title": "Query and Depth Upper Bounds for Quantum Unitaries via Grover Search",
    "abstract": "Comments: 15 pages",
    "descriptor": "\nComments: 15 pages\n",
    "authors": [
      "Gregory Rosenthal"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2111.07992"
  },
  {
    "id": "arXiv:2111.08123",
    "title": "The Bubble Transform and the de Rham Complex",
    "abstract": "Comments: Some typos and other minor errors corrected and additional explanations included",
    "descriptor": "\nComments: Some typos and other minor errors corrected and additional explanations included\n",
    "authors": [
      "Richard S. Falk",
      "Ragnar Winther"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2111.08123"
  },
  {
    "id": "arXiv:2111.08131",
    "title": "Quantum soundness of testing tensor codes",
    "abstract": "Comments: In FOCS 2021. v2: Added more general pasting method to handle codes with larger distances",
    "descriptor": "\nComments: In FOCS 2021. v2: Added more general pasting method to handle codes with larger distances\n",
    "authors": [
      "Zhengfeng Ji",
      "Anand Natarajan",
      "Thomas Vidick",
      "John Wright",
      "Henry Yuen"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computational Complexity (cs.CC)",
      "Operator Algebras (math.OA)"
    ],
    "url": "https://arxiv.org/abs/2111.08131"
  },
  {
    "id": "arXiv:2111.08446",
    "title": "Automatic Sleep Staging of EEG Signals: Recent Development, Challenges,  and Future Directions",
    "abstract": "Comments: 30 pages, 2 figures",
    "descriptor": "\nComments: 30 pages, 2 figures\n",
    "authors": [
      "Huy Phan",
      "Kaare Mikkelsen"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.08446"
  },
  {
    "id": "arXiv:2111.09378",
    "title": "MPF6D: Masked Pyramid Fusion 6D Pose Estimation",
    "abstract": "MPF6D: Masked Pyramid Fusion 6D Pose Estimation",
    "descriptor": "",
    "authors": [
      "Nuno Pereira",
      "Lu\u00eds A. Alexandre"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.09378"
  },
  {
    "id": "arXiv:2111.11294",
    "title": "Scaling Law for Recommendation Models: Towards General-purpose User  Representations",
    "abstract": "Comments: 10 pages, 6 figures, 6 tables",
    "descriptor": "\nComments: 10 pages, 6 figures, 6 tables\n",
    "authors": [
      "Kyuyong Shin",
      "Hanock Kwak",
      "Su Young Kim",
      "Max Nihlen Ramstrom",
      "Jisu Jeong",
      "Jung-Woo Ha",
      "Kyung-Min Kim"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.11294"
  },
  {
    "id": "arXiv:2111.11840",
    "title": "Local Permutation Equivariance For Graph Neural Networks",
    "abstract": "Comments: Permutation equivariant update function on sub-graphs",
    "descriptor": "\nComments: Permutation equivariant update function on sub-graphs\n",
    "authors": [
      "Joshua Mitton",
      "Roderick Murray-Smith"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.11840"
  },
  {
    "id": "arXiv:2111.12533",
    "title": "Tight bounds on the expected number of holes in random point sets",
    "abstract": "Tight bounds on the expected number of holes in random point sets",
    "descriptor": "",
    "authors": [
      "Martin Balko",
      "Manfred Scheucher",
      "Pavel Valtr"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Computational Geometry (cs.CG)",
      "Discrete Mathematics (cs.DM)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2111.12533"
  },
  {
    "id": "arXiv:2111.12950",
    "title": "Deep Representation Learning with an Information-theoretic Loss",
    "abstract": "Deep Representation Learning with an Information-theoretic Loss",
    "descriptor": "",
    "authors": [
      "Shin Ando"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.12950"
  },
  {
    "id": "arXiv:2111.13164",
    "title": "L\u00e9vy Induced Stochastic Differential Equation Equipped with Neural  Network for Time Series Forecasting",
    "abstract": "Comments: 20 pages, 41 figures",
    "descriptor": "\nComments: 20 pages, 41 figures\n",
    "authors": [
      "Luxuan Yang",
      "Ting Gao",
      "Yubin Lu",
      "Jinqiao Duan",
      "Tao Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Mathematical Finance (q-fin.MF)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.13164"
  },
  {
    "id": "arXiv:2112.01126",
    "title": "Situation-Aware Environment Perception Using a Multi-Layer Attention Map",
    "abstract": "Comments: Submitted to review and possible publication. Copyright will be transferred without notice Update: Removed minor typos, corrected FKZ",
    "descriptor": "\nComments: Submitted to review and possible publication. Copyright will be transferred without notice Update: Removed minor typos, corrected FKZ\n",
    "authors": [
      "Matti Henning",
      "Johannes M\u00fcller",
      "Fabian Gies",
      "Michael Buchholz",
      "Klaus Dietmayer"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2112.01126"
  },
  {
    "id": "arXiv:2112.02906",
    "title": "ALIKE: Accurate and Lightweight Keypoint Detection and Descriptor  Extraction",
    "abstract": "Comments: 11 pages, 11 figures",
    "descriptor": "\nComments: 11 pages, 11 figures\n",
    "authors": [
      "Xiaoming Zhao",
      "Xingming Wu",
      "Jinyu Miao",
      "Weihai Chen",
      "Peter C. Y. Chen",
      "Zhengguo Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.02906"
  },
  {
    "id": "arXiv:2112.03405",
    "title": "A Novel Deep Parallel Time-series Relation Network for Fault Diagnosis",
    "abstract": "A Novel Deep Parallel Time-series Relation Network for Fault Diagnosis",
    "descriptor": "",
    "authors": [
      "Chun Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.03405"
  },
  {
    "id": "arXiv:2112.04482",
    "title": "FLAVA: A Foundational Language And Vision Alignment Model",
    "abstract": "Comments: 18 pages",
    "descriptor": "\nComments: 18 pages\n",
    "authors": [
      "Amanpreet Singh",
      "Ronghang Hu",
      "Vedanuj Goswami",
      "Guillaume Couairon",
      "Wojciech Galuba",
      "Marcus Rohrbach",
      "Douwe Kiela"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.04482"
  },
  {
    "id": "arXiv:2112.05537",
    "title": "From Modular Decomposition Trees to Level-1 Networks: Pseudo-Cographs,  Polar-Cats and Prime Polar-Cats",
    "abstract": "From Modular Decomposition Trees to Level-1 Networks: Pseudo-Cographs,  Polar-Cats and Prime Polar-Cats",
    "descriptor": "",
    "authors": [
      "Marc Hellmuth",
      "Guillaume E. Scholz"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2112.05537"
  },
  {
    "id": "arXiv:2112.05632",
    "title": "Truthful Cake Sharing",
    "abstract": "Comments: Appears in the 36th AAAI Conference on Artificial Intelligence (AAAI), 2022",
    "descriptor": "\nComments: Appears in the 36th AAAI Conference on Artificial Intelligence (AAAI), 2022\n",
    "authors": [
      "Xiaohui Bei",
      "Xinhang Lu",
      "Warut Suksompong"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Theoretical Economics (econ.TH)"
    ],
    "url": "https://arxiv.org/abs/2112.05632"
  },
  {
    "id": "arXiv:2112.05977",
    "title": "Test Set Sizing Via Random Matrix Theory",
    "abstract": "Test Set Sizing Via Random Matrix Theory",
    "descriptor": "",
    "authors": [
      "Alexander Dubbs"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2112.05977"
  },
  {
    "id": "arXiv:2112.05997",
    "title": "Delay Function with Fixed Effort Verification",
    "abstract": "Delay Function with Fixed Effort Verification",
    "descriptor": "",
    "authors": [
      "Souvik Sur"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2112.05997"
  },
  {
    "id": "arXiv:2112.06096",
    "title": "Selecting Parallel In-domain Sentences for Neural Machine Translation  Using Monolingual Texts",
    "abstract": "Comments: Accepted to the CLIN Journal on Dec 6, 2021 (Camera-ready Version)",
    "descriptor": "\nComments: Accepted to the CLIN Journal on Dec 6, 2021 (Camera-ready Version)\n",
    "authors": [
      "Javad Pourmostafa Roshan Sharami",
      "Dimitar Shterionov",
      "Pieter Spronck"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.06096"
  },
  {
    "id": "arXiv:2112.06406",
    "title": "Hybrid Atlas Building with Deep Registration Priors",
    "abstract": "Hybrid Atlas Building with Deep Registration Priors",
    "descriptor": "",
    "authors": [
      "Nian Wu",
      "Jian Wang",
      "Miaomiao Zhang",
      "Guixu Zhang",
      "Yaxin Peng",
      "Chaomin Shen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.06406"
  },
  {
    "id": "arXiv:2112.07252",
    "title": "A Deep Knowledge Distillation framework for EEG assisted enhancement of  single-lead ECG based sleep staging",
    "abstract": "Comments: Preprint Only",
    "descriptor": "\nComments: Preprint Only\n",
    "authors": [
      "Vaibhav Joshi",
      "Sricharan Vijayarangan",
      "Preejith SP",
      "Mohanasankar Sivaprakasam"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.07252"
  },
  {
    "id": "arXiv:2112.07467",
    "title": "AI Ethics Principles in Practice: Perspectives of Designers and  Developers",
    "abstract": "AI Ethics Principles in Practice: Perspectives of Designers and  Developers",
    "descriptor": "",
    "authors": [
      "Conrad Sanderson",
      "David Douglas",
      "Qinghua Lu",
      "Emma Schleiger",
      "Jon Whittle",
      "Justine Lacey",
      "Glenn Newnham",
      "Stefan Hajkowicz",
      "Cathy Robinson",
      "David Hansen"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.07467"
  },
  {
    "id": "arXiv:2112.07668",
    "title": "Dual-Key Multimodal Backdoors for Visual Question Answering",
    "abstract": "Comments: 22 pages, 11 figures, 12 tables",
    "descriptor": "\nComments: 22 pages, 11 figures, 12 tables\n",
    "authors": [
      "Matthew Walmer",
      "Karan Sikka",
      "Indranil Sur",
      "Abhinav Shrivastava",
      "Susmit Jha"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.07668"
  },
  {
    "id": "arXiv:2112.08569",
    "title": "Toward Imagined Speech based Smart Communication System: Potential  Applications on Metaverse Conditions",
    "abstract": "Comments: Submitted to 2022 10th IEEE International Winter Conference on Brain-Computer Interface",
    "descriptor": "\nComments: Submitted to 2022 10th IEEE International Winter Conference on Brain-Computer Interface\n",
    "authors": [
      "Seo-Hyun Lee",
      "Young-Eun Lee",
      "Seong-Whan Lee"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2112.08569"
  },
  {
    "id": "arXiv:2112.08991",
    "title": "ADBCMM : Acronym Disambiguation by Building Counterfactuals and  Multilingual Mixing",
    "abstract": "Comments: SDU@AAAI-2022",
    "descriptor": "\nComments: SDU@AAAI-2022\n",
    "authors": [
      "Yixuan Weng",
      "Fei Xia",
      "Bin Li",
      "Xiusheng Huang",
      "Shizhu He"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.08991"
  },
  {
    "id": "arXiv:2112.09243",
    "title": "Confidence-Aware Subject-to-Subject Transfer Learning for Brain-Computer  Interface",
    "abstract": "Comments: Submitted to 2022 10th IEEE International Winter Conference on Brain-Computer Interface",
    "descriptor": "\nComments: Submitted to 2022 10th IEEE International Winter Conference on Brain-Computer Interface\n",
    "authors": [
      "Dong-Kyun Han",
      "Serkan Musellim",
      "Dong-Young Kim",
      "Ji-Hoon Jeong"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2112.09243"
  },
  {
    "id": "arXiv:2112.09397",
    "title": "Semi-Supervised Clustering via Information-Theoretic Markov Chain  Aggregation",
    "abstract": "Comments: 13 pages, 6 figures; this is an extended version of a short paper accepted at ACM SAC 2022 (minor changes to the text; error in source code corrected)",
    "descriptor": "\nComments: 13 pages, 6 figures; this is an extended version of a short paper accepted at ACM SAC 2022 (minor changes to the text; error in source code corrected)\n",
    "authors": [
      "Sophie Steger",
      "Bernhard C. Geiger",
      "Marek Smieja"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.09397"
  },
  {
    "id": "arXiv:2112.10680",
    "title": "Towards a Principled Learning Rate Adaptation for Natural Evolution  Strategies",
    "abstract": "Comments: accepted at EvoApplications2022",
    "descriptor": "\nComments: accepted at EvoApplications2022\n",
    "authors": [
      "Masahiro Nomura",
      "Isao Ono"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2112.10680"
  },
  {
    "id": "arXiv:2112.10769",
    "title": "Logarithmic Unbiased Quantization: Simple 4-bit Training in Deep  Learning",
    "abstract": "Logarithmic Unbiased Quantization: Simple 4-bit Training in Deep  Learning",
    "descriptor": "",
    "authors": [
      "Brian Chmiel",
      "Ron Banner",
      "Elad Hoffer",
      "Hilla Ben Yaacov",
      "Daniel Soudry"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.10769"
  },
  {
    "id": "arXiv:2112.10885",
    "title": "PRONTO: Preamble Overhead Reduction with Neural Networks for Coarse  Synchronization",
    "abstract": "PRONTO: Preamble Overhead Reduction with Neural Networks for Coarse  Synchronization",
    "descriptor": "",
    "authors": [
      "Nasim Soltani",
      "Debashri Roy",
      "Kaushik Chowdhury"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2112.10885"
  },
  {
    "id": "arXiv:2112.11607",
    "title": "The Complexity of Iterated Reversible Computation",
    "abstract": "Comments: 33 pages, 7 figures. This version adds a polynomial-time solution to the iterated integer interval exchange problem, listed as open in the previous version",
    "descriptor": "\nComments: 33 pages, 7 figures. This version adds a polynomial-time solution to the iterated integer interval exchange problem, listed as open in the previous version\n",
    "authors": [
      "David Eppstein"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Cellular Automata and Lattice Gases (nlin.CG)"
    ],
    "url": "https://arxiv.org/abs/2112.11607"
  },
  {
    "id": "arXiv:2112.11775",
    "title": "Multiple Choice Questions based Multi-Interest Policy Learning for  Conversational Recommendation",
    "abstract": "Comments: Accepted by WWW2022 conference",
    "descriptor": "\nComments: Accepted by WWW2022 conference\n",
    "authors": [
      "Yiming Zhang",
      "Lingfei Wu",
      "Qi Shen",
      "Yitong Pang",
      "Zhihua Wei",
      "Fangli Xu",
      "Bo Long",
      "Jian Pei"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2112.11775"
  },
  {
    "id": "arXiv:2112.12754",
    "title": "Toward a New Science of Common Sense",
    "abstract": "Comments: Initial version published in Proceedings of AAAI-22, the Thirty-Sixth AAAI Conference on Artificial Intelligence. Original version extended slightly to include acknowledgement of more recent work, including new references, and to clarify remarks in a few paragraphs",
    "descriptor": "\nComments: Initial version published in Proceedings of AAAI-22, the Thirty-Sixth AAAI Conference on Artificial Intelligence. Original version extended slightly to include acknowledgement of more recent work, including new references, and to clarify remarks in a few paragraphs\n",
    "authors": [
      "Ronald J. Brachman",
      "Hector J. Levesque"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.12754"
  },
  {
    "id": "arXiv:2112.13097",
    "title": "Faster Rates for Compressed Federated Learning with Client-Variance  Reduction",
    "abstract": "Comments: 44 pages",
    "descriptor": "\nComments: 44 pages\n",
    "authors": [
      "Haoyu Zhao",
      "Konstantin Burlachenko",
      "Zhize Li",
      "Peter Richt\u00e1rik"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Data Structures and Algorithms (cs.DS)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2112.13097"
  },
  {
    "id": "arXiv:2112.13706",
    "title": "Multi-Image Visual Question Answering",
    "abstract": "Multi-Image Visual Question Answering",
    "descriptor": "",
    "authors": [
      "Harsh Raj",
      "Janhavi Dadhania",
      "Akhilesh Bhardwaj",
      "Prabuchandran KJ"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.13706"
  },
  {
    "id": "arXiv:2112.13737",
    "title": "BALanCe: Deep Bayesian Active Learning via Equivalence Class Annealing",
    "abstract": "BALanCe: Deep Bayesian Active Learning via Equivalence Class Annealing",
    "descriptor": "",
    "authors": [
      "Renyu Zhang",
      "Aly A. Khan",
      "Robert L. Grossman",
      "Yuxin Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.13737"
  },
  {
    "id": "arXiv:2112.13926",
    "title": "Resource-Efficient and Delay-Aware Federated Learning Design under Edge  Heterogeneity",
    "abstract": "Comments: This paper is under review for possible publication",
    "descriptor": "\nComments: This paper is under review for possible publication\n",
    "authors": [
      "David Nickel",
      "Frank Po-Chen Lin",
      "Seyyedali Hosseinalipour",
      "Nicolo Michelusi",
      "Christopher G. Brinton"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.13926"
  },
  {
    "id": "arXiv:2112.14006",
    "title": "Multi-Band Wi-Fi Sensing with Matched Feature Granularity",
    "abstract": "Comments: 12 pages, 14 figures",
    "descriptor": "\nComments: 12 pages, 14 figures\n",
    "authors": [
      "Jianyuan Yu",
      "Wang",
      "Toshiaki Koike-Akino",
      "Ye Wang",
      "Philip V. Orlik",
      "R. Michael Buehrer"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2112.14006"
  },
  {
    "id": "arXiv:2112.14090",
    "title": "The full rank condition for sparse random matrices",
    "abstract": "Comments: 46 pages, 3 figures",
    "descriptor": "\nComments: 46 pages, 3 figures\n",
    "authors": [
      "Amin Coja-Oghlan",
      "Pu Gao",
      "Max Hahn-Klimroth",
      "Joon Lee",
      "Noela M\u00fcller",
      "Maurice Rolvien"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2112.14090"
  },
  {
    "id": "arXiv:2112.14582",
    "title": "Polyak-Ruppert-Averaged Q-Learning is Statistically Efficient",
    "abstract": "Polyak-Ruppert-Averaged Q-Learning is Statistically Efficient",
    "descriptor": "",
    "authors": [
      "Xiang Li",
      "Wenhao Yang",
      "Jiadong Liang",
      "Zhihua Zhang",
      "Michael I. Jordan"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.14582"
  },
  {
    "id": "arXiv:2112.15025",
    "title": "Constructing a Good Behavior Basis for Transfer using Generalized Policy  Updates",
    "abstract": "Comments: Published as a conference paper at ICLR 2022",
    "descriptor": "\nComments: Published as a conference paper at ICLR 2022\n",
    "authors": [
      "Safa Alver",
      "Doina Precup"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.15025"
  },
  {
    "id": "arXiv:2201.02135",
    "title": "Deep Reinforcement Learning, a textbook",
    "abstract": "Deep Reinforcement Learning, a textbook",
    "descriptor": "",
    "authors": [
      "Aske Plaat"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.02135"
  },
  {
    "id": "arXiv:2201.02692",
    "title": "Improved Input Reprogramming for GAN Conditioning",
    "abstract": "Comments: 24 pages, 7 figures",
    "descriptor": "\nComments: 24 pages, 7 figures\n",
    "authors": [
      "Tuan Dinh",
      "Daewon Seo",
      "Zhixu Du",
      "Liang Shang",
      "Kangwook Lee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2201.02692"
  },
  {
    "id": "arXiv:2201.04060",
    "title": "VR Viewport Pose Model for Quantifying and Exploiting Frame Correlations",
    "abstract": "Comments: Proceedings of the 2022 IEEE Conference on Computer Communications (INFOCOM), May 2022",
    "descriptor": "\nComments: Proceedings of the 2022 IEEE Conference on Computer Communications (INFOCOM), May 2022\n",
    "authors": [
      "Ying Chen",
      "Hojung Kwon",
      "Hazer Inaltekin",
      "Maria Gorlatova"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2201.04060"
  },
  {
    "id": "arXiv:2201.04426",
    "title": "The Geometry of Navigation Problems",
    "abstract": "Comments: Published in IEEE Transactions on Automatic Control, 21 January 2022",
    "descriptor": "\nComments: Published in IEEE Transactions on Automatic Control, 21 January 2022\n",
    "authors": [
      "Axel Barrau",
      "Silvere Bonnabel"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2201.04426"
  },
  {
    "id": "arXiv:2201.05334",
    "title": "This Must Be the Place: Predicting Engagement of Online Communities in a  Large-scale Distributed Campaign",
    "abstract": "This Must Be the Place: Predicting Engagement of Online Communities in a  Large-scale Distributed Campaign",
    "descriptor": "",
    "authors": [
      "Abraham Israeli",
      "Alexander Kremiansky",
      "Oren Tsur"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2201.05334"
  },
  {
    "id": "arXiv:2201.06126",
    "title": "Solving Inventory Management Problems with Inventory-dynamics-informed  Neural Networks",
    "abstract": "Comments: 34 pages, 5 figures",
    "descriptor": "\nComments: 34 pages, 5 figures\n",
    "authors": [
      "Lucas B\u00f6ttcher",
      "Thomas Asikis",
      "Ioannis Fragkos"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2201.06126"
  },
  {
    "id": "arXiv:2201.06652",
    "title": "Equitable Community Resilience: The Case of Winter Storm Uri in Texas",
    "abstract": "Equitable Community Resilience: The Case of Winter Storm Uri in Texas",
    "descriptor": "",
    "authors": [
      "Ali Nejat",
      "Laura Solitare",
      "Edward Pettitt",
      "Hamed Mohsenian-Rad"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2201.06652"
  },
  {
    "id": "arXiv:2201.06854",
    "title": "Convergence of a robust deep FBSDE method for stochastic control",
    "abstract": "Comments: 26 pages, 4 figures, 3 tables",
    "descriptor": "\nComments: 26 pages, 4 figures, 3 tables\n",
    "authors": [
      "Kristoffer Andersson",
      "Adam Andersson",
      "Cornelis W. Oosterlee"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Numerical Analysis (math.NA)",
      "Probability (math.PR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2201.06854"
  },
  {
    "id": "arXiv:2201.08482",
    "title": "Deep Attention-Based Supernovae Classification of Multi-Band  Light-Curves",
    "abstract": "Comments: Submitted to AJ on 14-Jan-2022",
    "descriptor": "\nComments: Submitted to AJ on 14-Jan-2022\n",
    "authors": [
      "\u00d3scar Pimentel",
      "Pablo A. Est\u00e9vez",
      "Francisco F\u00f6rster"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "High Energy Astrophysical Phenomena (astro-ph.HE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.08482"
  },
  {
    "id": "arXiv:2201.08614",
    "title": "Consumer Fairness in Recommender Systems: Contextualizing Definitions  and Mitigations",
    "abstract": "Comments: Accepted at the 44th European Conference on Information Retrieval (ECIR 2022)",
    "descriptor": "\nComments: Accepted at the 44th European Conference on Information Retrieval (ECIR 2022)\n",
    "authors": [
      "Ludovico Boratto",
      "Gianni Fenu",
      "Mirko Marras",
      "Giacomo Medda"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2201.08614"
  },
  {
    "id": "arXiv:2201.09372",
    "title": "Prioritizing municipal lead mitigation projects as a relaxed knapsack  optimization: a method and case study",
    "abstract": "Comments: 14 pages, 6 figures; fix typos",
    "descriptor": "\nComments: 14 pages, 6 figures; fix typos\n",
    "authors": [
      "Isaac Slavitt"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Optimization and Control (math.OC)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2201.09372"
  },
  {
    "id": "arXiv:2201.09699",
    "title": "EASY: Ensemble Augmented-Shot Y-shaped Learning: State-Of-The-Art  Few-Shot Classification with Simple Ingredients",
    "abstract": "EASY: Ensemble Augmented-Shot Y-shaped Learning: State-Of-The-Art  Few-Shot Classification with Simple Ingredients",
    "descriptor": "",
    "authors": [
      "Yassir Bendou",
      "Yuqing Hu",
      "Raphael Lafargue",
      "Giulia Lioi",
      "Bastien Pasdeloup",
      "St\u00e9phane Pateux",
      "Vincent Gripon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2201.09699"
  },
  {
    "id": "arXiv:2201.09802",
    "title": "Constrained Policy Optimization via Bayesian World Models",
    "abstract": "Constrained Policy Optimization via Bayesian World Models",
    "descriptor": "",
    "authors": [
      "Yarden As",
      "Ilnura Usmanova",
      "Sebastian Curi",
      "Andreas Krause"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2201.09802"
  },
  {
    "id": "arXiv:2201.09865",
    "title": "RePaint: Inpainting using Denoising Diffusion Probabilistic Models",
    "abstract": "Comments: We missed out on other diffusion models that work on inpainting. We corrected that and apologize for this mistake",
    "descriptor": "\nComments: We missed out on other diffusion models that work on inpainting. We corrected that and apologize for this mistake\n",
    "authors": [
      "Andreas Lugmayr",
      "Martin Danelljan",
      "Andres Romero",
      "Fisher Yu",
      "Radu Timofte",
      "Luc Van Gool"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.09865"
  },
  {
    "id": "arXiv:2201.10361",
    "title": "Reinforcement Learning-Based Deadline and Battery-Aware Offloading in  Smart Farm IoT-UAV Networks",
    "abstract": "Comments: Accepted Paper. Please check footnote in Page 1 for copyright",
    "descriptor": "\nComments: Accepted Paper. Please check footnote in Page 1 for copyright\n",
    "authors": [
      "Anne Catherine Nguyen",
      "Turgay Pamuklu",
      "Aisha Syed",
      "W. Sean Kennedy",
      "Melike Erol-Kantarci"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2201.10361"
  },
  {
    "id": "arXiv:2201.10510",
    "title": "Gold Functions and Switched Cube Functions Are Not 0-Extendable in  Dimension $n > 5$",
    "abstract": "Gold Functions and Switched Cube Functions Are Not 0-Extendable in  Dimension $n > 5$",
    "descriptor": "",
    "authors": [
      "Christof Beierle",
      "Claude Carlet"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2201.10510"
  },
  {
    "id": "arXiv:2201.10938",
    "title": "Projective Urban Texturing",
    "abstract": "Projective Urban Texturing",
    "descriptor": "",
    "authors": [
      "Yiangos Georgiou",
      "Melinos Averkiou",
      "Tom Kelly",
      "Evangelos Kalogerakis"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.10938"
  },
  {
    "id": "arXiv:2201.10967",
    "title": "Physics-informed ConvNet: Learning Physical Field from a Shallow Neural  Network",
    "abstract": "Physics-informed ConvNet: Learning Physical Field from a Shallow Neural  Network",
    "descriptor": "",
    "authors": [
      "Pengpeng Shi",
      "Zhi Zeng",
      "Tianshou Liang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2201.10967"
  },
  {
    "id": "arXiv:2201.11412",
    "title": "Reduction of Two-Dimensional Data for Speeding Up Convex Hull  Computation",
    "abstract": "Comments: 11 pages, 5 figures",
    "descriptor": "\nComments: 11 pages, 5 figures\n",
    "authors": [
      "Debashis Mukherjee"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2201.11412"
  },
  {
    "id": "arXiv:2201.11670",
    "title": "Strong Converse Theorem for Source Encryption under Side-Channel Attacks",
    "abstract": "Comments: 9 pages, 6 figures. The short version of this paper was submitted to ISIT2022, arXiv admin note: text overlap with arXiv:1801.02563",
    "descriptor": "\nComments: 9 pages, 6 figures. The short version of this paper was submitted to ISIT2022, arXiv admin note: text overlap with arXiv:1801.02563\n",
    "authors": [
      "Yasutada Oohama",
      "Bagus Santoso"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2201.11670"
  },
  {
    "id": "arXiv:2201.11710",
    "title": "Variable-Length Stop-Feedback Codes With Finite Optimal Decoding Times  for BI-AWGN Channels",
    "abstract": "Comments: 8 pages, 4 figures; fixed some errors in v1 and added some new results; a short version of this preprint was submitted to ISIT 2022",
    "descriptor": "\nComments: 8 pages, 4 figures; fixed some errors in v1 and added some new results; a short version of this preprint was submitted to ISIT 2022\n",
    "authors": [
      "Hengjie Yang",
      "Recep Can Yavas",
      "Victoria Kostina",
      "Richard D. Wesel"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2201.11710"
  },
  {
    "id": "arXiv:2201.11711",
    "title": "Algorithm Selection for Software Verification using Graph Attention  Networks",
    "abstract": "Comments: 29 pages, 7 figures, 5 tables, submitted to ACM Transactions on Software Engineering and Methodology; Updated Symbiotic reference and description in Table 1",
    "descriptor": "\nComments: 29 pages, 7 figures, 5 tables, submitted to ACM Transactions on Software Engineering and Methodology; Updated Symbiotic reference and description in Table 1\n",
    "authors": [
      "Will Leeson",
      "Matthew B Dwyer"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2201.11711"
  },
  {
    "id": "arXiv:2201.11793",
    "title": "Denoising Diffusion Restoration Models",
    "abstract": "Comments: Our code is available at this https URL",
    "descriptor": "\nComments: Our code is available at this https URL\n",
    "authors": [
      "Bahjat Kawar",
      "Michael Elad",
      "Stefano Ermon",
      "Jiaming Song"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.11793"
  },
  {
    "id": "arXiv:2201.11924",
    "title": "Close the Visual Domain Gap by Physics-Grounded Active Stereovision  Depth Sensor Simulation",
    "abstract": "Comments: 20 pages, 15 figures, 10 tables",
    "descriptor": "\nComments: 20 pages, 15 figures, 10 tables\n",
    "authors": [
      "Xiaoshuai Zhang",
      "Rui Chen",
      "Fanbo Xiang",
      "Yuzhe Qin",
      "Jiayuan Gu",
      "Zhan Ling",
      "Minghua Liu",
      "Peiyu Zeng",
      "Songfang Han",
      "Zhiao Huang",
      "Tongzhou Mu",
      "Jing Xu",
      "Hao Su"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2201.11924"
  },
  {
    "id": "arXiv:2201.11928",
    "title": "Quadruped Capturability and Push Recovery via a Switched-Systems  Characterization of Dynamic Balance",
    "abstract": "Quadruped Capturability and Push Recovery via a Switched-Systems  Characterization of Dynamic Balance",
    "descriptor": "",
    "authors": [
      "Hua Chen",
      "Zejun Hong",
      "Shunpeng Yang",
      "Patrick M. Wensing",
      "Wei Zhang"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2201.11928"
  },
  {
    "id": "arXiv:2201.11980",
    "title": "Differential Privacy Guarantees for Stochastic Gradient Langevin  Dynamics",
    "abstract": "Differential Privacy Guarantees for Stochastic Gradient Langevin  Dynamics",
    "descriptor": "",
    "authors": [
      "Th\u00e9o Ryffel",
      "Francis Bach",
      "David Pointcheval"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.11980"
  },
  {
    "id": "arXiv:2201.12038",
    "title": "A survey on flexible/restricted skyline and their applicability",
    "abstract": "A survey on flexible/restricted skyline and their applicability",
    "descriptor": "",
    "authors": [
      "Davide Canali"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2201.12038"
  },
  {
    "id": "arXiv:2201.12240",
    "title": "Mixing Implicit and Explicit Deep Learning with Skip DEQs and Infinite  Time Neural ODEs (Continuous DEQs)",
    "abstract": "Mixing Implicit and Explicit Deep Learning with Skip DEQs and Infinite  Time Neural ODEs (Continuous DEQs)",
    "descriptor": "",
    "authors": [
      "Avik Pal",
      "Alan Edelman",
      "Christopher Rackauckas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2201.12240"
  },
  {
    "id": "arXiv:2201.12242",
    "title": "Large Scale Generation of Labeled Type Data for Python",
    "abstract": "Large Scale Generation of Labeled Type Data for Python",
    "descriptor": "",
    "authors": [
      "Ibrahim Abdelaziz",
      "Julian Dolby",
      "Kavitha Srinivas"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2201.12242"
  },
  {
    "id": "arXiv:2201.12266",
    "title": "Six Questions about 6G",
    "abstract": "Comments: 6 pages, 3 figures, document also available in German, document available in a more attractive format, here: www.thinknet-6g.de",
    "descriptor": "\nComments: 6 pages, 3 figures, document also available in German, document available in a more attractive format, here: www.thinknet-6g.de\n",
    "authors": [
      "Kimberley Parsons Trommler",
      "Matthias Hafner",
      "Wolfgang Kellerer",
      "Peter Merz",
      "Sigurd Schuster",
      "Josef Urban",
      "Uwe Baeder",
      "Bertram Gunzelmann",
      "Andreas Kornbichler"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2201.12266"
  },
  {
    "id": "arXiv:2201.12468",
    "title": "Symbolic-Numeric Integration of Univariate Expressions based on Sparse  Regression",
    "abstract": "Comments: 8 pages. submitted to ISSAC 2022. Code at this https URL",
    "descriptor": "\nComments: 8 pages. submitted to ISSAC 2022. Code at this https URL\n",
    "authors": [
      "Shahriar Iravanian",
      "Carl Julius Martensen",
      "Alessandro Cheli",
      "Shashi Gowda",
      "Anand Jain",
      "Yingbo Ma",
      "Chris Rackauckas"
    ],
    "subjectives": [
      "Symbolic Computation (cs.SC)"
    ],
    "url": "https://arxiv.org/abs/2201.12468"
  },
  {
    "id": "arXiv:2201.12546",
    "title": "Progressive Continual Learning for Spoken Keyword Spotting",
    "abstract": "Comments: ICASSP 2022",
    "descriptor": "\nComments: ICASSP 2022\n",
    "authors": [
      "Yizheng Huang",
      "Nana Hou",
      "Nancy F. Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2201.12546"
  },
  {
    "id": "arXiv:2201.12723",
    "title": "VC-GPT: Visual Conditioned GPT for End-to-End Generative  Vision-and-Language Pre-training",
    "abstract": "Comments: Work in progress",
    "descriptor": "\nComments: Work in progress\n",
    "authors": [
      "Ziyang Luo",
      "Yadong Xi",
      "Rongsheng Zhang",
      "Jing Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2201.12723"
  },
  {
    "id": "arXiv:2201.12746",
    "title": "Efficient Near-Optimal Codes for General Repeat Channels",
    "abstract": "Comments: The prior version incorrectly stated that the constructions of Tal, Pfister and Fazeli require $O(n^4)$ runtime complexity to achieve $e^{-\\Theta(n)}$ decoding failure probability; the corrected result now included achieves a better tradeoff, and is more subtle to state",
    "descriptor": "\nComments: The prior version incorrectly stated that the constructions of Tal, Pfister and Fazeli require $O(n^4)$ runtime complexity to achieve $e^{-\\Theta(n)}$ decoding failure probability; the corrected result now included achieves a better tradeoff, and is more subtle to state\n",
    "authors": [
      "Francisco Pernice",
      "Ray Li",
      "Mary Wootters"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2201.12746"
  },
  {
    "id": "arXiv:2201.12870",
    "title": "General 2-path Problem",
    "abstract": "Comments: 14 pages,3 figures",
    "descriptor": "\nComments: 14 pages,3 figures\n",
    "authors": [
      "Qianghui Xiao"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2201.12870"
  },
  {
    "id": "arXiv:2201.12896",
    "title": "Augmenting Novelty Search with a Surrogate Model to Engineer  Meta-Diversity in Ensembles of Classifiers",
    "abstract": "Comments: 16 pages, 4 figures, 3 tables, EvoStar 2022",
    "descriptor": "\nComments: 16 pages, 4 figures, 3 tables, EvoStar 2022\n",
    "authors": [
      "Rui P. Cardoso",
      "Emma Hart",
      "David Burth Kurka",
      "Jeremy V. Pitt"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2201.12896"
  },
  {
    "id": "arXiv:2201.12898",
    "title": "Clearing Payments in Dynamic Financial Networks",
    "abstract": "Clearing Payments in Dynamic Financial Networks",
    "descriptor": "",
    "authors": [
      "Giuseppe C. Calafiore",
      "Giulia Fracastoro",
      "Anton V. Proskurnikov"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Systems and Control (eess.SY)",
      "Mathematical Finance (q-fin.MF)",
      "Risk Management (q-fin.RM)"
    ],
    "url": "https://arxiv.org/abs/2201.12898"
  },
  {
    "id": "arXiv:2201.13001",
    "title": "Out-of-distribution Detection Using Kernel Density Polytopes",
    "abstract": "Out-of-distribution Detection Using Kernel Density Polytopes",
    "descriptor": "",
    "authors": [
      "Jayanta Dey",
      "Ashwin De Silva",
      "Will LeVine",
      "Jong M. Shin",
      "Haoyin Xu",
      "Ali Geisa",
      "Tiffany Chu",
      "Leyla Isik",
      "Joshua T. Vogelstein"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Data Structures and Algorithms (cs.DS)",
      "Neurons and Cognition (q-bio.NC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2201.13001"
  },
  {
    "id": "arXiv:2201.13013",
    "title": "Filtering In Neural Implicit Functions",
    "abstract": "Comments: 8 pages, 9 figures",
    "descriptor": "\nComments: 8 pages, 9 figures\n",
    "authors": [
      "Yixin Zhuang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.13013"
  },
  {
    "id": "arXiv:2201.13106",
    "title": "Computational Complexity of Segmentation",
    "abstract": "Computational Complexity of Segmentation",
    "descriptor": "",
    "authors": [
      "Federico Adolfi",
      "Todd Wareham",
      "Iris van Rooij"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computational Complexity (cs.CC)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2201.13106"
  },
  {
    "id": "arXiv:2201.13114",
    "title": "An end-to-end deep learning approach for extracting stochastic dynamical  systems with $\u03b1$-stable L\u00e9vy noise",
    "abstract": "Comments: 19 pages,12 figures",
    "descriptor": "\nComments: 19 pages,12 figures\n",
    "authors": [
      "Cheng Fang",
      "Yubin Lu",
      "Ting Gao",
      "Jinqiao Duan"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.13114"
  },
  {
    "id": "arXiv:2201.13180",
    "title": "Learning on Arbitrary Graph Topologies via Predictive Coding",
    "abstract": "Comments: 15 pages, 11 figures",
    "descriptor": "\nComments: 15 pages, 11 figures\n",
    "authors": [
      "Tommaso Salvatori",
      "Luca Pinchetti",
      "Beren Millidge",
      "Yuhang Song",
      "Tianyi Bao",
      "Rafal Bogacz",
      "Thomas Lukasiewicz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.13180"
  },
  {
    "id": "arXiv:2201.13272",
    "title": "Output-Feedback Control of Viscous Liquid-Tank System and its Numerical  Approximation",
    "abstract": "Comments: 35 pages, 4 figures, submitted to Automatica for possible publication. arXiv admin note: text overlap with arXiv:2108.11052",
    "descriptor": "\nComments: 35 pages, 4 figures, submitted to Automatica for possible publication. arXiv admin note: text overlap with arXiv:2108.11052\n",
    "authors": [
      "Iasson Karafyllis",
      "Filippos Vokos",
      "Miroslav Krstic"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)",
      "Analysis of PDEs (math.AP)",
      "Numerical Analysis (math.NA)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2201.13272"
  },
  {
    "id": "arXiv:2201.13357",
    "title": "DNS: Determinantal Point Process Based Neural Network Sampler for  Ensemble Reinforcement Learning",
    "abstract": "DNS: Determinantal Point Process Based Neural Network Sampler for  Ensemble Reinforcement Learning",
    "descriptor": "",
    "authors": [
      "Hassam Sheikh",
      "Kizza Frisbee",
      "Mariano Phielipp"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.13357"
  },
  {
    "id": "arXiv:2201.13392",
    "title": "MHSnet: Multi-head and Spatial Attention Network with False-Positive  Reduction for Pulmonary Nodules Detection",
    "abstract": "MHSnet: Multi-head and Spatial Attention Network with False-Positive  Reduction for Pulmonary Nodules Detection",
    "descriptor": "",
    "authors": [
      "Juanyun Mai",
      "Minghao Wang",
      "Jiayin Zheng",
      "Yanbo Shao",
      "Zhaoqi Diao",
      "Xinliang Fu",
      "Yulong Chen",
      "Jianyu Xiao",
      "Jian You",
      "Airu Yin",
      "Yang Yang",
      "Xiangcheng Qiu",
      "Jinsheng Tao",
      "Bo Wang",
      "Hua Ji"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.13392"
  },
  {
    "id": "arXiv:2202.00120",
    "title": "QALD-9-plus: A Multilingual Dataset for Question Answering over DBpedia  and Wikidata Translated by Native Speakers",
    "abstract": "QALD-9-plus: A Multilingual Dataset for Question Answering over DBpedia  and Wikidata Translated by Native Speakers",
    "descriptor": "",
    "authors": [
      "Aleksandr Perevalov",
      "Dennis Diefenbach",
      "Ricardo Usbeck",
      "Andreas Both"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2202.00120"
  },
  {
    "id": "arXiv:2202.00543",
    "title": "Testability and local certification of monotone properties in  minor-closed classes",
    "abstract": "Comments: 14 pages v2: local certification result extended to classes of bounded asymptotic dimension",
    "descriptor": "\nComments: 14 pages v2: local certification result extended to classes of bounded asymptotic dimension\n",
    "authors": [
      "Louis Esperet",
      "Sergey Norin"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2202.00543"
  },
  {
    "id": "arXiv:2202.00619",
    "title": "Insights into the Core of the Assignment Game via Complementarity",
    "abstract": "Comments: 10 pages",
    "descriptor": "\nComments: 10 pages\n",
    "authors": [
      "Vijay V. Vazirani"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Data Structures and Algorithms (cs.DS)",
      "Theoretical Economics (econ.TH)"
    ],
    "url": "https://arxiv.org/abs/2202.00619"
  },
  {
    "id": "arXiv:2202.00648",
    "title": "Evidence for Super-Polynomial Advantage of QAOA over Unstructured Search",
    "abstract": "Evidence for Super-Polynomial Advantage of QAOA over Unstructured Search",
    "descriptor": "",
    "authors": [
      "John Golden",
      "Andreas B\u00e4rtschi",
      "Stephan Eidenbenz",
      "Daniel O'Malley"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2202.00648"
  },
  {
    "id": "arXiv:2202.00842",
    "title": "Streaming Multi-Talker ASR with Token-Level Serialized Output Training",
    "abstract": "Streaming Multi-Talker ASR with Token-Level Serialized Output Training",
    "descriptor": "",
    "authors": [
      "Naoyuki Kanda",
      "Jian Wu",
      "Yu Wu",
      "Xiong Xiao",
      "Zhong Meng",
      "Xiaofei Wang",
      "Yashesh Gaur",
      "Zhuo Chen",
      "Jinyu Li",
      "Takuya Yoshioka"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2202.00842"
  },
  {
    "id": "arXiv:2202.00964",
    "title": "Understanding Knowledge Integration in Language Models with Graph  Convolutions",
    "abstract": "Comments: Code is available: this https URL",
    "descriptor": "\nComments: Code is available: this https URL\n",
    "authors": [
      "Yifan Hou",
      "Guoji Fu",
      "Mrinmaya Sachan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.00964"
  },
  {
    "id": "arXiv:2202.01059",
    "title": "PINNs and GaLS: An Priori Error Estimates for Shallow Physically  Informed Neural Network Applied to Elliptic Problems",
    "abstract": "Comments: This work has been submitted to IFAC for possible publication",
    "descriptor": "\nComments: This work has been submitted to IFAC for possible publication\n",
    "authors": [
      "Umberto Zerbinati"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.01059"
  },
  {
    "id": "arXiv:2202.01094",
    "title": "RescoreBERT: Discriminative Speech Recognition Rescoring with BERT",
    "abstract": "Comments: Accepted to ICASSP 2022",
    "descriptor": "\nComments: Accepted to ICASSP 2022\n",
    "authors": [
      "Liyan Xu",
      "Yile Gu",
      "Jari Kolehmainen",
      "Haidar Khan",
      "Ankur Gandhe",
      "Ariya Rastrow",
      "Andreas Stolcke",
      "Ivan Bulyko"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2202.01094"
  },
  {
    "id": "arXiv:2202.01112",
    "title": "On Joint Communication and Channel Discrimination",
    "abstract": "On Joint Communication and Channel Discrimination",
    "descriptor": "",
    "authors": [
      "Han Wu",
      "Hamdi Joudeh"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.01112"
  },
  {
    "id": "arXiv:2202.01121",
    "title": "Decentralized Matching in Shared Intelligent Vehicles Fleet",
    "abstract": "Comments: authors note: the overlap has been removed in the revised version (Jan 7, 2022); arXiv admin note: text overlap with arXiv:2104.10022",
    "descriptor": "\nComments: authors note: the overlap has been removed in the revised version (Jan 7, 2022); arXiv admin note: text overlap with arXiv:2104.10022\n",
    "authors": [
      "Seyed Mehdi Meshkani",
      "Bilal Farooq"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2202.01121"
  },
  {
    "id": "arXiv:2202.01210",
    "title": "Deep Layer-wise Networks Have Closed-Form Weights",
    "abstract": "Comments: Since this version is similar to an older version, I should have updated the older version instead of creating a new version. I will now retract this version, and update a previous version to this",
    "descriptor": "\nComments: Since this version is similar to an older version, I should have updated the older version instead of creating a new version. I will now retract this version, and update a previous version to this\n",
    "authors": [
      "Chieh Wu",
      "Aria Masoomi",
      "Arthur Gretton",
      "Jennifer Dy"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2202.01210"
  },
  {
    "id": "arXiv:2202.01331",
    "title": "Fast Convex Optimization for Two-Layer ReLU Networks: Equivalent Model  Classes and Cone Decompositions",
    "abstract": "Comments: Update fixes Figure 2, several typos",
    "descriptor": "\nComments: Update fixes Figure 2, several typos\n",
    "authors": [
      "Aaron Mishkin",
      "Arda Sahiner",
      "Mert Pilanci"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.01331"
  },
  {
    "id": "arXiv:2202.01389",
    "title": "An Empirical Review of Optimization Techniques for Quantum Variational  Circuits",
    "abstract": "Comments: 13 pages, 4 figures",
    "descriptor": "\nComments: 13 pages, 4 figures\n",
    "authors": [
      "Owen Lockwood"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.01389"
  },
  {
    "id": "arXiv:2202.01587",
    "title": "MiDaS: Representative Sampling from Real-world Hypergraphs",
    "abstract": "Comments: Accepted to WWW 2022 - The Web Conference 2022",
    "descriptor": "\nComments: Accepted to WWW 2022 - The Web Conference 2022\n",
    "authors": [
      "Minyoung Choe",
      "Jaemin Yoo",
      "Geon Lee",
      "Woonsung Baek",
      "U Kang",
      "Kijung Shin"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2202.01587"
  },
  {
    "id": "arXiv:2202.01761",
    "title": "On expressive rule-based logics",
    "abstract": "Comments: Changes to the original version: general fixes and restructuring. Also clarifications and a reference added",
    "descriptor": "\nComments: Changes to the original version: general fixes and restructuring. Also clarifications and a reference added\n",
    "authors": [
      "Antti Kuusisto"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2202.01761"
  },
  {
    "id": "arXiv:2202.01824",
    "title": "Waveform inversion via reduced order modeling",
    "abstract": "Waveform inversion via reduced order modeling",
    "descriptor": "",
    "authors": [
      "Liliana Borcea",
      "Josselin Garnier",
      "Alexander V. Mamonov",
      "J\u00f6rn Zimmerling"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Geophysics (physics.geo-ph)"
    ],
    "url": "https://arxiv.org/abs/2202.01824"
  },
  {
    "id": "arXiv:2202.01841",
    "title": "Transport Score Climbing: Variational Inference Using Forward KL and  Adaptive Neural Transport",
    "abstract": "Comments: 14 pages, 8 figures",
    "descriptor": "\nComments: 14 pages, 8 figures\n",
    "authors": [
      "Liyi Zhang",
      "Christian A. Naesseth",
      "David M. Blei"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2202.01841"
  },
  {
    "id": "arXiv:2202.02006",
    "title": "5G Network on Wings: A Deep Reinforcement Learning Approach to UAV-based  Integrated Access and Backhaul",
    "abstract": "5G Network on Wings: A Deep Reinforcement Learning Approach to UAV-based  Integrated Access and Backhaul",
    "descriptor": "",
    "authors": [
      "Hongyi Zhang",
      "Jingya Li",
      "Zhiqiang Qi",
      "Xingqin Lin",
      "Anders Aronsson",
      "Jan Bosch",
      "Helena Holmstr\u00f6m Olsson"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.02006"
  },
  {
    "id": "arXiv:2202.02085",
    "title": "SignSGD: Fault-Tolerance to Blind and Byzantine Adversaries",
    "abstract": "Comments: this https URL",
    "descriptor": "\nComments: this https URL\n",
    "authors": [
      "Jason Akoun",
      "Sebastien Meyer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.02085"
  },
  {
    "id": "arXiv:2202.02163",
    "title": "COIL: Constrained Optimization in Learned Latent Space -- Learning  Representations for Valid Solutions",
    "abstract": "Comments: 10 pages",
    "descriptor": "\nComments: 10 pages\n",
    "authors": [
      "Peter J Bentley",
      "Soo Ling Lim",
      "Adam Gaier",
      "Linh Tran"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.02163"
  },
  {
    "id": "arXiv:2202.02188",
    "title": "Koopman von Neumann mechanics and the Koopman representation: A  perspective on solving nonlinear dynamical systems with quantum computers",
    "abstract": "Comments: 23 pages, 12 figures",
    "descriptor": "\nComments: 23 pages, 12 figures\n",
    "authors": [
      "Yen Ting Lin",
      "Robert B. Lowrie",
      "Denis Aslangil",
      "Yi\u011fit Suba\u015f\u0131",
      "Andrew T. Sornborger"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Data Structures and Algorithms (cs.DS)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2202.02188"
  }
]
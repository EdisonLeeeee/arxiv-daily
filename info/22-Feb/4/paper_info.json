[
  {
    "id": "arXiv:2202.01211",
    "title": "A Flexible Clustering Pipeline for Mining Text Intentions",
    "abstract": "Mining the latent intentions from large volumes of natural language inputs is\na key step to help data analysts design and refine Intelligent Virtual\nAssistants (IVAs) for customer service and sales support. We created a flexible\nand scalable clustering pipeline within the Verint Intent Manager (VIM) that\nintegrates the fine-tuning of language models, a high performing k-NN library\nand community detection techniques to help analysts quickly surface and\norganize relevant user intentions from conversational texts. The fine-tuning\nstep is necessary because pre-trained language models cannot encode texts to\nefficiently surface particular clustering structures when the target texts are\nfrom an unseen domain or the clustering task is not topic detection. We\ndescribe the pipeline and demonstrate its performance using BERT on three\nreal-world text mining tasks. As deployed in the VIM application, this\nclustering pipeline produces high quality results, improving the performance of\ndata analysts and reducing the time it takes to surface intentions from\ncustomer service data, thereby reducing the time it takes to build and deploy\nIVAs in new domains.",
    "descriptor": "\nComments: Submitted to WWW '22: The Web Conference 2022. arXiv admin note: substantial text overlap with arXiv:2202.00802\n",
    "authors": [
      "Xinyu Chen",
      "Ian Beaver"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.01211"
  },
  {
    "id": "arXiv:2202.01212",
    "title": "Training Semantic Descriptors for Image-Based Localization",
    "abstract": "Vision based solutions for the localization of vehicles have become popular\nrecently. We employ an image retrieval based visual localization approach. The\ndatabase images are kept with GPS coordinates and the location of the retrieved\ndatabase image serves as an approximate position of the query image. We show\nthat localization can be performed via descriptors solely extracted from\nsemantically segmented images. It is reliable especially when the environment\nis subjected to severe illumination and seasonal changes. Our experiments\nreveal that the localization performance of a semantic descriptor can increase\nup to the level of state-of-the-art RGB image based methods.",
    "descriptor": "\nComments: 4 pages, 4 figures, Accepted and Presented at Workshop on Perception for Autonomous Driving (PAD) / ECCV 2020\n",
    "authors": [
      "Ibrahim Cinaroglu",
      "Yalin Bastanlar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2202.01212"
  },
  {
    "id": "arXiv:2202.01214",
    "title": "Approximate Bisimulation Relations for Neural Networks and Application  to Assured Neural Network Compression",
    "abstract": "In this paper, we propose a concept of approximate bisimulation relation for\nfeedforward neural networks. In the framework of approximate bisimulation\nrelation, a novel neural network merging method is developed to compute the\napproximate bisimulation error between two neural networks based on\nreachability analysis of neural networks. The developed method is able to\nquantitatively measure the distance between the outputs of two neural networks\nwith the same inputs. Then, we apply the approximate bisimulation relation\nresults to perform neural networks model reduction and compute the compression\nprecision, i.e., assured neural networks compression. At last, using the\nassured neural network compression, we accelerate the verification processes of\nACAS Xu neural networks to illustrate the effectiveness and advantages of our\nproposed approximate bisimulation approach.",
    "descriptor": "",
    "authors": [
      "Weiming Xiang",
      "Zhongzhu Shao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.01214"
  },
  {
    "id": "arXiv:2202.01246",
    "title": "PolarDenseNet: A Deep Learning Model for CSI Feedback in MIMO Systems",
    "abstract": "In multiple-input multiple-output (MIMO) systems, the high-resolution channel\ninformation (CSI) is required at the base station (BS) to ensure optimal\nperformance, especially in the case of multi-user MIMO (MU-MIMO) systems. In\nthe absence of channel reciprocity in frequency division duplex (FDD) systems,\nthe user needs to send the CSI to the BS. Often the large overhead associated\nwith this CSI feedback in FDD systems becomes the bottleneck in improving the\nsystem performance. In this paper, we propose an AI-based CSI feedback based on\nan auto-encoder architecture that encodes the CSI at UE into a low-dimensional\nlatent space and decodes it back at the BS by effectively reducing the feedback\noverhead while minimizing the loss during recovery. Our simulation results show\nthat the AI-based proposed architecture outperforms the state-of-the-art\nhigh-resolution linear combination codebook using the DFT basis adopted in the\n5G New Radio (NR) system.",
    "descriptor": "",
    "authors": [
      "Pranav Madadi",
      "Jeongho Jeon",
      "Joonyoung Cho",
      "Caleb Lo",
      "Juho Lee",
      "Jianzhong Zhang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.01246"
  },
  {
    "id": "arXiv:2202.01248",
    "title": "Passing the Limits of Pure Local Search for the Maximum Weight  Independent Set Problem in d-Claw Free Graphs",
    "abstract": "In this paper, we consider the task of computing an independent set of\nmaximum weight in a given $d$-claw free graph $G=(V,E)$ equipped with a\npositive weight function $w:V\\rightarrow\\mathbb{R}_{>0}$. Recently, Neuwohner\nhas shown how to obtain approximation ratios of $\\frac{d-1+\\epsilon_d}{2}$ in\nquasi-polynomial time, where $0\\leq \\epsilon_d\\leq 1$ and\n$\\lim_{d\\rightarrow\\infty}\\epsilon_d = 0$. For the special case of the\n$d-1$-Set Packing Problem, she showed how to get down to a polynomial running\ntime. On the other hand, she provided examples showing that no local\nimprovement algorithm considering local improvements of logarithmic size can\nyield an approximation guarantee better than $\\frac{d-1}{2}$. However, it turns\nout that if one considers local improvements that arise by dropping vertex\nweights and running an algorithm devised for the unweighted setting on certain\nsub-instances of the given one, one can get beyond the\n$\\frac{d-1}{2}$-threshold and obtain approximation guarantees of\n$\\frac{d}{2}-\\Omega(d)$ in quasi-polynomial time. For $d-1$-Set Packing\ninstances, we can guarantee a polynomial running time.\nWe also conduct a more general investigation of the relation between\napproximation guarantees for the unweighted and weighted variants of both the\nMaximum Weight Independent Set Problem in $d$-claw free graphs and the\n$d-1$-Set Packing problem. In doing so, we can show that for any constant\n$\\sigma > 0$, there exists a constant $\\tau > 0$ such that a (quasi-)polynomial\ntime $1+\\tau\\cdot (d-2)$-approximation for the unweighted $d-1$-Set Packing\nProblem (the Maximum Cardinality Independent Set problem in $d$-claw free\ngraphs) implies a (quasi-)-polynomial time $1+\\sigma\\cdot (d-2)$-approximation\nfor the weighted $d-1$-Set Packing Problem (the Maximum Weight Independent Set\nproblem in $d$-claw free graphs).",
    "descriptor": "\nComments: 51 pages, 4 figures, 1 table. arXiv admin note: substantial text overlap with arXiv:2106.03555, arXiv:2106.03545\n",
    "authors": [
      "Meike Neuwohner"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2202.01248"
  },
  {
    "id": "arXiv:2202.01252",
    "title": "Speaker Normalization for Self-supervised Speech Emotion Recognition",
    "abstract": "Large speech emotion recognition datasets are hard to obtain, and small\ndatasets may contain biases. Deep-net-based classifiers, in turn, are prone to\nexploit those biases and find shortcuts such as speaker characteristics. These\nshortcuts usually harm a model's ability to generalize. To address this\nchallenge, we propose a gradient-based adversary learning framework that learns\na speech emotion recognition task while normalizing speaker characteristics\nfrom the feature representation. We demonstrate the efficacy of our method on\nboth speaker-independent and speaker-dependent settings and obtain new\nstate-of-the-art results on the challenging IEMOCAP dataset.",
    "descriptor": "",
    "authors": [
      "Itai Gat",
      "Hagai Aronowitz",
      "Weizhong Zhu",
      "Edmilson Morais",
      "Ron Hoory"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.01252"
  },
  {
    "id": "arXiv:2202.01256",
    "title": "Introduction to The Dynamic Pickup and Delivery Problem Benchmark --  ICAPS 2021 Competition",
    "abstract": "The Dynamic Pickup and Delivery Problem (DPDP) is an essential problem within\nthe logistics domain. So far, research on this problem has mainly focused on\nusing artificial data which fails to reflect the complexity of real-world\nproblems. In this draft, we would like to introduce a new benchmark from real\nbusiness scenarios as well as a simulator supporting the dynamic evaluation.\nThe benchmark and simulator have been published and successfully supported the\nICAPS 2021 Dynamic Pickup and Delivery Problem competition participated by 152\nteams.",
    "descriptor": "",
    "authors": [
      "Jianye Hao",
      "Jiawen Lu",
      "Xijun Li",
      "Xialiang Tong",
      "Xiang Xiang",
      "Mingxuan Yuan",
      "Hankz Hankui Zhuo"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.01256"
  },
  {
    "id": "arXiv:2202.01258",
    "title": "Accelerated Quality-Diversity for Robotics through Massive Parallelism",
    "abstract": "Quality-Diversity (QD) algorithms are a well-known approach to generate large\ncollections of diverse and high-quality policies. However, QD algorithms are\nalso known to be data-inefficient, requiring large amounts of computational\nresources and are slow when used in practice for robotics tasks. Policy\nevaluations are already commonly performed in parallel to speed up QD\nalgorithms but have limited capabilities on a single machine as most physics\nsimulators run on CPUs. With recent advances in simulators that run on\naccelerators, thousands of evaluations can performed in parallel on single\nGPU/TPU. In this paper, we present QDax, an implementation of MAP-Elites which\nleverages massive parallelism on accelerators to make QD algorithms more\naccessible. We first demonstrate the improvements on the number of evaluations\nper second that parallelism using accelerated simulators can offer. More\nimportantly, we show that QD algorithms are ideal candidates and can scale with\nmassive parallelism to be run at interactive timescales. The increase in\nparallelism does not significantly affect the performance of QD algorithms,\nwhile reducing experiment runtimes by two factors of magnitudes, turning days\nof computation into minutes. These results show that QD can now benefit from\nhardware acceleration, which contributed significantly to the bloom of deep\nlearning.",
    "descriptor": "",
    "authors": [
      "Bryan Lim",
      "Maxime Allard",
      "Luca Grillotti",
      "Antoine Cully"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.01258"
  },
  {
    "id": "arXiv:2202.01260",
    "title": "Shannon Bounds on Lossy Gray-Wyner Networks",
    "abstract": "The Gray-Wyner network subject to a fidelity criterion is studied. Upper and\nlower bounds for the trade-offs between the private sum-rate and the common\nrate are obtained for arbitrary sources subject to mean-squared error\ndistortion. The bounds meet exactly, leading to the computation of the rate\nregion, when the source is jointly Gaussian. They meet partially when the\nsources are modeled via an additive Gaussian \"channel\". The bounds are inspired\nfrom the Shannon bounds on the rate-distortion problem.",
    "descriptor": "\nComments: 6 pages, 2 figures\n",
    "authors": [
      "Erixhen Sula",
      "Michael Gastpar"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.01260"
  },
  {
    "id": "arXiv:2202.01261",
    "title": "Efficient Memory Partitioning in Software Defined Hardware",
    "abstract": "As programmers turn to software-defined hardware (SDH) to maintain a high\nlevel of productivity while programming hardware to run complex algorithms,\nheavy-lifting must be done by the compiler to automatically partition on-chip\narrays. In this paper, we introduce an automatic memory partitioning system\nthat can quickly compute more efficient partitioning schemes than prior\nsystems. Our system employs a variety of resource-saving optimizations and an\nML cost model to select the best partitioning scheme from an array of\ncandidates. We compared our system against various state-of-the-art SDH\ncompilers and FPGAs on a variety of benchmarks and found that our system\ngenerates solutions that, on average, consume 40.3% fewer logic resources,\n78.3% fewer FFs, 54.9% fewer Block RAMs (BRAMs), and 100% fewer DSPs.",
    "descriptor": "",
    "authors": [
      "Matthew Feldman",
      "Tian Zhao",
      "Kunle Olukotun"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.01261"
  },
  {
    "id": "arXiv:2202.01262",
    "title": "A semi-discrete numerical scheme for nonlocally regularized KdV-type  equations",
    "abstract": "A general class of KdV-type wave equations regularized with a\nconvolution-type nonlocality in space is considered. The class differs from the\nclass of the nonlinear nonlocal unidirectional wave equations previously\nstudied by the addition of a linear convolution term involving third-order\nderivative. To solve the Cauchy problem we propose a semi-discrete numerical\nmethod based on a uniform spatial discretization, that is an extension of a\npreviously published work of the present authors. We prove uniform convergence\nof the numerical method as the mesh size goes to zero. We also prove that the\nlocalization error resulting from localization to a finite domain is\nsignificantly less than a given threshold if the finite domain is large enough.\nTo illustrate the theoretical results, some numerical experiments are carried\nout for the Rosenau-KdV equation, the Rosenau-BBM-KdV equation and a\nconvolution-type integro-differential equation. The experiments conducted for\nthree particular choices of the kernel function confirm the error estimates\nthat we provide.",
    "descriptor": "\nComments: 16 pages, 4 figures, 1 table, to appear in the journal Applied Numerical Mathematics. arXiv admin note: text overlap with arXiv:1909.10917\n",
    "authors": [
      "H. A. Erbay",
      "S. Erbay",
      "A. Erkip"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.01262"
  },
  {
    "id": "arXiv:2202.01263",
    "title": "NoisyMix: Boosting Robustness by Combining Data Augmentations, Stability  Training, and Noise Injections",
    "abstract": "For many real-world applications, obtaining stable and robust statistical\nperformance is more important than simply achieving state-of-the-art predictive\ntest accuracy, and thus robustness of neural networks is an increasingly\nimportant topic. Relatedly, data augmentation schemes have been shown to\nimprove robustness with respect to input perturbations and domain shifts.\nMotivated by this, we introduce NoisyMix, a training scheme that combines data\naugmentations with stability training and noise injections to improve both\nmodel robustness and in-domain accuracy. This combination promotes models that\nare consistently more robust and that provide well-calibrated estimates of\nclass membership probabilities. We demonstrate the benefits of NoisyMix on a\nrange of benchmark datasets, including ImageNet-C, ImageNet-R, and ImageNet-P.\nMoreover, we provide theory to understand implicit regularization and\nrobustness of NoisyMix.",
    "descriptor": "",
    "authors": [
      "N. Benjamin Erichson",
      "Soon Hoe Lim",
      "Francisco Utrera",
      "Winnie Xu",
      "Ziang Cao",
      "Michael W. Mahoney"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.01263"
  },
  {
    "id": "arXiv:2202.01265",
    "title": "Automated processing of X-ray computed tomography images via panoptic  segmentation for modeling woven composite textiles",
    "abstract": "A new, machine learning-based approach for automatically generating 3D\ndigital geometries of woven composite textiles is proposed to overcome the\nlimitations of existing analytical descriptions and segmentation methods. In\nthis approach, panoptic segmentation is leveraged to produce instance segmented\nsemantic masks from X-ray computed tomography (CT) images. This effort\nrepresents the first deep learning based automated process for segmenting\nunique yarn instances in a woven composite textile. Furthermore, it improves on\nexisting methods by providing instance-level segmentation on low contrast CT\ndatasets. Frame-to-frame instance tracking is accomplished via an\nintersection-over-union (IoU) approach adopted from video panoptic segmentation\nfor assembling a 3D geometric model. A corrective recognition algorithm is\ndeveloped to improve the recognition quality (RQ). The panoptic quality (PQ)\nmetric is adopted to provide a new universal evaluation metric for\nreconstructed woven composite textiles. It is found that the panoptic\nsegmentation network generalizes well to new CT images that are similar to the\ntraining set but does not extrapolate well to CT images of differing geometry,\ntexture, and contrast. The utility of this approach is demonstrated by\ncapturing yarn flow directions, contact regions between individual yarns, and\nthe spatially varying cross-sectional areas of the yarns.",
    "descriptor": "",
    "authors": [
      "Aaron Allred",
      "Lauren J. Abbott",
      "Alireza Doostan",
      "Kurt Maute"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2202.01265"
  },
  {
    "id": "arXiv:2202.01267",
    "title": "FedSpace: An Efficient Federated Learning Framework at Satellites and  Ground Stations",
    "abstract": "Large-scale deployments of low Earth orbit (LEO) satellites collect massive\namount of Earth imageries and sensor data, which can empower machine learning\n(ML) to address global challenges such as real-time disaster navigation and\nmitigation. However, it is often infeasible to download all the high-resolution\nimages and train these ML models on the ground because of limited downlink\nbandwidth, sparse connectivity, and regularization constraints on the imagery\nresolution. To address these challenges, we leverage Federated Learning (FL),\nwhere ground stations and satellites collaboratively train a global ML model\nwithout sharing the captured images on the satellites. We show fundamental\nchallenges in applying existing FL algorithms among satellites and ground\nstations, and we formulate an optimization problem which captures a unique\ntrade-off between staleness and idleness. We propose a novel FL framework,\nnamed FedSpace, which dynamically schedules model aggregation based on the\ndeterministic and time-varying connectivity according to satellite orbits.\nExtensive numerical evaluations based on real-world satellite images and\nsatellite networks show that FedSpace reduces the training time by 1.7 days\n(38.6%) over the state-of-the-art FL algorithms.",
    "descriptor": "",
    "authors": [
      "Jinhyun So",
      "Kevin Hsieh",
      "Behnaz Arzani",
      "Shadi Noghabi",
      "Salman Avestimehr",
      "Ranveer Chandra"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.01267"
  },
  {
    "id": "arXiv:2202.01268",
    "title": "DASHA: Distributed Nonconvex Optimization with Communication  Compression, Optimal Oracle Complexity, and No Client Synchronization",
    "abstract": "We develop and analyze DASHA: a new family of methods for nonconvex\ndistributed optimization problems. When the local functions at the nodes have a\nfinite-sum or an expectation form, our new methods, DASHA-PAGE and\nDASHA-SYNC-MVR, improve the theoretical oracle and communication complexity of\nthe previous state-of-the-art method MARINA by Gorbunov et al. (2020). In\nparticular, to achieve an epsilon-stationary point, and considering the random\nsparsifier RandK as an example, our methods compute the optimal number of\ngradients $\\mathcal{O}\\left(\\frac{\\sqrt{m}}{\\varepsilon\\sqrt{n}}\\right)$ and\n$\\mathcal{O}\\left(\\frac{\\sigma}{\\varepsilon^{3/2}n}\\right)$ in finite-sum and\nexpectation form cases, respectively, while maintaining the SOTA communication\ncomplexity $\\mathcal{O}\\left(\\frac{d}{\\varepsilon \\sqrt{n}}\\right)$.\nFurthermore, unlike MARINA, the new methods DASHA, DASHA-PAGE and DASHA-MVR\nsend compressed vectors only and never synchronize the nodes, which makes them\nmore practical for federated learning. We extend our results to the case when\nthe functions satisfy the Polyak-Lojasiewicz condition. Finally, our theory is\ncorroborated in practice: we see a significant improvement in experiments with\nnonconvex classification and training of deep learning models.",
    "descriptor": "",
    "authors": [
      "Alexander Tyurin",
      "Peter Richt\u00e1rik"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.01268"
  },
  {
    "id": "arXiv:2202.01269",
    "title": "Robust Estimation for Nonparametric Families via Generative Adversarial  Networks",
    "abstract": "We provide a general framework for designing Generative Adversarial Networks\n(GANs) to solve high dimensional robust statistics problems, which aim at\nestimating unknown parameter of the true distribution given adversarially\ncorrupted samples. Prior work focus on the problem of robust mean and\ncovariance estimation when the true distribution lies in the family of Gaussian\ndistributions or elliptical distributions, and analyze depth or scoring rule\nbased GAN losses for the problem. Our work extend these to robust mean\nestimation, second moment estimation, and robust linear regression when the\ntrue distribution only has bounded Orlicz norms, which includes the broad\nfamily of sub-Gaussian, sub-Exponential and bounded moment distributions. We\nalso provide a different set of sufficient conditions for the GAN loss to work:\nwe only require its induced distance function to be a cumulative density\nfunction of some light-tailed distribution, which is easily satisfied by neural\nnetworks with sigmoid activation. In terms of techniques, our proposed GAN\nlosses can be viewed as a smoothed and generalized Kolmogorov-Smirnov distance,\nwhich overcomes the computational intractability of the original\nKolmogorov-Smirnov distance used in the prior work.",
    "descriptor": "",
    "authors": [
      "Banghua Zhu",
      "Jiantao Jiao",
      "Michael I. Jordan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Statistics Theory (math.ST)",
      "Computation (stat.CO)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.01269"
  },
  {
    "id": "arXiv:2202.01273",
    "title": "Beyond Images: Label Noise Transition Matrix Estimation for Tasks with  Lower-Quality Features",
    "abstract": "The label noise transition matrix, denoting the transition probabilities from\nclean labels to noisy labels, is crucial knowledge for designing statistically\nrobust solutions. Existing estimators for noise transition matrices, e.g.,\nusing either anchor points or clusterability, focus on computer vision tasks\nthat are relatively easier to obtain high-quality representations. However, for\nother tasks with lower-quality features, the uninformative variables may\nobscure the useful counterpart and make anchor-point or clusterability\nconditions hard to satisfy. We empirically observe the failures of these\napproaches on a number of commonly used datasets. In this paper, to handle this\nissue, we propose a generally practical information-theoretic approach to\ndown-weight the less informative parts of the lower-quality features. The\nsalient technical challenge is to compute the relevant information-theoretical\nmetrics using only noisy labels instead of clean ones. We prove that the\ncelebrated $f$-mutual information measure can often preserve the order when\ncalculated using noisy labels. The necessity and effectiveness of the proposed\nmethod is also demonstrated by evaluating the estimation error on a varied set\nof tabular data and text classification tasks with lower-quality features. Code\nis available at github.com/UCSC-REAL/Est-T-MI.",
    "descriptor": "",
    "authors": [
      "Zhaowei Zhu",
      "Jialu Wang",
      "Yang Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.01273"
  },
  {
    "id": "arXiv:2202.01275",
    "title": "Topological Classification in a Wasserstein Distance Based Vector Space",
    "abstract": "Classification of large and dense networks based on topology is very\ndifficult due to the computational challenges of extracting meaningful\ntopological features from real-world networks. In this paper we present a\ncomputationally tractable approach to topological classification of networks by\nusing principled theory from persistent homology and optimal transport to\ndefine a novel vector representation for topological features. The proposed\nvector space is based on the Wasserstein distance between persistence barcodes.\nThe 1-skeleton of the network graph is employed to obtain 1-dimensional\npersistence barcodes that represent connected components and cycles. These\nbarcodes and the corresponding Wasserstein distance can be computed very\nefficiently. The effectiveness of the proposed vector space is demonstrated\nusing support vector machines to classify simulated networks and measured\nfunctional brain networks.",
    "descriptor": "",
    "authors": [
      "Tananun Songdechakraiwut",
      "Bryan M. Krause",
      "Matthew I. Banks",
      "Kirill V. Nourski",
      "Barry D. Van Veen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.01275"
  },
  {
    "id": "arXiv:2202.01279",
    "title": "PromptSource: An Integrated Development Environment and Repository for  Natural Language Prompts",
    "abstract": "PromptSource is a system for creating, sharing, and using natural language\nprompts. Prompts are functions that map an example from a dataset to a natural\nlanguage input and target output. Using prompts to train and query language\nmodels is an emerging area in NLP that requires new tools that let users\ndevelop and refine these prompts collaboratively. PromptSource addresses the\nemergent challenges in this new setting with (1) a templating language for\ndefining data-linked prompts, (2) an interface that lets users quickly iterate\non prompt development by observing outputs of their prompts on many examples,\nand (3) a community-driven set of guidelines for contributing new prompts to a\ncommon pool. Over 2,000 prompts for roughly 170 datasets are already available\nin PromptSource. PromptSource is available at\nhttps://github.com/bigscience-workshop/promptsource.",
    "descriptor": "",
    "authors": [
      "Stephen H. Bach",
      "Victor Sanh",
      "Zheng-Xin Yong",
      "Albert Webson",
      "Colin Raffel",
      "Nihal V. Nayak",
      "Abheesht Sharma",
      "Taewoon Kim",
      "M Saiful Bari",
      "Thibault Fevry",
      "Zaid Alyafeai",
      "Manan Dey",
      "Andrea Santilli",
      "Zhiqing Sun",
      "Srulik Ben-David",
      "Canwen Xu",
      "Gunjan Chhablani",
      "Han Wang",
      "Jason Alan Fries",
      "Maged S. Al-shaibani",
      "Shanya Sharma",
      "Urmish Thakker",
      "Khalid Almubarak",
      "Xiangru Tang",
      "Xiangru Tang",
      "Mike Tian-Jian Jiang",
      "Alexander M. Rush"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.01279"
  },
  {
    "id": "arXiv:2202.01281",
    "title": "An Experience Report of Executive-Level Artificial Intelligence  Education in the United Arab Emirates",
    "abstract": "Teaching artificial intelligence (AI) is challenging. It is a fast moving\nfield and therefore difficult to keep people updated with the state-of-the-art.\nEducational offerings for students are ever increasing, beyond university\ndegree programs where AI education traditionally lay. In this paper, we present\nan experience report of teaching an AI course to business executives in the\nUnited Arab Emirates (UAE). Rather than focusing only on theoretical and\ntechnical aspects, we developed a course that teaches AI with a view to\nenabling students to understand how to incorporate it into existing business\nprocesses. We present an overview of our course, curriculum and teaching\nmethods, and we discuss our reflections on teaching adult learners, and to\nstudents in the UAE.",
    "descriptor": "\nComments: 8 pages, 3 figures, 2 tables, accepted to EAAI-22: The 12th Symposium on Educational Advances in Artificial Intelligence\n",
    "authors": [
      "David Johnson",
      "Mohammad Alsharid",
      "Rasheed El-Bouri",
      "Nigel Mehdi",
      "Farah Shamout",
      "Alexandre Szenicer",
      "David Toman",
      "Saqr Binghalib"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.01281"
  },
  {
    "id": "arXiv:2202.01284",
    "title": "Dr.Jit: A Just-In-Time Compiler for Differentiable Rendering",
    "abstract": "We present Dr.Jit, a domain-specific just-in-time compiler for physically\nbased rendering and its derivative. Dr.Jit traces high-level programs (e.g.,\nwritten in Python) and compiles them into efficient CPU or GPU megakernels. It\nachieves state-of-the-art performance thanks to global optimizations that\nspecialize code generation to the rendering or optimization task at hand.\nWhile Dr.Jit drastically simplifies the creation of fast Monte Carlo\nrenderers, its design was motivated by the needs of the differentiable\nrendering community. Builtin facilities for automatic differentiation expose\nfine-grained control over subtle details of the differentiation process needed\nto transform the derivative of a simulation into a simulation of the\nderivative, a prerequisite for high performance in this context. Just-in-time\ncompilation embraces the dynamic nature of gradient evaluation: only small\nportions of the renderer may need derivative tracking in a specific task, but\ntheir location cannot be known ahead of time. Our system specializes algorithms\non the fly and removes detected redundancies.",
    "descriptor": "",
    "authors": [
      "Wenzel Jakob",
      "S\u00e9bastien Speierer",
      "Nicolas Roussel",
      "Delio Vicini"
    ],
    "subjectives": [
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2202.01284"
  },
  {
    "id": "arXiv:2202.01286",
    "title": "ASR-Aware End-to-end Neural Diarization",
    "abstract": "We present a Conformer-based end-to-end neural diarization (EEND) model that\nuses both acoustic input and features derived from an automatic speech\nrecognition (ASR) model. Two categories of features are explored: features\nderived directly from ASR output (phones, position-in-word and word boundaries)\nand features derived from a lexical speaker change detection model, trained by\nfine-tuning a pretrained BERT model on the ASR output. Three modifications to\nthe Conformer-based EEND architecture are proposed to incorporate the features.\nFirst, ASR features are concatenated with acoustic features. Second, we propose\na new attention mechanism called contextualized self-attention that utilizes\nASR features to build robust speaker representations. Finally, multi-task\nlearning is used to train the model to minimize classification loss for the ASR\nfeatures along with diarization loss. Experiments on the two-speaker English\nconversations of Switchboard+SRE data sets show that multi-task learning with\nposition-in-word information is the most effective way of utilizing ASR\nfeatures, reducing the diarization error rate (DER) by 20% relative to the\nbaseline.",
    "descriptor": "\nComments: To appear in ICASSP 2022\n",
    "authors": [
      "Aparna Khare",
      "Eunjung Han",
      "Yuguang Yang",
      "Andreas Stolcke"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2202.01286"
  },
  {
    "id": "arXiv:2202.01287",
    "title": "Fenrir: Physics-Enhanced Regression for Initial Value Problems",
    "abstract": "We show how probabilistic numerics can be used to convert an initial value\nproblem into a Gauss--Markov process parametrised by the dynamics of the\ninitial value problem. Consequently, the often difficult problem of parameter\nestimation in ordinary differential equations is reduced to hyperparameter\nestimation in Gauss--Markov regression, which tends to be considerably easier.\nThe method's relation and benefits in comparison to classical numerical\nintegration and gradient matching approaches is elucidated. In particular, the\nmethod can, in contrast to gradient matching, handle partial observations, and\nhas certain routes for escaping local optima not available to classical\nnumerical integration. Experimental results demonstrate that the method is on\npar or moderately better than competing approaches.",
    "descriptor": "",
    "authors": [
      "Filip Tronarp",
      "Nathanael Bosch",
      "Philipp Hennig"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.01287"
  },
  {
    "id": "arXiv:2202.01288",
    "title": "Imitation Learning by Estimating Expertise of Demonstrators",
    "abstract": "Many existing imitation learning datasets are collected from multiple\ndemonstrators, each with different expertise at different parts of the\nenvironment. Yet, standard imitation learning algorithms typically treat all\ndemonstrators as homogeneous, regardless of their expertise, absorbing the\nweaknesses of any suboptimal demonstrators. In this work, we show that\nunsupervised learning over demonstrator expertise can lead to a consistent\nboost in the performance of imitation learning algorithms. We develop and\noptimize a joint model over a learned policy and expertise levels of the\ndemonstrators. This enables our model to learn from the optimal behavior and\nfilter out the suboptimal behavior of each demonstrator. Our model learns a\nsingle policy that can outperform even the best demonstrator, and can be used\nto estimate the expertise of any demonstrator at any state. We illustrate our\nfindings on real-robotic continuous control tasks from Robomimic and discrete\nenvironments such as MiniGrid and chess, out-performing competing methods in\n$21$ out of $23$ settings, with an average of $7\\%$ and up to $60\\%$\nimprovement in terms of the final reward.",
    "descriptor": "\nComments: 15 pages, submitted to ICML 2022\n",
    "authors": [
      "Mark Beliaev",
      "Andy Shih",
      "Stefano Ermon",
      "Dorsa Sadigh",
      "Ramtin Pedarsani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.01288"
  },
  {
    "id": "arXiv:2202.01289",
    "title": "Systems Mining with Heraklit: The Next Step",
    "abstract": "We suggest systems mining as the next step after process mining. Systems\nmining starts with a more careful investigation of runs, and constructs a\ndetailed model of behavior, more subtle than classical process mining. The\nresulting model is enriched with information about data. From this model, a\nsystem model can be deduced in a systematic way.",
    "descriptor": "\nComments: 16 pages, 18 figures\n",
    "authors": [
      "Peter Fettke",
      "Wolfgang Reisig"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2202.01289"
  },
  {
    "id": "arXiv:2202.01290",
    "title": "Cyclical Pruning for Sparse Neural Networks",
    "abstract": "Current methods for pruning neural network weights iteratively apply\nmagnitude-based pruning on the model weights and re-train the resulting model\nto recover lost accuracy. In this work, we show that such strategies do not\nallow for the recovery of erroneously pruned weights. To enable weight\nrecovery, we propose a simple strategy called \\textit{cyclical pruning} which\nrequires the pruning schedule to be periodic and allows for weights pruned\nerroneously in one cycle to recover in subsequent ones. Experimental results on\nboth linear models and large-scale deep neural networks show that cyclical\npruning outperforms existing pruning algorithms, especially at high sparsity\nratios. Our approach is easy to tune and can be readily incorporated into\nexisting pruning pipelines to boost performance.",
    "descriptor": "",
    "authors": [
      "Suraj Srinivas",
      "Andrey Kuzmin",
      "Markus Nagel",
      "Mart van Baalen",
      "Andrii Skliar",
      "Tijmen Blankevoort"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.01290"
  },
  {
    "id": "arXiv:2202.01291",
    "title": "Computer sciences and synthesis: retrospective and perspective",
    "abstract": "The problem of synthesis in computer sciences, including cybernetics,\nartificial intelligence and system analysis, is analyzed. Main methods of\nrealization this problem are discussed. Ways of search universal method of\ncreation universal synthetic science are represented. As example of such\nuniversal method polymetric analysis is given. Perspective of further\ndevelopment of this research, including application polymetric method for the\nresolution main problems of computer sciences, is analyzed too.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2111.09762\n",
    "authors": [
      "Vladislav Dorofeev",
      "Petro Trokhimchuk"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.01291"
  },
  {
    "id": "arXiv:2202.01292",
    "title": "Improved Regret for Differentially Private Exploration in Linear MDP",
    "abstract": "We study privacy-preserving exploration in sequential decision-making for\nenvironments that rely on sensitive data such as medical records. In\nparticular, we focus on solving the problem of reinforcement learning (RL)\nsubject to the constraint of (joint) differential privacy in the linear MDP\nsetting, where both dynamics and rewards are given by linear functions. Prior\nwork on this problem due to Luyo et al. (2021) achieves a regret rate that has\na dependence of $O(K^{3/5})$ on the number of episodes $K$. We provide a\nprivate algorithm with an improved regret rate with an optimal dependence of\n$O(\\sqrt{K})$ on the number of episodes. The key recipe for our stronger regret\nguarantee is the adaptivity in the policy update schedule, in which an update\nonly occurs when sufficient changes in the data are detected. As a result, our\nalgorithm benefits from low switching cost and only performs $O(\\log(K))$\nupdates, which greatly reduces the amount of privacy noise. Finally, in the\nmost prevalent privacy regimes where the privacy parameter $\\epsilon$ is a\nconstant, our algorithm incurs negligible privacy cost -- in comparison with\nthe existing non-private regret bounds, the additional regret due to privacy\nappears in lower-order terms.",
    "descriptor": "\nComments: 13 pages of main text, 30 pages in total\n",
    "authors": [
      "Dung Daniel Ngo",
      "Giuseppe Vietri",
      "Zhiwei Steven Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.01292"
  },
  {
    "id": "arXiv:2202.01293",
    "title": "Orthogonal Fold & Cut",
    "abstract": "We characterize the shapes that can be produced by \"orthogonal fold & cut\":\nfolding a rectangular sheet of paper along horizontal and vertical creases, and\nthen making a single straight cut (at any angle). Along the way, we solve a\nhandful of related problems: orthogonal fold & punch, 1D fold & cut, signed 1D\nfold & cut, and 1D interval fold & cut.",
    "descriptor": "\nComments: 10 pages, 7 figures. Presented at 23rd Thailand-Japan Conference on Discrete and Computational Geometry, Graphs, and Games\n",
    "authors": [
      "Joshua Ani",
      "Josh Brunner",
      "Erik D. Demaine",
      "Martin L. Demaine",
      "Dylan Hendrickson",
      "Victor Luo",
      "Rachana Madhukara"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Metric Geometry (math.MG)"
    ],
    "url": "https://arxiv.org/abs/2202.01293"
  },
  {
    "id": "arXiv:2202.01297",
    "title": "Age Distribution in Arbitrary Preemptive Memoryless Networks",
    "abstract": "We study the probability distribution of age of information (AoI) in\narbitrary networks with memoryless service times. A source node generates\npackets following a Poisson process, and then the packets are forwarded across\nthe network in such a way that newer updates preempt older ones. This model is\nequivalent to gossip networks that was recently studied by Yates, and for which\nhe obtained a recursive formula allowing the computation for the average AoI.\nIn this paper, we obtain a very simple characterization of the stationary\ndistribution of AoI at every node in the network. This allows for the\ncomputation of the average of an arbitrary function of the age. In particular,\nwe can compute age-violation probabilities. Furthermore, we show how it is\npossible to use insights from our simple characterization in order to\nsubstantially reduce the computation time of average AoIs in some structured\nnetworks. Finally, we describe how it is possible to use our characterization\nin order to obtain faster and more accurate Monte Carlo simulations estimating\nthe average AoI, or the average of an arbitrary function of the age.",
    "descriptor": "\nComments: 20 pages\n",
    "authors": [
      "Rajai Nasser",
      "Ibrahim Issa",
      "Ibrahim Abou-Faycal"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.01297"
  },
  {
    "id": "arXiv:2202.01299",
    "title": "On Coded Caching Systems with Offline Users",
    "abstract": "Coded caching is a technique that leverages locally cached contents at the\nusers to reduce the network's peak-time communication load. Coded caching\nachieves significant performance gains compared to uncoded caching schemes and\nis thus a promising technique to boost performance in future networks. In the\noriginal model introduced by Maddah-Ali and Niesen (MAN), a server stores\nmultiple files and is connected to multiple cache-aided users through an\nerror-free shared link; once the local caches have been filled and all users\nhave sent their demand to the server, the server can start sending coded\nmulticast messages to satisfy all users' demands. A practical limitation of the\noriginal MAN model is that it halts if the server does not receive all users'\ndemands, which is the limiting case of asynchronous coded caching when the\nrequests of some users arrive with infinite delay. In this paper we formally\ndefine a coded caching system where some users are offline. We propose\nachievable and converse bounds for this novel setting and show under which\nconditions they meet, thus providing an optimal solution, and when they are to\nwithin a constant multiplicative gap of two. Interestingly, when optimality can\nbe be shown, the optimal load-memory tradeoff only depends on the number active\nusers, and not on the total (active plus offline) number of users.",
    "descriptor": "",
    "authors": [
      "Yinbin Ma",
      "Daniela Tuninetti"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.01299"
  },
  {
    "id": "arXiv:2202.01300",
    "title": "Causal Inference Through the Structural Causal Marginal Problem",
    "abstract": "We introduce an approach to counterfactual inference based on merging\ninformation from multiple datasets. We consider a causal reformulation of the\nstatistical marginal problem: given a collection of marginal structural causal\nmodels (SCMs) over distinct but overlapping sets of variables, determine the\nset of joint SCMs that are counterfactually consistent with the marginal ones.\nWe formalise this approach for categorical SCMs using the response function\nformulation and show that it reduces the space of allowed marginal and joint\nSCMs. Our work thus highlights a new mode of falsifiability through additional\nvariables, in contrast to the statistical one via additional data.",
    "descriptor": "\nComments: 31 pages (9 pages main paper + bibliography and appendix), 6 figures\n",
    "authors": [
      "Luigi Gresele",
      "Julius von K\u00fcgelgen",
      "Jonas M. K\u00fcbler",
      "Elke Kirschbaum",
      "Bernhard Sch\u00f6lkopf",
      "Dominik Janzing"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.01300"
  },
  {
    "id": "arXiv:2202.01302",
    "title": "A Comparison of Online Hate on Reddit and 4chan: A Case Study of the  2020 US Election",
    "abstract": "The rapid integration of the Internet into our daily lives has led to many\nbenefits but also to a number of new, wide-spread threats such as online hate,\ntrolling, bullying, and generally aggressive behaviours. While research has\ntraditionally explored online hate, in particular, on one platform, the reality\nis that such hate is a phenomenon that often makes use of multiple online\nnetworks. In this article, we seek to advance the discussion into online hate\nby harnessing a comparative approach, where we make use of various Natural\nLanguage Processing (NLP) techniques to computationally analyse hateful content\nfrom Reddit and 4chan relating to the 2020 US Presidential Elections. Our\nfindings show how content and posting activity can differ depending on the\nplatform being used. Through this, we provide initial comparison into the\nplatform-specific behaviours of online hate, and how different platforms can\nserve specific purposes. We further provide several avenues for future research\nutilising a cross-platform approach so as to gain a more comprehensive\nunderstanding of the global hate ecosystem.",
    "descriptor": "\nComments: 2022 ACM Symposium on Applied Computing (SAC'22)\n",
    "authors": [
      "Fatima Zahrah",
      "Jason R. C. Nurse",
      "Michael Goldsmith"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.01302"
  },
  {
    "id": "arXiv:2202.01306",
    "title": "Harmony: Overcoming the hurdles of GPU memory capacity to train massive  DNN models on commodity servers",
    "abstract": "Deep neural networks (DNNs) have grown exponentially in complexity and size\nover the past decade, leaving only those who have access to massive\ndatacenter-based resources with the ability to develop and train such models.\nOne of the main challenges for the long tail of researchers who might have\naccess to only limited resources (e.g., a single multi-GPU server) is limited\nGPU memory capacity compared to model size. The problem is so acute that the\nmemory requirement of training large DNN models can often exceed the aggregate\ncapacity of all available GPUs on commodity servers; this problem only gets\nworse with the trend of ever-growing model sizes. Current solutions that rely\non virtualizing GPU memory (by swapping to/from CPU memory) incur excessive\nswapping overhead. In this paper, we present a new training framework, Harmony,\nand advocate rethinking how DNN frameworks schedule computation and move data\nto push the boundaries of training large models efficiently on modest multi-GPU\ndeployments. Across many large DNN models, Harmony is able to reduce swap load\nby up to two orders of magnitude and obtain a training throughput speedup of up\nto 7.6x over highly optimized baselines with virtualized memory.",
    "descriptor": "",
    "authors": [
      "Youjie Li",
      "Amar Phanishayee",
      "Derek Murray",
      "Jakub Tarnawski",
      "Nam Sung Kim"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.01306"
  },
  {
    "id": "arXiv:2202.01308",
    "title": "Impact Analysis of Harassment Against Women Using Association Rule  Mining Approaches: Bangladesh Prospective",
    "abstract": "In recent years, it has been noticed that women are making progress in every\nsector of society. Their involvement in every field, such as education, job\nmarket, social work, etc., is increasing at a remarkable rate. For the last\nseveral years, the government has been trying its level best for the\nadvancement of women in every sector by doing several research work and\nactivities and funding several organizations to motivate women. Although\nwomen's involvement in several fields is increasing, the big concern is they\nare facing several barriers in their advancement, and it is not surprising that\nsexual harassment is one of them. In Bangladesh, harassment against women,\nespecially students, is a common phenomenon, and it is increasing. In this\npaper, a survey-based and Apriori algorithm are used to analyze the several\nimpacts of harassment among several age groups. Also, several factors such as\nfrequent impacts of harassment, most vulnerable groups, women mostly facing\nharassment, the alleged person behind harassment, etc., are analyzed through\nassociation rule mining of Apriori algorithm and F.P. Growth algorithm. And\nthen, a comparison of performance between both algorithms has been shown\nbriefly. For this analysis, data have been carefully collected from all ages.",
    "descriptor": "\nComments: 15 pages, journal, 8 figures\n",
    "authors": [
      "Bahar Uddin Mahmud",
      "Afsana Sharmin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.01308"
  },
  {
    "id": "arXiv:2202.01309",
    "title": "Multi-Resolution Factor Graph Based Stereo Correspondence Algorithm",
    "abstract": "A dense depth-map of a scene at an arbitrary view orientation can be\nestimated from dense view correspondences among multiple lower-dimensional\nviews of the scene. These low-dimensional view correspondences are dependent on\nthe geometrical relationship among the views and the scene. Determining dense\nview correspondences is difficult in part due to presence of homogeneous\nregions in the scene and due to presence of occluded regions and illumination\ndifferences among the views. We present a new multi-resolution factor\ngraph-based stereo matching algorithm (MR-FGS) that utilizes both intra- and\ninter-resolution dependencies among the views as well as among the disparity\nestimates. The proposed framework allows exchange of information among multiple\nresolutions of the correspondence problem and is useful for handling larger\nhomogeneous regions in a scene. The MR-FGS algorithm was evaluated\nqualitatively and quantitatively using stereo pairs in the Middlebury stereo\nbenchmark dataset based on commonly used performance measures. When compared to\na recently developed factor graph model (FGS), the MR-FGS algorithm provided\nmore accurate disparity estimates without requiring the commonly used\npost-processing procedure known as the left-right consistency check. The\nmulti-resolution dependency constraint within the factor-graph model\nsignificantly improved contrast along depth boundaries in the MR-FGS generated\ndisparity maps.",
    "descriptor": "\nComments: 18 pages, 4 figures and 2 tables. arXiv admin note: text overlap with arXiv:2109.11077\n",
    "authors": [
      "Hanieh Shabanian",
      "Madhusudhanan Balasubramanian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.01309"
  },
  {
    "id": "arXiv:2202.01312",
    "title": "Causal Imitation Learning under Temporally Correlated Noise",
    "abstract": "We develop algorithms for imitation learning from policy data that was\ncorrupted by temporally correlated noise in expert actions. When noise affects\nmultiple timesteps of recorded data, it can manifest as spurious correlations\nbetween states and actions that a learner might latch on to, leading to poor\npolicy performance. To break up these spurious correlations, we apply modern\nvariants of the instrumental variable regression (IVR) technique of\neconometrics, enabling us to recover the underlying policy without requiring\naccess to an interactive expert. In particular, we present two techniques, one\nof a generative-modeling flavor (DoubIL) that can utilize access to a\nsimulator, and one of a game-theoretic flavor (ResiduIL) that can be run\nentirely offline. We find both of our algorithms compare favorably to\nbehavioral cloning on simulated control tasks.",
    "descriptor": "",
    "authors": [
      "Gokul Swamy",
      "Sanjiban Choudhury",
      "J. Andrew Bagnell",
      "Zhiwei Steven Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.01312"
  },
  {
    "id": "arXiv:2202.01315",
    "title": "Approximating Full Conformal Prediction at Scale via Influence Functions",
    "abstract": "Conformal prediction (CP) is a wrapper around traditional machine learning\nmodels, giving coverage guarantees under the sole assumption of\nexchangeability; in classification problems, for a chosen significance level\n$\\varepsilon$, CP guarantees that the number of errors is at most\n$\\varepsilon$, irrespective of whether the underlying model is misspecified.\nHowever, the prohibitive computational costs of full CP led researchers to\ndesign scalable alternatives, which alas do not attain the same guarantees or\nstatistical power of full CP. In this paper, we use influence functions to\nefficiently approximate full CP. We prove that our method is a consistent\napproximation of full CP, and empirically show that the approximation error\nbecomes smaller as the training set increases; e.g., for $10^{3}$ training\npoints the two methods output p-values that are $<10^{-3}$ apart: a negligible\nerror for any practical application. Our methods enable scaling full CP to\nlarge real-world datasets. We compare our full CP approximation ACP to\nmainstream CP alternatives, and observe that our method is computationally\ncompetitive whilst enjoying the statistical predictive power of full CP.",
    "descriptor": "\nComments: 18 pages, 15 figures\n",
    "authors": [
      "Javier Abad",
      "Umang Bhatt",
      "Adrian Weller",
      "Giovanni Cherubin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2202.01315"
  },
  {
    "id": "arXiv:2202.01317",
    "title": "Governing online goods: Maturity and formalization in Minecraft, Reddit,  and World of Warcraft communities",
    "abstract": "Building a successful community means governing active populations and\nlimited resources. This challenge often requires communities to design formal\ngovernance systems from scratch. But the characteristics of successful\ninstitutional designs are unclear. Communities that are more mature and\nestablished may have more elaborate formal policy systems. Alternatively, they\nmay require less formalization precisely because of their maturity. Indeed,\nscholars often downplay the role that formal rules relative to unwritten rules,\nnorms, and values. But in a community with formal rules, decisions are more\nconsistent, transparent, and legitimate. To understand the relationship of\nformal institutions to community maturity and governance style, we conduct a\nlarge-scale quantitative analysis applying institutional analysis frameworks of\nself-governance scholar Elinor Ostrom to 80,000 communities across 3 platforms:\nthe sandbox game Minecraft, the MMO game World of Warcraft, and Reddit. We\nclassify communities' written rules to test predictors of institutional\nformalization. From this analysis we extract two major findings. First,\ninstitutional formalization, the size and complexity of an online community's\ngovernance system, is generally positively associated with maturity, as\nmeasured by age, population size, or degree of user engagement. Second, we find\nthat online communities employ similar governance styles across platforms,\nstrongly favoring \"weak\" norms to \"strong\" requirements. These findings suggest\nthat designers and founders of online communities converge on styles of\ngovernance practice that are correlated with successful self-governance. With\ndeeper insights into the patterns of successful self-governance, we can help\nmore communities overcome the challenges of self-governance and create for\ntheir members powerful experiences of shared meaning and collective\nempowerment.",
    "descriptor": "\nComments: 23 pages. 4 figures\n",
    "authors": [
      "Seth Frey",
      "Qiankun Zhong",
      "Beril Bulat",
      "William D. Weisman",
      "Caitlyn Liu",
      "Stephen Fujimoto",
      "Hannah M. Wang",
      "Charles M. Schweik"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2202.01317"
  },
  {
    "id": "arXiv:2202.01319",
    "title": "Deep Learning for Epidemiologists: An Introduction to Neural Networks",
    "abstract": "Deep learning methods are increasingly being applied to problems in medicine\nand healthcare. However, few epidemiologists have received formal training in\nthese methods. To bridge this gap, this article introduces to the fundamentals\nof deep learning from an epidemiological perspective. Specifically, this\narticle reviews core concepts in machine learning (overfitting, regularization,\nhyperparameters), explains several fundamental deep learning architectures\n(convolutional neural networks, recurrent neural networks), and summarizes\ntraining, evaluation, and deployment of models. We aim to enable the reader to\nengage with and critically evaluate medical applications of deep learning,\nfacilitating a dialogue between computer scientists and epidemiologists that\nwill improve the safety and efficacy of applications of this technology.",
    "descriptor": "\nComments: 35 pages with 1.5 spacing, 6 figures\n",
    "authors": [
      "Stylianos Serghiou",
      "Kathryn Rough"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.01319"
  },
  {
    "id": "arXiv:2202.01322",
    "title": "How to Improve Deep Learning for Software Analytics (a case study with  code smell detection)",
    "abstract": "To reduce technical debt and make code more maintainable, it is important to\nbe able to warn programmers about code smells. State-of-the-art code small\ndetectors use deep learners, without much exploration of alternatives within\nthat technology.\nOne promising alternative for software analytics and deep learning is GHOST\n(from TSE'21) that relies on a combination of hyper-parameter optimization of\nfeedforward neural networks and a novel oversampling technique to deal with\nclass imbalance.\nThe prior study from TSE'21 proposing this novel \"fuzzy sampling\" was\nsomewhat limited in that the method was tested on defect prediction, but\nnothing else. Like defect prediction, code smell detection datasets have a\nclass imbalance (which motivated \"fuzzy sampling\"). Hence, in this work we test\nif fuzzy sampling is useful for code smell detection.\nThe results of this paper show that we can achieve better than\nstate-of-the-art results on code smell detection with fuzzy oversampling. For\nexample, for \"feature envy\", we were able to achieve 99+\\% AUC across all our\ndatasets, and on 8/10 datasets for \"misplaced class\". While our specific\nresults refer to code smell detection, they do suggest other lessons for other\nkinds of analytics. For example: (a) try better preprocessing before trying\ncomplex learners (b) include simpler learners as a baseline in software\nanalytics (c) try \"fuzzy sampling\" as one such baseline.",
    "descriptor": "\nComments: v1\n",
    "authors": [
      "Rahul Yedida",
      "Tim Menzies"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2202.01322"
  },
  {
    "id": "arXiv:2202.01323",
    "title": "PanoDepth: A Two-Stage Approach for Monocular Omnidirectional Depth  Estimation",
    "abstract": "Omnidirectional 3D information is essential for a wide range of applications\nsuch as Virtual Reality, Autonomous Driving, Robotics, etc. In this paper, we\npropose a novel, model-agnostic, two-stage pipeline for omnidirectional\nmonocular depth estimation. Our proposed framework PanoDepth takes one 360\nimage as input, produces one or more synthesized views in the first stage, and\nfeeds the original image and the synthesized images into the subsequent stereo\nmatching stage. In the second stage, we propose a differentiable Spherical\nWarping Layer to handle omnidirectional stereo geometry efficiently and\neffectively. By utilizing the explicit stereo-based geometric constraints in\nthe stereo matching stage, PanoDepth can generate dense high-quality depth. We\nconducted extensive experiments and ablation studies to evaluate PanoDepth with\nboth the full pipeline as well as the individual modules in each stage. Our\nresults show that PanoDepth outperforms the state-of-the-art approaches by a\nlarge margin for 360 monocular depth estimation.",
    "descriptor": "\nComments: Accepted by International Conference on 3D Vision (3DV). IEEE, 2021\n",
    "authors": [
      "Yuyan Li",
      "Zhixin Yan",
      "Ye Duan",
      "Liu Ren"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.01323"
  },
  {
    "id": "arXiv:2202.01327",
    "title": "Adaptive Sampling Strategies to Construct Equitable Training Datasets",
    "abstract": "In domains ranging from computer vision to natural language processing,\nmachine learning models have been shown to exhibit stark disparities, often\nperforming worse for members of traditionally underserved groups. One factor\ncontributing to these performance gaps is a lack of representation in the data\nthe models are trained on. It is often unclear, however, how to operationalize\nrepresentativeness in specific applications. Here we formalize the problem of\ncreating equitable training datasets, and propose a statistical framework for\naddressing this problem. We consider a setting where a model builder must\ndecide how to allocate a fixed data collection budget to gather training data\nfrom different subgroups. We then frame dataset creation as a constrained\noptimization problem, in which one maximizes a function of group-specific\nperformance metrics based on (estimated) group-specific learning rates and\ncosts per sample. This flexible approach incorporates preferences of\nmodel-builders and other stakeholders, as well as the statistical properties of\nthe learning task. When data collection decisions are made sequentially, we\nshow that under certain conditions this optimization problem can be efficiently\nsolved even without prior knowledge of the learning rates. To illustrate our\napproach, we conduct a simulation study of polygenic risk scores on synthetic\ngenomic data -- an application domain that often suffers from\nnon-representative data collection. We find that our adaptive sampling strategy\noutperforms several common data collection heuristics, including equal and\nproportional sampling, demonstrating the value of strategic dataset design for\nbuilding equitable models.",
    "descriptor": "\nComments: 15 pages, 2 figures\n",
    "authors": [
      "William Cai",
      "Ro Encarnacion",
      "Bobbie Chern",
      "Sam Corbett-Davies",
      "Miranda Bogen",
      "Stevie Bergman",
      "Sharad Goel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2202.01327"
  },
  {
    "id": "arXiv:2202.01331",
    "title": "Fast Convex Optimization for Two-Layer ReLU Networks: Equivalent Model  Classes and Cone Decompositions",
    "abstract": "We develop fast algorithms and robust software for convex optimization of\ntwo-layer neural networks with ReLU activation functions. Our work leverages a\nconvex reformulation of the standard weight-decay penalized training problem as\na set of group-$\\ell_1$-regularized data-local models, where locality is\nenforced by polyhedral cone constraints. In the special case of\nzero-regularization, we show that this problem is exactly equivalent to\nunconstrained optimization of a convex \"gated ReLU\" network. For problems with\nnon-zero regularization, we show that convex gated ReLU models obtain\ndata-dependent approximation bounds for the ReLU training problem. To optimize\nthe convex reformulations, we develop an accelerated proximal gradient method\nand a practical augmented Lagrangian solver. We show that these approaches are\nfaster than standard training heuristics for the non-convex problem, such as\nSGD, and outperform commercial interior-point solvers. Experimentally, we\nverify our theoretical results, explore the group-$\\ell_1$ regularization path,\nand scale convex optimization for neural networks to image classification on\nMNIST and CIFAR-10.",
    "descriptor": "\nComments: 44 pages, 6 tables, 18 figures\n",
    "authors": [
      "Aaron Mishkin",
      "Arda Sahiner",
      "Mert Pilanci"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.01331"
  },
  {
    "id": "arXiv:2202.01332",
    "title": "Training a Bidirectional GAN-based One-Class Classifier for Network  Intrusion Detection",
    "abstract": "The network intrusion detection task is challenging because of the imbalanced\nand unlabeled nature of the dataset it operates on. Existing generative\nadversarial networks (GANs), are primarily used for creating synthetic samples\nfrom reals. They also have been proved successful in anomaly detection tasks.\nIn our proposed method, we construct the trained encoder-discriminator as a\none-class classifier based on Bidirectional GAN (Bi-GAN) for detecting\nanomalous traffic from normal traffic other than calculating expensive and\ncomplex anomaly scores or thresholds. Our experimental result illustrates that\nour proposed method is highly effective to be used in network intrusion\ndetection tasks and outperforms other similar generative methods on the NSL-KDD\ndataset.",
    "descriptor": "\nComments: 15 pages, 8 figures\n",
    "authors": [
      "Wen Xu",
      "Julian Jang-Jaccard",
      "Tong Liu",
      "Fariza Sabrina"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.01332"
  },
  {
    "id": "arXiv:2202.01334",
    "title": "Adaptive Discrete Communication Bottlenecks with Dynamic Vector  Quantization",
    "abstract": "Vector Quantization (VQ) is a method for discretizing latent representations\nand has become a major part of the deep learning toolkit. It has been\ntheoretically and empirically shown that discretization of representations\nleads to improved generalization, including in reinforcement learning where\ndiscretization can be used to bottleneck multi-agent communication to promote\nagent specialization and robustness. The discretization tightness of most\nVQ-based methods is defined by the number of discrete codes in the\nrepresentation vector and the codebook size, which are fixed as\nhyperparameters. In this work, we propose learning to dynamically select\ndiscretization tightness conditioned on inputs, based on the hypothesis that\ndata naturally contains variations in complexity that call for different levels\nof representational coarseness. We show that dynamically varying tightness in\ncommunication bottlenecks can improve model performance on visual reasoning and\nreinforcement learning tasks.",
    "descriptor": "",
    "authors": [
      "Dianbo Liu",
      "Alex Lamb",
      "Xu Ji",
      "Pascal Notsawo",
      "Mike Mozer",
      "Yoshua Bengio",
      "Kenji Kawaguchi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.01334"
  },
  {
    "id": "arXiv:2202.01335",
    "title": "Recommendations for Visualization Recommendations: Exploring Preferences  and Priorities in Public Health",
    "abstract": "The promise of visualization recommendation systems is that analysts will be\nautomatically provided with relevant and high-quality visualizations that will\nreduce the work of manual exploration or chart creation. However, little\nresearch to date has focused on what analysts value in the design of\nvisualization recommendations. We interviewed 18 analysts in the public health\nsector and explored how they made sense of a popular in-domain dataset. in\nservice of generating visualizations to recommend to others. We also explored\nhow they interacted with a corpus of both automatically- and manually-generated\nvisualization recommendations, with the goal of uncovering how the design\nvalues of these analysts are reflected in current visualization recommendation\nsystems. We find that analysts champion simple charts with clear takeaways that\nare nonetheless connected with existing semantic information or domain\nhypotheses. We conclude by recommending that visualization recommendation\ndesigners explore ways of integrating context and expectation into their\nsystems.",
    "descriptor": "",
    "authors": [
      "Calvin Bao",
      "Siyao Li",
      "Sarah Flores",
      "Michael Correll",
      "Leilani Battle"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2202.01335"
  },
  {
    "id": "arXiv:2202.01336",
    "title": "Can Transformers be Strong Treatment Effect Estimators?",
    "abstract": "In this paper, we develop a general framework for based on Transformer\narchitectures to address a variety of challenging treatment effect estimation\n(TEE) problems. Our methods are applicable both when covariates are tabular and\nwhen they consist of sequences (e.g., in text), and can handle discrete,\ncontinuous, structured, or dosage-associated treatments. While Transformers\nhave already emerged as dominant methods for diverse domains, including natural\nlanguage and computer vision, our experiments with Transformers as Treatment\nEffect Estimators (TransTEE) demonstrate that these inductive biases are also\neffective on the sorts of estimation problems and datasets that arise in\nresearch aimed at estimating causal effects. Moreover, we propose a propensity\nscore network that is trained with TransTEE in an adversarial manner to promote\nindependence between covariates and treatments to further address selection\nbias. Through extensive experiments, we show that TransTEE significantly\noutperforms competitive baselines with greater parameter efficiency over a wide\nrange of benchmarks and settings.",
    "descriptor": "\nComments: Technical Report. The first two authors contributed equally to this work\n",
    "authors": [
      "Yi-Fan Zhang",
      "Hanlin Zhang",
      "Zachary C. Lipton",
      "Li Erran Li",
      "Eric P. Xing"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.01336"
  },
  {
    "id": "arXiv:2202.01337",
    "title": "Generalizability of Machine Learning Models: Quantitative Evaluation of  Three Methodological Pitfalls",
    "abstract": "Despite the great potential of machine learning, the lack of generalizability\nhas hindered the widespread adoption of these technologies in routine clinical\npractice. We investigate three methodological pitfalls: (1) violation of\nindependence assumption, (2) model evaluation with an inappropriate performance\nindicator, and (3) batch effect and how these pitfalls could affect the\ngeneralizability of machine learning models. We implement random forest and\ndeep convolutional neural network models using several medical imaging\ndatasets, including head and neck CT, lung CT, chest X-Ray, and\nhistopathological images, to quantify and illustrate the effect of these\npitfalls. We develop these models with and without the pitfall and compare the\nperformance of the resulting models in terms of accuracy, precision, recall,\nand F1 score. Our results showed that violation of the independence assumption\ncould substantially affect model generalizability. More specifically, (I)\napplying oversampling before splitting data into train, validation and test\nsets; (II) performing data augmentation before splitting data; (III)\ndistributing data points for a subject across training, validation, and test\nsets; and (IV) applying feature selection before splitting data led to\nsuperficial boosts in model performance. We also observed that inappropriate\nperformance indicators could lead to erroneous conclusions. Also, batch effect\ncould lead to developing models that lack generalizability. The aforementioned\nmethodological pitfalls lead to machine learning models with over-optimistic\nperformance. These errors, if made, cannot be captured using internal model\nevaluation, and the inaccurate predictions made by the model may lead to wrong\nconclusions and interpretations. Therefore, avoiding these pitfalls is a\nnecessary condition for developing generalizable models.",
    "descriptor": "\nComments: 13 pages, 7 Figures\n",
    "authors": [
      "Farhad Maleki",
      "Katie Ovens",
      "Rajiv Gupta",
      "Caroline Reinhold",
      "Alan Spatz",
      "Reza Forghani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2202.01337"
  },
  {
    "id": "arXiv:2202.01338",
    "title": "Regression Transformer: Concurrent Conditional Generation and Regression  by Blending Numerical and Textual Tokens",
    "abstract": "We report the Regression Transformer (RT), a method that abstracts regression\nas a conditional sequence modeling problem. The RT casts continuous properties\nas sequences of numerical tokens and encodes them jointly with conventional\ntokens. This yields a dichotomous model that can seamlessly transition between\nsolving regression tasks and conditional generation tasks; solely governed by\nthe mask location. We propose several extensions to the XLNet objective and\nadopt an alternating training scheme to concurrently optimize property\nprediction and conditional text generation based on a self-consistency loss.\nOur experiments on both chemical and protein languages demonstrate that the\nperformance of traditional regression models can be surpassed despite training\nwith cross entropy loss. Importantly, priming the same model with continuous\nproperties yields a highly competitive conditional generative models that\noutperforms specialized approaches in a constrained property optimization\nbenchmark. In sum, the Regression Transformer opens the door for \"swiss army\nknife\" models that excel at both regression and conditional generation. This\nfinds application particularly in property-driven, local exploration of the\nchemical or protein space.",
    "descriptor": "",
    "authors": [
      "Jannis Born",
      "Matteo Manica"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Biomolecules (q-bio.BM)"
    ],
    "url": "https://arxiv.org/abs/2202.01338"
  },
  {
    "id": "arXiv:2202.01339",
    "title": "Understanding Cross-Domain Few-Shot Learning: An Experimental Study",
    "abstract": "Cross-domain few-shot learning has drawn increasing attention for handling\nlarge differences between the source and target domains--an important concern\nin real-world scenarios. To overcome these large differences, recent works have\nconsidered exploiting small-scale unlabeled data from the target domain during\nthe pre-training stage. This data enables self-supervised pre-training on the\ntarget domain, in addition to supervised pre-training on the source domain. In\nthis paper, we empirically investigate scenarios under which it is advantageous\nto use each pre-training scheme, based on domain similarity and few-shot\ndifficulty: performance gain of self-supervised pre-training over supervised\npre-training increases when domain similarity is smaller or few-shot difficulty\nis lower. We further design two pre-training schemes, mixed-supervised and\ntwo-stage learning, that improve performance. In this light, we present seven\nfindings for CD-FSL which are supported by extensive experiments and analyses\non three source and eight target benchmark datasets with varying levels of\ndomain similarity and few-shot difficulty. Our code is available at\nhttps://anonymous.4open.science/r/understandingCDFSL.",
    "descriptor": "\nComments: Under review ICML 2022\n",
    "authors": [
      "Jaehoon Oh",
      "Sungnyun Kim",
      "Namgyu Ho",
      "Jin-Hwa Kim",
      "Hwanjun Song",
      "Se-Young Yun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.01339"
  },
  {
    "id": "arXiv:2202.01340",
    "title": "An Artificial Intelligence Dataset for Solar Energy Locations in India",
    "abstract": "Rapid development of renewable energy sources, particularly solar\nphotovoltaics, is critical to mitigate climate change. As a result, India has\nset ambitious goals to install 300 gigawatts of solar energy capacity by 2030.\nGiven the large footprint projected to meet these renewable energy targets the\npotential for land use conflicts over environmental and social values is high.\nTo expedite development of solar energy, land use planners will need access to\nup-to-date and accurate geo-spatial information of PV infrastructure. The\nmajority of recent studies use either predictions of resource suitability or\ndatabases that are either developed thru crowdsourcing that often have\nsignificant sampling biases or have time lags between when projects are\npermitted and when location data becomes available. Here, we address this\nshortcoming by developing a spatially explicit machine learning model to map\nutility-scale solar projects across India. Using these outputs, we provide a\ncumulative measure of the solar footprint across India and quantified the\ndegree of land modification associated with land cover types that may cause\nconflicts. Our analysis indicates that over 74\\% of solar development In India\nwas built on landcover types that have natural ecosystem preservation, and\nagricultural values. Thus, with a mean accuracy of 92\\% this method permits the\nidentification of the factors driving land suitability for solar projects and\nwill be of widespread interest for studies seeking to assess trade-offs\nassociated with the global decarbonization of green-energy systems. In the same\nway, our model increases the feasibility of remote sensing and long-term\nmonitoring of renewable energy deployment targets.",
    "descriptor": "",
    "authors": [
      "Anthony Ortiz",
      "Dhaval Negandhi",
      "Sagar R Mysorekar",
      "Joseph Kiesecker",
      "Shivaprakash K Nagaraju",
      "Caleb Robinson",
      "Priyal Bhatia",
      "Aditi Khurana",
      "Jane Wang",
      "Felipe Oviedo",
      "Juan Lavista Ferres"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.01340"
  },
  {
    "id": "arXiv:2202.01341",
    "title": "Robust Binary Models by Pruning Randomly-initialized Networks",
    "abstract": "We propose ways to obtain robust models against adversarial attacks from\nrandomly-initialized binary networks. Unlike adversarial training, which learns\nthe model parameters, we in contrast learn the structure of the robust model by\npruning a randomly-initialized binary network. Our method confirms the strong\nlottery ticket hypothesis in the presence of adversarial attacks. Compared to\nthe results obtained in a non-adversarial setting, we in addition improve the\nperformance and compression of the model by 1) using an adaptive pruning\nstrategy for different layers, and 2) using a different initialization scheme\nsuch that all model parameters are initialized either to +1 or -1. Our\nextensive experiments demonstrate that our approach performs not only better\nthan the state-of-the art for robust binary networks; it also achieves\ncomparable or even better performance than full-precision network training\nmethods.",
    "descriptor": "",
    "authors": [
      "Chen Liu",
      "Ziqi Zhao",
      "Sabine S\u00fcsstrunk",
      "Mathieu Salzmann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.01341"
  },
  {
    "id": "arXiv:2202.01344",
    "title": "Formal Mathematics Statement Curriculum Learning",
    "abstract": "We explore the use of expert iteration in the context of language modeling\napplied to formal mathematics. We show that at same compute budget, expert\niteration, by which we mean proof search interleaved with learning,\ndramatically outperforms proof search only. We also observe that when applied\nto a collection of formal statements of sufficiently varied difficulty, expert\niteration is capable of finding and solving a curriculum of increasingly\ndifficult problems, without the need for associated ground-truth proofs.\nFinally, by applying this expert iteration to a manually curated set of problem\nstatements, we achieve state-of-the-art on the miniF2F benchmark, automatically\nsolving multiple challenging problems drawn from high school olympiads.",
    "descriptor": "",
    "authors": [
      "Stanislas Polu",
      "Jesse Michael Han",
      "Kunhao Zheng",
      "Mantas Baksys",
      "Igor Babuschkin",
      "Ilya Sutskever"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.01344"
  },
  {
    "id": "arXiv:2202.01348",
    "title": "VindiCo: Privacy Safeguard Against Adaptation Based Spyware in  Human-in-the-Loop IoT",
    "abstract": "Personalized IoT adapts their behavior based on contextual information, such\nas user behavior and location. Unfortunately, the fact that personalized IoT\nadapts to user context opens a side-channel that leaks private information\nabout the user. To that end, we start by studying the extent to which a\nmalicious eavesdropper can monitor the actions taken by an IoT system and\nextract users' private information. In particular, we show two concrete\ninstantiations (in the context of mobile phones and smart homes) of a new\ncategory of spyware which we refer to as Context-Aware Adaptation Based Spyware\n(SpyCon). Experimental evaluations show that the developed SpyCon can predict\nusers' daily behavior with an accuracy of 90.3%. The rest of this paper is\ndevoted to introducing VindiCo, a software mechanism designed to detect and\nmitigate possible SpyCon. Being new spyware with no known prior signature or\nbehavior, traditional spyware detection that is based on code signature or app\nbehavior is not adequate to detect SpyCon. Therefore, VindiCo proposes a novel\ninformation-based detection engine along with several mitigation techniques to\nrestrain the ability of the detected SpyCon to extract private information. By\nhaving general detection and mitigation engines, VindiCo is agnostic to the\ninference algorithm used by SpyCon. Our results show that VindiCo reduces the\nability of SpyCon to infer user context from 90.3% to the baseline accuracy\n(accuracy based on random guesses) with negligible execution overhead.",
    "descriptor": "\nComments: 21 pages. First part of this work is published in the SafeThings'19: IEEE Security and Privacy Workshops (S&P Workshop) and in CitiFog'18: Proceedings of the 1st ACM International Workshop on Smart Cities and Fog Computing (Sensys'18 Workshop)\n",
    "authors": [
      "Salma Elmalaki",
      "Bo-Jhang Ho",
      "Moustafa Alzantot",
      "Yasser Shoukry",
      "Mani Srivastava"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.01348"
  },
  {
    "id": "arXiv:2202.01351",
    "title": "Technology Ethics in Action: Critical and Interdisciplinary Perspectives",
    "abstract": "This special issue interrogates the meaning and impacts of \"tech ethics\": the\nembedding of ethics into digital technology research, development, use, and\ngovernance. In response to concerns about the social harms associated with\ndigital technologies, many individuals and institutions have articulated the\nneed for a greater emphasis on ethics in digital technology. Yet as more groups\nembrace the concept of ethics, critical discourses have emerged questioning\nwhose ethics are being centered, whether \"ethics\" is the appropriate frame for\nimproving technology, and what it means to develop \"ethical\" technology in\npractice. This interdisciplinary issue takes up these questions, interrogating\nthe relationships among ethics, technology, and society in action. This special\nissue engages with the normative and contested notions of ethics itself, how\nethics has been integrated with technology across domains, and potential paths\nforward to support more just and egalitarian technology. Rather than starting\nfrom philosophical theories, the authors in this issue orient their articles\naround the real-world discourses and impacts of tech ethics--i.e., tech ethics\nin action.",
    "descriptor": "",
    "authors": [
      "Ben Green"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.01351"
  },
  {
    "id": "arXiv:2202.01354",
    "title": "Dissecting BFT Consensus: In Trusted Components we Trust!",
    "abstract": "The growing interest in secure multi-party database applications has led to\nthe widespread adoption of Byzantine Fault-Tolerant (BFT) consensus protocols\nthat can handle malicious attacks from byzantine replicas. Existing BFT\nprotocols permit byzantine replicas to equivocate their messages. As a result,\nthey need f more replicas than Paxos-style protocols to prevent safety\nviolations due to equivocation. This led to the design of Trust-BFT protocols,\nwhich require each replica to host an independent, trusted component.\nIn this work, we analyze the design of existing Trust-BFT and make the\nfollowing observations regarding these protocols: (i) they adopt weaker\nquorums, which prevents them from providing service in scenarios supported by\ntheir BFT counterparts, (ii) they rely on the data persistence of trusted\ncomponents at byzantine replicas, and (iii) they enforce sequential ordering of\nclient requests.\nTo resolve these challenges, we present solutions that facilitate the\nrecovery of Trust-BFT protocols despite their weak quorums or data persistence\ndependence. Further, we present the design of lightweight, fast, and flexible\nprotocols (FlexiTrust), which achieve up to 100% more throughput than their\nTrust-BFT counterparts.",
    "descriptor": "",
    "authors": [
      "Suyash Gupta",
      "Sajjad Rahnama",
      "Shubham Pandey",
      "Natacha Crooks",
      "Mohammad Sadoghi"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2202.01354"
  },
  {
    "id": "arXiv:2202.01356",
    "title": "Direct Molecular Conformation Generation",
    "abstract": "Molecular conformation generation aims to generate three-dimensional\ncoordinates of all the atoms in a molecule and is an important task in\nbioinformatics and pharmacology. Previous distance-based methods first predict\ninteratomic distances and then generate conformations based on them, which\ncould result in conflicting distances. In this work, we propose a method that\ndirectly predicts the coordinates of atoms. We design a dedicated loss function\nfor conformation generation, which is invariant to roto-translation of\ncoordinates of conformations and permutation of symmetric atoms in molecules.\nWe further design a backbone model that stacks multiple blocks, where each\nblock refines the conformation generated by its preceding block. Our method\nachieves state-of-the-art results on four public benchmarks: on small-scale\nGEOM-QM9 and GEOM-Drugs which have $200$K training data, we can improve the\nprevious best matching score by $3.5\\%$ and $28.9\\%$; on large-scale GEOM-QM9\nand GEOM-Drugs which have millions of training data, those two improvements are\n$47.1\\%$ and $36.3\\%$. This shows the effectiveness of our method and the great\npotential of the direct approach. Our code is released at\n\\url{https://github.com/DirectMolecularConfGen/DMCG}.",
    "descriptor": "",
    "authors": [
      "Jinhua Zhu",
      "Yingce Xia",
      "Chang Liu",
      "Lijun Wu",
      "Shufang Xie",
      "Tong Wang",
      "Yusong Wang",
      "Wengang Zhou",
      "Tao Qin",
      "Houqiang Li",
      "Tie-Yan Liu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.01356"
  },
  {
    "id": "arXiv:2202.01358",
    "title": "Safe Learning for Uncertainty-Aware Planning via Interval MDP  Abstraction-CDC&L-CSS Version",
    "abstract": "We study the problem of refining satisfiability bounds for partially-known\nswitched stochastic systems against planning specifications defined using\nsyntatically co-safe Linear Temporal Logic (scLTL). We propose an\nabstraction-based approach that iteratively generates high-confidence Interval\nMarkov Decision Process (IMDP) abstractions of the system from high-confidence\nbounds on the unknown component of the dynamics obtained via Gaussian process\nregression. In particular, we develop a synthesis strategy to sample the\nunknown dynamics by finding paths which avoid specification-violating states\nusing a product IMDP formulation. We further provide a heuristic to choose\namong various candidate paths to maximize the information gain. Finally, we\npropose an iterative algorithm to synthesize a satisfying control policy for\nthe product IMDP system. We demonstrate our work with a case study on mobile\nrobot navigation.",
    "descriptor": "\nComments: 8 pages, 3 figures. Submitted to L-CSS with CDC option\n",
    "authors": [
      "Jesse Jiang",
      "Ye Zhao",
      "Samuel Coogan"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.01358"
  },
  {
    "id": "arXiv:2202.01361",
    "title": "Generative Flow Networks for Discrete Probabilistic Modeling",
    "abstract": "We present energy-based generative flow networks (EB-GFN), a novel\nprobabilistic modeling algorithm for high-dimensional discrete data. Building\nupon the theory of generative flow networks (GFlowNets), we model the\ngeneration process by a stochastic data construction policy and thus amortize\nexpensive MCMC exploration into a fixed number of actions sampled from a\nGFlowNet. We show how GFlowNets can approximately perform large-block Gibbs\nsampling to mix between modes. We propose a framework to jointly train a\nGFlowNet with an energy function, so that the GFlowNet learns to sample from\nthe energy distribution, while the energy learns with an approximate MLE\nobjective with negative samples from the GFlowNet. We demonstrate EB-GFN's\neffectiveness on various probabilistic modeling tasks.",
    "descriptor": "\nComments: 17 pages; code: this https URL\n",
    "authors": [
      "Dinghuai Zhang",
      "Nikolay Malkin",
      "Zhen Liu",
      "Alexandra Volokhova",
      "Aaron Courville",
      "Yoshua Bengio"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.01361"
  },
  {
    "id": "arXiv:2202.01362",
    "title": "VNE Solution for Network Differentiated QoS and Security Requirements:  From the Perspective of Deep Reinforcement Learning",
    "abstract": "The rapid development and deployment of network services has brought a series\nof challenges to researchers. On the one hand, the needs of Internet end\nusers/applications reflect the characteristics of travel alienation, and they\npursue different perspectives of service quality. On the other hand, with the\nexplosive growth of information in the era of big data, a lot of private\ninformation is stored in the network. End users/applications naturally start to\npay attention to network security. In order to solve the requirements of\ndifferentiated quality of service (QoS) and security, this paper proposes a\nvirtual network embedding (VNE) algorithm based on deep reinforcement learning\n(DRL), aiming at the CPU, bandwidth, delay and security attributes of substrate\nnetwork. DRL agent is trained in the network environment constructed by the\nabove attributes. The purpose is to deduce the mapping probability of each\nsubstrate node and map the virtual node according to this probability. Finally,\nthe breadth first strategy (BFS) is used to map the virtual links. In the\nexperimental stage, the algorithm based on DRL is compared with other\nrepresentative algorithms in three aspects: long term average revenue, long\nterm revenue consumption ratio and acceptance rate. The results show that the\nalgorithm proposed in this paper has achieved good experimental results, which\nproves that the algorithm can be effectively applied to solve the end\nuser/application differentiated QoS and security requirements.",
    "descriptor": "",
    "authors": [
      "Chao Wang",
      "Ranbir Singh Batth",
      "Peiying Zhang",
      "Gagangeet Singh Aujla",
      "Youxiang Duan",
      "Lihua Ren"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2202.01362"
  },
  {
    "id": "arXiv:2202.01365",
    "title": "Feasibility of Interactive 3D Map for Remote Sighted Assistance",
    "abstract": "Remote sighted assistance (RSA) has emerged as a conversational assistive\ntechnology, where remote sighted workers, i.e., agents, provide real-time\nassistance to users with vision impairments via video-chat-like communication.\nResearchers found that agents' lack of environmental knowledge, the difficulty\nof orienting users in their surroundings, and the inability to estimate\ndistances from users' camera feeds are key challenges to sighted agents. To\naddress these challenges, researchers have suggested assisting agents with\ncomputer vision technologies, especially 3D reconstruction. This paper presents\na high-fidelity prototype of such an RSA, where agents use interactive 3D maps\nwith localization capability. We conducted a walkthrough study with thirteen\nagents and one user with simulated vision impairment using this prototype. The\nstudy revealed that, compared to baseline RSA, the agents were significantly\nfaster in providing navigational assistance to users, and their mental workload\nwas significantly reduced -- all indicate the feasibility and prospect of 3D\nmaps in RSA.",
    "descriptor": "",
    "authors": [
      "Jingyi Xie",
      "Rui Yu",
      "Sooyeon Lee",
      "Yao Lyu",
      "Syed Masum Billah",
      "John M. Carroll"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2202.01365"
  },
  {
    "id": "arXiv:2202.01367",
    "title": "Real-time Emergency Vehicle Event Detection Using Audio Data",
    "abstract": "In this work, we focus on detecting emergency vehicles using only audio data.\nImproved and quick detection can help in faster preemption of these vehicles at\nsignalized intersections thereby reducing overall response time in case of\nemergencies. Important audio features were extracted from raw data and passed\ninto extreme learning machines (ELM) for training. ELMs have been used in this\nwork because of its simplicity and shorter run-time which can therefore be used\nfor online learning. Recently, there have been many studies that focus on sound\nclassification but most of the methods used are complex to train and implement.\nThe results from this paper show that ELM can achieve similar performance with\nexceptionally shorter training times. The accuracy reported for ELM is about\n97% for emergency vehicle detection (EVD).",
    "descriptor": "",
    "authors": [
      "Zubayer Islam",
      "Mohamed Abdel-Aty"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2202.01367"
  },
  {
    "id": "arXiv:2202.01374",
    "title": "mSLAM: Massively multilingual joint pre-training for speech and text",
    "abstract": "We present mSLAM, a multilingual Speech and LAnguage Model that learns\ncross-lingual cross-modal representations of speech and text by pre-training\njointly on large amounts of unlabeled speech and text in multiple languages.\nmSLAM combines w2v-BERT pre-training on speech with SpanBERT pre-training on\ncharacter-level text, along with Connectionist Temporal Classification (CTC)\nlosses on paired speech and transcript data, to learn a single model capable of\nlearning from and representing both speech and text signals in a shared\nrepresentation space. We evaluate mSLAM on several downstream speech\nunderstanding tasks and find that joint pre-training with text improves quality\non speech translation, speech intent classification and speech language-ID\nwhile being competitive on multilingual ASR, when compared against speech-only\npre-training. Our speech translation model demonstrates zero-shot text\ntranslation without seeing any text translation data, providing evidence for\ncross-modal alignment of representations. mSLAM also benefits from multi-modal\nfine-tuning, further improving the quality of speech translation by directly\nleveraging text translation data during the fine-tuning process. Our empirical\nanalysis highlights several opportunities and challenges arising from\nlarge-scale multimodal pre-training, suggesting directions for future research.",
    "descriptor": "",
    "authors": [
      "Ankur Bapna",
      "Colin Cherry",
      "Yu Zhang",
      "Ye Jia",
      "Melvin Johnson",
      "Yong Cheng",
      "Simran Khanuja",
      "Jason Riesa",
      "Alexis Conneau"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.01374"
  },
  {
    "id": "arXiv:2202.01375",
    "title": "Resource Management and Security Scheme of ICPSs and IoT Based on VNE  Algorithm",
    "abstract": "The development of Intelligent Cyber-Physical Systems (ICPSs) in virtual\nnetwork environment is facing severe challenges. On the one hand, the Internet\nof things (IoT) based on ICPSs construction needs a large amount of reasonable\nnetwork resources support. On the other hand, ICPSs are facing severe network\nsecurity problems. The integration of ICPSs and network virtualization (NV) can\nprovide more efficient network resource support and security guarantees for IoT\nusers. Based on the above two problems faced by ICPSs, we propose a virtual\nnetwork embedded (VNE) algorithm with computing, storage resources and security\nconstraints to ensure the rationality and security of resource allocation in\nICPSs. In particular, we use reinforcement learning (RL) method as a means to\nimprove algorithm performance. We extract the important attribute\ncharacteristics of underlying network as the training environment of RL agent.\nAgent can derive the optimal node embedding strategy through training, so as to\nmeet the requirements of ICPSs for resource management and security. The\nembedding of virtual links is based on the breadth first search (BFS) strategy.\nTherefore, this is a comprehensive two-stage RL-VNE algorithm considering the\nconstraints of computing, storage and security three-dimensional resources.\nFinally, we design a large number of simulation experiments from the\nperspective of typical indicators of VNE algorithms. The experimental results\neffectively illustrate the effectiveness of the algorithm in the application of\nICPSs.",
    "descriptor": "",
    "authors": [
      "Peiying Zhang",
      "Chao Wang",
      "Chunxiao Jiang",
      "Neeraj Kumar",
      "Qinghua Lu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2202.01375"
  },
  {
    "id": "arXiv:2202.01380",
    "title": "Learning Mechanically Driven Emergent Behavior with Message Passing  Neural Networks",
    "abstract": "From designing architected materials to connecting mechanical behavior across\nscales, computational modeling is a critical tool in solid mechanics. Recently,\nthere has been a growing interest in using machine learning to reduce the\ncomputational cost of physics-based simulations. Notably, while machine\nlearning approaches that rely on Graph Neural Networks (GNNs) have shown\nsuccess in learning mechanics, the performance of GNNs has yet to be\ninvestigated on a myriad of solid mechanics problems. In this work, we examine\nthe ability of GNNs to predict a fundamental aspect of mechanically driven\nemergent behavior: the connection between a column's geometric structure and\nthe direction that it buckles. To accomplish this, we introduce the Asymmetric\nBuckling Columns (ABC) dataset, a dataset comprised of three sub-datasets of\nasymmetric and heterogeneous column geometries where the goal is to classify\nthe direction of symmetry breaking (left or right) under compression after the\nonset of instability. Because of complex local geometry, the \"image-like\" data\nrepresentations required for implementing standard convolutional neural network\nbased metamodels are not ideal, thus motivating the use of GNNs. In addition to\ninvestigating GNN model architecture, we study the effect of different input\ndata representation approaches, data augmentation, and combining multiple\nmodels as an ensemble. While we were able to obtain good results, we also\nshowed that predicting solid mechanics based emergent behavior is non-trivial.\nBecause both our model implementation and dataset are distributed under\nopen-source licenses, we hope that future researchers can build on our work to\ncreate enhanced mechanics-specific machine learning pipelines for capturing the\nbehavior of complex geometric structures.",
    "descriptor": "\nComments: 21 pages, 10 figures\n",
    "authors": [
      "Peerasait Prachaseree",
      "Emma Lejeune"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ],
    "url": "https://arxiv.org/abs/2202.01380"
  },
  {
    "id": "arXiv:2202.01381",
    "title": "ETSformer: Exponential Smoothing Transformers for Time-series  Forecasting",
    "abstract": "Transformers have been actively studied for time-series forecasting in recent\nyears. While often showing promising results in various scenarios, traditional\nTransformers are not designed to fully exploit the characteristics of\ntime-series data and thus suffer some fundamental limitations, e.g., they\ngenerally lack of decomposition capability and interpretability, and are\nneither effective nor efficient for long-term forecasting. In this paper, we\npropose ETSFormer, a novel time-series Transformer architecture, which exploits\nthe principle of exponential smoothing in improving Transformers for\ntime-series forecasting. In particular, inspired by the classical exponential\nsmoothing methods in time-series forecasting, we propose the novel exponential\nsmoothing attention (ESA) and frequency attention (FA) to replace the\nself-attention mechanism in vanilla Transformers, thus improving both accuracy\nand efficiency. Based on these, we redesign the Transformer architecture with\nmodular decomposition blocks such that it can learn to decompose the\ntime-series data into interpretable time-series components such as level,\ngrowth and seasonality. Extensive experiments on various time-series benchmarks\nvalidate the efficacy and advantages of the proposed method. The code and\nmodels of our implementations will be released.",
    "descriptor": "",
    "authors": [
      "Gerald Woo",
      "Chenghao Liu",
      "Doyen Sahoo",
      "Akshat Kumar",
      "Steven Hoi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.01381"
  },
  {
    "id": "arXiv:2202.01385",
    "title": "Technical Report: A Hierarchical Deliberative-Reactive System  Architecture for Task and Motion Planning in Partially Known Environments",
    "abstract": "We describe a task and motion planning architecture for highly dynamic\nsystems that combines a domain-independent sampling-based deliberative planning\nalgorithm with a global reactive planner. We leverage the recent development of\na reactive, vector field planner that provides guarantees of reachability to\nlarge regions of the environment even in the face of unknown or unforeseen\nobstacles. The reachability guarantees can be formalized using contracts that\nallow a deliberative planner to reason purely in terms of those contracts and\nsynthesize a plan by choosing a sequence of reactive behaviors and their target\nconfigurations, without evaluating specific motion plans between targets. This\nreduces both the search depth at which plans will be found, and the number of\nsamples required to ensure a plan exists, while crucially preserving\ncorrectness guarantees. The result is reduced computational cost of\nsynthesizing plans, and increased robustness of generated plans to actuator\nnoise, model misspecification, or unknown obstacles. Simulation studies show\nthat our hierarchical planning and execution architecture can solve complex\nnavigation and rearrangement tasks, even when faced with narrow passageways or\nincomplete world information.",
    "descriptor": "\nComments: Technical Report accompanying the paper \"A Hierarchical Deliberative-Reactive System Architecture for Task and Motion Planning in Partially Known Environments\" at ICRA 2022 (8 pages, 6 figures)\n",
    "authors": [
      "Vasileios Vasilopoulos",
      "Sebastian Castro",
      "William Vega-Brown",
      "Daniel E. Koditschek",
      "Nicholas Roy"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.01385"
  },
  {
    "id": "arXiv:2202.01390",
    "title": "Exploring Sub-skeleton Trajectories for Interpretable Recognition of  Sign Language",
    "abstract": "Recent advances in tracking sensors and pose estimation software enable smart\nsystems to use trajectories of skeleton joint locations for supervised\nlearning. We study the problem of accurately recognizing sign language words,\nwhich is key to narrowing the communication gap between hard and non-hard of\nhearing people.\nOur method explores a geometric feature space that we call `sub-skeleton'\naspects of movement. We assess similarity of feature space trajectories using\nnatural, speed invariant distance measures, which enables clear and insightful\nnearest neighbor classification. The simplicity and scalability of our basic\nmethod allows for immediate application in different data domains with little\nto no parameter tuning.\nWe demonstrate the effectiveness of our basic method, and a boosted\nvariation, with experiments on data from different application domains and\ntracking technologies. Surprisingly, our simple methods improve sign\nrecognition over recent, state-of-the-art approaches.",
    "descriptor": "\nComments: To appear in Proc. of the 27th International Conference on Database Systems for Advanced Applications (DASFAA-2022)\n",
    "authors": [
      "Joachim Gudmundsson",
      "Martin P. Seybold",
      "John Pfeifer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.01390"
  },
  {
    "id": "arXiv:2202.01391",
    "title": "Fair Representation Clustering with Several Protected Classes",
    "abstract": "We study the problem of fair $k$-median where each cluster is required to\nhave a fair representation of individuals from different groups. In the fair\nrepresentation $k$-median problem, we are given a set of points $X$ in a metric\nspace. Each point $x\\in X$ belongs to one of $\\ell$ groups. Further, we are\ngiven fair representation parameters $\\alpha_j$ and $\\beta_j$ for each group\n$j\\in [\\ell]$. We say that a $k$-clustering $C_1, \\cdots, C_k$ fairly\nrepresents all groups if the number of points from group $j$ in cluster $C_i$\nis between $\\alpha_j |C_i|$ and $\\beta_j |C_i|$ for every $j\\in[\\ell]$ and\n$i\\in [k]$. The goal is to find a set $\\mathcal{C}$ of $k$ centers and an\nassignment $\\phi: X\\rightarrow \\mathcal{C}$ such that the clustering defined by\n$(\\mathcal{C}, \\phi)$ fairly represents all groups and minimizes the\n$\\ell_1$-objective $\\sum_{x\\in X} d(x, \\phi(x))$.\nWe present an $O(\\log k)$-approximation algorithm that runs in time\n$n^{O(\\ell)}$. Note that the known algorithms for the problem either (i)\nviolate the fairness constraints by an additive term or (ii) run in time that\nis exponential in both $k$ and $\\ell$. We also consider an important special\ncase of the problem where $\\alpha_j = \\beta_j = \\frac{f_j}{f}$ and $f_j, f \\in\n\\mathbb{N}$ for all $j\\in [\\ell]$. For this special case, we present an $O(\\log\nk)$-approximation algorithm that runs in $(kf)^{O(\\ell)}\\log n + poly(n)$ time.",
    "descriptor": "",
    "authors": [
      "Zhen Dai",
      "Yury Makarychev",
      "Ali Vakilian"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.01391"
  },
  {
    "id": "arXiv:2202.01395",
    "title": "SDEX: Monte Carlo Simulation of Stochastic Differential Equations on  Memristor Crossbars",
    "abstract": "Here we present stochastic differential equations (SDEs) on a memristor\ncrossbar, where the source of gaussian noise is derived from the random\nconductance due to ion drift in the devices during programming. We examine the\neffects of line resistance on the generation of normal random vectors, showing\nthe skew and kurtosis are within acceptable bounds. We then show the\nimplementation of a stochastic differential equation solver for the\nBlack-Scholes SDE, and compare the distribution with the analytic solution. We\ndetermine that the random number generation works as intended, and calculate\nthe energy cost of the simulation.",
    "descriptor": "\nComments: 5 pages, 3 Figures, submitted to ISCAS 2022\n",
    "authors": [
      "Louis Primeau",
      "Amirali Amirsoleimani",
      "Roman Genov"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2202.01395"
  },
  {
    "id": "arXiv:2202.01397",
    "title": "Learning with Asymmetric Kernels: Least Squares and Feature  Interpretation",
    "abstract": "Asymmetric kernels naturally exist in real life, e.g., for conditional\nprobability and directed graphs. However, most of the existing kernel-based\nlearning methods require kernels to be symmetric, which prevents the use of\nasymmetric kernels. This paper addresses the asymmetric kernel-based learning\nin the framework of the least squares support vector machine named AsK-LS,\nresulting in the first classification method that can utilize asymmetric\nkernels directly. We will show that AsK-LS can learn with asymmetric features,\nnamely source and target features, while the kernel trick remains applicable,\ni.e., the source and target features exist but are not necessarily known.\nBesides, the computational burden of AsK-LS is as cheap as dealing with\nsymmetric kernels. Experimental results on the Corel database, directed graphs,\nand the UCI database will show that in the case asymmetric information is\ncrucial, the proposed AsK-LS can learn with asymmetric kernels and performs\nmuch better than the existing kernel methods that have to do symmetrization to\naccommodate asymmetric kernels.",
    "descriptor": "",
    "authors": [
      "Mingzhen He",
      "Fan He",
      "Lei Shi",
      "Xiaolin Huang",
      "Johan A.K. Suykens"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.01397"
  },
  {
    "id": "arXiv:2202.01402",
    "title": "GALAXY: Graph-based Active Learning at the Extreme",
    "abstract": "Active learning is a label-efficient approach to train highly effective\nmodels while interactively selecting only small subsets of unlabelled data for\nlabelling and training. In \"open world\" settings, the classes of interest can\nmake up a small fraction of the overall dataset -- most of the data may be\nviewed as an out-of-distribution or irrelevant class. This leads to extreme\nclass-imbalance, and our theory and methods focus on this core issue. We\npropose a new strategy for active learning called GALAXY (Graph-based Active\nLearning At the eXtrEme), which blends ideas from graph-based active learning\nand deep learning. GALAXY automatically and adaptively selects more\nclass-balanced examples for labeling than most other methods for active\nlearning. Our theory shows that GALAXY performs a refined form of uncertainty\nsampling that gathers a much more class-balanced dataset than vanilla\nuncertainty sampling. Experimentally, we demonstrate GALAXY's superiority over\nexisting state-of-art deep active learning algorithms in unbalanced vision\nclassification settings generated from popular datasets.",
    "descriptor": "",
    "authors": [
      "Jifan Zhang",
      "Julian Katz-Samuels",
      "Robert Nowak"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.01402"
  },
  {
    "id": "arXiv:2202.01414",
    "title": "DocBed: A Multi-Stage OCR Solution for Documents with Complex Layouts",
    "abstract": "Digitization of newspapers is of interest for many reasons including\npreservation of history, accessibility and search ability, etc. While\ndigitization of documents such as scientific articles and magazines is\nprevalent in literature, one of the main challenges for digitization of\nnewspaper lies in its complex layout (e.g. articles spanning multiple columns,\ntext interrupted by images) analysis, which is necessary to preserve human\nread-order. This work provides a major breakthrough in the digitization of\nnewspapers on three fronts: first, releasing a dataset of 3000 fully-annotated,\nreal-world newspaper images from 21 different U.S. states representing an\nextensive variety of complex layouts for document layout analysis; second,\nproposing layout segmentation as a precursor to existing optical character\nrecognition (OCR) engines, where multiple state-of-the-art image segmentation\nmodels and several post-processing methods are explored for document layout\nsegmentation; third, providing a thorough and structured evaluation protocol\nfor isolated layout segmentation and end-to-end OCR.",
    "descriptor": "\nComments: 7 pages, 6 figures, The Thirty-Fourth Annual Conference on Innovative Applications of Artificial Intelligence (IAAI-22), Collocated with AAAI-22\n",
    "authors": [
      "Wenzhen Zhu",
      "Negin Sokhandan",
      "Guang Yang",
      "Sujitha Martin",
      "Suchitra Sathyanarayana"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.01414"
  },
  {
    "id": "arXiv:2202.01415",
    "title": "Synthesis of Modeling, Visualization, and Programming in GeoGebra as an  Effective Approach for Teaching and Learning STEM Topics",
    "abstract": "GeoGebra is an interactive geometry, algebra, statistics, and calculus\napplication designed for teaching and learn-ing math, science, and engineering.\nIts dynamic interface allows its users to accurately and interactively\nvisualize their work, models, and results. GeoGebra employs the synthesis of\nthree key features: modeling, visualization, and programming (MVP). Many\nstudies have shown the positive effects of GeoGebra on the efficiency and\neffectiveness of learning and teaching topics related to science, technology,\nengineering, and mathematics. In this study, we dis-cuss how GeoGebra provides\nan environment for learning that is very interactive and collaborative between\nthe learner and the instructor. We also show how integrating GeoGebra into the\nlearning scheme can help improve the skills and knowledge of school and\nuniversity students in numerous advanced mathematical courses, such as\ncalcu-lus, mathematical statistics, linear algebra, linear programming,\ncomputer-aided design, computer-aided geomet-ric design, analytic and\nprojective geometry, and graphical representation. Therefore, this study shows\nthe effec-tiveness of GeoGebra and its MVP key features in science and\nengineering, particularly in topics related to mathe-matics. Each key feature\nof GeoGebra is thoroughly analyzed, and further analyses, along with how\nGeoGebra can be helpful in different topics, are discussed.",
    "descriptor": "\nComments: 4 figures\n",
    "authors": [
      "Rushan Ziatdinov",
      "James R. Valles Jr"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2202.01415"
  },
  {
    "id": "arXiv:2202.01417",
    "title": "Generalized Omega Turn Gait Enables Agile Limbless Robot Turning in  Complex Environments",
    "abstract": "Reorientation (turning in plane) plays a critical role for all robots in any\nfield application, especially those that in confined spaces. While important,\nreorientation remains a relatively unstudied problem for robots, including\nlimbless mechanisms, often called snake robots. Instead of looking at snakes,\nwe take inspiration from observations of the turning behavior of tiny nematode\nworms C. elegans. Our previous work presented an in-place and in-plane turning\ngait for limbless robots, called an omega turn, and prescribed it using a novel\ntwo-wave template. In this work, we advance omega turn-inspired controllers in\nthree aspects: 1) we use geometric methods to vary joint angle amplitudes and\nforward wave spatial frequency in our turning equation to establish a wide and\nprecise amplitude modulation and frequency modulation on omega turn; 2) we use\nthis new relationship to enable robots with fewer internal degrees of freedom\n(i.e., fewer joints in the body) to achieve desirable performance, and 3) we\napply compliant control methods to this relationship to handle unmodelled\neffects in the environment. We experimentally validate our approach on a\nlimbless robot that the omega turn can produce effective and robust turning\nmotion in various types of environments, such as granular media and rock pile.",
    "descriptor": "\nComments: Accepted to ICRA 2022\n",
    "authors": [
      "Tianyu Wang",
      "Baxi Chong",
      "Yuelin Deng",
      "Ruijie Fu",
      "Howie Choset",
      "Daniel I. Goldman"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.01417"
  },
  {
    "id": "arXiv:2202.01421",
    "title": "Characterization of Semantic Segmentation Models on Mobile Platforms for  Self-Navigation in Disaster-Struck Zones",
    "abstract": "The role of unmanned vehicles for searching and localizing the victims in\ndisaster impacted areas such as earthquake-struck zones is getting more\nimportant. Self-navigation on an earthquake zone has a unique challenge of\ndetecting irregularly shaped obstacles such as road cracks, debris on the\nstreets, and water puddles. In this paper, we characterize a number of\nstate-of-the-art FCN models on mobile embedded platforms for self-navigation at\nthese sites containing extremely irregular obstacles. We evaluate the models in\nterms of accuracy, performance, and energy efficiency. We present a few\noptimizations for our designed vision system. Lastly, we discuss the trade-offs\nof these models for a couple of mobile platforms that can each perform\nself-navigation. To enable vehicles to safely navigate earthquake-struck zones,\nwe compiled a new annotated image database of various earthquake impacted\nregions that is different than traditional road damage databases. We train our\ndatabase with a number of state-of-the-art semantic segmentation models in\norder to identify obstacles unique to earthquake-struck zones. Based on the\nstatistics and tradeoffs, an optimal CNN model is selected for the mobile\nvehicular platforms, which we apply to both low-power and extremely low-power\nconfigurations of our design. To our best knowledge, this is the first study\nthat identifies unique challenges and discusses the accuracy, performance, and\nenergy impact of edge-based self-navigation mobile vehicles for\nearthquake-struck zones. Our proposed database and trained models are publicly\navailable.",
    "descriptor": "\nComments: 12 pages, 18 figures\n",
    "authors": [
      "Ryan Zelek",
      "Hyeran Jeon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2202.01421"
  },
  {
    "id": "arXiv:2202.01422",
    "title": "Generation Alpha: Understanding the Next Cohort of University Students",
    "abstract": "Technology is changing at a blistering pace and is impacting on the way we\nconsider knowledge as a free commodity, along with the ability to apply skills,\nconcepts and understandings. Technology is aiding the way the world is\nevolving, and its contributions to education are not an exemption. While\ntechnology advances will play a crucial part in future teaching-learning\napproaches, educators will also be challenged by the next higher-education\ngeneration, the Alpha Generation. This entrepreneurial generation will embrace\nthe innovation, progressiveness, and advancement with the expectation that one\nin two Generation Alphas will obtain a university degree. In anticipating the\neducational challenges and opportunities of the future higher education\nenvironment, this research reflected on Generation Alpha as the next cohort of\nuniversity students, considering their preferred learning styles, perceptions\nand expectations relating to education. The research employed a theoretical\nanalysis based on the characteristics and traits that distinguishes Generation\nAlpha, spearheaded by technology advances. The empirical investigation\nconsidered three independent studies that were previous conducted by authors\nfrom Slovakia, Hungary, Australia, and Turkey to understand the challenges and\nopportunities pertaining to Generation Alpha. The research identified the\ninfluence of social media, social connections, high levels of perceptions and\nthe Generation Alpha's ability to interpret information as strengths to\nconsider in future teaching-learning approaches in the higher education\nenvironment. This research concluded with recommendations on how universities\ncould be transformed to ensure a better learning experience for Generation\nAlpha students, aligned with their characteristics, perceptions and\nexpectations.",
    "descriptor": "",
    "authors": [
      "Rushan Ziatdinov",
      "Juanee Cilliers"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2202.01422"
  },
  {
    "id": "arXiv:2202.01424",
    "title": "Identifying Friction in a Nonlinear Chaotic System Using a Universal  Adaptive Stabilizer",
    "abstract": "This paper proposes a friction model parameter identification routine that\ncan work with highly nonlinear and chaotic systems. The chosen system for this\nstudy is a passively-actuated tilted Furuta pendulum, which is known to have a\nhighly non linear and coupled model. The pendulum is tilted to ensure the\nexistence of a stable equilibrium configuration for all its degrees of freedom,\nand the link weights are the only external forces applied to the system. A\nnonlinear analytical model of the pendulum is derived, and a continuous\nfriction model considering static friction, dynamic friction, viscous friction,\nand the stribeck effect is selected from the literature. A high-gain Universal\nAdaptive Stabilizer (UAS) observer is designed to identify friction model\nparameters using joint angle measurements. The methodology is tested in\nsimulation and validated on an experimental setup. Despite the high\nnonlinearity of the system, the methodology is proven to converge to the exact\nparameter values, in simulation, and to yield qualitative parameter magnitudes\nin experiments where the goodness of fit was around 85\\% on average. The\ndiscrepancy between the simulation and the experimental results is attributed\nto the limitations of the friction model. The main advantage of the proposed\nmethod is the significant reduction in computational needs and the time\nrequired relative to conventional optimization-based identification routines.\nThe proposed approach yielded more than 99\\% reduction in the estimation time\nwhile being considerably more accurate than the optimization approach in every\ntest performed. One more advantage is that the approach can be easily adapted\nto fit other models to experimental data.",
    "descriptor": "\nComments: 16 pages, 12 figures\n",
    "authors": [
      "Ali Wadi",
      "Shayok Mukhopadhyay",
      "Lotfi Romdhane"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.01424"
  },
  {
    "id": "arXiv:2202.01425",
    "title": "A New Approach to Determine the Minimal Polynomials of Binary Modified  de Bruijn Sequences",
    "abstract": "A binary modified de Bruijn sequence is an infinite and periodic binary\nsequence derived by removing a zero from the longest run of zeros in a binary\nde Bruijn sequence. The minimal polynomial of the modified sequence is its\nunique least-degree characteristic polynomial. Leveraging on a recent\ncharacterization, we devise a novel general approach to determine the minimal\npolynomial. We translate the characterization into a problem of identifying a\nHamiltonian cycle in a specially constructed graph. Along the way, we\ndemonstrate the usefullness of computational tools from the cycle joining\nmethod in the modified setup.",
    "descriptor": "",
    "authors": [
      "Musthofa",
      "Indah Emilia Wijayanti",
      "Diah Junia Eksi Palupi",
      "Martianus Frederic Ezerman"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.01425"
  },
  {
    "id": "arXiv:2202.01426",
    "title": "Self-Supervised Monte Carlo Tree Search Learning for Object Retrieval in  Clutter",
    "abstract": "In this study, working with the task of object retrieval in clutter, we have\ndeveloped a robot learning framework in which Monte Carlo Tree Search (MCTS) is\nfirst applied to enable a Deep Neural Network (DNN) to learn the intricate\ninteractions between a robot arm and a complex scene containing many objects,\nallowing the DNN to partially clone the behavior of MCTS. In turn, the trained\nDNN is integrated into MCTS to help guide its search effort. We call this\napproach Monte Carlo tree search and learning for Object REtrieval (MORE),\nwhich delivers significant computational efficiency gains and added solution\noptimality. MORE is a self-supervised robotics framework/pipeline capable of\nworking in the real world that successfully embodies the System 2 $\\to$ System\n1 learning philosophy proposed by Kahneman, where learned knowledge, used\nproperly, can help greatly speed up a time-consuming decision process over\ntime. Videos and supplementary material can be found at\nhttps://github.com/arc-l/more",
    "descriptor": "\nComments: Accepted for ICRA 2022\n",
    "authors": [
      "Baichuan Huang",
      "Teng Guo",
      "Abdeslam Boularias",
      "Jingjin Yu"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.01426"
  },
  {
    "id": "arXiv:2202.01427",
    "title": "SparGE: Sparse Coding-based Patient Similarity Learning via Low-rank  Constraints and Graph Embedding",
    "abstract": "Patient similarity assessment (PSA) is pivotal to evidence-based and\npersonalized medicine, enabled by analyzing the increasingly available\nelectronic health records (EHRs). However, machine learning approaches for PSA\nhas to deal with inherent data deficiencies of EHRs, namely missing values,\nnoise, and small sample sizes. In this work, an end-to-end discriminative\nlearning framework, called SparGE, is proposed to address these data challenges\nof EHR for PSA. SparGE measures similarity by jointly sparse coding and graph\nembedding. First, we use low-rank constrained sparse coding to identify and\ncalculate weight for similar patients, while denoising against missing values.\nThen, graph embedding on sparse representations is adopted to measure the\nsimilarity between patient pairs via preserving local relationships defined by\ndistances. Finally, a global cost function is constructed to optimize related\nparameters. Experimental results on two private and public real-world\nhealthcare datasets, namely SingHEART and MIMIC-III, show that the proposed\nSparGE significantly outperforms other machine learning patient similarity\nmethods.",
    "descriptor": "",
    "authors": [
      "Xian Wei",
      "See Kiong Ng",
      "Tongtong Zhang",
      "Yingjie Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.01427"
  },
  {
    "id": "arXiv:2202.01428",
    "title": "Multi-Criteria Assessment of Shape Quality in CAD Systems of the Future",
    "abstract": "Unlike many other works, where authors are usually focused on one or two\nquality criteria, the current manuscript, which is a generalization of the\narticle [35] published in Russian, offers a multi-criteria approach to the\nassessment of the shape quality of curves that constitute component parts of\nthe surfaces used for the computer modelling of object shapes in various types\nof design. Based on the analysis of point particle motion along a curved path,\nrequirements for the quality of functional curves are proposed: a high order of\nsmoothness, a minimum number of curvature extrema, minimization of the maximum\nvalue of curvature and its variation rate, minimization of the potential energy\nof the curve, and aesthetic analysis from the standpoint of the laws of\ntechnical aesthetics. The authors do not set themselves the task of giving a\nsimple and precise mathematical definition of such curves. On the contrary,\nthis category can include various curves that meet certain quality criteria,\nthe refinement and addition of which is possible in the near future.\nEngineering practice shows that quality criteria can change over time, which\ndoes not diminish the need to develop multi-criteria methods for assessing the\nquality of geometric shapes. Technical issues faced during edge rounding in 3D\nmodels that affect the quality of industrial design product shape have been\nreviewed as an example of the imperfection of existing CAD systems.",
    "descriptor": "",
    "authors": [
      "Valerijan Muftejev",
      "Rushan Ziatdinov",
      "Rifkat Nabiyev"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2202.01428"
  },
  {
    "id": "arXiv:2202.01430",
    "title": "For the splitting method of the nonlinear heat equation with initial  datum in W^1,q",
    "abstract": "In this paper, we analyze an operator splitting scheme of the nonlinear heat\nequation in $\\Omega\\subset\\mathbb{R}^d$ ($d\\geq 1$): $\\partial_t u = \\Delta u +\n\\lambda |u|^{p-1} u$ in $\\Omega\\times(0,\\infty)$, $u=0$ in\n$\\partial\\Omega\\times(0,\\infty)$, $u ({\\bf x},0) =\\phi ({\\bf x})$ in $\\Omega$.\nwhere $\\lambda\\in\\{-1,1\\}$ and $\\phi \\in W^{1,q}(\\Omega)\\cap L^{\\infty}\n(\\Omega)$ with $2\\leq p < \\infty$ and $d(p-1)/2<q<\\infty$. We establish the\nwell-posedness of the approximation of $u$ in $L^r$-space ($r\\geq q$), and\nfurthermore, we derive its convergence rate of order $\\mathcal{O}(\\tau)$ for a\ntime step $\\tau>0$. Finally, we give some numerical examples to confirm the\nreliability of the analyzed result.",
    "descriptor": "",
    "authors": [
      "Hyung Jun Choi",
      "Woocheol Choi",
      "Youngwoo Koh"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)"
    ],
    "url": "https://arxiv.org/abs/2202.01430"
  },
  {
    "id": "arXiv:2202.01439",
    "title": "Sensing the Breath: A Multimodal Singing Tutoring Interface with Breath  Guidance",
    "abstract": "Breath is a significant component in singing performance, which is still\nunderresearched in most singing-related music interfaces. In this paper, we\npresent a multimodal system that detects the learner's singing pitch and\nbreathing states and provides real-time visual tutoring feedback. Specifically,\nthe breath detector is a wearable belt with pressure sensors and flexible\nfabric. It monitors real-time body movement of the abdomen, back waist, and\ntwin ribs. A breath visualization algorithm is developed to display real-time\nbreath states, together with the singing pitch contours on an interactive score\ninterface. User studies show that our system can help users not only gain\ndeeper breath during singing but also improve pitch accuracy in vocal training,\nespecially for those with some musical background.",
    "descriptor": "",
    "authors": [
      "Ziyue Piao",
      "Gus Xia"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2202.01439"
  },
  {
    "id": "arXiv:2202.01440",
    "title": "Optimized Potential Initialization for Low-latency Spiking Neural  Networks",
    "abstract": "Spiking Neural Networks (SNNs) have been attached great importance due to the\ndistinctive properties of low power consumption, biological plausibility, and\nadversarial robustness. The most effective way to train deep SNNs is through\nANN-to-SNN conversion, which have yielded the best performance in deep network\nstructure and large-scale datasets. However, there is a trade-off between\naccuracy and latency. In order to achieve high precision as original ANNs, a\nlong simulation time is needed to match the firing rate of a spiking neuron\nwith the activation value of an analog neuron, which impedes the practical\napplication of SNN. In this paper, we aim to achieve high-performance converted\nSNNs with extremely low latency (fewer than 32 time-steps). We start by\ntheoretically analyzing ANN-to-SNN conversion and show that scaling the\nthresholds does play a similar role as weight normalization. Instead of\nintroducing constraints that facilitate ANN-to-SNN conversion at the cost of\nmodel capacity, we applied a more direct way by optimizing the initial membrane\npotential to reduce the conversion loss in each layer. Besides, we demonstrate\nthat optimal initialization of membrane potentials can implement expected\nerror-free ANN-to-SNN conversion. We evaluate our algorithm on the CIFAR-10,\nCIFAR-100 and ImageNet datasets and achieve state-of-the-art accuracy, using\nfewer time-steps. For example, we reach top-1 accuracy of 93.38\\% on CIFAR-10\nwith 16 time-steps. Moreover, our method can be applied to other ANN-SNN\nconversion methodologies and remarkably promote performance when the time-steps\nis small.",
    "descriptor": "\nComments: Accepted by AAAI 2022\n",
    "authors": [
      "Tong Bu",
      "Jianhao Ding",
      "Zhaofei Yu",
      "Tiejun Huang"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.01440"
  },
  {
    "id": "arXiv:2202.01446",
    "title": "Noisy Sorting Capacity",
    "abstract": "Sorting is the task of ordering $n$ elements using pairwise comparisons. It\nis well known that $m=\\Theta(n\\log n)$ comparisons are both necessary and\nsufficient when the outcomes of the comparisons are observed with no noise. In\nthis paper, we study the sorting problem in the presence of noise. Unlike the\ncommon approach in the literature which aims to minimize the number of pairwise\ncomparisons $m$ to achieve a given desired error probability, our goal is to\ncharacterize the maximal ratio $\\frac{n\\log n}{m}$ such that the ordering of\nthe elements can be estimated with a vanishing error probability\nasymptotically. The maximal ratio is referred to as the noisy sorting capacity.\nIn this work, we derive upper and lower bounds on the noisy sorting capacity.\nThe algorithm that attains the lower bound is based on the well-known\nBurnashev--Zigangirov algorithm for coding over channels with feedback. By\ncomparing with existing algorithms in the literature under the proposed\nframework, we show that our algorithm can achieve a strictly larger ratio\nasymptotically.",
    "descriptor": "",
    "authors": [
      "Ziao Wang",
      "Nadim Ghaddar",
      "Lele Wang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.01446"
  },
  {
    "id": "arXiv:2202.01448",
    "title": "Deep Learning Algorithm for Threat Detection in Hackers Forum (Deep Web)",
    "abstract": "In our current society, the inter-connectivity of devices provides easy\naccess for netizens to utilize cyberspace technology for illegal activities.\nThe deep web platform is a consummative ecosystem shielded by boundaries of\ntrust, information sharing, trade-off, and review systems. Domain knowledge is\nshared among experts in hacker's forums which contain indicators of compromise\nthat can be explored for cyberthreat intelligence. Developing tools that can be\ndeployed for threat detection is integral in securing digital communication in\ncyberspace. In this paper, we addressed the use of TOR relay nodes for\nanonymizing communications in deep web forums. We propose a novel approach for\ndetecting cyberthreats using a deep learning algorithm Long Short-Term Memory\n(LSTM). The developed model outperformed the experimental results of other\nresearchers in this problem domain with an accuracy of 94\\% and precision of\n90\\%. Our model can be easily deployed by organizations in securing digital\ncommunications and detection of vulnerability exposure before cyberattack.",
    "descriptor": "\nComments: 9 pages, 5 figures. Preprint\n",
    "authors": [
      "Victor Adewopo",
      "Bilal Gonen",
      "Nelly Elsayed",
      "Murat Ozer",
      "Zaghloul Saad Elsayed"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.01448"
  },
  {
    "id": "arXiv:2202.01451",
    "title": "Topology Optimization with Tetra-kai-decahedra and Spheroidal Masks",
    "abstract": "A novel meshing scheme, based on regular tetra-kai-decahedron, also referred\nto as truncated octahedron, cells is presented for use in spatial topology\noptimization. A tetra-kai-decahedron mesh ensures face connectivity between\nelements thereby eliminating singular solutions from the solution space.\nVarious other benefits of implementing the said mesh are also highlighted, and\nthe corresponding finite element is introduced. Material mask overlay strategy\nor MMOS, a feature based method for topology optimization is extended for use\nin 3-dimensions (MMOS-3D) via the aforementioned finite element and spheroidal\nnegative masks. Formulation for density computation and sensitivity analysis\nfor gradient based optimization is developed. Examples on traditional\nstructural topology optimization problems are presented with detailed\ndiscussion on efficacy of the proposed approach.",
    "descriptor": "",
    "authors": [
      "Nikhil Singh",
      "Anupam Saxena"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2202.01451"
  },
  {
    "id": "arXiv:2202.01454",
    "title": "Deep Hierarchy in Bandits",
    "abstract": "Mean rewards of actions are often correlated. The form of these correlations\nmay be complex and unknown a priori, such as the preferences of a user for\nrecommended products and their categories. To maximize statistical efficiency,\nit is important to leverage these correlations when learning. We formulate a\nbandit variant of this problem where the correlations of mean action rewards\nare represented by a hierarchical Bayesian model with latent variables. Since\nthe hierarchy can have multiple layers, we call it deep. We propose a\nhierarchical Thompson sampling algorithm (HierTS) for this problem, and show\nhow to implement it efficiently for Gaussian hierarchies. The efficient\nimplementation is possible due to a novel exact hierarchical representation of\nthe posterior, which itself is of independent interest. We use this exact\nposterior to analyze the Bayes regret of HierTS in Gaussian bandits. Our\nanalysis reflects the structure of the problem, that the regret decreases with\nthe prior width, and also shows that hierarchies reduce the regret by\nnon-constant factors in the number of actions. We confirm these theoretical\nfindings empirically, in both synthetic and real-world experiments.",
    "descriptor": "",
    "authors": [
      "Joey Hong",
      "Branislav Kveton",
      "Sumeet Katariya",
      "Manzil Zaheer",
      "Mohammad Ghavamzadeh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.01454"
  },
  {
    "id": "arXiv:2202.01455",
    "title": "Error analysis of a fully discrete scheme for the  Cahn-Hilliard-Magneto-hydrodynamics problem",
    "abstract": "In this paper we analyze a fully discrete scheme for a general Cahn-Hilliard\nequation coupled with a nonsteady Magneto-hydrodynamics flow, which describes\ntwo immiscible, incompressible and electrically conducting fluids with\ndifferent mobilities, fluid viscosities and magnetic diffusivities. A typical\nfully discrete scheme, which is comprised of conforming finite element method\nand the Euler semi-implicit discretization based on a convex splitting of the\nenergy of the equation is considered in detail. We prove that our scheme is\nunconditionally energy stability and obtain some optimal error estimates for\nthe concentration field, the chemical potential, the velocity field, the\nmagnetic field and the pressure. The results of numerical tests are presented\nto validate the rates of convergence.",
    "descriptor": "",
    "authors": [
      "Hailong Qiu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.01455"
  },
  {
    "id": "arXiv:2202.01456",
    "title": "Fast and explainable clustering based on sorting",
    "abstract": "We introduce a fast and explainable clustering method called CLASSIX. It\nconsists of two phases, namely a greedy aggregation phase of the sorted data\ninto groups of nearby data points, followed by the merging of groups into\nclusters. The algorithm is controlled by two scalar parameters, namely a\ndistance parameter for the aggregation and another parameter controlling the\nminimal cluster size. Extensive experiments are conducted to give a\ncomprehensive evaluation of the clustering performance on synthetic and\nreal-world datasets, with various cluster shapes and low to high feature\ndimensionality. Our experiments demonstrate that CLASSIX competes with\nstate-of-the-art clustering algorithms. The algorithm has linear space\ncomplexity and achieves near linear time complexity on a wide range of\nproblems. Its inherent simplicity allows for the generation of intuitive\nexplanations of the computed clusters.",
    "descriptor": "",
    "authors": [
      "Xinye Chen",
      "Stefan G\u00fcttel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)",
      "Computation (stat.CO)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.01456"
  },
  {
    "id": "arXiv:2202.01457",
    "title": "Parallel domain discretization algorithm for RBF-FD and other meshless  numerical methods for solving PDEs",
    "abstract": "In this paper, we present a novel parallel dimension-independent node\npositioning algorithm that is capable of generating nodes with variable\ndensity, suitable for meshless numerical analysis. A very efficient sequential\nalgorithm based on Poisson disc sampling is parallelized for use on\nshared-memory computers, such as modern workstations with multi-core\nprocessors. The parallel algorithm uses a global spatial indexing method with\nits data divided into two levels, which allows for an efficient multi-threaded\nimplementation. The addition of bootstrapping enables the algorithm to use any\nnumber of parallel threads while remaining as general as its sequential\nvariant. We demonstrate the algorithm performance on six complex 2- and\n3-dimensional domains, which are either of non-rectangular shape or have\nvarying nodal spacing or both. We perform a run-time analysis of the algorithm,\nto demonstrate its ability to reach high speedups regardless of the domain and\nto show how well it scales on the experimental hardware with 16 processor\ncores. We also analyse the algorithm in terms of the effects of domain shape,\nquality of point placement, and various parallelization overheads.",
    "descriptor": "",
    "authors": [
      "Matja\u017e Depolli",
      "Jure Slak",
      "Gregor Kosec"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.01457"
  },
  {
    "id": "arXiv:2202.01459",
    "title": "Concept Bottleneck Model with Additional Unsupervised Concepts",
    "abstract": "With the increasing demands for accountability, interpretability is becoming\nan essential capability for real-world AI applications. However, most methods\nutilize post-hoc approaches rather than training the interpretable model. In\nthis article, we propose a novel interpretable model based on the concept\nbottleneck model (CBM). CBM uses concept labels to train an intermediate layer\nas the additional visible layer. However, because the number of concept labels\nrestricts the dimension of this layer, it is difficult to obtain high accuracy\nwith a small number of labels. To address this issue, we integrate supervised\nconcepts with unsupervised ones trained with self-explaining neural networks\n(SENNs). By seamlessly training these two types of concepts while reducing the\namount of computation, we can obtain both supervised and unsupervised concepts\nsimultaneously, even for large-sized images. We refer to the proposed model as\nthe concept bottleneck model with additional unsupervised concepts (CBM-AUC).\nWe experimentally confirmed that the proposed model outperformed CBM and SENN.\nWe also visualized the saliency map of each concept and confirmed that it was\nconsistent with the semantic meanings.",
    "descriptor": "\nComments: 13 pages, 6 figures\n",
    "authors": [
      "Yoshihide Sawada",
      "Keigo Nakamura"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.01459"
  },
  {
    "id": "arXiv:2202.01461",
    "title": "ExPoSe: Combining State-Based Exploration with Gradient-Based Online  Search",
    "abstract": "A tree-based online search algorithm iteratively simulates trajectories and\nupdates Q-value information on a set of states represented by a tree structure.\nAlternatively, policy gradient based online search algorithms update the\ninformation obtained from simulated trajectories directly onto the parameters\nof the policy and has been found to be effective. While tree-based methods\nlimit the updates from simulations to the states that exist in the tree and do\nnot interpolate the information to nearby states, policy gradient search\nmethods do not do explicit exploration. In this paper, we show that it is\npossible to combine and leverage the strengths of these two methods for\nimproved search performance. We examine the key reasons behind the improvement\nand propose a simple yet effective online search method, named Exploratory\nPolicy Gradient Search (ExPoSe), that updates both the parameters of the policy\nas well as search information on the states in the trajectory. We conduct\nexperiments on complex planning problems, which include Sokoban and Hamiltonian\ncycle search in sparse graphs and show that combining exploration with policy\ngradient improves online search performance.",
    "descriptor": "",
    "authors": [
      "Dixant Mittal",
      "Siddharth Arvindan",
      "Wee Sun Lee"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.01461"
  },
  {
    "id": "arXiv:2202.01469",
    "title": "Investigation of Torque Ripple in Voltage Source Inverter driven  Induction Motor Drive operated with Space Vector based Harmonic Elimination  Pulse Width Modulation Scheme",
    "abstract": "The lower order harmonic elimination using space vector pulse width\nmodulation (SVPWM) technique is possible by introducing the dwell time division\ncoefficient 'k' in space vector. In this paper, torque ripple analysis is\ncarried out for space vector based harmonic elimination (SVHE) scheme and the\nobtained results are compared with the existing schemes such as conventional\nand advanced bus clamping SVPWM schemes. Further, the obtained results are\nvalidated through simulation results. The SVHE scheme gives the lower torque\nripple than the conventional and advance bus clamping schemes at higher\nmodulation indices.",
    "descriptor": "\nComments: 6 pages, 6 figures, conference\n",
    "authors": [
      "Rohan Sandeep Burye",
      "Ravi Teja Arumalla",
      "Sheron Figarado"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.01469"
  },
  {
    "id": "arXiv:2202.01470",
    "title": "Boosting Monocular Depth Estimation with Sparse Guided Points",
    "abstract": "Existing monocular depth estimation shows excellent robustness in the wild,\nbut the affine-invariant prediction requires aligning with the ground truth\nglobally while being converted into the metric depth. In this work, we firstly\npropose a modified locally weighted linear regression strategy to leverage\nsparse ground truth and generate a flexible depth transformation to correct the\ncoarse misalignment brought by global recovery strategy. Applying this\nstrategy, we achieve significant improvement (more than 50% at most) over most\nrecent state-of-the-art methods on five zero-shot datasets. Moreover, we train\na robust depth estimation model with 6.3 million data and analyze the training\nprocess by decoupling the inaccuracy into coarse misalignment inaccuracy and\ndetail missing inaccuracy. As a result, our model based on ResNet50 even\noutperforms the state-of-the-art DPT ViT-Large model with the help of our\nrecovery strategy. In addition to accuracy, the consistency is also boosted for\nsimple per-frame video depth estimation. Compared with monocular depth\nestimation, robust video depth estimation, and depth completion methods, our\npipeline obtains state-of-the-art performance on video depth estimation without\nany post-processing. Experiments of 3D scene reconstruction from consistent\nvideo depth are conducted for intuitive comparison as well.",
    "descriptor": "\nComments: 15 pages\n",
    "authors": [
      "Guangkai Xu",
      "Wei Yin",
      "Hao Chen",
      "Kai Cheng",
      "Feng Zhao",
      "Chunhua Shen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.01470"
  },
  {
    "id": "arXiv:2202.01471",
    "title": "Variational integrators for non-autonomous systems with applications to  stabilization of multi-agent formations",
    "abstract": "Numerical methods that preserve geometric invariants of the system, such as\nenergy, momentum or the symplectic form, are called geometric integrators.\nVariational integrators are an important class of geometric integrators. The\ngeneral idea for those variational integrators is to discretize Hamilton's\nprinciple rather than the equations of motion in a way that preserves some of\nthe invariants of the original system. In this paper we construct variational\nintegrators with fixed time step for time-dependent Lagrangian systems\nmodelling an important class of autonomous dissipative systems. These\nintegrators are derived via a family of discrete Lagrangian functions each one\nfor a fixed time-step. This allows to recover at each step on the set of\ndiscrete sequences the preservation properties of variational integrators for\nautonomous Lagrangian systems, such as symplecticity or backward error analysis\nfor these systems. We also present a discrete Noether theorem for this class of\nsystems. Applications of the results are shown for the problem of formation\nstabilization of multi-agent systems.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2010.00425\n",
    "authors": [
      "Leonardo Colombo",
      "Manuela Gamonal Fern\u00e1ndez",
      "David Mart\u00edn de Diego"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2202.01471"
  },
  {
    "id": "arXiv:2202.01473",
    "title": "A multi-domain virtual network embedding algorithm with delay prediction",
    "abstract": "Virtual network embedding (VNE) is an crucial part of network virtualization\n(NV), which aims to map the virtual networks (VNs) to a shared substrate\nnetwork (SN). With the emergence of various delay-sensitive applications, how\nto improve the delay performance of the system has become a hot topic in\nacademic circles. Based on extensive research, we proposed a multi-domain\nvirtual network embedding algorithm based on delay prediction (DP-VNE).\nFirstly, the candidate physical nodes are selected by estimating the delay of\nvirtual requests, then particle swarm optimization (PSO) algorithm is used to\noptimize the mapping process, so as to reduce the delay of the system. The\nsimulation results show that compared with the other three advanced algorithms,\nthe proposed algorithm can significantly reduce the system delay while keeping\nother indicators unaffected.",
    "descriptor": "",
    "authors": [
      "Peiying Zhang",
      "Xue Pang",
      "Yongjing Ni",
      "Haipeng Yao",
      "Xin Li"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.01473"
  },
  {
    "id": "arXiv:2202.01477",
    "title": "Unsourced Random Access with a Massive MIMO Receiver Using Multiple  Stages of Orthogonal Pilots",
    "abstract": "We study the problem of unsourced random access (URA) over Rayleigh\nblock-fading channels with a receiver equipped with multiple antennas. We\nemploy multiple stages of orthogonal pilots, each of which is randomly picked\nfrom a codebook. In the proposed scheme, each user encodes its message using a\npolar code and appends it to the selected pilot sequences to construct its\ntransmitted signal. Accordingly, the received signal consists of superposition\nof the users' signals each composed of multiple pilot parts and a polar coded\npart. We use an iterative approach for decoding the transmitted messages along\nwith a suitable successive interference cancellation scheme. Performance of the\nproposed scheme is illustrated via extensive set of simulation results which\nshow that it significantly outperforms the existing approaches for URA over\nmulti-input multi-output fading channels.",
    "descriptor": "",
    "authors": [
      "Mohammad Javad Ahmadi",
      "Tolga M. Duman"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.01477"
  },
  {
    "id": "arXiv:2202.01478",
    "title": "Trajectory Forecasting from Detection with Uncertainty-Aware Motion  Encoding",
    "abstract": "Trajectory forecasting is critical for autonomous platforms to make safe\nplanning and actions. Currently, most trajectory forecasting methods assume\nthat object trajectories have been extracted and directly develop trajectory\npredictors based on the ground truth trajectories. However, this assumption\ndoes not hold in practical situations. Trajectories obtained from object\ndetection and tracking are inevitably noisy, which could cause serious\nforecasting errors to predictors built on ground truth trajectories. In this\npaper, we propose a trajectory predictor directly based on detection results\nwithout relying on explicitly formed trajectories. Different from the\ntraditional methods which encode the motion cue of an agent based on its\nclearly defined trajectory, we extract the motion information only based on the\naffinity cues among detection results, in which an affinity-aware state update\nmechanism is designed to take the uncertainty of association into account. In\naddition, considering that there could be multiple plausible matching\ncandidates, we aggregate the states of them. This design relaxes the\nundesirable effect of noisy trajectory obtained from data association.\nExtensive ablation experiments validate the effectiveness of our method and its\ngeneralization ability on different detectors. Cross-comparison to other\nforecasting schemes further proves the superiority of our method. Code will be\nreleased upon acceptance.",
    "descriptor": "\nComments: 11 pages, 4 figures\n",
    "authors": [
      "Pu Zhang",
      "Lei Bai",
      "Jianru Xue",
      "Jianwu Fang",
      "Nanning Zheng",
      "Wanli Ouyang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.01478"
  },
  {
    "id": "arXiv:2202.01479",
    "title": "MRI Reconstruction via Data Driven Markov Chain with Joint Uncertainty  Estimation",
    "abstract": "We introduce a framework that enables efficient sampling from learned\nprobability distributions for MRI reconstruction. Different from conventional\ndeep learning-based MRI reconstruction techniques, samples are drawn from the\nposterior distribution given the measured k-space using the Markov chain Monte\nCarlo (MCMC) method. In addition to the maximum a posteriori (MAP) estimate for\nthe image, which can be obtained with conventional methods, the minimum mean\nsquare error (MMSE) estimate and uncertainty maps can also be computed. The\ndata-driven Markov chains are constructed from the generative model learned\nfrom a given image database and are independent of the forward operator that is\nused to model the k-space measurement. This provides flexibility because the\nmethod can be applied to k-space acquired with different sampling schemes or\nreceive coils using the same pre-trained models. Furthermore, we use a\nframework based on a reverse diffusion process to be able to utilize advanced\ngenerative models. The performance of the method is evaluated on an open\ndataset using 10-fold accelerated acquisition.",
    "descriptor": "",
    "authors": [
      "Guanxiong Luo",
      "Martin Heide",
      "Martin Uecker"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.01479"
  },
  {
    "id": "arXiv:2202.01483",
    "title": "Variable Slope Trapezoidal Circulating Current Injection to Attenuate  Capacitor Voltage Ripple in Modular Multilevel Converter Based Variable Speed  Motor Drives Application",
    "abstract": "The main challenge in using the Modular Multilevel Converter-based\nconstant-torque variable-speed motor drives is increased sub-module capacitor\nvoltage ripples (SM-CVR) at lowfundamental frequency operation, due to the\ninverse relationship between SM-CVR and operating frequency. To address this\nissue, a variable slope trapezoidal circulating current (CC) is injected along\nwith square wave common-mode voltage (CMV). Compared to sinusoidal CC and\nsinusoidal CMV injection, the proposed injection technique can reduce the peak\nof the CC in the range of 0% to 50%, resulting in lesser device stress and\nimproved efficiency. Simulation results of the proposed technique are\npresented, and they are further compared with the existing injection techniques\nto show the superiority",
    "descriptor": "\nComments: 6 pages, 9 figures, conference\n",
    "authors": [
      "Kranthi Panuganti",
      "Rohan Sandeep Burye",
      "Sheron Figarado"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.01483"
  },
  {
    "id": "arXiv:2202.01488",
    "title": "Mobility Performance Analysis of Scalable Cell-Free Massive MIMO",
    "abstract": "While scalable cell-free massive MIMO (CF-mMIMO) shows advantages in static\nconditions, the impact of its changing serving access point (AP) set in a\nmobile network is not yet addressed. In this paper we first derive the CPU\ncluster and AP handover rates of scalable CF-mMIMO as exact numerical results\nand tight closed form approximations. We then use our closed form handover rate\nresult to analyse the mobility-aware throughput. We compare the mobility-aware\nspectral efficiency (SE) of scalable CF-mMIMO against distributed MIMO with\npure network- and UE-centric AP selection, for different AP densities and\nhandover delays. Our results reveal an important trade-off for future dense\nnetworks with low control delay: under moderate to high mobility, scalable\nCF-mMIMO maintains its advantage for the 95th-percentile users but at the cost\nof degraded median SE.",
    "descriptor": "",
    "authors": [
      "Yunlu Xiao",
      "Petri M\u00e4h\u00f6nen",
      "Ljiljana Simi\u0107"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2202.01488"
  },
  {
    "id": "arXiv:2202.01489",
    "title": "The Price of Distributed: Rate Loss in the CEO Problem",
    "abstract": "In the distributed remote (CEO) source coding problem, many separate encoders\nobserve independently noisy copies of an underlying source. The rate loss is\nthe difference between the rate required in this distributed setting and the\nrate that would be required in a setting where the encoders can fully\ncooperate. In this sense, the rate loss characterizes the price of distributed\nprocessing. We survey and extend the known results on the rate loss in various\nsettings, with a particular emphasis on the case where the noise in the\nobservations is Gaussian, but the underlying source is general.",
    "descriptor": "\nComments: Accepted to 56th Annual Conference on Information Sciences and Systems (CISS)\n",
    "authors": [
      "Arda Atalik",
      "Alper K\u00f6se",
      "Michael Gastpar"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.01489"
  },
  {
    "id": "arXiv:2202.01490",
    "title": "On the Utility of Marrying GIN and PMD for Improving Stack Overflow Code  Snippets",
    "abstract": "Software developers are increasingly dependent on question and answer portals\nand blogs for coding solutions. While such interfaces provide useful\ninformation, there are concerns that code hosted here is often incorrect,\ninsecure or incomplete. Previous work indeed detected a range of faults in code\nprovided on Stack Overflow through the use of static analysis. Static analysis\nmay go a far way towards quickly establishing the health of software code\navailable online. In addition, mechanisms that enable rapid automated program\nimprovement may then enhance such code. Accordingly, we present this proof of\nconcept. We use the PMD static analysis tool to detect performance faults for a\nsample of Stack Overflow Java code snippets, before performing mutations on\nthese snippets using GIN. We then re-analyse the performance faults in these\nsnippets after the GIN mutations. GIN's RandomSampler was used to perform\n17,986 unique line and statement patches on 3,034 snippets where PMD violations\nwere removed from 770 patched versions. Our outcomes indicate that static\nanalysis techniques may be combined with automated program improvement methods\nto enhance publicly available code with very little resource requirements. We\ndiscuss our planned research agenda in this regard.",
    "descriptor": "\nComments: 4 pages, 4 tables, 1 listing\n",
    "authors": [
      "Sherlock A. Licorish",
      "Markus Wagner"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2202.01490"
  },
  {
    "id": "arXiv:2202.01493",
    "title": "Spatial Computing and Intuitive Interaction: Bringing Mixed Reality and  Robotics Together",
    "abstract": "Spatial computing -- the ability of devices to be aware of their surroundings\nand to represent this digitally -- offers novel capabilities in human-robot\ninteraction. In particular, the combination of spatial computing and egocentric\nsensing on mixed reality devices enables them to capture and understand human\nactions and translate these to actions with spatial meaning, which offers\nexciting new possibilities for collaboration between humans and robots. This\npaper presents several human-robot systems that utilize these capabilities to\nenable novel robot use cases: mission planning for inspection, gesture-based\ncontrol, and immersive teleoperation. These works demonstrate the power of\nmixed reality as a tool for human-robot interaction, and the potential of\nspatial computing and mixed reality to drive the future of human-robot\ninteraction.",
    "descriptor": "",
    "authors": [
      "Jeffrey Delmerico",
      "Roi Poranne",
      "Federica Bogo",
      "Helen Oleynikova",
      "Eric Vollenweider",
      "Stelian Coros",
      "Juan Nieto",
      "Marc Pollefeys"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2202.01493"
  },
  {
    "id": "arXiv:2202.01497",
    "title": "End-to-End Latency Analysis and Optimal Block Size of Proof-of-Work  Blockchain Applications",
    "abstract": "Due to the increasing interest in blockchain technology for fostering secure,\nauditable, decentralized applications, a set of challenges associated with this\ntechnology need to be addressed. In this letter, we focus on the delay\nassociated with Proof-of-Work (PoW)-based blockchain networks, whereby\nparticipants validate the new information to be appended to a distributed\nledger via consensus to confirm transactions. We propose a novel end-to-end\nlatency model based on batch-service queuing theory that characterizes timers\nand forks for the first time. Furthermore, we derive an estimation of optimum\nblock size analytically. Endorsed by simulation results, we show that the\noptimal block size approximation is a consistent method that leads to\nclose-to-optimal performance by significantly reducing the overheads associated\nwith blockchain applications.",
    "descriptor": "",
    "authors": [
      "Francesc Wilhelmi",
      "Sergio Barrachina-Mu\u00f1oz",
      "Paolo Dini"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.01497"
  },
  {
    "id": "arXiv:2202.01498",
    "title": "Towards Understanding CNAME based First-Party Cookie Tracking in the  Field",
    "abstract": "Third-party web tracking is a common, and broadly used technique on the Web.\nAlmost every step of users' is tracked, analyzed, and later used in different\nuse cases (e.g., online advertisement). Different defense mechanisms have\nemerged to counter these practices (e.g., the recent step of browser vendors to\nban all third-party cookies). However, all of these countermeasures only target\nthird-party trackers, and ignore the first party because the narrative is that\nsuch monitoring is mostly used to improve the utilized service (e.g.,\nanalytical services).\nIn this paper, we present a large-scale measurement study that analyzes\ntracking performed by the first party but utilized by a third party to\ncircumvent standard tracking preventing techniques (i.e., the first party\nperforms the tracking in the name of the third party). We visit the top 15,000\nwebsites to analyze first-party cookies used to track users and a technique\ncalled \"DNS CNAME cloaking\", which can be used by a third party to place\nfirst-party cookies. Using this data, we show that 76% sites in our dataset\neffectively utilize such tracking techniques, and in a long-running analysis,\nwe show that the usage of such cookies increased by more than 50% over 2021.\nFurthermore, we shed light on the ecosystem utilizing first-party trackers, and\nfind that the established trackers already use such tracking, presumably to\navoid tracking blocking.",
    "descriptor": "",
    "authors": [
      "Nurullah Demir",
      "Daniel Theis",
      "Tobias Urban",
      "Norbert Pohlmann"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.01498"
  },
  {
    "id": "arXiv:2202.01503",
    "title": "Global sensitivity analysis based on Gaussian-process metamodelling for  complex biomechanical problems",
    "abstract": "Biomechanical models often need to describe very complex systems, organs or\ndiseases, and hence also include a large number of parameters. One of the\nattractive features of physics-based models is that in those models (most)\nparameters have a clear physical meaning. Nevertheless, the determination of\nthese parameters is often very elaborate and costly and shows a large scatter\nwithin the population. Hence, it is essential to identify the most important\nparameter for a particular problem at hand. In order to distinguish parameters\nwhich have a significant influence on a specific model output from\nnon-influential parameters, we use sensitivity analysis, in particular the\nSobol method as a global variance-based method. However, the Sobol method\nrequires a large number of model evaluations, which is prohibitive for\ncomputationally expensive models. We therefore employ Gaussian processes as a\nmetamodel for the underlying full model. Metamodelling introduces further\nuncertainty, which we also quantify. We demonstrate the approach by applying it\nto two different problems: nanoparticle-mediated drug delivery in a multiphase\ntumour-growth model, and arterial growth and remodelling. Even relatively small\nnumbers of evaluations of the full model suffice to identify the influential\nparameters in both cases and to separate them from non-influential parameters.\nThe approach also allows the quantification of higher-order interaction\neffects. We thus show that a variance-based global sensitivity analysis is\nfeasible for computationally expensive biomechanical models. Different aspects\nof sensitivity analysis are covered including a transparent declaration of the\nuncertainties involved in the estimation process. Such a global sensitivity\nanalysis not only helps to massively reduce costs for experimental\ndetermination of parameters but is also highly beneficial for inverse analysis\nof such complex models.",
    "descriptor": "",
    "authors": [
      "Barbara Wirthl",
      "Sebastian Brandstaeter",
      "Jonas Nitzler",
      "Bernhard A. Schrefler",
      "Wolfgang A. Wall"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2202.01503"
  },
  {
    "id": "arXiv:2202.01507",
    "title": "Comparison of Intelligent Approaches for Cycle Time Prediction in  Injection Moulding of a Medical Device Product",
    "abstract": "Injection moulding is an increasingly automated industrial process,\nparticularly when used for the production of high-value precision components\nsuch as polymeric medical devices. In such applications, achieving stringent\nproduct quality demands whilst also ensuring a highly efficient process can be\nchallenging. Cycle time is one of the most critical factors which directly\naffects the throughput rate of the process and hence is a key indicator of\nprocess efficiency. In this work, we examine a production data set from a real\nindustrial injection moulding process for manufacture of a high precision\nmedical device. The relationship between the process input variables and the\nresulting cycle time is mapped with an artificial neural network (ANN) and an\nadaptive neuro-fuzzy system (ANFIS). The predictive performance of different\ntraining methods and neuron numbers in ANN and the impact of model type and the\nnumbers of membership functions in ANFIS has been investigated. The strengths\nand limitations of the approaches are presented and the further research and\ndevelopment needed to ensure practical on-line use of these methods for dynamic\nprocess optimisation in the industrial process are discussed.",
    "descriptor": "",
    "authors": [
      "Mandana Kariminejad",
      "David Tormey",
      "Saif Huq",
      "Jim Morrison",
      "Marion McAfee"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.01507"
  },
  {
    "id": "arXiv:2202.01508",
    "title": "The Wiretap Channel for Capacitive PUF-Based Security Enclosures",
    "abstract": "In order to protect devices from physical manipulations, protective security\nenclosures were developed. However, these battery-backed solutions come with a\nreduced lifetime, and have to be actively and continuously monitored. In order\nto overcome these drawbacks, batteryless capacitive enclosures based on\nPhysical Unclonable Functions (PUFs) have been developed that generate a\nkey-encryption-key (KEK) for decryption of the key chain. In order to reproduce\nthe PUF-key reliably and to compensate the effect of noise and environmental\ninfluences, the key generation includes error correction codes. However,\ndrilling attacks that aim at partially destroying the enclosure also alter the\nPUF-response and are subjected to the same error correction procedures.\nCorrecting attack effects, however, is highly undesirable as it would destroy\nthe security concept of the enclosure. In general, designing error correction\ncodes such that they provide tamper-sensitivity to attacks, while still\ncorrecting noise and environmental effects is a challenging task. We tackle\nthis problem by first analyzing the behavior of the PUF-response under external\ninfluences and different post-processing parameters. From this, we derive a\nsystem model of the PUF-based enclosure, and construct a wiretap channel\nimplementation from $q$-ary polar codes. We verify the obtained error\ncorrection scheme in a Monte Carlo simulation and demonstrate that our wiretap\nchannel implementation achieves a physical layer security of 100 bits for 240\nbits of entropy for the PUF-secret. Through this, we further develop capacitive\nPUF-based security enclosures and bring them one step closer to their\ncommercial deployment.",
    "descriptor": "",
    "authors": [
      "Kathrin Garb",
      "Marvin Xhemrishi",
      "Ludwig K\u00fcrzinger",
      "Christoph Frisch"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.01508"
  },
  {
    "id": "arXiv:2202.01511",
    "title": "Challenging Common Assumptions in Convex Reinforcement Learning",
    "abstract": "The classic Reinforcement Learning (RL) formulation concerns the maximization\nof a scalar reward function. More recently, convex RL has been introduced to\nextend the RL formulation to all the objectives that are convex functions of\nthe state distribution induced by a policy. Notably, convex RL covers several\nrelevant applications that do not fall into the scalar formulation, including\nimitation learning, risk-averse RL, and pure exploration. In classic RL, it is\ncommon to optimize an infinite trials objective, which accounts for the state\ndistribution instead of the empirical state visitation frequencies, even though\nthe actual number of trajectories is always finite in practice. This is\ntheoretically sound since the infinite trials and finite trials objectives can\nbe proved to coincide and thus lead to the same optimal policy. In this paper,\nwe show that this hidden assumption does not hold in the convex RL setting. In\nparticular, we show that erroneously optimizing the infinite trials objective\nin place of the actual finite trials one, as it is usually done, can lead to a\nsignificant approximation error. Since the finite trials setting is the default\nin both simulated and real-world RL, we believe shedding light on this issue\nwill lead to better approaches and methodologies for convex RL, impacting\nrelevant research areas such as imitation learning, risk-averse RL, and pure\nexploration among others.",
    "descriptor": "",
    "authors": [
      "Mirco Mutti",
      "Riccardo De Santi",
      "Piersilvio De Bartolomeis",
      "Marcello Restelli"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.01511"
  },
  {
    "id": "arXiv:2202.01512",
    "title": "Data Heterogeneity-Robust Federated Learning via Group Client Selection  in Industrial IoT",
    "abstract": "Nowadays, the industrial Internet of Things (IIoT) has played an integral\nrole in Industry 4.0 and produced massive amounts of data for industrial\nintelligence. These data locate on decentralized devices in modern factories.\nTo protect the confidentiality of industrial data, federated learning (FL) was\nintroduced to collaboratively train shared machine learning models. However,\nthe local data collected by different devices skew in class distribution and\ndegrade industrial FL performance. This challenge has been widely studied at\nthe mobile edge, but they ignored the rapidly changing streaming data and\nclustering nature of factory devices, and more seriously, they may threaten\ndata security. In this paper, we propose FedGS, which is a hierarchical\ncloud-edge-end FL framework for 5G empowered industries, to improve industrial\nFL performance on non-i.i.d. data. Taking advantage of naturally clustered\nfactory devices, FedGS uses a gradient-based binary permutation algorithm\n(GBP-CS) to select a subset of devices within each factory and build\nhomogeneous super nodes participating in FL training. Then, we propose a\ncompound-step synchronization protocol to coordinate the training process\nwithin and among these super nodes, which shows great robustness against data\nheterogeneity. The proposed methods are time-efficient and can adapt to dynamic\nenvironments, without exposing confidential industrial data in risky\nmanipulation. We prove that FedGS has better convergence performance than\nFedAvg and give a relaxed condition under which FedGS is more\ncommunication-efficient. Extensive experiments show that FedGS improves\naccuracy by 3.5% and reduces training rounds by 59% on average, confirming its\nsuperior effectiveness and efficiency on non-i.i.d. data.",
    "descriptor": "",
    "authors": [
      "Zonghang Li",
      "Yihong He",
      "Hongfang Yu",
      "Jiawen Kang",
      "Xiaoping Li",
      "Zenglin Xu",
      "Dusit Niyato"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2202.01512"
  },
  {
    "id": "arXiv:2202.01515",
    "title": "Channel State Acquisition in FDD Massive MIMO: Rate-Distortion Bound and  Effectiveness of \"Analog\" Feedback",
    "abstract": "We consider the problem of estimating channel fading coefficients (modeled as\na correlated Gaussian vector) via Downlink (DL) training and Uplink (UL)\nfeedback in wideband FDD massive MIMO systems. Using rate-distortion theory, we\nderive optimal bounds on the achievable channel state estimation error in terms\nof the number of training pilots in DL ($\\beta_{tr}$) and feedback dimension in\nUL ($\\beta_{fb}$), with random, spatially isotropic pilots. It is shown that\nwhen the number of training pilots exceeds the channel covariance rank ($r$),\nthe optimal rate-distortion feedback strategy achieves an estimation error\ndecay of $\\Theta (SNR^{-\\alpha})$ in estimating the channel state, where\n$\\alpha = min (\\beta_{fb}/r , 1)$ is the so-called quality scaling exponent. We\nalso discuss an \"analog\" feedback strategy, showing that it can achieve the\noptimal quality scaling exponent for a wide range of training and feedback\ndimensions with no channel covariance knowledge and simple signal processing at\nthe user side. Our findings are supported by numerical simulations comparing\nvarious strategies in terms of channel state mean squared error and achievable\nergodic sum-rate in DL with zero-forcing precoding.",
    "descriptor": "\nComments: 9 pages, 3 figures. Extended version of a manuscript submitted to IEEE ISIT 2022\n",
    "authors": [
      "Mahdi Barzegar Khalilsarai",
      "Yi Song",
      "Tianyu Yang",
      "Giuseppe Caire"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.01515"
  },
  {
    "id": "arXiv:2202.01523",
    "title": "Bus Factor In Practice",
    "abstract": "Bus factor is a metric that identifies how resilient is the project to the\nsudden engineer turnover. It states the minimal number of engineers that have\nto be hit by a bus for a project to be stalled. Even though the metric is often\ndiscussed in the community, few studies consider its general relevance.\nMoreover, the existing tools for bus factor estimation focus solely on the data\nfrom version control systems, even though there exists other channels for\nknowledge generation and distribution. With a survey of 269 engineers, we find\nthat the bus factor is perceived as an important problem in collective\ndevelopment, and determine the highest impact channels of knowledge generation\nand distribution in software development teams. We also propose a multimodal\nbus factor estimation algorithm that uses data on code reviews and meetings\ntogether with the VCS data. We test the algorithm on 13 projects developed at\nJetBrains and compared its results to the results of the state-of-the-art tool\nby Avelino et al. against the ground truth collected in a survey of the\nengineers working on these projects. Our algorithm is slightly better in terms\nof both predicting the bus factor as well as key developers compared to the\nresults of Avelino et al. Finally, we use the interviews and the surveys to\nderive a set of best practices to address the bus factor issue and proposals\nfor the possible bus factor assessment tool.",
    "descriptor": "\nComments: 10 pages\n",
    "authors": [
      "Elgun Jabrayilzade",
      "Mikhail Evtikhiev",
      "Eray T\u00fcz\u00fcn",
      "Vladimir Kovalenko"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2202.01523"
  },
  {
    "id": "arXiv:2202.01525",
    "title": "Reliable Community Search in Dynamic Networks",
    "abstract": "Local community search is an important research topic to support complex\nnetwork data analysis in various scenarios like social networks, collaboration\nnetworks, and cellular networks. The evolution of networks over time has\nmotivated several recent studies to identify local communities from dynamic\nnetworks. However, they only utilized the aggregation of disjoint structural\ninformation to measure the quality of communities, which ignores the\nreliability of communities in a continuous time interval. To fill this research\ngap, we propose a novel $(\\theta,k)$-$core$ reliable community (CRC) model in\nthe weighted dynamic networks, and define the problem of the most reliable\ncommunity search that couples the desirable properties of connection strength,\ncohesive structure continuity, and the maximal member engagement. To solve this\nproblem, we first develop an online CRC search algorithm by proposing a\ndefinition of eligible edge set and deriving the eligible edge set based\npruning rules. % called the Eligible Edge Filtering-based CRC algorithm. After\nthat, we devise a Weighted Core Forest-Index and index-based dynamic\nprogramming CRC search algorithm, which can prune a large number of\ninsignificant intermediate results according to the maintained weight and\nstructure information in the index, as well as the proposed upper bound\nproperties. % our proposed pruning properties and upper bound properties.\nFinally, we conduct extensive experiments to verify the efficiency of our\nproposed algorithms and the effectiveness of our proposed community model on\neight real datasets under different parameter settings.",
    "descriptor": "",
    "authors": [
      "Yifu Tang",
      "Jianxin Li",
      "Nur Al Hasan Haldar",
      "Ziyu Guan",
      "Jiajie Xu",
      "Chengfei Liu"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2202.01525"
  },
  {
    "id": "arXiv:2202.01529",
    "title": "Comparative assessment of federated and centralized machine learning",
    "abstract": "Federated Learning (FL) is a privacy preserving machine learning scheme,\nwhere training happens with data federated across devices and not leaving them\nto sustain user privacy. This is ensured by making the untrained or partially\ntrained models to reach directly the individual devices and getting locally\ntrained \"on-device\" using the device owned data, and the server aggregating all\nthe partially trained model learnings to update a global model. Although almost\nall the model learning schemes in the federated learning setup use gradient\ndescent, there are certain characteristic differences brought about by the\nnon-IID nature of the data availability, that affects the training in\ncomparison to the centralized schemes. In this paper, we discuss the various\nfactors that affect the federated learning training, because of the non-IID\ndistributed nature of the data, as well as the inherent differences in the\nfederating learning approach as against the typical centralized gradient\ndescent techniques. We empirically demonstrate the effect of number of samples\nper device and the distribution of output labels on federated learning. In\naddition to the privacy advantage we seek through federated learning, we also\nstudy if there is a cost advantage while using federated learning frameworks.\nWe show that federated learning does have an advantage in cost when the model\nsizes to be trained are not reasonably large. All in all, we present the need\nfor careful design of model for both performance and cost.",
    "descriptor": "\nComments: 15 pages, 7 figures, 1 table\n",
    "authors": [
      "Ibrahim Abdul Majeed",
      "Sagar Kaushik",
      "Aniruddha Bardhan",
      "Venkata Siva Kumar Tadi",
      "Hwang-Ki Min",
      "Karthikeyan Kumaraguru",
      "Rajasekhara Duvvuru Muni"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2202.01529"
  },
  {
    "id": "arXiv:2202.01534",
    "title": "Influence-Augmented Local Simulators: A Scalable Solution for Fast Deep  RL in Large Networked Systems",
    "abstract": "Learning effective policies for real-world problems is still an open\nchallenge for the field of reinforcement learning (RL). The main limitation\nbeing the amount of data needed and the pace at which that data can be\nobtained. In this paper, we study how to build lightweight simulators of\ncomplicated systems that can run sufficiently fast for deep RL to be\napplicable. We focus on domains where agents interact with a reduced portion of\na larger environment while still being affected by the global dynamics. Our\nmethod combines the use of local simulators with learned models that mimic the\ninfluence of the global system. The experiments reveal that incorporating this\nidea into the deep RL workflow can considerably accelerate the training process\nand presents several opportunities for the future.",
    "descriptor": "",
    "authors": [
      "Miguel Suau",
      "Jinke He",
      "Matthijs T. J. Spaan",
      "Frans A. Oliehoek"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.01534"
  },
  {
    "id": "arXiv:2202.01537",
    "title": "Bending Graphs: Hierarchical Shape Matching using Gated Optimal  Transport",
    "abstract": "Shape matching has been a long-studied problem for the computer graphics and\nvision community. The objective is to predict a dense correspondence between\nmeshes that have a certain degree of deformation. Existing methods either\nconsider the local description of sampled points or discover correspondences\nbased on global shape information. In this work, we investigate a hierarchical\nlearning design, to which we incorporate local patch-level information and\nglobal shape-level structures. This flexible representation enables\ncorrespondence prediction and provides rich features for the matching stage.\nFinally, we propose a novel optimal transport solver by recurrently updating\nfeatures on non-confident nodes to learn globally consistent correspondences\nbetween the shapes. Our results on publicly available datasets suggest robust\nperformance in presence of severe deformations without the need for extensive\ntraining or refinement.",
    "descriptor": "",
    "authors": [
      "Mahdi Saleh",
      "Shun-Cheng Wu",
      "Luca Cosmo",
      "Nassir Navab",
      "Benjamin Busam",
      "Federico Tombari"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computational Geometry (cs.CG)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2202.01537"
  },
  {
    "id": "arXiv:2202.01541",
    "title": "Runge-Kutta-Nystr\u00f6m symplectic splitting methods of order 8",
    "abstract": "Different families of Runge-Kutta-Nystr\\\"om (RKN) symplectic splitting\nmethods of order 8 are presented for second-order systems of ordinary\ndifferential equations and are tested on numerical examples. They show a better\nefficiency than state-of-the-art symmetric compositions of 2nd-order symmetric\nschemes and RKN splitting methods of orders 4 and 6 for medium to high\naccuracy. For some particular examples, they are even more efficient than\nextrapolation methods for high accuracies and integrations over relatively\nshort time intervals.",
    "descriptor": "",
    "authors": [
      "F.Casas",
      "S.Blanes",
      "A.Escorihuela-Tom\u00e0s"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.01541"
  },
  {
    "id": "arXiv:2202.01542",
    "title": "A Method for Counting, Tracking and Monitoring of Visitors with RFID  sensors",
    "abstract": "This publication presents a method responsible for counting tracking and\nmonitoring visitors inside a building. The site examined is Manos Hatzidakis'\nHouse, situated in Xanthi. Specifically, we have conducted a study, which\nprovides recommendations, regarding the installation of sensors in the\nbuilding. We also present the communication protocols of the computer network\nused in order to ensure the efficient communication between the space examined\nand the sensor network. Finally, we describe the process of creating a website,\nwhich is designed to store and view the data.",
    "descriptor": "\nComments: 6 pages,8 figures, 22 references, Proceedings of 10th Panhellenic Electrical and Computer Engineering Students Conference (ECESCON) 2018 Xanthi\n",
    "authors": [
      "Alexandros Gazis",
      "Konstantinos Stamatis",
      "Eleftheria Katsiri"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2202.01542"
  },
  {
    "id": "arXiv:2202.01543",
    "title": "Design and Development of Automated Threat Hunting in Industrial Control  Systems",
    "abstract": "Traditional industrial systems, e.g., power plants, water treatment plants,\netc., were built to operate highly isolated and controlled capacity. Recently,\nIndustrial Control Systems (ICSs) have been exposed to the Internet for ease of\naccess and adaptation to advanced technologies. However, it creates security\nvulnerabilities. Attackers often exploit these vulnerabilities to launch an\nattack on ICSs. Towards this, threat hunting is performed to proactively\nmonitor the security of ICS networks and protect them against threats that\ncould make the systems malfunction. A threat hunter manually identifies threats\nand provides a hypothesis based on the available threat intelligence. In this\npaper, we motivate the gap in lacking research in the automation of threat\nhunting in ICS networks. We propose an automated extraction of threat\nintelligence and the generation and validation of a hypothesis. We present an\nautomated threat hunting framework based on threat intelligence provided by the\nICS MITRE ATT&CK framework to automate the tasks. Unlike the existing hunting\nsolutions which are cloud-based, costly and prone to human errors, our solution\nis a central and open-source implemented using different open-source\ntechnologies, e.g., Elasticsearch, Conpot, Metasploit, Web Single Page\nApplication (SPA), and a machine learning analyser. Our results demonstrate\nthat the proposed threat hunting solution can identify the network's attacks\nand alert a threat hunter with a hypothesis generated based on the techniques,\ntactics, and procedures (TTPs) from ICS MITRE ATT&CK. Then, a machine learning\nclassifier automatically predicts the future actions of the attack.",
    "descriptor": "",
    "authors": [
      "Masumi Arafune",
      "Sidharth Rajalakshmi",
      "Luigi Jaldon",
      "Zahra Jadidi",
      "Shantanu Pal",
      "Ernest Foo",
      "Nagarajan Venkatachalam"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2202.01543"
  },
  {
    "id": "arXiv:2202.01545",
    "title": "Byzantine-Robust Decentralized Learning via Self-Centered Clipping",
    "abstract": "In this paper, we study the challenging task of Byzantine-robust\ndecentralized training on arbitrary communication graphs. Unlike federated\nlearning where workers communicate through a server, workers in the\ndecentralized environment can only talk to their neighbors, making it harder to\nreach consensus. We identify a novel dissensus attack in which few malicious\nnodes can take advantage of information bottlenecks in the topology to poison\nthe collaboration. To address these issues, we propose a Self-Centered Clipping\n(SCClip) algorithm for Byzantine-robust consensus and optimization, which is\nthe first to provably converge to a $O(\\delta_{\\max}\\zeta^2/\\gamma^2)$\nneighborhood of the stationary point for non-convex objectives under standard\nassumptions. Finally, we demonstrate the encouraging empirical performance of\nSCClip under a large number of attacks.",
    "descriptor": "",
    "authors": [
      "Lie He",
      "Sai Praneeth Karimireddy",
      "Martin Jaggi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.01545"
  },
  {
    "id": "arXiv:2202.01546",
    "title": "QueryER: A Framework for Fast Analysis-Aware Deduplication over Dirty  Data",
    "abstract": "In this work, we explore the problem of correctly and efficiently answering\ncomplex SPJ queries issued directly on top of dirty data. We introduce QueryER,\na framework that seamlessly integrates Entity Resolution into Query Processing.\nQueryER executes analysis-aware deduplication by weaving ER operators into the\nquery plan. The experimental evaluation of our approach exhibits that it adapts\nto the workload and scales on both real and synthetic datasets.",
    "descriptor": "",
    "authors": [
      "Giorgos Alexiou",
      "George Papastefanatos",
      "Vassilis Stamatopoulos",
      "Georgia Koutrika",
      "Nectarios Koziris"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2202.01546"
  },
  {
    "id": "arXiv:2202.01550",
    "title": "Multi-Objective Optimization, different approach to query a database",
    "abstract": "The datasets available nowadays are very rich and complex, but how do we\nreach the information we are looking for? In this survey, two different\napproaches to query a dataset are analyzed and algorithms for each type are\nexplained. Specifically, the TA and NRA have been analyzed for the Top-K query\nand the Basic Block Nested Loops has been examined for the skyline query.\nMoreover, it's explained the core idea behind the Prioritized and Flexible\nskyline. In the end, the pros and cons of each type of analyzed query have been\nevaluated based on different criteria.",
    "descriptor": "\nComments: 7 pages, 11 references\n",
    "authors": [
      "Matteo Cordioli"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2202.01550"
  },
  {
    "id": "arXiv:2202.01551",
    "title": "Minimal Length of Nontrivial Solutions of the Isometry Equation and  MacWilliams Extension Property with Respect to Weighted Poset Metric",
    "abstract": "For $R\\triangleq Mat_{m}(\\mathbb{F})$, the ring of all the $m\\times m$\nmatrices over the finite field $\\mathbb{F}$ with $|\\mathbb{F}|=q$, and the left\n$R$-module $A\\triangleq Mat_{m,k}(\\mathbb{F})$ with $m+1\\leqslant k$, by\nderiving the minimal length of solutions of the related isometry equation,\nDyshko has proved in \\cite{3,4} that the minimal code length $n$ for $A^{n}$\nnot to satisfy the MacWilliams extension property with respect to Hamming\nweight is equal to $\\prod_{i=1}^{m}(q^{i}+1)$. In this paper, using the\nM\\\"{o}bius functions, we derive the minimal length of nontrivial solutions of\nthe isometry equation with respect to a finite lattice. For the finite vector\nspace $\\mathbf{H}\\triangleq\\prod_{i\\in\\Omega}\\mathbb{F}^{k_{i}}$, a poset\n$\\mathbf{P}=(\\Omega,\\preccurlyeq_{\\mathbf{P}})$ and a map\n$\\omega:\\Omega\\longrightarrow\\mathbb{R}^{+}$ give rise to the\n$(\\mathbf{P},\\omega)$-weight on $\\mathbf{H}$, which has been proposed by Hyun,\nKim and Park in \\cite{18}. For such a weight, we study the relations between\nthe MacWilliams extension property and other properties including admitting\nMacWilliams identity, Fourier-reflexivity of involved partitions and Unique\nDecomposition Property defined for $(\\mathbf{P},\\omega)$. We give necessary and\nsufficient conditions for $\\mathbf{H}$ to satisfy the MacWilliams extension\nproperty with the additional assumption that either $\\mathbf{P}$ is\nhierarchical or $\\omega$ is identically $1$, i.e., $(\\mathbf{P},\\omega)$-weight\ncoincides with $\\mathbf{P}$-weight, which further allow us to partly answer a\nconjecture proposed by Machado and Firer in \\cite{22}.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2201.10828\n",
    "authors": [
      "Yang Xu",
      "Haibin Kan",
      "Guangyue Han"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.01551"
  },
  {
    "id": "arXiv:2202.01554",
    "title": "Newton Type Methods for solving a Hasegawa-Mima Plasma Model",
    "abstract": "In [1], the non-linear space-time Hasegawa-Mima plasma equation is formulated\nas a coupled system of two linear PDE's, a solution of which is a pair (u, w).\nThe first equation is of hyperbolic type and the second of elliptic type.\nVariational frames for obtaining weak solutions to the initial value\nHasegawa-Mima problem with periodic boundary conditions were also derived. In a\nmore recent work [2], a numerical approach consisting of a finite element\nspace-domain combined with an Euler-implicit time scheme was used to discretize\nthe coupled variational Hasegawa-Mima model. A semi-linear version of this\nimplicit nonlinear scheme was tested for several types of initial conditions.\nThis semi-linear scheme proved to lack efficiency for long time, which\nnecessitates imposing a cap on the magnitude of the solution. To circumvent\nthis difficulty, in this paper, we use Newton-type methods (Newton, Chord and\nan introduced Modified Newton method) to solve numerically the fully-implicit\nnon-linear scheme. Testing these methods in FreeFEM++ indicates significant\nimprovements as no cap needs to be imposed for long time. In the sequel, we\ndemonstrate the validity of these methods by proving several results, in\nparticular the convergence of the implemented methods.",
    "descriptor": "\nComments: 27 pages, 5 figures with 48 subfigures\n",
    "authors": [
      "Sophie M. Moufawad",
      "Nabil R. Nassif"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.01554"
  },
  {
    "id": "arXiv:2202.01559",
    "title": "Robotic Aerial 6G Small Cells with Grasping End Effectors for mmWave  Relay Backhauling",
    "abstract": "Deployment of small cells in dense urban areas dedicated to the heterogeneous\nnetwork (HetNet) and associated relay nodes for improving backhauling is\nexpected to be an important structural element in the design of beyond 5G (B5G)\nand 6G wireless access networks. A key operational aspect in HetNets is how to\noptimally implement the wireless backhaul links to efficiently support the\ntraffic demand. In this work, we utilize the recently proposed Robotic Aerial\nSmall Cells (RASCs) that are able to grasp at different tall urban landforms as\nwireless relay nodes for backhauling. This can be considered as an alternative\nto fixed small cells (FSCs) which lack flexibility since once installed their\nposition cannot be altered. More specifically, on-demand deployment of RASCs is\nconsidered for constructing a millimeter-wave (mmWave) backhaul network to\noptimize available network capacity using a network flow-based mixed integer\nlinear programming (MILP) formulation. Numerical investigations reveal that for\nthe same required achievable throughput, the number of RASCs required are 25\\%\nto 65\\% less than the number of required FSCs. This result can have significant\nimplications in reducing required wireless network equipment (capex) to provide\na given network capacity and allows for an efficient and flexible network\ndensification.",
    "descriptor": "\nComments: 6 pages, 4 figures, conference\n",
    "authors": [
      "Jongyul Lee",
      "Vasilis Friderikos"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.01559"
  },
  {
    "id": "arXiv:2202.01560",
    "title": "Extending turbulence model uncertainty quantification using machine  learning",
    "abstract": "In order to achieve a more virtual design and certification process of jet\nengines in aviation industry, the uncertainty bounds for computational fluid\ndynamics have to be known. This work shows the application of a machine\nlearning methodology to quantify the epistemic uncertainties of turbulence\nmodels. The underlying method in order to estimate the uncertainty bounds is\nbased on an eigenspace perturbation of the Reynolds stress tensor in\ncombination with random forests.",
    "descriptor": "\nComments: NeurIPS2021 - Thirty-fifth Conference on Neural Information Processing Systems, Fourth Workshop on Machine Learning and the Physical Sciences, 5 pages, 4 figures\n",
    "authors": [
      "Marcel Matha",
      "Christian Morsbach"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2202.01560"
  },
  {
    "id": "arXiv:2202.01563",
    "title": "On the Number of Graphs with a Given Histogram",
    "abstract": "Let $G$ be a large (simple, unlabeled) dense graph on $n$ vertices. Suppose\nthat we only know, or can estimate, the empirical distribution of the number of\nsubgraphs $F$ that each vertex in $G$ participates in, for some fixed small\ngraph $F$. How many other graphs would look essentially the same to us, i.e.,\nwould have a similar local structure? In this paper, we derive upper and lower\nbounds on the number graphs whose empirical distribution lies close (in the\nKolmogorov-Smirnov distance) to that of $G$. Our bounds are given as solutions\nto a maximum entropy problem on random graphs of a fixed size $k$ that does not\ndepend on $n$, under $d$ global density constraints. The bounds are\nasymptotically close, with a gap that vanishes with $d$ at a rate that depends\non the concentration function of the center of the Kolmogorov-Smirnov ball.",
    "descriptor": "\nComments: 25 pages\n",
    "authors": [
      "Shahar Stein Ioushua",
      "Ofer Shayevitz"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.01563"
  },
  {
    "id": "arXiv:2202.01567",
    "title": "Perpetual maintenance of machines with different urgency requirements",
    "abstract": "A garden $G$ is populated by $n\\ge 1$ bamboos $b_1, b_2, ..., b_n$ with the\nrespective daily growth rates $h_1 \\ge h_2 \\ge \\dots \\ge h_n$. It is assumed\nthat the initial heights of bamboos are zero. The robotic gardener maintaining\nthe garden regularly attends bamboos and trims them to height zero according to\nsome schedule. The Bamboo Garden Trimming Problem (BGT) is to design a\nperpetual schedule of cuts to maintain the elevation of the bamboo garden as\nlow as possible. The bamboo garden is a metaphor for a collection of machines\nwhich have to be serviced, with different frequencies, by a robot which can\nservice only one machine at a time. The objective is to design a perpetual\nschedule of servicing which minimizes the maximum (weighted) waiting time for\nservicing.\nWe consider two variants of BGT. In discrete BGT the robot trims only one\nbamboo at the end of each day. In continuous BGT the bamboos can be cut at any\ntime, however, the robot needs time to move from one bamboo to the next.\nFor discrete BGT, we show a simple $4$-approximation algorithm and, by\nexploiting relationship between BGT and the classical Pinwheel scheduling\nproblem, we derive a $2$-approximation algorithm for the general case and a\ntighter approximation when the growth rates are balanced. A by-product of this\nlast approximation algorithm is that it settles one of the conjectures about\nthe Pinwheel problem. For continuous BGT, we propose approximation algorithms\nwhich achieve approximation ratios $O(\\log (h_1/h_n))$ and $O(\\log n)$.",
    "descriptor": "\nComments: 28 pages; 3 figures. A preliminary version appeared in the proceedings of SOFSEM 2017\n",
    "authors": [
      "Leszek G\u0105sieniec",
      "Ralf Klasing",
      "Christos Levcopoulos",
      "Andrzej Lingas",
      "Jie Min",
      "Tomasz Radzik"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2202.01567"
  },
  {
    "id": "arXiv:2202.01575",
    "title": "CoST: Contrastive Learning of Disentangled Seasonal-Trend  Representations for Time Series Forecasting",
    "abstract": "Deep learning has been actively studied for time series forecasting, and the\nmainstream paradigm is based on the end-to-end training of neural network\narchitectures, ranging from classical LSTM/RNNs to more recent TCNs and\nTransformers. Motivated by the recent success of representation learning in\ncomputer vision and natural language processing, we argue that a more promising\nparadigm for time series forecasting, is to first learn disentangled feature\nrepresentations, followed by a simple regression fine-tuning step -- we justify\nsuch a paradigm from a causal perspective. Following this principle, we propose\na new time series representation learning framework for time series forecasting\nnamed CoST, which applies contrastive learning methods to learn disentangled\nseasonal-trend representations. CoST comprises both time domain and frequency\ndomain contrastive losses to learn discriminative trend and seasonal\nrepresentations, respectively. Extensive experiments on real-world datasets\nshow that CoST consistently outperforms the state-of-the-art methods by a\nconsiderable margin, achieving a 21.3\\% improvement in MSE on multivariate\nbenchmarks. It is also robust to various choices of backbone encoders, as well\nas downstream regressors.",
    "descriptor": "",
    "authors": [
      "Gerald Woo",
      "Chenghao Liu",
      "Doyen Sahoo",
      "Akshat Kumar",
      "Steven Hoi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.01575"
  },
  {
    "id": "arXiv:2202.01577",
    "title": "An all Mach number finite volume method for isentropic two-phase flow",
    "abstract": "We present an implicit-explicit finite volume scheme for isentropic two phase\nflow in all Mach number regimes. The underlying model belongs to the class of\nsymmetric hyperbolic thermodynamically compatible models. The key element of\nthe scheme consists of a linearisation of pressure and enthalpy terms at a\nreference state. The resulting stiff linear parts are integrated implicitly,\nwhereas the non-linear higher order and transport terms are treated explicitly.\nDue to the flux splitting, the scheme is stable under a CFL condition which\ndetermined by the resolution of the slow material waves and allows large time\nsteps even in the presence of fast acoustic waves. Further the singular Mach\nnumber limits of the model are studied and the asymptotic preserving property\nof the scheme is proven. In numerical simulations the consistency with single\nphase flow, accuracy and the approximation of material waves in different Mach\nnumber regimes are assessed.",
    "descriptor": "",
    "authors": [
      "Maria Lukacova-Medvid'ova",
      "Gabriella Puppo",
      "Andrea Thomann"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.01577"
  },
  {
    "id": "arXiv:2202.01580",
    "title": "Fixed Points and 2-Cycles of Synchronous Dynamic Coloring Processes on  Trees",
    "abstract": "This paper considers synchronous discrete-time dynamical systems on graphs\nbased on the threshold model. It is well known that after a finite number of\nrounds these systems either reach a fixed point or enter a 2-cycle. The problem\nof finding the fixed points for this type of dynamical system is in general\nboth NP-hard and #P-complete. In this paper we give a surprisingly simple\ngraph-theoretic characterization of fixed points and 2-cycles for the class of\nfinite trees. Thus, the class of trees is the first nontrivial graph class for\nwhich a complete characterization of fixed points exists. This characterization\nenables us to provide bounds for the total number of fixed points and pure\n2-cycles. It also leads to an output-sensitive algorithm to efficiently\ngenerate these states.",
    "descriptor": "\nComments: 15 pages, 7 figures\n",
    "authors": [
      "Volker Turau"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2202.01580"
  },
  {
    "id": "arXiv:2202.01581",
    "title": "Are Bundles Good Deals for FOML?",
    "abstract": "Bundled products are often offered as good deals to customers. When we bundle\nquantifiers and modalities together (as in $\\exists x \\Box$, $\\Diamond \\forall\nx$ etc.) in first-order modal logic (FOML), we get new logical operators whose\ncombinations produce interesting fragments of FOML without any restriction on\nthe arity of predicates, the number of variables, or the modal scope. It is\nwell-known that finding decidable fragments of FOML is hard, so we may ask: do\nbundled fragments that exploit the distinct expressivity of FOML constitute\ngood deals in balancing the expressivity and complexity? There are a few\npositive earlier results on some particular fragments. In this paper, we try to\nfully map the terrain of bundled fragments of FOML in (un)decidability, and in\nthe cases without a definite answer yet, we show that they lack the finite\nmodel property. Moreover, whether the logics are interpreted over constant\ndomains (across states/worlds) or increasing domains presents another layer of\ncomplexity. We also present the \\textit{loosely bundled fragment}, which\ngeneralizes the bundles and yet retain decidability (over increasing domain\nmodels).",
    "descriptor": "",
    "authors": [
      "Mo Liu",
      "Anantha Padmanabha",
      "R Ramanujam",
      "Yanjing Wang"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2202.01581"
  },
  {
    "id": "arXiv:2202.01582",
    "title": "A Psychoacoustic Quality Criterion for Path-Traced Sound Propagation",
    "abstract": "In developing virtual acoustic environments, it is important to understand\nthe relationship between the computation cost and the perceptual significance\nof the resultant numerical error. In this paper, we propose a quality criterion\nthat evaluates the error significance of path-tracing-based sound propagation\nsimulators. We present an analytical formula that estimates the error signal\npower spectrum. With this spectrum estimation, we can use a modified Zwicker's\nloudness model to calculate the relative loudness of the error signal masked by\nthe ideal output. Our experimental results show that the proposed criterion can\nexplain the human perception of simulation error in a variety of cases.",
    "descriptor": "\nComments: 12 pages, 9 figures. To be published in IEEE TVCG\n",
    "authors": [
      "Chunxiao Cao",
      "Zili An",
      "Zhong Ren",
      "Dinesh Manocha",
      "Kun Zhou"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Graphics (cs.GR)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2202.01582"
  },
  {
    "id": "arXiv:2202.01587",
    "title": "MiDaS: Representative Sampling from Real-world Hypergraphs",
    "abstract": "Graphs are widely used for representing pairwise interactions in complex\nsystems. Since such real-world graphs are large and often evergrowing, sampling\na small representative subgraph is indispensable for various purposes:\nsimulation, visualization, stream processing, representation learning,\ncrawling, to name a few. However, many complex systems consist of group\ninteractions (e.g., collaborations of researchers and discussions on online Q&A\nplatforms), and thus they can be represented more naturally and accurately by\nhypergraphs (i.e., sets of sets) than by ordinary graphs. Motivated by the\nprevalence of large-scale hypergraphs, we study the problem of representative\nsampling from real-world hypergraphs, aiming to answer (Q1) what a\nrepresentative sub-hypergraph is and (Q2) how we can find a representative one\nrapidly without an extensive search. Regarding Q1, we propose to measure the\ngoodness of a sub-hypergraph by comparing it with the entire hypergraph in\nterms of ten graph-level, hyperedge-level, and node-level statistics. Regarding\nQ2, we first analyze the characteristics of six intuitive approaches in 11\nreal-world hypergraphs. Then, based on the analysis, we propose MiDaS, which\ndraws hyperedges with a bias towards those with high-degree nodes. Through\nextensive experiments, we demonstrate that MiDaS is (a) Representative: finding\noverall the most representative samples among 13 considered approaches, (b)\nFast: several orders of magnitude faster than the strongest competitors, which\nperforms an extensive search, and (c) Automatic: rapidly searching a proper\ndegree of bias.",
    "descriptor": "\nComments: Accepted to WWW 2022 - The Web Conference 2022\n",
    "authors": [
      "Minyoung Choe",
      "Jaemin Yoo",
      "Geon Lee",
      "Woonsung Baek",
      "U Kang",
      "Kijung Shin"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2202.01587"
  },
  {
    "id": "arXiv:2202.01594",
    "title": "Approximate NFA Universality and Related Problems Motivated by  Information Theory",
    "abstract": "In coding and information theory, it is desirable to construct maximal codes\nthat can be either variable length codes or error control codes of fixed\nlength. However deciding code maximality boils down to deciding whether a given\nNFA is universal, and this is a hard problem (including the case of whether the\nNFA accepts all words of a fixed length). On the other hand, it is acceptable\nto know whether a code is `approximately' maximal, which then boils down to\nwhether a given NFA is `approximately' universal. Here we introduce the notion\nof a $(1-\\epsilon)$-universal automaton and present polynomial randomized\napproximation algorithms to test NFA universality and related hard automata\nproblems, for certain natural probability distributions on the set of words. We\nalso conclude that the randomization aspect is necessary, as approximate\nuniversality remains hard for any polynomially computable $\\epsilon$.",
    "descriptor": "\nComments: 23 pages\n",
    "authors": [
      "Stavros Konstantinidis",
      "Mitja Mastnak",
      "Nelma Moreira",
      "Rog\u00e9rio Reis"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2202.01594"
  },
  {
    "id": "arXiv:2202.01600",
    "title": "Context-Based MEC Platform for Augmented-Reality Services in 5G Networks",
    "abstract": "Augmented reality (AR) has drawn great attention in recent years. However,\ncurrent AR devices have drawbacks, e.g., weak computation ability and large\npower consumption. To solve the problem, mobile edge computing (MEC) can be\nintroduced as a key technology to offload data and computation from AR devices\nto MEC servers via 5th Generation Mobile Communication Technology (5G)\nnetworks. To this end, a context-based MEC platform for AR services in 5G\nnetworks is proposed in this paper. On the platform, MEC is employed as a data\nprocessing center while AR devices are simplified as universal input/output\ndevices, which overcomes their limitations and achieves better user experience.\nMoreover, the proof-of-concept (PoC) hardware prototype of the platform, and\ntwo typical use cases providing AR services of navigation and face recognition\nrespectively are implemented to demonstrate the feasibility and effectiveness\nof the platform. Finally, the performance of the platform is also numerically\nevaluated, and the results validate the system design and agree well with the\ndesign expectations.",
    "descriptor": "\nComments: Accepted in VTC 2021 Fall\n",
    "authors": [
      "Yue Wang",
      "Tao Yu",
      "Kei Sakaguchi"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2202.01600"
  },
  {
    "id": "arXiv:2202.01601",
    "title": "A time dependent singularly perturbed problem with shift in space",
    "abstract": "We consider a singularly perturbed time dependent problem with a shift term\nin space. On appropriately defined layer adapted meshes of Dur\\'an- and S-type\nwe derive a-priori error estimates for the stationary problem. Using a\ndiscontinuous Galerkin method in time we obtain error estimates for the full\ndiscretisation. Introduction of a weighted scalar products and norms allows us\nto estimate the time-dependent problem in energy and balanced norm. So far it\nwas open to prove such a result. Some numerical results are given to confirm\nthe predicted theory and to show the effect of shifts on the solution.",
    "descriptor": "\nComments: 17 pages, 2 figures, 3 tables\n",
    "authors": [
      "Mirjana Brdar",
      "Sebastian Franz",
      "Lars Ludwig",
      "Hans-G\u00f6rg Roos"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.01601"
  },
  {
    "id": "arXiv:2202.01602",
    "title": "The Disagreement Problem in Explainable Machine Learning: A  Practitioner's Perspective",
    "abstract": "As various post hoc explanation methods are increasingly being leveraged to\nexplain complex models in high-stakes settings, it becomes critical to develop\na deeper understanding of if and when the explanations output by these methods\ndisagree with each other, and how such disagreements are resolved in practice.\nHowever, there is little to no research that provides answers to these critical\nquestions. In this work, we introduce and study the disagreement problem in\nexplainable machine learning. More specifically, we formalize the notion of\ndisagreement between explanations, analyze how often such disagreements occur\nin practice, and how do practitioners resolve these disagreements. To this end,\nwe first conduct interviews with data scientists to understand what constitutes\ndisagreement between explanations generated by different methods for the same\nmodel prediction, and introduce a novel quantitative framework to formalize\nthis understanding. We then leverage this framework to carry out a rigorous\nempirical analysis with four real-world datasets, six state-of-the-art post hoc\nexplanation methods, and eight different predictive models, to measure the\nextent of disagreement between the explanations generated by various popular\nexplanation methods. In addition, we carry out an online user study with data\nscientists to understand how they resolve the aforementioned disagreements. Our\nresults indicate that state-of-the-art explanation methods often disagree in\nterms of the explanations they output. Our findings underscore the importance\nof developing principled evaluation metrics that enable practitioners to\neffectively compare explanations.",
    "descriptor": "",
    "authors": [
      "Satyapriya Krishna",
      "Tessa Han",
      "Alex Gu",
      "Javin Pombra",
      "Shahin Jabbari",
      "Steven Wu",
      "Himabindu Lakkaraju"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.01602"
  },
  {
    "id": "arXiv:2202.01604",
    "title": "A Taxonomy for Contrasting Industrial Control Systems Asset Discovery  Tools",
    "abstract": "Asset scanning and discovery is the first and foremost step for organizations\nto understand what assets they have and what to protect. There is currently a\nplethora of free and commercial asset scanning tools specializing in\nidentifying assets in industrial control systems (ICS). However, there is\nlittle information available on their comparative capabilities and how their\nrespective features contrast. Nor is it clear to what depth of scanning these\ntools can reach and whether they are fit-for-purpose in a scaled industrial\nnetwork architecture. We provide the first systematic feature comparison of\nfree-to-use asset scanning tools on the basis of an ICS scanning taxonomy that\nwe propose. Based on the taxonomy, we investigate scanning depths reached by\nthe tools' features and validate our investigation through experimentation on\nSiemens, Schneider Electric, and Allen Bradley devices in a testbed\nenvironment.",
    "descriptor": "",
    "authors": [
      "Emmanouil Samanis",
      "Joseph Gardiner",
      "Awais Rashid"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.01604"
  },
  {
    "id": "arXiv:2202.01606",
    "title": "Graph Coloring with Physics-Inspired Graph Neural Networks",
    "abstract": "We show how graph neural networks can be used to solve the canonical graph\ncoloring problem. We frame graph coloring as a multi-class node classification\nproblem and utilize an unsupervised training strategy based on the statistical\nphysics Potts model. Generalizations to other multi-class problems such as\ncommunity detection, data clustering, and the minimum clique cover problem are\nstraightforward. We provide numerical benchmark results and illustrate our\napproach with an end-to-end application for a real-world scheduling use case\nwithin a comprehensive encode-process-decode framework. Our optimization\napproach performs on par or outperforms existing solvers, with the ability to\nscale to problems with millions of variables.",
    "descriptor": "\nComments: Manuscript: 8 pages, 4 figures, 2 tables. Supplemental Material: 1 page, 2 tables\n",
    "authors": [
      "Martin J. A. Schuetz",
      "J. Kyle Brubaker",
      "Zhihuai Zhu",
      "Helmut G. Katzgraber"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Artificial Intelligence (cs.AI)",
      "Optimization and Control (math.OC)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2202.01606"
  },
  {
    "id": "arXiv:2202.01612",
    "title": "Security of Microservice Applications: A Practitioners' Perspective on  Challenges and Best Practices",
    "abstract": "Cloud-based application deployment is becoming increasingly popular among\nbusinesses, thanks to the emergence of microservices. However, securing such\narchitectures is a challenging task since traditional security concepts cannot\nbe directly applied to microservice architectures due to their distributed\nnature. The situation is exacerbated by the scattered nature of guidelines and\nbest practices advocated by practitioners and organizations in this field. This\nresearch paper we aim to shay light over the current microservice security\ndiscussions hidden within Grey Literature (GL) sources. Particularly, we\nidentify the challenges that arise when securing microservice architectures, as\nwell as solutions recommended by practitioners to address these issues. For\nthis, we conducted a systematic GL study on the challenges and best practices\nof microservice security present in the Internet with the goal of capturing\nrelevant discussions in blogs, white papers, and standards. We collected 312 GL\nsources from which 57 were rigorously classified and analyzed. This analysis on\nthe one hand validated past academic literature studies in the area of\nmicroservice security, but it also identified improvements to existing\nmethodologies pointing towards future research directions.",
    "descriptor": "\nComments: This work has been submitted for publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Priyanka Billawa",
      "Anusha Bambhore Tukaram",
      "Nicol\u00e1s E. D\u00edaz Ferreyra",
      "Jan-Philipp Stegh\u00f6fer",
      "Riccardo Scandariato",
      "Georg Simhandl"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2202.01612"
  },
  {
    "id": "arXiv:2202.01614",
    "title": "The RoyalFlush System of Speech Recognition for M2MeT Challenge",
    "abstract": "This paper describes our RoyalFlush system for the track of multi-speaker\nautomatic speech recognition (ASR) in the M2MeT challenge. We adopted the\nserialized output training (SOT) based multi-speakers ASR system with\nlarge-scale simulation data. Firstly, we investigated a set of front-end\nmethods, including multi-channel weighted predicted error (WPE), beamforming,\nspeech separation, speech enhancement and so on, to process training,\nvalidation and test sets. But we only selected WPE and beamforming as our\nfrontend methods according to their experimental results. Secondly, we made\ngreat efforts in the data augmentation for multi-speaker ASR, mainly including\nadding noise and reverberation, overlapped speech simulation, multi-channel\nspeech simulation, speed perturbation, front-end processing, and so on, which\nbrought us a great performance improvement. Finally, in order to make full use\nof the performance complementary of different model architecture, we trained\nthe standard conformer based joint CTC/Attention (Conformer) and U2++ ASR model\nwith a bidirectional attention decoder, a modification of Conformer, to fuse\ntheir results. Comparing with the official baseline system, our system got a\n12.22% absolute Character Error Rate (CER) reduction on the validation set and\n12.11% on the test set.",
    "descriptor": "",
    "authors": [
      "Shuaishuai Ye",
      "Peiyao Wang",
      "Shunfei Chen",
      "Xinhui Hu",
      "Xinkang Xu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.01614"
  },
  {
    "id": "arXiv:2202.01615",
    "title": "Measuring Disparate Outcomes of Content Recommendation Algorithms with  Distributional Inequality Metrics",
    "abstract": "The harmful impacts of algorithmic decision systems have recently come into\nfocus, with many examples of systems such as machine learning (ML) models\namplifying existing societal biases. Most metrics attempting to quantify\ndisparities resulting from ML algorithms focus on differences between groups,\ndividing users based on demographic identities and comparing model performance\nor overall outcomes between these groups. However, in industry settings, such\ninformation is often not available, and inferring these characteristics carries\nits own risks and biases. Moreover, typical metrics that focus on a single\nclassifier's output ignore the complex network of systems that produce outcomes\nin real-world settings. In this paper, we evaluate a set of metrics originating\nfrom economics, distributional inequality metrics, and their ability to measure\ndisparities in content exposure in a production recommendation system, the\nTwitter algorithmic timeline. We define desirable criteria for metrics to be\nused in an operational setting, specifically by ML practitioners. We\ncharacterize different types of engagement with content on Twitter using these\nmetrics, and use these results to evaluate the metrics with respect to the\ndesired criteria. We show that we can use these metrics to identify content\nsuggestion algorithms that contribute more strongly to skewed outcomes between\nusers. Overall, we conclude that these metrics can be useful tools for\nunderstanding disparate outcomes in online social networks.",
    "descriptor": "\nComments: 11 pages, 7 figures\n",
    "authors": [
      "Tomo Lazovich",
      "Luca Belli",
      "Aaron Gonzales",
      "Amanda Bower",
      "Uthaipon Tantipongpipat",
      "Kristian Lum",
      "Ferenc Huszar",
      "Rumman Chowdhury"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.01615"
  },
  {
    "id": "arXiv:2202.01619",
    "title": "On Manifold Hypothesis: Hypersurface Submanifold Embedding Using  Osculating Hyperspheres",
    "abstract": "Consider a set of $n$ data points in the Euclidean space $\\mathbb{R}^d$. This\nset is called dataset in machine learning and data science. Manifold hypothesis\nstates that the dataset lies on a low-dimensional submanifold with high\nprobability. All dimensionality reduction and manifold learning methods have\nthe assumption of manifold hypothesis. In this paper, we show that the dataset\nlies on an embedded hypersurface submanifold which is locally\n$(d-1)$-dimensional. Hence, we show that the manifold hypothesis holds at least\nfor the embedding dimensionality $d-1$. Using an induction in a pyramid\nstructure, we also extend the embedding dimensionality to lower embedding\ndimensionalities to show the validity of manifold hypothesis for embedding\ndimensionalities $\\{1, 2, \\dots, d-1\\}$. For embedding the hypersurface, we\nfirst construct the $d$ nearest neighbors graph for data. For every point, we\nfit an osculating hypersphere $S^{d-1}$ using its neighbors where this\nhypersphere is osculating to a hypothetical hypersurface. Then, using surgery\ntheory, we apply surgery on the osculating hyperspheres to obtain $n$\nhyper-caps. We connect the hyper-caps to one another using partial\nhyper-cylinders. By connecting all parts, the embedded hypersurface is obtained\nas the disjoint union of these elements. We discuss the geometrical\ncharacteristics of the embedded hypersurface, such as having boundary, its\ntopology, smoothness, boundedness, orientability, compactness, and injectivity.\nSome discussion are also provided for the linearity and structure of data. This\npaper is the intersection of several fields of science including machine\nlearning, differential geometry, and algebraic topology.",
    "descriptor": "",
    "authors": [
      "Benyamin Ghojogh",
      "Fakhri Karray",
      "Mark Crowley"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Algebraic Topology (math.AT)",
      "Differential Geometry (math.DG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.01619"
  },
  {
    "id": "arXiv:2202.01622",
    "title": "A Gaussian method for the operator square root",
    "abstract": "We consider the approximation of the inverse square root of regularly\naccretive operators in Hilbert spaces. The approximation is of rational type\nand comes from the use of the Gauss-Legendre rule applied to a special integral\nformulation of the problem. We derive sharp error estimates, based on the use\nof the numerical range, and provide some numerical experiments. For practical\npurposes, the finite dimensional case is also considered. In this setting, the\nconvergence is shown to be of exponential type.",
    "descriptor": "",
    "authors": [
      "Eleonora Denich",
      "Paolo Novati"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.01622"
  },
  {
    "id": "arXiv:2202.01624",
    "title": "MFA: TDNN with Multi-scale Frequency-channel Attention for  Text-independent Speaker Verification with Short Utterances",
    "abstract": "The time delay neural network (TDNN) represents one of the state-of-the-art\nof neural solutions to text-independent speaker verification. However, they\nrequire a large number of filters to capture the speaker characteristics at any\nlocal frequency region. In addition, the performance of such systems may\ndegrade under short utterance scenarios. To address these issues, we propose a\nmulti-scale frequency-channel attention (MFA), where we characterize speakers\nat different scales through a novel dual-path design which consists of a\nconvolutional neural network and TDNN. We evaluate the proposed MFA on the\nVoxCeleb database and observe that the proposed framework with MFA can achieve\nstate-of-the-art performance while reducing parameters and computation\ncomplexity. Further, the MFA mechanism is found to be effective for speaker\nverification with short test utterances.",
    "descriptor": "\nComments: Accepted by ICASSP 2022\n",
    "authors": [
      "Tianchi Liu",
      "Rohan Kumar Das",
      "Kong Aik Lee",
      "Haizhou Li"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.01624"
  },
  {
    "id": "arXiv:2202.01627",
    "title": "Non-Vacuous Generalisation Bounds for Shallow Neural Networks",
    "abstract": "We focus on a specific class of shallow neural networks with a single hidden\nlayer, namely those with $L_2$-normalised data and either a sigmoid-shaped\nGaussian error function (\"erf\") activation or a Gaussian Error Linear Unit\n(GELU) activation. For these networks, we derive new generalisation bounds\nthrough the PAC-Bayesian theory; unlike most existing such bounds they apply to\nneural networks with deterministic rather than randomised parameters. Our\nbounds are empirically non-vacuous when the network is trained with vanilla\nstochastic gradient descent on MNIST and Fashion-MNIST.",
    "descriptor": "\nComments: 25 pages, 12 figures\n",
    "authors": [
      "Felix Biggs",
      "Benjamin Guedj"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.01627"
  },
  {
    "id": "arXiv:2202.01628",
    "title": "Feasible Wrench Set Computation for Legged Robots",
    "abstract": "During locomotion, legged robots interact with the ground by sequentially\nestablishing and breaking contact. The interaction wrenches that arise from\ncontact are used to steer the robot's Center of Mass (CoM) and reject\nperturbations that make the system deviate from the desired trajectory and\noften make them fall. The feasibility of a given control target (desired CoM\nwrench or acceleration) is conditioned by the contact point distribution,\nground friction, and actuation limits. In this work, we develop an algorithm to\ncompute the set of feasible wrenches that a legged robot can exert on its CoM\nthrough contact. The presented method can be used with any amount of\nnon-coplanar contacts and takes into account actuation limits and limitations\nbased on an inelastic contact model with Coulomb friction. This is exemplified\nwith a planar biped model standing with the feet at different heights.\nExploiting assumptions from the contact model, we explain how to compute the\nset of wrenches that are feasible on the CoM when the contacts remain in\nposition as well as the ones that are feasible when some of the contacts are\nbroken. Therefore, this algorithm can be used to assess whether a switch in\ncontact configuration is feasible while achieving a given control task.\nFurthermore, the method can be used to identify the directions in which the\nsystem is not actuated (i.e. a wrench cannot be exerted in those directions).\nWe show how having a joint be actuated or passive can change the non-actuated\nwrench directions of a robot at a given pose using a spatial model of a\nlower-extremity exoskeleton. Therefore, this algorithm is also a useful tool\nfor the design phase of the system. This work presents a useful tool for the\ncontrol and design of legged systems that extends on the current state of the\nart.",
    "descriptor": "\nComments: This work has been submitted to the \"IEEE Robotics and Automation Letters\" with \"IEEE International Conference on Intelligent Robots and Systems 2022\" option for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Ander Vallinas Prieto",
      "Arvid Q.L. Keemink",
      "Edwin H.F. van Asseldonk",
      "Herman van der Kooij"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.01628"
  },
  {
    "id": "arXiv:2202.01629",
    "title": "Use and abuse of instance parameters in the Lean mathematical library",
    "abstract": "The Lean mathematical library mathlib features extensive use of the typeclass\npattern for organising mathematical structures, based on Lean's mechanism of\ninstance parameters. Related mechanisms for typeclasses are available in other\nprovers including Agda, Coq and Isabelle with varying degrees of adoption. This\npaper analyses representative examples of design patterns involving instance\nparameters in the current Lean 3 version of mathlib, focussing on complications\narising at scale and how the mathlib community deals with them.",
    "descriptor": "\nComments: To be submitted to the conference Interactive Theorem Proving 2022 (Haifa, Israel)\n",
    "authors": [
      "Anne Baanen"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2202.01629"
  },
  {
    "id": "arXiv:2202.01639",
    "title": "Mathematical Content Browsing for Print-Disabled Readers Based on  Virtual-World Exploration and Audio-Visual Sensory substitution",
    "abstract": "Documents containing mathematical content remain largely inaccessible to\nblind and visually impaired readers because they are predominantly published as\nuntagged PDF which does not include the semantic data necessary for effective\naccessibility. We present a browsing approach for print-disabled readers\nspecifically aimed at such mathematical content. This approach draws on the\nnavigational mechanisms often used to explore the virtual worlds of text\nadventure games with audio-visual sensory substitution for graphical content.\nThe relative spatial placement of the elements of an equation are represented\nas a virtual world, so that the reader can navigate from element to element.\nText elements are announced conventionally using synthesised speech while\ngraphical elements, such as roots and fraction lines, are rendered using a\nmodification of the vOICe algorithm. The virtual world allows the reader to\ninteractively discover the spatial structure of the equation, while the\nrendition of graphical elements as sound allows the shape and identity of\nelements that cannot be synthesised as speech to be discovered and recognised.\nThe browsing approach was evaluated by eleven blind and fourteen sighted\nparticipants in a user trial that included the identification of twelve\nequations extracted from PDF documents. Overall, equations were identified\ncompletely correctly in 78% of cases (74% and 83% respectively for blind and\nsighted subjects). If partial correctness is considered, the performance is\nsubstantially higher. We conclude that the integration of a spatial model\nrepresented as a virtual world in conjunction with audio-visual sensory\nsubstitution for non-textual elements can be an effective way for blind and\nvisually impaired readers to read currently inaccessible mathematical content\nin PDF documents.",
    "descriptor": "",
    "authors": [
      "Rynhardt Kruger",
      "Febe de Wet",
      "Thomas Niesler"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2202.01639"
  },
  {
    "id": "arXiv:2202.01644",
    "title": "Entanglement: Cybercrime Connections of an Internet Marketing Forum  Population",
    "abstract": "Many activities related to cybercrime operations do not require much secrecy,\nsuch as developing websites or translating texts. This research provides\nindications that many users of a popular public internet marketing forum have\nconnections to cybercrime. It does so by investigating the involvement in\ncybercrime of a population of users interested in internet marketing, both at a\nmicro and macro scale. The research starts with a case study of three users\nconfirmed to be involved in cybercrime and their use of the public forum where\nusers share information about online advertising. It provides a first glimpse\nthat some business with cybercrime connection is being conducted in the clear.\nThe study then pans out to investigate the forum population's ties with\ncybercrime by finding crossover users, who are users from the public forum who\nalso comment on cybercrime forums. The cybercrime forums on which they discuss\nare analyzed and crossover users' strength of participation is reported. Also,\nto assess if they represent a sub-group of the forum population, their posting\nbehavior on the public forum is compared with that of non-crossover users. This\nblend of analyses shows that (i) a minimum of 7.2% of the public forum\npopulation are crossover users that have ties with cybercrime forums; (ii)\ntheir participation in cybercrime forums is limited; and (iii) their posting\nbehavior is relatively indistinguishable from that of non-crossover users. This\nis the first study to formally quantify how users of an internet marketing\npublic forum, a space for informal exchanges, have ties to cybercrime\nactivities. We conclude that crossover users are a substantial part of the\npopulation in the public forum, and, even though they have thus far been\noverlooked, their aggregated effect in the ecosystem must be considered.",
    "descriptor": "\nComments: 18 pages, 4 figures\n",
    "authors": [
      "Masarah Paquet-Clouston",
      "Serge-Olivier Paquette",
      "Sebasti\u00e1n Garc\u00eda",
      "Mar\u00eda Jos\u00e9 Erquiaga"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.01644"
  },
  {
    "id": "arXiv:2202.01645",
    "title": "AI-as-a-Service Toolkit for Human-Centered Intelligence in Autonomous  Driving",
    "abstract": "This paper presents a proof-of-concept implementation of the AI-as-a-service\ntoolkit developed within the H2020 TEACHING project and designed to implement\nan autonomous driving personalization system according to the output of an\nautomatic driver's stress recognition algorithm, both of them realizing a\nCyber-Physical System of Systems. In addition, we implemented a data-gathering\nsubsystem to collect data from different sensors, i.e., wearables and cameras,\nto automatize stress recognition. The system was attached for testing to a\ndriving emulation software, CARLA, which allows testing the approach's\nfeasibility with minimum cost and without putting at risk drivers and\npassengers. At the core of the relative subsystems, different learning\nalgorithms were implemented using Deep Neural Networks, Recurrent Neural\nNetworks, and Reinforcement Learning.",
    "descriptor": "",
    "authors": [
      "Valerio De Caro",
      "Saira Bano",
      "Achilles Machumilane",
      "Alberto Gotta",
      "Pietro Cassar\u00e1",
      "Antonio Carta",
      "Christos Sardianos",
      "Christos Chronis",
      "Iraklis Varlamis",
      "Konstantinos Tserpes",
      "Vincenzo Lomonaco",
      "Claudio Gallicchio",
      "Davide Bacciu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2202.01645"
  },
  {
    "id": "arXiv:2202.01646",
    "title": "Improving Lyrics Alignment through Joint Pitch Detection",
    "abstract": "In recent years, the accuracy of automatic lyrics alignment methods has\nincreased considerably. Yet, many current approaches employ frameworks designed\nfor automatic speech recognition (ASR) and do not exploit properties specific\nto music. Pitch is one important musical attribute of singing voice but it is\noften ignored by current systems as the lyrics content is considered\nindependent of the pitch. In practice, however, there is a temporal correlation\nbetween the two as note starts often correlate with phoneme starts. At the same\ntime the pitch is usually annotated with high temporal accuracy in ground truth\ndata while the timing of lyrics is often only available at the line (or word)\nlevel. In this paper, we propose a multi-task learning approach for lyrics\nalignment that incorporates pitch and thus can make use of a new source of\nhighly accurate temporal information. Our results show that the accuracy of the\nalignment result is indeed improved by our approach. As an additional\ncontribution, we show that integrating boundary detection in the\nforced-alignment algorithm reduces cross-line errors, which improves the\naccuracy even further.",
    "descriptor": "\nComments: To appear in Proc. ICASSP 2022\n",
    "authors": [
      "Jiawen Huang",
      "Emmanouil Benetos",
      "Sebastian Ewert"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.01646"
  },
  {
    "id": "arXiv:2202.01649",
    "title": "HECO: Automatic Code Optimizations for Efficient Fully Homomorphic  Encryption",
    "abstract": "In recent years, Fully Homomorphic Encryption (FHE) has undergone several\nbreakthroughs and advancements leading to a leap in performance. Today,\nperformance is no longer a major barrier to adoption. Instead, it is the\ncomplexity of developing an efficient FHE application that currently limits\ndeploying FHE in practice and at scale. Several FHE compilers have emerged\nrecently to ease FHE development. However, none of these answer how to\nautomatically transform imperative programs to secure and efficient FHE\nimplementations. This is a fundamental issue that needs to be addressed before\nwe can realistically expect broader use of FHE. Automating these\ntransformations is challenging because the restrictive set of operations in FHE\nand their non-intuitive performance characteristics require programs to be\ndrastically transformed to achieve efficiency. In addition, existing tools are\nmonolithic and focus on individual optimizations. Therefore, they fail to fully\naddress the needs of end-to-end FHE development. In this paper, we present\nHECO, a new end-to-end design for FHE compilers that takes high-level\nimperative programs and emits efficient and secure FHE implementations. In our\ndesign, we take a broader view of FHE development, extending the scope of\noptimizations beyond the cryptographic challenges existing tools focus on.",
    "descriptor": "",
    "authors": [
      "Alexander Viand",
      "Patrick Jattke",
      "Miro Haller",
      "Anwar Hithnawi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.01649"
  },
  {
    "id": "arXiv:2202.01651",
    "title": "A Survey of Methods for Automated Algorithm Configuration",
    "abstract": "Algorithm configuration (AC) is concerned with the automated search of the\nmost suitable parameter configuration of a parametrized algorithm. There is\ncurrently a wide variety of AC problem variants and methods proposed in the\nliterature. Existing reviews do not take into account all derivatives of the AC\nproblem, nor do they offer a complete classification scheme. To this end, we\nintroduce taxonomies to describe the AC problem and features of configuration\nmethods, respectively. We review existing AC literature within the lens of our\ntaxonomies, outline relevant design choices of configuration approaches,\ncontrast methods and problem variants against each other, and describe the\nstate of AC in industry. Finally, our review provides researchers and\npractitioners with a look at future research directions in the field of AC.",
    "descriptor": "\nComments: 52 pages, 6 figures\n",
    "authors": [
      "Elias Schede",
      "Jasmin Brandt",
      "Alexander Tornede",
      "Marcel Wever",
      "Viktor Bengs",
      "Eyke H\u00fcllermeier",
      "Kevin Tierney"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2202.01651"
  },
  {
    "id": "arXiv:2202.01653",
    "title": "Learning strides in convolutional neural networks",
    "abstract": "Convolutional neural networks typically contain several downsampling\noperators, such as strided convolutions or pooling layers, that progressively\nreduce the resolution of intermediate representations. This provides some\nshift-invariance while reducing the computational complexity of the whole\narchitecture. A critical hyperparameter of such layers is their stride: the\ninteger factor of downsampling. As strides are not differentiable, finding the\nbest configuration either requires cross-validation or discrete optimization\n(e.g. architecture search), which rapidly become prohibitive as the search\nspace grows exponentially with the number of downsampling layers. Hence,\nexploring this search space by gradient descent would allow finding better\nconfigurations at a lower computational cost. This work introduces DiffStride,\nthe first downsampling layer with learnable strides. Our layer learns the size\nof a cropping mask in the Fourier domain, that effectively performs resizing in\na differentiable way. Experiments on audio and image classification show the\ngenerality and effectiveness of our solution: we use DiffStride as a drop-in\nreplacement to standard downsampling layers and outperform them. In particular,\nwe show that introducing our layer into a ResNet-18 architecture allows keeping\nconsistent high performance on CIFAR10, CIFAR100 and ImageNet even when\ntraining starts from poor random stride configurations. Moreover, formulating\nstrides as learnable variables allows us to introduce a regularization term\nthat controls the computational complexity of the architecture. We show how\nthis regularization allows trading off accuracy for efficiency on ImageNet.",
    "descriptor": "\nComments: Spotlight at ICLR2022, open-source code available at this https URL\n",
    "authors": [
      "Rachid Riad",
      "Olivier Teboul",
      "David Grangier",
      "Neil Zeghidour"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.01653"
  },
  {
    "id": "arXiv:2202.01659",
    "title": "Enhancement of power grid monitoring based on data weighting",
    "abstract": "With their expansion, national power grid have had to work with huge sets of\ndata received from a vast number of substations and power plants. Given their\nlarge volume and variety, these data can be classified as big data. Managing\nthis massive amount of data is certainly challenging. Depending on the\napplication, parts of these data are more important for real-time network\noperation. Computing a network's observability score without assigning weights\nto different signals may not provide a complete picture of the received data's\nvalidity and thus lead to incorrect assessments of the network status.\nConsequently, signals critical to the network operation and functions of an\nenergy management system (EMS) should be assigned higher weights in\nobservability calculations. The weighted observability alongside the classic\nnon-weighted observability can serve as an indicator of each area's condition\nin comparison to that of other areas and so greatly facilitate the monitoring\nand verification of transmitted data. For calculating a weighted observability,\nthe current paper presents a method based on the Analytic Hierarchy Process\n(AHP), in which higher weights are assigned to data that are more valuable for\nand widely used by operators. The national electricity network of Iran was\nchosen for the evaluation of the proposed method's effect on data quality and\noperational risk. The results indicated that the introduced method positively\naffects the quality of received data and also corrects erroneous data in the\nnetwork.",
    "descriptor": "",
    "authors": [
      "Parisa Ataeian",
      "Abbas Rabiee",
      "Mehdi Derafshian Maram",
      "Mohsen Ghalei Monfared Zanjani"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.01659"
  },
  {
    "id": "arXiv:2202.01660",
    "title": "Computational Aspects of Conditional Minisum Approval Voting in  Elections with Interdependent Issues",
    "abstract": "Approval voting provides a simple, practical framework for multi-issue\nelections, and the most representative example among such election rules is the\nclassic Minisum approval voting rule. We consider a generalization of Minisum,\nintroduced by the work of Barrot and Lang [2016], referred to as Conditional\nMinisum, where voters are also allowed to express dependencies between issues.\nThe price we have to pay when we move to this higher level of expressiveness is\nthat we end up with a computationally hard rule. Motivated by this, we focus on\nthe computational aspects of Conditional Minisum, where progress has been\nrather scarce so far. We identify restrictions that concern the voters'\ndependencies and the value of an optimal solution, under which we provide the\nfirst multiplicative approximation algorithms for the problem. At the same\ntime, by additionally requiring certain structural properties for the union of\ndependencies cast by the whole electorate, we obtain optimal efficient\nalgorithms for well-motivated special cases. Overall, our work provides a\nbetter understanding on the complexity implications introduced by conditional\nvoting.",
    "descriptor": "\nComments: corrected version of the following IJCAI-20 publication: Evangelos Markakis and Georgios Papasotiropoulos. Computational aspects of conditional minisum approval voting in elections with interdependent issues. In Proceedings of the 22nd International Joint Conference on Artificial Intelligence (IJCAI-20), pages 304-310, 2020. (link: this https URL)\n",
    "authors": [
      "Evangelos Markakis",
      "Georgios Papasotiropoulos"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.01660"
  },
  {
    "id": "arXiv:2202.01661",
    "title": "Selection in the Presence of Implicit Bias: The Advantage of  Intersectional Constraints",
    "abstract": "In selection processes such as hiring, promotion, and college admissions,\nimplicit bias toward socially-salient attributes such as race, gender, or\nsexual orientation of candidates is known to produce persistent inequality and\nreduce aggregate utility for the decision maker. Interventions such as the\nRooney Rule and its generalizations, which require the decision maker to select\nat least a specified number of individuals from each affected group, have been\nproposed to mitigate the adverse effects of implicit bias in selection. Recent\nworks have established that such lower-bound constraints can be very effective\nin improving aggregate utility in the case when each individual belongs to at\nmost one affected group. However, in several settings, individuals may belong\nto multiple affected groups and, consequently, face more extreme implicit bias\ndue to this intersectionality. We consider independently drawn utilities and\nshow that, in the intersectional case, the aforementioned non-intersectional\nconstraints can only recover part of the total utility achievable in the\nabsence of implicit bias. On the other hand, we show that if one includes\nappropriate lower-bound constraints on the intersections, almost all the\nutility achievable in the absence of implicit bias can be recovered. Thus,\nintersectional constraints can offer a significant advantage over a\nreductionist dimension-by-dimension non-intersectional approach to reducing\ninequality.",
    "descriptor": "",
    "authors": [
      "Anay Mehrotra",
      "Bary S. R. Pradelski",
      "Nisheeth K. Vishnoi"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Theoretical Economics (econ.TH)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.01661"
  },
  {
    "id": "arXiv:2202.01665",
    "title": "On Monte Carlo Tree Search for Weighted Vertex Coloring",
    "abstract": "This work presents the first study of using the popular Monte Carlo Tree\nSearch (MCTS) method combined with dedicated heuristics for solving the\nWeighted Vertex Coloring Problem. Starting with the basic MCTS algorithm, we\ngradually introduce a number of algorithmic variants where MCTS is extended by\nvarious simulation strategies including greedy and local search heuristics. We\nconduct experiments on well-known benchmark instances to assess the value of\neach studied combination. We also provide empirical evidence to shed light on\nthe advantages and limits of each strategy.",
    "descriptor": "\nComments: 16 pages, 2 tables, 4 plots\n",
    "authors": [
      "Cyril Grelier",
      "Olivier Goudet",
      "Jin-Kao Hao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.01665"
  },
  {
    "id": "arXiv:2202.01666",
    "title": "Equality Is Not Equity: Proportional Fairness in Federated Learning",
    "abstract": "Ensuring fairness of machine learning (ML) algorithms is becoming an\nincreasingly important mission for ML service providers. This is even more\ncritical and challenging in the federated learning (FL) scenario, given a large\nnumber of diverse participating clients. Simply mandating equality across\nclients could lead to many undesirable consequences, potentially discouraging\nhigh-performing clients and resulting in sub-optimal overall performance. In\norder to achieve better equity rather than equality, in this work, we introduce\nand study proportional fairness (PF) in FL, which has a deep connection with\ngame theory. By viewing FL from a cooperative game perspective, where the\nplayers (clients) collaboratively learn a good model, we formulate PF as Nash\nbargaining solutions. Based on this concept, we propose PropFair, a novel and\neasy-to-implement algorithm for effectively finding PF solutions, and we prove\nits convergence properties. We illustrate through experiments that PropFair\nconsistently improves the worst-case and the overall performances\nsimultaneously over state-of-the-art fair FL algorithms for a wide array of\nvision and language datasets, thus achieving better equity.",
    "descriptor": "\nComments: 34 pages\n",
    "authors": [
      "Guojun Zhang",
      "Saber Malekmohammadi",
      "Xi Chen",
      "Yaoliang Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.01666"
  },
  {
    "id": "arXiv:2202.01670",
    "title": "Ranking with Confidence for Large Scale Comparison Data",
    "abstract": "In this work, we leverage a generative data model considering comparison\nnoise to develop a fast, precise, and informative ranking algorithm from\npairwise comparisons that produces a measure of confidence on each comparison.\nThe problem of ranking a large number of items from noisy and sparse pairwise\ncomparison data arises in diverse applications, like ranking players in online\ngames, document retrieval or ranking human perceptions. Although different\nalgorithms are available, we need fast, large-scale algorithms whose accuracy\ndegrades gracefully when the number of comparisons is too small. Fitting our\nproposed model entails solving a non-convex optimization problem, which we\ntightly approximate by a sum of quasi-convex functions and a regularization\nterm. Resorting to an iterative reweighted minimization and the Primal-Dual\nHybrid Gradient method, we obtain PD-Rank, achieving a Kendall tau 0.1 higher\nthan all comparing methods, even for 10\\% of wrong comparisons in simulated\ndata matching our data model, and leading in accuracy if data is generated\naccording to the Bradley-Terry model, in both cases faster by one order of\nmagnitude, in seconds. In real data, PD-Rank requires less computational time\nto achieve the same Kendall tau than active learning methods.",
    "descriptor": "\nComments: 17 pages, 10 figures\n",
    "authors": [
      "Filipa Valdeira",
      "Cl\u00e1udia Soares"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.01670"
  },
  {
    "id": "arXiv:2202.01672",
    "title": "SubOmiEmbed: Self-supervised Representation Learning of Multi-omics Data  for Cancer Type Classification",
    "abstract": "For personalized medicines, very crucial intrinsic information is present in\nhigh dimensional omics data which is difficult to capture due to the large\nnumber of molecular features and small number of available samples. Different\ntypes of omics data show various aspects of samples. Integration and analysis\nof multi-omics data give us a broad view of tumours, which can improve clinical\ndecision making. Omics data, mainly DNA methylation and gene expression\nprofiles are usually high dimensional data with a lot of molecular features. In\nrecent years, variational autoencoders (VAE) have been extensively used in\nembedding image and text data into lower dimensional latent spaces. In our\nproject, we extend the idea of using a VAE model for low dimensional latent\nspace extraction with the self-supervised learning technique of feature\nsubsetting. With VAEs, the key idea is to make the model learn meaningful\nrepresentations from different types of omics data, which could then be used\nfor downstream tasks such as cancer type classification. The main goals are to\novercome the curse of dimensionality and integrate methylation and expression\ndata to combine information about different aspects of same tissue samples, and\nhopefully extract biologically relevant features. Our extension involves\ntraining encoder and decoder to reconstruct the data from just a subset of it.\nBy doing this, we force the model to encode most important information in the\nlatent representation. We also added an identity to the subsets so that the\nmodel knows which subset is being fed into it during training and testing. We\nexperimented with our approach and found that SubOmiEmbed produces comparable\nresults to the baseline OmiEmbed with a much smaller network and by using just\na subset of the data. This work can be improved to integrate mutation-based\ngenomic data as well.",
    "descriptor": "",
    "authors": [
      "Sayed Hashim",
      "Muhammad Ali",
      "Karthik Nandakumar",
      "Mohammad Yaqub"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2202.01672"
  },
  {
    "id": "arXiv:2202.01677",
    "title": "Separating Rule Discovery and Global Solution Composition in a Learning  Classifier System",
    "abstract": "The utilization of digital agents to support crucial decision making is\nincreasing in many industrial scenarios. However, trust in suggestions made by\nthese agents is hard to achieve, though essential for profiting from their\napplication, resulting in a need for explanations for both the decision making\nprocess as well as the model itself. For many systems, such as common deep\nlearning black-box models, achieving at least some explainability requires\ncomplex post-processing, while other systems profit from being, to a reasonable\nextent, inherently interpretable. In this paper we propose an easily\ninterpretable rule-based learning system specifically designed and thus\nespecially suited for these scenarios and compare it on a set of regression\nproblems against XCSF, a prominent rule-based learning system with a long\nresearch history. One key advantage of our system is that the rules' conditions\nand which rules compose a solution to the problem are evolved separately. We\nutilise independent rule fitnesses which allows users to specifically tailor\ntheir model structure to fit the given requirements for explainability. We find\nthat the results of SupRB2's evaluation are comparable to XCSF's while allowing\neasier control of model structure and showing a substantially smaller\nsensitivity to random seeds and data splits. This increased control aids in\nsubsequently providing explanations for both the training and the final\nstructure of the model.",
    "descriptor": "",
    "authors": [
      "Michael Heider",
      "Helena Stegherr",
      "Jonathan Wurth",
      "Roman Sraj",
      "J\u00f6rg H\u00e4hner"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.01677"
  },
  {
    "id": "arXiv:2202.01678",
    "title": "Recognising the overlap graphs of subtrees of restricted trees is hard",
    "abstract": "The overlap graphs of subtrees in a tree (SOGs) generalise many other graphs\nclasses with set representation characterisations. The complexity of\nrecognising SOGs in open. The complexities of recognising many subclasses of\nSOGs are known. We consider several subclasses of SOGs by restricting the\nunderlying tree. For a fixed integer $k \\geq 3$, we consider:\n\\begin{my_itemize}\n\\item The overlap graphs of subtrees in a tree where that tree has $k$ leaves\n\\item The overlap graphs of subtrees in trees that can be derived from a\ngiven input tree by subdivision and have at least 3 leaves\n\\item The overlap and intersection graphs of paths in a tree where that tree\nhas maximum degree $k$ \\end{my_itemize}\nWe show that the recognition problems of these classes are NP-complete. For\nall other parameters we get circle graphs, well known to be polynomially\nrecognizable.",
    "descriptor": "",
    "authors": [
      "Jessica Enright",
      "Martin Pergel"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2202.01678"
  },
  {
    "id": "arXiv:2202.01679",
    "title": "Certifying Out-of-Domain Generalization for Blackbox Functions",
    "abstract": "Certifying the robustness of model performance under bounded data\ndistribution shifts has recently attracted intensive interests under the\numbrella of distributional robustness. However, existing techniques either make\nstrong assumptions on the model class and loss functions that can be certified,\nsuch as smoothness expressed via Lipschitz continuity of gradients, or require\nto solve complex optimization problems. As a result, the wider application of\nthese techniques is currently limited by its scalability and flexibility --\nthese techniques often do not scale to large-scale datasets with modern deep\nneural networks or cannot handle loss functions which may be non-smooth, such\nas the 0-1 loss. In this paper, we focus on the problem of certifying\ndistributional robustness for black box models and bounded losses, without\nother assumptions. We propose a novel certification framework given bounded\ndistance of mean and variance of two distributions. Our certification technique\nscales to ImageNet-scale datasets, complex models, and a diverse range of loss\nfunctions. We then focus on one specific application enabled by such\nscalability and flexibility, i.e., certifying out-of-domain generalization for\nlarge neural networks and loss functions such as accuracy and AUC. We\nexperimentally validate our certification method on a number of datasets,\nranging from ImageNet, where we provide the first non-vacuous certified\nout-of-domain generalization, to smaller classification tasks where we are able\nto compare with the state-of-the-art and show that our method performs\nconsiderably better.",
    "descriptor": "",
    "authors": [
      "Maurice Weber",
      "Linyi Li",
      "Boxin Wang",
      "Zhikuan Zhao",
      "Bo Li",
      "Ce Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.01679"
  },
  {
    "id": "arXiv:2202.01681",
    "title": "Domain Decomposition in space-time of 4D-VAR Data Assimilation problem:  a case study on the ROMS software",
    "abstract": "Domain Decomposition of 4D-VAR Data Assimilation (DD-4DVAR) is made up of\ndecomposition of the spate-time domain, solution of reduced forecast model and\nminimization of local 4D-VAR functionals. Relying on the existing software\nimplementation of ROMS software, we describe main components of DD-4D VAR DA\nmethod, highlighting the topics that we will should address both on the\nmathematical problem underlying ROMS and the MPI-based code implementation of\nthe ROMS-IS4DVAR formulation.",
    "descriptor": "",
    "authors": [
      "L. D'Amore",
      "R.Cacciapuoti",
      "A. Moore"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.01681"
  },
  {
    "id": "arXiv:2202.01683",
    "title": "On the properties of the exceptional set for the randomized Euler and  Runge-Kutta schemes",
    "abstract": "We show that the probability of the exceptional set decays exponentially for\na broad class of randomized algorithms approximating solutions of ODEs,\nadmitting a certain error decomposition. This class includes randomized\nexplicit and implicit Euler schemes, and the randomized two-stage Runge-Kutta\nscheme (under inexact information). We design a confidence interval for the\nexact solution of an IVP and perform numerical experiments to illustrate the\ntheoretical results.",
    "descriptor": "",
    "authors": [
      "Tomasz Bochacik"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.01683"
  },
  {
    "id": "arXiv:2202.01684",
    "title": "A Recent Survey of Event Triggered Control of Nonlinear Systems",
    "abstract": "The control systems are an essential part of every engineering system in any\nindustrial application. The basic purpose of controls is to manage the internal\noperations of the system and detect any unwanted or uncertain situation.\nFailure in any system may be caused by various reasons and need to be\nrestricted to save other components of the system. event-triggered control\nsystems manage errors and failures by identifying particular events caused by\nfailure and then mitigate the effect of that failure as much as possible. These\nsystems have become prominent due to their smooth and autonomous way of\ndetecting and minimizing risk in any system. The input to state stability\nproperty and a perfectly stabilized control are assumed for applying\nevent-triggered control systems. Switching topologies can be utilized as an\nalternative to ISS assumptions to design triggering events. There are some\nissues related to this approach like non-linearity of systems, multi-agent\ncommunication, heterogeneity and Zeno effect in systems while monitoring,\ncontrolling faults and taking feedbacks. The efficiency of neural networks and\nfuzzy technologies are considered in this regard which are investigated by many\nresearchers in the last decade. This survey reviews all work related to\nevent-triggered control systems, their applications, challenges and possible\nsolutions. The adaptability of these controls is evaluated based on the\nsolutions available as well as the applicability of solutions proposed by\nresearchers.",
    "descriptor": "",
    "authors": [
      "Raffay Yaqoob"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.01684"
  },
  {
    "id": "arXiv:2202.01690",
    "title": "Machine Learning and Artificial Intelligence in Next-Generation Wireless  Network",
    "abstract": "Due to the advancement in technologies, the next-generation wireless network\nwill be very diverse, complicated, and according to the changed demands of the\nconsumers. The current network operator methodologies and approaches are\ntraditional and cannot help the next generation networks to utilize their\nresources most appropriately. The limited capability of the traditional tools\nwill not allow the network providers to fulfill the demands of the network's\nsubscribers in the future. Therefore, this paper will focus on machine\nlearning, automation, artificial intelligence, and big data analytics for\nimproving the capacity and effectiveness of next-generation wireless networks.\nThe paper will discuss the role of these new technologies in improving the\nservice and performance of the network providers in the future. The paper will\nfind out that machine learning, big data analytics, and artificial intelligence\nwill help in making the next-generation wireless network self-adaptive,\nself-aware, prescriptive, and proactive. At the end of the paper, it will be\nprovided that future wireless network operators cannot work without shifting\ntheir operational framework to AI and machine learning technologies.",
    "descriptor": "",
    "authors": [
      "Wafeeq Iqbal",
      "Wei Wang",
      "Ting Zhu"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.01690"
  },
  {
    "id": "arXiv:2202.01691",
    "title": "Modeling Bounded Rationality in Multi-Agent Simulations Using Rationally  Inattentive Reinforcement Learning",
    "abstract": "Multi-agent reinforcement learning (MARL) is a powerful framework for\nstudying emergent behavior in complex agent-based simulations. However, RL\nagents are often assumed to be rational and behave optimally, which does not\nfully reflect human behavior. Here, we study more human-like RL agents which\nincorporate an established model of human-irrationality, the Rational\nInattention (RI) model. RI models the cost of cognitive information processing\nusing mutual information. Our RIRL framework generalizes and is more flexible\nthan prior work by allowing for multi-timestep dynamics and information\nchannels with heterogeneous processing costs. We evaluate RIRL in\nPrincipal-Agent (specifically manager-employee relations) problem settings of\nvarying complexity where RI models information asymmetry (e.g. it may be costly\nfor the manager to observe certain information about the employees). We show\nthat using RIRL yields a rich spectrum of new equilibrium behaviors that differ\nfrom those found under rational assumptions. For instance, some forms of a\nPrincipal's inattention can increase Agent welfare due to increased\ncompensation, while other forms of inattention can decrease Agent welfare by\nencouraging extra work effort. Additionally, new strategies emerge compared to\nthose under rationality assumptions, e.g., Agents are incentivized to increase\nwork effort. These results suggest RIRL is a powerful tool towards building AI\nagents that can mimic real human behavior.",
    "descriptor": "\nComments: 16 pages, 7 figures, including appendix\n",
    "authors": [
      "Tong Mu",
      "Stephan Zheng",
      "Alexander Trott"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.01691"
  },
  {
    "id": "arXiv:2202.01692",
    "title": "Review on the stabilization of non linear systems achieved by output  feedback control technique",
    "abstract": "Stability and control of a non-linear system represent an important system\nconfiguration that frequently arises in practical engineering. Stability covers\na vast range of systems that do not obey the superposition principle and\napplies to more real-world systems because all real control systems are\nnon-linear. For efficient stabilization of these systems, a great number of\nresearches have been proposed. This paper surveys some well-known facts as well\nas some recent developments and different strategies for the topic of\nstabilization of non-linear systems by output feedback control techniques.",
    "descriptor": "",
    "authors": [
      "Asifa Yousaf"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.01692"
  },
  {
    "id": "arXiv:2202.01694",
    "title": "Variational Nearest Neighbor Gaussian Processes",
    "abstract": "Variational approximations to Gaussian processes (GPs) typically use a small\nset of inducing points to form a low-rank approximation to the covariance\nmatrix. In this work, we instead exploit a sparse approximation of the\nprecision matrix. We propose variational nearest neighbor Gaussian process\n(VNNGP), which introduces a prior that only retains correlations within K\nnearest-neighboring observations, thereby inducing sparse precision structure.\nUsing the variational framework, VNNGP's objective can be factorized over both\nobservations and inducing points, enabling stochastic optimization with a time\ncomplexity of O($K^3$). Hence, we can arbitrarily scale the inducing point\nsize, even to the point of putting inducing points at every observed location.\nWe compare VNNGP to other scalable GPs through various experiments, and\ndemonstrate that VNNGP (1) can dramatically outperform low-rank methods, and\n(2) is less prone to overfitting than other nearest neighbor methods.",
    "descriptor": "",
    "authors": [
      "Luhuan Wu",
      "Geoff Pleiss",
      "John Cunningham"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.01694"
  },
  {
    "id": "arXiv:2202.01696",
    "title": "QoS-SLA-Aware Artificial Intelligence Adaptive Genetic Algorithm for  Multi-Request Offloading in Integrated Edge-Cloud Computing System for the  Internet of Vehicles",
    "abstract": "Internet of Vehicles (IoV) over Vehicular Ad-hoc Networks (VANETS) is an\nemerging technology enabling the development of smart cities applications for\nsafer, efficient, and pleasant travel. These applications have stringent\nrequirements expressed in Service Level Agreements (SLAs). Considering vehicles\nlimited computational and storage capabilities, applications requests are\noffloaded into an integrated edge-cloud computing system. Existing offloading\nsolutions focus on optimizing applications Quality of Service (QoS) while\nrespecting a single SLA constraint. They do not consider the impact of\noverlapped requests processing. Very few contemplate the varying speed of a\nvehicle. This paper proposes a novel Artificial Intelligence (AI) QoS-SLA-aware\ngenetic algorithm (GA) for multi-request offloading in a heterogeneous\nedge-cloud computing system, considering the impact of overlapping requests\nprocessing and dynamic vehicle speed. The objective of the optimization\nalgorithm is to improve the applications' Quality of Service (QoS) by\nminimizing the total execution time. The proposed algorithm integrates an\nadaptive penalty function to assimilate the SLAs constraints in terms of\nlatency, processing time, deadline, CPU, and memory requirements. Numerical\nexperiments and comparative analysis are achieved between our proposed\nQoS-SLA-aware GA, random, and GA baseline approaches. The results show that the\nproposed algorithm executes the requests 1.22 times faster on average compared\nto the random approach with 59.9% less SLA violations. While the GA baseline\napproach increases the performance of the requests by 1.14 times, it has 19.8%\nmore SLA violations than our approach.",
    "descriptor": "",
    "authors": [
      "Leila Ismail",
      "Huned Materwala",
      "Hossam S. Hassanein"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Performance (cs.PF)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.01696"
  },
  {
    "id": "arXiv:2202.01698",
    "title": "Understanding the Role of Context in Creating Enjoyable Co-Located  Interactions",
    "abstract": "In recent years, public discourse has blamed digital technologies for making\npeople feel \"alone together,\" distracting us from engaging with one another,\neven when we are interacting in-person. We argue that in order to design\ntechnologies that foster and augment co-located interactions, we need to first\nunderstand the context in which enjoyable co-located socialization takes place.\nWe address this gap by surveying and interviewing over 1,000 U.S.-based\nparticipants to understand what, where, with whom, how, and why people enjoy\nspending time in-person. Our findings suggest that people enjoy engaging in\neveryday activities with individuals with whom they have strong social ties\nbecause it helps enable nonverbal cues, facilitate spontaneity, support\nauthenticity, encourage undivided attention, and leverage the physicality of\ntheir bodies and the environment. We conclude by providing a set of\nrecommendations for designers interested in creating co-located technologies\nthat encourage social engagement and relationship building.",
    "descriptor": "\nComments: 26 pages, 3 figures, 2 tables\n",
    "authors": [
      "Szu-Yu",
      "Brian A. Smith",
      "Rajan Vaish",
      "Andr\u00e9s Monroy-Hern\u00e1ndez"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2202.01698"
  },
  {
    "id": "arXiv:2202.01699",
    "title": "DISC: A Plug-and-Play Compression Method for CNN Partition-Offloading",
    "abstract": "Partitioning CNN model computation between edge devices and servers has been\nproposed to alleviate edge devices' computing capability and network\ntransmission limitations. However, due to the large data size of the\nintermediate output in CNN models, the transmission latency is still the\nbottleneck for such partition-offloading. Though compression methods on images\nlike JPEG-based compression can be applied to the intermediate output data in\nCNN models, their compression rates are limited, and the compression leads to\nhigh accuracy loss. Other compression methods for partition-offloading adopt\ndeep learning technology and require hours of additional training. In this\npaper, we propose a novel compression method DISC for intermediate output data\nin CNN models. DISC can be applied to partition-offloading systems in a\nplug-and-play way without any additional training. It shows higher performance\non intermediate output data compression than the other compression methods\ndesigned for image compression. Further, AGLOP is developed to optimize the\npartition-offloading system by adjusting the partition point and the\nhyper-parameters of DISC. Based on our evaluation, DISC can achieve over 98%\ndata size reduction with less than $1\\%$ accuracy loss, and AGLOP can achieve\nover 91.2% end-to-end execution latency reduction compared with the original\npartition-offloading.",
    "descriptor": "",
    "authors": [
      "Xueyu Hou",
      "Yongjie Guan",
      "Tao Han",
      "Ning Zhang"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2202.01699"
  },
  {
    "id": "arXiv:2202.01708",
    "title": "The relationship between sentiment score and COVID-19 cases in the  United States",
    "abstract": "The coronavirus disease (COVID-19) continues to have devastating effects\nacross the globe. No nation has been free from the uncertainty brought by this\npandemic. The health, social and economic tolls associated with it are causing\nstrong emotions and spreading fear in people of all ages, genders, and races.\nSince the beginning of the COVID-19 pandemic, many have expressed their\nfeelings and opinions related to a wide range of aspects of their lives via\nTwitter. In this study, we consider a framework for extracting sentiment scores\nand opinions from COVID-19 related tweets. We connect users' sentiment with\nCOVID-19 cases across the USA and investigate the effect of specific COVID-19\nmilestones on public sentiment. The results of this work may help with the\ndevelopment of pandemic-related legislation, serve as a guide for scientific\nwork, as well as inform and educate the public on core issues related to the\npandemic.",
    "descriptor": "\nComments: 26 pages, 11 figures. Journal Information Science, 2022\n",
    "authors": [
      "Truong Luu",
      "Rosangela Follmann"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Computation and Language (cs.CL)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2202.01708"
  },
  {
    "id": "arXiv:2202.01709",
    "title": "Towards Coherent and Consistent Use of Entities in Narrative Generation",
    "abstract": "Large pre-trained language models (LMs) have demonstrated impressive\ncapabilities in generating long, fluent text; however, there is little to no\nanalysis on their ability to maintain entity coherence and consistency. In this\nwork, we focus on the end task of narrative generation and systematically\nanalyse the long-range entity coherence and consistency in generated stories.\nFirst, we propose a set of automatic metrics for measuring model performance in\nterms of entity usage. Given these metrics, we quantify the limitations of\ncurrent LMs. Next, we propose augmenting a pre-trained LM with a dynamic entity\nmemory in an end-to-end manner by using an auxiliary entity-related loss for\nguiding the reads and writes to the memory. We demonstrate that the dynamic\nentity memory increases entity coherence according to both automatic and human\njudgment and helps preserving entity-related information especially in settings\nwith a limited context window. Finally, we also validate that our automatic\nmetrics are correlated with human ratings and serve as a good indicator of the\nquality of generated stories.",
    "descriptor": "",
    "authors": [
      "Pinelopi Papalampidi",
      "Kris Cao",
      "Tomas Kocisky"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.01709"
  },
  {
    "id": "arXiv:2202.01710",
    "title": "Multi-Output Physics-Informed Neural Networks for Forward and Inverse  PDE Problems with Uncertainties",
    "abstract": "Physics-informed neural networks (PINNs) have recently been used to solve\nvarious computational problems which are governed by partial differential\nequations (PDEs). In this paper, we propose a multi-output physics-informed\nneural network (MO-PINN) which can provide solutions with uncertainty\ndistributions for both forward and inverse PDE problems with noisy data. In\nthis framework, the uncertainty arising from the noisy data is first translated\ninto multiple measurements regarding the prior noise distribution using the\nbootstrap method, and then the outputs of neural networks are designed to\nsatisfy the measurements as well as the underlying physical laws.The posterior\nestimation of target parameters can be obtained at the end of training, which\ncan be further used for uncertainty quantification and decision making. In this\npaper, MO-PINNs are demonstrated with a series of numerical experiments\nincluding both linear and nonlinear, forward and inverse problems. The results\nshow that MO-PINN is able to provide accurate predictions with noisy data.In\naddition, we also demonstrate that the prediction and posterior distributions\nfrom MO-PINNs are consistent with the solutions from traditional a finite\nelement method (FEM) solver and Monte Carlo methods given the same data and\nprior knowledge. Finally, we show that additional statistical knowledge can be\nincorporated into the training to improve the prediction if available.",
    "descriptor": "",
    "authors": [
      "Mingyuan Yang",
      "John T. Foster"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2202.01710"
  },
  {
    "id": "arXiv:2202.01711",
    "title": "Algorithmic Fairness Datasets: the Story so Far",
    "abstract": "Data-driven algorithms are being studied and deployed in diverse domains to\nsupport critical decisions, directly impacting on people's well-being. As a\nresult, a growing community of algorithmic fairness researchers has been\ninvestigating the equity of existing algorithms and proposing novel ones,\nadvancing the understanding of the risks and opportunities of automated\ndecision-making for different populations. Algorithmic fairness progress hinges\non data, which can be used appropriately only if adequately documented.\nUnfortunately, the algorithmic fairness community, as a whole, suffers from a\ncollective data documentation debt caused by a lack of information on specific\nresources (opacity) and scatteredness of available information (sparsity). In\nthis work, we survey over two hundred datasets employed in algorithmic fairness\nresearch, producing standardized and searchable documentation for each of them,\nalong with in-depth documentation for the three most popular fairness datasets,\nnamely Adult, COMPAS and German Credit. These documentation efforts support\nmultiple contributions. Firstly, we summarize the merits and limitations of\npopular algorithmic fairness datasets, questioning their suitability as\ngeneral-purpose fairness benchmarks. Secondly, we document hundreds of\navailable alternatives, annotating their domain and supported fairness tasks,\nto assist dataset users in task-oriented and domain-oriented search. Finally,\nwe analyze these resources from the perspective of five important data curation\ntopics: anonymization, consent, inclusivity, labeling of sensitive attributes,\nand transparency. We discuss different approaches and levels of attention to\nthese topics, making them tangible, and distill them into a set of best\npractices for the curation of novel datasets.",
    "descriptor": "",
    "authors": [
      "Alessandro Fabris",
      "Stefano Messina",
      "Gianmaria Silvello",
      "Gian Antonio Susto"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2202.01711"
  },
  {
    "id": "arXiv:2202.01712",
    "title": "Review of automated time series forecasting pipelines",
    "abstract": "Time series forecasting is fundamental for various use cases in different\ndomains such as energy systems and economics. Creating a forecasting model for\na specific use case requires an iterative and complex design process. The\ntypical design process includes the five sections (1) data pre-processing, (2)\nfeature engineering, (3) hyperparameter optimization, (4) forecasting method\nselection, and (5) forecast ensembling, which are commonly organized in a\npipeline structure. One promising approach to handle the ever-growing demand\nfor time series forecasts is automating this design process. The present paper,\nthus, analyzes the existing literature on automated time series forecasting\npipelines to investigate how to automate the design process of forecasting\nmodels. Thereby, we consider both Automated Machine Learning (AutoML) and\nautomated statistical forecasting methods in a single forecasting pipeline. For\nthis purpose, we firstly present and compare the proposed automation methods\nfor each pipeline section. Secondly, we analyze the automation methods\nregarding their interaction, combination, and coverage of the five pipeline\nsections. For both, we discuss the literature, identify problems, give\nrecommendations, and suggest future research. This review reveals that the\nmajority of papers only cover two or three of the five pipeline sections. We\nconclude that future research has to holistically consider the automation of\nthe forecasting pipeline to enable the large-scale application of time series\nforecasting.",
    "descriptor": "",
    "authors": [
      "Stefan Meisenbacher",
      "Marian Turowski",
      "Kaleb Phipps",
      "Martin R\u00e4tz",
      "Dirk M\u00fcller",
      "Veit Hagenmeyer",
      "Ralf Mikut"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.01712"
  },
  {
    "id": "arXiv:2202.01713",
    "title": "Developer Load Normalization Using Iterative Kuhn-Munkres Algorithm: An  Optimization Triaging Approach",
    "abstract": "Bug triage can be defined as the process of assigning a developer to a bug\nreport. The duty of the bug triage team is to study the developers profiles\nwell in order to make an appropriate match between the developers and the\nincoming bug reports. Thus, this process is a vital step in issue management\nsystem. In fact, the number of bug reports submitted every day is gradually\nincreasing which affects the developer workload. Thus, the triage team should\nconsider this factor in distributing the bugs and because of the manual\napproach, many developers are burden. In particular, triaging bug reports\nwithout considering the workload does not only affect the developers workload\nbut also leads to an increase in the number of unaddressed bug reports. As a\nresult, the fixing time of the reported bugs will relatively increase. Unlike\nother researchers who focus on automating the bug triage and ignoring the\ndeveloper workload, in this work, we handle the triaging process from a\ndifferent perspective. The proposed approach focuses on how to optimize the bug\nfixing time by normalizing the developer load in an automating system. To\nevaluate our work, we use 26,317 bug reports from different bug repositories.\nResults shows that our work outperforms other systems in terms of optimizing\nthe bug total fixing time and normalizing developer load.",
    "descriptor": "\nComments: 10 Pages, 8 Figures\n",
    "authors": [
      "Madonna Mayez",
      "Khaled Nagaty",
      "Abeer Hamdy"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2202.01713"
  },
  {
    "id": "arXiv:2202.01716",
    "title": "Multivariate Algorithmics for Eliminating Envy by Donating Goods",
    "abstract": "Fairly dividing a set of indivisible resources to a set of agents is of\nutmost importance in some applications. However, after an allocation has been\nimplemented the preferences of agents might change and envy might arise. We\nstudy the following problem to cope with such situations: Given an allocation\nof indivisible resources to agents with additive utility-based preferences, is\nit possible to socially donate some of the resources (which means removing\nthese resources from the allocation instance) such that the resulting modified\nallocation is envy-free (up to one good). We require that the number of deleted\nresources and/or the caused utilitarian welfare loss of the allocation are\nbounded. We conduct a thorough study of the (parameterized) computational\ncomplexity of this problem considering various natural and problem-specific\nparameters (e.g., the number of agents, the number of deleted resources, or the\nmaximum number of resources assigned to an agent in the initial allocation) and\ndifferent preference models, including unary and 0/1-valuations. In our\nstudies, we obtain a rich set of (parameterized) tractability and\nintractability results and discover several surprising contrasts, for instance,\nbetween the two closely related fairness concepts envy-freeness and\nenvy-freeness up to one good and between the influence of the parameters\nmaximum number and welfare of the deleted resources.",
    "descriptor": "\nComments: Accepted to AAMAS'22\n",
    "authors": [
      "Niclas Boehmer",
      "Robert Bredereck",
      "Klaus Heeger",
      "Du\u0161an Knop",
      "Junjie Luo"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2202.01716"
  },
  {
    "id": "arXiv:2202.01717",
    "title": "A User-Friendly Environment for Battery Data Science",
    "abstract": "We report a user-friendly software environment for battery data science. It\nis designed to streamline data management, data cleaning, and data analysis to\nhelp bridge the gap between the domain expertise of most battery scientists and\nthe tools needed as the field becomes increasingly data intensive. The software\nsolution suitable for ingesting battery test data from disparate sources. By\naggregating data in an intelligent way, users can streamline routine data\nanalysis tasks and leverage Jupyter Notebook functionality to build advanced\nscripts and analytics, thereby making battery engineering teams more\nproductive.",
    "descriptor": "",
    "authors": [
      "Robert Masse",
      "Dan Ulery",
      "Hardik Kamdar"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.01717"
  },
  {
    "id": "arXiv:2202.01718",
    "title": "MV-Datalog+-: Effective Rule-based Reasoning with Uncertain Observations",
    "abstract": "Modern applications combine information from a great variety of sources.\nOftentimes, some of these sources, like Machine-Learning systems, are not\nstrictly binary but associated with some degree of (lack of) confidence in the\nobservation. We propose MV-Datalog and MV-Datalog+- as extensions of Datalog\nand Datalog+-, respectively, to the fuzzy semantics of infinite-valued\nLukasiewicz logic L as languages for effectively reasoning in scenarios where\nsuch uncertain observations occur. We show that the semantics of MV-Datalog\nexhibits similar model-theoretic properties as Datalog. in particular, we show\nthat (fuzzy) entailment can be defined in terms of an analogue of minimal\nmodels and give a characterisation, and proof of the uniqueness of such minimal\nmodels. On the basis of this characterisation, we propose similar many-valued\nsemantics for rules with existential quantification in the head, extending\nDatalog+-.",
    "descriptor": "\nComments: Submitted to ICLP 2022\n",
    "authors": [
      "Matthias Lanzinger",
      "Stefano Sferrazza",
      "Georg Gottlob"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2202.01718"
  },
  {
    "id": "arXiv:2202.01719",
    "title": "FORML: Learning to Reweight Data for Fairness",
    "abstract": "Deployed machine learning models are evaluated by multiple metrics beyond\naccuracy, such as fairness and robustness. However, such models are typically\ntrained to minimize the average loss for a single metric, which is typically a\nproxy for accuracy. Training to optimize a single metric leaves these models\nprone to fairness violations, especially when the population of sub-groups in\nthe training data are imbalanced. This work addresses the challenge of jointly\noptimizing fairness and predictive performance in the multi-class\nclassification setting by introducing Fairness Optimized Reweighting via\nMeta-Learning (FORML), a training algorithm that balances fairness constraints\nand accuracy by jointly optimizing training sample weights and a neural\nnetwork's parameters. The approach increases fairness by learning to weight\neach training datum's contribution to the loss according to its impact on\nreducing fairness violations, balancing the contributions from both over- and\nunder-represented sub-groups. We empirically validate FORML on a range of\nbenchmark and real-world classification datasets and show that our approach\nimproves equality of opportunity fairness criteria over existing\nstate-of-the-art reweighting methods by approximately 1% on image\nclassification tasks and by approximately 5% on a face attribute prediction\ntask. This improvement is achieved without pre-processing data or\npost-processing model outputs, without learning an additional weighting\nfunction, and while maintaining accuracy on the original predictive metric.",
    "descriptor": "\nComments: 21 pages, 3 figures, Under Review\n",
    "authors": [
      "Bobby Yan",
      "Skyler Seto",
      "Nicholas Apostoloff"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.01719"
  },
  {
    "id": "arXiv:2202.01721",
    "title": "Variance-Optimal Augmentation Logging for Counterfactual Evaluation in  Contextual Bandits",
    "abstract": "Methods for offline A/B testing and counterfactual learning are seeing rapid\nadoption in search and recommender systems, since they allow efficient reuse of\nexisting log data. However, there are fundamental limits to using existing log\ndata alone, since the counterfactual estimators that are commonly used in these\nmethods can have large bias and large variance when the logging policy is very\ndifferent from the target policy being evaluated. To overcome this limitation,\nwe explore the question of how to design data-gathering policies that most\neffectively augment an existing dataset of bandit feedback with additional\nobservations for both learning and evaluation. To this effect, this paper\nintroduces Minimum Variance Augmentation Logging (MVAL), a method for\nconstructing logging policies that minimize the variance of the downstream\nevaluation or learning problem. We explore multiple approaches to computing\nMVAL policies efficiently, and find that they can be substantially more\neffective in decreasing the variance of an estimator than na\\\"ive approaches.",
    "descriptor": "\nComments: 19 pages, 4 figures, in submission\n",
    "authors": [
      "Aaron David Tucker",
      "Thorsten Joachims"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2202.01721"
  },
  {
    "id": "arXiv:2202.01724",
    "title": "Seeded Database Matching Under Noisy Column Repetitions",
    "abstract": "The re-identification or de-anonymization of users from anonymized data\nthrough matching with publicly-available correlated user data has raised\nprivacy concerns, leading to the complementary measure of obfuscation in\naddition to anonymization. Recent research provides a fundamental understanding\nof the conditions under which privacy attacks are successful, either in the\npresence of obfuscation or synchronization errors stemming from the sampling of\ntime-indexed databases. This paper presents a unified framework considering\nboth obfuscation and synchronization errors and investigates the matching of\ndatabases under noisy column repetitions. By devising replica detection and\nseeded deletion detection algorithms, and using information-theoretic tools,\nsufficient conditions for successful matching are derived. It is shown that a\nseed size logarithmic in the row size is enough to guarantee the detection of\nall deleted columns. It is also proved that this sufficient condition is\nnecessary, thus characterizing the database matching capacity of database\nmatching under noisy column repetitions.",
    "descriptor": "",
    "authors": [
      "Serhat Bakirtas",
      "Elza Erkip"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.01724"
  },
  {
    "id": "arXiv:2202.01725",
    "title": "RipsNet: a general architecture for fast and robust estimation of the  persistent homology of point clouds",
    "abstract": "The use of topological descriptors in modern machine learning applications,\nsuch as Persistence Diagrams (PDs) arising from Topological Data Analysis\n(TDA), has shown great potential in various domains. However, their practical\nuse in applications is often hindered by two major limitations: the\ncomputational complexity required to compute such descriptors exactly, and\ntheir sensitivity to even low-level proportions of outliers. In this work, we\npropose to bypass these two burdens in a data-driven setting by entrusting the\nestimation of (vectorization of) PDs built on top of point clouds to a neural\nnetwork architecture that we call RipsNet. Once trained on a given data set,\nRipsNet can estimate topological descriptors on test data very efficiently with\ngeneralization capacity. Furthermore, we prove that RipsNet is robust to input\nperturbations in terms of the 1-Wasserstein distance, a major improvement over\nthe standard computation of PDs that only enjoys Hausdorff stability, yielding\nRipsNet to substantially outperform exactly-computed PDs in noisy settings. We\nshowcase the use of RipsNet on both synthetic and real-world data. Our\nopen-source implementation is publicly available at\nhttps://github.com/hensel-f/ripsnet and will be included in the Gudhi library.",
    "descriptor": "\nComments: 23 pages, 4 figures\n",
    "authors": [
      "Thibault de Surrel",
      "Felix Hensel",
      "Mathieu Carri\u00e8re",
      "Th\u00e9o Lacombe",
      "Yuichi Ike",
      "Hiroaki Kurihara",
      "Marc Glisse",
      "Fr\u00e9d\u00e9ric Chazal"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.01725"
  },
  {
    "id": "arXiv:2202.01727",
    "title": "Skeleton-Based Action Segmentation with Multi-Stage Spatial-Temporal  Graph Convolutional Neural Networks",
    "abstract": "The ability to identify and temporally segment fine-grained actions in motion\ncapture sequences is crucial for applications in human movement analysis.\nMotion capture is typically performed with optical or inertial measurement\nsystems, which encode human movement as a time series of human joint locations\nand orientations or their higher-order representations. State-of-the-art action\nsegmentation approaches use multiple stages of temporal convolutions. The main\nidea is to generate an initial prediction with several layers of temporal\nconvolutions and refine these predictions over multiple stages, also with\ntemporal convolutions. Although these approaches capture long-term temporal\npatterns, the initial predictions do not adequately consider the spatial\nhierarchy among the human joints. To address this limitation, we present\nmulti-stage spatial-temporal graph convolutional neural networks (MS-GCN). Our\nframework decouples the architecture of the initial prediction generation stage\nfrom the refinement stages. Specifically, we replace the initial stage of\ntemporal convolutions with spatial-temporal graph convolutions, which better\nexploit the spatial configuration of the joints and their temporal dynamics.\nOur framework was compared to four strong baselines on five tasks. Experimental\nresults demonstrate that our framework achieves state-of-the-art performance.",
    "descriptor": "",
    "authors": [
      "Benjamin Filtjens",
      "Bart Vanrumste",
      "Peter Slaets"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.01727"
  },
  {
    "id": "arXiv:2202.01729",
    "title": "Can machines solve general queueing systems?",
    "abstract": "In this paper, we analyze how well a machine can solve a general problem in\nqueueing theory. To answer this question, we use a deep learning model to\npredict the stationary queue-length distribution of an $M/G/1$ queue (Poisson\narrivals, general service times, one server). To the best of our knowledge,\nthis is the first time a machine learning model is applied to a general\nqueueing theory problem. We chose $M/G/1$ queue for this paper because it lies\n\"on the cusp\" of the analytical frontier: on the one hand exact solution for\nthis model is available, which is both computationally and mathematically\ncomplex. On the other hand, the problem (specifically the service time\ndistribution) is general. This allows us to compare the accuracy and efficiency\nof the deep learning approach to the analytical solutions.\nThe two key challenges in applying machine learning to this problem are (1)\ngenerating a diverse set of training examples that provide a good\nrepresentation of a \"generic\" positive-valued distribution, and (2)\nrepresentations of the continuous distribution of service times as an input. We\nshow how we overcome these challenges.\nOur results show that our model is indeed able to predict the stationary\nbehavior of the $M/G/1$ queue extremely accurately: the average value of our\nmetric over the entire test set is $0.0009$. Moreover, our machine learning\nmodel is very efficient, computing very accurate stationary distributions in a\nfraction of a second (an approach based on simulation modeling would take much\nlonger to converge). We also present a case-study that mimics a real-life\nsetting and shows that our approach is more robust and provides more accurate\nsolutions compared to the existing methods. This shows the promise of extending\nour approach beyond the analytically solvable systems (e.g., $G/G/1$ or\n$G/G/c$).",
    "descriptor": "",
    "authors": [
      "Eliran Sherzer",
      "Arik Senderovich",
      "Opher Baron",
      "Dmitry Krass"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.01729"
  },
  {
    "id": "arXiv:2202.01730",
    "title": "Database Matching Under Column Repetitions",
    "abstract": "Motivated by synchronization errors in the sampling of time-indexed\ndatabases, matching of random databases under random column repetitions\n(including deletions) is investigated. Column histograms are used as a\npermutation-invariant feature to detect the repetition pattern, whose\nasymptotic-uniqueness is proved using information-theoretic tools. Repetition\ndetection is followed by a row matching scheme. Considering this overall\nscheme, sufficient conditions for successful database matching in terms of the\ndatabase growth rate are derived. A modified version of Fano's inequality leads\nto a tight necessary condition for successful matching, establishing the\nmatching capacity under column repetitions. This capacity is equal to the\nerasure bound, which assumes the repetition locations are known a-priori.",
    "descriptor": "",
    "authors": [
      "Serhat Bakirtas",
      "Elza Erkip"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.01730"
  },
  {
    "id": "arXiv:2202.01736",
    "title": "WatchAuth: User Authentication and Intent Recognition in Mobile Payments  using a Smartwatch",
    "abstract": "In this paper, we show that the tap gesture, performed when a user 'taps' a\nsmartwatch onto an NFC-enabled terminal to make a payment, is a biometric\ncapable of implicitly authenticating the user and simultaneously recognising\nintent-to-pay. The proposed system can be deployed purely in software on the\nwatch without requiring updates to payment terminals. It is agnostic to\nterminal type and position and the intent recognition portion does not require\nany training data from the user. To validate the system, we conduct a user\nstudy (n=16) to collect wrist motion data from users as they interact with\npayment terminals and to collect long-term data from a subset of them (n=9) as\nthey perform daily activities. Based on this data, we identify optimum gesture\nparameters and develop authentication and intent recognition models, for which\nwe achieve EERs of 0.08 and 0.04, respectively.",
    "descriptor": "",
    "authors": [
      "Jack Sturgess",
      "Simon Eberz",
      "Ivo Sluganovic",
      "Ivan Martinovic"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.01736"
  },
  {
    "id": "arXiv:2202.01740",
    "title": "Technological Factors Influencing Videoconferencing and Zoom Fatigue",
    "abstract": "The paper presents a conceptual, multidimensional approach to understand the\ntechnological factors that are assumed to or even have been proven to\ncontribute to what has been coined as Zoom Fatigue (ZF) or more generally\nVideoconferencing Fatigue (VCF). With the advent of the Covid-19 pandemic, the\nusage of VC services has drastically increased, leading to more and more\nreports about the ZF or VCF phenomenon. The paper is motivated by the fact that\nsome of the media outlets initially starting the debate on what Zoom fatigue is\nand how it can be avoided, as well as some of the scientific papers addressing\nthe topic, contain assumptions that are rather hypothetical and insufficiently\nunderpinned by scientific evidence. Most of these works are acknowledge the\nlacking evidence and partly suggest directions for future research. This paper\nintends to deepen the survey of VC-technology-related literature and to provide\nmore existing evidence, where possible, while reviewing some of the already\nprovided support or evidence for certain causal hypotheses. The technological\nfactors dimension and its identified sub-dimensions presented in this paper are\nembedded within a more holistic four-dimensional conceptual factors model\ndescribing the causes for ZF or VCF. The paper describing this overall\nconceptual model is written by the same group of authors and currently under\nrevision for an Open Access Journal publication. The present paper expands on\nthe technological factors dimension descriptions provided in the overall model\npaper and provides more detailed analyzes and concepts associated with how VC\ntechnology may affect users' perception, cognitive load, interaction and\ncommunication, possibly leading to stress, exhaustion and fatigue. The paper\ncurrently is a living document which will be expanded further with regard to\nthe evidence for or against the impact of certain technological factors.",
    "descriptor": "\nComments: 15 pages\n",
    "authors": [
      "Alexander Raake",
      "Markus Fiedler",
      "Katrin Schoenenberg",
      "Katrien De Moor",
      "Nicola D\u00f6ring"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computers and Society (cs.CY)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2202.01740"
  },
  {
    "id": "arXiv:2202.01741",
    "title": "How to Leverage Unlabeled Data in Offline Reinforcement Learning",
    "abstract": "Offline reinforcement learning (RL) can learn control policies from static\ndatasets but, like standard RL methods, it requires reward annotations for\nevery transition. In many cases, labeling large datasets with rewards may be\ncostly, especially if those rewards must be provided by human labelers, while\ncollecting diverse unlabeled data might be comparatively inexpensive. How can\nwe best leverage such unlabeled data in offline RL? One natural solution is to\nlearn a reward function from the labeled data and use it to label the unlabeled\ndata. In this paper, we find that, perhaps surprisingly, a much simpler method\nthat simply applies zero rewards to unlabeled data leads to effective data\nsharing both in theory and in practice, without learning any reward model at\nall. While this approach might seem strange (and incorrect) at first, we\nprovide extensive theoretical and empirical analysis that illustrates how it\ntrades off reward bias, sample complexity and distributional shift, often\nleading to good results. We characterize conditions under which this simple\nstrategy is effective, and further show that extending it with a simple\nreweighting approach can further alleviate the bias introduced by using\nincorrect reward labels. Our empirical evaluation confirms these findings in\nsimulated robotic locomotion, navigation, and manipulation settings.",
    "descriptor": "",
    "authors": [
      "Tianhe Yu",
      "Aviral Kumar",
      "Yevgen Chebotar",
      "Karol Hausman",
      "Chelsea Finn",
      "Sergey Levine"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.01741"
  },
  {
    "id": "arXiv:2202.01746",
    "title": "Pivot Gray Codes for the Spanning Trees of a Graph ft. the Fan",
    "abstract": "We consider the problem of listing all spanning trees of a graph $G$ such\nthat successive trees differ by pivoting a single edge around a vertex. Such a\nlisting is called a \"pivot Gray code\", and it has more stringent conditions\nthan known \"revolving-door\" Gray codes for spanning trees. Most revolving-door\nalgorithms employ a standard edge-deletion/edge-contraction recursive approach\nwhich we demonstrate presents natural challenges when requiring the \"pivot\"\nproperty. Our main result is the discovery of a greedy strategy to list the\nspanning trees of the fan graph in a pivot Gray code order. It is the first\ngreedy algorithm for exhaustively generating spanning trees using such a\nminimal change operation. The resulting listing is then studied to find a\nrecursive algorithm that produces the same listing in $O(1)$-amortized time\nusing $O(n)$ space. Additionally, we present $O(n)$-time algorithms for ranking\nand unranking the spanning trees for our listing; an improvement over the\ngeneric $O(n^3)$-time algorithm for ranking and unranking spanning trees of an\narbitrary graph. Finally, we discuss how our listing can be applied to find a\npivot Gray code for the wheel graph.",
    "descriptor": "\nComments: An extended version of arXiv:2108.09363 which was presented at COCOON 2021\n",
    "authors": [
      "Ben Cameron",
      "Aaron Grubb",
      "Joe Sawada"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2202.01746"
  },
  {
    "id": "arXiv:2202.01747",
    "title": "The Met Dataset: Instance-level Recognition for Artworks",
    "abstract": "This work introduces a dataset for large-scale instance-level recognition in\nthe domain of artworks. The proposed benchmark exhibits a number of different\nchallenges such as large inter-class similarity, long tail distribution, and\nmany classes. We rely on the open access collection of The Met museum to form a\nlarge training set of about 224k classes, where each class corresponds to a\nmuseum exhibit with photos taken under studio conditions. Testing is primarily\nperformed on photos taken by museum guests depicting exhibits, which introduces\na distribution shift between training and testing. Testing is additionally\nperformed on a set of images not related to Met exhibits making the task\nresemble an out-of-distribution detection problem. The proposed benchmark\nfollows the paradigm of other recent datasets for instance-level recognition on\ndifferent domains to encourage research on domain independent approaches. A\nnumber of suitable approaches are evaluated to offer a testbed for future\ncomparisons. Self-supervised and supervised contrastive learning are\neffectively combined to train the backbone which is used for non-parametric\nclassification that is shown as a promising direction. Dataset webpage:\nthis http URL",
    "descriptor": "",
    "authors": [
      "Nikolaos-Antonios Ypsilantis",
      "Noa Garcia",
      "Guangxing Han",
      "Sarah Ibrahimi",
      "Nanne Van Noord",
      "Giorgos Tolias"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.01747"
  },
  {
    "id": "arXiv:2202.01751",
    "title": "A Family of Current References Based on 2T Voltage References:  Demonstration in 0.18-$\u03bc$m with 0.1-nA PTAT and 1.1-$\u03bc$A CWT  38-ppm/$^\\circ$C Designs",
    "abstract": "The robustness of current and voltage references to process, voltage and\ntemperature (PVT) variations is paramount to the operation of integrated\ncircuits in real-world conditions. However, while recent voltage references can\nmeet most of these requirements with a handful of transistors, current\nreferences remain rather complex, requiring significant design time and silicon\narea. In this paper, we present a family of simple current references\nconsisting of a two-transistor (2T) ultra-low-power voltage reference, buffered\nonto a voltage-to-current converter by a single transistor. Two topologies are\nfabricated in a 0.18-$\\mu$m partially-depleted silicon-on-insulator (SOI)\ntechnology and measured over 10 dies. First, a 7T nA-range\nproportional-to-absolute-temperature (PTAT) reference intended for\nconstant-$g_m$ biasing of subthreshold operational amplifiers demonstrates a\n0.096-nA current with a line sensitivity (LS) of 1.48 %/V, a temperature\ncoefficient (TC) of 0.75 %/$^\\circ$C, and a variability $(\\sigma/\\mu)$ of 1.66\n%. Then, two 4T+1R $\\mu$A-range constant-with-temperature (CWT) references with\n(resp. without) TC calibration exhibit a 1.09-$\\mu$A (resp. 0.99-$\\mu$A)\ncurrent with a 0.21-%/V (resp. 0.20-%/V) LS, a 38-ppm/$^\\circ$C (resp.\n290-ppm/$^\\circ$C) TC, and a 0.87-% (resp. 0.65-%) $(\\sigma/\\mu)$. In addition,\nportability to common scaled CMOS technologies, such as 65-nm bulk and 28-nm\nfully-depleted SOI, is discussed and validated through post-layout simulations.",
    "descriptor": "\nComments: 14 pages, 24 figures\n",
    "authors": [
      "Martin Lefebvre",
      "David Bol"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2202.01751"
  },
  {
    "id": "arXiv:2202.01752",
    "title": "Near-Optimal Learning of Extensive-Form Games with Imperfect Information",
    "abstract": "This paper resolves the open question of designing near-optimal algorithms\nfor learning imperfect-information extensive-form games from bandit feedback.\nWe present the first line of algorithms that require only\n$\\widetilde{\\mathcal{O}}((XA+YB)/\\varepsilon^2)$ episodes of play to find an\n$\\varepsilon$-approximate Nash equilibrium in two-player zero-sum games, where\n$X,Y$ are the number of information sets and $A,B$ are the number of actions\nfor the two players. This improves upon the best known sample complexity of\n$\\widetilde{\\mathcal{O}}((X^2A+Y^2B)/\\varepsilon^2)$ by a factor of\n$\\widetilde{\\mathcal{O}}(\\max\\{X, Y\\})$, and matches the information-theoretic\nlower bound up to logarithmic factors. We achieve this sample complexity by two\nnew algorithms: Balanced Online Mirror Descent, and Balanced Counterfactual\nRegret Minimization. Both algorithms rely on novel approaches of integrating\n\\emph{balanced exploration policies} into their classical counterparts. We also\nextend our results to learning Coarse Correlated Equilibria in multi-player\ngeneral-sum games.",
    "descriptor": "",
    "authors": [
      "Yu Bai",
      "Chi Jin",
      "Song Mei",
      "Tiancheng Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.01752"
  },
  {
    "id": "arXiv:2202.01753",
    "title": "m-CUBES An efficient and portable implementation of multi-dimensional  integration for gpus",
    "abstract": "The task of multi-dimensional numerical integration is frequently encountered\nin physics and other scientific fields, e.g., in modeling the effects of\nsystematic uncertainties in physical systems and in Bayesian parameter\nestimation. Multi-dimensional integration is often time-prohibitive on CPUs.\nEfficient implementation on many-core architectures is challenging as the\nworkload across the integration space cannot be predicted a priori. We propose\nm-Cubes, a novel implementation of the well-known Vegas algorithm for execution\non GPUs. Vegas transforms integration variables followed by calculation of a\nMonte Carlo integral estimate using adaptive partitioning of the resulting\nspace. m-Cubes improves performance on GPUs by maintaining relatively uniform\nworkload across the processors. As a result, our optimized Cuda implementation\nfor Nvidia GPUs outperforms parallelization approaches proposed in past\nliterature. We further demonstrate the efficiency of m-Cubes by evaluating a\nsix-dimensional integral from a cosmology application, achieving significant\nspeedup and greater precision than the CUBA library's CPU implementation of\nVEGAS. We also evaluate m-Cubes on a standard integrand test suite. m-Cubes\noutperforms the serial implementations of the Cuba and GSL libraries by orders\nof magnitude speedup while maintaining comparable accuracy. Our approach yields\na speedup of at least 10 when compared against publicly available Monte Carlo\nbased GPU implementations. In summary, m-Cubes can solve integrals that are\nprohibitively expensive using standard libraries and custom implementations. A\nmodern C++ interface header-only implementation makes m-Cubes portable,\nallowing its utilization in complicated pipelines with easy to define stateful\nintegrals. Compatibility with non-Nvidia GPUs is achieved with our initial\nimplementation of m-Cubes using the Kokkos framework.",
    "descriptor": "",
    "authors": [
      "Ioannis Sakiotis",
      "Kamesh Arumugam",
      "Marc Paterno",
      "Desh Ranjan",
      "Balsa Terzic",
      "Mohammad Zubair"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2202.01753"
  },
  {
    "id": "arXiv:2202.01757",
    "title": "$k$-Transmitter Watchman Routes",
    "abstract": "We consider the watchman route problem for a $k$-transmitter watchman:\nstanding at point $p$ in a polygon $P$, the watchman can see $q\\in P$ if\n$\\overline{pq}$ intersects $P$'s boundary at most $k$ times -- $q$ is\n$k$-visible to $p$. Traveling along the $k$-transmitter watchman route, either\nall points in $P$ or a discrete set of points $S\\subset P$ must be $k$-visible\nto the watchman. We aim for minimizing the length of the $k$-transmitter\nwatchman route.\nWe show that even in simple polygons the shortest $k$-transmitter watchman\nroute problem for a discrete set of points $S\\subset P$ is NP-complete and\ncannot be approximated to within a logarithmic factor (unless P=NP), both with\nand without a given starting point. Moreover, we present a polylogarithmic\napproximation for the $k$-transmitter watchman route problem for a given\nstarting point and $S\\subset P$ with approximation ratio $O(\\log^2(|S|\\cdot n)\n\\log\\log (|S|\\cdot n) \\log(|S|+1))$ (with $|P|=n$).",
    "descriptor": "\nComments: 14 pages, 6 figures\n",
    "authors": [
      "Bengt J. Nilsson",
      "Christiane Schmidt"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2202.01757"
  },
  {
    "id": "arXiv:2202.01758",
    "title": "PRUNIX: Non-Ideality Aware Convolutional Neural Network Pruning for  Memristive Accelerators",
    "abstract": "In this work, PRUNIX, a framework for training and pruning convolutional\nneural networks is proposed for deployment on memristor crossbar based\naccelerators. PRUNIX takes into account the numerous non-ideal effects of\nmemristor crossbars including weight quantization, state-drift, aging and\nstuck-at-faults. PRUNIX utilises a novel Group Sawtooth Regularization intended\nto improve non-ideality tolerance as well as sparsity, and a novel Adaptive\nPruning Algorithm (APA) intended to minimise accuracy loss by considering the\nsensitivity of different layers of a CNN to pruning. We compare our\nregularization and pruning methods with other standards on multiple CNN\narchitectures, and observe an improvement of 13% test accuracy when\nquantization and other non-ideal effects are accounted for with an overall\nsparsity of 85%, which is similar to other methods",
    "descriptor": "\nComments: 5 pages, 4 figues, Accepted to International Symposium on Circuits and Systems (ISCAS) 2022\n",
    "authors": [
      "Ali Alshaarawy",
      "Amirali Amirsoleimani",
      "Roman Genov"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.01758"
  },
  {
    "id": "arXiv:2202.01761",
    "title": "On expressive rule-based logics",
    "abstract": "We investigate a family of rule-based logics. The focus is on very expressive\nlanguages. We provide a range of characterization results for the expressive\npowers of the logics and relate them with corresponding game systems.",
    "descriptor": "",
    "authors": [
      "Antti Kuusisto"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2202.01761"
  },
  {
    "id": "arXiv:2202.01762",
    "title": "Learning Physics through Images: An Application to Wind-Driven Spatial  Patterns",
    "abstract": "For centuries, scientists have observed nature to understand the laws that\ngovern the physical world. The traditional process of turning observations into\nphysical understanding is slow. Imperfect models are constructed and tested to\nexplain relationships in data. Powerful new algorithms are available that can\nenable computers to learn physics by observing images and videos. Inspired by\nthis idea, instead of training machine learning models using physical\nquantities, we trained them using images, that is, pixel information. For this\nwork, and as a proof of concept, the physics of interest are wind-driven\nspatial patterns. Examples of these phenomena include features in Aeolian dunes\nand the deposition of volcanic ash, wildfire smoke, and air pollution plumes.\nWe assume that the spatial patterns were collected by an imaging device that\nrecords the magnitude of the logarithm of deposition as a red, green, blue\n(RGB) color image with channels containing values ranging from 0 to 255. In\nthis paper, we explore deep convolutional neural network-based autoencoders to\nexploit relationships in wind-driven spatial patterns, which commonly occur in\ngeosciences, and reduce their dimensionality. Reducing the data dimension size\nwith an encoder allows us to train regression models linking geographic and\nmeteorological scalar input quantities to the encoded space. Once this is\nachieved, full predictive spatial patterns are reconstructed using the decoder.\nWe demonstrate this approach on images of spatial deposition from a pollution\nsource, where the encoder compresses the dimensionality to 0.02% of the\noriginal size and the full predictive model performance on test data achieves\nan accuracy of 92%.",
    "descriptor": "\nComments: 11 pages, 8 figures\n",
    "authors": [
      "M. Giselle Fern\u00e1ndez-Godino",
      "Donald D. Lucas",
      "Qingkai Kong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Geophysics (physics.geo-ph)"
    ],
    "url": "https://arxiv.org/abs/2202.01762"
  },
  {
    "id": "arXiv:2202.01764",
    "title": "JaQuAD: Japanese Question Answering Dataset for Machine Reading  Comprehension",
    "abstract": "Question Answering (QA) is a task in which a machine understands a given\ndocument and a question to find an answer. Despite impressive progress in the\nNLP area, QA is still a challenging problem, especially for non-English\nlanguages due to the lack of annotated datasets. In this paper, we present the\nJapanese Question Answering Dataset, JaQuAD, which is annotated by humans.\nJaQuAD consists of 39,696 extractive question-answer pairs on Japanese\nWikipedia articles. We finetuned a baseline model which achieves 78.92% for F1\nscore and 63.38% for EM on test set. The dataset and our experiments are\navailable at https://github.com/SkelterLabsInc/JaQuAD.",
    "descriptor": "\nComments: 11 pages, 3 figures, 6 tables\n",
    "authors": [
      "ByungHoon So",
      "Kyuhong Byun",
      "Kyungwon Kang",
      "Seongjin Cho"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.01764"
  },
  {
    "id": "arXiv:2202.01765",
    "title": "Who will Leave a Pediatric Weight Management Program and When? -- A  machine learning approach for predicting attrition patterns",
    "abstract": "Childhood obesity is a major public health concern. Multidisciplinary\npediatric weight management programs are considered standard treatment for\nchildren with obesity and severe obesity who are not able to be successfully\nmanaged in the primary care setting; however, high drop-out rates (referred to\nas attrition) are a major hurdle in delivering successful interventions.\nPredicting attrition patterns can help providers reduce the attrition rates.\nPrevious work has mainly focused on finding static predictors of attrition\nusing statistical analysis methods. In this study, we present a machine\nlearning model to predict (a) the likelihood of attrition, and (b) the change\nin body-mass index (BMI) percentile of children, at different time points after\njoining a weight management program. We use a five-year dataset containing the\ninformation related to around 4,550 children that we have compiled using data\nfrom the Nemours Pediatric Weight Management program. Our models show strong\nprediction performance as determined by high AUROC scores across different\ntasks (average AUROC of 0.75 for predicting attrition, and 0.73 for predicting\nweight outcomes). Additionally, we report the top features predicting attrition\nand weight outcomes in a series of explanatory experiments.",
    "descriptor": "",
    "authors": [
      "Hamed Fayyaz",
      "Thao-Ly T. Phan",
      "H. Timothy Bunnell",
      "Rahmatollah Beheshti"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.01765"
  },
  {
    "id": "arXiv:2202.01769",
    "title": "Improving Automatic Complexity Analysis of Integer Programs",
    "abstract": "In earlier work, we developed an approach for automatic complexity analysis\nof integer programs, based on an alternating modular inference of upper runtime\nand size bounds for program parts. In this paper, we show how recent techniques\nto improve automated termination analysis of integer programs (like the\ngeneration of multiphase-linear ranking functions and control-flow refinement)\ncan be integrated into our approach for the inference of runtime bounds. The\npower of the resulting approach is demonstrated by an extensive experimental\nevaluation with our new re-implementation of the corresponding tool KoAT.",
    "descriptor": "",
    "authors": [
      "J\u00fcrgen Giesl",
      "Nils Lommen",
      "Marcel Hark",
      "Fabian Meyer"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2202.01769"
  },
  {
    "id": "arXiv:2202.01771",
    "title": "Pre-Trained Language Models for Interactive Decision-Making",
    "abstract": "Language model (LM) pre-training has proven useful for a wide variety of\nlanguage processing tasks, but can such pre-training be leveraged for more\ngeneral machine learning problems? We investigate the effectiveness of language\nmodeling to scaffold learning and generalization in autonomous decision-making.\nWe describe a framework for imitation learning in which goals and observations\nare represented as a sequence of embeddings, and translated into actions using\na policy network initialized with a pre-trained transformer LM. We demonstrate\nthat this framework enables effective combinatorial generalization across\ndifferent environments, such as VirtualHome and BabyAI. In particular, for test\ntasks involving novel goals or novel scenes, initializing policies with\nlanguage models improves task completion rates by 43.6% in VirtualHome. We\nhypothesize and investigate three possible factors underlying the effectiveness\nof LM-based policy initialization. We find that sequential representations (vs.\nfixed-dimensional feature vectors) and the LM objective (not just the\ntransformer architecture) are both important for generalization. Surprisingly,\nhowever, the format of the policy inputs encoding (e.g. as a natural language\nstring vs. an arbitrary sequential encoding) has little influence. Together,\nthese results suggest that language modeling induces representations that are\nuseful for modeling not just language, but also goals and plans; these\nrepresentations can aid learning and generalization even outside of language\nprocessing.",
    "descriptor": "",
    "authors": [
      "Shuang Li",
      "Xavier Puig",
      "Yilun Du",
      "Clinton Wang",
      "Ekin Akyurek",
      "Antonio Torralba",
      "Jacob Andreas",
      "Igor Mordatch"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.01771"
  },
  {
    "id": "arXiv:2202.01778",
    "title": "Predicting Cyber-Attack using Cyber Situational Awareness: The Case of  Independent Power Producers (IPPs)",
    "abstract": "The increasing critical dependencies on Internetof-Things (IoT) have raised\nsecurity concerns; its application on the critical infrastructures (CIs) for\npower generation has come under massive cyber-attack over the years. Prior\nresearch efforts to understand cybersecurity from Cyber Situational Awareness\n(CSA) perspective fail to critically consider the various Cyber Situational\nAwareness (CSA) security vulnerabilities from a human behavioural perspective\nin line with the CI. This study evaluates CSA elements to predict cyber-attacks\nin the power generation sector. Data for this research article was collected\nfrom IPPs using the survey method. The analysis method was employed through\nPartial Least Squares Structural Equation Modeling (PLS-SEM) to assess the\nproposed model. The results revealed negative effects on people and\ncyber-attack, but significant in predicting cyber-attacks. The study also\nindicated that information handling is significant and positively influences\ncyber-attack. The study also reveals no mediation effect between the\nassociation of People and Attack and Information and Attack. It could result\nfrom an effective cyber security control implemented by the IPPs. Finally, the\nstudy also shows no sign of network infrastructure cyber-attack predictions.\nThe reasons could be because managers of IPPs had adequate access policies and\nsecurity measures in place.",
    "descriptor": "\nComments: 9 pages\n",
    "authors": [
      "Henry Matey Akwetey",
      "Paul Danquah",
      "Godfred Yaw Koi-Akrofi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.01778"
  },
  {
    "id": "arXiv:2202.01116",
    "title": "Unpaired Image Super-Resolution with Optimal Transport Maps",
    "abstract": "Real-world image super-resolution (SR) tasks often do not have paired\ndatasets limiting the application of supervised techniques. As a result, the\ntasks are usually approached by unpaired techniques based on Generative\nAdversarial Networks (GANs) which yield complex training losses with several\nregularization terms such as content and identity losses. We theoretically\ninvestigate the optimization problems which arise in such models and find two\nsurprising observations. First, the learned SR map is always an optimal\ntransport (OT) map. Second, we empirically show that the learned map is biased,\ni.e., it may not actually transform the distribution of low-resolution images\nto high-resolution images. Inspired by these findings, we propose an algorithm\nfor unpaired SR which learns an unbiased OT map for the perceptual transport\ncost. Unlike existing GAN-based alternatives, our algorithm has a simple\noptimization objective reducing the neccesity to perform complex hyperparameter\nselection and use additional regularizations. At the same time, it provides\nnearly state-of-the-art performance on the large-scale unpaired AIM-19 dataset.",
    "descriptor": "",
    "authors": [
      "Milena Gazdieva",
      "Litu Rout",
      "Alexander Korotin",
      "Alexander Filippov",
      "Evgeny Burnaev"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.01116"
  },
  {
    "id": "arXiv:2202.01208",
    "title": "Deep Learning for Ultrasound Speed-of-Sound Reconstruction: Impacts of  Training Data Diversity on Stability and Robustness",
    "abstract": "Ultrasound b-mode imaging is a qualitative approach and diagnostic quality\nstrongly depends on operators' training and experience. Quantitative approaches\ncan provide information about tissue properties; therefore, can be used for\nidentifying various tissue types, e.g., speed-of-sound in the tissue can be\nused as a biomarker for tissue malignancy, especially in breast imaging. Recent\nstudies showed the possibility of speed-of-sound reconstruction using deep\nneural networks that are fully trained on simulated data. However, because of\nthe ever present domain shift between simulated and measured data, the\nstability and performance of these models in real setups are still under\ndebate. In this study, we investigated the impacts of training data diversity\non the robustness of these networks by using multiple kinds of geometrical and\nnatural simulated phantom structures. On the simulated data, we investigated\nthe performance of the networks on out-of-domain echogenicity, geometries, and\nin the presence of noise. We further inspected the stability of employing such\ntissue modeling in a real data acquisition setup. We demonstrated that training\nthe network with a joint set of datasets including both geometrical and natural\ntissue models improves the stability of the predicted speed-of-sound values\nboth on simulated and measured data.",
    "descriptor": "\nComments: 32 pages, 17 figures, submitted to the Journal of Machine Learning for Biomedical Imaging (MELBA)\n",
    "authors": [
      "Farnaz Khun Jush",
      "Markus Biele",
      "Peter M. Dueppenbecker",
      "Andreas Maier"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.01208"
  },
  {
    "id": "arXiv:2202.01210",
    "title": "Deep Layer-wise Networks Have Closed-Form Weights",
    "abstract": "There is currently a debate within the neuroscience community over the\nlikelihood of the brain performing backpropagation (BP). To better mimic the\nbrain, training a network \\textit{one layer at a time} with only a \"single\nforward pass\" has been proposed as an alternative to bypass BP; we refer to\nthese networks as \"layer-wise\" networks. We continue the work on layer-wise\nnetworks by answering two outstanding questions. First, $\\textit{do they have a\nclosed-form solution?}$ Second, $\\textit{how do we know when to stop adding\nmore layers?}$ This work proves that the Kernel Mean Embedding is the\nclosed-form weight that achieves the network global optimum while driving these\nnetworks to converge towards a highly desirable kernel for classification; we\ncall it the $\\textit{Neural Indicator Kernel}$.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2006.08539\n",
    "authors": [
      "Chieh Wu",
      "Aria Masoomi",
      "Arthur Gretton",
      "Jennifer Dy"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2202.01210"
  },
  {
    "id": "arXiv:2202.01229",
    "title": "Data-Driven Behaviour Estimation in Parametric Games",
    "abstract": "A central question in multi-agent strategic games deals with learning the\nunderlying utilities driving the agents' behaviour. Motivated by the increasing\navailability of large data-sets, we develop an unifying data-driven technique\nto estimate agents' utility functions from their observed behaviour,\nirrespective of whether the observations correspond to (Nash) equilibrium\nconfigurations or to action profile trajectories. Under standard assumptions on\nthe parametrization of the utilities, the proposed inference method is\ncomputationally efficient and finds all the parameters that rationalize the\nobserved behaviour best. We numerically validate our theoretical findings on\nthe market share estimation problem under advertising competition, using\nhistorical data from the Coca-Cola Company and Pepsi Inc. duopoly.",
    "descriptor": "\nComments: 10 pages, 4 figures, 2 tables + 1 appendix\n",
    "authors": [
      "Anna M. Maddux",
      "Nicol\u00f2 Pagan",
      "Giuseppe Belgioioso",
      "Florian D\u00f6rfler"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computer Science and Game Theory (cs.GT)",
      "Multiagent Systems (cs.MA)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.01229"
  },
  {
    "id": "arXiv:2202.01243",
    "title": "Parameters or Privacy: A Provable Tradeoff Between Overparameterization  and Membership Inference",
    "abstract": "A surprising phenomenon in modern machine learning is the ability of a highly\noverparameterized model to generalize well (small error on the test data) even\nwhen it is trained to memorize the training data (zero error on the training\ndata). This has led to an arms race towards increasingly overparameterized\nmodels (c.f., deep learning). In this paper, we study an underexplored hidden\ncost of overparameterization: the fact that overparameterized models are more\nvulnerable to privacy attacks, in particular the membership inference attack\nthat predicts the (potentially sensitive) examples used to train a model. We\nsignificantly extend the relatively few empirical results on this problem by\ntheoretically proving for an overparameterized linear regression model with\nGaussian data that the membership inference vulnerability increases with the\nnumber of parameters. Moreover, a range of empirical studies indicates that\nmore complex, nonlinear models exhibit the same behavior. Finally, we study\ndifferent methods for mitigating such attacks in the overparameterized regime,\nsuch as noise addition and regularization, and conclude that simply reducing\nthe parameters of an overparameterized model is an effective strategy to\nprotect it from membership inference without greatly decreasing its\ngeneralization error.",
    "descriptor": "\nComments: 25 pages, 8 figures\n",
    "authors": [
      "Jasper Tan",
      "Blake Mason",
      "Hamid Javadi",
      "Richard G. Baraniuk"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.01243"
  },
  {
    "id": "arXiv:2202.01272",
    "title": "Jamming Resilient Indoor Factory Deployments: Design and Performance  Evaluation",
    "abstract": "In the framework of 5G-and-beyond Industry 4.0, jamming attacks for denial of\nservice are a rising threat which can severely compromise the system\nperformance. Therefore, in this paper we deal with the problem of jamming\ndetection and mitigation in indoor factory deployments. We design two jamming\ndetectors based on pseudo-random blanking of subcarriers with orthogonal\nfrequency division multiplexing and consider jamming mitigation with frequency\nhopping and random scheduling of the user equipments. We then evaluate the\nperformance of the system in terms of achievable BLER with ultra-reliable\nlow-latency communications traffic and jamming missed detection probability.\nSimulations are performed considering a 3rd Generation Partnership Project\nspatial channel model for the factory floor with a jammer stationed outside the\nplant trying to disrupt the communication inside the factory. Numerical results\nshow that jamming resiliency increases when using a distributed access point\ndeployment and exploiting channel correlation among antennas for jamming\ndetection, while frequency hopping is helpful in jamming mitigation only for\nstrict BLER requirements.",
    "descriptor": "\nComments: Accepted at the IEEE Wireless Communications and Networking Conference (WCNC), Apr. 2022\n",
    "authors": [
      "Leonardo Chiarello",
      "Paolo Baracca",
      "Karthik Upadhya",
      "Saeed R. Khosravirad",
      "Silvio Mandelli",
      "Thorsten Wild"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.01272"
  },
  {
    "id": "arXiv:2202.01274",
    "title": "Principled Graph Management",
    "abstract": "Graph Generation is a recently introduced enhanced Column Generation\nalgorithm for solving expanded Linear Programming relaxations of mixed integer\nlinear programs without weakening the expanded relaxations which characterize\nthese methods. To apply Graph Generation we must be able to map any given\ncolumn generated during pricing to a small directed acyclic graph for which any\npath from source to sink describes a feasible column. This structure is easily\nsatisfied for vehicle routing, crew scheduling and various logistics problems\nwhere pricing is a constrained shortest path problem. The construction of such\ngraphs trades off the size/diversity of a subset of columns modeled by the\ngraphs versus the additional computational time required to solve the problems\ninduced by larger graphs.\nGraph Generation (GG) has two computational bottlenecks. The first is\npricing. Pricing in GG and Column Generation (CG) is identical because of the\nstructure of the problems solved. The second bottleneck is the restricted\nmaster problem (RMP), which is more computationally intensive in GG than in CG\ngiven the same number of columns generated. By design GG converges in fewer\niterations than CG, and hence requires fewer calls to pricing. Therefore, when\nthe computation time of GG is dominated by pricing, as opposed to solving the\nRMP, GG converges much faster than CG in terms of time. However GG need not\nconverge faster than CG when the GG RMP, rather than pricing, dominates\ncomputation.\nIn this paper we introduce Principled Graph Management (PGM), which is an\nalgorithm to solve the GG RMP rapidly by exploiting its special structure. We\ndemonstrate the effectiveness of PGM inside a GG solution to the classical\nCapacitated Vehicle Routing Problem. We demonstrate that PGM solves the GG RMP\nhundreds of times faster than the baseline solver and that the improvement in\nspeed increases with problem size.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2110.01070\n",
    "authors": [
      "Julian Yarkony",
      "Amelia Regan"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2202.01274"
  },
  {
    "id": "arXiv:2202.01277",
    "title": "Global Optimization Networks",
    "abstract": "We consider the problem of estimating a good maximizer of a black-box\nfunction given noisy examples. To solve such problems, we propose to fit a new\ntype of function which we call a global optimization network (GON), defined as\nany composition of an invertible function and a unimodal function, whose unique\nglobal maximizer can be inferred in $\\mathcal{O}(D)$ time. In this paper, we\nshow how to construct invertible and unimodal functions by using linear\ninequality constraints on lattice models. We also extend to \\emph{conditional}\nGONs that find a global maximizer conditioned on specified inputs of other\ndimensions. Experiments show the GON maximizers are statistically significantly\nbetter predictions than those produced by convex fits, GPR, or DNNs, and are\nmore reasonable predictions for real-world problems.",
    "descriptor": "",
    "authors": [
      "Sen Zhao",
      "Erez Louidor",
      "Olexander Mangylov",
      "Maya Gupta"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.01277"
  },
  {
    "id": "arXiv:2202.01280",
    "title": "Combinatorial Gray codes-an updated survey",
    "abstract": "A combinatorial Gray code for a class of objects is a listing that contains\neach object from the class exactly once such that any two consecutive objects\nin the list differ only by a `small change'. Such listings are known for many\ndifferent combinatorial objects, including bitstrings, combinations,\npermutations, partitions, triangulations, but also for objects defined with\nrespect to a fixed graph, such as spanning trees, perfect matchings or vertex\ncolorings. This survey provides a comprehensive picture of the state-of-the-art\nof the research on combinatorial Gray codes. In particular, it gives an update\non Savage's influential survey [C. D. Savage. A survey of combinatorial Gray\ncodes. SIAM Rev., 39(4):605-629, 1997.], incorporating many more recent\ndevelopments. We also elaborate on the connections to closely related problems\nin graph theory, algebra, order theory, geometry and algorithms, which embeds\nthis research area into a broader context. Lastly, we collect and propose a\nnumber of challenging research problems, thus stimulating new research\nendeavors.",
    "descriptor": "",
    "authors": [
      "Torsten M\u00fctze"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2202.01280"
  },
  {
    "id": "arXiv:2202.01314",
    "title": "Gradient estimators for normalising flows",
    "abstract": "Recently a machine learning approach to Monte-Carlo simulations called Neural\nMarkov Chain Monte-Carlo (NMCMC) is gaining traction. In its most popular form\nit uses the neural networks to construct normalizing flows which are then\ntrained to approximate the desired target distribution. As this distribution is\nusually defined via a Hamiltonian or action, the standard learning algorithm\nrequires estimation of the action gradient with respect to the fields. In this\ncontribution we present another gradient estimator (and the corresponding\n[PyTorch implementation) that avoids this calculation, thus potentially\nspeeding up training for models with more complicated actions. We also study\nthe statistical properties of several gradient estimators and show that our\nformulation leads to better training results.",
    "descriptor": "\nComments: 19 pages, 5 figures\n",
    "authors": [
      "Piotr Bialas",
      "Piotr Korcyl",
      "Tomasz Stebel"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Machine Learning (cs.LG)",
      "High Energy Physics - Lattice (hep-lat)"
    ],
    "url": "https://arxiv.org/abs/2202.01314"
  },
  {
    "id": "arXiv:2202.01383",
    "title": "Machine Learning Solar Wind Driving Magnetospheric Convection in Tail  Lobes",
    "abstract": "To quantitatively study the driving mechanisms of magnetospheric convection\nin the magnetotail lobes on a global scale, we utilize data from the ARTEMIS\nspacecraft in the deep tail and the Cluster spacecraft in the near tail.\nPrevious work demonstrated that, in the lobes near the Moon, we can estimate\nthe convection by utilizing ARTEMIS measurements of lunar ions velocity. In\nthis paper, we analyze these datasets with machine learning models to determine\nwhat upstream factors drive the lobe convection in different magnetotail\nregions and thereby understand the mechanisms that control the dynamics of the\ntail lobes. Our results show that the correlations between the predicted and\ntest convection velocities for the machine learning models (> 0.75) are much\nbetter than those of the multiple linear regression model (~ 0.23 - 0.43). The\nsystematic analysis reveals that the IMF and magnetospheric activity play an\nimportant role in influencing plasma convection in the global magnetotail\nlobes.",
    "descriptor": "",
    "authors": [
      "Xin Cao",
      "Jasper S. Halekas",
      "Stein Haaland",
      "Suranga Ruhunusiri",
      "Karl-Heinz Glassmeier"
    ],
    "subjectives": [
      "Solar and Stellar Astrophysics (astro-ph.SR)",
      "Earth and Planetary Astrophysics (astro-ph.EP)",
      "Machine Learning (cs.LG)",
      "Space Physics (physics.space-ph)"
    ],
    "url": "https://arxiv.org/abs/2202.01383"
  },
  {
    "id": "arXiv:2202.01387",
    "title": "Data-Driven Stochastic Optimal Control using Linear Transfer Operators",
    "abstract": "We provide a data-driven framework for optimal control of a continuous-time\nstochastic dynamical system. The proposed framework relies on the linear\noperator theory involving linear Perron-Frobenius (P-F) and Koopman operators.\nOur first results involving the P-F operator provide a convex formulation to\nthe optimal control problem in the dual space of densities. This convex\nformulation of the stochastic optimal control problem leads to an\ninfinite-dimensional convex program. The finite-dimensional approximation of\nthe convex program is obtained using a data-driven approximation of the P-F\noperator. Our second results demonstrate the use of the Koopman operator, which\nis dual to the P-F operator, for the stochastic optimal control design. We show\nthat the Hamilton Jacobi Bellman (HJB) equation can be expressed using the\nKoopman operator. We provide an iterative procedure along the lines of a\npopular policy iteration algorithm based on the data-driven approximation of\nthe Koopman operator for solving the HJB equation. The two formulations, namely\nthe convex formulation involving P-F operator and Koopman based formulation\nusing HJB equation, can be viewed as dual to each other where the duality\nfollows due to the dual nature of P-F and Koopman operators. Finally, we\npresent several numerical examples to demonstrate the efficacy of the developed\nframework.",
    "descriptor": "\nComments: 14 pages\n",
    "authors": [
      "Umesh Vaidya",
      "Duvan Tellez-Castro"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.01387"
  },
  {
    "id": "arXiv:2202.01388",
    "title": "Self-consistent Gradient-like Eigen Decomposition in Solving  Schr\u00f6dinger Equations",
    "abstract": "The Schr\\\"odinger equation is at the heart of modern quantum mechanics. Since\nexact solutions of the ground state are typically intractable, standard\napproaches approximate Schr\\\"odinger equation as forms of nonlinear generalized\neigenvalue problems $F(V)V = SV\\Lambda$ in which $F(V)$, the matrix to be\ndecomposed, is a function of its own top-$k$ smallest eigenvectors $V$, leading\nto a \"self-consistency problem\". Traditional iterative methods heavily rely on\nhigh-quality initial guesses of $V$ generated via domain-specific heuristics\nmethods based on quantum mechanics. In this work, we eliminate such a need for\ndomain-specific heuristics by presenting a novel framework, Self-consistent\nGradient-like Eigen Decomposition (SCGLED) that regards $F(V)$ as a special\n\"online data generator\", thus allows gradient-like eigendecomposition methods\nin streaming $k$-PCA to approach the self-consistency of the equation from\nscratch in an iterative way similar to online learning. With several critical\nnumerical improvements, SCGLED is robust to initial guesses, free of\nquantum-mechanism-based heuristics designs, and neat in implementation. Our\nexperiments show that it not only can simply replace traditional\nheuristics-based initial guess methods with large performance advantage\n(achieved averagely 25x more precise than the best baseline in similar wall\ntime), but also is capable of finding highly precise solutions independently\nwithout any traditional iterative methods.",
    "descriptor": "",
    "authors": [
      "Xihan Li",
      "Xiang Chen",
      "Rasul Tutunov",
      "Haitham Bou-Ammar",
      "Lei Wang",
      "Jun Wang"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.01388"
  },
  {
    "id": "arXiv:2202.01389",
    "title": "An Empirical Review of Optimization Techniques for Quantum Variational  Circuits",
    "abstract": "Quantum Variational Circuits (QVCs) are often claimed as one of the most\npotent uses of both near term and long term quantum hardware. The standard\napproaches to optimizing these circuits rely on a classical system to compute\nthe new parameters at every optimization step. However, this process can be\nextremely challenging both in terms of navigating the exponentially scaling\ncomplex Hilbert space, barren plateaus, and the noise present in all\nforeseeable quantum hardware. Although a variety of optimization algorithms are\nemployed in practice, there is often a lack of theoretical or empirical\nmotivations for this choice. To this end we empirically evaluate the potential\nof many common gradient and gradient free optimizers on a variety of\noptimization tasks. These tasks include both classical and quantum data based\noptimization routines. Our evaluations were conducted in both noise free and\nnoisy simulations. The large number of problems and optimizers yields strong\nempirical guidance for choosing optimizers for QVCs that is currently lacking.",
    "descriptor": "\nComments: 13 pages, 4 figures\n",
    "authors": [
      "Owen Lockwood"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.01389"
  },
  {
    "id": "arXiv:2202.01405",
    "title": "Joint Speech Recognition and Audio Captioning",
    "abstract": "Speech samples recorded in both indoor and outdoor environments are often\ncontaminated with secondary audio sources. Most end-to-end monaural speech\nrecognition systems either remove these background sounds using speech\nenhancement or train noise-robust models. For better model interpretability and\nholistic understanding, we aim to bring together the growing field of automated\naudio captioning (AAC) and the thoroughly studied automatic speech recognition\n(ASR). The goal of AAC is to generate natural language descriptions of contents\nin audio samples. We propose several approaches for end-to-end joint modeling\nof ASR and AAC tasks and demonstrate their advantages over traditional\napproaches, which model these tasks independently. A major hurdle in evaluating\nour proposed approach is the lack of labeled audio datasets with both speech\ntranscriptions and audio captions. Therefore we also create a multi-task\ndataset by mixing the clean speech Wall Street Journal corpus with multiple\nlevels of background noises chosen from the AudioCaps dataset. We also perform\nextensive experimental evaluation and show improvements of our proposed methods\nas compared to existing state-of-the-art ASR and AAC methods.",
    "descriptor": "\nComments: 5 pages, 2 figures. Accepted for ICASSP 2022\n",
    "authors": [
      "Chaitanya Narisetty",
      "Emiru Tsunoo",
      "Xuankai Chang",
      "Yosuke Kashiwagi",
      "Michael Hentschel",
      "Shinji Watanabe"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2202.01405"
  },
  {
    "id": "arXiv:2202.01420",
    "title": "Anomalous sorption kinetics of self-interacting particles by a spherical  trap",
    "abstract": "In this paper we propose a computational framework for the investigation of\nthe correlated motion between positive and negative ions exposed to the\nattraction of a bubble surface that mimics the (oscillating) cell membrane. The\ncorrelated diffusion of surfactants is described by a Poisson-Nernst-Planck\n(PNP) system, in which the drift term is given by the gradient of a potential\nwhich includes both the effect of the bubble and the Coulomb interaction\nbetween the carriers. The latter term is obtained from the solution of a\nself-consistent Poisson equation. For very short Debye lengths one can adopt\nthe so called Quasi-Neutral limit which drastically simplifies the system, thus\nallowing for much faster numerical simulations. The paper has four main\nobjectives. The first one is to present a PNP model that describes ion charges\nin presence of a trap. The second one is to provide benchmark tests for the\nvalidation of simplified multiscale models under current development [1]. The\nthird one is to explore the relevance of the term describing the interaction\namong the apolar tails of the anions. The last one is to quantitatively explore\nthe validity of the Quasi-Neutral limit by comparison with detailed numerical\nsimulation for smaller and smaller Debye lengths. In order to reach these\ngoals, we propose a simple and efficient Alternate Direction Implicit method\nfor the numerical solution of the non-linear PNP system, which guarantees\nsecond order accuracy both in space and time, without requiring solution of\nnonlinear equation at each time step. New semi-implicit scheme for a simplified\nPNP system near quasi neutrality is also proposed.",
    "descriptor": "",
    "authors": [
      "Antonio Raudino",
      "Antonio Grassi",
      "Giuseppe Lombardo",
      "Giovanni Russo",
      "Clarissa Astuto",
      "Mario Corti"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.01420"
  },
  {
    "id": "arXiv:2202.01463",
    "title": "Minimax rate of consistency for linear models with missing values",
    "abstract": "Missing values arise in most real-world data sets due to the aggregation of\nmultiple sources and intrinsically missing information (sensor failure,\nunanswered questions in surveys...). In fact, the very nature of missing values\nusually prevents us from running standard learning algorithms. In this paper,\nwe focus on the extensively-studied linear models, but in presence of missing\nvalues, which turns out to be quite a challenging task. Indeed, the Bayes rule\ncan be decomposed as a sum of predictors corresponding to each missing pattern.\nThis eventually requires to solve a number of learning tasks, exponential in\nthe number of input features, which makes predictions impossible for current\nreal-world datasets. First, we propose a rigorous setting to analyze a\nleast-square type estimator and establish a bound on the excess risk which\nincreases exponentially in the dimension. Consequently, we leverage the missing\ndata distribution to propose a new algorithm, andderive associated adaptive\nrisk bounds that turn out to be minimax optimal. Numerical experiments\nhighlight the benefits of our method compared to state-of-the-art algorithms\nused for predictions with missing values.",
    "descriptor": "",
    "authors": [
      "Alexis Ayme",
      "Claire Boyer",
      "Aymeric Dieuleveut",
      "Erwan Scornet"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.01463"
  },
  {
    "id": "arXiv:2202.01466",
    "title": "Quantifying knowledge synchronisation in the 21st century",
    "abstract": "Humans acquire and accumulate knowledge through language usage and eagerly\nexchange their knowledge for advancement. Although geographical barriers had\npreviously limited communication, the emergence of information technology has\nopened new avenues for knowledge exchange. However, it is unclear which\ncommunication pathway is dominant in the 21st century. Here, we explore the\ndominant path of knowledge diffusion in the 21st century using Wikipedia, the\nlargest communal dataset. We evaluate the similarity of shared knowledge\nbetween population groups, distinguished based on their language usage. When\npopulation groups are more engaged with each other, their knowledge structure\nis more similar, where engagement is indicated by socioeconomic connections,\nsuch as cultural, linguistic, and historical features. Moreover, geographical\nproximity is no longer a critical requirement for knowledge dissemination.\nFurthermore, we integrate our data into a mechanistic model to better\nunderstand the underlying mechanism and suggest that the knowledge \"Silk Road\"\nof the 21st century is based online.",
    "descriptor": "\nComments: 35 pages, 11 figures\n",
    "authors": [
      "Jisung Yoon",
      "Jinseo Park",
      "Jinhyuk Yun",
      "Woo-Sung Jung"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2202.01466"
  },
  {
    "id": "arXiv:2202.01468",
    "title": "A unified surrogate-based scheme for black-box and preference-based  optimization",
    "abstract": "Black-box and preference-based optimization algorithms are global\noptimization procedures that aim to find the global solutions of an\noptimization problem using, respectively, the least amount of function\nevaluations or sample comparisons as possible. In the black-box case, the\nanalytical expression of the objective function is unknown and it can only be\nevaluated through a (costly) computer simulation or an experiment. In the\npreference-based case, the objective function is still unknown but it\ncorresponds to the subjective criterion of an individual. So, it is not\npossible to quantify such criterion in a reliable and consistent way.\nTherefore, preference-based optimization algorithms seek global solutions using\nonly comparisons between couples of different samples, for which a human\ndecision-maker indicates which of the two is preferred. Quite often, the\nblack-box and preference-based frameworks are covered separately and are\nhandled using different techniques. In this paper, we show that black-box and\npreference-based optimization problems are closely related and can be solved\nusing the same family of approaches, namely surrogate-based methods. Moreover,\nwe propose the generalized Metric Response Surface (gMRS) algorithm, an\noptimization scheme that is a generalization of the popular MSRS framework.\nFinally, we provide a convergence proof for the proposed optimization method.",
    "descriptor": "\nComments: 17 pages, 2 figures and 1 table. arXiv admin note: text overlap with arXiv:2202.01125\n",
    "authors": [
      "Davide Previtali",
      "Mirko Mazzoleni",
      "Antonio Ferramosca",
      "Fabio Previdi"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.01468"
  },
  {
    "id": "arXiv:2202.01487",
    "title": "A benchmark of state-of-the-art sound event detection systems evaluated  on synthetic soundscapes",
    "abstract": "This paper proposes a benchmark of submissions to Detection and\nClassification Acoustic Scene and Events 2021 Challenge (DCASE) Task 4\nrepresenting a sampling of the state-of-the-art in Sound Event Detection task.\nThe submissions are evaluated according to the two polyphonic sound detection\nscore scenarios proposed for the DCASE 2021 Challenge Task 4, which allow to\nmake an analysis on whether submissions are designed to perform fine-grained\ntemporal segmentation, coarse-grained temporal segmentation, or have been\ndesigned to be polyvalent on the scenarios proposed. We study the solutions\nproposed by participants to analyze their robustness to varying level target to\nnon-target signal-to-noise ratio and to temporal localization of target sound\nevents. A last experiment is proposed in order to study the impact of\nnon-target events on systems outputs. Results show that systems adapted to\nprovide coarse segmentation outputs are more robust to different target to\nnon-target signal-to-noise ratio and, with the help of specific data\naugmentation methods, they are more robust to time localization of the original\nevent. Results of the last experiment display that systems tend to spuriously\npredict short events when non-target events are present. This is particularly\ntrue for systems that are tailored to have a fine segmentation.",
    "descriptor": "",
    "authors": [
      "Francesca Ronchini",
      "Romain Serizel"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2202.01487"
  },
  {
    "id": "arXiv:2202.01494",
    "title": "PARCEL: Physics-based unsupervised contrastive representation learning  for parallel MR imaging",
    "abstract": "With the successful application of deep learning in magnetic resonance\nimaging, parallel imaging techniques based on neural networks have attracted\nwide attentions. However, without high-quality fully sampled datasets for\ntraining, the performance of these methods tends to be limited. To address this\nissue, this paper proposes a physics based unsupervised contrastive\nrepresentation learning (PARCEL) method to speed up parallel MR imaging.\nSpecifically, PARCEL has three key ingredients to achieve direct deep learning\nfrom the undersampled k-space data. Namely, a parallel framework has been\ndeveloped by learning two branches of model-based networks unrolled with the\nconjugate gradient algorithm; Augmented undersampled k-space data randomly\ndrawn from the obtained k-space data are used to help the parallel network to\ncapture the detailed information. A specially designed co-training loss is\ndesigned to guide the two networks to capture the inherent features and\nrepresentations of the-to-be-reconstructed MR image. The proposed method has\nbeen evaluated on in vivo datasets and compared to five state-of-the-art\nmethods, whose results show PARCEL is able to learn useful representations for\nmore accurate MR reconstructions without the reliance on the fully-sampled\ndatasets.",
    "descriptor": "",
    "authors": [
      "Shanshan Wang",
      "Ruoyou Wu",
      "Cheng Li",
      "Juan Zou",
      "Hairong Zheng"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.01494"
  },
  {
    "id": "arXiv:2202.01562",
    "title": "Doubly Robust Off-Policy Evaluation for Ranking Policies under the  Cascade Behavior Model",
    "abstract": "In real-world recommender systems and search engines, optimizing ranking\ndecisions to present a ranked list of relevant items is critical. Off-policy\nevaluation (OPE) for ranking policies is thus gaining a growing interest\nbecause it enables performance estimation of new ranking policies using only\nlogged data. Although OPE in contextual bandits has been studied extensively,\nits naive application to the ranking setting faces a critical variance issue\ndue to the huge item space. To tackle this problem, previous studies introduce\nsome assumptions on user behavior to make the combinatorial item space\ntractable. However, an unrealistic assumption may, in turn, cause serious bias.\nTherefore, appropriately controlling the bias-variance tradeoff by imposing a\nreasonable assumption is the key for success in OPE of ranking policies. To\nachieve a well-balanced bias-variance tradeoff, we propose the Cascade Doubly\nRobust estimator building on the cascade assumption, which assumes that a user\ninteracts with items sequentially from the top position in a ranking. We show\nthat the proposed estimator is unbiased in more cases compared to existing\nestimators that make stronger assumptions. Furthermore, compared to a previous\nestimator based on the same cascade assumption, the proposed estimator reduces\nthe variance by leveraging a control variate. Comprehensive experiments on both\nsynthetic and real-world data demonstrate that our estimator leads to more\naccurate OPE than existing estimators in a variety of settings.",
    "descriptor": "\nComments: WSDM2022\n",
    "authors": [
      "Haruka Kiyohara",
      "Yuta Saito",
      "Tatsuya Matsuhiro",
      "Yusuke Narita",
      "Nobuyuki Shimizu",
      "Yasuo Yamamoto"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.01562"
  },
  {
    "id": "arXiv:2202.01564",
    "title": "Weakly Supervised Nuclei Segmentation via Instance Learning",
    "abstract": "Weakly supervised nuclei segmentation is a critical problem for pathological\nimage analysis and greatly benefits the community due to the significant\nreduction of labeling cost. Adopting point annotations, previous methods mostly\nrely on less expressive representations for nuclei instances and thus have\ndifficulty in handling crowded nuclei. In this paper, we propose to decouple\nweakly supervised semantic and instance segmentation in order to enable more\neffective subtask learning and to promote instance-aware representation\nlearning. To achieve this, we design a modular deep network with two branches:\na semantic proposal network and an instance encoding network, which are trained\nin a two-stage manner with an instance-sensitive loss. Empirical results show\nthat our approach achieves the state-of-the-art performance on two public\nbenchmarks of pathological images from different types of organs.",
    "descriptor": "",
    "authors": [
      "Weizhen Liu",
      "Qian He",
      "Xuming He"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.01564"
  },
  {
    "id": "arXiv:2202.01566",
    "title": "Unified theory of atom-centered representations and graph convolutional  machine-learning schemes",
    "abstract": "Data-driven schemes that associate molecular and crystal structures with\ntheir microscopic properties share the need for a concise, effective\ndescription of the arrangement of their atomic constituents. Many types of\nmodels rely on descriptions of atom-centered environments, that are associated\nwith an atomic property or with an atomic contribution to an extensive\nmacroscopic quantity. Frameworks in this class can be understood in terms of\natom-centered density correlations (ACDC), that are used as a basis for a\nbody-ordered, symmetry-adapted expansion of the targets. Several other schemes,\nthat gather information on the relationship between neighboring atoms using\ngraph-convolutional (or message-passing) ideas, cannot be directly mapped to\ncorrelations centered around a single atom. We generalize the ACDC framework to\ninclude multi-centered information, generating representations that provide a\ncomplete linear basis to regress symmetric functions of atomic coordinates, and\nform the basis to systematize our understanding of both atom-centered and\ngraph-convolutional machine-learning schemes.",
    "descriptor": "",
    "authors": [
      "Jigyasa Nigam",
      "Guillaume Fraux",
      "Michele Ceriotti"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Chemical Physics (physics.chem-ph)"
    ],
    "url": "https://arxiv.org/abs/2202.01566"
  },
  {
    "id": "arXiv:2202.01571",
    "title": "Toric Geometry of Entropic Regularization",
    "abstract": "Entropic regularization is a method for large-scale linear programming.\nGeometrically, one traces intersections of the feasible polytope with scaled\ntoric varieties, starting at the Birch point. We compare this to log-barrier\nmethods, with reciprocal linear spaces, starting at the analytic center. We\nrevisit entropic regularization for unbalanced optimal transport, and we\ndevelop the use of optimal conic couplings. We compute the degree of the\nassociated toric variety, and we explore algorithms like iterative scaling.",
    "descriptor": "\nComments: 16 pages\n",
    "authors": [
      "Bernd Sturmfels",
      "Simon Telen",
      "Fran\u00e7ois-Xavier Vialard",
      "Max von Renesse"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Algebraic Geometry (math.AG)"
    ],
    "url": "https://arxiv.org/abs/2202.01571"
  },
  {
    "id": "arXiv:2202.01630",
    "title": "A deep complex network with multi-frame filtering for stereophonic  acoustic echo cancellation",
    "abstract": "In hands-free communication system, the coupling between the loudspeaker and\nthe microphone will generate echo signal, which can severely impair the quality\nof communication. Meanwhile, various types of noise in the communication\nenvironment further destroy the speech quality and intelligibility. It is hard\nto extract the near-end signal from the microphone input signal within one\nstep, especially in low signal-to-noise ratios. In this paper, we propose a\nmulti-stage approach to address this issue. On the one hand, we decompose the\necho cancellation into two stages, including linear echo cancellation module\nand residual echo suppression module. A multi-frame filtering strategy is\nintroduced to benefit estimating linear echo by utilizing more inter-frame\ninformation. On the other hand, we decouple the complex spectral mapping into\nmagnitude estimation and complex spectra refine. Experimental results\ndemonstrate that our proposed approach achieves stage-of-the-art performance\nover previous advanced algorithms under various conditions.",
    "descriptor": "",
    "authors": [
      "Linjuan Cheng",
      "Chengshi Zheng",
      "Andong Li",
      "Renhua Peng",
      "Xiaodong Li"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2202.01630"
  },
  {
    "id": "arXiv:2202.01636",
    "title": "On constant-time quantum annealing and guaranteed approximations for  graph optimization problems",
    "abstract": "Quantum Annealing (QA) is a computational framework where a quantum system's\ncontinuous evolution is used to find the global minimum of an objective\nfunction over an unstructured search space. It can be seen as a general\nmetaheuristic for optimization problems, including NP-hard ones if we allow an\nexponentially large running time. While QA is widely studied from a heuristic\npoint of view, little is known about theoretical guarantees on the quality of\nthe solutions obtained in polynomial time.\nIn this paper we use a technique borrowed from theoretical physics, the\nLieb-Robinson (LR) bound, and develop new tools proving that short, constant\ntime quantum annealing guarantees constant factor approximations ratios for\nsome optimization problems when restricted to bounded degree graphs.\nInformally, on bounded degree graphs the LR bound allows us to retrieve a\n(relaxed) locality argument, through which the approximation ratio can be\ndeduced by studying subgraphs of bounded radius.\nWe illustrate our tools on problems MaxCut and Maximum Independent Set for\ncubic graphs, providing explicit approximation ratios and the runtimes needed\nto obtain them. Our results are of similar flavor to the well-known ones\nobtained in the different but related QAOA (quantum optimization algorithms)\nframework.\nEventually, we discuss theoretical and experimental arguments for further\nimprovements.",
    "descriptor": "",
    "authors": [
      "Arthur Braida",
      "Simon Martiel",
      "Ioan Todinca"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2202.01636"
  },
  {
    "id": "arXiv:2202.01664",
    "title": "Removing Distortion Effects in Music Using Deep Neural Networks",
    "abstract": "Audio effects are an essential element in the context of music production,\nand therefore, modeling analog audio effects has been extensively researched\nfor decades using system-identification methods, circuit simulation, and\nrecently, deep learning. However, only few works tackled the reconstruction of\nsignals that were processed using an audio effect unit. Given the recent\nadvances in music source separation and automatic mixing, the removal of audio\neffects could facilitate an automatic remixing system. This paper focuses on\nremoving distortion and clipping applied to guitar tracks for music production\nwhile presenting a comparative investigation of different deep neural network\n(DNN) architectures on this task. We achieve exceptionally good results in\ndistortion removal using DNNs for effects that superimpose the clean signal to\nthe distorted signal, while the task is more challenging if the clean signal is\nnot superimposed. Nevertheless, in the latter case, the neural models under\nevaluation surpass one state-of-the-art declipping system in terms of\nsource-to-distortion ratio, leading to better quality and faster inference.",
    "descriptor": "\nComments: Submitted to the Journal of the Audio Engineering Society on January 24, 2022; audio clips available at this https URL; 10 pages, 7 figures\n",
    "authors": [
      "Johannes Imort",
      "Giorgio Fabbro",
      "Marco A. Mart\u00ednez Ram\u00edrez",
      "Stefan Uhlich",
      "Yuichiro Koyama",
      "Yuki Mitsufuji"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2202.01664"
  },
  {
    "id": "arXiv:2202.01671",
    "title": "Log-Euclidean Signatures for Intrinsic Distances Between Unaligned  Datasets",
    "abstract": "The need for efficiently comparing and representing datasets with unknown\nalignment spans various fields, from model analysis and comparison in machine\nlearning to trend discovery in collections of medical datasets. We use manifold\nlearning to compare the intrinsic geometric structures of different datasets by\ncomparing their diffusion operators, symmetric positive-definite (SPD) matrices\nthat relate to approximations of the continuous Laplace-Beltrami operator from\ndiscrete samples. Existing methods typically compare such operators in a\npointwise manner or assume known data alignment. Instead, we exploit the\nRiemannian geometry of SPD matrices to compare these operators and define a new\ntheoretically-motivated distance based on a lower bound of the log-Euclidean\nmetric. Our framework facilitates comparison of data manifolds expressed in\ndatasets with different sizes, numbers of features, and measurement modalities.\nOur log-Euclidean signature (LES) distance recovers meaningful structural\ndifferences, outperforming competing methods in various application domains.",
    "descriptor": "\nComments: 20 pages, 7 figures\n",
    "authors": [
      "Tal Shnitzer",
      "Mikhail Yurochkin",
      "Kristjan Greenewald",
      "Justin Solomon"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.01671"
  },
  {
    "id": "arXiv:2202.01675",
    "title": "Environmental and Safety Impacts of Vehicle-to-Everything Enabled  Applications: A Review of State-of-the-Art Studies",
    "abstract": "With the rapid development of communication technology, connected vehicles\n(CV) have the potential, through the sharing of data, to enhance vehicle safety\nand reduce vehicle energy consumption and emissions. Numerous research efforts\nare quantifying the impacts of CV applications, assuming instant and accurate\ncommunication among vehicles, devices, pedestrians, infrastructure, the\nnetwork, the cloud, and the grid, collectively known as V2X\n(vehicle-to-everything). The use of cellular vehicle-to-everything (C-V2X), to\nshare data is emerging as an efficient means to achieve this objective. C-V2X\nreleases 14 and 15 utilize the 4G LTE technology and release 16 utilizes the\nnew 5G new radio (NR) technology. C-V2X can function without network\ninfrastructure coverage and has a better communication range, improved latency,\nand greater data rates compared to older technologies. Such highly efficient\ninterchange of information among all participating parts in a CV environment\nwill not only provide timely data to enhance the capacity of the transportation\nsystem but can also be used to develop applications that enhance vehicle safety\nand minimize negative environmental impacts. However, before the full benefits\nof CV can be achieved, there is a need to thoroughly investigate the\neffectiveness, strengths, and weaknesses of different CV applications, the\ncommunication protocols, the varied results with different CV market\npenetration rates (MPRs), the interaction of CVs and human driven vehicles, the\nintegration of multiple applications, and the errors and latencies associated\nwith data communication. This paper reviews existing literature on the\nenvironmental, mobility and safety impacts of CV applications, identifies the\ngaps in our current research of CVs and recommends future research directions.",
    "descriptor": "\nComments: This paper is a literature review of V2X-enabled applications\n",
    "authors": [
      "Jianhe Du",
      "Kyoungho Ahn",
      "Mohamed Farag",
      "Hesham Rakha"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2202.01675"
  },
  {
    "id": "arXiv:2202.01682",
    "title": "How to build a cognitive map: insights from models of the hippocampal  formation",
    "abstract": "Learning and interpreting the structure of the environment is an innate\nfeature of biological systems, and is integral to guiding flexible behaviours\nfor evolutionary viability. The concept of a cognitive map has emerged as one\nof the leading metaphors for these capacities, and unravelling the learning and\nneural representation of such a map has become a central focus of neuroscience.\nWhile experimentalists are providing a detailed picture of the neural substrate\nof cognitive maps in hippocampus and beyond, theorists have been busy building\nmodels to bridge the divide between neurons, computation, and behaviour. These\nmodels can account for a variety of known representations and neural phenomena,\nbut often provide a differing understanding of not only the underlying\nprinciples of cognitive maps, but also the respective roles of hippocampus and\ncortex. In this Perspective, we bring many of these models into a common\nlanguage, distil their underlying principles of constructing cognitive maps,\nprovide novel (re)interpretations for neural phenomena, suggest how the\nprinciples can be extended to account for prefrontal cortex representations\nand, finally, speculate on the role of cognitive maps in higher cognitive\ncapacities.",
    "descriptor": "",
    "authors": [
      "James C.R. Whittington",
      "David McCaffary",
      "Jacob J.W. Bakermans",
      "Timothy E.J. Behrens"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.01682"
  },
  {
    "id": "arXiv:2202.01723",
    "title": "Systems Biology: Identifiability analysis and parameter identification  via systems-biology informed neural networks",
    "abstract": "The dynamics of systems biological processes are usually modeled by a system\nof ordinary differential equations (ODEs) with many unknown parameters that\nneed to be inferred from noisy and sparse measurements. Here, we introduce\nsystems-biology informed neural networks for parameter estimation by\nincorporating the system of ODEs into the neural networks. To complete the\nworkflow of system identification, we also describe structural and practical\nidentifiability analysis to analyze the identifiability of parameters. We use\nthe ultridian endocrine model for glucose-insulin interaction as the example to\ndemonstrate all these methods and their implementation.",
    "descriptor": "",
    "authors": [
      "Mitchell Daneker",
      "Zhen Zhang",
      "George Em Karniadakis",
      "Lu Lu"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.01723"
  },
  {
    "id": "arXiv:2202.01731",
    "title": "Fast Online Video Super-Resolution with Deformable Attention Pyramid",
    "abstract": "Video super-resolution (VSR) has many applications that pose strict causal,\nreal-time, and latency constraints, including video streaming and TV. We\naddress the VSR problem under these settings, which poses additional important\nchallenges since information from future frames are unavailable. Importantly,\ndesigning efficient, yet effective frame alignment and fusion modules remain\ncentral problems. In this work, we propose a recurrent VSR architecture based\non a deformable attention pyramid (DAP). Our DAP aligns and integrates\ninformation from the recurrent state into the current frame prediction. To\ncircumvent the computational cost of traditional attention-based methods, we\nonly attend to a limited number of spatial locations, which are dynamically\npredicted by the DAP. Comprehensive experiments and analysis of the proposed\nkey innovations show the effectiveness of our approach. We significantly reduce\nprocessing time in comparison to state-of-the-art methods, while maintaining a\nhigh performance. We surpass state-of-the-art method EDVR-M on two standard\nbenchmarks with a speed-up of over 3x.",
    "descriptor": "",
    "authors": [
      "Dario Fuoli",
      "Martin Danelljan",
      "Radu Timofte",
      "Luc Van Gool"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.01731"
  },
  {
    "id": "arXiv:2202.01748",
    "title": "Sequential Learning of the Topological Ordering for the Linear  Non-Gaussian Acyclic Model with Parametric Noise",
    "abstract": "Causal discovery, the learning of causality in a data mining scenario, has\nbeen of strong scientific and theoretical interest as a starting point to\nidentify \"what causes what?\" Contingent on assumptions, it is sometimes\npossible to identify an exact causal Directed Acyclic Graph (DAG), as opposed\nto a Markov equivalence class of graphs that gives ambiguity of causal\ndirections. The focus of this paper is on one such case: a linear structural\nequation model with non-Gaussian noise, a model known as the Linear\nNon-Gaussian Acyclic Model (LiNGAM). Given a specified parametric noise model,\nwe develop a novel sequential approach to estimate the causal ordering of a\nDAG. At each step of the procedure, only simple likelihood ratio scores are\ncalculated on regression residuals to decide the next node to append to the\ncurrent partial ordering. Under mild assumptions, the population version of our\nprocedure provably identifies a true ordering of the underlying causal DAG. We\nprovide extensive numerical evidence to demonstrate that our sequential\nprocedure is scalable to cases with possibly thousands of nodes and works well\nfor high-dimensional data. We also conduct an application to a single-cell gene\nexpression dataset to demonstrate our estimation procedure.",
    "descriptor": "",
    "authors": [
      "Gabriel Ruiz",
      "Oscar Hernan Madrid Padilla",
      "Qing Zhou"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.01748"
  },
  {
    "id": "arXiv:2202.01770",
    "title": "Exploring Multi-physics with Extremely Weak Supervision",
    "abstract": "Multi-physical inversion plays a critical role in geophysics. It has been\nwidely used to infer various physical properties (such as velocity and\nconductivity), simultaneously. Among those inversion problems, some are\nexplicitly governed by partial differential equations (PDEs), while others are\nnot. Without explicit governing equations, conventional multi-physical\ninversion techniques will not be feasible and data-driven inversion require\nexpensive full labels. To overcome this issue, we develop a new data-driven\nmulti-physics inversion technique with extremely weak supervision. Our key\nfinding is that the pseudo labels can be constructed by learning the local\nrelationship among geophysical properties at very sparse locations. We explore\na multi-physics inversion problem from two distinct measurements (seismic and\nEM data) to three geophysical properties (velocity, conductivity, and CO$_2$\nsaturation). Our results show that we are able to invert for properties without\nexplicit governing equations. Moreover, the label data on three geophysical\nproperties can be significantly reduced by 50 times (from 100 down to only 2\nlocations).",
    "descriptor": "",
    "authors": [
      "Shihang Feng",
      "Peng Jin",
      "Yinpeng Chen",
      "Xitong Zhang",
      "Zicheng Liu",
      "Youzuo Lin"
    ],
    "subjectives": [
      "Geophysics (physics.geo-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.01770"
  },
  {
    "id": "arXiv:2202.01773",
    "title": "Multiclass learning with margin: exponential rates with no bias-variance  trade-off",
    "abstract": "We study the behavior of error bounds for multiclass classification under\nsuitable margin conditions. For a wide variety of methods we prove that the\nclassification error under a hard-margin condition decreases exponentially fast\nwithout any bias-variance trade-off. Different convergence rates can be\nobtained in correspondence of different margin assumptions. With a\nself-contained and instructive analysis we are able to generalize known results\nfrom the binary to the multiclass setting.",
    "descriptor": "",
    "authors": [
      "Stefano Vigogna",
      "Giacomo Meanti",
      "Ernesto De Vito",
      "Lorenzo Rosasco"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.01773"
  },
  {
    "id": "arXiv:1809.05049",
    "title": "Categorical Representations of Continuous Domains and Continuous  L-Domains Based on Closure Spaces",
    "abstract": "Categorical Representations of Continuous Domains and Continuous  L-Domains Based on Closure Spaces",
    "descriptor": "",
    "authors": [
      "Longchun Wang",
      "Qingguo Li",
      "Lanlun Guo"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Logic (math.LO)"
    ],
    "url": "https://arxiv.org/abs/1809.05049"
  },
  {
    "id": "arXiv:1908.00089",
    "title": "A Model of Random Industrial SAT",
    "abstract": "Comments: 32 pages",
    "descriptor": "\nComments: 32 pages\n",
    "authors": [
      "Dina Barak-Pelleg",
      "Daniel Berend",
      "J.C. Saunders"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/1908.00089"
  },
  {
    "id": "arXiv:1909.01132",
    "title": "PageRank algorithm for Directed Hypergraph",
    "abstract": "Comments: There are some errors in the experiments. I will re-submit it later",
    "descriptor": "\nComments: There are some errors in the experiments. I will re-submit it later\n",
    "authors": [
      "Loc Tran",
      "Tho Quan",
      "An Mai"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1909.01132"
  },
  {
    "id": "arXiv:1911.12557",
    "title": "Quantum Weakest Preconditions for Reasoning about Expected Runtimes of  Quantum Programs",
    "abstract": "Quantum Weakest Preconditions for Reasoning about Expected Runtimes of  Quantum Programs",
    "descriptor": "",
    "authors": [
      "Junyi Liu",
      "Li Zhou",
      "Gilles Barthe",
      "Mingsheng Ying"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/1911.12557"
  },
  {
    "id": "arXiv:1912.04608",
    "title": "Forecasting future action sequences with attention: a new approach to  weakly supervised action forecasting",
    "abstract": "Forecasting future action sequences with attention: a new approach to  weakly supervised action forecasting",
    "descriptor": "",
    "authors": [
      "Yan Bin Ng",
      "Basura Fernando"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/1912.04608"
  },
  {
    "id": "arXiv:2002.11875",
    "title": "Optimality and Stability in Non-Convex Smooth Games",
    "abstract": "Comments: accepted by JMLR 2022",
    "descriptor": "\nComments: accepted by JMLR 2022\n",
    "authors": [
      "Guojun Zhang",
      "Pascal Poupart",
      "Yaoliang Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2002.11875"
  },
  {
    "id": "arXiv:2005.12794",
    "title": "Asymptotic links between signal processing, acoustic metamaterials and  biology",
    "abstract": "Asymptotic links between signal processing, acoustic metamaterials and  biology",
    "descriptor": "",
    "authors": [
      "Habib Ammari",
      "Bryn Davies"
    ],
    "subjectives": [
      "Analysis of PDEs (math.AP)",
      "Numerical Analysis (math.NA)",
      "Biological Physics (physics.bio-ph)"
    ],
    "url": "https://arxiv.org/abs/2005.12794"
  },
  {
    "id": "arXiv:2006.07082",
    "title": "Resource dependency and survivability in complex networks",
    "abstract": "Comments: 8 pages, 9 figures. Code is freely available at this https URL",
    "descriptor": "\nComments: 8 pages, 9 figures. Code is freely available at this https URL\n",
    "authors": [
      "Madhusudan Ingale",
      "Snehal M. Shekatkar"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)",
      "Adaptation and Self-Organizing Systems (nlin.AO)"
    ],
    "url": "https://arxiv.org/abs/2006.07082"
  },
  {
    "id": "arXiv:2007.02411",
    "title": "Assessing External Validity Over Worst-case Subpopulations",
    "abstract": "Comments: A previous version of the paper circulated under the title \"Robust Causal Inference Under Covariate Shift via Worst-Case Subpopulation Treatment Effects\" appeared in COLT 2020",
    "descriptor": "\nComments: A previous version of the paper circulated under the title \"Robust Causal Inference Under Covariate Shift via Worst-Case Subpopulation Treatment Effects\" appeared in COLT 2020\n",
    "authors": [
      "Sookyo Jeong",
      "Hongseok Namkoong"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Econometrics (econ.EM)"
    ],
    "url": "https://arxiv.org/abs/2007.02411"
  },
  {
    "id": "arXiv:2007.06986",
    "title": "Estimating the Potential of Program Repair Search Spaces with Commit  Analysis",
    "abstract": "Estimating the Potential of Program Repair Search Spaces with Commit  Analysis",
    "descriptor": "",
    "authors": [
      "Khashayar Etemadi",
      "Niloofar Tarighat",
      "Siddharth Yadav",
      "Matias Martinez",
      "Martin Monperrus"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2007.06986"
  },
  {
    "id": "arXiv:2008.03626",
    "title": "Directed hypergraph neural network",
    "abstract": "Comments: There are some errors in the experiments. I will re-submit it later",
    "descriptor": "\nComments: There are some errors in the experiments. I will re-submit it later\n",
    "authors": [
      "Loc Hoang Tran",
      "Linh Hoang Tran"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2008.03626"
  },
  {
    "id": "arXiv:2008.08733",
    "title": "Optimal Network Compression",
    "abstract": "Comments: 32 pages, 10 figures",
    "descriptor": "\nComments: 32 pages, 10 figures\n",
    "authors": [
      "Hamed Amini",
      "Zachary Feinstein"
    ],
    "subjectives": [
      "Risk Management (q-fin.RM)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2008.08733"
  },
  {
    "id": "arXiv:2009.03074",
    "title": "One-Clock Priced Timed Games with Negative Weights",
    "abstract": "Comments: arXiv admin note: substantial text overlap with arXiv:1507.03786",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:1507.03786\n",
    "authors": [
      "Thomas Brihaye",
      "Gilles Geeraerts",
      "Axel Haddad",
      "Engel Lefaucheux",
      "Benjamin Monmege"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2009.03074"
  },
  {
    "id": "arXiv:2009.09205",
    "title": "Adversarial Rain Attack and Defensive Deraining for DNN Perception",
    "abstract": "Adversarial Rain Attack and Defensive Deraining for DNN Perception",
    "descriptor": "",
    "authors": [
      "Liming Zhai",
      "Felix Juefei-Xu",
      "Qing Guo",
      "Xiaofei Xie",
      "Lei Ma",
      "Wei Feng",
      "Shengchao Qin",
      "Yang Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2009.09205"
  },
  {
    "id": "arXiv:2009.13065",
    "title": "Fixed Points Theorems for Non-Transitive Relations",
    "abstract": "Fixed Points Theorems for Non-Transitive Relations",
    "descriptor": "",
    "authors": [
      "J\u00e9r\u00e9my Dubut",
      "Akihisa Yamada"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2009.13065"
  },
  {
    "id": "arXiv:2010.03393",
    "title": "Complexity of the list homomorphism problem in hereditary graph classes",
    "abstract": "Complexity of the list homomorphism problem in hereditary graph classes",
    "descriptor": "",
    "authors": [
      "Karolina Okrasa",
      "Pawe\u0142 Rz\u0105\u017cewski"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2010.03393"
  },
  {
    "id": "arXiv:2010.06835",
    "title": "A Wrong Answer or a Wrong Question? An Intricate Relationship between  Question Reformulation and Answer Selection in Conversational Question  Answering",
    "abstract": "Comments: Accepted at the Workshop on Search-Oriented Conversational AI (SCAI) 2020. Code for error analysis: this https URL arXiv admin note: text overlap with arXiv:2004.14652",
    "descriptor": "\nComments: Accepted at the Workshop on Search-Oriented Conversational AI (SCAI) 2020. Code for error analysis: this https URL arXiv admin note: text overlap with arXiv:2004.14652\n",
    "authors": [
      "Svitlana Vakulenko",
      "Shayne Longpre",
      "Zhucheng Tu",
      "Raviteja Anantha"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2010.06835"
  },
  {
    "id": "arXiv:2010.11175",
    "title": "Build Smart Grids on Artificial Intelligence -- A Real-world Example",
    "abstract": "Comments: 19 pages, 24 figures",
    "descriptor": "\nComments: 19 pages, 24 figures\n",
    "authors": [
      "Shutang You",
      "Yilu Liu",
      "Hongyu Li",
      "Shengyuan Liu",
      "Kaiqi Sun",
      "Yinfeng Zhao",
      "Huangqing Xiao",
      "Jiaojiao Dong",
      "Yu Su",
      "Weikang Wang",
      "Yi Cui"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2010.11175"
  },
  {
    "id": "arXiv:2010.13972",
    "title": "GPUTreeShap: Massively Parallel Exact Calculation of SHAP Scores for  Tree Ensembles",
    "abstract": "GPUTreeShap: Massively Parallel Exact Calculation of SHAP Scores for  Tree Ensembles",
    "descriptor": "",
    "authors": [
      "Rory Mitchell",
      "Eibe Frank",
      "Geoffrey Holmes"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2010.13972"
  },
  {
    "id": "arXiv:2011.10682",
    "title": "Continuous-Time Convergence Rates in Potential and Monotone Games",
    "abstract": "Comments: 20 pages, 5 figures, manuscript submitted to SIAM Journal on Control and Optimization (SICON) for possible publication",
    "descriptor": "\nComments: 20 pages, 5 figures, manuscript submitted to SIAM Journal on Control and Optimization (SICON) for possible publication\n",
    "authors": [
      "Bolin Gao",
      "Lacra Pavel"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computer Science and Game Theory (cs.GT)",
      "Multiagent Systems (cs.MA)",
      "Systems and Control (eess.SY)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2011.10682"
  },
  {
    "id": "arXiv:2011.13396",
    "title": "Debug-Localize-Repair: A Symbiotic Construction for Heap Manipulations",
    "abstract": "Comments: Accepted at Formal Methods in System Design",
    "descriptor": "\nComments: Accepted at Formal Methods in System Design\n",
    "authors": [
      "Sahil Verma",
      "Subhajit Roy"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2011.13396"
  },
  {
    "id": "arXiv:2012.01847",
    "title": "String Diagram Rewrite Theory I: Rewriting with Frobenius Structure",
    "abstract": "String Diagram Rewrite Theory I: Rewriting with Frobenius Structure",
    "descriptor": "",
    "authors": [
      "Filippo Bonchi",
      "Fabio Gadducci",
      "Aleks Kissinger",
      "Pawel Sobocinski",
      "Fabio Zanasi"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Category Theory (math.CT)"
    ],
    "url": "https://arxiv.org/abs/2012.01847"
  },
  {
    "id": "arXiv:2101.01027",
    "title": "A splitting method for SDEs with locally Lipschitz drift: Illustration  on the FitzHugh-Nagumo model",
    "abstract": "Comments: 38 pages, 10 figures",
    "descriptor": "\nComments: 38 pages, 10 figures\n",
    "authors": [
      "Evelyn Buckwar",
      "Adeline Samson",
      "Massimiliano Tamborrino",
      "Irene Tubikanec"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Dynamical Systems (math.DS)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2101.01027"
  },
  {
    "id": "arXiv:2101.08611",
    "title": "General Decidability Results for Asynchronous Shared-Memory Programs:  Higher-Order and Beyond",
    "abstract": "General Decidability Results for Asynchronous Shared-Memory Programs:  Higher-Order and Beyond",
    "descriptor": "",
    "authors": [
      "Rupak Majumdar",
      "Ramanathan S. Thinniyam",
      "Georg Zetzsche"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2101.08611"
  },
  {
    "id": "arXiv:2102.01048",
    "title": "Secrecy: Secure collaborative analytics on secret-shared data",
    "abstract": "Secrecy: Secure collaborative analytics on secret-shared data",
    "descriptor": "",
    "authors": [
      "John Liagouris",
      "Vasiliki Kalavri",
      "Muhammad Faisal",
      "Mayank Varia"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2102.01048"
  },
  {
    "id": "arXiv:2102.01934",
    "title": "Noise-robust classification with hypergraph neural network",
    "abstract": "Comments: There are some errors in the experiments. I will re-submit it later",
    "descriptor": "\nComments: There are some errors in the experiments. I will re-submit it later\n",
    "authors": [
      "Nguyen Trinh Vu Dang",
      "Loc Tran",
      "Linh Tran"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.01934"
  },
  {
    "id": "arXiv:2102.02170",
    "title": "Interaction with an obstacle in the 2d focusing nonlinear Schr\u00f6dinger  equation",
    "abstract": "Interaction with an obstacle in the 2d focusing nonlinear Schr\u00f6dinger  equation",
    "descriptor": "",
    "authors": [
      "Oussama Landoulsi",
      "Svetlana Roudenko",
      "Kai Yang"
    ],
    "subjectives": [
      "Analysis of PDEs (math.AP)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2102.02170"
  },
  {
    "id": "arXiv:2102.02696",
    "title": "Active Boundary Loss for Semantic Segmentation",
    "abstract": "Comments: 7 pages, 6 figures; Accepted by AAAI 2022",
    "descriptor": "\nComments: 7 pages, 6 figures; Accepted by AAAI 2022\n",
    "authors": [
      "Chi Wang",
      "Yunke Zhang",
      "Miaomiao Cui",
      "Peiran Ren",
      "Yin Yang",
      "Xuansong Xie",
      "XianSheng Hua",
      "Hujun Bao",
      "Weiwei Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2102.02696"
  },
  {
    "id": "arXiv:2102.02705",
    "title": "EFloat: Entropy-coded Floating Point Format for Compressing Vector  Embedding Models",
    "abstract": "EFloat: Entropy-coded Floating Point Format for Compressing Vector  Embedding Models",
    "descriptor": "",
    "authors": [
      "Rajesh Bordawekar",
      "Bulent Abali",
      "Ming-Hung Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2102.02705"
  },
  {
    "id": "arXiv:2102.07389",
    "title": "And/or trade-off in artificial neurons: impact on adversarial robustness",
    "abstract": "And/or trade-off in artificial neurons: impact on adversarial robustness",
    "descriptor": "",
    "authors": [
      "Alessandro Fontana"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2102.07389"
  },
  {
    "id": "arXiv:2102.07869",
    "title": "Technical Report -- Expected Exploitability: Predicting the Development  of Functional Vulnerability Exploits",
    "abstract": "Technical Report -- Expected Exploitability: Predicting the Development  of Functional Vulnerability Exploits",
    "descriptor": "",
    "authors": [
      "Octavian Suciu",
      "Connor Nelson",
      "Zhuoer Lyu",
      "Tiffany Bao",
      "Tudor Dumitras"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2102.07869"
  },
  {
    "id": "arXiv:2102.09631",
    "title": "Peering Beyond the Gradient Veil with Distributed Auto Differentiation",
    "abstract": "Comments: 8 pages, 6 figures",
    "descriptor": "\nComments: 8 pages, 6 figures\n",
    "authors": [
      "Bradley T. Baker",
      "Aashis Khanal",
      "Vince D. Calhoun",
      "Barak Pearlmutter",
      "Sergey M. Plis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2102.09631"
  },
  {
    "id": "arXiv:2103.01710",
    "title": "Autobahn: Automorphism-based Graph Neural Nets",
    "abstract": "Comments: 10 pages, 5 figures",
    "descriptor": "\nComments: 10 pages, 5 figures\n",
    "authors": [
      "Erik Henning Thiede",
      "Wenda Zhou",
      "Risi Kondor"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.01710"
  },
  {
    "id": "arXiv:2103.07853",
    "title": "Membership Inference Attacks on Machine Learning: A Survey",
    "abstract": "Comments: Accepted by ACM Computing Surveys",
    "descriptor": "\nComments: Accepted by ACM Computing Surveys\n",
    "authors": [
      "Hongsheng Hu",
      "Zoran Salcic",
      "Lichao Sun",
      "Gillian Dobbie",
      "Philip S. Yu",
      "Xuyun Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2103.07853"
  },
  {
    "id": "arXiv:2103.08930",
    "title": "Time-dependent electromagnetic scattering from thin layers",
    "abstract": "Time-dependent electromagnetic scattering from thin layers",
    "descriptor": "",
    "authors": [
      "J\u00f6rg Nick",
      "Bal\u00e1zs Kov\u00e1cs",
      "Christian Lubich"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2103.08930"
  },
  {
    "id": "arXiv:2103.13466",
    "title": "Asymptotic Freeness of Layerwise Jacobians Caused by Invariance of  Multilayer Perceptron: The Haar Orthogonal Case",
    "abstract": "Comments: Any comments are welcomed. In v4, we changed notations for readability",
    "descriptor": "\nComments: Any comments are welcomed. In v4, we changed notations for readability\n",
    "authors": [
      "Benoit Collins",
      "Tomohiro Hayase"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Mathematical Physics (math-ph)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2103.13466"
  },
  {
    "id": "arXiv:2103.15449",
    "title": "Automated freezing of gait assessment with marker-based motion capture  and multi-stage spatial-temporal graph convolutional neural networks",
    "abstract": "Automated freezing of gait assessment with marker-based motion capture  and multi-stage spatial-temporal graph convolutional neural networks",
    "descriptor": "",
    "authors": [
      "Benjamin Filtjens",
      "Pieter Ginis",
      "Alice Nieuwboer",
      "Peter Slaets",
      "Bart Vanrumste"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.15449"
  },
  {
    "id": "arXiv:2103.16440",
    "title": "Neural Transformation Learning for Deep Anomaly Detection Beyond Images",
    "abstract": "Neural Transformation Learning for Deep Anomaly Detection Beyond Images",
    "descriptor": "",
    "authors": [
      "Chen Qiu",
      "Timo Pfrommer",
      "Marius Kloft",
      "Stephan Mandt",
      "Maja Rudolph"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2103.16440"
  },
  {
    "id": "arXiv:2103.16720",
    "title": "How to hunt wild constants",
    "abstract": "Comments: 39 pages, 3 figures",
    "descriptor": "\nComments: 39 pages, 3 figures\n",
    "authors": [
      "David R. Stoutemyer"
    ],
    "subjectives": [
      "Symbolic Computation (cs.SC)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2103.16720"
  },
  {
    "id": "arXiv:2104.03634",
    "title": "CineMPC: Controlling Camera Intrinsics and Extrinsics for Autonomous  Cinematography",
    "abstract": "CineMPC: Controlling Camera Intrinsics and Extrinsics for Autonomous  Cinematography",
    "descriptor": "",
    "authors": [
      "Pablo Pueyo",
      "Eduardo Montijano",
      "Ana C. Murillo",
      "Mac Schwager"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2104.03634"
  },
  {
    "id": "arXiv:2104.09237",
    "title": "Inverse Bayesian Optimization: Learning Human Acquisition Functions in  an Exploration vs Exploitation Search Task",
    "abstract": "Comments: 24 pages, 10 figures, 5 appendices",
    "descriptor": "\nComments: 24 pages, 10 figures, 5 appendices\n",
    "authors": [
      "Nathan Sandholtz",
      "Yohsuke Miyamoto",
      "Luke Bornn",
      "Maurice Smith"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Applications (stat.AP)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2104.09237"
  },
  {
    "id": "arXiv:2104.12199",
    "title": "Sampling Permutations for Shapley Value Estimation",
    "abstract": "Comments: 33 pages, 13 figures",
    "descriptor": "\nComments: 33 pages, 13 figures\n",
    "authors": [
      "Rory Mitchell",
      "Joshua Cooper",
      "Eibe Frank",
      "Geoffrey Holmes"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2104.12199"
  },
  {
    "id": "arXiv:2105.02103",
    "title": "Prototype Memory for Large-scale Face Representation Learning",
    "abstract": "Prototype Memory for Large-scale Face Representation Learning",
    "descriptor": "",
    "authors": [
      "Evgeny Smirnov",
      "Nikita Garaev",
      "Vasiliy Galyuk",
      "Evgeny Lukyanets"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.02103"
  },
  {
    "id": "arXiv:2105.02522",
    "title": "Neural graphical modelling in continuous-time: consistency guarantees  and algorithms",
    "abstract": "Neural graphical modelling in continuous-time: consistency guarantees  and algorithms",
    "descriptor": "",
    "authors": [
      "Alexis Bellot",
      "Kim Branson",
      "Mihaela van der Schaar"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2105.02522"
  },
  {
    "id": "arXiv:2105.07066",
    "title": "Node Selection Toward Faster Convergence for Federated Learning on  Non-IID Data",
    "abstract": "Node Selection Toward Faster Convergence for Federated Learning on  Non-IID Data",
    "descriptor": "",
    "authors": [
      "Hongda Wu",
      "Ping Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.07066"
  },
  {
    "id": "arXiv:2105.08170",
    "title": "Zero Dynamics, Pendulum Models, and Angular Momentum in Feedback Control  of Bipedal Locomotion",
    "abstract": "Comments: 20 pages, 14 figures. arXiv admin note: text overlap with arXiv:2008.10763",
    "descriptor": "\nComments: 20 pages, 14 figures. arXiv admin note: text overlap with arXiv:2008.10763\n",
    "authors": [
      "Yukai Gong",
      "Jessy Grizzle"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2105.08170"
  },
  {
    "id": "arXiv:2105.14172",
    "title": "A Stochastic Alternating Balance $k$-Means Algorithm for Fair Clustering",
    "abstract": "A Stochastic Alternating Balance $k$-Means Algorithm for Fair Clustering",
    "descriptor": "",
    "authors": [
      "Suyun Liu",
      "Luis Nunes Vicente"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.14172"
  },
  {
    "id": "arXiv:2105.14933",
    "title": "The use of Generative Adversarial Networks to characterise new physics  in multi-lepton final states at the LHC",
    "abstract": "Comments: 18 pages, 5 figures, 1 table, journal (JHEP)",
    "descriptor": "\nComments: 18 pages, 5 figures, 1 table, journal (JHEP)\n",
    "authors": [
      "Thabang Lebese",
      "Xifeng Ruan"
    ],
    "subjectives": [
      "High Energy Physics - Phenomenology (hep-ph)",
      "Machine Learning (cs.LG)",
      "High Energy Physics - Experiment (hep-ex)"
    ],
    "url": "https://arxiv.org/abs/2105.14933"
  },
  {
    "id": "arXiv:2106.00215",
    "title": "Necessary conditions for feedback stabilization and safety",
    "abstract": "Comments: 32 pages, 6 figures; added 2 figures, 1 example, and references brought to our attention by Rohit Gupta",
    "descriptor": "\nComments: 32 pages, 6 figures; added 2 figures, 1 example, and references brought to our attention by Rohit Gupta\n",
    "authors": [
      "Matthew D. Kvalheim",
      "Daniel E. Koditschek"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Robotics (cs.RO)",
      "Mathematical Physics (math-ph)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2106.00215"
  },
  {
    "id": "arXiv:2106.01182",
    "title": "Automating Speedrun Routing: Overview and Vision",
    "abstract": "Comments: 16 pages, submitted and accepted to the Special Session on Soft Computing Applied to Games of EvoApplications 2022 as part of EvoStar 2022, to be published in its proceedings",
    "descriptor": "\nComments: 16 pages, submitted and accepted to the Special Session on Soft Computing Applied to Games of EvoApplications 2022 as part of EvoStar 2022, to be published in its proceedings\n",
    "authors": [
      "Matthias Gro\u00df",
      "Dietlind Z\u00fchlke",
      "Boris Naujoks"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2106.01182"
  },
  {
    "id": "arXiv:2106.01987",
    "title": "PRINS: Scalable Model Inference for Component-based System Logs",
    "abstract": "Comments: To appear in Empirical Software Engineering",
    "descriptor": "\nComments: To appear in Empirical Software Engineering\n",
    "authors": [
      "Donghwan Shin",
      "Domenico Bianculli",
      "Lionel Briand"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2106.01987"
  },
  {
    "id": "arXiv:2106.03186",
    "title": "Reverse Engineering the Neural Tangent Kernel",
    "abstract": "Comments: 13 pages, 5 figures",
    "descriptor": "\nComments: 13 pages, 5 figures\n",
    "authors": [
      "James B. Simon",
      "Sajant Anand",
      "Michael R. DeWeese"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.03186"
  },
  {
    "id": "arXiv:2106.04149",
    "title": "To Smooth or Not? When Label Smoothing Meets Noisy Labels",
    "abstract": "Comments: Under Review",
    "descriptor": "\nComments: Under Review\n",
    "authors": [
      "Jiaheng Wei",
      "Hangyu Liu",
      "Tongliang Liu",
      "Gang Niu",
      "Yang Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.04149"
  },
  {
    "id": "arXiv:2106.05418",
    "title": "Probing transfer learning with a model of synthetic correlated datasets",
    "abstract": "Probing transfer learning with a model of synthetic correlated datasets",
    "descriptor": "",
    "authors": [
      "Federica Gerace",
      "Luca Saglietti",
      "Stefano Sarao Mannelli",
      "Andrew Saxe",
      "Lenka Zdeborov\u00e1"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)"
    ],
    "url": "https://arxiv.org/abs/2106.05418"
  },
  {
    "id": "arXiv:2106.06161",
    "title": "Bandwidth-Optimal Random Shuffling for GPUs",
    "abstract": "Bandwidth-Optimal Random Shuffling for GPUs",
    "descriptor": "",
    "authors": [
      "Rory Mitchell",
      "Daniel Stokes",
      "Eibe Frank",
      "Geoffrey Holmes"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2106.06161"
  },
  {
    "id": "arXiv:2106.07951",
    "title": "Maximal regularity of backward difference time discretization for  evolving surface PDEs and its application to nonlinear problems",
    "abstract": "Maximal regularity of backward difference time discretization for  evolving surface PDEs and its application to nonlinear problems",
    "descriptor": "",
    "authors": [
      "Bal\u00e1zs Kov\u00e1cs",
      "Buyang Li"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.07951"
  },
  {
    "id": "arXiv:2106.08161",
    "title": "Contrastive Mixture of Posteriors for Counterfactual Inference, Data  Integration and Fairness",
    "abstract": "Contrastive Mixture of Posteriors for Counterfactual Inference, Data  Integration and Fairness",
    "descriptor": "",
    "authors": [
      "Adam Foster",
      "\u00c1rpi Vez\u00e9r",
      "Craig A Glastonbury",
      "P\u00e1id\u00ed Creed",
      "Sam Abujudeh",
      "Aaron Sim"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Genomics (q-bio.GN)"
    ],
    "url": "https://arxiv.org/abs/2106.08161"
  },
  {
    "id": "arXiv:2106.08902",
    "title": "Adaptive Clustering and Personalization in Multi-Agent Stochastic Linear  Bandits",
    "abstract": "Comments: 25 pages, 8 figures",
    "descriptor": "\nComments: 25 pages, 8 figures\n",
    "authors": [
      "Avishek Ghosh",
      "Abishek Sankararaman",
      "Kannan Ramchandran"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.08902"
  },
  {
    "id": "arXiv:2106.10466",
    "title": "TS2Vec: Towards Universal Representation of Time Series",
    "abstract": "Comments: Appears in AAAI-2022",
    "descriptor": "\nComments: Appears in AAAI-2022\n",
    "authors": [
      "Zhihan Yue",
      "Yujing Wang",
      "Juanyong Duan",
      "Tianmeng Yang",
      "Congrui Huang",
      "Yunhai Tong",
      "Bixiong Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.10466"
  },
  {
    "id": "arXiv:2106.10771",
    "title": "Multirate Training of Neural Networks",
    "abstract": "Multirate Training of Neural Networks",
    "descriptor": "",
    "authors": [
      "Tiffany Vlaar",
      "Benedict Leimkuhler"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.10771"
  },
  {
    "id": "arXiv:2106.10887",
    "title": "Trust It or Not: Confidence-Guided Automatic Radiology Report Generation",
    "abstract": "Comments: 12 pages",
    "descriptor": "\nComments: 12 pages\n",
    "authors": [
      "Yixin Wang",
      "Zihao Lin",
      "Zhe Xu",
      "Haoyu Dong",
      "Jiang Tian",
      "Jie Luo",
      "Zhongchao Shi",
      "Yang Zhang",
      "Jianping Fan",
      "Zhiqiang He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.10887"
  },
  {
    "id": "arXiv:2106.12531",
    "title": "Wavenumber-Division Multiplexing in Line-of-Sight Holographic MIMO  Communications",
    "abstract": "Comments: 32 pages, 12 figures, submitted to IEEE Transactions on Wireless Communications",
    "descriptor": "\nComments: 32 pages, 12 figures, submitted to IEEE Transactions on Wireless Communications\n",
    "authors": [
      "Luca Sanguinetti",
      "Antonio A. D'Amico",
      "Merouane Debbah"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2106.12531"
  },
  {
    "id": "arXiv:2106.12892",
    "title": "Semiring Provenance for B\u00fcchi Games: Strategy Analysis with Absorptive  Polynomials",
    "abstract": "Comments: Full version of a paper at GandALF 2021, see arXiv:2109.08327 . Submitted to GandALF 2021 Special Issue on LMCS",
    "descriptor": "\nComments: Full version of a paper at GandALF 2021, see arXiv:2109.08327 . Submitted to GandALF 2021 Special Issue on LMCS\n",
    "authors": [
      "Erich Gr\u00e4del",
      "Niels L\u00fccking",
      "Matthias Naaf"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2106.12892"
  },
  {
    "id": "arXiv:2106.16004",
    "title": "What can linear interpolation of neural network loss landscapes tell us?",
    "abstract": "What can linear interpolation of neural network loss landscapes tell us?",
    "descriptor": "",
    "authors": [
      "Tiffany Vlaar",
      "Jonathan Frankle"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.16004"
  },
  {
    "id": "arXiv:2107.02434",
    "title": "Self-Adversarial Training incorporating Forgery Attention for Image  Forgery Localization",
    "abstract": "Comments: accepted by TIFS",
    "descriptor": "\nComments: accepted by TIFS\n",
    "authors": [
      "Long Zhuo",
      "Shunquan Tan",
      "Bin Li",
      "Jiwu Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2107.02434"
  },
  {
    "id": "arXiv:2107.03311",
    "title": "RoFL: Attestable Robustness for Secure Federated Learning",
    "abstract": "Comments: 21 pages, 21 figures",
    "descriptor": "\nComments: 21 pages, 21 figures\n",
    "authors": [
      "Lukas Burkhalter",
      "Hidde Lycklama",
      "Alexander Viand",
      "Nicolas K\u00fcchler",
      "Anwar Hithnawi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.03311"
  },
  {
    "id": "arXiv:2107.05802",
    "title": "How many degrees of freedom do we need to train deep networks: a loss  landscape perspective",
    "abstract": "Comments: ICLR 2022",
    "descriptor": "\nComments: ICLR 2022\n",
    "authors": [
      "Brett W. Larsen",
      "Stanislav Fort",
      "Nic Becker",
      "Surya Ganguli"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.05802"
  },
  {
    "id": "arXiv:2107.07056",
    "title": "Learning Sparse Interaction Graphs of Partially Detected Pedestrians for  Trajectory Prediction",
    "abstract": "Comments: 8 pages, 6 figures, Accepted by RA-L with ICRA 2022 presentation option",
    "descriptor": "\nComments: 8 pages, 6 figures, Accepted by RA-L with ICRA 2022 presentation option\n",
    "authors": [
      "Zhe Huang",
      "Ruohua Li",
      "Kazuki Shin",
      "Katherine Driggs-Campbell"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.07056"
  },
  {
    "id": "arXiv:2107.07699",
    "title": "A Comparative Study of Deep Learning Classification Methods on a Small  Environmental Microorganism Image Dataset (EMDS-6): from Convolutional Neural  Networks to Visual Transformers",
    "abstract": "A Comparative Study of Deep Learning Classification Methods on a Small  Environmental Microorganism Image Dataset (EMDS-6): from Convolutional Neural  Networks to Visual Transformers",
    "descriptor": "",
    "authors": [
      "Peng Zhao",
      "Chen Li",
      "Md Mamunur Rahaman",
      "Hao Xu",
      "Hechen Yang",
      "Hongzan Sun",
      "Tao Jiang",
      "Marcin Grzegorzek"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.07699"
  },
  {
    "id": "arXiv:2107.09110",
    "title": "OnlineSTL: Scaling Time Series Decomposition by 100x",
    "abstract": "Comments: 8 pages, 9 figures, vldb submission",
    "descriptor": "\nComments: 8 pages, 9 figures, vldb submission\n",
    "authors": [
      "Abhinav Mishra",
      "Ram Sriharsha",
      "Sichen Zhong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2107.09110"
  },
  {
    "id": "arXiv:2107.10577",
    "title": "A convergent finite element algorithm for mean curvature flow in  arbitrary codimension",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:1805.06667, arXiv:2010.11044, arXiv:1912.05924",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:1805.06667, arXiv:2010.11044, arXiv:1912.05924\n",
    "authors": [
      "Tim Binz",
      "Bal\u00e1zs Kov\u00e1cs"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2107.10577"
  },
  {
    "id": "arXiv:2107.12482",
    "title": "An Adaptive Control Algorithm for Quadruped Locomotion with  Proprioceptive Linear Legs",
    "abstract": "An Adaptive Control Algorithm for Quadruped Locomotion with  Proprioceptive Linear Legs",
    "descriptor": "",
    "authors": [
      "Bingchen Jin",
      "Yueheng Zhou",
      "Ye Zhao",
      "Ming Liu",
      "Chaoyang Song",
      "Jianwen Luo"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2107.12482"
  },
  {
    "id": "arXiv:2107.13055",
    "title": "Thrust Direction Control of an Underactuated Oscillating Swimming Robot",
    "abstract": "Comments: 6 pages. Published in and presented at the 2021 IEE/RSJ International Conference on Intelligent Robots and Systems",
    "descriptor": "\nComments: 6 pages. Published in and presented at the 2021 IEE/RSJ International Conference on Intelligent Robots and Systems\n",
    "authors": [
      "Gedaliah Knizhnik",
      "Mark Yim"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2107.13055"
  },
  {
    "id": "arXiv:2107.14513",
    "title": "Error Estimates for Adaptive Spectral Decompositions",
    "abstract": "Error Estimates for Adaptive Spectral Decompositions",
    "descriptor": "",
    "authors": [
      "Daniel H. Baffet",
      "Yannik G. Gleichmann",
      "Marcus J. Grote"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)"
    ],
    "url": "https://arxiv.org/abs/2107.14513"
  },
  {
    "id": "arXiv:2108.00303",
    "title": "Practical Adoption of Cloud Computing in Power Systems- Drivers,  Challenges, Guidance, and Real-world Use Cases",
    "abstract": "Practical Adoption of Cloud Computing in Power Systems- Drivers,  Challenges, Guidance, and Real-world Use Cases",
    "descriptor": "",
    "authors": [
      "Song Zhang",
      "Amritanshu Pandey",
      "Xiaochuan Luo",
      "Maggy Powell",
      "Ranjan Banerji",
      "Lei Fan",
      "Abhineet Parchure",
      "Edgardo Luzcando"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2108.00303"
  },
  {
    "id": "arXiv:2108.02234",
    "title": "Multi-Branch with Attention Network for Hand-Based Person Recognition",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:2101.05260",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2101.05260\n",
    "authors": [
      "Nathanael L. Baisa",
      "Bryan Williams",
      "Hossein Rahmani",
      "Plamen Angelov",
      "Sue Black"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.02234"
  },
  {
    "id": "arXiv:2108.03033",
    "title": "Nonground Abductive Logic Programming with Probabilistic Integrity  Constraints",
    "abstract": "Comments: Paper presented at the 37th International Conference on Logic Programming (ICLP 2021), 16 pages",
    "descriptor": "\nComments: Paper presented at the 37th International Conference on Logic Programming (ICLP 2021), 16 pages\n",
    "authors": [
      "Elena Bellodi",
      "Marco Gavanelli",
      "Riccardo Zese",
      "Evelina Lamma",
      "Fabrizio Riguzzi"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2108.03033"
  },
  {
    "id": "arXiv:2108.04382",
    "title": "The projection onto the cross",
    "abstract": "The projection onto the cross",
    "descriptor": "",
    "authors": [
      "Heinz H. Bauschke",
      "Manish Krishan Lal",
      "Xianfu Wang"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Functional Analysis (math.FA)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2108.04382"
  },
  {
    "id": "arXiv:2108.08230",
    "title": "Predicting Dynamic Stability of Power Grids using Graph Neural Networks",
    "abstract": "Comments: 8 pages, 13 pages including appendix, 31 pictures plus tikz pictures",
    "descriptor": "\nComments: 8 pages, 13 pages including appendix, 31 pictures plus tikz pictures\n",
    "authors": [
      "Christian Nauck",
      "Michael Lindner",
      "Konstantin Sch\u00fcrholt",
      "Haoming Zhang",
      "Paul Schultz",
      "J\u00fcrgen Kurths",
      "Ingrid Isenhardt",
      "Frank Hellmann"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2108.08230"
  },
  {
    "id": "arXiv:2108.09184",
    "title": "New binary self-dual codes of lengths 56, 62, 78, 92 and 94 from a  bordered construction",
    "abstract": "Comments: corrected typos; other minor corrections. arXiv admin note: substantial text overlap with arXiv:2102.10354, arXiv:2106.12355, arXiv:2102.12326",
    "descriptor": "\nComments: corrected typos; other minor corrections. arXiv admin note: substantial text overlap with arXiv:2102.10354, arXiv:2106.12355, arXiv:2102.12326\n",
    "authors": [
      "Joe Gildea",
      "Adrian Korban",
      "Adam Michael Roberts",
      "Alexander Tylyshchak"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2108.09184"
  },
  {
    "id": "arXiv:2108.10869",
    "title": "DROID-SLAM: Deep Visual SLAM for Monocular, Stereo, and RGB-D Cameras",
    "abstract": "DROID-SLAM: Deep Visual SLAM for Monocular, Stereo, and RGB-D Cameras",
    "descriptor": "",
    "authors": [
      "Zachary Teed",
      "Jia Deng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.10869"
  },
  {
    "id": "arXiv:2109.00407",
    "title": "Linear Fractional Transformation modeling of multibody dynamics around  parameter-dependent equilibrium",
    "abstract": "Linear Fractional Transformation modeling of multibody dynamics around  parameter-dependent equilibrium",
    "descriptor": "",
    "authors": [
      "Ervan Kassarian",
      "Francesco Sanfedino",
      "Daniel Alazard",
      "Charles-Antoine Chevrier",
      "Johan Montel"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2109.00407"
  },
  {
    "id": "arXiv:2109.01262",
    "title": "On the Accuracy of Analog Neural Network Inference Accelerators",
    "abstract": "Comments: Changes in v3: modified definition of state-independent error (factor of 2) for fairer comparison to state-proportional. Added more results on INT4 network",
    "descriptor": "\nComments: Changes in v3: modified definition of state-independent error (factor of 2) for fairer comparison to state-proportional. Added more results on INT4 network\n",
    "authors": [
      "T. Patrick Xiao",
      "Ben Feinberg",
      "Christopher H. Bennett",
      "Venkatraman Prabhakar",
      "Prashant Saxena",
      "Vineet Agrawal",
      "Sapan Agarwal",
      "Matthew J. Marinella"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.01262"
  },
  {
    "id": "arXiv:2109.02618",
    "title": "Bridging the Gap between Events and Frames through Unsupervised Domain  Adaptation",
    "abstract": "Bridging the Gap between Events and Frames through Unsupervised Domain  Adaptation",
    "descriptor": "",
    "authors": [
      "Nico Messikommer",
      "Daniel Gehrig",
      "Mathias Gehrig",
      "Davide Scaramuzza"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.02618"
  },
  {
    "id": "arXiv:2109.03699",
    "title": "Sample and Communication-Efficient Decentralized Actor-Critic Algorithms  with Finite-Time Analysis",
    "abstract": "Comments: 40 pages, 2 figures",
    "descriptor": "\nComments: 40 pages, 2 figures\n",
    "authors": [
      "Ziyi Chen",
      "Yi Zhou",
      "Rongrong Chen",
      "Shaofeng Zou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.03699"
  },
  {
    "id": "arXiv:2109.04749",
    "title": "A Holistic Approach to Reactive Mobile Manipulation",
    "abstract": "Comments: IEEE Robotics and Automation Letters (RA-L). Preprint Version. Accepted January, 2022. The code and videos can be found at this https URL",
    "descriptor": "\nComments: IEEE Robotics and Automation Letters (RA-L). Preprint Version. Accepted January, 2022. The code and videos can be found at this https URL\n",
    "authors": [
      "Jesse Haviland",
      "Niko S\u00fcnderhauf",
      "Peter Corke"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.04749"
  },
  {
    "id": "arXiv:2109.05759",
    "title": "Global-Local Dynamic Feature Alignment Network for Person  Re-Identification",
    "abstract": "Comments: 28 pages, 8 figures",
    "descriptor": "\nComments: 28 pages, 8 figures\n",
    "authors": [
      "Zhangqiang Ming",
      "Yong Yang",
      "Xiaoyong Wei",
      "Jianrong Yan",
      "Xiangkun Wang",
      "Fengjie Wang",
      "Min Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.05759"
  },
  {
    "id": "arXiv:2109.06715",
    "title": "IGNNITION: Bridging the Gap Between Graph Neural Networks and Networking  Systems",
    "abstract": "IGNNITION: Bridging the Gap Between Graph Neural Networks and Networking  Systems",
    "descriptor": "",
    "authors": [
      "David Pujol-Perich",
      "Jos\u00e9 Su\u00e1rez-Varela",
      "Miquel Ferriol",
      "Shihan Xiao",
      "Bo Wu",
      "Albert Cabellos-Aparicio",
      "Pere Barlet-Ros"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2109.06715"
  },
  {
    "id": "arXiv:2109.07744",
    "title": "Disaggregating and Consolidating Network Functionalities with SuperNIC",
    "abstract": "Comments: 17 pages, 22 figures",
    "descriptor": "\nComments: 17 pages, 22 figures\n",
    "authors": [
      "Yizhou Shan",
      "Will Lin",
      "Ryan Kosta",
      "Arvind Krishnamurthy",
      "Yiying Zhang"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2109.07744"
  },
  {
    "id": "arXiv:2109.08080",
    "title": "Non-hyperbolicity at large scales of a high-dimensional chaotic system",
    "abstract": "Comments: 20 pages",
    "descriptor": "\nComments: 20 pages\n",
    "authors": [
      "Caroline L. Wormell"
    ],
    "subjectives": [
      "Chaotic Dynamics (nlin.CD)",
      "Mathematical Physics (math-ph)",
      "Dynamical Systems (math.DS)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2109.08080"
  },
  {
    "id": "arXiv:2109.08265",
    "title": "Stability Analysis of Probabilistic Piecewise Constant Derivative  Systems",
    "abstract": "Comments: 21 pages, 2 figures",
    "descriptor": "\nComments: 21 pages, 2 figures\n",
    "authors": [
      "Spandan Das",
      "Pavithra Prabhakar"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.08265"
  },
  {
    "id": "arXiv:2109.14569",
    "title": "Partitioning Cloud-based Microservices (via Deep Learning)",
    "abstract": "Comments: version 2",
    "descriptor": "\nComments: version 2\n",
    "authors": [
      "Rahul Yedida",
      "Rahul Krishna",
      "Anup Kalia",
      "Tim Menzies",
      "Jin Xiao",
      "Maja Vukovic"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Software Engineering (cs.SE)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2109.14569"
  },
  {
    "id": "arXiv:2110.00269",
    "title": "A Survey of Knowledge Enhanced Pre-trained Models",
    "abstract": "Comments: 16 pages, 11 figures",
    "descriptor": "\nComments: 16 pages, 11 figures\n",
    "authors": [
      "Jian Yang",
      "Gang Xiao",
      "Yulong Shen",
      "Wei Jiang",
      "Xinyu Hu",
      "Ying Zhang",
      "Jinghui Peng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.00269"
  },
  {
    "id": "arXiv:2110.02375",
    "title": "Interpreting intermediate convolutional layers in unsupervised acoustic  word classification",
    "abstract": "Comments: ICASSP 2022",
    "descriptor": "\nComments: ICASSP 2022\n",
    "authors": [
      "Ga\u0161per Begu\u0161",
      "Alan Zhou"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.02375"
  },
  {
    "id": "arXiv:2110.02798",
    "title": "Dynamics of hot random hyperbolic graphs",
    "abstract": "Dynamics of hot random hyperbolic graphs",
    "descriptor": "",
    "authors": [
      "Fragkiskos Papadopoulos",
      "Sofoclis Zambirinis"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Social and Information Networks (cs.SI)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2110.02798"
  },
  {
    "id": "arXiv:2110.04703",
    "title": "Selectable Set Randomized Kaczmarz",
    "abstract": "Selectable Set Randomized Kaczmarz",
    "descriptor": "",
    "authors": [
      "Yotam Yaniv",
      "Jacob D. Moorman",
      "William Swartworth",
      "Thomas Tu",
      "Daji Landis",
      "Deanna Needell"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.04703"
  },
  {
    "id": "arXiv:2110.06765",
    "title": "libdlr: Efficient imaginary time calculations using the discrete Lehmann  representation",
    "abstract": "libdlr: Efficient imaginary time calculations using the discrete Lehmann  representation",
    "descriptor": "",
    "authors": [
      "Jason Kaye",
      "Kun Chen",
      "Hugo U. R. Strand"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Strongly Correlated Electrons (cond-mat.str-el)",
      "Mathematical Software (cs.MS)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.06765"
  },
  {
    "id": "arXiv:2110.06914",
    "title": "What Happens after SGD Reaches Zero Loss? --A Mathematical Framework",
    "abstract": "Comments: 56 pages, 2 figures",
    "descriptor": "\nComments: 56 pages, 2 figures\n",
    "authors": [
      "Zhiyuan Li",
      "Tianhao Wang",
      "Sanjeev Arora"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.06914"
  },
  {
    "id": "arXiv:2110.07262",
    "title": "Proactive Mobility Management of UEs using Sequence-to-Sequence Modeling",
    "abstract": "Comments: Submitted to ICC 2022",
    "descriptor": "\nComments: Submitted to ICC 2022\n",
    "authors": [
      "Vijaya Yajnanarayana"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2110.07262"
  },
  {
    "id": "arXiv:2110.07570",
    "title": "MGC: A Complex-Valued Graph Convolutional Network for Directed Graphs",
    "abstract": "Comments: 11 pages, 4 figures, 5 tables",
    "descriptor": "\nComments: 11 pages, 4 figures, 5 tables\n",
    "authors": [
      "Jie Zhang",
      "Bo Hui",
      "Po-Wei Harn",
      "Min-Te Sun",
      "Wei-Shinn Ku"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.07570"
  },
  {
    "id": "arXiv:2110.07683",
    "title": "Toward Realistic Backdoor Injection Attacks on DNNs using Rowhammer",
    "abstract": "Toward Realistic Backdoor Injection Attacks on DNNs using Rowhammer",
    "descriptor": "",
    "authors": [
      "M. Caner Tol",
      "Saad Islam",
      "Berk Sunar",
      "Ziming Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.07683"
  },
  {
    "id": "arXiv:2110.09348",
    "title": "Understanding Dimensional Collapse in Contrastive Self-supervised  Learning",
    "abstract": "Comments: In Proceedings of the 10th International Conference on Learning Representations (ICLR) 2022",
    "descriptor": "\nComments: In Proceedings of the 10th International Conference on Learning Representations (ICLR) 2022\n",
    "authors": [
      "Li Jing",
      "Pascal Vincent",
      "Yann LeCun",
      "Yuandong Tian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.09348"
  },
  {
    "id": "arXiv:2110.11285",
    "title": "How to Fairly Allocate Easy and Difficult Chores",
    "abstract": "Comments: Full version of paper published at AAMAS 2022. 33 pages",
    "descriptor": "\nComments: Full version of paper published at AAMAS 2022. 33 pages\n",
    "authors": [
      "Soroush Ebadian",
      "Dominik Peters",
      "Nisarg Shah"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2110.11285"
  },
  {
    "id": "arXiv:2110.12087",
    "title": "Gaussian Process Sampling and Optimization with Approximate Upper and  Lower Bounds",
    "abstract": "Comments: 19 pages",
    "descriptor": "\nComments: 19 pages\n",
    "authors": [
      "Vu Nguyen",
      "Marc Peter Deisenroth",
      "Michael A. Osborne"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.12087"
  },
  {
    "id": "arXiv:2110.13970",
    "title": "Rademacher Random Projections with Tensor Networks",
    "abstract": "Rademacher Random Projections with Tensor Networks",
    "descriptor": "",
    "authors": [
      "Beheshteh T. Rakhshan",
      "Guillaume Rabusseau"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.13970"
  },
  {
    "id": "arXiv:2110.14068",
    "title": "Drawing Robust Scratch Tickets: Subnetworks with Inborn Robustness Are  Found within Randomly Initialized Networks",
    "abstract": "Comments: Accepted at NeurIPS 2021",
    "descriptor": "\nComments: Accepted at NeurIPS 2021\n",
    "authors": [
      "Yonggan Fu",
      "Qixuan Yu",
      "Yang Zhang",
      "Shang Wu",
      "Xu Ouyang",
      "David Cox",
      "Yingyan Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.14068"
  },
  {
    "id": "arXiv:2110.14211",
    "title": "Beamforming Feedback-based Model-Driven Angle of Departure Estimation  Toward Legacy Support in WiFi Sensing: An Experimental Study",
    "abstract": "Comments: Submitted to IEEE Access",
    "descriptor": "\nComments: Submitted to IEEE Access\n",
    "authors": [
      "Sohei Itahara",
      "Sota Kondo",
      "Kota Yamashita",
      "Takayuki Nishio",
      "Koji Yamamoto",
      "Yusuke Koda"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2110.14211"
  },
  {
    "id": "arXiv:2111.01134",
    "title": "Comparing Bayesian Models for Organ Contouring in Head and Neck  Radiotherapy",
    "abstract": "Comments: 10 pages, 5 figures, To be published in \"SPIE Medical Imaging 2022\"",
    "descriptor": "\nComments: 10 pages, 5 figures, To be published in \"SPIE Medical Imaging 2022\"\n",
    "authors": [
      "Prerak Mody",
      "Nicolas Chaves-de-Plaza",
      "Klaus Hildebrandt",
      "Rene van Egmond",
      "Huib de Ridder",
      "Marius Staring"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.01134"
  },
  {
    "id": "arXiv:2111.01690",
    "title": "Recent Advances in End-to-End Automatic Speech Recognition",
    "abstract": "Comments: Accepted at APSIPA Transactions on Signal and Information Processing",
    "descriptor": "\nComments: Accepted at APSIPA Transactions on Signal and Information Processing\n",
    "authors": [
      "Jinyu Li"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2111.01690"
  },
  {
    "id": "arXiv:2111.04163",
    "title": "Quantitative Resilience of Generalized Integrators",
    "abstract": "Comments: arXiv admin note: substantial text overlap with arXiv:2101.12063",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2101.12063\n",
    "authors": [
      "Jean-Baptiste Bouvier",
      "Kathleen Xu",
      "Melkior Ornik"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2111.04163"
  },
  {
    "id": "arXiv:2111.07056",
    "title": "Selection of the Speed Command Distance for Improved Performance of a  Rule-Based VSL and Lane Change Control",
    "abstract": "Comments: 10 pages, 9 figures, 2 tables, submitted to T-ITS",
    "descriptor": "\nComments: 10 pages, 9 figures, 2 tables, submitted to T-ITS\n",
    "authors": [
      "Tianchen Yuan",
      "Faisal Alasiri",
      "Petros A. Ioannou"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2111.07056"
  },
  {
    "id": "arXiv:2111.07250",
    "title": "Metrics and Mechanisms: Measuring the Unmeasurable in the Science of  Science",
    "abstract": "Comments: 20 pages, 1 figure",
    "descriptor": "\nComments: 20 pages, 1 figure\n",
    "authors": [
      "Lingfei Wu",
      "Aniket Kittur",
      "Hyejin Youn",
      "Sta\u0161a Milojevi\u0107",
      "Erin Leahey",
      "Stephen M. Fiore",
      "Yong Yeol Ahn"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2111.07250"
  },
  {
    "id": "arXiv:2111.07769",
    "title": "A Finite-Sampling, Operational Domain Specific, and Provably Unbiased  Connected and Automated Vehicle Safety Metric",
    "abstract": "A Finite-Sampling, Operational Domain Specific, and Provably Unbiased  Connected and Automated Vehicle Safety Metric",
    "descriptor": "",
    "authors": [
      "Bowen Weng",
      "Linda Capito",
      "Umit Ozguner",
      "Keith Redmill"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2111.07769"
  },
  {
    "id": "arXiv:2111.08356",
    "title": "Inference-Time Unlabeled Personalized Federated Learning",
    "abstract": "Inference-Time Unlabeled Personalized Federated Learning",
    "descriptor": "",
    "authors": [
      "Ohad Amosy",
      "Gal Eyal",
      "Gal Chechik"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.08356"
  },
  {
    "id": "arXiv:2111.12281",
    "title": "Locality-based Graph Reordering for Processing Speed-Ups and Impact of  Diameter",
    "abstract": "Comments: 20 pages. Bachelor's thesis",
    "descriptor": "\nComments: 20 pages. Bachelor's thesis\n",
    "authors": [
      "Vedant Satav"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2111.12281"
  },
  {
    "id": "arXiv:2111.15208",
    "title": "HRNET: AI on Edge for mask detection and social distancing",
    "abstract": "HRNET: AI on Edge for mask detection and social distancing",
    "descriptor": "",
    "authors": [
      "Kinshuk Sengupta",
      "Praveen Ranjan Srivastava"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.15208"
  },
  {
    "id": "arXiv:2111.15379",
    "title": "Text classification problems via BERT embedding method and graph  convolutional neural network",
    "abstract": "Comments: There are some errors in the experiments. I will re-submit it later",
    "descriptor": "\nComments: There are some errors in the experiments. I will re-submit it later\n",
    "authors": [
      "Loc Hoang Tran",
      "Tuan Tran",
      "An Mai"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.15379"
  },
  {
    "id": "arXiv:2112.00900",
    "title": "Empirical Game-Theoretic Analysis in Mean Field Games",
    "abstract": "Comments: 9 papes, 3 figures",
    "descriptor": "\nComments: 9 papes, 3 figures\n",
    "authors": [
      "Yongzhao Wang",
      "Michael P. Wellman"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2112.00900"
  },
  {
    "id": "arXiv:2112.02043",
    "title": "Multilingual training for Software Engineering",
    "abstract": "Comments: Accepted at International Conference on Software Engineering (ICSE-2022)",
    "descriptor": "\nComments: Accepted at International Conference on Software Engineering (ICSE-2022)\n",
    "authors": [
      "Toufique Ahmed",
      "Premkumar Devanbu"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.02043"
  },
  {
    "id": "arXiv:2112.03638",
    "title": "Scaling Structured Inference with Randomization",
    "abstract": "Comments: Preprint",
    "descriptor": "\nComments: Preprint\n",
    "authors": [
      "Yao Fu",
      "John P. Cunningham",
      "Mirella Lapata"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Data Structures and Algorithms (cs.DS)",
      "Applications (stat.AP)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.03638"
  },
  {
    "id": "arXiv:2112.05290",
    "title": "Image-to-Image Translation-based Data Augmentation for Robust EV  Charging Inlet Detection",
    "abstract": "Comments: 8 pages",
    "descriptor": "\nComments: 8 pages\n",
    "authors": [
      "Yeonjun Bang",
      "Yeejin Lee",
      "Byeongkeun Kang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.05290"
  },
  {
    "id": "arXiv:2112.05615",
    "title": "Intelligent Transportation Systems Using External Infrastructure: A  Literature Survey",
    "abstract": "Comments: 14 pages, 4 tables, 4 figures",
    "descriptor": "\nComments: 14 pages, 4 tables, 4 figures\n",
    "authors": [
      "Christian Cre\u00df",
      "Alois C. Knoll"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2112.05615"
  },
  {
    "id": "arXiv:2112.05632",
    "title": "Truthful Cake Sharing",
    "abstract": "Comments: Appears in the 36th AAAI Conference on Artificial Intelligence (AAAI), 2022",
    "descriptor": "\nComments: Appears in the 36th AAAI Conference on Artificial Intelligence (AAAI), 2022\n",
    "authors": [
      "Xiaohui Bei",
      "Xinhang Lu",
      "Warut Suksompong"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Theoretical Economics (econ.TH)"
    ],
    "url": "https://arxiv.org/abs/2112.05632"
  },
  {
    "id": "arXiv:2112.05677",
    "title": "Concept Representation Learning with Contrastive Self-Supervised  Learning",
    "abstract": "Concept Representation Learning with Contrastive Self-Supervised  Learning",
    "descriptor": "",
    "authors": [
      "Daniel T. Chang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.05677"
  },
  {
    "id": "arXiv:2112.05911",
    "title": "Learning Contraction Policies from Offline Data",
    "abstract": "Learning Contraction Policies from Offline Data",
    "descriptor": "",
    "authors": [
      "Navid Rezazadeh",
      "Maxwell Kolarich",
      "Solmaz S. Kia",
      "Negar Mehr"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.05911"
  },
  {
    "id": "arXiv:2112.06809",
    "title": "Persistent Object Identification Leveraging Non-Visual Markers",
    "abstract": "Persistent Object Identification Leveraging Non-Visual Markers",
    "descriptor": "",
    "authors": [
      "Michael P. J. Camilleri",
      "Li Zhang",
      "Rasneer S. Bains",
      "Andrew Zisserman",
      "Christopher K. I. Williams"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2112.06809"
  },
  {
    "id": "arXiv:2112.09071",
    "title": "A Deep Learning Based Multitask Network for Respiration Rate Estimation  -- A Practical Perspective",
    "abstract": "Comments: Preprint Only",
    "descriptor": "\nComments: Preprint Only\n",
    "authors": [
      "Kapil Singh Rathore",
      "Sricharan Vijayarangan",
      "Preejith SP",
      "Mohanasankar Sivaprakasam"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.09071"
  },
  {
    "id": "arXiv:2112.11641",
    "title": "JoJoGAN: One Shot Face Stylization",
    "abstract": "Comments: code at this https URL",
    "descriptor": "\nComments: code at this https URL\n",
    "authors": [
      "Min Jin Chong",
      "David Forsyth"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.11641"
  },
  {
    "id": "arXiv:2112.12376",
    "title": "Revisiting and Advancing Fast Adversarial Training Through The Lens of  Bi-Level Optimization",
    "abstract": "Revisiting and Advancing Fast Adversarial Training Through The Lens of  Bi-Level Optimization",
    "descriptor": "",
    "authors": [
      "Yihua Zhang",
      "Guanhua Zhang",
      "Prashant Khanduri",
      "Mingyi Hong",
      "Shiyu Chang",
      "Sijia Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.12376"
  },
  {
    "id": "arXiv:2201.00001",
    "title": "Modeling Advection on Directed Graphs using Mat\u00e9rn Gaussian Processes  for Traffic Flow",
    "abstract": "Comments: Accepted at the Machine Learning and Physical Sciences NeurIPS 2021 Workshop this https URL",
    "descriptor": "\nComments: Accepted at the Machine Learning and Physical Sciences NeurIPS 2021 Workshop this https URL\n",
    "authors": [
      "Danielle C Maddix",
      "Nadim Saad",
      "Yuyang Wang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2201.00001"
  },
  {
    "id": "arXiv:2201.05800",
    "title": "Theoretical and Practical Aspects of Space-Time DG-SEM Implementations",
    "abstract": "Comments: updated 3D experiments, fixed typos",
    "descriptor": "\nComments: updated 3D experiments, fixed typos\n",
    "authors": [
      "Lea M. Versbach",
      "Viktor Linders",
      "Robert Kl\u00f6fkorn",
      "Philipp Birken"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2201.05800"
  },
  {
    "id": "arXiv:2201.08712",
    "title": "Improved Random Features for Dot Product Kernels",
    "abstract": "Comments: 72 pages",
    "descriptor": "\nComments: 72 pages\n",
    "authors": [
      "Jonas Wacker",
      "Motonobu Kanagawa",
      "Maurizio Filippone"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2201.08712"
  },
  {
    "id": "arXiv:2201.10328",
    "title": "ML4CO-KIDA: Knowledge Inheritance in Dataset Aggregation",
    "abstract": "Comments: NeurIPS 2021 ML4CO dual task 1st solution",
    "descriptor": "\nComments: NeurIPS 2021 ML4CO dual task 1st solution\n",
    "authors": [
      "Zixuan Cao",
      "Yang Xu",
      "Zhewei Huang",
      "Shuchang Zhou"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.10328"
  },
  {
    "id": "arXiv:2201.10456",
    "title": "Full abstraction for digital circuits",
    "abstract": "Comments: Reworded section 5, 23 pages, 6 figures",
    "descriptor": "\nComments: Reworded section 5, 23 pages, 6 figures\n",
    "authors": [
      "Dan R. Ghica",
      "George Kaye",
      "David Sprunger"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Programming Languages (cs.PL)",
      "Category Theory (math.CT)"
    ],
    "url": "https://arxiv.org/abs/2201.10456"
  },
  {
    "id": "arXiv:2201.11063",
    "title": "The BrainScaleS-2 accelerated neuromorphic system with hybrid plasticity",
    "abstract": "Comments: 22 pages, 10 figures; amended funding acknowledgements, added one citation",
    "descriptor": "\nComments: 22 pages, 10 figures; amended funding acknowledgements, added one citation\n",
    "authors": [
      "Christian Pehle",
      "Sebastian Billaudelle",
      "Benjamin Cramer",
      "Jakob Kaiser",
      "Korbinian Schreiber",
      "Yannik Stradmann",
      "Johannes Weis",
      "Aron Leibfried",
      "Eric M\u00fcller",
      "Johannes Schemmel"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2201.11063"
  },
  {
    "id": "arXiv:2201.11221",
    "title": "Linear lambda-calculus is linear",
    "abstract": "Comments: 27 pages",
    "descriptor": "\nComments: 27 pages\n",
    "authors": [
      "Alejandro D\u00edaz-Caro",
      "Gilles Dowek"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2201.11221"
  },
  {
    "id": "arXiv:2201.11410",
    "title": "Reinforcement Learning-Empowered Mobile Edge Computing for 6G Edge  Intelligence",
    "abstract": "Comments: 33 pages, 5 figures, 11 tables",
    "descriptor": "\nComments: 33 pages, 5 figures, 11 tables\n",
    "authors": [
      "Peng Wei",
      "Kun Guo",
      "Ye Li",
      "Jue Wang",
      "Wei Feng",
      "Shi Jin",
      "Ning Ge",
      "Ying-Chang Liang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Artificial Intelligence (cs.AI)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2201.11410"
  },
  {
    "id": "arXiv:2201.11650",
    "title": "Incremental Mining of Frequent Serial Episodes Considering Multiple  Occurrence",
    "abstract": "Incremental Mining of Frequent Serial Episodes Considering Multiple  Occurrence",
    "descriptor": "",
    "authors": [
      "Thomas Guyet",
      "Wenbin Zhang",
      "Albert Bifet"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2201.11650"
  },
  {
    "id": "arXiv:2201.11670",
    "title": "Strong Converse Theorem for Source Encryption under Side-Channel Attacks",
    "abstract": "Comments: 9 pages, 6 figures. arXiv admin note: text overlap with arXiv:1801.02563",
    "descriptor": "\nComments: 9 pages, 6 figures. arXiv admin note: text overlap with arXiv:1801.02563\n",
    "authors": [
      "Yasutada Oohama",
      "Bagus Santoso"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2201.11670"
  },
  {
    "id": "arXiv:2201.11840",
    "title": "GC3: An Optimizing Compiler for GPU Collective Communication",
    "abstract": "GC3: An Optimizing Compiler for GPU Collective Communication",
    "descriptor": "",
    "authors": [
      "Meghan Cowan",
      "Saeed Maleki",
      "Madanlal Musuvathi",
      "Olli Saarikivi",
      "Yifan Xiong"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2201.11840"
  },
  {
    "id": "arXiv:2201.12038",
    "title": "A survey on flexible/restricted skyline and their applicability",
    "abstract": "A survey on flexible/restricted skyline and their applicability",
    "descriptor": "",
    "authors": [
      "Davide Canali"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2201.12038"
  },
  {
    "id": "arXiv:2201.12374",
    "title": "On the Kolmogorov Complexity of Binary Classifiers",
    "abstract": "On the Kolmogorov Complexity of Binary Classifiers",
    "descriptor": "",
    "authors": [
      "Samuel Epstein"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2201.12374"
  },
  {
    "id": "arXiv:2201.12674",
    "title": "Rewiring with Positional Encodings for Graph Neural Networks",
    "abstract": "Rewiring with Positional Encodings for Graph Neural Networks",
    "descriptor": "",
    "authors": [
      "Rickard Br\u00fcel-Gabrielsson",
      "Mikhail Yurochkin",
      "Justin Solomon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.12674"
  },
  {
    "id": "arXiv:2201.12733",
    "title": "TPC: Transformation-Specific Smoothing for Point Cloud Models",
    "abstract": "Comments: 18 pages",
    "descriptor": "\nComments: 18 pages\n",
    "authors": [
      "Wenda Chu",
      "Linyi Li",
      "Bo Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.12733"
  },
  {
    "id": "arXiv:2201.12855",
    "title": "Augmented Business Process Management Systems: A Research Manifesto",
    "abstract": "Comments: 19 pages, 1 figure",
    "descriptor": "\nComments: 19 pages, 1 figure\n",
    "authors": [
      "Marlon Dumas",
      "Fabiana Fournier",
      "Lior Limonad",
      "Andrea Marrella",
      "Marco Montali",
      "Jana-Rebecca Rehse",
      "Rafael Accorsi",
      "Diego Calvanese",
      "Giuseppe De Giacomo",
      "Dirk Fahland",
      "Avigdor Gal",
      "Marcello La Rosa",
      "Hagen V\u00f6lzer",
      "Ingo Weber"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2201.12855"
  },
  {
    "id": "arXiv:2201.13195",
    "title": "Memory-Efficient Backpropagation through Large Linear Layers",
    "abstract": "Comments: Submitted",
    "descriptor": "\nComments: Submitted\n",
    "authors": [
      "Daniel Bershatsky",
      "Aleksandr Mikhalev",
      "Alexandr Katrutsa",
      "Julia Gusak",
      "Daniil Merkulov",
      "Ivan Oseledets"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2201.13195"
  },
  {
    "id": "arXiv:2201.13402",
    "title": "Privacy Limitations Of Interest-based Advertising On The Web: A  Post-mortem Empirical Analysis Of Google's FLoC",
    "abstract": "Privacy Limitations Of Interest-based Advertising On The Web: A  Post-mortem Empirical Analysis Of Google's FLoC",
    "descriptor": "",
    "authors": [
      "Alex Berke",
      "Dan Calacci"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2201.13402"
  },
  {
    "id": "arXiv:2202.00063",
    "title": "Efficient Reinforcement Learning in Block MDPs: A Model-free  Representation Learning Approach",
    "abstract": "Efficient Reinforcement Learning in Block MDPs: A Model-free  Representation Learning Approach",
    "descriptor": "",
    "authors": [
      "Xuezhou Zhang",
      "Yuda Song",
      "Masatoshi Uehara",
      "Mengdi Wang",
      "Alekh Agarwal",
      "Wen Sun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.00063"
  },
  {
    "id": "arXiv:2202.00441",
    "title": "Few-Bit Backward: Quantized Gradients of Activation Functions for Memory  Footprint Reduction",
    "abstract": "Comments: Submitted",
    "descriptor": "\nComments: Submitted\n",
    "authors": [
      "Georgii Novikov",
      "Daniel Bershatsky",
      "Julia Gusak",
      "Alex Shonenkov",
      "Denis Dimitrov",
      "Ivan Oseledets"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.00441"
  },
  {
    "id": "arXiv:2202.00448",
    "title": "Sim2Real Object-Centric Keypoint Detection and Description",
    "abstract": "Comments: accepted to AAAI2022",
    "descriptor": "\nComments: accepted to AAAI2022\n",
    "authors": [
      "Chengliang Zhong",
      "Chao Yang",
      "Jinshan Qi",
      "Fuchun Sun",
      "Huaping Liu",
      "Xiaodong Mu",
      "Wenbing Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.00448"
  },
  {
    "id": "arXiv:2202.00450",
    "title": "Approximation of Images via Generalized Higher Order Singular Value  Decomposition over Finite-dimensional Commutative Semisimple Algebra",
    "abstract": "Comments: Generalized matrix theory over a finite-dimensional commutative algebra with applications in image analysis",
    "descriptor": "\nComments: Generalized matrix theory over a finite-dimensional commutative algebra with applications in image analysis\n",
    "authors": [
      "Liang Liao",
      "Sen Lin",
      "Lun Li",
      "Xiuwei Zhang",
      "Song Zhao",
      "Yan Wang",
      "Xinqiang Wang",
      "Qi Gao",
      "Jingyu Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Commutative Algebra (math.AC)",
      "Representation Theory (math.RT)",
      "Spectral Theory (math.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.00450"
  },
  {
    "id": "arXiv:2202.00674",
    "title": "Just Another Method to Compute MTTF from Continuous Time Markov Chain",
    "abstract": "Comments: 3 pages, 1 figure",
    "descriptor": "\nComments: 3 pages, 1 figure\n",
    "authors": [
      "Eduardo M. Vasconcelos"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.00674"
  },
  {
    "id": "arXiv:2202.00677",
    "title": "An Embarrassingly Simple Consistency Regularization Method for  Semi-Supervised Medical Image Segmentation",
    "abstract": "Comments: Accepted at ISBI 2022",
    "descriptor": "\nComments: Accepted at ISBI 2022\n",
    "authors": [
      "Hritam Basak",
      "Rajarshi Bhattacharya",
      "Rukhshanda Hussain",
      "Agniv Chatterjee"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.00677"
  },
  {
    "id": "arXiv:2202.00738",
    "title": "LocUNet: Fast Urban Positioning Using Radio Maps and Deep Learning",
    "abstract": "Comments: To appear in ICASSP 2022. arXiv admin note: substantial text overlap with arXiv:2106.12556",
    "descriptor": "\nComments: To appear in ICASSP 2022. arXiv admin note: substantial text overlap with arXiv:2106.12556\n",
    "authors": [
      "\u00c7a\u011fkan Yapar",
      "Ron Levie",
      "Gitta Kutyniok",
      "Giuseppe Caire"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.00738"
  },
  {
    "id": "arXiv:2202.00824",
    "title": "KSD Aggregated Goodness-of-fit Test",
    "abstract": "Comments: 9 pages",
    "descriptor": "\nComments: 9 pages\n",
    "authors": [
      "Antonin Schrab",
      "Benjamin Guedj",
      "Arthur Gretton"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2202.00824"
  },
  {
    "id": "arXiv:2202.00834",
    "title": "Algorithms for Efficiently Learning Low-Rank Neural Networks",
    "abstract": "Comments: 52 pages, 4 figures, in submission",
    "descriptor": "\nComments: 52 pages, 4 figures, in submission\n",
    "authors": [
      "Kiran Vodrahalli",
      "Rakesh Shivanna",
      "Maheswaran Sathiamoorthy",
      "Sagar Jain",
      "Ed H. Chi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.00834"
  },
  {
    "id": "arXiv:2202.00941",
    "title": "CTMSTOU driven markets: simulated environment for regime-awareness in  trading policies",
    "abstract": "Comments: fix typo in title",
    "descriptor": "\nComments: fix typo in title\n",
    "authors": [
      "Selim Amrouni",
      "Aymeric Moulin",
      "Tucker Balch"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Artificial Intelligence (cs.AI)",
      "General Economics (econ.GN)",
      "Mathematical Finance (q-fin.MF)"
    ],
    "url": "https://arxiv.org/abs/2202.00941"
  },
  {
    "id": "arXiv:2202.01011",
    "title": "Auto-Transfer: Learning to Route Transferrable Representations",
    "abstract": "Comments: Accepted for publication in ICLR 2022",
    "descriptor": "\nComments: Accepted for publication in ICLR 2022\n",
    "authors": [
      "Keerthiram Murugesan",
      "Vijay Sadashivaiah",
      "Ronny Luss",
      "Karthikeyan Shanmugam",
      "Pin-Yu Chen",
      "Amit Dhurandhar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.01011"
  },
  {
    "id": "arXiv:2202.01197",
    "title": "VOS: Learning What You Don't Know by Virtual Outlier Synthesis",
    "abstract": "Comments: ICLR 2022",
    "descriptor": "\nComments: ICLR 2022\n",
    "authors": [
      "Xuefeng Du",
      "Zhaoning Wang",
      "Mu Cai",
      "Yixuan Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.01197"
  }
]
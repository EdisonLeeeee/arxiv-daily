[
  {
    "id": "arXiv:2202.08261",
    "title": "Evaluation and Analysis of Different Aggregation and Hyperparameter  Selection Methods for Federated Brain Tumor Segmentation",
    "abstract": "Availability of large, diverse, and multi-national datasets is crucial for\nthe development of effective and clinically applicable AI systems in the\nmedical imaging domain. However, forming a global model by bringing these\ndatasets together at a central location, comes along with various data privacy\nand ownership problems. To alleviate these problems, several recent studies\nfocus on the federated learning paradigm, a distributed learning approach for\ndecentralized data. Federated learning leverages all the available data without\nany need for sharing collaborators' data with each other or collecting them on\na central server. Studies show that federated learning can provide competitive\nperformance with conventional central training, while having a good\ngeneralization capability. In this work, we have investigated several federated\nlearning approaches on the brain tumor segmentation problem. We explore\ndifferent strategies for faster convergence and better performance which can\nalso work on strong Non-IID cases.",
    "descriptor": "\nComments: MICCAI 2021, Brain Lesion Workshop\n",
    "authors": [
      "Ece Isik-Polat",
      "Gorkem Polat",
      "Altan Kocyigit",
      "Alptekin Temizel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2202.08261"
  },
  {
    "id": "arXiv:2202.08265",
    "title": "XAI in the context of Predictive Process Monitoring: Too much to Reveal",
    "abstract": "Predictive Process Monitoring (PPM) has been integrated into process mining\ntools as a value-adding task. PPM provides useful predictions on the further\nexecution of the running business processes. To this end, machine\nlearning-based techniques are widely employed in the context of PPM. In order\nto gain stakeholders trust and advocacy of PPM predictions, eXplainable\nArtificial Intelligence (XAI) methods are employed in order to compensate for\nthe lack of transparency of most efficient predictive models. Even when\nemployed under the same settings regarding data, preprocessing techniques, and\nML models, explanations generated by multiple XAI methods differ profoundly. A\ncomparison is missing to distinguish XAI characteristics or underlying\nconditions that are deterministic to an explanation. To address this gap, we\nprovide a framework to enable studying the effect of different PPM-related\nsettings and ML model-related choices on characteristics and expressiveness of\nresulting explanations. In addition, we compare how different explainability\nmethods characteristics can shape resulting explanations and enable reflecting\nunderlying model reasoning process",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2202.08041\n",
    "authors": [
      "Ghada Elkhawaga",
      "Mervat Abuelkheir",
      "Manfred Reichert"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.08265"
  },
  {
    "id": "arXiv:2202.08266",
    "title": "Open-Ended Reinforcement Learning with Neural Reward Functions",
    "abstract": "Inspired by the great success of unsupervised learning in Computer Vision and\nNatural Language Processing, the Reinforcement Learning community has recently\nstarted to focus more on unsupervised discovery of skills. Most current\napproaches, like DIAYN or DADS, optimize some form of mutual information\nobjective. We propose a different approach that uses reward functions encoded\nby neural networks. These are trained iteratively to reward more complex\nbehavior. In high-dimensional robotic environments our approach learns a wide\nrange of interesting skills including front-flips for Half-Cheetah and\none-legged running for Humanoid. In the pixel-based Montezuma's Revenge\nenvironment our method also works with minimal changes and it learns complex\nskills that involve interacting with items and visiting diverse locations. A\nweb version of this paper which shows animations for the different skills is\navailable in https://as.inf.ethz.ch/research/open_ended_RL/main.html",
    "descriptor": "",
    "authors": [
      "Robert Meier",
      "Asier Mujika"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.08266"
  },
  {
    "id": "arXiv:2202.08267",
    "title": "More to Less (M2L): Enhanced Health Recognition in the Wild with Reduced  Modality of Wearable Sensors",
    "abstract": "Accurately recognizing health-related conditions from wearable data is\ncrucial for improved healthcare outcomes. To improve the recognition accuracy,\nvarious approaches have focused on how to effectively fuse information from\nmultiple sensors. Fusing multiple sensors is a common scenario in many\napplications, but may not always be feasible in real-world scenarios. For\nexample, although combining bio-signals from multiple sensors (i.e., a chest\npad sensor and a wrist wearable sensor) has been proved effective for improved\nperformance, wearing multiple devices might be impractical in the free-living\ncontext. To solve the challenges, we propose an effective more to less (M2L)\nlearning framework to improve testing performance with reduced sensors through\nleveraging the complementary information of multiple modalities during\ntraining. More specifically, different sensors may carry different but\ncomplementary information, and our model is designed to enforce collaborations\namong different modalities, where positive knowledge transfer is encouraged and\nnegative knowledge transfer is suppressed, so that better representation is\nlearned for individual modalities. Our experimental results show that our\nframework achieves comparable performance when compared with the full\nmodalities. Our code and results will be available at\nhttps://github.com/compwell-org/More2Less.git.",
    "descriptor": "\nComments: 4 pages, two figures and three tables\n",
    "authors": [
      "Huiyuan Yang",
      "Han Yu",
      "Kusha Sridhar",
      "Thomas Vaessen",
      "Inez Myin-Germeys",
      "Akane Sano"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.08267"
  },
  {
    "id": "arXiv:2202.08296",
    "title": "Controlling Epidemic Spread using Probabilistic Diffusion Models on  Networks",
    "abstract": "The spread of an epidemic is often modeled by an SIR random process on a\nsocial network graph. The MinINF problem for optimal social distancing involves\nminimizing the expected number of infections, when we are allowed to break at\nmost $B$ edges; similarly the MinINFNode problem involves removing at most $B$\nvertices. These are fundamental problems in epidemiology and network science.\nWhile a number of heuristics have been considered, the complexity of these\nproblems remains generally open. In this paper, we present two bicriteria\napproximation algorithms for MinINF, which give the first non-trivial\napproximations for this problem. The first is based on the cut sparsification\nresult of Karger \\cite{karger:mathor99}, and works when the transmission\nprobabilities are not too small. The second is a Sample Average Approximation\n(SAA) based algorithm, which we analyze for the Chung-Lu random graph model. We\nalso extend some of our results to tackle the MinINFNode problem.",
    "descriptor": "\nComments: To appear at AISTATS 2022\n",
    "authors": [
      "Amy Babay",
      "Michael Dinitz",
      "Aravind Srinivasan",
      "Leonidas Tsepenekas",
      "Anil Vullikanti"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.08296"
  },
  {
    "id": "arXiv:2202.08299",
    "title": "The learning phases in NN: From Fitting the Majority to Fitting a Few",
    "abstract": "The learning dynamics of deep neural networks are subject to controversy.\nUsing the information bottleneck (IB) theory separate fitting and compression\nphases have been put forward but have since been heavily debated. We approach\nlearning dynamics by analyzing a layer's reconstruction ability of the input\nand prediction performance based on the evolution of parameters during\ntraining. We show that a prototyping phase decreasing reconstruction loss\ninitially, followed by reducing classification loss of a few samples, which\nincreases reconstruction loss, exists under mild assumptions on the data. Aside\nfrom providing a mathematical analysis of single layer classification networks,\nwe also assess the behavior using common datasets and architectures from\ncomputer vision such as ResNet and VGG.",
    "descriptor": "",
    "authors": [
      "Johannes Schneider"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.08299"
  },
  {
    "id": "arXiv:2202.08300",
    "title": "A hybrid level-set / embedded boundary method applied to  solidification-melt problems",
    "abstract": "In this paper, we introduce a novel way to represent the interface for\ntwo-phase flows with phase change. We combine a level-set method with a\nCartesian embedded boundary method and take advantage of both. This is part of\nan effort to obtain a numerical strategy relying on Cartesian grids allowing\nthe simulation of complex boundaries with possible change of topology while\nretaining a high-order representation of the gradients on the interface and the\ncapability of properly applying boundary conditions on the interface. This\nleads to a two-fluid conservative second-order numerical method. The ability of\nthe method to correctly solve Stefan problems, onset dendrite growth with and\nwithout anisotropy is demonstrated through a variety of test cases. Finally, we\ntake advantage of the two-fluid representation to model a Rayleigh--B\\'enard\ninstability with a melting boundary.",
    "descriptor": "",
    "authors": [
      "A. Limare",
      "S. Popinet",
      "C. Josserand",
      "Z. Xue",
      "A. Ghigo"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2202.08300"
  },
  {
    "id": "arXiv:2202.08302",
    "title": "Efficient Distributed Machine Learning via Combinatorial Multi-Armed  Bandits",
    "abstract": "We consider the distributed stochastic gradient descent problem, where a main\nnode distributes gradient calculations among $n$ workers from which at most $b\n\\leq n$ can be utilized in parallel. By assigning tasks to all the workers and\nwaiting only for the $k$ fastest ones, the main node can trade-off the error of\nthe algorithm with its runtime by gradually increasing $k$ as the algorithm\nevolves. However, this strategy, referred to as adaptive k sync, can incur\nadditional costs since it ignores the computational efforts of slow workers. We\npropose a cost-efficient scheme that assigns tasks only to $k$ workers and\ngradually increases $k$. As the response times of the available workers are\nunknown to the main node a priori, we utilize a combinatorial multi-armed\nbandit model to learn which workers are the fastest while assigning gradient\ncalculations, and to minimize the effect of slow workers. Assuming that the\nmean response times of the workers are independent and exponentially\ndistributed with different means, we give empirical and theoretical guarantees\non the regret of our strategy, i.e., the extra time spent to learn the mean\nresponse times of the workers. Compared to adaptive k sync, our scheme achieves\nsignificantly lower errors with the same computational efforts while being\ninferior in terms of speed.",
    "descriptor": "",
    "authors": [
      "Maximilian Egger",
      "Rawad Bitar",
      "Antonia Wachter-Zeh",
      "Deniz G\u00fcnd\u00fcz"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.08302"
  },
  {
    "id": "arXiv:2202.08309",
    "title": "Contextualize differential privacy in image database: a lightweight  image differential privacy approach based on principle component analysis  inverse",
    "abstract": "Differential privacy (DP) has been the de-facto standard to preserve\nprivacy-sensitive information in database. Nevertheless, there lacks a clear\nand convincing contextualization of DP in image database, where individual\nimages' indistinguishable contribution to a certain analysis can be achieved\nand observed when DP is exerted. As a result, the privacy-accuracy trade-off\ndue to integrating DP is insufficiently demonstrated in the context of\ndifferentially-private image database. This work aims at contextualizing DP in\nimage database by an explicit and intuitive demonstration of integrating\nconceptional differential privacy with images. To this end, we design a\nlightweight approach dedicating to privatizing image database as a whole and\npreserving the statistical semantics of the image database to an adjustable\nlevel, while making individual images' contribution to such statistics\nindistinguishable. The designed approach leverages principle component analysis\n(PCA) to reduce the raw image with large amount of attributes to a lower\ndimensional space whereby DP is performed, so as to decrease the DP load of\ncalculating sensitivity attribute-by-attribute. The DP-exerted image data,\nwhich is not visible in its privatized format, is visualized through PCA\ninverse such that both a human and machine inspector can evaluate the\nprivatization and quantify the privacy-accuracy trade-off in an analysis on the\nprivatized image database. Using the devised approach, we demonstrate the\ncontextualization of DP in images by two use cases based on deep learning\nmodels, where we show the indistinguishability of individual images induced by\nDP and the privatized images' retention of statistical semantics in deep\nlearning tasks, which is elaborated by quantitative analyses on the\nprivacy-accuracy trade-off under different privatization settings.",
    "descriptor": "",
    "authors": [
      "Shiliang Zhang",
      "Xuehui Ma",
      "Hui Cao",
      "Tengyuan Zhao",
      "Yajie Yu",
      "Zhuzhu Wang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2202.08309"
  },
  {
    "id": "arXiv:2202.08310",
    "title": "Towards Verifiable Federated Learning",
    "abstract": "Federated learning (FL) is an emerging paradigm of collaborative machine\nlearning that preserves user privacy while building powerful models.\nNevertheless, due to the nature of open participation by self-interested\nentities, it needs to guard against potential misbehaviours by legitimate FL\nparticipants. FL verification techniques are promising solutions for this\nproblem. They have been shown to effectively enhance the reliability of FL\nnetworks and help build trust among participants. Verifiable federated learning\nhas become an emerging topic of research that has attracted significant\ninterest from the academia and the industry alike. Currently, there is no\ncomprehensive survey on the field of verifiable federated learning, which is\ninterdisciplinary in nature and can be challenging for researchers to enter\ninto. In this paper, we bridge this gap by reviewing works focusing on\nverifiable FL. We propose a novel taxonomy for verifiable FL covering both\ncentralised and decentralised FL settings, summarise the commonly adopted\nperformance evaluation approaches, and discuss promising directions towards a\nversatile verifiable FL framework.",
    "descriptor": "",
    "authors": [
      "Yanci Zhang",
      "Han Yu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.08310"
  },
  {
    "id": "arXiv:2202.08311",
    "title": "Single Trajectory Nonparametric Learning of Nonlinear Dynamics",
    "abstract": "Given a single trajectory of a dynamical system, we analyze the performance\nof the nonparametric least squares estimator (LSE). More precisely, we give\nnonasymptotic expected $l^2$-distance bounds between the LSE and the true\nregression function, where expectation is evaluated on a fresh, counterfactual,\ntrajectory. We leverage recently developed information-theoretic methods to\nestablish the optimality of the LSE for nonparametric hypotheses classes in\nterms of supremum norm metric entropy and a subgaussian parameter. Next, we\nrelate this subgaussian parameter to the stability of the underlying process\nusing notions from dynamical systems theory. When combined, these developments\nlead to rate-optimal error bounds that scale as $T^{-1/(2+q)}$ for suitably\nstable processes and hypothesis classes with metric entropy growth of order\n$\\delta^{-q}$. Here, $T$ is the length of the observed trajectory, $\\delta \\in\n\\mathbb{R}_+$ is the packing granularity and $q\\in (0,2)$ is a complexity term.\nFinally, we specialize our results to a number of scenarios of practical\ninterest, such as Lipschitz dynamics, generalized linear models, and dynamics\ndescribed by functions in certain classes of Reproducing Kernel Hilbert Spaces\n(RKHS).",
    "descriptor": "",
    "authors": [
      "Ingvar Ziemann",
      "Henrik Sandberg",
      "Nikolai Matni"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.08311"
  },
  {
    "id": "arXiv:2202.08312",
    "title": "Private Online Prefix Sums via Optimal Matrix Factorizations",
    "abstract": "Motivated by differentially-private (DP) training of machine learning models\nand other applications, we investigate the problem of computing prefix sums in\nthe online (streaming) setting with DP. This problem has previously been\naddressed by special-purpose tree aggregation schemes with hand-crafted\nestimators. We show that these previous schemes can all be viewed as specific\ninstances of a broad class of matrix-factorization-based DP mechanisms, and\nthat in fact much better mechanisms exist in this class.\nIn particular, we characterize optimal factorizations of linear queries under\nonline constraints, deriving existence, uniqueness, and explicit expressions\nthat allow us to efficiently compute optimal mechanisms, including for online\nprefix sums. These solutions improve over the existing state-of-the-art by a\nsignificant constant factor, and avoid some of the artifacts introduced by the\nuse of the tree data structure.",
    "descriptor": "\nComments: 23 pages, 1 figure\n",
    "authors": [
      "Brendan McMahan",
      "Keith Rush",
      "Abhradeep Guha Thakurta"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2202.08312"
  },
  {
    "id": "arXiv:2202.08314",
    "title": "Causal Process Mining from Relational Databases with Domain Knowledge",
    "abstract": "The plethora of algorithms in the research field of process mining builds on\ndirectly-follows relations. Even though various improvements have been made in\nthe last decade, there are serious weaknesses of these relationships. Once\nevents associated with different objects that relate with a cardinality of 1:N\nand N:M to each other, techniques based on directly-follows relations produce\nspurious relations, self-loops, and back-jumps. This is due to the fact that\nevent sequence as described in classical event logs differs from event\ncausation. In this paper, we address the research problem of representing the\ncausal structure of process-related event data. To this end, we develop a new\napproach called Causal Process Mining. This approach renounces the use of flat\nevent logs and considers relational databases of event data as an input. More\nspecifically, we transform the relational data structures based on the Causal\nProcess Template into what we call Causal Event Graph. We evaluate our approach\nand compare its outputs with techniques based on directly-follows relations in\na case study with an European food production company. Our results demonstrate\nthat directly-follows miners produce a large number of spurious relationships,\nwhich our approach captures correctly.",
    "descriptor": "\nComments: 46 pages, 5 tabels, 17 figures\n",
    "authors": [
      "Philipp Waibel",
      "Lukas Pfahlsberger",
      "Kate Revoredo",
      "Jan Mendling"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2202.08314"
  },
  {
    "id": "arXiv:2202.08315",
    "title": "Tensor-based Channel Tracking for RIS-Empowered Multi-User MIMO Wireless  Systems",
    "abstract": "The accurate estimation of Channel State Information (CSI) is of crucial\nimportance for the successful operation of Multiple-Input Multiple-Output\n(MIMO) communication systems, especially in a Multi-User (MU) time-varying\nenvironment and when employing the emerging technology of Reconfigurable\nIntelligent Surfaces (RISs). Their predominantly passive nature renders the\nestimation of the channels involved in the user-RIS-base station link a quite\nchallenging problem. Moreover, the time-varying nature of most of the realistic\nwireless channels drives up the cost of real-time channel tracking\nsignificantly, especially when RISs of massive size are deployed. In this\npaper, we develop a channel tracking scheme for the uplink of RIS-enabled MU\nMIMO systems in the presence of channel fading. The starting point is a tensor\nrepresentation of the received signal and we rely on its PARAllel FACtor\n(PARAFAC) analysis to both get the initial estimate and track the channel time\nvariation. Simulation results for various system settings are reported, which\nvalidate the feasibility and effectiveness of the proposed channel tracking\napproach.",
    "descriptor": "",
    "authors": [
      "Jide Yuan",
      "George C. Alexandropoulos",
      "Eleftherios Kofidis",
      "Tobias Lindstrm Jensen",
      "Elisabeth De Carvalho"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.08315"
  },
  {
    "id": "arXiv:2202.08316",
    "title": "FAMIE: A Fast Active Learning Framework for Multilingual Information  Extraction",
    "abstract": "This paper presents FAMIE, a comprehensive and efficient active learning (AL)\ntoolkit for multilingual information extraction. FAMIE is designed to address a\nfundamental problem in existing AL frameworks where annotators need to wait for\na long time between annotation batches due to the time-consuming nature of\nmodel training and data selection at each AL iteration. This hinders the\nengagement, productivity, and efficiency of annotators. Based on the idea of\nusing a small proxy network for fast data selection, we introduce a novel\nknowledge distillation mechanism to synchronize the proxy network with the main\nlarge model (i.e., BERT-based) to ensure the appropriateness of the selected\nannotation examples for the main model. Our AL framework can support multiple\nlanguages. The experiments demonstrate the advantages of FAMIE in terms of\ncompetitive performance and time efficiency for sequence labeling with AL. We\npublicly release our code (\\url{https://github.com/nlp-uoregon/famie}) and demo\nwebsite (\\url{this http URL}). A demo video for FAMIE is\nprovided at: \\url{https://youtu.be/I2i8n_jAyrY}.",
    "descriptor": "",
    "authors": [
      "Minh Van Nguyen",
      "Nghia Trung Ngo",
      "Bonan Min",
      "Thien Huu Nguyen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.08316"
  },
  {
    "id": "arXiv:2202.08320",
    "title": "TorchDrug: A Powerful and Flexible Machine Learning Platform for Drug  Discovery",
    "abstract": "Machine learning has huge potential to revolutionize the field of drug\ndiscovery and is attracting increasing attention in recent years. However,\nlacking domain knowledge (e.g., which tasks to work on), standard benchmarks\nand data preprocessing pipelines are the main obstacles for machine learning\nresearchers to work in this domain. To facilitate the progress of machine\nlearning for drug discovery, we develop TorchDrug, a powerful and flexible\nmachine learning platform for drug discovery built on top of PyTorch. TorchDrug\nbenchmarks a variety of important tasks in drug discovery, including molecular\nproperty prediction, pretrained molecular representations, de novo molecular\ndesign and optimization, retrosynthsis prediction, and biomedical knowledge\ngraph reasoning. State-of-the-art techniques based on geometric deep learning\n(or graph machine learning), deep generative models, reinforcement learning and\nknowledge graph reasoning are implemented for these tasks. TorchDrug features a\nhierarchical interface that facilitates customization from both novices and\nexperts in this domain. Tutorials, benchmark results and documentation are\navailable at https://torchdrug.ai. Code is released under Apache License 2.0.",
    "descriptor": "",
    "authors": [
      "Zhaocheng Zhu",
      "Chence Shi",
      "Zuobai Zhang",
      "Shengchao Liu",
      "Minghao Xu",
      "Xinyu Yuan",
      "Yangtian Zhang",
      "Junkun Chen",
      "Huiyu Cai",
      "Jiarui Lu",
      "Chang Ma",
      "Runcheng Liu",
      "Louis-Pascal Xhonneux",
      "Meng Qu",
      "Jian Tang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.08320"
  },
  {
    "id": "arXiv:2202.08325",
    "title": "A Data-Augmentation Is Worth A Thousand Samples: Exact Quantification  From Analytical Augmented Sample Moments",
    "abstract": "Data-Augmentation (DA) is known to improve performance across tasks and\ndatasets. We propose a method to theoretically analyze the effect of DA and\nstudy questions such as: how many augmented samples are needed to correctly\nestimate the information encoded by that DA? How does the augmentation policy\nimpact the final parameters of a model? We derive several quantities in\nclose-form, such as the expectation and variance of an image, loss, and model's\noutput under a given DA distribution. Those derivations open new avenues to\nquantify the benefits and limitations of DA. For example, we show that common\nDAs require tens of thousands of samples for the loss at hand to be correctly\nestimated and for the model training to converge. We show that for a training\nloss to be stable under DA sampling, the model's saliency map (gradient of the\nloss with respect to the model's input) must align with the smallest\neigenvector of the sample variance under the considered DA augmentation,\nhinting at a possible explanation on why models tend to shift their focus from\nedges to textures.",
    "descriptor": "",
    "authors": [
      "Randall Balestriero",
      "Ishan Misra",
      "Yann LeCun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.08325"
  },
  {
    "id": "arXiv:2202.08326",
    "title": "SAT Backdoors: Depth Beats Size",
    "abstract": "For several decades, much effort has been put into identifying classes of CNF\nformulas whose satisfiability can be decided in polynomial time. Classic\nresults are the linear-time tractability of Horn formulas (Aspvall, Plass, and\nTarjan, 1979) and Krom (i.e., 2CNF) formulas (Dowling and Gallier, 1984).\nBackdoors, introduced by Williams Gomes and Selman (2003), gradually extend\nsuch a tractable class to all formulas of bounded distance to the class.\nBackdoor size provides a natural but rather crude distance measure between a\nformula and a tractable class. Backdoor depth, introduced by M\\\"{a}hlmann,\nSiebertz, and Vigny (2021), is a more refined distance measure, which admits\nthe utilization of different backdoor variables in parallel. Bounded backdoor\nsize implies bounded backdoor depth, but there are formulas of constant\nbackdoor depth and arbitrarily large backdoor size.\nWe propose FPT approximation algorithms to compute backdoor depth into the\nclasses Horn and Krom. This leads to a linear-time algorithm for deciding the\nsatisfiability of formulas of bounded backdoor depth into these classes. We\nbase our FPT approximation algorithm on a sophisticated notion of obstructions,\nextending M\\\"{a}hlmann et al.'s obstruction trees in various ways, including\nthe addition of separator obstructions. We develop the algorithm through a new\ngame-theoretic framework that simplifies the reasoning about backdoors.\nFinally, we show that bounded backdoor depth captures tractable classes of\nCNF formulas not captured by any known method.",
    "descriptor": "",
    "authors": [
      "Jan Dreier",
      "Sebastian Ordyniak",
      "Stefan Szeider"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2202.08326"
  },
  {
    "id": "arXiv:2202.08333",
    "title": "Self-Supervised Representation Learning via Latent Graph Prediction",
    "abstract": "Self-supervised learning (SSL) of graph neural networks is emerging as a\npromising way of leveraging unlabeled data. Currently, most methods are based\non contrastive learning adapted from the image domain, which requires view\ngeneration and a sufficient number of negative samples. In contrast, existing\npredictive models do not require negative sampling, but lack theoretical\nguidance on the design of pretext training tasks. In this work, we propose the\nLaGraph, a theoretically grounded predictive SSL framework based on latent\ngraph prediction. Learning objectives of LaGraph are derived as self-supervised\nupper bounds to objectives for predicting unobserved latent graphs. In addition\nto its improved performance, LaGraph provides explanations for recent successes\nof predictive models that include invariance-based objectives. We provide\ntheoretical analysis comparing LaGraph to related methods in different domains.\nOur experimental results demonstrate the superiority of LaGraph in performance\nand the robustness to decreasing of training sample size on both graph-level\nand node-level tasks.",
    "descriptor": "",
    "authors": [
      "Yaochen Xie",
      "Zhao Xu",
      "Shuiwang Ji"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.08333"
  },
  {
    "id": "arXiv:2202.08335",
    "title": "Task-Agnostic Graph Explanations",
    "abstract": "Graph Neural Networks (GNNs) have emerged as powerful tools to encode graph\nstructured data. Due to their broad applications, there is an increasing need\nto develop tools to explain how GNNs make decisions given graph structured\ndata. Existing learning-based GNN explanation approaches are task-specific in\ntraining and hence suffer from crucial drawbacks. Specifically, they are\nincapable of producing explanations for a multitask prediction model with a\nsingle explainer. They are also unable to provide explanations in cases where\nthe GNN is trained in a self-supervised manner, and the resulting\nrepresentations are used in future downstream tasks. To address these\nlimitations, we propose a Task-Agnostic GNN Explainer (TAGE) trained under\nself-supervision with no knowledge of downstream tasks. TAGE enables the\nexplanation of GNN embedding models without downstream tasks and allows\nefficient explanation of multitask models. Our extensive experiments show that\nTAGE can significantly speed up the explanation efficiency by using the same\nmodel to explain predictions for multiple downstream tasks while achieving\nexplanation quality as good as or even better than current state-of-the-art GNN\nexplanation approaches.",
    "descriptor": "",
    "authors": [
      "Yaochen Xie",
      "Sumeet Katariya",
      "Xianfeng Tang",
      "Edward Huang",
      "Nikhil Rao",
      "Karthik Subbian",
      "Shuiwang Ji"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.08335"
  },
  {
    "id": "arXiv:2202.08338",
    "title": "Single-shot Hyper-parameter Optimization for Federated Learning: A  General Algorithm & Analysis",
    "abstract": "We address the relatively unexplored problem of hyper-parameter optimization\n(HPO) for federated learning (FL-HPO). We introduce Federated Loss SuRface\nAggregation (FLoRA), a general FL-HPO solution framework that can address use\ncases of tabular data and any Machine Learning (ML) model including gradient\nboosting training algorithms and therefore further expands the scope of FL-HPO.\nFLoRA enables single-shot FL-HPO: identifying a single set of good\nhyper-parameters that are subsequently used in a single FL training. Thus, it\nenables FL-HPO solutions with minimal additional communication overhead\ncompared to FL training without HPO. We theoretically characterize the\noptimality gap of FL-HPO, which explicitly accounts for the heterogeneous\nnon-IID nature of the parties' local data distributions, a dominant\ncharacteristic of FL systems. Our empirical evaluation of FLoRA for multiple ML\nalgorithms on seven OpenML datasets demonstrates significant model accuracy\nimprovements over the considered baseline, and robustness to increasing number\nof parties involved in FL-HPO training.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2112.08524\n",
    "authors": [
      "Yi Zhou",
      "Parikshit Ram",
      "Theodoros Salonidis",
      "Nathalie Baracaldo",
      "Horst Samulowitz",
      "Heiko Ludwig"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2202.08338"
  },
  {
    "id": "arXiv:2202.08340",
    "title": "A Developmentally-Inspired Examination of Shape versus Texture Bias in  Machines",
    "abstract": "Early in development, children learn to extend novel category labels to\nobjects with the same shape, a phenomenon known as the shape bias. Inspired by\nthese findings, Geirhos et al. (2019) examined whether deep neural networks\nshow a shape or texture bias by constructing images with conflicting shape and\ntexture cues. They found that convolutional neural networks strongly preferred\nto classify familiar objects based on texture as opposed to shape, suggesting a\ntexture bias. However, there are a number of differences between how the\nnetworks were tested in this study versus how children are typically tested. In\nthis work, we re-examine the inductive biases of neural networks by adapting\nthe stimuli and procedure from Geirhos et al. (2019) to more closely follow the\ndevelopmental paradigm and test on a wide range of pre-trained neural networks.\nAcross three experiments, we find that deep neural networks exhibit a\npreference for shape rather than texture when tested under conditions that more\nclosely replicate the developmental procedure.",
    "descriptor": "\nComments: 7 pages, 4 figures\n",
    "authors": [
      "Alexa R. Tartaglini",
      "Wai Keen Vong",
      "Brenden M. Lake"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.08340"
  },
  {
    "id": "arXiv:2202.08341",
    "title": "Anomalib: A Deep Learning Library for Anomaly Detection",
    "abstract": "This paper introduces anomalib, a novel library for unsupervised anomaly\ndetection and localization. With reproducibility and modularity in mind, this\nopen-source library provides algorithms from the literature and a set of tools\nto design custom anomaly detection algorithms via a plug-and-play approach.\nAnomalib comprises state-of-the-art anomaly detection algorithms that achieve\ntop performance on the benchmarks and that can be used off-the-shelf. In\naddition, the library provides components to design custom algorithms that\ncould be tailored towards specific needs. Additional tools, including\nexperiment trackers, visualizers, and hyper-parameter optimizers, make it\nsimple to design and implement anomaly detection models. The library also\nsupports OpenVINO model optimization and quantization for real-time deployment.\nOverall, anomalib is an extensive library for the design, implementation, and\ndeployment of unsupervised anomaly detection models from data to the edge.",
    "descriptor": "",
    "authors": [
      "Samet Akcay",
      "Dick Ameln",
      "Ashwin Vaidya",
      "Barath Lakshmanan",
      "Nilesh Ahuja",
      "Utku Genc"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.08341"
  },
  {
    "id": "arXiv:2202.08345",
    "title": "Learning Smooth Neural Functions via Lipschitz Regularization",
    "abstract": "Neural implicit fields have recently emerged as a useful representation for\n3D shapes. These fields are commonly represented as neural networks which map\nlatent descriptors and 3D coordinates to implicit function values. The latent\ndescriptor of a neural field acts as a deformation handle for the 3D shape it\nrepresents. Thus, smoothness with respect to this descriptor is paramount for\nperforming shape-editing operations. In this work, we introduce a novel\nregularization designed to encourage smooth latent spaces in neural fields by\npenalizing the upper bound on the field's Lipschitz constant. Compared with\nprior Lipschitz regularized networks, ours is computationally fast, can be\nimplemented in four lines of code, and requires minimal hyperparameter tuning\nfor geometric applications. We demonstrate the effectiveness of our approach on\nshape interpolation and extrapolation as well as partial shape reconstruction\nfrom 3D point clouds, showing both qualitative and quantitative improvements\nover existing state-of-the-art and non-regularized baselines.",
    "descriptor": "",
    "authors": [
      "Hsueh-Ti Derek Liu",
      "Francis Williams",
      "Alec Jacobson",
      "Sanja Fidler",
      "Or Litany"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2202.08345"
  },
  {
    "id": "arXiv:2202.08357",
    "title": "On the Complexity of Some Variations of Sorting by Transpositions",
    "abstract": "One of the main challenges in Computational Biology is to find the\nevolutionary distance between two organisms. In the field of comparative\ngenomics, one way to estimate such distance is to find a minimum cost sequence\nof rearrangements (large scale mutations) needed to transform one genome into\nanother, which is called the rearrangement distance. In the past decades, these\nproblems were studied considering many types of rearrangements (such as\nreversals, transpositions, transreversals, and revrevs) and considering the\nsame weight for all rearrangements, or different weights depending on the types\nof rearrangements. The complexity of the problems involving reversals,\ntranspositions, and both rearrangements is known, even though the hardness\nproof for the problem combining reversals and transpositions was recently\ngiven. In this paper, we enhance the knowledge for these problems by proving\nthat models involving transpositions alongside reversals, transreversals, and\nrevrevs are NP-hard, considering weights w1 for reversals and w2 for the other\nrearrangements such that w2/w1 is less than or equal to 1.5. In addition, we\naddress a cost function related to the number of fragmentations caused by a\nrearrangement, proving that the problem of finding a minimum cost sorting\nsequence, considering the fragmentation cost function with some restrictions,\nis NP-hard for transpositions and the combination of reversals and\ntranspositions.",
    "descriptor": "",
    "authors": [
      "Alexsandro Oliveira Alexandrino",
      "Andre Rodrigues Oliveira",
      "Ulisses Dias",
      "Zanoni Dias"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2202.08357"
  },
  {
    "id": "arXiv:2202.08359",
    "title": "Virtual Maps for Autonomous Exploration of Cluttered Underwater  Environments",
    "abstract": "We consider the problem of autonomous mobile robot exploration in an unknown\nenvironment, taking into account a robot's coverage rate, map uncertainty, and\nstate estimation uncertainty. This paper presents a novel exploration framework\nfor underwater robots operating in cluttered environments, built upon\nsimultaneous localization and mapping (SLAM) with imaging sonar. The proposed\nsystem comprises path generation, place recognition forecasting, belief\npropagation and utility evaluation using a virtual map, which estimates the\nuncertainty associated with map cells throughout a robot's workspace. We\nevaluate the performance of this framework in simulated experiments, showing\nthat our algorithm maintains a high coverage rate during exploration while also\nmaintaining low mapping and localization error. The real-world applicability of\nour framework is also demonstrated on an underwater remotely operated vehicle\n(ROV) exploring a harbor environment.",
    "descriptor": "\nComments: Preprint; Accepted for publication in the IEEE Journal of Oceanic Engineering\n",
    "authors": [
      "Jinkun Wang",
      "Fanfei Chen",
      "Yewei Huang",
      "John McConnell",
      "Tixiao Shan",
      "Brendan Englot"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.08359"
  },
  {
    "id": "arXiv:2202.08360",
    "title": "Vision Models Are More Robust And Fair When Pretrained On Uncurated  Images Without Supervision",
    "abstract": "Discriminative self-supervised learning allows training models on any random\ngroup of internet images, and possibly recover salient information that helps\ndifferentiate between the images. Applied to ImageNet, this leads to object\ncentric features that perform on par with supervised features on most\nobject-centric downstream tasks. In this work, we question if using this\nability, we can learn any salient and more representative information present\nin diverse unbounded set of images from across the globe. To do so, we train\nmodels on billions of random images without any data pre-processing or prior\nassumptions about what we want the model to learn. We scale our model size to\ndense 10 billion parameters to avoid underfitting on a large data size. We\nextensively study and validate our model performance on over 50 benchmarks\nincluding fairness, robustness to distribution shift, geographical diversity,\nfine grained recognition, image copy detection and many image classification\ndatasets. The resulting model, not only captures well semantic information, it\nalso captures information about artistic style and learns salient information\nsuch as geolocations and multilingual word embeddings based on visual content\nonly. More importantly, we discover that such model is more robust, more fair,\nless harmful and less biased than supervised models or models trained on object\ncentric datasets such as ImageNet.",
    "descriptor": "",
    "authors": [
      "Priya Goyal",
      "Quentin Duval",
      "Isaac Seessel",
      "Mathilde Caron",
      "Mannat Singh",
      "Ishan Misra",
      "Levent Sagun",
      "Armand Joulin",
      "Piotr Bojanowski"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2202.08360"
  },
  {
    "id": "arXiv:2202.08361",
    "title": "Vectorization of the Jacobi-type singular value decomposition method",
    "abstract": "The eigenvalue decomposition (EVD) of (a batch of) Hermitian matrices of\norder two has a role in many numerical algorithms, of which the one-sided\nJacobi method for the singular value decomposition (SVD) is the prime example.\nIn this paper the batched EVD is vectorized, with a vector-friendly data layout\nand the AVX-512 SIMD instructions of Intel CPUs, alongside other key components\nof a real and a complex OpenMP-parallel Jacobi-type SVD method, inspired by the\nsequential xGESVJ routines from LAPACK. These vectorized building blocks should\nbe portable to other platforms, with unconditional reproducibility guaranteed\nfor the batched EVD and several others. No avoidable overflow of the results\ncan occur with the proposed EVD or SVD. The measured accuracy of the proposed\nEVD often surpasses that of the xLAEV2 routines from LAPACK. While the batched\nEVD outperforms the matching sequence of xLAEV2 calls, speedup of the parallel\nSVD is modest but can be improved and is already beneficial with enough\nthreads. Regardless of their number, the proposed SVD method gives identical\nresults, but of somewhat lower accuracy than xGESVJ.",
    "descriptor": "\nComments: A separate \"supplementary materials\" document has been appended to the main paper as Appendix for technical reasons\n",
    "authors": [
      "Vedran Novakovi\u0107"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Mathematical Software (cs.MS)"
    ],
    "url": "https://arxiv.org/abs/2202.08361"
  },
  {
    "id": "arXiv:2202.08362",
    "title": "MMZDA: Enabling Social Welfare Maximization in Cross-Silo Federated  Learning",
    "abstract": "As one of the typical settings of Federated Learning (FL), cross-silo FL\nallows organizations to jointly train an optimal Machine Learning (ML) model.\nIn this case, some organizations may try to obtain the global model without\ncontributing their local training, lowering the social welfare. In this paper,\nwe model the interactions among organizations in cross-silo FL as a public\ngoods game for the first time and theoretically prove that there exists a\nsocial dilemma where the maximum social welfare is not achieved in Nash\nequilibrium. To overcome this social dilemma, we employ the Multi-player\nMulti-action Zero-Determinant (MMZD) strategy to maximize the social welfare.\nWith the help of the MMZD, an individual organization can unilaterally control\nthe social welfare without extra cost. Since the MMZD strategy can be adopted\nby all organizations, we further study the scenario where multiple\norganizations jointly adopt the MMZD strategy and form an MMZD Alliance\n(MMZDA). We prove theoretically that the MMZDA strategy strengthens the control\nof the maximum social welfare. Experimental results validate that the MMZD\nstrategy is effective in maximizing the social welfare and the MMZDA can\nachieve a larger maximum value.",
    "descriptor": "",
    "authors": [
      "Jianan Chen",
      "Qin Hu",
      "Honglu Jiang"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2202.08362"
  },
  {
    "id": "arXiv:2202.08370",
    "title": "Learning Transferrable Representations of Career Trajectories for  Economic Prediction",
    "abstract": "Understanding career trajectories -- the sequences of jobs that individuals\nhold over their working lives -- is important to economists for studying labor\nmarkets. In the past, economists have estimated relevant quantities by fitting\npredictive models to small surveys, but in recent years large datasets of\nonline resumes have also become available. These new datasets provide job\nsequences of many more individuals, but they are too large and complex for\nstandard econometric modeling. To this end, we adapt ideas from modern language\nmodeling to the analysis of large-scale job sequence data. We develop CAREER, a\ntransformer-based model that learns a low-dimensional representation of an\nindividual's job history. This representation can be used to predict jobs\ndirectly on a large dataset, or can be \"transferred\" to represent jobs in\nsmaller and better-curated datasets. We fit the model to a large dataset of\nresumes, 24 million people who are involved in more than a thousand unique\noccupations. It forms accurate predictions on held-out data, and it learns\nuseful career representations that can be fine-tuned to make accurate\npredictions on common economics datasets.",
    "descriptor": "",
    "authors": [
      "Keyon Vafa",
      "Emil Palikot",
      "Tianyu Du",
      "Ayush Kanodia",
      "Susan Athey",
      "David M. Blei"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.08370"
  },
  {
    "id": "arXiv:2202.08371",
    "title": "The Quarks of Attention",
    "abstract": "Attention plays a fundamental role in both natural and artificial\nintelligence systems. In deep learning, attention-based neural architectures,\nsuch as transformer architectures, are widely used to tackle problems in\nnatural language processing and beyond. Here we investigate the fundamental\nbuilding blocks of attention and their computational properties. Within the\nstandard model of deep learning, we classify all possible fundamental building\nblocks of attention in terms of their source, target, and computational\nmechanism. We identify and study three most important mechanisms: additive\nactivation attention, multiplicative output attention (output gating), and\nmultiplicative synaptic attention (synaptic gating). The gating mechanisms\ncorrespond to multiplicative extensions of the standard model and are used\nacross all current attention-based deep learning architectures. We study their\nfunctional properties and estimate the capacity of several attentional building\nblocks in the case of linear and polynomial threshold gates. Surprisingly,\nadditive activation attention plays a central role in the proofs of the lower\nbounds. Attention mechanisms reduce the depth of certain basic circuits and\nleverage the power of quadratic activations without incurring their full cost.",
    "descriptor": "",
    "authors": [
      "Pierre Baldi",
      "Roman Vershynin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.08371"
  },
  {
    "id": "arXiv:2202.08372",
    "title": "Fuzzy Pooling",
    "abstract": "Convolutional Neural Networks (CNNs) are artificial learning systems\ntypically based on two operations: convolution, which implements feature\nextraction through filtering, and pooling, which implements dimensionality\nreduction. The impact of pooling in the classification performance of the CNNs\nhas been highlighted in several previous works, and a variety of alternative\npooling operators have been proposed. However, only a few of them tackle with\nthe uncertainty that is naturally propagated from the input layer to the\nfeature maps of the hidden layers through convolutions. In this paper we\npresent a novel pooling operation based on (type-1) fuzzy sets to cope with the\nlocal imprecision of the feature maps, and we investigate its performance in\nthe context of image classification. Fuzzy pooling is performed by\nfuzzification, aggregation and defuzzification of feature map neighborhoods. It\nis used for the construction of a fuzzy pooling layer that can be applied as a\ndrop-in replacement of the current, crisp, pooling layers of CNN architectures.\nSeveral experiments using publicly available datasets show that the proposed\napproach can enhance the classification performance of a CNN. A comparative\nevaluation shows that it outperforms state-of-the-art pooling approaches.",
    "descriptor": "\nComments: The final version of the paper has been published in this https URL\n",
    "authors": [
      "Dimitrios E. Diamantis",
      "Dimitris K. Iakovidis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.08372"
  },
  {
    "id": "arXiv:2202.08373",
    "title": "Text-Based Action-Model Acquisition for Planning",
    "abstract": "Although there have been approaches that are capable of learning action\nmodels from plan traces, there is no work on learning action models from\ntextual observations, which is pervasive and much easier to collect from\nreal-world applications compared to plan traces. In this paper we propose a\nnovel approach to learning action models from natural language texts by\nintegrating Constraint Satisfaction and Natural Language Processing techniques.\nSpecifically, we first build a novel language model to extract plan traces from\ntexts, and then build a set of constraints to generate action models based on\nthe extracted plan traces. After that, we iteratively improve the language\nmodel and constraints until we achieve the convergent language model and action\nmodels. We empirically exhibit that our approach is both effective and\nefficient.",
    "descriptor": "",
    "authors": [
      "Kebing Jin",
      "Huaixun Chen",
      "Hankz Hankui Zhuo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.08373"
  },
  {
    "id": "arXiv:2202.08376",
    "title": "How to Fill the Optimum Set? Population Gradient Descent with Harmless  Diversity",
    "abstract": "Although traditional optimization methods focus on finding a single optimal\nsolution, most objective functions in modern machine learning problems,\nespecially those in deep learning, often have multiple or infinite numbers of\noptima. Therefore, it is useful to consider the problem of finding a set of\ndiverse points in the optimum set of an objective function. In this work, we\nframe this problem as a bi-level optimization problem of maximizing a diversity\nscore inside the optimum set of the main loss function, and solve it with a\nsimple population gradient descent framework that iteratively updates the\npoints to maximize the diversity score in a fashion that does not hurt the\noptimization of the main loss. We demonstrate that our method can efficiently\ngenerate diverse solutions on a variety of applications, including\ntext-to-image generation, text-to-mesh generation, molecular conformation\ngeneration and ensemble neural network training.",
    "descriptor": "",
    "authors": [
      "Chengyue Gong",
      "Lemeng Wu",
      "Qiang Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.08376"
  },
  {
    "id": "arXiv:2202.08381",
    "title": "Improving Performance Bounds for Weighted Round-Robin Schedulers under  Constrained Cross-Traffic",
    "abstract": "Weighted round robin (WRR) is a simple, efficient packet scheduler providing\nlow latency and fairness by assigning flow weights that define the number of\npossible packets to be sent consecutively. A variant of WRR that mitigates its\ntendency to increase burstiness, called interleaved weighted round robin\n(IWRR), has seen analytical treatment recently \\cite{TLBB21}; a network\ncalculus approach was used to obtain the best-possible strict service curve.\nFrom a different perspective, WRR can also be interpreted as an emulation of an\nidealized fair scheduler known as generalized processor sharing (GPS). Inspired\nby profound literature results on the performance analysis of GPS, we show that\nboth, WRR and IWRR, belong to a larger class of fair schedulers called\nbandwidth-sharing policies. We use this insight to derive new strict service\ncurves for both schedulers that, under the additional assumption of constrained\ncross-traffic flows, can significantly improve the state-of-the-art results and\nlead to smaller delay bounds.",
    "descriptor": "",
    "authors": [
      "Vlad-Cristian Constantin",
      "Paul Nikolaus",
      "Jens Schmitt"
    ],
    "subjectives": [
      "Performance (cs.PF)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2202.08381"
  },
  {
    "id": "arXiv:2202.08383",
    "title": "Morse Graphs: Topological Tools for Analyzing the Global Dynamics of  Robot Controllers",
    "abstract": "Understanding the global dynamics of a robot controller, such as identifying\nattractors and their regions of attraction (RoA), is important for safe\ndeployment and synthesizing more effective hybrid controllers. This paper\nproposes a topological framework to analyze the global dynamics of robot\ncontrollers, even data-driven ones, in an effective and explainable way. It\nbuilds a combinatorial representation representing the underlying system's\nstate space and non-linear dynamics, which is summarized in a directed acyclic\ngraph, the Morse graph. The approach only probes the dynamics locally by\nforward propagating short trajectories over a state-space discretization, which\nneeds to be a Lipschitz-continuous function. The framework is evaluated given\neither numerical or data-driven controllers for classical robotic benchmarks.\nIt is compared against established analytical and recent machine learning\nalternatives for estimating the RoAs of such controllers. It is shown to\noutperform them in accuracy and efficiency. It also provides deeper insights as\nit describes the global dynamics up to the discretization's resolution. This\nallows to use the Morse graph to identify how to synthesize controllers to form\nimproved hybrid solutions or how to identify the physical limitations of a\nrobotic system.",
    "descriptor": "",
    "authors": [
      "Ewerton R. Vieira",
      "Edgar Granados",
      "Aravind Sivaramakrishnan",
      "Marcio Gameiro",
      "Konstantin Mischaikow",
      "Kostas E. Bekris"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2202.08383"
  },
  {
    "id": "arXiv:2202.08384",
    "title": "Limitations of Neural Collapse for Understanding Generalization in Deep  Learning",
    "abstract": "The recent work of Papyan, Han, & Donoho (2020) presented an intriguing\n\"Neural Collapse\" phenomenon, showing a structural property of interpolating\nclassifiers in the late stage of training. This opened a rich area of\nexploration studying this phenomenon. Our motivation is to study the upper\nlimits of this research program: How far will understanding Neural Collapse\ntake us in understanding deep learning? First, we investigate its role in\ngeneralization. We refine the Neural Collapse conjecture into two separate\nconjectures: collapse on the train set (an optimization property) and collapse\non the test distribution (a generalization property). We find that while Neural\nCollapse often occurs on the train set, it does not occur on the test set. We\nthus conclude that Neural Collapse is primarily an optimization phenomenon,\nwith as-yet-unclear connections to generalization. Second, we investigate the\nrole of Neural Collapse in feature learning. We show simple, realistic\nexperiments where training longer leads to worse last-layer features, as\nmeasured by transfer-performance on a downstream task. This suggests that\nneural collapse is not always desirable for representation learning, as\npreviously claimed. Finally, we give preliminary evidence of a \"cascading\ncollapse\" phenomenon, wherein some form of Neural Collapse occurs not only for\nthe last layer, but in earlier layers as well. We hope our work encourages the\ncommunity to continue the rich line of Neural Collapse research, while also\nconsidering its inherent limitations.",
    "descriptor": "",
    "authors": [
      "Like Hui",
      "Mikhail Belkin",
      "Preetum Nakkiran"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.08384"
  },
  {
    "id": "arXiv:2202.08388",
    "title": "Generalizable Information Theoretic Causal Representation",
    "abstract": "It is evidence that representation learning can improve model's performance\nover multiple downstream tasks in many real-world scenarios, such as image\nclassification and recommender systems. Existing learning approaches rely on\nestablishing the correlation (or its proxy) between features and the downstream\ntask (labels), which typically results in a representation containing cause,\neffect and spurious correlated variables of the label. Its generalizability may\ndeteriorate because of the unstability of the non-causal parts. In this paper,\nwe propose to learn causal representation from observational data by\nregularizing the learning procedure with mutual information measures according\nto our hypothetical causal graph. The optimization involves a counterfactual\nloss, based on which we deduce a theoretical guarantee that the\ncausality-inspired learning is with reduced sample complexity and better\ngeneralization ability. Extensive experiments show that the models trained on\ncausal representations learned by our approach is robust under adversarial\nattacks and distribution shift.",
    "descriptor": "",
    "authors": [
      "Mengyue Yang",
      "Xinyu Cai",
      "Furui Liu",
      "Xu Chen",
      "Zhitang Chen",
      "Jianye Hao",
      "Jun Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.08388"
  },
  {
    "id": "arXiv:2202.08391",
    "title": "Graph Masked Autoencoder",
    "abstract": "Transformers have achieved state-of-the-art performance in learning graph\nrepresentations. However, there are still some challenges when applying\ntransformers to real-world scenarios due to the fact that deep transformers are\nhard to be trained from scratch and the memory consumption is large. To address\nthe two challenges, we propose Graph Masked Autoencoders (GMAE), a\nself-supervised model for learning graph representations, where vanilla graph\ntransformers are used as the encoder and the decoder. GMAE takes partially\nmasked graphs as input, and reconstructs the features of the masked nodes. We\nadopt asymmetric encoder-decoder design, where the encoder is a deep graph\ntransformer and the decoder is a shallow graph transformer. The masking\nmechanism and the asymmetric design make GMAE a memory-efficient model compared\nwith conventional transformers. We show that, compared with training from\nscratch, the graph transformer pre-trained using GMAE can achieve much better\nperformance after fine-tuning. We also show that, when serving as a\nconventional self-supervised graph representation model and using an SVM model\nas the downstream graph classifier, GMAE achieves state-of-the-art performance\non 5 of the 7 benchmark datasets.",
    "descriptor": "",
    "authors": [
      "Hongxu Chen",
      "Sixiao Zhang",
      "Guandong Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2202.08391"
  },
  {
    "id": "arXiv:2202.08393",
    "title": "Robust Reinforcement Learning via Genetic Curriculum",
    "abstract": "Achieving robust performance is crucial when applying deep reinforcement\nlearning (RL) in safety critical systems. Some of the state of the art\napproaches try to address the problem with adversarial agents, but these agents\noften require expert supervision to fine tune and prevent the adversary from\nbecoming too challenging to the trainee agent. While other approaches involve\nautomatically adjusting environment setups during training, they have been\nlimited to simple environments where low-dimensional encodings can be used.\nInspired by these approaches, we propose genetic curriculum, an algorithm that\nautomatically identifies scenarios in which the agent currently fails and\ngenerates an associated curriculum to help the agent learn to solve the\nscenarios and acquire more robust behaviors. As a non-parametric optimizer, our\napproach uses a raw, non-fixed encoding of scenarios, reducing the need for\nexpert supervision and allowing our algorithm to adapt to the changing\nperformance of the agent. Our empirical studies show improvement in robustness\nover the existing state of the art algorithms, providing training curricula\nthat result in agents being 2 - 8x times less likely to fail without\nsacrificing cumulative reward. We include an ablation study and share insights\non why our algorithm outperforms prior approaches.",
    "descriptor": "\nComments: Accepted to 2022 IEEE International Conference on Robotics and Automation (ICRA)\n",
    "authors": [
      "Yeeho Song",
      "Jeff Schneider"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.08393"
  },
  {
    "id": "arXiv:2202.08395",
    "title": "SWIM: Selective Write-Verify for Computing-in-Memory Neural Accelerators",
    "abstract": "Computing-in-Memory architectures based on non-volatile emerging memories\nhave demonstrated great potential for deep neural network (DNN) acceleration\nthanks to their high energy efficiency. However, these emerging devices can\nsuffer from significant variations during the mapping process i.e., programming\nweights to the devices), and if left undealt with, can cause significant\naccuracy degradation. The non-ideality of weight mapping can be compensated by\niterative programming with a write-verify scheme, i.e., reading the conductance\nand rewriting if necessary. In all existing works, such a practice is applied\nto every single weight of a DNN as it is being mapped, which requires extensive\nprogramming time. In this work, we show that it is only necessary to select a\nsmall portion of the weights for write-verify to maintain the DNN accuracy,\nthus achieving significant speedup. We further introduce a second derivative\nbased technique SWIM, which only requires a single pass of forward and\nbackpropagation, to efficiently select the weights that need write-verify.\nExperimental results on various DNN architectures for different datasets show\nthat SWIM can achieve up to 10x programming speedup compared with conventional\nfull-blown write-verify while attaining a comparable accuracy.",
    "descriptor": "",
    "authors": [
      "Zheyu Yan",
      "Xiaobo Sharon Hu",
      "Yiyu Shi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.08395"
  },
  {
    "id": "arXiv:2202.08396",
    "title": "Augment with Care: Contrastive Learning for the Boolean Satisfiability  Problem",
    "abstract": "Supervised learning can improve the design of state-of-the-art solvers for\ncombinatorial problems, but labelling large numbers of combinatorial instances\nis often impractical due to exponential worst-case complexity. Inspired by the\nrecent success of contrastive pre-training for images, we conduct a scientific\nstudy of the effect of augmentation design on contrastive pre-training for the\nBoolean satisfiability problem. While typical graph contrastive pre-training\nuses label-agnostic augmentations, our key insight is that many combinatorial\nproblems have well-studied invariances, which allow for the design of\nlabel-preserving augmentations. We find that label-preserving augmentations are\ncritical for the success of contrastive pre-training. We show that our\nrepresentations are able to achieve comparable test accuracy to\nfully-supervised learning while using only 1% of the labels. We also\ndemonstrate that our representations are more transferable to larger problems\nfrom unseen domains.",
    "descriptor": "",
    "authors": [
      "Haonan Duan",
      "Pashootan Vaezipoor",
      "Max B. Paulus",
      "Yangjun Ruan",
      "Chris J. Maddison"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2202.08396"
  },
  {
    "id": "arXiv:2202.08399",
    "title": "Shift-Memory Network for Temporal Scene Segmentation",
    "abstract": "Semantic segmentation has achieved great accuracy in understanding spatial\nlayout. For real-time tasks based on dynamic scenes, we extend semantic\nsegmentation in temporal domain to enhance the spatial accuracy with motion. We\nutilize a shift-mode network over streaming input to ensure zero-latency\noutput. For the data overlap under shifting network, this paper identifies\nrepeated computation in fixed periods across network layers. To avoid this\nredundancy, we derive a Shift-Memory Network (SMN) from encoding-decoding\nbaseline to reuse the network values without accuracy loss. Trained in\npatch-mode, the SMN extracts the network parameters for SMN to perform\ninference promptly in compact memory. We segment dynamic scenes from 1D\nscanning input and 2D video. The experiments of SMN achieve equivalent accuracy\nas shift-mode but in faster inference speeds and much smaller memory. This will\nfacilitate semantic segmentation in real-time application on edge devices.",
    "descriptor": "\nComments: 10 pages, 10 figures\n",
    "authors": [
      "Guo Cheng",
      "Jiang Yu Zheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.08399"
  },
  {
    "id": "arXiv:2202.08400",
    "title": "Real Time Motion Planning Using Constrained Iterative Linear Quadratic  Regulator for On-Road Self-Driving",
    "abstract": "Collision avoidance is one of the most challenging tasks people need to\nconsider for developing the self-driving technology. In this paper we propose a\nnew spatiotemporal motion planning algorithm that efficiently solves a\nconstrained nonlinear optimal control problem using the iterative linear\nquadratic regulator (iLQR), which takes into account the uncertain driving\nbehaviors of the traffic vehicles and minimizes the collision risks between the\nself-driving vehicle (referred to as the \"ego\" vehicle) and the traffic\nvehicles such that the ego vehicle is able to maintain sufficiently large\ndistances to all the surrounding vehicles for achieving the desired collision\navoidance maneuver in traffic. To this end, we introduce the concept of the\n\"collision polygon\" for computing the minimum distances between the ego vehicle\nand the traffic vehicles, and provide two different solutions for designing the\nconstraints of the motion planning problem by properly modeling the behaviors\nof the traffic vehicles in order to evaluate the collision risk. Finally, the\niLQR motion planning algorithm is validated in multiple real-time tasks for\ncollision avoidance using both a simulator and a level-3 autonomous driving\ntest platform.",
    "descriptor": "\nComments: 10 pages with 10 figures and 2 tables\n",
    "authors": [
      "Changxi You"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2202.08400"
  },
  {
    "id": "arXiv:2202.08401",
    "title": "Multi-Modal Fusion in Contact-Rich Precise Tasks via Hierarchical Policy  Learning",
    "abstract": "Combined visual and force feedback play an essential role in contact-rich\nrobotic manipulation tasks. Current methods focus on developing the feedback\ncontrol around a single modality while underrating the synergy of the sensors.\nFusing different sensor modalities is necessary but remains challenging. A key\nchallenge is to achieve an effective multi-modal and generalized control scheme\nto novel objects with precision. This paper proposes a practical multi-modal\nsensor fusion mechanism using hierarchical policy learning. To begin with, we\nuse a self-supervised encoder that extracts multi-view visual features and a\nhybrid motion/force controller that regulates force behaviors. Next, the\nmulti-modality fusion is simplified by hierarchical integration of the vision,\nforce, and proprioceptive data in the reinforcement learning (RL) algorithm.\nMoreover, with hierarchical policy learning, the control scheme can exploit the\nvisual feedback limits and explore the contribution of individual modality in\nprecise tasks. Experiments indicate that robots with the control scheme could\nassemble objects with 0.25mm clearance in simulation. The system could be\ngeneralized to widely varied initial configurations and new shapes. Experiments\nvalidate that the simulated system can be robustly transferred to reality\nwithout fine-tuning.",
    "descriptor": "",
    "authors": [
      "Piaopiao Jin",
      "Yinjie Lin",
      "Yanchao Tan",
      "Tiefeng Li",
      "Wei Yang"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.08401"
  },
  {
    "id": "arXiv:2202.08402",
    "title": "Federated Stochastic Gradient Descent Begets Self-Induced Momentum",
    "abstract": "Federated learning (FL) is an emerging machine learning method that can be\napplied in mobile edge systems, in which a server and a host of clients\ncollaboratively train a statistical model utilizing the data and computation\nresources of the clients without directly exposing their privacy-sensitive\ndata. We show that running stochastic gradient descent (SGD) in such a setting\ncan be viewed as adding a momentum-like term to the global aggregation process.\nBased on this finding, we further analyze the convergence rate of a federated\nlearning system by accounting for the effects of parameter staleness and\ncommunication resources. These results advance the understanding of the\nFederated SGD algorithm, and also forges a link between staleness analysis and\nfederated computing systems, which can be useful for systems designers.",
    "descriptor": "",
    "authors": [
      "Howard H. Yang",
      "Zuozhu Liu",
      "Yaru Fu",
      "Tony Q. S. Quek",
      "H. Vincent Poor"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.08402"
  },
  {
    "id": "arXiv:2202.08406",
    "title": "The Unboxing Experience: Exploration and Design of Initial Interactions  Between Children and Social Robots",
    "abstract": "Social robots are increasingly introduced into children's lives as\neducational and social companions, yet little is known about how these products\nmight best be introduced to their environments. The emergence of the \"unboxing\"\nphenomenon in media suggests that introduction is key to technology adoption\nwhere initial impressions are made. To better understand this phenomenon toward\ndesigning a positive unboxing experience in the context of social robots for\nchildren, we conducted three field studies with families of children aged 8 to\n13: (1) an exploratory free-play activity ($n=12$); (2) a co-design session\n($n=11$) that informed the development of a prototype box and a curated\nunboxing experience; and (3) a user study ($n=9$) that evaluated children's\nexperiences. Our findings suggest the unboxing experience of social robots can\nbe improved through the design of a creative aesthetic experience that engages\nthe child socially to guide initial interactions and foster a positive\nchild-robot relationship.",
    "descriptor": "\nComments: To be published in 2022 CHI Conference on Human Factors in Computing Systems (CHI '22)\n",
    "authors": [
      "Christine P Lee",
      "Bengisu Cagiltay",
      "Bilge Mutlu"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2202.08406"
  },
  {
    "id": "arXiv:2202.08407",
    "title": "AutoScore-Ordinal: An interpretable machine learning framework for  generating scoring models for ordinal outcomes",
    "abstract": "Background: Risk prediction models are useful tools in clinical\ndecision-making which help with risk stratification and resource allocations\nand may lead to a better health care for patients. AutoScore is a machine\nlearning-based automatic clinical score generator for binary outcomes. This\nstudy aims to expand the AutoScore framework to provide a tool for\ninterpretable risk prediction for ordinal outcomes. Methods: The\nAutoScore-Ordinal framework is generated using the same 6 modules of the\noriginal AutoScore algorithm including variable ranking, variable\ntransformation, score derivation (from proportional odds models), model\nselection, score fine-tuning, and model evaluation. To illustrate the\nAutoScore-Ordinal performance, the method was conducted on electronic health\nrecords data from the emergency department at Singapore General Hospital over\n2008 to 2017. The model was trained on 70% of the data, validated on 10% and\ntested on the remaining 20%. Results: This study included 445,989 inpatient\ncases, where the distribution of the ordinal outcome was 80.7% alive without\n30-day readmission, 12.5% alive with 30-day readmission, and 6.8% died\ninpatient or by day 30 post discharge. Two point-based risk prediction models\nwere developed using two sets of 8 predictor variables identified by the\nflexible variable selection procedure. The two models indicated reasonably good\nperformance measured by mean area under the receiver operating characteristic\ncurve (0.785 and 0.793) and generalized c-index (0.737 and 0.760), which were\ncomparable to alternative models. Conclusion: AutoScore-Ordinal provides an\nautomated and easy-to-use framework for development and validation of risk\nprediction models for ordinal outcomes, which can systematically identify\npotential predictors from high-dimensional data.",
    "descriptor": "",
    "authors": [
      "Seyed Ehsan Saffari",
      "Yilin Ning",
      "Xie Feng",
      "Bibhas Chakraborty",
      "Victor Volovici",
      "Roger Vaughan",
      "Marcus Eng Hock Ong",
      "Nan Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.08407"
  },
  {
    "id": "arXiv:2202.08408",
    "title": "Multivariate Time Series Forecasting with Dynamic Graph Neural ODEs",
    "abstract": "Multivariate time series forecasting has long received significant attention\nin real-world applications, such as energy consumption and traffic prediction.\nWhile recent methods demonstrate good forecasting abilities, they suffer from\nthree fundamental limitations. (i) Discrete neural architectures: Interlacing\nindividually parameterized spatial and temporal blocks to encode rich\nunderlying patterns leads to discontinuous latent state trajectories and higher\nforecasting numerical errors. (ii) High complexity: Discrete approaches\ncomplicate models with dedicated designs and redundant parameters, leading to\nhigher computational and memory overheads. (iii) Reliance on graph priors:\nRelying on predefined static graph structures limits their effectiveness and\npracticability in real-world applications. In this paper, we address all the\nabove limitations by proposing a continuous model to forecast Multivariate Time\nseries with dynamic Graph neural Ordinary Differential Equations (MTGODE).\nSpecifically, we first abstract multivariate time series into dynamic graphs\nwith time-evolving node features and unknown graph structures. Then, we design\nand solve a neural ODE to complement missing graph topologies and unify both\nspatial and temporal message passing, allowing deeper graph propagation and\nfine-grained temporal information aggregation to characterize stable and\nprecise latent spatial-temporal dynamics. Our experiments demonstrate the\nsuperiorities of MTGODE from various perspectives on five time series benchmark\ndatasets.",
    "descriptor": "\nComments: 14 pages, 6 figures, 5 tables\n",
    "authors": [
      "Ming Jin",
      "Yu Zheng",
      "Yuan-Fang Li",
      "Siheng Chen",
      "Bin Yang",
      "Shirui Pan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.08408"
  },
  {
    "id": "arXiv:2202.08409",
    "title": "Million.js: A Fast, Compiler-Augmented Virtual DOM for Performant  JavaScript UI Libraries",
    "abstract": "The need for developing and delivering interactive web applications has grown\nrapidly. Thus, JavaScript User Interface (UI) libraries were introduced, at the\ndetriment of performance and bundle size. To solve this problem, Million.js was\ncreated to allow for the creation of compiler-augmented JavaScript UI libraries\nthat are extensible, performant, and lightweight. This was accomplished by\ndesigning a computationally efficient diffing algorithm that relies on a\ncompiler, and then measuring the performance with a series of relevant and\nexhaustive benchmarks. Additionally, built-in mechanisms are implemented to\nallow for imperative optimizations, allowing the compiler to directly skip\nruntime diffing. When compared to other methods of virtual DOM rendering, these\nfindings showed that Million.js had superior performance, with 133% to 300%\nmore operations per second than other Virtual DOM libraries.",
    "descriptor": "\nComments: mirror: this https URL\n",
    "authors": [
      "Aiden Bai"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2202.08409"
  },
  {
    "id": "arXiv:2202.08413",
    "title": "Entropic Associative Memory for Manuscript Symbols",
    "abstract": "Manuscript symbols can be stored, recognized and retrieved from an entropic\ndigital memory that is associative and distributed but yet declarative; memory\nretrieval is a constructive operation, memory cues to objects not contained in\nthe memory are rejected directly without search, and memory operations can be\nperformed through parallel computations. Manuscript symbols, both letters and\nnumerals, are represented in Associative Memory Registers that have an\nassociated entropy. The memory recognition operation obeys an entropy trade-off\nbetween precision and recall, and the entropy level impacts on the quality of\nthe objects recovered through the memory retrieval operation. The present\nproposal is contrasted in several dimensions with neural networks models of\nassociative memory. We discuss the operational characteristics of the entropic\nassociative memory for retrieving objects with both complete and incomplete\ninformation, such as severe occlusions. The experiments reported in this paper\nadd evidence on the potential of this framework for developing practical\napplications and computational models of natural memory.",
    "descriptor": "\nComments: 24 pages, 13 figures\n",
    "authors": [
      "Rafael Morales",
      "No\u00e9 Hern\u00e1ndez",
      "Ricardo Cruz",
      "Victor D. Cruz",
      "Luis A. Pineda"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.08413"
  },
  {
    "id": "arXiv:2202.08414",
    "title": "FPIC: A Novel Semantic Dataset for Optical PCB Assurance",
    "abstract": "The continued outsourcing of printed circuit board (PCB) fabrication to\noverseas venues necessitates increased hardware assurance capabilities. Toward\nthis end, several automated optical inspection (AOI) techniques have been\nproposed in the past exploring various aspects of PCB images acquired using\ndigital cameras. In this work, we review state-of-the-art AOI techniques and\nobserved the strong, rapid trend toward machine learning (ML) solutions. These\nrequire significant amounts of labeled ground truth data, which is lacking in\nthe publicly available PCB data space. We propose the FICS PBC Image Collection\n(FPIC) dataset to address this bottleneck in available large-volume, diverse,\nsemantic annotations. Additionally, this work covers the potential increase in\nhardware security capabilities and observed methodological distinctions\nhighlighted during data collection.",
    "descriptor": "\nComments: Dataset is available at this https URL ; Submitted to ACM JETC\n",
    "authors": [
      "Nathan Jessurun",
      "Olivia P. Dizon-Paradis",
      "Jacob Harrison",
      "Shajib Ghosh",
      "Mark M. Tehranipoor",
      "Damon L. Woodard",
      "Navid Asadizanjani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2202.08414"
  },
  {
    "id": "arXiv:2202.08417",
    "title": "Retrieval-Augmented Reinforcement Learning",
    "abstract": "Most deep reinforcement learning (RL) algorithms distill experience into\nparametric behavior policies or value functions via gradient updates. While\neffective, this approach has several disadvantages: (1) it is computationally\nexpensive, (2) it can take many updates to integrate experiences into the\nparametric model, (3) experiences that are not fully integrated do not\nappropriately influence the agent's behavior, and (4) behavior is limited by\nthe capacity of the model. In this paper we explore an alternative paradigm in\nwhich we train a network to map a dataset of past experiences to optimal\nbehavior. Specifically, we augment an RL agent with a retrieval process\n(parameterized as a neural network) that has direct access to a dataset of\nexperiences. This dataset can come from the agent's past experiences, expert\ndemonstrations, or any other relevant source. The retrieval process is trained\nto retrieve information from the dataset that may be useful in the current\ncontext, to help the agent achieve its goal faster and more efficiently. We\nintegrate our method into two different RL agents: an offline DQN agent and an\nonline R2D2 agent. In offline multi-task problems, we show that the\nretrieval-augmented DQN agent avoids task interference and learns faster than\nthe baseline DQN agent. On Atari, we show that retrieval-augmented R2D2 learns\nsignificantly faster than the baseline R2D2 agent and achieves higher scores.\nWe run extensive ablations to measure the contributions of the components of\nour proposed method.",
    "descriptor": "",
    "authors": [
      "Anirudh Goyal",
      "Abram L. Friesen",
      "Andrea Banino",
      "Theophane Weber",
      "Nan Rosemary Ke",
      "Adria Puigdomenech Badia",
      "Arthur Guez",
      "Mehdi Mirza",
      "Ksenia Konyushkova",
      "Michal Valko",
      "Simon Osindero",
      "Timothy Lillicrap",
      "Nicolas Heess",
      "Charles Blundell"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.08417"
  },
  {
    "id": "arXiv:2202.08418",
    "title": "Neural Marionette: Unsupervised Learning of Motion Skeleton and Latent  Dynamics from Volumetric Video",
    "abstract": "We present Neural Marionette, an unsupervised approach that discovers the\nskeletal structure from a dynamic sequence and learns to generate diverse\nmotions that are consistent with the observed motion dynamics. Given a video\nstream of point cloud observation of an articulated body under arbitrary\nmotion, our approach discovers the unknown low-dimensional skeletal\nrelationship that can effectively represent the movement. Then the discovered\nstructure is utilized to encode the motion priors of dynamic sequences in a\nlatent structure, which can be decoded to the relative joint rotations to\nrepresent the full skeletal motion. Our approach works without any prior\nknowledge of the underlying motion or skeletal structure, and we demonstrate\nthat the discovered structure is even comparable to the hand-labeled ground\ntruth skeleton in representing a 4D sequence of motion. The skeletal structure\nembeds the general semantics of possible motion space that can generate motions\nfor diverse scenarios. We verify that the learned motion prior is generalizable\nto the multi-modal sequence generation, interpolation of two poses, and motion\nretargeting to a different skeletal structure.",
    "descriptor": "\nComments: 7 pages (main), 10 pages (appendix) and to be appeared in AAAI2022\n",
    "authors": [
      "Jinseok Bae",
      "Hojun Jang",
      "Cheol-Hui Min",
      "Hyungun Choi",
      "Young Min Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.08418"
  },
  {
    "id": "arXiv:2202.08420",
    "title": "Time-Correlated Sparsification for Efficient Over-the-Air Model  Aggregation in Wireless Federated Learning",
    "abstract": "Federated edge learning (FEEL) is a promising distributed machine learning\n(ML) framework to drive edge intelligence applications. However, due to the\ndynamic wireless environments and the resource limitations of edge devices,\ncommunication becomes a major bottleneck. In this work, we propose\ntime-correlated sparsification with hybrid aggregation (TCS-H) for\ncommunication-efficient FEEL, which exploits jointly the power of model\ncompression and over-the-air computation. By exploiting the temporal\ncorrelations among model parameters, we construct a global sparsification mask,\nwhich is identical across devices, and thus enables efficient model aggregation\nover-the-air. Each device further constructs a local sparse vector to explore\nits own important parameters, which are aggregated via digital communication\nwith orthogonal multiple access. We further design device scheduling and power\nallocation algorithms for TCS-H. Experiment results show that, under limited\ncommunication resources, TCS-H can achieve significantly higher accuracy\ncompared to the conventional top-K sparsification with orthogonal model\naggregation, with both i.i.d. and non-i.i.d. data distributions.",
    "descriptor": "\nComments: 6 pages, 3 figures, to appear in IEEE ICC 2022\n",
    "authors": [
      "Yuxuan Sun",
      "Sheng Zhou",
      "Zhisheng Niu",
      "Deniz G\u00fcnd\u00fcz"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.08420"
  },
  {
    "id": "arXiv:2202.08423",
    "title": "Chord-Conditioned Melody Choralization with Controllable Harmonicity and  Polyphonicity",
    "abstract": "Melody choralization, i.e. generating a four-part chorale based on a\nuser-given melody, has long been closely associated with J.S. Bach chorales.\nPrevious neural network-based systems rarely focus on chorale generation\nconditioned on a chord progression, and none of them realised controllable\nmelody choralization. To enable neural networks to learn the general principles\nof counterpoint from Bach's chorales, we first design a music representation\nthat encoded chord symbols for chord conditioning. We then propose DeepChoir, a\nmelody choralization system, which can generate a four-part chorale for a given\nmelody conditioned on a chord progression. Furthermore, with the improved\ndensity sampling, a user can control the extent of harmonicity and\npolyphonicity for the chorale generated by DeepChoir. Experimental results\nreveal the effectiveness of our data representation and the controllability of\nDeepChoir over harmonicity and polyphonicity. The code and generated samples\n(chorales, folk songs and a symphony) of DeepChoir, and the dataset we use now\nare available at https://github.com/sander-wood/deepchoir.",
    "descriptor": "\nComments: 7 pages, 4 figures, 2 tables\n",
    "authors": [
      "Shangda Wu",
      "Xiaobing Li",
      "Maosong Sun"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2202.08423"
  },
  {
    "id": "arXiv:2202.08429",
    "title": "CHEX: Multiversion Replay with Ordered Checkpoints",
    "abstract": "In scientific computing and data science disciplines, it is often necessary\nto share application workflows and repeat results. Current tools containerize\napplication workflows, and share the resulting container for repeating results.\nThese tools, due to containerization, do improve sharing of results. However,\nthey do not improve the efficiency of replay. In this paper, we present the\nmultiversion replay problem which arises when multiple versions of an\napplication are containerized, and each version must be replayed to repeat\nresults. To avoid executing each version separately, we develop CHEX, which\ncheckpoints program state and determines when it is permissible to reuse\nprogram state across versions. It does so using system call-based execution\nlineage. Our capability to identify common computations across versions enables\nus to consider optimizing replay using an in-memory cache, based on a\ncheckpoint-restore-switch system. We show the multiversion replay problem is\nNP-hard, and propose efficient heuristics for it. CHEX reduces overall replay\ntime by sharing common computations but avoids storing a large number of\ncheckpoints. We demonstrate that CHEX maintains lightweight package sharing,\nand improves the total time of multiversion replay by 50% on average.",
    "descriptor": "\nComments: 13 pages, 13 figures, VLDB\n",
    "authors": [
      "Naga Nithin Manne",
      "Shilvi Satpati",
      "Tanu Malik",
      "Amitabha Bagchi",
      "Ashish Gehani",
      "Amitabh Chaudhary"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2202.08429"
  },
  {
    "id": "arXiv:2202.08430",
    "title": "Emotion Recognition among Couples: A Survey",
    "abstract": "Couples' relationships affect the physical health and emotional well-being of\npartners. Automatically recognizing each partner's emotions could give a better\nunderstanding of their individual emotional well-being, enable interventions\nand provide clinical benefits. In the paper, we summarize and synthesize works\nthat have focused on developing and evaluating systems to automatically\nrecognize the emotions of each partner based on couples' interaction or\nconversation contexts. We identified 28 articles from IEEE, ACM, Web of\nScience, and Google Scholar that were published between 2010 and 2021. We\ndetail the datasets, features, algorithms, evaluation, and results of each work\nas well as present main themes. We also discuss current challenges, research\ngaps and propose future research directions. In summary, most works have used\naudio data collected from the lab with annotations done by external experts and\nused supervised machine learning approaches for binary classification of\npositive and negative affect. Performance results leave room for improvement\nwith significant research gaps such as no recognition using data from daily\nlife. This survey will enable new researchers to get an overview of this field\nand eventually enable the development of emotion recognition systems to inform\ninterventions to improve the emotional well-being of couples.",
    "descriptor": "\nComments: 22 pages, Under review at ACM Computing Surveys (CSUR)\n",
    "authors": [
      "George Boateng",
      "Elgar Fleisch",
      "Tobias Kowatsch"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2202.08430"
  },
  {
    "id": "arXiv:2202.08432",
    "title": "AKB-48: A Real-World Articulated Object Knowledge Base",
    "abstract": "Human life is populated with articulated objects. A comprehensive\nunderstanding of articulated objects, namely appearance, structure, physics\nproperty, and semantics, will benefit many research communities. As current\narticulated object understanding solutions are usually based on synthetic\nobject dataset with CAD models without physics properties, which prevent\nsatisfied generalization from simulation to real-world applications in visual\nand robotics tasks. To bridge the gap, we present AKB-48: a large-scale\nArticulated object Knowledge Base which consists of 2,037 real-world 3D\narticulated object models of 48 categories. Each object is described by a\nknowledge graph ArtiKG. To build the AKB-48, we present a fast articulation\nknowledge modeling (FArM) pipeline, which can fulfill the ArtiKG for an\narticulated object within 10-15 minutes, and largely reduce the cost for object\nmodeling in the real world. Using our dataset, we propose AKBNet, a novel\nintegral pipeline for Category-level Visual Articulation Manipulation (C-VAM)\ntask, in which we benchmark three sub-tasks, namely pose estimation, object\nreconstruction and manipulation. Dataset, codes, and models will be publicly\navailable at https://liuliu66.github.io/articulationobjects/.",
    "descriptor": "",
    "authors": [
      "Liu Liu",
      "Wenqiang Xu",
      "Haoyuan Fu",
      "Sucheng Qian",
      "Yang Han",
      "Cewu Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.08432"
  },
  {
    "id": "arXiv:2202.08433",
    "title": "ADD 2022: the First Audio Deep Synthesis Detection Challenge",
    "abstract": "Audio deepfake detection is an emerging topic, which was included in the\nASVspoof 2021. However, the recent shared tasks have not covered many real-life\nand challenging scenarios. The first Audio Deep synthesis Detection challenge\n(ADD) was motivated to fill in the gap. The ADD 2022 includes three tracks:\nlow-quality fake audio detection (LF), partially fake audio detection (PF) and\naudio fake game (FG). The LF track focuses on dealing with bona fide and fully\nfake utterances with various real-world noises etc. The PF track aims to\ndistinguish the partially fake audio from the real. The FG track is a rivalry\ngame, which includes two tasks: an audio generation task and an audio fake\ndetection task. In this paper, we describe the datasets, evaluation metrics,\nand protocols. We also report major findings that reflect the recent advances\nin audio deepfake detection tasks.",
    "descriptor": "\nComments: Accepted by ICASSP 2022\n",
    "authors": [
      "Jiangyan Yi",
      "Ruibo Fu",
      "Jianhua Tao",
      "Shuai Nie",
      "Haoxin Ma",
      "Chenglong Wang",
      "Tao Wang",
      "Zhengkun Tian",
      "Ye Bai",
      "Cunhang Fan",
      "Shan Liang",
      "Shiming Wang",
      "Shuai Zhang",
      "Xinrui Yan",
      "Le Xu",
      "Zhengqi Wen",
      "Haizhou Li"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2202.08433"
  },
  {
    "id": "arXiv:2202.08434",
    "title": "A Survey of Explainable Reinforcement Learning",
    "abstract": "Explainable reinforcement learning (XRL) is an emerging subfield of\nexplainable machine learning that has attracted considerable attention in\nrecent years. The goal of XRL is to elucidate the decision-making process of\nlearning agents in sequential decision-making settings. In this survey, we\npropose a novel taxonomy for organizing the XRL literature that prioritizes the\nRL setting. We overview techniques according to this taxonomy. We point out\ngaps in the literature, which we use to motivate and outline a roadmap for\nfuture work.",
    "descriptor": "",
    "authors": [
      "Stephanie Milani",
      "Nicholay Topin",
      "Manuela Veloso",
      "Fei Fang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.08434"
  },
  {
    "id": "arXiv:2202.08436",
    "title": "PENCIL: Deep Learning with Noisy Labels",
    "abstract": "Deep learning has achieved excellent performance in various computer vision\ntasks, but requires a lot of training examples with clean labels. It is easy to\ncollect a dataset with noisy labels, but such noise makes networks overfit\nseriously and accuracies drop dramatically. To address this problem, we propose\nan end-to-end framework called PENCIL, which can update both network parameters\nand label estimations as label distributions. PENCIL is independent of the\nbackbone network structure and does not need an auxiliary clean dataset or\nprior information about noise, thus it is more general and robust than existing\nmethods and is easy to apply. PENCIL can even be used repeatedly to obtain\nbetter performance. PENCIL outperforms previous state-of-the-art methods by\nlarge margins on both synthetic and real-world datasets with different noise\ntypes and noise rates. And PENCIL is also effective in multi-label\nclassification tasks through adding a simple attention structure on backbone\nnetworks. Experiments show that PENCIL is robust on clean datasets, too.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:1903.07788\n",
    "authors": [
      "Kun Yi",
      "Guo-Hua Wang",
      "Jianxin Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.08436"
  },
  {
    "id": "arXiv:2202.08443",
    "title": "Two continuous (4, 5) pairs of explicit 9-stage Runge-Kutta methods",
    "abstract": "An 11-dimensional family of embedded (4, 5) pairs of explicit 9-stage\nRunge-Kutta methods with an interpolant of order 5 is derived. Two optimized\nfor efficiency pairs are presented.",
    "descriptor": "\nComments: 18 pages, 9 figures, 4 tables\n",
    "authors": [
      "Misha Stepanov"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.08443"
  },
  {
    "id": "arXiv:2202.08444",
    "title": "A Survey on Deep Reinforcement Learning-based Approaches for Adaptation  and Generalization",
    "abstract": "Deep Reinforcement Learning (DRL) aims to create intelligent agents that can\nlearn to solve complex problems efficiently in a real-world environment.\nTypically, two learning goals: adaptation and generalization are used for\nbaselining DRL algorithm's performance on different tasks and domains. This\npaper presents a survey on the recent developments in DRL-based approaches for\nadaptation and generalization. We begin by formulating these goals in the\ncontext of task and domain. Then we review the recent works under those\napproaches and discuss future research directions through which DRL algorithms'\nadaptability and generalizability can be enhanced and potentially make them\napplicable to a broad range of real-world problems.",
    "descriptor": "",
    "authors": [
      "Pamul Yadav",
      "Ashutosh Mishra",
      "Junyong Lee",
      "Shiho Kim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.08444"
  },
  {
    "id": "arXiv:2202.08445",
    "title": "Extended MSO Model Checking via Small Vertex Integrity",
    "abstract": "We study the model checking problem of an extended $\\mathsf{MSO}$ with local\nand global cardinality constraints, called\n$\\mathsf{MSO}^{\\mathsf{GL}}_{\\mathsf{Lin}}$, introduced recently by Knop,\nKouteck\\'{y}, Masa\\v{r}\\'{\\i}k, and Toufar [Log. Methods Comput. Sci., 15(4),\n2019]. We show that the problem is fixed-parameter tractable parameterized by\nvertex integrity, where vertex integrity is a graph parameter standing between\nvertex cover number and treedepth. Our result thus fill a gap between the\nfixed-parameter tractability parameterized by vertex cover number and the\nW[1]-hardness parameterized by treedepth.",
    "descriptor": "",
    "authors": [
      "Tatsuya Gima",
      "Yota Otachi"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2202.08445"
  },
  {
    "id": "arXiv:2202.08446",
    "title": "MeNTT: A Compact and Efficient Processing-in-Memory Number Theoretic  Transform (NTT) Accelerator",
    "abstract": "Lattice-based cryptography (LBC) exploiting Learning with Errors (LWE)\nproblems is a promising candidate for post-quantum cryptography. Number\ntheoretic transform (NTT) is the latency- and energy- dominant process in the\ncomputation of LWE problems. This paper presents a compact and efficient\nin-MEmory NTT accelerator, named MeNTT, which explores optimized computation in\nand near a 6T SRAM array. Specifically-designed peripherals enable fast and\nefficient modular operations. Moreover, a novel mapping strategy reduces the\ndata flow between NTT stages into a unique pattern, which greatly simplifies\nthe routing among processing units (i.e., SRAM column in this work), reducing\nenergy and area overheads. The accelerator achieves significant latency and\nenergy reductions over prior arts.",
    "descriptor": "\nComments: This paper has been accepted to IEEE Transactions on Very Large Scale Integration (TVLSI)\n",
    "authors": [
      "Dai Li",
      "Akhil Pakala",
      "Kaiyuan Yang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.08446"
  },
  {
    "id": "arXiv:2202.08449",
    "title": "V2X-Sim: A Virtual Collaborative Perception Dataset for Autonomous  Driving",
    "abstract": "Vehicle-to-everything (V2X), which denotes the collaboration between a\nvehicle and any entity in its surrounding, can fundamentally improve the\nperception in self-driving systems. As the individual perception rapidly\nadvances, collaborative perception has made little progress due to the shortage\nof public V2X datasets. In this work, we present the V2X-Sim dataset, the first\npublic large-scale collaborative perception dataset in autonomous driving.\nV2X-Sim provides: 1) well-synchronized recordings from roadside infrastructure\nand multiple vehicles at the intersection to enable collaborative perception,\n2) multi-modality sensor streams to facilitate multi-modality perception, 3)\ndiverse well-annotated ground truth to support various downstream tasks\nincluding detection, tracking, and segmentation. We seek to inspire research on\nmulti-agent multi-modality multi-task perception, and our virtual dataset is\npromising to promote the development of collaborative perception before\nrealistic datasets become widely available.",
    "descriptor": "\nComments: 2021 IEEE International Conference on Computer Vision (ICCV) Simulation Technology for Embodied AI Workshop, Spotlight\n",
    "authors": [
      "Yiming Li",
      "Ziyan An",
      "Zixun Wang",
      "Yiqi Zhong",
      "Siheng Chen",
      "Chen Feng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.08449"
  },
  {
    "id": "arXiv:2202.08450",
    "title": "Design-Bench: Benchmarks for Data-Driven Offline Model-Based  Optimization",
    "abstract": "Black-box model-based optimization (MBO) problems, where the goal is to find\na design input that maximizes an unknown objective function, are ubiquitous in\na wide range of domains, such as the design of proteins, DNA sequences,\naircraft, and robots. Solving model-based optimization problems typically\nrequires actively querying the unknown objective function on design proposals,\nwhich means physically building the candidate molecule, aircraft, or robot,\ntesting it, and storing the result. This process can be expensive and time\nconsuming, and one might instead prefer to optimize for the best design using\nonly the data one already has. This setting -- called offline MBO -- poses\nsubstantial and different algorithmic challenges than more commonly studied\nonline techniques. A number of recent works have demonstrated success with\noffline MBO for high-dimensional optimization problems using high-capacity deep\nneural networks. However, the lack of standardized benchmarks in this emerging\nfield is making progress difficult to track. To address this, we present\nDesign-Bench, a benchmark for offline MBO with a unified evaluation protocol\nand reference implementations of recent methods. Our benchmark includes a suite\nof diverse and realistic tasks derived from real-world optimization problems in\nbiology, materials science, and robotics that present distinct challenges for\noffline MBO. Our benchmark and reference implementations are released at\ngithub.com/rail-berkeley/design-bench and\ngithub.com/rail-berkeley/design-baselines.",
    "descriptor": "",
    "authors": [
      "Brandon Trabucco",
      "Xinyang Geng",
      "Aviral Kumar",
      "Sergey Levine"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.08450"
  },
  {
    "id": "arXiv:2202.08452",
    "title": "PCB Component Detection using Computer Vision for Hardware Assurance",
    "abstract": "Printed Circuit Board (PCB) assurance in the optical domain is a crucial\nfield of study. Though there are many existing PCB assurance methods using\nimage processing, computer vision (CV), and machine learning (ML), the PCB\nfield is complex and increasingly evolving so new techniques are required to\novercome the emerging problems. Existing ML-based methods outperform\ntraditional CV methods, however they often require more data, have low\nexplainability, and can be difficult to adapt when a new technology arises. To\novercome these challenges, CV methods can be used in tandem with ML methods. In\nparticular, human-interpretable CV algorithms such as those that extract color,\nshape, and texture features increase PCB assurance explainability. This allows\nfor incorporation of prior knowledge, which effectively reduce the number of\ntrainable ML parameters and thus, the amount of data needed to achieve high\naccuracy when training or retraining an ML model. Hence, this study explores\nthe benefits and limitations of a variety of common computer vision-based\nfeatures for the task of PCB component detection using semantic data. Results\nof this study indicate that color features demonstrate promising performance\nfor PCB component detection. The purpose of this paper is to facilitate\ncollaboration between the hardware assurance, computer vision, and machine\nlearning communities.",
    "descriptor": "",
    "authors": [
      "Wenwei Zhao",
      "Suprith Gurudu",
      "Shayan Taheri",
      "Shajib Ghosh",
      "Mukhil Azhagan Mallaiyan Sathiaseelan",
      "Navid Asadizanjani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.08452"
  },
  {
    "id": "arXiv:2202.08453",
    "title": "TraSeTR: Track-to-Segment Transformer with Contrastive Query for  Instance-level Instrument Segmentation in Robotic Surgery",
    "abstract": "Surgical instrument segmentation -- in general a pixel classification task --\nis fundamentally crucial for promoting cognitive intelligence in robot-assisted\nsurgery (RAS). However, previous methods are struggling with discriminating\ninstrument types and instances. To address the above issues, we explore a mask\nclassification paradigm that produces per-segment predictions. We propose\nTraSeTR, a novel Track-to-Segment Transformer that wisely exploits tracking\ncues to assist surgical instrument segmentation. TraSeTR jointly reasons about\nthe instrument type, location, and identity with instance-level predictions\ni.e., a set of class-bbox-mask pairs, by decoding query embeddings.\nSpecifically, we introduce the prior query that encoded with previous temporal\nknowledge, to transfer tracking signals to current instances via identity\nmatching. A contrastive query learning strategy is further applied to reshape\nthe query feature space, which greatly alleviates the tracking difficulty\ncaused by large temporal variations. The effectiveness of our method is\ndemonstrated with state-of-the-art instrument type segmentation results on\nthree public datasets, including two RAS benchmarks from EndoVis Challenges and\none cataract surgery dataset CaDIS.",
    "descriptor": "\nComments: Accepted by ICRA 2022\n",
    "authors": [
      "Zixu Zhao",
      "Yueming Jin",
      "Pheng-Ann Heng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.08453"
  },
  {
    "id": "arXiv:2202.08455",
    "title": "Transformer for Graphs: An Overview from Architecture Perspective",
    "abstract": "Recently, Transformer model, which has achieved great success in many\nartificial intelligence fields, has demonstrated its great potential in\nmodeling graph-structured data. Till now, a great variety of Transformers has\nbeen proposed to adapt to the graph-structured data. However, a comprehensive\nliterature review and systematical evaluation of these Transformer variants for\ngraphs are still unavailable. It's imperative to sort out the existing\nTransformer models for graphs and systematically investigate their\neffectiveness on various graph tasks. In this survey, we provide a\ncomprehensive review of various Graph Transformer models from the architectural\ndesign perspective. We first disassemble the existing models and conclude three\ntypical ways to incorporate the graph information into the vanilla Transformer:\n1) GNNs as Auxiliary Modules, 2) Improved Positional Embedding from Graphs, and\n3) Improved Attention Matrix from Graphs. Furthermore, we implement the\nrepresentative components in three groups and conduct a comprehensive\ncomparison on various kinds of famous graph data benchmarks to investigate the\nreal performance gain of each component. Our experiments confirm the benefits\nof current graph-specific modules on Transformer and reveal their advantages on\ndifferent kinds of graph tasks.",
    "descriptor": "\nComments: 8 pages, 1 figures\n",
    "authors": [
      "Erxue Min",
      "Runfa Chen",
      "Yatao Bian",
      "Tingyang Xu",
      "Kangfei Zhao",
      "Wenbing Huang",
      "Peilin Zhao",
      "Junzhou Huang",
      "Sophia Ananiadou",
      "Yu Rong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.08455"
  },
  {
    "id": "arXiv:2202.08461",
    "title": "The Gene of Scientific Success",
    "abstract": "This paper elaborates how to identify and evaluate causal factors to improve\nscientific impact. Currently, analyzing scientific impact can be beneficial to\nvarious academic activities including funding application, mentor\nrecommendation, and discovering potential cooperators etc. It is universally\nacknowledged that high-impact scholars often have more opportunities to receive\nawards as an encouragement for their hard working. Therefore, scholars spend\ngreat efforts in making scientific achievements and improving scientific impact\nduring their academic life. However, what are the determinate factors that\ncontrol scholars' academic success? The answer to this question can help\nscholars conduct their research more efficiently. Under this consideration, our\npaper presents and analyzes the causal factors that are crucial for scholars'\nacademic success. We first propose five major factors including\narticle-centered factors, author-centered factors, venue-centered factors,\ninstitution-centered factors, and temporal factors. Then, we apply recent\nadvanced machine learning algorithms and jackknife method to assess the\nimportance of each causal factor. Our empirical results show that\nauthor-centered and article-centered factors have the highest relevancy to\nscholars' future success in the computer science area. Additionally, we\ndiscover an interesting phenomenon that the h-index of scholars within the same\ninstitution or university are actually very close to each other.",
    "descriptor": "",
    "authors": [
      "Xiangjie Kong",
      "Jun Zhang",
      "Da Zhang",
      "Yi Bu",
      "Ying Ding",
      "Feng Xia"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.08461"
  },
  {
    "id": "arXiv:2202.08463",
    "title": "A Creativity Survey of Parallel Sorting Algorithm",
    "abstract": "Sorting is one of the most fundamental problems in the field of computer\nscience. With the rapid development of manycore processors, it shows great\nimportance to design efficient parallel sort algorithm on manycore\narchitecture. This paper studies the parallel memory sorting method on modern\nhardware, and summarizes its research status and progress. Classify the\nresearch problems, research methods and measurement methods of the target\npapers and references. In the end, we summarize all the researches and list the\ndirections not researched and innovative places. Keywords: Sorting Algorithm,\nParallel Algorithm, Parallel Optimization, CPU, GPU, Memory Hierarchy",
    "descriptor": "",
    "authors": [
      "Tianyi Yu",
      "Wei Li"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2202.08463"
  },
  {
    "id": "arXiv:2202.08465",
    "title": "End-to-End Training of Both Translation Models in the Back-Translation  Framework",
    "abstract": "Semi-supervised learning algorithms in neural machine translation (NMT) have\nsignificantly improved translation quality compared to the supervised learning\nalgorithms by using additional monolingual corpora. Among them,\nback-translation is a theoretically well-structured and cutting-edge method.\nGiven two pre-trained NMT models between source and target languages, one\ntranslates a monolingual sentence as a latent sentence, and the other\nreconstructs the monolingual input sentence given the latent sentence.\nTherefore, previous works tried to apply the variational auto-encoder's (VAE)\ntraining framework to the back-translation framework. However, the discrete\nproperty of the latent sentence made it impossible to use backpropagation in\nthe framework. This paper proposes a categorical reparameterization trick that\ngenerates a differentiable sentence, with which we practically implement the\nVAE's training framework for the back-translation and train it by end-to-end\nbackpropagation. In addition, we propose several regularization techniques that\nare especially advantageous to this framework. In our experiments, we\ndemonstrate that our method makes backpropagation available through the latent\nsentences and improves the BLEU scores on the datasets of the WMT18 translation\ntask.",
    "descriptor": "",
    "authors": [
      "DongNyeong Heo",
      "Heeyoul Choi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.08465"
  },
  {
    "id": "arXiv:2202.08466",
    "title": "Insightful Mining Equilibria",
    "abstract": "The selfish mining attack, arguably the most famous game-theoretic attack in\nblockchain, indicates that the Bitcoin protocol is not incentive-compatible.\nMost subsequent works mainly focus on strengthening the selfish mining\nstrategy, thus enabling a single strategic agent more likely to deviate. In\nsharp contrast, little attention has been paid to the resistant behavior\nagainst the selfish mining attack, let alone further equilibrium analysis for\nminers and mining pools in the blockchain as a multi-agent system.\nIn this paper, first, we propose a strategy called insightful mining to\ncounteract selfish mining. By infiltrating an undercover miner into the selfish\npool, the insightful pool could acquire the number of its hidden blocks. We\nprove that, with this extra insight, the utility of the insightful pool could\nbe strictly greater than the selfish pool's when they have the same mining\npower. Then we investigate the mining game where all pools can either choose to\nbe honest or take the insightful mining strategy. We characterize the Nash\nequilibrium of this mining game, and derive three corollaries: (a) each mining\ngame has a pure Nash equilibrium; (b) honest mining is a Nash equilibrium if\nthe largest mining pool has a fraction of mining power no more than 1/3; (c)\nthere are at most two insightful pools under equilibrium no matter how the\nmining power is distributed.",
    "descriptor": "",
    "authors": [
      "Mengqian Zhang",
      "Yuhao Li",
      "Jichen Li",
      "Chaozhe Kong",
      "Xiaotie Deng"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2202.08466"
  },
  {
    "id": "arXiv:2202.08469",
    "title": "An analysis of citing and referencing habits across all scholarly  disciplines: approaches and trends in bibliographic metadata errors",
    "abstract": "Considering citing and referencing as facilitators of scientific\ncommunication and information retrieving; as providers of metadata which\nsupport searches in bibliographic catalogs and, as facets of descriptive\nrepresentation, the discussion expands previous approaches concerning errors in\nbibliographic metadata, based on the analysis of reference elements, i.e.\nbibliographic references, mentions, quotations, and respective in-text\nreference pointers, from current articles of journals across the 27 subject\nareas composing SCImago Journal & Country Rank. The findings pointed that\nbibliographic errors have perpetuated for decades and, insofar as information\nsupports other than printed documents become more popular among the scientific\ncommunity, bibliographic errors and their possible causes have increased,\ndespite the encouraged use of technological facilities, i.e. the reference\nmanagers. The results also suggested a trend of distancing among representative\ndescription facets, i.e., citing, referencing and cataloging, since the\nrevision being carried within the representative description, which culminated\non the publication of the conceptual models FRBR and IFLA-lRM, do not consider\nciting and referencing matters.",
    "descriptor": "",
    "authors": [
      "Erika Alves dos Santos",
      "Silvio Peroni",
      "Marcos Luiz Mucheroni"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2202.08469"
  },
  {
    "id": "arXiv:2202.08471",
    "title": "TransCG: A Large-Scale Real-World Dataset for Transparent Object Depth  Completion and Grasping",
    "abstract": "Transparent objects are common in our daily life and frequently handled in\nthe automated production line. Robust vision-based robotic grasping and\nmanipulation for these objects would be beneficial for automation. However, the\nmajority of current grasping algorithms would fail in this case since they\nheavily rely on the depth image, while ordinary depth sensors usually fail to\nproduce accurate depth information for transparent objects owing to the\nreflection and refraction of light. In this work, we address this issue by\ncontributing a large-scale real-world dataset for transparent object depth\ncompletion, which contains 57,715 RGB-D images from 130 different scenes. Our\ndataset is the first large-scale real-world dataset and provides the most\ncomprehensive annotation. Cross-domain experiments show that our dataset has a\ngreat generalization ability. Moreover, we propose an end-to-end depth\ncompletion network, which takes the RGB image and the inaccurate depth map as\ninputs and outputs a refined depth map. Experiments demonstrate superior\nefficacy, efficiency and robustness of our method over previous works, and it\nis able to process images of high resolutions under limited hardware resources.\nReal robot experiment shows that our method can also be applied to novel object\ngrasping robustly. The full dataset and our method are publicly available at\nwww.graspnet.net/transcg.",
    "descriptor": "\nComments: project page: www.graspnet.net/transcg\n",
    "authors": [
      "Hongjie Fang",
      "Hao-Shu Fang",
      "Sheng Xu",
      "Cewu Lu"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.08471"
  },
  {
    "id": "arXiv:2202.08472",
    "title": "Full-Span Log-Linear Model and Fast Learning Algorithm",
    "abstract": "The full-span log-linear(FSLL) model introduced in this paper is considered\nan $n$-th order Boltzmann machine, where $n$ is the number of all variables in\nthe target system. Let $X=(X_0,...,X_{n-1})$ be finite discrete random\nvariables that can take $|X|=|X_0|...|X_{n-1}|$ different values. The FSLL\nmodel has $|X|-1$ parameters and can represent arbitrary positive distributions\nof $X$. The FSLL model is a \"highest-order\" Boltzmann machine; nevertheless, we\ncan compute the dual parameters of the model distribution, which plays\nimportant roles in exponential families, in $O(|X|\\log|X|)$ time. Furthermore,\nusing properties of the dual parameters of the FSLL model, we can construct an\nefficient learning algorithm. The FSLL model is limited to small probabilistic\nmodels up to $|X|\\approx2^{25}$; however, in this problem domain, the FSLL\nmodel flexibly fits various true distributions underlying the training data\nwithout any hyperparameter tuning. The experiments presented that the FSLL\nsuccessfully learned six training datasets such that $|X|=2^{20}$ within one\nminute with a laptop PC.",
    "descriptor": "\nComments: 25pages, 6figures\n",
    "authors": [
      "Kazuya Takabatake",
      "Shotaro Akaho"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.08472"
  },
  {
    "id": "arXiv:2202.08477",
    "title": "A Method for Decrypting Data Infected with Hive Ransomware",
    "abstract": "Among the many types of malicious codes, ransomware poses a major threat.\nRansomware encrypts data and demands a ransom in exchange for decryption. As\ndata recovery is impossible if the encryption key is not obtained, some\ncompanies suffer from considerable damage, such as the payment of huge amounts\nof money or the loss of important data. In this paper, we analyzed Hive\nransomware, which appeared in June 2021. Hive ransomware has caused immense\nharm, leading the FBI to issue an alert about it. To minimize the damage caused\nby Hive Ransomware and to help victims recover their files, we analyzed Hive\nRansomware and studied recovery methods. By analyzing the encryption process of\nHive ransomware, we confirmed that vulnerabilities exist by using their own\nencryption algorithm. We have recovered the master key for generating the file\nencryption key partially, to enable the decryption of data encrypted by Hive\nransomware. We recovered 95% of the master key without the attacker's RSA\nprivate key and decrypted the actual infected data. To the best of our\nknowledge, this is the first successful attempt at decrypting Hive ransomware.\nIt is expected that our method can be used to reduce the damage caused by Hive\nransomware.",
    "descriptor": "",
    "authors": [
      "Giyoon Kim",
      "Soram Kim",
      "Soojin Kang",
      "Jongsung Kim"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.08477"
  },
  {
    "id": "arXiv:2202.08479",
    "title": "Revisiting the Evaluation Metrics of Paraphrase Generation",
    "abstract": "Paraphrase generation is an important NLP task that has achieved significant\nprogress recently. However, one crucial problem is overlooked, `how to evaluate\nthe quality of paraphrase?'. Most existing paraphrase generation models use\nreference-based metrics (e.g., BLEU) from neural machine translation (NMT) to\nevaluate their generated paraphrase. Such metrics' reliability is hardly\nevaluated, and they are only plausible when there exists a standard reference.\nTherefore, this paper first answers one fundamental question, `Are existing\nmetrics reliable for paraphrase generation?'. We present two conclusions that\ndisobey conventional wisdom in paraphrasing generation: (1) existing metrics\npoorly align with human annotation in system-level and segment-level paraphrase\nevaluation. (2) reference-free metrics outperform reference-based metrics,\nindicating that the standard references are unnecessary to evaluate the\nparaphrase's quality. Such empirical findings expose a lack of reliable\nautomatic evaluation metrics. Therefore, this paper proposes BBScore, a\nreference-free metric that can reflect the generated paraphrase's quality.\nBBScore consists of two sub-metrics: S3C score and SelfBLEU, which correspond\nto two criteria for paraphrase evaluation: semantic preservation and diversity.\nBy connecting two sub-metrics, BBScore significantly outperforms existing\nparaphrase evaluation metrics.",
    "descriptor": "",
    "authors": [
      "Lingfeng Shen",
      "Haiyun Jiang",
      "Lemao Liu",
      "Shuming Shi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.08479"
  },
  {
    "id": "arXiv:2202.08480",
    "title": "Structural and Semantic Contrastive Learning for Self-supervised Node  Representation Learning",
    "abstract": "Graph Contrastive Learning (GCL) recently has drawn much research interest\nfor learning generalizable, transferable, and robust node representations in a\nself-supervised fashion. In general, the contrastive learning process in GCL is\nperformed on top of the representations learned by a graph neural network (GNN)\nbackbone, which transforms and propagates the node contextual information based\non its local neighborhoods. However, existing GCL efforts have severe\nlimitations in terms of both encoding architecture, augmentation, and\ncontrastive objective, making them commonly inefficient and ineffective to use\nin different datasets. In this work, we go beyond the existing unsupervised GCL\ncounterparts and address their limitations by proposing a simple yet effective\nframework S$^3$-CL. Specifically, by virtue of the proposed structural and\nsemantic contrastive learning, even a simple neural network is able to learn\nexpressive node representations that preserve valuable structural and semantic\npatterns. Our experiments demonstrate that the node representations learned by\nS$^3$-CL achieve superior performance on different downstream tasks compared to\nthe state-of-the-art GCL methods.",
    "descriptor": "",
    "authors": [
      "Kaize Ding",
      "Yancheng Wang",
      "Yingzhen Yang",
      "Huan Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.08480"
  },
  {
    "id": "arXiv:2202.08482",
    "title": "Online Scheduling of Time-Critical Tasks to Minimize the Number of  Calibrations",
    "abstract": "We study the online scheduling problem where the machines need to be\ncalibrated before processing any jobs. To calibrate a machine, it will take\n$\\lambda$ time steps as the activation time, and then the machine will remain\ncalibrated status for $T$ time steps. The job can only be processed by the\nmachine that is in calibrated status. Given a set of jobs arriving online, each\nof the jobs is characterized by a release time, a processing time, and a\ndeadline. We assume that there is an infinite number of machines for usage. The\nobjective is to minimize the total number of calibrations while feasibly\nscheduling all jobs.\nFor the case that all jobs have unit processing times, we propose an\n$\\mathcal{O}(\\lambda)$-competitive algorithm, which is asymptotically optimal.\nWhen $\\lambda=0$, the problem is degraded to rent minimization, where our\nalgorithm achieves a competitive ratio of $3e+7(\\approx 15.16)$ which improves\nupon the previous results for such problems.",
    "descriptor": "",
    "authors": [
      "Zuzhi Chen",
      "Jialin Zhang"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2202.08482"
  },
  {
    "id": "arXiv:2202.08485",
    "title": "Multi-Objective Model Selection for Time Series Forecasting",
    "abstract": "Research on time series forecasting has predominantly focused on developing\nmethods that improve accuracy. However, other criteria such as training time or\nlatency are critical in many real-world applications. We therefore address the\nquestion of how to choose an appropriate forecasting model for a given dataset\namong the plethora of available forecasting methods when accuracy is only one\nof many criteria. For this, our contributions are two-fold. First, we present a\ncomprehensive benchmark, evaluating 7 classical and 6 deep learning forecasting\nmethods on 44 heterogeneous, publicly available datasets. The benchmark code is\nopen-sourced along with evaluations and forecasts for all methods. These\nevaluations enable us to answer open questions such as the amount of data\nrequired for deep learning models to outperform classical ones. Second, we\nleverage the benchmark evaluations to learn good defaults that consider\nmultiple objectives such as accuracy and latency. By learning a mapping from\nforecasting models to performance metrics, we show that our method PARETOSELECT\nis able to accurately select models from the Pareto front -- alleviating the\nneed to train or evaluate many forecasting models for model selection. To the\nbest of our knowledge, PARETOSELECT constitutes the first method to learn\ndefault models in a multi-objective setting.",
    "descriptor": "",
    "authors": [
      "Oliver Borchert",
      "David Salinas",
      "Valentin Flunkert",
      "Tim Januschowski",
      "Stephan G\u00fcnnemann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.08485"
  },
  {
    "id": "arXiv:2202.08486",
    "title": "Energy-Efficient UAV Communications: A Generalised Propulsion Energy  Consumption Model",
    "abstract": "This paper proposes a generalised propulsion energy consumption model (PECM)\nfor rotary-wing ummanned aerial vehicles (UAVs) under the consideration of the\npractical thrust-to-weight ratio (TWR) with respect to the velocity,\nacceleration and direction change of the UAVs. To verify the effectiveness of\nthe proposed PECM, we consider a UAV-enabled communication system, where a\nrotary-wing UAV serves multiple ground users as an aerial base station. We aim\nto maximize the energy efficiency (EE) of the UAV by jointly optimizing the\nuser scheduling and UAV trajectory variables. However, the formulated problem\nis a non-convex fractional integer programming problem, which is challenging to\nobtain its optimal solution. To tackle this, we propose an efficient iterative\nalgorithm by decomposing the original problem into two sub-problems to obtain a\nsuboptimal solution based on the successive convex approximation technique.\nSimulation results show that the optimized UAV trajectory by applying the\nproposed PECM are smoother and the corresponding EE has significant improvement\nas compared to other benchmark schemes.",
    "descriptor": "\nComments: 5 pages, 4 figures\n",
    "authors": [
      "Xinhong Dai",
      "Bin Duo",
      "Xiaojun Yuan",
      "Wanbin Tang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.08486"
  },
  {
    "id": "arXiv:2202.08487",
    "title": "LiDAR-Inertial 3D SLAM with Plane Constraint for Multi-story Building",
    "abstract": "The ubiquitous planes and structural consistency are the most apparent\nfeatures of indoor multi-story Buildings compared with outdoor environments. In\nthis paper, we propose a tightly coupled LiDAR-Inertial 3D SLAM framework with\nplane features for the multi-story building. The framework we proposed is\nmainly composed of three parts: tightly coupled LiDAR-Inertial odometry,\nextraction of representative planes of the structure, and factor graph\noptimization. By building a local map and inertial measurement unit (IMU)\npre-integration, we get LiDAR scan-to-local-map matching and IMU measurements,\nrespectively. Minimize the joint cost function to obtain the LiDAR-Inertial\nodometry information. Once a new keyframe is added to the graph, all the planes\nof this keyframe that can represent structural features are extracted to find\nthe constraint between different poses and stories. A keyframe-based factor\ngraph is conducted with the constraint of planes, and LiDAR-Inertial odometry\nfor keyframe poses refinement. The experimental results show that our algorithm\nhas outstanding performance in accuracy compared with the state-of-the-art\nalgorithms.",
    "descriptor": "",
    "authors": [
      "Jiashi Zhang",
      "Chengyang Zhang",
      "Jun Wu",
      "Jianxiang Jin",
      "Qiuguo Zhu"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.08487"
  },
  {
    "id": "arXiv:2202.08490",
    "title": "Dynamic Object Comprehension: A Framework For Evaluating Artificial  Visual Perception",
    "abstract": "Augmented and Mixed Reality are emerging as likely successors to the mobile\ninternet. However, many technical challenges remain. One of the key\nrequirements of these systems is the ability to create a continuity between\nphysical and virtual worlds, with the user's visual perception as the primary\ninterface medium. Building this continuity requires the system to develop a\nvisual understanding of the physical world. While there has been significant\nrecent progress in computer vision and AI techniques such as image\nclassification and object detection, success in these areas has not yet led to\nthe visual perception required for these critical MR and AR applications. A\nsignificant issue is that current evaluation criteria are insufficient for\nthese applications. To motivate and evaluate progress in this emerging area,\nthere is a need for new metrics. In this paper we outline limitations of\ncurrent evaluation criteria and propose new criteria.",
    "descriptor": "\nComments: Submitted to IEEE International Conference in Image Processing 2022\n",
    "authors": [
      "Scott Y.L. Chin",
      "Bradley R. Quinton"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.08490"
  },
  {
    "id": "arXiv:2202.08492",
    "title": "Feels Bad Man: Dissecting Automated Hateful Meme Detection Through the  Lens of Facebook's Challenge",
    "abstract": "Internet memes have become a dominant method of communication; at the same\ntime, however, they are also increasingly being used to advocate extremism and\nfoster derogatory beliefs. Nonetheless, we do not have a firm understanding as\nto which perceptual aspects of memes cause this phenomenon. In this work, we\nassess the efficacy of current state-of-the-art multimodal machine learning\nmodels toward hateful meme detection, and in particular with respect to their\ngeneralizability across platforms. We use two benchmark datasets comprising\n12,140 and 10,567 images from 4chan's \"Politically Incorrect\" board (/pol/) and\nFacebook's Hateful Memes Challenge dataset to train the competition's\ntop-ranking machine learning models for the discovery of the most prominent\nfeatures that distinguish viral hateful memes from benign ones. We conduct\nthree experiments to determine the importance of multimodality on\nclassification performance, the influential capacity of fringe Web communities\non mainstream social platforms and vice versa, and the models' learning\ntransferability on 4chan memes. Our experiments show that memes' image\ncharacteristics provide a greater wealth of information than its textual\ncontent. We also find that current systems developed for online detection of\nhate speech in memes necessitate further concentration on its visual elements\nto improve their interpretation of underlying cultural connotations, implying\nthat multimodal models fail to adequately grasp the intricacies of hate speech\nin memes and generalize across social media platforms.",
    "descriptor": "",
    "authors": [
      "Catherine Jennifer",
      "Fatemeh Tahmasbi",
      "Jeremy Blackburn",
      "Gianluca Stringhini",
      "Savvas Zannettou",
      "Emiliano De Cristofaro"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.08492"
  },
  {
    "id": "arXiv:2202.08494",
    "title": "Learning continuous models for continuous physics",
    "abstract": "Dynamical systems that evolve continuously over time are ubiquitous\nthroughout science and engineering. Machine learning (ML) provides data-driven\napproaches to model and predict the dynamics of such systems. A core issue with\nthis approach is that ML models are typically trained on discrete data, using\nML methodologies that are not aware of underlying continuity properties, which\nresults in models that often do not capture the underlying continuous dynamics\nof a system of interest. As a result, these ML models are of limited use for\nfor many scientific and engineering applications. To address this challenge, we\ndevelop a convergence test based on numerical analysis theory. Our test\nverifies whether a model has learned a function that accurately approximates a\nsystem's underlying continuous dynamics. Models that fail this test fail to\ncapture relevant dynamics, rendering them of limited utility for many\nscientific prediction tasks; while models that pass this test enable both\nbetter interpolation and better extrapolation in multiple ways. Our results\nillustrate how principled numerical analysis methods can be coupled with\nexisting ML training/testing methodologies to validate models for science and\nengineering applications.",
    "descriptor": "\nComments: 19 pages\n",
    "authors": [
      "Aditi S. Krishnapriyan",
      "Alejandro F. Queiruga",
      "N. Benjamin Erichson",
      "Michael W. Mahoney"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.08494"
  },
  {
    "id": "arXiv:2202.08495",
    "title": "Predict the Rover Mobility over Soft Terrain using Articulated Wheeled  Bevameter",
    "abstract": "Robot mobility is critical for mission success, especially in soft or\ndeformable terrains, where the complex wheel-soil interaction mechanics often\nleads to excessive wheel slip and sinkage, causing the eventual mission\nfailure. To improve the success rate, online mobility prediction using vision,\ninfrared imaging, or model-based stochastic methods have been used in the\nliterature. This paper proposes an on-board mobility prediction approach using\nan articulated wheeled bevameter that consists of a force-controlled arm and an\ninstrumented bevameter (with force and vision sensors) as its end-effector. The\nproposed bevameter, which emulates the traditional terramechanics tests such as\npressure-sinkage and shear experiments, can measure contact parameters ahead of\nthe rover's body in real-time, and predict the slip and sinkage of supporting\nwheels over the probed region. Based on the predicted mobility, the rover can\nselect a safer path in order to avoid dangerous regions such as those covered\nwith quicksand. Compared to the literature, our proposed method can avoid the\ncomplicated terramechanics modeling and time-consuming stochastic prediction;\nit can also mitigate the inaccuracy issues arising in non-contact vision-based\nmethods. We also conduct multiple experiments to validate the proposed\napproach.",
    "descriptor": "",
    "authors": [
      "Wenyao Zhang",
      "Shipeng Lv",
      "Feng Xue",
      "Chen Yao",
      "Zheng Zhu",
      "Zhenzhong Jia"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.08495"
  },
  {
    "id": "arXiv:2202.08497",
    "title": "The Development and Prospect of Code Clone",
    "abstract": "The application of code clone technology accelerates code search, improves\ncode reuse efficiency, and assists in software quality assessment and code\nvulnerability detection. However, the application of code clones also\nintroduces software quality issues and increases the cost of software\nmaintenance. As an important research field in software engineering, code clone\nhas been extensively explored and studied by researchers, and related studies\non various sub-research fields have emerged, including code clone detection,\ncode clone evolution, code clone analysis, etc. However, there lacks a\ncomprehensive exploration of the entire field of code clone, as well as an\nanalysis of the trend of each sub-research field. This paper collects related\nwork of code clones in the past ten years. In summary, the contributions of\nthis paper mainly include: (1) summarize and classify the sub-research fields\nof code clone, and explore the relative popularity and relation of these\nsub-research fields; (2) analyze the overall research trend of code clone and\neach sub-research field; (3) compare and analyze the difference between academy\nand industry regarding code clone research; (4) construct a network of\nresearchers, and excavate the major contributors in code clone research field;\n(5) The list of popular conferences and journals was statistically analyzed.\nThe popular research directions in the future include clone visualization,\nclone management, etc. For the clone detection technique, researchers can\noptimize the scalability and execution efficiency of the method, targeting\nparticular clone detection tasks and contextual environments, or apply the\ntechnology to other related research fields continuously.",
    "descriptor": "",
    "authors": [
      "Xunhui Zhang",
      "Tao Wang",
      "Yue Yu",
      "Yanzhi Zhang",
      "Yan Zhong",
      "Huaimin Wang"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2202.08497"
  },
  {
    "id": "arXiv:2202.08498",
    "title": "Mirror-Yolo: An attention-based instance segmentation and detection  model for mirrors",
    "abstract": "Mirrors can degrade the performance of computer vision models, however to\naccurately detect mirrors in images remains challenging. YOLOv4 achieves\nphenomenal results both in object detection accuracy and speed, nevertheless\nthe model often fails in detecting mirrors. In this paper, a novel mirror\ndetection method `Mirror-YOLO' is proposed, which mainly targets on mirror\ndetection. Based on YOLOv4, the proposed model embeds an attention mechanism\nfor better feature acquisition, and a hypercolumn-stairstep approach for\nfeature map fusion. Mirror-YOLO can also produce accurate bounding polygons for\ninstance segmentation. The effectiveness of our proposed model is demonstrated\nby our experiments, compared to the existing mirror detection methods, the\nproposed Mirror-YOLO achieves better performance in detection accuracy on the\nmirror image dataset.",
    "descriptor": "",
    "authors": [
      "Fengze Li",
      "Jieming Ma",
      "Zhongbei Tian",
      "Ji Ge",
      "Hai-Ning Liang",
      "Yungang Zhang",
      "Tianxi Wen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.08498"
  },
  {
    "id": "arXiv:2202.08499",
    "title": "The Complexity of SPEs in Mean-payoff Games",
    "abstract": "We establish that the subgame perfect equilibrium (SPE) threshold problem for\nmean-payoff games is NP-complete. While the SPE threshold problem was recently\nshown to be decidable (in doubly exponential time) and NP-hard, its exact worst\ncase complexity was left open.",
    "descriptor": "",
    "authors": [
      "L\u00e9onard Brice",
      "Jean-Fran\u00e7ois Raskin",
      "Marie van den Bogaard"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2202.08499"
  },
  {
    "id": "arXiv:2202.08502",
    "title": "CLS: Cross Labeling Supervision for Semi-Supervised Learning",
    "abstract": "It is well known that the success of deep neural networks is greatly\nattributed to large-scale labeled datasets. However, it can be extremely\ntime-consuming and laborious to collect sufficient high-quality labeled data in\nmost practical applications. Semi-supervised learning (SSL) provides an\neffective solution to reduce the cost of labeling by simultaneously leveraging\nboth labeled and unlabeled data. In this work, we present Cross Labeling\nSupervision (CLS), a framework that generalizes the typical pseudo-labeling\nprocess. Based on FixMatch, where a pseudo label is generated from a\nweakly-augmented sample to teach the prediction on a strong augmentation of the\nsame input sample, CLS allows the creation of both pseudo and complementary\nlabels to support both positive and negative learning. To mitigate the\nconfirmation bias of self-labeling and boost the tolerance to false labels, two\ndifferent initialized networks with the same structure are trained\nsimultaneously. Each network utilizes high-confidence labels from the other\nnetwork as additional supervision signals. During the label generation phase,\nadaptive sample weights are assigned to artificial labels according to their\nprediction confidence. The sample weight plays two roles: quantify the\ngenerated labels' quality and reduce the disruption of inaccurate labels on\nnetwork training. Experimental results on the semi-supervised classification\ntask show that our framework outperforms existing approaches by large margins\non the CIFAR-10 and CIFAR-100 datasets.",
    "descriptor": "",
    "authors": [
      "Yao Yao",
      "Junyi Shen",
      "Jin Xu",
      "Bin Zhong",
      "Li Xiao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.08502"
  },
  {
    "id": "arXiv:2202.08504",
    "title": "Finding Representative Sampling Subsets in Sensor Graphs using Time  Series Similarities",
    "abstract": "With the increasing use of IoT-enabled sensors, it is important to have\neffective methods for querying the sensors. For example, in a dense network of\nbattery-driven temperature sensors, it is often possible to query (sample) just\na subset of the sensors at any given time, since the values of the non-sampled\nsensors can be estimated from the sampled values. If we can divide the set of\nsensors into disjoint so-called representative sampling subsets that each\nrepresent the other sensors sufficiently well, we can alternate the sampling\nbetween the sampling subsets and thus, increase battery life significantly. In\nthis paper, we formulate the problem of finding representative sampling subsets\nas a graph problem on a so-called sensor graph with the sensors as nodes. Our\nproposed solution, SubGraphSample, consists of two phases. In Phase-I, we\ncreate edges in the sensor graph based on the similarities between the time\nseries of sensor values, analyzing six different techniques based on proven\ntime series similarity metrics. In Phase-II, we propose two new techniques and\nextend four existing ones to find the maximal number of representative sampling\nsubsets. Finally, we propose AutoSubGraphSample which auto-selects the best\ntechnique for Phase-I and Phase-II for a given dataset. Our extensive\nexperimental evaluation shows that our approach can yield significant battery\nlife improvements within realistic error bounds.",
    "descriptor": "",
    "authors": [
      "Roshni Chakraborty",
      "Josefine Holm",
      "Torben Bach Pedersen",
      "Petar Popovski"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2202.08504"
  },
  {
    "id": "arXiv:2202.08505",
    "title": "Schedule-based Analysis of Transmission Risk in Public Transportation  Systems",
    "abstract": "Airborne diseases, including COVID-19, raise the question of transmission\nrisk in public transportation systems. However, quantitative analysis of the\neffectiveness of transmission risk mitigation methods in public transportation\nis lacking. The paper develops a transmission risk modeling framework based on\nthe Wells-Riley model using as inputs transit operating characteristics,\nschedule, Origin-Destination (OD) demand, and virus characteristics. The model\nis sensitive to various factors that operators can control, as well as external\nfactors that may be subject of broader policy decisions (e.g. mask wearing).\nThe model is utilized to assess transmission risk as a function of OD flows,\nplanned operations, and factors such as mask-wearing, ventilation, and\ninfection rates. Using actual data from the Massachusetts Bay Transportation\nAuthority (MBTA) Red Line, the paper explores the transmission risk under\ndifferent infection rate scenarios, both in magnitude and spatial\ncharacteristics. The paper assesses the combined impact from viral load related\nfactors and passenger load factors. Increasing frequency can mitigate\ntransmission risk, but cannot fully compensate for increases in infection\nrates. Imbalanced passenger distribution on different cars of a train is shown\nto increase the overall system-wide infection probability. Spatial infection\nrate patterns should also be taken into account during policymaking as it is\nshown to impact transmission risk. For lines with branches, demand distribution\namong the branches is important and headway allocation adjustment among\nbranches to balance the load on trains to different branches can help reduce\nrisk.",
    "descriptor": "\nComments: Submitted to Transportation Research Part A: Policy and Practice on February 16, 2022\n",
    "authors": [
      "Jiali Zhou",
      "Haris N. Koutsopoulos"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Systems and Control (eess.SY)",
      "Physics and Society (physics.soc-ph)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2202.08505"
  },
  {
    "id": "arXiv:2202.08506",
    "title": "CSCNet: Contextual Semantic Consistency Network for Trajectory  Prediction in Crowded Spaces",
    "abstract": "Trajectory prediction aims to predict the movement trend of the agents like\npedestrians, bikers, vehicles. It is helpful to analyze and understand human\nactivities in crowded spaces and widely applied in many areas such as\nsurveillance video analysis and autonomous driving systems. Thanks to the\nsuccess of deep learning, trajectory prediction has made significant progress.\nThe current methods are dedicated to studying the agents' future trajectories\nunder the social interaction and the sceneries' physical constraints. Moreover,\nhow to deal with these factors still catches researchers' attention. However,\nthey ignore the \\textbf{Semantic Shift Phenomenon} when modeling these\ninteractions in various prediction sceneries. There exist several kinds of\nsemantic deviations inner or between social and physical interactions, which we\ncall the \"\\textbf{Gap}\". In this paper, we propose a \\textbf{C}ontextual\n\\textbf{S}emantic \\textbf{C}onsistency \\textbf{Net}work (\\textbf{CSCNet}) to\npredict agents' future activities with powerful and efficient context\nconstraints. We utilize a well-designed context-aware transfer to obtain the\nintermediate representations from the scene images and trajectories. Then we\neliminate the differences between social and physical interactions by aligning\nactivity semantics and scene semantics to cross the Gap. Experiments\ndemonstrate that CSCNet performs better than most of the current methods\nquantitatively and qualitatively.",
    "descriptor": "\nComments: Accepted by Pattern Recognition\n",
    "authors": [
      "Beihao Xia",
      "Conghao Wong",
      "Qinmu Peng",
      "Wei Yuan",
      "Xinge You"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.08506"
  },
  {
    "id": "arXiv:2202.08509",
    "title": "A Study of Designing Compact Audio-Visual Wake Word Spotting System  Based on Iterative Fine-Tuning in Neural Network Pruning",
    "abstract": "Audio-only-based wake word spotting (WWS) is challenging under noisy\nconditions due to environmental interference in signal transmission. In this\npaper, we investigate on designing a compact audio-visual WWS system by\nutilizing visual information to alleviate the degradation. Specifically, in\norder to use visual information, we first encode the detected lips to\nfixed-size vectors with MobileNet and concatenate them with acoustic features\nfollowed by the fusion network for WWS. However, the audio-visual model based\non neural networks requires a large footprint and a high computational\ncomplexity. To meet the application requirements, we introduce a neural network\npruning strategy via the lottery ticket hypothesis in an iterative fine-tuning\nmanner (LTH-IF), to the single-modal and multi-modal models, respectively.\nTested on our in-house corpus for audio-visual WWS in a home TV scene, the\nproposed audio-visual system achieves significant performance improvements over\nthe single-modality (audio-only or video-only) system under different noisy\nconditions. Moreover, LTH-IF pruning can largely reduce the network parameters\nand computations with no degradation of WWS performance, leading to a potential\nproduct solution for the TV wake-up scenario.",
    "descriptor": "\nComments: Accepted to ICASSP 2022. H. Zhou et al\n",
    "authors": [
      "Hengshun Zhou",
      "Jun Du",
      "Chao-Han Huck Yang",
      "Shifu Xiong",
      "Chin-Hui Lee"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2202.08509"
  },
  {
    "id": "arXiv:2202.08511",
    "title": "Scheduling Complexity of Interleaving Search",
    "abstract": "miniKanren is a lightweight embedded language for logic and relational\nprogramming. Many of its useful features come from a distinctive search\nstrategy, called interleaving search. However, with interleaving search\nconventional ways of reasoning about the complexity and performance of logical\nprograms become irrelevant. We identify an important key component --\nscheduling -- which makes the reasoning for miniKanren so different, and\npresent a semi-automatic technique to estimate the scheduling impact via\nsymbolic execution for a reasonably wide class of programs.",
    "descriptor": "",
    "authors": [
      "Dmitry Rozplokhas",
      "Dmitry Boulytchev"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2202.08511"
  },
  {
    "id": "arXiv:2202.08512",
    "title": "Visual Ground Truth Construction as Faceted Classification",
    "abstract": "Recent work in Machine Learning and Computer Vision has provided evidence of\nsystematic design flaws in the development of major object recognition\nbenchmark datasets. One such example is ImageNet, wherein, for several\ncategories of images, there are incongruences between the objects they\nrepresent and the labels used to annotate them. The consequences of this\nproblem are major, in particular considering the large number of machine\nlearning applications, not least those based on Deep Neural Networks, that have\nbeen trained on these datasets. In this paper we posit the problem to be the\nlack of a knowledge representation (KR) methodology providing the foundations\nfor the construction of these ground truth benchmark datasets. Accordingly, we\npropose a solution articulated in three main steps: (i) deconstructing the\nobject recognition process in four ordered stages grounded in the philosophical\ntheory of teleosemantics; (ii) based on such stratification, proposing a novel\nfour-phased methodology for organizing objects in classification hierarchies\naccording to their visual properties; and (iii) performing such classification\naccording to the faceted classification paradigm. The key novelty of our\napproach lies in the fact that we construct the classification hierarchies from\nvisual properties exploiting visual genus-differentiae, and not from\nlinguistically grounded properties. The proposed approach is validated by a set\nof experiments on the ImageNet hierarchy of musical experiments.",
    "descriptor": "",
    "authors": [
      "Fausto Giunchiglia",
      "Mayukh Bagchi",
      "Xiaolei Diao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.08512"
  },
  {
    "id": "arXiv:2202.08514",
    "title": "Survey on Self-supervised Representation Learning Using Image  Transformations",
    "abstract": "Deep neural networks need huge amount of training data, while in real world\nthere is a scarcity of data available for training purposes. To resolve these\nissues, self-supervised learning (SSL) methods are used. SSL using geometric\ntransformations (GT) is a simple yet powerful technique used in unsupervised\nrepresentation learning. Although multiple survey papers have reviewed SSL\ntechniques, there is none that only focuses on those that use geometric\ntransformations. Furthermore, such methods have not been covered in depth in\npapers where they are reviewed. Our motivation to present this work is that\ngeometric transformations have shown to be powerful supervisory signals in\nunsupervised representation learning. Moreover, many such works have found\ntremendous success, but have not gained much attention. We present a concise\nsurvey of SSL approaches that use geometric transformations. We shortlist six\nrepresentative models that use image transformations including those based on\npredicting and autoencoding transformations. We review their architecture as\nwell as learning methodologies. We also compare the performance of these models\nin the object recognition task on CIFAR-10 and ImageNet datasets. Our analysis\nindicates the AETv2 performs the best in most settings. Rotation with feature\ndecoupling also performed well in some settings. We then derive insights from\nthe observed results. Finally, we conclude with a summary of the results and\ninsights as well as highlighting open problems to be addressed and indicating\nvarious future directions.",
    "descriptor": "",
    "authors": [
      "Muhammad Ali",
      "Sayed Hashim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.08514"
  },
  {
    "id": "arXiv:2202.08515",
    "title": "Performance of Hybrid THz and Multi-Antenna RF System with Diversity  Combining",
    "abstract": "Recent studies investigate single-antenna radio frequency (RF) systems mixed\nwith terahertz (THz) wireless communications. This paper considers a two-tier\nsystem of THz for backhaul and multiple-antenna assisted RF for the access\nnetwork. We analyze the system performance by employing both selection\ncombining (SC) and maximal ratio combining (MRC) receivers for the RF link\nintegrated with the THz using the fixed-gain amplify and forward (AF) protocol.\nWe develop the probability density function (PDF) and cumulative distribution\nfunction (CDF) of the end-to-end signal-to-noise (SNR) of the dual-hop system\nover independent and non-identically distributed (i.ni.d.) $\\alpha$-$\\mu$\nfading channels with a statistical model for misalignment errors in the THz\nwireless link. We use the derived statistical results to develop analytical\nexpressions of the outage probability, average bit error rate (BER), and\nergodic capacity for the performance assessment of the considered system. We\ndevelop diversity order of the system using asymptotic analysis in the high SNR\nregion, demonstrating the scaling of system performance with the number of\nantennas. We use computer simulations to show the effect of system and channel\nparameters on the performance of the hybrid THz-RF link with multi-antenna\ndiversity schemes.",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication\n",
    "authors": [
      "Pranay Bhardwaj",
      "S. M. Zafaruddin"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.08515"
  },
  {
    "id": "arXiv:2202.08516",
    "title": "SAITS: Self-Attention-based Imputation for Time Series",
    "abstract": "Missing data in time series is a pervasive problem that puts obstacles in the\nway of pattern recognition, especially in real-world applications. A popular\nsolution is imputation, where the fundamental challenge is to determine what\nvalues should be filled in. This paper proposes SAITS, a novel method based on\nthe self-attention mechanism for missing value imputation in multivariate time\nseries. Trained by a joint-optimization approach, SAITS learns missing values\nfrom a weighted combination of two diagonally-masked self-attention (DMSA)\nblocks. DMSA explicitly captures both the temporal dependencies and feature\ncorrelations between time steps, which improves imputation accuracy and\ntraining speed. Meanwhile, the weighted-combination design enables SAITS to\ndynamically assign weights to the learned representations from two DMSA blocks\naccording to the attention map and the missingness information. Extensive\nexperiments demonstrate that SAITS outperforms the state-of-the-art methods on\nthe time-series imputation task efficiently and reveal SAITS' potential to\nimprove the learning performance of pattern recognition models on incomplete\ntime-series data from the real world.",
    "descriptor": "",
    "authors": [
      "Wenjie Du",
      "David C\u00f4t\u00e9",
      "Yan Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.08516"
  },
  {
    "id": "arXiv:2202.08517",
    "title": "TAFNet: A Three-Stream Adaptive Fusion Network for RGB-T Crowd Counting",
    "abstract": "In this paper, we propose a three-stream adaptive fusion network named\nTAFNet, which uses paired RGB and thermal images for crowd counting.\nSpecifically, TAFNet is divided into one main stream and two auxiliary streams.\nWe combine a pair of RGB and thermal images to constitute the input of main\nstream. Two auxiliary streams respectively exploit RGB image and thermal image\nto extract modality-specific features. Besides, we propose an Information\nImprovement Module (IIM) to fuse the modality-specific features into the main\nstream adaptively. Experiment results on RGBT-CC dataset show that our method\nachieves more than 20% improvement on mean average error and root mean squared\nerror compared with state-of-the-art method. The source code will be publicly\navailable at https://github.com/TANGHAIHAN/TAFNet.",
    "descriptor": "\nComments: This work has been accepted by IEEE International Symposium on Circuits and Systems (ISCAS) 2022\n",
    "authors": [
      "Haihan Tang",
      "Yi Wang",
      "Lap-Pui Chau"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.08517"
  },
  {
    "id": "arXiv:2202.08519",
    "title": "DeepHybrid: Deep Learning on Automotive Radar Spectra and Reflections  for Object Classification",
    "abstract": "Automated vehicles need to detect and classify objects and traffic\nparticipants accurately. Reliable object classification using automotive radar\nsensors has proved to be challenging. We propose a method that combines\nclassical radar signal processing and Deep Learning algorithms. The\nrange-azimuth information on the radar reflection level is used to extract a\nsparse region of interest from the range-Doppler spectrum. This is used as\ninput to a neural network (NN) that classifies different types of stationary\nand moving objects. We present a hybrid model (DeepHybrid) that receives both\nradar spectra and reflection attributes as inputs, e.g. radar cross-section.\nExperiments show that this improves the classification performance compared to\nmodels using only spectra. Moreover, a neural architecture search (NAS)\nalgorithm is applied to find a resource-efficient and high-performing NN. NAS\nyields an almost one order of magnitude smaller NN than the manually-designed\none while preserving the accuracy. The proposed method can be used for example\nto improve automatic emergency braking or collision avoidance systems.",
    "descriptor": "",
    "authors": [
      "Adriana-Eliza Cozma",
      "Lisa Morgan",
      "Martin Stolz",
      "David Stoeckel",
      "Kilian Rambach"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.08519"
  },
  {
    "id": "arXiv:2202.08522",
    "title": "Recovering Unbalanced Communities in the Stochastic Block Model With  Application to Clustering with a Faulty Oracle",
    "abstract": "The stochastic block model (SBM) is a fundamental model for studying graph\nclustering or community detection in networks. It has received great attention\nin the last decade and the balanced case, i.e., assuming all clusters have\nlarge size, has been well studied. However, our understanding of SBM with\nunbalanced communities (arguably, more relevant in practice) is still very\nlimited. In this paper, we provide a simple SVD-based algorithm for recovering\nthe communities in the SBM with communities of varying sizes. Under the\nKS-threshold conjecture, the tradeoff between the parameters in our algorithm\nis nearly optimal up to polylogarithmic factors for a wide range of regimes. As\na byproduct, we obtain a time-efficient algorithm with improved query\ncomplexity for a clustering problem with a faulty oracle, which improves upon a\nnumber of previous work (Mazumdarand Saha [NIPS 2017], Larsen, Mitzenmacher and\nTsourakakis [WWW 2020], Peng and Zhang[COLT 2021]). Under the KS-threshold\nconjecture, the query complexity of our algorithm is nearly optimal up to\npolylogarithmic factors.",
    "descriptor": "",
    "authors": [
      "Chandra Sekhar Mukherjee",
      "Pan Peng",
      "Jiapeng Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.08522"
  },
  {
    "id": "arXiv:2202.08523",
    "title": "Contrastive Meta Learning with Behavior Multiplicity for Recommendation",
    "abstract": "A well-informed recommendation framework could not only help users identify\ntheir interested items, but also benefit the revenue of various online\nplatforms (e.g., e-commerce, social media). Traditional recommendation models\nusually assume that only a single type of interaction exists between user and\nitem, and fail to model the multiplex user-item relationships from multi-typed\nuser behavior data, such as page view, add-to-favourite and purchase. While\nsome recent studies propose to capture the dependencies across different types\nof behaviors, two important challenges have been less explored: i) Dealing with\nthe sparse supervision signal under target behaviors (e.g., purchase). ii)\nCapturing the personalized multi-behavior patterns with customized dependency\nmodeling. To tackle the above challenges, we devise a new model CML,\nContrastive Meta Learning (CML), to maintain dedicated cross-type behavior\ndependency for different users. In particular, we propose a multi-behavior\ncontrastive learning framework to distill transferable knowledge across\ndifferent types of behaviors via the constructed contrastive loss. In addition,\nto capture the diverse multi-behavior patterns, we design a contrastive meta\nnetwork to encode the customized behavior heterogeneity for different users.\nExtensive experiments on three real-world datasets indicate that our method\nconsistently outperforms various state-of-the-art recommendation methods. Our\nempirical studies further suggest that the contrastive meta learning paradigm\noffers great potential for capturing the behavior multiplicity in\nrecommendation. We release our model implementation at:\nhttps://github.com/weiwei1206/CML.git.",
    "descriptor": "\nComments: Published as a full paper at WSDM 2022 and Awarded as Best Paper Candidate\n",
    "authors": [
      "Wei Wei",
      "Chao Huang",
      "Lianghao Xia",
      "Yong Xu",
      "Jiashu Zhao",
      "Dawei Yin"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.08523"
  },
  {
    "id": "arXiv:2202.08524",
    "title": "A Collection and Categorization of Open-Source Wind and Wind Power  Datasets",
    "abstract": "Wind power and other forms of renewable energy sources play an ever more\nimportant role in the energy supply of today's power grids. Forecasting\nrenewable energy sources has therefore become essential in balancing the power\ngrid. While a lot of focus is placed on new forecasting methods, little\nattention is given on how to compare, reproduce and transfer the methods to\nother use cases and data. One reason for this lack of attention is the limited\navailability of open-source datasets, as many currently used datasets are\nnon-disclosed and make reproducibility of research impossible. This\nunavailability of open-source datasets is especially prevalent in commercially\ninteresting fields such as wind power forecasting. However, with this paper we\nwant to enable researchers to compare their methods on publicly available\ndatasets by providing the, to our knowledge, largest up-to-date overview of\nexisting open-source wind power datasets, and a categorization into different\ngroups of datasets that can be used for wind power forecasting. We show that\nthere are publicly available datasets sufficient for wind power forecasting\ntasks and discuss the different data groups properties to enable researchers to\nchoose appropriate open-source datasets and compare their methods on them.",
    "descriptor": "\nComments: 21 pages, 6 tables, 5 figures\n",
    "authors": [
      "Nina Effenberger",
      "Nicole Ludwig"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.08524"
  },
  {
    "id": "arXiv:2202.08526",
    "title": "Point Cloud Generation with Continuous Conditioning",
    "abstract": "Generative models can be used to synthesize 3D objects of high quality and\ndiversity. However, there is typically no control over the properties of the\ngenerated object.This paper proposes a novel generative adversarial network\n(GAN) setup that generates 3D point cloud shapes conditioned on a continuous\nparameter. In an exemplary application, we use this to guide the generative\nprocess to create a 3D object with a custom-fit shape. We formulate this\ngeneration process in a multi-task setting by using the concept of auxiliary\nclassifier GANs. Further, we propose to sample the generator label input for\ntraining from a kernel density estimation (KDE) of the dataset. Our ablations\nshow that this leads to significant performance increase in regions with few\nsamples. Extensive quantitative and qualitative experiments show that we gain\nexplicit control over the object dimensions while maintaining good generation\nquality and diversity.",
    "descriptor": "\nComments: Accepted at International Conference on Artificial Intelligence and Statistics (AISTATS) 2022\n",
    "authors": [
      "Larissa T. Triess",
      "Andre B\u00fchler",
      "David Peter",
      "Fabian B. Flohr",
      "J. Marius Z\u00f6llner"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.08526"
  },
  {
    "id": "arXiv:2202.08533",
    "title": "AISHELL-NER: Named Entity Recognition from Chinese Speech",
    "abstract": "Named Entity Recognition (NER) from speech is among Spoken Language\nUnderstanding (SLU) tasks, aiming to extract semantic information from the\nspeech signal. NER from speech is usually made through a two-step pipeline that\nconsists of (1) processing the audio using an Automatic Speech Recognition\n(ASR) system and (2) applying an NER tagger to the ASR outputs. Recent works\nhave shown the capability of the End-to-End (E2E) approach for NER from English\nand French speech, which is essentially entity-aware ASR. However, due to the\nmany homophones and polyphones that exist in Chinese, NER from Chinese speech\nis effectively a more challenging task. In this paper, we introduce a new\ndataset AISEHLL-NER for NER from Chinese speech. Extensive experiments are\nconducted to explore the performance of several state-of-the-art methods. The\nresults demonstrate that the performance could be improved by combining\nentity-aware ASR and pretrained NER tagger, which can be easily applied to the\nmodern SLU pipeline. The dataset is publicly available at\ngithub.com/Alibaba-NLP/AISHELL-NER.",
    "descriptor": "",
    "authors": [
      "Boli Chen",
      "Guangwei Xu",
      "Xiaobin Wang",
      "Pengjun Xie",
      "Meishan Zhang",
      "Fei Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.08533"
  },
  {
    "id": "arXiv:2202.08536",
    "title": "Does the End Justify the Means? On the Moral Justification of  Fairness-Aware Machine Learning",
    "abstract": "Despite an abundance of fairness-aware machine learning (fair-ml) algorithms,\nthe moral justification of how these algorithms enforce fairness metrics is\nlargely unexplored. The goal of this paper is to elicit the moral implications\nof a fair-ml algorithm. To this end, we first consider the moral justification\nof the fairness metrics for which the algorithm optimizes. We present an\nextension of previous work to arrive at three propositions that can justify the\nfairness metrics. Different from previous work, our extension highlights that\nthe consequences of predicted outcomes are important for judging fairness. We\ndraw from the extended framework and empirical ethics to identify moral\nimplications of the fair-ml algorithm. We focus on the two optimization\nstrategies inherent to the algorithm: group-specific decision thresholds and\nrandomized decision thresholds. We argue that the justification of the\nalgorithm can differ depending on one's assumptions about the (social) context\nin which the algorithm is applied - even if the associated fairness metric is\nthe same. Finally, we sketch paths for future work towards a more complete\nevaluation of fair-ml algorithms, beyond their direct optimization objectives.",
    "descriptor": "",
    "authors": [
      "Hilde Weerts",
      "Lamb\u00e8r Royakkers",
      "Mykola Pechenizkiy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2202.08536"
  },
  {
    "id": "arXiv:2202.08537",
    "title": "Domain Adaptation for Underwater Image Enhancement via Content and Style  Separation",
    "abstract": "Underwater image suffer from color cast, low contrast and hazy effect due to\nlight absorption, refraction and scattering, which degraded the high-level\napplication, e.g, object detection and object tracking. Recent learning-based\nmethods demonstrate astonishing performance on underwater image enhancement,\nhowever, most of these works use synthesis pair data for supervised learning\nand ignore the domain gap to real-world data. In this paper, we propose a\ndomain adaptation framework for underwater image enhancement via content and\nstyle separation, we assume image could be disentangled to content and style\nlatent, and image could be clustered to the sub-domain of associated style in\nlatent space, the goal is to build up the mapping between underwater style\nlatent and clean one. Different from prior works of domain adaptation for\nunderwater image enhancement, which target to minimize the latent discrepancy\nof synthesis and real-world data, we aim to distinguish style latent from\ndifferent sub-domains. To solve the problem of lacking pair real-world data, we\nleverage synthesis to real image-to-image translation to obtain pseudo real\nunderwater image pairs for supervised learning, and enhancement can be achieved\nby input content and clean style latent into generator. Our model provide a\nuser interact interface to adjust different enhanced level by latent\nmanipulation. Experiment on various public real-world underwater benchmarks\ndemonstrate that the proposed framework is capable to perform domain adaptation\nfor underwater image enhancement and outperform various state-of-the-art\nunderwater image enhancement algorithms in quantity and quality. The model and\nsource code are available at https://github.com/fordevoted/UIESS",
    "descriptor": "\nComments: 11 pages, 11 figures\n",
    "authors": [
      "Yu-Wei Chen",
      "Soo-Chang Pei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.08537"
  },
  {
    "id": "arXiv:2202.08538",
    "title": "Two-dimensional structure functions to characterize convective rolls in  the marine atmospheric boundary layer from Sentinel-1 SAR images",
    "abstract": "We study the shape of convective rolls in the Marine Atmospheric Boundary\nLayer from Synthetic Aperture Radar images of the ocean. We propose a\nmultiscale analysis with structure functions which allow an easy generalization\nto analyse high-order statistics and so to finely describe the shape of the\nrolls. The two main results are : 1) second order structure function\ncharacterizes the size and direction of rolls just like correlation or power\nspectrum do, 2) high order statistics can be studied with skewness and Flatness\nwhich characterize the asymmetry and intermittency of rolls respectively. From\nthe best of our knowledge, this is the first time that the asymmetry and\nintermittency of rolls is shown from radar images of the ocean surface.",
    "descriptor": "",
    "authors": [
      "Carlos Granero-Belinchon",
      "St\u00e9phane G. Roux",
      "Nicolas B. Garnier",
      "Pierre Tandeo",
      "Chapron Bertrand",
      "Alexis Mouche"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)",
      "Atmospheric and Oceanic Physics (physics.ao-ph)",
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2202.08538"
  },
  {
    "id": "arXiv:2202.08539",
    "title": "When, where, and how to add new neurons to ANNs",
    "abstract": "Neurogenesis in ANNs is an understudied and difficult problem, even compared\nto other forms of structural learning like pruning. By decomposing it into\ntriggers and initializations, we introduce a framework for studying the various\nfacets of neurogenesis: when, where, and how to add neurons during the learning\nprocess. We present the Neural Orthogonality (NORTH*) suite of neurogenesis\nstrategies, combining layer-wise triggers and initializations based on the\northogonality of activations or weights to dynamically grow performant networks\nthat converge to an efficient size. We evaluate our contributions against other\nrecent neurogenesis works with MLPs.",
    "descriptor": "",
    "authors": [
      "Kaitlin Maile",
      "Emmanuel Rachelson",
      "Herv\u00e9 Luga",
      "Dennis G. Wilson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.08539"
  },
  {
    "id": "arXiv:2202.08541",
    "title": "Fokker-Planck Multi-Species Equations in the Adiabatic Asymptotics",
    "abstract": "The main concern of the present paper is the study of the multi-scale\ndynamics of thermonuclear fusion plasmas via a multi-species Fokker-Planck\nkinetic model. One of the goals is the generalization of the standard\nFokker-Planck collision operator to a multispecies one, conserving mass, total\nmomentum and energy, as well as satisfying Boltzmann's H-theorem. Secondly, the\npaper investigates in more details the reduced model used for the electron\ndescription in present simulations, and which considers the electrons in a\nthermodynamic equilibrium (adiabatic regime), whereas the ions are kept\nkinetic. On the one hand, we perform some mathematical asymptotic limits to\nobtain in the electron/ion low mass ratio limit the above-mentioned electron\nadiabatic regime. On the other hand, we develop a numerical scheme , based on a\nHermite spectral method, and perfom numerical simulations to illustrate and\ninvestigate in more details this asymptotics.",
    "descriptor": "",
    "authors": [
      "Francis Filbet",
      "Claudia Negulescu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.08541"
  },
  {
    "id": "arXiv:2202.08543",
    "title": "Resilience-Motivated Distribution System Restoration Considering  Electricity-Water-Gas Interdependency",
    "abstract": "A major outage in the electricity distribution system may affect the\noperation of water and natural gas supply systems, leading to an interruption\nof multiple services to critical customers. Therefore, enhancing resilience of\ncritical infrastructures requires joint efforts of multiple sectors. In this\npaper, a distribution system service restoration method considering the\nelectricity-water-gas interdependency is proposed. The objective is to provide\nelectricity, water, and natural gas supplies to critical customers in the\ndesired ratio according to their needs after an extreme event. The operational\nconstraints of electricity, water, and natural gas networks are considered. The\ncharacteristics of electricity-driven coupling components, including water\npumps and gas compressors, are also modeled. Relaxation techniques are applied\nto nonconvex constraints posed by physical laws of those networks.\nConsequently, the restoration problem is formulated as a mixed-integer\nsecond-order cone program, which can readily be solved by the off-the-shelf\nsolvers. The proposed method is validated by numerical simulations on\nelectricity-water-gas integrated systems, developed based on benchmark models\nof the subsystems. The results indicate that considering the interdependency\nrefines the allocation of limited generation resources and demonstrate the\nexactness of the proposed convex relaxation.",
    "descriptor": "",
    "authors": [
      "Jiaxu Li",
      "Yin Xu",
      "Ying Wang",
      "Meng Li",
      "Jinghan He",
      "Chen-Ching Liu",
      "Kevin P. Schneider"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.08543"
  },
  {
    "id": "arXiv:2202.08544",
    "title": "Efficient Classification of Local Problems in Regular Trees",
    "abstract": "We give practical, efficient algorithms that automatically determine the\ndistributed round complexity of a given locally checkable graph problem, in two\nsettings. We present one algorithm for unrooted regular trees and another\nalgorithm for rooted regular trees. The algorithms take the description of a\nlocally checkable labeling problem as input, and the running time is polynomial\nin the size of the problem description. The algorithms decide if the problem is\nsolvable in $O(\\log n)$ rounds. If not, it is known that the complexity has to\nbe $\\Theta(n^{1/k})$ for some $k = 1, 2, \\dotsc$, and in this case the\nalgorithms also output the right value of the exponent $k$.\nIn rooted trees in the $O(\\log n)$ case we can then further determine the\nexact complexity class by using algorithms from prior work; for unrooted trees\nthe more fine-grained classification in the $O(\\log n)$ region remains an open\nquestion.",
    "descriptor": "",
    "authors": [
      "Alkida Balliu",
      "Sebastian Brandt",
      "Yi-Jun Chang",
      "Dennis Olivetti",
      "Jan Studen\u00fd",
      "Jukka Suomela"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2202.08544"
  },
  {
    "id": "arXiv:2202.08545",
    "title": "Information Theory with Kernel Methods",
    "abstract": "We consider the analysis of probability distributions through their\nassociated covariance operators from reproducing kernel Hilbert spaces. We show\nthat the von Neumann entropy and relative entropy of these operators are\nintimately related to the usual notions of Shannon entropy and relative\nentropy, and share many of their properties. They come together with efficient\nestimation algorithms from various oracles on the probability distributions. We\nalso consider product spaces and show that for tensor product kernels, we can\ndefine notions of mutual information and joint entropies, which can then\ncharacterize independence perfectly, but only partially conditional\nindependence. We finally show how these new notions of relative entropy lead to\nnew upper-bounds on log partition functions, that can be used together with\nconvex optimization within variational inference methods, providing a new\nfamily of probabilistic inference methods.",
    "descriptor": "",
    "authors": [
      "Francis Bach"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.08545"
  },
  {
    "id": "arXiv:2202.08548",
    "title": "The Political Economy of Privacy Enhancing Technologies",
    "abstract": "\\ac{PETs} have increasingly become vital empowering tools in today's highly\ndatafied society. However, their development has been primarily concerned with\nimproving usability and ensuring confidentiality online. Privileging these\nconsiderations might unintendedly lead to fixed ideas about users, but\ndiversity of thought, action, ability, and circumstance play a fundamental role\nin the distortion and acceptance of any \\ac{PETs}. In this paper we elaborate\nsome of the manifestations of the distortions, like inadequate and exclusory\ndesign, and uneven distribution of costs and benefits. Drawing on Amartya Sen's\n\\emph{capability approach} we propose that a normative evaluation of personal,\nsocial, and political diversities can be used as a foundation to conceptualize\nand develop \\ac{PETs}. We outline a research agenda based on this proposition\nand suggest pertinent empirical and methodological research paths. Our\ncontribution offers an evaluative space to make inter-personal comparisons to\ninform the development of \\ac{PETs}.",
    "descriptor": "\nComments: 16 Pages, 1 Figure\n",
    "authors": [
      "Partha Das Chowdhury",
      "Andres Dominguez",
      "Marvin Kopo Ramkapane",
      "Awais Rashid"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2202.08548"
  },
  {
    "id": "arXiv:2202.08549",
    "title": "Oracle-Efficient Online Learning for Beyond Worst-Case Adversaries",
    "abstract": "In this paper, we study oracle-efficient algorithms for beyond worst-case\nanalysis of online learning. We focus on two settings. First, the smoothed\nanalysis setting of [RST11, HRS12] where an adversary is constrained to\ngenerating samples from distributions whose density is upper bounded by\n$1/\\sigma$ times the uniform density. Second, the setting of $K$-hint\ntransductive learning, where the learner is given access to $K$ hints per time\nstep that are guaranteed to include the true instance. We give the first known\noracle-efficient algorithms for both settings that depend only on the VC\ndimension of the class and parameters $\\sigma$ and $K$ that capture the power\nof the adversary. In particular, we achieve oracle-efficient regret bounds of $\nO ( \\sqrt{T (d / \\sigma )^{1/2} } ) $ and $ O ( \\sqrt{T d K } )$ respectively\nfor these setting. For the smoothed analysis setting, our results give the\nfirst oracle-efficient algorithm for online learning with smoothed adversaries\n[HRS21]. This contrasts the computational separation between online learning\nwith worst-case adversaries and offline learning established by [HK16]. Our\nalgorithms also imply improved bounds for worst-case setting with small\ndomains. In particular, we give an oracle-efficient algorithm with regret of $O\n( \\sqrt{T(d \\vert{\\mathcal{X}}\\vert ) ^{1/2} })$, which is a refinement of the\nearlier $O ( \\sqrt{T\\vert{\\mathcal{X} } \\vert })$ bound by [DS16].",
    "descriptor": "\nComments: Under submission\n",
    "authors": [
      "Nika Haghtalab",
      "Yanjun Han",
      "Abhishek Shetty",
      "Kunhe Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.08549"
  },
  {
    "id": "arXiv:2202.08550",
    "title": "Delay-adaptive step-sizes for asynchronous learning",
    "abstract": "In scalable machine learning systems, model training is often parallelized\nover multiple nodes that run without tight synchronization. Most analysis\nresults for the related asynchronous algorithms use an upper bound on the\ninformation delays in the system to determine learning rates. Not only are such\nbounds hard to obtain in advance, but they also result in unnecessarily slow\nconvergence. In this paper, we show that it is possible to use learning rates\nthat depend on the actual time-varying delays in the system. We develop general\nconvergence results for delay-adaptive asynchronous iterations and specialize\nthese to proximal incremental gradient descent and block-coordinate descent\nalgorithms. For each of these methods, we demonstrate how delays can be\nmeasured on-line, present delay-adaptive step-size policies, and illustrate\ntheir theoretical and practical advantages over the state-of-the-art.",
    "descriptor": "\nComments: 21 pages, 3 figures\n",
    "authors": [
      "Xuyang Wu",
      "Sindri Magnusson",
      "Hamid Reza Feyzmahdavian",
      "Mikael Johansson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2202.08550"
  },
  {
    "id": "arXiv:2202.08553",
    "title": "3D-Aware Indoor Scene Synthesis with Depth Priors",
    "abstract": "Despite the recent advancement of Generative Adversarial Networks (GANs) in\nlearning 3D-aware image synthesis from 2D data, existing methods fail to model\nindoor scenes due to the large diversity of room layouts and the objects\ninside. We argue that indoor scenes do not have a shared intrinsic structure,\nand hence only using 2D images cannot adequately guide the model with the 3D\ngeometry. In this work, we fill in this gap by introducing depth as a 3D prior.\nCompared with other 3D data formats, depth better fits the convolution-based\ngeneration mechanism and is more easily accessible in practice. Specifically,\nwe propose a dual-path generator, where one path is responsible for depth\ngeneration, whose intermediate features are injected into the other path as the\ncondition for appearance rendering. Such a design eases the 3D-aware synthesis\nwith explicit geometry information. Meanwhile, we introduce a switchable\ndiscriminator both to differentiate real v.s. fake domains and to predict the\ndepth from a given input. In this way, the discriminator can take the spatial\narrangement into account and advise the generator to learn an appropriate depth\ncondition. Extensive experimental results suggest that our approach is capable\nof synthesizing indoor scenes with impressively good quality and 3D\nconsistency, significantly outperforming state-of-the-art alternatives.",
    "descriptor": "",
    "authors": [
      "Zifan Shi",
      "Yujun Shen",
      "Jiapeng Zhu",
      "Dit-Yan Yeung",
      "Qifeng Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.08553"
  },
  {
    "id": "arXiv:2202.08555",
    "title": "Query Answering with Transitive and Linear-Ordered Data",
    "abstract": "We consider entailment problems involving powerful constraint languages such\nas frontier-guarded existential rules in which we impose additional semantic\nrestrictions on a set of distinguished relations. We consider restricting a\nrelation to be transitive, restricting a relation to be the transitive closure\nof another relation, and restricting a relation to be a linear order. We give\nsome natural variants of guardedness that allow inference to be decidable in\neach case, and isolate the complexity of the corresponding decision problems.\nFinally we show that slight changes in these conditions lead to undecidability.",
    "descriptor": "\nComments: This article was originally published at JAIR in 2018: this https URL (DOI 10.1613/jair.1.11240). This version of the paper includes one modification from the publisher version: we fix an incorrect proof for one of our undecidability results (Theorem 6.2). arXiv admin note: substantial text overlap with arXiv:1607.00813\n",
    "authors": [
      "Antoine Amarilli",
      "Michael Benedikt",
      "Pierre Bourhis",
      "Michael Vanden Boom"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2202.08555"
  },
  {
    "id": "arXiv:2202.08556",
    "title": "Heuristic Adaptability to Input Dynamics for SpMM on GPUs",
    "abstract": "Sparse Matrix-Matrix Multiplication (SpMM) has served as fundamental\ncomponents in various domains. Many previous studies exploit GPUs for SpMM\nacceleration because GPUs provide high bandwidth and parallelism. We point out\nthat a static design does not always improve the performance of SpMM on\ndifferent input data (e.g., >85\\% performance loss with a single algorithm). In\nthis paper, we consider the challenge of input dynamics from a novel\nauto-tuning perspective, while following issues remain to be solved: (1)\nOrthogonal design principles considering sparsity. Orthogonal design principles\nfor such a sparse problem should be extracted to form different algorithms, and\nfurther used for performance tuning. (2) Nontrivial implementations in the\nalgorithm space. Combining orthogonal design principles to create new\nalgorithms needs to tackle with new challenges like thread race handling. (3)\nHeuristic adaptability to input dynamics. The heuristic adaptability is\nrequired to dynamically optimize code for input dynamics.\nTo tackle these challenges, we first propose a novel three-loop model to\nextract orthogonal design principles for SpMM on GPUs. The model not only\ncovers previous SpMM designs, but also comes up with new designs absent from\nprevious studies. We propose techniques like conditional reduction to implement\nalgorithms missing in previous studies. We further propose DA-SpMM, a\nData-Aware heuristic GPU kernel for SpMM. DA-SpMM adaptively optimizes code\nconsidering input dynamics. Extensive experimental results show that, DA-SpMM\nachieves 1.26x~1.37x speedup compared with the best NVIDIA cuSPARSE algorithm\non average, and brings up to 5.59x end-to-end speedup to applications like\nGraph Neural Networks.",
    "descriptor": "\nComments: Accepted by Design Automation Conference (DAC) 2022\n",
    "authors": [
      "Guohao Dai",
      "Guyue Huang",
      "Shang Yang",
      "Zhongming Yu",
      "Hengrui Zhang",
      "Yufei Ding",
      "Yuan Xie",
      "Huazhong Yang",
      "Yu Wang"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2202.08556"
  },
  {
    "id": "arXiv:2202.08557",
    "title": "CADRE: A Cascade Deep Reinforcement Learning Framework for Vision-based  Autonomous Urban Driving",
    "abstract": "Vision-based autonomous urban driving in dense traffic is quite challenging\ndue to the complicated urban environment and the dynamics of the driving\nbehaviors. Widely-applied methods either heavily rely on hand-crafted rules or\nlearn from limited human experience, which makes them hard to generalize to\nrare but critical scenarios. In this paper, we present a novel CAscade Deep\nREinforcement learning framework, CADRE, to achieve model-free vision-based\nautonomous urban driving. In CADRE, to derive representative latent features\nfrom raw observations, we first offline train a Co-attention Perception Module\n(CoPM) that leverages the co-attention mechanism to learn the\ninter-relationships between the visual and control information from a\npre-collected driving dataset. Cascaded by the frozen CoPM, we then present an\nefficient distributed proximal policy optimization framework to online learn\nthe driving policy under the guidance of particularly designed reward\nfunctions. We perform a comprehensive empirical study with the CARLA NoCrash\nbenchmark as well as specific obstacle avoidance scenarios in autonomous urban\ndriving tasks. The experimental results well justify the effectiveness of CADRE\nand its superiority over the state-of-the-art by a wide margin.",
    "descriptor": "",
    "authors": [
      "Yinuo Zhao",
      "Kun Wu",
      "Zhiyuan Xu",
      "Zhengping Che",
      "Qi Lu",
      "Jian Tang",
      "Chi Harold Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.08557"
  },
  {
    "id": "arXiv:2202.08566",
    "title": "Efficient and Reliable Probabilistic Interactive Learning with  Structured Outputs",
    "abstract": "In this position paper, we study interactive learning for structured output\nspaces, with a focus on active learning, in which labels are unknown and must\nbe acquired, and on skeptical learning, in which the labels are noisy and may\nneed relabeling. These scenarios require expressive models that guarantee\nreliable and efficient computation of probabilistic quantities to measure\nuncertainty. We identify conditions under which a class of probabilistic models\n-- which we denote CRISPs -- meet all of these conditions, thus delivering\ntractable computation of the above quantities while preserving expressiveness.\nBuilding on prior work on tractable probabilistic circuits, we illustrate how\nCRISPs enable robust and efficient active and skeptical learning in large\nstructured output spaces.",
    "descriptor": "\nComments: Accepted at the AAAI-22 Workshop on Interactive Machine Learning\n",
    "authors": [
      "Stefano Teso",
      "Antonio Vergari"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.08566"
  },
  {
    "id": "arXiv:2202.08571",
    "title": "Comparison of standard and stabilization free Virtual Elements on  anisotropic elliptic problems",
    "abstract": "In this letter we compare the behaviour of standard Virtual Element Methods\n(VEM) and stabilization free Enlarged Enhancement Virtual Element Methods\n(E$^2$VEM) with the focus on some elliptic test problems whose solution and\ndiffusivity tensor are characterized by anisotropies. Results show that the\npossibility to avoid an arbitrary stabilizing part, offered by E$^2$VEM\nmethods, can reduce the magnitude of the error on general polygonal meshes and\nhelp convergence.",
    "descriptor": "",
    "authors": [
      "Stefano Berrone",
      "Andrea Borio",
      "Francesca Marcon"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.08571"
  },
  {
    "id": "arXiv:2202.08572",
    "title": "A Machine Learning Approach for Automated Filling of Data Entry Forms",
    "abstract": "Users frequently interact with software systems through data entry forms.\nHowever, form filling is time-consuming and error-prone. Although several\ntechniques have been proposed to auto-complete or pre-fill fields in the forms,\nthey provide limited support to help users fill categorical fields, i.e.,\nfields that require users to choose the right value among a large set of\noptions.\nIn this paper, we propose LAFF, a learning-based automated approach for\nfilling categorical fields in data entry forms. LAFF first builds Bayesian\nNetwork models by learning field dependencies from a set of historical input\ninstances, representing the values of the fields that have been filled in the\npast. To improve its learning ability, LAFF uses local modeling to effectively\nmine the local dependencies of fields in a cluster of input instances. During\nthe form filling phase, LAFF uses such models to predict possible values of a\ntarget field, based on the values in the already-filled fields of the form and\ntheir dependencies; the predicted values (endorsed based on field dependencies\nand prediction confidence) are then provided to the end-user as a list of\nsuggestions.\nWe evaluated LAFF by assessing its effectiveness and efficiency in form\nfilling on two datasets, one of them proprietary from the banking domain.\nExperimental results show that LAFF is able to provide accurate suggestions\nwith a Mean Reciprocal Rank value above 0.73. Furthermore, LAFF is efficient,\nrequiring at most 317 ms per suggestion.",
    "descriptor": "\nComments: 39 pages, 8 figures\n",
    "authors": [
      "Hichem Belgacem",
      "Xiaochen Li",
      "Domenico Bianculli",
      "Lionel C. Briand"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2202.08572"
  },
  {
    "id": "arXiv:2202.08576",
    "title": "Local Differential Privacy for Belief Functions",
    "abstract": "In this paper, we propose two new definitions of local differential privacy\nfor belief functions. One is based on Shafer's semantics of randomly coded\nmessages and the other from the perspective of imprecise probabilities. We show\nthat such basic properties as composition and post-processing also hold for our\nnew definitions. Moreover, we provide a hypothesis testing framework for these\ndefinitions and study the effect of \"don't know\" in the trade-off between\nprivacy and utility in discrete distribution estimation.",
    "descriptor": "",
    "authors": [
      "Qiyu Li",
      "Chunlai Zhou",
      "Biao Qin",
      "Zhiqiang Xu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.08576"
  },
  {
    "id": "arXiv:2202.08578",
    "title": "An Equivalence Between Data Poisoning and Byzantine Gradient Attacks",
    "abstract": "To study the resilience of distributed learning, the \"Byzantine\" literature\nconsiders a strong threat model where workers can report arbitrary gradients to\nthe parameter server. Whereas this model helped obtain several fundamental\nresults, it has sometimes been considered unrealistic, when the workers are\nmostly trustworthy machines. In this paper, we show a surprising equivalence\nbetween this model and data poisoning, a threat considered much more realistic.\nMore specifically, we prove that every gradient attack can be reduced to data\npoisoning, in any personalized federated learning system with PAC guarantees\n(which we show are both desirable and realistic). This equivalence makes it\npossible to obtain new impossibility results on the resilience to data\npoisoning as corollaries of existing impossibility theorems on Byzantine\nmachine learning. Moreover, using our equivalence, we derive a practical attack\nthat we show (theoretically and empirically) can be very effective against\nclassical personalized federated learning models.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2106.02398\n",
    "authors": [
      "Sadegh Farhadkhani",
      "Rachid Guerraoui",
      "L\u00ea-Nguy\u00ean Hoang",
      "Oscar Villemaud"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.08578"
  },
  {
    "id": "arXiv:2202.08583",
    "title": "Point cloud completion on structured feature map with feedback network",
    "abstract": "In this paper, we tackle the challenging problem of point cloud completion\nfrom the perspective of feature learning. Our key observation is that to\nrecover the underlying structures as well as surface details given a partial\ninput, a fundamental component is a good feature representation that can\ncapture both global structure and local geometric details. Towards this end, we\nfirst propose FSNet, a feature structuring module that can adaptively aggregate\npoint-wise features into a 2D structured feature map by learning multiple\nlatent patterns from local regions. We then integrate FSNet into a\ncoarse-to-fine pipeline for point cloud completion. Specifically, a 2D\nconvolutional neural network is adopted to decode feature maps from FSNet into\na coarse and complete point cloud. Next, a point cloud upsampling network is\nused to generate dense point cloud from the partial input and the coarse\nintermediate output. To efficiently exploit the local structures and enhance\nthe point distribution uniformity, we propose IFNet, a point upsampling module\nwith self-correction mechanism that can progressively refine details of the\ngenerated dense point cloud. We conduct both qualitative and quantitative\nexperiments on ShapeNet, MVP, and KITTI datasets, which demonstrate that our\nmethod outperforms state-of-the-art point cloud completion approaches.",
    "descriptor": "\nComments: to be published in journel of computational visual media\n",
    "authors": [
      "Zejia Su",
      "Haibin Huang",
      "Chongyang Ma",
      "Hui Huang",
      "Ruizhen Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.08583"
  },
  {
    "id": "arXiv:2202.08587",
    "title": "Gradients without Backpropagation",
    "abstract": "Using backpropagation to compute gradients of objective functions for\noptimization has remained a mainstay of machine learning. Backpropagation, or\nreverse-mode differentiation, is a special case within the general family of\nautomatic differentiation algorithms that also includes the forward mode. We\npresent a method to compute gradients based solely on the directional\nderivative that one can compute exactly and efficiently via the forward mode.\nWe call this formulation the forward gradient, an unbiased estimate of the\ngradient that can be evaluated in a single forward run of the function,\nentirely eliminating the need for backpropagation in gradient descent. We\ndemonstrate forward gradient descent in a range of problems, showing\nsubstantial savings in computation and enabling training up to twice as fast in\nsome cases.",
    "descriptor": "\nComments: 10 pages, 6 figures\n",
    "authors": [
      "At\u0131l\u0131m G\u00fcne\u015f Baydin",
      "Barak A. Pearlmutter",
      "Don Syme",
      "Frank Wood",
      "Philip Torr"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.08587"
  },
  {
    "id": "arXiv:2202.08589",
    "title": "Single UHD Image Dehazing via Interpretable Pyramid Network",
    "abstract": "Currently, most single image dehazing models cannot run an\nultra-high-resolution (UHD) image with a single GPU shader in real-time. To\naddress the problem, we introduce the principle of infinite approximation of\nTaylor's theorem with the Laplace pyramid pattern to build a model which is\ncapable of handling 4K hazy images in real-time. The N branch networks of the\npyramid network correspond to the N constraint terms in Taylor's theorem.\nLow-order polynomials reconstruct the low-frequency information of the image\n(e.g. color, illumination). High-order polynomials regress the high-frequency\ninformation of the image (e.g. texture). In addition, we propose a Tucker\nreconstruction-based regularization term that acts on each branch network of\nthe pyramid model. It further constrains the generation of anomalous signals in\nthe feature space. Extensive experimental results demonstrate that our approach\ncan not only run 4K images with haze in real-time on a single GPU (80FPS) but\nalso has unparalleled interpretability.\nThe developed method achieves state-of-the-art (SOTA) performance on two\nbenchmarks (O/I-HAZE) and our updated 4KID dataset while providing the reliable\ngroundwork for subsequent optimization schemes.",
    "descriptor": "",
    "authors": [
      "Boxue Xiao",
      "Zhuoran Zheng",
      "Xiang Chen",
      "Chen Lv",
      "Yunliang Zhuang",
      "Tao Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.08589"
  },
  {
    "id": "arXiv:2202.08596",
    "title": "Augmented Lagrangian approach to deriving discontinuous Galerkin methods  for nonlinear elasticity problems",
    "abstract": "We use the augmented Lagrangian formalism to derive discontinuous Galerkin\nformulations for problems in nonlinear elasticity. In elasticity stress is\ntypically a symmetric function of strain, leading to symmetric tangent\nstiffness matrices in Newtons method when conforming finite elements are used\nfor discretization. By use of the augmented Lagrangian framework, we can also\nobtain symmetric tangent stiffness matrices in discontinuous Galerkin methods.\nWe suggest two different approaches and give examples from plasticity and from\nlarge deformation hyperelasticity.",
    "descriptor": "",
    "authors": [
      "Peter Hansbo",
      "Mats G. Larson"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.08596"
  },
  {
    "id": "arXiv:2202.08602",
    "title": "Fingerprinting Deep Neural Networks Globally via Universal Adversarial  Perturbations",
    "abstract": "In this paper, we propose a novel and practical mechanism which enables the\nservice provider to verify whether a suspect model is stolen from the victim\nmodel via model extraction attacks. Our key insight is that the profile of a\nDNN model's decision boundary can be uniquely characterized by its\n\\textit{Universal Adversarial Perturbations (UAPs)}. UAPs belong to a\nlow-dimensional subspace and piracy models' subspaces are more consistent with\nvictim model's subspace compared with non-piracy model. Based on this, we\npropose a UAP fingerprinting method for DNN models and train an encoder via\n\\textit{contrastive learning} that takes fingerprint as inputs, outputs a\nsimilarity score. Extensive studies show that our framework can detect model IP\nbreaches with confidence $> 99.99 \\%$ within only $20$ fingerprints of the\nsuspect model. It has good generalizability across different model\narchitectures and is robust against post-modifications on stolen models.",
    "descriptor": "",
    "authors": [
      "Zirui Peng",
      "Shaofeng Li",
      "Guoxing Chen",
      "Cheng Zhang",
      "Haojin Zhu",
      "Minhui Xue"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.08602"
  },
  {
    "id": "arXiv:2202.08603",
    "title": "CoFED: Cross-silo Heterogeneous Federated Multi-task Learning via  Co-training",
    "abstract": "Federated Learning (FL) is a machine learning technique that enables\nparticipants to train high-quality models collaboratively without exchanging\ntheir private data. Participants in cross-silo FL settings are independent\norganizations with different task needs, and they are concerned not only with\ndata privacy, but also with training independently their unique models due to\nintellectual property. Most existing FL schemes are incapability for the above\nscenarios. In this paper, we propose a communication-efficient FL scheme,\nCoFED, based on pseudo-labeling unlabeled data like co-training. To the best of\nour knowledge, it is the first FL scheme compatible with heterogeneous tasks,\nheterogeneous models, and heterogeneous training algorithms simultaneously.\nExperimental results show that CoFED achieves better performance with a lower\ncommunication cost. Especially for the non-IID settings and heterogeneous\nmodels, the proposed method improves the performance by 35%.",
    "descriptor": "",
    "authors": [
      "Xingjian Cao",
      "Zonghang Li",
      "Hongfang Yu",
      "Gang Sun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.08603"
  },
  {
    "id": "arXiv:2202.08604",
    "title": "Two-Stage Architectural Fine-Tuning with Neural Architecture Search  using Early-Stopping in Image Classification",
    "abstract": "Deep neural networks (NN) perform well in various tasks (e.g., computer\nvision) because of the convolutional neural networks (CNN). However, the\ndifficulty of gathering quality data in the industry field hinders the\npractical use of NN. To cope with this issue, the concept of transfer learning\n(TL) has emerged, which leverages the fine-tuning of NNs trained on large-scale\ndatasets in data-scarce situations. Therefore, this paper suggests a two-stage\narchitectural fine-tuning method for image classification, inspired by the\nconcept of neural architecture search (NAS). One of the main ideas of our\nproposed method is a mutation with base architectures, which reduces the search\ncost by using given architectural information. Moreover, an early-stopping is\nalso considered which directly reduces NAS costs. Experimental results verify\nthat our proposed method reduces computational and searching costs by up to\n28.2% and 22.3%, compared to existing methods.",
    "descriptor": "\nComments: 5 pages, 6 figures, submitted to the 29th IEEE International Conference on Image Processing (IEEE ICIP)\n",
    "authors": [
      "Youngkee Kim",
      "Won Joon Yun",
      "Youn Kyu Lee",
      "Joongheon Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.08604"
  },
  {
    "id": "arXiv:2202.08613",
    "title": "On the evaluation of (meta-)solver approaches",
    "abstract": "Meta-solver approaches exploits a number of individual solvers to potentially\nbuild a better solver. To assess the performance of meta-solvers, one can\nsimply adopt the metrics typically used for individual solvers (e.g., runtime\nor solution quality), or employ more specific evaluation metrics (e.g., by\nmeasuring how close the meta-solver gets to its virtual best performance). In\nthis paper, based on some recently published works, we provide an overview of\ndifferent performance metrics for evaluating (meta-)solvers, by underlying\ntheir strengths and weaknesses.",
    "descriptor": "",
    "authors": [
      "Roberto Amadini",
      "Maurizio Gabbrielli",
      "Tong Liu",
      "Jacopo Mauro"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2202.08613"
  },
  {
    "id": "arXiv:2202.08614",
    "title": "Fourier PlenOctrees for Dynamic Radiance Field Rendering in Real-time",
    "abstract": "Implicit neural representations such as Neural Radiance Field (NeRF) have\nfocused mainly on modeling static objects captured under multi-view settings\nwhere real-time rendering can be achieved with smart data structures, e.g.,\nPlenOctree. In this paper, we present a novel Fourier PlenOctree (FPO)\ntechnique to tackle efficient neural modeling and real-time rendering of\ndynamic scenes captured under the free-view video (FVV) setting. The key idea\nin our FPO is a novel combination of generalized NeRF, PlenOctree\nrepresentation, volumetric fusion and Fourier transform. To accelerate FPO\nconstruction, we present a novel coarse-to-fine fusion scheme that leverages\nthe generalizable NeRF technique to generate the tree via spatial blending. To\ntackle dynamic scenes, we tailor the implicit network to model the Fourier\ncoefficients of timevarying density and color attributes. Finally, we construct\nthe FPO and train the Fourier coefficients directly on the leaves of a union\nPlenOctree structure of the dynamic sequence. We show that the resulting FPO\nenables compact memory overload to handle dynamic objects and supports\nefficient fine-tuning. Extensive experiments show that the proposed method is\n3000 times faster than the original NeRF and achieves over an order of\nmagnitude acceleration over SOTA while preserving high visual quality for the\nfree-viewpoint rendering of unseen dynamic scenes.",
    "descriptor": "",
    "authors": [
      "Liao Wang",
      "Jiakai Zhang",
      "Xinhang Liu",
      "Fuqiang Zhao",
      "Yanshun Zhang",
      "Yingliang Zhang",
      "Minye Wu",
      "Lan Xu",
      "Jingyi Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2202.08614"
  },
  {
    "id": "arXiv:2202.08619",
    "title": "Alexa versus Alexa: Controlling Smart Speakers by Self-Issuing Voice  Commands",
    "abstract": "We present Alexa versus Alexa (AvA), a novel attack that leverages audio\nfiles containing voice commands and audio reproduction methods in an offensive\nfashion, to gain control of Amazon Echo devices for a prolonged amount of time.\nAvA leverages the fact that Alexa running on an Echo device correctly\ninterprets voice commands originated from audio files even when they are played\nby the device itself -- i.e., it leverages a command self-issue vulnerability.\nHence, AvA removes the necessity of having a rogue speaker in proximity of the\nvictim's Echo, a constraint that many attacks share. With AvA, an attacker can\nself-issue any permissible command to Echo, controlling it on behalf of the\nlegitimate user. We have verified that, via AvA, attackers can control smart\nappliances within the household, buy unwanted items, tamper linked calendars\nand eavesdrop on the user. We also discovered two additional Echo\nvulnerabilities, which we call Full Volume and Break Tag Chain. The Full Volume\nincreases the self-issue command recognition rate, by doubling it on average,\nhence allowing attackers to perform additional self-issue commands. Break Tag\nChain increases the time a skill can run without user interaction, from eight\nseconds to more than one hour, hence enabling attackers to setup realistic\nsocial engineering scenarios. By exploiting these vulnerabilities, the\nadversary can self-issue commands that are correctly executed 99% of the times\nand can keep control of the device for a prolonged amount of time. We reported\nthese vulnerabilities to Amazon via their vulnerability research program, who\nrated them with a Medium severity score. Finally, to assess limitations of AvA\non a larger scale, we provide the results of a survey performed on a study\ngroup of 18 users, and we show that most of the limitations against AvA are\nhardly used in practice.",
    "descriptor": "\nComments: 15 pages, 5 figures, published in Proceedings of the 2022 ACM Asia Conference on Computer and Communications Security (ASIA CCS '22)\n",
    "authors": [
      "Sergio Esposito",
      "Daniele Sgandurra",
      "Giampaolo Bella"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.08619"
  },
  {
    "id": "arXiv:2202.08620",
    "title": "Kirin: A Quadruped Robot with High Payload Carrying Capability",
    "abstract": "The quadruped robot is a versatile mobile platform with potential ability for\nhigh payload carrying. However, most of the existing quadruped robots aim at\nhigh maneuverability, highly dynamic and agile locomotion. In spite of this,\npayload carrying is still an indispensable ability for the quadruped robots.\nDesign of a quadruped robot with high payload capacity is yet deeply explored.\nIn this study, a 50 kg electrically-actuated quadruped robot, Kirin, is\npresented to leverage the payload carrying capability. Kirin is an\ncharacterized with prismatic quasi-direct-drive (QDD) leg. This mechanism\ngreatly augments the payload carrying capability. This study presents several\ndesign principles for the payload-carrying-oriented quadruped robots, including\nthe mechanical design, actuator parameters selection, and locomotion control\nmethod. The theoretical analysis implies that the lifting task tends to be a\nbottleneck for the existing robots with the articulated knee joints. By using\nprismatic QDD leg, the payload carrying capability of Kirin is enhanced\ngreatly. To demonstrate Kirin's payload carrying capability, in preliminary\nexperiment, up to 125 kg payload lifting in static stance and 50 kg payload\ncarrying in dynamic trotting are tested. Whole body compliance with payload\ncarrying is also demonstrated.",
    "descriptor": "",
    "authors": [
      "Yueheng Zhou",
      "Ming Liu",
      "Chaoyang Song",
      "Jianwen Luo"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.08620"
  },
  {
    "id": "arXiv:2202.08625",
    "title": "Revisiting Over-smoothing in BERT from the Perspective of Graph",
    "abstract": "Recently over-smoothing phenomenon of Transformer-based models is observed in\nboth vision and language fields. However, no existing work has delved deeper to\nfurther investigate the main cause of this phenomenon. In this work, we make\nthe attempt to analyze the over-smoothing problem from the perspective of\ngraph, where such problem was first discovered and explored. Intuitively, the\nself-attention matrix can be seen as a normalized adjacent matrix of a\ncorresponding graph. Based on the above connection, we provide some theoretical\nanalysis and find that layer normalization plays a key role in the\nover-smoothing issue of Transformer-based models. Specifically, if the standard\ndeviation of layer normalization is sufficiently large, the output of\nTransformer stacks will converge to a specific low-rank subspace and result in\nover-smoothing. To alleviate the over-smoothing problem, we consider\nhierarchical fusion strategies, which combine the representations from\ndifferent layers adaptively to make the output more diverse. Extensive\nexperiment results on various data sets illustrate the effect of our fusion\nmethod.",
    "descriptor": "\nComments: Accepted by ICLR 2022 (Spotlight)\n",
    "authors": [
      "Han Shi",
      "Jiahui Gao",
      "Hang Xu",
      "Xiaodan Liang",
      "Zhenguo Li",
      "Lingpeng Kong",
      "Stephen M.S. Lee",
      "James T. Kwok"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.08625"
  },
  {
    "id": "arXiv:2202.08633",
    "title": "A novel HD Computing Algebra: Non-associative superposition of states  creating sparse bundles representing order information",
    "abstract": "Information inflow into a computational system is by a sequence of\ninformation items. Cognitive computing, i.e. performing transformations along\nthat sequence, requires to represent item information as well as sequential\ninformation. Among the most elementary operations is bundling, i.e. adding\nitems, leading to 'memory states', i.e. bundles, from which information can be\nretrieved. If the bundling operation used is associative, e.g. ordinary\nvector-addition, sequential information can not be represented without imposing\nadditional algebraic structure. A simple stochastic binary bundling rule\ninspired by the stochastic summation of neuronal activities allows the\nresulting memory state to represent both, item information as well as\nsequential information as long as it is non-associative. The memory state\nresulting from bundling together an arbitrary number of items is\nnon-homogeneous and has a degree of sparseness, which is controlled by the\nactivation threshold in summation. The bundling operation proposed allows to\nbuild a filter in the temporal as well as in the items' domain, which can be\nused to navigate the continuous inflow of information.",
    "descriptor": "",
    "authors": [
      "Stefan Reimann"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2202.08633"
  },
  {
    "id": "arXiv:2202.08639",
    "title": "Augmentation of Generalized Multivariable Grid-Forming Control for Power  Converters with Cascaded Controllers",
    "abstract": "The classic design of grid-forming control strategies for power converters\nrely on the stringent assumption of the timescale separation between DC and AC\nstates and their corresponding control loops, e.g., AC and DC loops, power and\ncascaded voltage and current loops, etc. This paper proposes a multi-input\nmulti-output based grid-forming (MIMO-GFM) control for the power converters\nusing a multivariable feedback structure. First, the MIMO-GFM control couples\nthe AC and DC loops by a general multivariable control transfer matrix. Then,\nthe parameters design is transformed into a standard fixed-structure H-infinity\nsynthesis. By this way, all the loops can be tuned simultaneously and optimally\nwithout relying on the assumptions of loop decoupling. Therefore, a superior\nand robust performance can be achieved. Experimental results verify the\nproposed method.",
    "descriptor": "",
    "authors": [
      "Meng Chen",
      "Dao Zhou",
      "Ali Tayyebi",
      "Eduardo Prieto-Araujo",
      "Florian D\u00f6rfler",
      "Frede Blaabjerg"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.08639"
  },
  {
    "id": "arXiv:2202.08640",
    "title": "Generalized Inverse Based Decoding",
    "abstract": "The concept of Generalized Inverse based Decoding (GID) is introduced, as an\nalgebraic framework for the syndrome decoding problem (SDP) and low weight\ncodeword problem (LWP). The framework has ground on two characterizations by\ngeneralized inverses (GIs), one for the null space of a matrix and the other\nfor the solution space of a system of linear equations over a finite field.\nGeneric GID solvers are proposed for SDP and LWP. It is shown that information\nset decoding (ISD) algorithms, such as Prange, Lee-Brickell, Leon, and Stern's\nalgorithms, are particular cases of GID solvers. All of them search GIs or\nelements of the null space under various specific strategies. However, as the\npaper shows the ISD variants do not search through the entire space, while our\nsolvers do even when they use just one Gaussian elimination. Apart from these,\nour GID framework clearly shows how each ISD algorithm, except for Prange's\nsolution, can be used as an SDP or LWP solver. A tight reduction from our\nproblems, viewed as optimization problems, to the MIN-SAT problem is also\nprovided. Experimental results show a very good behavior of the GID solvers.\nThe domain of easy weights can be reached by a very few iterations and even\nenlarged.",
    "descriptor": "\nComments: 41 pages, 5 figures, 5 page abstract submitted to ISIT2022\n",
    "authors": [
      "Ferucio Laurentiu Tiplea",
      "Vlad-Florin Dragoi"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.08640"
  },
  {
    "id": "arXiv:2202.08646",
    "title": "On-Time Communications Over Fading Channels",
    "abstract": "We consider the on-time transmissions of a sequence of packets over a fading\nchannel.Different from traditional in-time communications, we investigate how\nmany packets can be received $\\delta$-on-time, meaning that the packet is\nreceived with a deviation no larger than $\\delta$ slots. In this framework, we\nfirst derive the on-time reception rate of the random transmissions over the\nfading channel when no controlling is used. To improve the on-time reception\nrate, we further propose to schedule the transmissions by delaying, dropping,\nor repeating the packets. Specifically, we model the scheduling over the fading\nchannel as a Markov decision process (MDP) and then obtain the optimal\nscheduling policy using an efficient iterative algorithm. For a given sequence\nof packet transmissions, we analyze the on-time reception rate for the random\ntransmissions and the optimal scheduling. Our analytical and simulation results\nshow that the on-time reception rate of random transmissions decreases (to\nzero) with the sequence length.By using the optimal packet scheduling, the\non-time reception rate converges to a much larger constant. Moreover, we show\nthat the on-time reception rate increases if the target reception interval\nand/or the deviation tolerance $\\delta$ is increased, or the randomness of the\nfading channel is reduced.",
    "descriptor": "\nComments: Submitted to IEEE Journals for possible publication\n",
    "authors": [
      "Yan Li",
      "Yunquan Dong",
      "Byonghyo Shim"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.08646"
  },
  {
    "id": "arXiv:2202.08647",
    "title": "Semantically Proportional Patchmix for Few-Shot Learning",
    "abstract": "Few-shot learning aims to classify unseen classes with only a limited number\nof labeled data. Recent works have demonstrated that training models with a\nsimple transfer learning strategy can achieve competitive results in few-shot\nclassification. Although excelling at distinguishing training data, these\nmodels are not well generalized to unseen data, probably due to insufficient\nfeature representations on evaluation. To tackle this issue, we propose\nSemantically Proportional Patchmix (SePPMix), in which patches are cut and\npasted among training images and the ground truth labels are mixed\nproportionally to the semantic information of the patches. In this way, we can\nimprove the generalization ability of the model by regional dropout effect\nwithout introducing severe label noise. To learn more robust representations of\ndata, we further take rotate transformation on the mixed images and predict\nrotations as a rule-based regularizer. Extensive experiments on prevalent\nfew-shot benchmarks have shown the effectiveness of our proposed method.",
    "descriptor": "\nComments: 5 pages, 2figures. ICASSP 2022\n",
    "authors": [
      "Jingquan Wang",
      "Jing Xu",
      "Yu Pan",
      "Zenglin Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.08647"
  },
  {
    "id": "arXiv:2202.08648",
    "title": "Bode-based speed Proportional Integral and notch filter tuning of a  Permanent Magnet Synchronous Machine driven flexible system",
    "abstract": "A resonance and an antiresonance peak characterize many industrial mechanisms\ndynamics driven by a Permanent Magnet Synchronous Motor (PMSM). The presence of\nthe resonance peak can lead to vibrations and instability of the system. On\nthat account, advanced methods exist to tune the speed Proportional Integral\n(PI) controller based on adaptive or fuzzy theory. However, those methods\nrequire expertise in control theory and are not available in commercial drives.\nFor that, this paper proposes a Bode-based method for PI parameters selection\nin combination with a notch filter that can be easily set in any industrial\ndrive. The proposed method is compared with conventional tuning methods in a\nphysical setup.",
    "descriptor": "",
    "authors": [
      "Santiago Ramos Garces",
      "Abdelmajid Ben Yahya",
      "Nick van Oosterwyck",
      "Dries Jacques",
      "Stijn Derammelaere"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.08648"
  },
  {
    "id": "arXiv:2202.08649",
    "title": "Information and communication technology initiatives for knowledge  sharing in agriculture",
    "abstract": "A survey on status and trends of information and communication technologies\n(ICT) use for knowledge sharing in agriculture was attempted. Among asian\ncountries, India comes under the second next category after the advanced user\ncategory comprising Japan, South Korea and Taiwan. Both profit-motive and\nbusiness augmentation on one hand and community services and rural welfare on\nthe other have been the objectives of ICT-based models in agriculture in India.\nThe ICT endeavours for agriculture belong to a wide array of agencies, viz\nprivate sector, public sector, self-help groups and NGOs, and also include\ncombined endeavours. e-Learning is being increasingly resorted to both in (i)\nin campus or 'presence' mode, and (ii) 'distance' mode. Its use is gradually\neasing-out the stakeholders from the stranglehold of the inter-deterrence of\nthe 3 arms of the 'Iron Triangle', viz (i) quality, (ii) access, and (iii)\ncost. The social groups having less mobility are poised to benefit more from\nthis mode of education. This could also be one of the potent tools to bring\nabout gender mainstreaming. e-Learning is being integrated into the existing\norganizational and educational structure as a hybrid system that can be called\n'ICT-supported learning'. Connectivity, content development, infrastructure\ndevelopment, faculty developmeat, need assessment on a continuum, linking the\nnode3 and formation of consortia etc. are the areas identified that need to be\nsupported and developed.",
    "descriptor": "\nComments: this http URL\n",
    "authors": [
      "Siddhartha Paul Tiwari"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2202.08649"
  },
  {
    "id": "arXiv:2202.08656",
    "title": "Robust Sparse Voting",
    "abstract": "Many modern Internet applications, like content moderation and recommendation\non social media, require reviewing and score a large number of alternatives. In\nsuch a context, the voting can only be sparse, as the number of alternatives is\ntoo large for any individual to review a significant fraction of all of them.\nMoreover, in critical applications, malicious players might seek to hack the\nvoting process by entering dishonest reviews or creating fake accounts.\nClassical voting methods are unfit for this task, as they usually (a) require\neach reviewer to assess all available alternatives and (b) can be easily\nmanipulated by malicious players.\nThis paper defines precisely the problem of robust sparse voting, highlights\nits underlying technical challenges, and presents Mehestan, a novel voting\nmechanism that solves the problem. Namely, we prove that by using Mehestan, no\n(malicious) voter can have more than a small parametrizable effect on each\nalternative's score, and we identify conditions of voters comparability under\nwhich any unanimous preferences can be recovered, even when these preferences\nare expressed by voters on very different scales.",
    "descriptor": "",
    "authors": [
      "Youssef Allouah",
      "Rachid Guerraoui",
      "L\u00ea-Nguy\u00ean Hoang",
      "Oscar Villemaud"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Theoretical Economics (econ.TH)"
    ],
    "url": "https://arxiv.org/abs/2202.08656"
  },
  {
    "id": "arXiv:2202.08657",
    "title": "Bilimits in categories of partial maps",
    "abstract": "The closure of chains of embedding-projection pairs (ep-pairs) under bilimits\nin some categories of predomains and domains is standard and well-known. For\ninstance, Scott's $D_\\infty$ construction is well-known to produce directed\nbilimits of ep-pairs in the category of directed-complete partial orders, and\nde Jong and Escard\\'o have formalized this result in the constructive domain\ntheory of a topos. The explicit construcition of bilimits for categories of\npredomains and partial maps is considerably murkier as far as constructivity is\nconcerned; most expositions employ the constructive taboo that every\nlift-algebra is free, reducing the problem to the construction of bilimits in a\ncategory of pointed domains and strict maps. An explicit construction of the\nbilimit is proposed in the dissertation of Claire Jones, but no proof is given\nso it remained unclear if the category of dcpos and partial maps was closed\nunder directed bilimits of ep-pairs in a topos. We provide a\n(Grothendieck)-topos-valid proof that the category of dcpos and partial maps\nbetween them is closed under bilimits; then we describe some applications\ntoward models of axiomatic and synthetic domain theory.",
    "descriptor": "",
    "authors": [
      "Jonathan Sterling"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Category Theory (math.CT)"
    ],
    "url": "https://arxiv.org/abs/2202.08657"
  },
  {
    "id": "arXiv:2202.08658",
    "title": "The merged-staircase property: a necessary and nearly sufficient  condition for SGD learning of sparse functions on two-layer neural networks",
    "abstract": "It is currently known how to characterize functions that neural networks can\nlearn with SGD for two extremal parameterizations: neural networks in the\nlinear regime, and neural networks with no structural constraints. However, for\nthe main parametrization of interest (non-linear but regular networks) no tight\ncharacterization has yet been achieved, despite significant developments.\nWe take a step in this direction by considering depth-2 neural networks\ntrained by SGD in the mean-field regime. We consider functions on binary inputs\nthat depend on a latent low-dimensional subspace (i.e., small number of\ncoordinates). This regime is of interest since it is poorly understood how\nneural networks routinely tackle high-dimensional datasets and adapt to latent\nlow-dimensional structure without suffering from the curse of dimensionality.\nAccordingly, we study SGD-learnability with $O(d)$ sample complexity in a large\nambient dimension $d$.\nOur main results characterize a hierarchical property, the \"merged-staircase\nproperty\", that is both necessary and nearly sufficient for learning in this\nsetting.\nWe further show that non-linear training is necessary: for this class of\nfunctions, linear methods on any feature map (e.g., the NTK) are not capable of\nlearning efficiently. The key tools are a new \"dimension-free\" dynamics\napproximation result that applies to functions defined on a latent space of\nlow-dimension, a proof of global convergence based on polynomial identity\ntesting, and an improvement of lower bounds against linear methods for\nnon-almost orthogonal functions.",
    "descriptor": "",
    "authors": [
      "Emmanuel Abbe",
      "Enric Boix-Adsera",
      "Theodor Misiakiewicz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.08658"
  },
  {
    "id": "arXiv:2202.08669",
    "title": "PACSafe: Leveraging ARM Pointer Authentication for Memory Safety in  C/C++",
    "abstract": "Memory safety bugs remain in the top ranks of security vulnerabilities, even\nafter decades of research on their detection and prevention. Various\nmitigations have been proposed for C/C++, ranging from language dialects to\ninstrumentation. Among these, compiler-based instrumentation is particularly\npromising, not requiring manual code modifications and being able to achieve\nprecise memory safety. Unfortunately, existing compiler-based solutions\ncompromise in many areas, including performance but also usability and memory\nsafety guarantees. New developments in hardware can help improve performance\nand security of compiler-based memory safety. ARM Pointer Authentication, added\nin the ARMv8.3 architecture, is intended to enable hardware-assisted Control\nFlow Integrity. But since its operations are relatively generic, it also\nenables other, more comprehensive hardware-supported runtime integrity\napproaches. As such, we propose PACSafe, a memory safety approach based on ARM\nPointer Authentication. PACSafe uses pointer signatures to retrofit full memory\nsafety to C/C++ programs, protecting heap, stack, and globals against temporal\nand spatial vulnerabilities. We present a full, LLVM-based prototype\nimplementation, running on an M1 MacBook Pro, i.e., on actual ARMv8.3 hardware.\nOur prototype evaluation shows that the system outperforms similar approaches\nunder real-world conditions. This, together with its compatibility with\nuninstrumented libraries and cryptographic protection against attacks on\nmetadata, makes PACSafe a viable solution for retrofitting memory safety to\nC/C++ programs.",
    "descriptor": "",
    "authors": [
      "Konrad Hohentanner",
      "Philipp Zieris",
      "Julian Horsch"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Programming Languages (cs.PL)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2202.08669"
  },
  {
    "id": "arXiv:2202.08670",
    "title": "Domain Randomization for Object Counting",
    "abstract": "Recently, the use of synthetic datasets based on game engines has been shown\nto improve the performance of several tasks in computer vision. However, these\ndatasets are typically only appropriate for the specific domains depicted in\ncomputer games, such as urban scenes involving vehicles and people. In this\npaper, we present an approach to generate synthetic datasets for object\ncounting for any domain without the need for photo-realistic techniques\nmanually generated by expensive teams of 3D artists. We introduce a domain\nrandomization approach for object counting based on synthetic datasets that are\nquick and inexpensive to generate. We deliberately avoid photorealism and\ndrastically increase the variability of the dataset, producing images with\nrandom textures and 3D transformations, which improves generalization.\nExperiments show that our method facilitates good performance on various real\nword object counting datasets for multiple domains: people, vehicles, penguins,\nand fruit. The source code is available at: https://github.com/enric1994/dr4oc",
    "descriptor": "",
    "authors": [
      "Enric Moreu",
      "Kevin McGuinness",
      "Diego Ortego",
      "Noel E. O'Connor"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.08670"
  },
  {
    "id": "arXiv:2202.08674",
    "title": "Measuring Trustworthiness or Automating Physiognomy? A Comment on Safra,  Chevallier, Gr\u00e8zes, and Baumard (2020)",
    "abstract": "Interpersonal trust - a shared display of confidence and vulnerability toward\nother individuals - can be seen as instrumental in the development of human\nsocieties. Safra, Chevallier, Gr\\`ezes, and Baumard (2020) studied the\nhistorical progression of interpersonal trust by training a machine learning\n(ML) algorithm to generate trustworthiness ratings of historical portraits,\nbased on facial features. They reported that trustworthiness ratings of\nportraits dated between 1500--2000CE increased with time, claiming that this\nevidenced a broader increase in interpersonal trust coinciding with several\nmetrics of societal progress. We argue that these claims are confounded by\nseveral methodological and analytical issues and highlight troubling parallels\nbetween Safra et al.'s algorithm and the pseudoscience of physiognomy. We\ndiscuss the implications and potential real-world consequences of these issues\nin further detail.",
    "descriptor": "\nComments: 3 pages, 1 figure\n",
    "authors": [
      "Rory W Spanton",
      "Olivia Guest"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2202.08674"
  },
  {
    "id": "arXiv:2202.08675",
    "title": "Winograd Convolution: A Perspective from Fault Tolerance",
    "abstract": "Winograd convolution is originally proposed to reduce the computing overhead\nby converting multiplication in neural network (NN) with addition via linear\ntransformation. Other than the computing efficiency, we observe its great\npotential in improving NN fault tolerance and evaluate its fault tolerance\ncomprehensively for the first time. Then, we explore the use of fault tolerance\nof winograd convolution for either fault-tolerant or energy-efficient NN\nprocessing. According to our experiments, winograd convolution can be utilized\nto reduce fault-tolerant design overhead by 27.49\\% or energy consumption by\n7.19\\% without any accuracy loss compared to that without being aware of the\nfault tolerance",
    "descriptor": "\nComments: to be published in DAC 2022\n",
    "authors": [
      "Xinghua Xue",
      "Haitong Huang",
      "Cheng Liu",
      "Ying Wang",
      "Tao Luo",
      "Lei Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Hardware Architecture (cs.AR)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2202.08675"
  },
  {
    "id": "arXiv:2202.08679",
    "title": "Where Is My Training Bottleneck? Hidden Trade-Offs in Deep Learning  Preprocessing Pipelines",
    "abstract": "Preprocessing pipelines in deep learning aim to provide sufficient data\nthroughput to keep the training processes busy. Maximizing resource utilization\nis becoming more challenging as the throughput of training processes increases\nwith hardware innovations (e.g., faster GPUs, TPUs, and inter-connects) and\nadvanced parallelization techniques that yield better scalability. At the same\ntime, the amount of training data needed in order to train increasingly complex\nmodels is growing. As a consequence of this development, data preprocessing and\nprovisioning are becoming a severe bottleneck in end-to-end deep learning\npipelines.\nIn this paper, we provide an in-depth analysis of data preprocessing\npipelines from four different machine learning domains. We introduce a new\nperspective on efficiently preparing datasets for end-to-end deep learning\npipelines and extract individual trade-offs to optimize throughput,\npreprocessing time, and storage consumption. Additionally, we provide an\nopen-source profiling library that can automatically decide on a suitable\npreprocessing strategy to maximize throughput. By applying our generated\ninsights to real-world use-cases, we obtain an increased throughput of 3x to\n13x compared to an untuned system while keeping the pipeline functionally\nidentical. These findings show the enormous potential of data pipeline tuning.",
    "descriptor": "\nComments: To be published in SIGMOD, June 12-17, 2022, Philadelphia, PA, USA. Repository: this https URL\n",
    "authors": [
      "Alexander Isenko",
      "Ruben Mayer",
      "Jeffrey Jedele",
      "Hans-Arno Jacobsen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2202.08679"
  },
  {
    "id": "arXiv:2202.08686",
    "title": "Necessary and sufficient condition for a generic 3R serial manipulator  to be cuspidal",
    "abstract": "Cuspidal robots can travel from one inverse kinematic solution to another\nwithout meeting a singularity. The name cuspidal was coined based on the\nexistence of a cusp point in the workspace of 3R serial robots. The existence\nof a cusp point was proved to be a necessary and sufficient condition for\northogonal robots to be cuspidal, but it was not possible to extend this\ncondition to non-orthogonal robots. The goal of this paper is to prove that\nthis condition stands for any generic 3R robot. This result would give the\ndesigner more flexibility. In the presented work, the geometrical\ninterpretation of the inverse kinematics of 3R robots is revisited and\nimportant observations on the nonsingular change of posture are noted. The\npaper presents a theorem regarding the existence of reduced aspects in any\ngeneric 3R serial robot. Based on these observations and on this theorem, we\nprove that the existence of a cusp point is a necessary and sufficient\ncondition for any 3R generic robot to be cuspidal.",
    "descriptor": "",
    "authors": [
      "Durgesh Haribhau Salunkhe",
      "Christoforos Spartalis",
      "Jose Capco",
      "Damien Chablat",
      "Philippe Wenger"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.08686"
  },
  {
    "id": "arXiv:2202.08687",
    "title": "Term Rewriting Based On Set Automaton Matching",
    "abstract": "In previous work we have proposed an efficient pattern matching algorithm\nbased on the notion of set automaton. In this article we investigate how set\nautomata can be exploited to implement efficient term rewriting procedures.\nThese procedures interleave pattern matching steps and rewriting steps and thus\nsmoothly integrate redex discovery and subterm replacement. Concretely, we\npropose an optimised algorithm for outermost rewriting of left-linear term\nrewriting systems, prove its correctness, and present the results of some\nimplementation experiments.",
    "descriptor": "\nComments: Technical report to accompany a submission to FSCD 2022\n",
    "authors": [
      "Mark Bouwman",
      "Rick Erkens"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.08687"
  },
  {
    "id": "arXiv:2202.08688",
    "title": "Improved Optimal Testing Results from Global Hypercontractivity",
    "abstract": "The problem of testing low-degree polynomials has received significant\nattention over the years due to its importance in theoretical computer science,\nand in particular in complexity theory. The problem is specified by three\nparameters: field size $q$, degree $d$ and proximity parameter $\\delta$, and\nthe goal is to design a tester making as few as possible queries to a given\nfunction, which is able to distinguish between the case the given function has\ndegree at most $d$, and the case the given function is $\\delta$-far from any\ndegree $d$ function.\nA tester is called optimal if it makes $O(q^d+1/\\delta)$ queries (which are\nknown to be necessary). For the field of size $q$, the natural $t$-flat tester\nwas shown to be optimal first by Bhattacharyya et al. for $q=2$, and later by\nHaramaty et al. for all prime powers $q$. The dependency on the field size,\nhowever, is a tower-type function.\nWe improve the results above, showing that the dependency on the field size\nis polynomial. Our approach also applies in the more general setting of lifted\naffine invariant codes, and is based on studying the structure of the\ncollection of erroneous subspaces. i.e. subspaces $A$ such that $f|_{A}$ has\ndegree greater than $d$. Towards this end, we observe that these sets are\npoorly expanding in the affine version of the Grassmann graph and use that to\nestablish structural results on them via global hypercontractivity. We then use\nthis structure to perform local correction on $f$.",
    "descriptor": "",
    "authors": [
      "Tali Kaufman",
      "Dor Minzer"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2202.08688"
  },
  {
    "id": "arXiv:2202.08691",
    "title": "Non-linear stiffness behavior of planar serial robotic manipulators",
    "abstract": "The paper focuses on the stiffness analysis of multi-link serial planar\nmanipulators, which may demonstrate nonlinear stiffness behavior under the\ncompressive loading. Two important cases are considered, where the manipulator\nhas either a straight or non-straight initial configuration. It was proved that\nin the first case the loading may cause the buckling if it exceeds some\ncritical value, and the manipulator suddenly changes its straight shape and\nstiffness properties. For computing this critical force, a general\neigenvalue-based technique was proposed that can be applied to any multi-link\nserial manipulator. For the second case dealing with non-straight initial\nconfigurations, a universal energy-based technique was applied that allowed to\ndetect quasi-buckling phenomenon when it is observed very fast but not instant\nchange of the manipulator shape and its stiffness coefficient under the\nloading. These results are illustrated by numerous examples of non-linear\nstiffness behavior of three-and four-link manipulators that are subjected to\ncompressive force.",
    "descriptor": "",
    "authors": [
      "Wanda Zhao",
      "Alexandr Klimchik",
      "Anatol Pashkevich",
      "Damien Chablat"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.08691"
  },
  {
    "id": "arXiv:2202.08692",
    "title": "A study of deep perceptual metrics for image quality assessment",
    "abstract": "Several metrics exist to quantify the similarity between images, but they are\ninefficient when it comes to measure the similarity of highly distorted images.\nIn this work, we propose to empirically investigate perceptual metrics based on\ndeep neural networks for tackling the Image Quality Assessment (IQA) task. We\nstudy deep perceptual metrics according to different hyperparameters like the\nnetwork's architecture or training procedure. Finally, we propose our\nmulti-resolution perceptual metric (MR-Perceptual), that allows us to aggregate\nperceptual information at different resolutions and outperforms standard\nperceptual metrics on IQA tasks with varying image deformations. Our code is\navailable at https://github.com/ENSTA-U2IS/MR_perceptual",
    "descriptor": "",
    "authors": [
      "R\u00e9mi Kazmierczak",
      "Gianni Franchi",
      "Nacim Belkhir",
      "Antoine Manzanera",
      "David Filliat"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2202.08692"
  },
  {
    "id": "arXiv:2202.08695",
    "title": "Article's Scientific Prestige: measuring the impact of individual  articles in the Web of Science",
    "abstract": "We performed a citation analysis on the Web of Science publications\nconsisting of more than 63 million articles and 1.45 billion citations on 254\nsubjects from 1981 to 2020. We proposed the Article's Scientific Prestige (ASP)\nmetric and compared this metric to number of citations (#Cit) and journal grade\nin measuring the scientific impact of individual articles in the large-scale\nhierarchical and multi-disciplined citation network. In contrast to #Cit, ASP,\nthat is computed based on the eigenvector centrality, considers both direct and\nindirect citations, and provides steady-state evaluation cross different\ndisciplines. We found that ASP and #Cit are not aligned for most articles, with\na growing mismatch amongst the less cited articles. While both metrics are\nreliable for evaluating the prestige of articles such as Nobel Prize winning\narticles, ASP tends to provide more persuasive rankings than #Cit when the\narticles are not highly cited. The journal grade, that is eventually determined\nby a few highly cited articles, is unable to properly reflect the scientific\nimpact of individual articles. The number of references and coauthors are less\nrelevant to scientific impact, but subjects do make a difference.",
    "descriptor": "",
    "authors": [
      "Ying Chen",
      "Thorsten Koch",
      "Nazgul Zakiyeva",
      "Kailiang Liu",
      "Zhitong Xu",
      "Chun-houh Chen",
      "Junji Nakano",
      "Keisuke Honda"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2202.08695"
  },
  {
    "id": "arXiv:2202.08696",
    "title": "Conscious Commerce -- Digital Nudging and Sustainable E-commerce  Purchase Decisions",
    "abstract": "So-called 'fast fashion' consumption, amplified through cost-effective\ne-commerce, constitutes a major factor negatively impacting climate change. A\nrecently noted strategy to motivate consumers to more sustainable decisions is\ndigital nudging. This paper explores the capability of digital nudging in the\ncontext of green fashion e-commerce. To do so, digital default and social norm\nnudges are tested in an experimental setting of green fashion purchases. An\nonline experiment (n=320) was conducted, simulating an online retail scenario.\nResults failed to show statistically significant relationships between nudging\nstrategies and purchase decisions. However, explorative analyses show a\nbackfiring effect for the combination of nudges and thus, reveal a hitherto\nneglected impact of participants' identification on the effectiveness of the\ndigital nudging strategies. Consequently, this study contributes to digital\nnudging literature and informs practice with new insights on effective choice\narchitectures in e-commerce.",
    "descriptor": "\nComments: Australasian Conference on Information Systems\n",
    "authors": [
      "Milad Mirbabaie",
      "Julian Marx",
      "Johanna Germies"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2202.08696"
  },
  {
    "id": "arXiv:2202.08697",
    "title": "Distance learning as innovation technology of school geographical  education",
    "abstract": "The article substantiates the necessity of using innovative technologies in\nthe process of studying and teaching geographical disciplines at secondary\nschools. Particular attention is paid to distance learning as a pedagogical\ninnovation, its theoretical aspects and the ways of its introduction into the\neducational process. The relevance of using distance learning at the New\nUkrainian School is proved. Its advantages and disadvantages are revealed. The\nexamples of some forms of distance learning that will contribute to\ngeographical competence development according to European requirements are\nprovided. The article particularly focuses on the Massive Open Online Courses,\nmodern websites, virtual portals of individual teachers, LearningApps.org\nportal, and Moodle.",
    "descriptor": "\nComments: 1 table, 14 pages\n",
    "authors": [
      "Myroslav Syvyi",
      "Ordenbek Mazbayev",
      "Olga Varakuta",
      "Natalia Panteleeva",
      "Olga Bondarenko"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2202.08697"
  },
  {
    "id": "arXiv:2202.08699",
    "title": "How Do Smart Contracts Benefit Security Protocols?",
    "abstract": "Smart contracts have recently been adopted by many security protocols.\nHowever, existing studies lack satisfactory theoretical support on how\ncontracts benefit security protocols. This paper aims to give a systematic\nanalysis of smart contract (SC)-based security protocols to fulfill the gap of\nunclear arguments and statements. We firstly investigate \\textit{state of the\nart studies} and establish a formalized model of smart contract protocols with\nwell-defined syntax and assumptions. Then, we apply our formal framework to two\nconcrete instructions to explore corresponding advantages and desirable\nproperties. Through our analysis, we abstract three generic properties\n(\\textit{non-repudiation, non-equivocation, and non-frameability}) and\naccordingly identify two patterns. (1) a smart contract can be as an autonomous\nsubscriber to assist the trusted third party (TTP); (2) a smart contract can\nreplace traditional TTP. To the best of our knowledge, this is the first study\nto provide in-depth discussions of SC-based security protocols from a strictly\ntheoretical perspective.",
    "descriptor": "",
    "authors": [
      "Rujia Li",
      "Qin Wang",
      "Qi Wang",
      "David Galindo"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.08699"
  },
  {
    "id": "arXiv:2202.08700",
    "title": "Detecting and Learning the Unknown in Semantic Segmentation",
    "abstract": "Semantic segmentation is a crucial component for perception in automated\ndriving. Deep neural networks (DNNs) are commonly used for this task and they\nare usually trained on a closed set of object classes appearing in a closed\noperational domain. However, this is in contrast to the open world assumption\nin automated driving that DNNs are deployed to. Therefore, DNNs necessarily\nface data that they have never encountered previously, also known as anomalies,\nwhich are extremely safety-critical to properly cope with. In this work, we\nfirst give an overview about anomalies from an information-theoretic\nperspective. Next, we review research in detecting semantically unknown objects\nin semantic segmentation. We demonstrate that training for high entropy\nresponses on anomalous objects outperforms other recent methods, which is in\nline with our theoretical findings. Moreover, we examine a method to assess the\noccurrence frequency of anomalies in order to select anomaly types to include\ninto a model's set of semantic categories. We demonstrate that these anomalies\ncan then be learned in an unsupervised fashion, which is particularly suitable\nin online applications based on deep learning.",
    "descriptor": "\nComments: 37 pages, 7 figures, chapter in Deep Neural Networks and Data for Automated Driving\n",
    "authors": [
      "Robin Chan",
      "Svenja Uhlemeyer",
      "Matthias Rottmann",
      "Hanno Gottschalk"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.08700"
  },
  {
    "id": "arXiv:2202.08701",
    "title": "Revisiting reopened bugs in open source software systems",
    "abstract": "Reopened bugs can degrade the overall quality of a software system since they\nrequire unnecessary rework by developers. Moreover, reopened bugs also lead to\na loss of trust in the end-users regarding the quality of the software. Thus,\npredicting bugs that might be reopened could be extremely helpful for software\ndevelopers to avoid rework. Prior studies on reopened bug prediction focus only\non three open source projects (i.e., Apache, Eclipse, and OpenOffice) to\ngenerate insights. We observe that one out of the three projects (i.e., Apache)\nhas a data leak issue -- the bug status of reopened was included as training\ndata to predict reopened bugs. In addition, prior studies used an outdated\nprediction model pipeline (i.e., with old techniques for constructing a\nprediction model) to predict reopened bugs. Therefore, we revisit the reopened\nbugs study on a large scale dataset consisting of 47 projects tracked by JIRA\nusing the modern techniques such as SMOTE, permutation importance together with\n7 different machine learning models. We study the reopened bugs using a mixed\nmethods approach (i.e., both quantitative and qualitative study). We find that:\n1) After using an updated reopened bug prediction model pipeline, only 34%\nprojects give an acceptable performance with AUC >= 0.7. 2) There are four\nmajor reasons for a bug getting reopened, that is, technical (i.e.,\npatch/integration issues), documentation, human (i.e., due to incorrect bug\nassessment), and reasons not shown in the bug reports. 3) In projects with an\nacceptable AUC, 94% of the reopened bugs are due to patch issues (i.e., the\nusage of an incorrect patch) identified before bug reopening. Our study\nrevisits reopened bugs and provides new insights into developer's bug reopening\nactivities.",
    "descriptor": "",
    "authors": [
      "Ankur Tagra",
      "Haoxiang Zhang",
      "Gopi Krishnan Rajbahadur",
      "Ahmed E. Hassan"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2202.08701"
  },
  {
    "id": "arXiv:2202.08703",
    "title": "Robust Frequency Constrained UC Using Data Driven Logistic Regression  for Island Power Systems",
    "abstract": "In the current practice of short-term power scheduling, online power reserves\nare used to address generation mismatches and contingencies. Neither online\ninertia nor the speed of the committed units is considered in the scheduling\nprocess. With the increasing injection of uncertain renewable energy sources,\nthis practice is starting to fall short especially in island power systems,\nwhere the primary frequency response is already scarce, and any contingency\nleads to potentially poor frequency response. This paper introduces a data\ndriven linear constraint to improve the post-fault frequency quality in island\npower systems. A coherent initial data-set is obtained by simulating the system\nfrequency response of single outages. Then logistic regression is employed as a\npredictive analytic procedure to differentiate the acceptable and unacceptable\nincidents. To compare the conventional methods with the proposed approach and\nalso to handle the uncertain nature of renewable energy generation, an adaptive\nrobust unit commitment formulation is utilized. Results for the island power\nsystem of La Palma show that depending on the chosen cut-point on the logistic\nregression estimation the proposed method can improve the frequency response\nquality of the system while reducing the operation costs.",
    "descriptor": "",
    "authors": [
      "Mohammad Rajabdorri",
      "Enrique Lobato",
      "Lukas Sigrist"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.08703"
  },
  {
    "id": "arXiv:2202.08704",
    "title": "A Bi-Criteria FPTAS for Scheduling with Memory Constraints on Graph with  Bounded Tree-width",
    "abstract": "In this paper we study a scheduling problem arising from executing numerical\nsimulations on HPC architectures. With a constant number of parallel machines,\nthe objective is to minimize the makespan under memory constraints for the\nmachines. Those constraints come from a neighborhood graph G for the jobs.\nMotivated by a previous result on graphs G with bounded path-width, our focus\nis on the case when the neighborhood graph G has bounded tree-width. Our result\nis a bi-criteria fully polynomial time approximation algorithm based on a\ndynamic programming algorithm. It allows to find a solution within a factor of\n1 + epsilon of the optimal makespan, where the memory capacity of the machines\nmay be exceeded by a factor at most 1 + epsilon. This result relies on the use\nof a nice tree decomposition of G and its traversal in a specific way which may\nbe useful on its own. The case of unrelated machines is also tractable with\nminor modifications.",
    "descriptor": "",
    "authors": [
      "Eric Angel",
      "S\u00e9bastien Morais",
      "Damien Regnault"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2202.08704"
  },
  {
    "id": "arXiv:2202.08712",
    "title": "Mining On Alzheimer's Diseases Related Knowledge Graph to Identity  Potential AD-related Semantic Triples for Drug Repurposing",
    "abstract": "To date, there are no effective treatments for most neurodegenerative\ndiseases. Knowledge graphs can provide comprehensive and semantic\nrepresentation for heterogeneous data, and have been successfully leveraged in\nmany biomedical applications including drug repurposing. Our objective is to\nconstruct a knowledge graph from literature to study relations between\nAlzheimer's disease (AD) and chemicals, drugs and dietary supplements in order\nto identify opportunities to prevent or delay neurodegenerative progression. We\ncollected biomedical annotations and extracted their relations using SemRep via\nSemMedDB. We used both a BERT-based classifier and rule-based methods during\ndata preprocessing to exclude noise while preserving most AD-related semantic\ntriples. The 1,672,110 filtered triples were used to train with knowledge graph\ncompletion algorithms (i.e., TransE, DistMult, and ComplEx) to predict\ncandidates that might be helpful for AD treatment or prevention. Among three\nknowledge graph completion models, TransE outperformed the other two (MR =\n13.45, Hits@1 = 0.306). We leveraged the time-slicing technique to further\nevaluate the prediction results. We found supporting evidence for most highly\nranked candidates predicted by our model which indicates that our approach can\ninform reliable new knowledge. This paper shows that our graph mining model can\npredict reliable new relationships between AD and other entities (i.e., dietary\nsupplements, chemicals, and drugs). The knowledge graph constructed can\nfacilitate data-driven knowledge discoveries and the generation of novel\nhypotheses.",
    "descriptor": "\nComments: Submitted to the BMC Bioinformatics\n",
    "authors": [
      "Yi Nian",
      "Xinyue Hu",
      "Rui Zhang",
      "Jingna Feng",
      "Jingcheng Du",
      "Fang Li",
      "Yong Chen",
      "Cui Tao"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.08712"
  },
  {
    "id": "arXiv:2202.08713",
    "title": "Algorithmic Fair Allocation of Indivisible Items: A Survey and New  Questions",
    "abstract": "The theory of algorithmic fair allocation is within the center of multi-agent\nsystems and economics in the last decade due to its industrial and social\nimportance. At a high level, the problem is to assign a set of items that are\neither goods or chores to a set of agents so that every agent is happy with\nwhat she obtains. Particularly, in this survey, we focus on indivisible items,\nfor which absolute fairness such as envy-freeness and proportionality cannot be\nguaranteed. One main theme in the recent research agenda is about designing\nalgorithms that approximately achieve the fairness criteria. We aim at\npresenting a comprehensive survey of recent progresses through the prism of\nalgorithms, highlighting the ways to relax fairness notions and common\ntechniques to design algorithms, as well as the most interesting questions for\nfuture research.",
    "descriptor": "",
    "authors": [
      "Haris Aziz",
      "Bo Li",
      "Herve Moulin",
      "Xiaowei Wu"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2202.08713"
  },
  {
    "id": "arXiv:2202.08715",
    "title": "Primal and mixed finite element formulations for the relaxed  micromorphic model",
    "abstract": "The classical Cauchy continuum theory is suitable to model highly homogeneous\nmaterials. However, many materials, such as porous media or metamaterials,\nexhibit a pronounced microstructure. As a result, the classical continuum\ntheory cannot capture their mechanical behaviour without fully resolving the\nunderlying microstructure. In terms of finite element computations, this can be\ndone by modelling the entire body, including every interior cell. The relaxed\nmicromorphic continuum offers an alternative method by instead enriching the\nkinematics of the mathematical model. The theory introduces a microdistortion\nfield, encompassing nine extra degrees of freedom for each material point. The\ncorresponding elastic energy functional contains the gradient of the\ndisplacement field, the microdistortion field and its Curl (the\nmicro-dislocation). Therefore, the natural spaces of the fields are\n$[\\mathit{H}^1]^3$ for the displacement and $[\\mathit{H}(\\mathrm{curl})]^3$ for\nthe microdistortion, leading to unusual finite element formulations. In this\nwork we describe the construction of appropriate finite elements using\nN\\'ed\\'elec and Raviart-Thomas subspaces, encompassing solutions to the\norientation problem and the discrete consistent coupling condition. Further, we\nexplore the numerical behaviour of the relaxed micromorphic model for both a\nprimal and a mixed formulation. The focus of our benchmarks lies in the\ninfluence of the characteristic length $L_\\mathrm{c}$ and the correlation to\nthe classical Cauchy continuum theory.",
    "descriptor": "",
    "authors": [
      "Adam Sky",
      "Michael Neunteufel",
      "Ingo Muench",
      "Joachim Sch\u00f6berl",
      "Patrizio Neff"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.08715"
  },
  {
    "id": "arXiv:2202.08717",
    "title": "Level set based particle filter driven by optical flow: an application  to track the salt boundary from X-ray CT time-series",
    "abstract": "Image-based computational fluid dynamics have long played an important role\nin leveraging knowledge and understanding of several physical phenomena. In\nparticular, probabilistic computational methods have opened the way to\nmodelling the complex dynamics of systems in purely random turbulent motion. In\nthe field of structural geology, a better understanding of the deformation and\nstress state both within the salt and the surrounding rocks is of great\ninterest to characterize all kinds of subsurface long-terms energy-storage\nsystems. The objective of this research is to determine the non-linear\ndeformation of the salt boundary over time using a parallelized, stochastic\nfiltering approach from x-ray computed tomography (CT) image time series\ndepicting the evolution of salt structures triggered by gravity and under\ndifferential loading. This work represents a first step towards bringing\ntogether physical modeling and advanced stochastic image processing methods\nwhere model uncertainty is taken into account.",
    "descriptor": "",
    "authors": [
      "Karim Makki",
      "Jean Fran\u00e7ois Lecomte",
      "Lukas Fuchs",
      "Sylvie Schueller",
      "Etienne M\u00e9min"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2202.08717"
  },
  {
    "id": "arXiv:2202.08718",
    "title": "A Deterministic Pathogen Transmission Model Based on High-Fidelity  Physics",
    "abstract": "A deterministic pathogen transmission model based on high-fidelity physics\nhas been developed. The model combines computational fluid dynamics and\ncomputational crowd dynamics in order to be able to provide accurate tracing of\nviral matter that is exhaled, transmitted and inhaled via aerosols. The\nexamples shown indicate that even with modest computing resources, the\npropagation and transmission of viral matter can be simulated for relatively\nlarge areas with thousands of square meters, hundreds of pedestrians and\nseveral minutes of physical time. The results obtained and insights gained from\nthese simulations can be used to inform global pandemic propagation models,\nincreasing substantially their accuracy.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2009.03365\n",
    "authors": [
      "Rainald L\u00f6hner",
      "Harbir Antil",
      "Juan Marcelo Gimenez",
      "Sergio Idelsohn",
      "Eugenio O\u00f1ate"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Biological Physics (physics.bio-ph)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2202.08718"
  },
  {
    "id": "arXiv:2202.08721",
    "title": "Game Theoretic Models for Profit-Sharing in Multi-fleet Platoons",
    "abstract": "Profit-sharing is needed within platoons in order for competing\ntransportation companies to collaborate in forming platoons. In this paper, we\npropose distribution models of the profit designed for vehicles that are\nlocated at the same origin and are operated by competing transportation\ncompanies. The vehicles have default departure times, but can decide to depart\nat other times in order to benefit from platooning. We model the strategic\ninteraction among vehicles with game theory and consider pure Nash equilibria\nas the solution concept. In a numerical evaluation we compare the outcomes of\nthe games associated with different distribution models of the profit.",
    "descriptor": "\nComments: ITSC 2019\n",
    "authors": [
      "Alexander Johansson",
      "Jonas M\u00e5rtensson"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.08721"
  },
  {
    "id": "arXiv:2202.08724",
    "title": "Real-Time Cross-Fleet Pareto-Improving Truck Platoon Coordination",
    "abstract": "This paper studies a multi-fleet platoon coordination system in transport\nnetworks that deploy hubs to form trucks into platoons. The trucks belong to\ndifferent fleets that are interested in increasing their profits by platooning\nacross fleets. The profit of each fleet incorporates platooning rewards and\ncosts for waiting at hubs. Each truck has a fixed route and a waiting time\nbudget to spend at the hubs along its route. To ensure that all fleets are\nwilling to participate in the system, we develop a cross-fleet Pareto-improving\ncoordination strategy that guarantees higher fleet profits than a coordination\nstrategy without cross-fleet platoons. By leveraging multiple hubs for platoon\nformation, the coordination strategy can be implemented in a real-time and\ndistributed fashion while largely reducing the amount of travel information to\nbe shared for system-wide coordination. We evaluate the proposed strategy in a\nsimulation study over the Swedish transportation network. The cross-fleet\nplatooning strategy significantly improves fleets' profits compared with\nsingle-fleet platooning, especially the profits from smaller fleets. The\ncross-fleet platooning strategy also shows strong competitiveness in terms of\nthe system-wide profit compared to the case when a system planner optimizes all\nfleets' total profit.",
    "descriptor": "\nComments: ITSC 2021\n",
    "authors": [
      "Alexander Johansson",
      "Jonas M\u00e5rtensson",
      "Xiaotong Sun",
      "Yafeng Yin"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.08724"
  },
  {
    "id": "arXiv:2202.08725",
    "title": "A Completeness Result for Inequational Reasoning in a Full Higher-Order  Setting",
    "abstract": "This paper obtains a completeness result for inequational reasoning with\napplicative terms without variables in a setting where the intended semantic\nmodels are the full structures, the full type hierarchies over preorders for\nthe base types. The syntax allows for the specification that a given symbol be\ninterpreted as a monotone function, or an antitone function, or both. There is\na natural set of five rules for inequational reasoning. One can add variables\nand also add a substitution rule, but we observe that this logic would be\nincomplete for full structures. This is why the completeness result in this\npaper pertains to terms without variables. Since the completeness is already\nknown for the class of general (Henkin) structures, we are interested in full\nstructures. We present a completeness theorem. Our result is not optimal\nbecause we restrict to base preorders which have a weak completeness property:\nevery pair of elements has an upper bound and a lower bound. To compensate we\nadd several rules to the logic. We also present extensions and variations of\nour completeness result.",
    "descriptor": "\nComments: 23 pages\n",
    "authors": [
      "Lawrence S. Moss",
      "Thomas F. Icard"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2202.08725"
  },
  {
    "id": "arXiv:2202.08730",
    "title": "Colonoscopy polyp detection with massive endoscopic images",
    "abstract": "We improved an existing end-to-end polyp detection model with better average\nprecision validated by different data sets with trivial cost on detection\nspeed. Previous work on detecting polyps within colonoscopy \\cite{Chen2018}\nprovided an efficient end-to-end solution to alleviate doctor's examination\noverhead. However, our later experiments found this framework is not as robust\nas before as the condition of polyp capturing varies. In this work, we\nconducted several studies on data set, identifying main issues that causes low\nprecision rate in the task of polyp detection. We used an optimized anchor\ngeneration methods to get better anchor box shape and more boxes are used for\ndetection as we believe this is necessary for small object detection. A\nalternative backbone is used to compensate the heavy time cost introduced by\ndense anchor box regression. With use of the attention gate module, our model\ncan achieve state-of-the-art polyp detection performance while still maintain\nreal-time detection speed.",
    "descriptor": "\nComments: 13 pages, 10 figures\n",
    "authors": [
      "Jialin Yu",
      "Huogen Wang",
      "Ming Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.08730"
  },
  {
    "id": "arXiv:2202.08737",
    "title": "Listing Maximal k-Plexes in Large Real-World Graphs",
    "abstract": "Listing dense subgraphs in large graphs plays a key task in varieties of\nnetwork analysis applications like community detection. Clique, as the densest\nmodel, has been widely investigated. However, in practice, communities rarely\nform as cliques for various reasons, e.g., data noise. Therefore, $k$-plex, --\ngraph with each vertex adjacent to all but at most $k$ vertices, is introduced\nas a relaxed version of clique. Often, to better simulate cohesive communities,\nan emphasis is placed on connected $k$-plexes with small $k$. In this paper, we\ncontinue the research line of listing all maximal $k$-plexes and maximal\n$k$-plexes of prescribed size. Our first contribution is algorithm\n\\emph{ListPlex} that lists all maximal $k$-plexes in $O^*(\\gamma^D)$ time for\neach constant $k$, where $\\gamma$ is a value related to $k$ but strictly\nsmaller than 2, and $D$ is the degeneracy of the graph that is far less than\nthe vertex number $n$ in real-word graphs. Compared to the trivial bound of\n$2^n$, the improvement is significant, and our bound is better than all\npreviously known results. In practice, we further use several techniques to\naccelerate listing $k$-plexes of a given size, such as structural-based prune\nrules, cache-efficient data structures, and parallel techniques. All these\ntogether result in a very practical algorithm. Empirical results show that our\napproach outperforms the state-of-the-art solutions by up to orders of\nmagnitude.",
    "descriptor": "\nComments: WWW'2022\n",
    "authors": [
      "Zhengren Wang",
      "Yi Zhou",
      "Mingyun Xiao",
      "Bakhadyr Khoussainov"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2202.08737"
  },
  {
    "id": "arXiv:2202.08740",
    "title": "On H1, H(curl) and H(sym Curl) finite elements for matrix-valued Curl  problems",
    "abstract": "In this work we test the numerical behaviour of matrix-valued fields\napproximated by finite element subspaces of $[\\mathit{H}^1]^{3\\times 3}$,\n$[\\mathit{H}(\\mathrm{curl})]^3$ and $\\mathit{H}(\\mathrm{sym}\\mathrm{Curl})$ for\na linear abstract variational problem connected to the relaxed micromorphic\nmodel. The formulation of the corresponding finite elements is introduced,\nfollowed by numerical benchmarks and our conclusions. The relaxed micromorphic\ncontinuum model reduces the continuity assumptions of the classical\nmicromorphic model by replacing the full gradient of the microdistortion in the\nfree energy functional with the Curl. This results in a larger solution space\nfor the microdistortion, namely $[\\mathit{H}(\\mathrm{curl})]^3$ in place of the\nclassical $[\\mathit{H}^1]^{3\\times 3}$. The continuity conditions on the\nmicrodistortion can be further weakened by taking only the symmetric part of\nthe Curl. As shown in recent works, the new appropriate space for the\nmicrodistortion is then $\\mathit{H}(\\mathrm{sym}\\mathrm{Curl})$. The newly\nintroduced space gives rise to a new differential complex for the relaxed\nmicromorphic continuum theory.",
    "descriptor": "",
    "authors": [
      "Adam Sky",
      "Ingo Muench",
      "Patrizio Neff"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.08740"
  },
  {
    "id": "arXiv:2202.08743",
    "title": "Evolving Constructions for Balanced, Highly Nonlinear Boolean Functions",
    "abstract": "Finding balanced, highly nonlinear Boolean functions is a difficult problem\nwhere it is not known what nonlinearity values are possible to be reached in\ngeneral. At the same time, evolutionary computation is successfully used to\nevolve specific Boolean function instances, but the approach cannot easily\nscale for larger Boolean function sizes. Indeed, while evolving smaller Boolean\nfunctions is almost trivial, larger sizes become increasingly difficult, and\nevolutionary algorithms perform suboptimally. In this work, we ask whether\ngenetic programming (GP) can evolve constructions resulting in balanced Boolean\nfunctions with high nonlinearity. This question is especially interesting as\nthere are only a few known such constructions. Our results show that GP can\nfind constructions that generalize well, i.e., result in the required functions\nfor multiple tested sizes. Further, we show that GP evolves many equivalent\nconstructions under different syntactic representations. Interestingly, the\nsimplest solution found by GP is a particular case of the well-known indirect\nsum construction.",
    "descriptor": "\nComments: 22 pages, 5 figures, 6 tables\n",
    "authors": [
      "Claude Carlet",
      "Marko Djurasevic",
      "Domagoj Jakobovic",
      "Luca Mariot",
      "Stjepan Picek"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.08743"
  },
  {
    "id": "arXiv:2202.08747",
    "title": "Finding a Battleship of Uncertain Shape",
    "abstract": "Motivated by a game of Battleship, we consider the problem of efficiently\nhitting a ship of an uncertain shape within a large playing board. Formally, we\nfix a dimension $d\\in\\{1,2\\}$. A ship is a subset of $\\mathbb{Z}^d$. Given a\nfamily $F$ of ships, we say that an infinite subset $X\\subset\\mathbb{Z}^d$ of\nthe cells pierces $F$, if it intersects each translate of each ship in $F$ (by\na vector in $\\mathbb{Z}^d$). In this work, we study the lowest possible\n(asymptotic) density $\\pi(F)$ of such a piercing subset. To our knowledge, this\nproblem has previously been studied only in the special case $|F|=1$ (a single\nship). As our main contribution, we present a formula for $\\pi(F)$ when $F$\nconsists of 2 ships of size 2 each, and we identify the toughest families in\nseveral other cases. We also implement an algorithm for finding $\\pi(F)$ in 1D.",
    "descriptor": "\nComments: 10 pages, 6 figures\n",
    "authors": [
      "Eva-Maria Hainzl",
      "Maarten L\u00f6ffler",
      "Daniel Perz",
      "Josef Tkadlec",
      "Markus Wallinger"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2202.08747"
  },
  {
    "id": "arXiv:2202.08748",
    "title": "Multi-Fleet Platoon Matching: A Game-Theoretic Approach",
    "abstract": "We consider the platoon matching problem for a set of trucks with the same\norigin, but different destinations. It is assumed that the vehicles benefit\nfrom traveling in a platoon for instance through reduced fuel consumption. The\nvehicles belong to different fleet owners and their strategic interaction is\nmodeled as a non-cooperative game where the vehicle actions are their departure\ntimes. Each truck has a preferred departure time and its utility function is\ndefined as the difference between its benefit from platooning and the cost of\ndeviating from its preferred departure time. We show that the platoon matching\ngame is an exact potential game. An algorithm based on best response dynamics\nis proposed for finding a Nash equilibrium of the game. At a Nash equilibrium,\nvehicles with the same departure time are matched to form a platoon. Finally,\nthe total fuel reduction at the Nash equilibrium is studied and compared with\nthat of a cooperative matching solution where a common utility function for all\nvehicles is optimized.",
    "descriptor": "\nComments: ITSC 2018\n",
    "authors": [
      "Alexander Johansson",
      "Ehsan Nekouei",
      "Karl Henrik Johansson",
      "Jonas M\u00e5rtensson"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.08748"
  },
  {
    "id": "arXiv:2202.08751",
    "title": "Improving Rating and Relevance with Point-of-Interest Recommender System",
    "abstract": "The recommendation of points of interest (POIs) is essential in\nlocation-based social networks. It makes it easier for users and locations to\nshare information. Recently, researchers tend to recommend POIs by treating\nthem as large-scale retrieval systems that require a large amount of training\ndata representing query-item relevance. However, gathering user feedback in\nretrieval systems is an expensive task. Existing POI recommender systems make\nrecommendations based on user and item (location) interactions solely. However,\nthere are numerous sources of feedback to consider. For example, when the user\nvisits a POI, what is the POI is about and such. Integrating all these\ndifferent types of feedback is essential when developing a POI recommender. In\nthis paper, we propose using user and item information and auxiliary\ninformation to improve the recommendation modelling in a retrieval system. We\ndevelop a deep neural network architecture to model query-item relevance in the\npresence of both collaborative and content information. We also improve the\nquality of the learned representations of queries and items by including the\ncontextual information from the user feedback data. The application of these\nlearned representations to a large-scale dataset resulted in significant\nimprovements.",
    "descriptor": "",
    "authors": [
      "Syed Raza Bashir",
      "Vojislav Misic"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.08751"
  },
  {
    "id": "arXiv:2202.08752",
    "title": "OmniSyn: Synthesizing 360 Videos with Wide-baseline Panoramas",
    "abstract": "Immersive maps such as Google Street View and Bing Streetside provide\ntrue-to-life views with a massive collection of panoramas. However, these\npanoramas are only available at sparse intervals along the path they are taken,\nresulting in visual discontinuities during navigation. Prior art in view\nsynthesis is usually built upon a set of perspective images, a pair of\nstereoscopic images, or a monocular image, but barely examines wide-baseline\npanoramas, which are widely adopted in commercial platforms to optimize\nbandwidth and storage usage. In this paper, we leverage the unique\ncharacteristics of wide-baseline panoramas and present OmniSyn, a novel\npipeline for 360{\\deg} view synthesis between wide-baseline panoramas. OmniSyn\npredicts omnidirectional depth maps using a spherical cost volume and a\nmonocular skip connection, renders meshes in 360{\\deg} images, and synthesizes\nintermediate views with a fusion network. We demonstrate the effectiveness of\nOmniSyn via comprehensive experimental results including comparison with the\nstate-of-the-art methods on CARLA and Matterport datasets, ablation studies,\nand generalization studies on street views. We envision our work may inspire\nfuture research for this unheeded real-world task and eventually produce a\nsmoother experience for navigating immersive maps.",
    "descriptor": "",
    "authors": [
      "David Li",
      "Yinda Zhang",
      "Christian H\u00e4ne",
      "Danhang Tang",
      "Amitabh Varshney",
      "Ruofei Du"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2202.08752"
  },
  {
    "id": "arXiv:2202.08756",
    "title": "Ensemble Conformalized Quantile Regression for Probabilistic Time Series  Forecasting",
    "abstract": "This paper presents a novel probabilistic forecasting method called ensemble\nconformalized quantile regression (EnCQR). EnCQR constructs distribution-free\nand approximately marginally valid prediction intervals (PIs), is suitable for\nnonstationary and heteroscedastic time series data, and can be applied on top\nof any forecasting model, including deep learning architectures that are\ntrained on long data sequences. EnCQR exploits a bootstrap ensemble estimator,\nwhich enables the use of conformal predictors for time series by removing the\nrequirement of data exchangeability. The ensemble learners are implemented as\ngeneric machine learning algorithms performing quantile regression, which allow\nthe length of the PIs to adapt to local variability in the data. In the\nexperiments, we predict time series characterized by a different amount of\nheteroscedasticity. The results demonstrate that EnCQR outperforms models based\nonly on quantile regression or conformal prediction, and it provides sharper,\nmore informative, and valid PIs.",
    "descriptor": "",
    "authors": [
      "Vilde Jensen",
      "Filippo Maria Bianchi",
      "Stian Norman Anfinsen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.08756"
  },
  {
    "id": "arXiv:2202.08758",
    "title": "A Wavelet-based Dual-stream Network for Underwater Image Enhancement",
    "abstract": "We present a wavelet-based dual-stream network that addresses color cast and\nblurry details in underwater images. We handle these artifacts separately by\ndecomposing an input image into multiple frequency bands using discrete wavelet\ntransform, which generates the downsampled structure image and detail images.\nThese sub-band images are used as input to our dual-stream network that\nincorporates two sub-networks: the multi-color space fusion network and the\ndetail enhancement network. The multi-color space fusion network takes the\ndecomposed structure image as input and estimates the color corrected output by\nemploying the feature representations from diverse color spaces of the input.\nThe detail enhancement network addresses the blurriness of the original\nunderwater image by improving the image details from high-frequency sub-bands.\nWe validate the proposed method on both real-world and synthetic underwater\ndatasets and show the effectiveness of our model in color correction and blur\nremoval with low computational complexity.",
    "descriptor": "",
    "authors": [
      "Ziyin Ma",
      "Changjae Oh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2202.08758"
  },
  {
    "id": "arXiv:2202.08761",
    "title": "QuerTCI: A Tool Integrating GitHub Issue Querying with Comment  Classification",
    "abstract": "Issue tracking systems enable users and developers to comment on problems\nplaguing a software system. Empirical Software Engineering (ESE) researchers\nstudy (open-source) project issues and the comments and threads within to\ndiscover -- among others -- challenges developers face when, e.g.,\nincorporating new technologies, platforms, and programming language constructs.\nHowever, issue discussion threads accumulate over time and thus can become\nunwieldy, hindering any insight that researchers may gain. While existing\napproaches alleviate this burden by classifying issue thread comments, there is\na gap between searching popular open-source software repositories (e.g., those\non GitHub) for issues containing particular keywords and feeding the results\ninto a classification model. In this paper, we demonstrate a research\ninfrastructure tool called QuerTCI that bridges this gap by integrating the\nGitHub issue comment search API with the classification models found in\nexisting approaches. Using queries, ESE researchers can retrieve GitHub issues\ncontaining particular keywords, e.g., those related to a certain programming\nlanguage construct, and subsequently classify the kinds of discussions\noccurring in those issues. Using our tool, our hope is that ESE researchers can\nuncover challenges related to particular technologies using certain keywords\nthrough popular open-source repositories more seamlessly than previously\npossible. A tool demonstration video may be found at:\nhttps://youtu.be/fADKSxn0QUk.",
    "descriptor": "",
    "authors": [
      "Ye Paing",
      "Tatiana Castro V\u00e9lez",
      "Raffi Khatchadourian"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2202.08761"
  },
  {
    "id": "arXiv:2202.08763",
    "title": "Residual-based error estimation and adaptivity for stabilized immersed  isogeometric analysis using truncated hierarchical B-splines",
    "abstract": "We propose an adaptive mesh refinement strategy for immersed isogeometric\nanalysis, with application to steady heat conduction and viscous flow problems.\nThe proposed strategy is based on residual-based error estimation, which has\nbeen tailored to the immersed setting by the incorporation of appropriately\nscaled stabilization and boundary terms. Element-wise error indicators are\nelaborated for the Laplace and Stokes problems, and a THB-spline-based local\nmesh refinement strategy is proposed. The error estimation .and adaptivity\nprocedure is applied to a series of benchmark problems, demonstrating the\nsuitability of the technique for a range of smooth and non-smooth problems. The\nadaptivity strategy is also integrated in a scan-based analysis workflow,\ncapable of generating reliable, error-controlled, results from scan data,\nwithout the need for extensive user interactions or interventions.",
    "descriptor": "\nComments: Submitted to Journal of Mechanics\n",
    "authors": [
      "Sai C. Divi",
      "Pieter H. van Zuijlen",
      "Tuong Hoang",
      "Frits de Prenter",
      "Ferdinando Auricchio",
      "Alessandro Reali",
      "E. Harald van Brummelen",
      "Clemens V. Verhoosel"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Mathematical Physics (math-ph)"
    ],
    "url": "https://arxiv.org/abs/2202.08763"
  },
  {
    "id": "arXiv:2202.08766",
    "title": "Are spectral coarse spaces sufficiently robust for heterogeneous  Helmholtz problems?",
    "abstract": "Numerical solution of heterogeneous Helmholtz problems presents various\ncomputational challenges, with descriptive theory remaining out of reach for\nmany popular approaches. Robustness and scalability are key for practical and\nreliable solvers in large-scale applications, especially for large wave number\nproblems. In this work we explore the use of a GenEO-type coarse space to build\na two-level additive Schwarz method applicable to highly indefinite Helmholtz\nproblems. Through a range of numerical tests on a 2D model problem, discretised\nby finite elements on pollution-free meshes, we observe robust, wave number\nindependent convergence and scalability of our approach. We further provide\nresults showing a favourable comparison with the DtN coarse space. Our\nnumerical study shows promise that our solver methodology can be effective for\nchallenging heterogeneous applications.",
    "descriptor": "",
    "authors": [
      "Niall Bootland",
      "Victorita Dolean"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.08766"
  },
  {
    "id": "arXiv:2202.08771",
    "title": "Realistic Blur Synthesis for Learning Image Deblurring",
    "abstract": "Training learning-based deblurring methods demands a significant amount of\nblurred and sharp image pairs. Unfortunately, existing synthetic datasets are\nnot realistic enough, and existing real-world blur datasets provide limited\ndiversity of scenes and camera settings. As a result, deblurring models trained\non them still suffer from the lack of generalization ability for handling real\nblurred images. In this paper, we analyze various factors that introduce\ndifferences between real and synthetic blurred images, and present a novel blur\nsynthesis pipeline that can synthesize more realistic blur. We also present\nRSBlur, a novel dataset that contains real blurred images and the corresponding\nsequences of sharp images. The RSBlur dataset can be used for generating\nsynthetic blurred images to enable detailed analysis on the differences between\nreal and synthetic blur. With our blur synthesis pipeline and RSBlur dataset,\nwe reveal the effects of different factors in the blur synthesis. We also show\nthat our synthesis method can improve the deblurring performance on real\nblurred images.",
    "descriptor": "",
    "authors": [
      "Jaesung Rim",
      "Geonung Kim",
      "Jungeon Kim",
      "Junyong Lee",
      "Seungyong Lee",
      "Sunghyun Cho"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.08771"
  },
  {
    "id": "arXiv:2202.08772",
    "title": "A Survey of Knowledge-Intensive NLP with Pre-Trained Language Models",
    "abstract": "With the increasing of model capacity brought by pre-trained language models,\nthere emerges boosting needs for more knowledgeable natural language processing\n(NLP) models with advanced functionalities including providing and making\nflexible use of encyclopedic and commonsense knowledge. The mere pre-trained\nlanguage models, however, lack the capacity of handling such\nknowledge-intensive NLP tasks alone. To address this challenge, large numbers\nof pre-trained language models augmented with external knowledge sources are\nproposed and in rapid development. In this paper, we aim to summarize the\ncurrent progress of pre-trained language model-based knowledge-enhanced models\n(PLMKEs) by dissecting their three vital elements: knowledge sources,\nknowledge-intensive NLP tasks, and knowledge fusion methods. Finally, we\npresent the challenges of PLMKEs based on the discussion regarding the three\nelements and attempt to provide NLP practitioners with potential directions for\nfurther research.",
    "descriptor": "\nComments: Work in progress\n",
    "authors": [
      "Da Yin",
      "Li Dong",
      "Hao Cheng",
      "Xiaodong Liu",
      "Kai-Wei Chang",
      "Furu Wei",
      "Jianfeng Gao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.08772"
  },
  {
    "id": "arXiv:2202.08774",
    "title": "mmWave Communications for Indoor Dense Spaces: Ray-Tracing Based Channel  Characterization and Performance Comparison",
    "abstract": "In this paper, the indoor dense space (IDS) channel at 28 GHz is\ncharacterized through extensive Ray-Tracing (RT) simulations. We consider IDS\nas a specific type of indoor environment with confined geometry and packed with\nhumans, such as aircraft cabins and train wagons. Based on RT simulations, we\ncharacterize path loss, shadow fading, root-mean-square delay spread, Rician\nK-factor, azimuth/elevation angular spread of arrival/departure considering\ndifferent RT simulation scenarios of the fuselage geometry, material, and human\npresence. While the large-scale fading parameters are similar to the\nstate-of-the-art channel models, the small-scale fading parameters demonstrate\nricher multipath scattering in IDS, resulting in poorer bit error rate\nperformance in comparison to the 3GPP indoor channel model.",
    "descriptor": "",
    "authors": [
      "Ozan Alp Topal",
      "Mustafa Ozger",
      "Dominic Schupke",
      "Emil Bj\u00f6rnson",
      "Cicek Cavdar"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.08774"
  },
  {
    "id": "arXiv:2202.08779",
    "title": "Spiral Trajectories for Building Inspection with Quadrotors",
    "abstract": "Inspection of large building is an important task since it can prevent\nmaterial and human losses. A cheap and fast way to do the inspections is by\nsensors mounted on quadrotor vehicles. The challenge here is to compute a\ntrajectory so that the building is completely observed while this same\ntrajectory can be followed by the quadrotor in a smooth way. To address the\nproblem, we propose a method that receives a 2.5D model of the target building\nand computes a smooth trajectory that can be followed by the quadrotor\ncontroller. The computed trajectory is a Fourier series that matches the\ndesired behaviour. Our method has been tested in simulation and we have\ncompared it against polynomial trajectories. Our result show that the method is\nefficient and can be applied to different building shapes.",
    "descriptor": "\nComments: In preparation for conference\n",
    "authors": [
      "Juan Irving Vasquez",
      "David E. Troncoso Romero",
      "Mayra Antonio-Cruz",
      "Erik Zamora"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.08779"
  },
  {
    "id": "arXiv:2202.08780",
    "title": "Selling Information in Competitive Environments",
    "abstract": "We consider a setting where data buyers compete in a game of incomplete\ninformation, about which a data seller owns some payoff relevant information.\nWe formulate the problem facing the seller as a joint information and mechanism\ndesign problem: deciding which information to sell, while at the same time\neliciting the private value types of the buyers and collecting payments. We\nderive the welfare- and revenue-optimal mechanisms for a class of binary games.\nOur results reveal some important features of selling information in\ncompetitive environments: (i) the negative externalities arising from\ncompetition among buyers increase the profitability of selling information to\none of the buyers exclusively; (ii) in order for the buyers to follow the\nseller's action recommendations, the degree of information exclusivity must be\nlimited; (iii) the same obedience constraints also limit the distortions in the\nallocation of information that can be introduced by a monopolist seller; (iv)\nas competition across buyers becomes fiercer, these limitations become more\nsevere, weakening the impact of market power on the equilibrium allocation of\ninformation.",
    "descriptor": "",
    "authors": [
      "Alessandro Bonatti",
      "Munther Dahleh",
      "Thibaut Horel",
      "Amir Nouripour"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2202.08780"
  },
  {
    "id": "arXiv:2202.08788",
    "title": "Global Convergence of Sub-gradient Method for Robust Matrix Recovery:  Small Initialization, Noisy Measurements, and Over-parameterization",
    "abstract": "In this work, we study the performance of sub-gradient method (SubGM) on a\nnatural nonconvex and nonsmooth formulation of low-rank matrix recovery with\n$\\ell_1$-loss, where the goal is to recover a low-rank matrix from a limited\nnumber of measurements, a subset of which may be grossly corrupted with noise.\nWe study a scenario where the rank of the true solution is unknown and\nover-estimated instead. The over-estimation of the rank gives rise to an\nover-parameterized model in which there are more degrees of freedom than\nneeded. Such over-parameterization may lead to overfitting, or adversely affect\nthe performance of the algorithm. We prove that a simple SubGM with small\ninitialization is agnostic to both over-parameterization and noise in the\nmeasurements. In particular, we show that small initialization nullifies the\neffect of over-parameterization on the performance of SubGM, leading to an\nexponential improvement in its convergence rate. Moreover, we provide the first\nunifying framework for analyzing the behavior of SubGM under both outlier and\nGaussian noise models, showing that SubGM converges to the true solution, even\nunder arbitrarily large and arbitrarily dense noise values, and--perhaps\nsurprisingly--even if the globally optimal solutions do not correspond to the\nground truth. At the core of our results is a robust variant of restricted\nisometry property, called Sign-RIP, which controls the deviation of the\nsub-differential of the $\\ell_1$-loss from that of an ideal, expected loss. As\na byproduct of our results, we consider a subclass of robust low-rank matrix\nrecovery with Gaussian measurements, and show that the number of required\nsamples to guarantee the global convergence of SubGM is independent of the\nover-parameterized rank.",
    "descriptor": "",
    "authors": [
      "Jianhao Ma",
      "Salar Fattahi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.08788"
  },
  {
    "id": "arXiv:2202.08791",
    "title": "cosFormer: Rethinking Softmax in Attention",
    "abstract": "Transformer has shown great successes in natural language processing,\ncomputer vision, and audio processing. As one of its core components, the\nsoftmax attention helps to capture long-range dependencies yet prohibits its\nscale-up due to the quadratic space and time complexity to the sequence length.\nKernel methods are often adopted to reduce the complexity by approximating the\nsoftmax operator. Nevertheless, due to the approximation errors, their\nperformances vary in different tasks/corpus and suffer crucial performance\ndrops when compared with the vanilla softmax attention. In this paper, we\npropose a linear transformer called cosFormer that can achieve comparable or\nbetter accuracy to the vanilla transformer in both casual and cross attentions.\ncosFormer is based on two key properties of softmax attention: i).\nnon-negativeness of the attention matrix; ii). a non-linear re-weighting scheme\nthat can concentrate the distribution of the attention matrix. As its linear\nsubstitute, cosFormer fulfills these properties with a linear operator and a\ncosine-based distance re-weighting mechanism. Extensive experiments on language\nmodeling and text understanding tasks demonstrate the effectiveness of our\nmethod. We further examine our method on long sequences and achieve\nstate-of-the-art performance on the Long-Range Arena benchmark. The source code\nis available at https://github.com/OpenNLPLab/cosFormer.",
    "descriptor": "\nComments: Accepted to ICLR2022. Yiran Zhong is the corresponding author. Zhen Qin, Weixuan Sun, Hui Deng contributed equally to this work\n",
    "authors": [
      "Zhen Qin",
      "Weixuan Sun",
      "Hui Deng",
      "Dongxu Li",
      "Yunshen Wei",
      "Baohong Lv",
      "Junjie Yan",
      "Lingpeng Kong",
      "Yiran Zhong"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.08791"
  },
  {
    "id": "arXiv:2202.08792",
    "title": "Seeing Like a Toolkit: How Toolkits Envision the Work of AI Ethics",
    "abstract": "Numerous toolkits have been developed to support ethical AI development.\nHowever, toolkits, like all tools, encode assumptions in their design about\nwhat work should be done and how. In this paper, we conduct a qualitative\nanalysis of 27 AI ethics toolkits to critically examine how the work of ethics\nis imagined and how it is supported by these toolkits. Specifically, we examine\nthe discourses toolkits rely on when talking about ethical issues, who they\nimagine should do the work of ethics, and how they envision the work practices\ninvolved in addressing ethics. We find that AI ethics toolkits largely frame\nthe work of AI ethics to be technical work for individual technical\npractitioners, despite calls for engaging broader sets of stakeholders in\ngrappling with social aspects of AI ethics, and without contending with the\norganizational and political implications of AI ethics work in practice. Among\nall toolkits, we identify a mismatch between the imagined work of ethics and\nthe support the toolkits provide for doing that work. We identify a lack of\nguidance around how to navigate organizational power dynamics as they relate to\nperforming ethical work. We use these omissions to chart future work for\nresearchers and designers of AI ethics toolkits.",
    "descriptor": "\nComments: Pre-print manuscript\n",
    "authors": [
      "Richmond Y. Wong",
      "Michael A. Madaio",
      "Nick Merrill"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2202.08792"
  },
  {
    "id": "arXiv:2202.08794",
    "title": "Social network analysis of Staphylococcus aureus carriage in a general  youth population",
    "abstract": "Staphylococcus aureus nasal carriage increases risk of infection and has been\nassociated with lifestyle behavior and biological host characteristics. We used\nsocial network analysis to evaluate whether contacts have the same S. aureus\ngenotype, or whether contagiousness is an indirect effect of contacts sharing\nthe same lifestyle or characteristics.\nThe Fit Futures 1 study collected data on social contact among 1038 first\nlevel students in the same high school district in Norway. S. aureus persistent\ncarriage was determined from two nasal swab cultures and genotype from\nspa-typing of a positive throat swab culture. Bootstrap, t-tests, logistic\nregression, and autocorrelation were used to evaluate social network influence\non host risk factors and S. aureus carriage.\nBoth persistent carriage and spa-type were transmitted in the social network\n(p<0.001). The probability of carriage increased by 3.7% and 5.0% for each\nadditional S. aureus positive friend, in univariable regression and\nmultivariable autocorrelation analysis respectively. Male sex was associated\nwith a 15% lower risk of transmission compared to women, although the\nprevalence of carriage was higher for men (36% versus 24%). Medium physical\nactivity, medium and high alcohol-use, and normal-weight students had higher\nnumber of contacts, and increased risk of transmission (p<0.002).\nWe demonstrate direct social transmission of S. aureus in a general youth\npopulation. Lifestyle factors are associated with risk of transmission\nsuggesting indirect social group effects from having more similar environmental\nexposures. The predominance in carriage is determined by sex-specific\npredisposing host characteristics as social transmission is less frequent than\nin females. Better understanding of how social interactions influence S. aureus\ncarriage dynamics in the population is important for developing new preventive\nmeasures.",
    "descriptor": "\nComments: 37 pages, 9 figures, 10 tables\n",
    "authors": [
      "Dina Benedicte Stensen",
      "Rafael Adolfo Nozal Ca\u00f1adas",
      "Lars Sm\u00e5brekke",
      "Karina Olsen",
      "Christopher Sivert Nielsen",
      "Kristian Svendsen",
      "Anne Merethe Hanssen",
      "Johanna Sollid",
      "Gunnar Skov Simonsen",
      "Lars Ailo Bongo",
      "Anne-Sofie Furberg"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2202.08794"
  },
  {
    "id": "arXiv:2202.08796",
    "title": "Computation of Miura surfaces for general Dirichlet boundary conditions",
    "abstract": "A nonlinear partial differential equation (PDE) that models the possible\nshapes that a periodic Miura tessellation can take in the homogenization limit\nhas been established recently and solved only in specific cases. In this paper,\nthe existence and uniqueness of a solution to the PDE is proved for general\nDirichlet boundary conditions. Then a H^2-conforming discretization is\nintroduced to approximate the solution of the PDE and a fixed point algorithm\nis proposed to solve the associated discrete problem. A convergence proof for\nthe method is given as well as a convergence rate. Finally, numerical\nexperiments show the robustness of the method and that non trivial shapes can\nbe achieved using periodic Miura tessellations.",
    "descriptor": "",
    "authors": [
      "Frederic Marazzato"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)"
    ],
    "url": "https://arxiv.org/abs/2202.08796"
  },
  {
    "id": "arXiv:2202.08805",
    "title": "Making a Radical Misogynist: How online social engagement with the  Manosphere influences traits of radicalization",
    "abstract": "The algorithms and the interactions facilitated by online platforms have been\nused by radical groups to recruit vulnerable individuals to their cause. This\nhas resulted in the sharp growth of violent events and deteriorating online\ndiscourse. The Manosphere, a collection of radical anti-feminist communities,\nis one such group which has attracted attention due to their rapid growth and\nincreasingly violent real world outbursts. In this paper, we examine the social\nengagements between Reddit users who have participated in feminist discourse\nand the Manosphere communities on Reddit to understand the process of\ndevelopment of traits associated with the adoption of extremist ideologies. By\nusing existing research on the psychology of radicalization we track how\nspecific types of social engagement with the Manosphere influence the\ndevelopment of traits associated with radicalization. Our findings show that:\n(1) participation, even by the simple act of joining the Manosphere, has a\nsignificant influence on the language and outlook traits of a user, (2)\nManosphere elites are extremely effective propagators of radical traits and\ncause their increase even outside the Manosphere, and (3) community perception\ncan heavily influence a user's behavior. Finally, we examine how our findings\ncan help draft community and platform moderation policies to help mitigate the\nproblem of online radicalization.",
    "descriptor": "",
    "authors": [
      "Hussam Habib",
      "Padmini Srinivasan",
      "Rishab Nithyanand"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2202.08805"
  },
  {
    "id": "arXiv:2202.08806",
    "title": "Grammar-Based Grounded Lexicon Learning",
    "abstract": "We present Grammar-Based Grounded Lexicon Learning (G2L2), a lexicalist\napproach toward learning a compositional and grounded meaning representation of\nlanguage from grounded data, such as paired images and texts. At the core of\nG2L2 is a collection of lexicon entries, which map each word to a tuple of a\nsyntactic type and a neuro-symbolic semantic program. For example, the word\nshiny has a syntactic type of adjective; its neuro-symbolic semantic program\nhas the symbolic form {\\lambda}x. filter(x, SHINY), where the concept SHINY is\nassociated with a neural network embedding, which will be used to classify\nshiny objects. Given an input sentence, G2L2 first looks up the lexicon entries\nassociated with each token. It then derives the meaning of the sentence as an\nexecutable neuro-symbolic program by composing lexical meanings based on\nsyntax. The recovered meaning programs can be executed on grounded inputs. To\nfacilitate learning in an exponentially-growing compositional space, we\nintroduce a joint parsing and expected execution algorithm, which does local\nmarginalization over derivations to reduce the training time. We evaluate G2L2\non two domains: visual reasoning and language-driven navigation. Results show\nthat G2L2 can generalize from small amounts of data to novel compositions of\nwords.",
    "descriptor": "\nComments: NeurIPS 2021. Project page: this https URL\n",
    "authors": [
      "Jiayuan Mao",
      "Haoyue Shi",
      "Jiajun Wu",
      "Roger P. Levy",
      "Joshua B. Tenenbaum"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.08806"
  },
  {
    "id": "arXiv:2202.08808",
    "title": "Fast Dynamic Updates and Dynamic SpGEMM on MPI-Distributed Graphs",
    "abstract": "Sparse matrix multiplication (SpGEMM) is a fundamental kernel used in many\ndiverse application areas, both numerical and discrete. Recently, SpGEMM has\nreceived growing attention regarding implementations for specific (parallel)\narchitectures. Yet, this concerns only the static problem, where both input\nmatrices do not change. In many applications, however, matrices (or their\ncorresponding graphs) change over time. Although recomputing from scratch is\nvery expensive, we are not aware of any dynamic SpGEMM algorithms in the\nliterature.\nIn this paper, we thus propose a batch-dynamic algorithm for MPI-based\nparallel computing. Building on top of a distributed graph/matrix data\nstructure that allows for fast updates, our dynamic SpGEMM reduces the\ncommunication volume significantly. It does so by exploiting that updates\nchange far fewer matrix entries than there are non-zeros in the input operands.\nOur experiments with popular benchmark graphs show that our approach pays off.\nFor batches of insertions or removals of matrix entries, our dynamic SpGEMM is\nsubstantially faster than the static state-of-the-art algorithm in CombBLAS 2.0\nand in CTF.",
    "descriptor": "",
    "authors": [
      "Alexander van der Grinten",
      "Geert Custers",
      "Duy Le Thanh",
      "Henning Meyerhenke"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2202.08808"
  },
  {
    "id": "arXiv:2202.08812",
    "title": "Should I send this notification? Optimizing push notifications decision  making by modeling the future",
    "abstract": "Most recommender systems are myopic, that is they optimize based on the\nimmediate response of the user. This may be misaligned with the true objective,\nsuch as creating long term user satisfaction. In this work we focus on mobile\npush notifications, where the long term effects of recommender system decisions\ncan be particularly strong. For example, sending too many or irrelevant\nnotifications may annoy a user and cause them to disable notifications.\nHowever, a myopic system will always choose to send a notification since\nnegative effects occur in the future. This is typically mitigated using\nheuristics. However, heuristics can be hard to reason about or improve, require\nretuning each time the system is changed, and may be suboptimal. To counter\nthese drawbacks, there is significant interest in recommender systems that\noptimize directly for long-term value (LTV). Here, we describe a method for\nmaximising LTV by using model-based reinforcement learning (RL) to make\ndecisions about whether to send push notifications. We model the effects of\nsending a notification on the user's future behavior. Much of the prior work\napplying RL to maximise LTV in recommender systems has focused on session-based\noptimization, while the time horizon for notification decision making in this\nwork extends over several days. We test this approach in an A/B test on a major\nsocial network. We show that by optimizing decisions about push notifications\nwe are able to send less notifications and obtain a higher open rate than the\nbaseline system, while generating the same level of user engagement on the\nplatform as the existing, heuristic-based, system.",
    "descriptor": "",
    "authors": [
      "Conor O'Brien",
      "Huasen Wu",
      "Shaodan Zhai",
      "Dalin Guo",
      "Wenzhe Shi",
      "Jonathan J Hunt"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.08812"
  },
  {
    "id": "arXiv:2202.08814",
    "title": "MATCHA: A Fast and Energy-Efficient Accelerator for Fully Homomorphic  Encryption over the Torus",
    "abstract": "Fully Homomorphic Encryption over the Torus (TFHE) allows arbitrary\ncomputations to happen directly on ciphertexts using homomorphic logic gates.\nHowever, each TFHE gate on state-of-the-art hardware platforms such as GPUs and\nFPGAs is extremely slow ($>0.2ms$). Moreover, even the latest FPGA-based TFHE\naccelerator cannot achieve high energy efficiency, since it frequently invokes\nexpensive double-precision floating point FFT and IFFT kernels. In this paper,\nwe propose a fast and energy-efficient accelerator, MATCHA, to process TFHE\ngates. MATCHA supports aggressive bootstrapping key unrolling to accelerate\nTFHE gates without decryption errors by approximate multiplication-less integer\nFFTs and IFFTs, and a pipelined datapath. Compared to prior accelerators,\nMATCHA improves the TFHE gate processing throughput by $2.3\\times$, and the\nthroughput per Watt by $6.3\\times$.",
    "descriptor": "\nComments: 6 pages\n",
    "authors": [
      "Lei Jiang",
      "Qian Lou",
      "Nrushad Joshi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2202.08814"
  },
  {
    "id": "arXiv:2202.08815",
    "title": "GRAPHSHAP: Motif-based Explanations for Black-box Graph Classifiers",
    "abstract": "Most methods for explaining black-box classifiers (e.g., on tabular data,\nimages, or time series) rely on measuring the impact that the\nremoval/perturbation of features has on the model output. This forces the\nexplanation language to match the classifier features space. However, when\ndealing with graph data, in which the basic features correspond essentially to\nthe adjacency information describing the graph structure (i.e., the edges),\nthis matching between features space and explanation language might not be\nappropriate. In this regard, we argue that (i) a good explanation method for\ngraph classification should be fully agnostic with respect to the internal\nrepresentation used by the black-box; and (ii) a good explanation language for\ngraph classification tasks should be represented by higher-order structures,\nsuch as motifs. The need to decouple the feature space (edges) from the\nexplanation space (motifs) is thus a major challenge towards developing\nactionable explanations for graph classification tasks. In this paper we\nintroduce GRAPHSHAP, a Shapley-based approach able to provide motif-based\nexplanations for black-box graph classifiers, assuming no knowledge whatsoever\nabout the model or its training data: the only requirement is that the\nblack-box can be queried at will. Furthermore, we introduce additional\nauxiliary components such as a synthetic graph dataset generator, algorithms\nfor subgraph mining and ranking, a custom graph convolutional layer, and a\nkernel to approximate the explanation scores while maintaining linear time\ncomplexity. Finally, we test GRAPHSHAP on a real-world brain-network dataset\nconsisting of patients affected by Autism Spectrum Disorder and a control\ngroup. Our experiments highlight how the classification provided by a black-box\nmodel can be effectively explained by few connectomics patterns.",
    "descriptor": "\nComments: 20 pages, 9 figures\n",
    "authors": [
      "Alan Perotti",
      "Paolo Bajardi",
      "Francesco Bonchi",
      "Andr\u00e9 Panisson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.08815"
  },
  {
    "id": "arXiv:2202.08816",
    "title": "Learning and Evaluating Graph Neural Network Explanations based on  Counterfactual and Factual Reasoning",
    "abstract": "Structural data well exists in Web applications, such as social networks in\nsocial media, citation networks in academic websites, and threads data in\nonline forums. Due to the complex topology, it is difficult to process and make\nuse of the rich information within such data. Graph Neural Networks (GNNs) have\nshown great advantages on learning representations for structural data.\nHowever, the non-transparency of the deep learning models makes it non-trivial\nto explain and interpret the predictions made by GNNs. Meanwhile, it is also a\nbig challenge to evaluate the GNN explanations, since in many cases, the\nground-truth explanations are unavailable.\nIn this paper, we take insights of Counterfactual and Factual (CF^2)\nreasoning from causal inference theory, to solve both the learning and\nevaluation problems in explainable GNNs. For generating explanations, we\npropose a model-agnostic framework by formulating an optimization problem based\non both of the two casual perspectives. This distinguishes CF^2 from previous\nexplainable GNNs that only consider one of them. Another contribution of the\nwork is the evaluation of GNN explanations. For quantitatively evaluating the\ngenerated explanations without the requirement of ground-truth, we design\nmetrics based on Counterfactual and Factual reasoning to evaluate the necessity\nand sufficiency of the explanations. Experiments show that no matter\nground-truth explanations are available or not, CF^2 generates better\nexplanations than previous state-of-the-art methods on real-world datasets.\nMoreover, the statistic analysis justifies the correlation between the\nperformance on ground-truth evaluation and our proposed metrics.",
    "descriptor": "\nComments: To be published at the Web Conference 2022 (WWW 2022)\n",
    "authors": [
      "Juntao Tan",
      "Shijie Geng",
      "Zuohui Fu",
      "Yingqiang Ge",
      "Shuyuan Xu",
      "Yunqi Li",
      "Yongfeng Zhang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.08816"
  },
  {
    "id": "arXiv:2202.08818",
    "title": "Designing Word Filter Tools for Creator-led Comment Moderation",
    "abstract": "Online social platforms centered around content creators often allow comments\non content, where creators moderate the comments they receive. As creators can\nface overwhelming numbers of comments, with some of them harassing or hateful,\nplatforms typically provide tools such as word filters for creators to automate\naspects of moderation. From needfinding interviews with 19 creators about how\nthey use existing tools, we found that they struggled with writing good filters\nas well as organizing and revisiting their filters, due to the difficulty of\ndetermining what the filters actually catch. To address these issues, we\npresent FilterBuddy, a system that supports creators in authoring new filters\nor building from existing filter lists, as well as organizing their filters and\nvisualizing what comments are captured over time. We conducted an early-stage\nevaluation of FilterBuddy with YouTube creators, finding that participants see\nFilterBuddy not just as a moderation tool, but also a means to organize their\ncomments to better understand their audiences.",
    "descriptor": "\nComments: to be published in CHI Conference on Human Factors in Computing Systems (CHI '22)\n",
    "authors": [
      "Shagun Jhaver",
      "Quan Ze Chen",
      "Detlef Knauss",
      "Amy Zhang"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2202.08818"
  },
  {
    "id": "arXiv:2202.08821",
    "title": "Human-Algorithm Collaboration: Achieving Complementarity and Avoiding  Unfairness",
    "abstract": "Much of machine learning research focuses on predictive accuracy: given a\ntask, create a machine learning model (or algorithm) that maximizes accuracy.\nIn many settings, however, the final prediction or decision of a system is\nunder the control of a human, who uses an algorithm's output along with their\nown personal expertise in order to produce a combined prediction. One ultimate\ngoal of such collaborative systems is \"complementarity\": that is, to produce\nlower loss (equivalently, greater payoff or utility) than either the human or\nalgorithm alone. However, experimental results have shown that even in\ncarefully-designed systems, complementary performance can be elusive. Our work\nprovides three key contributions. First, we provide a theoretical framework for\nmodeling simple human-algorithm systems and demonstrate that multiple prior\nanalyses can be expressed within it. Next, we use this model to prove\nconditions where complementarity is impossible, and give constructive examples\nof where complementarity is achievable. Finally, we discuss the implications of\nour findings, especially with respect to the fairness of a classifier. In sum,\nthese results deepen our understanding of key factors influencing the combined\nperformance of human-algorithm systems, giving insight into how algorithmic\ntools can best be designed for collaborative environments.",
    "descriptor": "\nComments: Preliminary version accepted (panel presentation) at Neurips workshop on Human-Centered AI\n",
    "authors": [
      "Kate Donahue",
      "Alexandra Chouldechova",
      "Krishnaram Kenthapadi"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.08821"
  },
  {
    "id": "arXiv:2202.08824",
    "title": "Multi-stage Ensemble Model for Cross-market Recommendation",
    "abstract": "This paper describes the solution of our team PolimiRank for the WSDM Cup\n2022 on cross-market recommendation. The goal of the competition is to\neffectively exploit the information extracted from different markets to improve\nthe ranking accuracy of recommendations on two target markets. Our model\nconsists in a multi-stage approach based on the combination of data belonging\nto different markets. In the first stage, state-of-the-art recommenders are\nused to predict scores for user-item couples, which are ensembled in the\nfollowing 2 stages, employing a simple linear combination and more powerful\nGradient Boosting Decision Tree techniques. Our team ranked 4th in the final\nleaderboard.",
    "descriptor": "\nComments: 5 pages, 2 figures, 3 tables\n",
    "authors": [
      "Cesare Bernardis"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.08824"
  },
  {
    "id": "arXiv:2202.08827",
    "title": "LAMP: Extracting Text from Gradients with Language Model Priors",
    "abstract": "Recent work shows that sensitive user data can be reconstructed from gradient\nupdates, breaking the key privacy promise of federated learning. While success\nwas demonstrated primarily on image data, these methods do not directly\ntransfer to other domains such as text. In this work, we propose LAMP, a novel\nattack tailored to textual data, that successfully reconstructs original text\nfrom gradients. Our key insight is to model the prior probability of the text\nwith an auxiliary language model, utilizing it to guide the search towards more\nnatural text. Concretely, LAMP introduces a discrete text transformation\nprocedure that minimizes both the reconstruction loss and the prior text\nprobability, as provided by the auxiliary language model. The procedure is\nalternated with a continuous optimization of the reconstruction loss, which\nalso regularizes the length of the reconstructed embeddings. Our experiments\ndemonstrate that LAMP reconstructs the original text significantly more\nprecisely than prior work: we recover 5x more bigrams and $23\\%$ longer\nsubsequences on average. Moreover, we are first to recover inputs from batch\nsizes larger than 1 for textual models. These findings indicate that gradient\nupdates of models operating on textual data leak more information than\npreviously thought.",
    "descriptor": "",
    "authors": [
      "Dimitar I. Dimitrov",
      "Mislav Balunovi\u0107",
      "Nikola Jovanovi\u0107",
      "Martin Vechev"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2202.08827"
  },
  {
    "id": "arXiv:2202.08830",
    "title": "Optimal polynomial smoothers for multigrid V-cycles",
    "abstract": "The idea of using polynomial methods to improve simple smoother iterations\nwithin a multigrid method for a symmetric positive definite (SPD) system is\nrevisited. When the single-step smoother itself corresponds to an SPD operator,\nthere is in particular a very simple iteration, a close cousin of the Chebyshev\nsemi-iterative method, based on the Chebyshev polynomials of the fourth instead\nof first kind, that optimizes a two-level bound going back to Hackbusch. A full\nV-cycle bound for general polynomial smoothers is derived using the V-cycle\ntheory of McCormick. The fourth-kind Chebyshev iteration is quasi-optimal for\nthe V-cycle bound. The optimal polynomials for the V-cycle bound can be found\nnumerically, achieving an about 18% lower error contraction factor bound than\nthe fourth-kind Chebyshev iteration, asymptotically as the number of smoothing\nsteps goes to infinity. Implementation of the optimized iteration is discussed,\nand the performance of the polynomial smoothers are illustrated with a simple\nnumerical example.",
    "descriptor": "",
    "authors": [
      "James Lottes"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.08830"
  },
  {
    "id": "arXiv:2202.08833",
    "title": "The Exact Class of Graph Functions Generated by Graph Neural Networks",
    "abstract": "Given a graph function, defined on an arbitrary set of edge weights and node\nfeatures, does there exist a Graph Neural Network (GNN) whose output is\nidentical to the graph function? In this paper, we fully answer this question\nand characterize the class of graph problems that can be represented by GNNs.\nWe identify an algebraic condition, in terms of the permutation of edge weights\nand node features, which proves to be necessary and sufficient for a graph\nproblem to lie within the reach of GNNs. Moreover, we show that this condition\ncan be efficiently verified by checking quadratically many constraints. Note\nthat our refined characterization on the expressive power of GNNs are\northogonal to those theoretical results showing equivalence between GNNs and\nWeisfeiler-Lehman graph isomorphism heuristic. For instance, our\ncharacterization implies that many natural graph problems, such as min-cut\nvalue, max-flow value, and max-clique size, can be represented by a GNN. In\ncontrast, and rather surprisingly, there exist very simple graphs for which no\nGNN can correctly find the length of the shortest paths between all nodes. Note\nthat finding shortest paths is one of the most classical problems in Dynamic\nProgramming (DP). Thus, the aforementioned negative example highlights the\nmisalignment between DP and GNN, even though (conceptually) they follow very\nsimilar iterative procedures. Finally, we support our theoretical results by\nexperimental simulations.",
    "descriptor": "\nComments: 29 pages\n",
    "authors": [
      "Mohammad Fereydounian",
      "Hamed Hassani",
      "Javid Dadashkarimi",
      "Amin Karbasi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.08833"
  },
  {
    "id": "arXiv:2202.08835",
    "title": "General Cyclical Training of Neural Networks",
    "abstract": "This paper describes the principle of \"General Cyclical Training\" in machine\nlearning, where training starts and ends with \"easy training\" and the \"hard\ntraining\" happens during the middle epochs. We propose several manifestations\nfor training neural networks, including algorithmic examples (via\nhyper-parameters and loss functions), data-based examples, and model-based\nexamples. Specifically, we introduce several novel techniques: cyclical weight\ndecay, cyclical batch size, cyclical focal loss, cyclical softmax temperature,\ncyclical data augmentation, cyclical gradient clipping, and cyclical\nsemi-supervised learning. In addition, we demonstrate that cyclical weight\ndecay, cyclical softmax temperature, and cyclical gradient clipping (as three\nexamples of this principle) are beneficial in the test accuracy performance of\na trained model. Furthermore, we discuss model-based examples (such as\npretraining and knowledge distillation) from the perspective of general\ncyclical training and recommend some changes to the typical training\nmethodology. In summary, this paper defines the general cyclical training\nconcept and discusses several specific ways in which this concept can be\napplied to training neural networks. In the spirit of reproducibility, the code\nused in our experiments is available at \\url{https://github.com/lnsmith54/CFL}.",
    "descriptor": "\nComments: Position paper\n",
    "authors": [
      "Leslie N. Smith"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.08835"
  },
  {
    "id": "arXiv:2202.08836",
    "title": "Data-SUITE: Data-centric identification of in-distribution incongruous  examples",
    "abstract": "Systematic quantification of data quality is critical for consistent model\nperformance. Prior works have focused on out-of-distribution data. Instead, we\ntackle an understudied yet equally important problem of characterizing\nincongruous regions of in-distribution (ID) data, which may arise from feature\nspace heterogeneity. To this end, we propose a paradigm shift with Data-SUITE:\na data-centric framework to identify these regions, independent of a\ntask-specific model. DATA-SUITE leverages copula modeling, representation\nlearning, and conformal prediction to build feature-wise confidence interval\nestimators based on a set of training instances. These estimators can be used\nto evaluate the congruence of test instances with respect to the training set,\nto answer two practically useful questions: (1) which test instances will be\nreliably predicted by a model trained with the training instances? and (2) can\nwe identify incongruous regions of the feature space so that data owners\nunderstand the data's limitations or guide future data collection? We\nempirically validate Data-SUITE's performance and coverage guarantees and\ndemonstrate on cross-site medical data, biased data, and data with concept\ndrift, that Data-SUITE best identifies ID regions where a downstream model may\nbe reliable (independent of said model). We also illustrate how these\nidentified regions can provide insights into datasets and highlight their\nlimitations.",
    "descriptor": "",
    "authors": [
      "Nabeel Seedat",
      "Jonathan Crabbe",
      "Mihaela van der Schaar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.08836"
  },
  {
    "id": "arXiv:2202.08837",
    "title": "Adiabatic Quantum Computing for Multi Object Tracking",
    "abstract": "Multi-Object Tracking (MOT) is most often approached in the\ntracking-by-detection paradigm, where object detections are associated through\ntime. The association step naturally leads to discrete optimization problems.\nAs these optimization problems are often NP-hard, they can only be solved\nexactly for small instances on current hardware. Adiabatic quantum computing\n(AQC) offers a solution for this, as it has the potential to provide a\nconsiderable speedup on a range of NP-hard optimization problems in the near\nfuture. However, current MOT formulations are unsuitable for quantum computing\ndue to their scaling properties. In this work, we therefore propose the first\nMOT formulation designed to be solved with AQC. We employ an Ising model that\nrepresents the quantum mechanical system implemented on the AQC. We show that\nour approach is competitive compared with state-of-the-art optimization-based\napproaches, even when using of-the-shelf integer programming solvers. Finally,\nwe demonstrate that our MOT problem is already solvable on the current\ngeneration of real quantum computers for small examples, and analyze the\nproperties of the measured solutions.",
    "descriptor": "\nComments: 16 Pages\n",
    "authors": [
      "Jan-Nico Zaech",
      "Alexander Liniger",
      "Martin Danelljan",
      "Dengxin Dai",
      "Luc Van Gool"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.08837"
  },
  {
    "id": "arXiv:2105.13455",
    "title": "Perfect Matchings in the Semi-random Graph Process",
    "abstract": "The semi-random graph process is a single player game in which the player is\ninitially presented an empty graph on $n$ vertices. In each round, a vertex $u$\nis presented to the player independently and uniformly at random. The player\nthen adaptively selects a vertex $v$, and adds the edge $uv$ to the graph. For\na fixed monotone graph property, the objective of the player is to force the\ngraph to satisfy this property with high probability in as few rounds as\npossible.\nWe focus on the problem of constructing a perfect matching in as few rounds\nas possible. In particular, we present an adaptive strategy for the player\nwhich achieves a perfect matching in $\\beta n$ rounds, where the value of\n$\\beta < 1.206$ is derived from a solution to some system of differential\nequations. This improves upon the previously best known upper bound of\n$(1+2/e+o(1)) \\, n < 1.736 \\, n$ rounds. We also improve the previously best\nlower bound of $(\\ln 2 + o(1)) \\, n > 0.693 \\, n$ and show that the player\ncannot achieve the desired property in less than $\\alpha n$ rounds, where the\nvalue of $\\alpha > 0.932$ is derived from a solution to another system of\ndifferential equations. As a result, the gap between the upper and lower bounds\nis decreased roughly four times.",
    "descriptor": "",
    "authors": [
      "Pu Gao",
      "Calum MacRury",
      "Pawel Pralat"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2105.13455"
  },
  {
    "id": "arXiv:2202.08260",
    "title": "Low-Rank Phase Retrieval with Structured Tensor Models",
    "abstract": "We study the low-rank phase retrieval problem, where the objective is to\nrecover a sequence of signals (typically images) given the magnitude of linear\nmeasurements of those signals. Existing solutions involve recovering a matrix\nconstructed by vectorizing and stacking each image. These algorithms model this\nmatrix to be low-rank and leverage the low-rank property to decrease the sample\ncomplexity required for accurate recovery. However, when the number of\navailable measurements is more limited, these low-rank matrix models can often\nfail. We propose an algorithm called Tucker-Structured Phase Retrieval (TSPR)\nthat models the sequence of images as a tensor rather than a matrix that we\nfactorize using the Tucker decomposition. This factorization reduces the number\nof parameters that need to be estimated, allowing for a more accurate\nreconstruction in the under-sampled regime. Interestingly, we observe that this\nstructure also has improved performance in the over-determined setting when the\nTucker ranks are chosen appropriately. We demonstrate the effectiveness of our\napproach on real video datasets under several different measurement models.",
    "descriptor": "\nComments: A shorter version of this paper is in 2022 International Conference on Acoustics, Speech, and Signal Processing (ICASSP)\n",
    "authors": [
      "Soo Min Kwon",
      "Xin Li",
      "Anand D. Sarwate"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.08260"
  },
  {
    "id": "arXiv:2202.08262",
    "title": "Phase Aberration Robust Beamformer for Planewave US Using  Self-Supervised Learning",
    "abstract": "Ultrasound (US) is widely used for clinical imaging applications thanks to\nits real-time and non-invasive nature. However, its lesion detectability is\noften limited in many applications due to the phase aberration artefact caused\nby variations in the speed of sound (SoS) within body parts. To address this,\nhere we propose a novel self-supervised 3D CNN that enables phase aberration\nrobust plane-wave imaging. Instead of aiming at estimating the SoS distribution\nas in conventional methods, our approach is unique in that the network is\ntrained in a self-supervised manner to robustly generate a high-quality image\nfrom various phase aberrated images by modeling the variation in the speed of\nsound as stochastic. Experimental results using real measurements from\ntissue-mimicking phantom and \\textit{in vivo} scans confirmed that the proposed\nmethod can significantly reduce the phase aberration artifacts and improve the\nvisual quality of deep scans.",
    "descriptor": "\nComments: 10 pages, 12 figures, submitted to IEEE-TMI\n",
    "authors": [
      "Shujaat Khan",
      "Jaeyoung Huh",
      "Jong Chul Ye"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.08262"
  },
  {
    "id": "arXiv:2202.08303",
    "title": "OpenKBP-Opt: An international and reproducible evaluation of 76  knowledge-based planning pipelines",
    "abstract": "We establish an open framework for developing plan optimization models for\nknowledge-based planning (KBP) in radiotherapy. Our framework includes\nreference plans for 100 patients with head-and-neck cancer and high-quality\ndose predictions from 19 KBP models that were developed by different research\ngroups during the OpenKBP Grand Challenge. The dose predictions were input to\nfour optimization models to form 76 unique KBP pipelines that generated 7600\nplans. The predictions and plans were compared to the reference plans via: dose\nscore, which is the average mean absolute voxel-by-voxel difference in dose a\nmodel achieved; the deviation in dose-volume histogram (DVH) criterion; and the\nfrequency of clinical planning criteria satisfaction. We also performed a\ntheoretical investigation to justify our dose mimicking models. The range in\nrank order correlation of the dose score between predictions and their KBP\npipelines was 0.50 to 0.62, which indicates that the quality of the predictions\nis generally positively correlated with the quality of the plans. Additionally,\ncompared to the input predictions, the KBP-generated plans performed\nsignificantly better (P<0.05; one-sided Wilcoxon test) on 18 of 23 DVH\ncriteria. Similarly, each optimization model generated plans that satisfied a\nhigher percentage of criteria than the reference plans. Lastly, our theoretical\ninvestigation demonstrated that the dose mimicking models generated plans that\nare also optimal for a conventional planning model. This was the largest\ninternational effort to date for evaluating the combination of KBP prediction\nand optimization models. In the interest of reproducibility, our data and code\nis freely available at https://github.com/ababier/open-kbp-opt.",
    "descriptor": "\nComments: 19 pages, 7 tables, 6 figures\n",
    "authors": [
      "Aaron Babier",
      "Rafid Mahmood",
      "Binghao Zhang",
      "Victor G. L. Alves",
      "Ana Maria Barrag\u00e1n-Montero",
      "Joel Beaudry",
      "Carlos E. Cardenas",
      "Yankui Chang",
      "Zijie Chen",
      "Jaehee Chun",
      "Kelly Diaz",
      "Harold David Eraso",
      "Erik Faustmann",
      "Sibaji Gaj",
      "Skylar Gay",
      "Mary Gronberg",
      "Bingqi Guo",
      "Junjun He",
      "Gerd Heilemann",
      "Sanchit Hira",
      "Yuliang Huang",
      "Fuxin Ji",
      "Dashan Jiang",
      "Jean Carlo Jimenez Giraldo",
      "Hoyeon Lee",
      "Jun Lian",
      "Shuolin Liu",
      "Keng-Chi Liu",
      "Jos\u00e9 Marrugo",
      "Kentaro Miki",
      "Kunio Nakamura",
      "Tucker Netherton",
      "Dan Nguyen",
      "Hamidreza Nourzadeh",
      "Alexander F. I. Osman",
      "Zhao Peng",
      "Jos\u00e9 Dar\u00edo Quinto Mu\u00f1oz",
      "Christian Ramsl",
      "Dong Joo Rhee",
      "Juan David Rodriguez",
      "Hongming Shan",
      "Jeffrey V. Siebers",
      "Mumtaz H. Soomro",
      "Kay Sun",
      "Andr\u00e9s Usuga Hoyos",
      "Carlos Valderrama",
      "Rob Verbeek",
      "Enpei Wang",
      "Siri Willems"
    ],
    "subjectives": [
      "Medical Physics (physics.med-ph)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.08303"
  },
  {
    "id": "arXiv:2202.08329",
    "title": "CortexODE: Learning Cortical Surface Reconstruction by Neural ODEs",
    "abstract": "We present CortexODE, a deep learning framework for cortical surface\nreconstruction. CortexODE leverages neural ordinary different equations (ODEs)\nto deform an input surface into a target shape by learning a diffeomorphic\nflow. The trajectories of the points on the surface are modeled as ODEs, where\nthe derivatives of their coordinates are parameterized via a learnable\nLipschitz-continuous deformation network. This provides theoretical guarantees\nfor the prevention of self-intersections. CortexODE can be integrated to an\nautomatic learning-based pipeline, which reconstructs cortical surfaces\nefficiently in less than 6 seconds. The pipeline utilizes a 3D U-Net to predict\na white matter segmentation from brain Magnetic Resonance Imaging (MRI) scans,\nand further generates a signed distance function that represents an initial\nsurface. Fast topology correction is introduced to guarantee homeomorphism to a\nsphere. Following the isosurface extraction step, two CortexODE models are\ntrained to deform the initial surface to white matter and pial surfaces\nrespectively. The proposed pipeline is evaluated on large-scale neuroimage\ndatasets in various age groups including neonates (25-45 weeks), young adults\n(22-36 years) and elderly subjects (55-90 years). Our experiments demonstrate\nthat the CortexODE-based pipeline can achieve less than 0.2mm average geometric\nerror while being orders of magnitude faster compared to conventional\nprocessing pipelines.",
    "descriptor": "\nComments: Submitted to IEEE Transactions on Medical Imaging\n",
    "authors": [
      "Qiang Ma",
      "Liu Li",
      "Emma C. Robinson",
      "Bernhard Kainz",
      "Daniel Rueckert",
      "Amir Alansary"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.08329"
  },
  {
    "id": "arXiv:2202.08349",
    "title": "Approximating Output Probabilities of Shallow Quantum Circuits which are  Geometrically-local in any Fixed Dimension",
    "abstract": "We present a classical algorithm that, for any $D$-dimensional\ngeometrically-local, quantum circuit $C$ of polylogarithmic-depth, and any bit\nstring $x \\in {0,1}^n$, can compute the quantity $|<x|C|0^{\\otimes n}>|^2$ to\nwithin any inverse-polynomial additive error in quasi-polynomial time, for any\nfixed dimension $D$. This is an extension of the result [CC21], which\noriginally proved this result for $D = 3$. To see why this is interesting, note\nthat, while the $D = 1$ case of this result follows from standard use of Matrix\nProduct States, known for decades, the $D = 2$ case required novel and\ninteresting techniques introduced in [BGM19]. Extending to the case $D = 3$ was\neven more laborious and required further new techniques introduced in [CC21].\nOur work here shows that, while handling each new dimension has historically\nrequired a new insight, and fixed algorithmic primitive, based on known\ntechniques for $D \\leq 3$, we can now handle any fixed dimension $D > 3$.\nOur algorithm uses the Divide-and-Conquer framework of [CC21] to approximate\nthe desired quantity via several instantiations of the same problem type, each\ninvolving $D$-dimensional circuits on about half the number of qubits as the\noriginal. This division step is then applied recursively, until the width of\nthe recursively decomposed circuits in the $D^{th}$ dimension is so small that\nthey can effectively be regarded as $(D-1)$-dimensional problems by absorbing\nthe small width in the $D^{th}$ dimension into the qudit structure at the cost\nof a moderate increase in runtime. The main technical challenge lies in\nensuring that the more involved portions of the recursive circuit decomposition\nand error analysis from [CC21] still hold in higher dimensions, which requires\nsmall modifications to the analysis in some places.",
    "descriptor": "",
    "authors": [
      "Suchetan Dontha",
      "Shi Jie Samuel Tan",
      "Stephen Smith",
      "Sangheon Choi",
      "Matthew Coudron"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2202.08349"
  },
  {
    "id": "arXiv:2202.08351",
    "title": "Flat tori with large Laplacian eigenvalues in dimensions up to eight",
    "abstract": "We consider the optimization problem of maximizing the $k$-th Laplacian\neigenvalue, $\\lambda_{k}$, over flat $d$-dimensional tori of fixed volume. For\n$k=1$, this problem is equivalent to the densest lattice sphere packing\nproblem. For larger $k$, this is equivalent to the NP-hard problem of finding\nthe $d$-dimensional (dual) lattice with longest $k$-th shortest lattice vector.\nAs a result of extensive computations, for $d \\leq 8$, we obtain a sequence of\nflat tori, $T_{k,d}$, each of volume one, such that the $k$-th Laplacian\neigenvalue of $T_{k,d}$ is very large; for each (finite) $k$ the $k$-th\neigenvalue exceeds the value in (the $k\\to \\infty$ asymptotic) Weyl's law by a\nfactor between 1.54 and 2.01, depending on the dimension. Stationarity\nconditions are derived and numerically verified for $T_{k,d}$ and we describe\nthe degeneration of the tori as $k \\to \\infty$.",
    "descriptor": "\nComments: 18 pages, 3 figures\n",
    "authors": [
      "Chiu-Yen Kao",
      "Braxton Osting",
      "Jackson C. Turner"
    ],
    "subjectives": [
      "Spectral Theory (math.SP)",
      "Computational Geometry (cs.CG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2202.08351"
  },
  {
    "id": "arXiv:2202.08377",
    "title": "Generic nonadditivity of quantum capacity in simple channels",
    "abstract": "Determining capacities of quantum channels is a fundamental question in\nquantum information theory. Despite having rigorous coding theorems quantifying\nthe flow of information across quantum channels, their capacities are poorly\nunderstood due to super-additivity effects. Studying these phenomena is\nimportant for deepening our understanding of quantum information, yet simple\nand clean examples of super-additive channels are scarce. Here we study a\nsimple family of qutrit channels called the platypus channel, and show that it\nexhibits super-additivity of coherent information when used jointly with a\nvariety of qubit channels. A higher-dimensional variant of the platypus channel\ndisplays super-additivity of quantum capacity together with an erasure channel.\nSubject to the \"spin-alignment conjecture\" introduced in a companion paper, our\nresults on super-additivity of quantum capacity extend to lower-dimensional\nchannels as well as larger parameter ranges. In particular, super-additivity\noccurs between two weakly additive channels each with large capacity on their\nown, in stark contrast to previous results. Remarkably, a single, novel\ntransmission strategy achieves super-additivity in all examples. Our results\nshow that super-additivity is much more prevalent than previously thought. It\ncan occur across a wide variety of channels, even when both participating\nchannels have large quantum capacity.",
    "descriptor": "\nComments: 22 pages, 9 figures. See also the companion paper \"The platypus of the quantum channel zoo\"\n",
    "authors": [
      "Felix Leditzky",
      "Debbie Leung",
      "Vikesh Siddhu",
      "Graeme Smith",
      "John A. Smolin"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.08377"
  },
  {
    "id": "arXiv:2202.08380",
    "title": "The platypus of the quantum channel zoo",
    "abstract": "Understanding quantum channels and the strange behavior of their capacities\nis a key objective of quantum information theory. Here we study a remarkably\nsimple, low-dimensional, single-parameter family of quantum channels with\nexotic quantum information-theoretic features. As the simplest example from\nthis family, we focus on a qutrit-to-qutrit channel that is intuitively\nobtained by hybridizing together a simple degradable channel and a completely\nuseless qubit channel. Such hybridizing makes this channel's capacities behave\nin a variety of interesting ways. For instance, the private and classical\ncapacity of this channel coincide and can be explicitly calculated, even though\nthe channel does not belong to any class for which the underlying information\nquantities are known to be additive. Moreover, the quantum capacity of the\nchannel can be computed explicitly, given a clear and compelling conjecture is\ntrue. This \"spin alignment conjecture\", which may be of independent interest,\nis proved in certain special cases and additional numerical evidence for its\nvalidity is provided. Finally, we generalize the qutrit channel in two ways,\nand the resulting channels and their capacities display similarly rich\nbehavior. In a companion paper, we further show that the qutrit channel\ndemonstrates superadditivity when transmitting quantum information jointly with\na variety of assisting channels, in a manner unknown before.",
    "descriptor": "\nComments: 39 pages, 4 figures. See also the companion paper \"Generic nonadditivity of quantum capacity in simple channels\"\n",
    "authors": [
      "Felix Leditzky",
      "Debbie Leung",
      "Vikesh Siddhu",
      "Graeme Smith",
      "John A. Smolin"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.08380"
  },
  {
    "id": "arXiv:2202.08386",
    "title": "Laplacian operator on statistical manifold",
    "abstract": "In this paper, we define a Laplacian operator on a statistical manifold,\ncalled the vector Laplacian. This vector Laplacian incorporates information\nfrom the Amari-Chentsov tensor. We derive a formula for the vector Laplacian.\nWe also give two applications using the heat kernel associated with the vector\nLaplacian.",
    "descriptor": "",
    "authors": [
      "Ruichao Jiang",
      "Javad Tavakoli",
      "Yiqiang Zhao"
    ],
    "subjectives": [
      "Differential Geometry (math.DG)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.08386"
  },
  {
    "id": "arXiv:2202.08426",
    "title": "Synthetic Control As Online Linear Regression",
    "abstract": "This paper notes a simple connection between synthetic control and online\nlearning. Specifically, we recognize synthetic control as an instance of\nFollow-The-Leader (FTL). Standard results in online convex optimization then\nimply that, even when outcomes are chosen by an adversary, synthetic control\npredictions of counterfactual outcomes for the treated unit perform almost as\nwell as an oracle weighted average of control units' outcomes. Synthetic\ncontrol on differenced data performs almost as well as oracle weighted\ndifference-in-differences. We argue that this observation further supports the\nuse of synthetic control estimators in comparative case studies.",
    "descriptor": "",
    "authors": [
      "Jiafeng Chen"
    ],
    "subjectives": [
      "Econometrics (econ.EM)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2202.08426"
  },
  {
    "id": "arXiv:2202.08437",
    "title": "Visual attention analysis of pathologists examining whole slide images  of Prostate cancer",
    "abstract": "We study the attention of pathologists as they examine whole-slide images\n(WSIs) of prostate cancer tissue using a digital microscope. To the best of our\nknowledge, our study is the first to report in detail how pathologists navigate\nWSIs of prostate cancer as they accumulate information for their diagnoses. We\ncollected slide navigation data (i.e., viewport location, magnification level,\nand time) from 13 pathologists in 2 groups (5 genitourinary (GU) specialists\nand 8 general pathologists) and generated visual attention heatmaps and\nscanpaths. Each pathologist examined five WSIs from the TCGA PRAD dataset,\nwhich were selected by a GU pathology specialist. We examined and analyzed the\ndistributions of visual attention for each group of pathologists after each WSI\nwas examined. To quantify the relationship between a pathologist's attention\nand evidence for cancer in the WSI, we obtained tumor annotations from a\ngenitourinary specialist. We used these annotations to compute the overlap\nbetween the distribution of visual attention and annotated tumor region to\nidentify strong correlations. Motivated by this analysis, we trained a deep\nlearning model to predict visual attention on unseen WSIs. We find that the\nattention heatmaps predicted by our model correlate quite well with the ground\ntruth attention heatmap and tumor annotations on a test set of 17 WSIs by using\nvarious spatial and temporal evaluation metrics.",
    "descriptor": "\nComments: Accepted for oral presentation at ISBI 2022\n",
    "authors": [
      "Souradeep Chakraborty",
      "Ke Ma",
      "Rajarsi Gupta",
      "Beatrice Knudsen",
      "Gregory J. Zelinsky",
      "Joel H. Saltz",
      "Dimitris Samaras"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.08437"
  },
  {
    "id": "arXiv:2202.08447",
    "title": "RePair Grammars are the Smallest Grammars for Fibonacci Words",
    "abstract": "Grammar-based compression is a loss-less data compression scheme that\nrepresents a given string $w$ by a context-free grammar that generates only\n$w$. While computing the smallest grammar which generates a given string $w$ is\nNP-hard in general, a number of polynomial-time grammar-based compressors which\nwork well in practice have been proposed. RePair, proposed by Larsson and\nMoffat in 1999, is a grammar-based compressor which recursively replaces all\npossible occurrences of a most frequently occurring bigrams in the string.\nSince there can be multiple choices of the most frequent bigrams to replace,\ndifferent implementations of RePair can result in different grammars. In this\npaper, we show that the smallest grammars generating the Fibonacci words $F_k$\ncan be completely characterized by RePair, where $F_k$ denotes the $k$-th\nFibonacci word. Namely, all grammars for $F_k$ generated by any implementation\nof RePair are the smallest grammars for $F_k$, and no other grammars can be the\nsmallest for $F_k$. To the best of our knowledge, Fibonacci words are the first\nnon-trivial infinite family of strings for which RePair is optimal.",
    "descriptor": "",
    "authors": [
      "Takuya Mieno",
      "Shunsuke Inenaga",
      "Takashi Horiyama"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2202.08447"
  },
  {
    "id": "arXiv:2202.08456",
    "title": "MLP-ASR: Sequence-length agnostic all-MLP architectures for speech  recognition",
    "abstract": "We propose multi-layer perceptron (MLP)-based architectures suitable for\nvariable length input. MLP-based architectures, recently proposed for image\nclassification, can only be used for inputs of a fixed, pre-defined size.\nHowever, many types of data are naturally variable in length, for example,\nacoustic signals. We propose three approaches to extend MLP-based architectures\nfor use with sequences of arbitrary length. The first one uses a circular\nconvolution applied in the Fourier domain, the second applies a depthwise\nconvolution, and the final relies on a shift operation. We evaluate the\nproposed architectures on an automatic speech recognition task with the\nLibrispeech and Tedlium2 corpora. The best proposed MLP-based architectures\nimproves WER by 1.0 / 0.9%, 0.9 / 0.5% on Librispeech dev-clean/dev-other,\ntest-clean/test-other set, and 0.8 / 1.1% on Tedlium2 dev/test set using 86.4%\nthe size of self-attention-based architecture.",
    "descriptor": "\nComments: 8 pages, 4 figures\n",
    "authors": [
      "Jin Sakuma",
      "Tatsuya Komatsu",
      "Robin Scheibler"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2202.08456"
  },
  {
    "id": "arXiv:2202.08458",
    "title": "Wearable SELD dataset: Dataset for sound event localization and  detection using wearable devices around head",
    "abstract": "Sound event localization and detection (SELD) is a combined task of\nidentifying the sound event and its direction. Deep neural networks (DNNs) are\nutilized to associate them with the sound signals observed by a microphone\narray. Although ambisonic microphones are popular in the literature of SELD,\nthey might limit the range of applications due to their predetermined geometry.\nSome applications (including those for pedestrians that perform SELD while\nwalking) require a wearable microphone array whose geometry can be designed to\nsuit the task. In this paper, for the development of such a wearable SELD, we\npropose a dataset named Wearable SELD dataset. It consists of data recorded by\n24 microphones placed on a head and torso simulators (HATS) with some\naccessories mimicking wearable devices (glasses, earphones, and headphones). We\nalso provide experimental results of SELD using the proposed dataset and\nSELDNet to investigate the effect of microphone configuration.",
    "descriptor": "\nComments: 5 pages, 6 figures, accepted to IEEE Int. Conf. Acoust. Speech Signal Process. (ICASSP), 2022\n",
    "authors": [
      "Kento Nagatomo",
      "Masahiro Yasuda",
      "Kohei Yatabe",
      "Shoichiro Saito",
      "Yasuhiro Oikawa"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2202.08458"
  },
  {
    "id": "arXiv:2202.08470",
    "title": "Acoustic Event Detection with Classifier Chains",
    "abstract": "This paper proposes acoustic event detection (AED) with classifier chains, a\nnew classifier based on the probabilistic chain rule. The proposed AED with\nclassifier chains consists of a gated recurrent unit and performs iterative\nbinary detection of each event one by one. In each iteration, the event's\nactivity is estimated and used to condition the next output based on the\nprobabilistic chain rule to form classifier chains. Therefore, the proposed\nmethod can handle the interdependence among events upon classification, while\nthe conventional AED methods with multiple binary classifiers with a linear\nlayer and sigmoid function have placed an assumption of conditional\nindependence. In the experiments with a real-recording dataset, the proposed\nmethod demonstrates its superior AED performance to a relative 14.80%\nimprovement compared to a convolutional recurrent neural network baseline\nsystem with the multiple binary classifiers.",
    "descriptor": "\nComments: 5pages, presented at Interspeech2021\n",
    "authors": [
      "Tatsuya Komatsu",
      "Shinji Watanabe",
      "Koichi Miyazaki",
      "Tomoki Hayashi"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2202.08470"
  },
  {
    "id": "arXiv:2202.08474",
    "title": "Non-Autoregressive ASR with Self-Conditioned Folded Encoders",
    "abstract": "This paper proposes CTC-based non-autoregressive ASR with self-conditioned\nfolded encoders. The proposed method realizes non-autoregressive ASR with fewer\nparameters by folding the conventional stack of encoders into only two blocks;\nbase encoders and folded encoders. The base encoders convert the input audio\nfeatures into a neural representation suitable for recognition. This is\nfollowed by the folded encoders applied repeatedly for further refinement.\nApplying the CTC loss to the outputs of all encoders enforces the consistency\nof the input-output relationship. Thus, folded encoders learn to perform the\nsame operations as an encoder with deeper distinct layers. In experiments, we\ninvestigate how to set the number of layers and the number of iterations for\nthe base and folded encoders. The results show that the proposed method\nachieves a performance comparable to that of the conventional method using only\n38% as many parameters. Furthermore, it outperforms the conventional method\nwhen increasing the number of iterations.",
    "descriptor": "\nComments: 5 pages, accepted at ICASSP2022\n",
    "authors": [
      "Tatsuya Komatsu"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2202.08474"
  },
  {
    "id": "arXiv:2202.08489",
    "title": "A Faster Interior-Point Method for Sum-of-Squares Optimization",
    "abstract": "We present a faster interior-point method for optimizing sum-of-squares (SOS)\npolynomials, which are a central tool in polynomial optimization and capture\nconvex programming in the Lasserre hierarchy. Let $p = \\sum_i q^2_i$ be an\n$n$-variate SOS polynomial of degree $2d$. Denoting by $L := \\binom{n+d}{d}$\nand $U := \\binom{n+2d}{2d}$ the dimensions of the vector spaces in which\n$q_i$'s and $p$ live respectively, our algorithm runs in time\n$\\tilde{O}(LU^{1.87})$. This is polynomially faster than state-of-art SOS and\nsemidefinite programming solvers, which achieve runtime\n$\\tilde{O}(L^{0.5}\\min\\{U^{2.37}, L^{4.24}\\})$.\nThe centerpiece of our algorithm is a dynamic data structure for maintaining\nthe inverse of the Hessian of the SOS barrier function under the polynomial\ninterpolant basis, which efficiently extends to multivariate SOS optimization,\nand requires maintaining spectral approximations to low-rank perturbations of\nelementwise (Hadamard) products. This is the main challenge and departure from\nrecent IPM breakthroughs using inverse-maintenance, where low-rank updates to\nthe slack matrix readily imply the same for the Hessian matrix.",
    "descriptor": "",
    "authors": [
      "Shunhua Jiang",
      "Bento Natura",
      "Omri Weinstein"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2202.08489"
  },
  {
    "id": "arXiv:2202.08503",
    "title": "Early exclusion leads to cyclical cooperation in repeated group  interactions",
    "abstract": "Explaining the emergence and maintenance of cooperation among selfish\nindividuals from an evolutionary perspective remains a grand challenge in\nbiology, economy, and social sciences. Social exclusion is believed to be an\nanswer to this conundrum. However, previously related studies often assume\none-shot interactions and ignore how free-riding is identified, which seem to\nbe too idealistic. In this work, we consider repeated interactions where\nexcluders need to pay a monitoring cost to identify free-riders for exclusion\nand free-riders cannot participate in the following possible game interactions\nonce they are identified and excluded by excluders in the repeated interaction\nprocess. We reveal that the introduction of such exclusion can prevent the\nbreakdown of cooperation in repeated group interactions. In particular, we\ndemonstrate that an evolutionary oscillation among cooperators, defectors, and\nexcluders can appear in infinitely large populations when early exclusion is\nimplemented. In addition, we find that the population spends most of the time\nin states where cooperators dominate for early exclusion when stochastic\nmutation-selection is considered in finite populations. Our results highlight\nthat early exclusion is successful in solving the mentioned enigma of\ncooperation in repeated group interactions.",
    "descriptor": "\nComments: Accepted by Journal of the Royal Society Interface\n",
    "authors": [
      "Linjie Liu",
      "Zhilong Xiao",
      "Xiaojie Chen",
      "Attila Szolnoki"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2202.08503"
  },
  {
    "id": "arXiv:2202.08510",
    "title": "A hybrid 2-stage vision transformer for AI-assisted 5 class pathologic  diagnosis of gastric endoscopic biopsies",
    "abstract": "Gastric endoscopic screening is an effective way to decide appropriate\ngastric cancer (GC) treatment at an early stage, reducing GC-associated\nmortality rate. Although artificial intelligence (AI) has brought a great\npromise to assist pathologist to screen digitalized whole slide images,\nautomatic classification systems for guiding proper GC treatment based on\nclinical guideline are still lacking. Here, we propose an AI system classifying\n5 classes of GC histology, which can be perfectly matched to general treatment\nguidance. The AI system, mimicking the way pathologist understand slides\nthrough multi-scale self-attention mechanism using a 2-stage Vision\nTransformer, demonstrates clinical capability by achieving diagnostic\nsensitivity of above 85% for both internal and external cohort analysis.\nFurthermore, AI-assisted pathologists showed significantly improved diagnostic\nsensitivity by 10% within 18% saved screening time compared to human\npathologists. Our AI system has a great potential for providing presumptive\npathologic opinion for deciding proper treatment for early GC patients.",
    "descriptor": "",
    "authors": [
      "Yujin Oh",
      "Go Eun Bae",
      "Kyung-Hee Kim",
      "Min-Kyung Yeo",
      "Jong Chul Ye"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.08510"
  },
  {
    "id": "arXiv:2202.08520",
    "title": "End-to-end Music Remastering System Using Self-supervised and  Adversarial Training",
    "abstract": "Mastering is an essential step in music production, but it is also a\nchallenging task that has to go through the hands of experienced audio\nengineers, where they adjust tone, space, and volume of a song. Remastering\nfollows the same technical process, in which the context lies in mastering a\nsong for the times. As these tasks have high entry barriers, we aim to lower\nthe barriers by proposing an end-to-end music remastering system that\ntransforms the mastering style of input audio to that of the target. The system\nis trained in a self-supervised manner, in which released pop songs were used\nfor training. We also anticipated the model to generate realistic audio\nreflecting the reference's mastering style by applying a pre-trained encoder\nand a projection discriminator. We validate our results with quantitative\nmetrics and a subjective listening test and show that the model generated\nsamples of mastering style similar to the target.",
    "descriptor": "\nComments: IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) 2022\n",
    "authors": [
      "Junghyun Koo",
      "Seungryeol Paik",
      "Kyogu Lee"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2202.08520"
  },
  {
    "id": "arXiv:2202.08532",
    "title": "Mitigating Closed-model Adversarial Examples with Bayesian Neural  Modeling for Enhanced End-to-End Speech Recognition",
    "abstract": "In this work, we aim to enhance the system robustness of end-to-end automatic\nspeech recognition (ASR) against adversarially-noisy speech examples. We focus\non a rigorous and empirical \"closed-model adversarial robustness\" setting\n(e.g., on-device or cloud applications). The adversarial noise is only\ngenerated by closed-model optimization (e.g., evolutionary and zeroth-order\nestimation) without accessing gradient information of a targeted ASR model\ndirectly. We propose an advanced Bayesian neural network (BNN) based\nadversarial detector, which could model latent distributions against adaptive\nadversarial perturbation with divergence measurement. We further simulate\ndeployment scenarios of RNN Transducer, Conformer, and wav2vec-2.0 based ASR\nsystems with the proposed adversarial detection system. Leveraging the proposed\nBNN based detection system, we improve detection rate by +2.77 to +5.42%\n(relative +3.03 to +6.26%) and reduce the word error rate by 5.02 to 7.47% on\nLibriSpeech datasets compared to the current model enhancement methods against\nthe adversarial speech examples.",
    "descriptor": "\nComments: Accepted to ICASSP 2022\n",
    "authors": [
      "Chao-Han Huck Yang",
      "Zeeshan Ahmed",
      "Yile Gu",
      "Joseph Szurley",
      "Roger Ren",
      "Linda Liu",
      "Andreas Stolcke",
      "Ivan Bulyko"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2202.08532"
  },
  {
    "id": "arXiv:2202.08546",
    "title": "An overview of deep learning in medical imaging",
    "abstract": "Machine learning (ML) has seen enormous consideration during the most recent\ndecade. This success started in 2012 when an ML model accomplished a remarkable\ntriumph in the ImageNet Classification, the world's most famous competition for\ncomputer vision. This model was a kind of convolutional neural system (CNN)\ncalled deep learning (DL). Since then, researchers have started to participate\nefficiently in DL's fastest developing area of research. These days, DL systems\nare cutting-edge ML systems spanning a broad range of disciplines, from human\nlanguage processing to video analysis, and commonly used in the scholarly world\nand enterprise sector. Recent advances can bring tremendous improvement to the\nmedical field. Improved and innovative methods for data processing, image\nanalysis and can significantly improve the diagnostic technologies and\nmedicinal services gradually. A quick review of current developments with\nrelevant problems in the field of DL used for medical imaging has been\nprovided. The primary purposes of the review are four: (i) provide a brief\nprolog to DL by discussing different DL models, (ii) review of the DL usage for\nmedical image analysis (classification, detection, segmentation, and\nregistration), (iii) review seven main application fields of DL in medical\nimaging, (iv) give an initial stage to those keen on adding to the research\narea about DL in clinical imaging by providing links of some useful informative\nassets, such as freely available DL codes, public datasets Table 7, and medical\nimaging competition sources Table 8 and end our survey by outlining distinct\ncontinuous difficulties, lessons learned and future of DL in the field of\nmedical science.",
    "descriptor": "\nComments: 27pages, 3 figures, 9 tables\n",
    "authors": [
      "Imran Ul Haq"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.08546"
  },
  {
    "id": "arXiv:2202.08552",
    "title": "EBHI:A New Enteroscope Biopsy Histopathological H&E Image Dataset for  Image Classification Evaluation",
    "abstract": "Background and purpose: Colorectal cancer has become the third most common\ncancer worldwide, accounting for approximately 10% of cancer patients. Early\ndetection of the disease is important for the treatment of colorectal cancer\npatients. Histopathological examination is the gold standard for screening\ncolorectal cancer. However, the current lack of histopathological image\ndatasets of colorectal cancer, especially enteroscope biopsies, hinders the\naccurate evaluation of computer-aided diagnosis techniques. Methods: A new\npublicly available Enteroscope Biopsy Histopathological H&E Image Dataset\n(EBHI) is published in this paper. To demonstrate the effectiveness of the EBHI\ndataset, we have utilized several machine learning, convolutional neural\nnetworks and novel transformer-based classifiers for experimentation and\nevaluation, using an image with a magnification of 200x. Results: Experimental\nresults show that the deep learning method performs well on the EBHI dataset.\nTraditional machine learning methods achieve maximum accuracy of 76.02% and\ndeep learning method achieves a maximum accuracy of 95.37%. Conclusion: To the\nbest of our knowledge, EBHI is the first publicly available colorectal\nhistopathology enteroscope biopsy dataset with four magnifications and five\ntypes of images of tumor differentiation stages, totaling 5532 images. We\nbelieve that EBHI could attract researchers to explore new classification\nalgorithms for the automated diagnosis of colorectal cancer, which could help\nphysicians and patients in clinical settings.",
    "descriptor": "",
    "authors": [
      "Weiming Hu",
      "Chen Li",
      "Xiaoyan Li",
      "Md Mamunur Rahaman",
      "Yong Zhang",
      "Haoyuan Chen",
      "Wanli Liu",
      "Yudong Yao",
      "Hongzan Sun",
      "Ning Xu",
      "Xinyu Huang",
      "Marcin Grzegorze"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.08552"
  },
  {
    "id": "arXiv:2202.08567",
    "title": "Robust SVM Optimization in Banach spaces",
    "abstract": "We address the issue of binary classification in Banach spaces in presence of\nuncertainty. We show that a number of results from classical support vector\nmachines theory can be appropriately generalised to their robust counterpart in\nBanach spaces. These include the Representer Theorem, strong duality for the\nassociated Optimization problem as well as their geometric interpretation.\nFurthermore, we propose a game theoretic interpretation by expressing a Nash\nequilibrium problem formulation for the more general problem of finding the\nclosest points in two closed convex sets when the underlying space is reflexive\nand smooth.",
    "descriptor": "\nComments: 20 pages\n",
    "authors": [
      "Mohammed Sbihi",
      "Nicolas Couellan"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2202.08567"
  },
  {
    "id": "arXiv:2202.08574",
    "title": "Using Edge Contractions and Vertex Deletions to Reduce the Independence  Number and the Clique Number",
    "abstract": "We consider the following problem: for a given graph G and two integers k and\nd, can we apply a fixed graph operation at most k times in order to reduce a\ngiven graph parameter $\\pi$ by at least d? We show that this problem is NP-hard\nwhen the parameter is the independence number and the graph operation is vertex\ndeletion or edge contraction, even for fixed d=1 and when restricted to chordal\ngraphs. We also give a polynomial time algorithm for bipartite graphs when the\noperation is edge contraction, the parameter is the independence number and d\nis fixed. Further, we complete the complexity dichotomy on H-free graphs when\nthe parameter is the clique number and the operation is edge contraction by\nshowing that this problem is NP-hard in ($C_3+P_1$)-free graphs even for fixed\nd=1. Our results answer several open questions stated in [Diner et al.,\nTheoretical Computer Science, 746, p. 49-72 (2012)].",
    "descriptor": "\nComments: 13 pages, 2 figures\n",
    "authors": [
      "Felicia Lucke",
      "Felix Mann"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2202.08574"
  },
  {
    "id": "arXiv:2202.08580",
    "title": "Anatomically Parameterized Statistical Shape Model: Explaining  Morphometry through Statistical Learning",
    "abstract": "Statistical shape models (SSMs) are a popular tool to conduct morphological\nanalysis of anatomical structures which is a crucial step in clinical\npractices. However, shape representations through SSMs are based on shape\ncoefficients and lack an explicit one-to-one relationship with anatomical\nmeasures of clinical relevance. While a shape coefficient embeds a combination\nof anatomical measures, a formalized approach to find the relationship between\nthem remains elusive in the literature. This limits the use of SSMs to\nsubjective evaluations in clinical practices. We propose a novel SSM controlled\nby anatomical parameters derived from morphometric analysis. The proposed\nanatomically parameterized SSM (ANAT-SSM) is based on learning a linear mapping\nbetween shape coefficients and selected anatomical parameters. This mapping is\nlearned from a synthetic population generated by the standard SSM. Determining\nthe pseudo-inverse of the mapping allows us to build the ANAT-SSM. We further\nimpose orthogonality constraints to the anatomical parameterization to obtain\nindependent shape variation patterns. The proposed contribution was evaluated\non two skeletal databases of femoral and scapular bone shapes using clinically\nrelevant anatomical parameters. Anatomical measures of the synthetically\ngenerated shapes exhibited realistic statistics. The learned matrices\ncorroborated well with the obtained statistical relationship, while the two\nSSMs achieved moderate to excellent performance in predicting anatomical\nparameters on unseen shapes. This study demonstrates the use of anatomical\nrepresentation for creating anatomically parameterized SSM and as a result,\nremoves the limited clinical interpretability of standard SSMs. The proposed\nmodels could help analyze differences in relevant bone morphometry between\npopulations, and be integrated in patient-specific pre-surgery planning or\nin-surgery assessment.",
    "descriptor": "\nComments: 12 pages, 5 figures, 3 tables, Accepted for publication at IEEE Transactions on Biomedical Engineering\n",
    "authors": [
      "Arnaud Boutillon",
      "Asma Salhi",
      "Val\u00e9rie Burdin",
      "Bhushan Borotikar"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.08580"
  },
  {
    "id": "arXiv:2202.08599",
    "title": "Error Correction for Reliable Quantum Computing",
    "abstract": "Quantum computers herald the arrival of a new era in which previously\nintractable computational problems will be solved efficiently. However, quantum\ntechnology is held down by decoherence, a phenomenon that is omnipresent in the\nquantum paradigm and that renders quantum information useless when left\nunchecked. The science of quantum error correction, a discipline that seeks to\ncombine and protect quantum information from the effects of decoherence using\nstructures known as codes, has arisen to meet this challenge. Stabilizer codes,\na particular subclass of quantum codes, have enabled fast progress in the field\nof quantum error correction by allowing parallels to be drawn with the widely\nstudied field of classical error correction. This has resulted in the\nconstruction of the quantum counterparts of well-known capacity-approaching\nclassical codes like sparse codes and quantum turbo codes. However, quantum\ncodes obtained in this manner do not entirely evoke the stupendous error\ncorrecting abilities of their classical counterparts. This occurs because\nclassical strategies ignore important differences between the quantum and\nclassical paradigms, an issue that needs to be addressed if quantum error\ncorrection is to succeed in its battle with decoherence. In this dissertation\nwe study a phenomenon exclusive to the quantum paradigm, known as degeneracy,\nand its effects on the performance of sparse quantum codes. Furthermore, we\nalso analyze and present methods to improve the performance of a specific\nfamily of sparse quantum codes in various different scenarios.",
    "descriptor": "\nComments: PhD Dissertation. Defended on February 14 2022\n",
    "authors": [
      "Patricio Fuentes"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.08599"
  },
  {
    "id": "arXiv:2202.08680",
    "title": "Synthetic data for unsupervised polyp segmentation",
    "abstract": "Deep learning has shown excellent performance in analysing medical images.\nHowever, datasets are difficult to obtain due privacy issues, standardization\nproblems, and lack of annotations. We address these problems by producing\nrealistic synthetic images using a combination of 3D technologies and\ngenerative adversarial networks. We use zero annotations from medical\nprofessionals in our pipeline. Our fully unsupervised method achieves promising\nresults on five real polyp segmentation datasets. As a part of this study we\nrelease Synth-Colon, an entirely synthetic dataset that includes 20000\nrealistic colon images and additional details about depth and 3D geometry:\nhttps://enric1994.github.io/synth-colon",
    "descriptor": "",
    "authors": [
      "Enric Moreu",
      "Kevin McGuinness",
      "Noel E. O'Connor"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.08680"
  },
  {
    "id": "arXiv:2202.08682",
    "title": "End-to-end Neuron Instance Segmentation based on Weakly Supervised  Efficient UNet and Morphological Post-processing",
    "abstract": "Recent studies have demonstrated the superiority of deep learning in medical\nimage analysis, especially in cell instance segmentation, a fundamental step\nfor many biological studies. However, the good performance of the neural\nnetworks requires training on large unbiased dataset and annotations, which is\nlabor-intensive and expertise-demanding. In this paper, we present an\nend-to-end weakly-supervised framework to automatically detect and segment NeuN\nstained neuronal cells on histological images using only point annotations. We\nintegrate the state-of-the-art network, EfficientNet, into our U-Net-like\narchitecture. Validation results show the superiority of our model compared to\nother recent methods. In addition, we investigated multiple post-processing\nschemes and proposed an original strategy to convert the probability map into\nsegmented instances using ultimate erosion and dynamic reconstruction. This\napproach is easy to configure and outperforms other classical post-processing\ntechniques.",
    "descriptor": "",
    "authors": [
      "Huaqian Wu",
      "Nicolas Souedet",
      "Caroline Jan",
      "C\u00e9dric Clouchoux",
      "Thierry Delzescaux"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.08682"
  },
  {
    "id": "arXiv:2202.08702",
    "title": "A Two-stage U-Net for high-fidelity denoising of historical recordings",
    "abstract": "Enhancing the sound quality of historical music recordings is a long-standing\nproblem. This paper presents a novel denoising method based on a\nfully-convolutional deep neural network. A two-stage U-Net model architecture\nis designed to model and suppress the degradations with high fidelity. The\nmethod processes the time-frequency representation of audio, and is trained\nusing realistic noisy data to jointly remove hiss, clicks, thumps, and other\ncommon additive disturbances from old analog discs. The proposed model\noutperforms previous methods in both objective and subjective metrics. The\nresults of a formal blind listening test show that real gramophone recordings\ndenoised with this method have significantly better quality than the baseline\nmethods. This study shows the importance of realistic training data and the\npower of deep learning in audio restoration.",
    "descriptor": "\nComments: Accepted at ICASSP 2022\n",
    "authors": [
      "Eloi Moliner",
      "Vesa V\u00e4lim\u00e4ki"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2202.08702"
  },
  {
    "id": "arXiv:2202.08708",
    "title": "Learning stochastic dynamics and predicting emergent behavior using  transformers",
    "abstract": "We show that a neural network originally designed for language processing can\nlearn the dynamical rules of a stochastic system by observation of a single\ndynamical trajectory of the system, and can accurately predict its emergent\nbehavior under conditions not observed during training. We consider a lattice\nmodel of active matter undergoing continuous-time Monte Carlo dynamics,\nsimulated at a density at which its steady state comprises small, dispersed\nclusters. We train a neural network called a transformer on a single trajectory\nof the model. The transformer, which we show has the capacity to represent\ndynamical rules that are numerous and nonlocal, learns that the dynamics of\nthis model consists of a small number of processes. Forward-propagated\ntrajectories of the trained transformer, at densities not encountered during\ntraining, exhibit motility-induced phase separation and so predict the\nexistence of a nonequilibrium phase transition. Transformers have the\nflexibility to learn dynamical rules from observation without explicit\nenumeration of rates or coarse-graining of configuration space, and so the\nprocedure used here can be applied to a wide range of physical systems,\nincluding those with large and complex dynamical generators.",
    "descriptor": "",
    "authors": [
      "Corneel Casert",
      "Isaac Tamblyn",
      "Stephen Whitelam"
    ],
    "subjectives": [
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Soft Condensed Matter (cond-mat.soft)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.08708"
  },
  {
    "id": "arXiv:2202.08728",
    "title": "Locally private nonparametric confidence intervals and sequences",
    "abstract": "This work derives methods for performing nonparametric, nonasymptotic\nstatistical inference for population parameters under the constraint of local\ndifferential privacy (LDP). Given observations $(X_1, \\dots, X_n)$ with mean\n$\\mu^\\star$ that are privatized into $(Z_1, \\dots, Z_n)$, we introduce\nconfidence intervals (CI) and time-uniform confidence sequences (CS) for\n$\\mu^\\star \\in \\mathbb R$ when only given access to the privatized data. We\nintroduce a nonparametric and sequentially interactive generalization of\nWarner's famous \"randomized response\" mechanism, satisfying LDP for arbitrary\nbounded random variables, and then provide CIs and CSs for their means given\naccess to the resulting privatized observations. We extend these CSs to capture\ntime-varying (non-stationary) means, and conclude by illustrating how these\nmethods can be used to conduct private online A/B tests.",
    "descriptor": "",
    "authors": [
      "Ian Waudby-Smith",
      "Zhiwei Steven Wu",
      "Aaditya Ramdas"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Cryptography and Security (cs.CR)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.08728"
  },
  {
    "id": "arXiv:2202.08753",
    "title": "Strong spatial mixing for repulsive point processes",
    "abstract": "We prove that a Gibbs point process interacting via a finite-range, repulsive\npotential $\\phi$ exhibits a strong spatial mixing property for activities\n$\\lambda < e/\\Delta_{\\phi}$, where $\\Delta_{\\phi}$ is the potential-weighted\nconnective constant of $\\phi$, defined recently in [MP21]. Using this we derive\nseveral analytic and algorithmic consequences when $\\lambda$ satisfies this\nbound: (1) We prove new identities for the infinite volume pressure and surface\npressure of such a process (and in the case of the surface pressure establish\nits existence). (2) We prove that local block dynamics for sampling from the\nmodel on a box of volume $N$ in $\\mathbb R^d$ mixes in time $O(N \\log N)$,\ngiving efficient randomized algorithms to approximate the partition function of\nand approximately sample from these models. (3) We use the above identities and\nalgorithms to give efficient approximation algorithms for the pressure and\nsurface pressure.",
    "descriptor": "",
    "authors": [
      "Marcus Michelen",
      "Will Perkins"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Data Structures and Algorithms (cs.DS)",
      "Mathematical Physics (math-ph)"
    ],
    "url": "https://arxiv.org/abs/2202.08753"
  },
  {
    "id": "arXiv:2202.08757",
    "title": "Physical Layer Authentication for LEO Satellite Constellations",
    "abstract": "Physical layer authentication (PLA) is the process of claiming identity of a\nnode based on its physical layer characteristics such as channel fading or\nhardware imperfections. In this work, we propose a novel PLA method for the\ninter-satellite communication links (ISLs) of the LEO satellites. In the\nproposed PLA method, multiple receiving satellites validate the identity of the\ntransmitter by comparing the Doppler frequency measurements with the reference\nmobility information of the legitimate transmitter and then fuse their decision\nconsidering the selected decision rule. Analytical expressions are obtained for\nthe spoofing detection probability and false alarm probability of the fusion\nmethods. Numerically obtained high authentication performance results pave the\nway to a novel and easily integrable authentication mechanism for the LEO\nsatellite networks.",
    "descriptor": "",
    "authors": [
      "Ozan Alp Topal",
      "Gunes Karabulut Kurt"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.08757"
  },
  {
    "id": "arXiv:2202.08789",
    "title": "Hamilton-Jacobi equations on graphs with applications to semi-supervised  learning and data depth",
    "abstract": "Shortest path graph distances are widely used in data science and machine\nlearning, since they can approximate the underlying geodesic distance on the\ndata manifold. However, the shortest path distance is highly sensitive to the\naddition of corrupted edges in the graph, either through noise or an\nadversarial perturbation. In this paper we study a family of Hamilton-Jacobi\nequations on graphs that we call the $p$-eikonal equation. We show that the\n$p$-eikonal equation with $p=1$ is a provably robust distance-type function on\na graph, and the $p\\to \\infty$ limit recovers shortest path distances. While\nthe $p$-eikonal equation does not correspond to a shortest-path graph distance,\nwe nonetheless show that the continuum limit of the $p$-eikonal equation on a\nrandom geometric graph recovers a geodesic density weighted distance in the\ncontinuum. We consider applications of the $p$-eikonal equation to data depth\nand semi-supervised learning, and use the continuum limit to prove asymptotic\nconsistency results for both applications. Finally, we show the results of\nexperiments with data depth and semi-supervised learning on real image\ndatasets, including MNIST, FashionMNIST and CIFAR-10, which show that the\n$p$-eikonal equation offers significantly better results compared to shortest\npath distances.",
    "descriptor": "",
    "authors": [
      "Jeff Calder",
      "Mahmood Ettehad"
    ],
    "subjectives": [
      "Analysis of PDEs (math.AP)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.08789"
  },
  {
    "id": "arXiv:2202.08793",
    "title": "Multi-Channel Speech Denoising for Machine Ears",
    "abstract": "This work describes a speech denoising system for machine ears that aims to\nimprove speech intelligibility and the overall listening experience in noisy\nenvironments. We recorded approximately 100 hours of audio data with\nreverberation and moderate environmental noise using a pair of microphone\narrays placed around each of the two ears and then mixed sound recordings to\nsimulate adverse acoustic scenes. Then, we trained a multi-channel speech\ndenoising network (MCSDN) on the mixture of recordings. To improve the\ntraining, we employ an unsupervised method, complex angular central Gaussian\nmixture model (cACGMM), to acquire cleaner speech from noisy recordings to\nserve as the learning target. We propose a MCSDN-Beamforming-MCSDN framework in\nthe inference stage. The results of the subjective evaluation show that the\ncACGMM improves the training data, resulting in better noise reduction and user\npreference, and the entire system improves the intelligibility and listening\nexperience in noisy situations.",
    "descriptor": "\nComments: Accepted to ICASSP 2022\n",
    "authors": [
      "Cong Han",
      "E. Merve Kaya",
      "Kyle Hoefer",
      "Malcolm Slaney",
      "Simon Carlile"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.08793"
  },
  {
    "id": "arXiv:2202.08832",
    "title": "Universality of empirical risk minimization",
    "abstract": "Consider supervised learning from i.i.d. samples $\\{{\\boldsymbol\nx}_i,y_i\\}_{i\\le n}$ where ${\\boldsymbol x}_i \\in\\mathbb{R}^p$ are feature\nvectors and ${y} \\in \\mathbb{R}$ are labels. We study empirical risk\nminimization over a class of functions that are parameterized by $\\mathsf{k} =\nO(1)$ vectors ${\\boldsymbol \\theta}_1, . . . , {\\boldsymbol \\theta}_{\\mathsf k}\n\\in \\mathbb{R}^p$ , and prove universality results both for the training and\ntest error. Namely, under the proportional asymptotics $n,p\\to\\infty$, with\n$n/p = \\Theta(1)$, we prove that the training error depends on the random\nfeatures distribution only through its covariance structure. Further, we prove\nthat the minimum test error over near-empirical risk minimizers enjoys similar\nuniversality properties. In particular, the asymptotics of these quantities can\nbe computed $-$to leading order$-$ under a simpler model in which the feature\nvectors ${\\boldsymbol x}_i$ are replaced by Gaussian vectors ${\\boldsymbol\ng}_i$ with the same covariance. Earlier universality results were limited to\nstrongly convex learning procedures, or to feature vectors ${\\boldsymbol x}_i$\nwith independent entries. Our results do not make any of these assumptions. Our\nassumptions are general enough to include feature vectors ${\\boldsymbol x}_i$\nthat are produced by randomized featurization maps. In particular we explicitly\ncheck the assumptions for certain random features models (computing the output\nof a one-layer neural network with random weights) and neural tangent models\n(first-order Taylor approximation of two-layer networks).",
    "descriptor": "\nComments: 55 pages\n",
    "authors": [
      "Andrea Montanari",
      "Basil Saeed"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.08832"
  },
  {
    "id": "arXiv:2202.08834",
    "title": "Plasticity and evolvability under environmental variability: the joint  role of fitness-based selection and niche-limited competition",
    "abstract": "The diversity and quality of natural systems has been a puzzle and\ninspiration for communities studying artificial life. It is now widely admitted\nthat the adaptation mechanisms enabling these properties are largely influenced\nby the environments they inhabit. Organisms facing environmental variability\nhave two alternative adaptation mechanisms operating at different timescales:\n\\textit{plasticity}, the ability of a phenotype to survive in diverse\nenvironments and \\textit{evolvability}, the ability to adapt through mutations.\nAlthough vital under environmental variability, both mechanisms are associated\nwith fitness costs hypothesized to render them unnecessary in stable\nenvironments. In this work, we study the interplay between environmental\ndynamics and adaptation in a minimal model of the evolution of plasticity and\nevolvability. We experiment with different types of environments characterized\nby the presence of niches and a climate function that determines the fitness\nlandscape. We empirically show that environmental dynamics affect plasticity\nand evolvability differently and that the presence of diverse ecological niches\nfavors adaptability even in stable environments. We perform ablation studies of\nthe selection mechanisms to separate the role of fitness-based selection and\nniche-limited competition. Results obtained from our minimal model allow us to\npropose promising research directions in the study of open-endedness in\nbiological and artificial systems.",
    "descriptor": "",
    "authors": [
      "Eleni Nisioti",
      "Cl\u00e9ment Moulin-Frier"
    ],
    "subjectives": [
      "Populations and Evolution (q-bio.PE)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2202.08834"
  },
  {
    "id": "arXiv:1903.03309",
    "title": "Price of Anarchy in Bernoulli Congestion Games with Affine Costs",
    "abstract": "Comments: 29 pages, 6 figures",
    "descriptor": "\nComments: 29 pages, 6 figures\n",
    "authors": [
      "Roberto Cominetti",
      "Marco Scarsini",
      "Marc Schr\u00f6der",
      "Nicol\u00e1s Stier-Moses"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/1903.03309"
  },
  {
    "id": "arXiv:1905.02004",
    "title": "Ideal Tightly Couple (t,m,n) Secret Sharing",
    "abstract": "Comments: few errors in the articles within the proposed scheme, and also grammatical errors, so its our request pls withdraw our articles as soon as possible",
    "descriptor": "\nComments: few errors in the articles within the proposed scheme, and also grammatical errors, so its our request pls withdraw our articles as soon as possible\n",
    "authors": [
      "Fuyou Miao",
      "Keju Meng",
      "Wenchao Huang",
      "Yan Xiong",
      "Xingfu Wang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/1905.02004"
  },
  {
    "id": "arXiv:1905.12155",
    "title": "The Supermarket Model with Known and Predicted Service Times",
    "abstract": "Comments: Revision, 16 pages, 22 figures. Published at IEEE TPDS",
    "descriptor": "\nComments: Revision, 16 pages, 22 figures. Published at IEEE TPDS\n",
    "authors": [
      "Michael Mitzenmacher",
      "Matteo Dell'Amico"
    ],
    "subjectives": [
      "Performance (cs.PF)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/1905.12155"
  },
  {
    "id": "arXiv:1907.09470",
    "title": "Characterizing Attacks on Deep Reinforcement Learning",
    "abstract": "Comments: AAMAS 2022, 13 pages, 6 figures",
    "descriptor": "\nComments: AAMAS 2022, 13 pages, 6 figures\n",
    "authors": [
      "Xinlei Pan",
      "Chaowei Xiao",
      "Warren He",
      "Shuang Yang",
      "Jian Peng",
      "Mingjie Sun",
      "Jinfeng Yi",
      "Zijiang Yang",
      "Mingyan Liu",
      "Bo Li",
      "Dawn Song"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1907.09470"
  },
  {
    "id": "arXiv:1908.07565",
    "title": "Finding the right scale of a network: Efficient identification of causal  emergence through spectral clustering",
    "abstract": "Finding the right scale of a network: Efficient identification of causal  emergence through spectral clustering",
    "descriptor": "",
    "authors": [
      "Ross Griebenow",
      "Brennan Klein",
      "Erik Hoel"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/1908.07565"
  },
  {
    "id": "arXiv:1908.11568",
    "title": "Pacer: Comprehensive Network Side-Channel Mitigation in the Cloud",
    "abstract": "Pacer: Comprehensive Network Side-Channel Mitigation in the Cloud",
    "descriptor": "",
    "authors": [
      "Aastha Mehta",
      "Mohamed Alzayat",
      "Roberta de Viti",
      "Bj\u00f6rn B. Brandenburg",
      "Peter Druschel",
      "Deepak Garg"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/1908.11568"
  },
  {
    "id": "arXiv:1909.01127",
    "title": "MRI Reconstruction Using Deep Bayesian Estimation",
    "abstract": "MRI Reconstruction Using Deep Bayesian Estimation",
    "descriptor": "",
    "authors": [
      "GuanXiong Luo",
      "Na Zhao",
      "Wenhao Jiang",
      "Edward S. Hui",
      "Peng Cao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/1909.01127"
  },
  {
    "id": "arXiv:1909.11957",
    "title": "Drawing Early-Bird Tickets: Towards More Efficient Training of Deep  Networks",
    "abstract": "Comments: Accepted as ICLR2020 Spotlight",
    "descriptor": "\nComments: Accepted as ICLR2020 Spotlight\n",
    "authors": [
      "Haoran You",
      "Chaojian Li",
      "Pengfei Xu",
      "Yonggan Fu",
      "Yue Wang",
      "Xiaohan Chen",
      "Richard G. Baraniuk",
      "Zhangyang Wang",
      "Yingyan Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1909.11957"
  },
  {
    "id": "arXiv:1911.03314",
    "title": "FANN-on-MCU: An Open-Source Toolkit for Energy-Efficient Neural Network  Inference at the Edge of the Internet of Things",
    "abstract": "FANN-on-MCU: An Open-Source Toolkit for Energy-Efficient Neural Network  Inference at the Edge of the Internet of Things",
    "descriptor": "",
    "authors": [
      "Xiaying Wang",
      "Michele Magno",
      "Lukas Cavigelli",
      "Luca Benini"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1911.03314"
  },
  {
    "id": "arXiv:2002.03781",
    "title": "Deep Feature Fusion for Mitosis Counting",
    "abstract": "Deep Feature Fusion for Mitosis Counting",
    "descriptor": "",
    "authors": [
      "Robin Elizabeth Yancey"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2002.03781"
  },
  {
    "id": "arXiv:2002.07611",
    "title": "An Algorithmic Study of Fully Dynamic Independent Sets for Map Labeling",
    "abstract": "Comments: The full version of a paper appearing at ESA 2020, accepted by the ACM Journal of Experimental Algorithmics (JEA)",
    "descriptor": "\nComments: The full version of a paper appearing at ESA 2020, accepted by the ACM Journal of Experimental Algorithmics (JEA)\n",
    "authors": [
      "Sujoy Bhore",
      "Guangping Li",
      "Martin N\u00f6llenburg"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2002.07611"
  },
  {
    "id": "arXiv:2003.05438",
    "title": "Un-Mix: Rethinking Image Mixtures for Unsupervised Visual Representation  Learning",
    "abstract": "Comments: AAAI 2022 camera ready version with Appendix (add a formula example with InfoNCE). Code is available at: this https URL",
    "descriptor": "\nComments: AAAI 2022 camera ready version with Appendix (add a formula example with InfoNCE). Code is available at: this https URL\n",
    "authors": [
      "Zhiqiang Shen",
      "Zechun Liu",
      "Zhuang Liu",
      "Marios Savvides",
      "Trevor Darrell",
      "Eric Xing"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2003.05438"
  },
  {
    "id": "arXiv:2004.12088",
    "title": "SplitFed: When Federated Learning Meets Split Learning",
    "abstract": "Comments: Accepted at AAAI 2022, Authors preprint version, 14 pages",
    "descriptor": "\nComments: Accepted at AAAI 2022, Authors preprint version, 14 pages\n",
    "authors": [
      "Chandra Thapa",
      "M.A.P. Chamikara",
      "Seyit Camtepe",
      "Lichao Sun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2004.12088"
  },
  {
    "id": "arXiv:2006.10340",
    "title": "Perfectly Matched Layers on Cubic Domains forPauli's Equations",
    "abstract": "Perfectly Matched Layers on Cubic Domains forPauli's Equations",
    "descriptor": "",
    "authors": [
      "Laurence Halpern",
      "Jeffrey Rauch"
    ],
    "subjectives": [
      "Analysis of PDEs (math.AP)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2006.10340"
  },
  {
    "id": "arXiv:2007.03959",
    "title": "Non-monotone target sets for threshold values restricted to $0$, $1$,  and the vertex degree",
    "abstract": "Non-monotone target sets for threshold values restricted to $0$, $1$,  and the vertex degree",
    "descriptor": "",
    "authors": [
      "Julien Baste",
      "Stefan Ehard",
      "Dieter Rautenbach"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2007.03959"
  },
  {
    "id": "arXiv:2008.02011",
    "title": "Neural Loop Combiner: Neural Network Models for Assessing the  Compatibility of Loops",
    "abstract": "Comments: Accepted to the 21st International Society for Music Information Retrieval Conference (ISMIR 2020)",
    "descriptor": "\nComments: Accepted to the 21st International Society for Music Information Retrieval Conference (ISMIR 2020)\n",
    "authors": [
      "Bo-Yu Chen",
      "Jordan B. L. Smith",
      "Yi-Hsuan Yang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2008.02011"
  },
  {
    "id": "arXiv:2009.06301",
    "title": "Feedback Prediction for Proactive HARQ in the Context of Industrial  Internet of Things",
    "abstract": "Feedback Prediction for Proactive HARQ in the Context of Industrial  Internet of Things",
    "descriptor": "",
    "authors": [
      "Baris G\u00f6ktepe",
      "Tatiana Rykova",
      "Thomas Fehrenbach",
      "Thomas Schierl",
      "Cornelius Hellge"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2009.06301"
  },
  {
    "id": "arXiv:2009.06770",
    "title": "Joint Subgraph-to-Subgraph Transitions -- Generalizing Triadic Closure  for Powerful and Interpretable Graph Modeling",
    "abstract": "Comments: Published in WSDM 2021",
    "descriptor": "\nComments: Published in WSDM 2021\n",
    "authors": [
      "Justus Hibshman",
      "Daniel Gonzalez Cedre",
      "Satyaki Sikdar",
      "Tim Weninger"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2009.06770"
  },
  {
    "id": "arXiv:2010.11278",
    "title": "Deep Surrogate Q-Learning for Autonomous Driving",
    "abstract": "Comments: Accepted at ICRA 2022",
    "descriptor": "\nComments: Accepted at ICRA 2022\n",
    "authors": [
      "Maria Kalweit",
      "Gabriel Kalweit",
      "Moritz Werling",
      "Joschka Boedecker"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2010.11278"
  },
  {
    "id": "arXiv:2011.06125",
    "title": "Hurricane Forecasting: A Novel Multimodal Machine Learning Framework",
    "abstract": "Comments: Spotlight talk at NeurIPS 2021, Tackling Climate Change with AI ; Under revision by the AMS' Weather and Forecasting journal",
    "descriptor": "\nComments: Spotlight talk at NeurIPS 2021, Tackling Climate Change with AI ; Under revision by the AMS' Weather and Forecasting journal\n",
    "authors": [
      "L\u00e9onard Boussioux",
      "Cynthia Zeng",
      "Th\u00e9o Gu\u00e9nais",
      "Dimitris Bertsimas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Atmospheric and Oceanic Physics (physics.ao-ph)"
    ],
    "url": "https://arxiv.org/abs/2011.06125"
  },
  {
    "id": "arXiv:2101.01925",
    "title": "PTOPO: Computing the Geometry and the Topology of Parametric Curves",
    "abstract": "PTOPO: Computing the Geometry and the Topology of Parametric Curves",
    "descriptor": "",
    "authors": [
      "Christina Katsamaki",
      "Fabrice Rouillier",
      "Elias Tsigaridas"
    ],
    "subjectives": [
      "Symbolic Computation (cs.SC)"
    ],
    "url": "https://arxiv.org/abs/2101.01925"
  },
  {
    "id": "arXiv:2101.04935",
    "title": "Single-path Bit Sharing for Automatic Loss-aware Model Compression",
    "abstract": "Comments: 21 pages",
    "descriptor": "\nComments: 21 pages\n",
    "authors": [
      "Jing Liu",
      "Bohan Zhuang",
      "Peng Chen",
      "Chunhua Shen",
      "Jianfei Cai",
      "Mingkui Tan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2101.04935"
  },
  {
    "id": "arXiv:2101.08879",
    "title": "Privacy-Preserving and Efficient Verification of the Outcome in  Genome-Wide Association Studies",
    "abstract": "Comments: To appear in Proceedings of Privacy Enhancing Technologies Symposium (PETS) 2022",
    "descriptor": "\nComments: To appear in Proceedings of Privacy Enhancing Technologies Symposium (PETS) 2022\n",
    "authors": [
      "Anisa Halimi",
      "Leonard Dervishi",
      "Erman Ayday",
      "Apostolos Pyrgelis",
      "Juan Ramon Troncoso-Pastoriza",
      "Jean-Pierre Hubaux",
      "Xiaoqian Jiang",
      "Jaideep Vaidya"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2101.08879"
  },
  {
    "id": "arXiv:2101.12288",
    "title": "From Geometry to Topology: Inverse Theorems for Distributed Persistence",
    "abstract": "Comments: Accepted at SOCG 2022",
    "descriptor": "\nComments: Accepted at SOCG 2022\n",
    "authors": [
      "Elchanan Solomon",
      "Alexander Wagner",
      "Paul Bendich"
    ],
    "subjectives": [
      "Algebraic Topology (math.AT)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2101.12288"
  },
  {
    "id": "arXiv:2102.01198",
    "title": "Identification over Additive Noise Channels in the Presence of Feedback",
    "abstract": "Identification over Additive Noise Channels in the Presence of Feedback",
    "descriptor": "",
    "authors": [
      "Moritz Wiese",
      "Wafa Labidi",
      "Christian Deppe",
      "Holger Boche"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2102.01198"
  },
  {
    "id": "arXiv:2102.04776",
    "title": "Generative Models as Distributions of Functions",
    "abstract": "Comments: AISTATS 2022 Oral camera ready. Incorporated reviewer feedback",
    "descriptor": "\nComments: AISTATS 2022 Oral camera ready. Incorporated reviewer feedback\n",
    "authors": [
      "Emilien Dupont",
      "Yee Whye Teh",
      "Arnaud Doucet"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2102.04776"
  },
  {
    "id": "arXiv:2102.06828",
    "title": "Domain Adaptation for Time Series Forecasting via Attention Sharing",
    "abstract": "Domain Adaptation for Time Series Forecasting via Attention Sharing",
    "descriptor": "",
    "authors": [
      "Xiaoyong Jin",
      "Youngsuk Park",
      "Danielle C. Maddix",
      "Hao Wang",
      "Yuyang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2102.06828"
  },
  {
    "id": "arXiv:2102.09761",
    "title": "Scaling Creative Inspiration with Fine-Grained Functional Aspects of  Ideas",
    "abstract": "Comments: To appear in CHI 2022",
    "descriptor": "\nComments: To appear in CHI 2022\n",
    "authors": [
      "Tom Hope",
      "Ronen Tamari",
      "Hyeonsu Kang",
      "Daniel Hershcovich",
      "Joel Chan",
      "Aniket Kittur",
      "Dafna Shahaf"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2102.09761"
  },
  {
    "id": "arXiv:2102.10343",
    "title": "Measuring the Transferability of $\\ell_\\infty$ Attacks by the $\\ell_2$  Norm",
    "abstract": "Measuring the Transferability of $\\ell_\\infty$ Attacks by the $\\ell_2$  Norm",
    "descriptor": "",
    "authors": [
      "Sizhe Chen",
      "Qinghua Tao",
      "Zhixing Ye",
      "Xiaolin Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2102.10343"
  },
  {
    "id": "arXiv:2102.10408",
    "title": "Numerical analysis of a topology optimization problem for Stokes flow",
    "abstract": "Numerical analysis of a topology optimization problem for Stokes flow",
    "descriptor": "",
    "authors": [
      "Ioannis P. A. Papadopoulos",
      "Endre S\u00fcli"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)"
    ],
    "url": "https://arxiv.org/abs/2102.10408"
  },
  {
    "id": "arXiv:2103.08970",
    "title": "Space Exploration Architecture and Design Framework for  Commercialization",
    "abstract": "Comments: A former version was presented at the International Astronautical Congress 2019",
    "descriptor": "\nComments: A former version was presented at the International Astronautical Congress 2019\n",
    "authors": [
      "Hao Chen",
      "Melkior Ornik",
      "Koki Ho"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2103.08970"
  },
  {
    "id": "arXiv:2103.08981",
    "title": "Hierarchical Reinforcement Learning Framework for Stochastic Spaceflight  Campaign Design",
    "abstract": "Comments: A former version was presented at the AIAA ASCEND conference 2020",
    "descriptor": "\nComments: A former version was presented at the AIAA ASCEND conference 2020\n",
    "authors": [
      "Yuji Takubo",
      "Hao Chen",
      "Koki Ho"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2103.08981"
  },
  {
    "id": "arXiv:2103.09716",
    "title": "Quantitative Performance Assessment of CNN Units via Topological Entropy  Calculation",
    "abstract": "Comments: Conference paper at ICLR 2022",
    "descriptor": "\nComments: Conference paper at ICLR 2022\n",
    "authors": [
      "Yang Zhao",
      "Hao Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.09716"
  },
  {
    "id": "arXiv:2103.13253",
    "title": "Learning Versatile Neural Architectures by Propagating Network Codes",
    "abstract": "Comments: ICLR 2022. Project page: this https URL",
    "descriptor": "\nComments: ICLR 2022. Project page: this https URL\n",
    "authors": [
      "Mingyu Ding",
      "Yuqi Huo",
      "Haoyu Lu",
      "Linjie Yang",
      "Zhe Wang",
      "Zhiwu Lu",
      "Jingdong Wang",
      "Ping Luo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.13253"
  },
  {
    "id": "arXiv:2103.13877",
    "title": "Data-driven Aerodynamic Analysis of Structures using Gaussian Processes",
    "abstract": "Comments: 22 pages, 33 figures",
    "descriptor": "\nComments: 22 pages, 33 figures\n",
    "authors": [
      "Igor Kavrakov",
      "Allan McRobie",
      "Guido Morgenthal"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2103.13877"
  },
  {
    "id": "arXiv:2103.14473",
    "title": "Distilling a Powerful Student Model via Online Knowledge Distillation",
    "abstract": "Comments: Accepted by IEEE Transactions on Neural Networks and Learning Systems (IEEE TNNLS)",
    "descriptor": "\nComments: Accepted by IEEE Transactions on Neural Networks and Learning Systems (IEEE TNNLS)\n",
    "authors": [
      "Shaojie Li",
      "Mingbao Lin",
      "Yan Wang",
      "Yongjian Wu",
      "Yonghong Tian",
      "Ling Shao",
      "Rongrong Ji"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.14473"
  },
  {
    "id": "arXiv:2104.03154",
    "title": "Improving Robustness of Deep Reinforcement Learning Agents: Environment  Attack based on the Critic Network",
    "abstract": "Improving Robustness of Deep Reinforcement Learning Agents: Environment  Attack based on the Critic Network",
    "descriptor": "",
    "authors": [
      "Lucas Schott",
      "Hatem Hajri",
      "Sylvain Lamprier"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2104.03154"
  },
  {
    "id": "arXiv:2104.04610",
    "title": "Deep Time Series Forecasting with Shape and Temporal Criteria",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:2010.07349",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2010.07349\n",
    "authors": [
      "Vincent Le Guen",
      "Nicolas Thome"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.04610"
  },
  {
    "id": "arXiv:2104.07253",
    "title": "Integration of Pre-trained Networks with Continuous Token Interface for  End-to-End Spoken Language Understanding",
    "abstract": "Comments: Accepted for ICASSP 2022",
    "descriptor": "\nComments: Accepted for ICASSP 2022\n",
    "authors": [
      "Seunghyun Seo",
      "Donghyun Kwak",
      "Bowon Lee"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2104.07253"
  },
  {
    "id": "arXiv:2104.14368",
    "title": "Fast computation of matrix function-based centrality measures for  layer-coupled multiplex networks",
    "abstract": "Fast computation of matrix function-based centrality measures for  layer-coupled multiplex networks",
    "descriptor": "",
    "authors": [
      "Kai Bergermann",
      "Martin Stoll"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2104.14368"
  },
  {
    "id": "arXiv:2105.00925",
    "title": "Hyperspherically Regularized Networks for BYOL Improves Feature  Uniformity and Separability",
    "abstract": "Comments: 11 pages, 8 figures",
    "descriptor": "\nComments: 11 pages, 8 figures\n",
    "authors": [
      "Aiden Durrant",
      "Georgios Leontidis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.00925"
  },
  {
    "id": "arXiv:2105.04138",
    "title": "Near Interference-Free Space-Time User Scheduling for MmWave Cellular  Network",
    "abstract": "Near Interference-Free Space-Time User Scheduling for MmWave Cellular  Network",
    "descriptor": "",
    "authors": [
      "Ziyuan Sha",
      "Siyu Chen",
      "Zhaocheng Wang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2105.04138"
  },
  {
    "id": "arXiv:2105.04612",
    "title": "Representative community divisions of networks",
    "abstract": "Comments: 15 pages, 4 figures",
    "descriptor": "\nComments: 15 pages, 4 figures\n",
    "authors": [
      "Alec Kirkley",
      "M. E. J. Newman"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2105.04612"
  },
  {
    "id": "arXiv:2105.08532",
    "title": "Robust Learning in Heterogeneous Contexts",
    "abstract": "Comments: Paper under SPL review",
    "descriptor": "\nComments: Paper under SPL review\n",
    "authors": [
      "Muhammad Osama",
      "Dave Zachariah",
      "Petre Stoica"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.08532"
  },
  {
    "id": "arXiv:2105.09162",
    "title": "Isoparametric unfitted BDF -- Finite element method for PDEs on evolving  domains",
    "abstract": "Comments: 29 pages, 7 figures",
    "descriptor": "\nComments: 29 pages, 7 figures\n",
    "authors": [
      "Yimin Lou",
      "Christoph Lehrenfeld"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2105.09162"
  },
  {
    "id": "arXiv:2105.09673",
    "title": "An Exact Poly-Time Membership-Queries Algorithm for Extraction a  three-Layer ReLU Network",
    "abstract": "An Exact Poly-Time Membership-Queries Algorithm for Extraction a  three-Layer ReLU Network",
    "descriptor": "",
    "authors": [
      "Amit Daniely",
      "Elad Granot"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.09673"
  },
  {
    "id": "arXiv:2105.11512",
    "title": "Towards Low-Photon Nanoscale Imaging: Holographic Phase Retrieval via  Maximum Likelihood Optimization",
    "abstract": "Towards Low-Photon Nanoscale Imaging: Holographic Phase Retrieval via  Maximum Likelihood Optimization",
    "descriptor": "",
    "authors": [
      "David A. Barmherzig",
      "Ju Sun"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Information Theory (cs.IT)",
      "Optics (physics.optics)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2105.11512"
  },
  {
    "id": "arXiv:2105.13599",
    "title": "Short-Term Stock Price-Trend Prediction Using Meta-Learning",
    "abstract": "Comments: \\copyright 2021 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works",
    "descriptor": "\nComments: \\copyright 2021 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works\n",
    "authors": [
      "Shin-Hung Chang",
      "Cheng-Wen Hsu",
      "Hsing-Ying Li",
      "Wei-Sheng Zeng",
      "Jan-Ming Ho"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.13599"
  },
  {
    "id": "arXiv:2105.14536",
    "title": "On the Lagrangian-Eulerian Coupling in the Immersed Finite  Element/Difference Method",
    "abstract": "On the Lagrangian-Eulerian Coupling in the Immersed Finite  Element/Difference Method",
    "descriptor": "",
    "authors": [
      "Jae H. Lee",
      "Boyce E. Griffith"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2105.14536"
  },
  {
    "id": "arXiv:2106.00266",
    "title": "Did I do that? Blame as a means to identify controlled effects in  reinforcement learning",
    "abstract": "Did I do that? Blame as a means to identify controlled effects in  reinforcement learning",
    "descriptor": "",
    "authors": [
      "Oriol Corcoll",
      "Youssef Mohamed",
      "Raul Vicente"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.00266"
  },
  {
    "id": "arXiv:2106.03097",
    "title": "Preservation of Global Knowledge by Not-True Distillation in Federated  Learning",
    "abstract": "Comments: Under review",
    "descriptor": "\nComments: Under review\n",
    "authors": [
      "Gihun Lee",
      "Minchan Jeong",
      "Yongjin Shin",
      "Sangmin Bae",
      "Se-Young Yun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.03097"
  },
  {
    "id": "arXiv:2106.04096",
    "title": "Linear Convergence of Entropy-Regularized Natural Policy Gradient with  Linear Function Approximation",
    "abstract": "Linear Convergence of Entropy-Regularized Natural Policy Gradient with  Linear Function Approximation",
    "descriptor": "",
    "authors": [
      "Semih Cayci",
      "Niao He",
      "R. Srikant"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.04096"
  },
  {
    "id": "arXiv:2106.07249",
    "title": "Automatic winning shifts",
    "abstract": "Comments: 28 pages, 5 figures, 1 table",
    "descriptor": "\nComments: 28 pages, 5 figures, 1 table\n",
    "authors": [
      "Jarkko Peltom\u00e4ki",
      "Ville Salo"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2106.07249"
  },
  {
    "id": "arXiv:2106.07435",
    "title": "Misinformation versus Facts: Understanding the Influence of News  Regarding COVID-19 Vaccines on Vaccine Uptake",
    "abstract": "Comments: Accepted for publication in Health Data Science, 2022",
    "descriptor": "\nComments: Accepted for publication in Health Data Science, 2022\n",
    "authors": [
      "Hanjia Lyu",
      "Zihe Zheng",
      "Jiebo Luo"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2106.07435"
  },
  {
    "id": "arXiv:2106.07815",
    "title": "Asymptotically Optimal Locally Private Heavy Hitters via Parameterized  Sketches",
    "abstract": "Asymptotically Optimal Locally Private Heavy Hitters via Parameterized  Sketches",
    "descriptor": "",
    "authors": [
      "Hao Wu",
      "Anthony Wirth"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2106.07815"
  },
  {
    "id": "arXiv:2106.09659",
    "title": "Robustness and Consistency in Linear Quadratic Control with Untrusted  Predictions",
    "abstract": "Comments: 34 pages, 8 figures, ACM SIGMETRICS 2022",
    "descriptor": "\nComments: 34 pages, 8 figures, ACM SIGMETRICS 2022\n",
    "authors": [
      "Tongxin Li",
      "Ruixiao Yang",
      "Guannan Qu",
      "Guanya Shi",
      "Chenkai Yu",
      "Adam Wierman",
      "Steven Low"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2106.09659"
  },
  {
    "id": "arXiv:2106.15474",
    "title": "Semi-implicit methods for advection equations with explicit forms of  numerical solution",
    "abstract": "Semi-implicit methods for advection equations with explicit forms of  numerical solution",
    "descriptor": "",
    "authors": [
      "Peter Frolkovi\u010d",
      "Svetlana Kri\u0161kov\u00e1",
      "Michaela Rohov\u00e1",
      "Michal \u017derav\u00fd"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.15474"
  },
  {
    "id": "arXiv:2107.00211",
    "title": "A Few Interactions Improve Distributed Nonparametric Estimation,  Optimally",
    "abstract": "Comments: The result in the previous version is generalized to the case of any smoothness parameter \\beta&gt;0",
    "descriptor": "\nComments: The result in the previous version is generalized to the case of any smoothness parameter \\beta&gt;0\n",
    "authors": [
      "Jingbo Liu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2107.00211"
  },
  {
    "id": "arXiv:2107.00394",
    "title": "Global sensitivity analysis using derivative-based sparse Poincar\u00e9  chaos expansions",
    "abstract": "Global sensitivity analysis using derivative-based sparse Poincar\u00e9  chaos expansions",
    "descriptor": "",
    "authors": [
      "Nora L\u00fcthen",
      "Olivier Roustant",
      "Fabrice Gamboa",
      "Bertrand Iooss",
      "Stefano Marelli",
      "Bruno Sudret"
    ],
    "subjectives": [
      "Computation (stat.CO)",
      "Classical Analysis and ODEs (math.CA)",
      "Numerical Analysis (math.NA)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2107.00394"
  },
  {
    "id": "arXiv:2107.03961",
    "title": "Computational Benefits of Intermediate Rewards for Goal-Reaching Policy  Learning",
    "abstract": "Computational Benefits of Intermediate Rewards for Goal-Reaching Policy  Learning",
    "descriptor": "",
    "authors": [
      "Yuexiang Zhai",
      "Christina Baek",
      "Zhengyuan Zhou",
      "Jiantao Jiao",
      "Yi Ma"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.03961"
  },
  {
    "id": "arXiv:2107.05951",
    "title": "One-Point Gradient-Free Methods for Composite Optimization with  Applications to Distributed Optimization",
    "abstract": "Comments: New in v2: completely new text of the paper; 26 pages, 1 figure, 2 tables, 1 algorithm",
    "descriptor": "\nComments: New in v2: completely new text of the paper; 26 pages, 1 figure, 2 tables, 1 algorithm\n",
    "authors": [
      "Ivan Stepanov",
      "Artyom Voronov",
      "Aleksandr Beznosikov",
      "Alexander Gasnikov"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2107.05951"
  },
  {
    "id": "arXiv:2107.09251",
    "title": "Offline Preference-Based Apprenticeship Learning",
    "abstract": "Comments: ICML Workshop on Human-AI Collaboration in Sequential Decision-Making, 2021",
    "descriptor": "\nComments: ICML Workshop on Human-AI Collaboration in Sequential Decision-Making, 2021\n",
    "authors": [
      "Daniel Shin",
      "Daniel S. Brown",
      "Anca D. Dragan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.09251"
  },
  {
    "id": "arXiv:2107.09392",
    "title": "SVSNet: An End-to-end Speaker Voice Similarity Assessment Model",
    "abstract": "Comments: To appear in IEEE Signal Processing Letters (SPL)",
    "descriptor": "\nComments: To appear in IEEE Signal Processing Letters (SPL)\n",
    "authors": [
      "Cheng-Hung Hu",
      "Yu-Huai Peng",
      "Junichi Yamagishi",
      "Yu Tsao",
      "Hsin-Min Wang"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2107.09392"
  },
  {
    "id": "arXiv:2107.14210",
    "title": "A Parametric Microarchitecture Model for Accurate Basic Block Throughput  Prediction on Recent Intel CPUs",
    "abstract": "A Parametric Microarchitecture Model for Accurate Basic Block Throughput  Prediction on Recent Intel CPUs",
    "descriptor": "",
    "authors": [
      "Andreas Abel",
      "Jan Reineke"
    ],
    "subjectives": [
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2107.14210"
  },
  {
    "id": "arXiv:2108.00883",
    "title": "Sequential Multivariate Change Detection with Calibrated and Memoryless  False Detection Rates",
    "abstract": "Comments: 20 pages, 5 figures, open source implementation at this http URL",
    "descriptor": "\nComments: 20 pages, 5 figures, open source implementation at this http URL\n",
    "authors": [
      "Oliver Cobb",
      "Arnaud Van Looveren",
      "Janis Klaise"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2108.00883"
  },
  {
    "id": "arXiv:2108.01317",
    "title": "Deep Reinforcement Learning Based Networked Control with Network Delays  for Signal Temporal Logic Specifications",
    "abstract": "Comments: 8 pages, 7 figures, revised for submitting to a conference",
    "descriptor": "\nComments: 8 pages, 7 figures, revised for submitting to a conference\n",
    "authors": [
      "Junya Ikemoto",
      "Toshimitsu Ushio"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.01317"
  },
  {
    "id": "arXiv:2108.12717",
    "title": "Accelerating Serverless Computing by Harvesting Idle Resources",
    "abstract": "Comments: Accepted by the ACM WebConf 2022",
    "descriptor": "\nComments: Accepted by the ACM WebConf 2022\n",
    "authors": [
      "Hanfei Yu",
      "Hao Wang",
      "Jian Li",
      "Xu Yuan",
      "Seung-Jong Park"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.12717"
  },
  {
    "id": "arXiv:2108.13205",
    "title": "Model Predictive Contouring Control for Near-Time-Optimal Quadrotor  Flight",
    "abstract": "Comments: 17 pages, 16 figures. Video: this https URL",
    "descriptor": "\nComments: 17 pages, 16 figures. Video: this https URL\n",
    "authors": [
      "Angel Romero",
      "Sihao Sun",
      "Philipp Foehn",
      "Davide Scaramuzza"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2108.13205"
  },
  {
    "id": "arXiv:2109.03180",
    "title": "First Responders Got Wings: UAVs to the Rescue of Localization  Operations in Beyond 5G Systems",
    "abstract": "Comments: Accepted for publication in IEEE Communications Magazine",
    "descriptor": "\nComments: Accepted for publication in IEEE Communications Magazine\n",
    "authors": [
      "Antonio Albanese",
      "Vincenzo Sciancalepore",
      "Xavier Costa-P\u00e9rez"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2109.03180"
  },
  {
    "id": "arXiv:2109.04041",
    "title": "Keeping an Eye on Things: Deep Learned Features for Long-Term Visual  Localization",
    "abstract": "Keeping an Eye on Things: Deep Learned Features for Long-Term Visual  Localization",
    "descriptor": "",
    "authors": [
      "Mona Gridseth",
      "Timothy D. Barfoot"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.04041"
  },
  {
    "id": "arXiv:2109.04236",
    "title": "ECQ$^{\\text{x}}$: Explainability-Driven Quantization for Low-Bit and  Sparse DNNs",
    "abstract": "Comments: 22 pages, 10 figures, 1 table",
    "descriptor": "\nComments: 22 pages, 10 figures, 1 table\n",
    "authors": [
      "Daniel Becking",
      "Maximilian Dreyer",
      "Wojciech Samek",
      "Karsten M\u00fcller",
      "Sebastian Lapuschkin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.04236"
  },
  {
    "id": "arXiv:2109.08336",
    "title": "LoGG3D-Net: Locally Guided Global Descriptor Learning for 3D Place  Recognition",
    "abstract": "Comments: Accepted - ICRA 2022",
    "descriptor": "\nComments: Accepted - ICRA 2022\n",
    "authors": [
      "Kavisha Vidanapathirana",
      "Milad Ramezani",
      "Peyman Moghadam",
      "Sridha Sridharan",
      "Clinton Fookes"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.08336"
  },
  {
    "id": "arXiv:2109.08532",
    "title": "PAPIR: Practical RIS-aided Localization via Statistical User Information",
    "abstract": "Comments: Accepted for presentation at IEEE SPAWC 2021",
    "descriptor": "\nComments: Accepted for presentation at IEEE SPAWC 2021\n",
    "authors": [
      "Antonio Albanese",
      "Placido Mursia",
      "Vincenzo Sciancalepore",
      "Xavier Costa-P\u00e9rez"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2109.08532"
  },
  {
    "id": "arXiv:2109.08652",
    "title": "AutoPlace: Robust Place Recognition with Single-chip Automotive Radar",
    "abstract": "Comments: Accepted by IEEE Conference on Robotics and Automation (ICRA), 8 pages",
    "descriptor": "\nComments: Accepted by IEEE Conference on Robotics and Automation (ICRA), 8 pages\n",
    "authors": [
      "Kaiwen Cai",
      "Bing Wang",
      "Chris Xiaoxuan Lu"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.08652"
  },
  {
    "id": "arXiv:2109.08792",
    "title": "Learning to be Fair: A Consequentialist Approach to Equitable  Decision-Making",
    "abstract": "Learning to be Fair: A Consequentialist Approach to Equitable  Decision-Making",
    "descriptor": "",
    "authors": [
      "Alex Chohlas-Wood",
      "Madison Coots",
      "Henry Zhu",
      "Emma Brunskill",
      "Sharad Goel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2109.08792"
  },
  {
    "id": "arXiv:2109.10888",
    "title": "A Functional Operator for Model Uncertainty Quantification in the RKHS",
    "abstract": "Comments: Introduction clarified. Figure 3 label corrected. Updated version of arXiv:2103.01374",
    "descriptor": "\nComments: Introduction clarified. Figure 3 label corrected. Updated version of arXiv:2103.01374\n",
    "authors": [
      "Rishabh Singh",
      "Jose C. Principe"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2109.10888"
  },
  {
    "id": "arXiv:2109.10935",
    "title": "Robust Generalization of Quadratic Neural Networks via Function  Identification",
    "abstract": "Robust Generalization of Quadratic Neural Networks via Function  Identification",
    "descriptor": "",
    "authors": [
      "Kan Xu",
      "Hamsa Bastani",
      "Osbert Bastani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2109.10935"
  },
  {
    "id": "arXiv:2109.11160",
    "title": "Toward a Unified Framework for Debugging Concept-based Models",
    "abstract": "Comments: 11 pages, 1 figure. Accepted at the AAAI-22 Workshop on Interactive Machine Learning",
    "descriptor": "\nComments: 11 pages, 1 figure. Accepted at the AAAI-22 Workshop on Interactive Machine Learning\n",
    "authors": [
      "Andrea Bontempelli",
      "Fausto Giunchiglia",
      "Andrea Passerini",
      "Stefano Teso"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2109.11160"
  },
  {
    "id": "arXiv:2109.15134",
    "title": "Variational Marginal Particle Filters",
    "abstract": "Comments: Accepted to AISTATS 2022",
    "descriptor": "\nComments: Accepted to AISTATS 2022\n",
    "authors": [
      "Jinlin Lai",
      "Justin Domke",
      "Daniel Sheldon"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.15134"
  },
  {
    "id": "arXiv:2110.01670",
    "title": "A manifold learning approach for gesture recognition from micro-Doppler  radar measurements",
    "abstract": "A manifold learning approach for gesture recognition from micro-Doppler  radar measurements",
    "descriptor": "",
    "authors": [
      "Eric Mason",
      "Hrushikesh Mhaskar",
      "Adam Guo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.01670"
  },
  {
    "id": "arXiv:2110.02600",
    "title": "Sequential Reptile: Inter-Task Gradient Alignment for Multilingual  Learning",
    "abstract": "Comments: ICLR 2022",
    "descriptor": "\nComments: ICLR 2022\n",
    "authors": [
      "Seanie Lee",
      "Hae Beom Lee",
      "Juho Lee",
      "Sung Ju Hwang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.02600"
  },
  {
    "id": "arXiv:2110.03243",
    "title": "Sound Event Detection Guided by Semantic Contexts of Scenes",
    "abstract": "Comments: Accepted to ICASSP 2022",
    "descriptor": "\nComments: Accepted to ICASSP 2022\n",
    "authors": [
      "Noriyuki Tonami",
      "Keisuke Imoto",
      "Ryotaro Nagase",
      "Yuki Okamoto",
      "Takahiro Fukumori",
      "Yoichi Yamashita"
    ],
    "subjectives": [
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2110.03243"
  },
  {
    "id": "arXiv:2110.03836",
    "title": "Limits on Counting Triangles using Bipartite Independent Set Queries",
    "abstract": "Comments: 30 pages",
    "descriptor": "\nComments: 30 pages\n",
    "authors": [
      "Arijit Bishnu",
      "Arijit Ghosh",
      "Gopinath Mishra"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2110.03836"
  },
  {
    "id": "arXiv:2110.05695",
    "title": "The Mirrornet : Learning Audio Synthesizer Controls Inspired by  Sensorimotor Interaction",
    "abstract": "The Mirrornet : Learning Audio Synthesizer Controls Inspired by  Sensorimotor Interaction",
    "descriptor": "",
    "authors": [
      "Yashish M. Siriwardena",
      "Guilhem Marion",
      "Shihab Shamma"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2110.05695"
  },
  {
    "id": "arXiv:2110.06525",
    "title": "Automatic DJ Transitions with Differentiable Audio Effects and  Generative Adversarial Networks",
    "abstract": "Comments: To be published at ICASSP 2022",
    "descriptor": "\nComments: To be published at ICASSP 2022\n",
    "authors": [
      "Bo-Yu Chen",
      "Wei-Han Hsu",
      "Wei-Hsiang Liao",
      "Marco A. Mart\u00ednez Ram\u00edrez",
      "Yuki Mitsufuji",
      "Yi-Hsuan Yang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.06525"
  },
  {
    "id": "arXiv:2110.07298",
    "title": "LFPT5: A Unified Framework for Lifelong Few-shot Language Learning Based  on Prompt Tuning of T5",
    "abstract": "Comments: ICLR 2022. Code is available at this https URL",
    "descriptor": "\nComments: ICLR 2022. Code is available at this https URL\n",
    "authors": [
      "Chengwei Qin",
      "Shafiq Joty"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.07298"
  },
  {
    "id": "arXiv:2110.07807",
    "title": "Provable Regret Bounds for Deep Online Learning and Control",
    "abstract": "Provable Regret Bounds for Deep Online Learning and Control",
    "descriptor": "",
    "authors": [
      "Xinyi Chen",
      "Edgar Minasyan",
      "Jason D. Lee",
      "Elad Hazan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.07807"
  },
  {
    "id": "arXiv:2110.07881",
    "title": "$k\\texttt{-experts}$ -- Online Policies and Fundamental Limits",
    "abstract": "Comments: To appear in AISTATS 2022",
    "descriptor": "\nComments: To appear in AISTATS 2022\n",
    "authors": [
      "Samrat Mukhopadhyay",
      "Sourav Sahoo",
      "Abhishek Sinha"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.07881"
  },
  {
    "id": "arXiv:2110.07957",
    "title": "Don't speak too fast: The impact of data bias on self-supervised speech  models",
    "abstract": "Comments: Accepted by ICASSP 2022",
    "descriptor": "\nComments: Accepted by ICASSP 2022\n",
    "authors": [
      "Yen Meng",
      "Yi-Hui Chou",
      "Andy T. Liu",
      "Hung-yi Lee"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2110.07957"
  },
  {
    "id": "arXiv:2110.08258",
    "title": "A Framework for Learning to Request Rich and Contextually Useful  Information from Humans",
    "abstract": "Comments: 14 pages",
    "descriptor": "\nComments: 14 pages\n",
    "authors": [
      "Khanh Nguyen",
      "Yonatan Bisk",
      "Hal Daum\u00e9 III"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.08258"
  },
  {
    "id": "arXiv:2110.09888",
    "title": "Novel Features for Time Series Analysis: A Complex Networks Approach",
    "abstract": "Novel Features for Time Series Analysis: A Complex Networks Approach",
    "descriptor": "",
    "authors": [
      "Vanessa Freitas Silva",
      "Maria Eduarda Silva",
      "Pedro Ribeiro",
      "Fernando Silva"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.09888"
  },
  {
    "id": "arXiv:2110.10324",
    "title": "HARPS: An Online POMDP Framework for Human-Assisted Robotic Planning and  Sensing",
    "abstract": "HARPS: An Online POMDP Framework for Human-Assisted Robotic Planning and  Sensing",
    "descriptor": "",
    "authors": [
      "Luke Burks",
      "Hunter M. Ray",
      "Jamison McGinley",
      "Sousheel Vunnam",
      "Nisar Ahmed"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2110.10324"
  },
  {
    "id": "arXiv:2110.10804",
    "title": "Identifiable Deep Generative Models via Sparse Decoding",
    "abstract": "Identifiable Deep Generative Models via Sparse Decoding",
    "descriptor": "",
    "authors": [
      "Gemma E. Moran",
      "Dhanya Sridhar",
      "Yixin Wang",
      "David M. Blei"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2110.10804"
  },
  {
    "id": "arXiv:2110.11439",
    "title": "(Optimal) Online Bipartite Matching with Predicted Degrees",
    "abstract": "Comments: Added results showing the optimality of MinPredictedDegree on CLV-B random graphs",
    "descriptor": "\nComments: Added results showing the optimality of MinPredictedDegree on CLV-B random graphs\n",
    "authors": [
      "Anders Aamand",
      "Justin Y. Chen",
      "Piotr Indyk"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.11439"
  },
  {
    "id": "arXiv:2110.12064",
    "title": "Causal Effect Identification with Context-specific Independence  Relations of Control Variables",
    "abstract": "Comments: 10 pages, 5 figures, 2 algorithms, 1 table",
    "descriptor": "\nComments: 10 pages, 5 figures, 2 algorithms, 1 table\n",
    "authors": [
      "Ehsan Mokhtarian",
      "Fateme Jamshidi",
      "Jalal Etesami",
      "Negar Kiyavash"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.12064"
  },
  {
    "id": "arXiv:2110.14180",
    "title": "AeCoM: An Aerial Continuum Manipulator with Precise Kinematic Modeling  for Variable Loading and Tendon-slacking Prevention",
    "abstract": "AeCoM: An Aerial Continuum Manipulator with Precise Kinematic Modeling  for Variable Loading and Tendon-slacking Prevention",
    "descriptor": "",
    "authors": [
      "Rui Peng",
      "Zehao Wang",
      "Peng Lu"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.14180"
  },
  {
    "id": "arXiv:2110.14735",
    "title": "Towards Evaluating the Robustness of Neural Networks Learned by  Transduction",
    "abstract": "Comments: Paper published at ICLR 2022. arXiv admin note: text overlap with arXiv:2106.08387",
    "descriptor": "\nComments: Paper published at ICLR 2022. arXiv admin note: text overlap with arXiv:2106.08387\n",
    "authors": [
      "Jiefeng Chen",
      "Xi Wu",
      "Yang Guo",
      "Yingyu Liang",
      "Somesh Jha"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.14735"
  },
  {
    "id": "arXiv:2111.00947",
    "title": "Nested Multiple Instance Learning with Attention Mechanisms",
    "abstract": "Comments: Submitted to ICIP 2022",
    "descriptor": "\nComments: Submitted to ICIP 2022\n",
    "authors": [
      "Saul Fuster",
      "Trygve Eftest\u00f8l",
      "Kjersti Engan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.00947"
  },
  {
    "id": "arXiv:2111.05384",
    "title": "DataWords: Getting Contrarian with Text, Structured Data and  Explanations",
    "abstract": "Comments: 11 pages. Accepted for presentation at the Intelligent Systems Conference (IntelliSys) 2022, September 1-2, 2022, Amsterdam, The Netherlands",
    "descriptor": "\nComments: 11 pages. Accepted for presentation at the Intelligent Systems Conference (IntelliSys) 2022, September 1-2, 2022, Amsterdam, The Netherlands\n",
    "authors": [
      "Stephen I. Gallant",
      "Mirza Nasir Hossain"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2111.05384"
  },
  {
    "id": "arXiv:2111.08808",
    "title": "User Response and Sentiment Prediction for Automatic Dialogue Evaluation",
    "abstract": "Comments: Accepted at EMNLP 2021 Evaluations and Assessments of Neural Conversation Systems Workshop. 2 pages, 1 table",
    "descriptor": "\nComments: Accepted at EMNLP 2021 Evaluations and Assessments of Neural Conversation Systems Workshop. 2 pages, 1 table\n",
    "authors": [
      "Sarik Ghazarian",
      "Behnam Hedayatnia",
      "Alexandros Papangelis",
      "Yang Liu",
      "Dilek Hakkani-Tur"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2111.08808"
  },
  {
    "id": "arXiv:2111.10183",
    "title": "Computing Graph Edit Distance with Algorithms on Quantum Devices",
    "abstract": "Comments: 12 pages, 9 figures. Comments are welcome",
    "descriptor": "\nComments: 12 pages, 9 figures. Comments are welcome\n",
    "authors": [
      "Massimiliano Incudini",
      "Fabio Tarocco",
      "Riccardo Mengoni",
      "Alessandra Di Pierro",
      "Antonio Mandarino"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.10183"
  },
  {
    "id": "arXiv:2111.12583",
    "title": "Optimizing Latent Space Directions For GAN-based Local Image Editing",
    "abstract": "Comments: 4 pages, 5 figures, 1 table",
    "descriptor": "\nComments: 4 pages, 5 figures, 1 table\n",
    "authors": [
      "Ehsan Pajouheshgar",
      "Tong Zhang",
      "Sabine S\u00fcsstrunk"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.12583"
  },
  {
    "id": "arXiv:2111.13299",
    "title": "Exploiting full Resolution Feature Context for Liver Tumor and Vessel  Segmentation via Fusion Encoder: Application to Liver Tumor and Vessel 3D  reconstruction",
    "abstract": "Comments: 15 pages, 6 Figures",
    "descriptor": "\nComments: 15 pages, 6 Figures\n",
    "authors": [
      "Xiangyu Meng",
      "Xudong Zhang",
      "Gan Wang",
      "Ying Zhang",
      "Xin Shi",
      "Huanhuan Dai",
      "Zixuan Wang",
      "Xun Wang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.13299"
  },
  {
    "id": "arXiv:2111.14331",
    "title": "Improving Experience Replay with Successor Representation",
    "abstract": "Improving Experience Replay with Successor Representation",
    "descriptor": "",
    "authors": [
      "Yizhi Yuan",
      "Marcelo G Mattar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2111.14331"
  },
  {
    "id": "arXiv:2111.14984",
    "title": "Continuous conditional generative adversarial networks for data-driven  solutions of poroelasticity with heterogeneous material properties",
    "abstract": "Continuous conditional generative adversarial networks for data-driven  solutions of poroelasticity with heterogeneous material properties",
    "descriptor": "",
    "authors": [
      "T. Kadeethum",
      "D. O'Malley",
      "Y. Choi",
      "H. S. Viswanathan",
      "N. Bouklas",
      "H. Yoon"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2111.14984"
  },
  {
    "id": "arXiv:2112.00209",
    "title": "Environmental Sound Extraction Using Onomatopoeic Words",
    "abstract": "Comments: Accepted to ICASSP2022",
    "descriptor": "\nComments: Accepted to ICASSP2022\n",
    "authors": [
      "Yuki Okamoto",
      "Shota Horiguchi",
      "Masaaki Yamamoto",
      "Keisuke Imoto",
      "Yohei Kawaguchi"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2112.00209"
  },
  {
    "id": "arXiv:2112.01583",
    "title": "The Representation Jensen-R\u00e9nyi Divergence",
    "abstract": "Comments: We added more details about the experiments. We also improved visuals",
    "descriptor": "\nComments: We added more details about the experiments. We also improved visuals\n",
    "authors": [
      "Jhoan Keider Hoyos Osorio",
      "Oscar Skean",
      "Austin J. Brockmeier",
      "Luis Gonzalo Sanchez Giraldo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2112.01583"
  },
  {
    "id": "arXiv:2112.04017",
    "title": "fastball: A fast algorithm to sample bipartite graphs with fixed degree  sequences",
    "abstract": "fastball: A fast algorithm to sample bipartite graphs with fixed degree  sequences",
    "descriptor": "",
    "authors": [
      "Karl Godard",
      "Zachary P. Neal"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2112.04017"
  },
  {
    "id": "arXiv:2112.04214",
    "title": "Learning music audio representations via weak language supervision",
    "abstract": "Comments: Accepted to ICASSP 2022",
    "descriptor": "\nComments: Accepted to ICASSP 2022\n",
    "authors": [
      "Ilaria Manco",
      "Emmanouil Benetos",
      "Elio Quinton",
      "Gyorgy Fazekas"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2112.04214"
  },
  {
    "id": "arXiv:2112.04914",
    "title": "End-to-end Alexa Device Arbitration",
    "abstract": "Comments: Accepted for ICASSP 2022",
    "descriptor": "\nComments: Accepted for ICASSP 2022\n",
    "authors": [
      "Jarred Barber",
      "Yifeng Fan",
      "Tao Zhang"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2112.04914"
  },
  {
    "id": "arXiv:2112.07076",
    "title": "Real-Time Neural Voice Camouflage",
    "abstract": "Comments: 14 pages",
    "descriptor": "\nComments: 14 pages\n",
    "authors": [
      "Mia Chiquier",
      "Chengzhi Mao",
      "Carl Vondrick"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2112.07076"
  },
  {
    "id": "arXiv:2112.07544",
    "title": "Modeling Strong and Human-Like Gameplay with KL-Regularized Search",
    "abstract": "Modeling Strong and Human-Like Gameplay with KL-Regularized Search",
    "descriptor": "",
    "authors": [
      "Athul Paul Jacob",
      "David J. Wu",
      "Gabriele Farina",
      "Adam Lerer",
      "Hengyuan Hu",
      "Anton Bakhtin",
      "Jacob Andreas",
      "Noam Brown"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Artificial Intelligence (cs.AI)",
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.07544"
  },
  {
    "id": "arXiv:2112.08682",
    "title": "Isometric MT: Neural Machine Translation for Automatic Dubbing",
    "abstract": "Comments: Published in ICASSP 2022 - scheduled for 22-27 May 2022 in Singapore",
    "descriptor": "\nComments: Published in ICASSP 2022 - scheduled for 22-27 May 2022 in Singapore\n",
    "authors": [
      "Surafel M. Lakew",
      "Yogesh Virkar",
      "Prashant Mathur",
      "Marcello Federico"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.08682"
  },
  {
    "id": "arXiv:2112.09093",
    "title": "Network Realization Functions for Optimal Distributed Control",
    "abstract": "Comments: 12 pages, 6 figures, 1 table",
    "descriptor": "\nComments: 12 pages, 6 figures, 1 table\n",
    "authors": [
      "\u015eerban Sab\u0103u",
      "Andrei Speril\u0103",
      "Cristian Oar\u0103",
      "Ali Jadbabaie"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.09093"
  },
  {
    "id": "arXiv:2112.09631",
    "title": "Sublinear Time Approximation of Text Similarity Matrices",
    "abstract": "Comments: 25 pages, 10 figures",
    "descriptor": "\nComments: 25 pages, 10 figures\n",
    "authors": [
      "Archan Ray",
      "Nicholas Monath",
      "Andrew McCallum",
      "Cameron Musco"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.09631"
  },
  {
    "id": "arXiv:2112.10454",
    "title": "Blockchain Mining with Multiple Selfish Miners",
    "abstract": "Comments: arXiv admin note: substantial text overlap with arXiv:1811.08263",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:1811.08263\n",
    "authors": [
      "Qianlan Bai",
      "Yuedong Xu",
      "Nianyi Liu",
      "Xin Wang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2112.10454"
  },
  {
    "id": "arXiv:2112.10562",
    "title": "Hardness of the Generalized Coloring Numbers",
    "abstract": "Comments: 16 pages, 5 figures",
    "descriptor": "\nComments: 16 pages, 5 figures\n",
    "authors": [
      "Michael Breen-McKay",
      "Brian Lavallee",
      "Blair D. Sullivan"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2112.10562"
  },
  {
    "id": "arXiv:2201.02033",
    "title": "Convergence analysis of the Jacobi spectral collocation methods for  weakly singular nonlocal diffusion equations with volume constraints",
    "abstract": "Convergence analysis of the Jacobi spectral collocation methods for  weakly singular nonlocal diffusion equations with volume constraints",
    "descriptor": "",
    "authors": [
      "Jiashu Lu",
      "Mengna Yang",
      "Yufeng Nie"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2201.02033"
  },
  {
    "id": "arXiv:2201.02298",
    "title": "Local and Global Convergence of General Burer-Monteiro Tensor  Optimizations",
    "abstract": "Local and Global Convergence of General Burer-Monteiro Tensor  Optimizations",
    "descriptor": "",
    "authors": [
      "Shuang Li",
      "Qiuwei Li"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2201.02298"
  },
  {
    "id": "arXiv:2201.02863",
    "title": "PocketNN: Integer-only Training and Inference of Neural Networks via  Direct Feedback Alignment and Pocket Activations in Pure C++",
    "abstract": "Comments: Accepted in tinyML Research Symposium '22, March 2022, San Jose, CA (TinyML 2022). 7 pages, 4 figures, 2 tables",
    "descriptor": "\nComments: Accepted in tinyML Research Symposium '22, March 2022, San Jose, CA (TinyML 2022). 7 pages, 4 figures, 2 tables\n",
    "authors": [
      "Jaewoo Song",
      "Fangzhen Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2201.02863"
  },
  {
    "id": "arXiv:2201.04138",
    "title": "Overview of the HECKTOR Challenge at MICCAI 2021: Automatic Head and  Neck Tumor Segmentation and Outcome Prediction in PET/CT Images",
    "abstract": "Overview of the HECKTOR Challenge at MICCAI 2021: Automatic Head and  Neck Tumor Segmentation and Outcome Prediction in PET/CT Images",
    "descriptor": "",
    "authors": [
      "Vincent Andrearczyk",
      "Valentin Oreiller",
      "Sarah Boughdad",
      "Catherine Chez Le Rest",
      "Hesham Elhalawani",
      "Mario Jreige",
      "John O. Prior",
      "Martin Valli\u00e8res",
      "Dimitris Visvikis",
      "Mathieu Hatt",
      "Adrien Depeursinge"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.04138"
  },
  {
    "id": "arXiv:2201.04286",
    "title": "Evolutionary Action Selection for Gradient-based Policy Learning",
    "abstract": "Evolutionary Action Selection for Gradient-based Policy Learning",
    "descriptor": "",
    "authors": [
      "Yan Ma",
      "Tianxing Liu",
      "Bingsheng Wei",
      "Yi Liu",
      "Kang Xu",
      "Wei Li"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.04286"
  },
  {
    "id": "arXiv:2201.04489",
    "title": "Power-to-Gas in a gas and electricity distribution network: a  sensitivity analysis of modeling approaches",
    "abstract": "Power-to-Gas in a gas and electricity distribution network: a  sensitivity analysis of modeling approaches",
    "descriptor": "",
    "authors": [
      "Gabriele Fambri",
      "Cesar Diaz-Londono",
      "Andrea Mazza",
      "Marco Badami",
      "Robert Weiss"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2201.04489"
  },
  {
    "id": "arXiv:2201.06503",
    "title": "Analytic-DPM: an Analytic Estimate of the Optimal Reverse Variance in  Diffusion Probabilistic Models",
    "abstract": "Analytic-DPM: an Analytic Estimate of the Optimal Reverse Variance in  Diffusion Probabilistic Models",
    "descriptor": "",
    "authors": [
      "Fan Bao",
      "Chongxuan Li",
      "Jun Zhu",
      "Bo Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.06503"
  },
  {
    "id": "arXiv:2201.07209",
    "title": "Advancing Deep Residual Learning by Solving the Crux of Degradation in  Spiking Neural Networks",
    "abstract": "Comments: It is an older version of arXiv:2112.08954 and was submitted by mistake",
    "descriptor": "\nComments: It is an older version of arXiv:2112.08954 and was submitted by mistake\n",
    "authors": [
      "Yifan Hu",
      "Yujie Wu",
      "Lei Deng",
      "Guoqi Li"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2201.07209"
  },
  {
    "id": "arXiv:2201.09353",
    "title": "Distributed Bandits with Heterogeneous Agents",
    "abstract": "Distributed Bandits with Heterogeneous Agents",
    "descriptor": "",
    "authors": [
      "Lin Yang",
      "Yu-zhen Janice Chen",
      "Mohammad Hajiesmaili",
      "John CS Lui",
      "Don Towsley"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2201.09353"
  },
  {
    "id": "arXiv:2201.10574",
    "title": "Basic Quantum Algorithms",
    "abstract": "Comments: 104 pages",
    "descriptor": "\nComments: 104 pages\n",
    "authors": [
      "Renato Portugal"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2201.10574"
  },
  {
    "id": "arXiv:2201.11501",
    "title": "From Motion to Muscle",
    "abstract": "From Motion to Muscle",
    "descriptor": "",
    "authors": [
      "Marie D. Schmidt",
      "Tobias Glasmachers",
      "Ioannis Iossifidis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.11501"
  },
  {
    "id": "arXiv:2201.11522",
    "title": "High-level Synthesis using the Julia Language",
    "abstract": "Comments: Presented at the 2nd Workshop on Languages, Tools, and Techniques for Accelerator Design (LATTE'22)",
    "descriptor": "\nComments: Presented at the 2nd Workshop on Languages, Tools, and Techniques for Accelerator Design (LATTE'22)\n",
    "authors": [
      "Benjamin Biggs",
      "Ian McInerney",
      "Eric C. Kerrigan",
      "George A. Constantinides"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2201.11522"
  },
  {
    "id": "arXiv:2201.11865",
    "title": "FedLite: A Scalable Approach for Federated Learning on  Resource-constrained Clients",
    "abstract": "FedLite: A Scalable Approach for Federated Learning on  Resource-constrained Clients",
    "descriptor": "",
    "authors": [
      "Jianyu Wang",
      "Hang Qi",
      "Ankit Singh Rawat",
      "Sashank Reddi",
      "Sagar Waghmare",
      "Felix X. Yu",
      "Gauri Joshi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2201.11865"
  },
  {
    "id": "arXiv:2201.11928",
    "title": "Quadruped Capturability and Push Recovery via a Switched-Systems  Characterization of Dynamic Balance",
    "abstract": "Quadruped Capturability and Push Recovery via a Switched-Systems  Characterization of Dynamic Balance",
    "descriptor": "",
    "authors": [
      "Hua Chen",
      "Zejun Hong",
      "Shunpeng Yang",
      "Patrick M. Wensing",
      "Wei Zhang"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2201.11928"
  },
  {
    "id": "arXiv:2201.11931",
    "title": "Fast Interpretable Greedy-Tree Sums (FIGS)",
    "abstract": "Fast Interpretable Greedy-Tree Sums (FIGS)",
    "descriptor": "",
    "authors": [
      "Yan Shuo Tan",
      "Chandan Singh",
      "Keyan Nasseri",
      "Abhineet Agarwal",
      "Bin Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Applications (stat.AP)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2201.11931"
  },
  {
    "id": "arXiv:2201.11969",
    "title": "Approximately Equivariant Networks for Imperfectly Symmetric Dynamics",
    "abstract": "Approximately Equivariant Networks for Imperfectly Symmetric Dynamics",
    "descriptor": "",
    "authors": [
      "Rui Wang",
      "Robin Walters",
      "Rose Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.11969"
  },
  {
    "id": "arXiv:2201.12041",
    "title": "Rapid protein assignments and structures from raw NMR spectra with the  deep learning technique ARTINA",
    "abstract": "Rapid protein assignments and structures from raw NMR spectra with the  deep learning technique ARTINA",
    "descriptor": "",
    "authors": [
      "Piotr Klukowski",
      "Roland Riek",
      "Peter G\u00fcntert"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.12041"
  },
  {
    "id": "arXiv:2201.12351",
    "title": "Low-rank features based double transformation matrices learning for  image classification",
    "abstract": "Low-rank features based double transformation matrices learning for  image classification",
    "descriptor": "",
    "authors": [
      "Yu-Hong Cai",
      "Xiao-Jun Wu",
      "Zhe Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.12351"
  },
  {
    "id": "arXiv:2201.12380",
    "title": "Explaining Graph-level Predictions with Communication Structure-Aware  Cooperative Games",
    "abstract": "Explaining Graph-level Predictions with Communication Structure-Aware  Cooperative Games",
    "descriptor": "",
    "authors": [
      "Shichang Zhang",
      "Neil Shah",
      "Yozen Liu",
      "Yizhou Sun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.12380"
  },
  {
    "id": "arXiv:2201.12560",
    "title": "Sim-to-Real for Soft Robots using Differentiable FEM: Recipes for  Meshing, Damping, and Actuation",
    "abstract": "Comments: This work has been accepted to the IEEE RA-L and ICRA 2022. Copyright may be transferred without notice, after which this version may no longer be accessible",
    "descriptor": "\nComments: This work has been accepted to the IEEE RA-L and ICRA 2022. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Mathieu Dubied",
      "Mike Michelis",
      "Andrew Spielberg",
      "Robert Katzschmann"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2201.12560"
  },
  {
    "id": "arXiv:2201.12878",
    "title": "Polynomial functors and Shannon entropy",
    "abstract": "Comments: 13 pages",
    "descriptor": "\nComments: 13 pages\n",
    "authors": [
      "David I. Spivak"
    ],
    "subjectives": [
      "Category Theory (math.CT)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2201.12878"
  },
  {
    "id": "arXiv:2201.13361",
    "title": "Signing the Supermask: Keep, Hide, Invert",
    "abstract": "Comments: ICLR 2022 camera ready",
    "descriptor": "\nComments: ICLR 2022 camera ready\n",
    "authors": [
      "Nils Koster",
      "Oliver Grothe",
      "Achim Rettinger"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.13361"
  },
  {
    "id": "arXiv:2202.00060",
    "title": "SnAKe: Bayesian Optimization with Pathwise Exploration",
    "abstract": "Comments: 8 main pages, 32 with appendix, 29 figures, 8 tables. Changed format, better suited for pre-print. Added references",
    "descriptor": "\nComments: 8 main pages, 32 with appendix, 29 figures, 8 tables. Changed format, better suited for pre-print. Added references\n",
    "authors": [
      "Jose Pablo Folch",
      "Shiqiang Zhang",
      "Robert M Lee",
      "Behrang Shafei",
      "David Walz",
      "Calvin Tsay",
      "Mark van der Wilk",
      "Ruth Misener"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2202.00060"
  },
  {
    "id": "arXiv:2202.00075",
    "title": "SUGAR: Efficient Subgraph-level Training via Resource-aware Graph  Partitioning",
    "abstract": "SUGAR: Efficient Subgraph-level Training via Resource-aware Graph  Partitioning",
    "descriptor": "",
    "authors": [
      "Zihui Xue",
      "Yuedong Yang",
      "Mengtian Yang",
      "Radu Marculescu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.00075"
  },
  {
    "id": "arXiv:2202.00633",
    "title": "Efficient Policy Space Response Oracles",
    "abstract": "Comments: revised with single-column, 24 pages, 8 figures",
    "descriptor": "\nComments: revised with single-column, 24 pages, 8 figures\n",
    "authors": [
      "Ming Zhou",
      "Jingxiao Chen",
      "Ying Wen",
      "Weinan Zhang",
      "Yaodong Yang",
      "Yong Yu"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2202.00633"
  },
  {
    "id": "arXiv:2202.01477",
    "title": "Unsourced Random Access with a Massive MIMO Receiver Using Multiple  Stages of Orthogonal Pilots",
    "abstract": "Unsourced Random Access with a Massive MIMO Receiver Using Multiple  Stages of Orthogonal Pilots",
    "descriptor": "",
    "authors": [
      "Mohammad Javad Ahmadi",
      "Tolga M. Duman"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.01477"
  },
  {
    "id": "arXiv:2202.02339",
    "title": "Discovering Distribution Shifts using Latent Space Representations",
    "abstract": "Comments: 10 pages, 5 figures, 3 tables, 2 algorithms",
    "descriptor": "\nComments: 10 pages, 5 figures, 3 tables, 2 algorithms\n",
    "authors": [
      "Leo Betthauser",
      "Urszula Chajewska",
      "Maurice Diesendruck",
      "Rohith Pesala"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.02339"
  },
  {
    "id": "arXiv:2202.02641",
    "title": "Emblaze: Illuminating Machine Learning Representations through  Interactive Comparison of Embedding Spaces",
    "abstract": "Comments: 23 pages, 5 figures, 2 tables. To be presented at IUI'22. arXiv version updated Feb 16 2022 with corrected publication year and copyright",
    "descriptor": "\nComments: 23 pages, 5 figures, 2 tables. To be presented at IUI'22. arXiv version updated Feb 16 2022 with corrected publication year and copyright\n",
    "authors": [
      "Venkatesh Sivaraman",
      "Yiwei Wu",
      "Adam Perer"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.02641"
  },
  {
    "id": "arXiv:2202.02943",
    "title": "Learning fair representation with a parametric integral probability  metric",
    "abstract": "Comments: 24 pages, including references and appendix",
    "descriptor": "\nComments: 24 pages, including references and appendix\n",
    "authors": [
      "Dongha Kim",
      "Kunwoong Kim",
      "Insung Kong",
      "Ilsang Ohn",
      "Yongdai Kim"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.02943"
  },
  {
    "id": "arXiv:2202.02989",
    "title": "Graph Self-supervised Learning with Accurate Discrepancy Learning",
    "abstract": "Comments: 8 pages",
    "descriptor": "\nComments: 8 pages\n",
    "authors": [
      "Dongki Kim",
      "Jinheon Baek",
      "Sung Ju Hwang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.02989"
  },
  {
    "id": "arXiv:2202.03005",
    "title": "B2EA: An Evolutionary Algorithm Assisted by Two Bayesian Optimization  Modules for Neural Architecture Search",
    "abstract": "Comments: 25 pages",
    "descriptor": "\nComments: 25 pages\n",
    "authors": [
      "Hyunghun Cho",
      "Jungwook Shin",
      "Wonjong Rhee"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.03005"
  },
  {
    "id": "arXiv:2202.03349",
    "title": "Conditional Gradients for the Approximately Vanishing Ideal",
    "abstract": "Comments: 22 pages",
    "descriptor": "\nComments: 22 pages\n",
    "authors": [
      "E. Wirth",
      "S. Pokutta"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.03349"
  },
  {
    "id": "arXiv:2202.03643",
    "title": "SNPSFuzzer: A Fast Greybox Fuzzer for Stateful Network Protocols using  Snapshots",
    "abstract": "SNPSFuzzer: A Fast Greybox Fuzzer for Stateful Network Protocols using  Snapshots",
    "descriptor": "",
    "authors": [
      "Junqiang Li",
      "Senyi Li",
      "Gang Sun",
      "Ting Chen",
      "Hongfang Yu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2202.03643"
  },
  {
    "id": "arXiv:2202.04052",
    "title": "Decision boundaries and convex hulls in the feature space that deep  learning functions learn from images",
    "abstract": "Decision boundaries and convex hulls in the feature space that deep  learning functions learn from images",
    "descriptor": "",
    "authors": [
      "Roozbeh Yousefzadeh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2202.04052"
  },
  {
    "id": "arXiv:2202.04365",
    "title": "AIVC: Artificial Intelligence based Video Codec",
    "abstract": "AIVC: Artificial Intelligence based Video Codec",
    "descriptor": "",
    "authors": [
      "Th\u00e9o Ladune",
      "Pierrick Philippe"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.04365"
  },
  {
    "id": "arXiv:2202.04397",
    "title": "A hypothesis-driven method based on machine learning for neuroimaging  data analysis",
    "abstract": "Comments: 12 figures",
    "descriptor": "\nComments: 12 figures\n",
    "authors": [
      "JM Gorriz",
      "R. Martin-Clemente",
      "C.G. Puntonet",
      "A. Ortiz",
      "J. Ramirez",
      "J. Suckling"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2202.04397"
  },
  {
    "id": "arXiv:2202.04546",
    "title": "Proving Non-Termination and Lower Runtime Bounds with LoAT (System  Description)",
    "abstract": "Proving Non-Termination and Lower Runtime Bounds with LoAT (System  Description)",
    "descriptor": "",
    "authors": [
      "Florian Frohn",
      "J\u00fcrgen Giesl"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2202.04546"
  },
  {
    "id": "arXiv:2202.04832",
    "title": "Bayesian Optimisation for Mixed-Variable Inputs using Value Proposals",
    "abstract": "Bayesian Optimisation for Mixed-Variable Inputs using Value Proposals",
    "descriptor": "",
    "authors": [
      "Yan Zuo",
      "Amir Dezfouli",
      "Iadine Chades",
      "David Alexander",
      "Benjamin Ward Muir"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.04832"
  },
  {
    "id": "arXiv:2202.05619",
    "title": "Self-Sovereign Personal Cryptocurrencies: Foundations for Grassroots  Cryptoeconomy",
    "abstract": "Self-Sovereign Personal Cryptocurrencies: Foundations for Grassroots  Cryptoeconomy",
    "descriptor": "",
    "authors": [
      "Ehud Shapiro"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2202.05619"
  },
  {
    "id": "arXiv:2202.05872",
    "title": "REST: Integrating Term Rewriting with Program Verification (Extended  Version)",
    "abstract": "REST: Integrating Term Rewriting with Program Verification (Extended  Version)",
    "descriptor": "",
    "authors": [
      "Zachary Grannan",
      "Niki Vazou",
      "Eva Darulova",
      "Alexander J. Summers"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2202.05872"
  },
  {
    "id": "arXiv:2202.06374",
    "title": "Optimal sizing of a holdout set for safe predictive model updating",
    "abstract": "Comments: Manuscript includes appendices and supplementary material",
    "descriptor": "\nComments: Manuscript includes appendices and supplementary material\n",
    "authors": [
      "Sami Haidar-Wehbe",
      "Samuel R Emerson",
      "Louis J M Aslett",
      "James Liley"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2202.06374"
  },
  {
    "id": "arXiv:2202.06594",
    "title": "A formal algebraic approach for the quantitative modeling of connectors  in architectures",
    "abstract": "Comments: 56 pages, 6 figures",
    "descriptor": "\nComments: 56 pages, 6 figures\n",
    "authors": [
      "Christina Chrysovalanti Fountoukidou",
      "Maria Pittou"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2202.06594"
  },
  {
    "id": "arXiv:2202.06850",
    "title": "Multi-Task Deep Residual Echo Suppression with Echo-aware Loss",
    "abstract": "Comments: ICASSP 2022",
    "descriptor": "\nComments: ICASSP 2022\n",
    "authors": [
      "Shimin Zhang",
      "Ziteng Wang",
      "Jiayao Sun",
      "Yihui Fu",
      "Biao Tian",
      "Qiang Fu",
      "Lei Xie"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2202.06850"
  },
  {
    "id": "arXiv:2202.07025",
    "title": "Box Supervised Video Segmentation Proposal Network",
    "abstract": "Box Supervised Video Segmentation Proposal Network",
    "descriptor": "",
    "authors": [
      "Tanveer Hannan",
      "Rajat Koner",
      "Jonathan Kobold",
      "Matthias Schubert"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.07025"
  },
  {
    "id": "arXiv:2202.07075",
    "title": "Regional Differences in Information Privacy Concerns After the  Facebook-Cambridge Analytica Data Scandal",
    "abstract": "Regional Differences in Information Privacy Concerns After the  Facebook-Cambridge Analytica Data Scandal",
    "descriptor": "",
    "authors": [
      "Felipe Gonz\u00e1lez-Pizarro",
      "Andrea Figueroa",
      "Claudia L\u00f3pez",
      "Cecilia Aragon"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2202.07075"
  },
  {
    "id": "arXiv:2202.07291",
    "title": "Beyond Natural Motion: Exploring Discontinuity for Video Frame  Interpolation",
    "abstract": "Beyond Natural Motion: Exploring Discontinuity for Video Frame  Interpolation",
    "descriptor": "",
    "authors": [
      "Sangjin Lee",
      "Hyeongmin Lee",
      "Chajin Shin",
      "Hanbin Son",
      "Sangyoun Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.07291"
  },
  {
    "id": "arXiv:2202.07301",
    "title": "User-Oriented Robust Reinforcement Learning",
    "abstract": "User-Oriented Robust Reinforcement Learning",
    "descriptor": "",
    "authors": [
      "Haoyi You",
      "Beichen Yu",
      "Haiming Jin",
      "Zhaoxing Yang",
      "Jiahui Sun",
      "Xinbing Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.07301"
  },
  {
    "id": "arXiv:2202.07638",
    "title": "On the design of scalable networks to reject polynomial disturbances",
    "abstract": "On the design of scalable networks to reject polynomial disturbances",
    "descriptor": "",
    "authors": [
      "Shihao Xie",
      "Giovanni Russo"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.07638"
  },
  {
    "id": "arXiv:2202.07645",
    "title": "Towards a maturity model for crypto-agility assessment",
    "abstract": "Comments: typos corrected",
    "descriptor": "\nComments: typos corrected\n",
    "authors": [
      "Julian Hohm",
      "Andreas Heinemann",
      "Alexander Wiesmaier"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.07645"
  },
  {
    "id": "arXiv:2202.07820",
    "title": "A Survey of Semen Quality Evaluation in Microscopic Videos Using  Computer Assisted Sperm Analysis",
    "abstract": "A Survey of Semen Quality Evaluation in Microscopic Videos Using  Computer Assisted Sperm Analysis",
    "descriptor": "",
    "authors": [
      "Wenwei Zhao",
      "Pingli Ma",
      "Chen Li",
      "Xiaoning Bu",
      "Shuojia Zou",
      "Tao Jiang",
      "Marcin Grzegorzek"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.07820"
  },
  {
    "id": "arXiv:2202.07855",
    "title": "Conversational Speech Recognition By Learning Conversation-level  Characteristics",
    "abstract": "Comments: ICASSP 2022",
    "descriptor": "\nComments: ICASSP 2022\n",
    "authors": [
      "Kun Wei",
      "Yike Zhang",
      "Sining Sun",
      "Lei Xie",
      "Long Ma"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2202.07855"
  },
  {
    "id": "arXiv:2202.07902",
    "title": "When Does A Spectral Graph Neural Network Fail in Node Classification?",
    "abstract": "When Does A Spectral Graph Neural Network Fail in Node Classification?",
    "descriptor": "",
    "authors": [
      "Zhixian Chen",
      "Tengfei Ma",
      "Yang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.07902"
  },
  {
    "id": "arXiv:2202.07908",
    "title": "Error Floor Analysis of Irregular Repetition ALOHA",
    "abstract": "Comments: v2: updated formatting. Accepted for publication at IEEE ICC 2022, Communication Theory symposium",
    "descriptor": "\nComments: v2: updated formatting. Accepted for publication at IEEE ICC 2022, Communication Theory symposium\n",
    "authors": [
      "Federico Clazzer",
      "Alexandre Graell i Amat"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.07908"
  },
  {
    "id": "arXiv:2202.08238",
    "title": "A multi-reconstruction study of breast density estimation using Deep  Learning",
    "abstract": "Comments: 4 pages",
    "descriptor": "\nComments: 4 pages\n",
    "authors": [
      "Vikash Gupta",
      "Mutlu Demirer",
      "Robert W. Maxwell",
      "Richard D. White",
      "Barbaros Selnur Erdal"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.08238"
  }
]
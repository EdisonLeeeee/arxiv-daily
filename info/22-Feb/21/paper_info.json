[
  {
    "id": "arXiv:2202.08856",
    "title": "Iterated Belief Change, Computationally",
    "abstract": "Iterated Belief Change is the research area that investigates principles for\nthe dynamics of beliefs over (possibly unlimited) many subsequent belief\nchanges. In this paper, we demonstrate how iterated belief change is connected\nto computation. In particular, we show that iterative belief revision is Turing\ncomplete, even under the condition that broadly accepted principles like the\nDarwiche-Pearl postulates for iterated revision hold.",
    "descriptor": "",
    "authors": [
      "Kai Sauerwald",
      "Christoph Beierle"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.08856"
  },
  {
    "id": "arXiv:2202.08862",
    "title": "RemixIT: Continual self-training of speech enhancement models via  bootstrapped remixing",
    "abstract": "We present RemixIT, a simple yet effective selfsupervised method for training\nspeech enhancement without the need of a single isolated in-domain speech nor a\nnoise waveform. Our approach overcomes limitations of previous methods which\nmake them dependent to clean in-domain target signals and thus, sensitive to\nany domain mismatch between train and test samples. RemixIT is based on a\ncontinuous self-training scheme in which a pre-trained teacher model on\nout-of-domain data infers estimated pseudo-target signals for in-domain\nmixtures. Then, by permuting the estimated clean and noise signals and remixing\nthem together, we generate a new set of bootstrapped mixtures and corresponding\npseudo-targets which are used to train the student network. Vice-versa, the\nteacher periodically refines its estimates using the updated parameters of the\nlatest student models. Experimental results on multiple speech enhancement\ndatasets and tasks not only show the superiority of our method over prior\napproaches but also showcase that RemixIT can be combined with any separation\nmodel as well as be applied towards any semi-supervised and unsupervised domain\nadaptation task. Our analysis, paired with empirical evidence, sheds light on\nthe inside functioning of our self-training scheme wherein the student model\nkeeps obtaining better performance while observing severely degraded\npseudo-targets.",
    "descriptor": "\nComments: Submitted to IEEE Journal of Selected Topics in Signal Processing\n",
    "authors": [
      "Efthymios Tzinis",
      "Yossi Adi",
      "Vamsi Krishna Ithapu",
      "Buye Xu",
      "Paris Smaragdis",
      "Anurag Kumar"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2202.08862"
  },
  {
    "id": "arXiv:2202.08867",
    "title": "Fast online inference for nonlinear contextual bandit based on  Generative Adversarial Network",
    "abstract": "This work addresses the efficiency concern on inferring a nonlinear\ncontextual bandit when the number of arms $n$ is very large. We propose a\nneural bandit model with an end-to-end training process to efficiently perform\nbandit algorithms such as Thompson Sampling and UCB during inference. We\nadvance state-of-the-art time complexity to $O(\\log n)$ with approximate\nBayesian inference, neural random feature mapping, approximate global maxima\nand approximate nearest neighbor search. We further propose a generative\nadversarial network to shift the bottleneck of maximizing the objective for\nselecting optimal arms from inference time to training time, enjoying\nsignificant speedup with additional advantage of enabling batch and parallel\nprocessing. %The generative model can inference an approximate argmax of the\nposterior sampling in logarithmic time complexity with the help of approximate\nnearest neighbor search. Extensive experiments on classification and\nrecommendation tasks demonstrate order-of-magnitude improvement in inference\ntime no significant degradation on the performance.",
    "descriptor": "",
    "authors": [
      "Yun Da Tsai",
      "Shou De Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.08867"
  },
  {
    "id": "arXiv:2202.08869",
    "title": "A recommender system for automatic picking of subsurface formation tops",
    "abstract": "Geoscience domain experts traditionally correlate formation tops in the\nsubsurface using geophysical well logs (known as well-log correlation) by-hand.\nBased on individual well log interpretation and well-to-well comparisons, these\ncorrelations are done in the context of depositional models within a\nstratigraphic framework. Recently, many researchers have focused on automatic\nwell-log correlation using a variety of warping algorithms that measure well\nsimilarity, and both unsupervised and supervised machine learning methods that\nassign categorical labels based on known tops in many other wells. These\nmethods require a standardized suite of digital well logs (i.e. gamma ray logs\nfor every well) along with the depth to the top of the formations, which might\nnot be available in many cases. Herein, we propose a method that does not use\ngeophysical well logs for correlation, but rather uses already picked tops in\nmultiple wells to recommend the depth to the remaining unpicked tops in the\nwells. This recommender system calculates the depth to all formation tops in\nall the wells for two different datasets in two different basins. The Teapot\nDome dataset is composed of lithostratigraphic formation tops, and the\nMannville Group dataset is composed of sequence-stratigraphic (representing\nmultiple lithologic groups within a stratigraphic unit) formation tops. For the\ndemonstration, mean absolute error and root mean squared error of four-fold\ncross-validation compares the recommender system predictions to the ground\ntruth human interpretations. The recommender system is competitive and often\noutperforms state of the art spline interpolation methods. Lastly, increasing\nthe size of the training dataset decreases the prediction error, and that\nvariance in error decreases with increasing formation tops picked in each\nformation and well for the lithostratigraphic top picks.",
    "descriptor": "\nComments: 14 pages, 9 figures, 2 tables, 2 appendices\n",
    "authors": [
      "Jesse R. Pisel",
      "Joshua A. Dierker",
      "Sanya Srivastava",
      "Samira B. Ravilisetty",
      "Michael J. Pyrcz"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2202.08869"
  },
  {
    "id": "arXiv:2202.08870",
    "title": "An Optimal Algorithm for Product Structure in Planar Graphs",
    "abstract": "The \\emph{Product Structure Theorem} for planar graphs (Dujmovi\\'c et al.\\\n\\emph{JACM}, \\textbf{67}(4):22) states that any planar graph is contained in\nthe strong product of a planar $3$-tree, a path, and a $3$-cycle. We give a\nsimple linear-time algorithm for finding this decomposition as well as several\nrelated decompositions. This improves on the previous $O(n\\log n)$ time\nalgorithm (Morin.\\ \\emph{Algorithmica}, \\textbf{85}(5):1544--1558).",
    "descriptor": "\nComments: 14 pages, 5 figures\n",
    "authors": [
      "Prosenjit Bose",
      "Pat Morin",
      "Saeed Odak"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2202.08870"
  },
  {
    "id": "arXiv:2202.08871",
    "title": "Graph Data Augmentation for Graph Machine Learning: A Survey",
    "abstract": "Data augmentation has recently seen increased interest in graph machine\nlearning given its ability of creating extra training data and improving model\ngeneralization. Despite this recent upsurge, this area is still relatively\nunderexplored, due to the challenges brought by complex, non-Euclidean\nstructure of graph data, which limits the direct analogizing of traditional\naugmentation operations on other types of data. In this paper, we present a\ncomprehensive and systematic survey of graph data augmentation that summarizes\nthe literature in a structured manner. We first categorize graph data\naugmentation operations based on the components of graph data they modify or\ncreate. Next, we introduce recent advances in graph data augmentation,\nseparating by their learning objectives and methodologies. We conclude by\noutlining currently unsolved challenges as well as directions for future\nresearch. Overall, this paper aims to clarify the landscape of existing\nliterature in graph data augmentation and motivate additional work in this\narea. We provide a GitHub repository\n(https://github.com/zhao-tong/graph-data-augmentation-papers) with a reading\nlist that will be continuously updated.",
    "descriptor": "",
    "authors": [
      "Tong Zhao",
      "Gang Liu",
      "Stephan G\u00fcnnemann",
      "Meng Jiang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.08871"
  },
  {
    "id": "arXiv:2202.08882",
    "title": "Improving English to Sinhala Neural Machine Translation using  Part-of-Speech Tag",
    "abstract": "The performance of Neural Machine Translation (NMT) depends significantly on\nthe size of the available parallel corpus. Due to this fact, low resource\nlanguage pairs demonstrate low translation performance compared to high\nresource language pairs. The translation quality further degrades when NMT is\nperformed for morphologically rich languages. Even though the web contains a\nlarge amount of information, most people in Sri Lanka are unable to read and\nunderstand English properly. Therefore, there is a huge requirement of\ntranslating English content to local languages to share information among\nlocals. Sinhala language is the primary language in Sri Lanka and building an\nNMT system that can produce quality English to Sinhala translations is\ndifficult due to the syntactic divergence between these two languages under low\nresource constraints. Thus, in this research, we explore effective methods of\nincorporating Part of Speech (POS) tags to the Transformer input embedding and\npositional encoding to further enhance the performance of the baseline English\nto Sinhala neural machine translation model.",
    "descriptor": "",
    "authors": [
      "Ravinga Perera",
      "Thilakshi Fonseka",
      "Rashmini Naranpanawa",
      "Uthayasanker Thayasivam"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.08882"
  },
  {
    "id": "arXiv:2202.08884",
    "title": "BADDr: Bayes-Adaptive Deep Dropout RL for POMDPs",
    "abstract": "While reinforcement learning (RL) has made great advances in scalability,\nexploration and partial observability are still active research topics. In\ncontrast, Bayesian RL (BRL) provides a principled answer to both state\nestimation and the exploration-exploitation trade-off, but struggles to scale.\nTo tackle this challenge, BRL frameworks with various prior assumptions have\nbeen proposed, with varied success. This work presents a\nrepresentation-agnostic formulation of BRL under partially observability,\nunifying the previous models under one theoretical umbrella. To demonstrate its\npractical significance we also propose a novel derivation, Bayes-Adaptive Deep\nDropout rl (BADDr), based on dropout networks. Under this parameterization, in\ncontrast to previous work, the belief over the state and dynamics is a more\nscalable inference problem. We choose actions through Monte-Carlo tree search\nand empirically show that our method is competitive with state-of-the-art BRL\nmethods on small domains while being able to solve much larger ones.",
    "descriptor": "",
    "authors": [
      "Sammie Katt",
      "Hai Nguyen",
      "Frans A. Oliehoek",
      "Christopher Amato"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.08884"
  },
  {
    "id": "arXiv:2202.08890",
    "title": "Deep Transfer Learning on Satellite Imagery Improves Air Quality  Estimates in Developing Nations",
    "abstract": "Urban air pollution is a public health challenge in low- and middle-income\ncountries (LMICs). However, LMICs lack adequate air quality (AQ) monitoring\ninfrastructure. A persistent challenge has been our inability to estimate AQ\naccurately in LMIC cities, which hinders emergency preparedness and risk\nmitigation. Deep learning-based models that map satellite imagery to AQ can be\nbuilt for high-income countries (HICs) with adequate ground data. Here we\ndemonstrate that a scalable approach that adapts deep transfer learning on\nsatellite imagery for AQ can extract meaningful estimates and insights in LMIC\ncities based on spatiotemporal patterns learned in HIC cities. The approach is\ndemonstrated for Accra in Ghana, Africa, with AQ patterns learned from two US\ncities, specifically Los Angeles and New York.",
    "descriptor": "\nComments: Under review\n",
    "authors": [
      "Nishant Yadav",
      "Meytar Sorek-Hamer",
      "Michael Von Pohle",
      "Ata Akbari Asanjan",
      "Adwait Sahasrabhojanee",
      "Esra Suel",
      "Raphael Arku",
      "Violet Lingenfelter",
      "Michael Brauer",
      "Majid Ezzati",
      "Nikunj Oza",
      "Auroop R. Ganguly"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.08890"
  },
  {
    "id": "arXiv:2202.08892",
    "title": "Developing Imperceptible Adversarial Patches to Camouflage Military  Assets From Computer Vision Enabled Technologies",
    "abstract": "Convolutional neural networks (CNNs) have demonstrated rapid progress and a\nhigh level of success in object detection. However, recent evidence has\nhighlighted their vulnerability to adversarial attacks. These attacks are\ncalculated image perturbations or adversarial patches that result in object\nmisclassification or detection suppression. Traditional camouflage methods are\nimpractical when applied to disguise aircraft and other large mobile assets\nfrom autonomous detection in intelligence, surveillance and reconnaissance\ntechnologies and fifth generation missiles. In this paper we present a unique\nmethod that produces imperceptible patches capable of camouflaging large\nmilitary assets from computer vision-enabled technologies. We developed these\npatches by maximising object detection loss whilst limiting the patch's colour\nperceptibility. This work also aims to further the understanding of adversarial\nexamples and their effects on object detection algorithms.",
    "descriptor": "\nComments: 8 pages, 4 figures, 4 tables, submitted to WCCI 2022\n",
    "authors": [
      "Christopher Wise",
      "Jo Plested"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.08892"
  },
  {
    "id": "arXiv:2202.08894",
    "title": "Continuous-Time vs. Discrete-Time Vision-based SLAM: A Comparative Study",
    "abstract": "Robotic practitioners generally approach the vision-based SLAM problem\nthrough discrete-time formulations. This has the advantage of a consolidated\ntheory and very good understanding of success and failure cases. However,\ndiscrete-time SLAM needs tailored algorithms and simplifying assumptions when\nhigh-rate and/or asynchronous measurements, coming from different sensors, are\npresent in the estimation process. Conversely, continuous-time SLAM, often\noverlooked by practitioners, does not suffer from these limitations. Indeed, it\nallows integrating new sensor data asynchronously without adding a new\noptimization variable for each new measurement. In this way, the integration of\nasynchronous or continuous high-rate streams of sensor data does not require\ntailored and highly-engineered algorithms, enabling the fusion of multiple\nsensor modalities in an intuitive fashion. On the down side, continuous time\nintroduces a prior that could worsen the trajectory estimates in some\nunfavorable situations. In this work, we aim at systematically comparing the\nadvantages and limitations of the two formulations in vision-based SLAM. To do\nso, we perform an extensive experimental analysis, varying robot type, speed of\nmotion, and sensor modalities. Our experimental analysis suggests that,\nindependently of the trajectory type, continuous-time SLAM is superior to its\ndiscrete counterpart whenever the sensors are not time-synchronized. In the\ncontext of this work, we developed, and open source, a modular and efficient\nsoftware architecture containing state-of-the-art algorithms to solve the SLAM\nproblem in discrete and continuous time.",
    "descriptor": "\nComments: IEEE Robotics and Automation Letters (RA-L), 2022\n",
    "authors": [
      "Giovanni Cioffi",
      "Titus Cieslewski",
      "Davide Scaramuzza"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.08894"
  },
  {
    "id": "arXiv:2202.08896",
    "title": "Computing list homomorphisms in geometric intersection graphs",
    "abstract": "A homomorphism from a graph $G$ to a graph $H$ is an edge-preserving mapping\nfrom $V(G)$ to $V(H)$. Let $H$ be a fixed graph with possible loops. In the\nlist homomorphism problem, denoted by \\textsc{LHom}($H$), the instance is a\ngraph $G$, whose every vertex is equipped with a subset of $V(H)$, called list.\nWe ask whether there exists a homomorphism from $G$ to $H$, such that every\nvertex from $G$ is mapped to a vertex from its list.\nWe study the complexity of the \\textsc{LHom}($H$) problem in intersection\ngraphs of various geometric objects. In particular, we are interested in\nanswering the question for what graphs $H$ and for what types of geometric\nobjects, the \\textsc{LHom}($H$) problem can be solved in time subexponential in\nthe number of vertices of the instance.\nWe fully resolve this question for string graphs, i.e., intersection graphs\nof continuous curves in the plane. Quite surprisingly, it turns out that the\ndichotomy exactly coincides with the analogous dichotomy for graphs excluding a\nfixed path as an induced subgraph [Okrasa, Rz\\k{a}\\.zewski, STACS 2021].\nThen we turn our attention to subclasses of string graphs, defined as\nintersections of fat objects. We observe that the (non)existence of\nsubexponential-time algorithms in such classes is closely related to the size\n$\\mathrm{mrc}(H)$ of a maximum reflexive clique in $H$, i.e., maximum number of\npairwise adjacent vertices, each of which has a loop. We study the maximum\nvalue of $\\mathrm{mrc}(H)$ that guarantees the existence of a\nsubexponential-time algorithm for \\textsc{LHom}($H$) in intersection graphs of\n(i) convex fat objects, (ii) fat similarly-sized objects, and (iii) disks. In\nthe first two cases we obtain optimal results, by giving matching algorithms\nand lower bounds.\nFinally, we discuss possible extensions of our results to weighted\ngeneralizations of \\textsc{LHom}($H$).",
    "descriptor": "",
    "authors": [
      "S\u00e1ndor Kisfaludi-Bak",
      "Karolina Okrasa",
      "Pawe\u0142 Rz\u0105\u017cewski"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2202.08896"
  },
  {
    "id": "arXiv:2202.08897",
    "title": "Implementing Spiking Neural Networks on Neuromorphic Architectures: A  Review",
    "abstract": "Recently, both industry and academia have proposed several different\nneuromorphic systems to execute machine learning applications that are designed\nusing Spiking Neural Networks (SNNs). With the growing complexity on design and\ntechnology fronts, programming such systems to admit and execute a machine\nlearning application is becoming increasingly challenging. Additionally,\nneuromorphic systems are required to guarantee real-time performance, consume\nlower energy, and provide tolerance to logic and memory failures. Consequently,\nthere is a clear need for system software frameworks that can implement machine\nlearning applications on current and emerging neuromorphic systems, and\nsimultaneously address performance, energy, and reliability. Here, we provide a\ncomprehensive overview of such frameworks proposed for both, platform-based\ndesign and hardware-software co-design. We highlight challenges and\nopportunities that the future holds in the area of system software technology\nfor neuromorphic computing.",
    "descriptor": "",
    "authors": [
      "Phu Khanh Huynh",
      "M. Lakshmi Varshika",
      "Ankita Paul",
      "Murat Isik",
      "Adarsha Balaji",
      "Anup Das"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2202.08897"
  },
  {
    "id": "arXiv:2202.08898",
    "title": "Word Embeddings for Automatic Equalization in Audio Mixing",
    "abstract": "In recent years, machine learning has been widely adopted to automate the\naudio mixing process. Automatic mixing systems have been applied to various\naudio effects such as gain-adjustment, stereo panning, equalization, and\nreverberation. These systems can be controlled through visual interfaces,\nproviding audio examples, using knobs, and semantic descriptors. Using semantic\ndescriptors or textual information to control these systems is an effective way\nfor artists to communicate their creative goals. Furthermore, sometimes artists\nuse non-technical words that may not be understood by the mixing system, or\neven a mixing engineer. In this paper, we explore the novel idea of using word\nembeddings to represent semantic descriptors. Word embeddings are generally\nobtained by training neural networks on large corpora of written text. These\nembeddings serve as the input layer of the neural network to create a\ntranslation from words to EQ settings. Using this technique, the machine\nlearning model can also generate EQ settings for semantic descriptors that it\nhas not seen before. We perform experiments to demonstrate the feasibility of\nthis idea. In addition, we compare the EQ settings of humans with the\npredictions of the neural network to evaluate the quality of predictions. The\nresults showed that the embedding layer enables the neural network to\nunderstand semantic descriptors. We observed that the models with embedding\nlayers perform better those without embedding layers, but not as good as human\nlabels.",
    "descriptor": "\nComments: 17 pages, 3 Figures, 2 tables; Submitted to Journal of Audio Engineering\n",
    "authors": [
      "Satvik Venkatesh",
      "David Moffat",
      "Eduardo Reck Miranda"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2202.08898"
  },
  {
    "id": "arXiv:2202.08900",
    "title": "Attributable Watermarking of Speech Generative Models",
    "abstract": "Generative models are now capable of synthesizing images, speeches, and\nvideos that are hardly distinguishable from authentic contents. Such\ncapabilities cause concerns such as malicious impersonation and IP theft. This\npaper investigates a solution for model attribution, i.e., the classification\nof synthetic contents by their source models via watermarks embedded in the\ncontents. Building on past success of model attribution in the image domain, we\ndiscuss algorithmic improvements for generating user-end speech models that\nempirically achieve high attribution accuracy, while maintaining high\ngeneration quality. We show the trade off between attributability and\ngeneration quality under a variety of attacks on generated speech signals\nattempting to remove the watermarks, and the feasibility of learning robust\nwatermarks against these attacks.",
    "descriptor": "\nComments: Accepted to International Conference on Acoustics, Speech and Signal Processing (ICASSP) 2022\n",
    "authors": [
      "Yongbaek Cho",
      "Changhoon Kim",
      "Yezhou Yang",
      "Yi Ren"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Cryptography and Security (cs.CR)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2202.08900"
  },
  {
    "id": "arXiv:2202.08901",
    "title": "The Effects of Interactive AI Design on User Behavior: An Eye-tracking  Study of Fact-checking COVID-19 Claims",
    "abstract": "We conducted a lab-based eye-tracking study to investigate how the\ninteractivity of an AI-powered fact-checking system affects user interactions,\nsuch as dwell time, attention, and mental resources involved in using the\nsystem. A within-subject experiment was conducted, where participants used an\ninteractive and a non-interactive version of a mock AI fact-checking system and\nrated their perceived correctness of COVID-19 related claims. We collected\nweb-page interactions, eye-tracking data, and mental workload using NASA-TLX.\nWe found that the presence of the affordance of interactively manipulating the\nAI system's prediction parameters affected users' dwell times, and\neye-fixations on AOIs, but not mental workload. In the interactive system,\nparticipants spent the most time evaluating claims' correctness, followed by\nreading news. This promising result shows a positive role of interactivity in a\nmixed-initiative AI-powered system.",
    "descriptor": "",
    "authors": [
      "Li Shi",
      "Nilavra Bhattacharya",
      "Anubrata Das",
      "Matthew Lease",
      "Jacek Gwidzka"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2202.08901"
  },
  {
    "id": "arXiv:2202.08902",
    "title": "Error estimation and adaptivity for stochastic collocation finite  elements Part II: multilevel approximation",
    "abstract": "A multilevel adaptive refinement strategy for solving linear elliptic partial\ndifferential equations with random data is recalled in this work. The strategy\nextends the a posteriori error estimation framework introduced by Guignard and\nNobile in 2018 (SIAM J. Numer. Anal, 56, 3121--3143) to cover problems with a\nnonaffine parametric coefficient dependence. A suboptimal, but nonetheless\nreliable and convenient implementation of the strategy involves approximation\nof the decoupled PDE problems with a common finite element approximation space.\nComputational results obtained using such a single-level strategy are presented\nin part I of this work (Bespalov, Silvester and Xu, arXiv:2109.07320). Results\nobtained using a potentially more efficient multilevel approximation strategy,\nwhere meshes are individually tailored, are discussed herein. The codes used to\ngenerate the numerical results are available online.",
    "descriptor": "\nComments: 16 pages, 7 figures. arXiv admin note: text overlap with arXiv:2109.07320\n",
    "authors": [
      "Alex Bespalov",
      "David J. Silvester"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.08902"
  },
  {
    "id": "arXiv:2202.08903",
    "title": "Dynamic Service Provisioning in the Edge-cloud Continuum with Provable  Guarantees",
    "abstract": "We consider a hierarchical edge-cloud architecture in which services are\nprovided to mobile users as chains of virtual network functions. Each service\nhas specific computation requirements and target delay performance, which\nrequire placing the corresponding chain properly and allocating a suitable\namount of computing resources. Furthermore, chain migration may be necessary to\nmeet the services' target delay, or convenient to keep the service provisioning\ncost low. We tackle such issues by formalizing the problem of optimal chain\nplacement and resource allocation in the edge-cloud continuum, taking into\naccount migration, bandwidth, and computation costs. Specifically, we first\nenvision an algorithm that, leveraging resource augmentation, addresses the\nabove problem and provides an upper bound to the amount of resources required\nto find a feasible solution. We use this algorithm as a building block to\ndevise an efficient approach targeting the minimum-cost solution, while\nminimizing the required resource augmentation. Our results, obtained through\ntrace-driven, large-scale simulations, show that our solution can provide a\nfeasible solution by using half the amount of resources required by\nstate-of-the-art alternatives.",
    "descriptor": "",
    "authors": [
      "Itamar Cohen",
      "Carla Fabiana Chiasserini",
      "Paolo Giaccone",
      "Gabriel Scalosub"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2202.08903"
  },
  {
    "id": "arXiv:2202.08904",
    "title": "SGPT: GPT Sentence Embeddings for Semantic Search",
    "abstract": "GPT transformers are the largest language models available, yet semantic\nsearch is dominated by BERT transformers. We present SGPT-BE and SGPT-CE for\napplying GPT models as Bi-Encoders or Cross-Encoders to symmetric or asymmetric\nsearch.\nSGPT-BE produces semantically meaningful sentence embeddings by contrastive\nfine-tuning of only bias tensors and a novel pooling method. A 5.8 billion\nparameter SGPT-BE outperforms the best available sentence embeddings by 6%\nsetting a new state-of-the-art on BEIR. It outperforms the concurrently\nproposed OpenAI Embeddings of the 175B Davinci endpoint, which fine-tunes\n250,000 times more parameters.\nSGPT-CE uses log probabilities from GPT models without any fine-tuning. A 6.1\nbillion parameter SGPT-CE sets an unsupervised state-of-the-art on BEIR. It\nbeats the supervised state-of-the-art on 7 datasets, but significantly loses on\nother datasets. We show how this can be alleviated by adapting the prompt.\nSGPT-BE and SGPT-CE performance scales with model size. Yet, increased\nlatency, storage and compute costs should be considered. Code, models and\nresult files are freely available at https://github.com/Muennighoff/sgpt.",
    "descriptor": "",
    "authors": [
      "Niklas Muennighoff"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2202.08904"
  },
  {
    "id": "arXiv:2202.08906",
    "title": "Designing Effective Sparse Expert Models",
    "abstract": "Scale has opened new frontiers in natural language processing -- but at a\nhigh cost. In response, Mixture-of-Experts (MoE) and Switch Transformers have\nbeen proposed as an energy efficient path to even larger and more capable\nlanguage models. But advancing the state-of-the-art across a broad set of\nnatural language tasks has been hindered by training instabilities and\nuncertain quality during fine-tuning. Our work focuses on these issues and acts\nas a design guide. We conclude by scaling a sparse model to 269B parameters,\nwith a computational cost comparable to a 32B dense encoder-decoder Transformer\n(Stable and Transferable Mixture-of-Experts or ST-MoE-32B). For the first time,\na sparse model achieves state-of-the-art performance in transfer learning,\nacross a diverse set of tasks including reasoning (SuperGLUE, ARC Easy, ARC\nChallenge), summarization (XSum, CNN-DM), closed book question answering\n(WebQA, Natural Questions), and adversarially constructed tasks (Winogrande,\nANLI R3).",
    "descriptor": "\nComments: 25 pages main text, 39 pages overall\n",
    "authors": [
      "Barret Zoph",
      "Irwan Bello",
      "Sameer Kumar",
      "Nan Du",
      "Yanping Huang",
      "Jeff Dean",
      "Noam Shazeer",
      "William Fedus"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.08906"
  },
  {
    "id": "arXiv:2202.08907",
    "title": "Sampling Approximately Low-Rank Ising Models: MCMC meets Variational  Methods",
    "abstract": "We consider Ising models on the hypercube with a general interaction matrix\n$J$, and give a polynomial time sampling algorithm when all but $O(1)$\neigenvalues of $J$ lie in an interval of length one, a situation which occurs\nin many models of interest. This was previously known for the Glauber dynamics\nwhen *all* eigenvalues fit in an interval of length one; however, a single\noutlier can force the Glauber dynamics to mix torpidly. Our general result\nimplies the first polynomial time sampling algorithms for low-rank Ising models\nsuch as Hopfield networks with a fixed number of patterns and Bayesian\nclustering models with low-dimensional contexts, and greatly improves the\npolynomial time sampling regime for the antiferromagnetic/ferromagnetic Ising\nmodel with inconsistent field on expander graphs. It also improves on previous\napproximation algorithm results based on the naive mean-field approximation in\nvariational methods and statistical physics.\nOur approach is based on a new fusion of ideas from the MCMC and variational\ninference worlds. As part of our algorithm, we define a new nonconvex\nvariational problem which allows us to sample from an exponential reweighting\nof a distribution by a negative definite quadratic form, and show how to make\nthis procedure provably efficient using stochastic gradient descent. On top of\nthis, we construct a new simulated tempering chain (on an extended state space\narising from the Hubbard-Stratonovich transform) which overcomes the obstacle\nposed by large positive eigenvalues, and combine it with the SGD-based sampler\nto solve the full problem.",
    "descriptor": "\nComments: 43 pages\n",
    "authors": [
      "Frederic Koehler",
      "Holden Lee",
      "Andrej Risteski"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)",
      "Probability (math.PR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.08907"
  },
  {
    "id": "arXiv:2202.08909",
    "title": "Proofs, Circuits, and Communication",
    "abstract": "We survey lower-bound results in complexity theory that have been obtained\nvia newfound interconnections between propositional proof complexity, boolean\ncircuit complexity, and query/communication complexity. We advocate for the\ntheory of total search problems (TFNP) as a unifying language for these\nconnections and discuss how this perspective suggests a whole programme for\nfurther research.",
    "descriptor": "",
    "authors": [
      "Susanna F. de Rezende",
      "Mika G\u00f6\u00f6s",
      "Robert Robere"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2202.08909"
  },
  {
    "id": "arXiv:2202.08910",
    "title": "Combining Varied Learners for Binary Classification using Stacked  Generalization",
    "abstract": "The Machine Learning has various learning algorithms that are better in some\nor the other aspect when compared with each other but a common error that all\nalgorithms will suffer from is training data with very high dimensional feature\nset. This usually ends up algorithms into generalization error that deplete the\nperformance. This can be solved using an Ensemble Learning method known as\nStacking commonly termed as Stacked Generalization. In this paper we perform\nbinary classification using Stacked Generalization on high dimensional\nPolycystic Ovary Syndrome dataset and prove the point that model becomes\ngeneralized and metrics improve significantly. The various metrics are given in\nthis paper that also point out a subtle transgression found with Receiver\nOperating Characteristic Curve that was proved to be incorrect.",
    "descriptor": "\nComments: 9 pages, 4 figures, 5 tables, 8 equations\n",
    "authors": [
      "Sruthi Nair",
      "Abhishek Gupta",
      "Raunak Joshi",
      "Vidya Chitre"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.08910"
  },
  {
    "id": "arXiv:2202.08913",
    "title": "Machine learning models and facial regions videos for estimating heart  rate: a review on Patents, Datasets and Literature",
    "abstract": "Estimating heart rate is important for monitoring users in various\nsituations. Estimates based on facial videos are increasingly being researched\nbecause it makes it possible to monitor cardiac information in a non-invasive\nway and because the devices are simpler, requiring only cameras that capture\nthe user's face. From these videos of the user's face, machine learning is able\nto estimate heart rate. This study investigates the benefits and challenges of\nusing machine learning models to estimate heart rate from facial videos,\nthrough patents, datasets, and articles review. We searched Derwent Innovation,\nIEEE Xplore, Scopus, and Web of Science knowledge bases and identified 7 patent\nfilings, 11 datasets, and 20 articles on heart rate, photoplethysmography, or\nelectrocardiogram data. In terms of patents, we note the advantages of\ninventions related to heart rate estimation, as described by the authors. In\nterms of datasets, we discovered that most of them are for academic purposes\nand with different signs and annotations that allow coverage for subjects other\nthan heartbeat estimation. In terms of articles, we discovered techniques, such\nas extracting regions of interest for heart rate reading and using Video\nMagnification for small motion extraction, and models such as EVM-CNN and\nVGG-16, that extract the observed individual's heart rate, the best regions of\ninterest for signal extraction and ways to process them.",
    "descriptor": "",
    "authors": [
      "Tiago Palma Pagano",
      "Lucas Lemos Ortega",
      "Victor Rocha Santos",
      "Yasmin da Silva Bonfim",
      "Jos\u00e9 Vin\u00edcius Dantas Paranhos",
      "Paulo Henrique Miranda S\u00e1",
      "Lian Filipe Santana Nascimento",
      "Ingrid Winkler",
      "Erick Giovani Sperandio Nascimento"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2202.08913"
  },
  {
    "id": "arXiv:2202.08917",
    "title": "Discovering Fine-Grained Semantics in Knowledge Graph Relations",
    "abstract": "When it comes to comprehending and analyzing multi-relational data, the\nsemantics of relations are crucial. Polysemous relations between different\ntypes of entities, that represent multiple semantics, are common in real-world\nrelational datasets represented by knowledge graphs. For numerous use cases,\nsuch as entity type classification, question answering and knowledge graph\ncompletion, the correct semantic interpretation of these relations is\nnecessary. In this work, we provide a strategy for discovering the different\nsemantics associated with abstract relations and deriving many sub-relations\nwith fine-grained meaning. To do this, we leverage the types of the entities\nassociated with the relations and cluster the vector representations of\nentities and relations. The suggested method is able to automatically discover\nthe best number of sub-relations for a polysemous relation and determine their\nsemantic interpretation, according to our empirical evaluation.",
    "descriptor": "\nComments: 10 pages, 2 figures, 4 tables\n",
    "authors": [
      "Nitisha Jain",
      "Ralf Krestel"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.08917"
  },
  {
    "id": "arXiv:2202.08922",
    "title": "FLAME: Federated Learning Across Multi-device Environments",
    "abstract": "Federated Learning (FL) enables distributed training of machine learning\nmodels while keeping personal data on user devices private. While we witness\nincreasing applications of FL in the area of mobile sensing, such as\nhuman-activity recognition, FL has not been studied in the context of a\nmulti-device environment (MDE), wherein each user owns multiple data-producing\ndevices. With the proliferation of mobile and wearable devices, MDEs are\nincreasingly becoming popular in ubicomp settings, therefore necessitating the\nstudy of FL in them. FL in MDEs is characterized by high non-IID-ness across\nclients, complicated by the presence of both user and device heterogeneities.\nFurther, ensuring efficient utilization of system resources on FL clients in a\nMDE remains an important challenge. In this paper, we propose FLAME, a\nuser-centered FL training approach to counter statistical and system\nheterogeneity in MDEs, and bring consistency in inference performance across\ndevices. FLAME features (i) user-centered FL training utilizing the time\nalignment across devices from the same user; (ii) accuracy- and\nefficiency-aware device selection; and (iii) model personalization to devices.\nWe also present an FL evaluation testbed with realistic energy drain and\nnetwork bandwidth profiles, and a novel class-based data partitioning scheme to\nextend existing HAR datasets to a federated setup. Our experiment results on\nthree multi-device HAR datasets show that FLAME outperforms various baselines\nby 4.8-33.8% higher F-1 score, 1.02-2.86x greater energy efficiency, and up to\n2.02x speedup in convergence to target accuracy through fair distribution of\nthe FL workload.",
    "descriptor": "",
    "authors": [
      "Hyunsung Cho",
      "Akhil Mathur",
      "Fahim Kawsar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.08922"
  },
  {
    "id": "arXiv:2202.08926",
    "title": "On Guiding Visual Attention with Language Specification",
    "abstract": "While real world challenges typically define visual categories with language\nwords or phrases, most visual classification methods define categories with\nnumerical indices. However, the language specification of the classes provides\nan especially useful prior for biased and noisy datasets, where it can help\ndisambiguate what features are task-relevant. Recently, large-scale multimodal\nmodels have been shown to recognize a wide variety of high-level concepts from\na language specification even without additional image training data, but they\nare often unable to distinguish classes for more fine-grained tasks. CNNs, in\ncontrast, can extract subtle image features that are required for fine-grained\ndiscrimination, but will overfit to any bias or noise in datasets. Our insight\nis to use high-level language specification as advice for constraining the\nclassification evidence to task-relevant features, instead of distractors. To\ndo this, we ground task-relevant words or phrases with attention maps from a\npretrained large-scale model. We then use this grounding to supervise a\nclassifier's spatial attention away from distracting context. We show that\nsupervising spatial attention in this way improves performance on\nclassification tasks with biased and noisy data, including about 3-15%\nworst-group accuracy improvements and 41-45% relative improvements on fairness\nmetrics.",
    "descriptor": "\nComments: 14 pages, 9 figures\n",
    "authors": [
      "Suzanne Petryk",
      "Lisa Dunlap",
      "Keyan Nasseri",
      "Joseph Gonzalez",
      "Trevor Darrell",
      "Anna Rohrbach"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.08926"
  },
  {
    "id": "arXiv:2202.08931",
    "title": "Desingularization and p-Curvature of Recurrence Operators",
    "abstract": "Linear recurrence operators in characteristic $p$ are classified by their\n$p$-curvature. For a recurrence operator $L$, denote by $\\chi(L)$ the\ncharacteristic polynomial of its $p$-curvature. We can obtain information about\nthe factorization of $L$ by factoring $\\chi(L)$. The main theorem of this paper\ngives an unexpected relation between $\\chi(L)$ and the true singularities of\n$L$. An application is to speed up a fast algorithm for computing $\\chi(L)$ by\ndesingularizing $L$ first. Another contribution of this paper is faster\ndesingularization.",
    "descriptor": "\nComments: 7 pages\n",
    "authors": [
      "Yi Zhou",
      "Mark van Hoeij"
    ],
    "subjectives": [
      "Symbolic Computation (cs.SC)"
    ],
    "url": "https://arxiv.org/abs/2202.08931"
  },
  {
    "id": "arXiv:2202.08933",
    "title": "Design of EMG-driven Musculoskeletal Model for Volitional Control of a  Robotic Ankle Prosthesis",
    "abstract": "Existing robotic lower-limb prostheses use autonomous control to address\ncyclic, locomotive tasks, but they are inadequate to operate the prosthesis for\ndaily activities that are non-cyclic and unpredictable. To address this\nchallenge, this study aims to design a novel electromyography (EMG)-driven\nmusculoskeletal model for volitional control of a robotic ankle-foot\nprosthesis. This controller places the user in continuous control of the\ndevice, allowing them to freely manipulate the prosthesis behavior at will. The\nHill-type muscle model was used to model a dorsiflexor and a plantarflexor,\nwhich functioned around a virtual ankle joint. The model parameters were\ndetermined by fitting the model prediction to the experimental data collected\nfrom an able-bodied subject. EMG signals recorded from ankle agonist and\nantagonist muscle pair were used to activate the virtual muscle models. This\nmodel was validated via offline simulations and real-time prosthesis control.\nAdditionally, the feasibility of the proposed prosthesis control on assisting\nthe user's functional tasks was demonstrated. The present control may further\nimprove the function of robotic prosthesis for supporting versatile activities\nin individuals with lower-limb amputations.",
    "descriptor": "\nComments: 6 page conference submission pre-print\n",
    "authors": [
      "Chinmay Shah",
      "Aaron Fleming",
      "Varun Nalam",
      "Huang"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.08933"
  },
  {
    "id": "arXiv:2202.08934",
    "title": "Handling Imbalanced Datasets Through Optimum-Path Forest",
    "abstract": "In the last decade, machine learning-based approaches became capable of\nperforming a wide range of complex tasks sometimes better than humans,\ndemanding a fraction of the time. Such an advance is partially due to the\nexponential growth in the amount of data available, which makes it possible to\nextract trustworthy real-world information from them. However, such data is\ngenerally imbalanced since some phenomena are more likely than others. Such a\nbehavior yields considerable influence on the machine learning model's\nperformance since it becomes biased on the more frequent data it receives.\nDespite the considerable amount of machine learning methods, a graph-based\napproach has attracted considerable notoriety due to the outstanding\nperformance over many applications, i.e., the Optimum-Path Forest (OPF). In\nthis paper, we propose three OPF-based strategies to deal with the imbalance\nproblem: the $\\text{O}^2$PF and the OPF-US, which are novel approaches for\noversampling and undersampling, respectively, as well as a hybrid strategy\ncombining both approaches. The paper also introduces a set of variants\nconcerning the strategies mentioned above. Results compared against several\nstate-of-the-art techniques over public and private datasets confirm the\nrobustness of the proposed approaches.",
    "descriptor": "",
    "authors": [
      "Leandro Aparecido Passos",
      "Danilo S. Jodas",
      "Luiz C. F. Ribeiro",
      "Marco Akio",
      "Andre Nunes de Souza",
      "Jo\u00e3o Paulo Papa"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.08934"
  },
  {
    "id": "arXiv:2202.08935",
    "title": "A Formal Safety Characterization of Advanced Driver Assist Systems in  the Car-Following Regime with Scenario-Sampling",
    "abstract": "The capability to follow a lead-vehicle and avoid rear-end collisions is one\nof the most important functionalities for human drivers and various Advanced\nDriver Assist Systems (ADAS). Existing safety performance justification of the\ncar-following systems either relies on simple concrete scenarios with biased\nsurrogate metrics or requires a significantly long driving distance for risk\nobservation and inference. In this paper, we propose a guaranteed unbiased and\nsampling efficient scenario-based safety evaluation framework inspired by the\nprevious work on $\\epsilon\\delta$-almost safe set quantification. The proposal\ncharacterizes the complete safety performance of the test subject in the\ncar-following regime. The performance of the proposed method is also\ndemonstrated in challenging cases including some widely adopted car-following\ndecision-making modules and the commercially available Openpilot driving stack\nby CommaAI.",
    "descriptor": "",
    "authors": [
      "Bowen Weng",
      "Minghao Zhu",
      "Keith Redmill"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.08935"
  },
  {
    "id": "arXiv:2202.08937",
    "title": "When, Why, and Which Pretrained GANs Are Useful?",
    "abstract": "The literature has proposed several methods to finetune pretrained GANs on\nnew datasets, which typically results in higher performance compared to\ntraining from scratch, especially in the limited-data regime. However, despite\nthe apparent empirical benefits of GAN pretraining, its inner mechanisms were\nnot analyzed in-depth, and understanding of its role is not entirely clear.\nMoreover, the essential practical details, e.g., selecting a proper pretrained\nGAN checkpoint, currently do not have rigorous grounding and are typically\ndetermined by trial and error.\nThis work aims to dissect the process of GAN finetuning. First, we show that\ninitializing the GAN training process by a pretrained checkpoint primarily\naffects the model's coverage rather than the fidelity of individual samples.\nSecond, we explicitly describe how pretrained generators and discriminators\ncontribute to the finetuning process and explain the previous evidence on the\nimportance of pretraining both of them. Finally, as an immediate practical\nbenefit of our analysis, we describe a simple recipe to choose an appropriate\nGAN checkpoint that is the most suitable for finetuning to a particular target\ntask. Importantly, for most of the target tasks, Imagenet-pretrained GAN,\ndespite having poor visual quality, appears to be an excellent starting point\nfor finetuning, resembling the typical pretraining scenario of discriminative\ncomputer vision models.",
    "descriptor": "",
    "authors": [
      "Timofey Grigoryev",
      "Andrey Voynov",
      "Artem Babenko"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.08937"
  },
  {
    "id": "arXiv:2202.08938",
    "title": "Improving Intrinsic Exploration with Language Abstractions",
    "abstract": "Reinforcement learning (RL) agents are particularly hard to train when\nrewards are sparse. One common solution is to use intrinsic rewards to\nencourage agents to explore their environment. However, recent intrinsic\nexploration methods often use state-based novelty measures which reward\nlow-level exploration and may not scale to domains requiring more abstract\nskills. Instead, we explore natural language as a general medium for\nhighlighting relevant abstractions in an environment. Unlike previous work, we\nevaluate whether language can improve over existing exploration methods by\ndirectly extending (and comparing to) competitive intrinsic exploration\nbaselines: AMIGo (Campero et al., 2021) and NovelD (Zhang et al., 2021). These\nlanguage-based variants outperform their non-linguistic forms by 45-85% across\n13 challenging tasks from the MiniGrid and MiniHack environment suites.",
    "descriptor": "",
    "authors": [
      "Jesse Mu",
      "Victor Zhong",
      "Roberta Raileanu",
      "Minqi Jiang",
      "Noah Goodman",
      "Tim Rockt\u00e4schel",
      "Edward Grefenstette"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.08938"
  },
  {
    "id": "arXiv:2202.08942",
    "title": "Enhanced DeepONet for Modeling Partial Differential Operators  Considering Multiple Input Functions",
    "abstract": "Machine learning, especially deep learning is gaining much attention due to\nthe breakthrough performance in various cognitive applications. Recently,\nneural networks (NN) have been intensively explored to model partial\ndifferential equations as NN can be viewed as universal approximators for\nnonlinear functions. A deep network operator (DeepONet) architecture was\nproposed to model the general non-linear continuous operators for partial\ndifferential equations (PDE) due to its better generalization capabilities than\nexisting mainstream deep neural network architectures. However, existing\nDeepONet can only accept one input function, which limits its application. In\nthis work, we explore the DeepONet architecture to extend it to accept two or\nmore input functions. We propose new Enhanced DeepONet or EDeepONet high-level\nneural network structure, in which two input functions are represented by two\nbranch DNN sub-networks, which are then connected with output truck network via\ninner product to generate the output of the whole neural network. The proposed\nEDeepONet structure can be easily extended to deal with multiple input\nfunctions. Our numerical results on modeling two partial differential equation\nexamples shows that the proposed enhanced DeepONet is about 7X-17X or about one\norder of magnitude more accurate than the fully connected neural network and is\nabout 2X-3X more accurate than a simple extended DeepONet for both training and\ntest.",
    "descriptor": "\nComments: This paper was performed in the summer 2021 and the manuscript was submitted for review in Sept 2021\n",
    "authors": [
      "Lesley Tan",
      "Liang Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.08942"
  },
  {
    "id": "arXiv:2202.08944",
    "title": "Rethinking Machine Learning Robustness via its Link with the  Out-of-Distribution Problem",
    "abstract": "Despite multiple efforts made towards robust machine learning (ML) models,\ntheir vulnerability to adversarial examples remains a challenging problem that\ncalls for rethinking the defense strategy. In this paper, we take a step back\nand investigate the causes behind ML models' susceptibility to adversarial\nexamples. In particular, we focus on exploring the cause-effect link between\nadversarial examples and the out-of-distribution (OOD) problem. To that end, we\npropose an OOD generalization method that stands against both adversary-induced\nand natural distribution shifts. Through an OOD to in-distribution mapping\nintuition, our approach translates OOD inputs to the data distribution used to\ntrain and test the model. Through extensive experiments on three benchmark\nimage datasets of different scales (MNIST, CIFAR10, and ImageNet) and by\nleveraging image-to-image translation methods, we confirm that the adversarial\nexamples problem is a special case of the wider OOD generalization problem.\nAcross all datasets, we show that our translation-based approach consistently\nimproves robustness to OOD adversarial inputs and outperforms state-of-the-art\ndefenses by a significant margin, while preserving the exact accuracy on benign\n(in-distribution) data. Furthermore, our method generalizes on naturally OOD\ninputs such as darker or sharper images",
    "descriptor": "\nComments: 13 pages\n",
    "authors": [
      "Abderrahmen Amich",
      "Birhanu Eshete"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.08944"
  },
  {
    "id": "arXiv:2202.08946",
    "title": "Symphony: Composing Interactive Interfaces for Machine Learning",
    "abstract": "Interfaces for machine learning (ML), information and visualizations about\nmodels or data, can help practitioners build robust and responsible ML systems.\nDespite their benefits, recent studies of ML teams and our interviews with\npractitioners (n=9) showed that ML interfaces have limited adoption in\npractice. While existing ML interfaces are effective for specific tasks, they\nare not designed to be reused, explored, and shared by multiple stakeholders in\ncross-functional teams. To enable analysis and communication between different\nML practitioners, we designed and implemented Symphony, a framework for\ncomposing interactive ML interfaces with task-specific, data-driven components\nthat can be used across platforms such as computational notebooks and web\ndashboards. We developed Symphony through participatory design sessions with 10\nteams (n=31), and discuss our findings from deploying Symphony to 3 production\nML projects at Apple. Symphony helped ML practitioners discover previously\nunknown issues like data duplicates and blind spots in models while enabling\nthem to share insights with other stakeholders.",
    "descriptor": "\nComments: Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems\n",
    "authors": [
      "Alex B\u00e4uerle",
      "\u00c1ngel Alexander Cabrera",
      "Fred Hohman",
      "Megan Maher",
      "David Koski",
      "Xavier Suau",
      "Titus Barik",
      "Dominik Moritz"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.08946"
  },
  {
    "id": "arXiv:2202.08948",
    "title": "SKaMPI-OpenSHMEM: Measuring OpenSHMEM Communication Routines",
    "abstract": "Benchmarking is an important challenge in HPC, in particular, to be able to\ntune the basic blocks of the software environment used by applications. The\ncommunication library and distributed run-time environment are among the most\ncritical ones. In particular, many of the routines provided by communication\nlibraries can be adjusted using parameters such as buffer sizes and\ncommunication algorithm. As a consequence, being able to measure accurately the\ntime taken by these routines is crucial in order to optimize them and achieve\nthe best performance. For instance, the SKaMPI library was designed to measure\nthe time taken by MPI routines, relying on MPI's two-sided communication model\nto measure one-sided and two-sided peer-to-peer communication and collective\nroutines. In this paper, we discuss the benchmarking challenges specific to\nOpenSHMEM's communication model, mainly to avoid inter-call pipelining and\noverlapping when measuring the time taken by its routines. We extend SKaMPI for\nOpenSHMEM for this purpose and demonstrate measurement algorithms that address\nOpenSHMEM's communication model in practice. Scaling experiments are run on the\nSummit platform to compare different benchmarking approaches on the SKaMPI\nbenchmark operations. These show the advantages of our techniques for more\naccurate performance characterization.",
    "descriptor": "\nComments: 17 pages, OpenSHMEM workshop 2021\n",
    "authors": [
      "Camille Coti",
      "Allen D. Malony"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2202.08948"
  },
  {
    "id": "arXiv:2202.08951",
    "title": "Programming of linear virtual element methods in three dimensions",
    "abstract": "We present a simple and efficient MATLAB implementation of the linear virtual\nelement method for the three dimensional Poisson equation. The purpose of this\nsoftware is primarily educational, to demonstrate how the key components of the\nmethod can be translated into code.",
    "descriptor": "\nComments: VEM3d code\n",
    "authors": [
      "Yue Yu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.08951"
  },
  {
    "id": "arXiv:2202.08952",
    "title": "An Energy-Efficient and Runtime-Reconfigurable FPGA-Based Accelerator  for Robotic Localization Systems",
    "abstract": "Simultaneous Localization and Mapping (SLAM) estimates agents' trajectories\nand constructs maps, and localization is a fundamental kernel in autonomous\nmachines at all computing scales, from drones, AR, VR to self-driving cars. In\nthis work, we present an energy-efficient and runtime-reconfigurable FPGA-based\naccelerator for robotic localization. We exploit SLAM-specific data locality,\nsparsity, reuse, and parallelism, and achieve >5x performance improvement over\nthe state-of-the-art. Especially, our design is reconfigurable at runtime\naccording to the environment to save power while sustaining accuracy and\nperformance.",
    "descriptor": "\nComments: 2 pages, 6 figures, IEEE Custom Integrated Circuits Conference (CICC), April 24-27, 2022, Newport Beach, CA, USA\n",
    "authors": [
      "Qiang Liu",
      "Zishen Wan",
      "Bo Yu",
      "Weizhuang Liu",
      "Shaoshan Liu",
      "Arijit Raychowdhury"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2202.08952"
  },
  {
    "id": "arXiv:2202.08953",
    "title": "Classification of ADHD Patients by Kernel Hierarchical Extreme Learning  Machine",
    "abstract": "These days, the diagnosis of neuropsychiatric diseases through brain imaging\ntechnology has received more and more attention. The exploration of\ninteractions in brain functional connectivity based on functional magnetic\nresonance imaging (fMRI) data is critical for the study of mental illness.\nBecause attention-deficit/hyperactivity disorder (ADHD) is a chronic disease\nthat affects millions of children, it is difficult to diagnose, so there is\nstill much space for improvement in the accuracy of the diagnosis of the\ndisease. In this paper, we consider the dynamics of brain functional\nconnectivity, modeling a functional brain dynamics model from medical imaging,\nwhich helps to find differences in brain function interactions between normal\ncontrol (NC) children and ADHD children. In more detail, our method is used by\nBayesian Connectivity Change Point Model for dynamic detection, Local Binary\nEncoding Method for local feature extraction, and Kernel Hierarchical Extreme\nLearning Machine implementation classification. To validate our approach,\nexperimental comparisons of fMRI imaging data on 23 ADHD and 45 NC children\nwere performed, and our experimental methods achieved better classification\nresults than existing methods.",
    "descriptor": "",
    "authors": [
      "Sartaj Ahmed Salman",
      "Zhichao Lian",
      "Yuduo Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.08953"
  },
  {
    "id": "arXiv:2202.08955",
    "title": "R2-D2: Repetitive Reprediction Deep Decipher for Semi-Supervised Deep  Learning",
    "abstract": "Most recent semi-supervised deep learning (deep SSL) methods used a similar\nparadigm: use network predictions to update pseudo-labels and use pseudo-labels\nto update network parameters iteratively. However, they lack theoretical\nsupport and cannot explain why predictions are good candidates for\npseudo-labels in the deep learning paradigm. In this paper, we propose a\nprincipled end-to-end framework named deep decipher (D2) for SSL. Within the D2\nframework, we prove that pseudo-labels are related to network predictions by an\nexponential link function, which gives a theoretical support for using\npredictions as pseudo-labels. Furthermore, we demonstrate that updating\npseudo-labels by network predictions will make them uncertain. To mitigate this\nproblem, we propose a training strategy called repetitive reprediction (R2).\nFinally, the proposed R2-D2 method is tested on the large-scale ImageNet\ndataset and outperforms state-of-the-art methods by 5 percentage points.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:1908.04345\n",
    "authors": [
      "Guo-Hua Wang",
      "Jianxin Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.08955"
  },
  {
    "id": "arXiv:2202.08959",
    "title": "Deep Interest Highlight Network for Click-Through RatePrediction in  Trigger-Induced Recommendation",
    "abstract": "In many classical e-commerce platforms, personalized recommendation has been\nproven to be of great business value, which can improve user satisfaction and\nincrease the revenue of platforms. In this paper, we present a new\nrecommendation problem, Trigger-Induced Recommendation (TIR), where users'\ninstant interest can be explicitly induced with a trigger item and follow-up\nrelated target items are recommended accordingly. TIR has become ubiquitous and\npopular in e-commerce platforms. In this paper, we figure out that although\nexisting recommendation models are effective in traditional recommendation\nscenarios by mining users' interests based on their massive historical\nbehaviors, they are struggling in discovering users' instant interests in the\nTIR scenario due to the discrepancy between these scenarios, resulting in\ninferior performance. To tackle the problem, we propose a novel recommendation\nmethod named Deep Interest Highlight Network (DIHN) for Click-Through Rate\n(CTR) prediction in TIR scenarios. It has three main components including 1)\nUser Intent Network (UIN), which responds to generate a precise probability\nscore to predict user's intent on the trigger item; 2) Fusion Embedding Module\n(FEM), which adaptively fuses trigger item and target item embeddings based on\nthe prediction from UIN; and (3) Hybrid Interest Extracting Module (HIEM),\nwhich can effectively highlight users' instant interest from their behaviors\nbased on the result of FEM. Extensive offline and online evaluations on a\nreal-world e-commerce platform demonstrate the superiority of DIHN over\nstate-of-the-art methods.",
    "descriptor": "\nComments: Accepted by WWW 2022\n",
    "authors": [
      "Qijie Shen",
      "Hong Wen",
      "Wanjie Tao",
      "Jing Zhang",
      "Fuyu Lv",
      "Zulong Chen",
      "Zhao Li"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.08959"
  },
  {
    "id": "arXiv:2202.08960",
    "title": "Toward a traceable, explainable, and fairJD/Resume recommendation system",
    "abstract": "In the last few decades, companies are interested to adopt an online\nautomated recruitment process in an international recruitment environment. The\nproblem is that the recruitment of employees through the manual procedure is a\ntime and money consuming process. As a result, processing a significant number\nof applications through conventional methods can lead to the recruitment of\nclumsy individuals. Different JD/Resume matching model architectures have been\nproposed and reveal a high accuracy level in selecting relevant candidatesfor\nthe required job positions. However, the development of an automatic\nrecruitment system is still one of the main challenges. The reason is that the\ndevelopment of a fully automated recruitment system is a difficult task and\nposes different challenges. For example, providing a detailed matching\nexplanation for the targeted stakeholders is needed to ensure a transparent\nrecommendation. There are several knowledge bases that represent skills and\ncompetencies (e.g, ESCO, O*NET) that are used to identify the candidate and the\nrequired job skills for a matching purpose. Besides, modernpre-trained language\nmodels are fine-tuned for this context such as identifying lines where a\nspecific feature was introduced. Typically, pre-trained language models use\ntransfer-based machine learning models to be fine-tuned for a specific field.\nIn this proposal, our aim is to explore how modern language models (based on\ntransformers) can be combined with knowledge bases and ontologies to enhance\nthe JD/Resume matching process. Our system aims at using knowledge bases and\nfeatures to support the explainability of the JD/Resume matching. Finally,\ngiven that multiple software components, datasets, ontology, andmachine\nlearning models will be explored, we aim at proposing a fair, ex-plainable, and\ntraceable architecture for a Resume/JD matching purpose.",
    "descriptor": "",
    "authors": [
      "Amine Barrak",
      "Bram Adams",
      "Amal Zouaq"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.08960"
  },
  {
    "id": "arXiv:2202.08963",
    "title": "Understanding and Shifting Preferences for Battery Electric Vehicles",
    "abstract": "Identifying personalized interventions for an individual is an important\ntask. Recent work has shown that interventions that do not consider the\ndemographic background of individual consumers can, in fact, produce the\nreverse effect, strengthening opposition to electric vehicles. In this work, we\nfocus on methods for personalizing interventions based on an individual's\ndemographics to shift the preferences of consumers to be more positive towards\nBattery Electric Vehicles (BEVs). One of the constraints in building models to\nsuggest interventions for shifting preferences is that each intervention can\ninfluence the effectiveness of later interventions. This, in turn, requires\nmany subjects to evaluate effectiveness of each possible intervention. To\naddress this, we propose to identify personalized factors influencing BEV\nadoption, such as barriers and motivators. We present a method for predicting\nthese factors and show that the performance is better than always predicting\nthe most frequent factors. We then present a Reinforcement Learning (RL) model\nthat learns the most effective interventions, and compare the number of\nsubjects required for each approach.",
    "descriptor": "\nComments: 5 pages, 5 figures\n",
    "authors": [
      "Nikos Arechiga",
      "Francine Chen",
      "Rumen Iliev",
      "Emily Sumner",
      "Scott Carter",
      "Alex Filipowicz",
      "Nayeli Bravo",
      "Monica Van",
      "Kate Glazko",
      "Kalani Murakami",
      "Laurent Denoue",
      "Candice Hogan",
      "Katharine Sieck",
      "Charlene Wu",
      "Kent Lyons"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.08963"
  },
  {
    "id": "arXiv:2202.08964",
    "title": "Simulating User-Level Twitter Activity with XGBoost and Probabilistic  Hybrid Models",
    "abstract": "The Volume-Audience-Match simulator, or VAM was applied to predict future\nactivity on Twitter related to international economic affairs. VAM was applied\nto do timeseries forecasting to predict the: (1) number of total activities,\n(2) number of active old users, and (3) number of newly active users over the\nspan of 24 hours from the start time of prediction. VAM then used these volume\npredictions to perform user link predictions. A user-user edge was assigned to\neach of the activities in the 24 future timesteps. VAM considerably\noutperformed a set of baseline models in both the time series and\nuser-assignment tasks",
    "descriptor": "",
    "authors": [
      "Fred Mubang",
      "Lawrence Hall"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2202.08964"
  },
  {
    "id": "arXiv:2202.08965",
    "title": "High-performance automatic categorization and attribution of inventory  catalogs",
    "abstract": "Techniques of machine learning for automatic text categorization are applied\nand adapted for the problem of inventory catalog data attribution, with\ndifferent approaches explored and optimal solution addressing the tradeoff\nbetween accuracy and performance is selected.",
    "descriptor": "\nComments: 9 pages, 4 figures\n",
    "authors": [
      "Anton Kolonin"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.08965"
  },
  {
    "id": "arXiv:2202.08972",
    "title": "Deep Reinforcement Learning Based Multi-Access Edge Computing Schedule  for Internet of Vehicle",
    "abstract": "As intelligent transportation systems been implemented broadly and unmanned\narial vehicles (UAVs) can assist terrestrial base stations acting as\nmulti-access edge computing (MEC) to provide a better wireless network\ncommunication for Internet of Vehicles (IoVs), we propose a UAVs-assisted\napproach to help provide a better wireless network service retaining the\nmaximum Quality of Experience(QoE) of the IoVs on the lane. In the paper, we\npresent a Multi-Agent Graph Convolutional Deep Reinforcement Learning\n(M-AGCDRL) algorithm which combines local observations of each agent with a\nlow-resolution global map as input to learn a policy for each agent. The agents\ncan share their information with others in graph attention networks, resulting\nin an effective joint policy. Simulation results show that the M-AGCDRL method\nenables a better QoE of IoTs and achieves good performance.",
    "descriptor": "\nComments: 10 pages, 10 figures\n",
    "authors": [
      "Xiaoyu Dai",
      "Kaoru Ota",
      "Mianxiong Dong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.08972"
  },
  {
    "id": "arXiv:2202.08973",
    "title": "Energy-Efficient Parking Analytics System using Deep Reinforcement  Learning",
    "abstract": "Advances in deep vision techniques and ubiquity of smart cameras will drive\nthe next generation of video analytics. However, video analytics applications\nconsume vast amounts of energy as both deep learning techniques and cameras are\npower-hungry. In this paper, we focus on a parking video analytics platform and\npropose RL-CamSleep, a deep reinforcement learning-based technique, to actuate\nthe cameras to reduce the energy footprint while retaining the system's\nutility. Our key insight is that many video-analytics applications do not\nalways need to be operational, and we can design policies to activate video\nanalytics only when necessary. Moreover, our work is complementary to existing\nwork that focuses on improving hardware and software efficiency. We evaluate\nour approach on a city-scale parking dataset having 76 streets spread across\nthe city. Our analysis demonstrates how streets have various parking patterns,\nhighlighting the importance of an adaptive policy. Our approach can learn such\nan adaptive policy that can reduce the average energy consumption by 76.38% and\nachieve an average accuracy of more than 98% in performing video analytics.",
    "descriptor": "",
    "authors": [
      "Yoones Rezaei",
      "Stephen Lee",
      "Daniel Mosse"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.08973"
  },
  {
    "id": "arXiv:2202.08974",
    "title": "Multimodal Emotion Recognition using Transfer Learning from Speaker  Recognition and BERT-based models",
    "abstract": "Automatic emotion recognition plays a key role in computer-human interaction\nas it has the potential to enrich the next-generation artificial intelligence\nwith emotional intelligence. It finds applications in customer and/or\nrepresentative behavior analysis in call centers, gaming, personal assistants,\nand social robots, to mention a few. Therefore, there has been an increasing\ndemand to develop robust automatic methods to analyze and recognize the various\nemotions. In this paper, we propose a neural network-based emotion recognition\nframework that uses a late fusion of transfer-learned and fine-tuned models\nfrom speech and text modalities. More specifically, we i) adapt a residual\nnetwork (ResNet) based model trained on a large-scale speaker recognition task\nusing transfer learning along with a spectrogram augmentation approach to\nrecognize emotions from speech, and ii) use a fine-tuned bidirectional encoder\nrepresentations from transformers (BERT) based model to represent and recognize\nemotions from the text. The proposed system then combines the ResNet and\nBERT-based model scores using a late fusion strategy to further improve the\nemotion recognition performance. The proposed multimodal solution addresses the\ndata scarcity limitation in emotion recognition using transfer learning, data\naugmentation, and fine-tuning, thereby improving the generalization performance\nof the emotion recognition models. We evaluate the effectiveness of our\nproposed multimodal approach on the interactive emotional dyadic motion capture\n(IEMOCAP) dataset. Experimental results indicate that both audio and text-based\nmodels improve the emotion recognition performance and that the proposed\nmultimodal solution achieves state-of-the-art results on the IEMOCAP benchmark.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2108.02510\n",
    "authors": [
      "Sarala Padi",
      "Seyed Omid Sadjadi",
      "Dinesh Manocha",
      "Ram D. Sriram"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2202.08974"
  },
  {
    "id": "arXiv:2202.08975",
    "title": "Probing Pretrained Models of Source Code",
    "abstract": "Deep learning models are widely used for solving challenging code processing\ntasks, such as code generation or code summarization. Traditionally, a specific\nmodel architecture was carefully built to solve a particular code processing\ntask. However, recently general pretrained models such as CodeBERT or CodeT5\nhave been shown to outperform task-specific models in many applications. While\npretrained models are known to learn complex patterns from data, they may fail\nto understand some properties of source code. To test diverse aspects of code\nunderstanding, we introduce a set of diagnosting probing tasks. We show that\npretrained models of code indeed contain information about code syntactic\nstructure and correctness, the notions of identifiers, data flow and\nnamespaces, and natural language naming. We also investigate how probing\nresults are affected by using code-specific pretraining objectives, varying the\nmodel size, or finetuning.",
    "descriptor": "",
    "authors": [
      "Sergey Troshin",
      "Nadezhda Chirkova"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.08975"
  },
  {
    "id": "arXiv:2202.08978",
    "title": "Cyclical Focal Loss",
    "abstract": "The cross-entropy softmax loss is the primary loss function used to train\ndeep neural networks. On the other hand, the focal loss function has been\ndemonstrated to provide improved performance when there is an imbalance in the\nnumber of training samples in each class, such as in long-tailed datasets. In\nthis paper, we introduce a novel cyclical focal loss and demonstrate that it is\na more universal loss function than cross-entropy softmax loss or focal loss.\nWe describe the intuition behind the cyclical focal loss and our experiments\nprovide evidence that cyclical focal loss provides superior performance for\nbalanced, imbalanced, or long-tailed datasets. We provide numerous experimental\nresults for CIFAR-10/CIFAR-100, ImageNet, balanced and imbalanced 4,000\ntraining sample versions of CIFAR-10/CIFAR-100, and ImageNet-LT and Places-LT\nfrom the Open Long-Tailed Recognition (OLTR) challenge. Implementing the\ncyclical focal loss function requires only a few lines of code and does not\nincrease training time. In the spirit of reproducibility, our code is available\nat \\url{https://github.com/lnsmith54/CFL}.",
    "descriptor": "",
    "authors": [
      "Leslie N. Smith"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.08978"
  },
  {
    "id": "arXiv:2202.08979",
    "title": "The Response Shift Paradigm to Quantify Human Trust in AI  Recommendations",
    "abstract": "Explainability, interpretability and how much they affect human trust in AI\nsystems are ultimately problems of human cognition as much as machine learning,\nyet the effectiveness of AI recommendations and the trust afforded by end-users\nare typically not evaluated quantitatively. We developed and validated a\ngeneral purpose Human-AI interaction paradigm which quantifies the impact of AI\nrecommendations on human decisions. In our paradigm we confronted human users\nwith quantitative prediction tasks: asking them for a first response, before\nconfronting them with an AI's recommendations (and explanation), and then\nasking the human user to provide an updated final response. The difference\nbetween final and first responses constitutes the shift or sway in the human\ndecision which we use as metric of the AI's recommendation impact on the human,\nrepresenting the trust they place on the AI. We evaluated this paradigm on\nhundreds of users through Amazon Mechanical Turk using a multi-branched\nexperiment confronting users with good/poor AI systems that had good, poor or\nno explainability. Our proof-of-principle paradigm allows one to quantitatively\ncompare the rapidly growing set of XAI/IAI approaches in terms of their effect\non the end-user and opens up the possibility of (machine) learning trust.",
    "descriptor": "",
    "authors": [
      "Ali Shafti",
      "Victoria Derks",
      "Hannah Kay",
      "A. Aldo Faisal"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.08979"
  },
  {
    "id": "arXiv:2202.08981",
    "title": "A Summary of the ComParE COVID-19 Challenges",
    "abstract": "The COVID-19 pandemic has caused massive humanitarian and economic damage.\nTeams of scientists from a broad range of disciplines have searched for methods\nto help governments and communities combat the disease. One avenue from the\nmachine learning field which has been explored is the prospect of a digital\nmass test which can detect COVID-19 from infected individuals' respiratory\nsounds. We present a summary of the results from the INTERSPEECH 2021\nComputational Paralinguistics Challenges: COVID-19 Cough, (CCS) and COVID-19\nSpeech, (CSS).",
    "descriptor": "\nComments: 18 pages, 13 figures\n",
    "authors": [
      "Harry Coppock",
      "Alican Akman",
      "Christian Bergler",
      "Maurice Gerczuk",
      "Chlo\u00eb Brown",
      "Jagmohan Chauhan",
      "Andreas Grammenos",
      "Apinan Hasthanasombat",
      "Dimitris Spathis",
      "Tong Xia",
      "Pietro Cicuta",
      "Jing Han",
      "Shahin Amiriparian",
      "Alice Baird",
      "Lukas Stappen",
      "Sandra Ottl",
      "Panagiotis Tzirakis",
      "Anton Batliner",
      "Cecilia Mascolo",
      "Bj\u00f6rn W. Schuller"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2202.08981"
  },
  {
    "id": "arXiv:2202.08982",
    "title": "PGCN: Progressive Graph Convolutional Networks for Spatial-Temporal  Traffic Forecasting",
    "abstract": "The complex spatial-temporal correlations in transportation networks make the\ntraffic forecasting problem challenging. Since transportation system inherently\npossesses graph structures, much research efforts have been put with graph\nneural networks. Recently, constructing adaptive graphs to the data has shown\npromising results over the models relying on a single static graph structure.\nHowever, the graph adaptations are applied during the training phases, and do\nnot reflect the data used during the testing phases. Such shortcomings can be\nproblematic especially in traffic forecasting since the traffic data often\nsuffers from the unexpected changes and irregularities in the time series. In\nthis study, we propose a novel traffic forecasting framework called Progressive\nGraph Convolutional Network (PGCN). PGCN constructs a set of graphs by\nprogressively adapting to input data during the training and the testing\nphases. Specifically, we implemented the model to construct progressive\nadjacency matrices by learning trend similarities among graph nodes. Then, the\nmodel is combined with the dilated causal convolution and gated activation unit\nto extract temporal features. With residual and skip connections, PGCN performs\nthe traffic prediction. When applied to four real-world traffic datasets of\ndiverse geometric nature, the proposed model achieves state-of-the-art\nperformance with consistency in all datasets. We conclude that the ability of\nPGCN to progressively adapt to input data enables the model to generalize in\ndifferent study sites with robustness.",
    "descriptor": "\nComments: 9 pages, 5 figures, currently under review for KDD22\n",
    "authors": [
      "Yuyol Shin",
      "Yoonjin Yoon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.08982"
  },
  {
    "id": "arXiv:2202.08985",
    "title": "Out of Distribution Data Detection Using Dropout Bayesian Neural  Networks",
    "abstract": "We explore the utility of information contained within a dropout based\nBayesian neural network (BNN) for the task of detecting out of distribution\n(OOD) data. We first show how previous attempts to leverage the randomized\nembeddings induced by the intermediate layers of a dropout BNN can fail due to\nthe distance metric used. We introduce an alternative approach to measuring\nembedding uncertainty, justify its use theoretically, and demonstrate how\nincorporating embedding uncertainty improves OOD data identification across\nthree tasks: image classification, language classification, and malware\ndetection.",
    "descriptor": "",
    "authors": [
      "Andre T. Nguyen",
      "Fred Lu",
      "Gary Lopez Munoz",
      "Edward Raff",
      "Charles Nicholas",
      "James Holt"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.08985"
  },
  {
    "id": "arXiv:2202.08991",
    "title": "Joint Learning of Frequency and Spatial Domains for Dense Predictions",
    "abstract": "Current artificial neural networks mainly conduct the learning process in the\nspatial domain but neglect the frequency domain learning. However, the learning\ncourse performed in the frequency domain can be more efficient than that in the\nspatial domain. In this paper, we fully explore frequency domain learning and\npropose a joint learning paradigm of frequency and spatial domains. This\nparadigm can take full advantage of the preponderances of frequency learning\nand spatial learning; specifically, frequency and spatial domain learning can\neffectively capture global and local information, respectively. Exhaustive\nexperiments on two dense prediction tasks, i.e., self-supervised depth\nestimation and semantic segmentation, demonstrate that the proposed joint\nlearning paradigm can 1) achieve performance competitive to those of\nstate-of-the-art methods in both depth estimation and semantic segmentation\ntasks, even without pretraining; and 2) significantly reduce the number of\nparameters compared to other state-of-the-art methods, which provides more\nchance to develop real-world applications. We hope that the proposed method can\nencourage more research in cross-domain learning.",
    "descriptor": "",
    "authors": [
      "Shaocheng Jia",
      "Wei Yao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.08991"
  },
  {
    "id": "arXiv:2202.08992",
    "title": "Enhanced Multi-Objective A* Using Balanced Binary Search Trees",
    "abstract": "This work addresses the Multi-Objective Shortest Path Problem (MO-SPP): Given\na graph where each edge is associated with a non-negative cost vector, MO-SPP\naims to find all the Pareto-optimal paths connecting the given start and goal\nnodes. To solve MO-SPP, the popular multi-objective A* (MOA*) like algorithms\nmaintain a \"frontier\" set at any node during the search to keep track of the\nnon-dominated paths that reach that node. The computational efficiency of MOA*\nalgorithms directly depend on how efficiently one can maintain the frontier\nsets. Recently, several techniques have been developed in the literature to\naddress this issue mainly for two objectives. In this work, we introduce a new\nmethod to efficiently maintain these frontiers for multiple objectives by\nleveraging balanced binary search trees. We provide extensive simulation\nresults for problems with three, four and five objectives to show that our\nmethod outperforms existing techniques by an order of magnitude in general.",
    "descriptor": "",
    "authors": [
      "Zhongqiang Ren",
      "Sivakumar Rathinam",
      "Maxim Likhachev",
      "Howie Choset"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.08992"
  },
  {
    "id": "arXiv:2202.08996",
    "title": "Worst-Case to Average-Case Reductions via Additive Combinatorics",
    "abstract": "We present a new framework for designing worst-case to average-case\nreductions. For a large class of problems, it provides an explicit\ntransformation of algorithms running in time $T$ that are only correct on a\nsmall (subconstant) fraction of their inputs into algorithms running in time\n$\\widetilde{O}(T)$ that are correct on all inputs.\nUsing our framework, we obtain such efficient worst-case to average-case\nreductions for fundamental problems in a variety of computational models;\nnamely, algorithms for matrix multiplication, streaming algorithms for the\nonline matrix-vector multiplication problem, and static data structures for all\nlinear problems as well as for the multivariate polynomial evaluation problem.\nOur techniques crucially rely on additive combinatorics. In particular, we\nshow a local correction lemma that relies on a new probabilistic version of the\nquasi-polynomial Bogolyubov-Ruzsa lemma.",
    "descriptor": "",
    "authors": [
      "Vahid R. Asadi",
      "Alexander Golovnev",
      "Tom Gur",
      "Igor Shinkar"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2202.08996"
  },
  {
    "id": "arXiv:2202.09002",
    "title": "An Active and Contrastive Learning Framework for Fine-Grained Off-Road  Semantic Segmentation",
    "abstract": "Off-road semantic segmentation with fine-grained labels is necessary for\nautonomous vehicles to understand driving scenes, as the coarse-grained road\ndetection can not satisfy off-road vehicles with various mechanical properties.\nFine-grained semantic segmentation in off-road scenes usually has no unified\ncategory definition due to ambiguous nature environments, and the cost of\npixel-wise labeling is extremely high. Furthermore, semantic properties of\noff-road scenes can be very changeable due to various precipitations,\ntemperature, defoliation, etc. To address these challenges, this research\nproposes an active and contrastive learning-based method that does not rely on\npixel-wise labels, but only on patch-based weak annotations for model learning.\nThere is no need for predefined semantic categories, the contrastive\nlearning-based feature representation and adaptive clustering will discover the\ncategory model from scene data. In order to actively adapt to new scenes, a\nrisk evaluation method is proposed to discover and select hard frames with\nhigh-risk predictions for supplemental labeling, so as to update the model\nefficiently. Experiments conducted on our self-developed off-road dataset and\nDeepScene dataset demonstrate that fine-grained semantic segmentation can be\nlearned with only dozens of weakly labeled frames, and the model can\nefficiently adapt across scenes by weak supervision, while achieving almost the\nsame level of performance as typical fully supervised baselines.",
    "descriptor": "\nComments: 13 pages, 13 figures\n",
    "authors": [
      "Biao Gao",
      "Xijun Zhao",
      "Huijing Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.09002"
  },
  {
    "id": "arXiv:2202.09003",
    "title": "End-to-end contextual asr based on posterior distribution adaptation for  hybrid ctc/attention system",
    "abstract": "End-to-end (E2E) speech recognition architectures assemble all components of\ntraditional speech recognition system into a single model. Although it\nsimplifies ASR system, it introduces contextual ASR drawback: the E2E model has\nworse performance on utterances containing infrequent proper nouns. In this\nwork, we propose to add a contextual bias attention (CBA) module to attention\nbased encoder decoder (AED) model to improve its ability of recognizing the\ncontextual phrases. Specifically, CBA utilizes the context vector of source\nattention in decoder to attend to a specific bias embedding. Jointly learned\nwith the basic AED parameters, CBA can tell the model when and where to bias\nits output probability distribution. At inference stage, a list of bias phrases\nis preloaded and we adapt the posterior distributions of both CTC and attention\ndecoder according to the attended bias phrase of CBA. We evaluate the proposed\nmethod on GigaSpeech and achieve a consistent relative improvement on recall\nrate of bias phrases ranging from 15% to 28% compared to the baseline model.\nMeanwhile, our method shows a strong anti-bias ability as the performance on\ngeneral tests only degrades 1.7% even 2,000 bias phrases are present.",
    "descriptor": "\nComments: 5 pages, 5 tabels, 1 figure\n",
    "authors": [
      "Zhengyi Zhang",
      "Pan Zhou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2202.09003"
  },
  {
    "id": "arXiv:2202.09005",
    "title": "Reviews in motion: a large scale, longitudinal study of review  recommendations on Yelp",
    "abstract": "The United Nations Consumer Protection Guidelines lists \"access ... to\nadequate information ... to make informed choices\" as a core consumer\nprotection right. However, problematic online reviews and imperfections in\nalgorithms that detect those reviews pose obstacles to the fulfillment of this\nright. Research on reviews and review platforms often derives insights from a\nsingle web crawl, but the decisions those crawls observe may not be static. A\nplatform may feature a review one day and filter it from view the next day. An\nappreciation for these dynamics is necessary to understand how a platform\nchooses which reviews consumers encounter and which reviews may be unhelpful or\nsuspicious. We introduce a novel longitudinal angle to the study of reviews. We\nfocus on \"reclassification,\" wherein a platform changes its filtering decision\nfor a review. To that end, we perform repeated web crawls of Yelp to create\nthree longitudinal datasets. These datasets highlight the platform's dynamic\ntreatment of reviews. We compile over 12.5M reviews--more than 2M\nunique--across over 10k businesses. Our datasets are available for researchers\nto use.\nOur longitudinal approach gives us a unique perspective on Yelp's classifier\nand allows us to explore reclassification. We find that reviews routinely move\nbetween Yelp's two main classifier classes (\"Recommended\" and \"Not\nRecommended\")--up to 8% over eight years--raising concerns about prior works'\nuse of Yelp's classes as ground truth. These changes have impacts on small\nscales; for example, a business going from a 3.5 to 4.5 star rating despite no\nnew reviews. Some reviews move multiple times: we observed up to five\nreclassifications in eleven months. Our data suggests demographic disparities\nin reclassifications, with more changes in lower density and low-middle income\nareas.",
    "descriptor": "\nComments: 12 pages, 10 figures\n",
    "authors": [
      "Ryan Amos",
      "Roland Maio",
      "Prateek Mittal"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2202.09005"
  },
  {
    "id": "arXiv:2202.09006",
    "title": "KINet: Keypoint Interaction Networks for Unsupervised Forward Modeling",
    "abstract": "Object-centric representation is an essential abstraction for physical\nreasoning and forward prediction. Most existing approaches learn this\nrepresentation through extensive supervision (e.g., object class and bounding\nbox) although such ground-truth information is not readily accessible in\nreality. To address this, we introduce KINet (Keypoint Interaction Network) --\nan end-to-end unsupervised framework to reason about object interactions in\ncomplex systems based on a keypoint representation. Using visual observations,\nour model learns to associate objects with keypoint coordinates and discovers a\ngraph representation of the system as a set of keypoint embeddings and their\nrelations. It then learns an action-conditioned forward model using contrastive\nestimation to predict future keypoint states. By learning to perform physical\nreasoning in the keypoint space, our model automatically generalizes to\nscenarios with a different number of objects, and novel object geometries.\nExperiments demonstrate the effectiveness of our model to accurately perform\nforward prediction and learn plannable object-centric representations which can\nalso be used in downstream model-based control tasks.",
    "descriptor": "",
    "authors": [
      "Alireza Rezazadeh",
      "Changhyun Choi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.09006"
  },
  {
    "id": "arXiv:2202.09009",
    "title": "LG-LSQ: Learned Gradient Linear Symmetric Quantization",
    "abstract": "Deep neural networks with lower precision weights and operations at inference\ntime have advantages in terms of the cost of memory space and accelerator\npower. The main challenge associated with the quantization algorithm is\nmaintaining accuracy at low bit-widths. We propose learned gradient linear\nsymmetric quantization (LG-LSQ) as a method for quantizing weights and\nactivation functions to low bit-widths with high accuracy in integer neural\nnetwork processors. First, we introduce the scaling simulated gradient (SSG)\nmethod for determining the appropriate gradient for the scaling factor of the\nlinear quantizer during the training process. Second, we introduce the\narctangent soft round (ASR) method, which differs from the straight-through\nestimator (STE) method in its ability to prevent the gradient from becoming\nzero, thereby solving the discrete problem caused by the rounding process.\nFinally, to bridge the gap between full-precision and low-bit quantization\nnetworks, we propose the minimize discretization error (MDE) method to\ndetermine an accurate gradient in backpropagation. The ASR+MDE method is a\nsimple alternative to the STE method and is practical for use in different\nuniform quantization methods. In our evaluation, the proposed quantizer\nachieved full-precision baseline accuracy in various 3-bit networks, including\nResNet18, ResNet34, and ResNet50, and an accuracy drop of less than 1% in the\nquantization of 4-bit weights and 4-bit activations in lightweight models such\nas MobileNetV2 and ShuffleNetV2.",
    "descriptor": "",
    "authors": [
      "Shih-Ting Lin",
      "Zhaofang Li",
      "Yu-Hsiang Cheng",
      "Hao-Wen Kuo",
      "Chih-Cheng Lu",
      "Kea-Tiong Tang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.09009"
  },
  {
    "id": "arXiv:2202.09011",
    "title": "A class of twisted generalized Reed-Solomon codes",
    "abstract": "Let $\\mathbb{F}_q$ be a finite field of size $q$ and $\\mathbb{F}_q^*$ the set\nof non-zero elements of $\\mathbb{F}_q$. In this paper, we study a class of\ntwisted generalized Reed-Solomon code $C_\\ell(D, k, \\eta, \\vec{v})\\subset\n\\mathbb{F}_q^n$ generated by the following matrix \\[ \\left(\\begin{array}{cccc}\nv_{1} & v_{2} & \\cdots & v_{n} \\\\ v_{1} \\alpha_{1} & v_{2} \\alpha_{2} & \\cdots\n& v_{n} \\alpha_{n} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ v_{1}\n\\alpha_{1}^{\\ell-1} & v_{2} \\alpha_{2}^{\\ell-1} & \\cdots & v_{n}\n\\alpha_{n}^{\\ell-1} \\\\ v_{1} \\alpha_{1}^{\\ell+1} & v_{2} \\alpha_{2}^{\\ell+1} &\n\\cdots & v_{n} \\alpha_{n}^{\\ell+1} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\\nv_{1} \\alpha_{1}^{k-1} & v_{2} \\alpha_{2}^{k-1} & \\cdots & v_{n}\n\\alpha_{n}^{k-1} \\\\ v_{1}\\left(\\alpha_{1}^{\\ell}+\\eta\\alpha_{1}^{q-{2}}\\right)\n& v_{2}\\left(\\alpha_{2}^{\\ell}+ \\eta \\alpha_{2}^{q-2}\\right) &\\cdots &\nv_{n}\\left(\\alpha_{n}^{\\ell}+\\eta\\alpha_{n}^{q-2}\\right) \\end{array}\\right) \\]\nwhere $0\\leq \\ell\\leq k-1,$ the evaluation set\n$D=\\{\\alpha_{1},\\alpha_{2},\\cdots, \\alpha_{n}\\}\\subseteq \\mathbb{F}_q^*$,\nscaling vector $\\vec{v}=(v_1,v_2,\\cdots,v_n)\\in (\\mathbb{F}_q^*)^n$ and\n$\\eta\\in\\mathbb{F}_q^*$. The minimum distance and dual code of $C_\\ell(D, k,\n\\eta, \\vec{v})$ will be determined. For the special case $\\ell=k-1,$ a\nsufficient and necessary condition for $C_{k-1}(D, k, \\eta, \\vec{v})$ to be\nself-dual will be given. We will also show that the code is MDS or near-MDS.\nMoreover, a complete classification when the code is near-MDS or MDS will be\npresented.",
    "descriptor": "\nComments: 10 pages\n",
    "authors": [
      "Jun Zhang",
      "Zhengchun Zhou",
      "Chunming Tang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.09011"
  },
  {
    "id": "arXiv:2202.09013",
    "title": "Is Selling Complete Information (Approximately) Optimal?",
    "abstract": "We study the problem of selling information to a data-buyer who faces a\ndecision problem under uncertainty. We consider the classic Bayesian\ndecision-theoretic model pioneered by [Blackwell, 1951, 1953]. Initially, the\ndata buyer has only partial information about the payoff-relevant state of the\nworld. A data seller offers additional information about the state of the\nworld. The information is revealed through signaling schemes, also referred to\nas experiments. In the single-agent setting, any mechanism can be represented\nas a menu of experiments. [Bergemann et al., 2018] present a complete\ncharacterization of the revenue-optimal mechanism in a binary state and binary\naction environment. By contrast, no characterization is known for the case with\nmore actions. In this paper, we consider more general environments and study\narguably the simplest mechanism, which only sells the fully informative\nexperiment. In the environment with binary state and $m\\geq 3$ actions, we\nprovide an $O(m)$-approximation to the optimal revenue by selling only the\nfully informative experiment and show that the approximation ratio is tight up\nto an absolute constant factor. An important corollary of our lower bound is\nthat the size of the optimal menu must grow at least linearly in the number of\navailable actions, so no universal upper bound exists for the size of the\noptimal menu in the general single-dimensional setting.\nFor multi-dimensional environments, we prove that even in arguably the\nsimplest matching utility environment with 3 states and 3 actions, the ratio\nbetween the optimal revenue and the revenue by selling only the fully\ninformative experiment can grow immediately to a polynomial of the number of\nagent types. Nonetheless, if the distribution is uniform, we show that selling\nonly the fully informative experiment is indeed the optimal mechanism.",
    "descriptor": "",
    "authors": [
      "Dirk Bergemann",
      "Yang Cai",
      "Grigoris Velegkas",
      "Mingfei Zhao"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2202.09013"
  },
  {
    "id": "arXiv:2202.09014",
    "title": "How Well Do Self-Supervised Methods Perform in Cross-Domain Few-Shot  Learning?",
    "abstract": "Cross-domain few-shot learning (CDFSL) remains a largely unsolved problem in\nthe area of computer vision, while self-supervised learning presents a\npromising solution. Both learning methods attempt to alleviate the dependency\nof deep networks on the requirement of large-scale labeled data. Although\nself-supervised methods have recently advanced dramatically, their utility on\nCDFSL is relatively unexplored. In this paper, we investigate the role of\nself-supervised representation learning in the context of CDFSL via a thorough\nevaluation of existing methods. It comes as a surprise that even with shallow\narchitectures or small training datasets, self-supervised methods can perform\nfavorably compared to the existing SOTA methods. Nevertheless, no single\nself-supervised approach dominates all datasets indicating that existing\nself-supervised methods are not universally applicable. In addition, we find\nthat representations extracted from self-supervised methods exhibit stronger\nrobustness than the supervised method. Intriguingly, whether self-supervised\nrepresentations perform well on the source domain has little correlation with\ntheir applicability on the target domain. As part of our study, we conduct an\nobjective measurement of the performance for six kinds of representative\nclassifiers. The results suggest Prototypical Classifier as the standard\nevaluation recipe for CDFSL.",
    "descriptor": "",
    "authors": [
      "Yiyi Zhang",
      "Ying Zheng",
      "Xiaogang Xu",
      "Jun Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.09014"
  },
  {
    "id": "arXiv:2202.09016",
    "title": "Why, How and Where of Delays in Software Security Patch Management: An  Empirical Investigation in the Healthcare Sector",
    "abstract": "Numerous security attacks that resulted in devastating consequences can be\ntraced back to a delay in applying a security patch. Despite the criticality of\ntimely patch application, not much is known about why and how delays occur when\napplying security patches in practice, and how the delays can be mitigated.\nBased on longitudinal data collected from 132 delayed patching tasks over a\nperiod of four years and observations of patch meetings involving eight teams\nfrom two organisations in the healthcare domain, and using quantitative and\nqualitative data analysis approaches, we identify a set of reasons relating to\ntechnology, people and organisation as key explanations that cause delays in\npatching. Our findings also reveal that the most prominent cause of delays is\nattributable to coordination delays in the patch management process and a\nmajority of delays occur during the patch deployment phase. Towards mitigating\nthe delays, we describe a set of strategies employed by the studied\npractitioners. This research serves as the first step towards understanding the\npractical reasons for delays and possible mitigation strategies in\nvulnerability patch management. Our findings provide useful insights for\npractitioners to understand what and where improvement is needed in the patch\nmanagement process and guide them towards taking timely actions against\npotential attacks. Also, our findings help researchers to invest effort into\ndesigning and developing computer-supported tools to better support a timely\nsecurity patch management process.",
    "descriptor": "\nComments: 28 pages, 10 figures\n",
    "authors": [
      "Nesara Dissanayake",
      "Mansooreh Zahedi",
      "Asangi Jayatilaka",
      "M. Ali Babar"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2202.09016"
  },
  {
    "id": "arXiv:2202.09019",
    "title": "DARL1N: Distributed multi-Agent Reinforcement Learning with One-hop  Neighbors",
    "abstract": "Most existing multi-agent reinforcement learning (MARL) methods are limited\nin the scale of problems they can handle. Particularly, with the increase of\nthe number of agents, their training costs grow exponentially. In this paper,\nwe address this limitation by introducing a scalable MARL method called\nDistributed multi-Agent Reinforcement Learning with One-hop Neighbors (DARL1N).\nDARL1N is an off-policy actor-critic method that breaks the curse of\ndimensionality by decoupling the global interactions among agents and\nrestricting information exchanges to one-hop neighbors. Each agent optimizes\nits action value and policy functions over a one-hop neighborhood,\nsignificantly reducing the learning complexity, yet maintaining expressiveness\nby training with varying numbers and states of neighbors. This structure allows\nus to formulate a distributed learning framework to further speed up the\ntraining procedure. Comparisons with state-of-the-art MARL methods show that\nDARL1N significantly reduces training time without sacrificing policy quality\nand is scalable as the number of agents increases.",
    "descriptor": "",
    "authors": [
      "Baoqian Wang",
      "Junfei Xie",
      "Nikolay Atanasov"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.09019"
  },
  {
    "id": "arXiv:2202.09020",
    "title": "A Comprehensive Survey with Quantitative Comparison of Image Analysis  Methods for Microorganism Biovolume Measurements",
    "abstract": "With the acceleration of urbanization and living standards, microorganisms\nplay increasingly important roles in industrial production, bio-technique, and\nfood safety testing. Microorganism biovolume measurements are one of the\nessential parts of microbial analysis. However, traditional manual measurement\nmethods are time-consuming and challenging to measure the characteristics\nprecisely. With the development of digital image processing techniques, the\ncharacteristics of the microbial population can be detected and quantified. The\nchanging trend can be adjusted in time and provided a basis for the\nimprovement. The applications of the microorganism biovolume measurement method\nhave developed since the 1980s. More than 60 articles are reviewed in this\nstudy, and the articles are grouped by digital image segmentation methods with\nperiods. This study has high research significance and application value, which\ncan be referred to microbial researchers to have a comprehensive understanding\nof microorganism biovolume measurements using digital image analysis methods\nand potential applications.",
    "descriptor": "",
    "authors": [
      "Jiawei Zhang",
      "Chen Li",
      "Md Mamunur Rahaman",
      "Yudong Yao",
      "Pingli Ma",
      "Jinghua Zhang",
      "Xin Zhao",
      "Tao Jiang",
      "Marcin Grzegorzek"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2202.09020"
  },
  {
    "id": "arXiv:2202.09021",
    "title": "Effective Urban Region Representation Learning Using Heterogeneous Urban  Graph Attention Network (HUGAT)",
    "abstract": "Revealing the hidden patterns shaping the urban environment is essential to\nunderstand its dynamics and to make cities smarter. Recent studies have\ndemonstrated that learning the representations of urban regions can be an\neffective strategy to uncover the intrinsic characteristics of urban areas.\nHowever, existing studies lack in incorporating diversity in urban data\nsources. In this work, we propose heterogeneous urban graph attention network\n(HUGAT), which incorporates heterogeneity of diverse urban datasets. In HUGAT,\nheterogeneous urban graph (HUG) incorporates both the geo-spatial and temporal\npeople movement variations in a single graph structure. Given a HUG, a set of\nmeta-paths are designed to capture the rich urban semantics as composite\nrelations between nodes. Region embedding is carried out using heterogeneous\ngraph attention network (HAN). HUGAT is designed to consider multiple learning\nobjectives of city's geo-spatial and mobility variations simultaneously. In our\nextensive experiments on NYC data, HUGAT outperformed all the state-of-the-art\nmodels. Moreover, it demonstrated a robust generalization capability across the\nvarious prediction tasks of crime, average personal income, and bike flow as\nwell as the spatial clustering task.",
    "descriptor": "\nComments: 9 pages, 6 figures\n",
    "authors": [
      "Namwoo Kim",
      "Yoonjin Yoon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.09021"
  },
  {
    "id": "arXiv:2202.09022",
    "title": "TURNER: The Uncertainty-based Retrieval Framework for Chinese NER",
    "abstract": "Chinese NER is a difficult undertaking due to the ambiguity of Chinese\ncharacters and the absence of word boundaries. Previous work on Chinese NER\nfocus on lexicon-based methods to introduce boundary information and reduce\nout-of-vocabulary (OOV) cases during prediction. However, it is expensive to\nobtain and dynamically maintain high-quality lexicons in specific domains,\nwhich motivates us to utilize more general knowledge resources, e.g., search\nengines. In this paper, we propose TURNER: The Uncertainty-based Retrieval\nframework for Chinese NER. The idea behind TURNER is to imitate human behavior:\nwe frequently retrieve auxiliary knowledge as assistance when encountering an\nunknown or uncertain entity. To improve the efficiency and effectiveness of\nretrieval, we first propose two types of uncertainty sampling methods for\nselecting the most ambiguous entity-level uncertain components of the input\ntext. Then, the Knowledge Fusion Model re-predict the uncertain samples by\ncombining retrieved knowledge. Experiments on four benchmark datasets\ndemonstrate TURNER's effectiveness. TURNER outperforms existing lexicon-based\napproaches and achieves the new SOTA.",
    "descriptor": "",
    "authors": [
      "Zhichao Geng",
      "Hang Yan",
      "Zhangyue Yin",
      "Chenxin An",
      "Xipeng Qiu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2202.09022"
  },
  {
    "id": "arXiv:2202.09024",
    "title": "On The \"Majority is Least Stable\" Conjecture",
    "abstract": "We show that the \"majority is least stable\" conjecture is true for $n=1$ and\n$3$ and false for all odd $n\\geq 5$.",
    "descriptor": "",
    "authors": [
      "Aniruddha Biswas",
      "Palash Sarkar"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2202.09024"
  },
  {
    "id": "arXiv:2202.09025",
    "title": "Graph Auto-Encoder Via Neighborhood Wasserstein Reconstruction",
    "abstract": "Graph neural networks (GNNs) have drawn significant research attention\nrecently, mostly under the setting of semi-supervised learning. When\ntask-agnostic representations are preferred or supervision is simply\nunavailable, the auto-encoder framework comes in handy with a natural graph\nreconstruction objective for unsupervised GNN training. However, existing graph\nauto-encoders are designed to reconstruct the direct links, so GNNs trained in\nthis way are only optimized towards proximity-oriented graph mining tasks, and\nwill fall short when the topological structures matter. In this work, we\nrevisit the graph encoding process of GNNs which essentially learns to encode\nthe neighborhood information of each node into an embedding vector, and propose\na novel graph decoder to reconstruct the entire neighborhood information\nregarding both proximity and structure via Neighborhood Wasserstein\nReconstruction (NWR). Specifically, from the GNN embedding of each node, NWR\njointly predicts its node degree and neighbor feature distribution, where the\ndistribution prediction adopts an optimal-transport loss based on the\nWasserstein distance. Extensive experiments on both synthetic and real-world\nnetwork datasets show that the unsupervised node representations learned with\nNWR have much more advantageous in structure-oriented graph mining tasks, while\nalso achieving competitive performance in proximity-oriented ones.",
    "descriptor": "\nComments: ICLR 2022; Code available at this https URL\n",
    "authors": [
      "Mingyue Tang",
      "Carl Yang",
      "Pan Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2202.09025"
  },
  {
    "id": "arXiv:2202.09026",
    "title": "Post-quantum Multi-stage Secret Sharing Schemes using Inhomogeneous  Linear Recursion and Ajtai's Function",
    "abstract": "Secret sharing was firstly proposed in 1979 by Shamir and Blakley\nrespectively. To avoid deficiencies of original schemes, researchers presented\nimprovement schemes, among which the multi-secret sharing scheme (MSS) is\nsignificant. There are three categories of MSSs, however, we focus on\nmulti-stage secret sharing scheme (MSSS) recovering secrets with any order in\nthis work. By observing inhomogeneous linear recursions (ILRs) in the\nliterature, we conclude a general formula and divide ILRs into two types\naccording to different variables in them. Utilizing these two kinds of ILRs, we\npropose four verifiable MSSSs with Ajtai's function, which is a lattice-based\nfunction. Our schemes have the following advantages. Firstly, our schemes can\ndetect cheat of the dealer and participants, and are multi-use. Secondly, we\nhave several ways to restore secrets. Thirdly, we can turn our schemes into\nother types of MSSs due to the universality of our method. Fourthly, since we\nutilize a lattice-based function to mask shares, our schemes can resist the\nattack from the quantum computer with computational security. Finally, although\nour schemes need more memory consumption than some known schemes, we need much\nless time consumption, which makes our schemes more suitable facing limited\ncomputing power.",
    "descriptor": "\nComments: 36 pages,1 figure, 3 tables\n",
    "authors": [
      "Jing Yang",
      "Fang-Wei Fu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.09026"
  },
  {
    "id": "arXiv:2202.09027",
    "title": "Trusted AI in Multi-agent Systems: An Overview of Privacy and Security  for Distributed Learning",
    "abstract": "Motivated by the advancing computational capacity of distributed end-user\nequipments (UEs), as well as the increasing concerns about sharing private\ndata, there has been considerable recent interest in machine learning (ML) and\nartificial intelligence (AI) that can be processed on on distributed UEs.\nSpecifically, in this paradigm, parts of an ML process are outsourced to\nmultiple distributed UEs, and then the processed ML information is aggregated\non a certain level at a central server, which turns a centralized ML process\ninto a distributed one, and brings about significant benefits. However, this\nnew distributed ML paradigm raises new risks of privacy and security issues. In\nthis paper, we provide a survey of the emerging security and privacy risks of\ndistributed ML from a unique perspective of information exchange levels, which\nare defined according to the key steps of an ML process, i.e.: i) the level of\npreprocessed data, ii) the level of learning models, iii) the level of\nextracted knowledge and, iv) the level of intermediate results. We explore and\nanalyze the potential of threats for each information exchange level based on\nan overview of the current state-of-the-art attack mechanisms, and then discuss\nthe possible defense methods against such threats. Finally, we complete the\nsurvey by providing an outlook on the challenges and possible directions for\nfuture research in this critical area.",
    "descriptor": "",
    "authors": [
      "Chuan Ma",
      "Jun Li. Kang Wei",
      "Bo Liu",
      "Ming Ding",
      "Long Yuan",
      "Zhu Han",
      "H. Vicent Poor"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2202.09027"
  },
  {
    "id": "arXiv:2202.09028",
    "title": "A Note on the Implicit Bias Towards Minimal Depth of Deep Neural  Networks",
    "abstract": "Deep learning systems have steadily advanced the state of the art in a wide\nvariety of benchmarks, demonstrating impressive performance in tasks ranging\nfrom image classification \\citep{taigman2014deepface,zhai2021scaling}, language\nprocessing \\citep{devlin-etal-2019-bert,NEURIPS2020_1457c0d6}, open-ended\nenvironments \\citep{SilverHuangEtAl16nature,arulkumaran2019alphastar}, to\ncoding \\citep{chen2021evaluating}.\nA central aspect that enables the success of these systems is the ability to\ntrain deep models instead of wide shallow ones \\citep{7780459}. Intuitively, a\nneural network is decomposed into hierarchical representations from raw data to\nhigh-level, more abstract features. While training deep neural networks\nrepetitively achieves superior performance against their shallow counterparts,\nan understanding of the role of depth in representation learning is still\nlacking.\nIn this work, we suggest a new perspective on understanding the role of depth\nin deep learning. We hypothesize that {\\bf\\em SGD training of overparameterized\nneural networks exhibits an implicit bias that favors solutions of minimal\neffective depth}. Namely, SGD trains neural networks for which the top several\nlayers are redundant. To evaluate the redundancy of layers, we revisit the\nrecently discovered phenomenon of neural collapse\n\\citep{Papyan24652,han2021neural}.",
    "descriptor": "",
    "authors": [
      "Tomer Galanti"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.09028"
  },
  {
    "id": "arXiv:2202.09035",
    "title": "PISA: A Binary-Weight Processing-In-Sensor Accelerator for Edge Image  Processing",
    "abstract": "This work proposes a Processing-In-Sensor Accelerator, namely PISA, as a\nflexible, energy-efficient, and high-performance solution for real-time and\nsmart image processing in AI devices. PISA intrinsically implements a\ncoarse-grained convolution operation in Binarized-Weight Neural Networks\n(BWNNs) leveraging a novel compute-pixel with non-volatile weight storage at\nthe sensor side. This remarkably reduces the power consumption of data\nconversion and transmission to an off-chip processor. The design is completed\nwith a bit-wise near-sensor processing-in-DRAM computing unit to process the\nremaining network layers. Once the object is detected, PISA switches to typical\nsensing mode to capture the image for a fine-grained convolution using only the\nnear-sensor processing unit. Our circuit-to-application co-simulation results\non a BWNN acceleration demonstrate acceptable accuracy on various image\ndatasets in coarse-grained evaluation compared to baseline BWNN models, while\nPISA achieves a frame rate of 1000 and efficiency of ~1.74 TOp/s/W. Lastly,\nPISA substantially reduces data conversion and transmission energy by ~84%\ncompared to a baseline CPU-sensor design.",
    "descriptor": "\nComments: 11 pages, 16 figures\n",
    "authors": [
      "Shaahin Angizi",
      "Sepehr Tabrizchi",
      "Arman Roohi"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2202.09035"
  },
  {
    "id": "arXiv:2202.09036",
    "title": "Adaptivity and Confounding in Multi-Armed Bandit Experiments",
    "abstract": "Multi-armed bandit algorithms minimize experimentation costs required to\nconverge on optimal behavior. They do so by rapidly adapting experimentation\neffort away from poorly performing actions as feedback is observed. But this\ndesirable feature makes them sensitive to confounding, which is the primary\nconcern underlying classical randomized controlled trials. We highlight, for\ninstance, that popular bandit algorithms cannot address the problem of\nidentifying the best action when day-of-week effects may confound inferences.\nIn response, this paper proposes deconfounded Thompson sampling, which makes\nsimple, but critical, modifications to the way Thompson sampling is usually\napplied. Theoretical guarantees suggest the algorithm strikes a delicate\nbalance between adaptivity and robustness to confounding. It attains asymptotic\nlower bounds on the number of samples required to confidently identify the best\naction -- suggesting optimal adaptivity -- but also satisfies strong\nperformance guarantees in the presence of day-of-week effects and delayed\nobservations -- suggesting unusual robustness. At the core of the paper is a\nnew model of contextual bandit experiments in which issues of delayed learning\nand distribution shift arise organically.",
    "descriptor": "",
    "authors": [
      "Chao Qin",
      "Daniel Russo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.09036"
  },
  {
    "id": "arXiv:2202.09039",
    "title": "Critical Checkpoints for Evaluating Defence Models Against Adversarial  Attack and Robustness",
    "abstract": "From past couple of years there is a cycle of researchers proposing a defence\nmodel for adversaries in machine learning which is arguably defensible to most\nof the existing attacks in restricted condition (they evaluate on some bounded\ninputs or datasets). And then shortly another set of researcher finding the\nvulnerabilities in that defence model and breaking it by proposing a stronger\nattack model. Some common flaws are been noticed in the past defence models\nthat were broken in very short time. Defence models being broken so easily is a\npoint of concern as decision of many crucial activities are taken with the help\nof machine learning models. So there is an utter need of some defence\ncheckpoints that any researcher should keep in mind while evaluating the\nsoundness of technique and declaring it to be decent defence technique. In this\npaper, we have suggested few checkpoints that should be taken into\nconsideration while building and evaluating the soundness of defence models.\nAll these points are recommended after observing why some past defence models\nfailed and how some model remained adamant and proved their soundness against\nsome of the very strong attacks.",
    "descriptor": "\nComments: 16 pages, 8 figures\n",
    "authors": [
      "Kanak Tekwani",
      "Manojkumar Parmar"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.09039"
  },
  {
    "id": "arXiv:2202.09044",
    "title": "Social Welfare Maximization in cross-silo Federated Learning",
    "abstract": "As one of the typical settings of Federated Learning (FL), cross-silo FL\nallows organizations to jointly train an optimal Machine Learning (ML) model.\nIn this case, some organizations may try to obtain the global model without\ncontributing their local training, lowering the social welfare. In this paper,\nwe model the interactions among organizations in cross-silo FL as a public\ngoods game for the first time and theoretically prove that there exists a\nsocial dilemma where the maximum social welfare is not achieved in Nash\nequilibrium. To overcome this social dilemma, we employ the Multi-player\nMulti-action Zero-Determinant (MMZD) strategy to maximize the social welfare.\nWith the help of the MMZD, an individual organization can unilaterally control\nthe social welfare without extra cost. Experimental results validate that the\nMMZD strategy is effective in maximizing the social welfare.",
    "descriptor": "\nComments: Accepted by ICASSP 2022. arXiv admin note: substantial text overlap with arXiv:2202.08362\n",
    "authors": [
      "Jianan Chen",
      "Qin Hu",
      "Honglu Jiang"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2202.09044"
  },
  {
    "id": "arXiv:2202.09048",
    "title": "Task Specific Attention is one more thing you need for object detection",
    "abstract": "Various models have been proposed to solve the object detection problem.\nHowever, most of them require many hand-designed components to demonstrate good\nperformance. To mitigate these issues, Transformer based DETR and its variant\nDeformable DETR were suggested. They solved much of the complex issue of\ndesigning a head of object detection model but it has not been generally clear\nthat the Transformer-based models could be considered as the state-of-the-art\nmethod in object detection without doubt. Furthermore, as DETR adapted\nTransformer method only for the detection head, but still with including CNN\nfor the backbone body, it has not been certain that it would be possible to\nbuild the competent end-to-end pipeline with the combination of attention\nmodules. In this paper, we propose that combining several attention modules\nwith our new Task Specific Split Transformer(TSST) is a fairly good enough\nmethod to produce the best COCO results without traditionally hand-designed\ncomponents. By splitting generally purposed attention module into two separated\nmission specific attention module, the proposed method addresses the way to\ndesign simpler object detection models than before. Extensive experiments on\nthe COCO benchmark demonstrate the effectiveness of our approach. Code is\nreleased at https://github.com/navervision/tsst",
    "descriptor": "",
    "authors": [
      "Sang Yon Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.09048"
  },
  {
    "id": "arXiv:2202.09049",
    "title": "CLSEG: Contrastive Learning of Story Ending Generation",
    "abstract": "Story Ending Generation (SEG) is a challenging task in natural language\ngeneration. Recently, methods based on Pre-trained Language Models (PLM) have\nachieved great prosperity, which can produce fluent and coherent story endings.\nHowever, the pre-training objective of PLM-based methods is unable to model the\nconsistency between story context and ending. The goal of this paper is to\nadopt contrastive learning to generate endings more consistent with story\ncontext, while there are two main challenges in contrastive learning of SEG.\nFirst is the negative sampling of wrong endings inconsistent with story\ncontexts. The second challenge is the adaptation of contrastive learning for\nSEG. To address these two issues, we propose a novel Contrastive Learning\nframework for Story Ending Generation (CLSEG), which has two steps:\nmulti-aspect sampling and story-specific contrastive learning. Particularly,\nfor the first issue, we utilize novel multi-aspect sampling mechanisms to\nobtain wrong endings considering the consistency of order, causality, and\nsentiment. To solve the second issue, we well-design a story-specific\ncontrastive training strategy that is adapted for SEG. Experiments show that\nCLSEG outperforms baselines and can produce story endings with stronger\nconsistency and rationality.",
    "descriptor": "\nComments: Accepted by ICASSP 2022. Code and Data: this https URL\n",
    "authors": [
      "Yuqiang Xie",
      "Yue Hu",
      "Luxi Xing",
      "Yunpeng Li",
      "Wei Peng",
      "Ping Guo"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.09049"
  },
  {
    "id": "arXiv:2202.09050",
    "title": "Guide Local Feature Matching by Overlap Estimation",
    "abstract": "Local image feature matching under large appearance, viewpoint, and distance\nchanges is challenging yet important. Conventional methods detect and match\ntentative local features across the whole images, with heuristic consistency\nchecks to guarantee reliable matches. In this paper, we introduce a novel\nOverlap Estimation method conditioned on image pairs with TRansformer, named\nOETR, to constrain local feature matching in the commonly visible region. OETR\nperforms overlap estimation in a two-step process of feature correlation and\nthen overlap regression. As a preprocessing module, OETR can be plugged into\nany existing local feature detection and matching pipeline, to mitigate\npotential view angle or scale variance. Intensive experiments show that OETR\ncan boost state-of-the-art local feature matching performance substantially,\nespecially for image pairs with small shared regions. The code will be publicly\navailable at https://github.com/AbyssGaze/OETR.",
    "descriptor": "",
    "authors": [
      "Ying Chen",
      "Dihe Huang",
      "Shang Xu",
      "Jianlin Liu",
      "Yong Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.09050"
  },
  {
    "id": "arXiv:2202.09052",
    "title": "Tackling benign nonconvexity with smoothing and stochastic gradients",
    "abstract": "Non-convex optimization problems are ubiquitous in machine learning,\nespecially in Deep Learning. While such complex problems can often be\nsuccessfully optimized in practice by using stochastic gradient descent (SGD),\ntheoretical analysis cannot adequately explain this success. In particular, the\nstandard analyses do not show global convergence of SGD on non-convex\nfunctions, and instead show convergence to stationary points (which can also be\nlocal minima or saddle points). We identify a broad class of nonconvex\nfunctions for which we can show that perturbed SGD (gradient descent perturbed\nby stochastic noise -- covering SGD as a special case) converges to a global\nminimum (or a neighborhood thereof), in contrast to gradient descent without\nnoise that can get stuck in local minima far from a global solution. For\nexample, on non-convex functions that are relatively close to a convex-like\n(strongly convex or PL) function we show that SGD can converge linearly to a\nglobal optimum.",
    "descriptor": "",
    "authors": [
      "Harsh Vardhan",
      "Sebastian U. Stich"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.09052"
  },
  {
    "id": "arXiv:2202.09055",
    "title": "Convergence analysis of a finite difference method for stochastic  Cahn--Hilliard equation",
    "abstract": "This paper presents the convergence analysis of the spatial finite difference\nmethod (FDM) for the stochastic Cahn--Hilliard equation with Lipschitz\nnonlinearity and multiplicative noise. Based on fine estimates of the discrete\nGreen function, we prove that both the spatial semi-discrete numerical solution\nand its Malliavin derivative have strong convergence order $1$. Further, by\nshowing the negative moment estimates of the exact solution, we obtain that the\ndensity of the spatial semi-discrete numerical solution converges in\n$L^1(\\mathbb R)$ to the exact one. Finally, we apply an exponential Euler\nmethod to discretize the spatial semi-discrete numerical solution in time and\nshow that the temporal strong convergence order is nearly $\\frac38$, where a\ndifficulty we overcome is to derive the optimal H\\\"older continuity of the\nspatial semi-discrete numerical solution.",
    "descriptor": "",
    "authors": [
      "Jialin Hong",
      "Diancong Jin",
      "Derui Sheng"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.09055"
  },
  {
    "id": "arXiv:2202.09056",
    "title": "Efficient solution of 3D elasticity problems with smoothed aggregation  algebraic multigrid and block arithmetics",
    "abstract": "Efficient solution of 3D elasticity problems is an important part of many\nindustrial and scientific applications. Smoothed aggregation algebraic\nmultigrid using rigid body modes for the tentative prolongation operator\nconstruction is an efficient and robust choice for the solution of linear\nsystems arising from the discretization of elasticity equations. The system\nmatrices on every level of the multigrid hierarchy have block structure, so\nusing block representation and block arithmetics should significantly improve\nthe solver efficiency. However, the tentative prolongation operator\nconstruction may only be done using scalar representation. The paper proposes a\ncouple of practical approaches for enabling the use of block arithmetics with\nsmoothed aggregation algebraic multigrid based on the open-source AMGCL\nlibrary. It is shown on the example of two real-world model problems that the\nsuggested improvements may speed up the solution by 50% and reduce the memory\nrequirements for the preconditioner by 30%. The implementation is\nstraightforward and only requires a minimal amount of code.",
    "descriptor": "\nComments: 10 pages, 2 figures\n",
    "authors": [
      "Denis Demidov"
    ],
    "subjectives": [
      "Mathematical Software (cs.MS)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.09056"
  },
  {
    "id": "arXiv:2202.09057",
    "title": "Fast K\u00f6tter-Nielsen-H\u00f8holdt Interpolation over Skew Polynomial Rings",
    "abstract": "Skew polynomials are a class of non-commutative polynomials that have several\napplications in computer science, coding theory and cryptography. In\nparticular, skew polynomials can be used to construct and decode evaluation\ncodes in several metrics, like e.g. the Hamming, rank, sum-rank and skew\nmetric. In this paper we propose a fast divide-and-conquer variant of the\nK\\\"otter-Nielsen-H{\\o}holdt (KNH) interpolation over free modules over skew\npolynomial rings. The proposed KNH interpolation can be used to solve the\ninterpolation step of interpolation-based decoding of (interleaved) Gabidulin,\nlinearized Reed-Solomon and skew Reed-Solomon codes efficiently, which have\nvarious applications in coding theory and code-based quantum-resistant\ncryptography.",
    "descriptor": "\nComments: 6 pages, 1 figure, submitted to: 25th International Symposium on Mathematical Theory of Networks and Systems (MTNS)\n",
    "authors": [
      "Hannes Bartz",
      "Thomas Jerkovits"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.09057"
  },
  {
    "id": "arXiv:2202.09060",
    "title": "Controllability of Networked Sampled-data Systems",
    "abstract": "The controllability of networked sampled-data systems with zero-order\nsamplers on the control and transmission channels is explored, where single-\nand multi-rate sampling patterns are considered, respectively. The effects of\nsampling on controllability of networked systems are analyzed, with some\nsufficient and/or necessary controllability conditions derived. Different from\nthe sampling control of single systems, the pathological sampling of node\nsystems could be eliminated by the network structure and inner couplings under\nsome conditions. While for singular topology matrix, the pathological sampling\nof single nodes will cause the entire system to lose controllability. Moreover,\ncontrollability of networked systems with specific node dynamics will not be\naffected by any periodic sampling. All the results indicate that whether a\nnetworked system is under pathological sampling or not is jointly determined by\nmutually coupled factors.",
    "descriptor": "",
    "authors": [
      "Zixuan Yang",
      "Xiaofan Wang",
      "Lin Wang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.09060"
  },
  {
    "id": "arXiv:2202.09061",
    "title": "VLP: A Survey on Vision-Language Pre-training",
    "abstract": "In the past few years, the emergence of pre-training models has brought\nuni-modal fields such as computer vision (CV) and natural language processing\n(NLP) to a new era. Substantial works have shown they are beneficial for\ndownstream uni-modal tasks and avoid training a new model from scratch. So can\nsuch pre-trained models be applied to multi-modal tasks? Researchers have\nexplored this problem and made significant progress. This paper surveys recent\nadvances and new frontiers in vision-language pre-training (VLP), including\nimage-text and video-text pre-training. To give readers a better overall grasp\nof VLP, we first review its recent advances from five aspects: feature\nextraction, model architecture, pre-training objectives, pre-training datasets,\nand downstream tasks. Then, we summarize the specific VLP models in detail.\nFinally, we discuss the new frontiers in VLP. To the best of our knowledge,\nthis is the first survey on VLP. We hope that this survey can shed light on\nfuture research in the VLP field.",
    "descriptor": "\nComments: A Survey on Vision-Language Pre-training\n",
    "authors": [
      "Feilong Chen",
      "Duzhan Zhang",
      "Minglun Han",
      "Xiuyi Chen",
      "Jing Shi",
      "Shuang Xu",
      "Bo Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.09061"
  },
  {
    "id": "arXiv:2202.09064",
    "title": "Can Interpretable Reinforcement Learning Manage Assets Your Way?",
    "abstract": "Personalisation of products and services is fast becoming the driver of\nsuccess in banking and commerce. Machine learning holds the promise of gaining\na deeper understanding of and tailoring to customers' needs and preferences.\nWhereas traditional solutions to financial decision problems frequently rely on\nmodel assumptions, reinforcement learning is able to exploit large amounts of\ndata to improve customer modelling and decision-making in complex financial\nenvironments with fewer assumptions. Model explainability and interpretability\npresent challenges from a regulatory perspective which demands transparency for\nacceptance; they also offer the opportunity for improved insight into and\nunderstanding of customers. Post-hoc approaches are typically used for\nexplaining pretrained reinforcement learning models. Based on our previous\nmodeling of customer spending behaviour, we adapt our recent reinforcement\nlearning algorithm that intrinsically characterizes desirable behaviours and we\ntransition to the problem of asset management. We train inherently\ninterpretable reinforcement learning agents to give investment advice that is\naligned with prototype financial personality traits which are combined to make\na final recommendation. We observe that the trained agents' advice adheres to\ntheir intended characteristics, they learn the value of compound growth, and,\nwithout any explicit reference, the notion of risk as well as improved policy\nconvergence.",
    "descriptor": "",
    "authors": [
      "Charl Maree",
      "Christian Omlin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.09064"
  },
  {
    "id": "arXiv:2202.09069",
    "title": "Analysis of optimal preconditioners for CutFEM",
    "abstract": "In this paper we consider a class of unfitted finite element methods for\nscalar elliptic problems. These so-called CutFEM methods use standard finite\nelement spaces on a fixed unfitted triangulation combined with the Nitsche\ntechnique and a ghost penalty stabilization. As a model problem we consider the\napplication of such a method to the Poisson interface problem. We introduce and\nanalyze a new class of preconditioners that is based on a subspace\ndecomposition approach. The unfitted finite element space is split into two\nsubspaces, where one subspace is the standard finite element space associated\nto the background mesh and the second subspace is spanned by all cut basis\nfunctions corresponding to nodes on the cut elements. We will show that this\nsplitting is stable, uniformly in the discretization parameter and in the\nlocation of the interface in the triangulation. Based on this we introduce an\nefficient preconditioner that is uniformly spectrally equivalent to the\nstiffness matrix. Using a similar splitting, it is shown that the same\npreconditioning approach can also be applied to a fictitious domain CutFEM\ndiscretization of the Poisson equation. Results of numerical experiments are\nincluded that illustrate optimality of such preconditioners for the Poisson\ninterface problem and the Poisson fictitious domain problem.",
    "descriptor": "\nComments: 20 pages, 3 figures. arXiv admin note: substantial text overlap with arXiv:2107.01182\n",
    "authors": [
      "Sven Gross",
      "Arnold Reusken"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.09069"
  },
  {
    "id": "arXiv:2202.09076",
    "title": "Improving Test Automation Maturity: a Multivocal Literature Review",
    "abstract": "Mature test automation is key for achieving software quality at speed. In\nthis paper, we present a multivocal literature review with the objective to\nsurvey and synthesize the guidelines given in the literature for improving test\nautomation maturity. We selected and reviewed 81 primary studies, consisting of\n26 academic literature and 55 grey literature sources. From primary studies, we\nextracted 26 test automation best practices (e.g., Define an effective test\nautomation strategy, Set up good test environments, Develop high-quality test\nscripts) and collected many pieces of advice (e.g., in forms of\nimplementation/improvement approaches, technical techniques, concepts,\nexperience-based heuristics) on how to conduct these best practices. We made\nmain observations: (1) There are only 6 best practices whose positive effect on\nmaturity improvement have been evaluated by academic studies using formal\nempirical methods; (2) Several technical related best practices in this MLR\nwere not presented in test maturity models; (3) Some best practices can be\nlinked to success factors and maturity impediments proposed by other scholars;\n(4) Most pieces of advice on how to conduct proposed best practices were\nidentified from experience studies and their effectiveness need to be further\nevaluated with cross-site empirical evidence using formal empirical methods;\n(5) In the literature, some advice on how to conduct certain best practices are\nconflicting, and some advice on how to conduct certain best practices still\nneed further qualitative analysis.",
    "descriptor": "\nComments: Journal of Software: Testing, Verification and Reliability (2022)\n",
    "authors": [
      "Yuqing Wang",
      "Mika V.M\u00e4ntyl\u00e4",
      "Zihao Liu",
      "Jouni Markkula",
      "P\u00e4ivi Raulamo-jurvanen"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2202.09076"
  },
  {
    "id": "arXiv:2202.09095",
    "title": "Private Information Retrieval from Colluding and Byzantine Servers with  Binary Reed-Muller Codes",
    "abstract": "In this work, a flexible and robust private information retrieval (PIR)\nscheme based on binary non-maximum distance separable (non-MDS) codes is\nconsidered. This combines previous works on PIR schemes based on transitive\nnon-MDS codes on one hand, and PIR from MDS-coded Byzantine and non-responsive\nservers on the other hand. More specifically, a PIR scheme employing binary\nReed-Muller (RM) codes tolerant to colluding, Byzantine, and non-responsive\nservers is constructed, and bounds for the achievable rates are derived under\ncertain conditions. The construction of such schemes turns out to be much more\ninvolved than for MDS codes. Namely, the binary query vectors have to be\nselected with great care to hit the desired information sets, which is\ntechnically challenging as will be shown.",
    "descriptor": "\nComments: conference submission, 6 pages\n",
    "authors": [
      "Perttu Saarela",
      "Matteo Allaix",
      "Ragnar Freij-Hollanti",
      "Camilla Hollanti"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.09095"
  },
  {
    "id": "arXiv:2202.09096",
    "title": "A Free Lunch with Influence Functions? Improving Neural Network  Estimates with Concepts from Semiparametric Statistics",
    "abstract": "Parameter estimation in the empirical fields is usually undertaken using\nparametric models, and such models are convenient because they readily\nfacilitate statistical inference. Unfortunately, they are unlikely to have a\nsufficiently flexible functional form to be able to adequately model real-world\nphenomena, and their usage may therefore result in biased estimates and invalid\ninference. Unfortunately, whilst non-parametric machine learning models may\nprovide the needed flexibility to adapt to the complexity of real-world\nphenomena, they do not readily facilitate statistical inference, and may still\nexhibit residual bias. We explore the potential for semiparametric theory (in\nparticular, the Influence Function) to be used to improve neural networks and\nmachine learning algorithms in terms of (a) improving initial estimates without\nneeding more data (b) increasing the robustness of our models, and (c) yielding\nconfidence intervals for statistical inference. We propose a new neural network\nmethod MultiNet, which seeks the flexibility and diversity of an ensemble using\na single architecture. Results on causal inference tasks indicate that MultiNet\nyields better performance than other approaches, and that all considered\nmethods are amenable to improvement from semiparametric techniques under\ncertain conditions. In other words, with these techniques we show that we can\nimprove existing neural networks for `free', without needing more data, and\nwithout needing to retrain them. Finally, we provide the expression for\nderiving influence functions for estimands from a general graph, and the code\nto do so automatically.",
    "descriptor": "",
    "authors": [
      "Matthew J. Vowels",
      "Sina Akbari",
      "Jalal Etesami",
      "Necati Cihan Camgoz",
      "Richard Bowden"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.09096"
  },
  {
    "id": "arXiv:2202.09097",
    "title": "Lightweight Multi-Drone Detection and 3D-Localization via YOLO",
    "abstract": "In this work, we present and evaluate a method to perform real-time multiple\ndrone detection and three-dimensional localization using state-of-the-art\ntiny-YOLOv4 object detection algorithm and stereo triangulation. Our computer\nvision approach eliminates the need for computationally expensive stereo\nmatching algorithms, thereby significantly reducing the memory footprint and\nmaking it deployable on embedded systems. Our drone detection system is highly\nmodular (with support for various detection algorithms) and capable of\nidentifying multiple drones in a system, with real-time detection accuracy of\nup to 77\\% with an average FPS of 332 (on Nvidia Titan Xp). We also test the\ncomplete pipeline in AirSim environment, detecting drones at a maximum distance\nof 8 meters, with a mean error of $23\\%$ of the distance. We also release the\nsource code for the project, with pre-trained models and the curated synthetic\nstereo dataset.",
    "descriptor": "",
    "authors": [
      "Aryan Sharma",
      "Nitik Jain",
      "Mangal Kothari"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.09097"
  },
  {
    "id": "arXiv:2202.09099",
    "title": "AMS_ADRN at SemEval-2022 Task 5: A Suitable Image-text Multimodal Joint  Modeling Method for Multi-task Misogyny Identification",
    "abstract": "Women are influential online, especially in image-based social media such as\nTwitter and Instagram. However, many in the network environment contain gender\ndiscrimination and aggressive information, which magnify gender stereotypes and\ngender inequality. Therefore, the filtering of illegal content such as gender\ndiscrimination is essential to maintain a healthy social network environment.\nIn this paper, we describe the system developed by our team for SemEval-2022\nTask 5: Multimedia Automatic Misogyny Identification. More specifically, we\nintroduce two novel system to analyze these posts: a multimodal multi-task\nlearning architecture that combines Bertweet for text encoding with ResNet-18\nfor image representation, and a single-flow transformer structure which\ncombines text embeddings from BERT-Embeddings and image embeddings from several\ndifferent modules such as EfficientNet and ResNet. In this manner, we show that\nthe information behind them can be properly revealed. Our approach achieves\ngood performance on each of the two subtasks of the current competition,\nranking 15th for Subtask A (0.746 macro F1-score), 11th for Subtask B (0.706\nmacro F1-score) while exceeding the official baseline results by high margins.",
    "descriptor": "",
    "authors": [
      "Da Li",
      "Ming Yi",
      "Yukai He"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.09099"
  },
  {
    "id": "arXiv:2202.09102",
    "title": "Predicting Sex and Stroke Success -- Computer-aided Player Grunt  Analysis in Tennis Matches",
    "abstract": "Professional athletes increasingly use automated analysis of meta- and signal\ndata to improve their training and game performance. As in other related\nhuman-to-human research fields, signal data, in particular, contain important\nperformance- and mood-specific indicators for automated analysis. In this\npaper, we introduce the novel data set SCORE! to investigate the performance of\nseveral features and machine learning paradigms in the prediction of the sex\nand immediate stroke success in tennis matches, based only on vocal expression\nthrough players' grunts. The data was gathered from YouTube, labelled under the\nexact same definition, and the audio processed for modelling. We extract\nseveral widely used basic, expert-knowledge, and deep acoustic features of the\naudio samples and evaluate their effectiveness in combination with various\nmachine learning approaches. In a binary setting, the best system, using\nspectrograms and a Convolutional Recurrent Neural Network, achieves an\nunweighted average recall (UAR) of 84.0 % for the player sex prediction task,\nand 60.3 % predicting stroke success, based only on acoustic cues in players'\ngrunts of both sexes. Further, we achieve a UAR of 58.3 %, and 61.3 %, when the\nmodels are exclusively trained on female or male grunts, respectively.",
    "descriptor": "",
    "authors": [
      "Lukas Stappen",
      "Manuel Milling",
      "Valentin Munst",
      "Korakot Hoffmann",
      "Bjorn W. Schuller"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Multimedia (cs.MM)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2202.09102"
  },
  {
    "id": "arXiv:2202.09105",
    "title": "Event-Triggered Distributed Model Predictive Control for Platoon  Coordination at Hubs in a Transport System",
    "abstract": "This paper considers the problem of hub-based platoon coordination for a\nlarge-scale transport system, where trucks have individual utility functions to\noptimize. An event-triggered distributed model predictive control method is\nproposed to solve the optimal scheduling of waiting times at hubs for\nindividual trucks. In this distributed framework, trucks are allowed to decide\ntheir waiting times independently and only limited information is shared\nbetween trucks. Both the predicted reward gained from platooning and the\npredicted cost for waiting at hubs are included in each truck's utility\nfunction. The performance of the coordination method is demonstrated in a\nsimulation with one hundred trucks over the Swedish road network.",
    "descriptor": "\nComments: CDC 2021\n",
    "authors": [
      "Ting Bai",
      "Alexander Johansson",
      "Karl Henrik Johansson",
      "Jonas M\u00e5rtensson"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.09105"
  },
  {
    "id": "arXiv:2202.09108",
    "title": "Large-Scale Acoustic Characterization of Singaporean Children's English  Pronunciation",
    "abstract": "In this work, we investigate pronunciation differences in English spoken by\nSingaporean children in relation to their American and British counterparts by\nconducting Kmeans clustering and Archetypal analysis on selected vowel pairs\nand approximants. Given that Singapore adopts British English as the\ninstitutional standard due to historical reasons, one might expect Singaporean\nchildren to follow British pronunciation patterns. Indeed, Singaporean and\nBritish children are more similar in their production of syllable-final /r/ --\nthey do not lower their third formant nearly as much as American children do,\nsuggesting a lack of rhoticity. Interestingly, Singaporean children also\npresent similar patterns to American children when it comes to their fronting\nof vowels as demonstrated across various vowels including TRAP-BATH split\nvowels. Singaporean children's English also demonstrated characteristics that\ndo not resemble any of the other two populations. We observe that Singaporean\nchildren's vowel height characteristics are distinct from both that of American\nand British children. In tense and lax vowel pairs, we also consistently\nobserve that the distinction is less conspicuous for Singaporean children\ncompared to the other speaker groups. Further, while American and British\nchildren demonstrate lowering of F1 and F2 formants in transitions into\nsyllable-final /l/s, a wide gap between F2 and F3 formants, and small\ndifference between F1 and F2 formants, all of these are not exhibited in\nSingaporean children's pronunciation. These findings point towards potential\nsociolinguistic implications of how Singapore English might be evolving to\nembody more than British pronunciation characteristics. Furthermore, these\nfindings also suggest that Singapore English could be have been influenced by\nlanguages beyond American and British English, potentially due to Singapore's\nmultilingual environment.",
    "descriptor": "",
    "authors": [
      "Yuling Gu",
      "Nancy F. Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2202.09108"
  },
  {
    "id": "arXiv:2202.09110",
    "title": "Iterative Learning for Instance Segmentation",
    "abstract": "Instance segmentation is a computer vision task where separate objects in an\nimage are detected and segmented. State-of-the-art deep neural network models\nrequire large amounts of labeled data in order to perform well in this task.\nMaking these annotations is time-consuming. We propose for the first time, an\niterative learning and annotation method that is able to detect, segment and\nannotate instances in datasets composed of multiple similar objects. The\napproach requires minimal human intervention and needs only a bootstrapping set\ncontaining very few annotations. Experiments on two different datasets show the\nvalidity of the approach in different applications related to visual\ninspection.",
    "descriptor": "\nComments: 5 pages, 6 figures\n",
    "authors": [
      "Tuomas Sormunen",
      "Arttu L\u00e4ms\u00e4",
      "Miguel Bordallo Lopez"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.09110"
  },
  {
    "id": "arXiv:2202.09112",
    "title": "Prepare your video for streaming with Segue",
    "abstract": "We identify new opportunities in video streaming, involving the joint\nconsideration of offline video chunking and online rate adaptation. We observe\nthat due to a video's complexity varying over time, certain parts are more\nlikely to cause performance impairments during playback with a particular rate\nadaptation algorithm. To address this, we propose careful use of\nvariable-length video segments, and augmentation of certain segments with\nadditional bitrate tracks. The key novelty of Segue is in making these\ndecisions based on the video's time varying complexity and the expected rate\nadaptation behavior over time. We propose and implement several methods for\nsuch adaptation-aware chunking. Our results show that Segue substantially\nreduces rebuffering and quality fluctuations, while maintaining video quality\ndelivered; Segue improves QoE by 9% on average, and by 22% in low-bandwidth\nconditions. Beyond our specific approach, we view our problem framing as a\nfirst step in a new thread on algorithmic and design innovation in video\nstreaming, and leave the reader with several interesting open questions.",
    "descriptor": "",
    "authors": [
      "Melissa Licciardello",
      "Lukas Humbel",
      "Fabian Rohr",
      "Maximilian Gr\u00fcner",
      "Ankit Singla"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2202.09112"
  },
  {
    "id": "arXiv:2202.09113",
    "title": "How to Manage Tiny Machine Learning at Scale: An Industrial Perspective",
    "abstract": "Tiny machine learning (TinyML) has gained widespread popularity where machine\nlearning (ML) is democratized on ubiquitous microcontrollers, processing sensor\ndata everywhere in real-time. To manage TinyML in the industry, where mass\ndeployment happens, we consider the hardware and software constraints, ranging\nfrom available onboard sensors and memory size to ML-model architectures and\nruntime platforms. However, Internet of Things (IoT) devices are typically\ntailored to specific tasks and are subject to heterogeneity and limited\nresources. Moreover, TinyML models have been developed with different\nstructures and are often distributed without a clear understanding of their\nworking principles, leading to a fragmented ecosystem. Considering these\nchallenges, we propose a framework using Semantic Web technologies to enable\nthe joint management of TinyML models and IoT devices at scale, from modeling\ninformation to discovering possible combinations and benchmarking, and\neventually facilitate TinyML component exchange and reuse. We present an\nontology (semantic schema) for neural network models aligned with the World\nWide Web Consortium (W3C) Thing Description, which semantically describes IoT\ndevices. Furthermore, a Knowledge Graph of 23 publicly available ML models and\nsix IoT devices were used to demonstrate our concept in three case studies, and\nwe shared the code and examples to enhance reproducibility:\nhttps://github.com/Haoyu-R/How-to-Manage-TinyML-at-Scale",
    "descriptor": "\nComments: Accepted by The 2022 tinyML Research Symposium\n",
    "authors": [
      "Haoyu Ren",
      "Darko Anicic",
      "Thomas Runkler"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2202.09113"
  },
  {
    "id": "arXiv:2202.09115",
    "title": "Towards Simple and Accurate Human Pose Estimation with Stair Network",
    "abstract": "In this paper, we focus on tackling the precise keypoint coordinates\nregression task. Most existing approaches adopt complicated networks with a\nlarge number of parameters, leading to a heavy model with poor\ncost-effectiveness in practice. To overcome this limitation, we develop a small\nyet discrimicative model called STair Network, which can be simply stacked\ntowards an accurate multi-stage pose estimation system. Specifically, to reduce\ncomputational cost, STair Network is composed of novel basic feature extraction\nblocks which focus on promoting feature diversity and obtaining rich local\nrepresentations with fewer parameters, enabling a satisfactory balance on\nefficiency and performance. To further improve the performance, we introduce\ntwo mechanisms with negligible computational cost, focusing on feature fusion\nand replenish. We demonstrate the effectiveness of the STair Network on two\nstandard datasets, e.g., 1-stage STair Network achieves a higher accuracy than\nHRNet by 5.5% on COCO test dataset with 80\\% fewer parameters and 68% fewer\nGFLOPs.",
    "descriptor": "",
    "authors": [
      "Chenru Jiang",
      "Kaizhu Huang",
      "Shufei Zhang",
      "Shufei Zhang",
      "Jimin Xiao",
      "Zhenxing Niu",
      "Amir Hussain"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.09115"
  },
  {
    "id": "arXiv:2202.09119",
    "title": "Truck Platoon Formation at Hubs: An Optimal Release Time Rule",
    "abstract": "We consider a hub-based platoon coordination problem in which vehicles arrive\nat a hub according to an independent and identically distributed stochastic\narrival process. The vehicles wait at the hub, and a platoon coordinator, at\neach time-step, decides whether to release the vehicles from the hub in the\nform of a platoon or wait for more vehicles to arrive. The platoon release time\nproblem is modeled as a stopping rule problem wherein the objective is to\nmaximize the average platooning benefit of the vehicles located at the hub and\nthere is a cost of having vehicles waiting at the hub. We show that the\nstopping rule problem is monotone and the optimal platoon release time policy\nwill therefore be in the form of a one time-step look-ahead rule. The\nperformance of the optimal release rule is numerically compared with (i) a\nperiodic release time rule and (ii) a non-causal release time rule where the\ncoordinator knows all the future realizations of the arrival process. Our\nnumerical results show that the optimal release time rule achieves a close\nperformance to that of the non-causal rule and outperforms the periodic rule,\nespecially when the arrival rate is low.",
    "descriptor": "\nComments: IFAC2020\n",
    "authors": [
      "Alexander Johansson",
      "Valerio Turri",
      "Ehsan Nekouei",
      "Karl H. Johansson",
      "Jonas M\u00e5rtensson"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.09119"
  },
  {
    "id": "arXiv:2202.09122",
    "title": "Decentralized Verifiable Mail-in Ballot Counting for Postal Voting",
    "abstract": "As computer vision is prevalently used for mail-in ballot processing and\ncounting, it becomes a point of centralized trust in postal voting. We propose\nDVote, a prototype system of postal voting that provides decentralized trust in\ncomputer vision. With blockchain and layer-2 technologies, DVote decentralizes\nthe computation and model training of computer vision to a group of scrutineers\nthat hold the AnyTrust assumption, i.e., at least one member is honest.\nConsequently, the computational integrity is anchored to the trustworthiness of\na large public blockchain such as Ethereum.",
    "descriptor": "",
    "authors": [
      "Peichen Xie",
      "Zihan Zheng",
      "Xian Zhang",
      "Shuo Chen"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.09122"
  },
  {
    "id": "arXiv:2202.09123",
    "title": "Make Every Word Count: Adaptive BA with Fewer Words",
    "abstract": "Byzantine Agreement is a key component in many distributed systems. While\nDolev and Reischuk have proven a long time ago that quadratic communication\ncomplexity is necessary for worst-case runs, the question of what can be done\nin practically common runs with fewer failures remained open. In this paper we\npresent the first Byzantine Broadcast algorithm with $O(n(f+1))$ communication\ncomplexity, where $0\\leq f\\leq t$ is the actual number of process failures in a\nrun. And for BA with strong unanimity, we present the first optimal-resilience\nalgorithm that has linear communication complexity in the failure-free case and\na quadratic cost otherwise.",
    "descriptor": "",
    "authors": [
      "Shir Cohen",
      "Idit Keidar",
      "Alexander Spiegelman"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2202.09123"
  },
  {
    "id": "arXiv:2202.09128",
    "title": "Energy Efficient Dual-Functional Radar-Communication: Rate-Splitting  Multiple Access, Low-Resolution DACs, and RF Chain Selection",
    "abstract": "Dual-Functional Radar-Communication systems enhance the benefits of\ncommunications and radar sensing by jointly implementing these on the same\nhardware platform and using the common RF resources. An important and latest\nconcern to be addressed in designing such Dual-Functional Radar-Communication\nsystems is maximizing the energy-efficiency. In this paper, we consider a\nDual-Functional Radar-Communication system performing simultaneous multi-user\ncommunications and radar sensing, and investigate the energy-efficiency\nbehaviour with respect to active transmission elements. Specifically, we\nformulate a problem to find the optimal precoders and the number of active RF\nchains for maximum energy-efficiency by taking into consideration the power\nconsumption of low-resolution Digital-to-Analog Converters on each RF chain\nunder communications and radar performance constraints. We consider\nRate-Splitting Multiple Access to perform multi-user communications with\nperfect and imperfect Channel State Information at Transmitter. The formulated\nnon-convex optimization problem is solved by means of a novel algorithm. We\ndemonstrate by numerical results that Rate Splitting Multiple Access achieves\nan improved energy-efficiency by employing a smaller number of RF chains\ncompared to Space Division Multiple Access, owing to its generalized structure\nand improved interference management capabilities.",
    "descriptor": "",
    "authors": [
      "Onur Dizdar",
      "Aryan Kaushik",
      "Bruno Clerckx",
      "Christos Masouros"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.09128"
  },
  {
    "id": "arXiv:2202.09134",
    "title": "Quantifying the Effects of Data Augmentation",
    "abstract": "We provide results that exactly quantify how data augmentation affects the\nconvergence rate and variance of estimates. They lead to some unexpected\nfindings: Contrary to common intuition, data augmentation may increase rather\nthan decrease uncertainty of estimates, such as the empirical prediction risk.\nOur main theoretical tool is a limit theorem for functions of randomly\ntransformed, high-dimensional random vectors. The proof draws on work in\nprobability on noise stability of functions of many variables. The pathological\nbehavior we identify is not a consequence of complex models, but can occur even\nin the simplest settings -- one of our examples is a linear ridge regressor\nwith two parameters. On the other hand, our results also show that data\naugmentation can have real, quantifiable benefits.",
    "descriptor": "",
    "authors": [
      "Kevin H. Huang",
      "Peter Orbanz",
      "Morgane Austern"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.09134"
  },
  {
    "id": "arXiv:2202.09136",
    "title": "FORT: Right-proving and Attribute-blinding Self-sovereign Authentication",
    "abstract": "Nowadays, there is a plethora of services that are provided and paid for\nonline, like video streaming subscriptions, car or parking sharing, purchasing\ntickets for events, etc. Online services usually issue tokens directly related\nto the identities of their users after signing up into their platform, and the\nusers need to authenticate using the same credentials each time they are\nwilling to use the service. Likewise, when using in-person services like going\nto a concert, after paying for this service the user usually gets a ticket\nwhich proves that he/she has the right to use that service. In both scenarios,\nthe main concerns are the centralization of the systems, and that they do not\nensure customers' privacy. The involved Service Providers are Trusted Third\nParties, authorities that offer services and handle private data about users.\nIn this paper, we design and implement FORT, a decentralized system that allows\ncustomers to prove their right to use specific services (either online or\nin-person) without revealing sensitive information. To achieve decentralization\nwe propose a solution where all the data is handled by a Blockchain. We\ndescribe and uniquely identify users' rights using Non-Fungible Tokens (NFTs),\nand possession of these rights is demonstrated by using Zero-Knowledge Proofs,\ncryptographic primitives that allow us to guarantee customers' privacy.\nFurthermore, we provide benchmarks of FORT which show that our protocol is\nefficient enough to be used in devices with low computing resources, like\nsmartphones or smartwatches, which are the kind of devices commonly used in our\nuse case scenario.",
    "descriptor": "",
    "authors": [
      "Xavier Salleras",
      "Sergi Rovira",
      "Vanesa Daza"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.09136"
  },
  {
    "id": "arXiv:2202.09144",
    "title": "Modelling the semantics of text in complex document layouts using graph  transformer networks",
    "abstract": "Representing structured text from complex documents typically calls for\ndifferent machine learning techniques, such as language models for paragraphs\nand convolutional neural networks (CNNs) for table extraction, which prohibits\ndrawing links between text spans from different content types. In this article\nwe propose a model that approximates the human reading pattern of a document\nand outputs a unique semantic representation for every text span irrespective\nof the content type they are found in. We base our architecture on a graph\nrepresentation of the structured text, and we demonstrate that not only can we\nretrieve semantically similar information across documents but also that the\nembedding space we generate captures useful semantic information, similar to\nlanguage models that work only on text sequences.",
    "descriptor": "",
    "authors": [
      "Thomas Roland Barillot",
      "Jacob Saks",
      "Polena Lilyanova",
      "Edward Torgas",
      "Yachen Hu",
      "Yuanqing Liu",
      "Varun Balupuri",
      "Paul Gaskell"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.09144"
  },
  {
    "id": "arXiv:2202.09145",
    "title": "Generalizing Aggregation Functions in GNNs:High-Capacity GNNs via  Nonlinear Neighborhood Aggregators",
    "abstract": "Graph neural networks (GNNs) have achieved great success in many graph\nlearning tasks. The main aspect powering existing GNNs is the multi-layer\nnetwork architecture to learn the nonlinear graph representations for the\nspecific learning tasks. The core operation in GNNs is message propagation in\nwhich each node updates its representation by aggregating its neighbors'\nrepresentations. Existing GNNs mainly adopt either linear neighborhood\naggregation (mean,sum) or max aggregator in their message propagation. (1) For\nlinear aggregators, the whole nonlinearity and network's capacity of GNNs are\ngenerally limited due to deeper GNNs usually suffer from over-smoothing issue.\n(2) For max aggregator, it usually fails to be aware of the detailed\ninformation of node representations within neighborhood. To overcome these\nissues, we re-think the message propagation mechanism in GNNs and aim to\ndevelop the general nonlinear aggregators for neighborhood information\naggregation in GNNs. One main aspect of our proposed nonlinear aggregators is\nthat they provide the optimally balanced aggregators between max and mean/sum\naggregations. Thus, our aggregators can inherit both (i) high nonlinearity that\nincreases network's capacity and (ii) detail-sensitivity that preserves the\ndetailed information of representations together in GNNs' message propagation.\nPromising experiments on several datasets show the effectiveness of the\nproposed nonlinear aggregators.",
    "descriptor": "",
    "authors": [
      "Beibei Wang",
      "Bo Jiang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.09145"
  },
  {
    "id": "arXiv:2202.09146",
    "title": "MultiRes-NetVLAD: Augmenting Place Recognition Training with  Low-Resolution Imagery",
    "abstract": "Visual Place Recognition (VPR) is a crucial component of 6-DoF localization,\nvisual SLAM and structure-from-motion pipelines, tasked to generate an initial\nlist of place match hypotheses by matching global place descriptors. However,\ncommonly-used CNN-based methods either process multiple image resolutions after\ntraining or use a single resolution and limit multi-scale feature extraction to\nthe last convolutional layer during training. In this paper, we augment NetVLAD\nrepresentation learning with low-resolution image pyramid encoding which leads\nto richer place representations. The resultant multi-resolution feature pyramid\ncan be conveniently aggregated through VLAD into a single compact\nrepresentation, avoiding the need for concatenation or summation of multiple\npatches in recent multi-scale approaches. Furthermore, we show that the\nunderlying learnt feature tensor can be combined with existing multi-scale\napproaches to improve their baseline performance. Evaluation on 15\nviewpoint-varying and viewpoint-consistent benchmarking datasets confirm that\nthe proposed MultiRes-NetVLAD leads to state-of-the-art Recall@N performance\nfor global descriptor based retrieval, compared against 11 existing techniques.\nSource code is publicly available at\nhttps://github.com/Ahmedest61/MultiRes-NetVLAD.",
    "descriptor": "\nComments: 12 pages, 6 Figures, Accepted for publication in IEEE RA-L 2022 and ICRA 2022, includes supplementary material\n",
    "authors": [
      "Ahmad Khaliq",
      "Michael Milford",
      "Sourav Garg"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.09146"
  },
  {
    "id": "arXiv:2202.09149",
    "title": "Analysis and approximations of an optimal control problem for the  Allen-Cahn equation",
    "abstract": "The scope of this paper is the analysis and approximation of an optimal\ncontrol problem related to the Allen-Cahn equation. A tracking functional is\nminimized subject to the Allen-Cahn equation using distributed controls that\nsatisfy point-wise control constraints. First and second order necessary and\nsufficient conditions are proved. The lowest order discontinuous Galerkin - in\ntime - scheme is considered for the approximation of the control to state and\nadjoint state mappings. Under a suitable restriction on maximum size of the\ntemporal and spatial discretization parameters $k$, $h$ respectively in terms\nof the parameter $\\epsilon$ that describes the thickness of the interface\nlayer, a-priori estimates are proved with constants depending polynomially upon\n$1/ \\epsilon$. Unlike to previous works for the uncontrolled Allen-Cahn problem\nour approach does not rely on a construction of an approximation of the\nspectral estimate, and as a consequence our estimates are valid under low\nregularity assumptions imposed by the optimal control setting. These estimates\nare also valid in cases where the solution and its discrete approximation do\nnot satisfy uniform space-time bounds independent of $\\epsilon$. These\nestimates and a suitable localization technique, via the second order condition\n(see\n\\cite{Arada-Casas-Troltzsch_2002,Casas-Mateos-Troltzsch_2005,Casas-Raymond_2006,Casas-Mateos-Raymond_2007}),\nallows to prove error estimates for the difference between local optimal\ncontrols and their discrete approximation as well as between the associated\nstate and adjoint state variables and their discrete approximations",
    "descriptor": "",
    "authors": [
      "Konstantinos Chrysafinos",
      "Dimitra Plaka"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2202.09149"
  },
  {
    "id": "arXiv:2202.09150",
    "title": "Personalization Trade-offs in Designing a Dialogue-based Information  System for Support-Seeking of Sexual Violence Survivors",
    "abstract": "The lack of reliable, personalized information often complicates sexual\nviolence survivors' support-seeking. Recently, there is an emerging approach to\nconversational information systems for support-seeking of sexual violence\nsurvivors, featuring personalization with wide availability and anonymity.\nHowever, a single best solution might not exist as sexual violence survivors\nhave different needs and purposes in seeking support channels. To better\nenvision conversational support-seeking systems for sexual violence survivors,\nwe explore personalization trade-offs in designing such information systems. We\nimplement a high-fidelity prototype dialogue-based information system through\nfour design workshop sessions with three professional caregivers and\ninterviewed with four self-identified survivors using our prototype. We then\nidentify two forms of personalization trade-offs for conversational\nsupport-seeking systems: (1) specificity and sensitivity in understanding users\nand (2) relevancy and inclusiveness in providing information. To handle these\ntrade-offs, we propose a reversed approach that starts from designing\ninformation and inclusive tailoring that considers unspecified needs,\nrespectively.",
    "descriptor": "\nComments: 15 pages, 2 figures, 1 table, accepted for CHI 2022\n",
    "authors": [
      "Hyeok Kim",
      "Youjin Hwang",
      "Jieun Lee",
      "Youngjin Kwon",
      "Yujin Park",
      "Joonhwan Lee"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2202.09150"
  },
  {
    "id": "arXiv:2202.09152",
    "title": "The application of geographic information systems in schools around the  world: a retrospective analysis",
    "abstract": "The article is devoted to the problem of incorporation geographic information\nsystems (GIS) in world school practice. The authors single out the stages of\nGIS application in school geographical education based on the retrospective\nanalysis of the scientific literature. The first stage (late 70s - early 90s of\nthe 20th century) is the beginning of the first educational GIS programs and\npartnership agreements between schools and universities. The second stage (mid\n90s of the 20th century - the beginning of the 21st century) comprises the\ndistribution of GIS-educational programs in European and Australian schools\nwith the involvement of leading developers of GIS-packages (ESRI, Intergraph,\nMapInfo Corp., etc.). The third stage (2005-2012) marks the spread of the GIS\nschool education in Eastern Europe, Asia, Africa and Latin America; on the\nfourth stage (from 2012 to the present) geographic information systems emerge\nin school curricula in most countries. The haracteristics of the\nGIS-technologies development stages are given considering the GIS didactic\npossibilities for the study of school geography, as well as highlighting their\nadvantages and disadvantages.",
    "descriptor": "\nComments: 16 pages, 6 figure, 2 table\n",
    "authors": [
      "Ihor Kholoshyn",
      "Tetiana Nazarenko",
      "Olga Bondarenko",
      "Olena Hanchuk",
      "Iryna Varfolomyeyeva"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2202.09152"
  },
  {
    "id": "arXiv:2202.09153",
    "title": "Gaussian Mixture Convolution Networks",
    "abstract": "This paper proposes a novel method for deep learning based on the analytical\nconvolution of multidimensional Gaussian mixtures. In contrast to tensors,\nthese do not suffer from the curse of dimensionality and allow for a compact\nrepresentation, as data is only stored where details exist. Convolution kernels\nand data are Gaussian mixtures with unconstrained weights, positions, and\ncovariance matrices. Similar to discrete convolutional networks, each\nconvolution step produces several feature channels, represented by independent\nGaussian mixtures. Since traditional transfer functions like ReLUs do not\nproduce Gaussian mixtures, we propose using a fitting of these functions\ninstead. This fitting step also acts as a pooling layer if the number of\nGaussian components is reduced appropriately. We demonstrate that networks\nbased on this architecture reach competitive accuracy on Gaussian mixtures\nfitted to the MNIST and ModelNet data sets.",
    "descriptor": "\nComments: To be published in ICLR 2022\n",
    "authors": [
      "Adam Celarek",
      "Pedro Hermosilla",
      "Bernhard Kerbl",
      "Timo Ropinski",
      "Michael Wimmer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.09153"
  },
  {
    "id": "arXiv:2202.09155",
    "title": "PerFED-GAN: Personalized Federated Learning via Generative Adversarial  Networks",
    "abstract": "Federated learning is gaining popularity as a distributed machine learning\nmethod that can be used to deploy AI-dependent IoT applications while\nprotecting client data privacy and security. Due to the differences of clients,\na single global model may not perform well on all clients, so the personalized\nfederated learning method, which trains a personalized model for each client\nthat better suits its individual needs, becomes a research hotspot. Most\npersonalized federated learning research, however, focuses on data\nheterogeneity while ignoring the need for model architecture heterogeneity.\nMost existing federated learning methods uniformly set the model architecture\nof all clients participating in federated learning, which is inconvenient for\neach client's individual model and local data distribution requirements, and\nalso increases the risk of client model leakage. This paper proposes a\nfederated learning method based on co-training and generative adversarial\nnetworks(GANs) that allows each client to design its own model to participate\nin federated learning training independently without sharing any model\narchitecture or parameter information with other clients or a center. In our\nexperiments, the proposed method outperforms the existing methods in mean test\naccuracy by 42% when the client's model architecture and data distribution vary\nsignificantly.",
    "descriptor": "",
    "authors": [
      "Xingjian Cao",
      "Gang Sun",
      "Hongfang Yu",
      "Mohsen Guizani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.09155"
  },
  {
    "id": "arXiv:2202.09157",
    "title": "Tackling A Class of Hard Subset-Sum Problems: Integration of Lattice  Attacks with Disaggregation Techniques",
    "abstract": "Subset-sum problems belong to the NP class and play an important role in both\ncomplexity theory and knapsack-based cryptosystems, which have been proved in\nthe literature to become hardest when the so-called density approaches one.\nLattice attacks, which are acknowledged in the literature as the most effective\nmethods, fail occasionally even when the number of unknown variables is of\nmedium size. In this paper we propose a modular disaggregation technique and a\nsimplified lattice formulation based on which two lattice attack algorithms are\nfurther designed. We introduce the new concept \"jump points\" in our\ndisaggregation technique, and derive inequality conditions to identify superior\njump points which can more easily cut-off non-desirable short integer\nsolutions. Empirical tests have been conducted to show that integrating the\ndisaggregation technique with lattice attacks can effectively raise success\nratios to 100% for randomly generated problems with density one and of\ndimensions up to 100. Finally, statistical regressions are conducted to test\nsignificant features, thus revealing reasonable factors behind the empirical\nsuccess of our algorithms and techniques proposed in this paper.",
    "descriptor": "\nComments: 50 pages, 6 figures, 17 tables\n",
    "authors": [
      "Bojun Lu",
      "Duan Li",
      "Rujun Jiang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.09157"
  },
  {
    "id": "arXiv:2202.09161",
    "title": "The use of AR elements in the study of foreign languages at the  university",
    "abstract": "The article deals with the analysis of the impact of the using AR technology\nin the study of a foreign language by university students. It is stated out\nthat AR technology can be a good tool for learning a foreign language. The use\nof elements of AR in the course of studying a foreign language, in particular\nin the form of virtual excursions, is proposed. Advantages of using AR\ntechnology in the study of the German language are identified, namely: the\npossibility of involvement of different channels of information perception, the\nintegrity of the representation of the studied object, the faster and better\nmemorization of new vocabulary, the development of communicative foreign\nlanguage skills. The ease and accessibility of using QR codes to obtain\ninformation about the object of study from open Internet sources is shown. The\nresults of a survey of students after virtual tours are presented. A\nreorientation of methodological support for the study of a foreign language at\nuniversities is proposed. Attention is drawn to the use of AR elements in order\nto support students with different learning styles (audio, visual,\nkinesthetic).",
    "descriptor": "\nComments: 14 pages, 5 figures, 1 table\n",
    "authors": [
      "Rostyslav Tarasenko",
      "Svitlana Amelina",
      "Yuliya Kazhan",
      "Olga Bondarenko"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2202.09161"
  },
  {
    "id": "arXiv:2202.09163",
    "title": "Selection Strategies for Commonsense Knowledge",
    "abstract": "Selection strategies are broadly used in first-order logic theorem proving to\nselect those parts of a large knowledge base that are necessary to proof a\ntheorem at hand. Usually, these selection strategies do not take the meaning of\nsymbol names into account. In knowledge bases with commonsense knowledge,\nsymbol names are usually chosen to have a meaning and this meaning provides\nvaluable information for selection strategies. We introduce the vector-based\nselection strategy, a purely statistical selection technique for commonsense\nknowledge based on word embeddings. We compare different commonsense knowledge\nselection techniques for the purpose of theorem proving and demonstrate the\nusefulness of vector-based selection with a case study.",
    "descriptor": "",
    "authors": [
      "Claudia Schon"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.09163"
  },
  {
    "id": "arXiv:2202.09166",
    "title": "Evaluating the Construct Validity of Text Embeddings with Application to  Survey Questions",
    "abstract": "Text embedding models from Natural Language Processing can map text data\n(e.g. words, sentences, documents) to supposedly meaningful numerical\nrepresentations (a.k.a. text embeddings). While such models are increasingly\napplied in social science research, one important issue is often not addressed:\nthe extent to which these embeddings are valid representations of constructs\nrelevant for social science research. We therefore propose the use of the\nclassic construct validity framework to evaluate the validity of text\nembeddings. We show how this framework can be adapted to the opaque and\nhigh-dimensional nature of text embeddings, with application to survey\nquestions. We include several popular text embedding methods (e.g. fastText,\nGloVe, BERT, Sentence-BERT, Universal Sentence Encoder) in our construct\nvalidity analyses. We find evidence of convergent and discriminant validity in\nsome cases. We also show that embeddings can be used to predict respondent's\nanswers to completely new survey questions. Furthermore, BERT-based embedding\ntechniques and the Universal Sentence Encoder provide more valid\nrepresentations of survey questions than do others. Our results thus highlight\nthe necessity to examine the construct validity of text embeddings before\ndeploying them in social science research.",
    "descriptor": "\nComments: Under review\n",
    "authors": [
      "Qixiang Fang",
      "Dong Nguyen",
      "Daniel L Oberski"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Computation and Language (cs.CL)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2202.09166"
  },
  {
    "id": "arXiv:2202.09171",
    "title": "Linearization and Identification of Multiple-Attractors Dynamical System  through Laplacian Eigenmaps",
    "abstract": "Dynamical Systems (DS) are fundamental to the modeling and understanding of\ntime evolving phenomena, and find application in physics, biology and control.\nAs determining an analytical description of the dynamics is often difficult,\ndata-driven approaches are preferred for identifying and controlling nonlinear\nDS with multiple equilibrium points. Identification of such DS has been treated\nlargely as a supervised learning problem. Instead, we focus on a unsupervised\nlearning scenario where we know neither the number nor the type of dynamics. We\npropose a Graph-based spectral clustering method that takes advantage of a\nvelocity-augmented kernel to connect data-points belonging to the same\ndynamics, while preserving the natural temporal evolution. We study the\neigenvectors and eigenvalues of the Graph Laplacian and show that they form a\nset of orthogonal embedding spaces, one for each sub-dynamics. We prove that\nthere always exist a set of 2-dimensional embedding spaces in which the\nsub-dynamics are linear, and n-dimensional embedding where they are\nquasi-linear. We compare the clustering performance of our algorithm to Kernel\nK-Means, Spectral Clustering and Gaussian Mixtures and show that, even when\nthese algorithms are provided with the true number of sub-dynamics, they fail\nto cluster them correctly. We learn a diffeomorphism from the Laplacian\nembedding space to the original space and show that the Laplacian embedding\nleads to good reconstruction accuracy and a faster training time through an\nexponential decaying loss, compared to the state of the art\ndiffeomorphism-based approaches.",
    "descriptor": "",
    "authors": [
      "Bernardo Fichera",
      "Aude Billard"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.09171"
  },
  {
    "id": "arXiv:2202.09177",
    "title": "Space4HGNN: A Novel, Modularized and Reproducible Platform to Evaluate  Heterogeneous Graph Neural Network",
    "abstract": "Heterogeneous Graph Neural Network (HGNN) has been successfully employed in\nvarious tasks, but we cannot accurately know the importance of different design\ndimensions of HGNNs due to diverse architectures and applied scenarios.\nBesides, in the research community of HGNNs, implementing and evaluating\nvarious tasks still need much human effort. To mitigate these issues, we first\npropose a unified framework covering most HGNNs, consisting of three\ncomponents: heterogeneous linear transformation, heterogeneous graph\ntransformation, and heterogeneous message passing layer. Then we build a\nplatform Space4HGNN by defining a design space for HGNNs based on the unified\nframework, which offers modularized components, reproducible implementations,\nand standardized evaluation for HGNNs. Finally, we conduct experiments to\nanalyze the effect of different designs. With the insights found, we distill a\ncondensed design space and verify its effectiveness.",
    "descriptor": "",
    "authors": [
      "Tianyu Zhao",
      "Cheng Yang",
      "Yibo Li",
      "Quan Gan",
      "Zhenyi Wang",
      "Fengqi Liang",
      "Huan Zhao",
      "Yingxia Shao",
      "Xiao Wang",
      "Chuan Shi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.09177"
  },
  {
    "id": "arXiv:2202.09179",
    "title": "Incorporating Texture Information into Dimensionality Reduction for  High-Dimensional Images",
    "abstract": "High-dimensional imaging is becoming increasingly relevant in many fields\nfrom astronomy and cultural heritage to systems biology. Visual exploration of\nsuch high-dimensional data is commonly facilitated by dimensionality reduction.\nHowever, common dimensionality reduction methods do not include spatial\ninformation present in images, such as local texture features, into the\nconstruction of low-dimensional embeddings. Consequently, exploration of such\ndata is typically split into a step focusing on the attribute space followed by\na step focusing on spatial information, or vice versa. In this paper, we\npresent a method for incorporating spatial neighborhood information into\ndistance-based dimensionality reduction methods, such as t-Distributed\nStochastic Neighbor Embedding (t-SNE). We achieve this by modifying the\ndistance measure between high-dimensional attribute vectors associated with\neach pixel such that it takes the pixel's spatial neighborhood into account.\nBased on a classification of different methods for comparing image patches, we\nexplore a number of different approaches. We compare these approaches from a\ntheoretical and experimental point of view. Finally, we illustrate the value of\nthe proposed methods by qualitative and quantitative evaluation on synthetic\ndata and two real-world use cases.",
    "descriptor": "\nComments: 10 pages main paper, 8 pages supplemental material. To appear at IEEE 15th Pacific Visualization Symposium 2022\n",
    "authors": [
      "Alexander Vieth",
      "Anna Vilanova",
      "Boudewijn Lelieveldt",
      "Elmar Eisemann",
      "Thomas H\u00f6llt"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.09179"
  },
  {
    "id": "arXiv:2202.09189",
    "title": "Task-oriented Scheduling for Networked Control Systems: An Age of  Information-Aware Implementation on Software-defined Radios",
    "abstract": "Networked control systems (NCSs) are feedback control loops that are closed\nover a communication network. Emerging applications, such as telerobotics,\ndrones and autonomous driving are the most prominent examples of such systems.\nRegular and timely information sharing between the components of NCSs is\nessential, as stale information can lead to performance degradation or even\nphysical damage. In this work, we consider multiple heterogeneous NCSs that\ntransmit their system state over a shared physical wireless channel towards a\ngateway node. We conduct a comprehensive experimental study on selected MAC\nprotocols using software-defined radios with state-of-the-art (SotA) solutions\nthat have been designed to increase information freshness and control\nperformance. As a significant improvement over the SotA, we propose a\ncontention-free algorithm that is able to outperform the existing solutions by\ncombining their strengths in one protocol. In addition, we propose a new metric\ncalled normalized mean squared error and demonstrate its effectiveness as\nutility for scheduling in a case study with multiple inverted pendulums. From\nour experimental study and results, we observe that a control-aware\nprioritization of the sub-systems contributes to minimizing the negative\neffects of information staleness on control performance. In particular, as the\nnumber of devices increases, the benefit of control-awareness to the quality of\ncontrol stands out when compared to protocols that focus solely on maximizing\ninformation freshness.",
    "descriptor": "",
    "authors": [
      "Onur Ayan",
      "Polina Kutsevol",
      "Hasan Ya\u011f\u0131z \u00d6zkan",
      "Wolfgang Kellerer"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.09189"
  },
  {
    "id": "arXiv:2202.09195",
    "title": "A Review on Methods and Applications in Multimodal Deep Learning",
    "abstract": "Deep Learning has implemented a wide range of applications and has become\nincreasingly popular in recent years. The goal of multimodal deep learning\n(MMDL) is to create models that can process and link information using various\nmodalities. Despite the extensive development made for unimodal learning, it\nstill cannot cover all the aspects of human learning. Multimodal learning helps\nto understand and analyze better when various senses are engaged in the\nprocessing of information. This paper focuses on multiple types of modalities,\ni.e., image, video, text, audio, body gestures, facial expressions, and\nphysiological signals. Detailed analysis of the baseline approaches and an\nin-depth study of recent advancements during the last five years (2017 to 2021)\nin multimodal deep learning applications has been provided. A fine-grained\ntaxonomy of various multimodal deep learning methods is proposed, elaborating\non different applications in more depth. Lastly, main issues are highlighted\nseparately for each domain, along with their possible future research\ndirections.",
    "descriptor": "\nComments: 29 pages. arXiv admin note: substantial text overlap with arXiv:2105.11087\n",
    "authors": [
      "Jabeen Summaira",
      "Xi Li",
      "Amin Muhammad Shoib",
      "Jabbar Abdul"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2202.09195"
  },
  {
    "id": "arXiv:2202.09196",
    "title": "An Integrated Optimization and Machine Learning Models to Predict the  Admission Status of Emergency Patients",
    "abstract": "This work proposes a framework for optimizing machine learning algorithms.\nThe practicality of the framework is illustrated using an important case study\nfrom the healthcare domain, which is predicting the admission status of\nemergency department (ED) patients (e.g., admitted vs. discharged) using\npatient data at the time of triage. The proposed framework can mitigate the\ncrowding problem by proactively planning the patient boarding process. A large\nretrospective dataset of patient records is obtained from the electronic health\nrecord database of all ED visits over three years from three major locations of\na healthcare provider in the Midwest of the US. Three machine learning\nalgorithms are proposed: T-XGB, T-ADAB, and T-MLP. T-XGB integrates extreme\ngradient boosting (XGB) and Tabu Search (TS), T-ADAB integrates Adaboost and\nTS, and T-MLP integrates multi-layer perceptron (MLP) and TS. The proposed\nalgorithms are compared with the traditional algorithms: XGB, ADAB, and MLP, in\nwhich their parameters are tunned using grid search. The three proposed\nalgorithms and the original ones are trained and tested using nine data groups\nthat are obtained from different feature selection methods. In other words, 54\nmodels are developed. Performance was evaluated using five measures: Area under\nthe curve (AUC), sensitivity, specificity, F1, and accuracy. The results show\nthat the newly proposed algorithms resulted in high AUC and outperformed the\ntraditional algorithms. The T-ADAB performs the best among the newly developed\nalgorithms. The AUC, sensitivity, specificity, F1, and accuracy of the best\nmodel are 95.4%, 99.3%, 91.4%, 95.2%, 97.2%, respectively.",
    "descriptor": "",
    "authors": [
      "Abdulaziz Ahmed",
      "Omar Ashour",
      "Haneen Ali",
      "Mohammad Firouz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.09196"
  },
  {
    "id": "arXiv:2202.09198",
    "title": "Deep-Learning Architectures for Multi-Pitch Estimation: Towards Reliable  Evaluation",
    "abstract": "Extracting pitch information from music recordings is a challenging but\nimportant problem in music signal processing. Frame-wise transcription or\nmulti-pitch estimation aims for detecting the simultaneous activity of pitches\nin polyphonic music recordings and has recently seen major improvements thanks\nto deep-learning techniques, with a variety of proposed network architectures.\nIn this paper, we realize different architectures based on CNNs, the U-net\nstructure, and self-attention components. We propose several modifications to\nthese architectures including self-attention modules for skip connections,\nrecurrent layers to replace the self-attention, and a multi-task strategy with\nsimultaneous prediction of the degree of polyphony. We compare variants of\nthese architectures in different sizes for multi-pitch estimation, focusing on\nWestern classical music beyond the piano-solo scenario using the MusicNet and\nSchubert Winterreise datasets. Our experiments indicate that most architectures\nyield competitive results and that larger model variants seem to be beneficial.\nHowever, we find that these results substantially depend on randomization\neffects and the particular choice of the training-test split, which questions\nthe claim of superiority for particular architectures given only small\nimprovements. We therefore investigate the influence of dataset splits in the\npresence of several movements of a work cycle (cross-version evaluation) and\npropose a best-practice splitting strategy for MusicNet, which weakens the\ninfluence of individual test tracks and suppresses overfitting to specific\nworks and recording conditions. A final evaluation on a mixed dataset suggests\nthat improvements on one specific dataset do not necessarily generalize to\nother scenarios, thus emphasizing the need for further high-quality multi-pitch\ndatasets in order to reliably measure progress in music transcription tasks.",
    "descriptor": "",
    "authors": [
      "Christof Wei\u00df",
      "Geoffroy Peeters"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2202.09198"
  },
  {
    "id": "arXiv:2202.09200",
    "title": "Geometric representation of the weighted harmonic mean of $n$ positive  values and potential uses",
    "abstract": "This paper is dedicated to the analysis and detailed study of a procedure to\ngenerate both the weighted arithmetic and harmonic means of $n$ positive real\nnumbers. Together with this interpretation, we prove some relevant properties\nthat will allow us to define numerical approximation methods in several\ndimensions adapted to discontinuities.",
    "descriptor": "\nComments: 21 pages, 4 figures\n",
    "authors": [
      "S.Amat",
      "P. Ortiz",
      "J.Ruiz",
      "J.C.Trillo",
      "D.F. Ya\u00f1ez"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.09200"
  },
  {
    "id": "arXiv:2202.09203",
    "title": "An Adaptive Finite Element DtN Method for Maxwell's Equations",
    "abstract": "This paper is concerned with a numerical solution to the scattering of a\ntime-harmonic electromagnetic wave by a bounded and impenetrable obstacle in\nthree dimensions. The electromagnetic wave propagation is modeled by a boundary\nvalue problem of Maxwell's equations in the exterior domain of the obstacle.\nBased on the Dirichlet-to-Neumann (DtN) operator, which is defined by an\ninfinite series, an exact transparent boundary condition is introduced and the\nscattering problem is reduced equivalently into a bounded domain. An a\nposteriori error estimate based adaptive finite element DtN method is developed\nto solve the discrete variational problem, where the DtN operator is truncated\ninto a sum of finitely many terms. The a posteriori error estimate takes into\naccount both the finite element approximation error and the truncation error of\nthe DtN operator. The latter is shown to decay exponentially with respect to\nthe truncation parameter. Numerical experiments are presented to illustrate the\neffectiveness of the proposed method.",
    "descriptor": "",
    "authors": [
      "Gang Bao",
      "Mingming Zhang",
      "Xue Jiang",
      "Peijun Li",
      "Xiaokai Yuan"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.09203"
  },
  {
    "id": "arXiv:2202.09206",
    "title": "Spatio-Temporal Outdoor Lighting Aggregation on Image Sequences using  Transformer Networks",
    "abstract": "In this work, we focus on outdoor lighting estimation by aggregating\nindividual noisy estimates from images, exploiting the rich image information\nfrom wide-angle cameras and/or temporal image sequences. Photographs inherently\nencode information about the scene's lighting in the form of shading and\nshadows. Recovering the lighting is an inverse rendering problem and as that\nill-posed. Recent work based on deep neural networks has shown promising\nresults for single image lighting estimation, but suffers from robustness. We\ntackle this problem by combining lighting estimates from several image views\nsampled in the angular and temporal domain of an image sequence. For this task,\nwe introduce a transformer architecture that is trained in an end-2-end fashion\nwithout any statistical post-processing as required by previous work. Thereby,\nwe propose a positional encoding that takes into account the camera calibration\nand ego-motion estimation to globally register the individual estimates when\ncomputing attention between visual words. We show that our method leads to\nimproved lighting estimation while requiring less hyper-parameters compared to\nthe state-of-the-art.",
    "descriptor": "\nComments: 11 pages, 7 figures, 1 table, currently under a review process\n",
    "authors": [
      "Haebom Lee",
      "Christian Homeyer",
      "Robert Herzog",
      "Jan Rexilius",
      "Carsten Rother"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.09206"
  },
  {
    "id": "arXiv:2202.09207",
    "title": "Leveraging Self-Sovereign Identity, Blockchain, and Zero-Knowledge Proof  to Build a Privacy-Preserving Vaccination Pass",
    "abstract": "The current humanitarian health crisis popularized the debate on data\nprivacy. At the same time, several cities, states, and even countries put the\nmandatory presentation of health pass to access services into practice. In this\narticle, we explore the concepts of self-sovereign identity, blockchain, and\nzero-knowledge proofs to propose a solution to the problem of presenting proof\nof vaccination. This solution allows users to prove that they are vaccinated\nfor different pathogens without revealing their identity. The architecture is\nloosely coupled, allowing components to be exchanged, which we discuss when we\npresent the implementation of a working prototype.",
    "descriptor": "",
    "authors": [
      "Mauricio de Vasconcelos Barros",
      "Frederico Schardong",
      "Ricardo Felipe Cust\u00f3dio"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.09207"
  },
  {
    "id": "arXiv:2202.09210",
    "title": "Hedonic Diversity Games: A Complexity Picture with More than Two Colors",
    "abstract": "Hedonic diversity games are a variant of the classical Hedonic games designed\nto better model a variety of questions concerning diversity and fairness.\nPrevious works mainly targeted the case with two diversity classes (represented\nas colors in the model) and provided some initial complexity-theoretic and\nexistential results concerning Nash and individually stable outcomes. Here, we\ndesign new algorithms accompanied with lower bounds which provide a complete\nparameterized-complexity picture for computing Nash and individually stable\noutcomes with respect to the most natural parameterizations of the problem.\nCrucially, our results hold for general Hedonic diversity games where the\nnumber of colors is not necessarily restricted to two, and show that -- apart\nfrom two trivial cases -- a necessary condition for tractability in this\nsetting is that the number of colors is bounded by the parameter. Moreover, for\nthe special case of two colors we resolve an open question asked in previous\nwork (Boehmer and Elkind, AAAI 2020).",
    "descriptor": "\nComments: Accepted to AAAI '22\n",
    "authors": [
      "Robert Ganian",
      "Thekla Hamm",
      "Du\u0161an Knop",
      "\u0160imon Schierreich",
      "Ond\u0159ej Such\u00fd"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2202.09210"
  },
  {
    "id": "arXiv:2202.09212",
    "title": "Molecule Generation for Drug Design: a Graph Learning Perspective",
    "abstract": "Machine learning has revolutionized many fields, and graph learning is\nrecently receiving increasing attention. From the application perspective, one\nof the emerging and attractive areas is aiding the design and discovery of\nmolecules, especially in drug industry. In this survey, we provide an overview\nof the state-of-the-art molecule (and mostly for de novo drug) design and\ndiscovery aiding methods whose methodology involves (deep) graph learning.\nSpecifically, we propose to categorize these methods into three groups: i) all\nat once, ii) fragment-based and iii) node-by-node. We further present some\nrepresentative public datasets and summarize commonly utilized evaluation\nmetrics for generation and optimization, respectively. Finally, we discuss\nchallenges and directions for future research, from the drug design\nperspective.",
    "descriptor": "",
    "authors": [
      "Nianzu Yang",
      "Huaijin Wu",
      "Junchi Yan",
      "Xiaoyong Pan",
      "Ye Yuan",
      "Le Song"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.09212"
  },
  {
    "id": "arXiv:2202.09214",
    "title": "Pinpointing Anomaly Events in Logs from Stability Testing -- N-Grams vs.  Deep-Learning",
    "abstract": "As stability testing execution logs can be very long, software engineers need\nhelp in locating anomalous events. We develop and evaluate two models for\nscoring individual log-events for anomalousness, namely an N-Gram model and a\nDeep Learning model with LSTM (Long short-term memory). Both are trained on\nnormal log sequences only. We evaluate the models with long log sequences of\nAndroid stability testing in our company case and with short log sequences from\nHDFS (Hadoop Distributed File System) public dataset. We evaluate next event\nprediction accuracy and computational efficiency. The N-Gram model is more\naccurate in stability testing logs (0.848 vs 0.831), whereas almost identical\naccuracy is seen in HDFS logs (0.849 vs 0.847). The N-Gram model has superior\ncomputational efficiency compared to the Deep model (4 to 13 seconds vs 16\nminutes to nearly 4 hours), making it the preferred choice for our case\ncompany. Scoring individual log events for anomalousness seems like a good aid\nfor root cause analysis of failing test cases, and our case company plans to\nadd it to its online services. Despite the recent surge in using deep learning\nin software system anomaly detection, we found no benefits in doing so.\nHowever, future work should consider whether our finding holds with different\nLSTM-model hyper-parameters, other datasets, and with other deep-learning\napproaches that promise better accuracy and computational efficiency than LSTM\nbased models.",
    "descriptor": "\nComments: Accepted to 5th Workshop on NEXt level of Test Automation (NEXTA), ICST Workshops 2022\n",
    "authors": [
      "Mika M\u00e4ntyl\u00e4",
      "Mart\u00edn Varela",
      "Shayan Hashemi"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2202.09214"
  },
  {
    "id": "arXiv:2202.09215",
    "title": "On the Significance of Knowing the Arrival Order in Prophet Inequality",
    "abstract": "In a prophet inequality problem, $n$ boxes arrive online, each containing\nsome value that is drawn independently from a known distribution. Upon the\narrival of a box, its value is realized, and an online algorithm decides,\nimmediately and irrevocably, whether to accept it or proceed to the next box.\nClearly, an online algorithm that knows the arrival order may be more powerful\nthan an online algorithm that is unaware of the order. Despite the growing\ninterest in the role of the arrival order on the performance of online\nalgorithms, the effect of knowledge of the order has been overlooked thus far.\nOur goal in this paper is to quantify the loss due to unknown order. We\ndefine the order competitive ratio as the worst-case ratio between the\nperformance of the best order-unaware and the best order-aware algorithms. We\nstudy the order competitive ratio for two objective functions, namely (i)\nmax-expectation: maximizing the expected accepted value, and (ii)\nmax-probability: maximizing the probability of accepting the box with the\nlargest value. For the max-expectation objective, we're golden: we give a\ndeterministic order-unaware algorithm that achieves an order competitive ratio\nof the inverse of the golden ratio (i.e., $1/\\phi \\approx 0.618$). For the\nmax-probability objective, we give a deterministic order-unaware algorithm that\nachieves an order competitive ratio of $\\ln \\frac{1}{\\lambda} \\approx 0.806$\n(where $\\lambda$ is the unique solution to $\\frac{x}{1-x}= \\ln \\frac{1}{x}$).\nBoth results are tight. Our algorithms are inevitably adaptive and go beyond\nsingle-threshold algorithms.",
    "descriptor": "",
    "authors": [
      "Tomer Ezra",
      "Michal Feldman",
      "Nick Gravin",
      "Zhihao Gavin Tang"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2202.09215"
  },
  {
    "id": "arXiv:2202.09221",
    "title": "A practical DMPs Implementation for Skill Creation and Teleoperation  with Assistive Manipulators",
    "abstract": "Assistive robotic manipulators are becoming increasingly important for people\nwith disabilities. Teleoperating the manipulator in mundane tasks is part of\ntheir daily lives. Instead of steering the robot through all actions, applying\nself-recorded motion skills could greatly facilitate repetitive tasks. Dynamic\nMovement Primitives (DMP) are a powerful method for skill learning. For this\nuse case, however, they need a simple heuristic to specify where to start and\nstop a skill without additional sensors. This paper provides the concept of\nlocal, global, and hybrid skills that form a modular basis for composing\nsingle-handed tasks with ease. A focus is on presenting the necessary\nmathematical details to support custom implementations with assistive robot\narms. Experiments validate the developed methods for scratching an itchy spot,\nsorting objects on a desk, and feeding a piggy bank with coins. The paper is\naccompanied by an open-source implementation at\nhttps://github.com/fzi-forschungszentrum-informatik/ArNe",
    "descriptor": "\nComments: 8 pages, 9 figures, submitted to the IEEE 19th International Conference on Ubiquitous Robots, Jeju, Korea\n",
    "authors": [
      "Stefan Scherzinger",
      "Pascal Becker",
      "Arne Roennau",
      "R\u00fcdiger Dillmann"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.09221"
  },
  {
    "id": "arXiv:2202.09222",
    "title": "Improving AoI via Learning-based Distributed MAC in Wireless Networks",
    "abstract": "In this work, we consider a remote monitoring scenario in which multiple\nsensors share a wireless channel to deliver their status updates to a process\nmonitor via an access point (AP). Moreover, we consider that the sensors\nrandomly arrive and depart from the network as they become active and inactive.\nThe goal of the sensors is to devise a medium access strategy to collectively\nminimize the long-term mean network \\ac{AoI} of their respective processes at\nthe remote monitor. For this purpose, we propose specific modifications to\nALOHA-QT algorithm, a distributed medium access algorithm that employs a policy\ntree (PT) and reinforcement learning (RL) to achieve high throughput. We\nprovide the upper bound on the mean network Age of Information (AoI) for the\nproposed algorithm along with pointers for selecting its key parameter. The\nresults reveal that the proposed algorithm reduces mean network \\ac{AoI} by\nmore than 50 percent for state of the art stationary randomized policies while\nsuccessfully adjusting to a changing number of active users in the network. The\nalgorithm needs less memory and computation than ALOHA-QT while performing\nbetter in terms of AoI.",
    "descriptor": "\nComments: Accepted in IEEE INFOCOM Workshop on Age of Information (AoI) 2022\n",
    "authors": [
      "Yash Deshpande",
      "Onur Ayan",
      "Wolfgang Kellerer"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2202.09222"
  },
  {
    "id": "arXiv:2202.09223",
    "title": "History Data Driven Distributed Consensus in Networks",
    "abstract": "The association of weights in a distributed consensus protocol quantify the\ntrust that an agent has on its neighbors in a network. An important problem in\nsuch networked systems is the uncertainty in the estimation of trust between\nneighboring agents, coupled with the losses arising from mistakenly associating\nwrong amounts of trust with different neighboring agents. We introduce a\nprobabilistic approach which uses the historical data collected in the network,\nto determine the level of trust between each agent. Specifically, using the\nfinite history of the shared data between neighbors, we obtain a configuration\nwhich represents the confidence estimate of every neighboring agent's\ntrustworthiness. Finally, we propose a History-Data-Driven (HDD) distributed\nconsensus protocol which translates the computed configuration data into\nweights to be used in the consensus update. The approach using the historical\ndata in the context of a distributed consensus setting marks the novel\ncontribution of our paper.",
    "descriptor": "",
    "authors": [
      "Venkatraman Renganathan",
      "Angela Fontan",
      "Karthik Ganapathy"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.09223"
  },
  {
    "id": "arXiv:2202.09226",
    "title": "Faster change of order algorithm for Gr\u00f6bner bases under shape and  stability assumptions",
    "abstract": "Solving polynomial systems whose solution set is finite is usually done in\ntwo main steps: compute a Gr\\\"obner basis for the degree reverse lexicographic\norder, and perform a change of order to find the lexicographic Gr\\\"obner basis.\nThe second step is generally considered as better understood, in terms of\nalgorithms and complexity. Yet, after two decades of progress on the first\nstep, it turns out that the change of order now takes a large part of the\nsolving time for many instances, including those that are generic or reached\nafter applying a random change of variables.\nLike the fastest known change of order algorithms, this work focuses on the\nlatter situation, where the ideal defined by the system satisfies structural\nproperties. First, the ideal has a shape lexicographic Gr\\\"obner basis. Second,\nthe set of leading terms with respect to the degree reverse lexicographic order\nhas a stability property; in particular, the multiplication matrix of the\nsmallest variable is computed for free from the input Gr\\\"obner basis.\nThe current fastest algorithms rely on the sparsity of this multiplication\nmatrix to find its minimal polynomial efficiently using Wiedemann's approach.\nThis paper starts from the observation that this sparsity is a consequence of\nan algebraic structure, which can be exploited to represent the matrix\nconcisely as a univariate polynomial matrix. We show that the Hermite normal\nform of that matrix yields the sought lexicographic Gr\\\"obner basis, under\nassumptions which cover the shape position case. This leads to an improved\ncomplexity bound for the second step. The practical benefit is also confirmed\nvia implementations based on the state-of-the-art software libraries msolve and\nPML.",
    "descriptor": "\nComments: 9 pages, 2 tables\n",
    "authors": [
      "J\u00e9r\u00e9my Berthomieu",
      "Vincent Neiger",
      "Mohab Safey El Din"
    ],
    "subjectives": [
      "Symbolic Computation (cs.SC)",
      "Commutative Algebra (math.AC)"
    ],
    "url": "https://arxiv.org/abs/2202.09226"
  },
  {
    "id": "arXiv:2202.09228",
    "title": "Topology-Level Reactivity in Distributed Reactive Programs: Reactive  Acquaintance Management using Flocks",
    "abstract": "Reactive programming is a popular paradigm to program event-driven\napplications, and it is often proposed as a paradigm to write distributed\napplications. One such type of application is *prosumer* applications, which\nare distributed applications that both produce and consume many events. We\nanalyse the problems that occur when using a reactive programming language or\nframework to implement prosumer applications. We find that the assumption of an\nopen network, which means prosumers of various types spontaneously join and\nleave the network, can cause a lot of code complexity or run-time inefficiency.\nAt the basis of these issues lies *acquaintance management*: the ability to\ndiscover prosumers as they join and leave the network, and correctly\nmaintaining this state throughout the reactive program. Most existing reactive\nprogramming languages and frameworks have limited support for managing\nacquaintances, resulting in accidental complexity of the code or inefficient\ncomputations.\nIn this paper we present acquaintance management for reactive programs.\nFirst, we design an *acquaintance discovery* mechanism to create a *flock* that\nautomatically discovers prosumers on the network. An important aspect of flocks\nis their integration with reactive programs, such that a reactive program can\ncorrectly and efficiently maintain its state. To this end we design an\n*acquaintance maintenance* mechanism: a new type of operator for functional\nreactive programming languages that we call `deploy-*`. The `deploy-*` operator\nenables correct and efficient reactions to time-varying collections of\ndiscovered prosumers. The proposed mechanisms are implemented in a reactive\nprogramming language called Stella, which serves as a linguistic vehicle to\ndemonstrate the ideas of our approach. Our implementation of acquaintance\nmanagement results in computationally efficient and idiomatic reactive code.\nWe evaluate our approach quantitatively via benchmarks that show that our\nimplementation is efficient: computations will efficiently update whenever a\nnew prosumer is discovered, or a connected prosumer is dropped. To evaluate the\ndistributed capabilities of our prototype implementation, we implement a\nuse-case that simulates the bike-sharing infrastructure of Brussels, and we run\nit on a Raspberry Pi cluster computer. We consider our work to be an important\nstep to use functional reactive programming to build distributed systems for\nopen networks, in other words, distributed reactive programs that involve many\nprosumer devices and sensors that spontaneously join and leave the network.",
    "descriptor": "",
    "authors": [
      "Sam Van den Vonder",
      "Thierry Renaux",
      "Wolfgang De Meuter"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2202.09228"
  },
  {
    "id": "arXiv:2202.09229",
    "title": "Figuring and Drawing: A Visual Approach to Principled Programming",
    "abstract": "A standing challenge in undergraduate Computer Science curricula is the\nteaching and learning of computer programming. Through this paper which is an\nessay about programming, we aim to contribute to the plethora of existing\npedagogies, approaches and philosophies, by discussing a specific feature of\nour approach in teaching principled programming to undergraduate students, in\ntheir first semester of studies, namely the utilization of pictures, both\ntext-based and raster-based graphics. Although the given course has evolved\nsubstantially over the thirty years of its delivery regarding the programming\nlanguages (Miranda, C, C++, Java) and paradigms (functional, imperative,\nobject-oriented, combination of procedural and object-oriented) used, the\ndiscussed visual feature has been maintained and steadily strengthened.\nWe list abstraction, problem decomposition and synthesis, information hiding,\nreusability, modularity and extensibility as key principles of problem solving\nand algorithmic thinking. These principles are closely aligned with the\nadvocated computational thinking techniques of problem decomposition, pattern\nrecognition, pattern generalization and algorithm design. We aim for our\nstudents to familiarize themselves with all the above principles through\npractical problem solving. Our ongoing inquiry has been whether the problem\ndomain of pictures is contributing valuably towards this aim. Moreover, an\nadded-value is that students get a glimpse of computational complexity in a\nvisual, empirical way.\nThe presented work is not related to visual programming, since the students\nwrite their programs textually and not graphically; it's the output of their\nprograms which is in visual form. Our approach though is loosely related to the\nclassical paradigm of turtle graphics. However, our focus is Computer Science\nmajors, who should be able to design and build turtles and other objects and\nnot just use them. Indeed, the programming principles course helps them to do\nboth and also to appreciate the multitude of algorithmic ways for producing the\nsame visual output. Currently the given programming principles are approached\nboth from a procedural, process-based and an object-oriented, concept-based\nperspective and the course uses the Java language. Through the presented\nexample problems, we aim to show the appropriateness of the visual domain of\npictures for supporting the learning of principled programming. The problem\ndomain of pictures is abundantly rich with potential examples to draw from.\nMoreover, as reported in the literature, female students may show higher\ninterest towards visual problem domains in programming classes, in relation to\nother problem domains. We plan to investigate this conjecture in the context of\nour broader aim to encourage more females to follow university studies in\ncomputer science; in this paper only a cursory finding is presented, that bears\nsome relation to what is reported in the literature.",
    "descriptor": "",
    "authors": [
      "Elpida Keravnou-Papailiou"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2202.09229"
  },
  {
    "id": "arXiv:2202.09230",
    "title": "United Monoids: Finding Simplicial Sets and Labelled Algebraic Graphs in  Trees",
    "abstract": "Graphs and various graph-like combinatorial structures, such as preorders and\nhypergraphs, are ubiquitous in programming. This paper focuses on representing\ngraphs in a purely functional programming language like Haskell. There are\nseveral existing approaches; one of the most recently developed ones is the\n\"algebraic graphs\" approach (2017). It uses an algebraic data type to represent\ngraphs and has attracted users, including from industry, due to its emphasis on\nequational reasoning and making a common class of bugs impossible by\neliminating internal invariants.\nThe previous formulation of algebraic graphs did not support edge labels,\nwhich was a serious practical limitation. In this paper, we redesign the main\nalgebraic data type and remove this limitation. We follow a fairly standard\napproach of parameterising a data structure with a semiring of edge labels. The\nnew formulation is both more general and simpler: the two operations for\ncomposing graphs used in the previous work can now be obtained from a single\noperation by fixing the semiring parameter to zero and one, respectively.\nBy instantiating the new data type with different semirings, and working out\nlaws for interpreting the resulting expression trees, we discover an unusual\nalgebraic structure, which we call \"united monoids\", that is, a pair of monoids\nwhose unit elements coincide. We believe that it is worth studying united\nmonoids in their full generality, going beyond the graphs which prompted their\ndiscovery. To that end, we characterise united monoids with a minimal set of\naxioms, prove a few basic theorems, and discuss several notable examples.\nWe validate the presented approach by implementing it in the open-source\n*algebraic-graphs* library. Our theoretical contributions are supported by\nproofs that are included in the paper and have also been machine-checked in\nAgda. By extending algebraic graphs with support for edge labels, we make them\nsuitable for a much larger class of possible applications. By studying united\nmonoids, we provide a theoretical foundation for further research in this area.",
    "descriptor": "",
    "authors": [
      "Andrey Mokhov"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2202.09230"
  },
  {
    "id": "arXiv:2202.09231",
    "title": "Debootstrapping without Archeology: Stacked Implementations in Camlboot",
    "abstract": "Context: It is common for programming languages that their reference\nimplementation is implemented in the language itself. This requires a\n\"bootstrap\": a copy of a previous version of the implementation is provided\nalong with the sources, to be able to run the implementation itself. Those\nbootstrap files are opaque binaries; they could contain bugs, or even malicious\nchanges that could reproduce themselves when running the source version of the\nlanguage implementation -- this is called the \"trusting trust attack\". For this\nreason, a collective project called Bootstrappable was launched in 2016 to\nremove those bootstraps, providing alternative build paths that do not rely on\nopaque binaries.\nInquiry: Debootstrapping generally combines a mix of two approaches. The\n\"archaeological\" approach works by locating old versions of systems, or legacy\nalternative implementations, that do not need the bootstrap, and by preserving\nor restoring the ability to run them. The \"tailored\" approach re-implements a\nnew, non-bootstrapped implementation of the system to debootstrap. Currently,\nthe \"tailored\" approach is dominant for low-level system components (C,\ncoreutils), and the \"archaeological\" approach is dominant among the few\nhigher-level languages that were debootstrapped.\nApproach: We advocate for the benefits of \"tailored\" debootstrapping\nimplementations of high-level languages. The new implementation needs not be\nproduction-ready, it suffices that it is able to run the reference\nimplementation correctly. We argue that this is feasible with a reasonable\ndevelopment effort, with several side benefits besides debootstrapping.\nKnowledge: We propose a specific design of composing/stacking several\nimplementations: a reference interpreter for the language of interest,\nimplemented in a small subset of the language, and a compiler for this small\nsubset (in another language). Developing a reference interpreter is valuable\nindependently of debootstrapping: it may help clarify the language semantics,\nand can be reused for other purposes such as differential testing of the other\nimplementations.\nGrounding: We present Camlboot, our project to debootstrap the OCaml\ncompiler, version 4.07. Once we converged on this final design, the last\nversion of Camlboot took about a person-month of implementation effort,\ndemonstrating feasibility. Using diverse double-compilation, we were able to\nprove the absence of trusting trust attack in the existing bootstrap of the\nstandard OCaml implementation.\nImportance: To our knowledge, this document is the first scholarly discussion\nof \"tailored\" debootstrapping for high-level programming languages.\nDebootstrapping is an interesting problem which recently grew an active\ncommunity of free software contributors, but so far the interactions with the\nprogramming-language research community have been minimal. We share our\nexperience on Camlboot, trying to highlight aspects that are of interest to\nother language designers and implementors; we hope to foster stronger ties\nbetween the Bootstrappable project and relevant academic communities. In\nparticular, the debootstrapping experience has been an interesting reflection\non OCaml design and implementation, and we hope that other language\nimplementors would find it equally valuable.",
    "descriptor": "",
    "authors": [
      "Nathana\u00eblle Courant",
      "Julien Lepiller",
      "Gabriel Scherer"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2202.09231"
  },
  {
    "id": "arXiv:2202.09236",
    "title": "On the Secrecy Gain of Formally Unimodular Construction $\\text{A}_4$  Lattices",
    "abstract": "Lattice coding for the Gaussian wiretap channel is considered, where the goal\nis to ensure reliable communication between two authorized parties while\npreventing an eavesdropper from learning the transmitted messages. Recently, a\nmeasure called secrecy gain was proposed as a design criterion to quantify the\nsecrecy-goodness of the applied lattice code. In this paper, the theta series\nof the so-called formally unimodular lattices obtained by Construction\n$\\text{A}_4$ from codes over $\\mathbb{Z}_4$ is derived, and we provide a\nuniversal approach to determine their secrecy gains. Initial results indicate\nthat Construction $\\text{A}_4$ lattices can achieve a higher secrecy gain than\nthe best-known formally unimodular lattices from the literature. Furthermore, a\nnew code construction of formally self-dual $\\mathbb{Z}_4$-linear codes is\npresented.",
    "descriptor": "",
    "authors": [
      "Maiara F. Bollauf",
      "Hsuan-Yin Lin",
      "\u00d8yvind Ytrehus"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.09236"
  },
  {
    "id": "arXiv:2202.09244",
    "title": "Transfer and Marginalize: Explaining Away Label Noise with Privileged  Information",
    "abstract": "Supervised learning datasets often have privileged information, in the form\nof features which are available at training time but are not available at test\ntime e.g. the ID of the annotator that provided the label. We argue that\nprivileged information is useful for explaining away label noise, thereby\nreducing the harmful impact of noisy labels. We develop a simple and efficient\nmethod for supervised neural networks: it transfers via weight sharing the\nknowledge learned with privileged information and approximately marginalizes\nover privileged information at test time. Our method, TRAM (TRansfer and\nMarginalize), has minimal training time overhead and has the same test time\ncost as not using privileged information. TRAM performs strongly on CIFAR-10H,\nImageNet and Civil Comments benchmarks.",
    "descriptor": "",
    "authors": [
      "Mark Collier",
      "Rodolphe Jenatton",
      "Efi Kokiopoulou",
      "Jesse Berent"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.09244"
  },
  {
    "id": "arXiv:2202.09248",
    "title": "Stochastic Perturbations of Tabular Features for Non-Deterministic  Inference with Automunge",
    "abstract": "Injecting gaussian noise into training features is well known to have\nregularization properties. This paper considers noise injections to numeric or\ncategoric tabular features as passed to inference, which translates inference\nto a non-deterministic outcome and may have relevance to fairness\nconsiderations, adversarial example protection, or other use cases benefiting\nfrom non-determinism. We offer the Automunge library for tabular preprocessing\nas a resource for the practice, which includes options to integrate random\nsampling or entropy seeding with the support of quantum circuits for an\nimproved randomness profile in comparison to pseudo random number generators.\nBenchmarking shows that neural networks may demonstrate an improved performance\nwhen a known noise profile is mitigated with corresponding injections to both\ntraining and inference, and that gradient boosting appears to be robust to a\nmild noise profile in inference, suggesting that stochastic perturbations could\nbe integrated into existing data pipelines for prior trained gradient boosting\nmodels.",
    "descriptor": "\nComments: 41 pages, 17 figures, preprint\n",
    "authors": [
      "Nicholas J. Teague"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.09248"
  },
  {
    "id": "arXiv:2202.09250",
    "title": "Data-Driven Enhanced Model Reduction for Bifurcating Models in  Computational Fluid Dynamics",
    "abstract": "We investigate various data-driven methods to enhance projection-based model\nreduction techniques with the aim of capturing bifurcating solutions. To show\nthe effectiveness of the data-driven enhancements, we focus on the\nincompressible Navier-Stokes equations and different types of bifurcations. To\nrecover solutions past a Hopf bifurcation, we propose an approach that combines\nproper orthogonal decomposition with Hankel dynamic mode decomposition. To\napproximate solutions close to a pitchfork bifurcation, we combine localized\nreduced models with artificial neural networks. Several numerical examples are\nshown to demonstrate the feasibility of the presented approaches.",
    "descriptor": "",
    "authors": [
      "Martin W. Hess",
      "Annalisa Quaini",
      "Gianluigi Rozza"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.09250"
  },
  {
    "id": "arXiv:2202.09253",
    "title": "Sketching Distances in Monotone Graph Classes",
    "abstract": "We study the problems of adjacency sketching, small-distance sketching, and\napproximate distance threshold sketching for monotone classes of graphs. The\nproblem is to obtain randomized sketches of the vertices of any graph G in the\nclass, so that adjacency, exact distance thresholds, or approximate distance\nthresholds of two vertices u, v can be decided (with high probability) from the\nsketches of u and v, by a decoder that does not know the graph. The goal is to\ndetermine when sketches of constant size exist.\nWe show that, for monotone classes of graphs, there is a strict hierarchy:\napproximate distance threshold sketches imply small-distance sketches, which\nimply adjacency sketches, whereas the reverse implications are each false. The\nexistence of an adjacency sketch is equivalent to the condition of bounded\narboricity, while the existence of small-distance sketches is equivalent to the\ncondition of bounded expansion. Classes of constant expansion admit approximate\ndistance threshold sketches, while a monotone graph class can have arbitrarily\nsmall non-constant expansion without admitting an approximate distance\nthreshold sketch.",
    "descriptor": "\nComments: 35 pages, 2 figures\n",
    "authors": [
      "Louis Esperet",
      "Nathaniel Harms",
      "Andrey Kupavskii"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2202.09253"
  },
  {
    "id": "arXiv:2202.09256",
    "title": "Traffic-Aware Dynamic Functional Split for 5G Cloud Radio Access  Networks",
    "abstract": "As we are moving towards adopting virtualization technologies for next\ngeneration mobile networks, 5G base station (called gNB) is segregated into a\nRadio Unit (RU), a Distributed Unit (DU), and a Central Unit (CU) in order to\nsupport Cloud based Radio Access Networks (C-RAN) where RU and DU are connected\nthrough a fronthaul link while CU and DU are connected through a midhaul link.\nAlthough virtualization of CU gives benefits of centralization to the\noperators, there are other issues to be solved such as optimization of midhaul\nbandwidth and computing resources at edge cloud and central cloud where the DUs\nand CUs are deployed, respectively. In this paper, we propose a dynamic\nfunctional split selection for the DUs in 5G C-RAN by adopting to traffic\nheterogeneity where the midhaul bandwidth is limited. We proposed an\noptimization problem that maximizes the centralization of the C-RAN system by\noperating more number of DUs on split Option-7 by changing the channel\nbandwidth of the DUs. The dynamical selection of split options among each CU-DU\npair gives 90% centralization over the static functional split for a given\nmidhaul bandwidth.",
    "descriptor": "",
    "authors": [
      "Himank Gupta",
      "Antony Franklin A",
      "Mayank Kumar",
      "Bheemarjuna Reddy Tamma"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2202.09256"
  },
  {
    "id": "arXiv:2202.09259",
    "title": "Reduced-Order Modeling of Thermal Dynamics in District Energy Networks  using Spectral Clustering",
    "abstract": "Simulation of thermal dynamics in city-scale district energy grids often\nbecomes computationally prohibitive for long simulation runs. Current model\norder reduction methods offer limited interpretability with regards to the\nnon-reduced system, and are not in general applicable for e.g., varying flow\nrates, multiple producers, or changing flow directions. This article presents a\nnovel method based on graph theory that approximates the solution of an\noptimization problem that minimizes the local truncation error for heat\ntransport in the grid. It is shown that the method can be used to reduce the\nthermal dynamic model of a city-scale energy grid, resulting in a coarser\ntemporal and spatial resolution. The relative root mean square error was 2.3\\%\ncompared to the non-reduced system for the evaluation scenario at the instances\nof the coarser time step, for every temperature state of the original graph.",
    "descriptor": "",
    "authors": [
      "Johan Simonsson",
      "Khalid Tourkey Atta",
      "Wolfgang Birk"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.09259"
  },
  {
    "id": "arXiv:2202.09262",
    "title": "Soft Actor-Critic Deep Reinforcement Learning for Fault Tolerant Flight  Control",
    "abstract": "Fault-tolerant flight control faces challenges, as developing a model-based\ncontroller for each unexpected failure is unrealistic, and online learning\nmethods can handle limited system complexity due to their low sample\nefficiency. In this research, a model-free coupled-dynamics flight controller\nfor a jet aircraft able to withstand multiple failure types is proposed. An\noffline trained cascaded Soft Actor-Critic Deep Reinforcement Learning\ncontroller is successful on highly coupled maneuvers, including a coordinated\n40 degree bank climbing turn with a normalized Mean Absolute Error of 2.64%.\nThe controller is robust to six failure cases, including the rudder jammed at\n-15 deg, the aileron effectiveness reduced by 70%, a structural failure, icing\nand a backward c.g. shift as the response is stable and the climbing turn is\ncompleted successfully. Robustness to biased sensor noise, atmospheric\ndisturbances, and to varying initial flight conditions and reference signal\nshapes is also demonstrated.",
    "descriptor": "\nComments: This paper has been presented at the 2022 AIAA SciTech Forum and Exposition, and accepted for publication in the corresponding AIAA proceedings\n",
    "authors": [
      "Killian Dally",
      "Erik-Jan van Kampen"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.09262"
  },
  {
    "id": "arXiv:2202.09263",
    "title": "Is Cross-Attention Preferable to Self-Attention for Multi-Modal Emotion  Recognition?",
    "abstract": "Humans express their emotions via facial expressions, voice intonation and\nword choices. To infer the nature of the underlying emotion, recognition models\nmay use a single modality, such as vision, audio, and text, or a combination of\nmodalities. Generally, models that fuse complementary information from multiple\nmodalities outperform their uni-modal counterparts. However, a successful model\nthat fuses modalities requires components that can effectively aggregate\ntask-relevant information from each modality. As cross-modal attention is seen\nas an effective mechanism for multi-modal fusion, in this paper we quantify the\ngain that such a mechanism brings compared to the corresponding self-attention\nmechanism. To this end, we implement and compare a cross-attention and a\nself-attention model. In addition to attention, each model uses convolutional\nlayers for local feature extraction and recurrent layers for global sequential\nmodelling. We compare the models using different modality combinations for a\n7-class emotion classification task using the IEMOCAP dataset. Experimental\nresults indicate that albeit both models improve upon the state-of-the-art in\nterms of weighted and unweighted accuracy for tri- and bi-modal configurations,\ntheir performance is generally statistically comparable. The code to replicate\nthe experiments is available at https://github.com/smartcameras/SelfCrossAttn",
    "descriptor": "\nComments: Accepted at ICASSP 2022\n",
    "authors": [
      "Vandana Rajan",
      "Alessio Brutti",
      "Andrea Cavallaro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2202.09263"
  },
  {
    "id": "arXiv:2202.09264",
    "title": "Structure-aware combinatorial group testing: a new method for pandemic  screening",
    "abstract": "Combinatorial group testing (CGT) is used to identify defective items from a\nset of items by grouping them together and performing a small number of tests\non the groups. Recently, group testing has been used to design efficient\nCOVID-19 testing, so that resources are saved while still identifying all\ninfected individuals. Due to test waiting times, a focus is given to\nnon-adaptive CGT, where groups are designed a priori and all tests can be done\nin parallel. The design of the groups can be done using Cover-Free Families\n(CFFs). The main assumption behind CFFs is that a small number $d$ of positives\nare randomly spread across a population of $n$ individuals. However, for\ninfectious diseases, it is reasonable to assume that infections show up in\nclusters of individuals with high contact (children in the same classroom\nwithin a school, households within a neighbourhood, students taking the same\ncourses within a university, people seating close to each other in a stadium).\nThe general structure of these communities can be modeled using hypergraphs,\nwhere vertices are items to be tested and edges represent clusters containing\nhigh contacts. We consider hypergraphs with non-overlapping edges and\noverlapping edges (first two examples and last two examples, respectively). We\ngive constructions of what we call structure-aware CFF, which uses the\nstructure of the underlying hypergraph. We revisit old CFF constructions,\nboosting the number of defectives they can identify by taking the hypergraph\nstructure into account. We also provide new constructions based on hypergraph\nparameters.",
    "descriptor": "",
    "authors": [
      "Thais Bardini Idalino",
      "Lucia Moura"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2202.09264"
  },
  {
    "id": "arXiv:2202.09265",
    "title": "Deep Movement Primitives: toward Breast Cancer Examination Robot",
    "abstract": "Breast cancer is the most common type of cancer worldwide. A robotic system\nperforming autonomous breast palpation can make a significant impact on the\nrelated health sector worldwide. However, robot programming for breast\npalpating with different geometries is very complex and unsolved. Robot\nlearning from demonstrations (LfD) reduces the programming time and cost.\nHowever, the available LfD are lacking the modelling of the manipulation\npath/trajectory as an explicit function of the visual sensory information. This\npaper presents a novel approach to manipulation path/trajectory planning called\ndeep Movement Primitives that successfully generates the movements of a\nmanipulator to reach a breast phantom and perform the palpation. We show the\neffectiveness of our approach by a series of real-robot experiments of reaching\nand palpating a breast phantom. The experimental results indicate our approach\noutperforms the state-of-the-art method.",
    "descriptor": "\nComments: To appear in the 36th AAAI conference\n",
    "authors": [
      "Oluwatoyin Sanni",
      "Giorgio Bonvicini",
      "Muhammad Arshad Khan",
      "Pablo C. Lopez-Custodio",
      "Kiyanoush Nazari",
      "Amir M. Ghalamzan E."
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.09265"
  },
  {
    "id": "arXiv:2202.09268",
    "title": "Using dual quaternions in robotics",
    "abstract": "We advocate for the use of dual quaternions to represent poses and twists for\nrobotics. We show how to represent torques and forces using dual quaternions.\nWe introduce the notion of the Lie derivative, and explain how it can be used\nto calculate the behavior of actuators. We show how to combine dual quaternions\nwith the Newton-Raphson method to compute forward kinematics for parallel\nrobots. We derive the equations of motion in dual quaternion form. This paper\ncontains results we have not seen before, which are listed in the conclusion.",
    "descriptor": "",
    "authors": [
      "Stephen Montgomery-Smith",
      "Cecil Shy"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.09268"
  },
  {
    "id": "arXiv:2202.09269",
    "title": "Quantification of Actual Road User Behavior on the Basis of Given  Traffic Rules",
    "abstract": "Driving on roads is restricted by various traffic rules, aiming to ensure\nsafety for all traffic participants. However, human road users usually do not\nadhere to these rules strictly, resulting in varying degrees of rule\nconformity. Such deviations from given rules are key components of today's road\ntraffic. In autonomous driving, robotic agents can disturb traffic flow, when\nrule deviations are not taken into account. In this paper, we present an\napproach to derive the distribution of degrees of rule conformity from human\ndriving data. We demonstrate our method with the Waymo Open Motion dataset and\nSafety Distance and Speed Limit rules.",
    "descriptor": "\nComments: Daniel Bogdoll and Moritz Nekolla contributed equally\n",
    "authors": [
      "Daniel Bogdoll",
      "Moritz Nekolla",
      "Tim Joseph",
      "J. Marius Z\u00f6llner"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.09269"
  },
  {
    "id": "arXiv:2202.09270",
    "title": "When Kinematics Dominates Mechanics: Locally Volume-Preserving  Primitives for Model Reduction in Finite Elasticity",
    "abstract": "A new, and extremely fast, computational modeling paradigm is introduced here\nfor specific finite elasticity problems that arise in the context of soft\nrobotics. Whereas continuum mechanics is a very classical area of study, and\nsignificant effort has been devoted to the development of intricate\nconstitutive models for finite elasticity, we show that in the kinds of\nlarge-strain mechanics problems arising in soft robotics, many of the\nparameters in constitutive models are irrelevant. For the most part, the\nisochoric (locally volume-preserving) constraint dominates behavior, and this\ncan be built into closed-form kinematic deformation fields before even\nconsidering other aspects of constitutive modeling. We therefore focus on\ndeveloping and applying primitive deformations that each observe this\nconstraint. It is shown that by composing a wide enough variety of such\ndeformations that the most common behaviors observed in soft robots can be\nreplicated. Case studies include an inflatable rubber chamber, a slender rubber\nrod, and a rubber block subjected to different boundary conditions. We show\nthat this method is at least 50 times faster than the ABAQUS implementation of\nthe finite element method (FEM). Physical experiments and measurements show\nthat both our method and ABAQUS have approximately 10% error relative to\nexperimentally measured displacements, as well as to each other. Our method\nprovides a real-time alternative to FEM, and captures essential degrees of\nfreedom for use in feedback control systems.",
    "descriptor": "",
    "authors": [
      "Xu Yi",
      "Gregory S. Chirikjian"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.09270"
  },
  {
    "id": "arXiv:2202.09271",
    "title": "Enhanced Behavioral Cloning with Environmental Losses for Self-Driving  Vehicles",
    "abstract": "Learned path planners have attracted research interest due to their ability\nto model human driving behavior and rapid inference. Recent works on behavioral\ncloning show that simple imitation of expert observations is not sufficient to\nhandle complex driving scenarios. Besides, predictions that land outside\ndrivable areas can lead to potentially dangerous situations. This paper\nproposes a set of loss functions, namely Social loss and Road loss, which\naccount for modelling risky social interactions in path planning. These losses\nact as a repulsive scalar field that surrounds non-drivable areas. Predictions\nthat land near these regions incur in a higher training cost, which is\nminimized using backpropagation. This methodology provides additional\nenvironment feedback to the traditional supervised learning set up. We\nvalidated this approach on a large-scale urban driving dataset. The results\nshow the agent learns to imitate human driving while exhibiting better safety\nmetrics. Furthermore, the proposed methodology has positive effects on\ninference without the need to artificially generate unsafe driving examples.\nThe explanability study suggests that the benefits obtained are associated with\na higher relevance of non-drivable areas in the agent's decisions compared to\nclassical behavioral cloning.",
    "descriptor": "",
    "authors": [
      "Nelson Fernandez Pinto",
      "Thomas Gilles"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.09271"
  },
  {
    "id": "arXiv:2202.09274",
    "title": "Towards 6G zero touch networks: The case of automated Cloud-RAN  deployments",
    "abstract": "The arrival of 6G technologies shall massively increase the proliferation of\non-demand and ephemeral networks. Creating and removing customized networks on\nthe fly notably requires fully automation to guarantee commissioning-time\nacceleration. In this paper, we address the deployment automation of an\nend-to-end mobile network, with special focus on RAN units (referred to as\nCloud-RAN). The Cloud-RAN automation is especially challenging due to the\nstrong latency constraints expected in 6G as well as the required management of\nphysical antennas. To automatically instantiate a Cloud-RAN chain, we introduce\na Zero Touch Commissioning (ZTC) model which performs resource discovery while\nlooking for both antennas and computing capacity as near as possible to the\ntargeted coverage zone. We validate the ZTC model by a testbed which deploys,\nconfigures and starts the network service without human intervention while\nusing Kubernetes-based infrastructures as well as open-source RAN and core\nelements implementing the mobile network functions.",
    "descriptor": "\nComments: Added to IEEE Xplore: 10 February 2022, Publisher: IEEE\n",
    "authors": [
      "Bini Angui",
      "Romuald Corbel",
      "Veronica Quintuna Rodriguez",
      "Emile Stephan"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2202.09274"
  },
  {
    "id": "arXiv:2202.09275",
    "title": "Rethinking Pareto Frontier for Performance Evaluation of Deep Neural  Networks",
    "abstract": "Recent efforts in deep learning show a considerable advancement in\nredesigning deep learning models for low-resource and edge devices. The\nperformance optimization of deep learning models are conducted either manually\nor through automatic architecture search, or a combination of both. The\nthroughput and power consumption of deep learning models strongly depend on the\ntarget hardware. We propose to use a \\emph{multi-dimensional} Pareto frontier\nto re-define the efficiency measure using a multi-objective optimization, where\nother variables such as power consumption, latency, and accuracy play a\nrelative role in defining a dominant model. Furthermore, a random version of\nthe multi-dimensional Pareto frontier is introduced to mitigate the uncertainty\nof accuracy, latency, and throughput variations of deep learning models in\ndifferent experimental setups. These two breakthroughs provide an objective\nbenchmarking method for a wide range of deep learning models. We run our novel\nmulti-dimensional stochastic relative efficiency on a wide range of deep image\nclassification models trained ImageNet data. Thank to this new approach we\ncombine competing variables with stochastic nature simultaneously in a single\nrelative efficiency measure. This allows to rank deep models that run\nefficiently on different computing hardware, and combines inference efficiency\nwith training efficiency objectively.",
    "descriptor": "",
    "authors": [
      "Vahid Partovi Nia",
      "Alireza Ghaffari",
      "Mahdi Zolnouri",
      "Yvon Savaria"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2202.09275"
  },
  {
    "id": "arXiv:2202.09276",
    "title": "Geometric Regularization from Overparameterization explains Double  Descent and other findings",
    "abstract": "The volume of the distribution of possible weight configurations associated\nwith a loss value may be the source of implicit regularization from\noverparameterization due to the phenomenon of contracting volume with\nincreasing dimensions for geometric figures demonstrated by hyperspheres. This\npaper introduces geometric regularization and explores potential applicability\nto several unexplained phenomenon including double descent, the differences\nbetween wide and deep networks, the benefits of He initialization and retained\nproximity in training, gradient confusion, fitness landscape properties, double\ndescent in other learning paradigms, and other findings for overparameterized\nlearning. Experiments are conducted by aggregating histograms of loss values\ncorresponding to randomly sampled initializations in small setups, which find\ndirectional correlations in zero or central mode dominance from deviations in\nwidth, depth, and initialization distributions. Double descent is likely due to\na regularization phase change when a training path reaches low enough loss that\nthe loss manifold volume contraction from a reduced range of potential weight\nsets is amplified by an overparameterized geometry.",
    "descriptor": "\nComments: 19 pages, 17 figures, preprint\n",
    "authors": [
      "Nicholas J. Teague"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.09276"
  },
  {
    "id": "arXiv:2202.09277",
    "title": "(2.5+1)D Spatio-Temporal Scene Graphs for Video Question Answering",
    "abstract": "Spatio-temporal scene-graph approaches to video-based reasoning tasks such as\nvideo question-answering (QA) typically construct such graphs for every video\nframe. Such approaches often ignore the fact that videos are essentially\nsequences of 2D \"views\" of events happening in a 3D space, and that the\nsemantics of the 3D scene can thus be carried over from frame to frame.\nLeveraging this insight, we propose a (2.5+1)D scene graph representation to\nbetter capture the spatio-temporal information flows inside the videos.\nSpecifically, we first create a 2.5D (pseudo-3D) scene graph by transforming\nevery 2D frame to have an inferred 3D structure using an off-the-shelf 2D-to-3D\ntransformation module, following which we register the video frames into a\nshared (2.5+1)D spatio-temporal space and ground each 2D scene graph within it.\nSuch a (2.5+1)D graph is then segregated into a static sub-graph and a dynamic\nsub-graph, corresponding to whether the objects within them usually move in the\nworld. The nodes in the dynamic graph are enriched with motion features\ncapturing their interactions with other graph nodes. Next, for the video QA\ntask, we present a novel transformer-based reasoning pipeline that embeds the\n(2.5+1)D graph into a spatio-temporal hierarchical latent space, where the\nsub-graphs and their interactions are captured at varied granularity. To\ndemonstrate the effectiveness of our approach, we present experiments on the\nNExT-QA and AVSD-QA datasets. Our results show that our proposed (2.5+1)D\nrepresentation leads to faster training and inference, while our hierarchical\nmodel showcases superior performance on the video QA task versus the state of\nthe art.",
    "descriptor": "\nComments: Accepted at AAAI 2022 (Oral)\n",
    "authors": [
      "Anoop Cherian",
      "Chiori Hori",
      "Tim K. Marks",
      "Jonathan Le Roux"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.09277"
  },
  {
    "id": "arXiv:2202.09282",
    "title": "FinNet: Solving Time-Independent Differential Equations with Finite  Difference Neural Network",
    "abstract": "In recent years, deep learning approaches for partial differential equations\nhave received much attention due to their mesh-freeness and other desirable\nproperties. However, most of the works so far concentrated on time-dependent\nnonlinear differential equations. In this work, we analyze potential issues\nwith the well-known Physic Informed Neural Network for differential equations\nthat are not time-dependent. This analysis motivates us to introduce a novel\ntechnique, namely FinNet, for solving differential equations by incorporating\nfinite difference into deep learning. Even though we use a mesh during the\ntraining phase, the prediction phase is mesh-free. We illustrate the\neffectiveness of our method through experiments on solving various equations.",
    "descriptor": "",
    "authors": [
      "Son N. T. Tu",
      "Thu Nguyen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.09282"
  },
  {
    "id": "arXiv:2202.09283",
    "title": "Surf or sleep? Understanding the influence of bedtime patterns on campus",
    "abstract": "Poor sleep habits may cause serious problems of mind and body, and it is a\ncommonly observed issue for college students due to study workload as well as\npeer and social influence. Understanding its impact and identifying students\nwith poor sleep habits matters a lot in educational management. Most of the\ncurrent research is either based on self-reports and questionnaires, suffering\nfrom a small sample size and social desirability bias, or the methods used are\nnot suitable for the education system. In this paper, we develop a general\ndata-driven method for identifying students' sleep patterns according to their\nInternet access pattern stored in the education management system and explore\nits influence from various aspects. First, we design a Possion-based\nprobabilistic mixture model to cluster students according to the distribution\nof bedtime and identify students who are used to staying up late. Second, we\nprofile students from five aspects (including eight dimensions) based on\ncampus-behavior data and build Bayesian networks to explore the relationship\nbetween behavioral characteristics and sleeping habits. Finally, we test the\npredictability of sleeping habits. This paper not only contributes to the\nunderstanding of student sleep from a cognitive and behavioral perspective but\nalso presents a new approach that provides an effective framework for various\neducational institutions to detect the sleeping patterns of students.",
    "descriptor": "\nComments: 10 pages. ACM SIGKDD Explorations, Dec 2021\n",
    "authors": [
      "Teng Guo",
      "Linhong Li",
      "Dongyu Zhang",
      "Feng Xia"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2202.09283"
  },
  {
    "id": "arXiv:2202.09284",
    "title": "Amenable Sparse Network Investigator",
    "abstract": "As the optimization problem of pruning a neural network is nonconvex and the\nstrategies are only guaranteed to find local solutions, a good initialization\nbecomes paramount. To this end, we present the Amenable Sparse Network\nInvestigator ASNI algorithm that learns a sparse network whose initialization\nis compressed. The learned sparse structure found by ASNI is amenable since its\ncorresponding initialization, which is also learned by ASNI, consists of only\n2L numbers, where L is the number of layers. Requiring just a few numbers for\nparameter initialization of the learned sparse network makes the sparse network\namenable. The learned initialization set consists of L signed pairs that act as\nthe centroids of parameter values of each layer. These centroids are learned by\nthe ASNI algorithm after only one single round of training. We experimentally\nshow that the learned centroids are sufficient to initialize the nonzero\nparameters of the learned sparse structure in order to achieve approximately\nthe accuracy of non-sparse network. We also empirically show that in order to\nlearn the centroids, one needs to prune the network globally and gradually.\nHence, for parameter pruning we propose a novel strategy based on a sigmoid\nfunction that specifies the sparsity percentage across the network globally.\nThen, pruning is done magnitude-wise and after each epoch of training. We have\nperformed a series of experiments utilizing networks such as ResNets,\nVGG-style, small convolutional, and fully connected ones on ImageNet, CIFAR10,\nand MNIST datasets.",
    "descriptor": "",
    "authors": [
      "Saeed Damadi",
      "Erfan Nouri",
      "Hamed Pirsiavash"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.09284"
  },
  {
    "id": "arXiv:2202.09288",
    "title": "Optimization of the Sparse Multi-Threaded Cholesky Factorization for  A64FX",
    "abstract": "Sparse linear algebra routines are fundamental building blocks of a large\nvariety of scientific applications. Direct solvers, which are methods for\nsolving linear systems via the factorization of matrices into products of\ntriangular matrices, are commonly used in many contexts. The Cholesky\nfactorization is the fastest direct method for symmetric and definite positive\nmatrices. This paper presents selective nesting, a method to determine the\noptimal task granularity for the parallel Cholesky factorization based on the\nstructure of sparse matrices. We propose the OPT-D-COST algorithm, which\nautomatically and dynamically applies selective nesting. OPT-D-COST leverages\nmatrix sparsity to drive complex task-based parallel workloads in the context\nof direct solvers. We run an extensive evaluation campaign considering a\nheterogeneous set of 60 sparse matrices and a parallel machine featuring the\nA64FX processor. OPT-D-COST delivers an average performance speedup of\n1.46$\\times$ with respect to the best state-of-the-art parallel method to run\ndirect solvers.",
    "descriptor": "",
    "authors": [
      "Valentin Le F\u00e8vre",
      "Tetsuzo Usui",
      "Marc Casas"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2202.09288"
  },
  {
    "id": "arXiv:2202.09291",
    "title": "Bayesian and Randomized Clock Auctions",
    "abstract": "In a single-parameter mechanism design problem, a provider is looking to sell\na service to a group of potential buyers. Each buyer $i$ has a private value\n$v_i$ for receiving the service and a feasibility constraint restricts which\nsets of buyers can be served simultaneously. Recent work in economics\nintroduced clock auctions as a superior class of auctions for this problem, due\nto their transparency, simplicity, and strong incentive guarantees. Subsequent\nwork focused on evaluating the social welfare approximation guarantees of these\nauctions, leading to strong impossibility results: in the absence of prior\ninformation regarding the buyers' values, no deterministic clock auction can\nachieve a bounded approximation, even for simple feasibility constraints with\nonly two maximal feasible sets.\nWe show that these negative results can be circumvented by using prior\ninformation or by leveraging randomization. We provide clock auctions that give\na $O(\\log\\log k)$ approximation for general downward-closed feasibility\nconstraints with $k$ maximal feasible sets for three different information\nmodels, ranging from full access to the value distributions to complete absence\nof information. The more information the seller has, the simpler these auctions\nare. Under full access, we use a particularly simple deterministic clock\nauction, called a single-price clock auction, which is only slightly more\ncomplex than posted price mechanisms. In this auction, each buyer is offered a\nsingle price and a feasible set is selected among those who accept their\noffers. In the other extreme, where no prior information is available, this\napproximation guarantee is obtained using a complex randomized clock auction.\nIn addition to our main results, we propose a parameterization that\ninterpolates between single-price clock auctions and general clock auctions,\npaving the way for an exciting line of future research.",
    "descriptor": "",
    "authors": [
      "Michal Feldman",
      "Vasilis Gkatzelis",
      "Nick Gravin",
      "Daniel Schoepflin"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2202.09291"
  },
  {
    "id": "arXiv:2202.09292",
    "title": "System Safety and Artificial Intelligence",
    "abstract": "This chapter formulates seven lessons for preventing harm in artificial\nintelligence (AI) systems based on insights from the field of system safety for\nsoftware-based automation in safety-critical domains. New applications of AI\nacross societal domains and public organizations and infrastructures come with\nnew hazards, which lead to new forms of harm, both grave and pernicious. The\ntext addresses the lack of consensus for diagnosing and eliminating new AI\nsystem hazards. For decades, the field of system safety has dealt with\naccidents and harm in safety-critical systems governed by varying degrees of\nsoftware-based automation and decision-making. This field embraces the core\nassumption of systems and control that AI systems cannot be safeguarded by\ntechnical design choices on the model or algorithm alone, instead requiring an\nend-to-end hazard analysis and design frame that includes the context of use,\nimpacted stakeholders and the formal and informal institutional environment in\nwhich the system operates. Safety and other values are then inherently\nsocio-technical and emergent system properties that require design and control\nmeasures to instantiate these across the technical, social and institutional\ncomponents of a system. This chapter honors system safety pioneer Nancy\nLeveson, by situating her core lessons for today's AI system safety challenges.\nFor every lesson, concrete tools are offered for rethinking and reorganizing\nthe safety management of AI systems, both in design and governance. This\nhistory tells us that effective AI safety management requires transdisciplinary\napproaches and a shared language that allows involvement of all levels of\nsociety.",
    "descriptor": "\nComments: To appear in: Oxford Handbook on AI Governance (Oxford University Press, 2022 forthcoming)\n",
    "authors": [
      "Roel I.J. Dobbe"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2202.09292"
  },
  {
    "id": "arXiv:2202.09298",
    "title": "Stratified Multivariate Multiscale Dispersion Entropy for Physiological  Signal Analysis",
    "abstract": "Multivariate Entropy quantification algorithms are becoming a prominent tool\nfor the extraction of information from multi-channel physiological time-series.\nHowever, during the analysis of physiological signals from heterogeneous organ\nsystems, certain channels may overshadow the patterns of others, resulting in\ninformation loss. Here, we introduce the framework of Stratified Entropy to\ncontrol the prioritization of each channels' dynamics based on their allocation\nto respective strata, leading to a richer description of the multi-channel\nsignal. As an implementation of the framework, three algorithmic variations of\nthe Stratified Multivariate Multiscale Dispersion Entropy are introduced. These\nvariations and the original algorithm are applied to synthetic and\nphysiological time-series, formulated from electroencephalogram, arterial blood\npressure, electrocardiogram, and nasal respiratory signals. The results of\nexperiments conducted on synthetic time-series indicate that the variations\nsuccessfully prioritize channels based on their strata allocation while\nmaintaining the low computation time of the original algorithm. Based on the\nphysiological time-series results, the distributions of features extracted from\nhealthy sleep versus sleep with obstructive sleep apnea display increased\nstatistical difference for certain strata allocations in the variations. This\nsuggests improved physiological state monitoring by the variations.\nFurthermore, stratified algorithms can be modified to utilize a priori\nknowledge for the stratification of channels. Thus, our research provides a\nnovel approach of multivariate analysis for the extraction of previously\ninaccessible information from heterogeneous systems.",
    "descriptor": "",
    "authors": [
      "Evangelos Kafantaris",
      "Tsz-Yan Milly Lo",
      "Javier Escudero"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.09298"
  },
  {
    "id": "arXiv:2202.09300",
    "title": "Exploring Adversarially Robust Training for Unsupervised Domain  Adaptation",
    "abstract": "Unsupervised Domain Adaptation (UDA) methods aim to transfer knowledge from a\nlabeled source domain to an unlabeled target domain. UDA has been extensively\nstudied in the computer vision literature. Deep networks have been shown to be\nvulnerable to adversarial attacks. However, very little focus is devoted to\nimproving the adversarial robustness of deep UDA models, causing serious\nconcerns about model reliability. Adversarial Training (AT) has been considered\nto be the most successful adversarial defense approach. Nevertheless,\nconventional AT requires ground-truth labels to generate adversarial examples\nand train models, which limits its effectiveness in the unlabeled target\ndomain. In this paper, we aim to explore AT to robustify UDA models: How to\nenhance the unlabeled data robustness via AT while learning domain-invariant\nfeatures for UDA? To answer this, we provide a systematic study into multiple\nAT variants that potentially apply to UDA. Moreover, we propose a novel\nAdversarially Robust Training method for UDA accordingly, referred to as\nARTUDA. Extensive experiments on multiple attacks and benchmarks show that\nARTUDA consistently improves the adversarial robustness of UDA models.",
    "descriptor": "",
    "authors": [
      "Shao-Yuan Lo",
      "Vishal M. Patel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.09300"
  },
  {
    "id": "arXiv:2202.09301",
    "title": "Illuminating the Space of Dungeon Maps, Locked-door Missions and Enemy  Placement Through MAP-Elites",
    "abstract": "Procedural Content Generation (PCG) methods are valuable tools to speed up\nthe game development process. Moreover, PCG may also present in games as\nfeatures, such as the procedural dungeon generation (PDG) in Moonlighter\n(Digital Sun, 2018). This paper introduces an extended version of an\nevolutionary dungeon generator by incorporating a MAP-Elites population. Our\ndungeon levels are discretized with rooms that may have locked-door missions\nand enemies within them. We encoded the dungeons through a tree structure to\nensure the feasibility of missions. We performed computational and user\nfeedback experiments to evaluate our PDG approach. They show that our approach\naccurately converges almost the whole MAP-Elite population for most executions.\nFinally, players' feedback indicates that they enjoyed the generated levels,\nand they could not indicate an algorithm as a level generator.",
    "descriptor": "\nComments: 9 pages, 6 figures, submitted to GECCO '22\n",
    "authors": [
      "Breno M. F. Viana",
      "Leonardo T. Pereira",
      "Claudio F. M. Toledo"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.09301"
  },
  {
    "id": "arXiv:2202.09305",
    "title": "Masked prediction tasks: a parameter identifiability view",
    "abstract": "The vast majority of work in self-supervised learning, both theoretical and\nempirical (though mostly the latter), have largely focused on recovering good\nfeatures for downstream tasks, with the definition of \"good\" often being\nintricately tied to the downstream task itself. This lens is undoubtedly very\ninteresting, but suffers from the problem that there isn't a \"canonical\" set of\ndownstream tasks to focus on -- in practice, this problem is usually resolved\nby competing on the benchmark dataset du jour.\nIn this paper, we present an alternative lens: one of parameter\nidentifiability. More precisely, we consider data coming from a parametric\nprobabilistic model, and train a self-supervised learning predictor with a\nsuitably chosen parametric form. Then, we ask whether we can read off the\nground truth parameters of the probabilistic model from the optimal predictor.\nWe focus on the widely used self-supervised learning method of predicting\nmasked tokens, which is popular for both natural languages and visual data.\nWhile incarnations of this approach have already been successfully used for\nsimpler probabilistic models (e.g. learning fully-observed undirected graphical\nmodels), we focus instead on latent-variable models capturing sequential\nstructures -- namely Hidden Markov Models with both discrete and conditionally\nGaussian observations. We show that there is a rich landscape of possibilities,\nout of which some prediction tasks yield identifiability, while others do not.\nOur results, borne of a theoretical grounding of self-supervised learning,\ncould thus potentially beneficially inform practice. Moreover, we uncover close\nconnections with uniqueness of tensor rank decompositions -- a widely used tool\nin studying identifiability through the lens of the method of moments.",
    "descriptor": "",
    "authors": [
      "Bingbin Liu",
      "Daniel Hsu",
      "Pradeep Ravikumar",
      "Andrej Risteski"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.09305"
  },
  {
    "id": "arXiv:2202.09307",
    "title": "Cyber Human Interaction",
    "abstract": "Cyber human interaction is a broad term encompassing the range of\ninteractions that humans can have with technology. While human interaction with\nfixed and mobile computers is well understood, the world is on the cusp of\nubiquitous and sustained interactions between humans and robots. While robotic\nsystems are intertwined with computing and computing technologies, the word\nrobot here describes technologies that can physically affect and in turn be\naffected by their environments which includes humans. This chapter delves into\nissues of cyber human interaction from the perspective of humans interacting\nwith a subset of robots known as assistive robots. Assistive robots are robots\ndesigned to assist individuals with mobility or capacity limitations in\ncompleting everyday activities, commonly called instrumental activities of\ndaily living. These range from household chores, eating or drinking to any\nactivity with which a user may need the daily assistance of a caregiver to\ncomplete. One common type of assistive robot is the wheelchair mounted robotic\narm. This device is designed to attach to a user's wheelchair to allow him or\nher to complete their activities independently. In short, these devices have\nsensors that allow them to sense and process their environment with varying\nlevels of autonomy to perform actions that benefit and improve the well-being\nof people with capability limitations or disabilities. While human robot\ninteraction is a popular research topic, not much research has been dedicated\nwith regard to individual with limitations. In this chapter, we provide an\noverview of assistive robotic devices, discuss common methods of user\ninteraction, and the need for an adaptive compensation framework to support\npotential users in regaining their functional capabilities.",
    "descriptor": "\nComments: 39 pages, 8 figures\n",
    "authors": [
      "Michael A. Rupp",
      "Aman Behal"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2202.09307"
  },
  {
    "id": "arXiv:2202.09312",
    "title": "Learning Predictions for Algorithms with Predictions",
    "abstract": "A burgeoning paradigm in algorithm design is the field of algorithms with\npredictions, in which algorithms are designed to take advantage of a\npossibly-imperfect prediction of some aspect of the problem. While much work\nhas focused on using predictions to improve competitive ratios, running times,\nor other performance measures, less effort has been devoted to the question of\nhow to obtain the predictions themselves, especially in the critical online\nsetting. We introduce a general design approach for algorithms that learn\npredictors: (1) identify a functional dependence of the performance measure on\nthe prediction quality, and (2) apply techniques from online learning to learn\npredictors against adversarial instances, tune robustness-consistency\ntrade-offs, and obtain new statistical guarantees. We demonstrate the\neffectiveness of our approach at deriving learning algorithms by analyzing\nmethods for bipartite matching, page migration, ski-rental, and job scheduling.\nIn the first and last settings we improve upon existing learning-theoretic\nresults by deriving online results, obtaining better or more general\nstatistical guarantees, and utilizing a much simpler analysis, while in the\nsecond and fourth we provide the first learning-theoretic guarantees.",
    "descriptor": "",
    "authors": [
      "Mikhail Khodak",
      "Maria-Florina Balcan",
      "Ameet Talwalkar",
      "Sergei Vassilvitskii"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.09312"
  },
  {
    "id": "arXiv:2202.09315",
    "title": "Unsupervised Multiple-Object Tracking with a Dynamical Variational  Autoencoder",
    "abstract": "In this paper, we present an unsupervised probabilistic model and associated\nestimation algorithm for multi-object tracking (MOT) based on a dynamical\nvariational autoencoder (DVAE), called DVAE-UMOT. The DVAE is a latent-variable\ndeep generative model that can be seen as an extension of the variational\nautoencoder for the modeling of temporal sequences. It is included in DVAE-UMOT\nto model the objects' dynamics, after being pre-trained on an unlabeled\nsynthetic dataset of single-object trajectories. Then the distributions and\nparameters of DVAE-UMOT are estimated on each multi-object sequence to track\nusing the principles of variational inference: Definition of an approximate\nposterior distribution of the latent variables and maximization of the\ncorresponding evidence lower bound of the data likehood function. DVAE-UMOT is\nshown experimentally to compete well with and even surpass the performance of\ntwo state-of-the-art probabilistic MOT models. Code and data are publicly\navailable.",
    "descriptor": "",
    "authors": [
      "Xiaoyu Lin",
      "Laurent Girin",
      "Xavier Alameda-Pineda"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.09315"
  },
  {
    "id": "arXiv:2202.09318",
    "title": "DataMUX: Data Multiplexing for Neural Networks",
    "abstract": "In this paper, we introduce data multiplexing (DataMUX), a technique that\nenables deep neural networks to process multiple inputs simultaneously using a\nsingle compact representation. DataMUX demonstrates that neural networks are\ncapable of generating accurate predictions over mixtures of inputs, resulting\nin increased throughput with minimal extra memory requirements. Our approach\nuses two key components -- 1) a multiplexing layer that performs a fixed linear\ntransformation to each input before combining them to create a mixed\nrepresentation of the same size as a single input, which is then processed by\nthe base network, and 2) a demultiplexing layer that converts the base\nnetwork's output back into independent representations before producing\npredictions for each input. We show the viability of DataMUX for different\narchitectures (Transformers, and to a lesser extent MLPs and CNNs) across six\ndifferent tasks spanning sentence classification, named entity recognition and\nimage classification. For instance, DataMUX for Transformers can multiplex up\nto $20$x/$40$x inputs, achieving $11$x/$18$x increase in throughput with\nminimal absolute performance drops of $<2\\%$ and $<4\\%$ respectively on MNLI, a\nnatural language inference task. We also provide a theoretical construction for\nmultiplexing in self-attention networks and analyze the effect of various\ndesign elements in DataMUX.",
    "descriptor": "",
    "authors": [
      "Vishvak Murahari",
      "Carlos E. Jimenez",
      "Runzhe Yang",
      "Karthik Narasimhan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.09318"
  },
  {
    "id": "arXiv:2202.09320",
    "title": "Distributed Transient Safety Verification via Robust Control Invariant  Sets: A Microgrid Application",
    "abstract": "Modern safety-critical energy infrastructures are increasingly operated in a\nhierarchical and modular control framework which allows for limited data\nexchange between the modules. In this context, it is important for each module\nto synthesize and communicate constraints on the values of exchanged\ninformation in order to assure system-wide safety. To ensure transient safety\nin inverter-based microgrids, we develop a set invariance-based distributed\nsafety verification algorithm for each inverter module. Applying Nagumo's\ninvariance condition, we construct a robust polynomial optimization problem to\njointly search for safety-admissible set of control set-points and design\nparameters, under allowable disturbances from neighbors. We use sum-of-squares\n(SOS) programming to solve the verification problem and we perform numerical\nsimulations using grid-forming inverters to illustrate the algorithm.",
    "descriptor": "",
    "authors": [
      "Jean-Baptiste Bouvier",
      "Sai Pushpak Nandanoori",
      "Melkior Ornik",
      "Soumya Kundu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.09320"
  },
  {
    "id": "arXiv:2202.09329",
    "title": "Rank-Sensitive Computation of the Rank Profile of a Polynomial Matrix",
    "abstract": "Consider a matrix $\\mathbf{F} \\in \\mathbb{K}^{m \\times n}$ of univariate\npolynomials over a field~$\\mathbb{K}$. We study the problem of computing the\ncolumn rank profile of $\\mathbf{F}$. To this end we first give an algorithm\nwhich improves the minimal kernel basis algorithm of Zhou, Labahn, and\nStorjohann (Proceedings ISSAC 2012). We then provide a second algorithm which\ncomputes the column rank profile of $\\mathbf{F}$ with a rank-sensitive\ncomplexity of $O\\tilde{~}(r^{\\omega-2} n (m+D))$ operations in $\\mathbb{K}$.\nHere, $D$ is the sum of row degrees of $\\mathbf{F}$, $\\omega$ is the exponent\nof matrix multiplication, and $O\\tilde{~}(\\cdot)$ hides logarithmic factors.",
    "descriptor": "\nComments: 10 pages, 2 algorithms, 1 figure\n",
    "authors": [
      "George Labahn",
      "Vincent Neiger",
      "Thi Xuan Vu",
      "Wei Zhou"
    ],
    "subjectives": [
      "Symbolic Computation (cs.SC)",
      "Rings and Algebras (math.RA)"
    ],
    "url": "https://arxiv.org/abs/2202.09329"
  },
  {
    "id": "arXiv:2202.09338",
    "title": "Signal Decomposition Using Masked Proximal Operators",
    "abstract": "We consider the well-studied problem of decomposing a vector time series\nsignal into components with different characteristics, such as smooth,\nperiodic, nonnegative, or sparse. We propose a simple and general framework in\nwhich the components are defined by loss functions (which include constraints),\nand the signal decomposition is carried out by minimizing the sum of losses of\nthe components (subject to the constraints). When each loss function is the\nnegative log-likelihood of a density for the signal component, our method\ncoincides with maximum a posteriori probability (MAP) estimation; but it also\nincludes many other interesting cases. We give two distributed optimization\nmethods for computing the decomposition, which find the optimal decomposition\nwhen the component class loss functions are convex, and are good heuristics\nwhen they are not. Both methods require only the masked proximal operator of\neach of the component loss functions, a generalization of the well-known\nproximal operator that handles missing entries in its argument. Both methods\nare distributed, i.e., handle each component separately. We derive tractable\nmethods for evaluating the masked proximal operators of some loss functions\nthat, to our knowledge, have not appeared in the literature.",
    "descriptor": "\nComments: The manuscript has 57 pages, 22 figures and 2 tables. Also hosted at this https URL For code, see this https URL\n",
    "authors": [
      "Bennet E. Meyers",
      "Stephen P. Boyd"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.09338"
  },
  {
    "id": "arXiv:2202.09339",
    "title": "A reliability measure for smart surveillance systems",
    "abstract": "We present a reliability measure for smart surveillance systems, taking into\naccount the adversarial nature of intrusion. Our approach is based on\npercolation theory and is a generalisation of Hamedmoghadam et al.'s\nreliability measure. Specifically, our approach incorporates a customisable\ncost function to allow modelling a diverse range of situations, such as access\nrestrictions, monitoring, and failures. We demonstrate our approach by applying\nit to a digital twin of a smart building, albeit challenges remain in\nestimating and modelling the key parameters needed.",
    "descriptor": "\nComments: 8 pages, 9 figures\n",
    "authors": [
      "Anj Simmons"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.09339"
  },
  {
    "id": "arXiv:2202.09340",
    "title": "Learning Physics-Informed Neural Networks without Stacked  Back-propagation",
    "abstract": "Physics-Informed Neural Network (PINN) has become a commonly used machine\nlearning approach to solve partial differential equations (PDE). But, facing\nhigh-dimensional second-order PDE problems, PINN will suffer from severe\nscalability issues since its loss includes second-order derivatives, the\ncomputational cost of which will grow along with the dimension during stacked\nback-propagation. In this paper, we develop a novel approach that can\nsignificantly accelerate the training of Physics-Informed Neural Networks. In\nparticular, we parameterize the PDE solution by the Gaussian smoothed model and\nshow that, derived from Stein's Identity, the second-order derivatives can be\nefficiently calculated without back-propagation. We further discuss the model\ncapacity and provide variance reduction methods to address key limitations in\nthe derivative estimation. Experimental results show that our proposed method\ncan achieve competitive error compared to standard PINN training but is two\norders of magnitude faster.",
    "descriptor": "",
    "authors": [
      "Di He",
      "Wenlei Shi",
      "Shanda Li",
      "Xiaotian Gao",
      "Jia Zhang",
      "Jiang Bian",
      "Liwei Wang",
      "Tie-Yan Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.09340"
  },
  {
    "id": "arXiv:2202.09344",
    "title": "Towards the Combination of Model Checking and Runtime Verification on  Multi-Agent Systems",
    "abstract": "Multi-Agent Systems (MAS) are notoriously complex and hard to verify. In\nfact, it is not trivial to model a MAS, and even when a model is built, it is\nnot always possible to verify, in a formal way, that it is actually behaving as\nwe expect. Usually, it is relevant to know whether an agent is capable of\nfulfilling its own goals. One possible way to check this is through Model\nChecking. Specifically, by verifying Alternating-time Temporal Logic (ATL)\nproperties, where the notion of strategies for achieving goals can be\ndescribed. Unfortunately, the resulting model checking problem is not decidable\nin general. In this paper, we present a verification procedure based on\ncombining Model Checking and Runtime Verification, where sub-models of the MAS\nmodel belonging to decidable fragments are verified by a model checker, and\nruntime monitors are used to verify the rest. Furthermore, we implement our\ntechnique and show experimental results.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2112.13621\n",
    "authors": [
      "Angelo Ferrando",
      "Vadim Malvone"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2202.09344"
  },
  {
    "id": "arXiv:2202.09346",
    "title": "Improving Molecular Contrastive Learning via Faulty Negative Mitigation  and Decomposed Fragment Contrast",
    "abstract": "Deep learning has been a prevalence in computational chemistry and widely\nimplemented in molecule property predictions. Recently, self-supervised\nlearning (SSL), especially contrastive learning (CL), gathers growing attention\nfor the potential to learn molecular representations that generalize to the\ngigantic chemical space. Unlike supervised learning, SSL can directly leverage\nlarge unlabeled data, which greatly reduces the effort to acquire molecular\nproperty labels through costly and time-consuming simulations or experiments.\nHowever, most molecular SSL methods borrow the insights from the machine\nlearning community but neglect the unique cheminformatics (e.g., molecular\nfingerprints) and multi-level graphical structures (e.g., functional groups) of\nmolecules. In this work, we propose iMolCLR: improvement of Molecular\nContrastive Learning of Representations with graph neural networks (GNNs) in\ntwo aspects, (1) mitigating faulty negative contrastive instances via\nconsidering cheminformatics similarities between molecule pairs; (2)\nfragment-level contrasting between intra- and inter-molecule substructures\ndecomposed from molecules. Experiments have shown that the proposed strategies\nsignificantly improve the performance of GNN models on various challenging\nmolecular property predictions. In comparison to the previous CL framework,\niMolCLR demonstrates an averaged 1.3% improvement of ROC-AUC on 7\nclassification benchmarks and an averaged 4.8% decrease of the error on 5\nregression benchmarks. On most benchmarks, the generic GNN pre-trained by\niMolCLR rivals or even surpasses supervised learning models with sophisticated\narchitecture designs and engineered features. Further investigations\ndemonstrate that representations learned through iMolCLR intrinsically embed\nscaffolds and functional groups that can reason molecule similarities.",
    "descriptor": "\nComments: 30 pages, 4 figures, 4 tables. Manuscript in submission\n",
    "authors": [
      "Yuyang Wang",
      "Rishikesh Magar",
      "Chen Liang",
      "Amir Barati Farimani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Chemical Physics (physics.chem-ph)"
    ],
    "url": "https://arxiv.org/abs/2202.09346"
  },
  {
    "id": "arXiv:2202.09348",
    "title": "A Machine Learning Paradigm for Studying Pictorial Realism: Are  Constable's Clouds More Real than His Contemporaries?",
    "abstract": "European artists have sought to create life-like images since the\nRenaissance. The techniques used by artists to impart realism to their\npaintings often rely on approaches based in mathematics, like linear\nperspective; yet the means used to assess the verisimilitude of realist\npaintings have remained subjective, even intuitive. An exploration of\nalternative and relatively objective methods for evaluating pictorial realism\ncould enhance existing art historical research. We propose a\nmachine-learning-based paradigm for studying pictorial realism in an\nexplainable way. Unlike subjective evaluations made by art historians or\ncomputer-based painting analysis exploiting inexplicable learned features, our\nframework assesses realism by measuring the similarity between clouds painted\nby exceptionally skillful 19th-century landscape painters like John Constable\nand photographs of clouds. The experimental results of cloud classification\nshow that Constable approximates more consistently than his contemporaries the\nformal features of actual clouds in his paintings. Our analyses suggest that\nartists working in the decades leading up to the invention of photography\nworked in a mode that anticipated some of the stylistic features of\nphotography. The study is a springboard for deeper analyses of pictorial\nrealism using computer vision and machine learning.",
    "descriptor": "",
    "authors": [
      "Zhuomin Zhang",
      "Elizabeth C. Mansfield",
      "Jia Li",
      "John Russell",
      "George S. Young",
      "Catherine Adams",
      "James Z. Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.09348"
  },
  {
    "id": "arXiv:2202.09352",
    "title": "Assessment of Cyber-Physical Intrusion Detection and Classification for  Industrial Control Systems",
    "abstract": "The increasing interaction of industrial control systems (ICSs) with public\nnetworks and digital devices introduces new cyber threats to power systems and\nother critical infrastructure. Recent cyber-physical attacks such as Stuxnet\nand Irongate revealed unexpected ICS vulnerabilities and a need for improved\nsecurity measures. Intrusion detection systems constitute a key security\ntechnology, which typically monitor network data for detecting malicious\nactivities. However, a central characteristic of modern ICSs is the increasing\ninterdependency of physical and cyber network processes. Thus, the integration\nof network and physical process data is seen as a promising approach to improve\npredictability in intrusion detection for ICSs by accounting for physical\nconstraints and underlying process patterns. This work systematically assesses\nreal-time cyber-physical intrusion detection and multiclass classification,\nbased on a comparison to its purely network data-based counterpart and\nevaluation of misclassifications and detection delay. Multiple supervised\nmachine learning models are applied on a recent cyber-physical dataset,\ndescribing various cyber attacks and physical faults on a generic ICS. A key\nfinding is that integration of physical process data improves detection and\nclassification of all attack types. In addition, it enables simultaneous\nprocessing of attacks and faults, paving the way for holistic cross-domain\ncause analysis.",
    "descriptor": "\nComments: Submitted to the 5th International Conference on Smart Energy Systems and Technologies (SEST)\n",
    "authors": [
      "Nils M\u00fcller",
      "Charalampos Ziras",
      "Kai Heussen"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.09352"
  },
  {
    "id": "arXiv:2202.09357",
    "title": "ProxSkip: Yes! Local Gradient Steps Provably Lead to Communication  Acceleration! Finally!",
    "abstract": "We introduce \\algname{ProxSkip} -- a surprisingly simple and provably\nefficient method for minimizing the sum of a smooth ($f$) and an expensive\nnonsmooth proximable ($\\psi$) function. The canonical approach to solving such\nproblems is via the proximal gradient descent (\\algname{ProxGD}) algorithm,\nwhich is based on the evaluation of the gradient of $f$ and the prox operator\nof $\\psi$ in each iteration. In this work we are specifically interested in the\nregime in which the evaluation of prox is costly relative to the evaluation of\nthe gradient, which is the case in many applications. \\algname{ProxSkip} allows\nfor the expensive prox operator to be skipped in most iterations: while its\niteration complexity is $\\cO(\\kappa \\log \\nicefrac{1}{\\varepsilon})$, where\n$\\kappa$ is the condition number of $f$, the number of prox evaluations is\n$\\cO(\\sqrt{\\kappa} \\log \\nicefrac{1}{\\varepsilon})$ only. Our main motivation\ncomes from federated learning, where evaluation of the gradient operator\ncorresponds to taking a local \\algname{GD} step independently on all devices,\nand evaluation of prox corresponds to (expensive) communication in the form of\ngradient averaging. In this context, \\algname{ProxSkip} offers an effective\n{\\em acceleration} of communication complexity. Unlike other local\ngradient-type methods, such as \\algname{FedAvg}, \\algname{SCAFFOLD},\n\\algname{S-Local-GD} and \\algname{FedLin}, whose theoretical communication\ncomplexity is worse than, or at best matching, that of vanilla \\algname{GD} in\nthe heterogeneous data regime, we obtain a provable and large improvement\nwithout any heterogeneity-bounding assumptions.",
    "descriptor": "\nComments: 20 pages\n",
    "authors": [
      "Konstantin Mishchenko",
      "Grigory Malinovsky",
      "Sebastian Stich",
      "Peter Richt\u00e1rik"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2202.09357"
  },
  {
    "id": "arXiv:1910.04358",
    "title": "Sub-linear Sequence Search via a Repeated And Merged Bloom Filter  (RAMBO): Indexing 170 TB data in 14 hours",
    "abstract": "Whole-genome shotgun sequencing (WGS), especially that of microbial genomes,\nhas been the core of recent research advances in large-scale comparative\ngenomics. The data deluge has resulted in exponential growth in genomic\ndatasets over the past years and has shown no sign of slowing down. Given\nterabytes of genetic sequences from raw reads and assembled genomes, there is a\nneed for a fast and memory efficient sequence search method. We propose a\ndata-structure which is based on Bloom filter. Here the number of Bloom Filter\nlookups scales sub-linear in the number of files, and hence it is significantly\nfaster than state of the art algorithm BIGSI (BItsliced Genomic Signature Index\n- a notable recent method for sequence search). The proposed idea is called\nRepeated and Merged BloOm Filter (RAMBO) which is theoretically sound and\ninspired by the Count-Min Sketch data structure, a popular streaming algorithm.\nRAMBO provides a significant improvement over state of the art methods in terms\nof query time when evaluated on real genomic datasets. Furthermore the\ninsertion and query process supports parallelism. Due to the sub-linear scaling\nof query time (O(\\sqrt(K)) vs O(K)), the larger the size and number of\ndatasets, the bigger the query time gains are with RAMBO over BIGSI. We provide\nrigorous empirical evaluations to support our theoretical claims. With RAMBO ,\nwe show a remarkable enhancement in the search and processing capabilities over\nBIGSI. We show how we can reduce the processing time of 170TB WGS dataset from\n6 weeks by BIGSI to mere 14 hours (72x faster) with similar levels of\ncompression. The query time using RAMBO decreases to around 3 ms compared to\nmore than 120ms for BIGSI.",
    "descriptor": "\nComments: 17 pages\n",
    "authors": [
      "Gaurav Gupta",
      "Minghao Yan",
      "Benjamin Coleman",
      "R. A. Leo Elworth",
      "Todd Treangen",
      "Anshumali Shrivastava"
    ],
    "subjectives": [
      "Genomics (q-bio.GN)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/1910.04358"
  },
  {
    "id": "arXiv:2202.08853",
    "title": "Scalable approach to many-body localization via quantum data",
    "abstract": "We are interested in how quantum data can allow for practical solutions to\notherwise difficult computational problems. A notoriously difficult phenomenon\nfrom quantum many-body physics is the emergence of many-body localization\n(MBL). So far, is has evaded a comprehensive analysis. In particular, numerical\nstudies are challenged by the exponential growth of the Hilbert space\ndimension. As many of these studies rely on exact diagonalization of the\nsystem's Hamiltonian, only small system sizes are accessible. In this work, we\npropose a highly flexible neural network based learning approach that, once\ngiven training data, circumvents any computationally expensive step. In this\nway, we can efficiently estimate common indicators of MBL such as the adjacent\ngap ratio or entropic quantities. Our estimator can be trained on data from\nvarious system sizes at once which grants the ability to extrapolate from\nsmaller to larger ones. Moreover, using transfer learning we show that already\na two-dimensional feature vector is sufficient to obtain several different\nindicators at various energy densities at once. We hope that our approach can\nbe applied to large-scale quantum experiments to provide new insights into\nquantum many-body physics.",
    "descriptor": "\nComments: 8+5 pages with 6+3 figures\n",
    "authors": [
      "Alexander Gresch",
      "Lennart Bittel",
      "Martin Kliesch"
    ],
    "subjectives": [
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Machine Learning (cs.LG)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2202.08853"
  },
  {
    "id": "arXiv:2202.08876",
    "title": "Training neural networks using monotone variational inequality",
    "abstract": "Despite the vast empirical success of neural networks, theoretical\nunderstanding of the training procedures remains limited, especially in\nproviding performance guarantees of testing performance due to the non-convex\nnature of the optimization problem. Inspired by a recent work of (Juditsky &\nNemirovsky, 2019), instead of using the traditional loss function minimization\napproach, we reduce the training of the network parameters to another problem\nwith convex structure -- to solve a monotone variational inequality (MVI). The\nsolution to MVI can be found by computationally efficient procedures, and\nimportantly, this leads to performance guarantee of $\\ell_2$ and\n$\\ell_{\\infty}$ bounds on model recovery accuracy and prediction accuracy under\nthe theoretical setting of training one-layer linear neural network. In\naddition, we study the use of MVI for training multi-layer neural networks and\npropose a practical algorithm called \\textit{stochastic variational inequality}\n(SVI), and demonstrates its applicability in training fully-connected neural\nnetworks and graph neural networks (GNN) (SVI is completely general and can be\nused to train other types of neural networks). We demonstrate the competitive\nor better performance of SVI compared to the stochastic gradient descent (SGD)\non both synthetic and real network data prediction tasks regarding various\nperformance metrics.",
    "descriptor": "",
    "authors": [
      "Chen Xu",
      "Xiuyuan Cheng",
      "Yao Xie"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.08876"
  },
  {
    "id": "arXiv:2202.08880",
    "title": "Ray-transfer functions for camera simulation of 3D scenes with hidden  lens design",
    "abstract": "Combining image sensor simulation tools (e.g., ISETCam) with physically based\nray tracing (e.g., PBRT) offers possibilities for designing and evaluating\nnovel imaging systems as well as for synthesizing physically accurate, labeled\nimages for machine learning. One practical limitation has been simulating the\noptics precisely: Lens manufacturers generally prefer to keep lens design\nconfidential. We present a pragmatic solution to this problem using a black box\nlens model in Zemax; such models provide necessary optical information while\npreserving the lens designer's intellectual property. First, we describe and\nprovide software to construct a polynomial ray transfer function that\ncharacterizes how rays entering the lens at any position and angle subsequently\nexit the lens. We implement the ray-transfer calculation as a camera model in\nPBRT and confirm that the PBRT ray-transfer calculations match the Zemax lens\ncalculations for edge spread functions and relative illumination.",
    "descriptor": "",
    "authors": [
      "Thomas Goossens",
      "Zheng Lyu",
      "Jamyuen Ko",
      "Gordon Wan",
      "Joyce Farrell",
      "Brian Wandell"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Graphics (cs.GR)",
      "Optics (physics.optics)"
    ],
    "url": "https://arxiv.org/abs/2202.08880"
  },
  {
    "id": "arXiv:2202.08883",
    "title": "Curriculum optimization for low-resource speech recognition",
    "abstract": "Modern end-to-end speech recognition models show astonishing results in\ntranscribing audio signals into written text. However, conventional data\nfeeding pipelines may be sub-optimal for low-resource speech recognition, which\nstill remains a challenging task. We propose an automated curriculum learning\napproach to optimize the sequence of training examples based on both the\nprogress of the model while training and prior knowledge about the difficulty\nof the training examples. We introduce a new difficulty measure called\ncompression ratio that can be used as a scoring function for raw audio in\nvarious noise conditions. The proposed method improves speech recognition Word\nError Rate performance by up to 33% relative over the baseline system",
    "descriptor": "",
    "authors": [
      "Anastasia Kuznetsova",
      "Anurag Kumar",
      "Jennifer Drexler Fox",
      "Francis Tyers"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2202.08883"
  },
  {
    "id": "arXiv:2202.08916",
    "title": "Graph Convolutional Networks for Multi-modality Medical Imaging:  Methods, Architectures, and Clinical Applications",
    "abstract": "Image-based characterization and disease understanding involve integrative\nanalysis of morphological, spatial, and topological information across\nbiological scales. The development of graph convolutional networks (GCNs) has\ncreated the opportunity to address this information complexity via graph-driven\narchitectures, since GCNs can perform feature aggregation, interaction, and\nreasoning with remarkable flexibility and efficiency. These GCNs capabilities\nhave spawned a new wave of research in medical imaging analysis with the\noverarching goal of improving quantitative disease understanding, monitoring,\nand diagnosis. Yet daunting challenges remain for designing the important\nimage-to-graph transformation for multi-modality medical imaging and gaining\ninsights into model interpretation and enhanced clinical decision support. In\nthis review, we present recent GCNs developments in the context of medical\nimage analysis including imaging data from radiology and histopathology. We\ndiscuss the fast-growing use of graph network architectures in medical image\nanalysis to improve disease diagnosis and patient outcomes in clinical\npractice. To foster cross-disciplinary research, we present GCNs technical\nadvancements, emerging medical applications, identify common challenges in the\nuse of image-based GCNs and their extensions in model interpretation,\nlarge-scale benchmarks that promise to transform the scope of medical image\nstudies and related graph-driven medical research.",
    "descriptor": "",
    "authors": [
      "Kexin Ding",
      "Mu Zhou",
      "Zichen Wang",
      "Qiao Liu",
      "Corey W. Arnold",
      "Shaoting Zhang",
      "Dimitri N. Metaxas"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.08916"
  },
  {
    "id": "arXiv:2202.08925",
    "title": "Quantisation-aware Precoding for MU-MIMO with Limited-capacity Fronthaul",
    "abstract": "Base stations in 5G and beyond use advanced antenna systems (AASs), where\nmultiple passive antenna elements and radio units are integrated into a single\nbox. A critical bottleneck of such a system is the digital fronthaul between\nthe AAS and baseband unit (BBU), which has limited capacity. In this paper, we\nstudy an AAS used for precoded downlink transmission over a multi-user\nmultiple-input multiple-output (MU-MIMO) channel. First, we present the\nbaseline quantization-unaware precoding scheme created when a precoder is\ncomputed at the BBU and then quantized to be sent over the fronthaul. We\npropose a new precoding design that is aware of the fronthaul quantization. We\nformulate an optimization problem to minimize the mean squared error at the\nreceiver side. We rewrite the problem to utilize mixed-integer programming to\nsolve it. The numerical results manifest that our proposed precoding greatly\noutperforms quantization-unaware precoding in terms of sum rate.",
    "descriptor": "\nComments: 5 pages, 3 figures, accepted for publication in IEEE ICASSP 2022 conference\n",
    "authors": [
      "Yasaman Khorsandmanesh",
      "Emil Bj\u00f6rnson",
      "Joakim Jald\u00e8n"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.08925"
  },
  {
    "id": "arXiv:2202.08930",
    "title": "A Distributed Algorithm for Measure-valued Optimization with Additive  Objective",
    "abstract": "We propose a distributed nonparametric algorithm for solving measure-valued\noptimization problems with additive objectives. Such problems arise in several\ncontexts in stochastic learning and control including Langevin sampling from an\nunnormalized prior, mean field neural network learning and Wasserstein gradient\nflows. The proposed algorithm comprises a two-layer alternating direction\nmethod of multipliers (ADMM). The outer-layer ADMM generalizes the Euclidean\nconsensus ADMM to the Wasserstein consensus ADMM, and to its\nentropy-regularized version Sinkhorn consensus ADMM. The inner-layer ADMM turns\nout to be a specific instance of the standard Euclidean ADMM. The overall\nalgorithm realizes operator splitting for gradient flows in the manifold of\nprobability measures.",
    "descriptor": "",
    "authors": [
      "Iman Nodozi",
      "Abhishek Halder"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.08930"
  },
  {
    "id": "arXiv:2202.08936",
    "title": "Prior image-based medical image reconstruction using a style-based  generative adversarial network",
    "abstract": "Computed medical imaging systems require a computational reconstruction\nprocedure for image formation. In order to recover a useful estimate of the\nobject to-be-imaged when the recorded measurements are incomplete, prior\nknowledge about the nature of object must be utilized. In order to improve the\nconditioning of an ill-posed imaging inverse problem, deep learning approaches\nare being actively investigated for better representing object priors and\nconstraints. This work proposes to use a style-based generative adversarial\nnetwork (StyleGAN) to constrain an image reconstruction problem in the case\nwhere additional information in the form of a prior image of the sought-after\nobject is available. An optimization problem is formulated in the intermediate\nlatent-space of a StyleGAN, that is disentangled with respect to meaningful\nimage attributes or \"styles\", such as the contrast used in magnetic resonance\nimaging (MRI). Discrepancy between the sought-after and prior images is\nmeasured in the disentangled latent-space, and is used to regularize the\ninverse problem in the form of constraints on specific styles of the\ndisentangled latent-space. A stylized numerical study inspired by MR imaging is\ndesigned, where the sought-after and the prior image are structurally similar,\nbut belong to different contrast mechanisms. The presented numerical studies\ndemonstrate the superiority of the proposed approach as compared to classical\napproaches in the form of traditional metrics.",
    "descriptor": "",
    "authors": [
      "Varun A. Kelkar",
      "Mark A. Anastasio"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Medical Physics (physics.med-ph)"
    ],
    "url": "https://arxiv.org/abs/2202.08936"
  },
  {
    "id": "arXiv:2202.08956",
    "title": "GNN-Surrogate: A Hierarchical and Adaptive Graph Neural Network for  Parameter Space Exploration of Unstructured-Mesh Ocean Simulations",
    "abstract": "We propose GNN-Surrogate, a graph neural network-based surrogate model to\nexplore the parameter space of ocean climate simulations. Parameter space\nexploration is important for domain scientists to understand the influence of\ninput parameters (e.g., wind stress) on the simulation output (e.g.,\ntemperature). The exploration requires scientists to exhaust the complicated\nparameter space by running a batch of computationally expensive simulations.\nOur approach improves the efficiency of parameter space exploration with a\nsurrogate model that predicts the simulation outputs accurately and\nefficiently. Specifically, GNN-Surrogate predicts the output field with given\nsimulation parameters so scientists can explore the simulation parameter space\nwith visualizations from user-specified visual mappings. Moreover, our\ngraph-based techniques are designed for unstructured meshes, making the\nexploration of simulation outputs on irregular grids efficient. For efficient\ntraining, we generate hierarchical graphs and use adaptive resolutions. We give\nquantitative and qualitative evaluations on the MPAS-Ocean simulation to\ndemonstrate the effectiveness and efficiency of GNN-Surrogate. Source code is\npublicly available at https://github.com/trainsn/GNN-Surrogate.",
    "descriptor": "\nComments: Accepted by TVCG Special Issue on the 2022 IEEE Pacific Visualization Symposium (PacificVis)\n",
    "authors": [
      "Neng Shi",
      "Jiayi Xu",
      "Skylar W. Wurster",
      "Hanqi Guo",
      "Jonathan Woodring",
      "Luke P. Van Roekel",
      "Han-Wei Shen"
    ],
    "subjectives": [
      "Atmospheric and Oceanic Physics (physics.ao-ph)",
      "Artificial Intelligence (cs.AI)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.08956"
  },
  {
    "id": "arXiv:2202.08967",
    "title": "Ensemble and Multimodal Approach for Forecasting Cryptocurrency Price",
    "abstract": "Since the birth of Bitcoin in 2009, cryptocurrencies have emerged to become a\nglobal phenomenon and an important decentralized financial asset. Due to this\ndecentralization, the value of these digital currencies against fiat currencies\nis highly volatile over time. Therefore, forecasting the crypto-fiat currency\nexchange rate is an extremely challenging task. For reliable forecasting, this\npaper proposes a multimodal AdaBoost-LSTM ensemble approach that employs all\nmodalities which derive price fluctuation such as social media sentiments,\nsearch volumes, blockchain information, and trading data. To better support\ninvestment decision making, the approach forecasts also the fluctuation\ndistribution. The conducted extensive experiments demonstrated the\neffectiveness of relying on multimodalities instead of only trading data.\nFurther experiments demonstrate the outperformance of the proposed approach\ncompared to existing tools and methods with a 19.29% improvement.",
    "descriptor": "",
    "authors": [
      "Zeyd Boukhers",
      "Azeddine Bouabdallah",
      "Matthias Lohr",
      "Jan J\u00fcrjens"
    ],
    "subjectives": [
      "Statistical Finance (q-fin.ST)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.08967"
  },
  {
    "id": "arXiv:2202.08968",
    "title": "Stock Embeddings: Learning Distributed Representations for Financial  Assets",
    "abstract": "Identifying meaningful relationships between the price movements of financial\nassets is a challenging but important problem in a variety of financial\napplications. However with recent research, particularly those using machine\nlearning and deep learning techniques, focused mostly on price forecasting, the\nliterature investigating the modelling of asset correlations has lagged\nsomewhat. To address this, inspired by recent successes in natural language\nprocessing, we propose a neural model for training stock embeddings, which\nharnesses the dynamics of historical returns data in order to learn the nuanced\nrelationships that exist between financial assets. We describe our approach in\ndetail and discuss a number of ways that it can be used in the financial\ndomain. Furthermore, we present the evaluation results to demonstrate the\nutility of this approach, compared to several important benchmarks, in two\nreal-world financial analytics tasks.",
    "descriptor": "\nComments: Currently under review. 9 pages, 4 figures\n",
    "authors": [
      "Rian Dolphin",
      "Barry Smyth",
      "Ruihai Dong"
    ],
    "subjectives": [
      "Statistical Finance (q-fin.ST)",
      "Machine Learning (cs.LG)",
      "Computational Finance (q-fin.CP)"
    ],
    "url": "https://arxiv.org/abs/2202.08968"
  },
  {
    "id": "arXiv:2202.08969",
    "title": "Private Quantiles Estimation in the Presence of Atoms",
    "abstract": "We address the differentially private estimation of multiple quantiles (MQ)\nof a dataset, a key building block in modern data analysis. We apply the recent\nnon-smoothed Inverse Sensitivity (IS) mechanism to this specific problem and\nestablish that the resulting method is closely related to the current\nstate-of-the-art, the JointExp algorithm, sharing in particular the same\ncomputational complexity and a similar efficiency. However, we demonstrate both\ntheoretically and empirically that (non-smoothed) JointExp suffers from an\nimportant lack of performance in the case of peaked distributions, with a\npotentially catastrophic impact in the presence of atoms. While its smoothed\nversion would allow to leverage the performance guarantees of IS, it remains an\nopen challenge to implement. As a proxy to fix the problem we propose a simple\nand numerically efficient method called Heuristically Smoothed JointExp\n(HSJointExp), which is endowed with performance guarantees for a broad class of\ndistributions and achieves results that are orders of magnitude better on\nproblematic datasets.",
    "descriptor": "",
    "authors": [
      "Cl\u00e9ment Lalanne",
      "Cl\u00e9ment Gastaud",
      "Nicolas Grislain",
      "Aur\u00e9lien Garivier",
      "R\u00e9mi Gribonval"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.08969"
  },
  {
    "id": "arXiv:2202.08977",
    "title": "Fairness constraint in Structural Econometrics and Application to fair  estimation using Instrumental Variables",
    "abstract": "A supervised machine learning algorithm determines a model from a learning\nsample that will be used to predict new observations. To this end, it\naggregates individual characteristics of the observations of the learning\nsample. But this information aggregation does not consider any potential\nselection on unobservables and any status-quo biases which may be contained in\nthe training sample. The latter bias has raised concerns around the so-called\n\\textit{fairness} of machine learning algorithms, especially towards\ndisadvantaged groups. In this chapter, we review the issue of fairness in\nmachine learning through the lenses of structural econometrics models in which\nthe unknown index is the solution of a functional equation and issues of\nendogeneity are explicitly accounted for. We model fairness as a linear\noperator whose null space contains the set of strictly {\\it fair} indexes. A\n{\\it fair} solution is obtained by projecting the unconstrained index into the\nnull space of this operator or by directly finding the closest solution of the\nfunctional equation into this null space. We also acknowledge that policymakers\nmay incur a cost when moving away from the status quo. Achieving\n\\textit{approximate fairness} is obtained by introducing a fairness penalty in\nthe learning procedure and balancing more or less heavily the influence between\nthe status quo and a full fair solution.",
    "descriptor": "",
    "authors": [
      "Samuele Centorrino",
      "Jean-Pierre Florens",
      "Jean-Michel Loubes"
    ],
    "subjectives": [
      "Econometrics (econ.EM)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.08977"
  },
  {
    "id": "arXiv:2202.08994",
    "title": "REFUGE2 Challenge: Treasure for Multi-Domain Learning in Glaucoma  Assessment",
    "abstract": "Glaucoma is the second leading cause of blindness and is the leading cause of\nirreversible blindness disease in the world. Early screening for glaucoma in\nthe population is significant. Color fundus photography is the most cost\neffective imaging modality to screen for ocular diseases. Deep learning network\nis often used in color fundus image analysis due to its powful feature\nextraction capability. However, the model training of deep learning method\nneeds a large amount of data, and the distribution of data should be abundant\nfor the robustness of model performance. To promote the research of deep\nlearning in color fundus photography and help researchers further explore the\nclinical application signification of AI technology, we held a REFUGE2\nchallenge. This challenge released 2,000 color fundus images of four models,\nincluding Zeiss, Canon, Kowa and Topcon, which can validate the stabilization\nand generalization of algorithms on multi-domain. Moreover, three sub-tasks\nwere designed in the challenge, including glaucoma classification, cup/optic\ndisc segmentation, and macular fovea localization. These sub-tasks technically\ncover the three main problems of computer vision and clinicly cover the main\nresearchs of glaucoma diagnosis. Over 1,300 international competitors joined\nthe REFUGE2 challenge, 134 teams submitted more than 3,000 valid preliminary\nresults, and 22 teams reached the final. This article summarizes the methods of\nsome of the finalists and analyzes their results. In particular, we observed\nthat the teams using domain adaptation strategies had high and robust\nperformance on the dataset with multi-domain. This indicates that UDA and other\nmulti-domain related researches will be the trend of deep learning field in the\nfuture, and our REFUGE2 datasets will play an important role in these\nresearches.",
    "descriptor": "\nComments: 29 pages, 20 figures\n",
    "authors": [
      "Huihui Fang",
      "Fei Li",
      "Huazhu Fu",
      "Xu Sun",
      "Xingxing Cao",
      "Jaemin Son",
      "Shuang Yu",
      "Menglu Zhang",
      "Chenglang Yuan",
      "Cheng Bian",
      "Baiying Lei",
      "Benjian Zhao",
      "Xinxing Xu",
      "Shaohua Li",
      "Francisco Fumero",
      "Jose Sigut",
      "Haidar Almubarak",
      "Yakoub Bazi",
      "Yuanhao Guo",
      "Yating Zhou",
      "Ujjwal Baid",
      "Shubham Innani",
      "Tianjiao Guo",
      "Jie Yang",
      "Jos\u00e9 Ignacio Orlando",
      "Hrvoje Bogunovi\u0107",
      "Xiulan Zhang",
      "Yanwu Xu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.08994"
  },
  {
    "id": "arXiv:2202.09008",
    "title": "On Variance Estimation of Random Forests",
    "abstract": "Ensemble methods based on subsampling, such as random forests, are popular in\napplications due to their high predictive accuracy. Existing literature views a\nrandom forest prediction as an infinite-order incomplete U-statistic to\nquantify its uncertainty. However, these methods focus on a small subsampling\nsize of each tree, which is theoretically valid but practically limited. This\npaper develops an unbiased variance estimator based on incomplete U-statistics,\nwhich allows the tree size to be comparable with the overall sample size,\nmaking statistical inference possible in a broader range of real applications.\nSimulation results demonstrate that our estimators enjoy lower bias and more\naccurate confidence interval coverage without additional computational costs.\nWe also propose a local smoothing procedure to reduce the variation of our\nestimator, which shows improved numerical performance when the number of trees\nis relatively small. Further, we investigate the ratio consistency of our\nproposed variance estimator under specific scenarios. In particular, we develop\na new \"double U-statistic\" formulation to analyze the Hoeffding decomposition\nof the estimator's variance.",
    "descriptor": "",
    "authors": [
      "Tianning Xu",
      "Ruoqing Zhu",
      "Xiaofeng Shao"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2202.09008"
  },
  {
    "id": "arXiv:2202.09046",
    "title": "Microplankton life histories revealed by holographic microscopy and deep  learning",
    "abstract": "The marine microbial food web plays a central role in the global carbon\ncycle. Our mechanistic understanding of the ocean, however, is biased towards\nits larger constituents, while rates and biomass fluxes in the microbial food\nweb are mainly inferred from indirect measurements and ensemble averages. Yet,\nresolution at the level of the individual microplankton is required to advance\nour understanding of the oceanic food web. Here, we demonstrate that, by\ncombining holographic microscopy with deep learning, we can follow\nmicroplanktons throughout their lifespan, continuously measuring their three\ndimensional position and dry mass. The deep learning algorithms circumvent the\ncomputationally intensive processing of holographic data and allow rapid\nmeasurements over extended time periods. This permits us to reliably estimate\ngrowth rates, both in terms of dry mass increase and cell divisions, as well as\nto measure trophic interactions between species such as predation events. The\nindividual resolution provides information about selectivity, individual\nfeeding rates and handling times for individual microplanktons. This method is\nparticularly useful to explore the flux of carbon through micro-zooplankton,\nthe most important and least known group of primary consumers in the global\noceans. We exemplify this by detailed descriptions of micro-zooplankton feeding\nevents, cell divisions, and long term monitoring of single cells from division\nto division.",
    "descriptor": "\nComments: 20 pages, 4 figure, 5 supplementary figure\n",
    "authors": [
      "Harshith Bachimanchi",
      "Benjamin Midtvedt",
      "Daniel Midtvedt",
      "Erik Selander",
      "Giovanni Volpe"
    ],
    "subjectives": [
      "Biological Physics (physics.bio-ph)",
      "Soft Condensed Matter (cond-mat.soft)",
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2202.09046"
  },
  {
    "id": "arXiv:2202.09054",
    "title": "Interpolation and Regularization for Causal Learning",
    "abstract": "We study the problem of learning causal models from observational data\nthrough the lens of interpolation and its counterpart -- regularization. A\nlarge volume of recent theoretical, as well as empirical work, suggests that,\nin highly complex model classes, interpolating estimators can have good\nstatistical generalization properties and can even be optimal for statistical\nlearning. Motivated by an analogy between statistical and causal learning\nrecently highlighted by Janzing (2019), we investigate whether interpolating\nestimators can also learn good causal models. To this end, we consider a simple\nlinearly confounded model and derive precise asymptotics for the *causal risk*\nof the min-norm interpolator and ridge-regularized regressors in the\nhigh-dimensional regime. Under the principle of independent causal mechanisms,\na standard assumption in causal learning, we find that interpolators cannot be\noptimal and causal learning requires stronger regularization than statistical\nlearning. This resolves a recent conjecture in Janzing (2019). Beyond this\nassumption, we find a larger range of behavior that can be precisely\ncharacterized with a new measure of *confounding strength*. If the confounding\nstrength is negative, causal learning requires weaker regularization than\nstatistical learning, interpolators can be optimal, and the optimal\nregularization can even be negative. If the confounding strength is large, the\noptimal regularization is infinite, and learning from observational data is\nactively harmful.",
    "descriptor": "",
    "authors": [
      "Leena Chennuru Vankadara",
      "Luca Rendsburg",
      "Ulrike von Luxburg",
      "Debarghya Ghoshdastidar"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.09054"
  },
  {
    "id": "arXiv:2202.09059",
    "title": "Towards better understanding and better generalization of few-shot  classification in histology images with contrastive learning",
    "abstract": "Few-shot learning is an established topic in natural images for years, but\nfew work is attended to histology images, which is of high clinical value since\nwell-labeled datasets and rare abnormal samples are expensive to collect. Here,\nwe facilitate the study of few-shot learning in histology images by setting up\nthree cross-domain tasks that simulate real clinics problems. To enable\nlabel-efficient learning and better generalizability, we propose to incorporate\ncontrastive learning (CL) with latent augmentation (LA) to build a few-shot\nsystem. CL learns useful representations without manual labels, while LA\ntransfers semantic variations of the base dataset in an unsupervised way. These\ntwo components fully exploit unlabeled training data and can scale gracefully\nto other label-hungry problems. In experiments, we find i) models learned by CL\ngeneralize better than supervised learning for histology images in unseen\nclasses, and ii) LA brings consistent gains over baselines. Prior studies of\nself-supervised learning mainly focus on ImageNet-like images, which only\npresent a dominant object in their centers. Recent attention has been paid to\nimages with multi-objects and multi-textures. Histology images are a natural\nchoice for such a study. We show the superiority of CL over supervised learning\nin terms of generalization for such data and provide our empirical\nunderstanding for this observation. The findings in this work could contribute\nto understanding how the model generalizes in the context of both\nrepresentation learning and histological image analysis. Code is available.",
    "descriptor": "",
    "authors": [
      "Jiawei Yang",
      "Hanbo Chen",
      "Jiangpeng Yan",
      "Xiaoyu Chen",
      "Jianhua Yao"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.09059"
  },
  {
    "id": "arXiv:2202.09079",
    "title": "Central limit theorem for full discretization of parabolic SPDE",
    "abstract": "In order to characterize the fluctuation between the ergodic limit and the\ntime-averaging estimator of a full discretization in a quantitative way, we\nestablish a central limit theorem for the full discretization of the parabolic\nstochastic partial differential equation. The theorem shows that the normalized\ntime-averaging estimator converges to a normal distribution with the variance\nbeing the same as that of the continuous case, where the scale used for the\nnormalization corresponds to the temporal strong convergence order of the\nconsidered full discretization. A key ingredient in the proof is to extract an\nappropriate martingale difference series sum from the normalized time-averaging\nestimator so that the convergence to the normal distribution of such a sum and\nthe convergence to zero in probability of the remainder are well balanced. The\nmain novelty of our method to balance the convergence lies in proposing an\nappropriately modified Poisson equation so as to possess the space-independent\nregularity estimates. As a byproduct, the full discretization is shown to\nfulfill the weak law of large numbers, namely, the time-averaging estimator\nconverges to the ergodic limit in probability.",
    "descriptor": "",
    "authors": [
      "Chuchu Chen",
      "Tonghe Dang",
      "Jialin Hong",
      "Tau Zhou"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.09079"
  },
  {
    "id": "arXiv:2202.09081",
    "title": "VCVTS: Multi-speaker Video-to-Speech synthesis via cross-modal knowledge  transfer from voice conversion",
    "abstract": "Though significant progress has been made for speaker-dependent\nVideo-to-Speech (VTS) synthesis, little attention is devoted to multi-speaker\nVTS that can map silent video to speech, while allowing flexible control of\nspeaker identity, all in a single system. This paper proposes a novel\nmulti-speaker VTS system based on cross-modal knowledge transfer from voice\nconversion (VC), where vector quantization with contrastive predictive coding\n(VQCPC) is used for the content encoder of VC to derive discrete phoneme-like\nacoustic units, which are transferred to a Lip-to-Index (Lip2Ind) network to\ninfer the index sequence of acoustic units. The Lip2Ind network can then\nsubstitute the content encoder of VC to form a multi-speaker VTS system to\nconvert silent video to acoustic units for reconstructing accurate spoken\ncontent. The VTS system also inherits the advantages of VC by using a speaker\nencoder to produce speaker representations to effectively control the speaker\nidentity of generated speech. Extensive evaluations verify the effectiveness of\nproposed approach, which can be applied in both constrained vocabulary and open\nvocabulary conditions, achieving state-of-the-art performance in generating\nhigh-quality speech with high naturalness, intelligibility and speaker\nsimilarity. Our demo page is released here:\nhttps://wendison.github.io/VCVTS-demo/",
    "descriptor": "\nComments: Accepted to ICASSP 2022. Demo page is available at this https URL\n",
    "authors": [
      "Disong Wang",
      "Shan Yang",
      "Dan Su",
      "Xunying Liu",
      "Dong Yu",
      "Helen Meng"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)",
      "Sound (cs.SD)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2202.09081"
  },
  {
    "id": "arXiv:2202.09082",
    "title": "Speaker Identity Preservation in Dysarthric Speech Reconstruction by  Adversarial Speaker Adaptation",
    "abstract": "Dysarthric speech reconstruction (DSR), which aims to improve the quality of\ndysarthric speech, remains a challenge, not only because we need to restore the\nspeech to be normal, but also must preserve the speaker's identity. The speaker\nrepresentation extracted by the speaker encoder (SE) optimized for speaker\nverification has been explored to control the speaker identity. However, the SE\nmay not be able to fully capture the characteristics of dysarthric speakers\nthat are previously unseen. To address this research problem, we propose a\nnovel multi-task learning strategy, i.e., adversarial speaker adaptation (ASA).\nThe primary task of ASA fine-tunes the SE with the speech of the target\ndysarthric speaker to effectively capture identity-related information, and the\nsecondary task applies adversarial training to avoid the incorporation of\nabnormal speaking patterns into the reconstructed speech, by regularizing the\ndistribution of reconstructed speech to be close to that of reference speech\nwith high quality. Experiments show that the proposed approach can achieve\nenhanced speaker similarity and comparable speech naturalness with a strong\nbaseline approach. Compared with dysarthric speech, the reconstructed speech\nachieves 22.3% and 31.5% absolute word error rate reduction for speakers with\nmoderate and moderate-severe dysarthria respectively. Our demo page is released\nhere: https://wendison.github.io/ASA-DSR-demo/",
    "descriptor": "\nComments: Accepted to ICASSP 2022. Demo page is available at this https URL\n",
    "authors": [
      "Disong Wang",
      "Songxiang Liu",
      "Xixin Wu",
      "Hui Lu",
      "Lifa Sun",
      "Xunying Liu",
      "Helen Meng"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Multimedia (cs.MM)",
      "Sound (cs.SD)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.09082"
  },
  {
    "id": "arXiv:2202.09093",
    "title": "Toward a Smart Resource Allocation Policy via Artificial Intelligence in  6G Networks: Centralized or Decentralized?",
    "abstract": "In this paper, we design a new smart softwaredefined radio access network\n(RAN) architecture with important properties like flexibility and traffic\nawareness for sixth generation (6G) wireless networks. In particular, we\nconsider a hierarchical resource allocation framework for the proposed smart\nsoft-RAN model, where the software-defined network (SDN) controller is the\nfirst and foremost layer of the framework. This unit dynamically monitors the\nnetwork to select a network operation type on the basis of distributed or\ncentralized resource allocation architectures to perform decision-making\nintelligently. In this paper, our aim is to make the network more scalable and\nmore flexible in terms of achievable data rate, overhead, and complexity\nindicators. To this end, we introduce a new metric, throughput overhead\ncomplexity (TOC), for the proposed machine learning-based algorithm, which\nmakes a trade-off between these performance indicators. In particular, the\ndecision making based on TOC is solved via deep reinforcement learning (DRL),\nwhich determines an appropriate resource allocation policy. Furthermore, for\nthe selected algorithm, we employ the soft actor-critic method, which is more\naccurate, scalable, and robust than other learning methods. Simulation results\ndemonstrate that the proposed smart network achieves better performance in\nterms of TOC compared to fixed centralized or distributed resource management\nschemes that lack dynamism. Moreover, our proposed algorithm outperforms\nconventional learning methods employed in other state-of-the-art network\ndesigns.",
    "descriptor": "\nComments: Submitted to IEEE for possible publications\n",
    "authors": [
      "Ali Nouruzi",
      "Atefeh Rezaei",
      "Ata Khalili",
      "Nader Mokari",
      "Mohammad Reza Javan",
      "Eduard A. Jorswieck",
      "Halim Yanikomeroglu"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2202.09093"
  },
  {
    "id": "arXiv:2202.09107",
    "title": "Comparison of an Apocalypse-Free and an Apocalypse-Prone First-Order  Low-Rank Optimization Algorithm",
    "abstract": "We compare two first-order low-rank optimization algorithms, namely\n$\\text{P}^2\\text{GD}$ (Schneider and Uschmajew, 2015), which has been proven to\nbe apocalypse-prone (Levin et al., 2021), and its apocalypse-free version\n$\\text{P}^2\\text{GDR}$ obtained by equipping $\\text{P}^2\\text{GD}$ with a\nsuitable rank reduction mechanism (Olikier et al., 2022). Here an apocalypse\nrefers to the situation where the stationarity measure goes to zero along a\nconvergent sequence whereas it is nonzero at the limit. The comparison is\nconducted on two simple examples of apocalypses, the original one (Levin et\nal., 2021) and a new one. We also present a potential side effect of the rank\nreduction mechanism of $\\text{P}^2\\text{GDR}$ and discuss the choice of the\nrank reduction parameter.",
    "descriptor": "",
    "authors": [
      "Guillaume Olikier",
      "Kyle A. Gallivan",
      "P.-A. Absil"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.09107"
  },
  {
    "id": "arXiv:2202.09121",
    "title": "Echo-aware Adaptation of Sound Event Localization and Detection in  Unknown Environments",
    "abstract": "Our goal is to develop a sound event localization and detection (SELD) system\nthat works robustly in unknown environments. A SELD system trained on known\nenvironment data is degraded in an unknown environment due to environmental\neffects such as reverberation and noise not contained in the training data.\nPrevious studies on related tasks have shown that domain adaptation methods are\neffective when data on the environment in which the system will be used is\navailable even without labels. However adaptation to unknown environments\nremains a difficult task. In this study, we propose echo-aware feature\nrefinement (EAR) for SELD, which suppresses environmental effects at the\nfeature level by using additional spatial cues of the unknown environment\nobtained through measuring acoustic echoes. FOA-MEIR, an impulse response\ndataset containing over 100 environments, was recorded to validate the proposed\nmethod. Experiments on FOA-MEIR show that the EAR effectively improves SELD\nperformance in unknown environments.",
    "descriptor": "\nComments: 5 pages, 3 figures, to appear in IEEE ICASSP 2022\n",
    "authors": [
      "Masahiro Yasuda",
      "Yasunori Ohishi",
      "Shoichiro Saito"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2202.09121"
  },
  {
    "id": "arXiv:2202.09124",
    "title": "Multi-view and Multi-modal Event Detection Utilizing Transformer-based  Multi-sensor fusion",
    "abstract": "We tackle a challenging task: multi-view and multi-modal event detection that\ndetects events in a wide-range real environment by utilizing data from\ndistributed cameras and microphones and their weak labels. In this task,\ndistributed sensors are utilized complementarily to capture events that are\ndifficult to capture with a single sensor, such as a series of actions of\npeople moving in an intricate room, or communication between people located far\napart in a room. For sensors to cooperate effectively in such a situation, the\nsystem should be able to exchange information among sensors and combines\ninformation that is useful for identifying events in a complementary manner.\nFor such a mechanism, we propose a Transformer-based multi-sensor fusion\n(MultiTrans) which combines multi-sensor data on the basis of the relationships\nbetween features of different viewpoints and modalities. In the experiments\nusing a dataset newly collected for this task, our proposed method using\nMultiTrans improved the event detection performance and outperformed\ncomparatives.",
    "descriptor": "\nComments: 5 pages, 5 figures, to appear in IEEE ICASSP 2022\n",
    "authors": [
      "Masahiro Yasuda",
      "Yasunori Ohishi",
      "Shoichiro Saito",
      "Noboru Harada"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2202.09124"
  },
  {
    "id": "arXiv:2202.09129",
    "title": "Efficient computation of the volume of a polytope in high-dimensions  using Piecewise Deterministic Markov Processes",
    "abstract": "Computing the volume of a polytope in high dimensions is computationally\nchallenging but has wide applications. Current state-of-the-art algorithms to\ncompute such volumes rely on efficient sampling of a Gaussian distribution\nrestricted to the polytope, using e.g. Hamiltonian Monte Carlo. We present a\nnew sampling strategy that uses a Piecewise Deterministic Markov Process. Like\nHamiltonian Monte Carlo, this new method involves simulating trajectories of a\nnon-reversible process and inherits similar good mixing properties. However,\nimportantly, the process can be simulated more easily due to its piecewise\nlinear trajectories - and this leads to a reduction of the computational cost\nby a factor of the dimension of the space. Our experiments indicate that our\nmethod is numerically robust and is one order of magnitude faster (or better)\nthan existing methods using Hamiltonian Monte Carlo. On a single core\nprocessor, we report computational time of a few minutes up to dimension 500.",
    "descriptor": "",
    "authors": [
      "Augustin Chevallier",
      "Fr\u00e9d\u00e9ric Cazals",
      "Paul Fearnhead"
    ],
    "subjectives": [
      "Computation (stat.CO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.09129"
  },
  {
    "id": "arXiv:2202.09167",
    "title": "Domain Adaptation of low-resource Target-Domain models using  well-trained ASR Conformer Models",
    "abstract": "In this paper, we investigate domain adaptation for low-resource Automatic\nSpeech Recognition (ASR) of target-domain data, when a well-trained ASR model\ntrained with a large dataset is available. We argue that in the encoder-decoder\nframework, the decoder of the well-trained ASR model is largely tuned towards\nthe source-domain, hurting the performance of target-domain models in vanilla\ntransfer-learning. On the other hand, the encoder layers of the well-trained\nASR model mostly capture the acoustic characteristics. We, therefore, propose\nto use the embeddings tapped from these encoder layers as features for a\ndownstream Conformer target-domain model and show that they provide significant\nimprovements. We do ablation studies on which encoder layer is optimal to tap\nthe embeddings, as well as the effect of freezing or updating the well-trained\nASR model's encoder layers. We further show that applying Spectral Augmentation\n(SpecAug) on the proposed features (this is in addition to default SpecAug on\ninput spectral features) provides a further improvement on the target-domain\nperformance. For the LibriSpeech-100-clean data as target-domain and SPGI-5000\nas a well-trained model, we get 30% relative improvement over baseline.\nSimilarly, with WSJ data as target-domain and LibriSpeech-960 as a well-trained\nmodel, we get 50% relative improvement over baseline.",
    "descriptor": "\nComments: 5 pages,2 figures\n",
    "authors": [
      "Vrunda N. Sukhadia",
      "S. Umesh"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2202.09167"
  },
  {
    "id": "arXiv:2202.09172",
    "title": "Enumeration of corner polyhedra and 3-connected Schnyder labelings",
    "abstract": "We show that corner polyhedra and 3-connected Schnyder labelings join the\ngrowing list of planar structures that can be set in exact correspondence with\n(weighted) models of quadrant walks via a bijection due to Kenyon, Miller,\nSheffield and Wilson.\nOur approach leads to a first polynomial time algorithm to count these\nstructures, and to the determination of their exact asymptotic growth\nconstants: the number $p_n$ of corner polyhedra and $s_n$ of 3-connected\nSchnyder woods of size $n$ respectively satisfy $(p_n)^{1/n}\\to 9/2$ and\n$(s_n)^{1/n}\\to 16/3$ as $n$ goes to infinity.\nWhile the growth rates are rational, like in the case of previously known\ninstances of such correspondences, the exponent of the asymptotic polynomial\ncorrection to the exponential growth does not appear to follow from the now\nstandard Denisov-Wachtel approach, due to a bimodal behavior of the step set of\nthe underlying tandem walk. However a heuristic argument suggests that these\nexponents are $-1-\\pi/\\arccos(9/16)\\approx -4.23$ for $p_n$ and\n$-1-\\pi/\\arccos(22/27)\\approx -6.08$ for $s_n$, which would imply that the\nassociated series are not D-finite.",
    "descriptor": "\nComments: 26 pages\n",
    "authors": [
      "\u00c9ric Fusy",
      "Erkan Narmanli",
      "Gilles Schaeffer"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2202.09172"
  },
  {
    "id": "arXiv:2202.09182",
    "title": "Churn modeling of life insurance policies via statistical and machine  learning methods -- Analysis of important features",
    "abstract": "Life assurance companies typically possess a wealth of data covering multiple\nsystems and databases. These data are often used for analyzing the past and for\ndescribing the present. Taking account of the past, the future is mostly\nforecasted by traditional statistical methods. So far, only a few attempts were\nundertaken to perform estimations by means of machine learning approaches. In\nthis work, the individual contract cancellation behavior of customers within\ntwo partial stocks is modeled by the aid of various classification methods.\nPartial stocks of private pension and endowment policy are considered. We\ndescribe the data used for the modeling, their structured and in which way they\nare cleansed. The utilized models are calibrated on the basis of an extensive\ntuning process, then graphically evaluated regarding their goodness-of-fit and\nwith the help of a variable relevance concept, we investigate which features\nnotably affect the individual contract cancellation behavior.",
    "descriptor": "",
    "authors": [
      "Andreas Groll",
      "Carsten Wasserfuhr",
      "Leonid Zeldin"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2202.09182"
  },
  {
    "id": "arXiv:2202.09188",
    "title": "Testing the boundaries: Normalizing Flows for higher dimensional data  sets",
    "abstract": "Normalizing Flows (NFs) are emerging as a powerful class of generative\nmodels, as they not only allow for efficient sampling, but also deliver, by\nconstruction, density estimation. They are of great potential usage in High\nEnergy Physics (HEP), where complex high dimensional data and probability\ndistributions are everyday's meal. However, in order to fully leverage the\npotential of NFs it is crucial to explore their robustness as data\ndimensionality increases. Thus, in this contribution, we discuss the\nperformances of some of the most popular types of NFs on the market, on some\ntoy data sets with increasing number of dimensions.",
    "descriptor": "\nComments: 6 pages, Proceedings of the 20th International Workshop on Advanced Computing and Analysis Techniques in Physics Research (ACAT 2021)\n",
    "authors": [
      "Humberto Reyes-Gonzalez",
      "Riccardo Torre"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "High Energy Physics - Phenomenology (hep-ph)"
    ],
    "url": "https://arxiv.org/abs/2202.09188"
  },
  {
    "id": "arXiv:2202.09191",
    "title": "Heroes in orientations of chordal graphs",
    "abstract": "We characterize all digraphs $H$ such that orientations of chordal graphs\nwith no induced copy of $H$ have bounded dichromatic number.",
    "descriptor": "",
    "authors": [
      "Pierre Aboulker",
      "Guillaume Aubian",
      "Raphael Steiner"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2202.09191"
  },
  {
    "id": "arXiv:2202.09194",
    "title": "Circuit Extraction for ZX-diagrams can be #P-hard",
    "abstract": "The ZX-calculus is a graphical language for reasoning about quantum\ncomputation using ZX-diagrams, a certain flexible generalisation of quantum\ncircuits that can be used to represent linear maps from $m$ to $n$ qubits for\nany $m,n \\geq 0$. Some applications for the ZX-calculus, such as quantum\ncircuit optimisation and synthesis, rely on being able to efficiently translate\na ZX-diagram back into a quantum circuit of comparable size. While several\nsufficient conditions are known for describing families of ZX-diagrams that can\nbe efficiently transformed back into circuits, it has previously been\nconjectured that the general problem of circuit extraction is hard. That is,\nthat it should not be possible to efficiently convert an arbitrary ZX-diagram\ndescribing a unitary linear map into an equivalent quantum circuit. In this\npaper we prove this conjecture by showing that the circuit extraction problem\nis #P-hard, and so is itself at least as hard as strong simulation of quantum\ncircuits. In addition to our main hardness result, which relies specifically on\nthe circuit representation, we give a representation-agnostic hardness result.\nNamely, we show that any oracle that takes as input a ZX-diagram description of\na unitary and produces samples of the output of the associated quantum\ncomputation enables efficient probabilistic solutions to NP-complete problems.",
    "descriptor": "\nComments: 15 pages + 3 page appendix\n",
    "authors": [
      "Niel de Beaudrap",
      "Aleks Kissinger",
      "John van de Wetering"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2202.09194"
  },
  {
    "id": "arXiv:2202.09233",
    "title": "Nonstationary multi-output Gaussian processes via harmonizable spectral  mixtures",
    "abstract": "Kernel design for Multi-output Gaussian Processes (MOGP) has received\nincreased attention recently. In particular, the Multi-Output Spectral Mixture\nkernel (MOSM) arXiv:1709.01298 approach has been praised as a general model in\nthe sense that it extends other approaches such as Linear Model of\nCorregionalization, Intrinsic Corregionalization Model and Cross-Spectral\nMixture. MOSM relies on Cram\\'er's theorem to parametrise the power spectral\ndensities (PSD) as a Gaussian mixture, thus, having a structural restriction:\nby assuming the existence of a PSD, the method is only suited for multi-output\nstationary applications. We develop a nonstationary extension of MOSM by\nproposing the family of harmonizable kernels for MOGPs, a class of kernels that\ncontains both stationary and a vast majority of non-stationary processes. A\nmain contribution of the proposed harmonizable kernels is that they\nautomatically identify a possible nonstationary behaviour meaning that\npractitioners do not need to choose between stationary or non-stationary\nkernels. The proposed method is first validated on synthetic data with the\npurpose of illustrating the key properties of our approach, and then compared\nto existing MOGP methods on two real-world settings from finance and\nelectroencephalography.",
    "descriptor": "\nComments: Accepted at AISTATS 2022\n",
    "authors": [
      "Mat\u00edas Altamirano",
      "Felipe Tobar"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.09233"
  },
  {
    "id": "arXiv:2202.09254",
    "title": "Cell-Free Massive MIMO in Virtualized CRAN: How to Minimize the Total  Network Power?",
    "abstract": "Previous works on cell-free massive MIMO mostly consider physical-layer and\nfronthaul transport aspects. How to deploy cell-free massive MIMO functionality\nin a practical wireless system is an open problem. This paper proposes a new\ncell-free architecture that can be implemented on top of a virtualized cloud\nradio access network (V-CRAN). We aim to minimize the end-to-end power\nconsumption by jointly considering the radio, optical fronthaul, virtualized\ncloud processing resources, and spectral efficiency requirements of the user\nequipments. The considered optimization problem is cast in a mixed binary\nsecond-order cone programming form and, thus, the global optimum can be found\nusing a branch-and-bound algorithm. The optimal power-efficient solution of our\nproposed cell-free system is compared with conventional small-cell implemented\nusing V-CRAN, to determine the benefits of cell-free networking. The numerical\nresults demonstrate that cell-free massive MIMO increases the maximum rate\nsubstantially, which can be provided with almost the same energy per bit. We\nshow that it is more power-efficient to activate cell-free massive MIMO already\nat low spectral efficiencies (above 1 bit/s/Hz).",
    "descriptor": "\nComments: Accepted to be presented in IEEE ICC 2022, 6 pages, 3 figures\n",
    "authors": [
      "\u00d6zlem Tu\u011ffe Demir",
      "Meysam Masoudi",
      "Emil Bj\u00f6rnson",
      "Cicek Cavdar"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.09254"
  },
  {
    "id": "arXiv:2202.09258",
    "title": "Autoencoding Low-Resolution MRI for Semantically Smooth Interpolation of  Anisotropic MRI",
    "abstract": "High-resolution medical images are beneficial for analysis but their\nacquisition may not always be feasible. Alternatively, high-resolution images\ncan be created from low-resolution acquisitions using conventional upsampling\nmethods, but such methods cannot exploit high-level contextual information\ncontained in the images. Recently, better performing deep-learning based\nsuper-resolution methods have been introduced. However, these methods are\nlimited by their supervised character, i.e. they require high-resolution\nexamples for training. Instead, we propose an unsupervised deep learning\nsemantic interpolation approach that synthesizes new intermediate slices from\nencoded low-resolution examples. To achieve semantically smooth interpolation\nin through-plane direction, the method exploits the latent space generated by\nautoencoders. To generate new intermediate slices, latent space encodings of\ntwo spatially adjacent slices are combined using their convex combination.\nSubsequently, the combined encoding is decoded to an intermediate slice. To\nconstrain the model, a notion of semantic similarity is defined for a given\ndataset. For this, a new loss is introduced that exploits the spatial\nrelationship between slices of the same volume. During training, an existing\nin-between slice is generated using a convex combination of its neighboring\nslice encodings. The method was trained and evaluated using publicly available\ncardiac cine, neonatal brain and adult brain MRI scans. In all evaluations, the\nnew method produces significantly better results in terms of Structural\nSimilarity Index Measure and Peak Signal-to-Noise Ratio (p< 0.001 using\none-sided Wilcoxon signed-rank test) than a cubic B-spline interpolation\napproach. Given the unsupervised nature of the method, high-resolution training\ndata is not required and hence, the method can be readily applied in clinical\nsettings.",
    "descriptor": "\nComments: Medical Image Analysis, 2022\n",
    "authors": [
      "J\u00f6rg Sander",
      "Bob D. de Vos",
      "Ivana I\u0161gum"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Medical Physics (physics.med-ph)"
    ],
    "url": "https://arxiv.org/abs/2202.09258"
  },
  {
    "id": "arXiv:2202.09266",
    "title": "Informativity conditions for data-driven control based on input-state  data and polyhedral cross-covariance noise bounds",
    "abstract": "Modeling and control of dynamical systems rely on measured data, which\ncontains information about the system. Finite data measurements typically lead\nto a set of system models that are unfalsified, i.e., that explain the data.\nThe problem of data-informativity for stabilization or control with quadratic\nperformance is concerned with the existence of a controller that stabilizes all\nunfalsified systems or achieves a desired quadratic performance. Recent results\nin the literature provide informativity conditions for control based on\ninput-state data and ellipsoidal noise bounds, such as energy or magnitude\nbounds. In this paper, we consider informativity of input-state data for\ncontrol where noise bounds are defined through the cross-covariance of the\nnoise with respect to an instrumental variable; bounds that were introduced\noriginally as a noise characterization in parameter bounding identification.\nThe considered cross-covariance bounds are defined by a finite number of\nhyperplanes, which induce a (possibly unbounded) polyhedral set of unfalsified\nsystems. We provide informativity conditions for input-state data with\npolyhedral cross-covariance bounds for stabilization and\n$\\mathcal{H}_2$/$\\mathcal{H}_\\infty$ control through vertex/half-space\nrepresentations of the polyhedral set of unfalsified systems.",
    "descriptor": "",
    "authors": [
      "Tom R. V. Steentjes",
      "Mircea Lazar",
      "Paul M. J. Van den Hof"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.09266"
  },
  {
    "id": "arXiv:2202.09289",
    "title": "Towards a Numerical Proof of Turbulence Closure",
    "abstract": "The development of turbulence closure models, parametrizing the influence of\nsmall non-resolved scales on the dynamics of large resolved ones, is an\noutstanding theoretical challenge with vast applicative relevance. We present a\nclosure, based on deep recurrent neural networks, that quantitatively\nreproduces, within statistical errors, Eulerian and Lagrangian structure\nfunctions and the intermittent statistics of the energy cascade, including\nthose of subgrid fluxes. To achieve high-order statistical accuracy, and thus a\nstringent statistical test, we employ shell models of turbulence. Our results\nencourage the development of similar approaches for 3D Navier-Stokes\nturbulence.",
    "descriptor": "",
    "authors": [
      "Giulio Ortali",
      "Alessandro Corbetta",
      "Gianluigi Rozza",
      "Federico Toschi"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Machine Learning (cs.LG)",
      "Chaotic Dynamics (nlin.CD)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2202.09289"
  },
  {
    "id": "arXiv:2202.09297",
    "title": "tinyMAN: Lightweight Energy Manager using Reinforcement Learning for  Energy Harvesting Wearable IoT Devices",
    "abstract": "Advances in low-power electronics and machine learning techniques lead to\nmany novel wearable IoT devices. These devices have limited battery capacity\nand computational power. Thus, energy harvesting from ambient sources is a\npromising solution to power these low-energy wearable devices. They need to\nmanage the harvested energy optimally to achieve energy-neutral operation,\nwhich eliminates recharging requirements. Optimal energy management is a\nchallenging task due to the dynamic nature of the harvested energy and the\nbattery energy constraints of the target device. To address this challenge, we\npresent a reinforcement learning-based energy management framework, tinyMAN,\nfor resource-constrained wearable IoT devices. The framework maximizes the\nutilization of the target device under dynamic energy harvesting patterns and\nbattery constraints. Moreover, tinyMAN does not rely on forecasts of the\nharvested energy which makes it a prediction-free approach. We deployed tinyMAN\non a wearable device prototype using TensorFlow Lite for Micro thanks to its\nsmall memory footprint of less than 100 KB. Our evaluations show that tinyMAN\nachieves less than 2.36 ms and 27.75 $\\mu$J while maintaining up to 45% higher\nutility compared to prior approaches.",
    "descriptor": "\nComments: 7 pages, 4 figures, accepted as \"Full Paper\" for the 2022 tinyML Research Symposium\n",
    "authors": [
      "Toygun Basaklar",
      "Yigit Tuncel",
      "Umit Y. Ogras"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.09297"
  },
  {
    "id": "arXiv:2202.09309",
    "title": "Dimension-Free Noninteractive Simulation from Gaussian Sources",
    "abstract": "Let $X$ and $Y$ be two real-valued random variables. Let\n$(X_{1},Y_{1}),(X_{2},Y_{2}),\\ldots$ be independent identically distributed\ncopies of $(X,Y)$. Suppose there are two players A and B. Player A has access\nto $X_{1},X_{2},\\ldots$ and player B has access to $Y_{1},Y_{2},\\ldots$.\nWithout communication, what joint probability distributions can players A and B\njointly simulate? That is, if $k,m$ are fixed positive integers, what\nprobability distributions on $\\{1,\\ldots,m\\}^{2}$ are equal to the distribution\nof $(f(X_{1},\\ldots,X_{k}),\\,g(Y_{1},\\ldots,Y_{k}))$ for some\n$f,g\\colon\\mathbb{R}^{k}\\to\\{1,\\ldots,m\\}$?\nWhen $X$ and $Y$ are standard Gaussians with fixed correlation\n$\\rho\\in(-1,1)$, we show that the set of probability distributions that can be\nnoninteractively simulated from $k$ Gaussian samples is the same for any $k\\geq\nm^{2}$. Previously, it was not even known if this number of samples $m^{2}$\nwould be finite or not, except when $m\\leq 2$.\nConsequently, a straightforward brute-force search deciding whether or not a\nprobability distribution on $\\{1,\\ldots,m\\}^{2}$ is within distance\n$0<\\epsilon<|\\rho|$ of being noninteractively simulated from $k$ correlated\nGaussian samples has run time bounded by $(5/\\epsilon)^{m(\\log(\\epsilon/2) /\n\\log|\\rho|)^{m^{2}}}$, improving a bound of Ghazi, Kamath and Raghavendra.\nA nonlinear central limit theorem (i.e. invariance principle) of Mossel then\ngeneralizes this result to decide whether or not a probability distribution on\n$\\{1,\\ldots,m\\}^{2}$ is within distance $0<\\epsilon<|\\rho|$ of being\nnoninteractively simulated from $k$ samples of a given finite discrete\ndistribution $(X,Y)$ in run time that does not depend on $k$, with constants\nthat again improve a bound of Ghazi, Kamath and Raghavendra.",
    "descriptor": "\nComments: 33 pages\n",
    "authors": [
      "Steven Heilman",
      "Alex Tarter"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Computational Complexity (cs.CC)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.09309"
  },
  {
    "id": "arXiv:2202.09353",
    "title": "Model Calibration of the Liquid Mercury Spallation Target using  Evolutionary Neural Networks and Sparse Polynomial Expansions",
    "abstract": "The mercury constitutive model predicting the strain and stress in the target\nvessel plays a central role in improving the lifetime prediction and future\ntarget designs of the mercury targets at the Spallation Neutron Source (SNS).\nWe leverage the experiment strain data collected over multiple years to improve\nthe mercury constitutive model through a combination of large-scale simulations\nof the target behavior and the use of machine learning tools for parameter\nestimation. We present two interdisciplinary approaches for surrogate-based\nmodel calibration of expensive simulations using evolutionary neural networks\nand sparse polynomial expansions. The experiments and results of the two\nmethods show a very good agreement for the solid mechanics simulation of the\nmercury spallation target. The proposed methods are used to calibrate the\ntensile cutoff threshold, mercury density, and mercury speed of sound during\nintense proton pulse experiments. Using strain experimental data from the\nmercury target sensors, the newly calibrated simulations achieve 7\\% average\nimprovement on the signal prediction accuracy and 8\\% reduction in mean\nabsolute error compared to previously reported reference parameters, with some\nsensors experiencing up to 30\\% improvement. The proposed calibrated\nsimulations can significantly aid in fatigue analysis to estimate the mercury\ntarget lifetime and integrity, which reduces abrupt target failure and saves a\ntremendous amount of costs. However, an important conclusion from this work\npoints out to a deficiency in the current constitutive model based on the\nequation of state in capturing the full physics of the spallation reaction.\nGiven that some of the calibrated parameters that show a good agreement with\nthe experimental data can be nonphysical mercury properties, we need a more\nadvanced two-phase flow model to capture bubble dynamics and mercury\ncavitation.",
    "descriptor": "\nComments: 26 pages, 10 figures, 6 tables\n",
    "authors": [
      "Majdi I. Radaideh",
      "Hoang Tran",
      "Lianshan Lin",
      "Hao Jiang",
      "Drew Winder",
      "Sarma Gorti",
      "Guannan Zhang",
      "Justin Mach",
      "Sarah Cousineau"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Machine Learning (cs.LG)",
      "Accelerator Physics (physics.acc-ph)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2202.09353"
  },
  {
    "id": "arXiv:2202.09359",
    "title": "Machine Learning Models in Stock Market Prediction",
    "abstract": "The paper focuses on predicting the Nifty 50 Index by using 8 Supervised\nMachine Learning Models. The techniques used for empirical study are Adaptive\nBoost (AdaBoost), k-Nearest Neighbors (kNN), Linear Regression (LR), Artificial\nNeural Network (ANN), Random Forest (RF), Stochastic Gradient Descent (SGD),\nSupport Vector Machine (SVM) and Decision Trees (DT). Experiments are based on\nhistorical data of Nifty 50 Index of Indian Stock Market from 22nd April, 1996\nto 16th April, 2021, which is time series data of around 25 years. During the\nperiod there were 6220 trading days excluding all the non trading days. The\nentire trading dataset was divided into 4 subsets of different size-25% of\nentire data, 50% of entire data, 75% of entire data and entire data. Each\nsubset was further divided into 2 parts-training data and testing data. After\napplying 3 tests- Test on Training Data, Test on Testing Data and Cross\nValidation Test on each subset, the prediction performance of the used models\nwere compared and after comparison, very interesting results were found. The\nevaluation results indicate that Adaptive Boost, k- Nearest Neighbors, Random\nForest and Decision Trees under performed with increase in the size of data\nset. Linear Regression and Artificial Neural Network shown almost similar\nprediction results among all the models but Artificial Neural Network took more\ntime in training and validating the model. Thereafter Support Vector Machine\nperformed better among rest of the models but with increase in the size of data\nset, Stochastic Gradient Descent performed better than Support Vector Machine.",
    "descriptor": "",
    "authors": [
      "Gurjeet Singh"
    ],
    "subjectives": [
      "Statistical Finance (q-fin.ST)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.09359"
  },
  {
    "id": "arXiv:1611.04175",
    "title": "Recognizing and Eliciting Weakly Single Crossing Profiles on Trees",
    "abstract": "Recognizing and Eliciting Weakly Single Crossing Profiles on Trees",
    "descriptor": "",
    "authors": [
      "Palash Dey"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Artificial Intelligence (cs.AI)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/1611.04175"
  },
  {
    "id": "arXiv:1708.06899",
    "title": "Human experts vs. machines in taxa recognition",
    "abstract": "Comments: 12 pages, 6 figures, 4 tables; link to the dataset fixed",
    "descriptor": "\nComments: 12 pages, 6 figures, 4 tables; link to the dataset fixed\n",
    "authors": [
      "Johanna \u00c4rje",
      "Jenni Raitoharju",
      "Alexandros Iosifidis",
      "Ville Tirronen",
      "Kristian Meissner",
      "Moncef Gabbouj",
      "Serkan Kiranyaz",
      "Salme K\u00e4rkk\u00e4inen"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/1708.06899"
  },
  {
    "id": "arXiv:1810.03772",
    "title": "The existence of perfect codes in Doob graphs",
    "abstract": "Comments: 5 IEEE pages. V.2: accepted version; the introduction has been extended by a mini-survey",
    "descriptor": "\nComments: 5 IEEE pages. V.2: accepted version; the introduction has been extended by a mini-survey\n",
    "authors": [
      "Denis S. Krotov"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/1810.03772"
  },
  {
    "id": "arXiv:1810.12138",
    "title": "Audio inpainting of music by means of neural networks",
    "abstract": "Comments: Presented at the 146th AES Convention [arXiv:1810.12138v2]. For the journal version, published in published in IEEE TASLP, see [arXiv:1810.12138v2]",
    "descriptor": "\nComments: Presented at the 146th AES Convention [arXiv:1810.12138v2]. For the journal version, published in published in IEEE TASLP, see [arXiv:1810.12138v2]\n",
    "authors": [
      "Andr\u00e9s Marafioti",
      "Nicki Holighaus",
      "Piotr Majdak",
      "Nathana\u00ebl Perraudin"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/1810.12138"
  },
  {
    "id": "arXiv:1908.06280",
    "title": "No-Reference Light Field Image Quality Assessment Based on  Spatial-Angular Measurement",
    "abstract": "Comments: Published on IEEE TCSVT",
    "descriptor": "\nComments: Published on IEEE TCSVT\n",
    "authors": [
      "Likun Shi",
      "Wei Zhou",
      "Zhibo Chen",
      "Jinglin Zhang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computational Geometry (cs.CG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/1908.06280"
  },
  {
    "id": "arXiv:1908.09520",
    "title": "NETR-Tree: An Eifficient Framework for Social-Based Time-Aware Spatial  Keyword Query",
    "abstract": "NETR-Tree: An Eifficient Framework for Social-Based Time-Aware Spatial  Keyword Query",
    "descriptor": "",
    "authors": [
      "Xiuqi Huang",
      "Yuanning Gao",
      "Xiaofeng Gao",
      "Guihai Chen"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/1908.09520"
  },
  {
    "id": "arXiv:1909.02358",
    "title": "Tensor Oriented No-Reference Light Field Image Quality Assessment",
    "abstract": "Comments: Published on IEEE TIP",
    "descriptor": "\nComments: Published on IEEE TIP\n",
    "authors": [
      "Wei Zhou",
      "Likun Shi",
      "Zhibo Chen",
      "Jinglin Zhang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/1909.02358"
  },
  {
    "id": "arXiv:1911.03069",
    "title": "Towards local testability for quantum coding",
    "abstract": "Comments: 44 pages, an extended abstract appeared at ITCS 2021 v2: journal version",
    "descriptor": "\nComments: 44 pages, an extended abstract appeared at ITCS 2021 v2: journal version\n",
    "authors": [
      "Anthony Leverrier",
      "Vivien Londe",
      "Gilles Z\u00e9mor"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Information Theory (cs.IT)",
      "Geometric Topology (math.GT)"
    ],
    "url": "https://arxiv.org/abs/1911.03069"
  },
  {
    "id": "arXiv:1912.09893",
    "title": "A Fair Comparison of Graph Neural Networks for Graph Classification",
    "abstract": "Comments: Extended version of the paper published at the International Conference on Learning Representations (ICLR), 2020. Additional results are shown in the appendix",
    "descriptor": "\nComments: Extended version of the paper published at the International Conference on Learning Representations (ICLR), 2020. Additional results are shown in the appendix\n",
    "authors": [
      "Federico Errica",
      "Marco Podda",
      "Davide Bacciu",
      "Alessio Micheli"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1912.09893"
  },
  {
    "id": "arXiv:1912.12871",
    "title": "Text Steganalysis with Attentional LSTM-CNN",
    "abstract": "Comments: error content",
    "descriptor": "\nComments: error content\n",
    "authors": [
      "YongJian Bao",
      "Hao Yang",
      "Zhongliang Yang",
      "Sheng Liu",
      "Yongfeng Huang"
    ],
    "subjectives": [
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/1912.12871"
  },
  {
    "id": "arXiv:2001.05297",
    "title": "Dialectal Layers in West Iranian: a Hierarchical Dirichlet Process  Approach to Linguistic Relationships",
    "abstract": "Comments: 28 pp",
    "descriptor": "\nComments: 28 pp\n",
    "authors": [
      "Chundra Aroor Cathcart"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2001.05297"
  },
  {
    "id": "arXiv:2003.01491",
    "title": "A Cubical Language for Bishop Sets",
    "abstract": "Comments: Final version to be published in Logical Methods in Computer Science, special issue for FSCD'19",
    "descriptor": "\nComments: Final version to be published in Logical Methods in Computer Science, special issue for FSCD'19\n",
    "authors": [
      "Jonathan Sterling",
      "Carlo Angiuli",
      "Daniel Gratzer"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Logic (math.LO)"
    ],
    "url": "https://arxiv.org/abs/2003.01491"
  },
  {
    "id": "arXiv:2003.09224",
    "title": "Probabilistic Visual Navigation with Bidirectional Image Prediction",
    "abstract": "Comments: 14 pages, 9 figures, 4 tables",
    "descriptor": "\nComments: 14 pages, 9 figures, 4 tables\n",
    "authors": [
      "Noriaki Hirose",
      "Shun Taguchi",
      "Fei Xia",
      "Roberto Martin-Martin",
      "Kosuke Tahara",
      "Masanori Ishigaki",
      "Silvio Savarese"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2003.09224"
  },
  {
    "id": "arXiv:2004.10971",
    "title": "MemTorch: An Open-source Simulation Framework for Memristive Deep  Learning Systems",
    "abstract": "Comments: Accepted for Publication in Neurocomputing",
    "descriptor": "\nComments: Accepted for Publication in Neurocomputing\n",
    "authors": [
      "Corey Lammie",
      "Wei Xiang",
      "Bernab\u00e9 Linares-Barranco",
      "Mostafa Rahimi Azghadi"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2004.10971"
  },
  {
    "id": "arXiv:2006.10325",
    "title": "When OT meets MoM: Robust estimation of Wasserstein Distance",
    "abstract": "When OT meets MoM: Robust estimation of Wasserstein Distance",
    "descriptor": "",
    "authors": [
      "Guillaume Staerman",
      "Pierre Laforgue",
      "Pavlo Mozharovskyi",
      "Florence d'Alch\u00e9-Buc"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2006.10325"
  },
  {
    "id": "arXiv:2007.08031",
    "title": "Optimal Coreset for Gaussian Kernel Density Estimation",
    "abstract": "Optimal Coreset for Gaussian Kernel Density Estimation",
    "descriptor": "",
    "authors": [
      "Wai Ming Tai"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Geometry (cs.CG)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2007.08031"
  },
  {
    "id": "arXiv:2007.13819",
    "title": "Multi-Level Local SGD for Heterogeneous Hierarchical Networks",
    "abstract": "Comments: 36 pages, 10 figures, ICLR 2021",
    "descriptor": "\nComments: 36 pages, 10 figures, ICLR 2021\n",
    "authors": [
      "Timothy Castiglia",
      "Anirban Das",
      "Stacy Patterson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2007.13819"
  },
  {
    "id": "arXiv:2009.06301",
    "title": "Feedback Prediction for Proactive HARQ in the Context of Industrial  Internet of Things",
    "abstract": "Feedback Prediction for Proactive HARQ in the Context of Industrial  Internet of Things",
    "descriptor": "",
    "authors": [
      "Baris G\u00f6ktepe",
      "Tatiana Rykova",
      "Thomas Fehrenbach",
      "Thomas Schierl",
      "Cornelius Hellge"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2009.06301"
  },
  {
    "id": "arXiv:2009.09876",
    "title": "MAC address anonymization for crowd counting",
    "abstract": "MAC address anonymization for crowd counting",
    "descriptor": "",
    "authors": [
      "Jean-Fran\u00e7ois Determe",
      "Sophia Azzagnuni",
      "Utkarsh Singh",
      "Fran\u00e7ois Horlin",
      "Philippe De Doncker"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2009.09876"
  },
  {
    "id": "arXiv:2010.04524",
    "title": "Multi-Objective Optimisation of Multi-Output Neural Trees",
    "abstract": "Comments: 19-24 July 2020",
    "descriptor": "\nComments: 19-24 July 2020\n",
    "authors": [
      "Varun Ojha",
      "Giuseppe Nicosia"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2010.04524"
  },
  {
    "id": "arXiv:2010.07426",
    "title": "A Theoretical Perspective on Hyperdimensional Computing",
    "abstract": "Comments: Updates with published version",
    "descriptor": "\nComments: Updates with published version\n",
    "authors": [
      "Anthony Thomas",
      "Sanjoy Dasgupta",
      "Tajana Rosing"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2010.07426"
  },
  {
    "id": "arXiv:2010.10370",
    "title": "Monitoring Large Crowds With WiFi: A Privacy-Preserving Approach",
    "abstract": "Monitoring Large Crowds With WiFi: A Privacy-Preserving Approach",
    "descriptor": "",
    "authors": [
      "Jean-Fran\u00e7ois Determe",
      "Sophia Azzagnuni",
      "Utkarsh Singh",
      "Fran\u00e7ois Horlin",
      "Philippe De Doncker"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Hardware Architecture (cs.AR)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2010.10370"
  },
  {
    "id": "arXiv:2010.11887",
    "title": "Conditional independence by typing",
    "abstract": "Conditional independence by typing",
    "descriptor": "",
    "authors": [
      "Maria I. Gorinova",
      "Andrew D. Gordon",
      "Charles Sutton",
      "Matthijs V\u00e1k\u00e1r"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2010.11887"
  },
  {
    "id": "arXiv:2010.12066",
    "title": "Learning Patterns in Imaginary Vowels for an Intelligent Brain Computer  Interface (BCI) Design",
    "abstract": "Learning Patterns in Imaginary Vowels for an Intelligent Brain Computer  Interface (BCI) Design",
    "descriptor": "",
    "authors": [
      "Parisa Ghane",
      "Gahangir Hossain"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Human-Computer Interaction (cs.HC)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2010.12066"
  },
  {
    "id": "arXiv:2010.14162",
    "title": "Time domain boundary integral equations and convolution quadrature for  scattering by composite media (extended preprint)",
    "abstract": "Time domain boundary integral equations and convolution quadrature for  scattering by composite media (extended preprint)",
    "descriptor": "",
    "authors": [
      "Alexander Rieder",
      "Francisco-Javier Sayas",
      "Jens Markus Melenk"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2010.14162"
  },
  {
    "id": "arXiv:2010.15490",
    "title": "Linearizing Combinators",
    "abstract": "Comments: Final version. This paper has been accepted and will be published in Theory and Applications of Categories",
    "descriptor": "\nComments: Final version. This paper has been accepted and will be published in Theory and Applications of Categories\n",
    "authors": [
      "Robin Cockett",
      "Jean-Simon Pacaud Lemay"
    ],
    "subjectives": [
      "Category Theory (math.CT)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2010.15490"
  },
  {
    "id": "arXiv:2011.13681",
    "title": "Point and Ask: Incorporating Pointing into Visual Question Answering",
    "abstract": "Point and Ask: Incorporating Pointing into Visual Question Answering",
    "descriptor": "",
    "authors": [
      "Arjun Mani",
      "Nobline Yoo",
      "Will Hinthorn",
      "Olga Russakovsky"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2011.13681"
  },
  {
    "id": "arXiv:2012.06027",
    "title": "Comparison of Update and Genetic Training Algorithms in a Memristor  Crossbar Perceptron",
    "abstract": "Comparison of Update and Genetic Training Algorithms in a Memristor  Crossbar Perceptron",
    "descriptor": "",
    "authors": [
      "Kyle N. Edwards",
      "Xiao Shen"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2012.06027"
  },
  {
    "id": "arXiv:2012.06530",
    "title": "Modules over monads and operational semantics (expanded version)",
    "abstract": "Modules over monads and operational semantics (expanded version)",
    "descriptor": "",
    "authors": [
      "Andr\u00e9 Hirschowitz",
      "Tom Hirschowitz",
      "Ambroise Lafont"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Logic in Computer Science (cs.LO)",
      "Category Theory (math.CT)"
    ],
    "url": "https://arxiv.org/abs/2012.06530"
  },
  {
    "id": "arXiv:2012.07451",
    "title": "QoS Aware Robot Trajectory Optimization with IRS-Assisted  Millimeter-Wave Communications",
    "abstract": "Comments: arXiv admin note: substantial text overlap with arXiv:2010.14653",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2010.14653\n",
    "authors": [
      "Cristian Tatino",
      "Nikolaos Pappas",
      "Di Yuan"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2012.07451"
  },
  {
    "id": "arXiv:2101.00172",
    "title": "Chunk List: Concurrent Data Structures",
    "abstract": "Comments: 20 pages, 3 figures A full implementation can be found at this https URL Update: Revised format to align closer to IEEE standards",
    "descriptor": "\nComments: 20 pages, 3 figures A full implementation can be found at this https URL Update: Revised format to align closer to IEEE standards\n",
    "authors": [
      "Daniel Szelogowski"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Databases (cs.DB)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2101.00172"
  },
  {
    "id": "arXiv:2101.03603",
    "title": "Target Detection and Segmentation in Circular-Scan  Synthetic-Aperture-Sonar Images using Semi-Supervised Convolutional  Encoder-Decoders",
    "abstract": "Comments: Submitted to IEEE Journal of Oceanic Engineering",
    "descriptor": "\nComments: Submitted to IEEE Journal of Oceanic Engineering\n",
    "authors": [
      "Isaac J. Sledge",
      "Matthew S. Emigh",
      "Jonathan L. King",
      "Denton L. Woods",
      "J. Tory Cobb",
      "Jose C. Principe"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2101.03603"
  },
  {
    "id": "arXiv:2101.08551",
    "title": "Customer Price Sensitivities in Competitive Automobile Insurance Markets",
    "abstract": "Customer Price Sensitivities in Competitive Automobile Insurance Markets",
    "descriptor": "",
    "authors": [
      "Robert Matthijs Verschuren"
    ],
    "subjectives": [
      "Applications (stat.AP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2101.08551"
  },
  {
    "id": "arXiv:2102.13624",
    "title": "What Doesn't Kill You Makes You Robust(er): How to Adversarially Train  against Data Poisoning",
    "abstract": "Comments: 25 pages, 15 figures",
    "descriptor": "\nComments: 25 pages, 15 figures\n",
    "authors": [
      "Jonas Geiping",
      "Liam Fowl",
      "Gowthami Somepalli",
      "Micah Goldblum",
      "Michael Moeller",
      "Tom Goldstein"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2102.13624"
  },
  {
    "id": "arXiv:2103.00111",
    "title": "Graph Self-Supervised Learning: A Survey",
    "abstract": "Comments: 26 pages, 9 figures, 9 tables",
    "descriptor": "\nComments: 26 pages, 9 figures, 9 tables\n",
    "authors": [
      "Yixin Liu",
      "Ming Jin",
      "Shirui Pan",
      "Chuan Zhou",
      "Yu Zheng",
      "Feng Xia",
      "Philip S. Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.00111"
  },
  {
    "id": "arXiv:2103.00778",
    "title": "Explaining Adversarial Vulnerability with a Data Sparsity Hypothesis",
    "abstract": "Explaining Adversarial Vulnerability with a Data Sparsity Hypothesis",
    "descriptor": "",
    "authors": [
      "Mahsa Paknezhad",
      "Cuong Phuc Ngo",
      "Amadeus Aristo Winarto",
      "Alistair Cheong",
      "Chuen Yang Beh",
      "Jiayang Wu",
      "Hwee Kuan Lee"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2103.00778"
  },
  {
    "id": "arXiv:2103.08813",
    "title": "Multi-objective minimum time optimal control for low-thrust trajectory  design",
    "abstract": "Comments: Extended version of the paper published in 2021 European Control Conference (ECC), 9 pages, 2 figures",
    "descriptor": "\nComments: Extended version of the paper published in 2021 European Control Conference (ECC), 9 pages, 2 figures\n",
    "authors": [
      "Nikolaus Vertovec",
      "Sina Ober-Bl\u00f6baum",
      "Kostas Margellos"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2103.08813"
  },
  {
    "id": "arXiv:2103.12992",
    "title": "Non-Compression Auto-Encoder for Detecting Road Surface Abnormality via  Vehicle Driving Noise",
    "abstract": "Comments: 3 pages",
    "descriptor": "\nComments: 3 pages\n",
    "authors": [
      "YeongHyeon Park",
      "JongHee Jung"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.12992"
  },
  {
    "id": "arXiv:2103.16009",
    "title": "Revisiting Local Descriptor for Improved Few-Shot Classification",
    "abstract": "Comments: 23 pages, 7 figures, 7 tables",
    "descriptor": "\nComments: 23 pages, 7 figures, 7 tables\n",
    "authors": [
      "Jun He",
      "Richang Hong",
      "Xueliang Liu",
      "Mingliang Xu",
      "Qianru Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.16009"
  },
  {
    "id": "arXiv:2103.17203",
    "title": "Universal Prediction Band via Semi-Definite Programming",
    "abstract": "Comments: 21 pages, 4 figures",
    "descriptor": "\nComments: 21 pages, 4 figures\n",
    "authors": [
      "Tengyuan Liang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Econometrics (econ.EM)",
      "Optimization and Control (math.OC)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2103.17203"
  },
  {
    "id": "arXiv:2104.08376",
    "title": "Concadia: Tackling Image Accessibility with Descriptive Texts and  Context",
    "abstract": "Concadia: Tackling Image Accessibility with Descriptive Texts and  Context",
    "descriptor": "",
    "authors": [
      "Elisa Kreiss",
      "Noah D. Goodman",
      "Christopher Potts"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2104.08376"
  },
  {
    "id": "arXiv:2104.09124",
    "title": "DisCo: Remedy Self-supervised Learning on Lightweight Models with  Distilled Contrastive Learning",
    "abstract": "DisCo: Remedy Self-supervised Learning on Lightweight Models with  Distilled Contrastive Learning",
    "descriptor": "",
    "authors": [
      "Yuting Gao",
      "Jia-Xin Zhuang",
      "Shaohui Lin",
      "Hao Cheng",
      "Xing Sun",
      "Ke Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2104.09124"
  },
  {
    "id": "arXiv:2104.14756",
    "title": "Predicting Intraoperative Hypoxemia with Joint Sequence Autoencoder  Networks",
    "abstract": "Predicting Intraoperative Hypoxemia with Joint Sequence Autoencoder  Networks",
    "descriptor": "",
    "authors": [
      "Hanyang Liu",
      "Michael Montana",
      "Dingwen Li",
      "Thomas Kannampallil",
      "Chenyang Lu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.14756"
  },
  {
    "id": "arXiv:2104.14912",
    "title": "Nearest-Neighbor-based Collision Avoidance for Quadrotors via  Reinforcement Learning",
    "abstract": "Comments: Accepted to the 39th IEEE Conference on Robotics and Automation (ICRA). Fixed some typos",
    "descriptor": "\nComments: Accepted to the 39th IEEE Conference on Robotics and Automation (ICRA). Fixed some typos\n",
    "authors": [
      "Ramzi Ourari",
      "Kai Cui",
      "Ahmed Elshamanhory",
      "Heinz Koeppl"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.14912"
  },
  {
    "id": "arXiv:2105.03966",
    "title": "Unit Ball Model for Embedding Hierarchical Structures in the Complex  Hyperbolic Space",
    "abstract": "Unit Ball Model for Embedding Hierarchical Structures in the Complex  Hyperbolic Space",
    "descriptor": "",
    "authors": [
      "Huiru Xiao",
      "Caigao Jiang",
      "Yangqiu Song",
      "James Zhang",
      "Junwu Xiong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.03966"
  },
  {
    "id": "arXiv:2105.04123",
    "title": "Neural Program Repair with Execution-based Backpropagation",
    "abstract": "Neural Program Repair with Execution-based Backpropagation",
    "descriptor": "",
    "authors": [
      "He Ye",
      "Matias Martinez",
      "Martin Monperrus"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2105.04123"
  },
  {
    "id": "arXiv:2105.04319",
    "title": "A Bregman Learning Framework for Sparse Neural Networks",
    "abstract": "Comments: 43 pages, 5 figures, some minor modifications, weakened assumptions",
    "descriptor": "\nComments: 43 pages, 5 figures, some minor modifications, weakened assumptions\n",
    "authors": [
      "Leon Bungert",
      "Tim Roith",
      "Daniel Tenbrinck",
      "Martin Burger"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2105.04319"
  },
  {
    "id": "arXiv:2105.10433",
    "title": "When is Assortment Optimization Optimal?",
    "abstract": "When is Assortment Optimization Optimal?",
    "descriptor": "",
    "authors": [
      "Will Ma"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2105.10433"
  },
  {
    "id": "arXiv:2105.12125",
    "title": "An explicit algorithm for normal forms in small overlap monoids",
    "abstract": "Comments: 21 pages, 1 figure (a significant amount of detail was added to the proof of correctness of the normal form algorithm)",
    "descriptor": "\nComments: 21 pages, 1 figure (a significant amount of detail was added to the proof of correctness of the normal form algorithm)\n",
    "authors": [
      "James D. Mitchell",
      "Maria Tsalakou"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Data Structures and Algorithms (cs.DS)",
      "Rings and Algebras (math.RA)"
    ],
    "url": "https://arxiv.org/abs/2105.12125"
  },
  {
    "id": "arXiv:2105.13455",
    "title": "Perfect Matchings in the Semi-random Graph Process",
    "abstract": "Comments: Minor corrections made. Accepted to SIAM Journal on Discrete Mathematics (SIDMA)",
    "descriptor": "\nComments: Minor corrections made. Accepted to SIAM Journal on Discrete Mathematics (SIDMA)\n",
    "authors": [
      "Pu Gao",
      "Calum MacRury",
      "Pawel Pralat"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2105.13455"
  },
  {
    "id": "arXiv:2106.02398",
    "title": "Strategyproof Learning: Building Trustworthy User-Generated Datasets",
    "abstract": "Comments: 31 pages",
    "descriptor": "\nComments: 31 pages\n",
    "authors": [
      "Sadegh Farhadkhani",
      "Rachid Guerraoui",
      "L\u00ea-Nguy\u00ean Hoang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.02398"
  },
  {
    "id": "arXiv:2106.03403",
    "title": "Network Inference and Influence Maximization from Samples",
    "abstract": "Comments: Parellel results about the LT model are added to the conference (ICML 2021) version",
    "descriptor": "\nComments: Parellel results about the LT model are added to the conference (ICML 2021) version\n",
    "authors": [
      "Zhijie Zhang",
      "Wei Chen",
      "Xiaoming Sun",
      "Jialin Zhang"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.03403"
  },
  {
    "id": "arXiv:2106.03480",
    "title": "A Distance Covariance-based Kernel for Nonlinear Causal Clustering in  Heterogeneous Populations",
    "abstract": "Comments: 17 pages, 3 figures; accepted to 1st Conference on Causal Learning and Reasoning (CLeaR 2022)",
    "descriptor": "\nComments: 17 pages, 3 figures; accepted to 1st Conference on Causal Learning and Reasoning (CLeaR 2022)\n",
    "authors": [
      "Alex Markham",
      "Richeek Das",
      "Moritz Grosse-Wentrup"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.03480"
  },
  {
    "id": "arXiv:2106.06345",
    "title": "Proximal Optimal Transport Modeling of Population Dynamics",
    "abstract": "Proximal Optimal Transport Modeling of Population Dynamics",
    "descriptor": "",
    "authors": [
      "Charlotte Bunne",
      "Laetitia Meng-Papaxanthos",
      "Andreas Krause",
      "Marco Cuturi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.06345"
  },
  {
    "id": "arXiv:2106.13082",
    "title": "On the relationship between predictive coding and backpropagation",
    "abstract": "On the relationship between predictive coding and backpropagation",
    "descriptor": "",
    "authors": [
      "Robert Rosenbaum"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2106.13082"
  },
  {
    "id": "arXiv:2106.13996",
    "title": "Optimization of a Moving Sensor Trajectory for Observing a Point Scalar  Source in Turbulent Flow",
    "abstract": "Optimization of a Moving Sensor Trajectory for Observing a Point Scalar  Source in Turbulent Flow",
    "descriptor": "",
    "authors": [
      "Constantinos F. Panagiotou",
      "Davide Cerizza",
      "Tamer A. Zaki",
      "Yosuke Hasegawa"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2106.13996"
  },
  {
    "id": "arXiv:2106.16239",
    "title": "Fixed points of nonnegative neural networks",
    "abstract": "Comments: 13 pages",
    "descriptor": "\nComments: 13 pages\n",
    "authors": [
      "Tomasz Piotrowski",
      "Renato L. G. Cavalcante"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.16239"
  },
  {
    "id": "arXiv:2107.00630",
    "title": "Variational Diffusion Models",
    "abstract": "Comments: Published at NeurIPS'21. Camera-ready version",
    "descriptor": "\nComments: Published at NeurIPS'21. Camera-ready version\n",
    "authors": [
      "Diederik P. Kingma",
      "Tim Salimans",
      "Ben Poole",
      "Jonathan Ho"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.00630"
  },
  {
    "id": "arXiv:2107.04755",
    "title": "Beyond Low-pass Filtering: Graph Convolutional Networks with Automatic  Filtering",
    "abstract": "Comments: 12 pages",
    "descriptor": "\nComments: 12 pages\n",
    "authors": [
      "Zonghan Wu",
      "Shirui Pan",
      "Guodong Long",
      "Jing Jiang",
      "Chengqi Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.04755"
  },
  {
    "id": "arXiv:2107.09507",
    "title": "EEG-based Cross-Subject Driver Drowsiness Recognition with an  Interpretable Convolutional Neural Network",
    "abstract": "EEG-based Cross-Subject Driver Drowsiness Recognition with an  Interpretable Convolutional Neural Network",
    "descriptor": "",
    "authors": [
      "Jian Cui",
      "Zirui Lan",
      "Olga Sourina",
      "Wolfgang M\u00fcller-Wittig"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2107.09507"
  },
  {
    "id": "arXiv:2107.09899",
    "title": "Structure-Aware Long Short-Term Memory Network for 3D Cephalometric  Landmark Detection",
    "abstract": "Comments: IEEE Transactions on medical images",
    "descriptor": "\nComments: IEEE Transactions on medical images\n",
    "authors": [
      "Runnan Chen",
      "Yuexin Ma",
      "Nenglun Chen",
      "Lingjie Liu",
      "Zhiming Cui",
      "Yanhong Lin",
      "Wenping Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.09899"
  },
  {
    "id": "arXiv:2107.10137",
    "title": "Improved Text Classification via Contrastive Adversarial Training",
    "abstract": "Improved Text Classification via Contrastive Adversarial Training",
    "descriptor": "",
    "authors": [
      "Lin Pan",
      "Chung-Wei Hang",
      "Avirup Sil",
      "Saloni Potdar"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2107.10137"
  },
  {
    "id": "arXiv:2107.13094",
    "title": "Discrete Lehmann representation of imaginary time Green's functions",
    "abstract": "Discrete Lehmann representation of imaginary time Green's functions",
    "descriptor": "",
    "authors": [
      "Jason Kaye",
      "Kun Chen",
      "Olivier Parcollet"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Strongly Correlated Electrons (cond-mat.str-el)"
    ],
    "url": "https://arxiv.org/abs/2107.13094"
  },
  {
    "id": "arXiv:2108.02092",
    "title": "Online Knowledge Distillation for Efficient Pose Estimation",
    "abstract": "Comments: ICCV 2021",
    "descriptor": "\nComments: ICCV 2021\n",
    "authors": [
      "Zheng Li",
      "Jingwen Ye",
      "Mingli Song",
      "Ying Huang",
      "Zhigeng Pan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.02092"
  },
  {
    "id": "arXiv:2108.07313",
    "title": "Federated Asymptotics: a model to compare federated learning algorithms",
    "abstract": "Comments: 42 pages (11 main pages, 2 reference pages, 29 appendix pages), 13 figures",
    "descriptor": "\nComments: 42 pages (11 main pages, 2 reference pages, 29 appendix pages), 13 figures\n",
    "authors": [
      "Gary Cheng",
      "Karan Chadha",
      "John Duchi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2108.07313"
  },
  {
    "id": "arXiv:2108.10252",
    "title": "Federated Multi-Task Learning under a Mixture of Distributions",
    "abstract": "Comments: 77 pages, NeurIPS 2021",
    "descriptor": "\nComments: 77 pages, NeurIPS 2021\n",
    "authors": [
      "Othmane Marfoq",
      "Giovanni Neglia",
      "Aur\u00e9lien Bellet",
      "Laetitia Kameni",
      "Richard Vidal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2108.10252"
  },
  {
    "id": "arXiv:2108.13952",
    "title": "Morphence: Moving Target Defense Against Adversarial Examples",
    "abstract": "Morphence: Moving Target Defense Against Adversarial Examples",
    "descriptor": "",
    "authors": [
      "Abderrahmen Amich",
      "Birhanu Eshete"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2108.13952"
  },
  {
    "id": "arXiv:2109.00727",
    "title": "Some Inapproximability Results of MAP Inference and Exponentiated  Determinantal Point Processes",
    "abstract": "Comments: 28 pages. This is an extended version of our conference paper presented at AISTATS 2021. Has been accepted for Journal of Artificial Intelligence Research",
    "descriptor": "\nComments: 28 pages. This is an extended version of our conference paper presented at AISTATS 2021. Has been accepted for Journal of Artificial Intelligence Research\n",
    "authors": [
      "Naoto Ohsaka"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.00727"
  },
  {
    "id": "arXiv:2109.03537",
    "title": "On the Transferability of Pre-trained Language Models: A Study from  Artificial Datasets",
    "abstract": "Comments: AAAI 2022 main conference paper. 10 pages, 3 figures, 2 tables",
    "descriptor": "\nComments: AAAI 2022 main conference paper. 10 pages, 3 figures, 2 tables\n",
    "authors": [
      "Cheng-Han Chiang",
      "Hung-yi Lee"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.03537"
  },
  {
    "id": "arXiv:2109.04261",
    "title": "Learning cortical representations through perturbed and adversarial  dreaming",
    "abstract": "Comments: 35 pages, 15 figures; ; Jakob Jordan and Walter Senn share senior authorship",
    "descriptor": "\nComments: 35 pages, 15 figures; ; Jakob Jordan and Walter Senn share senior authorship\n",
    "authors": [
      "Nicolas Deperrois",
      "Mihai A. Petrovici",
      "Walter Senn",
      "Jakob Jordan"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.04261"
  },
  {
    "id": "arXiv:2109.04833",
    "title": "Multimodal Federated Learning on IoT Data",
    "abstract": "Comments: 12 pages, IoTDI '22, May 3-6, 2022, Milan, Italy",
    "descriptor": "\nComments: 12 pages, IoTDI '22, May 3-6, 2022, Milan, Italy\n",
    "authors": [
      "Yuchen Zhao",
      "Payam Barnaghi",
      "Hamed Haddadi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.04833"
  },
  {
    "id": "arXiv:2109.05489",
    "title": "Illuminating Diverse Neural Cellular Automata for Level Generation",
    "abstract": "Comments: 9 pages, 7 figures",
    "descriptor": "\nComments: 9 pages, 7 figures\n",
    "authors": [
      "Sam Earle",
      "Justin Snider",
      "Matthew C. Fontaine",
      "Stefanos Nikolaidis",
      "Julian Togelius"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.05489"
  },
  {
    "id": "arXiv:2109.06949",
    "title": "Targeted Cross-Validation",
    "abstract": "Targeted Cross-Validation",
    "descriptor": "",
    "authors": [
      "Jiawei Zhang",
      "Jie Ding",
      "Yuhong Yang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.06949"
  },
  {
    "id": "arXiv:2109.10048",
    "title": "Computational Complexity of Quadratic Unconstrained Binary Optimization",
    "abstract": "Computational Complexity of Quadratic Unconstrained Binary Optimization",
    "descriptor": "",
    "authors": [
      "Hirotoshi Yasuoka"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2109.10048"
  },
  {
    "id": "arXiv:2109.14478",
    "title": "Quadratic-Curve-Lifted Reed-Solomon Codes",
    "abstract": "Comments: 16 pages, 2 figures. A short version is accepted by WCC 2022 (12th International Workshop on Coding and Cryptography)",
    "descriptor": "\nComments: 16 pages, 2 figures. A short version is accepted by WCC 2022 (12th International Workshop on Coding and Cryptography)\n",
    "authors": [
      "Hedongliang Liu",
      "Lukas Holzbaur",
      "Nikita Polyanskii",
      "Sven Puchinger",
      "Antonia Wachter-Zeh"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Algebraic Geometry (math.AG)"
    ],
    "url": "https://arxiv.org/abs/2109.14478"
  },
  {
    "id": "arXiv:2110.00307",
    "title": "The case for the Humanities Citation Index (HuCI): a citation index by  the humanities, for the humanities",
    "abstract": "The case for the Humanities Citation Index (HuCI): a citation index by  the humanities, for the humanities",
    "descriptor": "",
    "authors": [
      "Giovanni Colavizza",
      "Silvio Peroni",
      "Matteo Romanello"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2110.00307"
  },
  {
    "id": "arXiv:2110.01742",
    "title": "Focal Onset Detection Using Parallel Genetic Naive Bayes Classifiers",
    "abstract": "Comments: 6 pages, 3 figures",
    "descriptor": "\nComments: 6 pages, 3 figures\n",
    "authors": [
      "Scot Davidson",
      "Niamh McCallan",
      "Kok Yew Ng",
      "Pardis Biglarbeigi",
      "Dewar Finlay",
      "Boon Leong Lan",
      "James McLaughlin"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2110.01742"
  },
  {
    "id": "arXiv:2110.02578",
    "title": "Decoupled Adaptation for Cross-Domain Object Detection",
    "abstract": "Decoupled Adaptation for Cross-Domain Object Detection",
    "descriptor": "",
    "authors": [
      "Junguang Jiang",
      "Baixu Chen",
      "Jianmin Wang",
      "Mingsheng Long"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.02578"
  },
  {
    "id": "arXiv:2110.02998",
    "title": "Federated Learning via Plurality Vote",
    "abstract": "Federated Learning via Plurality Vote",
    "descriptor": "",
    "authors": [
      "Kai Yue",
      "Richeng Jin",
      "Chau-Wai Wong",
      "Huaiyu Dai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.02998"
  },
  {
    "id": "arXiv:2110.04186",
    "title": "Medical Dead-ends and Learning to Identify High-risk States and  Treatments",
    "abstract": "Medical Dead-ends and Learning to Identify High-risk States and  Treatments",
    "descriptor": "",
    "authors": [
      "Mehdi Fatemi",
      "Taylor W. Killian",
      "Jayakumar Subramanian",
      "Marzyeh Ghassemi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.04186"
  },
  {
    "id": "arXiv:2110.04385",
    "title": "Individualized Hear-through For Acoustic Transparency Using PCA-Based  Sound Pressure Estimation At The Eardrum",
    "abstract": "Comments: 5 pages, 5 figures, accepted to ICASSP 2022",
    "descriptor": "\nComments: 5 pages, 5 figures, accepted to ICASSP 2022\n",
    "authors": [
      "Wenyu Jin",
      "Tim Schoof",
      "Henning Schepker"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2110.04385"
  },
  {
    "id": "arXiv:2110.04398",
    "title": "The Role of Masks in Mitigating Viral Spread on Networks",
    "abstract": "The Role of Masks in Mitigating Viral Spread on Networks",
    "descriptor": "",
    "authors": [
      "Yurun Tian",
      "Anirudh Sridhar",
      "Chai Wah Wu",
      "Simon A. Levin",
      "H.Vincent Poor",
      "Osman Yagan"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2110.04398"
  },
  {
    "id": "arXiv:2110.05054",
    "title": "Source Mixing and Separation Robust Audio Steganography",
    "abstract": "Comments: Accepted to ICASSP 2022",
    "descriptor": "\nComments: Accepted to ICASSP 2022\n",
    "authors": [
      "Naoya Takahashi",
      "Mayank Kumar Singh",
      "Yuki Mitsufuji"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Cryptography and Security (cs.CR)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.05054"
  },
  {
    "id": "arXiv:2110.05059",
    "title": "Amicable examples for informed source separation",
    "abstract": "Comments: Accepted to ICASSP 2022",
    "descriptor": "\nComments: Accepted to ICASSP 2022\n",
    "authors": [
      "Naoya Takahashi",
      "Yuki Mitsufuji"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.05059"
  },
  {
    "id": "arXiv:2110.05645",
    "title": "A global convergence theory for deep ReLU implicit networks via  over-parameterization",
    "abstract": "Comments: Accepted by ICLR 2022",
    "descriptor": "\nComments: Accepted by ICLR 2022\n",
    "authors": [
      "Tianxiang Gao",
      "Hailiang Liu",
      "Jia Liu",
      "Hridesh Rajan",
      "Hongyang Gao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.05645"
  },
  {
    "id": "arXiv:2110.05695",
    "title": "The Mirrornet : Learning Audio Synthesizer Controls Inspired by  Sensorimotor Interaction",
    "abstract": "The Mirrornet : Learning Audio Synthesizer Controls Inspired by  Sensorimotor Interaction",
    "descriptor": "",
    "authors": [
      "Yashish M. Siriwardena",
      "Guilhem Marion",
      "Shihab Shamma"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2110.05695"
  },
  {
    "id": "arXiv:2110.08470",
    "title": "Case-based Reasoning for Better Generalization in Text-Adventure Games",
    "abstract": "Comments: Published as a conference paper at ICLR 2022",
    "descriptor": "\nComments: Published as a conference paper at ICLR 2022\n",
    "authors": [
      "Mattia Atzeni",
      "Shehzaad Dhuliawala",
      "Keerthiram Murugesan",
      "Mrinmaya Sachan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.08470"
  },
  {
    "id": "arXiv:2110.10415",
    "title": "Depth360: Self-supervised Learning for Monocular Depth Estimation using  Learnable Camera Distortion Model",
    "abstract": "Comments: 8 pages, 6 figures, 2 tables",
    "descriptor": "\nComments: 8 pages, 6 figures, 2 tables\n",
    "authors": [
      "Noriaki Hirose",
      "Kosuke Tahara"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.10415"
  },
  {
    "id": "arXiv:2110.12177",
    "title": "Vertebrae segmentation, identification and localization using a graph  optimization and a synergistic cycle",
    "abstract": "Comments: The iterative location-segmentation refinement scheme we claimed as one of the contributions has been found in previous reference",
    "descriptor": "\nComments: The iterative location-segmentation refinement scheme we claimed as one of the contributions has been found in previous reference\n",
    "authors": [
      "Di Meng",
      "Eslam Mohammed",
      "Edmond Boyer",
      "Sergi Pujades"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.12177"
  },
  {
    "id": "arXiv:2110.12396",
    "title": "Using Motion History Images with 3D Convolutional Networks in Isolated  Sign Language Recognition",
    "abstract": "Using Motion History Images with 3D Convolutional Networks in Isolated  Sign Language Recognition",
    "descriptor": "",
    "authors": [
      "Ozge Mercanoglu Sincan",
      "Hacer Yalim Keles"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.12396"
  },
  {
    "id": "arXiv:2110.12536",
    "title": "Neo: Generalizing Confusion Matrix Visualization to Hierarchical and  Multi-Output Labels",
    "abstract": "Comments: Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems",
    "descriptor": "\nComments: Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems\n",
    "authors": [
      "Jochen G\u00f6rtler",
      "Fred Hohman",
      "Dominik Moritz",
      "Kanit Wongsuphasawat",
      "Donghao Ren",
      "Rahul Nair",
      "Marc Kirchner",
      "Kayur Patel"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.12536"
  },
  {
    "id": "arXiv:2110.12595",
    "title": "Fast Rank-1 NMF for Missing Data with KL Divergence",
    "abstract": "Comments: 16 pages, 5 figures, accepted to the 25th International Conference on Artificial Intelligence and Statistics (AISTATS 2022)",
    "descriptor": "\nComments: 16 pages, 5 figures, accepted to the 25th International Conference on Artificial Intelligence and Statistics (AISTATS 2022)\n",
    "authors": [
      "Kazu Ghalamkari",
      "Mahito Sugiyama"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.12595"
  },
  {
    "id": "arXiv:2110.12787",
    "title": "Parallel Feedforward Compensation for Output Synchronization: Fully  Distributed Control and Indefinite Laplacian",
    "abstract": "Comments: 10 pages, 8 figures, submitted to systems and control letters",
    "descriptor": "\nComments: 10 pages, 8 figures, submitted to systems and control letters\n",
    "authors": [
      "Mengmou Li",
      "Ioannis Lestas",
      "Li Qiu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2110.12787"
  },
  {
    "id": "arXiv:2110.13506",
    "title": "A DPDK-Based Acceleration Method for Experience Sampling of Distributed  Reinforcement Learning",
    "abstract": "A DPDK-Based Acceleration Method for Experience Sampling of Distributed  Reinforcement Learning",
    "descriptor": "",
    "authors": [
      "Masaki Furukawa",
      "Hiroki Matsutani"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.13506"
  },
  {
    "id": "arXiv:2110.14503",
    "title": "Simple data balancing achieves competitive worst-group-accuracy",
    "abstract": "Comments: Accepted at CLeaR (Causal Learning and Reasoning) 2022",
    "descriptor": "\nComments: Accepted at CLeaR (Causal Learning and Reasoning) 2022\n",
    "authors": [
      "Badr Youbi Idrissi",
      "Martin Arjovsky",
      "Mohammad Pezeshki",
      "David Lopez-Paz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.14503"
  },
  {
    "id": "arXiv:2111.05463",
    "title": "An Open-Source RRAM Compiler",
    "abstract": "Comments: 5 pages",
    "descriptor": "\nComments: 5 pages\n",
    "authors": [
      "Dimitris Antoniadis",
      "Andrea Mifsud",
      "Peilong Feng",
      "Timothy G. Constandinou"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2111.05463"
  },
  {
    "id": "arXiv:2111.05592",
    "title": "Improving the Chamberlin Digital State Variable Filter",
    "abstract": "Improving the Chamberlin Digital State Variable Filter",
    "descriptor": "",
    "authors": [
      "Victor Lazzarini",
      "Joseph Timoney"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2111.05592"
  },
  {
    "id": "arXiv:2111.07637",
    "title": "Drone delivery: Reliable Cellular UAV Communication Using Multi-Operator  Diversity",
    "abstract": "Comments: 6 pages, 8 figures, ICC2022, Camera Ready",
    "descriptor": "\nComments: 6 pages, 8 figures, ICC2022, Camera Ready\n",
    "authors": [
      "Achiel Colpaert",
      "Micha\u00ebl Raes",
      "Evgenii Vinogradov",
      "Sofie Pollin"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2111.07637"
  },
  {
    "id": "arXiv:2111.07691",
    "title": "Theoretical Guarantees for the Statistical Finite Element Method",
    "abstract": "Comments: 27 pages for main article, 11 pages for supplement, 8 figures; typos corrected",
    "descriptor": "\nComments: 27 pages for main article, 11 pages for supplement, 8 figures; typos corrected\n",
    "authors": [
      "Yanni Papandreou",
      "Jon Cockayne",
      "Mark Girolami",
      "Andrew B. Duncan"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2111.07691"
  },
  {
    "id": "arXiv:2111.11516",
    "title": "Shape-Dependent Multi-Weight Magnetic Artificial Synapses for  Neuromorphic Computing",
    "abstract": "Comments: 27 pages 6 figures 1 table",
    "descriptor": "\nComments: 27 pages 6 figures 1 table\n",
    "authors": [
      "Thomas Leonard",
      "Samuel Liu",
      "Mahshid Alamdar",
      "Can Cui",
      "Otitoaleke G. Akinola",
      "Lin Xue",
      "T. Patrick Xiao",
      "Joseph S. Friedman",
      "Matthew J. Marinella",
      "Christopher H. Bennett",
      "Jean Anne C. Incorvia"
    ],
    "subjectives": [
      "Mesoscale and Nanoscale Physics (cond-mat.mes-hall)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2111.11516"
  },
  {
    "id": "arXiv:2111.14616",
    "title": "DeepGate: Learning Neural Representations of Logic Gates",
    "abstract": "Comments: Accepted by DAC2022",
    "descriptor": "\nComments: Accepted by DAC2022\n",
    "authors": [
      "Min Li",
      "Sadaf Khan",
      "Zhengyuan Shi",
      "Naixing Wang",
      "Yu Huang",
      "Qiang Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.14616"
  },
  {
    "id": "arXiv:2111.14696",
    "title": "The Computational Drug Repositioning without Negative Sampling",
    "abstract": "Comments: 9 pages,4 figures",
    "descriptor": "\nComments: 9 pages,4 figures\n",
    "authors": [
      "Xinxing Yang",
      "Genke Yang",
      "Jian Chu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2111.14696"
  },
  {
    "id": "arXiv:2112.00275",
    "title": "Learning from Mistakes based on Class Weighting with Application to  Neural Architecture Search",
    "abstract": "Learning from Mistakes based on Class Weighting with Application to  Neural Architecture Search",
    "descriptor": "",
    "authors": [
      "Jay Gala",
      "Pengtao Xie"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.00275"
  },
  {
    "id": "arXiv:2112.01280",
    "title": "Learning Graphon Mean Field Games and Approximate Nash Equilibria",
    "abstract": "Comments: Accepted to the Tenth International Conference on Learning Representations (ICLR); Fixed some typos",
    "descriptor": "\nComments: Accepted to the Tenth International Conference on Learning Representations (ICLR); Fixed some typos\n",
    "authors": [
      "Kai Cui",
      "Heinz Koeppl"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2112.01280"
  },
  {
    "id": "arXiv:2112.07922",
    "title": "Ten years of image analysis and machine learning competitions in  dementia",
    "abstract": "Comments: 12 pages, 4 tables",
    "descriptor": "\nComments: 12 pages, 4 tables\n",
    "authors": [
      "Esther E. Bron",
      "Stefan Klein",
      "Annika Reinke",
      "Janne M. Papma",
      "Lena Maier-Hein",
      "Daniel C. Alexander",
      "Neil P. Oxtoby"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.07922"
  },
  {
    "id": "arXiv:2112.10767",
    "title": "GCN-Geo: A Graph Convolution Network-based Fine-grained IP Geolocation  Framework",
    "abstract": "Comments: Under Review",
    "descriptor": "\nComments: Under Review\n",
    "authors": [
      "Shichang Ding",
      "Xiangyang Luo",
      "Jinwei Wang",
      "Xiaoming Fu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.10767"
  },
  {
    "id": "arXiv:2112.13311",
    "title": "A direct imaging method for the exterior and interior inverse scattering  problems",
    "abstract": "Comments: 28 pages, 7 figures",
    "descriptor": "\nComments: 28 pages, 7 figures\n",
    "authors": [
      "Deyue Zhang",
      "Yue Wu",
      "Yinglin Wang",
      "Yukun Guo"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)"
    ],
    "url": "https://arxiv.org/abs/2112.13311"
  },
  {
    "id": "arXiv:2112.13753",
    "title": "Conversion Rate Prediction via Meta Learning in Small-Scale  Recommendation Scenarios",
    "abstract": "Conversion Rate Prediction via Meta Learning in Small-Scale  Recommendation Scenarios",
    "descriptor": "",
    "authors": [
      "Xiaofeng Pan",
      "Ming Li",
      "Jing Zhang",
      "Keren Yu",
      "Luping Wang",
      "Hong Wen",
      "Chengjun Mao",
      "Bo Cao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2112.13753"
  },
  {
    "id": "arXiv:2201.00001",
    "title": "Modeling Advection on Directed Graphs using Mat\u00e9rn Gaussian Processes  for Traffic Flow",
    "abstract": "Comments: Accepted at the Machine Learning and Physical Sciences NeurIPS 2021 Workshop this https URL",
    "descriptor": "\nComments: Accepted at the Machine Learning and Physical Sciences NeurIPS 2021 Workshop this https URL\n",
    "authors": [
      "Danielle C Maddix",
      "Nadim Saad",
      "Yuyang Wang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2201.00001"
  },
  {
    "id": "arXiv:2201.00384",
    "title": "Randomized Signature Layers for Signal Extraction in Time Series Data",
    "abstract": "Randomized Signature Layers for Signal Extraction in Time Series Data",
    "descriptor": "",
    "authors": [
      "Enea Monzio Compagnoni",
      "Luca Biggio",
      "Antonio Orvieto",
      "Thomas Hofmann",
      "Josef Teichmann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2201.00384"
  },
  {
    "id": "arXiv:2201.01336",
    "title": "Bearing-based Autonomous Communication Relay Positioning under  Field-of-View Constraints",
    "abstract": "Comments: 20 pages, 11 figures, submitted to \"Advanced Control for Applications\" on Sep 2021, first round review version resubmitted on Feb 2022",
    "descriptor": "\nComments: 20 pages, 11 figures, submitted to \"Advanced Control for Applications\" on Sep 2021, first round review version resubmitted on Feb 2022\n",
    "authors": [
      "Marco Fabris",
      "Daniel Zelazo"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2201.01336"
  },
  {
    "id": "arXiv:2201.02300",
    "title": "Hyperparameter Selection Methods for Fitted Q-Evaluation with Error  Guarantee",
    "abstract": "Comments: AAAI22-AI4DO (workshop)",
    "descriptor": "\nComments: AAAI22-AI4DO (workshop)\n",
    "authors": [
      "Kohei Miyaguchi"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.02300"
  },
  {
    "id": "arXiv:2201.06618",
    "title": "VAQF: Fully Automatic Software-Hardware Co-Design Framework for Low-Bit  Vision Transformer",
    "abstract": "VAQF: Fully Automatic Software-Hardware Co-Design Framework for Low-Bit  Vision Transformer",
    "descriptor": "",
    "authors": [
      "Mengshu Sun",
      "Haoyu Ma",
      "Guoliang Kang",
      "Yifan Jiang",
      "Tianlong Chen",
      "Xiaolong Ma",
      "Zhangyang Wang",
      "Yanzhi Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.06618"
  },
  {
    "id": "arXiv:2201.06699",
    "title": "AESPA: Accuracy Preserving Low-degree Polynomial Activation for Fast  Private Inference",
    "abstract": "Comments: 11 pages, 5 figures",
    "descriptor": "\nComments: 11 pages, 5 figures\n",
    "authors": [
      "Jaiyoung Park",
      "Michael Jaemin Kim",
      "Wonkyung Jung",
      "Jung Ho Ahn"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.06699"
  },
  {
    "id": "arXiv:2201.06814",
    "title": "Leaving No One Behind: A Multi-Scenario Multi-Task Meta Learning  Approach for Advertiser Modeling",
    "abstract": "Comments: WSDM2022",
    "descriptor": "\nComments: WSDM2022\n",
    "authors": [
      "Qianqian Zhang",
      "Xinru Liao",
      "Quan Liu",
      "Jian Xu",
      "Bo Zheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.06814"
  },
  {
    "id": "arXiv:2201.08013",
    "title": "Comparative Study on Reliability Estimation Using Monte Carlo Simulation  with Application to Cylindrical Pressure Vessel",
    "abstract": "Comparative Study on Reliability Estimation Using Monte Carlo Simulation  with Application to Cylindrical Pressure Vessel",
    "descriptor": "",
    "authors": [
      "Abolfazl Zolfaghari"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2201.08013"
  },
  {
    "id": "arXiv:2201.10113",
    "title": "Two heads are better than one: Enhancing medical representations by  pre-training over structured and unstructured electronic health records",
    "abstract": "Comments: 30 pages, 5 figures",
    "descriptor": "\nComments: 30 pages, 5 figures\n",
    "authors": [
      "Sicen Liu",
      "Xiaolong Wang",
      "Yongshuai Hou",
      "Ge Li",
      "Hui Wang",
      "Hui Xu",
      "Yang Xiang",
      "Buzhou Tang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.10113"
  },
  {
    "id": "arXiv:2201.11133",
    "title": "Inference-optimized AI and high performance computing for gravitational  wave detection at scale",
    "abstract": "Comments: 19 pages, 8 figures; v2. Accepted to Frontiers in Artificial Intelligence, Special Issue: Efficient AI in Particle Physics and Astrophysics",
    "descriptor": "\nComments: 19 pages, 8 figures; v2. Accepted to Frontiers in Artificial Intelligence, Special Issue: Efficient AI in Particle Physics and Astrophysics\n",
    "authors": [
      "Pranshu Chaturvedi",
      "Asad Khan",
      "Minyang Tian",
      "E. A. Huerta",
      "Huihuo Zheng"
    ],
    "subjectives": [
      "General Relativity and Quantum Cosmology (gr-qc)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.11133"
  },
  {
    "id": "arXiv:2201.11162",
    "title": "Self-Certifying Classification by Linearized Deep Assignment",
    "abstract": "Self-Certifying Classification by Linearized Deep Assignment",
    "descriptor": "",
    "authors": [
      "Bastian Boll",
      "Alexander Zeilmann",
      "Stefania Petra",
      "Christoph Schn\u00f6rr"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2201.11162"
  },
  {
    "id": "arXiv:2201.11766",
    "title": "Recursive Decoding: A Situated Cognition Approach to Compositional  Generation in Grounded Language Understanding",
    "abstract": "Recursive Decoding: A Situated Cognition Approach to Compositional  Generation in Grounded Language Understanding",
    "descriptor": "",
    "authors": [
      "Matthew Setzler",
      "Scott Howland",
      "Lauren Phillips"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.11766"
  },
  {
    "id": "arXiv:2201.12451",
    "title": "Extracting Finite Automata from RNNs Using State Merging",
    "abstract": "Comments: Preprint",
    "descriptor": "\nComments: Preprint\n",
    "authors": [
      "William Merrill",
      "Nikolaos Tsilivis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.12451"
  },
  {
    "id": "arXiv:2201.12518",
    "title": "Zeroth-Order Actor-Critic",
    "abstract": "Zeroth-Order Actor-Critic",
    "descriptor": "",
    "authors": [
      "Yuheng Lei",
      "Jianyu Chen",
      "Shengbo Eben Li",
      "Sifa Zheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2201.12518"
  },
  {
    "id": "arXiv:2201.12559",
    "title": "Task-Balanced Batch Normalization for Exemplar-based Class-Incremental  Learning",
    "abstract": "Comments: Preprint",
    "descriptor": "\nComments: Preprint\n",
    "authors": [
      "Sungmin Cha",
      "Soonwon Hong",
      "Moontae Lee",
      "Taesup Moon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.12559"
  },
  {
    "id": "arXiv:2201.12585",
    "title": "LBCF: A Large-Scale Budget-Constrained Causal Forest Algorithm",
    "abstract": "Comments: Published in Web Conference 2022 (WWW'2022)",
    "descriptor": "\nComments: Published in Web Conference 2022 (WWW'2022)\n",
    "authors": [
      "Meng Ai",
      "Biao Li",
      "Heyang Gong",
      "Qingwei Yu",
      "Shengjie Xue",
      "Yuan Zhang",
      "Yunzhou Zhang",
      "Peng Jiang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2201.12585"
  },
  {
    "id": "arXiv:2202.00192",
    "title": "Tight Cuts in Bipartite Grafts I: Capital Distance Components",
    "abstract": "Tight Cuts in Bipartite Grafts I: Capital Distance Components",
    "descriptor": "",
    "authors": [
      "Nanao Kita"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2202.00192"
  },
  {
    "id": "arXiv:2202.00263",
    "title": "Fully Online Meta-Learning Without Task Boundaries",
    "abstract": "Fully Online Meta-Learning Without Task Boundaries",
    "descriptor": "",
    "authors": [
      "Jathushan Rajasegaran",
      "Chelsea Finn",
      "Sergey Levine"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.00263"
  },
  {
    "id": "arXiv:2202.00718",
    "title": "Personalized Federated Learning via Convex Clustering",
    "abstract": "Comments: Changed template. Figure 4 separated into Figure 4 and Figure 5",
    "descriptor": "\nComments: Changed template. Figure 4 separated into Figure 4 and Figure 5\n",
    "authors": [
      "Aleksandar Armacki",
      "Dragana Bajovic",
      "Dusan Jakovetic",
      "Soummya Kar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.00718"
  },
  {
    "id": "arXiv:2202.00720",
    "title": "Gradient Based Clustering",
    "abstract": "Comments: Change of template",
    "descriptor": "\nComments: Change of template\n",
    "authors": [
      "Aleksandar Armacki",
      "Dragana Bajovic",
      "Dusan Jakovetic",
      "Soummya Kar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.00720"
  },
  {
    "id": "arXiv:2202.00886",
    "title": "Accurate calibration of multi-perspective cameras from a generalization  of the hand-eye constraint",
    "abstract": "Comments: accepted in the 2022 IEEE International Conference on Robotics and Automation (ICRA), Philadelphia (PA), USA",
    "descriptor": "\nComments: accepted in the 2022 IEEE International Conference on Robotics and Automation (ICRA), Philadelphia (PA), USA\n",
    "authors": [
      "Yifu Wang",
      "Wenqing Jiang",
      "Kun Huang",
      "S\u00f6ren Schwertfeger",
      "Laurent Kneip"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.00886"
  },
  {
    "id": "arXiv:2202.01094",
    "title": "RescoreBERT: Discriminative Speech Recognition Rescoring with BERT",
    "abstract": "Comments: Accepted to ICASSP 2022",
    "descriptor": "\nComments: Accepted to ICASSP 2022\n",
    "authors": [
      "Liyan Xu",
      "Yile Gu",
      "Jari Kolehmainen",
      "Haidar Khan",
      "Ankur Gandhe",
      "Ariya Rastrow",
      "Andreas Stolcke",
      "Ivan Bulyko"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2202.01094"
  },
  {
    "id": "arXiv:2202.01691",
    "title": "Solving Dynamic Principal-Agent Problems with a Rationally Inattentive  Principal",
    "abstract": "Comments: 22 pages, 8 figures, including appendix",
    "descriptor": "\nComments: 22 pages, 8 figures, including appendix\n",
    "authors": [
      "Tong Mu",
      "Stephan Zheng",
      "Alexander Trott"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.01691"
  },
  {
    "id": "arXiv:2202.02212",
    "title": "SSHA: Video Violence Recognition and Localization Using a  Semi-Supervised Hard Attention Model",
    "abstract": "Comments: 10 pages, 4 figures, 3 tables",
    "descriptor": "\nComments: 10 pages, 4 figures, 3 tables\n",
    "authors": [
      "Hamid Mohammadi",
      "Ehsan Nazerfard"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.02212"
  },
  {
    "id": "arXiv:2202.02293",
    "title": "A nonlinear PPH-type reconstruction based on equilateral triangles",
    "abstract": "Comments: 12 pages, 3 figures",
    "descriptor": "\nComments: 12 pages, 3 figures\n",
    "authors": [
      "S. Amat",
      "P. Ortiz",
      "J. Ruiz",
      "J.C. Trillo",
      "D. F. Ya\u00f1ez"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.02293"
  },
  {
    "id": "arXiv:2202.02387",
    "title": "Automatic Identification of Self-Admitted Technical Debt from Different  Sources",
    "abstract": "Automatic Identification of Self-Admitted Technical Debt from Different  Sources",
    "descriptor": "",
    "authors": [
      "Yikun Li",
      "Mohamed Soliman",
      "Paris Avgeriou"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.02387"
  },
  {
    "id": "arXiv:2202.02864",
    "title": "Alpha Blending with No Division Operations",
    "abstract": "Comments: 10 pages, 1 figure",
    "descriptor": "\nComments: 10 pages, 1 figure\n",
    "authors": [
      "Jerry R. Van Aken"
    ],
    "subjectives": [
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2202.02864"
  },
  {
    "id": "arXiv:2202.02947",
    "title": "Parallel Successive Learning for Dynamic Distributed Model Training over  Heterogeneous Wireless Networks",
    "abstract": "Parallel Successive Learning for Dynamic Distributed Model Training over  Heterogeneous Wireless Networks",
    "descriptor": "",
    "authors": [
      "Seyyedali Hosseinalipour",
      "Su Wang",
      "Nicolo Michelusi",
      "Vaneet Aggarwal",
      "Christopher G. Brinton",
      "David J. Love",
      "Mung Chiang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Networking and Internet Architecture (cs.NI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.02947"
  },
  {
    "id": "arXiv:2202.03212",
    "title": "Introducing explainable supervised machine learning into interactive  feedback loops for statistical production system",
    "abstract": "Comments: Irving Fisher Committee (IFC) - Bank of Italy workshop on Data science in central banking: Applications and tools. arXiv admin note: text overlap with arXiv:2107.08045",
    "descriptor": "\nComments: Irving Fisher Committee (IFC) - Bank of Italy workshop on Data science in central banking: Applications and tools. arXiv admin note: text overlap with arXiv:2107.08045\n",
    "authors": [
      "Carlos Mougan",
      "George Kanellos",
      "Johannes Micheler",
      "Jose Martinez",
      "Thomas Gottron"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.03212"
  },
  {
    "id": "arXiv:2202.03484",
    "title": "Self-supervised Speaker Recognition Training Using Human-Machine  Dialogues",
    "abstract": "Comments: 5 pages, 2 figures",
    "descriptor": "\nComments: 5 pages, 2 figures\n",
    "authors": [
      "Metehan Cekic",
      "Ruirui Li",
      "Zeya Chen",
      "Yuguang Yang",
      "Andreas Stolcke",
      "Upamanyu Madhow"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.03484"
  },
  {
    "id": "arXiv:2202.04798",
    "title": "Augmenting Neural Networks with Priors on Function Values",
    "abstract": "Augmenting Neural Networks with Priors on Function Values",
    "descriptor": "",
    "authors": [
      "Hunter Nisonoff",
      "Yixin Wang",
      "Jennifer Listgarten"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.04798"
  },
  {
    "id": "arXiv:2202.04814",
    "title": "Royalflush Speaker Diarization System for ICASSP 2022 Multi-channel  Multi-party Meeting Transcription Challenge",
    "abstract": "Royalflush Speaker Diarization System for ICASSP 2022 Multi-channel  Multi-party Meeting Transcription Challenge",
    "descriptor": "",
    "authors": [
      "Jingguang Tian",
      "Xinhui Hu",
      "Xinkang Xu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2202.04814"
  },
  {
    "id": "arXiv:2202.05089",
    "title": "Backpropagation Clipping for Deep Learning with Differential Privacy",
    "abstract": "Comments: We found a bug in our implementation code that invalidates our experimental results",
    "descriptor": "\nComments: We found a bug in our implementation code that invalidates our experimental results\n",
    "authors": [
      "Timothy Stevens",
      "Ivoline C. Ngong",
      "David Darais",
      "Calvin Hirsch",
      "David Slater",
      "Joseph P. Near"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.05089"
  },
  {
    "id": "arXiv:2202.05226",
    "title": "Deadwooding: Robust Global Pruning for Deep Neural Networks",
    "abstract": "Comments: 12 pages, 5 figures",
    "descriptor": "\nComments: 12 pages, 5 figures\n",
    "authors": [
      "Sawinder Kaur",
      "Ferdinando Fioretto",
      "Asif Salekin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.05226"
  },
  {
    "id": "arXiv:2202.05505",
    "title": "Software Architecture for Quantum Computing Systems -- A Systematic  Review",
    "abstract": "Software Architecture for Quantum Computing Systems -- A Systematic  Review",
    "descriptor": "",
    "authors": [
      "Arif Ali Khan",
      "Aakash Ahmad",
      "Muhammad Waseem",
      "Peng Liang",
      "Mahdi Fahmideh",
      "Tommi Mikkonen",
      "Pekka Abrahamsson"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2202.05505"
  },
  {
    "id": "arXiv:2202.05592",
    "title": "Video-driven Neural Physically-based Facial Asset for Production",
    "abstract": "Comments: For project page, see this https URL Notice: You may not copy, reproduce, distribute, publish, display, perform, modify, create derivative works, transmit, or in any way exploit any such content, nor may you distribute any part of this content over any network, including a local area network, sell or offer it for sale, or use such content to construct any kind of database",
    "descriptor": "\nComments: For project page, see this https URL Notice: You may not copy, reproduce, distribute, publish, display, perform, modify, create derivative works, transmit, or in any way exploit any such content, nor may you distribute any part of this content over any network, including a local area network, sell or offer it for sale, or use such content to construct any kind of database\n",
    "authors": [
      "Longwen Zhang",
      "Chuxiao Zeng",
      "Qixuan Zhang",
      "Hongyang Lin",
      "Ruixiang Cao",
      "Wei Yang",
      "Lan Xu",
      "Jingyi Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.05592"
  },
  {
    "id": "arXiv:2202.05839",
    "title": "Abstraction for Deep Reinforcement Learning",
    "abstract": "Abstraction for Deep Reinforcement Learning",
    "descriptor": "",
    "authors": [
      "Murray Shanahan",
      "Melanie Mitchell"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.05839"
  },
  {
    "id": "arXiv:2202.06344",
    "title": "A Data Augmentation Method for Fully Automatic Brain Tumor Segmentation",
    "abstract": "Comments: 15 pages, 7 figures, 4tables",
    "descriptor": "\nComments: 15 pages, 7 figures, 4tables\n",
    "authors": [
      "Yu Wang",
      "Yarong Ji",
      "Hongbing Xiao"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.06344"
  },
  {
    "id": "arXiv:2202.06588",
    "title": "Conditional Generation Net for Medication Recommendation",
    "abstract": "Comments: 11 pages. To be published at The Web Conference 2022 (WWW 2022)",
    "descriptor": "\nComments: 11 pages. To be published at The Web Conference 2022 (WWW 2022)\n",
    "authors": [
      "Rui Wu",
      "Zhaopeng Qiu",
      "Jiacheng Jiang",
      "Guilin Qi",
      "Xian Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.06588"
  },
  {
    "id": "arXiv:2202.06670",
    "title": "Learning Weakly-Supervised Contrastive Representations",
    "abstract": "Comments: Published as ICLR 2022. arXiv admin note: substantial text overlap with arXiv:2106.02869",
    "descriptor": "\nComments: Published as ICLR 2022. arXiv admin note: substantial text overlap with arXiv:2106.02869\n",
    "authors": [
      "Yao-Hung Hubert Tsai",
      "Tianqin Li",
      "Weixin Liu",
      "Peiyuan Liao",
      "Ruslan Salakhutdinov",
      "Louis-Philippe Morency"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.06670"
  },
  {
    "id": "arXiv:2202.06690",
    "title": "ArgSciChat: A Dataset for Argumentative Dialogues on Scientific Papers",
    "abstract": "ArgSciChat: A Dataset for Argumentative Dialogues on Scientific Papers",
    "descriptor": "",
    "authors": [
      "Federico Ruggeri",
      "Mohsen Mesgar",
      "Iryna Gurevych"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.06690"
  },
  {
    "id": "arXiv:2202.06948",
    "title": "Towards Best Practice of Interpreting Deep Learning Models for EEG-based  Brain Computer Interfaces",
    "abstract": "Towards Best Practice of Interpreting Deep Learning Models for EEG-based  Brain Computer Interfaces",
    "descriptor": "",
    "authors": [
      "Jian Cui",
      "Bin Weng"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.06948"
  },
  {
    "id": "arXiv:2202.07136",
    "title": "Debiased Pseudo Labeling in Self-Training",
    "abstract": "Debiased Pseudo Labeling in Self-Training",
    "descriptor": "",
    "authors": [
      "Baixu Chen",
      "Junguang Jiang",
      "Ximei Wang",
      "Jianmin Wang",
      "Mingsheng Long"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.07136"
  },
  {
    "id": "arXiv:2202.07191",
    "title": "Improving Human Sperm Head Morphology Classification with Unsupervised  Anatomical Feature Distillation",
    "abstract": "Comments: Accepted to ISBI 2022 proceedings",
    "descriptor": "\nComments: Accepted to ISBI 2022 proceedings\n",
    "authors": [
      "Yejia Zhang",
      "Jingjing Zhang",
      "Xiaomin Zha",
      "Yiru Zhou",
      "Yunxia Cao",
      "Danny Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.07191"
  },
  {
    "id": "arXiv:2202.07301",
    "title": "User-Oriented Robust Reinforcement Learning",
    "abstract": "User-Oriented Robust Reinforcement Learning",
    "descriptor": "",
    "authors": [
      "Haoyi You",
      "Beichen Yu",
      "Haiming Jin",
      "Zhaoxing Yang",
      "Jiahui Sun",
      "Xinbing Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.07301"
  },
  {
    "id": "arXiv:2202.07365",
    "title": "A Statistical Learning View of Simple Kriging",
    "abstract": "A Statistical Learning View of Simple Kriging",
    "descriptor": "",
    "authors": [
      "Emilia Siviero",
      "Emilie Chautru",
      "Stephan Cl\u00e9men\u00e7on"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.07365"
  },
  {
    "id": "arXiv:2202.07732",
    "title": "Multi-Modal Data Fusion in Enhancing Human-Machine Interaction for  Robotic Applications: A Survey",
    "abstract": "Comments: Planning to add more changes",
    "descriptor": "\nComments: Planning to add more changes\n",
    "authors": [
      "Tauheed Khan Mohd",
      "Nicole Nguyen",
      "Ahmad Y Javaid"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2202.07732"
  },
  {
    "id": "arXiv:2202.07757",
    "title": "Architecture Agnostic Federated Learning for Neural Networks",
    "abstract": "Architecture Agnostic Federated Learning for Neural Networks",
    "descriptor": "",
    "authors": [
      "Disha Makhija",
      "Xing Han",
      "Nhat Ho",
      "Joydeep Ghosh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.07757"
  },
  {
    "id": "arXiv:2202.07798",
    "title": "BB-ML: Basic Block Performance Prediction using Machine Learning  Techniques",
    "abstract": "BB-ML: Basic Block Performance Prediction using Machine Learning  Techniques",
    "descriptor": "",
    "authors": [
      "Shamminuj Aktar",
      "Hamdy Abdelkhalik",
      "Nazmul Haque Turja",
      "Yehia Arafa",
      "Atanu Barai",
      "Nishant Panda",
      "Gopinath Chennupati",
      "Nandakishore Santhi",
      "Stephan Eidenbenz",
      "Abdel-Hameed Badawy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2202.07798"
  },
  {
    "id": "arXiv:2202.07983",
    "title": "ADAM Challenge: Detecting Age-related Macular Degeneration from Fundus  Images",
    "abstract": "Comments: 29 pages, 17 figures",
    "descriptor": "\nComments: 29 pages, 17 figures\n",
    "authors": [
      "Huihui Fang",
      "Fei Li",
      "Huazhu Fu",
      "Xu Sun",
      "Xingxing Cao",
      "Fengbin Lin",
      "Jaemin Son",
      "Sunho Kim",
      "Gwenole Quellec",
      "Sarah Matta",
      "Sharath M Shankaranarayana",
      "Yi-Ting Chen",
      "Chuen-heng Wang",
      "Nisarg A. Shah",
      "Chia-Yen Lee",
      "Chih-Chung Hsu",
      "Hai Xie",
      "Baiying Lei",
      "Ujjwal Baid",
      "Shubham Innani",
      "Kang Dang",
      "Wenxiu Shi",
      "Ravi Kamble",
      "Nitin Singhal",
      "Jos\u00e9 Ignacio Orlando",
      "Hrvoje Bogunovi\u0107",
      "Xiulan Zhang",
      "Yanwu Xu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.07983"
  },
  {
    "id": "arXiv:2202.08173",
    "title": "Distributed k-Means with Outliers in General Metrics",
    "abstract": "Distributed k-Means with Outliers in General Metrics",
    "descriptor": "",
    "authors": [
      "Enrico Dandolo",
      "Andrea Pietracaprina",
      "Geppino Pucci"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.08173"
  },
  {
    "id": "arXiv:2202.08373",
    "title": "Text-Based Action-Model Acquisition for Planning",
    "abstract": "Text-Based Action-Model Acquisition for Planning",
    "descriptor": "",
    "authors": [
      "Kebing Jin",
      "Huaixun Chen",
      "Hankz Hankui Zhuo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.08373"
  },
  {
    "id": "arXiv:2202.08445",
    "title": "Extended MSO Model Checking via Small Vertex Integrity",
    "abstract": "Extended MSO Model Checking via Small Vertex Integrity",
    "descriptor": "",
    "authors": [
      "Tatsuya Gima",
      "Yota Otachi"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2202.08445"
  },
  {
    "id": "arXiv:2202.08504",
    "title": "Finding Representative Sampling Subsets in Sensor Graphs using Time  Series Similarities",
    "abstract": "Finding Representative Sampling Subsets in Sensor Graphs using Time  Series Similarities",
    "descriptor": "",
    "authors": [
      "Roshni Chakraborty",
      "Josefine Holm",
      "Torben Bach Pedersen",
      "Petar Popovski"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2202.08504"
  },
  {
    "id": "arXiv:2202.08553",
    "title": "3D-Aware Indoor Scene Synthesis with Depth Priors",
    "abstract": "3D-Aware Indoor Scene Synthesis with Depth Priors",
    "descriptor": "",
    "authors": [
      "Zifan Shi",
      "Yujun Shen",
      "Jiapeng Zhu",
      "Dit-Yan Yeung",
      "Qifeng Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.08553"
  },
  {
    "id": "arXiv:2202.08604",
    "title": "Two-Stage Architectural Fine-Tuning with Neural Architecture Search  using Early-Stopping in Image Classification",
    "abstract": "Comments: 5 pages, 6 figures",
    "descriptor": "\nComments: 5 pages, 6 figures\n",
    "authors": [
      "Youngkee Kim",
      "Won Joon Yun",
      "Youn Kyu Lee",
      "Joongheon Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.08604"
  },
  {
    "id": "arXiv:2202.08836",
    "title": "Data-SUITE: Data-centric identification of in-distribution incongruous  examples",
    "abstract": "Data-SUITE: Data-centric identification of in-distribution incongruous  examples",
    "descriptor": "",
    "authors": [
      "Nabeel Seedat",
      "Jonathan Crabb\u00e9",
      "Mihaela van der Schaar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.08836"
  }
]
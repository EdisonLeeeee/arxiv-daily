[
  {
    "id": "arXiv:2202.05271",
    "title": "A Field of Experts Prior for Adapting Neural Networks at Test Time",
    "abstract": "Performance of convolutional neural networks (CNNs) in image analysis tasks\nis often marred in the presence of acquisition-related distribution shifts\nbetween training and test images. Recently, it has been proposed to tackle this\nproblem by fine-tuning trained CNNs for each test image. Such\ntest-time-adaptation (TTA) is a promising and practical strategy for improving\nrobustness to distribution shifts as it requires neither data sharing between\ninstitutions nor annotating additional data. Previous TTA methods use a helper\nmodel to increase similarity between outputs and/or features extracted from a\ntest image with those of the training images. Such helpers, which are typically\nmodeled using CNNs, can be task-specific and themselves vulnerable to\ndistribution shifts in their inputs. To overcome these problems, we propose to\ncarry out TTA by matching the feature distributions of test and training\nimages, as modelled by a field-of-experts (FoE) prior. FoEs model complicated\nprobability distributions as products of many simpler expert distributions. We\nuse 1D marginal distributions of a trained task CNN's features as experts in\nthe FoE model. Further, we compute principal components of patches of the task\nCNN's features, and consider the distributions of PCA loadings as additional\nexperts. We validate the method on 5 MRI segmentation tasks (healthy tissues in\n4 anatomical regions and lesions in 1 one anatomy), using data from 17 clinics,\nand on a MRI registration task, using data from 3 clinics. We find that the\nproposed FoE-based TTA is generically applicable in multiple tasks, and\noutperforms all previous TTA methods for lesion segmentation. For healthy\ntissue segmentation, the proposed method outperforms other task-agnostic\nmethods, but a previous TTA method which is specifically designed for\nsegmentation performs the best for most of the tested datasets. Our code is\npublicly available.",
    "descriptor": "\nComments: Manuscript under review\n",
    "authors": [
      "Neerav Karani",
      "Georg Brunner",
      "Ertunc Erdil",
      "Simin Fei",
      "Kerem Tezcan",
      "Krishna Chaitanya",
      "Ender Konukoglu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.05271"
  },
  {
    "id": "arXiv:2202.05272",
    "title": "Single-channel speech enhancement by using psychoacoustical model  inspired fusion framework",
    "abstract": "When the parameters of Bayesian Short-time Spectral Amplitude (STSA)\nestimator for speech enhancement are selected based on the characteristics of\nthe human auditory system, the gain function of the estimator becomes more\nflexible. Although this type of estimator in acoustic domain is quite effective\nin reducing the back-ground noise at high frequencies, it produces more speech\ndistortions, which make the high-frequency contents of the speech such as\nfriciatives less perceptible in heavy noise conditions, resulting in\nintelligibility reduction. On the other hand, the speech enhancement scheme,\nwhich exploits the psychoacoustic evidence of frequency selectivity in the\nmodulation domain, is found to be able to increase the intelligibility of noisy\nspeech by a substantial amount, but also suffers from the temporal slurring\nproblem due to its essential design constraint. In order to achieve the joint\nimprovements in both the perceived speech quality and intelligibility, we\nproposed and investigated a fusion framework by combining the merits of\nacoustic and modulation domain approaches while avoiding their respective\nweaknesses. Objective measure evaluation shows that the proposed speech\nenhancement fusion framework can provide consistent improvements in the\nperceived speech quality and intelligibility across different SNR levels in\nvarious noise conditions, while compared to the other baseline techniques.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2202.04882\n",
    "authors": [
      "Suman Samui"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2202.05272"
  },
  {
    "id": "arXiv:2202.05274",
    "title": "Motion Puzzle: Arbitrary Motion Style Transfer by Body Part",
    "abstract": "This paper presents Motion Puzzle, a novel motion style transfer network that\nadvances the state-of-the-art in several important respects. The Motion Puzzle\nis the first that can control the motion style of individual body parts,\nallowing for local style editing and significantly increasing the range of\nstylized motions. Designed to keep the human's kinematic structure, our\nframework extracts style features from multiple style motions for different\nbody parts and transfers them locally to the target body parts. Another major\nadvantage is that it can transfer both global and local traits of motion style\nby integrating the adaptive instance normalization and attention modules while\nkeeping the skeleton topology. Thus, it can capture styles exhibited by dynamic\nmovements, such as flapping and staggering, significantly better than previous\nwork. In addition, our framework allows for arbitrary motion style transfer\nwithout datasets with style labeling or motion pairing, making many publicly\navailable motion datasets available for training. Our framework can be easily\nintegrated with motion generation frameworks to create many applications, such\nas real-time motion transfer. We demonstrate the advantages of our framework\nwith a number of examples and comparisons with previous work.",
    "descriptor": "\nComments: 16 pages\n",
    "authors": [
      "Deok-Kyeong Jang",
      "Soomin Park",
      "Sung-Hee Lee"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.05274"
  },
  {
    "id": "arXiv:2202.05292",
    "title": "On One-Bit Quantization",
    "abstract": "We consider the one-bit quantizer that minimizes the mean squared error for a\nsource living in a real Hilbert space. The optimal quantizer is a projection\nfollowed by a thresholding operation, and we provide methods for identifying\nthe optimal direction along which to project. As an application of our methods,\nwe characterize the optimal one-bit quantizer for a continuous-time random\nprocess that exhibits low-dimensional structure. We numerically show that this\noptimal quantizer is found by a neural-network-based compressor trained via\nstochastic gradient descent.",
    "descriptor": "",
    "authors": [
      "Sourbh Bhadane",
      "Aaron B. Wagner"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.05292"
  },
  {
    "id": "arXiv:2202.05294",
    "title": "Universal Learning Waveform Selection Strategies for Adaptive Target  Tracking",
    "abstract": "Online selection of optimal waveforms for target tracking with active sensors\nhas long been a problem of interest. Many conventional solutions utilize an\nestimation-theoretic interpretation, in which a waveform-specific\nCram\\'{e}r-Rao lower bound on measurement error is used to select the optimal\nwaveform for each tracking step. However, this approach is only valid in the\nhigh SNR regime, and requires a rather restrictive set of assumptions regarding\nthe target motion and measurement models. Further, due to computational\nconcerns, many traditional approaches are limited to near-term, or myopic,\noptimization, even though radar scenes exhibit strong temporal correlation.\nMore recently, reinforcement learning has been proposed for waveform selection,\nin which the problem is framed as a Markov decision process (MDP), allowing for\nlong-term planning. However, a major limitation of reinforcement learning is\nthat the memory length of the underlying Markov process is often unknown for\nrealistic target and channel dynamics, and a more general framework is\ndesirable. This work develops a universal sequential waveform selection scheme\nwhich asymptotically achieves Bellman optimality in any radar scene which can\nbe modeled as a $U^{\\text{th}}$ order Markov process for a finite, but unknown,\ninteger $U$. Our approach is based on well-established tools from the field of\nuniversal source coding, where a stationary source is parsed into variable\nlength phrases in order to build a context-tree, which is used as a\nprobabalistic model for the scene's behavior. We show that an algorithm based\non a multi-alphabet version of the Context-Tree Weighting (CTW) method can be\nused to optimally solve a broad class of waveform-agile tracking problems while\nmaking minimal assumptions about the environment's behavior.",
    "descriptor": "\nComments: 23 pages, 5 figures\n",
    "authors": [
      "Charles E. Thornton",
      "R. Michael Buehrer",
      "Harpreet S. Dhillon",
      "Anthony F. Martone"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.05294"
  },
  {
    "id": "arXiv:2202.05295",
    "title": "Non-stationary Anderson acceleration with optimized damping",
    "abstract": "Anderson acceleration (AA) has a long history of use and a strong recent\ninterest due to its potential ability to dramatically improve the linear\nconvergence of the fixed-point iteration. Most authors are simply using and\nanalyzing the stationary version of Anderson acceleration (sAA) with a constant\ndamping factor or without damping. Little attention has been paid to\nnonstationary algorithms. However, damping can be useful and is sometimes\ncrucial for simulations in which the underlying fixed-point operator is not\nglobally contractive. The role of this damping factor has not been fully\nunderstood. In the present work, we consider the non-stationary Anderson\nacceleration algorithm with optimized damping (AAoptD) in each iteration to\nfurther speed up linear and nonlinear iterations by applying one extra\ninexpensive optimization. We analyze this procedure and develop an efficient\nand inexpensive implementation scheme. We also show that, compared with the\nstationary Anderson acceleration with fixed window size sAA(m), optimizing the\ndamping factors is related to dynamically packaging sAA(m) and sAA(1) in each\niteration (alternating window size $m$ is another direction of producing\nnon-stationary AA). Moreover, we show by extensive numerical experiments that\nthe proposed non-stationary Anderson acceleration with optimized damping\nprocedure often converges much faster than stationary AA with constant damping\nor without damping.",
    "descriptor": "\nComments: 27pages, 16 figures\n",
    "authors": [
      "Kewang Chen",
      "Cornelis Vuik"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.05295"
  },
  {
    "id": "arXiv:2202.05297",
    "title": "Face Beneath the Ink: Synthetic Data and Tattoo Removal with Application  to Face Recognition",
    "abstract": "Systems that analyse faces have seen significant improvements in recent years\nand are today used in numerous application scenarios. However, these systems\nhave been found to be negatively affected by facial alterations such as\ntattoos. To better understand and mitigate the effect of facial tattoos in\nfacial analysis systems, large datasets of images of individuals with and\nwithout tattoos are needed. To this end, we propose a generator for\nautomatically adding realistic tattoos to facial images. Moreover, we\ndemonstrate the feasibility of the generation by training a deep learning-based\nmodel for removing tattoos from face images. The experimental results show that\nit is possible to remove facial tattoos from real images without degrading the\nquality of the image. Additionally, we show that it is possible to improve face\nrecognition accuracy by using the proposed deep learning-based tattoo removal\nbefore extracting and comparing facial features.",
    "descriptor": "",
    "authors": [
      "Mathias Ibsen",
      "Christian Rathgeb",
      "Pawel Drozdowski",
      "Christoph Busch"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.05297"
  },
  {
    "id": "arXiv:2202.05299",
    "title": "Characterization of matrices with bounded Graver bases and depth  parameters and applications to integer programming",
    "abstract": "An intensive line of research on fixed parameter tractability of integer\nprogramming is focused on exploiting the relation between the sparsity of a\nconstraint matrix $A$ and the norm of the elements of its Graver basis. In\nparticular, integer programming is fixed parameter tractable when parameterized\nby the primal tree-depth and the entry complexity of $A$, and when\nparameterized by the dual tree-depth and the entry complexity of $A$; both\nthese parameterization imply that $A$ is sparse, in particular, the number of\nits non-zero entries is linear in the number of columns or rows, respectively.\nWe study preconditioners transforming a given matrix to an equivalent sparse\nmatrix if it exists and provide structural results characterizing the existence\nof a sparse equivalent matrix in terms of the structural properties of the\nassociated column matroid. In particular, our results imply that the\n$\\ell_1$-norm of the Graver basis is bounded by a function of the maximum\n$\\ell_1$-norm of a circuit of $A$. We use our results to design a parameterized\nalgorithm that constructs a matrix equivalent to an input matrix $A$ that has\nsmall primal/dual tree-depth and entry complexity if such an equivalent matrix\nexists.\nOur results yield parameterized algorithms for integer programming when\nparameterized by the $\\ell_1$-norm of the Graver basis of the constraint\nmatrix, when parameterized by the $\\ell_1$-norm of the circuits of the\nconstraint matrix, when parameterized by the smallest primal tree-depth and\nentry complexity of a matrix equivalent to the constraint matrix, and when\nparameterized by the smallest dual tree-depth and entry complexity of a matrix\nequivalent to the constraint matrix.",
    "descriptor": "",
    "authors": [
      "Marcin Brianski",
      "Martin Koutecky",
      "Daniel Kral",
      "Kristyna Pekarkova",
      "Felix Schroder"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2202.05299"
  },
  {
    "id": "arXiv:2202.05302",
    "title": "Trust in AI: Interpretability is not necessary or sufficient, while  black-box interaction is necessary and sufficient",
    "abstract": "The problem of human trust in artificial intelligence is one of the most\nfundamental problems in applied machine learning. Our processes for evaluating\nAI trustworthiness have substantial ramifications for ML's impact on science,\nhealth, and humanity, yet confusion surrounds foundational concepts. What does\nit mean to trust an AI, and how do humans assess AI trustworthiness? What are\nthe mechanisms for building trustworthy AI? And what is the role of\ninterpretable ML in trust? Here, we draw from statistical learning theory and\nsociological lenses on human-automation trust to motivate an AI-as-tool\nframework, which distinguishes human-AI trust from human-AI-human trust.\nEvaluating an AI's contractual trustworthiness involves predicting future model\nbehavior using behavior certificates (BCs) that aggregate behavioral evidence\nfrom diverse sources including empirical out-of-distribution and out-of-task\nevaluation and theoretical proofs linking model architecture to behavior. We\nclarify the role of interpretability in trust with a ladder of model access.\nInterpretability (level 3) is not necessary or even sufficient for trust, while\nthe ability to run a black-box model at-will (level 2) is necessary and\nsufficient. While interpretability can offer benefits for trust, it can also\nincur costs. We clarify ways interpretability can contribute to trust, while\nquestioning the perceived centrality of interpretability to trust in popular\ndiscourse. How can we empower people with tools to evaluate trust? Instead of\ntrying to understand how a model works, we argue for understanding how a model\nbehaves. Instead of opening up black boxes, we should create more behavior\ncertificates that are more correct, relevant, and understandable. We discuss\nhow to build trusted and trustworthy AI responsibly.",
    "descriptor": "",
    "authors": [
      "Max W. Shen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.05302"
  },
  {
    "id": "arXiv:2202.05306",
    "title": "Characterizing and overcoming the greedy nature of learning in  multi-modal deep neural networks",
    "abstract": "We hypothesize that due to the greedy nature of learning in multi-modal deep\nneural networks, these models tend to rely on just one modality while\nunder-fitting the other modalities. Such behavior is counter-intuitive and\nhurts the models' generalization, as we observe empirically. To estimate the\nmodel's dependence on each modality, we compute the gain on the accuracy when\nthe model has access to it in addition to another modality. We refer to this\ngain as the conditional utilization rate. In the experiments, we consistently\nobserve an imbalance in conditional utilization rates between modalities,\nacross multiple tasks and architectures. Since conditional utilization rate\ncannot be computed efficiently during training, we introduce a proxy for it\nbased on the pace at which the model learns from each modality, which we refer\nto as the conditional learning speed. We propose an algorithm to balance the\nconditional learning speeds between modalities during training and demonstrate\nthat it indeed addresses the issue of greedy learning. The proposed algorithm\nimproves the model's generalization on three datasets: Colored MNIST, Princeton\nModelNet40, and NVIDIA Dynamic Hand Gesture.",
    "descriptor": "",
    "authors": [
      "Nan Wu",
      "Stanis\u0142aw Jastrz\u0119bski",
      "Kyunghyun Cho",
      "Krzysztof J. Geras"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.05306"
  },
  {
    "id": "arXiv:2202.05313",
    "title": "Integrating Testing and Operation-related Quantitative Evidences in  Assurance Cases to Argue Safety of Data-Driven AI/ML Components",
    "abstract": "In the future, AI will increasingly find its way into systems that can\npotentially cause physical harm to humans. For such safety-critical systems, it\nmust be demonstrated that their residual risk does not exceed what is\nacceptable. This includes, in particular, the AI components that are part of\nsuch systems' safety-related functions. Assurance cases are an intensively\ndiscussed option today for specifying a sound and comprehensive safety argument\nto demonstrate a system's safety. In previous work, it has been suggested to\nargue safety for AI components by structuring assurance cases based on two\ncomplementary risk acceptance criteria. One of these criteria is used to derive\nquantitative targets regarding the AI. The argumentation structures commonly\nproposed to show the achievement of such quantitative targets, however, focus\non failure rates from statistical testing. Further important aspects are only\nconsidered in a qualitative manner -- if at all. In contrast, this paper\nproposes a more holistic argumentation structure for having achieved the\ntarget, namely a structure that integrates test results with runtime aspects\nand the impact of scope compliance and test data quality in a quantitative\nmanner. We elaborate different argumentation options, present the underlying\nmathematical considerations, and discuss resulting implications for their\npractical application. Using the proposed argumentation structure might not\nonly increase the integrity of assurance cases but may also allow claims on\nquantitative targets that would not be justifiable otherwise.",
    "descriptor": "\nComments: 8 pages\n",
    "authors": [
      "Michael Kl\u00e4s",
      "Lisa J\u00f6ckel",
      "Rasmus Adler",
      "Jan Reich"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2202.05313"
  },
  {
    "id": "arXiv:2202.05314",
    "title": "Mosaics of Combinatorial Designs for Semantic Security on Quantum  Wiretap Channels",
    "abstract": "We study semantic security for classical-quantum channels. Our security\nfunctions are functional forms of mosaics of combinatorial designs. We extend\nmethods for classical channels to classical-quantum channels to demonstrate\nthat mosaics of designs ensure semantic security for classical-quantum\nchannels, and are also capacity achieving coding scheme. The legitimate channel\nusers share an additional public resource, more precisely, a seed chosen\nuniformly at random. An advantage of these modular wiretap codes is that we\nprovide explicit code constructions that can be implemented in practice for\nevery channels, giving an arbitrary public code.",
    "descriptor": "",
    "authors": [
      "Holger Boche",
      "Minglai Cai",
      "Moritz Wiese"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.05314"
  },
  {
    "id": "arXiv:2202.05315",
    "title": "Audio Matters Too: How Audial Avatar Customization Enhances Visual  Avatar Customization",
    "abstract": "Avatar customization is known to positively affect crucial outcomes in\nnumerous domains. However, it is unknown whether audial customization can\nconfer the same benefits as visual customization. We conducted a preregistered\n2 x 2 (visual choice vs. visual assignment x audial choice vs. audial\nassignment) study in a Java programming game. Participants with visual choice\nexperienced higher avatar identification and autonomy. Participants with audial\nchoice experienced higher avatar identification and autonomy, but only within\nthe group of participants who had visual choice available. Visual choice led to\nan increase in time spent, and indirectly led to increases in intrinsic\nmotivation, immersion, time spent, future play motivation, and likelihood of\ngame recommendation. Audial choice moderated the majority of these effects. Our\nresults suggest that audial customization plays an important enhancing role\nvis-\\`a-vis visual customization. However, audial customization appears to have\na weaker effect compared to visual customization. We discuss the implications\nfor avatar customization more generally across digital applications.",
    "descriptor": "\nComments: 27 pages\n",
    "authors": [
      "Dominic Kao",
      "Rabindra Ratan",
      "Christos Mousas",
      "Amogh Joshi",
      "Edward F. Melcer"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2202.05315"
  },
  {
    "id": "arXiv:2202.05317",
    "title": "A Multi-task Learning Framework for Product Ranking with BERT",
    "abstract": "Product ranking is a crucial component for many e-commerce services. One of\nthe major challenges in product search is the vocabulary mismatch between query\nand products, which may be a larger vocabulary gap problem compared to other\ninformation retrieval domains. While there is a growing collection of neural\nlearning to match methods aimed specifically at overcoming this issue, they do\nnot leverage the recent advances of large language models for product search.\nOn the other hand, product ranking often deals with multiple types of\nengagement signals such as clicks, add-to-cart, and purchases, while most of\nthe existing works are focused on optimizing one single metric such as\nclick-through rate, which may suffer from data sparsity. In this work, we\npropose a novel end-to-end multi-task learning framework for product ranking\nwith BERT to address the above challenges. The proposed model utilizes\ndomain-specific BERT with fine-tuning to bridge the vocabulary gap and employs\nmulti-task learning to optimize multiple objectives simultaneously, which\nyields a general end-to-end learning framework for product search. We conduct a\nset of comprehensive experiments on a real-world e-commerce dataset and\ndemonstrate significant improvement of the proposed approach over the\nstate-of-the-art baseline methods.",
    "descriptor": "\nComments: accepted by WWW22\n",
    "authors": [
      "Xuyang Wu",
      "Alessandro Magnani",
      "Suthee Chaidaroon",
      "Ajit Puthenputhussery",
      "Ciya Liao",
      "Yi Fang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2202.05317"
  },
  {
    "id": "arXiv:2202.05324",
    "title": "Understanding the Digital News Consumption Experience During the COVID  Pandemic",
    "abstract": "During the COVID-19 pandemic, people sought information through digital news\nplatforms. To investigate how to design these platforms to support users' needs\nin a crisis, we conducted a two-week diary study with 22 participants across\nthe United States. Participants' news-consumption experience followed two\nstages: in the \\textbf{seeking} stage, participants increased their general\nconsumption, motivated by three common informational needs -- specifically, to\nfind, understand and verify relevant news pieces. Participants then moved to\nthe \\textbf{sustaining} stage, and coping with the news emotionally became as\nimportant as their informational needs. We elicited design ideas from\nparticipants and used these to distill six themes for creating digital news\nplatforms that provide better informational and emotional support during a\ncrisis. Thus, we contribute, first, a model of users' needs over time with\nrespect to engaging with crisis news, and second, example design concepts for\nsupporting users' needs in each of these stages.",
    "descriptor": "\nComments: ACM conference format\n",
    "authors": [
      "Mingrui Ray Zhang",
      "Ashley Boone",
      "Sara M Behbakht",
      "Alexis Hiniker"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2202.05324"
  },
  {
    "id": "arXiv:2202.05328",
    "title": "Forward Build Systems, Formally",
    "abstract": "Build systems are a fundamental part of software construction, but their\ncorrectness has received comparatively little attention, relative to more\nprominent parts of the toolchain. In this paper, we address the correctness of\n\\emph{forward build systems}, which automatically determine the dependency\nstructure of the build, rather than having it specified by the programmer.\nWe first define what it means for a forward build system to be correct -- it\nmust behave identically to simply executing the programmer-specified commands\nin order. Of course, realistic build systems avoid repeated work, stop early\nwhen possible, and run commands in parallel, and we prove that these\noptimizations, as embodied in the recent forward build system \\textsc{Rattle},\npreserve our definition of correctness. Along the way, we show that other\nforward build systems, such as \\textsc{Fabricate} and \\textsc{Memoize}, are\nalso correct.\nWe carry out all of our work in \\Agda, and describe in detail the assumptions\nunderlying both \\textsc{Rattle} itself and our modeling of it.",
    "descriptor": "\nComments: CPP 2022: Proceedings of the 11th ACM SIGPLAN International Conference on Certified Programs and Proofs\n",
    "authors": [
      "Sarah Spall",
      "Neil Mitchell",
      "Sam Tobin-Hochstadt"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2202.05328"
  },
  {
    "id": "arXiv:2202.05329",
    "title": "Spork: Structured Merge for Java with Formatting Preservation",
    "abstract": "The highly parallel workflows of modern software development have made\nmerging of source code a common activity for developers. The state of the\npractice is based on line-based merge, which is ubiquitously used with \"git\nmerge\". Line-based merge is however a generalized technique for any text that\ncannot leverage the structured nature of source code, making merge conflicts a\ncommon occurrence. As a remedy, research has proposed structured merge tools,\nwhich typically operate on abstract syntax trees instead of raw text.\nStructured merging greatly reduces the prevalence of merge conflicts but\nsuffers from important limitations, the main ones being a tendency to alter the\nformatting of the merged code and being prone to excessive running times. In\nthis paper, we present SPORK, a novel structured merge tool for JAVA. SPORK is\nunique as it preserves formatting to a significantly greater degree than\ncomparable state-of-the-art tools. SPORK is also overall faster than the state\nof the art, in particular significantly reducing worst-case running times in\npractice. We demonstrate these properties by replaying 1740 real-world file\nmerges collected from 119 open-source projects, and further demonstrate several\nkey differences between SPORK and the state of the art with in-depth case\nstudies.",
    "descriptor": "\nComments: 21 pages, 18 figures, 11 tables, accepted for publication in IEEE Transactions on Software Engineering\n",
    "authors": [
      "Simon Lars\u00e9n",
      "Jean-R\u00e9my Falleri",
      "Benoit Baudry",
      "Martin Monperrus"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2202.05329"
  },
  {
    "id": "arXiv:2202.05331",
    "title": "Describing image focused in cognitive and visual details for visually  impaired people: An approach to generating inclusive paragraphs",
    "abstract": "Several services for people with visual disabilities have emerged recently\ndue to achievements in Assistive Technologies and Artificial Intelligence\nareas. Despite the growth in assistive systems availability, there is a lack of\nservices that support specific tasks, such as understanding the image context\npresented in online content, e.g., webinars. Image captioning techniques and\ntheir variants are limited as Assistive Technologies as they do not match the\nneeds of visually impaired people when generating specific descriptions. We\npropose an approach for generating context of webinar images combining a dense\ncaptioning technique with a set of filters, to fit the captions in our domain,\nand a language model for the abstractive summary task. The results demonstrated\nthat we can produce descriptions with higher interpretability and focused on\nthe relevant information for that group of people by combining image analysis\nmethods and neural language models.",
    "descriptor": "\nComments: Accepted in the 17th International Joint Conference on Computer Vision, Imaging and Computer Graphics Theory and Applications (VISAPP) 2022\n",
    "authors": [
      "Daniel Louzada Fernandes",
      "Marcos Henrique Fonseca Ribeiro",
      "Fabio Ribeiro Cerqueira",
      "Michel Melo Silva"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.05331"
  },
  {
    "id": "arXiv:2202.05332",
    "title": "An Initial Description of Capabilities and Constraints for a  Computational Auditory System (an Artificial Ear) for Cognitive Architectures",
    "abstract": "We present an initial set of factors, features, and constraints for\ndeveloping a Computational Auditory System (CAS, aka less formally an\nartificial ear, AE) for use by cognitive architectures. We start to define a\nCAS and what tasks it should be able to perform. We then outline the features\nof a CAS for use by a cognitive architecture and factors that influence its\nperformance. We conclude with an update on what has been created so far and\ninsights on how to create and use a CAS in a cognitive architecture and include\na set of functionalities for an artificial ear.",
    "descriptor": "\nComments: 13 pages, 2 figures, 2 tables Keywords: computational auditory system, artificial ear, cognitive architecture\n",
    "authors": [
      "Frank E. Ritter",
      "Mathieu Brener"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2202.05332"
  },
  {
    "id": "arXiv:2202.05333",
    "title": "Factored World Models for Zero-Shot Generalization in Robotic  Manipulation",
    "abstract": "World models for environments with many objects face a combinatorial\nexplosion of states: as the number of objects increases, the number of possible\narrangements grows exponentially. In this paper, we learn to generalize over\nrobotic pick-and-place tasks using object-factored world models, which combat\nthe combinatorial explosion by ensuring that predictions are equivariant to\npermutations of objects. Previous object-factored models were limited either by\ntheir inability to model actions, or by their inability to plan for complex\nmanipulation tasks. We build on recent contrastive methods for training\nobject-factored world models, which we extend to model continuous robot actions\nand to accurately predict the physics of robotic pick-and-place. To do so, we\nuse a residual stack of graph neural networks that receive action information\nat multiple levels in both their node and edge neural networks. Crucially, our\nlearned model can make predictions about tasks not represented in the training\ndata. That is, we demonstrate successful zero-shot generalization to novel\ntasks, with only a minor decrease in model performance. Moreover, we show that\nan ensemble of our models can be used to plan for tasks involving up to 12 pick\nand place actions using heuristic search. We also demonstrate transfer to a\nphysical robot.",
    "descriptor": "",
    "authors": [
      "Ondrej Biza",
      "Thomas Kipf",
      "David Klee",
      "Robert Platt",
      "Jan-Willem van de Meent",
      "Lawson L. S. Wong"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.05333"
  },
  {
    "id": "arXiv:2202.05334",
    "title": "Learning the Pedestrian-Vehicle Interaction for Pedestrian Trajectory  Prediction",
    "abstract": "In this paper, we study the interaction between pedestrians and vehicles and\npropose a novel neural network structure called the Pedestrian-Vehicle\nInteraction (PVI) extractor for learning the pedestrian-vehicle interaction. We\nimplement the proposed PVI extractor on both sequential approaches (long\nshort-term memory (LSTM) models) and non-sequential approaches (convolutional\nmodels). We use the Waymo Open Dataset that contains real-world urban traffic\nscenes with both pedestrian and vehicle annotations. For the LSTM-based models,\nour proposed model is compared with Social-LSTM and Social-GAN, and using our\nproposed PVI extractor reduces the average displacement error (ADE) and the\nfinal displacement error (FDE) by 7.46% and 5.24%, respectively. For the\nconvolutional-based models, our proposed model is compared with Social-STGCNN\nand Social-IWSTCNN, and using our proposed PVI extractor reduces the ADE and\nFDE by 2.10% and 1.27%, respectively. The results show that the\npedestrian-vehicle interaction influences pedestrian behavior, and the models\nusing the proposed PVI extractor can capture the interaction between\npedestrians and vehicles, and thereby outperform the compared methods.",
    "descriptor": "\nComments: 7 pages, 3 figures. Accepted in 2022 the 8th International Conference on Control Automation and Robotics (ICCAR), IEEE, 2022\n",
    "authors": [
      "Chi Zhang",
      "Christian Berger"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.05334"
  },
  {
    "id": "arXiv:2202.05337",
    "title": "Neural Network Training Using Closed-Loop Data: Hazards and an  Instrumental Variable (IVNN) Solution",
    "abstract": "An increasing trend in the use of neural networks in control systems is being\nobserved. The aim of this paper is to reveal that the straightforward\napplication of learning neural network feedforward controllers with closed-loop\ndata may introduce parameter inconsistency that degrades control performance,\nand to provide a solution. The proposed method employs instrumental variables\nto ensure consistent parameter estimates. A nonlinear system example reveals\nthat the developed instrumental variable neural network (IVNN) approach\nasymptotically recovers the optimal solution, while pre-existing approaches are\nshown to lead to inconsistent estimates.",
    "descriptor": "",
    "authors": [
      "Johan Kon",
      "Marcel Heertjes",
      "Tom Oomen"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.05337"
  },
  {
    "id": "arXiv:2202.05338",
    "title": "Accountability in an Algorithmic Society: Relationality, Responsibility,  and Robustness in Machine Learning",
    "abstract": "In 1996, philosopher Helen Nissenbaum issued a clarion call concerning the\nerosion of accountability in society due to the ubiquitous delegation of\nconsequential functions to computerized systems. Using the conceptual framing\nof moral blame, Nissenbaum described four types of barriers to accountability\nthat computerization presented: 1) \"many hands,\" the problem of attributing\nmoral responsibility for outcomes caused by many moral actors; 2) \"bugs,\" a way\nsoftware developers might shrug off responsibility by suggesting software\nerrors are unavoidable; 3) \"computer as scapegoat,\" shifting blame to computer\nsystems as if they were moral actors; and 4) \"ownership without liability,\" a\nfree pass to the tech industry to deny responsibility for the software they\nproduce. We revisit these four barriers in relation to the recent ascendance of\ndata-driven algorithmic systems--technology often folded under the heading of\nmachine learning (ML) or artificial intelligence (AI)--to uncover the new\nchallenges for accountability that these systems present. We then look ahead to\nhow one might construct and justify a moral, relational framework for holding\nresponsible parties accountable, and argue that the FAccT community is uniquely\nwell-positioned to develop such a framework to weaken the four barriers.",
    "descriptor": "\nComments: Preprint\n",
    "authors": [
      "A. Feder Cooper",
      "Benjamin Laufer",
      "Emanuel Moss",
      "Helen Nissenbaum"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.05338"
  },
  {
    "id": "arXiv:2202.05343",
    "title": "Coded ResNeXt: a network for designing disentangled information paths",
    "abstract": "To avoid treating neural networks as highly complex black boxes, the deep\nlearning research community has tried to build interpretable models allowing\nhumans to understand the decisions taken by the model. Unfortunately, the focus\nis mostly on manipulating only the very high-level features associated with the\nlast layers. In this work, we look at neural network architectures for\nclassification in a more general way and introduce an algorithm which defines\nbefore the training the paths of the network through which the per-class\ninformation flows. We show that using our algorithm we can extract a lighter\nsingle-purpose binary classifier for a particular class by removing the\nparameters that do not participate in the predefined information path of that\nclass, which is approximately 60% of the total parameters. Notably, leveraging\ncoding theory to design the information paths enables us to use intermediate\nnetwork layers for making early predictions without having to evaluate the full\nnetwork. We demonstrate that a slightly modified ResNeXt model, trained with\nour algorithm, can achieve higher classification accuracy on CIFAR-10/100 and\nImageNet than the original ResNeXt, while having all the aforementioned\nproperties.",
    "descriptor": "",
    "authors": [
      "Apostolos Avranas",
      "Marios Kountouris"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.05343"
  },
  {
    "id": "arXiv:2202.05347",
    "title": "Development and Validation of an AI-Driven Model for the La Rance Tidal  Barrage: A Generalisable Case Study",
    "abstract": "In this work, an AI-Driven (autonomous) model representation of the La Rance\ntidal barrage was developed using novel parametrisation and Deep Reinforcement\nLearning (DRL) techniques. Our model results were validated with experimental\nmeasurements, yielding the first Tidal Range Structure (TRS) model validated\nagainst a constructed tidal barrage and made available to academics. In order\nto proper model La Rance, parametrisation methodologies were developed for\nsimulating (i) turbines (in pumping and power generation modes), (ii)\ntransition ramp functions (for opening and closing hydraulic structures) and\n(iii) equivalent lagoon wetted area. Furthermore, an updated DRL method was\nimplemented for optimising the operation of the hydraulic structures that\ncompose La Rance. The achieved objective of this work was to verify the\ncapabilities of an AI-Driven TRS model to appropriately predict (i) turbine\npower and (ii) lagoon water level variations. In addition, the observed\noperational strategy and yearly energy output of our AI-Driven model appeared\nto be comparable with those reported for the La Rance tidal barrage. The\noutcomes of this work (developed methodologies and DRL implementations) are\ngeneralisable and can be applied to other TRS projects. Furthermore, this work\nprovided insights which allow for more realistic simulation of TRS operation,\nenabled through our AI-Driven model.",
    "descriptor": "\nComments: 30 pages, 22 figures and 6 tables\n",
    "authors": [
      "T\u00falio Marcondes Moreira",
      "Jackson Geraldo de Faria Jr",
      "Pedro O.S. Vaz-de-Melo",
      "Gilberto Medeiros-Ribeiro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.05347"
  },
  {
    "id": "arXiv:2202.05352",
    "title": "Domain Adversarial Training: A Game Perspective",
    "abstract": "The dominant line of work in domain adaptation has focused on learning\ninvariant representations using domain-adversarial training. In this paper, we\ninterpret this approach from a game theoretical perspective. Defining optimal\nsolutions in domain-adversarial training as a local Nash equilibrium, we show\nthat gradient descent in domain-adversarial training can violate the asymptotic\nconvergence guarantees of the optimizer, oftentimes hindering the transfer\nperformance. Our analysis leads us to replace gradient descent with high-order\nODE solvers (i.e., Runge-Kutta), for which we derive asymptotic convergence\nguarantees. This family of optimizers is significantly more stable and allows\nmore aggressive learning rates, leading to high performance gains when used as\na drop-in replacement over standard optimizers. Our experiments show that in\nconjunction with state-of-the-art domain-adversarial methods, we achieve up to\n3.5% improvement with less than of half training iterations. Our optimizers are\neasy to implement, free of additional parameters, and can be plugged into any\ndomain-adversarial framework.",
    "descriptor": "\nComments: ICLR 2022\n",
    "authors": [
      "David Acuna",
      "Marc T Law",
      "Guojun Zhang",
      "Sanja Fidler"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2202.05352"
  },
  {
    "id": "arXiv:2202.05360",
    "title": "Formalized functional analysis with semilinear maps",
    "abstract": "Semilinear maps are a generalization of linear maps between vector spaces\nwhere we allow the scalar action to be twisted by a ring homomorphism such as\ncomplex conjugation. In particular, this generalization unifies the concepts of\nlinear and conjugate-linear maps. We implement this generalization in Lean's\n\\textsf{mathlib} library, along with a number of important results in\nfunctional analysis which previously were impossible to formalize properly.\nSpecifically, we prove the Fr\\'echet--Riesz representation theorem and the\nspectral theorem for compact self-adjoint operators generically over real and\ncomplex Hilbert spaces. We also show that semilinear maps have applications\nbeyond functional analysis by formalizing the one-dimensional case of a theorem\nof Dieudonn\\'e and Manin that classifies the isocrystals over an algebraically\nclosed field with positive characteristic.",
    "descriptor": "",
    "authors": [
      "Fr\u00e9d\u00e9ric Dupuis",
      "Robert Y. Lewis",
      "Heather Macbeth"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Operator Algebras (math.OA)",
      "Spectral Theory (math.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.05360"
  },
  {
    "id": "arXiv:2202.05364",
    "title": "The MeLa BitChute Dataset",
    "abstract": "In this paper we present a near-complete dataset of over 3M videos from 61K\nchannels over 2.5 years (June 2019 to December 2021) from the social video\nhosting platform BitChute, a commonly used alternative to YouTube.\nAdditionally, we include a variety of video-level metadata, including comments,\nchannel descriptions, and views for each video. The MeLa-BitChute dataset can\nbe found at:\nhttps://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/KRD1VS.",
    "descriptor": "",
    "authors": [
      "Milo Trujillo",
      "Maur\u00edcio Gruppi",
      "Cody Buntain",
      "Benjamin D. Horne"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.05364"
  },
  {
    "id": "arXiv:2202.05373",
    "title": "Adaptive Control of Distributed Energy Resources for Distribution Grid  Voltage Stability",
    "abstract": "Volt-VAR and Volt-Watt functionality in photovoltaic (PV) smart inverters\nprovide mechanisms to ensure system voltage magnitudes and power factors remain\nwithin acceptable limits. However, these control functions can become unstable,\nintroducing oscillations in system voltages when not appropriately configured\nor maliciously altered during a cyberattack. In the event that Volt-VAR and\nVolt-Watt control functions in a portion of PV smart inverters in a\ndistribution grid are unstable, the proposed adaptation scheme utilizes the\nremaining and stably-behaving PV smart inverters and other Distributed Energy\nResources to mitigate the effect of the instability. The adaptation mechanism\nis entirely decentralized, model-free, communication-free, and requires\nvirtually no external configuration. We provide a derivation of the adaptive\ncontrol approach and validate the algorithm in experiments on the IEEE 37 and\n8500 node test feeders.",
    "descriptor": "",
    "authors": [
      "Daniel Arnold",
      "Shammya Saha",
      "Sy-Toan Ngo",
      "Ciaran Roberts",
      "Anna Scaglione",
      "Nathan Johnson",
      "Sean Peisert",
      "David Pinney"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.05373"
  },
  {
    "id": "arXiv:2202.05383",
    "title": "Including Facial Expressions in Contextual Embeddings for Sign Language  Generation",
    "abstract": "State-of-the-art sign language generation frameworks lack expressivity and\nnaturalness which is the result of only focusing manual signs, neglecting the\naffective, grammatical and semantic functions of facial expressions. The\npurpose of this work is to augment semantic representation of sign language\nthrough grounding facial expressions. We study the effect of modeling the\nrelationship between text, gloss, and facial expressions on the performance of\nthe sign generation systems. In particular, we propose a Dual Encoder\nTransformer able to generate manual signs as well as facial expressions by\ncapturing the similarities and differences found in text and sign gloss\nannotation. We take into consideration the role of facial muscle activity to\nexpress intensities of manual signs by being the first to employ facial action\nunits in sign language generation. We perform a series of experiments showing\nthat our proposed model improves the quality of automatically generated sign\nlanguage.",
    "descriptor": "",
    "authors": [
      "Carla Viegas",
      "Mert \u0130nan",
      "Lorna Quandt",
      "Malihe Alikhani"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.05383"
  },
  {
    "id": "arXiv:2202.05385",
    "title": "Cyclops: Open Platform for Scale Truck Platooning",
    "abstract": "Cyclops, introduced in this paper, is an open research platform for everyone\nthat wants to validate novel ideas and approaches in the area of self-driving\nheavy-duty vehicle platooning. The platform consists of multiple 1/14 scale\nsemi-trailer trucks, a scale proving ground, and associated computing,\ncommunication and control modules that enable self-driving on the proving\nground. A perception system for each vehicle is composed of a lidar-based\nobject tracking system and a lane detection/control system. The former is to\nmaintain the gap to the leading vehicle and the latter is to maintain the\nvehicle within the lane by steering control. The lane detection system is\noptimized for truck platooning where the field of view of the front-facing\ncamera is severely limited due to a small gap to the leading vehicle. This\nplatform is particularly amenable to validate mitigation strategies for\nsafety-critical situations. Indeed, a simplex structure is adopted in the\nembedded module for testing various fail safe operations. We illustrate a\nscenario where camera sensor fails in the perception system but the vehicle\noperates at a reduced capacity to a graceful stop. Details of the Cyclops\nincluding 3D CAD designs and algorithm source codes are released for those who\nwant to build similar testbeds.",
    "descriptor": "",
    "authors": [
      "Hyeongyu Lee",
      "Jaegeun Park",
      "Changjin Koo",
      "Jong-Chan Kim",
      "Yongsoon Eun"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.05385"
  },
  {
    "id": "arXiv:2202.05387",
    "title": "TwHIN: Embedding the Twitter Heterogeneous Information Network for  Personalized Recommendation",
    "abstract": "Social networks, such as Twitter, form a heterogeneous information network\n(HIN) where nodes represent domain entities (e.g., user, content, advertiser,\netc.) and edges represent one of many entity interactions (e.g, a user\nre-sharing content or \"following\" another). Interactions from multiple relation\ntypes can encode valuable information about social network entities not fully\ncaptured by a single relation; for instance, a user's preference for accounts\nto follow may depend on both user-content engagement interactions and the other\nusers they follow. In this work, we investigate knowledge-graph embeddings for\nentities in the Twitter HIN (TwHIN); we show that these pretrained\nrepresentations yield significant offline and online improvement for a diverse\nrange of downstream recommendation and classification tasks: personalized ads\nrankings, account follow-recommendation, offensive content detection, and\nsearch ranking. We discuss design choices and practical challenges of deploying\nindustry-scale HIN embeddings, including compressing them to reduce end-to-end\nmodel latency and handling parameter drift across versions.",
    "descriptor": "",
    "authors": [
      "Ahmed El-Kishky",
      "Thomas Markovich",
      "Serim Park",
      "Chetan Verma",
      "Baekjin Kim",
      "Ramy Eskander",
      "Yury Malkov",
      "Frank Portman",
      "Sof\u00eda Samaniego",
      "Ying Xiao",
      "Aria Haghighi"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2202.05387"
  },
  {
    "id": "arXiv:2202.05395",
    "title": "Robust, Deep, and Reinforcement Learning for Management of Communication  and Power Networks",
    "abstract": "This thesis develops data-driven machine learning algorithms to managing and\noptimizing the next-generation highly complex cyberphysical systems, which\ndesperately need ground-breaking control, monitoring, and decision making\nschemes that can guarantee robustness, scalability, and situational awareness.\nThe present thesis first develops principled methods to make generic machine\nlearning models robust against distributional uncertainties and adversarial\ndata. Particular focus will be on parametric models where some training data\nare being used to learn a parametric model. The developed framework is of high\ninterest especially when training and testing data are drawn from \"slightly\"\ndifferent distribution. We then introduce distributionally robust learning\nframeworks to minimize the worst-case expected loss over a prescribed ambiguity\nset of training distributions quantified via Wasserstein distance. Later, we\nbuild on this robust framework to design robust semi-supervised learning over\ngraph methods. The second part of this thesis aspires to fully unleash the\npotential of next-generation wired and wireless networks, where we design\n\"smart\" network entities using (deep) reinforcement learning approaches.\nFinally, this thesis enhances the power system operation and control. Our\ncontribution is on sustainable distribution grids with high penetration of\nrenewable sources and demand response programs. To account for unanticipated\nand rapidly changing renewable generation and load consumption scenarios, we\nspecifically delegate reactive power compensation to both utility-owned control\ndevices (e.g., capacitor banks), as well as smart inverters of distributed\ngeneration units with cyber-capabilities.",
    "descriptor": "\nComments: PhD thesis\n",
    "authors": [
      "Alireza Sadeghi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.05395"
  },
  {
    "id": "arXiv:2202.05400",
    "title": "PARSE: Pairwise Alignment of Representations in Semi-Supervised EEG  Learning for Emotion Recognition",
    "abstract": "We propose PARSE, a novel semi-supervised architecture for learning strong\nEEG representations for emotion recognition. To reduce the potential\ndistribution mismatch between the large amounts of unlabeled data and the\nlimited amount of labeled data, PARSE uses pairwise representation alignment.\nFirst, our model performs data augmentation followed by label guessing for\nlarge amounts of original and augmented unlabeled data. This is then followed\nby sharpening of the guessed labels and convex combinations of the unlabeled\nand labeled data. Finally, representation alignment and emotion classification\nare performed. To rigorously test our model, we compare PARSE to several\nstate-of-the-art semi-supervised approaches which we implement and adapt for\nEEG learning. We perform these experiments on four public EEG-based emotion\nrecognition datasets, SEED, SEED-IV, SEED-V and AMIGOS (valence and arousal).\nThe experiments show that our proposed framework achieves the overall best\nresults with varying amounts of limited labeled samples in SEED, SEED-IV and\nAMIGOS (valence), while approaching the overall best result (reaching the\nsecond-best) in SEED-V and AMIGOS (arousal). The analysis shows that our\npairwise representation alignment considerably improves the performance by\nreducing the distribution alignment between unlabeled and labeled data,\nespecially when only 1 sample per class is labeled.",
    "descriptor": "",
    "authors": [
      "Guangyi Zhang",
      "Ali Etemad"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.05400"
  },
  {
    "id": "arXiv:2202.05402",
    "title": "Do People Engage Cognitively with AI? Impact of AI Assistance on  Incidental Learning",
    "abstract": "When people receive advice while making difficult decisions, they often make\nbetter decisions in the moment and also increase their knowledge in the\nprocess. However, such incidental learning can only occur when people\ncognitively engage with the information they receive and process this\ninformation thoughtfully. How do people process the information and advice they\nreceive from AI, and do they engage with it deeply enough to enable learning?\nTo answer these questions, we conducted three experiments in which individuals\nwere asked to make nutritional decisions and received simulated AI\nrecommendations and explanations. In the first experiment, we found that when\npeople were presented with both a recommendation and an explanation before\nmaking their choice, they made better decisions than they did when they\nreceived no such help, but they did not learn. In the second experiment,\nparticipants first made their own choice, and only then saw a recommendation\nand an explanation from AI; this condition also resulted in improved decisions,\nbut no learning. However, in our third experiment, participants were presented\nwith just an AI explanation but no recommendation and had to arrive at their\nown decision. This condition led to both more accurate decisions and learning\ngains. We hypothesize that learning gains in this condition were due to deeper\nengagement with explanations needed to arrive at the decisions. This work\nprovides some of the most direct evidence to date that it may not be sufficient\nto include explanations together with AI-generated recommendation to ensure\nthat people engage carefully with the AI-provided information. This work also\npresents one technique that enables incidental learning and, by implication,\ncan help people process AI recommendations and explanations more carefully.",
    "descriptor": "\nComments: 13 pages, 6 figures, to appear in ACM IUI'22\n",
    "authors": [
      "Krzysztof Z. Gajos",
      "Lena Mamykina"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.05402"
  },
  {
    "id": "arXiv:2202.05403",
    "title": "Learning Temporal Rules from Noisy Timeseries Data",
    "abstract": "Events across a timeline are a common data representation, seen in different\ntemporal modalities. Individual atomic events can occur in a certain temporal\nordering to compose higher level composite events. Examples of a composite\nevent are a patient's medical symptom or a baseball player hitting a home run,\ncaused distinct temporal orderings of patient vitals and player movements\nrespectively. Such salient composite events are provided as labels in temporal\ndatasets and most works optimize models to predict these composite event labels\ndirectly. We focus on uncovering the underlying atomic events and their\nrelations that lead to the composite events within a noisy temporal data\nsetting. We propose Neural Temporal Logic Programming (Neural TLP) which first\nlearns implicit temporal relations between atomic events and then lifts logic\nrules for composite events, given only the composite events labels for\nsupervision. This is done through efficiently searching through the\ncombinatorial space of all temporal logic rules in an end-to-end differentiable\nmanner. We evaluate our method on video and healthcare datasets where it\noutperforms the baseline methods for rule discovery.",
    "descriptor": "\nComments: 19 pages, 5 figures\n",
    "authors": [
      "Karan Samel",
      "Zelin Zhao",
      "Binghong Chen",
      "Shuang Li",
      "Dharmashankar Subramanian",
      "Irfan Essa",
      "Le Song"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.05403"
  },
  {
    "id": "arXiv:2202.05404",
    "title": "Regularized Q-learning",
    "abstract": "Q-learning is widely used algorithm in reinforcement learning community.\nUnder the lookup table setting, its convergence is well established. However,\nits behavior is known to be unstable with the linear function approximation\ncase. This paper develops a new Q-learning algorithm that converges when linear\nfunction approximation is used. We prove that simply adding an appropriate\nregularization term ensures convergence of the algorithm. We prove its\nstability using a recent analysis tool based on switching system models.\nMoreover, we experimentally show that it converges in environments where\nQ-learning with linear function approximation has known to diverge. We also\nprovide an error bound on the solution where the algorithm converges.",
    "descriptor": "",
    "authors": [
      "Han-Dong Lim",
      "Do Wan Kim",
      "Donghwan Lee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.05404"
  },
  {
    "id": "arXiv:2202.05411",
    "title": "Incremental Learning of Structured Memory via Closed-Loop Transcription",
    "abstract": "This work proposes a minimal computational model for learning a structured\nmemory of multiple object classes in an incremental setting. Our approach is\nbased on establishing a closed-loop transcription between multiple classes and\ntheir corresponding subspaces, known as a linear discriminative representation,\nin a low-dimensional feature space. Our method is both simpler and more\nefficient than existing approaches to incremental learning, in terms of model\nsize, storage, and computation: it requires only a single, fixed-capacity\nautoencoding network with a feature space that is used for both discriminative\nand generative purposes. All network parameters are optimized simultaneously\nwithout architectural manipulations, by solving a constrained minimax game\nbetween the encoding and decoding maps over a single rate reduction-based\nobjective. Experimental results show that our method can effectively alleviate\ncatastrophic forgetting, achieving significantly better performance than prior\nwork for both generative and discriminative purposes.",
    "descriptor": "\nComments: 13 pages\n",
    "authors": [
      "Shengbang Tong",
      "Xili Dai",
      "Ziyang Wu",
      "Mingyang Li",
      "Brent Yi",
      "Yi Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.05411"
  },
  {
    "id": "arXiv:2202.05412",
    "title": "Checking Continuous Stochastic Logic against Quantum Continuous-Time  Markov Chains",
    "abstract": "Verifying quantum systems has attracted a lot of interest in the last\ndecades. In this paper, we study the quantitative model-checking of quantum\ncontinuous-time Markov chains (quantum CTMCs). The branching-time properties of\nquantum CTMCs are specified by continuous stochastic logic (CSL), which is\nfamous for verifying real-time systems, including classical CTMCs. The core of\nchecking the CSL formulas lies in tackling multiphase until formulas. We\ndevelop an algebraic method using proper projection, matrix exponentiation, and\ndefinite integration to symbolically calculate the probability measures of path\nformulas. Thus the decidability of CSL is established. To be efficient,\nnumerical methods are incorporated to guarantee that the time complexity is\npolynomial in the encoding size of the input model and linear in the size of\nthe input formula. A running example of Apollonian networks is further provided\nto demonstrate our method.",
    "descriptor": "",
    "authors": [
      "Jingyi Mei",
      "Ming Xu",
      "Ji Guan",
      "Yuxin Deng",
      "Nengkun Yu"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2202.05412"
  },
  {
    "id": "arXiv:2202.05413",
    "title": "A Machine-Learning-Aided Visual Analysis Workflow for Investigating Air  Pollution Data",
    "abstract": "Analyzing air pollution data is challenging as there are various analysis\nfocuses from different aspects: feature (what), space (where), and time (when).\nAs in most geospatial analysis problems, besides high-dimensional features, the\ntemporal and spatial dependencies of air pollution induce the complexity of\nperforming analysis. Machine learning methods, such as dimensionality\nreduction, can extract and summarize important information of the data to lift\nthe burden of understanding such a complicated environment. In this paper, we\npresent a methodology that utilizes multiple machine learning methods to\nuniformly explore these aspects. With this methodology, we develop a visual\nanalytic system that supports a flexible analysis workflow, allowing domain\nexperts to freely explore different aspects based on their analysis needs. We\ndemonstrate the capability of our system and analysis workflow supporting a\nvariety of analysis tasks with multiple use cases.",
    "descriptor": "\nComments: To appear in the Proceedings of IEEE PacificVis 2022\n",
    "authors": [
      "Yun-Hsin Kuo",
      "Takanori Fujiwara",
      "Charles C.-K. Chou",
      "Chun-houh Chen",
      "Kwan-Liu Ma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.05413"
  },
  {
    "id": "arXiv:2202.05416",
    "title": "FAAG: Fast Adversarial Audio Generation through Interactive Attack  Optimisation",
    "abstract": "Automatic Speech Recognition services (ASRs) inherit deep neural networks'\nvulnerabilities like crafted adversarial examples. Existing methods often\nsuffer from low efficiency because the target phases are added to the entire\naudio sample, resulting in high demand for computational resources. This paper\nproposes a novel scheme named FAAG as an iterative optimization-based method to\ngenerate targeted adversarial examples quickly. By injecting the noise over the\nbeginning part of the audio, FAAG generates adversarial audio in high quality\nwith a high success rate timely. Specifically, we use audio's logits output to\nmap each character in the transcription to an approximate position of the\naudio's frame. Thus, an adversarial example can be generated by FAAG in\napproximately two minutes using CPUs only and around ten seconds with one GPU\nwhile maintaining an average success rate over 85%. Specifically, the FAAG\nmethod can speed up around 60% compared with the baseline method during the\nadversarial example generation process. Furthermore, we found that appending\nbenign audio to any suspicious examples can effectively defend against the\ntargeted adversarial attack. We hope that this work paves the way for inventing\nnew adversarial attacks against speech recognition with computational\nconstraints.",
    "descriptor": "",
    "authors": [
      "Yuantian Miao",
      "Chao Chen",
      "Lei Pan",
      "Jun Zhang",
      "Yang Xiang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Cryptography and Security (cs.CR)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2202.05416"
  },
  {
    "id": "arXiv:2202.05420",
    "title": "A Characterization of Semi-Supervised Adversarially-Robust PAC  Learnability",
    "abstract": "We study the problem of semi-supervised learning of an adversarially-robust\npredictor in the PAC model, where the learner has access to both labeled and\nunlabeled examples. The sample complexity in semi-supervised learning has two\nparameters, the number of labeled examples and the number of unlabeled\nexamples. We consider the complexity measures, $VC_U \\leq dim_U \\leq VC$ and\n$VC^*$, where $VC$ is the standard $VC$-dimension, $VC^*$ is its dual, and the\nother two measures appeared in Montasser et al. (2019). The best sample bound\nknown for robust supervised PAC learning is $O(VC \\cdot VC^*)$, and we will\ncompare our sample bounds to $\\Lambda$ which is the minimal number of labeled\nexamples required by any robust supervised PAC learning algorithm. Our main\nresults are the following: (1) in the realizable setting it is sufficient to\nhave $O(VC_U)$ labeled examples and $O(\\Lambda)$ unlabeled examples. (2) In the\nagnostic setting, let $\\eta$ be the minimal agnostic error. The sample\ncomplexity depends on the resulting error rate. If we allow an error of\n$2\\eta+\\epsilon$, it is still sufficient to have $O(VC_U)$ labeled examples and\n$O(\\Lambda)$ unlabeled examples. If we insist on having an error\n$\\eta+\\epsilon$ then $\\Omega(dim_U)$ labeled examples are necessary, as in the\nsupervised case. The above results show that there is a significant benefit in\nsemi-supervised robust learning, as there are hypothesis classes with $VC_U=0$\nand $dim_U$ arbitrary large. In supervised learning, having access only to\nlabeled examples requires at least $\\Lambda \\geq dim_U$ labeled examples.\nSemi-supervised require only $O(1)$ labeled examples and $O(\\Lambda)$ unlabeled\nexamples. A byproduct of our result is that if we assume that the distribution\nis robustly realizable by a hypothesis class, then with respect to the 0-1 loss\nwe can learn with only $O(VC_U)$ labeled examples, even if the $VC$ is\ninfinite.",
    "descriptor": "",
    "authors": [
      "Idan Attias",
      "Steve Hanneke",
      "Yishay Mansour"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.05420"
  },
  {
    "id": "arXiv:2202.05423",
    "title": "Understanding Curriculum Learning in Policy Optimization for Solving  Combinatorial Optimization Problems",
    "abstract": "Over the recent years, reinforcement learning (RL) has shown impressive\nperformance in finding strategic solutions for game environments, and recently\nstarts to show promising results in solving combinatorial optimization (CO)\nproblems, inparticular when coupled with curriculum learning to facilitate\ntraining. Despite emerging empirical evidence, theoretical study on why RL\nhelps is still at its early stage. This paper presents the first systematic\nstudy on policy optimization methods for solving CO problems. We show that CO\nproblems can be naturally formulated as latent Markov Decision Processes\n(LMDPs), and prove convergence bounds on natural policy gradient (NPG) for\nsolving LMDPs. Furthermore, our theory explains the benefit of curriculum\nlearning: it can find a strong sampling policy and reduce the distribution\nshift, a critical quantity that governs the convergence rate in our theorem.\nFor a canonical combinatorial problem, Secretary Problem, we formally prove\nthat distribution shift is reduced exponentially with curriculum learning. Our\ntheory also shows we can simplify the curriculum learning scheme used in prior\nwork from multi-step to single-step. Lastly, we provide extensive experiments\non Secretary Problem and Online Knapsack to empirically verify our findings.",
    "descriptor": "\nComments: 28 pages, 8 figures\n",
    "authors": [
      "Runlong Zhou",
      "Yuandong Tian",
      "Yi Wu",
      "Simon S. Du"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.05423"
  },
  {
    "id": "arXiv:2202.05430",
    "title": "Wind power ramp prediction algorithm based on wavelet deep belief  network",
    "abstract": "The wind power ramp events threaten the power grid safety significantly. To\nimprove the ramp prediction accuracy, a hybrid wavelet deep belief network\nalgorithm with adaptive feature selection (WDBNAFS) is proposed. First, the\nwind power characteristic is analyzed. Then, wavelet decomposition is addressed\nto the time series, and an adaptive feature selection algorithm is proposed to\nselect the inputs of the prediction model. Finally, a deep belief network is\nemployed to predict the wind power ramp event, and the proposed WDBNAFS was\ntestified with the experiments based on the practical data. The simulation\nresults demonstrate that the prediction accuracy of the proposed algorithm is\nmore than 90%.",
    "descriptor": "\nComments: in Chinese language\n",
    "authors": [
      "Zhenhao Tang",
      "Qingyu Meng",
      "Shengxian Cao",
      "Yang Li",
      "Zhongha Mu",
      "Xiaoya Pang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.05430"
  },
  {
    "id": "arXiv:2202.05433",
    "title": "A Survey on Programmatic Weak Supervision",
    "abstract": "Labeling training data has become one of the major roadblocks to using\nmachine learning. Among various weak supervision paradigms, programmatic weak\nsupervision (PWS) has achieved remarkable success in easing the manual labeling\nbottleneck by programmatically synthesizing training labels from multiple\npotentially noisy supervision sources. This paper presents a comprehensive\nsurvey of recent advances in PWS. In particular, we give a brief introduction\nof the PWS learning paradigm, and review representative approaches for each\ncomponent within PWS's learning workflow. In addition, we discuss complementary\nlearning paradigms for tackling limited labeled data scenarios and how these\nrelated approaches can be used in conjunction with PWS. Finally, we identify\nseveral critical challenges that remain under-explored in the area to hopefully\ninspire future research directions in the field.",
    "descriptor": "\nComments: 8 pages\n",
    "authors": [
      "Jieyu Zhang",
      "Cheng-Yu Hsieh",
      "Yue Yu",
      "Chao Zhang",
      "Alexander Ratner"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2202.05433"
  },
  {
    "id": "arXiv:2202.05435",
    "title": "Dual Task Framework for Debiasing Persona-grounded Dialogue Dataset",
    "abstract": "This paper introduces a simple yet effective data-centric approach for the\ntask of improving persona-conditioned dialogue agents. Prior model-centric\napproaches unquestioningly depend on the raw crowdsourced benchmark datasets\nsuch as Persona-Chat. In contrast, we aim to fix annotation artifacts in\nbenchmarking, which is orthogonally applicable to any dialogue model.\nSpecifically, we augment relevant personas to improve dialogue dataset/agent,\nby leveraging the primal-dual structure of the two tasks, predicting dialogue\nresponses and personas based on each other. Experiments on Persona-Chat show\nthat our approach outperforms pre-trained LMs by an 11.7 point gain in terms of\naccuracy.",
    "descriptor": "\nComments: Accepted to AAAI2022\n",
    "authors": [
      "Minju Kim",
      "Beong-woo Kwak",
      "Youngwook Kim",
      "Hong-in Lee",
      "Seung-won Hwang",
      "Jinyoung Yeo"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.05435"
  },
  {
    "id": "arXiv:2202.05436",
    "title": "Minimax Regret Optimization for Robust Machine Learning under  Distribution Shift",
    "abstract": "In this paper, we consider learning scenarios where the learned model is\nevaluated under an unknown test distribution which potentially differs from the\ntraining distribution (i.e. distribution shift). The learner has access to a\nfamily of weight functions such that the test distribution is a reweighting of\nthe training distribution under one of these functions, a setting typically\nstudied under the name of Distributionally Robust Optimization (DRO). We\nconsider the problem of deriving regret bounds in the classical learning theory\nsetting, and require that the resulting regret bounds hold uniformly for all\npotential test distributions. We show that the DRO formulation does not\nguarantee uniformly small regret under distribution shift. We instead propose\nan alternative method called Minimax Regret Optimization (MRO), and show that\nunder suitable conditions this method achieves uniformly low regret across all\ntest distributions. We also adapt our technique to have stronger guarantees\nwhen the test distributions are heterogeneous in their similarity to the\ntraining data. Given the widespead optimization of worst case risks in current\napproaches to robust machine learning, we believe that MRO can be a strong\nalternative to address distribution shift scenarios.",
    "descriptor": "",
    "authors": [
      "Alekh Agarwal",
      "Tong Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.05436"
  },
  {
    "id": "arXiv:2202.05439",
    "title": "Determination the Solution of a Stochastic Parabolic Equation by the  Terminal Value",
    "abstract": "This paper studies the inverse problem of determination the history for a\nstochastic diffusion process, by means of the value at the final time $T$. By\nestablishing a new Carleman estimate, the conditional stability of the problem\nis proven. Based on the idea of Tikhonov method, a regularized solution is\nproposed. The analysis of the existence and uniqueness of the regularized\nsolution, and proof for error estimate under an a-proior assumption are\npresent. Numerical verification of the regularization, including numerical\nalgorithm and examples are also illustrated.",
    "descriptor": "",
    "authors": [
      "Fangfang Dou",
      "Wanli Du"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.05439"
  },
  {
    "id": "arXiv:2202.05441",
    "title": "Invariance Principle Meets Out-of-Distribution Generalization on Graphs",
    "abstract": "Despite recent developments in using the invariance principle from causality\nto enable out-of-distribution (OOD) generalization on Euclidean data, e.g.,\nimages, studies on graph data are limited. Different from images, the complex\nnature of graphs poses unique challenges that thwart the adoption of the\ninvariance principle for OOD generalization. In particular, distribution shifts\non graphs can happen at both structure-level and attribute-level, which\nincreases the difficulty of capturing the invariance. Moreover, domain or\nenvironment partitions, which are often required by OOD methods developed on\nEuclidean data, can be expensive to obtain for graphs. Aiming to bridge this\ngap, we characterize distribution shifts on graphs with causal models, and show\nthat the OOD generalization on graphs with invariance principle is possible by\nidentifying an invariant subgraph for making predictions. We propose a novel\nframework to explicitly model this process using a contrastive strategy. By\ncontrasting the estimated invariant subgraphs, our framework can provably\nidentify the underlying invariant subgraph under mild assumptions. Experiments\nacross several synthetic and real-world datasets demonstrate the\nstate-of-the-art OOD generalization ability of our method.",
    "descriptor": "\nComments: A preprint version\n",
    "authors": [
      "Yongqiang Chen",
      "Yonggang Zhang",
      "Han Yang",
      "Kaili Ma",
      "Binghui Xie",
      "Tongliang Liu",
      "Bo Han",
      "James Cheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.05441"
  },
  {
    "id": "arXiv:2202.05444",
    "title": "Computational-Statistical Gaps in Reinforcement Learning",
    "abstract": "Reinforcement learning with function approximation has recently achieved\ntremendous results in applications with large state spaces. This empirical\nsuccess has motivated a growing body of theoretical work proposing necessary\nand sufficient conditions under which efficient reinforcement learning is\npossible. From this line of work, a remarkably simple minimal sufficient\ncondition has emerged for sample efficient reinforcement learning: MDPs with\noptimal value function $V^*$ and $Q^*$ linear in some known low-dimensional\nfeatures. In this setting, recent works have designed sample efficient\nalgorithms which require a number of samples polynomial in the feature\ndimension and independent of the size of state space. They however leave\nfinding computationally efficient algorithms as future work and this is\nconsidered a major open problem in the community.\nIn this work, we make progress on this open problem by presenting the first\ncomputational lower bound for RL with linear function approximation: unless\nNP=RP, no randomized polynomial time algorithm exists for deterministic\ntransition MDPs with a constant number of actions and linear optimal value\nfunctions. To prove this, we show a reduction from Unique-Sat, where we convert\na CNF formula into an MDP with deterministic transitions, constant number of\nactions and low dimensional linear optimal value functions. This result also\nexhibits the first computational-statistical gap in reinforcement learning with\nlinear function approximation, as the underlying statistical problem is\ninformation-theoretically solvable with a polynomial number of queries, but no\ncomputationally efficient algorithm exists unless NP=RP. Finally, we also prove\na quasi-polynomial time lower bound under the Randomized Exponential Time\nHypothesis.",
    "descriptor": "",
    "authors": [
      "Daniel Kane",
      "Sihan Liu",
      "Shachar Lovett",
      "Gaurav Mahajan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computational Complexity (cs.CC)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.05444"
  },
  {
    "id": "arXiv:2202.05446",
    "title": "Faster No-Regret Learning Dynamics for Extensive-Form Correlated and  Coarse Correlated Equilibria",
    "abstract": "A recent emerging trend in the literature on learning in games has been\nconcerned with providing faster learning dynamics for correlated and coarse\ncorrelated equilibria in normal-form games. Much less is known about the\nsignificantly more challenging setting of extensive-form games, which can\ncapture both sequential and simultaneous moves, as well as imperfect\ninformation. In this paper we establish faster no-regret learning dynamics for\n\\textit{extensive-form correlated equilibria (EFCE)} in multiplayer general-sum\nimperfect-information extensive-form games. When all players follow our\naccelerated dynamics, the correlated distribution of play is an\n$O(T^{-3/4})$-approximate EFCE, where the $O(\\cdot)$ notation suppresses\nparameters polynomial in the description of the game. This significantly\nimproves over the best prior rate of $O(T^{-1/2})$. To achieve this, we develop\na framework for performing accelerated \\emph{Phi-regret minimization} via\npredictions. One of our key technical contributions -- that enables us to\nemploy our generic template -- is to characterize the stability of fixed points\nassociated with \\emph{trigger deviation functions} through a refined\nperturbation analysis of a structured Markov chain. Furthermore, for the\nsimpler solution concept of extensive-form \\emph{coarse} correlated equilibrium\n(EFCCE) we give a new succinct closed-form characterization of the associated\nfixed points, bypassing the expensive computation of stationary distributions\nrequired for EFCE. Our results place EFCCE closer to \\emph{normal-form coarse\ncorrelated equilibria} in terms of the per-iteration complexity, although the\nformer prescribes a much more compelling notion of correlation. Finally,\nexperiments conducted on standard benchmarks corroborate our theoretical\nfindings.",
    "descriptor": "\nComments: Preliminary parts of this paper will appear at the AAAI-22 Workshop on Reinforcement Learning in Games. This version also contains results from an earlier preprint published by a subset of the authors (arXiv:2109.08138)\n",
    "authors": [
      "Ioannis Anagnostides",
      "Gabriele Farina",
      "Christian Kroer",
      "Andrea Celli",
      "Tuomas Sandholm"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2202.05446"
  },
  {
    "id": "arXiv:2202.05447",
    "title": "PSACCF: Prioritized Online Slice Admission Control Considering Fairness  in 5G/B5G Networks",
    "abstract": "5G/B5G is envisioned to support various services with the assistance of\nnetwork slices, each slice instance asks for adequate resources to provide the\npre-negotiated service quality to its subscribers. Slice Admission Control\n(SAC) algorithm is a necessity for Slice Providers (SPs) to guarantee the QoS\nof each admitted request. Except for resource restrictions, more factors need\nto be considered in the sliced environment during the admission process, such\nas priority and fairness. The former relates to the innate characteristics of\ndifferent services, while the latter matters because slices are instantiated on\nthe shared physical equipments. In this paper, we investigate the SAC problem\nin 5G/B5G networks, taking priority and fairness into account simultaneously.\nReinterpretation of the two intuitively conflicting concepts are proposed in\nadvance to cope with this special scenario, then an online SAC algorithm called\nPrioritized Slice Admission Control Considering Fairness, PSACCF in short, is\ndesigned to help maintaining priority and achieving an adjustable degree of\nfairness under the assumption of rational service subscribers. Numerous\nsimulations are carried out and the results show that PSACCF can effectively\nenhance the fairness indicator without compromising the priority requirement,\nand exhibits stronger stability and adaptability over existing policies.",
    "descriptor": "",
    "authors": [
      "Miao Dai",
      "Long Luo",
      "Jing Ren",
      "Hongfang Yu",
      "Gang Sun"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2202.05447"
  },
  {
    "id": "arXiv:2202.05448",
    "title": "Achieving Minimax Rates in Pool-Based Batch Active Learning",
    "abstract": "We consider a batch active learning scenario where the learner adaptively\nissues batches of points to a labeling oracle. Sampling labels in batches is\nhighly desirable in practice due to the smaller number of interactive rounds\nwith the labeling oracle (often human beings). However, batch active learning\ntypically pays the price of a reduced adaptivity, leading to suboptimal\nresults. In this paper we propose a solution which requires a careful trade off\nbetween the informativeness of the queried points and their diversity. We\ntheoretically investigate batch active learning in the practically relevant\nscenario where the unlabeled pool of data is available beforehand (pool-based\nactive learning). We analyze a novel stage-wise greedy algorithm and show that,\nas a function of the label complexity, the excess risk of this algorithm\noperating in the realizable setting for which we prove matches the known\nminimax rates in standard statistical learning settings. Our results also\nexhibit a mild dependence on the batch size. These are the first theoretical\nresults that employ careful trade offs between informativeness and diversity to\nrigorously quantify the statistical performance of batch active learning in the\npool-based scenario.",
    "descriptor": "",
    "authors": [
      "Claudio Gentile",
      "Zhilei Wang",
      "Tong Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.05448"
  },
  {
    "id": "arXiv:2202.05451",
    "title": "ACORT: A Compact Object Relation Transformer for Parameter Efficient  Image Captioning",
    "abstract": "Recent research that applies Transformer-based architectures to image\ncaptioning has resulted in state-of-the-art image captioning performance,\ncapitalising on the success of Transformers on natural language tasks.\nUnfortunately, though these models work well, one major flaw is their large\nmodel sizes. To this end, we present three parameter reduction methods for\nimage captioning Transformers: Radix Encoding, cross-layer parameter sharing,\nand attention parameter sharing. By combining these methods, our proposed ACORT\nmodels have 3.7x to 21.6x fewer parameters than the baseline model without\ncompromising test performance. Results on the MS-COCO dataset demonstrate that\nour ACORT models are competitive against baselines and SOTA approaches, with\nCIDEr score >=126. Finally, we present qualitative results and ablation studies\nto demonstrate the efficacy of the proposed changes further. Code and\npre-trained models are publicly available at\nhttps://github.com/jiahuei/sparse-image-captioning.",
    "descriptor": "\nComments: Neurocomputing; In Press\n",
    "authors": [
      "Jia Huei Tan",
      "Ying Hua Tan",
      "Chee Seng Chan",
      "Joon Huang Chuah"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.05451"
  },
  {
    "id": "arXiv:2202.05453",
    "title": "Robust estimation algorithms don't need to know the corruption level",
    "abstract": "Real data are rarely pure. Hence the past half-century has seen great\ninterest in robust estimation algorithms that perform well even when part of\nthe data is corrupt. However, their vast majority approach optimal accuracy\nonly when given a tight upper bound on the fraction of corrupt data. Such\nbounds are not available in practice, resulting in weak guarantees and often\npoor performance. This brief note abstracts the complex and pervasive\nrobustness problem into a simple geometric puzzle. It then applies the puzzle's\nsolution to derive a universal meta technique that converts any robust\nestimation algorithm requiring a tight corruption-level upper bound to achieve\nits optimal accuracy into one achieving essentially the same accuracy without\nusing any upper bounds.",
    "descriptor": "",
    "authors": [
      "Ayush Jain",
      "Alon Orlitsky",
      "Vaishakh Ravindrakumar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.05453"
  },
  {
    "id": "arXiv:2202.05456",
    "title": "NEAT: A Label Noise-resistant Complementary Item Recommender System with  Trustworthy Evaluation",
    "abstract": "The complementary item recommender system (CIRS) recommends the complementary\nitems for a given query item. Existing CIRS models consider the item\nco-purchase signal as a proxy of the complementary relationship due to the lack\nof human-curated labels from the huge transaction records. These methods\nrepresent items in a complementary embedding space and model the complementary\nrelationship as a point estimation of the similarity between items vectors.\nHowever, co-purchased items are not necessarily complementary to each other.\nFor example, customers may frequently purchase bananas and bottled water within\nthe same transaction, but these two items are not complementary. Hence, using\nco-purchase signals directly as labels will aggravate the model performance. On\nthe other hand, the model evaluation will not be trustworthy if the labels for\nevaluation are not reflecting the true complementary relatedness. To address\nthe above challenges from noisy labeling of the copurchase data, we model the\nco-purchases of two items as a Gaussian distribution, where the mean denotes\nthe co-purchases from the complementary relatedness, and covariance denotes the\nco-purchases from the noise. To do so, we represent each item as a Gaussian\nembedding and parameterize the Gaussian distribution of co-purchases by the\nmeans and covariances from item Gaussian embedding. To reduce the impact of the\nnoisy labels during evaluation, we propose an independence test-based method to\ngenerate a trustworthy label set with certain confidence. Our extensive\nexperiments on both the publicly available dataset and the large-scale\nreal-world dataset justify the effectiveness of our proposed model in\ncomplementary item recommendations compared with the state-of-the-art models.",
    "descriptor": "\nComments: 11 pages, 4 figures; Published in: 2021 IEEE International Conference on Big Data (Big Data)\n",
    "authors": [
      "Luyi Ma",
      "Jianpeng Xu",
      "Jason H.D. Cho",
      "Evren Korpeoglu",
      "Sushant Kumar",
      "Kannan Achan"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2202.05456"
  },
  {
    "id": "arXiv:2202.05457",
    "title": "Hindi/Bengali Sentiment Analysis Using Transfer Learning and Joint Dual  Input Learning with Self Attention",
    "abstract": "Sentiment Analysis typically refers to using natural language processing,\ntext analysis and computational linguistics to extract affect and emotion based\ninformation from text data. Our work explores how we can effectively use deep\nneural networks in transfer learning and joint dual input learning settings to\neffectively classify sentiments and detect hate speech in Hindi and Bengali\ndata. We start by training Word2Vec word embeddings for Hindi \\textbf{HASOC\ndataset} and Bengali hate speech and then train LSTM and subsequently, employ\nparameter sharing based transfer learning to Bengali sentiment classifiers by\nreusing and fine-tuning the trained weights of Hindi classifiers with both\nclassifier being used as baseline in our study. Finally, we use BiLSTM with\nself attention in joint dual input learning setting where we train a single\nneural network on Hindi and Bengali dataset simultaneously using their\nrespective embeddings.",
    "descriptor": "",
    "authors": [
      "Shahrukh Khan",
      "Mahnoor Shahid"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.05457"
  },
  {
    "id": "arXiv:2202.05458",
    "title": "Conditional Contrastive Learning with Kernel",
    "abstract": "Conditional contrastive learning frameworks consider the conditional sampling\nprocedure that constructs positive or negative data pairs conditioned on\nspecific variables. Fair contrastive learning constructs negative pairs, for\nexample, from the same gender (conditioning on sensitive information), which in\nturn reduces undesirable information from the learned representations; weakly\nsupervised contrastive learning constructs positive pairs with similar\nannotative attributes (conditioning on auxiliary information), which in turn\nare incorporated into the representations. Although conditional contrastive\nlearning enables many applications, the conditional sampling procedure can be\nchallenging if we cannot obtain sufficient data pairs for some values of the\nconditioning variable. This paper presents Conditional Contrastive Learning\nwith Kernel (CCL-K) that converts existing conditional contrastive objectives\ninto alternative forms that mitigate the insufficient data problem. Instead of\nsampling data according to the value of the conditioning variable, CCL-K uses\nthe Kernel Conditional Embedding Operator that samples data from all available\ndata and assigns weights to each sampled data given the kernel similarity\nbetween the values of the conditioning variable. We conduct experiments using\nweakly supervised, fair, and hard negatives contrastive learning, showing CCL-K\noutperforms state-of-the-art baselines.",
    "descriptor": "",
    "authors": [
      "Yao-Hung Hubert Tsai",
      "Tianqin Li",
      "Martin Q. Ma",
      "Han Zhao",
      "Kun Zhang",
      "Louis-Philippe Morency",
      "Ruslan Salakhutdinov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.05458"
  },
  {
    "id": "arXiv:2202.05460",
    "title": "Reduced order modeling with Barlow Twins self-supervised learning:  Navigating the space between linear and nonlinear solution manifolds",
    "abstract": "We propose a unified data-driven reduced order model (ROM) that bridges the\nperformance gap between linear and nonlinear manifold approaches. Deep learning\nROM (DL-ROM) using deep-convolutional autoencoders (DC-AE) has been shown to\ncapture nonlinear solution manifolds but fails to perform adequately when\nlinear subspace approaches such as proper orthogonal decomposition (POD) would\nbe optimal. Besides, most DL-ROM models rely on convolutional layers, which\nmight limit its application to only a structured mesh. The proposed framework\nin this study relies on the combination of an autoencoder (AE) and Barlow Twins\n(BT) self-supervised learning, where BT maximizes the information content of\nthe embedding with the latent space through a joint embedding architecture.\nThrough a series of benchmark problems of natural convection in porous media,\nBT-AE performs better than the previous DL-ROM framework by providing\ncomparable results to POD-based approaches for problems where the solution lies\nwithin a linear subspace as well as DL-ROM autoencoder-based techniques where\nthe solution lies on a nonlinear manifold; consequently, bridges the gap\nbetween linear and nonlinear reduced manifolds. Furthermore, this BT-AE\nframework can operate on unstructured meshes, which provides flexibility in its\napplication to standard numerical solvers, on-site measurements, experimental\ndata, or a combination of these sources.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2107.11460\n",
    "authors": [
      "Teeratorn Kadeethum",
      "Francesco Ballarin",
      "Daniel O'Malley",
      "Youngsoo Choi",
      "Nikolaos Bouklas",
      "Hongkyu Yoon"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Machine Learning (cs.LG)",
      "Mathematical Physics (math-ph)"
    ],
    "url": "https://arxiv.org/abs/2202.05460"
  },
  {
    "id": "arXiv:2202.05465",
    "title": "WAD-CMSN: Wasserstein Distance based Cross-Modal Semantic Network for  Zero-Shot Sketch-Based Image Retrieval",
    "abstract": "Zero-shot sketch-based image retrieval (ZSSBIR), as a popular studied branch\nof computer vision, attracts wide attention recently. Unlike sketch-based image\nretrieval (SBIR), the main aim of ZSSBIR is to retrieve natural images given\nfree hand-drawn sketches that may not appear during training. Previous\napproaches used semantic aligned sketch-image pairs or utilized memory\nexpensive fusion layer for projecting the visual information to a low\ndimensional subspace, which ignores the significant heterogeneous cross-domain\ndiscrepancy between highly abstract sketch and relevant image. This may yield\npoor performance in the training phase. To tackle this issue and overcome this\ndrawback, we propose a Wasserstein distance based cross-modal semantic network\n(WAD-CMSN) for ZSSBIR. Specifically, it first projects the visual information\nof each branch (sketch, image) to a common low dimensional semantic subspace\nvia Wasserstein distance in an adversarial training manner. Furthermore,\nidentity matching loss is employed to select useful features, which can not\nonly capture complete semantic knowledge, but also alleviate the over-fitting\nphenomenon caused by the WAD-CMSN model. Experimental results on the\nchallenging Sketchy (Extended) and TU-Berlin (Extended) datasets indicate the\neffectiveness of the proposed WAD-CMSN model over several competitors.",
    "descriptor": "",
    "authors": [
      "Guanglong Xu",
      "Zhensheng Hu",
      "Jia Cai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.05465"
  },
  {
    "id": "arXiv:2202.05469",
    "title": "Privacy-preserving Generative Framework Against Membership Inference  Attacks",
    "abstract": "Artificial intelligence and machine learning have been integrated into all\naspects of our lives and the privacy of personal data has attracted more and\nmore attention. Since the generation of the model needs to extract the\neffective information of the training data, the model has the risk of leaking\nthe privacy of the training data. Membership inference attacks can measure the\nmodel leakage of source data to a certain degree. In this paper, we design a\nprivacy-preserving generative framework against membership inference attacks,\nthrough the information extraction and data generation capabilities of the\ngenerative model variational autoencoder (VAE) to generate synthetic data that\nmeets the needs of differential privacy. Instead of adding noise to the model\noutput or tampering with the training process of the target model, we directly\nprocess the original data. We first map the source data to the latent space\nthrough the VAE model to get the latent code, then perform noise process\nsatisfying metric privacy on the latent code, and finally use the VAE model to\nreconstruct the synthetic data. Our experimental evaluation demonstrates that\nthe machine learning model trained with newly generated synthetic data can\neffectively resist membership inference attacks and still maintain high\nutility.",
    "descriptor": "\nComments: Under Review\n",
    "authors": [
      "Ruikang Yang",
      "Jianfeng Ma",
      "Yinbin Miao",
      "Xindi Ma"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.05469"
  },
  {
    "id": "arXiv:2202.05470",
    "title": "Jigsaw Puzzle: Selective Backdoor Attack to Subvert Malware Classifiers",
    "abstract": "Malware classifiers are subject to training-time exploitation due to the need\nto regularly retrain using samples collected from the wild. Recent work has\ndemonstrated the feasibility of backdoor attacks against malware classifiers,\nand yet the stealthiness of such attacks is not well understood. In this paper,\nwe investigate this phenomenon under the clean-label setting (i.e., attackers\ndo not have complete control over the training or labeling process).\nEmpirically, we show that existing backdoor attacks in malware classifiers are\nstill detectable by recent defenses such as MNTD. To improve stealthiness, we\npropose a new attack, Jigsaw Puzzle (JP), based on the key observation that\nmalware authors have little to no incentive to protect any other authors'\nmalware but their own. As such, Jigsaw Puzzle learns a trigger to complement\nthe latent patterns of the malware author's samples, and activates the backdoor\nonly when the trigger and the latent pattern are pieced together in a sample.\nWe further focus on realizable triggers in the problem space (e.g., software\ncode) using bytecode gadgets broadly harvested from benign software. Our\nevaluation confirms that Jigsaw Puzzle is effective as a backdoor, remains\nstealthy against state-of-the-art defenses, and is a threat in realistic\nsettings that depart from reasoning about feature-space only attacks. We\nconclude by exploring promising approaches to improve backdoor defenses.",
    "descriptor": "\nComments: 18 pages, 3 figures\n",
    "authors": [
      "Limin Yang",
      "Zhi Chen",
      "Jacopo Cortellazzi",
      "Feargus Pendlebury",
      "Kevin Tu",
      "Fabio Pierazzi",
      "Lorenzo Cavallaro",
      "Gang Wang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.05470"
  },
  {
    "id": "arXiv:2202.05472",
    "title": "Dandelion: Certified Approximations of Elementary Functions",
    "abstract": "Elementary function operations such as sin and exp cannot in general be\ncomputed exactly on today's digital computers, and thus have to be\napproximated. The standard approximations in library functions typically\nprovide only a limited set of precisions, and are too inefficient for many\napplications. Polynomial approximations that are customized to a limited input\ndomain and output accuracy can provide superior performance. In fact, the Remez\nalgorithm computes the best possible approximation for a given polynomial\ndegree, but has so far not been formally verified.\nThis paper presents Dandelion, an automated certificate checker for\npolynomial approximations of elementary functions computed with Remez-like\nalgorithms that is fully verified in the HOL4 theorem prover. Dandelion checks\nwhether the difference between a polynomial approximation and its target\nreference elementary function remains below a given error bound for all inputs\nin a given constraint. By extracting a verified binary with the CakeML\ncompiler, Dandelion can validate certificates within a reasonable time, fully\nautomating previous manually verified approximations.",
    "descriptor": "",
    "authors": [
      "Heiko Becker",
      "Mohit Tekriwal",
      "Eva Darulova",
      "Anastasia Volkova",
      "Jean-Baptiste Jeannin"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2202.05472"
  },
  {
    "id": "arXiv:2202.05474",
    "title": "Bench-Marking And Improving Arabic Automatic Image Captioning Through  The Use Of Multi-Task Learning Paradigm",
    "abstract": "The continuous increase in the use of social media and the visual content on\nthe internet have accelerated the research in computer vision field in general\nand the image captioning task in specific. The process of generating a caption\nthat best describes an image is a useful task for various applications such as\nit can be used in image indexing and as a hearing aid for the visually\nimpaired. In recent years, the image captioning task has witnessed remarkable\nadvances regarding both datasets and architectures, and as a result, the\ncaptioning quality has reached an astounding performance. However, the majority\nof these advances especially in datasets are targeted for English, which left\nother languages such as Arabic lagging behind. Although Arabic language, being\nspoken by more than 450 million people and being the most growing language on\nthe internet, lacks the fundamental pillars it needs to advance its image\ncaptioning research, such as benchmarks or unified datasets. This works is an\nattempt to expedite the synergy in this task by providing unified datasets and\nbenchmarks, while also exploring methods and techniques that could enhance the\nperformance of Arabic image captioning. The use of multi-task learning is\nexplored, alongside exploring various word representations and different\nfeatures. The results showed that the use of multi-task learning and\npre-trained word embeddings noticeably enhanced the quality of image\ncaptioning, however the presented results shows that Arabic captioning still\nlags behind when compared to the English language. The used dataset and code\nare available at this link.",
    "descriptor": "",
    "authors": [
      "Muhy Eddin Za'ter",
      "Bashar Talaftha"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.05474"
  },
  {
    "id": "arXiv:2202.05481",
    "title": "Concurrent Training of a Control Policy and a State Estimator for  Dynamic and Robust Legged Locomotion",
    "abstract": "In this paper, we propose a locomotion training framework where a control\npolicy and a state estimator are trained concurrently. The framework consists\nof a policy network which outputs the desired joint positions and a state\nestimation network which outputs estimates of the robot's states such as the\nbase linear velocity, foot height, and contact probability. We exploit a fast\nsimulation environment to train the networks and the trained networks are\ntransferred to the real robot. The trained policy and state estimator are\ncapable of traversing diverse terrains such as a hill, slippery plate, and\nbumpy road. We also demonstrate that the learned policy can run at up to 3.75\nm/s on normal flat ground and 3.54 m/s on a slippery plate with the coefficient\nof friction of 0.22.",
    "descriptor": "\nComments: Accepted for IEEE Robotics and Automation Letters and ICRA 2022\n",
    "authors": [
      "Gwanghyeon Ji",
      "Juhyeok Mun",
      "Hyeongjun Kim",
      "Jemin Hwangbo"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.05481"
  },
  {
    "id": "arXiv:2202.05484",
    "title": "Strong core and Pareto-optimal solutions for the multiple partners  matching problem under lexicographic preferences",
    "abstract": "In a multiple partners matching problem the agents can have multiple partners\nup to their capacities. In this paper we consider both the two-sided\nmany-to-many stable matching problem and the one-sided stable fixtures problem\nunder lexicographic preferences. We study strong core and Pareto-optimal\nsolutions for this setting from a computational point of view. First we provide\nan example to show that the strong core can be empty even under these severe\nrestrictions for many-to-many problems, and that deciding the non-emptiness of\nthe strong core is NP-hard. We also show that for a given matching checking\nPareto-optimality and the strong core properties are co-NP-complete problems\nfor the many-to-many problem, and deciding the existence of a complete\nPareto-optimal matching is also NP-hard for the fixtures problem. On the\npositive side, we give efficient algorithms for finding a near feasible strong\ncore solution, where the capacities are only violated by at most one unit for\neach agent, and also for finding a half-matching in the strong core of\nfractional matchings. These polynomial time algorithms are based on the Top\nTrading Cycle algorithm. Finally, we also show that finding a maximum size\nmatching that is Pareto-optimal can be done efficiently for many-to-many\nproblems, which is in contrast with the hardness result for the fixtures\nproblem.",
    "descriptor": "",
    "authors": [
      "P\u00e9ter Bir\u00f3",
      "Gergely Cs\u00e1ji"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Theoretical Economics (econ.TH)"
    ],
    "url": "https://arxiv.org/abs/2202.05484"
  },
  {
    "id": "arXiv:2202.05487",
    "title": "Kevin: de Brujin-based topology with demand-aware links and greedy  routing",
    "abstract": "We propose Kevin, a novel demand-aware reconfigurable rack-to-rack datacenter\nnetwork realized with a simple and efficient control plane. In particular,\nKevin makes effective use of the network capacity by supporting integrated and\nmulti-hop routing as well as work-conserving scheduling. To this end, Kevin\nrelies on local greedy routing with small forwarding tables which require local\nupdates only during topological reconfigurations, making this approach ideal\nfor dynamic networks. Specifically, Kevin is based on a de Brujin topology\n(using a small number of optical circuit switches) in which static links are\nenhanced with opportunistic links.",
    "descriptor": "",
    "authors": [
      "Johannes Zerwas",
      "Csaba Gy\u00f6rgyi",
      "Andreas Blenk",
      "Stefan Schmid",
      "Chen Avin"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2202.05487"
  },
  {
    "id": "arXiv:2202.05488",
    "title": "Noise Augmentation Is All You Need For FGSM Fast Adversarial Training:  Catastrophic Overfitting And Robust Overfitting Require Different  Augmentation",
    "abstract": "Adversarial training (AT) and its variants are the most effective approaches\nfor obtaining adversarially robust models. A unique characteristic of AT is\nthat an inner maximization problem needs to be solved repeatedly before the\nmodel weights can be updated, which makes the training slow. FGSM AT\nsignificantly improves its efficiency but it fails when the step size grows.\nThe SOTA GradAlign makes FGSM AT compatible with a higher step size, however,\nits regularization on input gradient makes it 3 to 4 times slower than FGSM AT.\nOur proposed NoiseAug removes the extra computation overhead by directly\nregularizing on the input itself. The key contribution of this work lies in an\nempirical finding that single-step FGSM AT is not as hard as suggested in the\npast line of work: noise augmentation is all you need for (FGSM) fast AT.\nTowards understanding the success of our NoiseAug, we perform an extensive\nanalysis and find that mitigating Catastrophic Overfitting (CO) and Robust\nOverfitting (RO) need different augmentations. Instead of more samples caused\nby data augmentation, we identify what makes NoiseAug effective for preventing\nCO might lie in its improved local linearity.",
    "descriptor": "",
    "authors": [
      "Chaoning Zhang",
      "Kang Zhang",
      "Axi Niu",
      "Chenshuang Zhang",
      "Jiu Feng",
      "Chang D. Yoo",
      "In So Kweon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.05488"
  },
  {
    "id": "arXiv:2202.05491",
    "title": "Exemplar-free Online Continual Learning",
    "abstract": "Targeted for real world scenarios, online continual learning aims to learn\nnew tasks from sequentially available data under the condition that each data\nis observed only once by the learner. Though recent works have made remarkable\nachievements by storing part of learned task data as exemplars for knowledge\nreplay, the performance is greatly relied on the size of stored exemplars while\nthe storage consumption is a significant constraint in continual learning. In\naddition, storing exemplars may not always be feasible for certain applications\ndue to privacy concerns. In this work, we propose a novel exemplar-free method\nby leveraging nearest-class-mean (NCM) classifier where the class mean is\nestimated during training phase on all data seen so far through online mean\nupdate criteria. We focus on image classification task and conduct extensive\nexperiments on benchmark datasets including CIFAR-100 and Food-1k. The results\ndemonstrate that our method without using any exemplar outperforms\nstate-of-the-art exemplar-based approaches with large margins under standard\nprotocol (20 exemplars per class) and is able to achieve competitive\nperformance even with larger exemplar size (100 exemplars per class).",
    "descriptor": "\nComments: Submitted for review\n",
    "authors": [
      "Jiangpeng He",
      "Fengqing Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.05491"
  },
  {
    "id": "arXiv:2202.05500",
    "title": "Multi-Modal Fusion for Sensorimotor Coordination in Steering Angle  Prediction",
    "abstract": "Imitation learning is employed to learn sensorimotor coordination for\nsteering angle prediction in an end-to-end fashion requires expert\ndemonstrations. These expert demonstrations are paired with environmental\nperception and vehicle control data. The conventional frame-based RGB camera is\nthe most common exteroceptive sensor modality used to acquire the environmental\nperception data. The frame-based RGB camera has produced promising results when\nused as a single modality in learning end-to-end lateral control. However, the\nconventional frame-based RGB camera has limited operability in illumination\nvariation conditions and is affected by the motion blur. The event camera\nprovides complementary information to the frame-based RGB camera. This work\nexplores the fusion of frame-based RGB and event data for learning end-to-end\nlateral control by predicting steering angle. In addition, how the\nrepresentation from event data fuse with frame-based RGB data helps to predict\nthe lateral control robustly for the autonomous vehicle. To this end, we\npropose DRFuser, a novel convolutional encoder-decoder architecture for\nlearning end-to-end lateral control. The encoder module is branched between the\nframe-based RGB data and event data along with the self-attention layers.\nMoreover, this study has also contributed to our own collected dataset\ncomprised of event, frame-based RGB, and vehicle control data. The efficacy of\nthe proposed method is experimentally evaluated on our collected dataset, Davis\nDriving dataset (DDD), and Carla Eventscape dataset. The experimental results\nillustrate that the proposed method DRFuser outperforms the state-of-the-art in\nterms of root-mean-square error (RMSE) and mean absolute error (MAE) used as\nevaluation metrics.",
    "descriptor": "",
    "authors": [
      "Farzeen Munir",
      "Shoaib Azam",
      "Byung-Geun Lee",
      "Moongu Jeon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.05500"
  },
  {
    "id": "arXiv:2202.05505",
    "title": "Software Architecture for Quantum Computing Systems-A Systematic Review",
    "abstract": "Quantum computing systems rely on the principles of quantum mechanics to\nperform a multitude of computationally challenging tasks more efficiently than\ntheir classical counterparts. The architecture of software-intensive systems\ncan empower architects who can leverage architecture-centric processes,\npractices, description languages, etc., to model, develop, and evolve quantum\ncomputing software (quantum software for short) at higher abstraction levels.\nWe conducted a systematic literature review (SLR) to investigate (i)\narchitectural process, (ii) modeling notations, (iii) architecture design\npatterns, (iv) tool support, and (iv) challenging factors for quantum software\narchitecture. Results of the SLR indicate that quantum software represents a\nnew genre of software-intensive systems; however, existing processes and\nnotations can be tailored to derive the architecting activities and develop\nmodeling languages for quantum software. Quantum bits (Qubits) mapped to\nQuantum gates (Qugates) can be represented as architectural components and\nconnectors that implement quantum software. Tool-chains can incorporate\nreusable knowledge and human roles (e.g., quantum domain engineers, quantum\ncode developers) to automate and customize the architectural process. Results\nof this SLR can facilitate researchers and practitioners to develop new\nhypotheses to be tested, derive reference architectures, and leverage\narchitecture-centric principles and practices to engineer emerging and next\ngenerations of quantum software.",
    "descriptor": "",
    "authors": [
      "Arif Ali Khan",
      "Aakash Ahmad",
      "Muhammad Waseem",
      "Peng Liang",
      "Mahdi Fahmideh",
      "Tommi Mikkonen",
      "Pekka Abrahamsson"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2202.05505"
  },
  {
    "id": "arXiv:2202.05508",
    "title": "Towards Weakly-Supervised Text Spotting using a Multi-Task Transformer",
    "abstract": "Text spotting end-to-end methods have recently gained attention in the\nliterature due to the benefits of jointly optimizing the text detection and\nrecognition components. Existing methods usually have a distinct separation\nbetween the detection and recognition branches, requiring exact annotations for\nthe two tasks. We introduce TextTranSpotter (TTS), a transformer-based approach\nfor text spotting and the first text spotting framework which may be trained\nwith both fully- and weakly-supervised settings. By learning a single latent\nrepresentation per word detection, and using a novel loss function based on the\nHungarian loss, our method alleviates the need for expensive localization\nannotations. Trained with only text transcription annotations on real data, our\nweakly-supervised method achieves competitive performance with previous\nstate-of-the-art fully-supervised methods. When trained in a fully-supervised\nmanner, TextTranSpotter shows state-of-the-art results on multiple benchmarks\n\\footnote {Our code will be publicly available upon publication.",
    "descriptor": "",
    "authors": [
      "Yair Kittenplon",
      "Inbal Lavi",
      "Sharon Fogel",
      "Yarin Bar",
      "R. Manmatha",
      "Pietro Perona"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.05508"
  },
  {
    "id": "arXiv:2202.05510",
    "title": "Support Vectors and Gradient Dynamics for Implicit Bias in ReLU Networks",
    "abstract": "Understanding implicit bias of gradient descent has been an important goal in\nmachine learning research. Unfortunately, even for a single-neuron ReLU\nnetwork, it recently proved impossible to characterize the implicit\nregularization with the square loss by an explicit function of the norm of\nmodel parameters. In order to close the gap between the existing theory and the\nintriguing empirical behavior of ReLU networks, here we examine the gradient\nflow dynamics in the parameter space when training single-neuron ReLU networks.\nSpecifically, we discover implicit bias in terms of support vectors in ReLU\nnetworks, which play a key role in why and how ReLU networks generalize well.\nMoreover, we analyze gradient flows with respect to the magnitude of the norm\nof initialization, and show the impact of the norm in gradient dynamics.\nLastly, under some conditions, we prove that the norm of the learned weight\nstrictly increases on the gradient flow.",
    "descriptor": "",
    "authors": [
      "Sangmin Lee",
      "Byeongsu Sim",
      "Jong Chul Ye"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.05510"
  },
  {
    "id": "arXiv:2202.05511",
    "title": "Inference with System W Satisfies Syntax Splitting",
    "abstract": "In this paper, we investigate inductive inference with system W from\nconditional belief bases with respect to syntax splitting. The concept of\nsyntax splitting for inductive inference states that inferences about\nindependent parts of the signature should not affect each other. This was\ncaptured in work by Kern-Isberner, Beierle, and Brewka in the form of\npostulates for inductive inference operators expressing syntax splitting as a\ncombination of relevance and independence; it was also shown that c-inference\nfulfils syntax splitting, while system P inference and system Z both fail to\nsatisfy it. System W is a recently introduced inference system for nonmonotonic\nreasoning that captures and properly extends system Z as well as c-inference.\nWe show that system W fulfils the syntax splitting postulates for inductive\ninference operators by showing that it satisfies the required properties of\nrelevance and independence. This makes system W another inference operator\nbesides c-inference that fully complies with syntax splitting, while in\ncontrast to c-inference, also extending rational closure.",
    "descriptor": "",
    "authors": [
      "Jonas Haldimann",
      "Christoph Beierle"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.05511"
  },
  {
    "id": "arXiv:2202.05515",
    "title": "Multi-Access Coded Caching Schemes from Maximal Cross Resolvable Designs",
    "abstract": "We study the problem of multi-access coded caching (MACC): a central server\nhas $N$ files, $K$ ($K \\leq N$) caches each of which stores $M$ out of the $N$\nfiles, $K$ users each of which demands one out of the $N$ files, and each user\naccesses $z$ caches. The objective is to jointly design the placement,\ndelivery, and user-to-cache association, to optimize the achievable rate. This\nproblem has been extensively studied in the literature under the assumption\nthat a user accesses only one cache. However, when a user accesses more caches,\nthis problem has been studied only under the assumption that a user accesses\n$z$ consecutive caches with a cyclic wrap-around over the boundaries. A natural\nquestion is how other user-to-cache associations fare against the cyclic\nwrap-around user-to-cache association. A bipartite graph can describe a general\nuser-to-cache association. We identify a class of bipartite graphs that, when\nused as a user-to-cache association, achieves either a lesser rate or a lesser\nsubpacketization than all other existing MACC schemes using a cyclic\nwrap-around user-to-cache association. The placement and delivery strategy of\nour MACC scheme is constructed using a combinatorial structure called maximal\ncross resolvable design.",
    "descriptor": "\nComments: 34 pages, 5 figures and 3 tables\n",
    "authors": [
      "Niladri Das",
      "B. Sundar Rajan"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.05515"
  },
  {
    "id": "arXiv:2202.05517",
    "title": "Electricity Consumption Forecasting for Out-of-distribution Time-of-Use  Tariffs",
    "abstract": "In electricity markets, retailers or brokers want to maximize profits by\nallocating tariff profiles to end consumers. One of the objectives of such\ndemand response management is to incentivize the consumers to adjust their\nconsumption so that the overall electricity procurement in the wholesale\nmarkets is minimized, e.g. it is desirable that consumers consume less during\npeak hours when cost of procurement for brokers from wholesale markets are\nhigh. We consider a greedy solution to maximize the overall profit for brokers\nby optimal tariff profile allocation. This in-turn requires forecasting\nelectricity consumption for each user for all tariff profiles. This forecasting\nproblem is challenging compared to standard forecasting problems due to\nfollowing reasons: i. the number of possible combinations of hourly tariffs is\nhigh and retailers may not have considered all combinations in the past\nresulting in a biased set of tariff profiles tried in the past, ii. the\nprofiles allocated in the past to each user is typically based on certain\npolicy. These reasons violate the standard i.i.d. assumptions, as there is a\nneed to evaluate new tariff profiles on existing customers and historical data\nis biased by the policies used in the past for tariff allocation. In this work,\nwe consider several scenarios for forecasting and optimization under these\nconditions. We leverage the underlying structure of how consumers respond to\nvariable tariff rates by comparing tariffs across hours and shifting loads, and\npropose suitable inductive biases in the design of deep neural network based\narchitectures for forecasting under such scenarios. More specifically, we\nleverage attention mechanisms and permutation equivariant networks that allow\ndesirable processing of tariff profiles to learn tariff representations that\nare insensitive to the biases in the data and still representative of the task.",
    "descriptor": "\nComments: Accepted paper at AAAI workshop AIBSD 2022\n",
    "authors": [
      "Jyoti Narwariya",
      "Chetan Verma",
      "Pankaj Malhotra",
      "Lovekesh Vig",
      "Easwara Subramanian",
      "Sanjay Bhat"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.05517"
  },
  {
    "id": "arXiv:2202.05522",
    "title": "Unsupervised HDR Imaging: What Can Be Learned from a Single 8-bit Video?",
    "abstract": "Recently, Deep Learning-based methods for inverse tone-mapping standard\ndynamic range (SDR) images to obtain high dynamic range (HDR) images have\nbecome very popular. These methods manage to fill over-exposed areas\nconvincingly both in terms of details and dynamic range. Typically, these\nmethods, to be effective, need to learn from large datasets and to transfer\nthis knowledge to the network weights. In this work, we tackle this problem\nfrom a completely different perspective. What can we learn from a single SDR\nvideo? With the presented zero-shot approach, we show that, in many cases, a\nsingle SDR video is sufficient to be able to generate an HDR video of the same\nquality or better than other state-of-the-art methods.",
    "descriptor": "",
    "authors": [
      "Francesco Banterle",
      "Demetris Marnerides",
      "Kurt Debattista",
      "Thomas Bashford-Rogers"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2202.05522"
  },
  {
    "id": "arXiv:2202.05525",
    "title": "From Unsupervised to Few-shot Graph Anomaly Detection: A Multi-scale  Contrastive Learning Approach",
    "abstract": "Anomaly detection from graph data is an important data mining task in many\napplications such as social networks, finance, and e-commerce. Existing efforts\nin graph anomaly detection typically only consider the information in a single\nscale (view), thus inevitably limiting their capability in capturing anomalous\npatterns in complex graph data. To address this limitation, we propose a novel\nframework, graph ANomaly dEtection framework with Multi-scale cONtrastive\nlEarning (ANEMONE in short). By using a graph neural network as a backbone to\nencode the information from multiple graph scales (views), we learn better\nrepresentation for nodes in a graph. In maximizing the agreements between\ninstances at both the patch and context levels concurrently, we estimate the\nanomaly score of each node with a statistical anomaly estimator according to\nthe degree of agreement from multiple perspectives. To further exploit a\nhandful of ground-truth anomalies (few-shot anomalies) that may be collected in\nreal-life applications, we further propose an extended algorithm, ANEMONE-FS,\nto integrate valuable information in our method. We conduct extensive\nexperiments under purely unsupervised settings and few-shot anomaly detection\nsettings, and we demonstrate that the proposed method ANEMONE and its variant\nANEMONE-FS consistently outperform state-of-the-art algorithms on six benchmark\ndatasets.",
    "descriptor": "\nComments: 13 pages, 5 figures, 5 tables\n",
    "authors": [
      "Yu Zheng",
      "Ming Jin",
      "Yixin Liu",
      "Lianhua Chi",
      "Khoa T. Phan",
      "Shirui Pan",
      "Yi-Ping Phoebe Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.05525"
  },
  {
    "id": "arXiv:2202.05528",
    "title": "MusIAC: An extensible generative framework for Music Infilling  Applications with multi-level Control",
    "abstract": "We present a novel music generation framework for music infilling, with a\nuser friendly interface. Infilling refers to the task of generating musical\nsections given the surrounding multi-track music. The proposed\ntransformer-based framework is extensible for new control tokens as the added\nmusic control tokens such as tonal tension per bar and track polyphony level in\nthis work. We explore the effects of including several musically meaningful\ncontrol tokens, and evaluate the results using objective metrics related to\npitch and rhythm. Our results demonstrate that adding additional control tokens\nhelps to generate music with stronger stylistic similarities to the original\nmusic. It also provides the user with more control to change properties like\nthe music texture and tonal tension in each bar compared to previous research\nwhich only provided control for track density. We present the model in a Google\nColab notebook to enable interactive generation.",
    "descriptor": "\nComments: preprint for The 11th International Conference on Artificial Intelligence in Music, Sound, Art and Design (EvoMUSART) 2022\n",
    "authors": [
      "Rui Guo",
      "Ivor Simpson",
      "Chris Kiefer",
      "Thor Magnusson",
      "Dorien Herremans"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2202.05528"
  },
  {
    "id": "arXiv:2202.05529",
    "title": "An inductive-recursive universe generic for small families",
    "abstract": "We show that it is possible to construct a universe in all Grothendieck topoi\nwith injective codes a la Pujet and Tabareau which is nonetheless generic for\nsmall families. As a trivial consequence, we show that their observational type\ntheory admits interpretations in Grothendieck topoi suitable for use as\ninternal languages.",
    "descriptor": "",
    "authors": [
      "Daniel Gratzer"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2202.05529"
  },
  {
    "id": "arXiv:2202.05530",
    "title": "An Improved EPA based Receiver Design for Uplink LDPC Coded SCMA System",
    "abstract": "Sparse code multiple access (SCMA) is an emerging paradigm for efficient\nenabling of massive connectivity in future machine-type communications (MTC).\nIn this letter, we conceive the uplink transmissions of the low-density parity\ncheck (LDPC) coded SCMA system. Traditional receiver design of LDPC-SCMA\nsystem, which is based on message passing algorithm (MPA) for multiuser\ndetection followed by individual LDPC decoding, may suffer from the drawback of\nthe high complexity and large decoding latency, especially when the system has\nlarge codebook size and/or high overloading factor. To address this problem, we\nintroduce a novel receiver design by applying the expectation propagation\nalgorithm (EPA) to the joint detection and decoding (JDD) involving an\naggregated factor graph of LDPC code and sparse codebooks. Our numerical\nresults demonstrate the superiority of the proposed EPA based JDD receiver over\nthe conventional Turbo receiver in terms of both significantly lower complexity\nand faster convergence rate without noticeable error rate performance\ndegradation.",
    "descriptor": "",
    "authors": [
      "Lingyun Chai",
      "Zilong Liu",
      "Pei Xiao",
      "Amine Maaref",
      "Lin Bai"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.05530"
  },
  {
    "id": "arXiv:2202.05531",
    "title": "Cyclical Curriculum Learning",
    "abstract": "Artificial neural networks (ANN) are inspired by human learning. However,\nunlike human education, classical ANN does not use a curriculum. Curriculum\nLearning (CL) refers to the process of ANN training in which examples are used\nin a meaningful order. When using CL, training begins with a subset of the\ndataset and new samples are added throughout the training, or training begins\nwith the entire dataset and the number of samples used is reduced. With these\nchanges in training dataset size, better results can be obtained with\ncurriculum, anti-curriculum, or random-curriculum methods than the vanilla\nmethod. However, a generally efficient CL method for various architectures and\ndata sets is not found. In this paper, we propose cyclical curriculum learning\n(CCL), in which the data size used during training changes cyclically rather\nthan simply increasing or decreasing. Instead of using only the vanilla method\nor only the curriculum method, using both methods cyclically like in CCL\nprovides more successful results. We tested the method on 18 different data\nsets and 15 architectures in image and text classification tasks and obtained\nmore successful results than no-CL and existing CL methods. We also have shown\ntheoretically that it is less erroneous to apply CL and vanilla cyclically\ninstead of using only CL or only vanilla method. The code of Cyclical\nCurriculum is available at\nhttps://github.com/CyclicalCurriculum/Cyclical-Curriculum.",
    "descriptor": "",
    "authors": [
      "H. Toprak Kesgin",
      "M. Fatih Amasyali"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.05531"
  },
  {
    "id": "arXiv:2202.05535",
    "title": "A Lightweight, Efficient and Explainable-by-Design Convolutional Neural  Network for Internet Traffic Classification",
    "abstract": "Traffic classification, i.e. the identification of the type of applications\nflowing in a network, is a strategic task for numerous activities (e.g.,\nintrusion detection, routing). This task faces some critical challenges that\ncurrent deep learning approaches do not address. The design of current\napproaches do not take into consideration the fact that networking hardware\n(e.g., routers) often runs with limited computational resources. Further, they\ndo not meet the need for faithful explainability highlighted by regulatory\nbodies. Finally, these traffic classifiers are evaluated on small datasets\nwhich fail to reflect the diversity of applications in real commercial\nsettings. Therefore, this paper introduces a Lightweight, Efficient and\neXplainable-by-design convolutional neural network (LEXNet) for Internet\ntraffic classification, which relies on a new residual block (for lightweight\nand efficiency purposes) and prototype layer (for explainability). Based on a\ncommercial-grade dataset, our evaluation shows that LEXNet succeeds to maintain\nthe same accuracy as the best performing state-of-the-art neural network, while\nproviding the additional features previously mentioned. Moreover, we\ndemonstrate that LEXNet significantly reduces the model size and inference time\ncompared to the state-of-the-art neural networks with explainability-by-design\nand post hoc explainability methods. Finally, we illustrate the explainability\nfeature of our approach, which stems from the communication of detected\napplication prototypes to the end-user, and we highlight the faithfulness of\nLEXNet explanations through a comparison with post hoc methods.",
    "descriptor": "",
    "authors": [
      "Kevin Fauvel",
      "Alessandro Finamore",
      "Lixuan Yang",
      "Fuxing Chen",
      "Dario Rossi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.05535"
  },
  {
    "id": "arXiv:2202.05538",
    "title": "Hybridization of Capsule and LSTM Networks for unsupervised anomaly  detection on multivariate data",
    "abstract": "Deep learning techniques have recently shown promise in the field of anomaly\ndetection, providing a flexible and effective method of modelling systems in\ncomparison to traditional statistical modelling and signal processing-based\nmethods. However, there are a few well publicised issues Neural Networks (NN)s\nface such as generalisation ability, requiring large volumes of labelled data\nto be able to train effectively and understanding spatial context in data. This\npaper introduces a novel NN architecture which hybridises the\nLong-Short-Term-Memory (LSTM) and Capsule Networks into a single network in a\nbranched input Autoencoder architecture for use on multivariate time series\ndata. The proposed method uses an unsupervised learning technique to overcome\nthe issues with finding large volumes of labelled training data. Experimental\nresults show that without hyperparameter optimisation, using Capsules\nsignificantly reduces overfitting and improves the training efficiency.\nAdditionally, results also show that the branched input models can learn\nmultivariate data more consistently with or without Capsules in comparison to\nthe non-branched input models. The proposed model architecture was also tested\non an open-source benchmark, where it achieved state-of-the-art performance in\noutlier detection, and overall performs best over the metrics tested in\ncomparison to current state-of-the art methods.",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Ayman Elhalwagy",
      "Tatiana Kalganova"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.05538"
  },
  {
    "id": "arXiv:2202.05539",
    "title": "A Sonification of the zCOSMOS Galaxy Dataset",
    "abstract": "Sonification is the transformation of data into acoustic signals, achievable\nthrough different techniques. Sonification can be defined as a way to represent\ndata values and relations as perceivable sounds, aiming at facilitating their\ncommunication and interpretation. Like data visualization provides meaning via\nimages, sonification conveys meaning via sound. Sonification approaches are\nuseful in a number of scenario. A first case is the possibility to receive\ninformation while keeping other sensory channels free, like in medical\nenvironment, in driving experience, etc. Another scenario addresses an easier\nrecognition of patterns when data present high dimensionality and cardinality.\nFinally, sonification can be applied to presentation and dissemination\ninitiatives, also with artistic goals. The zCOSMOS dataset contains detailed\ndata about almost 20000 galaxies, describing the evolution of a relatively\nsmall portion of the universe in the last 10 million years in terms of galaxy\nmass, absolute luminosity, redshift, distance, age, and star formation rate.\nThe present paper proposes a sonification for the mentioned dataset, with the\nfollowing goals: i) providing a general description of the dataset, accessible\nvia sound, which could also make unnoticed patterns emerge; ii) realizing an\nartistic but scientifically accurate sonic portrait of a portion of the\nuniverse, thus filling the gap between art and science in the context of\nscientific dissemination and so-called \"edutainment\"; iii) adding value to the\ndataset, since also scientific data and achievements must be considered as a\ncultural heritage that needs to be preserved and enhanced. Both scientific and\ntechnological aspects of the sonification are addressed.",
    "descriptor": "\nComments: 18 pages, 6 figures\n",
    "authors": [
      "S. Bardelli",
      "Claudia Ferretti",
      "Luca Andrea Ludovico",
      "Giorgio Presti",
      "Maurizio Rinaldi"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Computers and Society (cs.CY)",
      "Audio and Speech Processing (eess.AS)",
      "Physics Education (physics.ed-ph)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2202.05539"
  },
  {
    "id": "arXiv:2202.05541",
    "title": "Designing a Social Media Analytics Dashboard for Government Agency  Crisis Communications",
    "abstract": "Social media have become a valuable source for extracting data about societal\ncrises and an important outlet to disseminate official information. Government\nagencies are increasingly turning to social media to use it as a mouthpiece in\ntimes of crisis. Gaining intelligence through social media analytics, however,\nremains a challenge for government agencies, e.g. due to a lack of training and\ninstruments. To mitigate this shortcoming, government agencies need tools that\nsupport them in analysing social media data for the public good. This paper\npresents a design science research approach that guides the development of a\nsocial media analytics dashboard for a regional government agency. Preliminary\nresults from a workshop and the resulting design of a first prototype are\nreported. A user-friendly and responsive design that is secure, flexible, and\nquick in use could identified as requirements, as well as information display\nof regional discussion statistics, sentiment, and emerging topics.",
    "descriptor": "\nComments: Australasian Conference on Information Systems\n",
    "authors": [
      "Ali Sercan Basyurt",
      "Julian Marx",
      "Stefan Stieglitz",
      "Milad Mirbabaie"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2202.05541"
  },
  {
    "id": "arXiv:2202.05546",
    "title": "Insertion Time of Random Walk Cuckoo Hashing below the Peeling Threshold",
    "abstract": "When it comes to hash tables, the only truly respectable insertion time is\n$O(1)$, possibly qualified as expected and/or amortised. While insertions into\ncuckoo hash tables indeed seem to take $O(1)$ expected time in practice, only\npolylogarithmic guarantees are proven in all but the simplest of practically\nrelevant cases. Given the widespread use of cuckoo hashing to implement compact\ndictionaries and Bloom filter alternatives, closing this gap is an important\nopen problem for theoreticians.\nIn this paper, we show that random walk insertions into cuckoo hash tables\ntake $O(1)$ expected amortised time when any number $k \\geq 3$ of hash\nfunctions is used and the load factor is below the corresponding peeling\nthreshold (e.g. $\\approx 0.81$ for $k = 3$). To our knowledge, this is the\nfirst meaningful guarantee for constant time insertion for cuckoo hashing that\nworks for $k \\in \\{3,\\dots,9\\}$.\nIn addition to being useful in its own right, we hope that our key-centred\nanalysis method can be a stepping stone on the path to the true end goal:\n$O(1)$ time insertions for all load factors below the load threshold (e.g.\n$\\approx 0.91$ for $k = 3$).",
    "descriptor": "",
    "authors": [
      "Stefan Walzer"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2202.05546"
  },
  {
    "id": "arXiv:2202.05548",
    "title": "The Risks, Benefits, and Consequences of Prepublication Moderation:  Evidence from 17 Wikipedia Language Editions",
    "abstract": "Many online communities rely on postpublication moderation where contributors\n-- even those that are perceived as being risky -- are allowed to publish\nmaterial immediately without review. An alternative arrangement involves\nmoderating content before publication. A range of communities have argued\nagainst prepublication moderation by suggesting that it makes contributing less\nenjoyable for new members and that it will distract established community\nmembers with extra moderation work. We present an empirical analysis of the\neffects of a prepublication review system called \\textit{FlaggedRevs} that was\ndeployed by several Wikipedia language editions. We used panel data from 17\nlarge Wikipedia editions to test a series of hypotheses related to the effect\nof the system on activity levels and contribution quality within the affected\ncommunities. We found that the system was very effective at keeping low-quality\ncontributions from ever becoming visible. Although there is some evidence that\nthe system discouraged participation among unregistered users, our analysis\nsuggests that the system's effects on contribution volume and quality were\nmoderate at most. Our findings imply that concerns regarding the major negative\neffects of prepublication moderation systems on contribution quality, project\nproductivity, and community sustainability may be overstated.",
    "descriptor": "\nComments: This paper has been accepted with minor revision at The 25th ACM Conference On Computer- Supported Cooperative Work And Social Computing (CSCW 2022)\n",
    "authors": [
      "Chau Tran",
      "Kaylea Champion",
      "Benjamin Mako Hill",
      "Rachel Greenstadt"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2202.05548"
  },
  {
    "id": "arXiv:2202.05549",
    "title": "Lightning: Scaling the GPU Programming Model Beyond a Single GPU",
    "abstract": "The GPU programming model is primarily designed to support the development of\napplications that run on one GPU. However, just a single GPU is limited in its\ncapabilities in terms of memory capacity and compute power. To handle large\nproblems that exceed these capabilities, one must rewrite application code to\nmanually transfer data between GPU memory and higher-level memory and/or\ndistribute the work across multiple GPUs, possibly in multiple nodes. This\nmeans a large engineering effort is required to scale GPU applications beyond a\nsingle GPU.\nWe present Lightning: a framework that follows the common GPU programming\nparadigm, but enables scaling to larger problems. Lightning enables multi-GPU\nexecution of GPU kernels, even across multiple nodes, and seamlessly spills\ndata to main memory and disk when required. Existing CUDA kernels can easily be\nadapted for use in Lightning, with data access annotations on these kernels\nallowing Lightning to infer their data requirements and dependencies. Lightning\nefficiently distributes the work/data across GPUs and maximizes efficiency by\noverlapping scheduling, data movement, and work when possible.\nWe present the design and implementation of Lightning, as well as\nexperimental results on up to 32 GPUs for eight benchmarks and an application\nfrom geospatial clustering. Evaluation shows excellent performance on problem\nsizes that far exceed the memory capacity of a single GPU.",
    "descriptor": "\nComments: To be published at 36th IEEE International Parallel & Distributed Processing Symposium (IPDPS)\n",
    "authors": [
      "Stijn Heldens",
      "Pieter Hijma",
      "Ben van Werkhoven",
      "Jason Maassen",
      "Rob. V. van Nieuwpoort"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2202.05549"
  },
  {
    "id": "arXiv:2202.05550",
    "title": "The Factorial-Basis Method for Finding Definite-Sum Solutions of Linear  Recurrences With Polynomial Coefficients",
    "abstract": "The problem of finding a nonzero solution of a linear recurrence $Ly = 0$\nwith polynomial coefficients where $y$ has the form of a definite\nhypergeometric sum, related to the Inverse Creative Telescoping Problem of\n[14][Sec. 8], has now been open for three decades. Here we present an algorithm\n(implemented in a SageMath package) which, given such a recurrence and a\nquasi-triangular, shift-compatible factorial basis $\\mathcal{B} = \\langle\nP_k(n)\\rangle_{k=0}^\\infty$ of the polynomial space $\\mathbb{K}[n]$ over a\nfield $\\mathbb{K}$ of characteristic zero, computes a recurrence satisfied by\nthe coefficient sequence $c = \\langle c_k\\rangle_{k=0}^\\infty$ of the solution\n$y_n = \\sum_{k=0}^\\infty c_kP_k(n)$ (where, thanks to the quasi-triangularity\nof $\\mathcal{B}$, the sum on the right terminates for each $n \\in \\mathbb{N}$).\nMore generally, if $\\mathcal{B}$ is $m$-sieved for some $m \\in \\mathbb{N}$, our\nalgorithm computes a system of $m$ recurrences satisfied by the $m$-sections of\nthe coefficient sequence $c$. If an explicit nonzero solution of this system\ncan be found, we obtain an explicit nonzero solution of $Ly = 0$.",
    "descriptor": "\nComments: 54 pages\n",
    "authors": [
      "Antonio Jim\u00e9nez-Pastor",
      "Marko Petkov\u0161ek"
    ],
    "subjectives": [
      "Symbolic Computation (cs.SC)",
      "Mathematical Software (cs.MS)"
    ],
    "url": "https://arxiv.org/abs/2202.05550"
  },
  {
    "id": "arXiv:2202.05554",
    "title": "Improved bounds for randomly colouring simple hypergraphs",
    "abstract": "We study the problem of sampling almost uniform proper $q$-colourings in\n$k$-uniform simple hypergraphs with maximum degree $\\Delta$. For any $\\delta >\n0$, if $k \\geq\\frac{20(1+\\delta)}{\\delta}$ and $q \\geq\n100\\Delta^{\\frac{2+\\delta}{k-4/\\delta-4}}$, the running time of our algorithm\nis $\\tilde{O}(\\mathrm{poly}(\\Delta k)\\cdot n^{1.01})$, where $n$ is the number\nof vertices. Our result requires fewer colours than previous results for\ngeneral hypergraphs (Jain, Pham, and Voung, 2021; He, Sun, and Wu, 2021), and\ndoes not require $\\Omega(\\log n)$ colours unlike the work of Frieze and Anastos\n(2017).",
    "descriptor": "",
    "authors": [
      "Weiming Feng",
      "Heng Guo",
      "Jiaheng Wang"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2202.05554"
  },
  {
    "id": "arXiv:2202.05555",
    "title": "A note on the spectral analysis of matrix sequences via GLT momentary  symbols: from all-at-once solution of parabolic problems to distributed  fractional order matrices",
    "abstract": "The first focus of this paper is the characterization of the spectrum and the\nsingular values of the coefficient matrix stemming from the discretization with\nspace-time grid for a parabolic diffusion problem and from the approximation of\ndistributed order fractional equations. For this purpose we will use the\nclassical GLT theory and the new concept of GLT momentary symbols. The first\npermits to describe the singular value or eigenvalue asymptotic distribution of\nthe sequence of the coefficient matrices, the latter permits to derive a\nfunction, which describes the singular value or eigenvalue distribution of the\nmatrix of the sequence, even for small matrix-sizes but under given\nassumptions. The note is concluded with a list of open problems, including the\nuse of our machinery in the study of iteration matrices, especially those\nconcerning multigrid-type techniques.",
    "descriptor": "",
    "authors": [
      "Matthias Bolten",
      "Sven-Erik Ekstr\u00f6m",
      "Isabella Furci",
      "Stefano Serra-Capizzano"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.05555"
  },
  {
    "id": "arXiv:2202.05562",
    "title": "Perfect Matchings and Quantum Physics: Progress on Krenn's Conjecture",
    "abstract": "In 2017, Krenn reported that certain problems related to the perfect\nmatchings and colourings of graphs emerge out of studying the constructability\nof general quantum states using modern photonic technologies. He realized that\nif we can prove that the \\emph{weighted matching index} of a graph, a parameter\ndefined in terms of perfect matchings and colourings of the graph is at most 2,\nthat could lead to exciting insights on the potential of resources of quantum\ninference. Motivated by this, he conjectured that the {weighted matching index}\nof any graph is at most 2. The first result on this conjecture was by Bogdanov,\nwho proved that the \\emph{(unweighted) matching index} of graphs\n(non-isomorphic to $K_4$) is at most 2, thus classifying graphs non-isomorphic\nto $K_4$ into Type 0, Type 1 and Type 2. By definition, the weighted matching\nindex of Type 0 graphs is 0. We give a structural characterization for Type 2\ngraphs, using which we settle Krenn's conjecture for Type 2 graphs. Using this\ncharacterization, we provide a simple $O(|V||E|)$ time algorithm to find the\nunweighted matching index of any graph. In view of our work, Krenn's conjecture\nremains to be proved only for Type 1 graphs. We give upper bounds for the\nweighted matching index in terms of connectivity parameters for such graphs.\nUsing these bounds, for a slightly simplified version, we settle Krenn's\nconjecture for the class of graphs with vertex connectivity at most 2 and the\nclass of graphs with maximum degree at most 4.\nKrenn has been publicizing his conjecture in various ways since 2017. He has\neven declared a reward for a resolution of his conjecture. We hope that this\narticle will popularize the problem among computer scientists.",
    "descriptor": "\nComments: 17 pages, 4 figures\n",
    "authors": [
      "L. Sunil Chandran",
      "Rishikesh Gajjala"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)",
      "Mathematical Physics (math-ph)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2202.05562"
  },
  {
    "id": "arXiv:2202.05564",
    "title": "A Partial Reciprocity-based Channel Prediction Framework for FDD massive  MIMO with High Mobility",
    "abstract": "Massive multiple-input multiple-output (MIMO) is believed to deliver\nunrepresented spectral efficiency gains for 5G and beyond. However, a practical\nchallenge arises during its commercial deployment, which is known as the \"curse\nof mobility\". The performance of massive MIMO drops alarmingly when the\nvelocity level of user increases. In this paper, we tackle the problem in\nfrequency division duplex (FDD) massive MIMO with a novel Channel State\nInformation (CSI) acquisition framework. A joint angle-delay-Doppler (JADD)\nwideband beamformer is proposed for channel training. Our idea consists in the\nexploitation of the partial channel reciprocity of FDD and the\nangle-delay-Doppler channel structure. More precisely, the base station (BS)\nestimates the angle-delay-Doppler information of the UL channel based on UL\npilots using Matrix Pencil method. It then computes the wideband JADD\nbeamformers according to the extracted parameters. Afterwards, the user\nestimates and feeds back some scalar coefficients for the BS to reconstruct the\npredicted DL channel. Asymptotic analysis shows that the CSI prediction error\nconverges to zero when the number of BS antennas and the bandwidth increases.\nNumerical results with industrial channel model demonstrate that our framework\ncan well adapt to high speed (350 km/h), large CSI delay (10 ms) and channel\nsample noise.",
    "descriptor": "\nComments: 9 figures, 14 pages\n",
    "authors": [
      "Ziao Qin",
      "Haifan Yin",
      "Yandi Cao",
      "Weidong Li",
      "David Gesbert"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.05564"
  },
  {
    "id": "arXiv:2202.05567",
    "title": "Shuffle Private Linear Contextual Bandits",
    "abstract": "Differential privacy (DP) has been recently introduced to linear contextual\nbandits to formally address the privacy concerns in its associated personalized\nservices to participating users (e.g., recommendations). Prior work largely\nfocus on two trust models of DP: the central model, where a central server is\nresponsible for protecting users sensitive data, and the (stronger) local\nmodel, where information needs to be protected directly on user side. However,\nthere remains a fundamental gap in the utility achieved by learning algorithms\nunder these two privacy models, e.g., $\\tilde{O}(\\sqrt{T})$ regret in the\ncentral model as compared to $\\tilde{O}(T^{3/4})$ regret in the local model, if\nall users are unique within a learning horizon $T$. In this work, we aim to\nachieve a stronger model of trust than the central model, while suffering a\nsmaller regret than the local model by considering recently popular shuffle\nmodel of privacy. We propose a general algorithmic framework for linear\ncontextual bandits under the shuffle trust model, where there exists a trusted\nshuffler in between users and the central server, that randomly permutes a\nbatch of users data before sending those to the server. We then instantiate\nthis framework with two specific shuffle protocols: one relying on privacy\namplification of local mechanisms, and another incorporating a protocol for\nsumming vectors and matrices of bounded norms. We prove that both these\ninstantiations lead to regret guarantees that significantly improve on that of\nthe local model, and can potentially be of the order $\\tilde{O}(T^{3/5})$ if\nall users are unique. We also verify this regret behavior with simulations on\nsynthetic data. Finally, under the practical scenario of non-unique users, we\nshow that the regret of our shuffle private algorithm scale as\n$\\tilde{O}(T^{2/3})$, which matches that the central model could achieve in\nthis case.",
    "descriptor": "",
    "authors": [
      "Sayak Ray Chowdhury",
      "Xingyu Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.05567"
  },
  {
    "id": "arXiv:2202.05569",
    "title": "RIS-Aided Wireless Communications: Extra Degrees of Freedom via Rotation  and Location Optimization",
    "abstract": "We consider the extra degree of freedom offered by the rotation of the\nreconfigurable intelligent surface (RIS) plane and investigate its potential in\nimproving the performance of RIS-assisted wireless communication systems. By\nconsidering radiation pattern modeling at all involved nodes, we first derive\nthe composite channel gain and present a closed-form upper bound for the system\nergodic capacity over cascade Rician fading channels. Then, we reconstruct the\ncomposite channel gain by taking the rotations at the RIS plane, transmit\nantenna, and receive antenna into account, and extract the optimal rotation\nangles after investigating their impacts on the capacity. Moreover, we present\na location-dependent expression of the ergodic capacity and investigate the RIS\ndeployment strategy, i.e. the joint rotation adjustment and location selection.\nFinally, simulation results verify the accuracy of the theoretical analyses and\ndeployment strategy. Although the RIS location has a big impact on the\nperformance, our results showcase that the RIS rotation plays a more important\nrole. In other words, we can obtain a considerable improvement by properly\nrotating the RIS rather than moving it over a wide area. For instance, we can\nachieve more than 200\\% performance improvement through rotating the RIS by\n42.14$^{\\circ}$, while an 150\\% improvement is obtained by shifting the RIS\nover 400 meters.",
    "descriptor": "",
    "authors": [
      "Yajun Cheng",
      "Wei Peng",
      "Chongwen Huang",
      "George C. Alexandropoulos",
      "Chau Yuen",
      "M\u00e9rouane Debbah"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.05569"
  },
  {
    "id": "arXiv:2202.05572",
    "title": "STEP: State Estimator for Legged Robots Using a Preintegrated foot  Velocity Factor",
    "abstract": "We propose a novel state estimator for legged robots, STEP, achieved through\na novel preintegrated foot velocity factor. In the preintegrated foot velocity\nfactor, the usual non-slip assumption is not adopted. Instead, the end effector\nvelocity becomes observable by exploiting the body speed obtained from a stereo\ncamera. In other words, the preintegrated end effector's pose can be estimated.\nAnother advantage of our approach is that it eliminates the necessity for a\ncontact detection step, unlike the typical approaches. The proposed method has\nalso been validated in harsh-environment simulations and real-world experiments\ncontaining uneven or slippery terrains.",
    "descriptor": "",
    "authors": [
      "Yeeun Kim",
      "Byeongho Yu",
      "Eungchang Mason Lee",
      "Joon-ha Kim",
      "Hae-won Park",
      "Hyun Myung"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.05572"
  },
  {
    "id": "arXiv:2202.05573",
    "title": "Very Pwnable Network: Cisco AnyConnect Security Analysis",
    "abstract": "Corporate Virtual Private Networks (VPNs) enable users to work from home or\nwhile traveling. At the same time, VPNs are tied to a company's network\ninfrastructure, forcing users to install proprietary clients for network\ncompatibility reasons. VPN clients run with high privileges to encrypt and\nreroute network traffic. Thus, bugs in VPN clients pose a substantial risk to\ntheir users and in turn the corporate network. Cisco, the dominating vendor of\nenterprise network hardware, offers VPN connectivity with their AnyConnect\nclient for desktop and mobile devices. While past security research primarily\nfocused on the AnyConnect Windows client, we show that Linux and iOS are based\non different architectures and have distinct security issues. Our reverse\nengineering as well as the follow-up design analysis and fuzzing reveal 13 new\nvulnerabilities. Seven of these are located in the Linux client. The root cause\nfor privilege escalations on Linux is anchored so deep in the client's\narchitecture that it only got patched with a partial workaround. A similar\nanalysis on iOS uncovers three AnyConnect-specific bugs as well as three\ngeneral issues in iOS network extensions, which apply to all kinds of VPNs and\nare not restricted to AnyConnect.",
    "descriptor": "",
    "authors": [
      "Gerbert Roitburd",
      "Matthias Ortmann",
      "Matthias Hollick",
      "Jiska Classen"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.05573"
  },
  {
    "id": "arXiv:2202.05577",
    "title": "A Quick Repair Facility for Debugging",
    "abstract": "Modern development environments provide a widely used auto-correction\nfacility for quickly repairing syntactic errors. Auto-correction cannot deal\nwith semantic errors, which are much more difficult to repair. Automated\nprogram repair techniques, designed for repairing semantic errors, are not\nwell-suited for interactive use while debugging, as they typically assume the\nexistence of a high-quality test suite and take considerable time. To bridge\nthe gap, we developed ROSE, a tool to suggest quick-yet-effective repairs of\nsemantic errors during debugging. ROSE does not rely on a test suite. Instead,\nit assumes a debugger stopping point where a problem is observed. It asks the\ndeveloper to quickly describe what is wrong, performs a light-weight fault\nlocalization to identify potential responsible locations, and uses a\ngenerate-and-validate strategy to produce and validate repairs. Finally, it\npresents the results so the developer can choose and make the appropriate\nrepair. To assess its utility, we implemented a prototype of ROSE that works in\nthe Eclipse IDE and applied it to two benchmarks, QuixBugs and Defects4J, for\nrepair. ROSE was able to suggest correct repairs for 17 QuixBugs and 16\nDefects4J errors in seconds.",
    "descriptor": "",
    "authors": [
      "Steven P. Reiss",
      "Qi Xin"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2202.05577"
  },
  {
    "id": "arXiv:2202.05583",
    "title": "Similarity learning for wells based on logging data",
    "abstract": "One of the first steps during the investigation of geological objects is the\ninterwell correlation. It provides information on the structure of the objects\nunder study, as it comprises the framework for constructing geological models\nand assessing hydrocarbon reserves. Today, the detailed interwell correlation\nrelies on manual analysis of well-logging data. Thus, it is time-consuming and\nof a subjective nature. The essence of the interwell correlation constitutes an\nassessment of the similarities between geological profiles. There were many\nattempts to automate the process of interwell correlation by means of\nrule-based approaches, classic machine learning approaches, and deep learning\napproaches in the past. However, most approaches are of limited usage and\ninherent subjectivity of experts. We propose a novel framework to solve the\ngeological profile similarity estimation based on a deep learning model. Our\nsimilarity model takes well-logging data as input and provides the similarity\nof wells as output. The developed framework enables (1) extracting patterns and\nessential characteristics of geological profiles within the wells and (2) model\ntraining following the unsupervised paradigm without the need for manual\nanalysis and interpretation of well-logging data. For model testing, we used\ntwo open datasets originating in New Zealand and Norway. Our data-based\nsimilarity models provide high performance: the accuracy of our model is\n$0.926$ compared to $0.787$ for baselines based on the popular gradient\nboosting approach. With them, an oil\\&gas practitioner can improve interwell\ncorrelation quality and reduce operation time.",
    "descriptor": "",
    "authors": [
      "Evgenia Romanenkova",
      "Alina Rogulina",
      "Anuar Shakirov",
      "Nikolay Stulov",
      "Alexey Zaytsev",
      "Leyla Ismailova",
      "Dmitry Kovalev",
      "Klemens Katterbauer",
      "Abdallah AlShehri"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.05583"
  },
  {
    "id": "arXiv:2202.05587",
    "title": "Formal verification of iterative convergence of numerical algorithms",
    "abstract": "Physical systems are usually modeled by differential equations, but solving\nthese differential equations analytically is often intractable. Instead, the\ndifferential equations can be solved numerically by discretization in a finite\ncomputational domain. The discretized equation is reduced to a large linear\nsystem, whose solution is typically found using an iterative solver. We start\nwith an initial guess, x_0, and iterate the algorithm to obtain a sequence of\nsolution vectors, x_m. The iterative algorithm is said to converge to solution\n$x$ if and only if x_m converges to $x$.\nAccuracy of the numerical solutions is important, especially in the design of\nsafety critical systems such as airplanes, cars, or nuclear power plants. It is\ntherefore important to formally guarantee that the iterative solvers converge\nto the \"true\" solution of the original differential equation. In this paper, we\nfirst formalize the necessary and sufficient conditions for iterative\nconvergence in the Coq proof assistant. We then extend this result to two\nclassical iterative methods: Gauss-Seidel iteration and Jacobi iteration. We\nformalize conditions for the convergence of the Gauss--Seidel classical\niterative method, based on positive definiteness of the iterative matrix. We\nthen formally state conditions for convergence of Jacobi iteration and\ninstantiate it with an example to demonstrate convergence of iterative\nsolutions to the direct solution of the linear system. We leverage recent\ndevelopments of the Coq linear algebra and mathcomp library for our\nformalization.",
    "descriptor": "",
    "authors": [
      "Mohit Tekriwal",
      "Joshua Miller",
      "Jean-Baptiste Jeannin"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.05587"
  },
  {
    "id": "arXiv:2202.05591",
    "title": "Predicting Fuel Consumption in Power Generation Plants using Machine  Learning and Neural Networks",
    "abstract": "The instability of power generation from national grids has led industries\n(e.g., telecommunication) to rely on plant generators to run their businesses.\nHowever, these secondary generators create additional challenges such as fuel\nleakages in and out of the system and perturbations in the fuel level gauges.\nConsequently, telecommunication operators have been involved in a constant need\nfor fuel to supply diesel generators. With the increase in fuel prices due to\nsocio-economic factors, excessive fuel consumption and fuel pilferage become a\nproblem, and this affects the smooth run of the network companies. In this\nwork, we compared four machine learning algorithms (i.e. Gradient Boosting,\nRandom Forest, Neural Network, and Lasso) to predict the amount of fuel\nconsumed by a power generation plant. After evaluating the predictive accuracy\nof these models, the Gradient Boosting model out-perform the other three\nregressor models with the highest Nash efficiency value of 99.1%.",
    "descriptor": "",
    "authors": [
      "Gabin Maxime Nguegnang",
      "Marcellin Atemkeng",
      "Theophilus Ansah-Narh",
      "Rockefeller Rockefeller",
      "Gabin Maxime Nguegnang",
      "Marco Andrea Garuti"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.05591"
  },
  {
    "id": "arXiv:2202.05592",
    "title": "Video-driven Neural Physically-based Facial Asset for Production",
    "abstract": "Production-level workflows for producing convincing 3D dynamic human faces\nhave long relied on a disarray of labor-intensive tools for geometry and\ntexture generation, motion capture and rigging, and expression synthesis.\nRecent neural approaches automate individual components but the corresponding\nlatent representations cannot provide artists explicit controls as in\nconventional tools. In this paper, we present a new learning-based,\nvideo-driven approach for generating dynamic facial geometries with\nhigh-quality physically-based assets. Two key components are well-structured\nlatent spaces due to dense temporal samplings from videos and explicit facial\nexpression controls to regulate the latent spaces. For data collection, we\nconstruct a hybrid multiview-photometric capture stage, coupling with an\nultra-fast video camera to obtain raw 3D facial assets. We then model the\nfacial expression, geometry and physically-based textures using separate VAEs\nwith a global MLP-based expression mapping across the latent spaces, to\npreserve characteristics across respective attributes while maintaining\nexplicit controls over geometry and texture. We also introduce to model the\ndelta information as wrinkle maps for physically-base textures, achieving\nhigh-quality rendering of dynamic textures. We demonstrate our approach in\nhigh-fidelity performer-specific facial capture and cross-identity facial\nmotion retargeting. In addition, our neural asset along with fast adaptation\nschemes can also be deployed to handle in-the-wild videos. Besides, we motivate\nthe utility of our explicit facial disentangle strategy by providing promising\nphysically-based editing results like geometry and material editing or winkle\ntransfer with high realism. Comprehensive experiments show that our technique\nprovides higher accuracy and visual fidelity than previous video-driven facial\nreconstruction and animation methods.",
    "descriptor": "",
    "authors": [
      "Longwen Zhang",
      "Chuxiao Zeng",
      "Qixuan Zhang",
      "Hongyang Lin",
      "Ruixiang Cao",
      "Wei Yang",
      "Lan Xu",
      "Jingyi Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.05592"
  },
  {
    "id": "arXiv:2202.05594",
    "title": "The Shapley Value in Machine Learning",
    "abstract": "Over the last few years, the Shapley value, a solution concept from\ncooperative game theory, has found numerous applications in machine learning.\nIn this paper, we first discuss fundamental concepts of cooperative game theory\nand axiomatic properties of the Shapley value. Then we give an overview of the\nmost important applications of the Shapley value in machine learning: feature\nselection, explainability, multi-agent reinforcement learning, ensemble\npruning, and data valuation. We examine the most crucial limitations of the\nShapley value and point out directions for future research.",
    "descriptor": "\nComments: this https URL\n",
    "authors": [
      "Benedek Rozemberczki",
      "Lauren Watson",
      "P\u00e9ter Bayer",
      "Hao-Tsung Yang",
      "Oliv\u00e9r Kiss",
      "Sebastian Nilsson",
      "Rik Sarkar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2202.05594"
  },
  {
    "id": "arXiv:2202.05599",
    "title": "ClidSum: A Benchmark Dataset for Cross-Lingual Dialogue Summarization",
    "abstract": "We present ClidSum, a benchmark dataset for building cross-lingual\nsummarization systems on dialogue documents. It consists of 67k+ dialogue\ndocuments from two subsets (i.e., SAMSum and MediaSum) and 112k+ annotated\nsummaries in different target languages. Based on the proposed ClidSum, we\nintroduce two benchmark settings for supervised and semi-supervised scenarios,\nrespectively. We then build various baseline systems in different paradigms\n(pipeline and end-to-end) and conduct extensive experiments on ClidSum to\nprovide deeper analyses. Furthermore, we propose mDialBART which extends\nmBART-50 (a multi-lingual BART) via further pre-training. The multiple\nobjectives used in the further pre-training stage help the pre-trained model\ncapture the structural characteristics as well as important content in\ndialogues and the transformation from source to the target language.\nExperimental results show the superiority of mDialBART, as an end-to-end model,\noutperforms strong pipeline models on ClidSum. Finally, we discuss specific\nchallenges that current approaches faced with this task and give multiple\npromising directions for future research. We have released the dataset and code\nat https://github.com/krystalan/ClidSum.",
    "descriptor": "",
    "authors": [
      "Jiaan Wang",
      "Fandong Meng",
      "Ziyao Lu",
      "Duo Zheng",
      "Zhixu Li",
      "Jianfeng Qu",
      "Jie Zhou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.05599"
  },
  {
    "id": "arXiv:2202.05607",
    "title": "Online Decision Transformer",
    "abstract": "Recent work has shown that offline reinforcement learning (RL) can be\nformulated as a sequence modeling problem (Chen et al., 2021; Janner et al.,\n2021) and solved via approaches similar to large-scale language modeling.\nHowever, any practical instantiation of RL also involves an online component,\nwhere policies pretrained on passive offline datasets are finetuned via\ntaskspecific interactions with the environment. We propose Online Decision\nTransformers (ODT), an RL algorithm based on sequence modeling that blends\noffline pretraining with online finetuning in a unified framework. Our\nframework uses sequence-level entropy regularizers in conjunction with\nautoregressive modeling objectives for sample-efficient exploration and\nfinetuning. Empirically, we show that ODT is competitive with the\nstate-of-the-art in absolute performance on the D4RL benchmark but shows much\nmore significant gains during the finetuning procedure.",
    "descriptor": "",
    "authors": [
      "Qinqing Zheng",
      "Amy Zhang",
      "Aditya Grover"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.05607"
  },
  {
    "id": "arXiv:2202.05609",
    "title": "Non-Stop & Non-Breakable Code Review Services in a Distributed System:  Detecting Issues in Real Time",
    "abstract": "The two most significant bottlenecks in code merging are the build process\nand the unit tests. However, as the number of items to be checked in a code\nreview increases, that code review becomes a bottleneck for code merging as\nwell. Because of the dependency structure between code review services, an\nerror in one service affects the entire service. As a result, whenever a\nservice error occurs, it is crucial to have methods for determining which code\nreview service has ultimately caused the error. With the goal of achieving a\nnon-stop & non-breakable code review service, this paper describes an early\nerror detection method along with a case study of the service.",
    "descriptor": "\nComments: 3 pages, 4 figures\n",
    "authors": [
      "Geunsik Lim",
      "Yonghwi Kwon",
      "Joonbae Park",
      "Chul-Joo Kim"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2202.05609"
  },
  {
    "id": "arXiv:2202.05613",
    "title": "CMW-Net: Learning a Class-Aware Sample Weighting Mapping for Robust Deep  Learning",
    "abstract": "Modern deep neural networks can easily overfit to biased training data\ncontaining corrupted labels or class imbalance. Sample re-weighting methods are\npopularly used to alleviate this data bias issue. Most current methods,\nhowever, require to manually pre-specify the weighting schemes as well as their\nadditional hyper-parameters relying on the characteristics of the investigated\nproblem and training data. This makes them fairly hard to be generally applied\nin practical scenarios, due to their significant complexities and inter-class\nvariations of data bias situations. To address this issue, we propose a\nmeta-model capable of adaptively learning an explicit weighting scheme directly\nfrom data. Specifically, by seeing each training class as a separate learning\ntask, our method aims to extract an explicit weighting function with sample\nloss and task/class feature as input, and sample weight as output, expecting to\nimpose adaptively varying weighting schemes to different sample classes based\non their own intrinsic bias characteristics. Synthetic and real data\nexperiments substantiate the capability of our method on achieving proper\nweighting schemes in various data bias cases, like the class imbalance,\nfeature-independent and dependent label noise scenarios, and more complicated\nbias scenarios beyond conventional cases. Besides, the task-transferability of\nthe learned weighting scheme is also substantiated, by readily deploying the\nweighting function learned on relatively smaller-scale CIFAR-10 dataset on much\nlarger-scale full WebVision dataset. A performance gain can be readily achieved\ncompared with previous SOAT ones without additional hyper-parameter tuning and\nmeta gradient descent step. The general availability of our method for multiple\nrobust deep learning issues, including partial-label learning, semi-supervised\nlearning and selective classification, has also been validated.",
    "descriptor": "\nComments: 16 pages main paper\n",
    "authors": [
      "Jun Shu",
      "Xiang Yuan",
      "Deyu Meng",
      "Zongben Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.05613"
  },
  {
    "id": "arXiv:2202.05619",
    "title": "Self-Sovereign Personal Cryptocurrencies: Foundations for Grassroots  Cryptoeconomy",
    "abstract": "The ecosystem of cryptocurrencies benefits the few and exacerbates economic\ninequality. Here, we aim to offer an egalitarian and inclusive alternative by\nmorphing the concepts, tools and technologies developed by the cryptocurrencies\necosystem, together with the distributed computing technology that enabled it,\ninto novel foundations for grassroots cryptoeconomy. The foundations are\nlayered, with each layer consisting of a cryptoeconomic component and a\ncomputational component, supporting the layers above.\nA key message of this paper is the coupling of the economic and computational\nfeatures of the novel consensus-free zone: rich economic functionality with\nlean computational implementations. They make the proposed layered\narchitecture, inclusive of the consensus-based layer, promising foundations for\ngrassroots cryptoeconomy.",
    "descriptor": "",
    "authors": [
      "Ehud Shapiro"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2202.05619"
  },
  {
    "id": "arXiv:2202.05626",
    "title": "Audio-Based Deep Learning Frameworks for Detecting COVID-19",
    "abstract": "This paper evaluates a wide range of audio-based deep learning frameworks\napplied to the breathing, cough, and speech sounds for detecting COVID-19. In\ngeneral, the audio recording inputs are transformed into low-level spectrogram\nfeatures, then they are fed into pre-trained deep learning models to extract\nhigh-level embedding features. Next, the dimension of these high-level\nembedding features are reduced before finetuning using Light Gradient Boosting\nMachine (LightGBM) as a back-end classification. Our experiments on the Second\nDiCOVA Challenge achieved the highest Area Under the Curve (AUC), F1 score,\nsensitivity score, and specificity score of 89.03%, 64.41%, 63.33%, and 95.13%,\nrespectively. Based on these scores, our method outperforms the\nstate-of-the-art systems, and improves the challenge baseline by 4.33%, 6.00%\nand 8.33% in terms of AUC, F1 score and sensitivity score, respectively.",
    "descriptor": "",
    "authors": [
      "Dat Ngo",
      "Lam Pham",
      "Truong Hoang",
      "Sefki Kolozali",
      "Delaram Jarchi"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2202.05626"
  },
  {
    "id": "arXiv:2202.05628",
    "title": "Artemis: Articulated Neural Pets with Appearance and Motion synthesis",
    "abstract": "We human are entering into a virtual era, and surely want to bring animals to\nvirtual world as well for companion. Yet, computer-generated (CGI) furry\nanimals is limited by tedious off-line rendering, let alone interactive motion\ncontrol. In this paper, we present ARTEMIS, a novel neural modeling and\nrendering pipeline for generating ARTiculated neural pets with appEarance and\nMotion synthesIS. Our ARTEMIS enables interactive motion control, real-time\nanimation and photo-realistic rendering of furry animals. The core of ARTEMIS\nis a neural-generated (NGI) animal engine, which adopts an efficient octree\nbased representation for animal animation and fur rendering. The animation then\nbecomes equivalent to voxel level skeleton based deformation. We further use a\nfast octree indexing, an efficient volumetric rendering scheme to generate\nappearance and density features maps. Finally, we propose a novel shading\nnetwork to generate high-fidelity details of appearance and opacity under novel\nposes. For the motion control module in ARTEMIS, we combine state-of-the-art\nanimal motion capture approach with neural character control scheme. We\nintroduce an effective optimization scheme to reconstruct skeletal motion of\nreal animals captured by a multi-view RGB and Vicon camera array. We feed the\ncaptured motion into a neural character control scheme to generate abstract\ncontrol signals with motion styles. We further integrate ARTEMIS into existing\nengines that support VR headsets, providing an unprecedented immersive\nexperience where a user can intimately interact with a variety of virtual\nanimals with vivid movements and photo-realistic appearance. Extensive\nexperiments and showcases demonstrate the effectiveness of our ARTEMIS system\nto achieve highly realistic rendering of NGI animals in real-time, providing\ndaily immersive and interactive experience with digital animals unseen before.",
    "descriptor": "",
    "authors": [
      "Haimin Luo",
      "Teng Xu",
      "Yuheng Jiang",
      "Chenglin Zhou",
      "QIwei Qiu",
      "Yingliang Zhang",
      "Wei Yang",
      "Lan Xu",
      "Jingyi Yu"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.05628"
  },
  {
    "id": "arXiv:2202.05629",
    "title": "BlockMeter: An Application Agnostic Performance Measurement Framework  For Private Blockchain Platforms",
    "abstract": "Blockchain Technology is an emerging technology with the potential to disrupt\na number of application domains. Though blockchain platforms like Bitcoin and\nEthereum have seen immense success and acceptability, their nature of being\npublic and anonymous make them unsuitable for many enterprise level use-cases.\nTo address this issue, Linux Foundation has started an open source umbrella\ninitiative, known as the Hyperledger Platforms. Under this initiative, a number\nof private blockchain platforms have been developed which can be used for\ndifferent enterprise level applications. However, the scalability and\nperformance of these private blockchains must be examined to understand their\nsuitability for different use-cases. Recent researches and projects on\nperformance benchmarking for private blockchain systems are very specific to\nuse-cases and are generally tied to a blockchain platform. In this article, we\npresentBlockMeter, an application agnostic performance benchmarking framework\nfor private blockchain platforms. This framework can be utilised to measure the\nkey performance matrices of any application deployed on top of an external\nprivate blockchain application in real-time. In this article, we present the\narchitecture of the framework and discuss its different implementation aspects.\nThen, to showcase the applicability of the framework, we use BlockMeter to\nevaluate the two most widely used Hyperledger platforms, Hyperledger Fabric and\nHyperledgerSawtooth, against a number of use-cases.",
    "descriptor": "",
    "authors": [
      "Ifteher Alom",
      "Md Sadek Ferdous",
      "Mohammad Jabed Morshed Chowdhury"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2202.05629"
  },
  {
    "id": "arXiv:2202.05630",
    "title": "Scale-free Unconstrained Online Learning for Curved Losses",
    "abstract": "A sequence of works in unconstrained online convex optimisation have\ninvestigated the possibility of adapting simultaneously to the norm $U$ of the\ncomparator and the maximum norm $G$ of the gradients. In full generality,\nmatching upper and lower bounds are known which show that this comes at the\nunavoidable cost of an additive $G U^3$, which is not needed when either $G$ or\n$U$ is known in advance. Surprisingly, recent results by Kempka et al. (2019)\nshow that no such price for adaptivity is needed in the specific case of\n$1$-Lipschitz losses like the hinge loss. We follow up on this observation by\nshowing that there is in fact never a price to pay for adaptivity if we\nspecialise to any of the other common supervised online learning losses: our\nresults cover log loss, (linear and non-parametric) logistic regression, square\nloss prediction, and (linear and non-parametric) least-squares regression. We\nalso fill in several gaps in the literature by providing matching lower bounds\nwith an explicit dependence on $U$. In all cases we obtain scale-free\nalgorithms, which are suitably invariant under rescaling of the data. Our\ngeneral goal is to establish achievable rates without concern for computational\nefficiency, but for linear logistic regression we also provide an adaptive\nmethod that is as efficient as the recent non-adaptive algorithm by Agarwal et\nal. (2021).",
    "descriptor": "\nComments: 33 pages\n",
    "authors": [
      "Jack J. Mayo",
      "H\u00e9di Hadiji",
      "Tim van Erven"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.05630"
  },
  {
    "id": "arXiv:2202.05638",
    "title": "Efficient Kernel UCB for Contextual Bandits",
    "abstract": "In this paper, we tackle the computational efficiency of kernelized UCB\nalgorithms in contextual bandits. While standard methods require a O(CT^3)\ncomplexity where T is the horizon and the constant C is related to optimizing\nthe UCB rule, we propose an efficient contextual algorithm for large-scale\nproblems. Specifically, our method relies on incremental Nystrom approximations\nof the joint kernel embedding of contexts and actions. This allows us to\nachieve a complexity of O(CTm^2) where m is the number of Nystrom points. To\nrecover the same regret as the standard kernelized UCB algorithm, m needs to be\nof order of the effective dimension of the problem, which is at most\nO(\\sqrt(T)) and nearly constant in some cases.",
    "descriptor": "\nComments: To appear at AISTATS2022\n",
    "authors": [
      "Houssam Zenati",
      "Alberto Bietti",
      "Eustache Diemert",
      "Julien Mairal",
      "Matthieu Martin",
      "Pierre Gaillard"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.05638"
  },
  {
    "id": "arXiv:2202.05639",
    "title": "A Scalable Database for the Storage of Object-Centric Event Logs",
    "abstract": "Object-centric process mining provides a set of techniques for the analysis\nof event data where events are associated to several objects. To store\nObject-centric Event Logs (OCELs), the JSON-OCEL and JSON-XML formats have been\nrecently proposed. However, the proposed implementations of the OCEL are\nfile-based. This means that the entire file needs to be parsed in order to\napply process mining techniques, such as the discovery of object-centric\nprocess models. In this paper, we propose a database storage for the OCEL\nformat using the MongoDB document database. Since documents in MongoDB are\nequivalent to JSON objects, the current JSON implementation of the standard\ncould be translated straightforwardly in a series of MongoDB collections.",
    "descriptor": "",
    "authors": [
      "Alessandro Berti",
      "Anahita Farhang Ghahfarokhi",
      "Gyunam Park",
      "Wil M.P. van der Aalst"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2202.05639"
  },
  {
    "id": "arXiv:2202.05641",
    "title": "NALABS: Detecting Bad Smells in Natural Language Requirements and Test  Specifications",
    "abstract": "In large-scale embedded system development, requirement and test\nspecifications are often expressed in natural language are playing an important\nrole in software quality. In the context of developing such products,\nrequirement review is performed in many cases manually using these\nspecifications as a basis for quality assurance. Low-quality specifications can\nhave expensive consequences during the requirement engineering process.\nEspecially, if feedback loops during requirement engineering are long, leading\nto artifacts that are not easily maintainable, are hard to understand, and are\ninefficient to port to other system variants. We use the idea of smells to\nspecifications expressed in natural language, defining a set of specifications\nfor bad smells. We developed a tool called NALABS (NAtural LAnguage Bad\nSmells), available on https://github.com/eduardenoiu/NALABS and used for\nautomatically checking specifications. We discuss some of the decisions made\nfor its implementation, and future work.",
    "descriptor": "",
    "authors": [
      "Kostadin Rajkovic",
      "Eduard Enoiu"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2202.05641"
  },
  {
    "id": "arXiv:2202.05651",
    "title": "Notes on switching lemmas",
    "abstract": "We prove three switching lemmas, for random restrictions for which variables\nare set independently; for random restrictions where variables are set in\nblocks (both due to Hastad [Hastad 86]); and for a distribution appropriate for\nthe bijective pigeonhole principle [Beame et al. 94, Krajicek et al. 95]. The\nproofs are based on Beame's version [Beame 94] of Razborov's proof of the\nswitching lemma in [Razborov 93], except using families of weighted\nrestrictions rather than families of restrictions which are all the same size.\nThis follows a suggestion of Beame in [Beame 94]. The result is something\nbetween Hastad's and Razborov's methods of proof. We use probabilistic\narguments rather than counting ones, in a similar way to Hastad, but rather\nthan doing induction on the terms in our formula with an inductive hypothesis\ninvolving conditional probability, as Hastad does, we explicitly build one\nfunction to bound the probabilities for the whole formula.",
    "descriptor": "\nComments: These notes were originally published online in May 2009 on the author's website\n",
    "authors": [
      "Neil Thapen"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2202.05651"
  },
  {
    "id": "arXiv:2202.05652",
    "title": "Numerical schemes for a multi-species BGK model with velocity-dependent  collision frequency",
    "abstract": "We consider a kinetic description of a multi-species gas mixture modeled with\nBhatnagar-Gross-Krook (BGK) collision operators, in which the collision\nfrequency varies not only in time and space but also with the microscopic\nvelocity. In this model, the Maxwellians typically used in standard BGK\noperators are replaced by a generalization of such target functions, which are\ndefined by a variational procedure \\cite{arXiv:2101.09047}. In this paper we\npresent a numerical method for simulating this model, which uses an\nImplicit-Explicit (IMEX) scheme to minimize a certain potential function,\nmimicking the Lagrange functional that appears in the theoretical derivation.\nWe show that theoretical properties such as conservation of mass, total\nmomentum and total energy as well as positivity of the distribution functions\nare preserved by the numerical method, and illustrate its usefulness and\neffectiveness with numerical examples.",
    "descriptor": "",
    "authors": [
      "Jeffrey Haack",
      "Cory Hauck",
      "Christian Klingenberg",
      "Marlies Pirner",
      "Sandra Warnecke"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Mathematical Physics (math-ph)"
    ],
    "url": "https://arxiv.org/abs/2202.05652"
  },
  {
    "id": "arXiv:2202.05655",
    "title": "Spatial Reuse in Dense Wireless Areas: A Cross-layer Optimization  Approach via ADMM",
    "abstract": "This paper introduces an efficient method for communication resource use in\ndense wireless areas where all nodes must communicate with a common destination\nnode. The proposed method groups nodes based on their \\newt{distance from the\ndestination} and creates a structured multi-hop configuration in which each\ngroup can relay its neighbor's data. \\newt{The large number of active radio\nnodes and the common direction of communication toward a single destination are\nexploited to reuse the limited spectrum resources in spatially separated\ngroups}. Spectrum allocation constraints among groups are then embedded in a\njoint routing and resource allocation framework to optimize the route and\namount of resources allocated to each node. \\newt{The solution to this problem\nuses coordination among the lower-layers of the wireless-network protocol stack\nto outperform conventional approaches where these layers are decoupled.\nFurthermore, the structure of this problem is exploited to obtain} a\nsemi-distributed optimization algorithm based on the alternating direction\nmethod of multipliers (ADMM) where each node can optimize its resources\nindependently based on local channel information.",
    "descriptor": "",
    "authors": [
      "Haleh Tabrizi",
      "Borja Peleato",
      "Golnaz Farhadi",
      "John M. Cioffi",
      "Ghadah Aldabbagh"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.05655"
  },
  {
    "id": "arXiv:2202.05656",
    "title": "InterpretTime: a new approach for the systematic evaluation of  neural-network interpretability in time series classification",
    "abstract": "We present a novel approach to evaluate the performance of interpretability\nmethods for time series classification, and propose a new strategy to assess\nthe similarity between domain experts and machine data interpretation. The\nnovel approach leverages a new family of synthetic datasets and introduces new\ninterpretability evaluation metrics. The approach addresses several common\nissues encountered in the literature, and clearly depicts how well an\ninterpretability method is capturing neural network's data usage, providing a\nsystematic interpretability evaluation framework. The new methodology\nhighlights the superiority of Shapley Value Sampling and Integrated Gradients\nfor interpretability in time-series classification tasks.",
    "descriptor": "",
    "authors": [
      "Hugues Turb\u00e9",
      "Mina Bjelogrlic",
      "Christian Lovis",
      "Gianmarco Mengaldo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.05656"
  },
  {
    "id": "arXiv:2202.05658",
    "title": "Stable approximation of Helmholtz solutions by evanescent plane waves",
    "abstract": "Solutions of the Helmholtz equation are known to be well approximated by\nsuperpositions of propagative plane waves. This observation is the foundation\nof successful Trefftz methods. However, when too many plane waves are used, the\ncomputation of the expansion is known to be numerically unstable. We explain\nhow this effect is due to the presence of exponentially large coefficients in\nthe expansion and can drastically limit the efficiency of the approach. In this\nwork, we show that the Helmholtz solutions on a disk can be exactly represented\nby a continuous superposition of evanescent plane waves, generalizing the\nstandard Herglotz representation. Here, by evanescent plane waves, we mean\nexponential plane waves with complex-valued propagation vector, whose absolute\nvalue decays exponentially in one direction. In addition, the density in this\nrepresentation is proved to be uniformly bounded in a suitable weighted\nLebesgue norm, hence overcoming the instability observed with propagative plane\nwaves and paving the way for stable discrete expansions. In view of practical\nimplementations, discretization strategies are investigated. We construct\nsuitable finite-dimensional sets of evanescent plane waves using sampling\nstrategies in a parametric domain. Provided one uses sufficient oversampling\nand regularization, the resulting approximations are shown to be both\ncontrollably accurate and numerically stable, as supported by numerical\nevidence.",
    "descriptor": "",
    "authors": [
      "Emile Parolin",
      "Daan Huybrechs",
      "Andrea Moiola"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.05658"
  },
  {
    "id": "arXiv:2202.05659",
    "title": "Tiny Object Tracking: A Large-scale Dataset and A Baseline",
    "abstract": "Tiny objects, frequently appearing in practical applications, have weak\nappearance and features, and receive increasing interests in meany vision\ntasks, such as object detection and segmentation. To promote the research and\ndevelopment of tiny object tracking, we create a large-scale video dataset,\nwhich contains 434 sequences with a total of more than 217K frames. Each frame\nis carefully annotated with a high-quality bounding box. In data creation, we\ntake 12 challenge attributes into account to cover a broad range of viewpoints\nand scene complexities, and annotate these attributes for facilitating the\nattribute-based performance analysis. To provide a strong baseline in tiny\nobject tracking, we propose a novel Multilevel Knowledge Distillation Network\n(MKDNet), which pursues three-level knowledge distillations in a unified\nframework to effectively enhance the feature representation, discrimination and\nlocalization abilities in tracking tiny objects. Extensive experiments are\nperformed on the proposed dataset, and the results prove the superiority and\neffectiveness of MKDNet compared with state-of-the-art methods. The dataset,\nthe algorithm code, and the evaluation code are available at\nhttps://github.com/mmic-lcl/Datasets-and-benchmark-code.",
    "descriptor": "",
    "authors": [
      "Yabin Zhu",
      "Chenglong Li",
      "Yao Liu",
      "Xiao Wang",
      "Jin Tang",
      "Bin Luo",
      "Zhixiang Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.05659"
  },
  {
    "id": "arXiv:2202.05661",
    "title": "Adaptive Read Thresholds for NAND Flash",
    "abstract": "A primary source of increased read time on NAND flash comes from the fact\nthat in the presence of noise, the flash medium must be read several times\nusing different read threshold voltages for the decoder to succeed. This paper\nproposes an algorithm that uses a limited number of re-reads to characterize\nthe noise distribution and recover the stored information. Both hard and soft\ndecoding are considered. For hard decoding, the paper attempts to find a read\nthreshold minimizing bit-error-rate (BER) and derives an expression for the\nresulting codeword-error-rate. For soft decoding, it shows that minimizing BER\nand minimizing codeword-error-rate are competing objectives in the presence of\na limited number of allowed re-reads, and proposes a trade-off between the two.\nThe proposed method does not require any prior knowledge about the noise\ndistribution, but can take advantage of such information when it is available.\nEach read threshold is chosen based on the results of previous reads, following\nan optimal policy derived through a dynamic programming backward recursion. The\nmethod and results are studied from the perspective of an SLC Flash memory with\nGaussian noise for each level but the paper explains how the method could be\nextended to other scenarios.",
    "descriptor": "",
    "authors": [
      "Borja Peleato",
      "Rajiv Agarwal",
      "John Cioffi",
      "Minghai Qin",
      "Paul H. Siegel"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.05661"
  },
  {
    "id": "arXiv:2202.05662",
    "title": "A Novel Chaos-based Light-weight Image Encryption Scheme for Multi-modal  Hearing Aids",
    "abstract": "Multimodal hearing aids (HAs) aim to deliver more intelligible audio in noisy\nenvironments by contextually sensing and processing data in the form of not\nonly audio but also visual information (e.g. lip reading). Machine learning\ntechniques can play a pivotal role for the contextually processing of\nmultimodal data. However, since the computational power of HA devices is low,\ntherefore this data must be processed either on the edge or cloud which, in\nturn, poses privacy concerns for sensitive user data. Existing literature\nproposes several techniques for data encryption but their computational\ncomplexity is a major bottleneck to meet strict latency requirements for\ndevelopment of future multi-modal hearing aids. To overcome this problem, this\npaper proposes a novel real-time audio/visual data encryption scheme based on\nchaos-based encryption using the Tangent-Delay Ellipse Reflecting Cavity-Map\nSystem (TD-ERCS) map and Non-linear Chaotic (NCA) Algorithm. The results\nachieved against different security parameters, including Correlation\nCoefficient, Unified Averaged Changed Intensity (UACI), Key Sensitivity\nAnalysis, Number of Changing Pixel Rate (NPCR), Mean-Square Error (MSE), Peak\nSignal to Noise Ratio (PSNR), Entropy test, and Chi-test, indicate that the\nnewly proposed scheme is more lightweight due to its lower execution time as\ncompared to existing schemes and more secure due to increased key-space against\nmodern brute-force attacks.",
    "descriptor": "",
    "authors": [
      "Awais Aziz Shah",
      "Ahsan Adeel",
      "Jawad Ahmad",
      "Ahmed Al-Dubai",
      "Mandar Gogate",
      "Abhijeet Bishnu",
      "Muhammad Diyan",
      "Tassadaq Hussain",
      "Kia Dashtipour",
      "Tharm Ratnarajah",
      "Amir Hussain"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2202.05662"
  },
  {
    "id": "arXiv:2202.05664",
    "title": "Predictive modeling of microbiological seawater quality classification  in karst region using cascade model",
    "abstract": "In this paper, an in-depth analysis of Escherichia coli seawater measurements\nduring the bathing season in the city of Rijeka, Croatia was conducted.\nSubmerged sources of groundwater were observed at several measurement locations\nwhich could be the cause for increased E. coli values. This specificity of\nkarst terrain is usually not considered during the monitoring process, thus a\nnovel measurement methodology is proposed. A cascade machine learning model is\nused to predict coastal water quality based on meteorological data, which\nimproves the level of accuracy due to data imbalance resulting from rare\noccurrences of measurements with reduced water quality. Currently, the cascade\nmodel is employed as a filter method, where measurements not classified as\nexcellent quality need to be further analyzed. However, with improvements\nproposed in the paper, the cascade model could be ultimately used as a\nstandalone method.",
    "descriptor": "\nComments: Submitted to Marine Pollution Bulletin\n",
    "authors": [
      "Ivana Lu\u010din",
      "Sini\u0161a Dru\u017eeta",
      "Goran Mau\u0161a",
      "Marta Alvir",
      "Luka Grb\u010di\u0107",
      "Darija Vuki\u0107 Lu\u0161i\u0107",
      "Ante Sikirica",
      "Lado Kranj\u010devi\u0107"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.05664"
  },
  {
    "id": "arXiv:2202.05667",
    "title": "A Multi-Domain VNE Algorithm based on Load Balancing in the IoT networks",
    "abstract": "Virtual network embedding is one of the key problems of network\nvirtualization. Since virtual network mapping is an NP-hard problem, a lot of\nresearch has focused on the evolutionary algorithm's masterpiece genetic\nalgorithm. However, the parameter setting in the traditional method is too\ndependent on experience, and its low flexibility makes it unable to adapt to\nincreasingly complex network environments. In addition, link-mapping strategies\nthat do not consider load balancing can easily cause link blocking in\nhigh-traffic environments. In the IoT environment involving medical, disaster\nrelief, life support and other equipment, network performance and stability are\nparticularly important. Therefore, how to provide a more flexible virtual\nnetwork mapping service in a heterogeneous network environment with large\ntraffic is an urgent problem. Aiming at this problem, a virtual network mapping\nstrategy based on hybrid genetic algorithm is proposed. This strategy uses a\ndynamically calculated cross-probability and pheromone-based mutation gene\nselection strategy to improve the flexibility of the algorithm. In addition, a\nweight update mechanism based on load balancing is introduced to reduce the\nprobability of mapping failure while balancing the load. Simulation results\nshow that the proposed method performs well in a number of performance metrics\nincluding mapping average quotation, link load balancing, mapping cost-benefit\nratio, acceptance rate and running time.",
    "descriptor": "",
    "authors": [
      "Peiying Zhang",
      "Fanglin Liu",
      "Chunxiao Jiang",
      "Abderrahim Benslimane",
      "Juan-Luis Gorricho",
      "Joan Serrat-Fernacute"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.05667"
  },
  {
    "id": "arXiv:2202.05679",
    "title": "Rethinking Graph Convolutional Networks in Knowledge Graph Completion",
    "abstract": "Graph convolutional networks (GCNs) -- which are effective in modeling graph\nstructures -- have been increasingly popular in knowledge graph completion\n(KGC). GCN-based KGC models first use GCNs to generate expressive entity\nrepresentations and then use knowledge graph embedding (KGE) models to capture\nthe interactions among entities and relations. However, many GCN-based KGC\nmodels fail to outperform state-of-the-art KGE models though introducing\nadditional computational complexity. This phenomenon motivates us to explore\nthe real effect of GCNs in KGC. Therefore, in this paper, we build upon\nrepresentative GCN-based KGC models and introduce variants to find which factor\nof GCNs is critical in KGC. Surprisingly, we observe from experiments that the\ngraph structure modeling in GCNs does not have a significant impact on the\nperformance of KGC models, which is in contrast to the common belief. Instead,\nthe transformations for entity representations are responsible for the\nperformance improvements. Based on the observation, we propose a simple yet\neffective framework named LTE-KGE, which equips existing KGE models with\nlinearly transformed entity embeddings. Experiments demonstrate that LTE-KGE\nmodels lead to similar performance improvements with GCN-based KGC methods,\nwhile being more computationally efficient. These results suggest that existing\nGCNs are unnecessary for KGC, and novel GCN-based KGC models should count on\nmore ablation studies to validate their effectiveness. The code of all the\nexperiments is available on GitHub at https://github.com/MIRALab-USTC/GCN4KGC.",
    "descriptor": "\nComments: Accepted to WWW 2022\n",
    "authors": [
      "Zhanqiu Zhang",
      "Jie Wang",
      "Jieping Ye",
      "Feng Wu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.05679"
  },
  {
    "id": "arXiv:2202.05682",
    "title": "GenderedNews: Une approche computationnelle des \u00e9carts de  repr\u00e9sentation des genres dans la presse fran\u00e7aise",
    "abstract": "In this article, we present GenderedNews (https://gendered-news.imag.fr), an\nonline dashboard which gives weekly measures of gender imbalance in French\nonline press. We use Natural Language Processing (NLP) methods to quantify\ngender inequalities in the media, in the wake of global projects like the\nGlobal Media Monitoring Project. Such projects are instrumental in highlighting\ngender imbalance in the media and its very slow evolution. However, their\ngeneralisation is limited by their sampling and cost in terms of time, data and\nstaff. Automation allows us to offer complementary measures to quantify\ninequalities in gender representation. We understand representation as the\npresence and distribution of men and women mentioned and quoted in the news --\nas opposed to representation as stereotypification. In this paper, we first\nreview different means adopted by previous studies on gender inequality in the\nmedia : qualitative content analysis, quantitative content analysis and\ncomputational methods. We then detail the methods adopted by {\\it GenderedNews}\nand the two metrics implemented: the masculinity rate of mentions and the\nproportion of men quoted in online news. We describe the data collected daily\n(seven main titles of French online news media) and the methodology behind our\nmetrics, as well as a few visualisations. We finally propose to illustrate\npossible analysis of our data by conducting an in-depth observation of a sample\nof two months of our database.",
    "descriptor": "\nComments: Paper in French\n",
    "authors": [
      "Ange Richard",
      "Gilles Bastin",
      "Fran\u00e7ois Portet"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2202.05682"
  },
  {
    "id": "arXiv:2202.05684",
    "title": "Statistical Analysis Based Feature Selection Enhanced RF-PUF with >99.8%  Accuracy on Unmodified Commodity Transmitters for IoT Physical Security",
    "abstract": "Due to the diverse and mobile nature of the deployment environment, smart\ncommodity devices are vulnerable to various attacks which can grant\nunauthorized access to a rogue device in a large, connected network.\nTraditional digital signature-based authentication methods are vulnerable to\nkey recovery attacks, CSRF, etc. To circumvent this, RF-PUF had been proposed\nas a promising alternative that utilizes the inherent nonidealities of the\ndevices as physical signatures. RF-PUF offers a robust authentication method\nthat is resilient to key-hacking methods due to the absence of secret key\nrequirements and does not require any additional circuitry on the transmitter\nend, eliminating additional power, area, and computational burden. In this\nwork, for the first time, we analyze the effectiveness of RF-PUF on commodity\ndevices, purchased off-the-shelf, without any modifications whatsoever. Data\nwere collected from 30 Xbee S2C modules and released as a public dataset. A new\nfeature has been engineered through statistical property analysis. With a new\nand robust feature set, it has been shown that 95% accuracy can be achieved\nusing only ~1.8 ms of test data, reaching >99.8% accuracy with more data and a\nnetwork of higher model capacity, without any assisting digital preamble. The\ndesign space has been explored in detail and the effect of the wireless channel\nhas been determined. The performance of some popular ML algorithms has been\ncompared with the NN approach. A thorough investigation on various PUF\nproperties has been done and both intra and inter-PUF distances have been\ncalculated. With extensive testing of 41238000 cases, the detection probability\nfor RF-PUF for our data is found to be 0.9987, which, for the first time,\nexperimentally establishes RF-PUF as a strong authentication method. Finally,\nthe potential attack models and the robustness of RF-PUF against them have been\ndiscussed.",
    "descriptor": "\nComments: 18 pages, 10 figures, we have made our dataset (used in this work) public and available at: this https URL\n",
    "authors": [
      "Md Faizul Bari",
      "Parv Agrawal",
      "Baibhab Chatterjee",
      "Shreyas Sen"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.05684"
  },
  {
    "id": "arXiv:2202.05685",
    "title": "SuperCon: Supervised Contrastive Learning for Imbalanced Skin Lesion  Classification",
    "abstract": "Convolutional neural networks (CNNs) have achieved great success in skin\nlesion classification. A balanced dataset is required to train a good model.\nHowever, due to the appearance of different skin lesions in practice, severe or\neven deadliest skin lesion types (e.g., melanoma) naturally have quite small\namount represented in a dataset. In that, classification performance\ndegradation occurs widely, it is significantly important to have CNNs that work\nwell on class imbalanced skin lesion image dataset. In this paper, we propose\nSuperCon, a two-stage training strategy to overcome the class imbalance problem\non skin lesion classification. It contains two stages: (i) representation\ntraining that tries to learn a feature representation that closely aligned\namong intra-classes and distantly apart from inter-classes, and (ii) classifier\nfine-tuning that aims to learn a classifier that correctly predict the label\nbased on the learnt representations. In the experimental evaluation, extensive\ncomparisons have been made among our approach and other existing approaches on\nskin lesion benchmark datasets. The results show that our two-stage training\nstrategy effectively addresses the class imbalance classification problem, and\nsignificantly improves existing works in terms of F1-score and AUC score,\nresulting in state-of-the-art performance.",
    "descriptor": "",
    "authors": [
      "Keyu Chen",
      "Di Zhuang",
      "J. Morris Chang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.05685"
  },
  {
    "id": "arXiv:2202.05687",
    "title": "Towards Adversarially Robust Deepfake Detection: An Ensemble Approach",
    "abstract": "Detecting deepfakes is an important problem, but recent work has shown that\nDNN-based deepfake detectors are brittle against adversarial deepfakes, in\nwhich an adversary adds imperceptible perturbations to a deepfake to evade\ndetection. In this work, we show that a modification to the detection strategy\nin which we replace a single classifier with a carefully chosen ensemble, in\nwhich input transformations for each model in the ensemble induces pairwise\northogonal gradients, can significantly improve robustness beyond the de facto\nsolution of adversarial training. We present theoretical results to show that\nsuch orthogonal gradients can help thwart a first-order adversary by reducing\nthe dimensionality of the input subspace in which adversarial deepfakes lie. We\nvalidate the results empirically by instantiating and evaluating a randomized\nversion of such \"orthogonal\" ensembles for adversarial deepfake detection and\nfind that these randomized ensembles exhibit significantly higher robustness as\ndeepfake detectors compared to state-of-the-art deepfake detectors against\nadversarial deepfakes, even those created using strong PGD-500 attacks.",
    "descriptor": "",
    "authors": [
      "Ashish Hooda",
      "Neal Mangaokar",
      "Ryan Feng",
      "Kassem Fawaz",
      "Somesh Jha",
      "Atul Prakash"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.05687"
  },
  {
    "id": "arXiv:2202.05689",
    "title": "Conservative Extensions for Existential Rules",
    "abstract": "We study the problem to decide, given sets T1,T2 of tuple-generating\ndependencies (TGDs), also called existential rules, whether T2 is a\nconservative extension of T1. We consider two natural notions of conservative\nextension, one pertaining to answers to conjunctive queries over databases and\none to homomorphisms between chased databases. Our main results are that these\nproblems are undecidable for linear TGDs, undecidable for guarded TGDs even\nwhen T1 is empty, and decidable for frontier-one TGDs.",
    "descriptor": "",
    "authors": [
      "Jean Christoph Jung",
      "Carsten Lutz",
      "Jerzy Macinkowski"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2202.05689"
  },
  {
    "id": "arXiv:2202.05690",
    "title": "HaT5: Hate Language Identification using Text-to-Text Transfer  Transformer",
    "abstract": "We investigate the performance of a state-of-the art (SoTA) architecture T5\n(available on the SuperGLUE) and compare with it 3 other previous SoTA\narchitectures across 5 different tasks from 2 relatively diverse datasets. The\ndatasets are diverse in terms of the number and types of tasks they have. To\nimprove performance, we augment the training data by using an autoregressive\nmodel. We achieve near-SoTA results on a couple of the tasks - macro F1 scores\nof 81.66% for task A of the OLID 2019 dataset and 82.54% for task A of the hate\nspeech and offensive content (HASOC) 2021 dataset, where SoTA are 82.9% and\n83.05%, respectively. We perform error analysis and explain why one of the\nmodels (Bi-LSTM) makes the predictions it does by using a publicly available\nalgorithm: Integrated Gradient (IG). This is because explainable artificial\nintelligence (XAI) is essential for earning the trust of users. The main\ncontributions of this work are the implementation method of T5, which is\ndiscussed; the data augmentation using a new conversational AI model\ncheckpoint, which brought performance improvements; and the revelation on the\nshortcomings of HASOC 2021 dataset. It reveals the difficulties of poor data\nannotation by using a small set of examples where the T5 model made the correct\npredictions, even when the ground truth of the test set were incorrect (in our\nopinion). We also provide our model checkpoints on the HuggingFace hub1 to\nfoster transparency.",
    "descriptor": "\nComments: 7 pages, 3 figures , conference\n",
    "authors": [
      "Sana Sabah Sabry",
      "Tosin Adewumi",
      "Nosheen Abid",
      "Gy\u00f6rgy Kovacs",
      "Foteini Liwicki",
      "Marcus Liwicki"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.05690"
  },
  {
    "id": "arXiv:2202.05691",
    "title": "A Tight $(\\frac{3}{2}+\u03b5)$-Approximation for Unsplittable  Capacitated Vehicle Routing on Trees",
    "abstract": "We give a polynomial time $(3/2+\\epsilon)$-approximation algorithm for the\nunsplittable capacitated vehicle routing problem (CVRP) on trees. Our\napproximation ratio is tight, given that it is NP-hard to approximate this\nproblem to better than a $3/2$ factor.",
    "descriptor": "",
    "authors": [
      "Claire Mathieu",
      "Hang Zhou"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2202.05691"
  },
  {
    "id": "arXiv:2202.05693",
    "title": "Black-box Identity Testing of Noncommutative Rational Formulas of  Inversion Height Two in Deterministic Quasipolynomial-time",
    "abstract": "Hrube\\v{s} and Wigderson (2015) initiated the complexity-theoretic study of\nnoncommutative formulas with inverse gates. They introduced the Rational\nIdentity Testing (RIT) problem which is to decide whether a noncommutative\nrational formula computes zero in the free skew field. In the white-box\nsetting, deterministic polynomial-time algorithms are known for this problem\nfollowing the works of Garg, Gurvits, Oliveira, and Wigderson (2016) and\nIvanyos, Qiao, and Subrahmanyam (2018).\nA central open problem in this area is to design efficient deterministic\nblack-box identity testing algorithm for rational formulas. In this paper, we\nsolve this problem for the first nested inverse case. More precisely, we obtain\na deterministic quasipolynomial-time black-box RIT algorithm for noncommutative\nrational formulas of inversion height two via a hitting set construction.\nSeveral new technical ideas are involved in the hitting set construction,\nincluding key concepts from matrix coefficient realization theory\n(Vol\\v{c}i\\v{c}, 2018) and properties of cyclic division algebra (Lam, 2001).\nEn route to the proof, an important step is to embed the hitting set of Forbes\nand Shpilka for noncommutative formulas (2013) inside a cyclic division algebra\nof small index.",
    "descriptor": "",
    "authors": [
      "V. Arvind",
      "Abhranil Chatterjee",
      "Partha Mukhopadhyay"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2202.05693"
  },
  {
    "id": "arXiv:2202.05694",
    "title": "Continual Learning with Invertible Generative Models",
    "abstract": "Catastrophic forgetting (CF) happens whenever a neural network overwrites\npast knowledge while being trained on new tasks. Common techniques to handle CF\ninclude regularization of the weights (using, e.g., their importance on past\ntasks), and rehearsal strategies, where the network is constantly re-trained on\npast data. Generative models have also been applied for the latter, in order to\nhave endless sources of data. In this paper, we propose a novel method that\ncombines the strengths of regularization and generative-based rehearsal\napproaches. Our generative model consists of a normalizing flow (NF), a\nprobabilistic and invertible neural network, trained on the internal embeddings\nof the network. By keeping a single NF throughout the training process, we show\nthat our memory overhead remains constant. In addition, exploiting the\ninvertibility of the NF, we propose a simple approach to regularize the\nnetwork's embeddings with respect to past tasks. We show that our method\nperforms favorably with espect to state-of-the-art approaches in the\nliterature, with bounded computational power and memory overheads.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2007.02443\n",
    "authors": [
      "Jary Pomponi",
      "Simone Scardapane",
      "Aurelio Uncini"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.05694"
  },
  {
    "id": "arXiv:2202.05695",
    "title": "Positive-Unlabeled Domain Adaptation",
    "abstract": "Domain Adaptation methodologies have shown to effectively generalize from a\nlabeled source domain to a label scarce target domain. Previous research has\neither focused on unlabeled domain adaptation without any target supervision or\nsemi-supervised domain adaptation with few labeled target examples per class.\nOn the other hand Positive-Unlabeled (PU-) Learning has attracted increasing\ninterest in the weakly supervised learning literature since in quite some real\nworld applications positive labels are much easier to obtain than negative\nones. In this work we are the first to introduce the challenge of\nPositive-Unlabeled Domain Adaptation where we aim to generalise from a fully\nlabeled source domain to a target domain where only positive and unlabeled data\nis available. We present a novel two-step learning approach to this problem by\nfirstly identifying reliable positive and negative pseudo-labels in the target\ndomain guided by source domain labels and a positive-unlabeled risk estimator.\nThis enables us to use a standard classifier on the target domain in a second\nstep. We validate our approach by running experiments on benchmark datasets for\nvisual object recognition. Furthermore we propose real world examples for our\nsetting and validate our superior performance on parking occupancy data.",
    "descriptor": "",
    "authors": [
      "Jonas Sonntag",
      "Gunnar Behrens",
      "Lars Schmidt-Thieme"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.05695"
  },
  {
    "id": "arXiv:2202.05697",
    "title": "XIGA: An eXtended IsoGeometric Analysis approach for multi-material  problems",
    "abstract": "Multi-material problems often exhibit complex geometries along with physical\nresponses presenting large spatial gradients or discontinuities. In these\ncases, providing high-quality body-fitted finite element analysis meshes and\nobtaining accurate solutions remain challenging. Immersed boundary techniques\nprovide elegant solutions for such problems. Enrichment methods alleviate the\nneed for generating conforming analysis grids by capturing discontinuities\nwithin mesh elements. Additionally, increased accuracy of physical responses\nand geometry description can be achieved with higher-order approximation bases.\nIn particular, using B-splines has become popular with the development of\nIsoGeometric Analysis. In this work, an eXtended IsoGeometric Analysis (XIGA)\napproach is proposed for multi-material problems. The computational domain\ngeometry is described implicitly by level set functions. A novel generalized\nHeaviside enrichment strategy is employed to accommodate an arbitrary number of\nmaterials without artificially stiffening the physical response. Higher-order\nB-spline functions are used for both geometry representation and analysis.\nBoundary and interface conditions are enforced weakly via Nitsche's method, and\na new face-oriented ghost stabilization methodology is used to mitigate\nnumerical instabilities arising from small material integration subdomains.\nTwo- and three-dimensional heat transfer and elasticity problems are solved to\nvalidate the approach. Numerical studies provide insight into the ability to\nhandle multiple materials considering sharp-edged and curved interfaces, as\nwell as the impact of higher-order bases and stabilization on the solution\naccuracy and conditioning.",
    "descriptor": "",
    "authors": [
      "L. Noel",
      "M. Schmidt",
      "K. Doble",
      "J.A. Evans",
      "K. Maute"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.05697"
  },
  {
    "id": "arXiv:2202.05698",
    "title": "Self-adjusting optimization algorithm for solving the setunion knapsack  problem",
    "abstract": "The set-union knapsack problem (SUKP) is a constrained composed optimization\nproblem. It is more difficulty for solving because values and weights depend on\nitems and elements respectively. In this paper, we present two self-adjusting\noptimization algorithms for approximating SUKP from items and elements\nperspective respectively. By analyzing the dynamic characters in the SUKP, we\ndesign two types of self-adjusting repair and optimization operators that are\nbased on the different loading process. We use the novel\nteaching-learning-based optimization algorithm (TLBO) to design a general\ndiscrete framework (DTLBO) suitable for these two types of operators. In\naddition, we introduce elite opposite search and natural selection mechanism\ninto DTLBO to furtherly improve the performance of the algorithm from the\nperspective of population. Finally, we performed experimental comparisons on\nbenchmark sets to verify the effectiveness of the proposed algorithm. The\nexperimental results show that the item-based self-adjusting optimization\nalgorithm I-DTLBO is outstanding, and the algorithm is superior to the other\nswarm intelligence methods for solving SUKP. IDTLBO algorithm reaches the upper\nboundary of the current swarm intelligence algorithms for solving SUKP in 10\ninstances, and gotten new upper boundary in 15 instances. The algorithm E-DTLBO\nbased on element loading only perform slightly better on small and middle data\nsets, but worse on large-scale instances. It shows that element-based design is\nnot suitable for solving SUKP.",
    "descriptor": "",
    "authors": [
      "Congcong Wu",
      "Xiangyun Gao",
      "Xueyong Liu",
      "Bowen Sun"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.05698"
  },
  {
    "id": "arXiv:2202.05700",
    "title": "Axiomatizing consciousness, with applications",
    "abstract": "Consciousness will be introduced axiomatically, inspired by Buddhist insight\nmeditation and psychology, logic in computer science, and cognitive\nneuroscience, as consisting of a stream of $configurations$ that is $compound$,\n$discrete$, and (non-deterministically) $computable$. Within this context the\nnotions of self, concentration, mindfulness, and various forms of suffering can\nbe defined. As an application of this set up, it will be shown how a combined\ndevelopment of concentration and mindfulness can attenuate and eventually\neradicate some of the forms of suffering.",
    "descriptor": "\nComments: 17 pages, 2 figures\n",
    "authors": [
      "Henk Barendregt",
      "Antonino Raffone"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.05700"
  },
  {
    "id": "arXiv:2202.05701",
    "title": "Minimality Notions via Factorization Systems and Examples",
    "abstract": "For the minimization of state-based systems (i.e. the reduction of the number\nof states while retaining the system's semantics), there are two obvious\naspects: removing unnecessary states of the system and merging redundant states\nin the system. In the present article, we relate the two aspects on coalgebras\nby defining an abstract notion of minimality.\nThe abstract notions minimality and minimization live in a general category\nwith a factorization system. We will find criteria on the category that ensure\nuniqueness, existence, and functoriality of the minimization aspects. The\nproofs of these results instantiate to those for reachability and observability\nminimization in the standard coalgebra literature. Finally, we will see how the\ntwo aspects of minimization interact and under which criteria they can be\nsequenced in any order, like in automata minimization.",
    "descriptor": "\nComments: Extended journal version of the conference paper arXiv:2106.07233, and thus, expected substantial text overlap\n",
    "authors": [
      "Thorsten Wi\u00dfmann"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2202.05701"
  },
  {
    "id": "arXiv:2202.05709",
    "title": "A Python Tool for Object-Centric Process Mining Comparison",
    "abstract": "Object-centric process mining provides a more holistic view of processes\nwhere we analyze processes with multiple case notions. However, most\nobject-centric process mining techniques consider the whole event log rather\nthan the comparison of existing behaviors in the log. In this paper, we\nintroduce a stand-alone object-centric process cube tool built on the PM4PY-MDL\nprocess mining framework. Our infrastructure uses both object and event\nattributes to build the process cube which leads to different types of\nmaterialization. Furthermore, our tool is equipped with the state of the art\nobject-centric process mining techniques. Through our tool the user can\nvisualize the extracted object-centric event log from process cube operations,\nexport the object-centric event log, discover the state-of-the-art\nobject-centric process model for the extracted log, and compare the process\nmodels side-by-side.",
    "descriptor": "",
    "authors": [
      "Anahita Farhang Ghahfarokhi",
      "Wil M.P. van der Aalst"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2202.05709"
  },
  {
    "id": "arXiv:2202.05710",
    "title": "Collaborative Dispersion by Silent Robots",
    "abstract": "In the dispersion problem, a set of $k$ co-located mobile robots must\nrelocate themselves in distinct nodes of an unknown network. The network is\nmodeled as an anonymous graph $G=(V,E)$, where the nodes of the graph are not\nlabeled. The edges incident to a node $v$ with degree $d$ are labeled with port\nnumbers in the range $0,1, \\cdots, d-1$ at $v$. The robots have unique ids in\nthe range $[0,L]$, where $L \\ge k$, and are initially placed at a source node\n$s$. Each robot knows only its own id but does not know the ids of the other\nrobots or the values of $L,k$. The task of dispersion was traditionally\nachieved with the assumption of two types of communication abilities: (a) when\nsome robots are at the same node, they can communicate by exchanging messages\nbetween them (b) any two robots in the network can exchange messages between\nthem.\nIn this paper, we ask whether this ability of communication among co-located\nrobots is necessary to achieve dispersion. We show that even if the ability of\ncommunication is not available, the task of dispersion by a set of mobile\nrobots can be achieved in a much weaker model where a robot at a node $v$ has\nthe access of following very restricted information at the beginning of any\nround: (1) am I alone at $v$? (2) the number of robots at $v$ increased or\ndecreased compare to the previous round?\nWe propose a deterministic algorithm that achieves dispersion on any given\ngraph $G=(V,E)$ in time $O\\left( k\\log L+k^2 \\log \\Delta\\right)$, where\n$\\Delta$ is the maximum degree of a node in $G$. Each robot uses $O(\\log L+\n\\log \\Delta)$ additional memory. We also prove that the task of dispersion\ncannot be achieved by a set of mobile robots with $o(\\log L + \\log \\Delta)$\nadditional memory.",
    "descriptor": "",
    "authors": [
      "Barun Gorain",
      "Partha Sarathi Mandal",
      "Kaushik Mondal",
      "Supantha Pandit"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2202.05710"
  },
  {
    "id": "arXiv:2202.05711",
    "title": "Global Optimization of Data Pipelines in Heterogeneous Cloud  Environments",
    "abstract": "Modern production data processing and machine learning pipelines on the cloud\nare critical components for many cloud-based companies. These pipelines are\ntypically composed of complex workflows represented by directed acyclic graphs\n(DAGs). Cloud environments are attractive to these workflows due to the wide\nrange of choice with heterogeneous instances and prices that can provide the\nflexibility for different cost-performance needs. However, this flexibility\nalso leads to the complexity of selecting the right resource configuration\n(e.g., instance type, resource demands) for each task in the DAG, while\nsimultaneously scheduling the tasks with the selected resources to reach the\noptimal end-to-end performance and cost. These two decisions are often\ncodependent resulting in an NP-hard scheduling optimization bottleneck.\nExisting solutions only focus solely on either problem and ignore the co-effect\non the end-to-end optimum. We propose AGORA, a scheduler that considers both\ntask-level resource allocation and execution for DAG workflows as a whole in\nheterogeneous cloud environments. AGORA first (1) studies the characteristics\nof the tasks from prior runs and gives predictions on resource configurations,\nand (2) automatically finds the best configuration with its corresponding\nschedules for the entire workflow with a cost-performance objective. We\nevaluate AGORA in a heterogeneous Amazon Web Services (AWS) cloud environment\nwith multi-tenant workflows served by Airflow and demonstrate a performance\nimprovement up to 45% and cost reduction up to 77% compared to state-of-the-art\nschedulers. In addition, we apply AGORA to a real-world production trace from\nAlibaba and show cost reduction of 65% and DAG completion time reduction of\n57%.",
    "descriptor": "\nComments: 13 pages\n",
    "authors": [
      "Erica Lin",
      "Luna Xu",
      "Suraj Bramhavar",
      "Marco Montes de Oca",
      "Sean Gorsky",
      "Lingyun Yi",
      "Arianna Groetsema",
      "Jeffrey Chou"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2202.05711"
  },
  {
    "id": "arXiv:2202.05713",
    "title": "Cross Domain Few-Shot Learning via Meta Adversarial Training",
    "abstract": "Few-shot relation classification (RC) is one of the critical problems in\nmachine learning. Current research merely focuses on the set-ups that both\ntraining and testing are from the same domain. However, in practice, this\nassumption is not always guaranteed. In this study, we present a novel model\nthat takes into consideration the afore-mentioned cross-domain situation. Not\nlike previous models, we only use the source domain data to train the\nprototypical networks and test the model on target domain data. A meta-based\nadversarial training framework (\\textbf{MBATF}) is proposed to fine-tune the\ntrained networks for adapting to data from the target domain. Empirical studies\nconfirm the effectiveness of the proposed model.",
    "descriptor": "\nComments: 5 pages including references, submitted to ACL2021\n",
    "authors": [
      "Jirui Qi",
      "Richong Zhang",
      "Chune Li",
      "Yongyi Mao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.05713"
  },
  {
    "id": "arXiv:2202.05714",
    "title": "Modeling Reservoir Release Using Pseudo-Prospective Learning and  Physical Simulations to Predict Water Temperature",
    "abstract": "This paper proposes a new data-driven method for predicting water temperature\nin stream networks with reservoirs. The water flows released from reservoirs\ngreatly affect the water temperature of downstream river segments. However, the\ninformation of released water flow is often not available for many reservoirs,\nwhich makes it difficult for data-driven models to capture the impact to\ndownstream river segments. In this paper, we first build a state-aware graph\nmodel to represent the interactions amongst streams and reservoirs, and then\npropose a parallel learning structure to extract the reservoir release\ninformation and use it to improve the prediction. In particular, for reservoirs\nwith no available release information, we mimic the water managers' release\ndecision process through a pseudo-prospective learning method, which infers the\nrelease information from anticipated water temperature dynamics. For reservoirs\nwith the release information, we leverage a physics-based model to simulate the\nwater release temperature and transfer such information to guide the learning\nprocess for other reservoirs. The evaluation for the Delaware River Basin shows\nthat the proposed method brings over 10\\% accuracy improvement over existing\ndata-driven models for stream temperature prediction when the release data is\nnot available for any reservoirs. The performance is further improved after we\nincorporate the release data and physical simulations for a subset of\nreservoirs.",
    "descriptor": "",
    "authors": [
      "Xiaowei Jia",
      "Shengyu Chen",
      "Yiqun Xie",
      "Haoyu Yang",
      "Alison Appling",
      "Samantha Oliver",
      "Zhe Jiang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.05714"
  },
  {
    "id": "arXiv:2202.05716",
    "title": "Choices, Risks, and Reward Reports: Charting Public Policy for  Reinforcement Learning Systems",
    "abstract": "In the long term, reinforcement learning (RL) is considered by many AI\ntheorists to be the most promising path to artificial general intelligence.\nThis places RL practitioners in a position to design systems that have never\nexisted before and lack prior documentation in law and policy. Public agencies\ncould intervene on complex dynamics that were previously too opaque to\ndeliberate about, and long-held policy ambitions would finally be made\ntractable. In this whitepaper we illustrate this potential and how it might be\ntechnically enacted in the domains of energy infrastructure, social media\nrecommender systems, and transportation. Alongside these unprecedented\ninterventions come new forms of risk that exacerbate the harms already\ngenerated by standard machine learning tools. We correspondingly present a new\ntypology of risks arising from RL design choices, falling under four\ncategories: scoping the horizon, defining rewards, pruning information, and\ntraining multiple agents. Rather than allowing RL systems to unilaterally\nreshape human domains, policymakers need new mechanisms for the rule of reason,\nforeseeability, and interoperability that match the risks these systems pose.\nWe argue that criteria for these choices may be drawn from emerging subfields\nwithin antitrust, tort, and administrative law. It will then be possible for\ncourts, federal and state agencies, and non-governmental organizations to play\nmore active roles in RL specification and evaluation. Building on the \"model\ncards\" and \"datasheets\" frameworks proposed by Mitchell et al. and Gebru et\nal., we argue the need for Reward Reports for AI systems. Reward Reports are\nliving documents for proposed RL deployments that demarcate design choices.",
    "descriptor": "\nComments: 60 pages\n",
    "authors": [
      "Thomas Krendl Gilbert",
      "Sarah Dean",
      "Tom Zick",
      "Nathan Lambert"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2202.05716"
  },
  {
    "id": "arXiv:2202.05718",
    "title": "Audio Defect Detection in Music with Deep Networks",
    "abstract": "With increasing amounts of music being digitally transferred from production\nto distribution, automatic means of determining media quality are needed.\nProtection mechanisms in digital audio processing tools have not eliminated the\nneed of production entities located downstream the distribution chain to assess\naudio quality and detect defects inserted further upstream. Such analysis often\nrelies on the received audio and scarce meta-data alone. Deliberate use of\nartefacts such as clicks in popular music as well as more recent defects\nstemming from corruption in modern audio encodings call for data-centric and\ncontext sensitive solutions for detection. We present a convolutional network\narchitecture following end-to-end encoder decoder configuration to develop\ndetectors for two exemplary audio defects. A click detector is trained and\ncompared to a traditional signal processing method, with a discussion on\ncontext sensitivity. Additional post-processing is used for data augmentation\nand workflow simulation. The ability of our models to capture variance is\nexplored in a detector for artefacts from decompression of corrupted MP3\ncompressed audio. For both tasks we describe the synthetic generation of\nartefacts for controlled detector training and evaluation. We evaluate our\ndetectors on the large open-source Free Music Archive (FMA) and genre-specific\ndatasets.",
    "descriptor": "\nComments: 6 pages\n",
    "authors": [
      "Daniel Wolff",
      "R\u00e9mi Mignot",
      "Axel Roebel"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2202.05718"
  },
  {
    "id": "arXiv:2202.05722",
    "title": "Recovering Stochastic Dynamics via Gaussian Schr\u00f6dinger Bridges",
    "abstract": "We propose a new framework to reconstruct a stochastic process\n$\\left\\{\\mathbb{P}_{t}: t \\in[0, T]\\right\\}$ using only samples from its\nmarginal distributions, observed at start and end times $0$ and $T$. This\nreconstruction is useful to infer population dynamics, a crucial challenge,\ne.g., when modeling the time-evolution of cell populations from single-cell\nsequencing data. Our general framework encompasses the more specific\nSchr\\\"odinger bridge (SB) problem, where $\\mathbb{P}_{t}$ represents the\nevolution of a thermodynamic system at almost equilibrium. Estimating such\nbridges is notoriously difficult, motivating our proposal for a novel adaptive\nscheme called the GSBflow. Our goal is to rely on Gaussian approximations of\nthe data to provide the reference stochastic process needed to estimate SB. To\nthat end, we solve the \\acs{SB} problem with Gaussian marginals, for which we\nprovide, as a central contribution, a closed-form solution and\nSDE-representation. We use these formulas to define the reference process used\nto estimate more complex SBs, and show that this does indeed help with its\nnumerical solution. We obtain notable improvements when reconstructing both\nsynthetic processes and single-cell genomics experiments.",
    "descriptor": "",
    "authors": [
      "Charlotte Bunne",
      "Ya-Ping Hsieh",
      "Marco Cuturi",
      "Andreas Krause"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2202.05722"
  },
  {
    "id": "arXiv:2202.05725",
    "title": "On the Detection of Adaptive Adversarial Attacks in Speaker Verification  Systems",
    "abstract": "Speaker verification systems have been widely used in smart phones and\nInternet of things devices to identify a legitimate user. In recent work, it\nhas been shown that adversarial attacks, such as FAKEBOB, can work effectively\nagainst speaker verification systems. The goal of this paper is to design a\ndetector that can distinguish an original audio from an audio contaminated by\nadversarial attacks. Specifically, our designed detector, called MEH-FEST,\ncalculates the minimum energy in high frequencies from the short-time Fourier\ntransform of an audio and uses it as a detection metric. Through both analysis\nand experiments, we show that our proposed detector is easy to implement, fast\nto process an input audio, and effective in determining whether an audio is\ncorrupted by FAKEBOB attacks. The experimental results indicate that the\ndetector is extremely effective: with near zero false positive and false\nnegative rates for detecting FAKEBOB attacks in Gaussian mixture model (GMM)\nand i-vector speaker verification systems. Moreover, adaptive adversarial\nattacks against our proposed detector and their countermeasures are discussed\nand studied, showing the game between attackers and defenders.",
    "descriptor": "",
    "authors": [
      "Zesheng Chen"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2202.05725"
  },
  {
    "id": "arXiv:2202.05728",
    "title": "Deep soccer captioning with transformer: dataset, semantics-related  losses, and multi-level evaluation",
    "abstract": "This work aims at generating captions for soccer videos using deep learning.\nIn this context, this paper introduces a dataset, model, and triple-level\nevaluation. The dataset consists of 22k caption-clip pairs and three visual\nfeatures (images, optical flow, inpainting) for ~500 hours of \\emph{SoccerNet}\nvideos. The model is divided into three parts: a transformer learns language,\nConvNets learn vision, and a fusion of linguistic and visual features generates\ncaptions. The paper suggests evaluating generated captions at three levels:\nsyntax (the commonly used evaluation metrics such as BLEU-score and CIDEr),\nmeaning (the quality of descriptions for a domain expert), and corpus (the\ndiversity of generated captions). The paper shows that the diversity of\ngenerated captions has improved (from 0.07 reaching 0.18) with\nsemantics-related losses that prioritize selected words. Semantics-related\nlosses and the utilization of more visual features (optical flow, inpainting)\nimproved the normalized captioning score by 28\\%. The web page of this work:\nhttps://sites.google.com/view/soccercaptioning}{https://sites.google.com/view/soccercaptioning",
    "descriptor": "",
    "authors": [
      "Ahmad Hammoudeh",
      "Bastein Vanderplaetse",
      "St\u00e9phane Dupont"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.05728"
  },
  {
    "id": "arXiv:2202.05732",
    "title": "CAP-VMs: Capability-Based Isolation and Sharing for Microservices",
    "abstract": "Cloud stacks must isolate microservices, while permitting efficient data\nsharing between isolated services deployed on the same physical host.\nTraditionally, the MMU enforces isolation and permits sharing at a page\ngranularity. MMU approaches, however, lead to cloud stacks with large TCBs in\nkernel space, and the page granularity requires inefficient OS interfaces for\ndata sharing. Forthcoming CPUs with hardware support for memory capabilities\noffer new opportunities to implement isolation and sharing at a finer\ngranularity.\nWe describe cVMs, a new VM-like abstraction that uses memory capabilities to\nisolate application components while supporting efficient data sharing, all\nwithout mandating application code to be capability-aware. cVMs share a single\nvirtual address space safely, each having only capabilities to access its own\nmemory. A cVM may include a library OS, minimizing its dependency on the cloud\nenvironment. cVMs efficiently exchange data through two capability-based\nprimitives assisted by a small trusted monitor: (i) an asynchronous read/write\ninterface to buffers shared between cVMs; and (ii) a call interface to transfer\ncontrol between cVMs. Using these two primitives, we build more expressive\nmechanisms for efficient cross-cVM communication. Our prototype implementation\nusing CHERI RISC-V capabilities shows that cVMs isolate microservices (Redis\nand Python) with low overhead while improving data sharing.",
    "descriptor": "",
    "authors": [
      "Vasily A. Sartakov",
      "Llu\u00eds Vilanova",
      "David Eyers",
      "Takahiro Shinagawa",
      "Peter Pietzuch"
    ],
    "subjectives": [
      "Operating Systems (cs.OS)"
    ],
    "url": "https://arxiv.org/abs/2202.05732"
  },
  {
    "id": "arXiv:2202.05735",
    "title": "SleepPPG-Net: a deep learning algorithm for robust sleep staging from  continuous photoplethysmography",
    "abstract": "Introduction: Sleep staging is an essential component in the diagnosis of\nsleep disorders and management of sleep health. It is traditionally measured in\na clinical setting and requires a labor-intensive labeling process. We\nhypothesize that it is possible to perform robust 4-class sleep staging using\nthe raw photoplethysmography (PPG) time series and modern advances in deep\nlearning (DL). Methods: We used two publicly available sleep databases that\nincluded raw PPG recordings, totalling 2,374 patients and 23,055 hours. We\ndeveloped SleepPPG-Net, a DL model for 4-class sleep staging from the raw PPG\ntime series. SleepPPG-Net was trained end-to-end and consists of a residual\nconvolutional network for automatic feature extraction and a temporal\nconvolutional network to capture long-range contextual information. We\nbenchmarked the performance of SleepPPG-Net against models based on the\nbest-reported state-of-the-art (SOTA) algorithms. Results: When benchmarked on\na held-out test set, SleepPPG-Net obtained a median Cohen's Kappa ($\\kappa$)\nscore of 0.75 against 0.69 for the best SOTA approach. SleepPPG-Net showed good\ngeneralization performance to an external database, obtaining a $\\kappa$ score\nof 0.74 after transfer learning. Perspective: Overall, SleepPPG-Net provides\nnew SOTA performance. In addition, performance is high enough to open the path\nto the development of wearables that meet the requirements for usage in\nclinical applications such as the diagnosis and monitoring of obstructive sleep\napnea.",
    "descriptor": "\nComments: 23 pages, 10 figures\n",
    "authors": [
      "Kevin Kotzen",
      "Peter H. Charlton",
      "Sharon Salabi",
      "Amir Landesberg",
      "Joachim A. Behar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.05735"
  },
  {
    "id": "arXiv:2202.05737",
    "title": "Improving Generalization via Uncertainty Driven Perturbations",
    "abstract": "Recently Shah et al., 2020 pointed out the pitfalls of the simplicity bias -\nthe tendency of gradient-based algorithms to learn simple models - which\ninclude the model's high sensitivity to small input perturbations, as well as\nsub-optimal margins. In particular, while Stochastic Gradient Descent yields\nmax-margin boundary on linear models, such guarantee does not extend to\nnon-linear models. To mitigate the simplicity bias, we consider\nuncertainty-driven perturbations (UDP) of the training data points, obtained\niteratively by following the direction that maximizes the model's estimated\nuncertainty. Unlike loss-driven perturbations, uncertainty-guided perturbations\ndo not cross the decision boundary, allowing for using a larger range of values\nfor the hyperparameter that controls the magnitude of the perturbation.\nMoreover, as real-world datasets have non-isotropic distances between data\npoints of different classes, the above property is particularly appealing for\nincreasing the margin of the decision boundary, which in turn improves the\nmodel's generalization. We show that UDP is guaranteed to achieve the maximum\nmargin decision boundary on linear models and that it notably increases it on\nchallenging simulated datasets. Interestingly, it also achieves competitive\nloss-based robustness and generalization trade-off on several datasets.",
    "descriptor": "",
    "authors": [
      "Matteo Pagliardini",
      "Gilberto Manunza",
      "Martin Jaggi",
      "Michael I. Jordan",
      "Tatjana Chavdarova"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.05737"
  },
  {
    "id": "arXiv:2202.05738",
    "title": "Patch-NetVLAD+: Learned patch descriptor and weighted matching strategy  for place recognition",
    "abstract": "Visual Place Recognition (VPR) in areas with similar scenes such as urban or\nindoor scenarios is a major challenge. Existing VPR methods using global\ndescriptors have difficulty capturing local specific regions (LSR) in the scene\nand are therefore prone to localization confusion in such scenarios. As a\nresult, finding the LSR that are critical for location recognition becomes key.\nTo address this challenge, we introduced Patch-NetVLAD+, which was inspired by\npatch-based VPR researches. Our method proposed a fine-tuning strategy with\ntriplet loss to make NetVLAD suitable for extracting patch-level descriptors.\nMoreover, unlike existing methods that treat all patches in an image equally,\nour method extracts patches of LSR, which present less frequently throughout\nthe dataset, and makes them play an important role in VPR by assigning proper\nweights to them. Experiments on Pittsburgh30k and Tokyo247 datasets show that\nour approach achieved up to 6.35\\% performance improvement than existing\npatch-based methods.",
    "descriptor": "",
    "authors": [
      "Yingfeng Cai",
      "Junqiao Zhao",
      "Jiafeng Cui",
      "Fenglin Zhang",
      "Chen Ye",
      "Tiantian Feng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.05738"
  },
  {
    "id": "arXiv:2202.05742",
    "title": "On the computation of Gr\u00f6bner bases for pluriweighted-homogeneous  systems",
    "abstract": "In this paper, we examine the structure of systems which are weighted\nhomogeneous for several systems of weights, and how it impacts Gr\\\"obner basis\ncomputations. We present different ways to compute Gr\\\"obner bases for systems\nwith this structure, either directly or by reducing to existing structures. We\nalso present optimization techniques which are suitable for this structure.\nThe most natural orderings to compute a Gr\\\"obner basis for systems with this\nstructure are weighted orderings following the systems of weights, and we\ndiscuss the possibility to use the algorithms in order to directly compute a\nbasis for such an order, regardless of the structure of the system.\nWe discuss applicable notions of regularity which could be used to evaluate\nthe complexity of the algorithm, and prove that they are generic if non-empty.\nFinally, we present experimental data from a prototype implementation of the\nalgorithms in SageMath.",
    "descriptor": "\nComments: 10 pages\n",
    "authors": [
      "Thibaut Verron"
    ],
    "subjectives": [
      "Symbolic Computation (cs.SC)"
    ],
    "url": "https://arxiv.org/abs/2202.05742"
  },
  {
    "id": "arXiv:2202.05747",
    "title": "Incentive Compatible Queues Without Money",
    "abstract": "For job scheduling systems, where jobs require some amount of processing and\nthen leave the system, it is natural for each user to provide an estimate of\ntheir job's time requirement in order to aid the scheduler. However, if there\nis no incentive mechanism for truthfulness, each user will be motivated to\nprovide estimates that give their job precedence in the schedule, so that the\njob completes as early as possible.\nWe examine how to make such scheduling systems incentive compatible, without\nusing monetary charges, under a natural queueing theory framework. In our\nsetup, each user has an estimate of their job's running time, but it is\npossible for this estimate to be incorrect. We examine scheduling policies\nwhere if a job exceeds its estimate, it is with some probability \"punished\" and\nre-scheduled after other jobs, to disincentivize underestimates of job times.\nHowever, because user estimates may be incorrect (without any malicious\nintent), excessive punishment may incentivize users to overestimate their job\ntimes, which leads to less efficient scheduling. We describe two natural\nscheduling policies, BlindTrust and MeasuredTrust. We show that, for both of\nthese policies, given the parameters of the system, we can efficiently\ndetermine the set of punishment probabilities that are incentive compatible, in\nthat users are incentivized to provide their actual estimate of the job time.\nMoreover, we prove for MeasuredTrust that in the limit as estimates converge to\nperfect accuracy, the range of punishment probabilities that are incentive\ncompatible converges to $[0,1]$. Our formalism establishes a framework for\nstudying further queue-based scheduling problems where job time estimates from\nusers are utilized, and the system needs to incentivize truthful reporting of\nestimates.",
    "descriptor": "\nComments: 20 pages\n",
    "authors": [
      "Isaac Grosof",
      "Michael Mitzenmacher"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2202.05747"
  },
  {
    "id": "arXiv:2202.05748",
    "title": "Borrowing from yourself: Faster future video segmentation with partial  channel update",
    "abstract": "Semantic segmentation is a well-addressed topic in the computer vision\nliterature, but the design of fast and accurate video processing networks\nremains challenging. In addition, to run on embedded hardware, computer vision\nmodels often have to make compromises on accuracy to run at the required speed,\nso that a latency/accuracy trade-off is usually at the heart of these real-time\nsystems' design. For the specific case of videos, models have the additional\npossibility to make use of computations made for previous frames to mitigate\nthe accuracy loss while being real-time.\nIn this work, we propose to tackle the task of fast future video segmentation\nprediction through the use of convolutional layers with time-dependent channel\nmasking. This technique only updates a chosen subset of the feature maps at\neach time-step, bringing simultaneously less computation and latency, and\nallowing the network to leverage previously computed features. We apply this\ntechnique to several fast architectures and experimentally confirm its benefits\nfor the future prediction subtask.",
    "descriptor": "",
    "authors": [
      "Evann Courdier",
      "Fran\u00e7ois Fleuret"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.05748"
  },
  {
    "id": "arXiv:2202.05749",
    "title": "Constrained Optimization with Dynamic Bound-scaling for Effective  NLPBackdoor Defense",
    "abstract": "We develop a novel optimization method for NLPbackdoor inversion. We leverage\na dynamically reducing temperature coefficient in the softmax function to\nprovide changing loss landscapes to the optimizer such that the process\ngradually focuses on the ground truth trigger, which is denoted as a one-hot\nvalue in a convex hull. Our method also features a temperature rollback\nmechanism to step away from local optimals, exploiting the observation that\nlocal optimals can be easily deter-mined in NLP trigger inversion (while not in\ngeneral optimization). We evaluate the technique on over 1600 models (with\nroughly half of them having injected backdoors) on 3 prevailing NLP tasks, with\n4 different backdoor attacks and 7 architectures. Our results show that the\ntechnique is able to effectively and efficiently detect and remove backdoors,\noutperforming 4 baseline methods.",
    "descriptor": "",
    "authors": [
      "Guangyu Shen",
      "Yingqi Liu",
      "Guanhong Tao",
      "Qiuling Xu",
      "Zhuo Zhang",
      "Shengwei An",
      "Shiqing Ma",
      "Xiangyu Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.05749"
  },
  {
    "id": "arXiv:2202.05751",
    "title": "GitHub Sponsors: Exploring a New Way to Contribute to Open Source",
    "abstract": "GitHub Sponsors, launched in 2019, enables donations to individual open\nsource software (OSS) developers. Financial support for OSS maintainers and\ndevelopers is a major issue in terms of sustaining OSS projects, and the\nability to donate to individuals is expected to support the sustainability of\ndevelopers, projects, and community. In this work, we conducted a mixed-methods\nstudy of GitHub Sponsors, including quantitative and qualitative analyses, to\nunderstand the characteristics of developers who are likely to receive\ndonations and what developers think about donations to individuals. We found\nthat: (1) sponsored developers are more active than non-sponsored developers,\n(2) the possibility to receive donations is related to whether there is someone\nin their community who is donating, and (3) developers are sponsoring as a new\nway to contribute to OSS. Our findings are the first step towards data-informed\nguidance for using GitHub Sponsors, opening up avenues for future work on this\nnew way of financially sustaining the OSS community.",
    "descriptor": "\nComments: 12 pages, ICSE 2022\n",
    "authors": [
      "Naomichi Shimada",
      "Tao Xiao",
      "Hideaki Hata",
      "Christoph Treude",
      "Kenichi Matsumoto"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2202.05751"
  },
  {
    "id": "arXiv:2202.05756",
    "title": "A Novel Speech Intelligibility Enhancement Model based on  CanonicalCorrelation and Deep Learning",
    "abstract": "Current deep learning (DL) based approaches to speech intelligibility\nenhancement in noisy environments are often trained to minimise the feature\ndistance between noise-free speech and enhanced speech signals. Despite\nimproving the speech quality, such approaches do not deliver required levels of\nspeech intelligibility in everyday noisy environments .\nIntelligibility-oriented (I-O) loss functions have recently been developed to\ntrain DL approaches for robust speech enhancement. Here, we formulate, for the\nfirst time, a novel canonical correlation based I-O loss function to more\neffectively train DL algorithms. Specifically, we present a\ncanonical-correlation based short-time objective intelligibility (CC-STOI) cost\nfunction to train a fully convolutional neural network (FCN) model. We carry\nout comparative simulation experiments to show that our CC-STOI based speech\nenhancement framework outperforms state-of-the-art DL models trained with\nconventional distance-based and STOI-based loss functions, using objective and\nsubjective evaluation measures for case of both unseen speakers and noises.\nOngoing future work is evaluating the proposed approach for design of robust\nhearing-assistive technology.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2202.04172\n",
    "authors": [
      "Tassadaq Hussain",
      "Muhammad Diyan",
      "Mandar Gogate",
      "Kia Dashtipour",
      "Ahsan Adeel",
      "Yu Tsao",
      "Amir Hussain"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2202.05756"
  },
  {
    "id": "arXiv:2202.05758",
    "title": "Using Random Perturbations to Mitigate Adversarial Attacks on Sentiment  Analysis Models",
    "abstract": "Attacks on deep learning models are often difficult to identify and therefore\nare difficult to protect against. This problem is exacerbated by the use of\npublic datasets that typically are not manually inspected before use. In this\npaper, we offer a solution to this vulnerability by using, during testing,\nrandom perturbations such as spelling correction if necessary, substitution by\nrandom synonym, or simply dropping the word. These perturbations are applied to\nrandom words in random sentences to defend NLP models against adversarial\nattacks. Our Random Perturbations Defense and Increased Randomness Defense\nmethods are successful in returning attacked models to similar accuracy of\nmodels before attacks. The original accuracy of the model used in this work is\n80% for sentiment classification. After undergoing attacks, the accuracy drops\nto accuracy between 0% and 44%. After applying our defense methods, the\naccuracy of the model is returned to the original accuracy within statistical\nsignificance.",
    "descriptor": "\nComments: To be published in the proceedings for the 18th International Conference on Natural Language Processing (ICON 2021)\n",
    "authors": [
      "Abigail Swenor",
      "Jugal Kalita"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.05758"
  },
  {
    "id": "arXiv:2202.05760",
    "title": "Assessing Privacy Risks from Feature Vector Reconstruction Attacks",
    "abstract": "In deep neural networks for facial recognition, feature vectors are numerical\nrepresentations that capture the unique features of a given face. While it is\nknown that a version of the original face can be recovered via \"feature\nreconstruction,\" we lack an understanding of the end-to-end privacy risks\nproduced by these attacks. In this work, we address this shortcoming by\ndeveloping metrics that meaningfully capture the threat of reconstructed face\nimages. Using end-to-end experiments and user studies, we show that\nreconstructed face images enable re-identification by both commercial facial\nrecognition systems and humans, at a rate that is at worst, a factor of four\ntimes higher than randomized baselines. Our results confirm that feature\nvectors should be recognized as Personal Identifiable Information (PII) in\norder to protect user privacy.",
    "descriptor": "\nComments: 7 pages\n",
    "authors": [
      "Emily Wenger",
      "Francesca Falzon",
      "Josephine Passananti",
      "Haitao Zheng",
      "Ben Y. Zhao"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.05760"
  },
  {
    "id": "arXiv:2202.05766",
    "title": "Learning via nonlinear conjugate gradients and depth-varying neural ODEs",
    "abstract": "The inverse problem of supervised reconstruction of depth-variable\n(time-dependent) parameters in a neural ordinary differential equation (NODE)\nis considered, that means finding the weights of a residual network with time\ncontinuous layers. The NODE is treated as an isolated entity describing the\nfull network as opposed to earlier research, which embedded it between pre- and\npost-appended layers trained by conventional methods. The proposed parameter\nreconstruction is done for a general first order differential equation by\nminimizing a cost functional covering a variety of loss functions and penalty\nterms. A nonlinear conjugate gradient method (NCG) is derived for the\nminimization. Mathematical properties are stated for the differential equation\nand the cost functional. The adjoint problem needed is derived together with a\nsensitivity problem. The sensitivity problem can estimate changes in the\nnetwork output under perturbation of the trained parameters. To preserve\nsmoothness during the iterations the Sobolev gradient is calculated and\nincorporated. As a proof-of-concept, numerical results are included for a NODE\nand two synthetic datasets, and compared with standard gradient approaches (not\nbased on NODEs). The results show that the proposed method works well for deep\nlearning with infinite numbers of layers, and has built-in stability and\nsmoothness.",
    "descriptor": "\nComments: 26 pages, 3 figures\n",
    "authors": [
      "George Baravdish",
      "Gabriel Eilertsen",
      "Rym Jaroudi",
      "B. Tomas Johansson",
      "Luk\u00e1\u0161 Mal\u00fd",
      "Jonas Unger"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2202.05766"
  },
  {
    "id": "arXiv:2202.05767",
    "title": "A PDE-Based Analysis of the Symmetric Two-Armed Bernoulli Bandit",
    "abstract": "This work addresses a version of the two-armed Bernoulli bandit problem where\nthe sum of the means of the arms is one (the symmetric two-armed Bernoulli\nbandit). In a regime where the gap between these means goes to zero and the\nnumber of prediction periods approaches infinity, we obtain the leading order\nterms of the expected regret and pseudoregret for this problem by associating\neach of them with a solution of a linear parabolic partial differential\nequation. Our results improve upon the previously known results; specifically\nwe explicitly compute the leading order term of the optimal regret and\npseudoregret in three different scaling regimes for the gap. Additionally, we\nobtain new non-asymptotic bounds for any given time horizon.",
    "descriptor": "",
    "authors": [
      "Vladimir A. Kobzar",
      "Robert V. Kohn"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Analysis of PDEs (math.AP)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.05767"
  },
  {
    "id": "arXiv:2202.05768",
    "title": "Finding the Shape of Lacunae of the Wave Equation Using Artificial  Neural Networks",
    "abstract": "We apply a fully connected neural network to determine the shape of the\nlacunae in the solutions of the wave equation. Lacunae are the regions of\nquietness behind the trailing fronts of the propagating waves. The network is\ntrained using a computer simulated data set containing a sufficiently large\nnumber of samples. The network is then shown to correctly reconstruct the shape\nof lacunae including the configurations when it is fully enclosed.",
    "descriptor": "\nComments: 12 pages\n",
    "authors": [
      "Alina Chertock",
      "Christopher Leonard",
      "Semyon Tsynkov"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.05768"
  },
  {
    "id": "arXiv:2202.05769",
    "title": "The Benefit of Hindsight: Tracing Edge-Cases in Distributed Systems",
    "abstract": "Today's distributed tracing frameworks only trace a small fraction of all\nrequests. For application developers troubleshooting rare edge-cases, the\ntracing framework is unlikely to capture a relevant trace at all, because it\ncannot know which requests will be problematic until after-the-fact.\nApplication developers thus heavily depend on luck.\nIn this paper, we remove the dependence on luck for any edge-case where\nsymptoms can be programmatically detected, such as high tail latency, errors,\nand bottlenecked queues. We propose a lightweight and always-on distributed\ntracing system, Hindsight, where each constituent node acts analogously to a\ncar dash-cam that, upon detecting a sudden jolt in momentum, persists the last\nhour of footage. Hindsight implements a retroactive sampling abstraction: when\nthe symptoms of a problem are detected, Hindsight retrieves and persists\ncoherent trace data from all relevant nodes that serviced the request.\nDevelopers using Hindsight receive the exact edge-case traces they desire; by\ncomparison existing sampling-based tracing systems depend wholly on\nserendipity.\nOur experimental evaluation shows that Hindsight successfully collects\nedge-case symptomatic requests in real-world use cases. Hindsight adds only\nnanosecond-level overhead to generate trace data, can handle GB/s of data per\nnode, transparently integrates with existing distributed tracing systems, and\npersists full, detailed traces when an edge-case problem is detected.",
    "descriptor": "",
    "authors": [
      "Lei Zhang",
      "Vaastav Anand",
      "Zhiqiang Xie",
      "Ymir Vigfusson",
      "Jonathan Mace"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2202.05769"
  },
  {
    "id": "arXiv:2202.05770",
    "title": "Reliability function for streaming over a DMC with feedback",
    "abstract": "Conventionally, posterior matching is investigated in channel coding and\nblock encoding contexts -- the source symbols are equiprobably distributed and\nare entirely known by the encoder before the transmission. In this paper, we\nconsider a streaming source, whose symbols progressively arrive at the encoder\nat a sequence of deterministic times. We derive the joint source-channel coding\n(JSCC) reliability function for streaming over a discrete memoryless channel\n(DMC) with feedback under regularity conditions. We propose a novel\ninstantaneous encoding phase that operates during the symbol arriving period\nand that achieves the JSCC reliability function for streaming when followed by\na block code that achieves the JSCC reliability function for a classical source\nwhose symbols are fully accessible before the transmission. The instantaneous\nencoding phase partitions the evolving message alphabet into groups whose\npriors are close to the capacity-achieving distribution, and randomizes the\ngroup indices to ensure that the transmitted group index has the\ncapacity-achieving distribution. Surprisingly, the JSCC reliability function\nfor streaming is equal to that for a fully accessible source, implying that the\nknowledge of the entire symbol sequence before the transmission offers no\nadvantage in terms of the reliability function. For equiprobably distributed\nsource symbols, we design a low complexity algorithm for the instantaneous\nencoding phase. It groups the source sequences into sets we call types, which\nenable the encoder and the decoder to track the priors and the posteriors of\nsource sequences jointly, leading to a log-linear complexity in time.",
    "descriptor": "",
    "authors": [
      "Nian Guo",
      "Victoria Kostina"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.05770"
  },
  {
    "id": "arXiv:2202.05771",
    "title": "Torque Computation with the Isogeometric Mortar Method for the  Simulation of Electric Machines",
    "abstract": "In this work isogeometric mortaring is used for the simulation of a six pole\npermanent magnet synchronous machine. Isogeometric mortaring is especially well\nsuited for the efficient computation of rotating electric machines as it allows\nfor an exact geometry representation for arbitrary rotation angles without the\nneed of remeshing. The appropriate B-spline spaces needed for the solution of\nMaxwell's equations and the corresponding mortar spaces are introduced. Unlike\nin classical finite element methods their construction is straightforward in\nthe isogeometric case. The torque in the machine is computed using two\ndifferent methods, i.e., Arkkio's method and by using the Lagrange multipliers\nfrom the mortaring.",
    "descriptor": "",
    "authors": [
      "Melina Merkel",
      "Bernard Kapidani",
      "Sebastian Sch\u00f6ps",
      "Rafael V\u00e1zquez"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.05771"
  },
  {
    "id": "arXiv:2202.05773",
    "title": "Visualising Multiplayer Game Spaces",
    "abstract": "We compare four different `game-spaces' in terms of their usefulness in\ncharacterising multi-player tabletop games, with a particular interest in any\nunderlying change to a game's characteristics as the number of players changes.\nIn each case we take a 16-dimensional feature space, and reduce it to a\n2-dimensional visualizable landscape.\nWe find that a space obtained from optimization of parameters in Monte Carlo\nTree Search (MCTS) is the most directly interpretable to characterise our set\nof games in terms of the relative importance of imperfect information,\nadversarial opponents and reward sparsity. These results do not correlate with\na space defined using attributes of the game-tree.\nThis dimensionality reduction does not show any general effect as the number\nof players. We therefore consider the question using the original features to\nclassify the games into two sets; those for which the characteristics of the\ngame changes significantly as the number of players changes, and those for\nwhich there is no such effect.",
    "descriptor": "\nComments: 13 pages, 7 figures, Accepted for IEEE Transactions on Games\n",
    "authors": [
      "James Goodman",
      "Diego Perez-Liebana",
      "Simon Lucas"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2202.05773"
  },
  {
    "id": "arXiv:2202.05776",
    "title": "Privately Estimating Graph Parameters in Sublinear time",
    "abstract": "We initiate a systematic study of algorithms that are both differentially\nprivate and run in sublinear time for several problems in which the goal is to\nestimate natural graph parameters. Our main result is a differentially-private\n$(1+\\rho)$-approximation algorithm for the problem of computing the average\ndegree of a graph, for every $\\rho>0$. The running time of the algorithm is\nroughly the same as its non-private version proposed by Goldreich and Ron\n(Sublinear Algorithms, 2005). We also obtain the first differentially-private\nsublinear-time approximation algorithms for the maximum matching size and the\nminimum vertex cover size of a graph.\nAn overarching technique we employ is the notion of coupled global\nsensitivity of randomized algorithms. Related variants of this notion of\nsensitivity have been used in the literature in ad-hoc ways. Here we formalize\nthe notion and develop it as a unifying framework for privacy analysis of\nrandomized approximation algorithms.",
    "descriptor": "",
    "authors": [
      "Jeremiah Blocki",
      "Elena Grigorescu",
      "Tamalika Mukherjee"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.05776"
  },
  {
    "id": "arXiv:2202.05778",
    "title": "White-Box Attacks on Hate-speech BERT Classifiers in German with  Explicit and Implicit Character Level Defense",
    "abstract": "In this work, we evaluate the adversarial robustness of BERT models trained\non German Hate Speech datasets. We also complement our evaluation with two\nnovel white-box character and word level attacks thereby contributing to the\nrange of attacks available. Furthermore, we also perform a comparison of two\nnovel character-level defense strategies and evaluate their robustness with one\nanother.",
    "descriptor": "",
    "authors": [
      "Shahrukh Khan",
      "Mahnoor Shahid",
      "Navdeeppal Singh"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.05778"
  },
  {
    "id": "arXiv:2202.05780",
    "title": "A Modern Self-Referential Weight Matrix That Learns to Modify Itself",
    "abstract": "The weight matrix (WM) of a neural network (NN) is its program. The programs\nof many traditional NNs are learned through gradient descent in some error\nfunction, then remain fixed. The WM of a self-referential NN, however, can keep\nrapidly modifying all of itself during runtime. In principle, such NNs can\nmeta-learn to learn, and meta-meta-learn to meta-learn to learn, and so on, in\nthe sense of recursive self-improvement. While NN architectures potentially\ncapable of implementing such behavior have been proposed since the '90s, there\nhave been few if any practical studies. Here we revisit such NNs, building upon\nrecent successes of fast weight programmers and closely related linear\nTransformers. We propose a scalable self-referential WM (SRWM) that uses outer\nproducts and the delta update rule to modify itself. We evaluate our SRWM in\nsupervised few-shot learning and in multi-task reinforcement learning with\nprocedurally generated game environments. Our experiments demonstrate both\npractical applicability and competitive performance of the proposed SRWM. Our\ncode is public.",
    "descriptor": "",
    "authors": [
      "Kazuki Irie",
      "Imanol Schlag",
      "R\u00f3bert Csord\u00e1s",
      "J\u00fcrgen Schmidhuber"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.05780"
  },
  {
    "id": "arXiv:2202.05786",
    "title": "Multi-Modal Knowledge Graph Construction and Application: A Survey",
    "abstract": "Recent years have witnessed the resurgence of knowledge engineering which is\nfeatured by the fast growth of knowledge graphs. However, most of existing\nknowledge graphs are represented with pure symbols, which hurts the machine's\ncapability to understand the real world. The multi-modalization of knowledge\ngraphs is an inevitable key step towards the realization of human-level machine\nintelligence. The results of this endeavor are Multi-modal Knowledge Graphs\n(MMKGs). In this survey on MMKGs constructed by texts and images, we first give\ndefinitions of MMKGs, followed with the preliminaries on multi-modal tasks and\ntechniques. We then systematically review the challenges, progresses and\nopportunities on the construction and application of MMKGs respectively, with\ndetailed analyses of the strength and weakness of different solutions. We\nfinalize this survey with open research problems relevant to MMKGs.",
    "descriptor": "\nComments: 21 pages, 8 figures, 6 tables\n",
    "authors": [
      "Xiangru Zhu",
      "Zhixu Li",
      "Xiaodan Wang",
      "Xueyao Jiang",
      "Penglei Sun",
      "Xuwu Wang",
      "Yanghua Xiao",
      "Nicholas Jing Yuan"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.05786"
  },
  {
    "id": "arXiv:2202.05793",
    "title": "Answer Set Planning: A Survey",
    "abstract": "Answer Set Planning refers to the use of Answer Set Programming (ASP) to\ncompute plans, i.e., solutions to planning problems, that transform a given\nstate of the world to another state. The development of efficient and scalable\nanswer set solvers has provided a significant boost to the development of\nASP-based planning systems. This paper surveys the progress made during the\nlast two and a half decades in the area of answer set planning, from its\nfoundations to its use in challenging planning domains. The survey explores the\nadvantages and disadvantages of answer set planning. It also discusses typical\napplications of answer set planning and presents a set of challenges for future\nresearch.",
    "descriptor": "\nComments: 68 pages, 6 figures\n",
    "authors": [
      "Tran Cao Son",
      "Enrico Pontelli",
      "Marcello Balduccini",
      "Torsten Schaub"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.05793"
  },
  {
    "id": "arXiv:2202.05795",
    "title": "Meta-learning with GANs for anomaly detection, with deployment in  high-speed rail inspection system",
    "abstract": "Anomaly detection has been an active research area with a wide range of\npotential applications. Key challenges for anomaly detection in the AI era with\nbig data include lack of prior knowledge of potential anomaly types, highly\ncomplex and noisy background in input data, scarce abnormal samples, and\nimbalanced training dataset. In this work, we propose a meta-learning framework\nfor anomaly detection to deal with these issues. Within this framework, we\nincorporate the idea of generative adversarial networks (GANs) with appropriate\nchoices of loss functions including structural similarity index measure (SSIM).\nExperiments with limited labeled data for high-speed rail inspection\ndemonstrate that our meta-learning framework is sharp and robust in identifying\nanomalies. Our framework has been deployed in five high-speed railways of China\nsince 2021: it has reduced more than 99.7% workload and saved 96.7% inspection\ntime.",
    "descriptor": "",
    "authors": [
      "Haoyang Cao",
      "Xin Guo",
      "Guan Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.05795"
  },
  {
    "id": "arXiv:2202.05797",
    "title": "Distributionally Robust Data Join",
    "abstract": "Suppose we are given two datasets: a labeled dataset and unlabeled dataset\nwhich also has additional auxiliary features not present in the first dataset.\nWhat is the most principled way to use these datasets together to construct a\npredictor?\nThe answer should depend upon whether these datasets are generated by the\nsame or different distributions over their mutual feature sets, and how similar\nthe test distribution will be to either of those distributions. In many\napplications, the two datasets will likely follow different distributions, but\nboth may be close to the test distribution. We introduce the problem of\nbuilding a predictor which minimizes the maximum loss over all probability\ndistributions over the original features, auxiliary features, and binary\nlabels, whose Wasserstein distance is $r_1$ away from the empirical\ndistribution over the labeled dataset and $r_2$ away from that of the unlabeled\ndataset. This can be thought of as a generalization of distributionally robust\noptimization (DRO), which allows for two data sources, one of which is\nunlabeled and may contain auxiliary features.",
    "descriptor": "",
    "authors": [
      "Pranjal Awasthi",
      "Christopher Jung",
      "Jamie Morgenstern"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.05797"
  },
  {
    "id": "arXiv:2202.05798",
    "title": "The Dual Form of Neural Networks Revisited: Connecting Test Time  Predictions to Training Patterns via Spotlights of Attention",
    "abstract": "Linear layers in neural networks (NNs) trained by gradient descent can be\nexpressed as a key-value memory system which stores all training datapoints and\nthe initial weights, and produces outputs using unnormalised dot attention over\nthe entire training experience. While this has been technically known since the\n'60s, no prior work has effectively studied the operations of NNs in such a\nform, presumably due to prohibitive time and space complexities and impractical\nmodel sizes, all of them growing linearly with the number of training patterns\nwhich may get very large. However, this dual formulation offers a possibility\nof directly visualizing how an NN makes use of training patterns at test time,\nby examining the corresponding attention weights. We conduct experiments on\nsmall scale supervised image classification tasks in single-task, multi-task,\nand continual learning settings, as well as language modelling, and discuss\npotentials and limits of this view for better understanding and interpreting\nhow NNs exploit training patterns. Our code is public.",
    "descriptor": "\nComments: Two first authors\n",
    "authors": [
      "Kazuki Irie",
      "R\u00f3bert Csord\u00e1s",
      "J\u00fcrgen Schmidhuber"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.05798"
  },
  {
    "id": "arXiv:2202.05799",
    "title": "Rate-matching the regret lower-bound in the linear quadratic regulator  with unknown dynamics",
    "abstract": "The theory of reinforcement learning currently suffers from a mismatch\nbetween its empirical performance and the theoretical characterization of its\nperformance, with consequences for, e.g., the understanding of sample\nefficiency, safety, and robustness. The linear quadratic regulator with unknown\ndynamics is a fundamental reinforcement learning setting with significant\nstructure in its dynamics and cost function, yet even in this setting there is\na gap between the best known regret lower-bound of $\\Omega_p(\\sqrt{T})$ and the\nbest known upper-bound of $O_p(\\sqrt{T}\\,\\text{polylog}(T))$. The contribution\nof this paper is to close that gap by establishing a novel regret upper-bound\nof $O_p(\\sqrt{T})$. Our proof is constructive in that it analyzes the regret of\na concrete algorithm, and simultaneously establishes an estimation error bound\non the dynamics of $O_p(T^{-1/4})$ which is also the first to match the rate of\na known lower-bound. The two keys to our improved proof technique are (1) a\nmore precise upper- and lower-bound on the system Gram matrix and (2) a\nself-bounding argument for the expected estimation error of the optimal\ncontroller.",
    "descriptor": "",
    "authors": [
      "Feicheng Wang",
      "Lucas Janson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2202.05799"
  },
  {
    "id": "arXiv:2202.05800",
    "title": "A Newton-type algorithm for federated learning based on incremental  Hessian eigenvector sharing",
    "abstract": "There is a growing interest in the decentralized optimization framework that\ngoes under the name of Federated Learning (FL). In particular, much attention\nis being turned to FL scenarios where the network is strongly heterogeneous in\nterms of communication resources (e.g., bandwidth) and data distribution. In\nthese cases, communication between local machines (agents) and the central\nserver (Master) is a main consideration. In this work, we present an original\ncommunication-constrained Newton-type (NT) algorithm designed to accelerate FL\nin such heterogeneous scenarios. The algorithm is by design robust to non\ni.i.d. data distributions, handles heterogeneity of agents' communication\nresources (CRs), only requires sporadic Hessian computations, and achieves\nsuper-linear convergence. This is possible thanks to an incremental strategy,\nbased on a singular value decomposition (SVD) of the local Hessian matrices,\nwhich exploits (possibly) outdated second-order information. The proposed\nsolution is thoroughly validated on real datasets by assessing (i) the number\nof communication rounds required for convergence, (ii) the overall amount of\ndata transmitted and (iii) the number of local Hessian computations required.\nFor all these metrics, the proposed approach shows superior performance against\nstate-of-the art techniques like GIANT and FedNL.",
    "descriptor": "",
    "authors": [
      "Nicol\u00f2 Dal Fabbro",
      "Subhrakanti Dey",
      "Michele Rossi",
      "Luca Schenato"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2202.05800"
  },
  {
    "id": "arXiv:2202.05801",
    "title": "Parametrized motion planning and topological complexity",
    "abstract": "In this paper we study paramertized motion planning algorithms which provide\nuniversal and flexible solutions to diverse motion planning problems. Such\nalgorithms are intended to function under a variety of external conditions\nwhich are viewed as parameters and serve as part of the input of the algorithm.\nContinuing a recent paper, we study further the concept of parametrized\ntopological complexity. We analyse in full detail the problem of controlling a\nswarm of robots in the presence of multiple obstacles in Euclidean space which\nserved for us a natural motivating example. We present an explicit parametrized\nmotion planning algorithm solving the motion planning problem for any number of\nrobots and obstacles.. This algorithm is optimal, it has minimal possible\ntopological complexity for any d odd. We also analyse the parametrized\ntopological complexity of sphere bundles using the Stiefel - Whitney\ncharacteristic classes.",
    "descriptor": "",
    "authors": [
      "Michael Farber",
      "Shmuel Weinberger"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Algebraic Topology (math.AT)"
    ],
    "url": "https://arxiv.org/abs/2202.05801"
  },
  {
    "id": "arXiv:2202.05806",
    "title": "Evaluating MT Systems: A Theoretical Framework",
    "abstract": "This paper outlines a theoretical framework using which different automatic\nmetrics can be designed for evaluation of Machine Translation systems. It\nintroduces the concept of {\\em cognitive ease} which depends on {\\em adequacy}\nand {\\em lack of fluency}. Thus, cognitive ease becomes the main parameter to\nbe measured rather than comprehensibility. The framework allows the components\nof cognitive ease to be broken up and computed based on different linguistic\nlevels etc. Independence of dimensions and linearly combining them provides for\na highly modular approach.\nThe paper places the existing automatic methods in an overall framework, to\nunderstand them better and to improve upon them in future. It can also be used\nto evaluate the newer types of MT systems, such as speech to speech translation\nand discourse translation.",
    "descriptor": "\nComments: 18 pages\n",
    "authors": [
      "Rajeev Sangal"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.05806"
  },
  {
    "id": "arXiv:2202.05808",
    "title": "Investigating Power laws in Deep Representation Learning",
    "abstract": "Representation learning that leverages large-scale labelled datasets, is\ncentral to recent progress in machine learning. Access to task relevant labels\nat scale is often scarce or expensive, motivating the need to learn from\nunlabelled datasets with self-supervised learning (SSL). Such large unlabelled\ndatasets (with data augmentations) often provide a good coverage of the\nunderlying input distribution. However evaluating the representations learned\nby SSL algorithms still requires task-specific labelled samples in the training\npipeline. Additionally, the generalization of task-specific encoding is often\nsensitive to potential distribution shift. Inspired by recent advances in\ntheoretical machine learning and vision neuroscience, we observe that the\neigenspectrum of the empirical feature covariance matrix often follows a power\nlaw. For visual representations, we estimate the coefficient of the power law,\n$\\alpha$, across three key attributes which influence representation learning:\nlearning objective (supervised, SimCLR, Barlow Twins and BYOL), network\narchitecture (VGG, ResNet and Vision Transformer), and tasks (object and scene\nrecognition). We observe that under mild conditions, proximity of $\\alpha$ to\n1, is strongly correlated to the downstream generalization performance.\nFurthermore, $\\alpha \\approx 1$ is a strong indicator of robustness to label\nnoise during fine-tuning. Notably, $\\alpha$ is computable from the\nrepresentations without knowledge of any labels, thereby offering a framework\nto evaluate the quality of representations in unlabelled datasets.",
    "descriptor": "",
    "authors": [
      "Arna Ghosh",
      "Arnab Kumar Mondal",
      "Kumar Krishna Agrawal",
      "Blake Richards"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2202.05808"
  },
  {
    "id": "arXiv:2202.05810",
    "title": "An a posteriori error estimator for the spectral fractional power of the  Laplacian",
    "abstract": "We develop a novel a posteriori error estimator for the L2 error committed by\nthe finite element discretization of the solution of the fractional Laplacian.\nOur a posteriori error estimator takes advantage of the semi-discretization\nscheme using a rational approximation which allows to reformulate the\nfractional problem into a family of non-fractional parametric problems. The\nestimator involves applying the implicit Bank-Weiser error estimation strategy\nto each parametric non-fractional problem and reconstructing the fractional\nerror through the same rational approximation used to compute the solution to\nthe original fractional problem. We provide several numerical examples in both\ntwo and three-dimensions demonstrating the effectivity of our estimator for\nvarying fractional powers and its ability to drive an adaptive mesh refinement\nstrategy.",
    "descriptor": "",
    "authors": [
      "Rapha\u00ebl Bulle",
      "Olga Barrera",
      "St\u00e9phane P. A. Bordas",
      "Franz Chouly",
      "Jack S. Hale"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.05810"
  },
  {
    "id": "arXiv:2202.05811",
    "title": "Overhead Image Factors for Underwater Sonar-based SLAM",
    "abstract": "Simultaneous localization and mapping (SLAM) is a critical capability for any\nautonomous underwater vehicle (AUV). However, robust, accurate state estimation\nis still a work in progress when using low-cost sensors. We propose enhancing a\ntypical low-cost sensor package using widely available and often free prior\ninformation; overhead imagery. Given an AUV's sonar image and a partially\noverlapping, globally-referenced overhead image, we propose using a\nconvolutional neural network (CNN) to generate a synthetic overhead image\npredicting the above-surface appearance of the sonar image contents. We then\nuse this synthetic overhead image to register our observations to the provided\nglobal overhead image. Once registered, the transformation is introduced as a\nfactor into a pose SLAM factor graph. We use a state-of-the-art simulation\nenvironment to perform validation over a series of benchmark trajectories and\nquantitatively show the improved accuracy of robot state estimation using the\nproposed approach. We also show qualitative outcomes from a real AUV field\ndeployment. Video attachment: https://youtu.be/_uWljtp58ks",
    "descriptor": "\nComments: To appear in RA-L 2022 and presented at ICRA 2022\n",
    "authors": [
      "John McConnell",
      "Fanfei Chen",
      "Brendan Englot"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.05811"
  },
  {
    "id": "arXiv:2202.05816",
    "title": "Why just FRET when you can Refactor? Retuning FRETISH Requirements",
    "abstract": "Formal verification of a software system relies on formalising the\nrequirements to which it should adhere, which can be challenging. While\nformalising requirements from natural-language, we have dependencies that lead\nto duplication of information across many requirements, meaning that a change\nto one requirement causes updates in several places. We propose to adapt code\nrefactorings for NASA's Formal Requirements Elicitation Tool (FRET), our\ntool-of-choice. Refactoring is the process of reorganising software to improve\nits internal structure without altering its external behaviour; it can also be\napplied to requirements, to make them more manageable by reducing repetition.\nFRET automatically translates requirements (written in its input language\nFretish) into Temporal Logic, which enables us to formally verify that\nrefactoring has preserved the requirements' underlying meaning. In this paper,\nwe present four refactorings for Fretish requirements and explain their\nutility. We describe the application of one of these refactorings to the\nrequirements of a civilian aircraft engine software controller, to decouple the\ndependencies from the duplication, and analyse how this changes the number of\nrequirements and the number of repetitions. We evaluate our approach using\nSpot, a tool for checking equivalence of Temporal Logic specifications.",
    "descriptor": "",
    "authors": [
      "Matt Luckcuck",
      "Marie Farrell",
      "Ois\u00edn Sheridan"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2202.05816"
  },
  {
    "id": "arXiv:2202.05817",
    "title": "The HaMSE Ontology: Using Semantic Technologies to support Music  Representation Interoperability and Musicological Analysis",
    "abstract": "The use of Semantic Technologies - in particular the Semantic Web - has\nrevealed to be a great tool for describing the cultural heritage domain and\nartistic practices. However, the panorama of ontologies for musicological\napplications seems to be limited and restricted to specific applications. In\nthis research, we propose HaMSE, an ontology capable of describing musical\nfeatures that can assist musicological research. More specifically, HaMSE\nproposes to address sues that have been affecting musicological research for\ndecades: the representation of music and the relationship between quantitative\nand qualitative data. To do this, HaMSE allows the alignment between different\nmusic representation systems and describes a set of musicological features that\ncan allow the music analysis at different granularity levels.",
    "descriptor": "",
    "authors": [
      "Andrea Poltronieri",
      "Aldo Gangemi"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Multimedia (cs.MM)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2202.05817"
  },
  {
    "id": "arXiv:2202.05819",
    "title": "Nonprehensile Manipulation of a Stick Using Impulsive Forces",
    "abstract": "The problem of nonprehensile manipulation of a stick in three-dimensional\nspace using intermittent impulsive forces is considered. The objective is to\njuggle the stick between a sequence of configurations that are rotationally\nsymmetric about the vertical axis. The dynamics of the stick is described by\nfive generalized coordinates and three control inputs. Between two consecutive\nrotationally symmetric configurations, the dynamics is conveniently represented\nby a Poincar\\'e map in the reference frame of the juggler. Stabilization of the\norbit associated with a desired juggling motion is accomplished by stabilizing\na fixed point on the Poincar\\'e map. The Impulse Controlled Poincar\\'e Map\napproach is used to stabilize the orbit, and numerical simulations are used\ndemonstrate convergence to the desired juggling motion from an arbitrary\ninitial configuration. In the limiting case, where consecutive rotationally\nsymmetric configurations are chosen arbitrarily close, it is shown that the\ndynamics reduces to that of steady precession of the stick on a hoop.",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible. This version submitted to the IEEE Transactions on Robotics on 4 Feb 2022\n",
    "authors": [
      "Aakash Khandelwal",
      "Nilay Kant",
      "Ranjan Mukherjee"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.05819"
  },
  {
    "id": "arXiv:2202.05820",
    "title": "Expectation Consistent Plug-and-Play for MRI",
    "abstract": "For image recovery problems, plug-and-play (PnP) methods have been developed\nthat replace the proximal step in an optimization algorithm with a call to an\napplication-specific denoiser, often implemented using a deep neural network.\nAlthough such methods have been successful, they can be improved. For example,\nthe denoiser is often trained using white Gaussian noise, while PnP's denoiser\ninput error is often far from white and Gaussian, with statistics that are\ndifficult to predict from iteration to iteration. PnP methods based on\napproximate message passing (AMP) are an exception, but only when the forward\noperator behaves like a large random matrix. In this work, we design a PnP\nmethod using the expectation consistent (EC) approximation algorithm, a\ngeneralization of AMP, that offers predictable error statistics at each\niteration, from which a deep-net denoiser can be effectively trained.",
    "descriptor": "",
    "authors": [
      "Saurav K Shastri",
      "Rizwan Ahmad",
      "Christopher A Metzler",
      "Philip Schniter"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.05820"
  },
  {
    "id": "arXiv:2202.05821",
    "title": "PEg TRAnsfer Workflow recognition challenge report: Does multi-modal  data improve recognition?",
    "abstract": "This paper presents the design and results of the \"PEg TRAnsfert Workflow\nrecognition\" (PETRAW) challenge whose objective was to develop surgical\nworkflow recognition methods based on one or several modalities, among video,\nkinematic, and segmentation data, in order to study their added value. The\nPETRAW challenge provided a data set of 150 peg transfer sequences performed on\na virtual simulator. This data set was composed of videos, kinematics, semantic\nsegmentation, and workflow annotations which described the sequences at three\ndifferent granularity levels: phase, step, and activity. Five tasks were\nproposed to the participants: three of them were related to the recognition of\nall granularities with one of the available modalities, while the others\naddressed the recognition with a combination of modalities. Average\napplication-dependent balanced accuracy (AD-Accuracy) was used as evaluation\nmetric to take unbalanced classes into account and because it is more\nclinically relevant than a frame-by-frame score. Seven teams participated in at\nleast one task and four of them in all tasks. Best results are obtained with\nthe use of the video and the kinematics data with an AD-Accuracy between 93%\nand 90% for the four teams who participated in all tasks. The improvement\nbetween video/kinematic-based methods and the uni-modality ones was significant\nfor all of the teams. However, the difference in testing execution time between\nthe video/kinematic-based and the kinematic-based methods has to be taken into\nconsideration. Is it relevant to spend 20 to 200 times more computing time for\nless than 3% of improvement? The PETRAW data set is publicly available at\nwww.synapse.org/PETRAW to encourage further research in surgical workflow\nrecognition.",
    "descriptor": "\nComments: Challenge report\n",
    "authors": [
      "Arnaud Huaulm\u00e9",
      "Kanako Harada",
      "Quang-Minh Nguyen",
      "Bogyu Park",
      "Seungbum Hong",
      "Min-Kook Choi",
      "Michael Peven",
      "Yunshuang Li",
      "Yonghao Long",
      "Qi Dou",
      "Satyadwyoom Kumar",
      "Seenivasan Lalithkumar",
      "Ren Hongliang",
      "Hiroki Matsuzaki",
      "Yuto Ishikawa",
      "Yuriko Harai",
      "Satoshi Kondo",
      "Mamoru Mitsuishi",
      "Pierre Jannin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2202.05821"
  },
  {
    "id": "arXiv:2202.05822",
    "title": "CLIPasso: Semantically-Aware Object Sketching",
    "abstract": "Abstraction is at the heart of sketching due to the simple and minimal nature\nof line drawings. Abstraction entails identifying the essential visual\nproperties of an object or scene, which requires semantic understanding and\nprior knowledge of high-level concepts. Abstract depictions are therefore\nchallenging for artists, and even more so for machines. We present an object\nsketching method that can achieve different levels of abstraction, guided by\ngeometric and semantic simplifications. While sketch generation methods often\nrely on explicit sketch datasets for training, we utilize the remarkable\nability of CLIP (Contrastive-Language-Image-Pretraining) to distill semantic\nconcepts from sketches and images alike. We define a sketch as a set of\nB\\'ezier curves and use a differentiable rasterizer to optimize the parameters\nof the curves directly with respect to a CLIP-based perceptual loss. The\nabstraction degree is controlled by varying the number of strokes. The\ngenerated sketches demonstrate multiple levels of abstraction while maintaining\nrecognizability, underlying structure, and essential visual components of the\nsubject drawn.",
    "descriptor": "\nComments: this https URL\n",
    "authors": [
      "Yael Vinker",
      "Ehsan Pajouheshgar",
      "Jessica Y. Bo",
      "Roman Christian Bachmann",
      "Amit Haim Bermano",
      "Daniel Cohen-Or",
      "Amir Zamir",
      "Ariel Shamir"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.05822"
  },
  {
    "id": "arXiv:2202.05826",
    "title": "End-to-end Algorithm Synthesis with Recurrent Networks: Logical  Extrapolation Without Overthinking",
    "abstract": "Machine learning systems perform well on pattern matching tasks, but their\nability to perform algorithmic or logical reasoning is not well understood. One\nimportant reasoning capability is logical extrapolation, in which models\ntrained only on small/simple reasoning problems can synthesize complex\nalgorithms that scale up to large/complex problems at test time. Logical\nextrapolation can be achieved through recurrent systems, which can be iterated\nmany times to solve difficult reasoning problems. We observe that this approach\nfails to scale to highly complex problems because behavior degenerates when\nmany iterations are applied -- an issue we refer to as \"overthinking.\" We\npropose a recall architecture that keeps an explicit copy of the problem\ninstance in memory so that it cannot be forgotten. We also employ a progressive\ntraining routine that prevents the model from learning behaviors that are\nspecific to iteration number and instead pushes it to learn behaviors that can\nbe repeated indefinitely. These innovations prevent the overthinking problem,\nand enable recurrent systems to solve extremely hard logical extrapolation\ntasks, some requiring over 100K convolutional layers, without overthinking.",
    "descriptor": "",
    "authors": [
      "Arpit Bansal",
      "Avi Schwarzschild",
      "Eitan Borgnia",
      "Zeyad Emam",
      "Furong Huang",
      "Micah Goldblum",
      "Tom Goldstein"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.05826"
  },
  {
    "id": "arXiv:2202.05827",
    "title": "Automated Architecture Search for Brain-inspired Hyperdimensional  Computing",
    "abstract": "This paper represents the first effort to explore an automated architecture\nsearch for hyperdimensional computing (HDC), a type of brain-inspired neural\nnetwork. Currently, HDC design is largely carried out in an\napplication-specific ad-hoc manner, which significantly limits its application.\nFurthermore, the approach leads to inferior accuracy and efficiency, which\nsuggests that HDC cannot perform competitively against deep neural networks.\nHerein, we present a thorough study to formulate an HDC architecture search\nspace. On top of the search space, we apply reinforcement-learning to\nautomatically explore the HDC architectures. The searched HDC architectures\nshow competitive performance on case studies involving a drug discovery dataset\nand a language recognition task. On the Clintox dataset, which tries to learn\nfeatures from developed drugs that passed/failed clinical trials for toxicity\nreasons, the searched HDC architecture obtains the state-of-the-art ROC-AUC\nscores, which are 0.80% higher than the manually designed HDC and 9.75% higher\nthan conventional neural networks. Similar results are achieved on the language\nrecognition task, with 1.27% higher performance than conventional methods.",
    "descriptor": "",
    "authors": [
      "Junhuan Yang",
      "Yi Sheng",
      "Sizhe Zhang",
      "Ruixuan Wang",
      "Kenneth Foreman",
      "Mikell Paige",
      "Xun Jiao",
      "Weiwen Jiang",
      "Lei Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.05827"
  },
  {
    "id": "arXiv:2202.05830",
    "title": "Learning Fast Samplers for Diffusion Models by Differentiating Through  Sample Quality",
    "abstract": "Diffusion models have emerged as an expressive family of generative models\nrivaling GANs in sample quality and autoregressive models in likelihood scores.\nStandard diffusion models typically require hundreds of forward passes through\nthe model to generate a single high-fidelity sample. We introduce\nDifferentiable Diffusion Sampler Search (DDSS): a method that optimizes fast\nsamplers for any pre-trained diffusion model by differentiating through sample\nquality scores. We also present Generalized Gaussian Diffusion Models (GGDM), a\nfamily of flexible non-Markovian samplers for diffusion models. We show that\noptimizing the degrees of freedom of GGDM samplers by maximizing sample quality\nscores via gradient descent leads to improved sample quality. Our optimization\nprocedure backpropagates through the sampling process using the\nreparametrization trick and gradient rematerialization. DDSS achieves strong\nresults on unconditional image generation across various datasets (e.g., FID\nscores on LSUN church 128x128 of 11.6 with only 10 inference steps, and 4.82\nwith 20 steps, compared to 51.1 and 14.9 with strongest DDPM/DDIM baselines).\nOur method is compatible with any pre-trained diffusion model without\nfine-tuning or re-training required.",
    "descriptor": "\nComments: Published as a conference paper at ICLR 2022\n",
    "authors": [
      "Daniel Watson",
      "William Chan",
      "Jonathan Ho",
      "Mohammad Norouzi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.05830"
  },
  {
    "id": "arXiv:2202.05832",
    "title": "SafePicking: Learning Safe Object Extraction via Object-Level Mapping",
    "abstract": "Robots need object-level scene understanding to manipulate objects while\nreasoning about contact, support, and occlusion among objects. Given a pile of\nobjects, object recognition and reconstruction can identify the boundary of\nobject instances, giving important cues as to how the objects form and support\nthe pile. In this work, we present a system, SafePicking, that integrates\nobject-level mapping and learning-based motion planning to generate a motion\nthat safely extracts occluded target objects from a pile. Planning is done by\nlearning a deep Q-network that receives observations of predicted poses and a\ndepth-based heightmap to output a motion trajectory, trained to maximize a\nsafety metric reward. Our results show that the observation fusion of poses and\ndepth-sensing gives both better performance and robustness to the model. We\nevaluate our methods using the YCB objects in both simulation and the real\nworld, achieving safe object extraction from piles.",
    "descriptor": "\nComments: 7 pages, 6 figures, IEEE International Conference on Robotics and Automation (ICRA) 2022\n",
    "authors": [
      "Kentaro Wada",
      "Stephen James",
      "Andrew J. Davison"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.05832"
  },
  {
    "id": "arXiv:2202.05833",
    "title": "Active Privacy-Utility Trade-off Against Inference in Time-Series Data  Sharing",
    "abstract": "Internet of things (IoT) devices, such as smart meters, smart speakers and\nactivity monitors, have become highly popular thanks to the services they\noffer. However, in addition to their many benefits, they raise privacy concerns\nsince they share fine-grained time-series user data with untrusted third\nparties. In this work, we consider a user releasing her data containing\npersonal information in return of a service from an honest-but-curious service\nprovider (SP). We model user's personal information as two correlated random\nvariables (r.v.'s), one of them, called the secret variable, is to be kept\nprivate, while the other, called the useful variable, is to be disclosed for\nutility. We consider active sequential data release, where at each time step\nthe user chooses from among a finite set of release mechanisms, each revealing\nsome information about the user's personal information, i.e., the true values\nof the r.v.'s, albeit with different statistics. The user manages data release\nin an online fashion such that the maximum amount of information is revealed\nabout the latent useful variable as quickly as possible, while the confidence\nfor the sensitive variable is kept below a predefined level. For privacy\nmeasure, we consider both the probability of correctly detecting the true value\nof the secret and the mutual information (MI) between the secret and the\nreleased data. We formulate both problems as partially observable Markov\ndecision processes (POMDPs), and numerically solve them by advantage\nactor-critic (A2C) deep reinforcement learning (DRL). We evaluate the\nprivacy-utility trade-off (PUT) of the proposed policies on both the synthetic\ndata and smoking activity dataset, and show their validity by testing the\nactivity detection accuracy of the SP modeled by a long short-term memory\n(LSTM) neural network.",
    "descriptor": "\nComments: 12 pages, 12 figures\n",
    "authors": [
      "Ecenaz Erdemir",
      "Pier Luigi Dragotti",
      "Deniz Gunduz"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.05833"
  },
  {
    "id": "arXiv:2202.05834",
    "title": "Predicting Out-of-Distribution Error with the Projection Norm",
    "abstract": "We propose a metric -- Projection Norm -- to predict a model's performance on\nout-of-distribution (OOD) data without access to ground truth labels.\nProjection Norm first uses model predictions to pseudo-label test samples and\nthen trains a new model on the pseudo-labels. The more the new model's\nparameters differ from an in-distribution model, the greater the predicted OOD\nerror. Empirically, our approach outperforms existing methods on both image and\ntext classification tasks and across different network architectures.\nTheoretically, we connect our approach to a bound on the test error for\noverparameterized linear models. Furthermore, we find that Projection Norm is\nthe only approach that achieves non-trivial detection performance on\nadversarial examples. Our code is available at\nhttps://github.com/yaodongyu/ProjNorm.",
    "descriptor": "",
    "authors": [
      "Yaodong Yu",
      "Zitong Yang",
      "Alexander Wei",
      "Yi Ma",
      "Jacob Steinhardt"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.05834"
  },
  {
    "id": "arXiv:2202.02728",
    "title": "Hierarchical Risk Parity and Minimum Variance Portfolio Design on NIFTY  50 Stocks",
    "abstract": "Portfolio design and optimization have been always an area of research that\nhas attracted a lot of attention from researchers from the finance domain.\nDesigning an optimum portfolio is a complex task since it involves accurate\nforecasting of future stock returns and risks and making a suitable tradeoff\nbetween them. This paper proposes a systematic approach to designing portfolios\nusing two algorithms, the critical line algorithm, and the hierarchical risk\nparity algorithm on eight sectors of the Indian stock market. While the\nportfolios are designed using the stock price data from Jan 1, 2016, to Dec 31,\n2020, they are tested on the data from Jan 1, 2021, to Aug 26, 2021. The\nbacktesting results of the portfolios indicate while the performance of the CLA\nalgorithm is superior on the training data, the HRP algorithm has outperformed\nthe CLA algorithm on the test data.",
    "descriptor": "\nComments: The is the preprint version of our published paper listed in the IEEE Xplore. The final paper is published in the Proceedings of the IEEE International Conference on Decision Aid Sciences and Applications, pp. 668-675, December 7-8, 2021, Bahrain. The preprint consists of 8 pages and it contains 32 figures and 9 tables\n",
    "authors": [
      "Jaydip Sen",
      "Sidra Mehtab",
      "Abhishek Dutta",
      "Saikat Mondal"
    ],
    "subjectives": [
      "Portfolio Management (q-fin.PM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.02728"
  },
  {
    "id": "arXiv:2202.05183",
    "title": "Discovering Quantum Phase Transitions with Fermionic Neural Networks",
    "abstract": "Deep neural networks have been extremely successful as highly accurate wave\nfunction ans\\\"atze for variational Monte Carlo calculations of molecular ground\nstates. We present an extension of one such ansatz, FermiNet, to calculations\nof the ground states of periodic Hamiltonians, and study the homogeneous\nelectron gas. FermiNet calculations of the ground-state energies of small\nelectron gas systems are in excellent agreement with previous initiator full\nconfiguration interaction quantum Monte Carlo and diffusion Monte Carlo\ncalculations. We investigate the spin-polarized homogeneous electron gas and\ndemonstrate that the same neural network architecture is capable of accurately\nrepresenting both the delocalized Fermi liquid state and the localized Wigner\ncrystal state. The network is given no \\emph{a priori} knowledge that a phase\ntransition exists, but converges on the translationally invariant ground state\nat high density and spontaneously breaks the symmetry to produce the\ncrystalline ground state at low density.",
    "descriptor": "\nComments: 12 pages, 3 figures\n",
    "authors": [
      "G. Cassella",
      "H. Sutterud",
      "S. Azadi",
      "N. D. Drummond",
      "D. Pfau",
      "J. S. Spencer",
      "W. M. C. Foulkes"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Other Condensed Matter (cond-mat.other)",
      "Strongly Correlated Electrons (cond-mat.str-el)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.05183"
  },
  {
    "id": "arXiv:2202.05267",
    "title": "On Real-time Image Reconstruction with Neural Networks for MRI-guided  Radiotherapy",
    "abstract": "MRI-guidance techniques that dynamically adapt radiation beams to follow\ntumor motion in real-time will lead to more accurate cancer treatments and\nreduced collateral healthy tissue damage. The gold-standard for reconstruction\nof undersampled MR data is compressed sensing (CS) which is computationally\nslow and limits the rate that images can be available for real-time adaptation.\nHere, we demonstrate the use of automated transform by manifold approximation\n(AUTOMAP), a generalized framework that maps raw MR signal to the target image\ndomain, to rapidly reconstruct images from undersampled radial k-space data.\nThe AUTOMAP neural network was trained to reconstruct images from a\ngolden-angle radial acquisition, a benchmark for motion-sensitive imaging, on\nlung cancer patient data and generic images from ImageNet. Model training was\nsubsequently augmented with motion-encoded k-space data derived from videos in\nthe YouTube-8M dataset to encourage motion robust reconstruction. We find that\nAUTOMAP-reconstructed radial k-space has equivalent accuracy to CS but with\nmuch shorter processing times after initial fine-tuning on retrospectively\nacquired lung cancer patient data. Validation of motion-trained models with a\nvirtual dynamic lung tumor phantom showed that the generalized motion\nproperties learned from YouTube lead to improved target tracking accuracy. Our\nwork shows that AUTOMAP can achieve real-time, accurate reconstruction of\nradial data. These findings imply that neural-network-based reconstruction is\npotentially superior to existing approaches for real-time image guidance\napplications.",
    "descriptor": "\nComments: 11 pages, 6 figures, 1 table\n",
    "authors": [
      "David E. J. Waddington",
      "Nicholas Hindley",
      "Neha Koonjoo",
      "Christopher Chiu",
      "Tess Reynolds",
      "Paul Z. Y. Liu",
      "Bo Zhu",
      "Danyal Bhutto",
      "Chiara Paganelli",
      "Paul J. Keall",
      "Matthew S. Rosen"
    ],
    "subjectives": [
      "Medical Physics (physics.med-ph)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2202.05267"
  },
  {
    "id": "arXiv:2202.05268",
    "title": "HNF-Netv2 for Brain Tumor Segmentation using multi-modal MR Imaging",
    "abstract": "In our previous work, $i.e.$, HNF-Net, high-resolution feature representation\nand light-weight non-local self-attention mechanism are exploited for brain\ntumor segmentation using multi-modal MR imaging. In this paper, we extend our\nHNF-Net to HNF-Netv2 by adding inter-scale and intra-scale semantic\ndiscrimination enhancing blocks to further exploit global semantic\ndiscrimination for the obtained high-resolution features. We trained and\nevaluated our HNF-Netv2 on the multi-modal Brain Tumor Segmentation Challenge\n(BraTS) 2021 dataset. The result on the test set shows that our HNF-Netv2\nachieved the average Dice scores of 0.878514, 0.872985, and 0.924919, as well\nas the Hausdorff distances ($95\\%$) of 8.9184, 16.2530, and 4.4895 for the\nenhancing tumor, tumor core, and whole tumor, respectively. Our method won the\nRSNA 2021 Brain Tumor AI Challenge Prize (Segmentation Task), which ranks 8th\nout of all 1250 submitted results.",
    "descriptor": "\nComments: RSNA 2021 Brain Tumor AI Challenge Top Solution. arXiv admin note: substantial text overlap with arXiv:2012.15318\n",
    "authors": [
      "Haozhe Jia",
      "Chao Bai",
      "Weidong Cai",
      "Heng Huang",
      "Yong Xia"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.05268"
  },
  {
    "id": "arXiv:2202.05269",
    "title": "A Plug-and-Play Approach to Multiparametric Quantitative MRI: Image  Reconstruction using Pre-Trained Deep Denoisers",
    "abstract": "Current spatiotemporal deep learning approaches to Magnetic Resonance\nFingerprinting (MRF) build artefact-removal models customised to a particular\nk-space subsampling pattern which is used for fast (compressed) acquisition.\nThis may not be useful when the acquisition process is unknown during training\nof the deep learning model and/or changes during testing time. This paper\nproposes an iterative deep learning plug-and-play reconstruction approach to\nMRF which is adaptive to the forward acquisition process. Spatiotemporal image\npriors are learned by an image denoiser i.e. a Convolutional Neural Network\n(CNN), trained to remove generic white gaussian noise (not a particular\nsubsampling artefact) from data. This CNN denoiser is then used as a\ndata-driven shrinkage operator within the iterative reconstruction algorithm.\nThis algorithm with the same denoiser model is then tested on two simulated\nacquisition processes with distinct subsampling patterns. The results show\nconsistent de-aliasing performance against both acquisition schemes and\naccurate mapping of tissues' quantitative bio-properties. Software available:\nhttps://github.com/ketanfatania/QMRI-PnP-Recon-POC",
    "descriptor": "",
    "authors": [
      "Ketan Fatania",
      "Carolin M. Pirkl",
      "Marion I. Menzel",
      "Peter Hall",
      "Mohammad Golbabaee"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.05269"
  },
  {
    "id": "arXiv:2202.05270",
    "title": "A Deep Learning Approach for Digital ColorReconstruction of Lenticular  Films",
    "abstract": "We propose the first accurate digitization and color reconstruction process\nfor historical lenticular film that is robust to artifacts. Lenticular films\nemerged in the 1920s and were one of the first technologies that permitted to\ncapture full color information in motion. The technology leverages an RGB\nfilter and cylindrical lenticules embossed on the film surface to encode the\ncolor in the horizontal spatial dimension of the image. To project the pictures\nthe encoding process was reversed using an appropriate analog device. In this\nwork, we introduce an automated, fully digital pipeline to process the scan of\nlenticular films and colorize the image. Our method merges deep learning with a\nmodel-based approach in order to maximize the performance while making sure\nthat the reconstructed colored images truthfully match the encoded color\ninformation. Our model employs different strategies to achieve an effective\ncolor reconstruction, in particular (i) we use data augmentation to create a\nrobust lenticule segmentation network, (ii) we fit the lenticules raster\nprediction to obtain a precise vectorial lenticule localization, and (iii) we\ntrain a colorization network that predicts interpolation coefficients in order\nto obtain a truthful colorization. We validate the proposed method on a\nlenticular film dataset and compare it to other approaches. Since no colored\ngroundtruth is available as reference, we conduct a user study to validate our\nmethod in a subjective manner. The results of the study show that the proposed\nmethod is largely preferred with respect to other existing and baseline\nmethods.",
    "descriptor": "",
    "authors": [
      "Stefano D'Aronco",
      "Giorgio Trumpy",
      "David Pfluger",
      "Jan Dirk Wegner"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.05270"
  },
  {
    "id": "arXiv:2202.05273",
    "title": "Towards a Guideline for Evaluation Metrics in Medical Image Segmentation",
    "abstract": "In the last decade, research on artificial intelligence has seen rapid growth\nwith deep learning models, especially in the field of medical image\nsegmentation. Various studies demonstrated that these models have powerful\nprediction capabilities and achieved similar results as clinicians. However,\nrecent studies revealed that the evaluation in image segmentation studies lacks\nreliable model performance assessment and showed statistical bias by incorrect\nmetric implementation or usage. Thus, this work provides an overview and\ninterpretation guide on the following metrics for medical image segmentation\nevaluation in binary as well as multi-class problems: Dice similarity\ncoefficient, Jaccard, Sensitivity, Specificity, Rand index, ROC curves, Cohen's\nKappa, and Hausdorff distance. As a summary, we propose a guideline for\nstandardized medical image segmentation evaluation to improve evaluation\nquality, reproducibility, and comparability in the research field.",
    "descriptor": "\nComments: Source Code: this https URL\n",
    "authors": [
      "Dominik M\u00fcller",
      "I\u00f1aki Soto-Rey",
      "Frank Kramer"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.05273"
  },
  {
    "id": "arXiv:2202.05282",
    "title": "Translation and Rotation Equivariant Normalizing Flow (TRENF) for  Optimal Cosmological Analysis",
    "abstract": "Our universe is homogeneous and isotropic, and its perturbations obey\ntranslation and rotation symmetry. In this work we develop Translation and\nRotation Equivariant Normalizing Flow (TRENF), a generative Normalizing Flow\n(NF) model which explicitly incorporates these symmetries, defining the data\nlikelihood via a sequence of Fourier space-based convolutions and pixel-wise\nnonlinear transforms. TRENF gives direct access to the high dimensional data\nlikelihood p(x|y) as a function of the labels y, such as cosmological\nparameters. In contrast to traditional analyses based on summary statistics,\nthe NF approach has no loss of information since it preserves the full\ndimensionality of the data. On Gaussian random fields, the TRENF likelihood\nagrees well with the analytical expression and saturates the Fisher information\ncontent in the labels y. On nonlinear cosmological overdensity fields from\nN-body simulations, TRENF leads to significant improvements in constraining\npower over the standard power spectrum summary statistic. TRENF is also a\ngenerative model of the data, and we show that TRENF samples agree well with\nthe N-body simulations it trained on, and that the inverse mapping of the data\nagrees well with a Gaussian white noise both visually and on various summary\nstatistics: when this is perfectly achieved the resulting p(x|y) likelihood\nanalysis becomes optimal. Finally, we develop a generalization of this model\nthat can handle effects that break the symmetry of the data, such as the survey\nmask, which enables likelihood analysis on data without periodic boundaries.",
    "descriptor": "\nComments: 11 pages, 10 figures. Submitted to MNRAS. Comments welcome\n",
    "authors": [
      "Biwei Dai",
      "Uros Seljak"
    ],
    "subjectives": [
      "Cosmology and Nongalactic Astrophysics (astro-ph.CO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.05282"
  },
  {
    "id": "arXiv:2202.05311",
    "title": "Mining the manifolds of deep generative models for multiple  data-consistent solutions of ill-posed tomographic imaging problems",
    "abstract": "Tomographic imaging is in general an ill-posed inverse problem. Typically, a\nsingle regularized image estimate of the sought-after object is obtained from\ntomographic measurements. However, there may be multiple objects that are all\nconsistent with the same measurement data. The ability to generate such\nalternate solutions is important because it may enable new assessments of\nimaging systems. In principle, this can be achieved by means of posterior\nsampling methods. In recent years, deep neural networks have been employed for\nposterior sampling with promising results. However, such methods are not yet\nfor use with large-scale tomographic imaging applications. On the other hand,\nempirical sampling methods may be computationally feasible for large-scale\nimaging systems and enable uncertainty quantification for practical\napplications. Empirical sampling involves solving a regularized inverse problem\nwithin a stochastic optimization framework in order to obtain alternate\ndata-consistent solutions. In this work, we propose a new empirical sampling\nmethod that computes multiple solutions of a tomographic inverse problem that\nare consistent with the same acquired measurement data. The method operates by\nrepeatedly solving an optimization problem in the latent space of a style-based\ngenerative adversarial network (StyleGAN), and was inspired by the Photo\nUpsampling via Latent Space Exploration (PULSE) method that was developed for\nsuper-resolution tasks. The proposed method is demonstrated and analyzed via\nnumerical studies that involve two stylized tomographic imaging modalities.\nThese studies establish the ability of the method to perform efficient\nempirical sampling and uncertainty quantification.",
    "descriptor": "\nComments: Submitted to IEEE Transactions on Medical Imaging\n",
    "authors": [
      "Sayantan Bhadra",
      "Umberto Villa",
      "Mark A. Anastasio"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.05311"
  },
  {
    "id": "arXiv:2202.05318",
    "title": "Personalization Improves Privacy-Accuracy Tradeoffs in Federated  Optimization",
    "abstract": "Large-scale machine learning systems often involve data distributed across a\ncollection of users. Federated optimization algorithms leverage this structure\nby communicating model updates to a central server, rather than entire\ndatasets. In this paper, we study stochastic optimization algorithms for a\npersonalized federated learning setting involving local and global models\nsubject to user-level (joint) differential privacy. While learning a private\nglobal model induces a cost of privacy, local learning is perfectly private. We\nshow that coordinating local learning with private centralized learning yields\na generically useful and improved tradeoff between accuracy and privacy. We\nillustrate our theoretical results with experiments on synthetic and real-world\ndatasets.",
    "descriptor": "",
    "authors": [
      "Alberto Bietti",
      "Chen-Yu Wei",
      "Miroslav Dudik",
      "John Langford",
      "Zhiwei Steven Wu"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2202.05318"
  },
  {
    "id": "arXiv:2202.05327",
    "title": "Three-dimensional graph products with unbounded stack-number",
    "abstract": "We prove that the stack-number of the strong product of three $n$-vertex\npaths is $\\Theta(n^{1/3})$. The best previously known upper bound was $O(n)$.\nNo non-trivial lower bound was known. This is the first explicit example of a\ngraph family with bounded maximum degree and unbounded stack-number.\nThe main tool used in our proof of the lower bound is the topological overlap\ntheorem of Gromov. We actually prove a stronger result in terms of so-called\ntriangulations of Cartesian products. We conclude that triangulations of\nthree-dimensional Cartesian products of any sufficiently large connected graphs\nhave large stack-number.\nThe upper bound is a special case of a more general construction based on\nfamilies of permutations derived from Hadamard matrices.\nThe strong product of three paths is also the first example of a bounded\ndegree graph with bounded queue-number and unbounded stack-number. A natural\nquestion that follows from our result is to determine the smallest $\\Delta_0$\nsuch that there exist a graph family with unbounded stack-number, bounded\nqueue-number and maximum degree $\\Delta_0$. We show that $\\Delta_0\\in \\{6,7\\}$.",
    "descriptor": "",
    "authors": [
      "David Eppstein",
      "and Robert Hickingbotham",
      "Laura Merker",
      "Sergey Norin",
      "Micha\u0142 T. Seweryn",
      "David R. Wood"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2202.05327"
  },
  {
    "id": "arXiv:2202.05336",
    "title": "Dynamic Background Subtraction by Generative Neural Networks",
    "abstract": "Background subtraction is a significant task in computer vision and an\nessential step for many real world applications. One of the challenges for\nbackground subtraction methods is dynamic background, which constitute\nstochastic movements in some parts of the background. In this paper, we have\nproposed a new background subtraction method, called DBSGen, which uses two\ngenerative neural networks, one for dynamic motion removal and another for\nbackground generation. At the end, the foreground moving objects are obtained\nby a pixel-wise distance threshold based on a dynamic entropy map. The proposed\nmethod has a unified framework that can be optimized in an end-to-end and\nunsupervised fashion. The performance of the method is evaluated over dynamic\nbackground sequences and it outperforms most of state-of-the-art methods. Our\ncode is publicly available at https://github.com/FatemeBahri/DBSGen.",
    "descriptor": "\nComments: 8 pages, 5 figures\n",
    "authors": [
      "Fateme Bahri",
      "Nilanjan Ray"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.05336"
  },
  {
    "id": "arXiv:2202.05339",
    "title": "Closure operators: Complexity and applications to classification and  decision-making",
    "abstract": "We study the complexity of closure operators, with applications to machine\nlearning and decision theory. In machine learning, closure operators emerge\nnaturally in data classification and clustering. In decision theory, they can\nmodel equivalence of choice menus, and therefore situations with a preference\nfor flexibility. Our contribution is to formulate a notion of complexity of\nclosure operators, which translate into the complexity of a classifier in ML,\nor of a utility function in decision theory.",
    "descriptor": "",
    "authors": [
      "Hamed Hamze Bajgiran",
      "Federico Echenique"
    ],
    "subjectives": [
      "Theoretical Economics (econ.TH)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.05339"
  },
  {
    "id": "arXiv:2202.05354",
    "title": "Optimal Transport for Super Resolution Applied to Astronomy Imaging",
    "abstract": "Super resolution is an essential tool in optics, especially on interstellar\nscales, due to physical laws restricting possible imaging resolution. We\npropose using optimal transport and entropy for super resolution applications.\nWe prove that the reconstruction is accurate when sparsity is known and noise\nor distortion is small enough. We prove that the optimizer is stable and robust\nto noise and perturbations. We compare this method to a state of the art\nconvolutional neural network and get similar results for much less\ncomputational cost and greater methodological flexibility.",
    "descriptor": "\nComments: 5 pages, 2 figures\n",
    "authors": [
      "Michael Rawson",
      "Jakob Hultgren"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.05354"
  },
  {
    "id": "arXiv:2202.05355",
    "title": "DDoS-UNet: Incorporating temporal information using Dynamic Dual-channel  UNet for enhancing super-resolution of dynamic MRI",
    "abstract": "Magnetic resonance imaging (MRI) provides high spatial resolution and\nexcellent soft-tissue contrast without using harmful ionising radiation.\nDynamic MRI is an essential tool for interventions to visualise movements or\nchanges of the target organ. However, such MRI acquisition with high temporal\nresolution suffers from limited spatial resolution - also known as the\nspatio-temporal trade-off of dynamic MRI. Several approaches, including deep\nlearning based super-resolution approaches, have been proposed to mitigate this\ntrade-off. Nevertheless, such an approach typically aims to super-resolve each\ntime-point separately, treating them as individual volumes. This research\naddresses the problem by creating a deep learning model which attempts to learn\nboth spatial and temporal relationships. A modified 3D UNet model, DDoS-UNet,\nis proposed - which takes the low-resolution volume of the current time-point\nalong with a prior image volume. Initially, the network is supplied with a\nstatic high-resolution planning scan as the prior image along with the\nlow-resolution input to super-resolve the first time-point. Then it continues\nstep-wise by using the super-resolved time-points as the prior image while\nsuper-resolving the subsequent time-points. The model performance was tested\nwith 3D dynamic data that was undersampled to different in-plane levels. The\nproposed network achieved an average SSIM value of 0.951$\\pm$0.017 while\nreconstructing the lowest resolution data (i.e. only 4\\% of the k-space\nacquired) - which could result in a theoretical acceleration factor of 25. The\nproposed approach can be used to reduce the required scan-time while achieving\nhigh spatial resolution.",
    "descriptor": "",
    "authors": [
      "Soumick Chatterjee",
      "Chompunuch Sarasaen",
      "Georg Rose",
      "Andreas N\u00fcrnberger",
      "Oliver Speck"
    ],
    "subjectives": [
      "Medical Physics (physics.med-ph)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2202.05355"
  },
  {
    "id": "arXiv:2202.05382",
    "title": "Give me a knee radiograph, I will tell you where the knee joint area is:  a deep convolutional neural network adventure",
    "abstract": "Knee pain is undoubtedly the most common musculoskeletal symptom that impairs\nquality of life, confines mobility and functionality across all ages. Knee pain\nis clinically evaluated by routine radiographs, where the widespread adoption\nof radiographic images and their availability at low cost, make them the\nprinciple component in the assessment of knee pain and knee pathologies, such\nas arthritis, trauma, and sport injuries. However, interpretation of the knee\nradiographs is still highly subjective, and overlapping structures within the\nradiographs and the large volume of images needing to be analyzed on a daily\nbasis, make interpretation challenging for both naive and experienced\npractitioners. There is thus a need to implement an artificial intelligence\nstrategy to objectively and automatically interpret knee radiographs,\nfacilitating triage of abnormal radiographs in a timely fashion. The current\nwork proposes an accurate and effective pipeline for autonomous detection,\nlocalization, and classification of knee joint area in plain radiographs\ncombining the You Only Look Once (YOLO v3) deep convolutional neural network\nwith a large and fully-annotated knee radiographs dataset. The present work is\nexpected to stimulate more interest from the deep learning computer vision\ncommunity to this pragmatic and clinical application.",
    "descriptor": "\nComments: 13 Pages, 4 Figures\n",
    "authors": [
      "Shi Yan",
      "Taghi Ramazanian",
      "Elham Sagheb",
      "Walter K. Kremers",
      "Vipin Chaudhary",
      "Michael Taunton",
      "Hilal Maradit Kremers",
      "Ahmad P. Tafti"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.05382"
  },
  {
    "id": "arXiv:2202.05388",
    "title": "Massively parallel pixel-by-pixel nanophotonic optimization using a  Green's function formalism",
    "abstract": "We introduce an efficient parallelization scheme to implement pixel-by-pixel\nnanophotonic optimization using a Green's function based formalism. The crucial\ninsight in our proposal is the reframing of the optimization algorithm as a\nlarge-scale data processing pipeline, which allows for the efficient\ndistribution of computational tasks across thousands of workers. We demonstrate\nthe utility of our implementation by exercising it to optimize a high numerical\naperture focusing metalens at problem sizes that would otherwise be far out of\nreach for the Green's function based method. Finally, we highlight the\nconnection to powerful ideas from reinforcement learning as a natural corollary\nof reinterpreting the nanophotonic inverse design problem as a graph traversal\nenabled by the pixel-by-pixel optimization paradigm.",
    "descriptor": "\nComments: 10 pages, 7 figures\n",
    "authors": [
      "Jiahui Wang",
      "Alfred K. C. Cheung",
      "Aleksandra Spyra",
      "Ian A. D. Williamson",
      "Jian Guan",
      "Martin F. Schubert"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Emerging Technologies (cs.ET)",
      "Optics (physics.optics)"
    ],
    "url": "https://arxiv.org/abs/2202.05388"
  },
  {
    "id": "arXiv:2202.05396",
    "title": "Enhancing ASR for Stuttered Speech with Limited Data Using Detect and  Pass",
    "abstract": "It is estimated that around 70 million people worldwide are affected by a\nspeech disorder called stuttering. With recent advances in Automatic Speech\nRecognition (ASR), voice assistants are increasingly useful in our everyday\nlives. Many technologies in education, retail, telecommunication and healthcare\ncan now be operated through voice. Unfortunately, these benefits are not\naccessible for People Who Stutter (PWS). We propose a simple but effective\nmethod called 'Detect and Pass' to make modern ASR systems accessible for\nPeople Who Stutter in a limited data setting. The algorithm uses a context\naware classifier trained on a limited amount of data, to detect acoustic frames\nthat contain stutter. To improve robustness on stuttered speech, this extra\ninformation is passed on to the ASR model to be utilized during inference. Our\nexperiments show a reduction of 12.18% to 71.24% in Word Error Rate (WER)\nacross various state of the art ASR systems. Upon varying the threshold of the\nassociated posterior probability of stutter for each stacked frame used in\ndetermining low frame rate (LFR) acoustic features, we were able to determine\nan optimal setting that reduced the WER by 23.93% to 71.67% across different\nASR systems.",
    "descriptor": "",
    "authors": [
      "Olabanji Shonibare",
      "Xiaosu Tong",
      "Venkatesh Ravichandran"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2202.05396"
  },
  {
    "id": "arXiv:2202.05397",
    "title": "Neural Architecture Search for Energy Efficient Always-on Audio Models",
    "abstract": "Mobile and edge computing devices for always-on audio classification require\nenergy-efficient neural network architectures. We present a neural architecture\nsearch (NAS) that optimizes accuracy, energy efficiency and memory usage. The\nsearch is run on Vizier, a black-box optimization service. We present a search\nstrategy that uses both Bayesian and regularized evolutionary search with\nparticle swarms, and employs early-stopping to reduce the computational burden.\nThe search returns architectures for a sound-event classification dataset based\nupon AudioSet with similar accuracy to MobileNetV1/V2 implementations but with\nan order of magnitude less energy per inference and a much smaller memory\nfootprint.",
    "descriptor": "",
    "authors": [
      "Daniel T. Speckhard",
      "Karolis Misiunas",
      "Sagi Perel",
      "Tenghui Zhu",
      "Simon Carlile",
      "Malcolm Slaney"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2202.05397"
  },
  {
    "id": "arXiv:2202.05422",
    "title": "Posterior Consistency for Bayesian Relevance Vector Machines",
    "abstract": "Statistical modeling and inference problems with sample sizes substantially\nsmaller than the number of available covariates are challenging. Chakraborty et\nal. (2012) did a full hierarchical Bayesian analysis of nonlinear regression in\nsuch situations using relevance vector machines based on reproducing kernel\nHilbert space (RKHS). But they did not provide any theoretical properties\nassociated with their procedure. The present paper revisits their problem,\nintroduces a new class of global-local priors different from theirs, and\nprovides results on posterior consistency as well as posterior contraction\nrates",
    "descriptor": "",
    "authors": [
      "Xiao Fang",
      "Malay Ghosh"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.05422"
  },
  {
    "id": "arXiv:2202.05452",
    "title": "Information Design for Differential Privacy",
    "abstract": "Firms and statistical agencies that publish aggregate data face practical and\nlegal requirements to protect the privacy of individuals. Increasingly, these\norganizations meet these standards by using publication mechanisms which\nsatisfy differential privacy. We consider the problem of choosing such a\nmechanism so as to maximize the value of its output to end users. We show that\nthis is equivalent to a constrained information design problem, and\ncharacterize its solution. Moreover, by introducing a new order on information\nstructures and showing that it ranks them by their usefulness to agents with\nsupermodular payoffs, we show that the simple geometric mechanism is optimal\nwhenever data users face supermodular decision problems.",
    "descriptor": "",
    "authors": [
      "Ian M. Schmutte",
      "Nathan Yoder"
    ],
    "subjectives": [
      "Theoretical Economics (econ.TH)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.05452"
  },
  {
    "id": "arXiv:2202.05492",
    "title": "Entroformer: A Transformer-based Entropy Model for Learned Image  Compression",
    "abstract": "One critical component in lossy deep image compression is the entropy model,\nwhich predicts the probability distribution of the quantized latent\nrepresentation in the encoding and decoding modules. Previous works build\nentropy models upon convolutional neural networks which are inefficient in\ncapturing global dependencies. In this work, we propose a novel\ntransformer-based entropy model, termed Entroformer, to capture long-range\ndependencies in probability distribution estimation effectively and\nefficiently. Different from vision transformers in image classification, the\nEntroformer is highly optimized for image compression, including a top-k\nself-attention and a diamond relative position encoding. Meanwhile, we further\nexpand this architecture with a parallel bidirectional context model to speed\nup the decoding process. The experiments show that the Entroformer achieves\nstate-of-the-art performance on image compression while being time-efficient.",
    "descriptor": "\nComments: Accepted at ICLR 2022 for poster. arXiv admin note: text overlap with arXiv:1809.02736 by other authors\n",
    "authors": [
      "Yichen Qian",
      "Ming Lin",
      "Xiuyu Sun",
      "Zhiyu Tan",
      "Rong Jin"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.05492"
  },
  {
    "id": "arXiv:2202.05498",
    "title": "Fast and Robust Sparsity Learning over Networks: A Decentralized  Surrogate Median Regression Approach",
    "abstract": "Decentralized sparsity learning has attracted a significant amount of\nattention recently due to its rapidly growing applications. To obtain the\nrobust and sparse estimators, a natural idea is to adopt the non-smooth median\nloss combined with a $\\ell_1$ sparsity regularizer. However, most of the\nexisting methods suffer from slow convergence performance caused by the {\\em\ndouble} non-smooth objective. To accelerate the computation, in this paper, we\nproposed a decentralized surrogate median regression (deSMR) method for\nefficiently solving the decentralized sparsity learning problem. We show that\nour proposed algorithm enjoys a linear convergence rate with a simple\nimplementation. We also investigate the statistical guarantee, and it shows\nthat our proposed estimator achieves a near-oracle convergence rate without any\nrestriction on the number of network nodes. Moreover, we establish the\ntheoretical results for sparse support recovery. Thorough numerical experiments\nand real data study are provided to demonstrate the effectiveness of our\nmethod.",
    "descriptor": "\nComments: IEEE Transactions on Signal Processing, 2022\n",
    "authors": [
      "Weidong Liu",
      "Xiaojun Mao",
      "Xin Zhang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2202.05498"
  },
  {
    "id": "arXiv:2202.05506",
    "title": "On the preferred extensions of argumentation frameworks: bijections with  naive extensions",
    "abstract": "This paper deals with the problem of finding the preferred extensions of an\nargumentation framework by means of a bijection with the naive extensions of\nanother framework. First we consider the case where an argumentation framework\nis naive-realizable: its naive and preferred extensions are equal. Recognizing\nnaive-realizable argumentation frameworks is hard, but we show that it is\ntractable for frameworks with bounded in-degree. Next, we give a bijection\nbetween the preferred extensions of an argumentation framework being\nadmissible-closed (the intersection of two admissible sets is admissible) and\nthe naive extensions of another framework on the same set of arguments. On the\nother hand, we prove that identifying admissible-closed argumentation\nframeworks is coNP-complete. At last, we introduce the notion of irreducible\nself-defending sets as those that are not the union of others. It turns out\nthere exists a bijection between the preferred extensions of an argumentation\nframework and the naive extensions of a framework on its irreducible\nself-defending sets. Consequently, the preferred extensions of argumentation\nframeworks with some lattice properties can be listed with polynomial delay and\npolynomial space.",
    "descriptor": "\nComments: 13 pages, 5 figures\n",
    "authors": [
      "Mohammed Elaroussi",
      "Lhouari Nourine",
      "Mohammed Said Radjef",
      "Simon Vilmin"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Artificial Intelligence (cs.AI)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2202.05506"
  },
  {
    "id": "arXiv:2202.05514",
    "title": "Dilated convolutional neural network-based deep reference picture  generation for video compression",
    "abstract": "Motion estimation and motion compensation are indispensable parts of inter\nprediction in video coding. Since the motion vector of objects is mostly in\nfractional pixel units, original reference pictures may not accurately provide\na suitable reference for motion compensation. In this paper, we propose a deep\nreference picture generator which can create a picture that is more relevant to\nthe current encoding frame, thereby further reducing temporal redundancy and\nimproving video compression efficiency. Inspired by the recent progress of\nConvolutional Neural Network(CNN), this paper proposes to use a dilated CNN to\nbuild the generator. Moreover, we insert the generated deep picture into\nVersatile Video Coding(VVC) as a reference picture and perform a comprehensive\nset of experiments to evaluate the effectiveness of our network on the latest\nVVC Test Model VTM. The experimental results demonstrate that our proposed\nmethod achieves on average 9.7% bit saving compared with VVC under low-delay P\nconfiguration.",
    "descriptor": "",
    "authors": [
      "Haoyue Tian",
      "Pan Gao",
      "Ran Wei",
      "Manoranjan Paul"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2202.05514"
  },
  {
    "id": "arXiv:2202.05520",
    "title": "What Does it Mean for a Language Model to Preserve Privacy?",
    "abstract": "Natural language reflects our private lives and identities, making its\nprivacy concerns as broad as those of real life. Language models lack the\nability to understand the context and sensitivity of text, and tend to memorize\nphrases present in their training sets. An adversary can exploit this tendency\nto extract training data. Depending on the nature of the content and the\ncontext in which this data was collected, this could violate expectations of\nprivacy. Thus there is a growing interest in techniques for training language\nmodels that preserve privacy. In this paper, we discuss the mismatch between\nthe narrow assumptions made by popular data protection techniques (data\nsanitization and differential privacy), and the broadness of natural language\nand of privacy as a social norm. We argue that existing protection methods\ncannot guarantee a generic and meaningful notion of privacy for language\nmodels. We conclude that language models should be trained on text data which\nwas explicitly produced for public use.",
    "descriptor": "\nComments: 21 pages, 2 figures\n",
    "authors": [
      "Hannah Brown",
      "Katherine Lee",
      "Fatemehsadat Mireshghalla",
      "Reza Shokri",
      "Florian Tram\u00e8r"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.05520"
  },
  {
    "id": "arXiv:2202.05536",
    "title": "The enumeration of meet-irreducible elements based on hierarchical  decompositions of implicational bases",
    "abstract": "We study the well-known problem of translating between two representations of\nclosure systems, namely implicational bases and meet-irreducible elements.\nAlbeit its importance, the problem is open. In this paper, we introduce splits\nof an implicational base. It is a partitioning operation of the implications\nwhich we recursively apply to obtain a binary tree representing a decomposition\nof the implicational base. We show that this decomposition can be conducted in\npolynomial time and space in the size of the input implicational base. Focusing\non the case of acyclic splits, we obtain a recursive characterization of the\nmeet-irreducible elements of the associated closure system. We use this\ncharacterization and hypergraph dualization to derive new results for the\ntranslation problem in acyclic convex geometries.",
    "descriptor": "\nComments: 30 pages, 22 figures\n",
    "authors": [
      "Lhouari Nourine",
      "Simon Vilmin"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2202.05536"
  },
  {
    "id": "arXiv:2202.05551",
    "title": "Derivatives in Proton CT",
    "abstract": "Algorithmic derivatives can be useful to quantify uncertainties and optimize\nparameters using computer simulations. Whether they actually are, depends on\nhow \"well-linearizable\" the program is.\nProton computed tomography (pCT) is a medical imaging technology with the\npotential to increase the spatial accuracy of the dose delivered in proton-beam\nradiotherapy. The Bergen pCT collaboration is developing and constructing a\ndigital tracking calorimeter (DTC) to measure the position, direction and\nenergy of protons after they passed through a patient, and a software pipeline\nto process these data into a pCT image.\nWe revisit the software pipeline from the perspective of algorithmic\ndifferentiation (AD). In the early subprocedures, several obstacles such as\ndiscrete variables or frequent discontinuities were identified, and are\nprobably tackled best by using surrogate models. The model-based iterative\nreconstruction (MBIR) subprocedure in the end seems to be AD-ready, and we\npropose changes in the AD workflow that can reduce the memory consumption in\nreverse mode.",
    "descriptor": "\nComments: 25 pages, 11 figures\n",
    "authors": [
      "Max Aehle",
      "Johan Alme",
      "Gergely G\u00e1bor Barnaf\u00f6ldi",
      "Johannes Bl\u00fchdorn",
      "Tea Bodova",
      "Vyacheslav Borshchov",
      "Anthony van den Brink",
      "Mamdouh Chaar",
      "Viljar Eikeland",
      "Gregory Feofilov",
      "Christoph Garth",
      "Nicolas R. Gauger",
      "Georgi Genov",
      "Ola Gr\u00f8ttvik",
      "H\u00e5vard Helstrup",
      "Sergey Igolkin",
      "Ralf Keidel",
      "Chinorat Kobdaj",
      "Tobias Kortus",
      "Viktor Leonhardt",
      "Shruti Mehendale",
      "Raju Ningappa Mulawade",
      "Odd Harald Odland",
      "George O'Neill",
      "G\u00e1bor Papp",
      "Thomas Peitzmann",
      "Helge Egil Seime Pettersen",
      "Pierluigi Piersimoni",
      "Rohit Pochampalli",
      "Maksym Protsenko",
      "Max Rauch",
      "Attiq Ur Rehman",
      "Matthias Richter",
      "Dieter R\u00f6hrich",
      "Max Sagebaum",
      "Joshua Santana",
      "Alexander Schilling",
      "Joao Seco",
      "Arnon Songmoolnak",
      "Jarle Rambo S\u00f8lie",
      "Ganesh Tambave",
      "Ihor Tymchuk",
      "Kjetil Ullaland",
      "Monika Varga-Kofarago"
    ],
    "subjectives": [
      "Medical Physics (physics.med-ph)",
      "Mathematical Software (cs.MS)"
    ],
    "url": "https://arxiv.org/abs/2202.05551"
  },
  {
    "id": "arXiv:2202.05560",
    "title": "Controlling Confusion via Generalisation Bounds",
    "abstract": "We establish new generalisation bounds for multiclass classification by\nabstracting to a more general setting of discretised error types. Extending the\nPAC-Bayes theory, we are hence able to provide fine-grained bounds on\nperformance for multiclass classification, as well as applications to other\nlearning problems including discretisation of regression losses. Tractable\ntraining objectives are derived from the bounds. The bounds are uniform over\nall weightings of the discretised error types and thus can be used to bound\nweightings not foreseen at training, including the full confusion matrix in the\nmulticlass classification case.",
    "descriptor": "\nComments: 31 pages\n",
    "authors": [
      "Reuben Adams",
      "John Shawe-Taylor",
      "Benjamin Guedj"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2202.05560"
  },
  {
    "id": "arXiv:2202.05568",
    "title": "On change of measure inequalities for $f$-divergences",
    "abstract": "We propose new change of measure inequalities based on $f$-divergences (of\nwhich the Kullback-Leibler divergence is a particular case). Our strategy\nrelies on combining the Legendre transform of $f$-divergences and the\nYoung-Fenchel inequality. By exploiting these new change of measure\ninequalities, we derive new PAC-Bayesian generalisation bounds with a\ncomplexity involving $f$-divergences, and holding in mostly unchartered\nsettings (such as heavy-tailed losses). We instantiate our results for the most\npopular $f$-divergences.",
    "descriptor": "\nComments: 17 pages\n",
    "authors": [
      "Antoine Picard-Weibel",
      "Benjamin Guedj"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Probability (math.PR)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2202.05568"
  },
  {
    "id": "arXiv:2202.05610",
    "title": "Explainable Machine Learning for Breakdown Prediction in High Gradient  RF Cavities",
    "abstract": "Radio Frequency (RF) breakdowns are one of the most prevalent limiting\nfactors in RF cavities for particle accelerators. During a breakdown, field\nenhancement associated with small deformations on the cavity surface results in\nelectrical arcs. Such arcs lead to beam aborts, reduce machine availability and\ncan cause irreparable damage on the RF cavity surface. In this paper, we\npropose a machine learning strategy to discover breakdown precursors in CERN's\nCompact Linear Collider (CLIC) accelerating structures. By interpreting the\nparameters of the learned models with explainable Artificial Intelligence (AI),\nwe reverse-engineer physical properties for deriving fast, reliable, and simple\nrule based models. Based on 6 months of historical data and dedicated\nexperiments, our models show fractions of data with high influence on the\noccurrence of breakdowns. Specifically, it is shown that in many cases a rise\nof the vacuum pressure is observed before a breakdown is detected with the\ncurrent interlock sensors.",
    "descriptor": "",
    "authors": [
      "Christoph Obermair",
      "Thomas Cartier-Michaud",
      "Andrea Apollonio",
      "William Millar",
      "Lukas Felsberger",
      "Lorenz Fischl",
      "Holger Severin Bovbjerg",
      "Daniel Wollmann",
      "Walter Wuensch",
      "Nuria Catalan-Lasheras",
      "Mar\u00e7\u00e0 Boronat",
      "Franz Pernkopf",
      "Graeme Burt"
    ],
    "subjectives": [
      "Accelerator Physics (physics.acc-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.05610"
  },
  {
    "id": "arXiv:2202.05612",
    "title": "Inference and FDR Control for Simulated Ising Models in High-dimension",
    "abstract": "This paper studies the consistency and statistical inference of simulated\nIsing models in the high dimensional background. Our estimators are based on\nthe Markov chain Monte Carlo maximum likelihood estimation (MCMC-MLE) method\npenalized by the Elastic-net. Under mild conditions that ensure a specific\nconvergence rate of MCMC method, the $\\ell_{1}$ consistency of\nElastic-net-penalized MCMC-MLE is proved. We further propose a decorrelated\nscore test based on the decorrelated score function and prove the asymptotic\nnormality of the score function without the influence of many nuisance\nparameters under the assumption that accelerates the convergence of the MCMC\nmethod. The one-step estimator for a single parameter of interest is purposed\nby linearizing the decorrelated score function to solve its root, as well as\nits normality and confidence interval for the true value, therefore, be\nestablished. Finally, we use different algorithms to control the false\ndiscovery rate (FDR) via traditional p-values and novel e-values.",
    "descriptor": "\nComments: 39 pages\n",
    "authors": [
      "Haoyu Wei",
      "Xiaoyu Lei",
      "Huiming Zhang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2202.05612"
  },
  {
    "id": "arXiv:2202.05614",
    "title": "Measuring dissimilarity with diffeomorphism invariance",
    "abstract": "Measures of similarity (or dissimilarity) are a key ingredient to many\nmachine learning algorithms. We introduce DID, a pairwise dissimilarity measure\napplicable to a wide range of data spaces, which leverages the data's internal\nstructure to be invariant to diffeomorphisms. We prove that DID enjoys\nproperties which make it relevant for theoretical study and practical use. By\nrepresenting each datum as a function, DID is defined as the solution to an\noptimization problem in a Reproducing Kernel Hilbert Space and can be expressed\nin closed-form. In practice, it can be efficiently approximated via Nystr\\\"om\nsampling. Empirical experiments support the merits of DID.",
    "descriptor": "\nComments: A pre-print\n",
    "authors": [
      "Th\u00e9ophile Cantelobre",
      "Carlo Ciliberto",
      "Benjamin Guedj",
      "Alessandro Rudi"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.05614"
  },
  {
    "id": "arXiv:2202.05621",
    "title": "Long-Time Convergence and Propagation of Chaos for Nonlinear MCMC",
    "abstract": "In this paper, we study the long-time convergence and uniform strong\npropagation of chaos for a class of nonlinear Markov chains for Markov chain\nMonte Carlo (MCMC). Our technique is quite simple, making use of recent\ncontraction estimates for linear Markov kernels and basic techniques from\nMarkov theory and analysis. Moreover, the same proof strategy applies to both\nthe long-time convergence and propagation of chaos. We also show, via some\nexperiments, that these nonlinear MCMC techniques are viable for use in\nreal-world high-dimensional inference such as Bayesian neural networks.",
    "descriptor": "\nComments: 18+12 pages, 2 figures\n",
    "authors": [
      "James Vuckovic"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2202.05621"
  },
  {
    "id": "arXiv:2202.05623",
    "title": "A Wasserstein GAN for Joint Learning of Inpainting and its Spatial  Optimisation",
    "abstract": "Classic image inpainting is a restoration method that reconstructs missing\nimage parts. However, a carefully selected mask of known pixels that yield a\nhigh quality inpainting can also act as a sparse image representation. This\nchallenging spatial optimisation problem is essential for practical\napplications such as compression. So far, it has been almost exclusively\naddressed by model-based approaches. First attempts with neural networks seem\npromising, but are tailored towards specific inpainting operators or require\npostprocessing. To address this issue, we propose the first generative\nadversarial network for spatial inpainting data optimisation. In contrast to\nprevious approaches, it allows joint training of an inpainting generator and a\ncorresponding mask optimisation network. With a Wasserstein distance, we ensure\nthat our inpainting results accurately reflect the statistics of natural\nimages. This yields significant improvements in visual quality and speed over\nconventional stochastic models and also outperforms current spatial\noptimisation networks.",
    "descriptor": "",
    "authors": [
      "Pascal Peter"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.05623"
  },
  {
    "id": "arXiv:2202.05631",
    "title": "Vehicle and License Plate Recognition with Novel Dataset for Toll  Collection",
    "abstract": "We propose an automatic framework for toll collection, consisting of three\nsteps: vehicle type recognition, license plate localization, and reading.\nHowever, each of the three steps becomes non-trivial due to image variations\ncaused by several factors. The traditional vehicle decorations on the front\ncause variations among vehicles of the same type. These decorations make\nlicense plate localization and recognition difficult due to severe background\nclutter and partial occlusions. Likewise, on most vehicles, specifically\ntrucks, the position of the license plate is not consistent. Lastly, for\nlicense plate reading, the variations are induced by non-uniform font styles,\nsizes, and partially occluded letters and numbers. Our proposed framework takes\nadvantage of both data availability and performance evaluation of the backbone\ndeep learning architectures. We gather a novel dataset, \\emph{Diverse Vehicle\nand License Plates Dataset (DVLPD)}, consisting of 10k images belonging to six\nvehicle types. Each image is then manually annotated for vehicle type, license\nplate, and its characters and digits. For each of the three tasks, we evaluate\nYou Only Look Once (YOLO)v2, YOLOv3, YOLOv4, and FasterRCNN. For real-time\nimplementation on a Raspberry Pi, we evaluate the lighter versions of YOLO\nnamed Tiny YOLOv3 and Tiny YOLOv4. The best Mean Average Precision (mAP@0.5) of\n98.8% for vehicle type recognition, 98.5% for license plate detection, and\n98.3% for license plate reading is achieved by YOLOv4, while its lighter\nversion, i.e., Tiny YOLOv4 obtained a mAP of 97.1%, 97.4%, and 93.7% on vehicle\ntype recognition, license plate detection, and license plate reading,\nrespectively. The dataset and the training codes are available at\nhttps://github.com/usama-x930/VT-LPR",
    "descriptor": "",
    "authors": [
      "Muhammad Usama",
      "Hafeez Anwar",
      "Muhammad Muaz Shahid",
      "Abbas Anwar",
      "Saeed Anwar",
      "Helmuth Hlavacs"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.05631"
  },
  {
    "id": "arXiv:2202.05650",
    "title": "Bernstein Flows for Flexible Posteriors in Variational Bayes",
    "abstract": "Variational inference (VI) is a technique to approximate difficult to compute\nposteriors by optimization. In contrast to MCMC, VI scales to many\nobservations. In the case of complex posteriors, however, state-of-the-art VI\napproaches often yield unsatisfactory posterior approximations. This paper\npresents Bernstein flow variational inference (BF-VI), a robust and easy-to-use\nmethod, flexible enough to approximate complex multivariate posteriors. BF-VI\ncombines ideas from normalizing flows and Bernstein polynomial-based\ntransformation models. In benchmark experiments, we compare BF-VI solutions\nwith exact posteriors, MCMC solutions, and state-of-the-art VI methods\nincluding normalizing flow based VI. We show for low-dimensional models that\nBF-VI accurately approximates the true posterior; in higher-dimensional models,\nBF-VI outperforms other VI methods. Further, we develop with BF-VI a Bayesian\nmodel for the semi-structured Melanoma challenge data, combining a CNN model\npart for image data with an interpretable model part for tabular data, and\ndemonstrate for the first time how the use of VI in semi-structured models.",
    "descriptor": "",
    "authors": [
      "Oliver D\u00fcrr",
      "Stephan H\u00f6rling",
      "Daniel Dold",
      "Ivonne Kovylov",
      "Beate Sick"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.05650"
  },
  {
    "id": "arXiv:2202.05676",
    "title": "Deep artificial neural network for prediction of atrial fibrillation  through the analysis of 12-leads standard ECG",
    "abstract": "Atrial Fibrillation (AF) is a heart's arrhythmia which, despite being often\nasymptomatic, represents an important risk factor for stroke, therefore being\nable to predict AF at the electrocardiogram exam, would be of great impact on\nactively targeting patients at high risk. In the present work we use\nConvolution Neural Networks to analyze ECG and predict Atrial Fibrillation\nstarting from realistic datasets, i.e. considering fewer ECG than other studies\nand extending the maximal distance between ECG and AF diagnosis. We achieved\n75.5% (0.75) AUC firstly increasing our dataset size by a shifting technique\nand secondarily using the dilation parameter of the convolution neural network.\nIn addition we find that, contrarily to what is commonly used by clinicians\nreporting AF at the exam, the most informative leads for the task of predicting\nAF are D1 and avR. Similarly, we find that the most important frequencies to\ncheck are in the range of 5-20 Hz. Finally, we develop a net able to manage at\nthe same time the electrocardiographic signal together with the electronic\nhealth record, showing that integration between different sources of data is a\nprofitable path. In fact, the 2.8% gain of such net brings us to a 78.6% (std\n0.77) AUC. In future works we will deepen both the integration of sources and\nthe reason why we claim avR is the most informative lead.",
    "descriptor": "\nComments: 10 pages, 2 figures, 5 tables\n",
    "authors": [
      "A. Scagnetto",
      "G. Barbati",
      "I. Gandin",
      "C. Cappelletto",
      "G. Baj",
      "A. Cazzaniga",
      "F. Cuturello",
      "A. Ansuini",
      "L. Bortolussi",
      "A. Di Lenarda"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.05676"
  },
  {
    "id": "arXiv:2202.05677",
    "title": "Cross-Block Difference Guided Fast CU Partition for VVC Intra Coding",
    "abstract": "In this paper, we propose a new fast CU partition algorithm for VVC intra\ncoding based on cross-block difference. This difference is measured by the\ngradient and the content of sub-blocks obtained from partition and is employed\nto guide the skipping of unnecessary horizontal and vertical partition modes.\nWith this guidance, a fast determination of block partitions is accordingly\nachieved. Compared with VVC, our proposed method can save 41.64% (on average)\nencoding time with only 0.97% (on average) increase of BD-rate.",
    "descriptor": "\nComments: Accepted by 2021 VCIP\n",
    "authors": [
      "Hewei Liu",
      "Shuyuan Zhu",
      "Ruiqin Xiong",
      "Guanghui Liu",
      "Bing Zeng"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2202.05677"
  },
  {
    "id": "arXiv:2202.05686",
    "title": "Graphon-aided Joint Estimation of Multiple Graphs",
    "abstract": "We consider the problem of estimating the topology of multiple networks from\nnodal observations, where these networks are assumed to be drawn from the same\n(unknown) random graph model. We adopt a graphon as our random graph model,\nwhich is a nonparametric model from which graphs of potentially different sizes\ncan be drawn. The versatility of graphons allows us to tackle the joint\ninference problem even for the cases where the graphs to be recovered contain\ndifferent number of nodes and lack precise alignment across the graphs. Our\nsolution is based on combining a maximum likelihood penalty with graphon\nestimation schemes and can be used to augment existing network inference\nmethods. We validate our proposed approach by comparing its performance against\ncompeting methods in synthetic and real-world datasets.",
    "descriptor": "\nComments: 5 pages, 2 figures\n",
    "authors": [
      "Madeline Navarro",
      "Santiago Segarra"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.05686"
  },
  {
    "id": "arXiv:2202.05702",
    "title": "Machine Learning for Stock Prediction Based on Fundamental Analysis",
    "abstract": "Application of machine learning for stock prediction is attracting a lot of\nattention in recent years. A large amount of research has been conducted in\nthis area and multiple existing results have shown that machine learning\nmethods could be successfully used toward stock predicting using stocks\nhistorical data. Most of these existing approaches have focused on short term\nprediction using stocks historical price and technical indicators. In this\npaper, we prepared 22 years worth of stock quarterly financial data and\ninvestigated three machine learning algorithms: Feed-forward Neural Network\n(FNN), Random Forest (RF) and Adaptive Neural Fuzzy Inference System (ANFIS)\nfor stock prediction based on fundamental analysis. In addition, we applied RF\nbased feature selection and bootstrap aggregation in order to improve model\nperformance and aggregate predictions from different models. Our results show\nthat RF model achieves the best prediction results, and feature selection is\nable to improve test performance of FNN and ANFIS. Moreover, the aggregated\nmodel outperforms all baseline models as well as the benchmark DJIA index by an\nacceptable margin for the test period. Our findings demonstrate that machine\nlearning models could be used to aid fundamental analysts with decision-making\nregarding stock investment.",
    "descriptor": "\nComments: 10 pages. IEEE Symposium Series on Computational Intelligence, Orlando, Florida,USA, December 2021\n",
    "authors": [
      "Yuxuan Huang",
      "Luiz Fernando Capretz",
      "Danny Ho"
    ],
    "subjectives": [
      "Statistical Finance (q-fin.ST)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2202.05702"
  },
  {
    "id": "arXiv:2202.05703",
    "title": "Molecule Generation from Input-Attributions over Graph Convolutional  Networks",
    "abstract": "It is well known that Drug Design is often a costly process both in terms of\ntime and economic effort. While good Quantitative Structure-Activity\nRelationship models (QSAR) can help predicting molecular properties without the\nneed to synthesize them, it is still required to come up with new molecules to\nbe tested. This is mostly done in lack of tools to determine which\nmodifications are more promising or which aspects of a molecule are more\ninfluential for the final activity/property. Here we present an automatic\nprocess which involves Graph Convolutional Network models and input-attribution\nmethods to generate new molecules. We also explore the problems of\nover-optimization and applicability, recognizing them as two important aspects\nin the practical use of such automatic tools.",
    "descriptor": "\nComments: ELLIS Machine Learning for Molecules workshop (ML4Molecules) 2021\n",
    "authors": [
      "Dylan Savoia",
      "Alessio Ragno",
      "Roberto Capobianco"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.05703"
  },
  {
    "id": "arXiv:2202.05704",
    "title": "Semi-Supervised GCN for learning Molecular Structure-Activity  Relationships",
    "abstract": "Since the introduction of artificial intelligence in medicinal chemistry, the\nnecessity has emerged to analyse how molecular property variation is modulated\nby either single atoms or chemical groups. In this paper, we propose to train\ngraph-to-graph neural network using semi-supervised learning for attributing\nstructure-property relationships. As initial case studies we apply the method\nto solubility and molecular acidity while checking its consistency in\ncomparison with known experimental chemical data. As final goal, our approach\ncould represent a valuable tool to deal with problems such as activity cliffs,\nlead optimization and de-novo drug design.",
    "descriptor": "\nComments: ELLIS Machine Learning for Molecules workshop (ML4Molecules) 2021\n",
    "authors": [
      "Alessio Ragno",
      "Dylan Savoia",
      "Roberto Capobianco"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.05704"
  },
  {
    "id": "arXiv:2202.05736",
    "title": "Estimating flow fields with Reduced Order Models of Centrifugal Pumps",
    "abstract": "The estimation of fluid flows inside a centrifugal pump in realtime is a\nchallenging task that cannot be achieved with long-established methods like CFD\ndue to their computational demands. We use a projection-based reduced order\nmodel (ROM) instead. Based on this ROM, a realtime observer can be devised that\nestimates the temporally and spatially resolved velocity and pressure fields\ninside the pump. The entire fluid-solid domain is treated as a fluid in order\nto be able to consider moving rigid bodies in the reduction method. A greedy\nalgorithm is introduced for finding suitable and as few measurement locations\nas possible. Robust observability is ensured with an extended Kalman filter,\nwhich is based on a time-variant observability matrix obtained from the\nnonlinear velocity ROM. We present the results of the velocity and pressure\nROMs based on a unsteady Reynolds-averaged Navier-Stokes CFD simulation of a 2D\ncentrifugal model pump, as well as the results for the extended Kalman filter.",
    "descriptor": "\nComments: 14 pages, 12 figures\n",
    "authors": [
      "Kamil David Sommer",
      "Lucas Reineking",
      "Yogesh Parry Ravichandran",
      "Romuald Skoda",
      "Martin M\u00f6nnigmann"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.05736"
  },
  {
    "id": "arXiv:2202.05744",
    "title": "The xmuspeech system for multi-channel multi-party meeting transcription  challenge",
    "abstract": "This paper describes the system developed by the XMUSPEECH team for the\nMulti-channel Multi-party Meeting Transcription Challenge (M2MeT). For the\nspeaker diarization task, we propose a multi-channel speaker diarization system\nthat obtains spatial information of speaker by Difference of Arrival (DOA)\ntechnology. Speaker-spatial embedding is generated by x-vector and s-vector\nderived from Filter-and-Sum Beamforming (FSB) which makes the embedding more\nrobust. Specifically, we propose a novel multi-channel sequence-to-sequence\nneural network architecture named Discriminative Multi-stream Neural Network\n(DMSNet) which consists of Attention Filter-and-Sum block (AFSB) and Conformer\nencoder. We explore DMSNet to address overlapped speech problem on\nmulti-channel audio. Compared with LSTM based OSD module, we achieve a\ndecreases of 10.1% in Detection Error Rate(DetER). By performing DMSNet based\nOSD module, the DER of cluster-based diarization system decrease significantly\nform 13.44% to 7.63%. Our best fusion system achieves 7.09% and 9.80% of the\ndiarization error rate (DER) on evaluation set and test set.",
    "descriptor": "",
    "authors": [
      "Jie Wang",
      "Yuji Liu",
      "Binling Wang",
      "Yiming Zhi",
      "Song Li1",
      "Shipeng Xia",
      "Jiayang Zhang",
      "Lin Li1",
      "Qingyang Hong",
      "Feng Tong"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2202.05744"
  },
  {
    "id": "arXiv:2202.05750",
    "title": "Bounded nonlinear forecasts of partially observed geophysical systems  with physics-constrained deep learning",
    "abstract": "The complexity of real-world geophysical systems is often compounded by the\nfact that the observed measurements depend on hidden variables. These latent\nvariables include unresolved small scales and/or rapidly evolving processes,\npartially observed couplings, or forcings in coupled systems. This is the case\nin ocean-atmosphere dynamics, for which unknown interior dynamics can affect\nsurface observations. The identification of computationally-relevant\nrepresentations of such partially-observed and highly nonlinear systems is thus\nchallenging and often limited to short-term forecast applications. Here, we\ninvestigate the physics-constrained learning of implicit dynamical embeddings,\nleveraging neural ordinary differential equation (NODE) representations. A key\nobjective is to constrain their boundedness, which promotes the generalization\nof the learned dynamics to arbitrary initial condition. The proposed\narchitecture is implemented within a deep learning framework, and its relevance\nis demonstrated with respect to state-of-the-art schemes for different\ncase-studies representative of geophysical dynamics.",
    "descriptor": "",
    "authors": [
      "Said Ouala",
      "Steven L. Brunton",
      "Ananda Pascual",
      "Bertrand Chapron",
      "Fabrice Collard",
      "Lucile Gaultier",
      "Ronan Fablet"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2202.05750"
  },
  {
    "id": "arXiv:2202.05757",
    "title": "Product-Coproduct Prographs and Triangulations of the Sphere",
    "abstract": "In this paper, we explain how the classical Catalan families of objects\ninvolving paths, tableaux, triangulations, parentheses configurations and more\ngeneralize canonically to a three-dimensional version. In particular, we\npresent product-coproduct prographs as central objects explaining the\ncombinatorics of the triangulations of the sphere. Then we expose a natural way\nto extend the Tamari lattice to the product-coproduct prographs.",
    "descriptor": "",
    "authors": [
      "Nicolas Borie",
      "Justine Falque"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2202.05757"
  },
  {
    "id": "arXiv:2202.05775",
    "title": "Inference of Multiscale Gaussian Graphical Model",
    "abstract": "Gaussian Graphical Models (GGMs) are widely used for exploratory data\nanalysis in various fields such as genomics, ecology, psychometry. In a\nhigh-dimensional setting, when the number of variables exceeds the number of\nobservations by several orders of magnitude, the estimation of GGM is a\ndifficult and unstable optimization problem. Clustering of variables or\nvariable selection is often performed prior to GGM estimation. We propose a new\nmethod allowing to simultaneously infer a hierarchical clustering structure and\nthe graphs describing the structure of independence at each level of the\nhierarchy. This method is based on solving a convex optimization problem\ncombining a graphical lasso penalty with a fused type lasso penalty. Results on\nreal and synthetic data are presented.",
    "descriptor": "",
    "authors": [
      "Do Edmond Sanou",
      "Christophe Ambroise",
      "Genevi\u00e8ve Robin"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.05775"
  },
  {
    "id": "arXiv:2202.05777",
    "title": "Metastability of the Potts ferromagnet on random regular graphs",
    "abstract": "We study the performance of Markov chains for the $q$-state ferromagnetic\nPotts model on random regular graphs. It is conjectured that their performance\nis dictated by metastability phenomena, i.e., the presence of \"phases\"\n(clusters) in the sample space where Markov chains with local update rules,\nsuch as the Glauber dynamics, are bound to take exponential time to escape, and\ntherefore cause slow mixing. The phases that are believed to drive these\nmetastability phenomena in the case of the Potts model emerge as local, rather\nthan global, maxima of the so-called Bethe functional, and previous approaches\nof analysing these phases based on optimisation arguments fall short of the\ntask.\nOur first contribution is to detail the emergence of the metastable phases\nfor the $q$-state Potts model on the $d$-regular random graph for all integers\n$q,d\\geq 3$, and establish that for an interval of temperatures, delineated by\nthe uniqueness and the Kesten-Stigum thresholds on the $d$-regular tree, the\ntwo phases coexist. The proofs are based on a conceptual connection between\nspatial properties and the structure of the Potts distribution on the random\nregular graph, rather than complicated moment calculations.\nBased on this new structural understanding of the model, we obtain various\nalgorithmic consequences. We first complement recent fast mixing results for\nGlauber dynamics by Blanca and Gheissari below the uniqueness threshold,\nshowing an exponential lower bound on the mixing time above the uniqueness\nthreshold. Then, we obtain tight results even for the non-local Swendsen-Wang\nchain, where we establish slow mixing/metastability for the whole interval of\ntemperatures where the chain is conjectured to mix slowly on the random regular\ngraph. The key is to bound the conductance of the chains using a random graph\n\"planting\" argument combined with delicate bounds on random-graph percolation.",
    "descriptor": "\nComments: Abstract shortened for arXiv\n",
    "authors": [
      "Amin Coja-Oghlan",
      "Andreas Galanis",
      "Leslie Ann Goldberg",
      "Jean Bernoulli Ravelomanana",
      "Daniel Stefankovic",
      "Eric Vigoda"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2202.05777"
  },
  {
    "id": "arXiv:2202.05791",
    "title": "The Power of Adaptivity in SGD: Self-Tuning Step Sizes with Unbounded  Gradients and Affine Variance",
    "abstract": "We study convergence rates of AdaGrad-Norm as an exemplar of adaptive\nstochastic gradient methods (SGD), where the step sizes change based on\nobserved stochastic gradients, for minimizing non-convex, smooth objectives.\nDespite their popularity, the analysis of adaptive SGD lags behind that of non\nadaptive methods in this setting. Specifically, all prior works rely on some\nsubset of the following assumptions: (i) uniformly-bounded gradient norms, (ii)\nuniformly-bounded stochastic gradient variance (or even noise support), (iii)\nconditional independence between the step size and stochastic gradient. In this\nwork, we show that AdaGrad-Norm exhibits an order optimal convergence rate of\n$\\mathcal{O}\\left(\\frac{\\mathrm{poly}\\log(T)}{\\sqrt{T}}\\right)$ after $T$\niterations under the same assumptions as optimally-tuned non adaptive SGD\n(unbounded gradient norms and affine noise variance scaling), and crucially,\nwithout needing any tuning parameters. We thus establish that adaptive gradient\nmethods exhibit order-optimal convergence in much broader regimes than\npreviously understood.",
    "descriptor": "",
    "authors": [
      "Matthew Faw",
      "Isidoros Tziotis",
      "Constantine Caramanis",
      "Aryan Mokhtari",
      "Sanjay Shakkottai",
      "Rachel Ward"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2202.05791"
  },
  {
    "id": "arXiv:2202.05812",
    "title": "Distributed saddle point problems for strongly concave-convex functions",
    "abstract": "In this paper, we propose GT-GDA, a distributed optimization method to solve\nsaddle point problems of the form: $\\min_{\\mathbf{x}} \\max_{\\mathbf{y}}\n\\{F(\\mathbf{x},\\mathbf{y}) :=G(\\mathbf{x}) + \\langle \\mathbf{y}, \\overline{P}\n\\mathbf{x} \\rangle - H(\\mathbf{y})\\}$, where the functions $G(\\cdot)$,\n$H(\\cdot)$, and the the coupling matrix $\\overline{P}$ are distributed over a\nstrongly connected network of nodes. GT-GDA is a first-order method that uses\ngradient tracking to eliminate the dissimilarity caused by heterogeneous data\ndistribution among the nodes. In the most general form, GT-GDA includes a\nconsensus over the local coupling matrices to achieve the optimal (unique)\nsaddle point, however, at the expense of increased communication. To avoid\nthis, we propose a more efficient variant GT-GDA-Lite that does not incur the\nadditional communication and analyze its convergence in various scenarios. We\nshow that GT-GDA converges linearly to the unique saddle point solution when\n$G(\\cdot)$ is smooth and convex, $H(\\cdot)$ is smooth and strongly convex, and\nthe global coupling matrix $\\overline{P}$ has full column rank. We further\ncharacterize the regime under which GT-GDA exhibits a network\ntopology-independent convergence behavior. We next show the linear convergence\nof GT-GDA to an error around the unique saddle point, which goes to zero when\nthe coupling cost ${\\langle \\mathbf y, \\overline{P} \\mathbf x \\rangle}$ is\ncommon to all nodes, or when $G(\\cdot)$ and $H(\\cdot)$ are quadratic. Numerical\nexperiments illustrate the convergence properties and importance of GT-GDA and\nGT-GDA-Lite for several applications.",
    "descriptor": "",
    "authors": [
      "Muhammad I. Qureshi",
      "Usman A. Khan"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.05812"
  },
  {
    "id": "arXiv:1409.7618",
    "title": "Multiple Object Tracking: A Literature Review",
    "abstract": "Comments: Accepted by Artificial Intelligence",
    "descriptor": "\nComments: Accepted by Artificial Intelligence\n",
    "authors": [
      "Wenhan Luo",
      "Junliang Xing",
      "Anton Milan",
      "Xiaoqin Zhang",
      "Wei Liu",
      "Tae-Kyun Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/1409.7618"
  },
  {
    "id": "arXiv:1810.06784",
    "title": "ProMP: Proximal Meta-Policy Search",
    "abstract": "Comments: The first three authors contributed equally. Published at ICLR 2019",
    "descriptor": "\nComments: The first three authors contributed equally. Published at ICLR 2019\n",
    "authors": [
      "Jonas Rothfuss",
      "Dennis Lee",
      "Ignasi Clavera",
      "Tamim Asfour",
      "Pieter Abbeel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1810.06784"
  },
  {
    "id": "arXiv:1811.02710",
    "title": "Abstract hypernormalisation, and normalisation-by-trace-evaluation for  generative systems",
    "abstract": "Comments: 54 pages; v2: added diverse new examples, exegeses, and applications",
    "descriptor": "\nComments: 54 pages; v2: added diverse new examples, exegeses, and applications\n",
    "authors": [
      "Richard Garner"
    ],
    "subjectives": [
      "Category Theory (math.CT)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/1811.02710"
  },
  {
    "id": "arXiv:1904.03961",
    "title": "Filter Pruning by Switching to Neighboring CNNs with Good Attributes",
    "abstract": "Comments: Accepted by IEEE Transactions on Neural Networks and Learning Systems",
    "descriptor": "\nComments: Accepted by IEEE Transactions on Neural Networks and Learning Systems\n",
    "authors": [
      "Yang He",
      "Ping Liu",
      "Linchao Zhu",
      "Yi Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/1904.03961"
  },
  {
    "id": "arXiv:1910.03392",
    "title": "Experimental Validation of Fully Distributed Peer-to-Peer Optimal  Voltage Control with Minimal Model Requirements",
    "abstract": "Experimental Validation of Fully Distributed Peer-to-Peer Optimal  Voltage Control with Minimal Model Requirements",
    "descriptor": "",
    "authors": [
      "Lukas Ortmann",
      "Alexander Prostejovsky",
      "Kai Heussen",
      "Saverio Bolognani"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/1910.03392"
  },
  {
    "id": "arXiv:2002.00717",
    "title": "Error-feedback stochastic modeling strategy for time series forecasting  with convolutional neural networks",
    "abstract": "Error-feedback stochastic modeling strategy for time series forecasting  with convolutional neural networks",
    "descriptor": "",
    "authors": [
      "Xinze Zhang",
      "Kun He",
      "Yukun Bao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2002.00717"
  },
  {
    "id": "arXiv:2002.02513",
    "title": "Multi Type Mean Field Reinforcement Learning",
    "abstract": "Comments: Paper to appear in the Proceedings of International Conference on Autonomous Agents and Multi-Agent Systems (AAMAS) 2020. Revised version has some typos corrected",
    "descriptor": "\nComments: Paper to appear in the Proceedings of International Conference on Autonomous Agents and Multi-Agent Systems (AAMAS) 2020. Revised version has some typos corrected\n",
    "authors": [
      "Sriram Ganapathi Subramanian",
      "Pascal Poupart",
      "Matthew E. Taylor",
      "Nidhi Hegde"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2002.02513"
  },
  {
    "id": "arXiv:2003.07655",
    "title": "Book Embeddings of Nonplanar Graphs with Small Faces in Few Pages",
    "abstract": "Book Embeddings of Nonplanar Graphs with Small Faces in Few Pages",
    "descriptor": "",
    "authors": [
      "Michael A. Bekos",
      "Giordano Da Lozzo",
      "Svenja Griesbach",
      "Martin Gronemann",
      "Fabrizio Montecchiani",
      "Chrysanthi Raftopoulou"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2003.07655"
  },
  {
    "id": "arXiv:2004.10846",
    "title": "Reducing the Feeder Effect in Public School Admissions: A Bias-aware  Analysis for Targeted Interventions",
    "abstract": "Reducing the Feeder Effect in Public School Admissions: A Bias-aware  Analysis for Targeted Interventions",
    "descriptor": "",
    "authors": [
      "Yuri Faenza",
      "Swati Gupta",
      "Xuan Zhang"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2004.10846"
  },
  {
    "id": "arXiv:2008.12959",
    "title": "Puzzle-AE: Novelty Detection in Images through Solving Puzzles",
    "abstract": "Comments: The paper is under consideration at Computer Vision and Image Understanding",
    "descriptor": "\nComments: The paper is under consideration at Computer Vision and Image Understanding\n",
    "authors": [
      "Mohammadreza Salehi",
      "Ainaz Eftekhar",
      "Niousha Sadjadi",
      "Mohammad Hossein Rohban",
      "Hamid R. Rabiee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2008.12959"
  },
  {
    "id": "arXiv:2009.13108",
    "title": "NITI: Training Integer Neural Networks Using Integer-only Arithmetic",
    "abstract": "NITI: Training Integer Neural Networks Using Integer-only Arithmetic",
    "descriptor": "",
    "authors": [
      "Maolin Wang",
      "Seyedramin Rasoulinezhad",
      "Philip H.W. Leong",
      "Hayden K.H. So"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2009.13108"
  },
  {
    "id": "arXiv:2010.05652",
    "title": "Interval Query Problem on Cube-free Median Graphs",
    "abstract": "Comments: ISAAC'21, 21 pages",
    "descriptor": "\nComments: ISAAC'21, 21 pages\n",
    "authors": [
      "Soh Kumabe"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2010.05652"
  },
  {
    "id": "arXiv:2010.13766",
    "title": "Contextual Latent-Movements Off-Policy Optimization for Robotic  Manipulation Skills",
    "abstract": "Contextual Latent-Movements Off-Policy Optimization for Robotic  Manipulation Skills",
    "descriptor": "",
    "authors": [
      "Samuele Tosatto",
      "Georgia Chalvatzaki",
      "Jan Peters"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2010.13766"
  },
  {
    "id": "arXiv:2011.00962",
    "title": "Unified greedy approximability beyond submodular maximization",
    "abstract": "Unified greedy approximability beyond submodular maximization",
    "descriptor": "",
    "authors": [
      "Yann Disser",
      "David Weckbecker"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2011.00962"
  },
  {
    "id": "arXiv:2011.11066",
    "title": "Matrix-wise $\\ell_0$-constrained Sparse Nonnegative Least Squares",
    "abstract": "Comments: 20 pages + 18 pages supplementary material. This is the second version of a work originally called \"A Homotopy-based Algorithm for Sparse Multiple Right-hand Sides Nonnegative Least Squares\". Although the central concept is the same, the paper has been almost completely rewritten",
    "descriptor": "\nComments: 20 pages + 18 pages supplementary material. This is the second version of a work originally called \"A Homotopy-based Algorithm for Sparse Multiple Right-hand Sides Nonnegative Least Squares\". Although the central concept is the same, the paper has been almost completely rewritten\n",
    "authors": [
      "Nicolas Nadisic",
      "Jeremy E Cohen",
      "Arnaud Vandaele",
      "Nicolas Gillis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2011.11066"
  },
  {
    "id": "arXiv:2011.14956",
    "title": "Handling Noisy Labels via One-Step Abductive Multi-Target Learning: An  Application to Helicobacter Pylori Segmentation",
    "abstract": "Comments: 71 pages, 39 figures",
    "descriptor": "\nComments: 71 pages, 39 figures\n",
    "authors": [
      "Yongquan Yang",
      "Yiming Yang",
      "Jie Chen",
      "Jiayi Zheng",
      "Zhongxi Zheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2011.14956"
  },
  {
    "id": "arXiv:2012.08456",
    "title": "TACTO: A Fast, Flexible, and Open-source Simulator for High-Resolution  Vision-based Tactile Sensors",
    "abstract": "Comments: Accepted to IEEE RAL and ICRA 2022",
    "descriptor": "\nComments: Accepted to IEEE RAL and ICRA 2022\n",
    "authors": [
      "Shaoxiong Wang",
      "Mike Lambeta",
      "Po-Wei Chou",
      "Roberto Calandra"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2012.08456"
  },
  {
    "id": "arXiv:2012.08668",
    "title": "Mitigating Bias in Calibration Error Estimation",
    "abstract": "Comments: To be published in AISTATS 2022. Code is available this https URL",
    "descriptor": "\nComments: To be published in AISTATS 2022. Code is available this https URL\n",
    "authors": [
      "Rebecca Roelofs",
      "Nicholas Cain",
      "Jonathon Shlens",
      "Michael C. Mozer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2012.08668"
  },
  {
    "id": "arXiv:2101.08936",
    "title": "Numerical Methods for Backward Stochastic Differential Equations: A  Survey",
    "abstract": "Comments: 43 pages",
    "descriptor": "\nComments: 43 pages\n",
    "authors": [
      "Jared Chessari",
      "Reiichiro Kawai",
      "Yuji Shinozaki",
      "Toshihiro Yamada"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2101.08936"
  },
  {
    "id": "arXiv:2101.09333",
    "title": "SPAD-Based Optical Wireless Communication with Signal Pre-Distortion and  Noise Normalization",
    "abstract": "SPAD-Based Optical Wireless Communication with Signal Pre-Distortion and  Noise Normalization",
    "descriptor": "",
    "authors": [
      "Shenjie Huang",
      "Majid Safari"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2101.09333"
  },
  {
    "id": "arXiv:2102.01284",
    "title": "Single Model Deep Learning on Imbalanced Small Datasets for Skin Lesion  Classification",
    "abstract": "Single Model Deep Learning on Imbalanced Small Datasets for Skin Lesion  Classification",
    "descriptor": "",
    "authors": [
      "Peng Yao",
      "Shuwei Shen",
      "Mengjuan Xu",
      "Peng Liu",
      "Fan Zhang",
      "Jinyu Xing",
      "Pengfei Shao",
      "Benjamin Kaffenberger",
      "Ronald X. Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.01284"
  },
  {
    "id": "arXiv:2102.04671",
    "title": "A Single-Timescale Method for Stochastic Bilevel Optimization",
    "abstract": "Comments: Minor edits in Table 1",
    "descriptor": "\nComments: Minor edits in Table 1\n",
    "authors": [
      "Tianyi Chen",
      "Yuejiao Sun",
      "Quan Xiao",
      "Wotao Yin"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2102.04671"
  },
  {
    "id": "arXiv:2102.05573",
    "title": "A Witness Two-Sample Test",
    "abstract": "Comments: AISTATS2022",
    "descriptor": "\nComments: AISTATS2022\n",
    "authors": [
      "Jonas M. K\u00fcbler",
      "Wittawat Jitkrittum",
      "Bernhard Sch\u00f6lkopf",
      "Krikamol Muandet"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2102.05573"
  },
  {
    "id": "arXiv:2102.10127",
    "title": "Crowbar: Behavioral Symbolic Execution for Deductive Verification of  Active Objects",
    "abstract": "Crowbar: Behavioral Symbolic Execution for Deductive Verification of  Active Objects",
    "descriptor": "",
    "authors": [
      "Eduard Kamburjan",
      "Marco Scaletta",
      "Nils Rollshausen"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2102.10127"
  },
  {
    "id": "arXiv:2103.02542",
    "title": "Modularity and Mutual Information in Networks: Two Sides of the Same  Coin",
    "abstract": "Modularity and Mutual Information in Networks: Two Sides of the Same  Coin",
    "descriptor": "",
    "authors": [
      "Qian Wang",
      "Yongkang Guo",
      "Zhihuan Huang",
      "Yuqing Kong"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2103.02542"
  },
  {
    "id": "arXiv:2103.08417",
    "title": "Distributed Linear-Quadratic Control with Graph Neural Networks",
    "abstract": "Distributed Linear-Quadratic Control with Graph Neural Networks",
    "descriptor": "",
    "authors": [
      "Fernando Gama",
      "Somayeh Sojoudi"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2103.08417"
  },
  {
    "id": "arXiv:2103.14867",
    "title": "A nonlinear diffusion method for semi-supervised learning on hypergraphs",
    "abstract": "A nonlinear diffusion method for semi-supervised learning on hypergraphs",
    "descriptor": "",
    "authors": [
      "Francesco Tudisco",
      "Konstantin Prokopchik",
      "Austin R. Benson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ],
    "url": "https://arxiv.org/abs/2103.14867"
  },
  {
    "id": "arXiv:2103.16833",
    "title": "A categorical framework for congruence of applicative bisimilarity in  higher-order languages",
    "abstract": "A categorical framework for congruence of applicative bisimilarity in  higher-order languages",
    "descriptor": "",
    "authors": [
      "Tom Hirschowitz",
      "Ambroise Lafont"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2103.16833"
  },
  {
    "id": "arXiv:2104.00563",
    "title": "Latent Variable Sequential Set Transformers For Joint Multi-Agent Motion  Prediction",
    "abstract": "Comments: 26 pages, 17 figures, 8 tables",
    "descriptor": "\nComments: 26 pages, 17 figures, 8 tables\n",
    "authors": [
      "Roger Girgis",
      "Florian Golemo",
      "Felipe Codevilla",
      "Martin Weiss",
      "Jim Aldon D'Souza",
      "Samira Ebrahimi Kahou",
      "Felix Heide",
      "Christopher Pal"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2104.00563"
  },
  {
    "id": "arXiv:2104.00584",
    "title": "Model Selection for Time Series Forecasting: Empirical Analysis of  Different Estimators",
    "abstract": "Model Selection for Time Series Forecasting: Empirical Analysis of  Different Estimators",
    "descriptor": "",
    "authors": [
      "Vitor Cerqueira",
      "Luis Torgo",
      "Carlos Soares"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.00584"
  },
  {
    "id": "arXiv:2104.01161",
    "title": "An Audio-Based Deep Learning Framework For BBC Television Programme  Classification",
    "abstract": "An Audio-Based Deep Learning Framework For BBC Television Programme  Classification",
    "descriptor": "",
    "authors": [
      "Lam Pham",
      "Chris Baume",
      "Qiuqiang Kong",
      "Tassadaq Hussain",
      "Wenwu Wang",
      "Mark Plumbley"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2104.01161"
  },
  {
    "id": "arXiv:2104.01976",
    "title": "FABRIC: A Framework for the Design and Evaluation of Collaborative  Robots with Extended Human Adaptation",
    "abstract": "Comments: The article is in review for publication in Transactions on Human-Robot Interaction",
    "descriptor": "\nComments: The article is in review for publication in Transactions on Human-Robot Interaction\n",
    "authors": [
      "O. Can G\u00f6r\u00fcr",
      "Benjamin Rosman",
      "Fikret Sivrikaya",
      "Sahin Albayrak"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2104.01976"
  },
  {
    "id": "arXiv:2104.02032",
    "title": "Artificial Neural Network Modeling for Airline Disruption Management",
    "abstract": "Comments: Published in Journal of Aerospace Information Systems",
    "descriptor": "\nComments: Published in Journal of Aerospace Information Systems\n",
    "authors": [
      "Kolawole Ogunsina",
      "Wendy A. Okolo"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2104.02032"
  },
  {
    "id": "arXiv:2104.05614",
    "title": "A Dynamic Response Recovery Framework Using Ambient Synchrophasor Data",
    "abstract": "A Dynamic Response Recovery Framework Using Ambient Synchrophasor Data",
    "descriptor": "",
    "authors": [
      "Shaohui Liu",
      "Hao Zhu",
      "Vassilis Kekatos"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Signal Processing (eess.SP)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2104.05614"
  },
  {
    "id": "arXiv:2104.06102",
    "title": "Finite-dimensional output stabilization for a class of linear  distributed parameter systems -- a small-gain approach",
    "abstract": "Finite-dimensional output stabilization for a class of linear  distributed parameter systems -- a small-gain approach",
    "descriptor": "",
    "authors": [
      "Lars Gr\u00fcne",
      "Thomas Meurer"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Dynamical Systems (math.DS)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2104.06102"
  },
  {
    "id": "arXiv:2104.08795",
    "title": "Intuitive Physics Guided Exploration for Sample Efficient Sim2real  Transfer",
    "abstract": "Intuitive Physics Guided Exploration for Sample Efficient Sim2real  Transfer",
    "descriptor": "",
    "authors": [
      "Buddhika Laknath Semage",
      "Thommen George Karimpanal",
      "Santu Rana",
      "Svetha Venkatesh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2104.08795"
  },
  {
    "id": "arXiv:2105.03153",
    "title": "Pairwise Fairness for Ordinal Regression",
    "abstract": "Pairwise Fairness for Ordinal Regression",
    "descriptor": "",
    "authors": [
      "Matth\u00e4us Kleindessner",
      "Samira Samadi",
      "Muhammad Bilal Zafar",
      "Krishnaram Kenthapadi",
      "Chris Russell"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.03153"
  },
  {
    "id": "arXiv:2105.07475",
    "title": "Integrating Geometry-Driven and Data-Driven Positioning via  Combinatorial Data Augmentation",
    "abstract": "Comments: submitted to a possible IEEE journal",
    "descriptor": "\nComments: submitted to a possible IEEE journal\n",
    "authors": [
      "Seung Min Yu",
      "Jihong Park",
      "Seung-Woo Ko"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2105.07475"
  },
  {
    "id": "arXiv:2105.08472",
    "title": "Yet another eigenvalue algorithm for solving polynomial systems",
    "abstract": "Comments: 30 pages",
    "descriptor": "\nComments: 30 pages\n",
    "authors": [
      "Mat\u00edas R. Bender",
      "Simon Telen"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Symbolic Computation (cs.SC)",
      "Algebraic Geometry (math.AG)"
    ],
    "url": "https://arxiv.org/abs/2105.08472"
  },
  {
    "id": "arXiv:2105.14987",
    "title": "Crouzeix-Raviart triangular elements are inf-sup stable",
    "abstract": "Comments: 18 pages, 1 figure",
    "descriptor": "\nComments: 18 pages, 1 figure\n",
    "authors": [
      "C. Carstensen",
      "S. Sauter"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2105.14987"
  },
  {
    "id": "arXiv:2106.00875",
    "title": "The Hardest Explicit Construction",
    "abstract": "Comments: Improved parameters in first rigidity reduction, simplified Lemma 3, fixed minor typos",
    "descriptor": "\nComments: Improved parameters in first rigidity reduction, simplified Lemma 3, fixed minor typos\n",
    "authors": [
      "Oliver Korten"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2106.00875"
  },
  {
    "id": "arXiv:2106.01483",
    "title": "Multiscale Domain Adaptive YOLO for Cross-Domain Object Detection",
    "abstract": "Multiscale Domain Adaptive YOLO for Cross-Domain Object Detection",
    "descriptor": "",
    "authors": [
      "Mazin Hnewa",
      "Hayder Radha"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.01483"
  },
  {
    "id": "arXiv:2106.03186",
    "title": "Reverse Engineering the Neural Tangent Kernel",
    "abstract": "Comments: 15 pages, 5 figures",
    "descriptor": "\nComments: 15 pages, 5 figures\n",
    "authors": [
      "James B. Simon",
      "Sajant Anand",
      "Michael R. DeWeese"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.03186"
  },
  {
    "id": "arXiv:2106.04895",
    "title": "Policy Finetuning: Bridging Sample-Efficient Offline and Online  Reinforcement Learning",
    "abstract": "Comments: Published in NeurIPS 2021",
    "descriptor": "\nComments: Published in NeurIPS 2021\n",
    "authors": [
      "Tengyang Xie",
      "Nan Jiang",
      "Huan Wang",
      "Caiming Xiong",
      "Yu Bai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.04895"
  },
  {
    "id": "arXiv:2106.06091",
    "title": "DECORE: Deep Compression with Reinforcement Learning",
    "abstract": "DECORE: Deep Compression with Reinforcement Learning",
    "descriptor": "",
    "authors": [
      "Manoj Alwani",
      "Yang Wang",
      "Vashisht Madhavan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.06091"
  },
  {
    "id": "arXiv:2106.06926",
    "title": "Bellman-consistent Pessimism for Offline Reinforcement Learning",
    "abstract": "Comments: NeurIPS 2021 (Oral)",
    "descriptor": "\nComments: NeurIPS 2021 (Oral)\n",
    "authors": [
      "Tengyang Xie",
      "Ching-An Cheng",
      "Nan Jiang",
      "Paul Mineiro",
      "Alekh Agarwal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.06926"
  },
  {
    "id": "arXiv:2106.10424",
    "title": "On Generalization of Adversarial Imitation Learning and Beyond",
    "abstract": "On Generalization of Adversarial Imitation Learning and Beyond",
    "descriptor": "",
    "authors": [
      "Tian Xu",
      "Ziniu Li",
      "Yang Yu",
      "Zhi-Quan Luo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.10424"
  },
  {
    "id": "arXiv:2107.03065",
    "title": "Msdtron: a high-capability multi-speaker speech synthesis system for  diverse data using characteristic information",
    "abstract": "Comments: Accepted by ICASSP-2022",
    "descriptor": "\nComments: Accepted by ICASSP-2022\n",
    "authors": [
      "Qinghua Wu",
      "Quanbo Shen",
      "Jian Luan",
      "YuJun Wang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2107.03065"
  },
  {
    "id": "arXiv:2107.05287",
    "title": "End-to-end Trainable Deep Neural Network for Robotic Grasp Detection and  Semantic Segmentation from RGB",
    "abstract": "End-to-end Trainable Deep Neural Network for Robotic Grasp Detection and  Semantic Segmentation from RGB",
    "descriptor": "",
    "authors": [
      "Stefan Ainetter",
      "Friedrich Fraundorfer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2107.05287"
  },
  {
    "id": "arXiv:2107.05893",
    "title": "PU-Flow: a Point Cloud Upsampling Network with Normalizing Flows",
    "abstract": "PU-Flow: a Point Cloud Upsampling Network with Normalizing Flows",
    "descriptor": "",
    "authors": [
      "Aihua Mao",
      "Zihui Du",
      "Junhui Hou",
      "Yaqi Duan",
      "Yong-jin Liu",
      "Ying He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.05893"
  },
  {
    "id": "arXiv:2107.06093",
    "title": "A generalized hypothesis test for community structure and homophily in  networks",
    "abstract": "A generalized hypothesis test for community structure and homophily in  networks",
    "descriptor": "",
    "authors": [
      "Eric Yanchenko",
      "Srijan Sengupta"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2107.06093"
  },
  {
    "id": "arXiv:2107.07112",
    "title": "On the Evaluation of Neural Code Summarization",
    "abstract": "Comments: Accepted by ICSE 2022 (The 44th International Conference on Software Engineering)",
    "descriptor": "\nComments: Accepted by ICSE 2022 (The 44th International Conference on Software Engineering)\n",
    "authors": [
      "Ensheng Shi",
      "Yanlin Wang",
      "Lun Du",
      "Junjie Chen",
      "Shi Han",
      "Hongyu Zhang",
      "Dongmei Zhang",
      "Hongbin Sun"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.07112"
  },
  {
    "id": "arXiv:2107.07455",
    "title": "Shifts: A Dataset of Real Distributional Shift Across Multiple  Large-Scale Tasks",
    "abstract": "Shifts: A Dataset of Real Distributional Shift Across Multiple  Large-Scale Tasks",
    "descriptor": "",
    "authors": [
      "Andrey Malinin",
      "Neil Band",
      "Ganshin",
      "Alexander",
      "German Chesnokov",
      "Yarin Gal",
      "Mark J. F. Gales",
      "Alexey Noskov",
      "Andrey Ploskonosov",
      "Liudmila Prokhorenkova",
      "Ivan Provilkov",
      "Vatsal Raina",
      "Vyas Raina",
      "Roginskiy",
      "Denis",
      "Mariya Shmatova",
      "Panos Tigas",
      "Boris Yangel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.07455"
  },
  {
    "id": "arXiv:2107.12048",
    "title": "Decentralized Federated Learning: Balancing Communication and Computing  Costs",
    "abstract": "Decentralized Federated Learning: Balancing Communication and Computing  Costs",
    "descriptor": "",
    "authors": [
      "Wei Liu",
      "Li Chen",
      "Wenyi Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2107.12048"
  },
  {
    "id": "arXiv:2107.12560",
    "title": "Perception-and-Regulation Network for Salient Object Detection",
    "abstract": "Perception-and-Regulation Network for Salient Object Detection",
    "descriptor": "",
    "authors": [
      "Jinchao Zhu",
      "Xiaoyu Zhang",
      "Xian Fang",
      "Feng Dong",
      "Li Yuehua",
      "Junnan Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.12560"
  },
  {
    "id": "arXiv:2107.13708",
    "title": "Learning how to listen: Automatically finding bug patterns in  event-driven JavaScript APIs",
    "abstract": "Comments: 19 pages, 6 figures. Accepted and to appear in IEEE TSE",
    "descriptor": "\nComments: 19 pages, 6 figures. Accepted and to appear in IEEE TSE\n",
    "authors": [
      "Ellen Arteca",
      "Max Sch\u00e4fer",
      "Frank Tip"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2107.13708"
  },
  {
    "id": "arXiv:2108.02658",
    "title": "Sparse Communication via Mixed Distributions",
    "abstract": "Comments: Accepted for oral presentation at ICLR 2022",
    "descriptor": "\nComments: Accepted for oral presentation at ICLR 2022\n",
    "authors": [
      "Ant\u00f3nio Farinhas",
      "Wilker Aziz",
      "Vlad Niculae",
      "Andr\u00e9 F. T. Martins"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.02658"
  },
  {
    "id": "arXiv:2108.03477",
    "title": "A Tool for Organizing Key Characteristics of Virtual, Augmented, and  Mixed Reality for Human-Robot Interaction Systems: Synthesizing VAM-HRI  Trends and Takeaways",
    "abstract": "Comments: Accepted to Robotics and Automation Magazine Special Issue on Extended Reality in Robotics",
    "descriptor": "\nComments: Accepted to Robotics and Automation Magazine Special Issue on Extended Reality in Robotics\n",
    "authors": [
      "Thomas R. Groechel",
      "Michael E. Walker",
      "Christine T. Chang",
      "Eric Rosen",
      "Jessica Zosa Forde"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2108.03477"
  },
  {
    "id": "arXiv:2108.04840",
    "title": "Post-hoc Interpretability for Neural NLP: A Survey",
    "abstract": "Post-hoc Interpretability for Neural NLP: A Survey",
    "descriptor": "",
    "authors": [
      "Andreas Madsen",
      "Siva Reddy",
      "Sarath Chandar"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2108.04840"
  },
  {
    "id": "arXiv:2108.08103",
    "title": "AdapterHub Playground: Simple and Flexible Few-Shot Learning with  Adapters",
    "abstract": "AdapterHub Playground: Simple and Flexible Few-Shot Learning with  Adapters",
    "descriptor": "",
    "authors": [
      "Tilman Beck",
      "Bela Bohlender",
      "Christina Viehmann",
      "Vincent Hane",
      "Yanik Adamson",
      "Jaber Khuri",
      "Jonas Brossmann",
      "Jonas Pfeiffer",
      "Iryna Gurevych"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2108.08103"
  },
  {
    "id": "arXiv:2108.09201",
    "title": "Performance Bounds for Sampling and Remote Estimation of Gauss-Markov  Processes over a Noisy Channel with Random Delay",
    "abstract": "Comments: 5 pages, 2 figures, accepted by IEEE SPAWC 2021",
    "descriptor": "\nComments: 5 pages, 2 figures, accepted by IEEE SPAWC 2021\n",
    "authors": [
      "Tasmeen Zaman Ornee",
      "Yin Sun"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2108.09201"
  },
  {
    "id": "arXiv:2108.10879",
    "title": "Are socially-aware trajectory prediction models really socially-aware?",
    "abstract": "Are socially-aware trajectory prediction models really socially-aware?",
    "descriptor": "",
    "authors": [
      "Saeed Saadatnejad",
      "Mohammadhossein Bahari",
      "Pedram Khorsandi",
      "Mohammad Saneian",
      "Seyed-Mohsen Moosavi-Dezfooli",
      "Alexandre Alahi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.10879"
  },
  {
    "id": "arXiv:2108.13064",
    "title": "Trust Enhancement Issues in Program Repair",
    "abstract": "Comments: To appear in 44th International Conference on Software Engineering (ICSE) 2022. The first two authors contributed equally and are joint \"first authors\"",
    "descriptor": "\nComments: To appear in 44th International Conference on Software Engineering (ICSE) 2022. The first two authors contributed equally and are joint \"first authors\"\n",
    "authors": [
      "Yannic Noller",
      "Ridwan Shariffdeen",
      "Xiang Gao",
      "Abhik Roychoudhury"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2108.13064"
  },
  {
    "id": "arXiv:2108.13161",
    "title": "Differentiable Prompt Makes Pre-trained Language Models Better Few-shot  Learners",
    "abstract": "Comments: Accepted by ICLR 2022",
    "descriptor": "\nComments: Accepted by ICLR 2022\n",
    "authors": [
      "Ningyu Zhang",
      "Luoqiu Li",
      "Xiang Chen",
      "Shumin Deng",
      "Zhen Bi",
      "Chuanqi Tan",
      "Fei Huang",
      "Huajun Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2108.13161"
  },
  {
    "id": "arXiv:2109.01425",
    "title": "Novel split quality measures for stratified multilabel Cross Validation  with application to large and sparse gene ontology datasets",
    "abstract": "Comments: 15 pages, 2 figures",
    "descriptor": "\nComments: 15 pages, 2 figures\n",
    "authors": [
      "Henri Tiittanen",
      "Liisa Holm",
      "Petri T\u00f6r\u00f6nen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Genomics (q-bio.GN)"
    ],
    "url": "https://arxiv.org/abs/2109.01425"
  },
  {
    "id": "arXiv:2109.03431",
    "title": "Fixed Support Tree-Sliced Wasserstein Barycenter",
    "abstract": "Comments: AISTATS 2022",
    "descriptor": "\nComments: AISTATS 2022\n",
    "authors": [
      "Yuki Takezawa",
      "Ryoma Sato",
      "Zornitsa Kozareva",
      "Sujith Ravi",
      "Makoto Yamada"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.03431"
  },
  {
    "id": "arXiv:2109.03795",
    "title": "Desiderata for Representation Learning: A Causal Perspective",
    "abstract": "Comments: 68 pages",
    "descriptor": "\nComments: 68 pages\n",
    "authors": [
      "Yixin Wang",
      "Michael I. Jordan"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2109.03795"
  },
  {
    "id": "arXiv:2109.05524",
    "title": "A Decidability-Based Loss Function",
    "abstract": "Comments: 23 pages, 7 figures",
    "descriptor": "\nComments: 23 pages, 7 figures\n",
    "authors": [
      "Pedro Silva",
      "Gladston Moreira",
      "Vander Freitas",
      "Rodrigo Silva",
      "David Menotti",
      "Eduardo Luz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.05524"
  },
  {
    "id": "arXiv:2109.05668",
    "title": "UMPNet: Universal Manipulation Policy Network for Articulated Objects",
    "abstract": "Comments: RA-L/ICRA 2022. Project page: this https URL",
    "descriptor": "\nComments: RA-L/ICRA 2022. Project page: this https URL\n",
    "authors": [
      "Zhenjia Xu",
      "Zhanpeng He",
      "Shuran Song"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.05668"
  },
  {
    "id": "arXiv:2109.06721",
    "title": "Linear block and convolutional MDS codes to required rate, distance and  type",
    "abstract": "Linear block and convolutional MDS codes to required rate, distance and  type",
    "descriptor": "",
    "authors": [
      "Ted Hurley"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2109.06721"
  },
  {
    "id": "arXiv:2109.08971",
    "title": "Envy-Free and Pareto-Optimal Allocations for Agents with Asymmetric  Random Valuations",
    "abstract": "Comments: 21 pages, 5 figures",
    "descriptor": "\nComments: 21 pages, 5 figures\n",
    "authors": [
      "Yushi Bai",
      "Paul G\u00f6lz"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2109.08971"
  },
  {
    "id": "arXiv:2109.11732",
    "title": "Holistic Semi-Supervised Approaches for EEG Representation Learning",
    "abstract": "Comments: Accepted by IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP 2022)",
    "descriptor": "\nComments: Accepted by IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP 2022)\n",
    "authors": [
      "Guangyi Zhang",
      "Ali Etemad"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.11732"
  },
  {
    "id": "arXiv:2110.01964",
    "title": "Deductive Verification of Programs with Underspecified Semantics by  Model Extraction",
    "abstract": "Deductive Verification of Programs with Underspecified Semantics by  Model Extraction",
    "descriptor": "",
    "authors": [
      "Eduard Kamburjan",
      "Nathan Wasser"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2110.01964"
  },
  {
    "id": "arXiv:2110.03177",
    "title": "EE-Net: Exploitation-Exploration Neural Networks in Contextual Bandits",
    "abstract": "Comments: 20 pages, ICLR 2022",
    "descriptor": "\nComments: 20 pages, ICLR 2022\n",
    "authors": [
      "Yikun Ban",
      "Yuchen Yan",
      "Arindam Banerjee",
      "Jingrui He"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.03177"
  },
  {
    "id": "arXiv:2110.03479",
    "title": "Camera Calibration through Camera Projection Loss",
    "abstract": "Comments: 5 pages, ICASSP 2022",
    "descriptor": "\nComments: 5 pages, ICASSP 2022\n",
    "authors": [
      "Talha Hanif Butt",
      "Murtaza Taj"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.03479"
  },
  {
    "id": "arXiv:2110.03794",
    "title": "Optimal Deployment and Operation of Robotic Aerial 6G Small Cells with  Grasping End Effectors",
    "abstract": "Optimal Deployment and Operation of Robotic Aerial 6G Small Cells with  Grasping End Effectors",
    "descriptor": "",
    "authors": [
      "Yuan Liao",
      "Vasilis Friderikos"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2110.03794"
  },
  {
    "id": "arXiv:2110.05085",
    "title": "Efficiently and Globally Solving Joint Beamforming and Compression  Problem in the Cooperative Cellular Network via Lagrangian Duality",
    "abstract": "Comments: 5 pages, 1 figure, accepted for publication in IEEE ICASSP 2022",
    "descriptor": "\nComments: 5 pages, 1 figure, accepted for publication in IEEE ICASSP 2022\n",
    "authors": [
      "Xilai Fan",
      "Ya-Feng Liu",
      "Liang Liu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.05085"
  },
  {
    "id": "arXiv:2110.05572",
    "title": "EchoVPR: Echo State Networks for Visual Place Recognition",
    "abstract": "Comments: Accepted to IEEE RA&L with presentation in ICRA 2022 conference. 8 pages + supplementary materials",
    "descriptor": "\nComments: Accepted to IEEE RA&L with presentation in ICRA 2022 conference. 8 pages + supplementary materials\n",
    "authors": [
      "Anil Ozdemir",
      "Mark Scerri",
      "Andrew B. Barron",
      "Andrew Philippides",
      "Michael Mangan",
      "Eleni Vasilaki",
      "Luca Manneschi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.05572"
  },
  {
    "id": "arXiv:2110.05941",
    "title": "Rank-based loss for learning hierarchical representations",
    "abstract": "Comments: This version corrects a bug in the baseline results",
    "descriptor": "\nComments: This version corrects a bug in the baseline results\n",
    "authors": [
      "Ines Nolasco",
      "Dan Stowell"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.05941"
  },
  {
    "id": "arXiv:2110.06363",
    "title": "A Side-channel Analysis of Sensor Multiplexing for Covert Channels and  Application Fingerprinting on Mobile Devices",
    "abstract": "A Side-channel Analysis of Sensor Multiplexing for Covert Channels and  Application Fingerprinting on Mobile Devices",
    "descriptor": "",
    "authors": [
      "Carlton Shepherd",
      "Jan Kalbantner",
      "Benjamin Semal",
      "Konstantinos Markantonakis"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.06363"
  },
  {
    "id": "arXiv:2110.09784",
    "title": "SSAST: Self-Supervised Audio Spectrogram Transformer",
    "abstract": "Comments: Accepted at AAAI2022. Code at this https URL",
    "descriptor": "\nComments: Accepted at AAAI2022. Code at this https URL\n",
    "authors": [
      "Yuan Gong",
      "Cheng-I Jeff Lai",
      "Yu-An Chung",
      "James Glass"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.09784"
  },
  {
    "id": "arXiv:2110.10117",
    "title": "Beyond Exact Gradients: Convergence of Stochastic Soft-Max Policy  Gradient Methods with Entropy Regularization",
    "abstract": "Beyond Exact Gradients: Convergence of Stochastic Soft-Max Policy  Gradient Methods with Entropy Regularization",
    "descriptor": "",
    "authors": [
      "Yuhao Ding",
      "Junzi Zhang",
      "Javad Lavaei"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.10117"
  },
  {
    "id": "arXiv:2110.10234",
    "title": "Collaboration Challenges in Building ML-Enabled Systems: Communication,  Documentation, Engineering, and Process",
    "abstract": "Comments: 22 pages, 10 figures, 5 tables",
    "descriptor": "\nComments: 22 pages, 10 figures, 5 tables\n",
    "authors": [
      "Nadia Nahar",
      "Shurui Zhou",
      "Grace Lewis",
      "Christian K\u00e4stner"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.10234"
  },
  {
    "id": "arXiv:2110.11316",
    "title": "CLOOB: Modern Hopfield Networks with InfoLOOB Outperform CLIP",
    "abstract": "Comments: 17 pages (+ appendix); Blog: this https URL GitHub: this https URL",
    "descriptor": "\nComments: 17 pages (+ appendix); Blog: this https URL GitHub: this https URL\n",
    "authors": [
      "Andreas F\u00fcrst",
      "Elisabeth Rumetshofer",
      "Johannes Lehner",
      "Viet Tran",
      "Fei Tang",
      "Hubert Ramsauer",
      "David Kreil",
      "Michael Kopp",
      "G\u00fcnter Klambauer",
      "Angela Bitto-Nemling",
      "Sepp Hochreiter"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.11316"
  },
  {
    "id": "arXiv:2110.11385",
    "title": "Self-Initiated Open World Learning for Autonomous AI Agents",
    "abstract": "Comments: Published in AAAI 2022 Spring Symposium Series",
    "descriptor": "\nComments: Published in AAAI 2022 Spring Symposium Series\n",
    "authors": [
      "Bing Liu",
      "Eric Robertson",
      "Scott Grigsby",
      "Sahisnu Mazumder"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.11385"
  },
  {
    "id": "arXiv:2110.15836",
    "title": "Combining Unsupervised and Text Augmented Semi-Supervised Learning for  Low Resourced Autoregressive Speech Recognition",
    "abstract": "Comments: 5 pages, minor changes for camera ready version, to be published in IEEE ICASSP 2022",
    "descriptor": "\nComments: 5 pages, minor changes for camera ready version, to be published in IEEE ICASSP 2022\n",
    "authors": [
      "Chak-Fai Li",
      "Francis Keith",
      "William Hartmann",
      "Matthew Snover"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.15836"
  },
  {
    "id": "arXiv:2111.00052",
    "title": "Diagnosing Data from ICTs to Provide Focused Assistance in Agricultural  Adoptions",
    "abstract": "Diagnosing Data from ICTs to Provide Focused Assistance in Agricultural  Adoptions",
    "descriptor": "",
    "authors": [
      "Ashwin S",
      "Mallika Subramanian",
      "Anmol Agarwal",
      "Pratyush Priyadarshi",
      "Shrey Gupta",
      "Kiran Garimella",
      "Sanjeev Kumar",
      "Ritesh Kumar",
      "Lokesh Garg",
      "Erica Arya",
      "Ponnurangam Kumaraguru"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2111.00052"
  },
  {
    "id": "arXiv:2111.00080",
    "title": "Targeted Hardening of Electric Distribution System for Enhanced  Resilience against Earthquakes",
    "abstract": "Comments: 6 pages, 4 figures",
    "descriptor": "\nComments: 6 pages, 4 figures\n",
    "authors": [
      "Mahan Fakouri Fard",
      "Mostafa Sahraei-Ardakani",
      "Ge Ou",
      "Mingxi Liu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2111.00080"
  },
  {
    "id": "arXiv:2111.00121",
    "title": "Longitudinal Analysis of Mask and No-Mask on Child Face Recognition",
    "abstract": "Comments: 5 Pages, 3 Figure",
    "descriptor": "\nComments: 5 Pages, 3 Figure\n",
    "authors": [
      "Praveen Kumar Chandaliya",
      "Zahid Akhtar",
      "Neeta Nain"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.00121"
  },
  {
    "id": "arXiv:2111.02359",
    "title": "SVD-Embedded Deep Autoencoder for MIMO Communications",
    "abstract": "Comments: 7 pages, 5 figures, 2 tables, To appear in the IEEE International Conference on Communications (ICC 2022)",
    "descriptor": "\nComments: 7 pages, 5 figures, 2 tables, To appear in the IEEE International Conference on Communications (ICC 2022)\n",
    "authors": [
      "Xinliang Zhang",
      "Mojtaba Vaezi",
      "Timothy J. O'Shea"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.02359"
  },
  {
    "id": "arXiv:2111.03301",
    "title": "Frequency-Aware Physics-Inspired Degradation Model for Real-World Image  Super-Resolution",
    "abstract": "Comments: 22 pages,12 figures",
    "descriptor": "\nComments: 22 pages,12 figures\n",
    "authors": [
      "Zhenxing Dong",
      "Hong Cao",
      "Wang Shen",
      "Yu Gan",
      "Yuye Ling",
      "Guangtao Zhai",
      "Yikai Su"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.03301"
  },
  {
    "id": "arXiv:2111.04986",
    "title": "Unified Group Fairness on Federated Learning",
    "abstract": "Comments: Under Review",
    "descriptor": "\nComments: Under Review\n",
    "authors": [
      "Fengda Zhang",
      "Kun Kuang",
      "Yuxuan Liu",
      "Long Chen",
      "Chao Wu",
      "Fei Wu",
      "Jiaxun Lu",
      "Yunfeng Shao",
      "Jun Xiao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.04986"
  },
  {
    "id": "arXiv:2111.10815",
    "title": "A User Centric Blockage Model for Wireless Networks",
    "abstract": "A User Centric Blockage Model for Wireless Networks",
    "descriptor": "",
    "authors": [
      "F. Baccelli",
      "B. Liu",
      "L. Decreusefond",
      "R. Song"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2111.10815"
  },
  {
    "id": "arXiv:2112.04424",
    "title": "Training Robust Zero-Shot Voice Conversion Models with Self-supervised  Features",
    "abstract": "Training Robust Zero-Shot Voice Conversion Models with Self-supervised  Features",
    "descriptor": "",
    "authors": [
      "Trung Dang",
      "Dung Tran",
      "Peter Chin",
      "Kazuhito Koishida"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2112.04424"
  },
  {
    "id": "arXiv:2112.05409",
    "title": "Batch Label Inference and Replacement Attacks in Black-Boxed Vertical  Federated Learning",
    "abstract": "Comments: 13 pages, 9 figures, 3 tables, related previous work see arXiv:2007.03608",
    "descriptor": "\nComments: 13 pages, 9 figures, 3 tables, related previous work see arXiv:2007.03608\n",
    "authors": [
      "Yang Liu",
      "Tianyuan Zou",
      "Yan Kang",
      "Wenhan Liu",
      "Yuanqin He",
      "Zhihao Yi",
      "Qiang Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.05409"
  },
  {
    "id": "arXiv:2112.05675",
    "title": "Assessing the Fairness of AI Systems: AI Practitioners' Processes,  Challenges, and Needs for Support",
    "abstract": "Comments: Camera-ready preprint of paper accepted to the CSCW conference",
    "descriptor": "\nComments: Camera-ready preprint of paper accepted to the CSCW conference\n",
    "authors": [
      "Michael Madaio",
      "Lisa Egede",
      "Hariharan Subramonyam",
      "Jennifer Wortman Vaughan",
      "Hanna Wallach"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2112.05675"
  },
  {
    "id": "arXiv:2112.06989",
    "title": "Analyzing a Caching Model",
    "abstract": "Comments: Presented at the Neurips 2021 Workshop ML for System",
    "descriptor": "\nComments: Presented at the Neurips 2021 Workshop ML for System\n",
    "authors": [
      "Leon Sixt",
      "Evan Zheran Liu",
      "Marie Pellat",
      "James Wexler",
      "Milad Hashemi",
      "Been Kim",
      "Martin Maas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.06989"
  },
  {
    "id": "arXiv:2112.07928",
    "title": "Imagine by Reasoning: A Reasoning-Based Implicit Semantic Data  Augmentation for Long-Tailed Classification",
    "abstract": "Comments: Accepted by AAAI2022",
    "descriptor": "\nComments: Accepted by AAAI2022\n",
    "authors": [
      "Xiaohua Chen",
      "Yucan Zhou",
      "Dayan Wu",
      "Wanqian Zhang",
      "Yu Zhou",
      "Bo Li",
      "Weiping Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.07928"
  },
  {
    "id": "arXiv:2112.08581",
    "title": "A First Mathematical Runtime Analysis of the Non-Dominated Sorting  Genetic Algorithm II (NSGA-II)",
    "abstract": "Comments: Full version of one paper accepted in AAAI 2022",
    "descriptor": "\nComments: Full version of one paper accepted in AAAI 2022\n",
    "authors": [
      "Weijie Zheng",
      "Yufei Liu",
      "Benjamin Doerr"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.08581"
  },
  {
    "id": "arXiv:2112.10934",
    "title": "Understanding Software Architecture Erosion: A Systematic Mapping Study",
    "abstract": "Comments: Accepted for publication in Journal of Software: Evolution and Process, 2022",
    "descriptor": "\nComments: Accepted for publication in Journal of Software: Evolution and Process, 2022\n",
    "authors": [
      "Ruiyin Li",
      "Peng Liang",
      "Mohamed Soliman",
      "Paris Avgeriou"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2112.10934"
  },
  {
    "id": "arXiv:2112.14499",
    "title": "Decidable problems in substitution shifts",
    "abstract": "Decidable problems in substitution shifts",
    "descriptor": "",
    "authors": [
      "Marie-Pierre B\u00e9al",
      "Dominique Perrin",
      "Antonio Restivo"
    ],
    "subjectives": [
      "Dynamical Systems (math.DS)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2112.14499"
  },
  {
    "id": "arXiv:2112.14518",
    "title": "Mutual influence between language and perception in multi-agent  communication games",
    "abstract": "Mutual influence between language and perception in multi-agent  communication games",
    "descriptor": "",
    "authors": [
      "Xenia Ohmer",
      "Michael Marino",
      "Michael Franke",
      "Peter K\u00f6nig"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2112.14518"
  },
  {
    "id": "arXiv:2112.15187",
    "title": "Stability-Preserving Automatic Tuning of PID Control with Reinforcement  Learning",
    "abstract": "Comments: 9 figures, 3 table, 18 pages",
    "descriptor": "\nComments: 9 figures, 3 table, 18 pages\n",
    "authors": [
      "Ayub I. Lakhani",
      "Myisha A. Chowdhury",
      "Qiugang Lu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.15187"
  },
  {
    "id": "arXiv:2201.00007",
    "title": "Confidence-Aware Multi-Teacher Knowledge Distillation",
    "abstract": "Comments: 5 pages, 4 figure, 4 tables, submitted to ICASSP 2022",
    "descriptor": "\nComments: 5 pages, 4 figure, 4 tables, submitted to ICASSP 2022\n",
    "authors": [
      "Hailin Zhang",
      "Defang Chen",
      "Can Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2201.00007"
  },
  {
    "id": "arXiv:2201.00138",
    "title": "Joint Vehicle Tracking and RSU Selection for V2I Communications with  Extended Kalman Filter",
    "abstract": "Comments: 6 Pages, 5 figures, submitted manuscript for possible publication",
    "descriptor": "\nComments: 6 Pages, 5 figures, submitted manuscript for possible publication\n",
    "authors": [
      "Jiho Song",
      "Seong-Hwan Hyun",
      "Jong-Ho Lee",
      "Jeongsik Choi",
      "Seong-Cheol Kim"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2201.00138"
  },
  {
    "id": "arXiv:2201.00910",
    "title": "Energy-based Proportional Fairness in Cooperative Edge Computing",
    "abstract": "Energy-based Proportional Fairness in Cooperative Edge Computing",
    "descriptor": "",
    "authors": [
      "Thai T. Vu",
      "Dinh Thai Hoang",
      "Khoa T. Phan",
      "Diep N. Nguyen",
      "Eryk Dutkiewicz"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2201.00910"
  },
  {
    "id": "arXiv:2201.01872",
    "title": "Gait Analysis for A Tilt-rotor: The Dynamic Invertible Gait",
    "abstract": "Gait Analysis for A Tilt-rotor: The Dynamic Invertible Gait",
    "descriptor": "",
    "authors": [
      "Zhe Shen",
      "Takeshi Tsuchiya"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2201.01872"
  },
  {
    "id": "arXiv:2201.01930",
    "title": "Codes from symmetric polynomials",
    "abstract": "Codes from symmetric polynomials",
    "descriptor": "",
    "authors": [
      "Mrinmoy Datta",
      "Trygve Johnsen"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Algebraic Geometry (math.AG)"
    ],
    "url": "https://arxiv.org/abs/2201.01930"
  },
  {
    "id": "arXiv:2201.03327",
    "title": "TiltedBERT: Resource Adjustable Version of BERT",
    "abstract": "TiltedBERT: Resource Adjustable Version of BERT",
    "descriptor": "",
    "authors": [
      "Sajjad Kachuee",
      "Mohammad Sharifkhani"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2201.03327"
  },
  {
    "id": "arXiv:2201.04271",
    "title": "No Community Can Do Everything: Why People Participate in Similar Online  Communities",
    "abstract": "Comments: Accepted to CSCW 2022",
    "descriptor": "\nComments: Accepted to CSCW 2022\n",
    "authors": [
      "Nathan TeBlunthuis",
      "Charles Kiene",
      "Isabella Brown",
      "Laura Alia Levi",
      "Nicole McGinnis",
      "Benjamin Mako Hill"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2201.04271"
  },
  {
    "id": "arXiv:2201.04469",
    "title": "Best Arm Identification with a Fixed Budget under a Small Gap",
    "abstract": "Best Arm Identification with a Fixed Budget under a Small Gap",
    "descriptor": "",
    "authors": [
      "Masahiro Kato",
      "Kaito Ariu",
      "Masaaki Imaizumi",
      "Masatoshi Uehara",
      "Masahiro Nomura",
      "Chao Qin"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Econometrics (econ.EM)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2201.04469"
  },
  {
    "id": "arXiv:2201.05072",
    "title": "SparseP: Towards Efficient Sparse Matrix Vector Multiplication on Real  Processing-In-Memory Systems",
    "abstract": "Comments: To appear in the Proceedings of the ACM on Measurement and Analysis of Computing Systems (POMACS) 2022 and the ACM SIGMETRICS 2022 conference",
    "descriptor": "\nComments: To appear in the Proceedings of the ACM on Measurement and Analysis of Computing Systems (POMACS) 2022 and the ACM SIGMETRICS 2022 conference\n",
    "authors": [
      "Christina Giannoula",
      "Ivan Fernandez",
      "Juan G\u00f3mez-Luna",
      "Nectarios Koziris",
      "Georgios Goumas",
      "Onur Mutlu"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2201.05072"
  },
  {
    "id": "arXiv:2201.05373",
    "title": "A New Deep Hybrid Boosted and Ensemble Learning-based Brain Tumor  Analysis using MRI",
    "abstract": "Comments: 26 pages, 9 figures, 8 tables",
    "descriptor": "\nComments: 26 pages, 9 figures, 8 tables\n",
    "authors": [
      "Mirza Mumtaz Zahoor",
      "Shahzad Ahmad Qureshi",
      "Saddam Hussain Khan",
      "Asifullah Khan"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.05373"
  },
  {
    "id": "arXiv:2201.05993",
    "title": "Computer Simulation-Based Learning: Student Self-Efficacy During  COVID-19 Outbreak",
    "abstract": "Computer Simulation-Based Learning: Student Self-Efficacy During  COVID-19 Outbreak",
    "descriptor": "",
    "authors": [
      "Thaweesak Trongtirakul",
      "Kamonnit Pusorn",
      "Umpaporn Peerawanichkul"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2201.05993"
  },
  {
    "id": "arXiv:2201.08322",
    "title": "Error-and-erasure Decoding of Product and Staircase Codes with  Simplified Extrinsic Message Passing",
    "abstract": "Comments: Submitted to IEEE",
    "descriptor": "\nComments: Submitted to IEEE\n",
    "authors": [
      "Sisi Miao",
      "Lukas Rapp",
      "Laurent Schmalen"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2201.08322"
  },
  {
    "id": "arXiv:2201.10012",
    "title": "First-Order Game Logic and Modal Mu-Calculus",
    "abstract": "First-Order Game Logic and Modal Mu-Calculus",
    "descriptor": "",
    "authors": [
      "Noah Abou El Wafa",
      "Andr\u00e9 Platzer"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Computer Science and Game Theory (cs.GT)",
      "Logic (math.LO)"
    ],
    "url": "https://arxiv.org/abs/2201.10012"
  },
  {
    "id": "arXiv:2201.11205",
    "title": "Generative Trees: Adversarial and Copycat",
    "abstract": "Generative Trees: Adversarial and Copycat",
    "descriptor": "",
    "authors": [
      "Richard Nock",
      "Mathieu Guillame-Bert"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.11205"
  },
  {
    "id": "arXiv:2201.11617",
    "title": "List Decoding of 2-Interleaved Binary Alternant Codes",
    "abstract": "List Decoding of 2-Interleaved Binary Alternant Codes",
    "descriptor": "",
    "authors": [
      "Chih-Chiang Huang",
      "Hedongliang Liu",
      "Lukas Holzbaur",
      "Sven Puchinger",
      "Antonia Wachter-Zeh"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2201.11617"
  },
  {
    "id": "arXiv:2201.13008",
    "title": "Communication-Efficient Distributed Multiple Testing for Large-Scale  Inference",
    "abstract": "Comments: Submitted to the 2022 IEEE International Symposium on Information Theory (ISIT)",
    "descriptor": "\nComments: Submitted to the 2022 IEEE International Symposium on Information Theory (ISIT)\n",
    "authors": [
      "Mehrdad Pournaderi",
      "Yu Xiang"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2201.13008"
  },
  {
    "id": "arXiv:2201.13396",
    "title": "NAS-Bench-Suite: NAS Evaluation is (Now) Surprisingly Easy",
    "abstract": "Comments: ICLR 2022",
    "descriptor": "\nComments: ICLR 2022\n",
    "authors": [
      "Yash Mehta",
      "Colin White",
      "Arber Zela",
      "Arjun Krishnakumar",
      "Guri Zabergja",
      "Shakiba Moradian",
      "Mahmoud Safari",
      "Kaicheng Yu",
      "Frank Hutter"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2201.13396"
  },
  {
    "id": "arXiv:2202.00453",
    "title": "Changes in co-publication patterns among China, the European Union (28)  and the United States of America, 2016-2021",
    "abstract": "Comments: 11 pages, 4 figures, 4 tables",
    "descriptor": "\nComments: 11 pages, 4 figures, 4 tables\n",
    "authors": [
      "Caroline S. Wagner",
      "Xiaojing Cai"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2202.00453"
  },
  {
    "id": "arXiv:2202.00506",
    "title": "Multi-cell Non-coherent Over-the-Air Computation for Federated Edge  Learning",
    "abstract": "Comments: 6 pages, accepted to International Conference on Communications (ICC) 2022",
    "descriptor": "\nComments: 6 pages, accepted to International Conference on Communications (ICC) 2022\n",
    "authors": [
      "Mohammad Hassan Adeli",
      "Alphan Sahin"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.00506"
  },
  {
    "id": "arXiv:2202.00907",
    "title": "Using Deep Learning to Bootstrap Abstractions for Hierarchical Robot  Planning",
    "abstract": "Using Deep Learning to Bootstrap Abstractions for Hierarchical Robot  Planning",
    "descriptor": "",
    "authors": [
      "Naman Shah",
      "Siddharth Srivastava"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.00907"
  },
  {
    "id": "arXiv:2202.00948",
    "title": "Eikonal Fields for Refractive Novel-View Synthesis",
    "abstract": "Comments: 8 pages, 6 figures",
    "descriptor": "\nComments: 8 pages, 6 figures\n",
    "authors": [
      "Mojtaba Bemana",
      "Karol Myszkowski",
      "Jeppe Revall Frisvad",
      "Hans-Peter Seidel",
      "Tobias Ritschel"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.00948"
  },
  {
    "id": "arXiv:2202.00964",
    "title": "Understanding Knowledge Integration in Language Models with Graph  Convolutions",
    "abstract": "Comments: Code is available: this https URL",
    "descriptor": "\nComments: Code is available: this https URL\n",
    "authors": [
      "Yifan Hou",
      "Guoji Fu",
      "Mrinmaya Sachan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.00964"
  },
  {
    "id": "arXiv:2202.01564",
    "title": "Weakly Supervised Nuclei Segmentation via Instance Learning",
    "abstract": "Comments: Accepted by ISBI 2022 as Oral Presentation",
    "descriptor": "\nComments: Accepted by ISBI 2022 as Oral Presentation\n",
    "authors": [
      "Weizhen Liu",
      "Qian He",
      "Xuming He"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2202.01564"
  },
  {
    "id": "arXiv:2202.01581",
    "title": "Are Bundles Good Deals for FOML?",
    "abstract": "Are Bundles Good Deals for FOML?",
    "descriptor": "",
    "authors": [
      "Mo Liu",
      "Anantha Padmanabha",
      "R Ramanujam",
      "Yanjing Wang"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2202.01581"
  },
  {
    "id": "arXiv:2202.01718",
    "title": "MV-Datalog+-: Effective Rule-based Reasoning with Uncertain Observations",
    "abstract": "Comments: Submitted to ICLP 2022",
    "descriptor": "\nComments: Submitted to ICLP 2022\n",
    "authors": [
      "Matthias Lanzinger",
      "Stefano Sferrazza",
      "Georg Gottlob"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2202.01718"
  },
  {
    "id": "arXiv:2202.02262",
    "title": "Decoupling Local and Global Representations of Time Series",
    "abstract": "Decoupling Local and Global Representations of Time Series",
    "descriptor": "",
    "authors": [
      "Sana Tonekaboni",
      "Chun-Liang Li",
      "Sercan Arik",
      "Anna Goldenberg",
      "Tomas Pfister"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.02262"
  },
  {
    "id": "arXiv:2202.02521",
    "title": "Comparative study of 3D object detection frameworks based on LiDAR data  and sensor fusion techniques",
    "abstract": "Comments: 2021 International Conference on Industrial Automation, Robotics and Control Engineering (IARCE 2021)",
    "descriptor": "\nComments: 2021 International Conference on Industrial Automation, Robotics and Control Engineering (IARCE 2021)\n",
    "authors": [
      "Sreenivasa Hikkal Venugopala"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.02521"
  },
  {
    "id": "arXiv:2202.03100",
    "title": "Sequential Channel Synthesis",
    "abstract": "Comments: 18 pages, no figures. Short version was submitted to the ISIT 2022",
    "descriptor": "\nComments: 18 pages, no figures. Short version was submitted to the ISIT 2022\n",
    "authors": [
      "Lei Yu",
      "Venkat Anantharam"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.03100"
  },
  {
    "id": "arXiv:2202.03104",
    "title": "SimGRACE: A Simple Framework for Graph Contrastive Learning without Data  Augmentation",
    "abstract": "Comments: Accepted by The Web Conference 2022 (WWW 2022)",
    "descriptor": "\nComments: Accepted by The Web Conference 2022 (WWW 2022)\n",
    "authors": [
      "Jun Xia",
      "Lirong Wu",
      "Jintao Chen",
      "Bozhen Hu",
      "Stan Z.Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2202.03104"
  },
  {
    "id": "arXiv:2202.03159",
    "title": "$L^2$-Betti numbers and computability of reals",
    "abstract": "Comments: 35 pages; v2: clarified Theorem 1.5; Lean implementation available at this https URL",
    "descriptor": "\nComments: 35 pages; v2: clarified Theorem 1.5; Lean implementation available at this https URL\n",
    "authors": [
      "Clara Loeh",
      "Matthias Uschold"
    ],
    "subjectives": [
      "Group Theory (math.GR)",
      "Logic in Computer Science (cs.LO)",
      "Geometric Topology (math.GT)",
      "Logic (math.LO)"
    ],
    "url": "https://arxiv.org/abs/2202.03159"
  },
  {
    "id": "arXiv:2202.03279",
    "title": "On the sensitivity of implementations of a least-squares collocation  method for linear higher-index differential-algebraic equations",
    "abstract": "On the sensitivity of implementations of a least-squares collocation  method for linear higher-index differential-algebraic equations",
    "descriptor": "",
    "authors": [
      "Michael Hanke"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.03279"
  },
  {
    "id": "arXiv:2202.03392",
    "title": "Large-scale Personalized Video Game Recommendation via Social-aware  Contextualized Graph Neural Network",
    "abstract": "Large-scale Personalized Video Game Recommendation via Social-aware  Contextualized Graph Neural Network",
    "descriptor": "",
    "authors": [
      "Liangwei Yang",
      "Zhiwei Liu",
      "Yu Wang",
      "Chen Wang",
      "Ziwei Fan",
      "Philip S. Yu"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2202.03392"
  },
  {
    "id": "arXiv:2202.03527",
    "title": "Integrated Multiscale Domain Adaptive YOLO",
    "abstract": "Comments: This paper is a significantly expanded version of our 2021 ICIP paper arXiv:2106.01483 and includes new tools and architectures for improving the original MS-DAYOLO framework",
    "descriptor": "\nComments: This paper is a significantly expanded version of our 2021 ICIP paper arXiv:2106.01483 and includes new tools and architectures for improving the original MS-DAYOLO framework\n",
    "authors": [
      "Mazin Hnewa",
      "Hayder Radha"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.03527"
  },
  {
    "id": "arXiv:2202.03613",
    "title": "Conformal prediction for the design problem",
    "abstract": "Comments: 32 pages, 7 figures",
    "descriptor": "\nComments: 32 pages, 7 figures\n",
    "authors": [
      "Clara Fannjiang",
      "Stephen Bates",
      "Anastasios N. Angelopoulos",
      "Jennifer Listgarten",
      "Michael I. Jordan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2202.03613"
  },
  {
    "id": "arXiv:2202.03771",
    "title": "Energy Management Based on Multi-Agent Deep Reinforcement Learning for A  Multi-Energy Industrial Park",
    "abstract": "Comments: Accepted by Applied Energy",
    "descriptor": "\nComments: Accepted by Applied Energy\n",
    "authors": [
      "Dafeng Zhu",
      "Bo Yang",
      "Yuxiang Liu",
      "Zhaojian Wang",
      "Kai Ma",
      "Xinping Guan"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.03771"
  },
  {
    "id": "arXiv:2202.03997",
    "title": "Wi-Fi Rate Adaptation using a Simple Deep Reinforcement Learning  Approach",
    "abstract": "Wi-Fi Rate Adaptation using a Simple Deep Reinforcement Learning  Approach",
    "descriptor": "",
    "authors": [
      "Ruben Queiros",
      "Eduardo Nuno Almeida",
      "Helder Fontes",
      "Jose Ruela",
      "Rui Campos"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2202.03997"
  },
  {
    "id": "arXiv:2202.04047",
    "title": "An exact quantum hidden subgroup algorithm and applications to solvable  groups",
    "abstract": "Comments: Minor changes and corrections, some new references",
    "descriptor": "\nComments: Minor changes and corrections, some new references\n",
    "authors": [
      "Muhammad Imran",
      "Gabor Ivanyos"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2202.04047"
  },
  {
    "id": "arXiv:2202.04258",
    "title": "A Data-Driven Approach to Robust Hypothesis Testing Using Sinkhorn  Uncertainty Sets",
    "abstract": "Comments: 22 pages, 7 figures",
    "descriptor": "\nComments: 22 pages, 7 figures\n",
    "authors": [
      "Jie Wang",
      "Yao Xie"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.04258"
  },
  {
    "id": "arXiv:2202.04376",
    "title": "Improving short-term bike sharing demand forecast through an irregular  convolutional neural network",
    "abstract": "Comments: 20 pages with 9 figures",
    "descriptor": "\nComments: 20 pages with 9 figures\n",
    "authors": [
      "Xinyu Li",
      "Yang Xu",
      "Xiaohu Zhang",
      "Wenzhong Shi",
      "Yang Yue",
      "Qingquan Li"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.04376"
  },
  {
    "id": "arXiv:2202.04546",
    "title": "Proving Non-Termination and Lower Runtime Bounds with LoAT (System  Description)",
    "abstract": "Proving Non-Termination and Lower Runtime Bounds with LoAT (System  Description)",
    "descriptor": "",
    "authors": [
      "Florian Frohn",
      "J\u00fcrgen Giesl"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2202.04546"
  },
  {
    "id": "arXiv:2202.04634",
    "title": "Offline Reinforcement Learning with Realizability and Single-policy  Concentrability",
    "abstract": "Offline Reinforcement Learning with Realizability and Single-policy  Concentrability",
    "descriptor": "",
    "authors": [
      "Wenhao Zhan",
      "Baihe Huang",
      "Audrey Huang",
      "Nan Jiang",
      "Jason D. Lee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.04634"
  },
  {
    "id": "arXiv:2202.04828",
    "title": "Learning Latent Causal Dynamics",
    "abstract": "Learning Latent Causal Dynamics",
    "descriptor": "",
    "authors": [
      "Weiran Yao",
      "Guangyi Chen",
      "Kun Zhang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.04828"
  },
  {
    "id": "arXiv:2202.04883",
    "title": "Towards the automated large-scale reconstruction of past road networks  from historical maps",
    "abstract": "Comments: 36 pages, 22 figures",
    "descriptor": "\nComments: 36 pages, 22 figures\n",
    "authors": [
      "Johannes H. Uhl",
      "Stefan Leyk",
      "Yao-Yi Chiang",
      "Craig A. Knoblock"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2202.04883"
  },
  {
    "id": "arXiv:2202.04942",
    "title": "Spherical Transformer",
    "abstract": "Comments: 9 pages with 10 figures",
    "descriptor": "\nComments: 9 pages with 10 figures\n",
    "authors": [
      "Sungmin Cho",
      "Raehyuk Jung",
      "Junseok Kwon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.04942"
  },
  {
    "id": "arXiv:2202.05063",
    "title": "PCENet: High Dimensional Surrogate Modeling for Learning Uncertainty",
    "abstract": "PCENet: High Dimensional Surrogate Modeling for Learning Uncertainty",
    "descriptor": "",
    "authors": [
      "Paz Fink Shustin",
      "Shashanka Ubaru",
      "Vasileios Kalantzis",
      "Lior Horesh",
      "Haim Avron"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.05063"
  },
  {
    "id": "arXiv:2202.05128",
    "title": "Load Balancing and Resource Allocation in Fog-Assisted 5G Networks: An  Incentive-based Game Theoretic Approach",
    "abstract": "Comments: Paper contains 5 authors, 17 references, 8 figures, 5 keywords; a research-based paper relating to optimisation of task offloading cost in fog-assisted networks",
    "descriptor": "\nComments: Paper contains 5 authors, 17 references, 8 figures, 5 keywords; a research-based paper relating to optimisation of task offloading cost in fog-assisted networks\n",
    "authors": [
      "Snigdha Kashyap",
      "Saahil Kumar Singh",
      "Abhishek Rouniyar",
      "Rajsi Saxena",
      "Avinash Kumar"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2202.05128"
  },
  {
    "id": "arXiv:2202.05152",
    "title": "Feature-level augmentation to improve robustness of deep neural networks  to affine transformations",
    "abstract": "Feature-level augmentation to improve robustness of deep neural networks  to affine transformations",
    "descriptor": "",
    "authors": [
      "Adrian Sandru",
      "Mariana-Iuliana Georgescu",
      "Radu Tudor Ionescu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.05152"
  },
  {
    "id": "arXiv:2202.05200",
    "title": "Visual Servoing for Pose Control of Soft Continuum Arm in a Structured  Environment",
    "abstract": "Comments: 9 pages, 5 figures, to be published in RA-L + RoboSoft",
    "descriptor": "\nComments: 9 pages, 5 figures, to be published in RA-L + RoboSoft\n",
    "authors": [
      "Shivani Kamtikar",
      "Samhita Marri",
      "Benjamin Walt",
      "Naveen Kumar Uppalapati",
      "Girish Krishnan",
      "Girish Chowdhary"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.05200"
  }
]
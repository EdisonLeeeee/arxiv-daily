[
  {
    "id": "arXiv:2202.04068",
    "title": "Test Automation Maturity Improves Product Quality -- Quantitative Study  of Open Source Projects Using Continuous Integration",
    "abstract": "The popularity of continuous integration (CI) is increasing as a result of\nmarket pressure to release product features or updates frequently. The ability\nof CI to deliver quality at speed depends on reliable test automation. In this\npaper, we present an empirical study to observe the effect of test automation\nmaturity (assessed by standard best practices in the literature) on product\nquality, test automation effort, and release cycle in the CI context of open\nsource projects. We run our test automation maturity survey and got responses\nfrom 37 open source java projects. We also mined software repositories of the\nsame projects. The main results of regression analysis reveal that, higher\nlevels of test automation maturity are positively associated with higher\nproduct quality (p-value=0.000624) and shorter release cycle (p-value=0.01891);\nThere is no statistically significant evidence of increased test automation\neffort due to higher levels of test automation maturity and product quality.\nThus, we conclude that, a potential benefit of improving test automation\nmaturity (using standard best practices) is product quality improvement and\nrelease cycle acceleration in the CI context of open source projects. We\nencourage future research to extend our findings by adding more datasets with\ndifferent programming languages and CI tools, closed source projects, and\nlarge-scale industrial projects. Our recommendation to practitioners (in the\nsimilar CI context) is to utilize standard best practices to improve test\nautomation maturity.",
    "descriptor": "",
    "authors": [
      "Yuqing Wang",
      "Mika M\u00e4ntyl\u00e4",
      "Zihao Liu",
      "Jouni Markkula"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2202.04068"
  },
  {
    "id": "arXiv:2202.04069",
    "title": "Detecting and Localizing Copy-Move and Image-Splicing Forgery",
    "abstract": "In the world of fake news and deepfakes, there have been an alarmingly large\nnumber of cases of images being tampered with and published in newspapers, used\nin court, and posted on social media for defamation purposes. Detecting these\ntampered images is an important task and one we try to tackle. In this paper,\nwe focus on the methods to detect if an image has been tampered with using both\nDeep Learning and Image transformation methods and comparing the performances\nand robustness of each method. We then attempt to identify the tampered area of\nthe image and predict the corresponding mask. Based on the results, suggestions\nand approaches are provided to achieve a more robust framework to detect and\nidentify the forgeries.",
    "descriptor": "",
    "authors": [
      "Aditya Pandey",
      "Anshuman Mitra"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2202.04069"
  },
  {
    "id": "arXiv:2202.04070",
    "title": "Joint user association and power allocation in ultra-dense mmWave  networks: a multi-connectivity approach",
    "abstract": "In ultra-dense millimeter wave (mmWave) networks, mmWave signals suffer from\nsevere path losses and are easily blocked by obstacles. Meanwhile, ultra-dense\ndeployment causes excessive handovers, which reduces the data link reliability.\nTo alleviate the above issues, the novel technology, known as\nmulti-connectivity enabled user association (MCUA) is incorporated in this\nletter. We aim to jointly optimize MCUAs and downlink (DL) power allocations\n(PAs) to maximize the DL rate of each user simultaneously, rather than total.\nThis is a non-convex nonlinear 0-1 mixed integer multi-objective optimization\nproblem and quite complicated. To solve it, we first use the weighted sum\nmethod to scalarize it as a single-objective optimization problem (SOOP), and\nthen relax the binary association variables to real ones. Considering that the\nrelaxed SOOP is still non-convex, we perform a series of transformations upon\nit and make it a differential of convex programming. Finally, we develop an\niterative algorithm based on the convex-concave procedure to solve the SOOP.\nNumerical results are presented to demonstrate the effectiveness of the\nproposed algorithms.",
    "descriptor": "",
    "authors": [
      "Ailing Chen",
      "Shengchang Li",
      "Jichen Xiong",
      "Kezhong Jin",
      "Zhenzhou Tang"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2202.04070"
  },
  {
    "id": "arXiv:2202.04072",
    "title": "Latent gaze information in highly dynamic decision-tasks",
    "abstract": "Digitization is penetrating more and more areas of life. Tasks are\nincreasingly being completed digitally, and are therefore not only fulfilled\nfaster, more efficiently but also more purposefully and successfully. The rapid\ndevelopments in the field of artificial intelligence in recent years have\nplayed a major role in this, as they brought up many helpful approaches to\nbuild on. At the same time, the eyes, their movements, and the meaning of these\nmovements are being progressively researched. The combination of these\ndevelopments has led to exciting approaches. In this dissertation, I present\nsome of these approaches which I worked on during my Ph.D.\nFirst, I provide insight into the development of models that use artificial\nintelligence to connect eye movements with visual expertise. This is\ndemonstrated for two domains or rather groups of people: athletes in\ndecision-making actions and surgeons in arthroscopic procedures. The resulting\nmodels can be considered as digital diagnostic models for automatic expertise\nrecognition. Furthermore, I show approaches that investigate the\ntransferability of eye movement patterns to different expertise domains and\nsubsequently, important aspects of techniques for generalization. Finally, I\naddress the temporal detection of confusion based on eye movement data. The\nresults suggest the use of the resulting model as a clock signal for possible\ndigital assistance options in the training of young professionals. An\ninteresting aspect of my research is that I was able to draw on very valuable\ndata from DFB youth elite athletes as well as on long-standing experts in\narthroscopy. In particular, the work with the DFB data attracted the interest\nof radio and print media, namely DeutschlandFunk Nova and SWR DasDing. All\nresulting articles presented here have been published in internationally\nrenowned journals or at conferences.",
    "descriptor": "\nComments: Doctoral dissertation\n",
    "authors": [
      "Benedikt Hosp"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.04072"
  },
  {
    "id": "arXiv:2202.04075",
    "title": "Joint-bone Fusion Graph Convolutional Network for Semi-supervised  Skeleton Action Recognition",
    "abstract": "In recent years, graph convolutional networks (GCNs) play an increasingly\ncritical role in skeleton-based human action recognition. However, most\nGCN-based methods still have two main limitations: 1) They only consider the\nmotion information of the joints or process the joints and bones separately,\nwhich are unable to fully explore the latent functional correlation between\njoints and bones for action recognition. 2) Most of these works are performed\nin the supervised learning way, which heavily relies on massive labeled\ntraining data. To address these issues, we propose a semi-supervised\nskeleton-based action recognition method which has been rarely exploited\nbefore. We design a novel correlation-driven joint-bone fusion graph\nconvolutional network (CD-JBF-GCN) as an encoder and use a pose prediction head\nas a decoder to achieve semi-supervised learning. Specifically, the CD-JBF-GC\ncan explore the motion transmission between the joint stream and the bone\nstream, so that promoting both streams to learn more discriminative feature\nrepresentations. The pose prediction based auto-encoder in the self-supervised\ntraining stage allows the network to learn motion representation from unlabeled\ndata, which is essential for action recognition. Extensive experiments on two\npopular datasets, i.e. NTU-RGB+D and Kinetics-Skeleton, demonstrate that our\nmodel achieves the state-of-the-art performance for semi-supervised\nskeleton-based action recognition and is also useful for fully-supervised\nmethods.",
    "descriptor": "",
    "authors": [
      "Zhigang Tu",
      "Jiaxu Zhang",
      "Hongyan Li",
      "Yujin Chen",
      "Junsong Yuan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.04075"
  },
  {
    "id": "arXiv:2202.04076",
    "title": "K-ST: A Formal Executable Semantics of PLC Structured Text Language",
    "abstract": "Programmable Logic Controllers (PLCs) are responsible for automating process\ncontrol in many industrial systems (e.g. in manufacturing and public\ninfrastructure), and thus it is critical to ensure that they operate correctly\nand safely. The majority of PLCs are programmed in languages such as Structured\nText (ST). However, a lack of formal semantics makes it difficult to ascertain\nthe correctness of their translators and compilers, which vary from\nvendor-to-vendor. In this work, we develop K-ST, a formal executable semantics\nfor ST in the K framework. Defined with respect to the IEC 61131-3 standard and\nPLC vendor manuals, K-ST is a high-level reference semantics that can be used\nto evaluate the correctness and consistency of different ST implementations. We\nvalidate K-ST by executing 509 ST programs extracted from Github and comparing\nthe results against existing commercial compilers (i.e., CODESYS,\nCX-Programmer, and GX Works2). We then apply K-ST to validate the\nimplementation of the open source OpenPLC platform, comparing the executions of\nseveral test programs to uncover five bugs and nine functional defects in the\ncompiler.",
    "descriptor": "\nComments: Under review of IEEE Transactions on Software Engineering\n",
    "authors": [
      "Kun Wang",
      "Jingyi Wang",
      "Christopher M. Poskitt",
      "Xiangxiang Chen",
      "Jun Sun",
      "Peng Cheng"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2202.04076"
  },
  {
    "id": "arXiv:2202.04092",
    "title": "Machine Explanations and Human Understanding",
    "abstract": "Explanations are hypothesized to improve human understanding of machine\nlearning models and achieve a variety of desirable outcomes, ranging from model\ndebugging to enhancing human decision making. However, empirical studies have\nfound mixed and even negative results. An open question, therefore, is under\nwhat conditions explanations can improve human understanding and in what way.\nUsing adapted causal diagrams, we provide a formal characterization of the\ninterplay between machine explanations and human understanding, and show how\nhuman intuitions play a central role in enabling human understanding.\nSpecifically, we identify three core concepts of interest that cover all\nexisting quantitative measures of understanding in the context of human-AI\ndecision making: task decision boundary, model decision boundary, and model\nerror. Our key result is that without assumptions about task-specific\nintuitions, explanations may potentially improve human understanding of model\ndecision boundary, but they cannot improve human understanding of task decision\nboundary or model error. To achieve complementary human-AI performance, we\narticulate possible ways on how explanations need to work with human\nintuitions. For instance, human intuitions about the relevance of features\n(e.g., education is more important than age in predicting a person's income)\ncan be critical in detecting model error. We validate the importance of human\nintuitions in shaping the outcome of machine explanations with empirical\nhuman-subject studies. Overall, our work provides a general framework along\nwith actionable implications for future algorithmic development and empirical\nexperiments of machine explanations.",
    "descriptor": "\nComments: 26 pages, 13 figures\n",
    "authors": [
      "Chacha Chen",
      "Shi Feng",
      "Amit Sharma",
      "Chenhao Tan"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2202.04092"
  },
  {
    "id": "arXiv:2202.04101",
    "title": "Face2PPG: An unsupervised pipeline for blood volume pulse extraction  from faces",
    "abstract": "Photoplethysmography (PPG) signals have become a key technology in many\nfields such as medicine, well-being, or sports. Our work proposes a set of\npipelines to extract remote PPG signals (rPPG) from the face, robustly,\nreliably, and in a configurable manner. We identify and evaluate the possible\nchoices in the critical steps of unsupervised rPPG methodologies. We evaluate a\nstate-of-the-art processing pipeline in six different datasets, incorporating\nimportant corrections in the methodology that ensure reproducible and fair\ncomparisons. In addition, we extend the pipeline by proposing three novel\nideas; 1) a new method to stabilize the detected face based on a rigid mesh\nnormalization; 2) a new method to dynamically select the different regions in\nthe face that provide the best raw signals, and 3) a new RGB to rPPG\ntransformation method called Orthogonal Matrix Image Transformation (OMIT)\nbased on QR decomposition, that increases robustness against compression\nartifacts. We show that all three changes introduce noticeable improvements in\nretrieving rPPG signals from faces, obtaining state-of-the-art results compared\nwith unsupervised, non-learning-based methodologies, and in some databases,\nvery close to supervised, learning-based methods. We perform a comparative\nstudy to quantify the contribution of each proposed idea. In addition, we\ndepict a series of observations that could help in future implementations.",
    "descriptor": "\nComments: 20 pages, 10 figures\n",
    "authors": [
      "Constantino \u00c1lvarez Casado",
      "Miguel Bordallo L\u00f3pez"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.04101"
  },
  {
    "id": "arXiv:2202.04104",
    "title": "Teaching Networks to Solve Optimization Problems",
    "abstract": "Leveraging machine learning to optimize the optimization process is an\nemerging field which holds the promise to bypass the fundamental computational\nbottleneck caused by traditional iterative solvers in critical applications\nrequiring near-real-time optimization. The majority of existing approaches\nfocus on learning data-driven optimizers that lead to fewer iterations in\nsolving an optimization. In this paper, we take a different approach and\npropose to replace the iterative solvers altogether with a trainable parametric\nset function that outputs the optimal arguments/parameters of an optimization\nproblem in a single feed-forward. We denote our method as, Learning to Optimize\nthe Optimization Process (LOOP). We show the feasibility of learning such\nparametric (set) functions to solve various classic optimization problems,\nincluding linear/nonlinear regression, principal component analysis,\ntransport-based core-set, and quadratic programming in supply management\napplications. In addition, we propose two alternative approaches for learning\nsuch parametric functions, with and without a solver in the-LOOP. Finally, we\ndemonstrate the effectiveness of our proposed approach through various\nnumerical experiments.",
    "descriptor": "",
    "authors": [
      "Xinran Liu",
      "Yuzhe Lu",
      "Ali Abbasi",
      "Meiyi Li",
      "Javad Mohammadi",
      "Soheil Kolouri"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.04104"
  },
  {
    "id": "arXiv:2202.04105",
    "title": "Hierarchical Dependency Constrained Tree Augmented Naive Bayes  Classifiers for Hierarchical Feature Spaces",
    "abstract": "The Tree Augmented Naive Bayes (TAN) classifier is a type of probabilistic\ngraphical model that constructs a single-parent dependency tree to estimate the\ndistribution of the data. In this work, we propose two novel Hierarchical\ndependency-based Tree Augmented Naive Bayes algorithms, i.e. Hie-TAN and\nHie-TAN-Lite. Both methods exploit the pre-defined parent-child\n(generalisation-specialisation) relationships between features as a type of\nconstraint to learn the tree representation of dependencies among features,\nwhilst the latter further eliminates the hierarchical redundancy during the\nclassifier learning stage. The experimental results showed that Hie-TAN\nsuccessfully obtained better predictive performance than several other\nhierarchical dependency constrained classification algorithms, and its\npredictive performance was further improved by eliminating the hierarchical\nredundancy, as suggested by the higher accuracy obtained by Hie-TAN-Lite.",
    "descriptor": "",
    "authors": [
      "Cen Wan",
      "Alex A. Freitas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.04105"
  },
  {
    "id": "arXiv:2202.04108",
    "title": "A Lagrangian Duality Approach to Active Learning",
    "abstract": "We consider the batch active learning problem, where only a subset of the\ntraining data is labeled, and the goal is to query a batch of unlabeled samples\nto be labeled so as to maximally improve model performance. We formulate the\nlearning problem using constrained optimization, where each constraint bounds\nthe performance of the model on labeled samples. Considering a primal-dual\napproach, we optimize the primal variables, corresponding to the model\nparameters, as well as the dual variables, corresponding to the constraints. As\neach dual variable indicates how significantly the perturbation of the\nrespective constraint affects the optimal value of the objective function, we\nuse it as a proxy of the informativeness of the corresponding training sample.\nOur approach, which we refer to as Active Learning via Lagrangian dualitY, or\nALLY, leverages this fact to select a diverse set of unlabeled samples with the\nhighest estimated dual variables as our query set. We show, via numerical\nexperiments, that our proposed approach performs similarly to or better than\nstate-of-the-art active learning methods in a variety of classification and\nregression tasks. We also demonstrate how ALLY can be used in a generative mode\nto create novel, maximally-informative samples. The implementation code for\nALLY can be found at https://github.com/juanelenter/ALLY.",
    "descriptor": "",
    "authors": [
      "Juan Elenter",
      "Navid NaderiAlizadeh",
      "Alejandro Ribeiro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2202.04108"
  },
  {
    "id": "arXiv:2202.04109",
    "title": "Learning Similarity Metrics for Volumetric Simulations with Multiscale  CNNs",
    "abstract": "Simulations that produce three-dimensional data are ubiquitous in science,\nranging from fluid flows to plasma physics. We propose a similarity model based\non entropy, which allows for the creation of physically meaningful ground truth\ndistances for the similarity assessment of scalar and vectorial data, produced\nfrom transport and motion-based simulations. Utilizing two data acquisition\nmethods derived from this model, we create collections of fields from numerical\nPDE solvers and existing simulation data repositories, and highlight the\nimportance of an appropriate data distribution for an effective training\nprocess. Furthermore, a multiscale CNN architecture that computes a volumetric\nsimilarity metric (VolSiM) is proposed. To the best of our knowledge this is\nthe first learning method inherently designed to address the challenges arising\nfor the similarity assessment of high-dimensional simulation data.\nAdditionally, the tradeoff between a large batch size and an accurate\ncorrelation computation for correlation-based loss functions is investigated,\nand the metric's invariance with respect to rotation and scale operations is\nanalyzed. Finally, the robustness and generalization of VolSiM is evaluated on\na large range of test data, as well as a particularly challenging turbulence\ncase study, that is close to potential real-world applications.",
    "descriptor": "\nComments: Main paper: 8 pages, Appendix: 10 pages. Source code available at this https URL and further information at this https URL\n",
    "authors": [
      "Georg Kohl",
      "Li-Wei Chen",
      "Nils Thuerey"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2202.04109"
  },
  {
    "id": "arXiv:2202.04110",
    "title": "PGMax: Factor Graphs for Discrete Probabilistic Graphical Models and  Loopy Belief Propagation in JAX",
    "abstract": "PGMax is an open-source Python package for easy specification of discrete\nProbabilistic Graphical Models (PGMs) as factor graphs, and automatic\nderivation of efficient and scalable loopy belief propagation (LBP)\nimplementation in JAX. It supports general factor graphs, and can effectively\nleverage modern accelerators like GPUs for inference. Compared with existing\nalternatives, PGMax obtains higher-quality inference results with\norders-of-magnitude inference speedups. PGMax additionally interacts seamlessly\nwith the rapidly growing JAX ecosystem, opening up exciting new possibilities.\nOur source code, examples and documentation are available at\nhttps://github.com/vicariousinc/PGMax.",
    "descriptor": "",
    "authors": [
      "Guangyao Zhou",
      "Nishanth Kumar",
      "Miguel L\u00e1zaro-Gredilla",
      "Shrinu Kushagra",
      "Dileep George"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.04110"
  },
  {
    "id": "arXiv:2202.04112",
    "title": "Disentangle Saliency Detection into Cascaded Detail Modeling and Body  Filling",
    "abstract": "Salient object detection has been long studied to identify the most visually\nattractive objects in images/videos. Recently, a growing amount of approaches\nhave been proposed all of which rely on the contour/edge information to improve\ndetection performance. The edge labels are either put into the loss directly or\nused as extra supervision. The edge and body can also be learned separately and\nthen fused afterward. Both methods either lead to high prediction errors near\nthe edge or cannot be trained in an end-to-end manner. Another problem is that\nexisting methods may fail to detect objects of various sizes due to the lack of\nefficient and effective feature fusion mechanisms. In this work, we propose to\ndecompose the saliency detection task into two cascaded sub-tasks, \\emph{i.e.},\ndetail modeling and body filling. Specifically, the detail modeling focuses on\ncapturing the object edges by supervision of explicitly decomposed detail label\nthat consists of the pixels that are nested on the edge and near the edge. Then\nthe body filling learns the body part which will be filled into the detail map\nto generate more accurate saliency map. To effectively fuse the features and\nhandle objects at different scales, we have also proposed two novel multi-scale\ndetail attention and body attention blocks for precise detail and body\nmodeling. Experimental results show that our method achieves state-of-the-art\nperformances on six public datasets.",
    "descriptor": "\nComments: Accepted by TOMM; the first two authors contribute equally to this work\n",
    "authors": [
      "Yue Song",
      "Hao Tang",
      "Nicu Sebe",
      "Wei Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.04112"
  },
  {
    "id": "arXiv:2202.04113",
    "title": "Physical Zero-knowledge Proofs for Flow Free, Hamiltonian Cycles, and  Many-to-many k-disjoint Covering Paths",
    "abstract": "In this paper we describe protocols which use a standard deck of cards to\nprovide a perfectly sound zero-knowledge proof for Hamiltonian cycles and Flow\nFree puzzles. The latter can easily be extended to provide a protocol for a\nzero-knowledge proof of many-to-many k-disjoint path coverings.",
    "descriptor": "\nComments: Submitted for review\n",
    "authors": [
      "Eammon Hart",
      "Joshua A. McGinnis"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2202.04113"
  },
  {
    "id": "arXiv:2202.04115",
    "title": "Financial Vision Based Reinforcement Learning Trading Strategy",
    "abstract": "Recent advances in artificial intelligence (AI) for quantitative trading have\nled to its general superhuman performance in significant trading performance.\nHowever, the potential risk of AI trading is a \"black box\" decision. Some AI\ncomputing mechanisms are complex and challenging to understand. If we use AI\nwithout proper supervision, AI may lead to wrong choices and make huge losses.\nHence, we need to ask about the AI \"black box\", including why did AI decide to\ndo this or not? Why can people trust AI or not? How can people fix their\nmistakes? These problems also highlight the challenges that AI technology can\nexplain in the trading field.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2104.07715\n",
    "authors": [
      "Yun-Cheng Tsai",
      "Fu-Min Szu",
      "Jun-Hao Chen",
      "Samuel Yen-Chi Chen"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.04115"
  },
  {
    "id": "arXiv:2202.04121",
    "title": "IoT Malware Detection Architecture using a Novel Channel Boosted and  Squeezed CNN",
    "abstract": "Interaction between devices, people, and the Internet has given birth to a\nnew digital communication model, the Internet of Things (IoT). The seamless\nnetwork of these smart devices is the core of this IoT model. However, on the\nother hand, integrating smart devices to constitute a network introduces many\nsecurity challenges. These connected devices have created a security blind\nspot, where cybercriminals can easily launch an attack to compromise the\ndevices using malware proliferation techniques. Therefore, malware detection is\nconsidered a lifeline for the survival of IoT devices against cyberattacks.\nThis study proposes a novel IoT Malware Detection Architecture (iMDA) using\nsqueezing and boosting dilated convolutional neural network (CNN). The proposed\narchitecture exploits the concepts of edge and smoothing, multi-path dilated\nconvolutional operations, channel squeezing, and boosting in CNN. Edge and\nsmoothing operations are employed with split-transform-merge (STM) blocks to\nextract local structure and minor contrast variation in the malware images. STM\nblocks performed multi-path dilated convolutional operations, which helped\nrecognize the global structure of malware patterns. Additionally, channel\nsqueezing and merging helped to get the prominent reduced and diverse feature\nmaps, respectively. Channel squeezing and boosting are applied with the help of\nSTM block at the initial, middle and final levels to capture the texture\nvariation along with the depth for the sake of malware pattern hunting. The\nproposed architecture has shown substantial performance compared with the\ncustomized CNN models. The proposed iMDA has achieved Accuracy: 97.93%,\nF1-Score: 0.9394, Precision: 0.9864, MCC: 0. 8796, Recall: 0.8873, AUC-PR:\n0.9689 and AUC-ROC: 0.9938.",
    "descriptor": "",
    "authors": [
      "Muhammad Asam",
      "Saddam Hussain Khan",
      "Tauseef Jamal",
      "Asifullah Khan"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.04121"
  },
  {
    "id": "arXiv:2202.04123",
    "title": "Random Linear Network Coding in NOMA Optical Wireless Networks",
    "abstract": "Optical wireless communication (OWC) has the potential to provide high\ncommunication speeds that support the massive use of the Internet that is\nexpected in the near future. In OWC, optical access points (APs) are deployed\non the celling to serve multiple users. In this context, efficient multiple\naccess schemes are required to share the resources among the users and align\nmulti-user interference. Recently, non-orthogonal multiple access (NOMA) has\nbeen studied to serve multiple users simultaneously using the same resources,\nwhile a different power level is allocated to each user. Despite the acceptable\nperformance of NOMA, users might experience a high packet loss due to high\nnoise, which results from the use of successive interference cancelation (SIC).\nIn this work, random linear network coding (RLNC) is proposed to enhance the\nperformance of NOMA in an optical wireless network where users are divided into\nmulticast groups, and each group contains users that slightly differ in their\nchannel gains. Moreover, a fixed power allocation (FPA) strategy is considered\namong these groups to avoid complexity. The performance of the proposed scheme\nis evaluated in terms of total packet success probability. The results show\nthat the proposed scheme is more suitable for the network considered compared\nto other benchmark schemes such as traditional NOMA and orthogonal transmission\nschemes. Moreover, the total packet success probability is highly affected by\nthe level of power allocated to each group in all the scenarios.",
    "descriptor": "",
    "authors": [
      "Ahmed A. M. Hassan",
      "Ahmad Adnan Qidan",
      "Mansourah K. Aljohani",
      "Taisir E. H. El-Gorashi",
      "Jaafar M. H. Elmirghani"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.04123"
  },
  {
    "id": "arXiv:2202.04124",
    "title": "A Mini-Block Natural Gradient Method for Deep Neural Networks",
    "abstract": "The training of deep neural networks (DNNs) is currently predominantly done\nusing first-order methods. Some of these methods (e.g., Adam, AdaGrad, and\nRMSprop, and their variants) incorporate a small amount of curvature\ninformation by using a diagonal matrix to precondition the stochastic gradient.\nRecently, effective second-order methods, such as KFAC, K-BFGS, Shampoo, and\nTNT, have been developed for training DNNs, by preconditioning the stochastic\ngradient by layer-wise block-diagonal matrices. Here we propose and analyze the\nconvergence of an approximate natural gradient method, mini-block Fisher (MBF),\nthat lies in between these two classes of methods. Specifically, our method\nuses a block-diagonal approximation to the Fisher matrix, where for each layer\nin the DNN, whether it is convolutional or feed-forward and fully connected,\nthe associated diagonal block is also block-diagonal and is composed of a large\nnumber of mini-blocks of modest size. Our novel approach utilizes the\nparallelism of GPUs to efficiently perform computations on the large number of\nmatrices in each layer. Consequently, MBF's per-iteration computational cost is\nonly slightly higher than it is for first-order methods. Finally, the\nperformance of our proposed method is compared to that of several baseline\nmethods, on both Auto-encoder and CNN problems, to validate its effectiveness\nboth in terms of time efficiency and generalization power.",
    "descriptor": "",
    "authors": [
      "Achraf Bahamou",
      "Donald Goldfarb",
      "Yi Ren"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.04124"
  },
  {
    "id": "arXiv:2202.04125",
    "title": "A stabilized formulation for the solution of the incompressible unsteady  Stokes equations in the frequency domain",
    "abstract": "A stabilized finite element method is introduced for the simulation of\ntime-periodic creeping flows, such as those found in the cardiorespiratory\nsystems. The new technique, which is formulated in the frequency rather than\ntime domain, strictly uses real arithmetics and permits the use of similar\nshape functions for pressure and velocity for ease of implementation. It\ninvolves the addition of the Laplacian of pressure to the continuity equation\nwith a complex-valued stabilization parameter that is derived systematically\nfrom the momentum equation. The numerical experiments show the excellent\naccuracy and robustness of the proposed method in simulating flows in complex\nand canonical geometries for a wide range of conditions. The present method\nsignificantly outperforms a traditional solver in terms of both computational\ncost and scalability, which lowers the overall solution turnover time by\nseveral orders of magnitude.",
    "descriptor": "",
    "authors": [
      "Mahdi Esmaily"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.04125"
  },
  {
    "id": "arXiv:2202.04129",
    "title": "Independent Policy Gradient for Large-Scale Markov Potential Games:  Sharper Rates, Function Approximation, and Game-Agnostic Convergence",
    "abstract": "We examine global non-asymptotic convergence properties of policy gradient\nmethods for multi-agent reinforcement learning (RL) problems in Markov\npotential games (MPG). To learn a Nash equilibrium of an MPG in which the size\nof state space and/or the number of players can be very large, we propose new\nindependent policy gradient algorithms that are run by all players in tandem.\nWhen there is no uncertainty in the gradient evaluation, we show that our\nalgorithm finds an $\\epsilon$-Nash equilibrium with $O(1/\\epsilon^2)$ iteration\ncomplexity which does not explicitly depend on the state space size. When the\nexact gradient is not available, we establish $O(1/\\epsilon^5)$ sample\ncomplexity bound in a potentially infinitely large state space for a\nsample-based algorithm that utilizes function approximation. Moreover, we\nidentify a class of independent policy gradient algorithms that enjoys\nconvergence for both zero-sum Markov games and Markov cooperative games with\nthe players that are oblivious to the types of games being played. Finally, we\nprovide computational experiments to corroborate the merits and the\neffectiveness of our theoretical developments.",
    "descriptor": "\nComments: 68 pages, 6 figures\n",
    "authors": [
      "Dongsheng Ding",
      "Chen-Yu Wei",
      "Kaiqing Zhang",
      "Mihailo R. Jovanovi\u0107"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Science and Game Theory (cs.GT)",
      "Multiagent Systems (cs.MA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2202.04129"
  },
  {
    "id": "arXiv:2202.04132",
    "title": "Untrimmed Action Anticipation",
    "abstract": "Egocentric action anticipation consists in predicting a future action the\ncamera wearer will perform from egocentric video. While the task has recently\nattracted the attention of the research community, current approaches assume\nthat the input videos are \"trimmed\", meaning that a short video sequence is\nsampled a fixed time before the beginning of the action. We argue that, despite\nthe recent advances in the field, trimmed action anticipation has a limited\napplicability in real-world scenarios where it is important to deal with\n\"untrimmed\" video inputs and it cannot be assumed that the exact moment in\nwhich the action will begin is known at test time. To overcome such\nlimitations, we propose an untrimmed action anticipation task, which, similarly\nto temporal action detection, assumes that the input video is untrimmed at test\ntime, while still requiring predictions to be made before the actions actually\ntake place. We design an evaluation procedure for methods designed to address\nthis novel task, and compare several baselines on the EPIC-KITCHENS-100\ndataset. Experiments show that the performance of current models designed for\ntrimmed action anticipation is very limited and more research on this task is\nrequired.",
    "descriptor": "",
    "authors": [
      "Ivan Rodin",
      "Antonino Furnari",
      "Dimitrios Mavroeidis",
      "Giovanni Maria Farinella"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.04132"
  },
  {
    "id": "arXiv:2202.04134",
    "title": "A Novel Ontology-guided Attribute Partitioning Ensemble Learning Model  for Early Prediction of Cognitive Deficits using Quantitative Structural MRI  in Very Preterm Infants",
    "abstract": "Structural magnetic resonance imaging studies have shown that brain\nanatomical abnormalities are associated with cognitive deficits in preterm\ninfants. Brain maturation and geometric features can be used with machine\nlearning models for predicting later neurodevelopmental deficits. However,\ntraditional machine learning models would suffer from a large\nfeature-to-instance ratio (i.e., a large number of features but a small number\nof instances/samples). Ensemble learning is a paradigm that strategically\ngenerates and integrates a library of machine learning classifiers and has been\nsuccessfully used on a wide variety of predictive modeling problems to boost\nmodel performance. Attribute (i.e., feature) bagging method is the most\ncommonly used feature partitioning scheme, which randomly and repeatedly draws\nfeature subsets from the entire feature set. Although attribute bagging method\ncan effectively reduce feature dimensionality to handle the large\nfeature-to-instance ratio, it lacks consideration of domain knowledge and\nlatent relationship among features. In this study, we proposed a novel\nOntology-guided Attribute Partitioning (OAP) method to better draw feature\nsubsets by considering domain-specific relationship among features. With the\nbetter partitioned feature subsets, we developed an ensemble learning\nframework, which is referred to as OAP Ensemble Learning (OAP-EL). We applied\nthe OAP-EL to predict cognitive deficits at 2 year of age using quantitative\nbrain maturation and geometric features obtained at term equivalent age in very\npreterm infants. We demonstrated that the proposed OAP-EL approach\nsignificantly outperformed the peer ensemble learning and traditional machine\nlearning approaches.",
    "descriptor": "",
    "authors": [
      "Zhiyuan Li",
      "Hailong Li",
      "Adebayo Braimah",
      "Jonathan R. Dillman",
      "Nehal A.Parikh",
      "Lili He"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.04134"
  },
  {
    "id": "arXiv:2202.04135",
    "title": "ns-3 and 5G-LENA extensions to support MIMO",
    "abstract": "MIMO spatial multiplexing is an essential feature to increase the\ncommunication data rates in current and future cellular systems. Currently, the\nns-3 lte module leverages an abstraction model for 2x2 MIMO with spatial\nmultiplexing of 2 streams; while mmwave and nr modules were lacking the spatial\nmultiplexing option until this work, since the ns-3 models were not supporting\nthe usage of multiple antennas for spatial multiplexing and an abstraction\nmodel such as the one used in the lte module is not suitable for the mmWave\nfrequencies. In this paper, we propose, implement and evaluate 2-stream MIMO\nspatial multiplexing models for ns-3 and the nr module. The proposed extension\nfor the ns-3 supports multiple antennas for MIMO spatial multiplexing and can\nbe used by any ns-3 module that is compatible with the ns-3 antenna array based\nmodels, such as nr and mmwave modules. We leverage this ns-3 extension to model\n2-stream MIMO by exploiting dual-polarized antennas and their orthogonality\nunder line-of-sight conditions, as it happens at high frequency bands, to send\nthe two data streams. The proposed model does not rely on abstraction, as the\nMIMO model in the ns-3 lte module, and can thus model more realistically the\npropagation differences of the two streams, correlation, inter-stream\ninterference, and allows design and evaluation of the rank adaptation\nalgorithms. Additionally, we propose and evaluate an adaptive rank adaptation\nscheme and compare it with a fixed scheme. The developed MIMO spatial\nmultiplexing models for the ns-3 simulator and the nr module are openly\navailable.",
    "descriptor": "",
    "authors": [
      "Biljana Bojovic",
      "Zoraze Ali",
      "Sandra Lagen",
      "Katerina Koutlia"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.04135"
  },
  {
    "id": "arXiv:2202.04136",
    "title": "Generative multitask learning mitigates target-causing confounding",
    "abstract": "We propose a simple and scalable approach to causal representation learning\nfor multitask learning. Our approach requires minimal modification to existing\nML systems, and improves robustness to prior probability shift. The improvement\ncomes from mitigating unobserved confounders that cause the targets, but not\nthe input. We refer to them as target-causing confounders. These confounders\ninduce spurious dependencies between the input and targets. This poses a\nproblem for the conventional approach to multitask learning, due to its\nassumption that the targets are conditionally independent given the input. Our\nproposed approach takes into account the dependency between the targets in\norder to alleviate target-causing confounding. All that is required in addition\nto usual practice is to estimate the joint distribution of the targets to\nswitch from discriminative to generative classification, and to predict all\ntargets jointly. Our results on the Attributes of People and Taskonomy datasets\nreflect the conceptual improvement in robustness to prior probability shift.",
    "descriptor": "",
    "authors": [
      "Taro Makino",
      "Krzysztof Geras",
      "Kyunghyun Cho"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.04136"
  },
  {
    "id": "arXiv:2202.04137",
    "title": "Machine Learning in Heterogeneous Porous Materials",
    "abstract": "The \"Workshop on Machine learning in heterogeneous porous materials\" brought\ntogether international scientific communities of applied mathematics, porous\nmedia, and material sciences with experts in the areas of heterogeneous\nmaterials, machine learning (ML) and applied mathematics to identify how ML can\nadvance materials research. Within the scope of ML and materials research, the\ngoal of the workshop was to discuss the state-of-the-art in each community,\npromote crosstalk and accelerate multi-disciplinary collaborative research, and\nidentify challenges and opportunities. As the end result, four topic areas were\nidentified: ML in predicting materials properties, and discovery and design of\nnovel materials, ML in porous and fractured media and time-dependent phenomena,\nMulti-scale modeling in heterogeneous porous materials via ML, and Discovery of\nmaterials constitutive laws and new governing equations. This workshop was part\nof the AmeriMech Symposium series sponsored by the National Academies of\nSciences, Engineering and Medicine and the U.S. National Committee on\nTheoretical and Applied Mechanics.",
    "descriptor": "\nComments: The workshop link is: this https URL\n",
    "authors": [
      "Martha D'Eli",
      "Hang Deng",
      "Cedric Fraces",
      "Krishna Garikipati",
      "Lori Graham-Brady",
      "Amanda Howard",
      "Geoerge Karniadakid",
      "Vahid Keshavarzzadeh",
      "Robert M. Kirby",
      "Nathan Kutz",
      "Chunhui Li",
      "Xing Liu",
      "Hannah Lu",
      "Pania Newell",
      "Daniel O'Malley",
      "Masa Prodanovic",
      "Gowri Srinivasan",
      "Alexandre Tartakovsky",
      "Daniel M. Tartakovsky",
      "Hamdi Tchelepi",
      "Bozo Vazic",
      "Hari Viswanathan",
      "Hongkyu Yoon",
      "Piotr Zarzycki"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Materials Science (cond-mat.mtrl-sci)"
    ],
    "url": "https://arxiv.org/abs/2202.04137"
  },
  {
    "id": "arXiv:2202.04139",
    "title": "Simplified Graph Convolution with Heterophily",
    "abstract": "Graph convolutional networks (GCNs) (Kipf & Welling, 2017) attempt to extend\nthe success of deep learning in modeling image and text data to graphs.\nHowever, like other deep models, GCNs comprise repeated nonlinear\ntransformations of inputs and are therefore time and memory intensive to train.\nRecent work has shown that a much simpler and faster model, Simple Graph\nConvolution (SGC) (Wu et al., 2019), is competitive with GCNs in common graph\nmachine learning benchmarks. The use of graph data in SGC implicitly assumes\nthe common but not universal graph characteristic of homophily, wherein nodes\nlink to nodes which are similar. Here we show that SGC is indeed ineffective\nfor heterophilous (i.e., non-homophilous) graphs via experiments on synthetic\nand real-world datasets. We propose Adaptive Simple Graph Convolution (ASGC),\nwhich we show can adapt to both homophilous and heterophilous graph structure.\nLike SGC, ASGC is not a deep model, and hence is fast, scalable, and\ninterpretable. We find that our non-deep method often outperforms\nstate-of-the-art deep models at node classification on a benchmark of\nreal-world datasets. The SGC paper questioned whether the complexity of graph\nneural networks is warranted for common graph problems involving homophilous\nnetworks; our results suggest that this question is still open even for more\ncomplicated problems involving heterophilous networks.",
    "descriptor": "",
    "authors": [
      "Sudhanshu Chanpuriya",
      "Cameron Musco"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2202.04139"
  },
  {
    "id": "arXiv:2202.04140",
    "title": "Optimal Evaluation of Symmetry-Adapted $n$-Correlations Via Recursive  Contraction of Sparse Symmetric Tensors",
    "abstract": "We present a comprehensive analysis of an algorithm for evaluating\nhigh-dimensional polynomials that are invariant under permutations and\nrotations. The key bottleneck is the contraction of a high-dimensional\nsymmetric and sparse tensor with a specific sparsity pattern that is directly\nrelated to the symmetries imposed on the polynomial. We propose an explicit\nconstruction of a recursive evaluation strategy and show that it is optimal in\nthe limit of infinite polynomial degree.",
    "descriptor": "",
    "authors": [
      "Illia Kaliuzhnyi",
      "Christoph Ortner"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.04140"
  },
  {
    "id": "arXiv:2202.04141",
    "title": "Utility of Optical See-Through Head Mounted Displays in Augmented  Reality-Assisted Surgery: A systematic review",
    "abstract": "This article presents a systematic review of optical see-through head mounted\ndisplay (OST-HMD) usage in augmented reality (AR) surgery applications from\n2013 to 2020. Articles were categorised by: OST-HMD device, surgical\nspeciality, surgical application context, visualisation content, experimental\ndesign and evaluation, accuracy and human factors of human-computer\ninteraction. 91 articles fulfilled all inclusion criteria. Some clear trends\nemerge. The Microsoft HoloLens increasingly dominates the field, with\northopaedic surgery being the most popular application (28.6\\%). By far the\nmost common surgical context is surgical guidance (n=58) and segmented\npreoperative models dominate visualisation (n = 40). Experiments mainly involve\nphantoms (n = 43) or system setup (n = 21), with patient case studies ranking\nthird (n = 19), reflecting the comparative infancy of the field. Experiments\ncover issues from registration to perception with very different accuracy\nresults. Human factors emerge as significant to OST-HMD utility. Some factors\nare addressed by the systems proposed, such as attention shift away from the\nsurgical site and mental mapping of 2D images to 3D patient anatomy. Other\npersistent human factors remain or are caused by OST-HMD solutions, including\nease of use, comfort and spatial perception issues. The significant upward\ntrend in published articles is clear, but such devices are not yet established\nin the operating room and clinical studies showing benefit are lacking. A\nfocused effort addressing technical registration and perceptual factors in the\nlab coupled with design that incorporates human factors considerations to solve\nclear clinical problems should ensure that the significant current research\nefforts will succeed.",
    "descriptor": "",
    "authors": [
      "Manuel Birlo",
      "P.J. \"Eddie'' Edwards",
      "Matthew Clarkson",
      "Danail Stoyanov"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2202.04141"
  },
  {
    "id": "arXiv:2202.04145",
    "title": "Using a Language Model in a Kiosk Recommender System at Fast-Food  Restaurants",
    "abstract": "Kiosks are a popular self-service option in many fast-food restaurants, they\nsave time for the visitors and save labor for the fast-food chains. In this\npaper, we propose an effective design of a kiosk shopping cart recommender\nsystem that combines a language model as a vectorizer and a neural\nnetwork-based classifier. The model performs better than other models in\noffline tests and exhibits performance comparable to the best models in A/B/C\ntests.",
    "descriptor": "",
    "authors": [
      "Eduard Zubchuk",
      "Dmitry Menshikov",
      "Nikolay Mikhaylovskiy"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2202.04145"
  },
  {
    "id": "arXiv:2202.04147",
    "title": "The Rate-Distortion-Perception Tradeoff: The Role of Common Randomness",
    "abstract": "A rate-distortion-perception (RDP) tradeoff has recently been proposed by\nBlau and Michaeli and also Matsumoto. Focusing on the case of perfect realism,\nwhich coincides with the problem of distribution-preserving lossy compression\nstudied by Li et al., a coding theorem for the RDP tradeoff that allows for a\nspecified amount of common randomness between the encoder and decoder is\nprovided. The existing RDP tradeoff is recovered by allowing for the amount of\ncommon randomness to be infinite. The quadratic Gaussian case is examined in\ndetail.",
    "descriptor": "",
    "authors": [
      "Aaron B. Wagner"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2202.04147"
  },
  {
    "id": "arXiv:2202.04148",
    "title": "Unified Characterization and Precoding for Non-Stationary Channels",
    "abstract": "Modern wireless channels are increasingly dense and mobile making the channel\nhighly non-stationary. The time-varying distribution and the existence of joint\ninterference across multiple degrees of freedom (e.g., users, antennas,\nfrequency and symbols) in such channels render conventional precoding\nsub-optimal in practice, and have led to historically poor characterization of\ntheir statistics. The core of our work is the derivation of a high-order\ngeneralization of Mercer's Theorem to decompose the non-stationary channel into\nconstituent fading sub-channels (2-D eigenfunctions) that are jointly\northogonal across its degrees of freedom. Consequently, transmitting these\neigenfunctions with optimally derived coefficients eventually mitigates any\ninterference across these dimensions and forms the foundation of the proposed\njoint spatio-temporal precoding. The precoded symbols directly reconstruct the\ndata symbols at the receiver upon demodulation, thereby significantly reducing\nits computational burden, by alleviating the need for any complementary\ndecoding. These eigenfunctions are paramount to extracting the second-order\nchannel statistics, and therefore completely characterize the underlying\nchannel. Theory and simulations show that such precoding leads to\n${>}10^4{\\times}$ BER improvement (at 20dB) over existing methods for\nnon-stationary channels.",
    "descriptor": "",
    "authors": [
      "Zhibin Zou",
      "Maqsood Careem",
      "Aveek Dutta",
      "Ngwe Thawdar"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.04148"
  },
  {
    "id": "arXiv:2202.04153",
    "title": "Source Matching and Rewriting",
    "abstract": "A typical compiler flow relies on a uni-directional sequence of\ntranslation/optimization steps that lower the program abstract representation,\nmaking it hard to preserve higher-level program information across each\ntransformation step. On the other hand, modern ISA extensions and hardware\naccelerators can benefit from the compiler's ability to detect and raise\nprogram idioms to acceleration instructions or optimized library calls.\nAlthough recent works based on Multi-Level IR (MLIR) have been proposed for\ncode raising, they rely on specialized languages, compiler recompilation, or\nin-depth dialect knowledge. This paper presents Source Matching and Rewriting\n(SMR), a user-oriented source-code-based approach for MLIR idiom matching and\nrewriting that does not require a compiler expert's intervention. SMR uses a\ntwo-phase automaton-based DAG-matching algorithm inspired by early work on\ntree-pattern matching. First, the idiom Control-Dependency Graph (CDG) is\nmatched against the program's CDG to rule out code fragments that do not have a\ncontrol-flow structure similar to the desired idiom. Second, candidate code\nfragments from the previous phase have their Data-Dependency Graphs (DDGs)\nconstructed and matched against the idiom DDG. Experimental results show that\nSMR can effectively match idioms from Fortran (FIR) and C (CIL) programs while\nraising them as BLAS calls to improve performance.",
    "descriptor": "\nComments: 10 pages, 7 figures\n",
    "authors": [
      "Vinicius Couto",
      "Luciano Zago",
      "Herv\u00e9 Yviquel",
      "Guido Ara\u00fajo"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2202.04153"
  },
  {
    "id": "arXiv:2202.04157",
    "title": "A Policy Gradient Algorithm for the Risk-Sensitive Exponential Cost MDP",
    "abstract": "We study the risk-sensitive exponential cost MDP formulation and develop a\ntrajectory-based gradient algorithm to find the stationary point of the cost\nassociated with a set of parameterized policies. We derive a formula that can\nbe used to compute the policy gradient from (state, action, cost) information\ncollected from sample paths of the MDP for each fixed parameterized policy.\nUnlike the traditional average-cost problem, standard stochastic approximation\ntheory cannot be used to exploit this formula. To address the issue, we\nintroduce a truncated and smooth version of the risk-sensitive cost and show\nthat this new cost criterion can be used to approximate the risk-sensitive cost\nand its gradient uniformly under some mild assumptions. We then develop a\ntrajectory-based gradient algorithm to minimize the smooth truncated estimation\nof the risk-sensitive cost and derive conditions under which a sequence of\ntruncations can be used to solve the original, untruncated cost problem.",
    "descriptor": "",
    "authors": [
      "Mehrdad Moharrami",
      "Yashaswini Murthy",
      "Arghyadip Roy",
      "R. Srikant"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.04157"
  },
  {
    "id": "arXiv:2202.04161",
    "title": "Logical Reasoning for Task Oriented Dialogue Systems",
    "abstract": "In recent years, large pretrained models have been used in dialogue systems\nto improve successful task completion rates. However, lack of reasoning\ncapabilities of dialogue platforms make it difficult to provide relevant and\nfluent responses, unless the designers of a conversational experience spend a\nconsiderable amount of time implementing these capabilities in external rule\nbased modules. In this work, we propose a novel method to fine-tune pretrained\ntransformer models such as Roberta and T5. to reason over a set of facts in a\ngiven dialogue context. Our method includes a synthetic data generation\nmechanism which helps the model learn logical relations, such as comparison\nbetween list of numerical values, inverse relations (and negation), inclusion\nand exclusion for categorical attributes, and application of a combination of\nattributes over both numerical and categorical values, and spoken form for\nnumerical values, without need for additional training dataset. We show that\nthe transformer based model can perform logical reasoning to answer questions\nwhen the dialogue context contains all the required information, otherwise it\nis able to extract appropriate constraints to pass to downstream components\n(e.g. a knowledge base) when partial information is available. We observe that\ntransformer based models such as UnifiedQA-T5 can be fine-tuned to perform\nlogical reasoning (such as numerical and categorical attributes' comparison)\nover attributes that been seen in training time (e.g., accuracy of 90\\%+ for\ncomparison of smaller than $k_{\\max}$=5 values over heldout test dataset).",
    "descriptor": "",
    "authors": [
      "Sajjad Beygi",
      "Maryam Fazel-Zarandi",
      "Alessandra Cervone",
      "Prakash Krishnan",
      "Siddhartha Reddy Jonnalagadda"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.04161"
  },
  {
    "id": "arXiv:2202.04165",
    "title": "Instantaneous and limiting behavior of an n-node blockchain under cyber  attacks from a single hacker",
    "abstract": "We investigate the instantaneous and limiting behavior of an n-node\nblockchain which is under continuous monitoring of the IT department of a\ncompany but faces non-stop cyber attacks from a single hacker. The blockchain\nis functional as far as no data stored on it has been changed, deleted, or\nlocked. Once the IT department detects the attack from the hacker, it will\nimmediately re-set the blockchain, rendering all previous efforts of the hacker\nin vain. The hacker will not stop until the blockchain is dysfunctional. For\narbitrary distributions of the hacking times and detecting times, we derive the\nlimiting functional probability, instantaneous functional probability, and mean\nfunctional time of the blockchain. We also show that all these quantities are\nincreasing functions of the number of nodes, substantiating the intuition that\nthe more nodes a blockchain has, the harder it is for a hacker to succeed in a\ncyber attack.",
    "descriptor": "",
    "authors": [
      "Xiufeng Xu",
      "Liang Hong"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Optimization and Control (math.OC)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2202.04165"
  },
  {
    "id": "arXiv:2202.04169",
    "title": "SwiftAgg: Communication-Efficient and Dropout-Resistant Secure  Aggregation for Federated Learning with Worst-Case Security Guarantees",
    "abstract": "We propose SwiftAgg, a novel secure aggregation protocol for federated\nlearning systems, where a central server aggregates local models of $N$\ndistributed users, each of size $L$, trained on their local data, in a\nprivacy-preserving manner. Compared with state-of-the-art secure aggregation\nprotocols, SwiftAgg significantly reduces the communication overheads without\nany compromise on security. Specifically, in presence of at most $D$ dropout\nusers, SwiftAgg achieves a users-to-server communication load of $(T+1)L$ and a\nusers-to-users communication load of up to $(N-1)(T+D+1)L$, with a worst-case\ninformation-theoretic security guarantee, against any subset of up to $T$\nsemi-honest users who may also collude with the curious server. The key idea of\nSwiftAgg is to partition the users into groups of size $D+T+1$, then in the\nfirst phase, secret sharing and aggregation of the individual models are\nperformed within each group, and then in the second phase, model aggregation is\nperformed on $D+T+1$ sequences of users across the groups. If a user in a\nsequence drops out in the second phase, the rest of the sequence remain silent.\nThis design allows only a subset of users to communicate with each other, and\nonly the users in a single group to directly communicate with the server,\neliminating the requirements of 1) all-to-all communication network across\nusers; and 2) all users communicating with the server, for other secure\naggregation protocols. This helps to substantially slash the communication\ncosts of the system.",
    "descriptor": "",
    "authors": [
      "Tayyebeh Jahani-Nezhad",
      "Mohammad Ali Maddah-Ali",
      "Songze Li",
      "Giuseppe Caire"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.04169"
  },
  {
    "id": "arXiv:2202.04171",
    "title": "Inferring Strategies from Observations in Long Iterated Prisoner's  Dilemma Experiments",
    "abstract": "While many theoretical studies have revealed the strategies that could lead\nto and maintain cooperation in the Iterated Prisoner's Dilemma, less is known\nabout what human participants actually do in this game and how strategies\nchange when being confronted with anonymous partners in each round. Previous\nattempts used short experiments, made different assumptions of possible\nstrategies, and led to very different conclusions. We present here two long\ntreatments that differ in the partner matching strategy used, i.e. fixed or\nshuffled partners. Here we use unsupervised methods to cluster the players\nbased on their actions and then Hidden Markov Model to infer what are those\nstrategies in each cluster. Analysis of the inferred strategies reveals that\nfixed partner interaction leads to a behavioral self-organization. Shuffled\npartners generate subgroups of strategies that remain entangled, apparently\nblocking the self-selection process that leads to fully cooperating\nparticipants in the fixed partner treatment. Analyzing the latter in more\ndetail shows that AllC, AllD, TFT- and WSLS-like behavior can be observed. This\nstudy also reveals that long treatments are needed as experiments less than 25\nrounds capture mostly the learning phase participants go through in these kinds\nof experiments.",
    "descriptor": "",
    "authors": [
      "Eladio Montero-Porras",
      "Jelena Grujic",
      "Elias Fernandez-Domingos",
      "Tom Lenaerts"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2202.04171"
  },
  {
    "id": "arXiv:2202.04173",
    "title": "Exploring the Limits of Domain-Adaptive Training for Detoxifying  Large-Scale Language Models",
    "abstract": "Pre-trained language models (LMs) are shown to easily generate toxic\nlanguage. In this work, we systematically explore domain-adaptive training to\nreduce the toxicity of language models. We conduct this study on three\ndimensions: training corpus, model size, and parameter efficiency. For the\ntraining corpus, we propose to leverage the generative power of LMs and\ngenerate nontoxic datasets for domain-adaptive training, which mitigates the\nexposure bias and is shown to be more data-efficient than using a curated\npre-training corpus. We demonstrate that the self-generation method\nconsistently outperforms the existing baselines across various model sizes on\nboth automatic and human evaluations, even when it uses a 1/3 smaller training\ncorpus. We then comprehensively study detoxifying LMs with parameter sizes\nranging from 126M up to 530B (3x larger than GPT-3), a scale that has never\nbeen studied before. We find that i) large LMs have similar toxicity levels as\nsmaller ones given the same pre-training corpus, and ii) large LMs require more\nendeavor to detoxify. We also explore parameter-efficient training methods for\ndetoxification. We demonstrate that adding and training adapter-only layers in\nLMs not only saves a lot of parameters but also achieves a better trade-off\nbetween toxicity and perplexity than whole model adaptation for the large-scale\nmodels.",
    "descriptor": "",
    "authors": [
      "Boxin Wang",
      "Wei Ping",
      "Chaowei Xiao",
      "Peng Xu",
      "Mostofa Patwary",
      "Mohammad Shoeybi",
      "Bo Li",
      "Anima Anandkumar",
      "Bryan Catanzaro"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.04173"
  },
  {
    "id": "arXiv:2202.04176",
    "title": "Police Text Analysis: Topic Modeling and Spatial Relative Density  Estimation",
    "abstract": "We analyze a large corpus of police incident narrative documents in\nunderstanding the spatial distribution of the topics. The motivation for doing\nthis is that police narratives in each incident report contains very\nfine-grained information that is richer than the category that is manually\nassigned by the police. Our approach is to split the corpus into topics using\ntwo different unsupervised machine learning algorithms - Latent Dirichlet\nAllocation and Non-negative Matrix Factorization. We validate the performance\nof each learned topic model using model coherence. Then, using a k-nearest\nneighbors density ratio estimation (kNN-DRE) approach that we propose, we\nestimate the spatial density ratio per topic and use this for data discovery\nand analysis of each topic, allowing for insights into the described incidents\nat scale. We provide a qualitative assessment of each topic and highlight some\nkey benefits for using our kNN-DRE model for estimating spatial trends.",
    "descriptor": "\nComments: 9 pages, 12 figures\n",
    "authors": [
      "Sarah Huestis-Mitchell",
      "Xiuyuan Cheng",
      "Yao Xie"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2202.04176"
  },
  {
    "id": "arXiv:2202.04178",
    "title": "VAEL: Bridging Variational Autoencoders and Probabilistic Logic  Programming",
    "abstract": "We present VAEL, a neuro-symbolic generative model integrating variational\nautoencoders (VAE) with the reasoning capabilities of probabilistic logic (L)\nprogramming. Besides standard latent subsymbolic variables, our model exploits\na probabilistic logic program to define a further structured representation,\nwhich is used for logical reasoning. The entire process is end-to-end\ndifferentiable. Once trained, VAEL can solve new unseen generation tasks by (i)\nleveraging the previously acquired knowledge encoded in the neural component\nand (ii) exploiting new logical programs on the structured latent space. Our\nexperiments provide support on the benefits of this neuro-symbolic integration\nboth in terms of task generalization and data efficiency. To the best of our\nknowledge, this work is the first to propose a general-purpose end-to-end\nframework integrating probabilistic logic programming into a deep generative\nmodel.",
    "descriptor": "",
    "authors": [
      "Eleonora Misino",
      "Giuseppe Marra",
      "Emanuele Sansone"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.04178"
  },
  {
    "id": "arXiv:2202.04181",
    "title": "TransformNet: Self-supervised representation learning through predicting  geometric transformations",
    "abstract": "Deep neural networks need a big amount of training data, while in the real\nworld there is a scarcity of data available for training purposes. To resolve\nthis issue unsupervised methods are used for training with limited data. In\nthis report, we describe the unsupervised semantic feature learning approach\nfor recognition of the geometric transformation applied to the input data. The\nbasic concept of our approach is that if someone is unaware of the objects in\nthe images, he/she would not be able to quantitatively predict the geometric\ntransformation that was applied to them. This self supervised scheme is based\non pretext task and the downstream task. The pretext classification task to\nquantify the geometric transformations should force the CNN to learn high-level\nsalient features of objects useful for image classification. In our baseline\nmodel, we define image rotations by multiples of 90 degrees. The CNN trained on\nthis pretext task will be used for the classification of images in the CIFAR-10\ndataset as a downstream task. we run the baseline method using various models,\nincluding ResNet, DenseNet, VGG-16, and NIN with a varied number of rotations\nin feature extracting and fine-tuning settings. In extension of this baseline\nmodel we experiment with transformations other than rotation in pretext task.\nWe compare performance of selected models in various settings with different\ntransformations applied to images,various data augmentation techniques as well\nas using different optimizers. This series of different type of experiments\nwill help us demonstrate the recognition accuracy of our self-supervised model\nwhen applied to a downstream task of classification.",
    "descriptor": "",
    "authors": [
      "Sayed Hashim",
      "Muhammad Ali"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.04181"
  },
  {
    "id": "arXiv:2202.04185",
    "title": "OSM-tree: A Sortedness-Aware Index",
    "abstract": "Indexes facilitate efficient querying when the selection predicate is on an\nindexed key. As a result, when loading data, if we anticipate future selective\n(point or range) queries, we typically maintain an index that is gradually\npopulated as new data is ingested. In that respect, indexing can be perceived\nas the process of adding structure to an incoming, otherwise unsorted, data\ncollection. The process of adding structure comes at a cost, as instead of\nsimply appending incoming data, every new entry is inserted into the index. If\nthe data ingestion order matches the indexed attribute order, the ingestion\ncost is entirely redundant and can be avoided (e.g., via bulk loading in a\nB+-tree). However, state-of-the-art index designs do not benefit when data is\ningested in an order that is close to being sorted but not fully sorted. In\nthis paper, we study how indexes can benefit from partial data sortedness or\nnear-sortedness, and we propose an ensemble of techniques that combine bulk\nloading, index appends, variable node fill/split factor, and buffering, to\noptimize the ingestion cost of a tree index in presence of partial data\nsortedness. We further augment the proposed design with necessary metadata\nstructures to ensure competitive read performance. We apply the proposed design\nparadigm on a state-of-the-art B+-tree, and we propose the Ordered Sort-Merge\ntree (OSM-tree). OSM-tree outperforms the state of the art by up to 8.8x in\ningestion performance in the presence of sortedness, while falling back to a\nB+-tree's ingestion performance when data is scrambled. OSM-tree offers\ncompetitive query performance, leading to performance benefits between 28% and\n5x for mixed read/write workloads.",
    "descriptor": "",
    "authors": [
      "Aneesh Raman",
      "Subhadeep Sarkar",
      "Matthaios Olma",
      "Manos Athanassoulis"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2202.04185"
  },
  {
    "id": "arXiv:2202.04187",
    "title": "FMP: Toward Fair Graph Message Passing against Topology Bias",
    "abstract": "Despite recent advances in achieving fair representations and predictions\nthrough regularization, adversarial debiasing, and contrastive learning in\ngraph neural networks (GNNs), the working mechanism (i.e., message passing)\nbehind GNNs inducing unfairness issue remains unknown. In this work, we\ntheoretically and experimentally demonstrate that representative aggregation in\nmessage-passing schemes accumulates bias in node representation due to topology\nbias induced by graph topology. Thus, a \\textsf{F}air \\textsf{M}essage\n\\textsf{P}assing (FMP) scheme is proposed to aggregate useful information from\nneighbors but minimize the effect of topology bias in a unified framework\nconsidering graph smoothness and fairness objectives. The proposed FMP is\neffective, transparent, and compatible with back-propagation training. An\nacceleration approach on gradient calculation is also adopted to improve\nalgorithm efficiency. Experiments on node classification tasks demonstrate that\nthe proposed FMP outperforms the state-of-the-art baselines in effectively and\nefficiently mitigating bias on three real-world datasets.",
    "descriptor": "",
    "authors": [
      "Zhimeng Jiang",
      "Xiaotian Han",
      "Chao Fan",
      "Zirui Liu",
      "Na Zou",
      "Ali Mostafavi",
      "Xia Hu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.04187"
  },
  {
    "id": "arXiv:2202.04191",
    "title": "Robust preconditioning for a mixed formulation of phase-field fracture  problems",
    "abstract": "In this work, we consider fracture propagation in nearly incompressible and\n(fully) incompressible materials using a phase-field formulation. We use a\nmixed form of the elasticity equation to overcome volume locking effects and\ndevelop a robust, nonlinear and linear solver scheme and preconditioner for the\nresulting system. The coupled variational inequality system, which is solved\nmonolithically, consists of three unknowns: displacements, pressure, and\nphase-field. Nonlinearities due to coupling, constitutive laws, and crack\nirreversibility are solved using a combined Newton algorithm for the\nnonlinearities in the partial differential equation and employing a primal-dual\nactive set strategy for the crack irreverrsibility constraint. The linear\nsystem in each Newton step is solved iteratively with a flexible generalized\nminimal residual method (GMRES). The key contribution of this work is the\ndevelopment of a problem-specific preconditioner that leverages the\nsaddle-point structure of the displacement and pressure variable. Four\nnumerical examples in pure solids and pressure-driven fractures are conducted\non uniformly and locally refined meshes to investigate the robustness of the\nsolver concerning the Poisson ratio as well as the discretization and\nregularization parameters.",
    "descriptor": "",
    "authors": [
      "Timo Heister",
      "Katrin Mang",
      "Thomas Wick"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.04191"
  },
  {
    "id": "arXiv:2202.04192",
    "title": "An Executable Formal Model of the VHDL in Isabelle/HOL",
    "abstract": "In the hardware design process, hardware components are usually described in\na hardware description language. Most of the hardware description languages,\nsuch as Verilog and VHDL, do not have mathematical foundation and hence are not\nfit for formal reasoning about the design. To enable formal reasoning in one of\nthe most commonly used description language VHDL, we define a formal model of\nthe VHDL language in Isabelle/HOL. Our model targets the functional part of\nVHDL designs used in industry, specifically the design of the LEON3 processor's\ninteger unit. We cover a wide range of features in the VHDL language that are\nusually not modelled in the literature and define a novel operational semantics\nfor it. Furthermore, our model can be exported to OCaml code for execution,\nturning the formal model into a VHDL simulator. We have tested our simulator\nagainst simple designs used in the literature, as well as the div32 module in\nthe LEON3 design. The Isabelle/HOL code is publicly available:\nhttps://zhehou.github.io/apps/VHDLModel.zip",
    "descriptor": "",
    "authors": [
      "Wilayat Khan",
      "Zhe Hou",
      "David Sanan",
      "Jamel Nebhen",
      "Yang Liu",
      "Alwen Tiu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Formal Languages and Automata Theory (cs.FL)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2202.04192"
  },
  {
    "id": "arXiv:2202.04193",
    "title": "Data-Driven Chance Constrained Control using Kernel Distribution  Embeddings",
    "abstract": "We present a data-driven algorithm for efficiently computing stochastic\ncontrol policies for general joint chance constrained optimal control problems.\nOur approach leverages the theory of kernel distribution embeddings, which\nallows representing expectation operators as inner products in a reproducing\nkernel Hilbert space. This framework enables approximately reformulating the\noriginal problem using a dataset of observed trajectories from the system\nwithout imposing prior assumptions on the parameterization of the system\ndynamics or the structure of the uncertainty. By optimizing over a finite\nsubset of stochastic open-loop control trajectories, we relax the original\nproblem to a linear program over the control parameters that can be efficiently\nsolved using standard convex optimization techniques. We demonstrate our\nproposed approach in simulation on a system with nonlinear non-Markovian\ndynamics navigating in a cluttered environment.",
    "descriptor": "\nComments: Submitted to 4th Annual Learning for Dynamics & Control Conference (L4DC) 2022\n",
    "authors": [
      "Adam J. Thorpe",
      "Thomas Lew",
      "Meeko M. K. Oishi",
      "Marco Pavone"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Robotics (cs.RO)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2202.04193"
  },
  {
    "id": "arXiv:2202.04194",
    "title": "A second-order Magnus-type integrator for evolution equations with delay",
    "abstract": "We rewrite abstract delay equations to nonautonomous abstract Cauchy problems\nallowing us to introduce a Magnus-type integrator for the former. We prove the\nsecond-order convergence of the obtained Magnus-type integrator. We also show\nthat if the differential operators involved admit a common invariant set for\ntheir generated semigroups, then the Magnus-type integrator will respect this\ninvariant set as well, allowing for much weaker assumptions to obtain the\ndesired convergence. As an illustrative example we consider a space-dependent\nepidemic model with latent period and diffusion.",
    "descriptor": "",
    "authors": [
      "Petra Csom\u00f3s",
      "D\u00e1vid Kunszenti-Kov\u00e1cs"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Functional Analysis (math.FA)"
    ],
    "url": "https://arxiv.org/abs/2202.04194"
  },
  {
    "id": "arXiv:2202.04200",
    "title": "MaskGIT: Masked Generative Image Transformer",
    "abstract": "Generative transformers have experienced rapid popularity growth in the\ncomputer vision community in synthesizing high-fidelity and high-resolution\nimages. The best generative transformer models so far, however, still treat an\nimage naively as a sequence of tokens, and decode an image sequentially\nfollowing the raster scan ordering (i.e. line-by-line). We find this strategy\nneither optimal nor efficient. This paper proposes a novel image synthesis\nparadigm using a bidirectional transformer decoder, which we term MaskGIT.\nDuring training, MaskGIT learns to predict randomly masked tokens by attending\nto tokens in all directions. At inference time, the model begins with\ngenerating all tokens of an image simultaneously, and then refines the image\niteratively conditioned on the previous generation. Our experiments demonstrate\nthat MaskGIT significantly outperforms the state-of-the-art transformer model\non the ImageNet dataset, and accelerates autoregressive decoding by up to 64x.\nBesides, we illustrate that MaskGIT can be easily extended to various image\nediting tasks, such as inpainting, extrapolation, and image manipulation.",
    "descriptor": "",
    "authors": [
      "Huiwen Chang",
      "Han Zhang",
      "Lu Jiang",
      "Ce Liu",
      "William T. Freeman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.04200"
  },
  {
    "id": "arXiv:2202.04212",
    "title": "Fault Detection and Diagnosis with Imbalanced and Noisy Data: A Hybrid  Framework for Rotating Machinery",
    "abstract": "Fault diagnosis plays an essential role in reducing the maintenance costs of\nrotating machinery manufacturing systems. In many real applications of fault\ndetection and diagnosis, data tend to be imbalanced, meaning that the number of\nsamples for some fault classes is much less than the normal data samples. At\nthe same time, in an industrial condition, accelerometers encounter high levels\nof disruptive signals and the collected samples turn out to be heavily noisy.\nAs a consequence, many traditional Fault Detection and Diagnosis (FDD)\nframeworks get poor classification performances when dealing with real-world\ncircumstances. Three main solutions have been proposed in the literature to\ncope with this problem: (1) the implementation of generative algorithms to\nincrease the amount of under-represented input samples, (2) the employment of a\nclassifier being powerful to learn from imbalanced and noisy data, (3) the\ndevelopment of an efficient data pre-processing including feature extraction\nand data augmentation. This paper proposes a hybrid framework which uses the\nthree aforementioned components to achieve an effective signal-based FDD system\nfor imbalanced conditions. Specifically, it first extracts the fault features,\nusing Fourier and wavelet transforms to make full use of the signals. Then, it\nemploys Wasserstein Generative Adversarial Networks (WGAN) to generate\nsynthetic samples to populate the rare fault class and enhance the training\nset. Moreover, to achieve a higher performance a novel combination of\nConvolutional Long Short-term Memory (CLSTM) and Weighted Extreme Learning\nMachine (WELM) is proposed. To verify the effectiveness of the developed\nframework, different datasets settings on different imbalance severities and\nnoise degrees were used. The comparative results demonstrate that in different\nscenarios GAN-CLSTM-ELM outperforms the other state-of-the-art FDD frameworks.",
    "descriptor": "\nComments: 23 pages, 11 figures\n",
    "authors": [
      "Masoud Jalayer",
      "Amin Kaboli",
      "Carlotta Orsenigo",
      "Carlo Vercellis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.04212"
  },
  {
    "id": "arXiv:2202.04213",
    "title": "Stein Particle Filter for Nonlinear, Non-Gaussian State Estimation",
    "abstract": "Estimation of a dynamical system's latent state subject to sensor noise and\nmodel inaccuracies remains a critical yet difficult problem in robotics. While\nKalman filters provide the optimal solution in the least squared sense for\nlinear and Gaussian noise problems, the general nonlinear and non-Gaussian\nnoise case is significantly more complicated, typically relying on sampling\nstrategies that are limited to low-dimensional state spaces. In this paper we\ndevise a general inference procedure for filtering of nonlinear, non-Gaussian\ndynamical systems that exploits the differentiability of both the update and\nprediction models to scale to higher dimensional spaces. Our method, Stein\nparticle filter, can be seen as a deterministic flow of particles, embedded in\na reproducing kernel Hilbert space, from an initial state to the desirable\nposterior. The particles evolve jointly to conform to a posterior approximation\nwhile interacting with each other through a repulsive force. We evaluate the\nmethod in simulation and in complex localization tasks while comparing it to\nsequential Monte Carlo solutions.",
    "descriptor": "\nComments: 8 pages, 3 figures, Robotics and Automation Letters\n",
    "authors": [
      "Fahira Afzal Maken",
      "Fabio Ramos",
      "Lionel Ott"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.04213"
  },
  {
    "id": "arXiv:2202.04215",
    "title": "QAC: Quantum-computing Aided Composition",
    "abstract": "In this chapter I will discuss the role of quantum computing in computer\nmusic and how it can be integrated to better serve the creative artists. I will\nstart by considering different approaches in current computer music and quantum\ncomputing tools, as well as reviewing some previous attempts to integrate them.\nThen, I will reflect on the meaning of this integration and present what I\ncoined as QAC (Quantum-computing Aided Composition) as well as an early attempt\nat realizing it. This chapter will also introduce The QAC Toolkit Max package,\nanalyze its performance, and explore some examples of what it can offer to\nrealtime creative practice. Lastly, I will present a real case scenario of QAC\nin the creative work Disklavier Prelude #3.",
    "descriptor": "\nComments: Pre-publication draft, to appear in book 'Quantum Computer Music', E. R. Miranda (Ed.)\n",
    "authors": [
      "Omar Costa Hamido"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Human-Computer Interaction (cs.HC)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2202.04215"
  },
  {
    "id": "arXiv:2202.04224",
    "title": "Intelligent Autonomous Intersection Management",
    "abstract": "Connected Autonomous Vehicles will make autonomous intersection management a\nreality replacing traditional traffic signal control. Autonomous intersection\nmanagement requires time and speed adjustment of vehicles arriving at an\nintersection for collision-free passing through the intersection. Due to its\ncomputational complexity, this problem has been studied only when vehicle\narrival times towards the vicinity of the intersection are known beforehand,\nwhich limits the applicability of these solutions for real-time deployment. To\nsolve the real-time autonomous traffic intersection management problem, we\npropose a reinforcement learning (RL) based multiagent architecture and a novel\nRL algorithm coined multi-discount Q-learning. In multi-discount Q-learning, we\nintroduce a simple yet effective way to solve a Markov Decision Process by\npreserving both short-term and long-term goals, which is crucial for\ncollision-free speed control. Our empirical results show that our RL-based\nmultiagent solution can achieve near-optimal performance efficiently when\nminimizing the travel time through an intersection.",
    "descriptor": "\nComments: 13 pages, 3 figures, 2 tables\n",
    "authors": [
      "Udesh Gunarathna",
      "Shanika Karunasekara",
      "Renata Borovica-Gajic",
      "Egemen Tanin"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.04224"
  },
  {
    "id": "arXiv:2202.04231",
    "title": "Real-Time Event-Based Tracking and Detection for Maritime Environments",
    "abstract": "Event cameras are ideal for object tracking applications due to their ability\nto capture fast-moving objects while mitigating latency and data redundancy.\nExisting event-based clustering and feature tracking approaches for\nsurveillance and object detection work well in the majority of cases, but fall\nshort in a maritime environment. Our application of maritime vessel detection\nand tracking requires a process that can identify features and output a\nconfidence score representing the likelihood that the feature was produced by a\nvessel, which may trigger a subsequent alert or activate a classification\nsystem. However, the maritime environment presents unique challenges such as\nthe tendency of waves to produce the majority of events, demanding the majority\nof computational processing and producing false positive detections. By\nfiltering redundant events and analyzing the movement of each event cluster, we\ncan identify and track vessels while ignoring shorter lived and erratic\nfeatures such as those produced by waves.",
    "descriptor": "\nComments: 6 pages, 7 figures. Accepted by IEEE AIPR 2021 (Oral)\n",
    "authors": [
      "Stephanie Aelmore",
      "Richard C. Ordonez",
      "Shibin Parameswaran",
      "Justin Mauger"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2202.04231"
  },
  {
    "id": "arXiv:2202.04235",
    "title": "Towards Compositional Adversarial Robustness: Generalizing Adversarial  Training to Composite Semantic Perturbations",
    "abstract": "Model robustness against adversarial examples of single perturbation type\nsuch as the $\\ell_{p}$-norm has been widely studied, yet its generalization to\nmore realistic scenarios involving multiple semantic perturbations and their\ncomposition remains largely unexplored. In this paper, we firstly propose a\nnovel method for generating composite adversarial examples. By utilizing\ncomponent-wise projected gradient descent and automatic attack-order\nscheduling, our method can find the optimal attack composition. We then propose\n\\textbf{generalized adversarial training} (\\textbf{GAT}) to extend model\nrobustness from $\\ell_{p}$-norm to composite semantic perturbations, such as\nthe combination of Hue, Saturation, Brightness, Contrast, and Rotation. The\nresults on ImageNet and CIFAR-10 datasets show that GAT can be robust not only\nto any single attack but also to any combination of multiple attacks. GAT also\noutperforms baseline $\\ell_{\\infty}$-norm bounded adversarial training\napproaches by a significant margin.",
    "descriptor": "",
    "authors": [
      "Yun-Yun Tsai",
      "Lei Hsiung",
      "Pin-Yu Chen",
      "Tsung-Yi Ho"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.04235"
  },
  {
    "id": "arXiv:2202.04236",
    "title": "Data-Driven Online Interactive Bidding Strategy for Demand Response",
    "abstract": "Demand response (DR), as one of the important energy resources in the\nfuture's grid, provides the services of peak shaving, enhancing the efficiency\nof renewable energy utilization with a short response period, and low cost.\nVarious categories of DR are established, e.g. automated DR, incentive DR,\nemergency DR, and demand bidding. However, with the practical issue of the\nunawareness of residential and commercial consumers' utility models, the\nresearches about demand bidding aggregator involved in the electricity market\nare just at the beginning stage. For this issue, the bidding price and bidding\nquantity are two required decision variables while considering the\nuncertainties due to the market and participants. In this paper, we determine\nthe bidding and purchasing strategy simultaneously employing the smart meter\ndata and functions. A two-agent deep deterministic policy gradient method is\ndeveloped to optimize the decisions through learning historical bidding\nexperiences. The online learning further utilizes the daily newest bidding\nexperience attained to ensure trend tracing and self-adaptation. Two\nenvironment simulators are adopted for testifying the robustness of the model.\nThe results prove that when facing diverse situations the proposed model can\nearn the optimal profit via off/online learning the bidding rules and robustly\nmaking the proper bid.",
    "descriptor": "\nComments: 31 pages\n",
    "authors": [
      "Kuan-Cheng Lee",
      "Hong-Tzer Yang",
      "Wenjun Tang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.04236"
  },
  {
    "id": "arXiv:2202.04237",
    "title": "Learning Robust Convolutional Neural Networks with Relevant Feature  Focusing via Explanations",
    "abstract": "Existing image recognition techniques based on convolutional neural networks\n(CNNs) basically assume that the training and test datasets are sampled from\ni.i.d distributions. However, this assumption is easily broken in the real\nworld because of the distribution shift that occurs when the co-occurrence\nrelations between objects and backgrounds in input images change. Under this\ntype of distribution shift, CNNs learn to focus on features that are not\ntask-relevant, such as backgrounds from the training data, and degrade their\naccuracy on the test data. To tackle this problem, we propose relevant feature\nfocusing (ReFF). ReFF detects task-relevant features and regularizes CNNs via\nexplanation outputs (e.g., Grad-CAM). Since ReFF is composed of post-hoc\nexplanation modules, it can be easily applied to off-the-shelf CNNs.\nFurthermore, ReFF requires no additional inference cost at test time because it\nis only used for regularization while training. We demonstrate that CNNs\ntrained with ReFF focus on features relevant to the target task and that ReFF\nimproves the test-time accuracy.",
    "descriptor": "",
    "authors": [
      "Kazuki Adachi",
      "Shin'ya Yamaguchi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.04237"
  },
  {
    "id": "arXiv:2202.04239",
    "title": "A multiscale spatiotemporal approach for smallholder irrigation  detection",
    "abstract": "In presenting an irrigation detection methodology that leverages multiscale\nsatellite imagery of vegetation abundance, this paper introduces a process to\nsupplement limited ground-collected labels and ensure classifier applicability\nin an area of interest. Spatiotemporal analysis of MODIS 250m Enhanced\nVegetation Index (EVI) timeseries characterizes native vegetation phenologies\nat regional scale to provide the basis for a continuous phenology map that\nguides supplementary label collection over irrigated and non-irrigated\nagriculture. Subsequently, validated dry season greening and senescence cycles\nobserved in 10m Sentinel-2 imagery are used to train a suite of classifiers for\nautomated detection of potential smallholder irrigation. Strategies to improve\nmodel robustness are demonstrated, including a method of data augmentation that\nrandomly shifts training samples; and an assessment of classifier types that\nproduce the best performance in withheld target regions. The methodology is\napplied to detect smallholder irrigation in two states in the Ethiopian\nhighlands, Tigray and Amhara. Results show that a transformer-based neural\nnetwork architecture allows for the most robust prediction performance in\nwithheld regions, followed closely by a CatBoost random forest model. Over\nwithheld ground-collection survey labels, the transformer-based model achieves\n96.7% accuracy over non-irrigated samples and 95.9% accuracy over irrigated\nsamples. Over a larger set of samples independently collected via the\nintroduced method of label supplementation, non-irrigated and irrigated labels\nare predicted with 98.3% and 95.5% accuracy, respectively. The detection model\nis then deployed over Tigray and Amhara, revealing crop rotation patterns and\nyear-over-year irrigated area change. Predictions suggest that irrigated area\nin these two states has decreased by approximately 40% from 2020 to 2021.",
    "descriptor": "",
    "authors": [
      "Terence Conlon",
      "Christopher Small",
      "Vijay Modi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.04239"
  },
  {
    "id": "arXiv:2202.04241",
    "title": "Distillation with Contrast is All You Need for Self-Supervised Point  Cloud Representation Learning",
    "abstract": "In this paper, we propose a simple and general framework for self-supervised\npoint cloud representation learning. Human beings understand the 3D world by\nextracting two levels of information and establishing the relationship between\nthem. One is the global shape of an object, and the other is the local\nstructures of it. However, few existing studies in point cloud representation\nlearning explored how to learn both global shapes and local-to-global\nrelationships without a specified network architecture. Inspired by how human\nbeings understand the world, we utilize knowledge distillation to learn both\nglobal shape information and the relationship between global shape and local\nstructures. At the same time, we combine contrastive learning with knowledge\ndistillation to make the teacher network be better updated. Our method achieves\nthe state-of-the-art performance on linear classification and multiple other\ndownstream tasks. Especially, we develop a variant of ViT for 3D point cloud\nfeature extraction, which also achieves comparable results with existing\nbackbones when combined with our framework, and visualization of the attention\nmaps show that our model does understand the point cloud by combining the\nglobal shape information and multiple local structural information, which is\nconsistent with the inspiration of our representation learning method. Our code\nwill be released soon.",
    "descriptor": "",
    "authors": [
      "Kexue Fu",
      "Peng Gao",
      "Renrui Zhang",
      "Hongsheng Li",
      "Yu Qiao",
      "Manning Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.04241"
  },
  {
    "id": "arXiv:2202.04243",
    "title": "Motion-Aware Transformer For Occluded Person Re-identification",
    "abstract": "Recently, occluded person re-identification(Re-ID) remains a challenging task\nthat people are frequently obscured by other people or obstacles, especially in\na crowd massing situation. In this paper, we propose a self-supervised deep\nlearning method to improve the location performance for human parts through\noccluded person Re-ID. Unlike previous works, we find that motion information\nderived from the photos of various human postures can help identify major human\nbody components. Firstly, a motion-aware transformer encoder-decoder\narchitecture is designed to obtain keypoints heatmaps and part-segmentation\nmaps. Secondly, an affine transformation module is utilized to acquire motion\ninformation from the keypoint detection branch. Then the motion information\nwill support the segmentation branch to achieve refined human part segmentation\nmaps, and effectively divide the human body into reasonable groups. Finally,\nseveral cases demonstrate the efficiency of the proposed model in\ndistinguishing different representative parts of the human body, which can\navoid the background and occlusion disturbs. Our method consistently achieves\nstate-of-the-art results on several popular datasets, including occluded,\npartial, and holistic.",
    "descriptor": "\nComments: 12 pages, 3 figures\n",
    "authors": [
      "Mi Zhou",
      "Hongye Liu",
      "Zhekun Lv",
      "Wei Hong",
      "Xiai Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.04243"
  },
  {
    "id": "arXiv:2202.04245",
    "title": "Regulatory Instruments for Fair Personalized Pricing",
    "abstract": "Personalized pricing is a business strategy to charge different prices to\nindividual consumers based on their characteristics and behaviors. It has\nbecome common practice in many industries nowadays due to the availability of a\ngrowing amount of high granular consumer data. The discriminatory nature of\npersonalized pricing has triggered heated debates among policymakers and\nacademics on how to design regulation policies to balance market efficiency and\nequity. In this paper, we propose two sound policy instruments, i.e., capping\nthe range of the personalized prices or their ratios. We investigate the\noptimal pricing strategy of a profit-maximizing monopoly under both regulatory\nconstraints and the impact of imposing them on consumer surplus, producer\nsurplus, and social welfare. We theoretically prove that both proposed\nconstraints can help balance consumer surplus and producer surplus at the\nexpense of total surplus for common demand distributions, such as uniform,\nlogistic, and exponential distributions. Experiments on both simulation and\nreal-world datasets demonstrate the correctness of these theoretical results.\nOur findings and insights shed light on regulatory policy design for the\nincreasingly monopolized business in the digital era.",
    "descriptor": "\nComments: WWW 2022\n",
    "authors": [
      "Renzhe Xu",
      "Xingxuan Zhang",
      "Peng Cui",
      "Bo Li",
      "Zheyan Shen",
      "Jiazheng Xu"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)",
      "Econometrics (econ.EM)"
    ],
    "url": "https://arxiv.org/abs/2202.04245"
  },
  {
    "id": "arXiv:2202.04250",
    "title": "GenAD: General Representations of Multivariate Time Seriesfor Anomaly  Detection",
    "abstract": "The reliability of wireless base stations in China Mobile is of vital\nimportance, because the cell phone users are connected to the stations and the\nbehaviors of the stations are directly related to user experience. Although the\nmonitoring of the station behaviors can be realized by anomaly detection on\nmultivariate time series, due to complex correlations and various temporal\npatterns of multivariate series in large-scale stations, building a general\nunsupervised anomaly detection model with a higher F1-score remains a\nchallenging task. In this paper, we propose a General representation of\nmultivariate time series for Anomaly Detection(GenAD). First, we pre-train a\ngeneral model on large-scale wireless base stations with self-supervision,\nwhich can be easily transferred to a specific station anomaly detection with a\nsmall amount of training data. Second, we employ Multi-Correlation Attention\nand Time-Series Attention to represent the correlations and temporal patterns\nof the stations. With the above innovations, GenAD increases F1-score by total\n9% on real-world datasets in China Mobile, while the performance does not\nsignificantly degrade on public datasets with only 10% of the training data.",
    "descriptor": "",
    "authors": [
      "Xiaolei Hua",
      "Lin Zhu",
      "Shenglin Zhang",
      "Zeyan Li",
      "Su Wang",
      "Dong Zhou",
      "Shuo Wang",
      "Chao Deng"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.04250"
  },
  {
    "id": "arXiv:2202.04251",
    "title": "Improving greedy core-set configurations for active learning with  uncertainty-scaled distances",
    "abstract": "We scale perceived distances of the core-set algorithm by a factor of\nuncertainty and search for low-confidence configurations, finding significant\nimprovements in sample efficiency across CIFAR10/100 and SVHN image\nclassification, especially in larger acquisition sizes. We show the necessity\nof our modifications and explain how the improvement is due to a probabilistic\nquadratic speed-up in the convergence of core-set loss, under assumptions about\nthe relationship of model uncertainty and misclassification.",
    "descriptor": "",
    "authors": [
      "Yuchen Li",
      "Frank Rudzicz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.04251"
  },
  {
    "id": "arXiv:2202.04256",
    "title": "GiraffeDet: A Heavy-Neck Paradigm for Object Detection",
    "abstract": "In conventional object detection frameworks, a backbone body inherited from\nimage recognition models extracts deep latent features and then a neck module\nfuses these latent features to capture information at different scales. As the\nresolution in object detection is much larger than in image recognition, the\ncomputational cost of the backbone often dominates the total inference cost.\nThis heavy-backbone design paradigm is mostly due to the historical legacy when\ntransferring image recognition models to object detection rather than an\nend-to-end optimized design for object detection. In this work, we show that\nsuch paradigm indeed leads to sub-optimal object detection models. To this end,\nwe propose a novel heavy-neck paradigm, GiraffeDet, a giraffe-like network for\nefficient object detection. The GiraffeDet uses an extremely lightweight\nbackbone and a very deep and large neck module which encourages dense\ninformation exchange among different spatial scales as well as different levels\nof latent semantics simultaneously. This design paradigm allows detectors to\nprocess the high-level semantic information and low-level spatial information\nat the same priority even in the early stage of the network, making it more\neffective in detection tasks. Numerical evaluations on multiple popular object\ndetection benchmarks show that GiraffeDet consistently outperforms previous\nSOTA models across a wide spectrum of resource constraints.",
    "descriptor": "",
    "authors": [
      "Yiqi Jiang",
      "Zhiyu Tan",
      "Junyan Wang",
      "Xiuyu Sun",
      "Ming Lin",
      "Hao Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.04256"
  },
  {
    "id": "arXiv:2202.04257",
    "title": "On the hyper-singular boundary integral equation methods for dynamic  poroelasticity: three dimensional case",
    "abstract": "In our previous work [SIAM J. Sci. Comput. 43(3) (2021) B784-B810], an\naccurate hyper-singular boundary integral equation method for dynamic\nporoelasticity in two dimensions has been developed. This work is devoted to\nstudying the more complex and difficult three-dimensional problems with Neumann\nboundary condition and both the direct and indirect methods are adopted to\nconstruct combined boundary integral equations. The strongly-singular and\nhyper-singular integral operators are reformulated into compositions of\nweakly-singular integral operators and tangential-derivative operators, which\nallow us to prove the jump relations associated with the poroelastic layer\npotentials and boundary integral operators in a simple manner. Relying on both\nthe investigated spectral properties of the strongly-singular operators, which\nindicate that the corresponding eigenvalues accumulate at three points whose\nvalues are only dependent on two Lam\\'e constants, and the spectral properties\nof the Calder\\'on relations of the poroelasticity, we propose\nlow-GMRES-iteration regularized integral equations. Numerical examples are\npresented to demonstrate the accuracy and efficiency of the proposed\nmethodology by means of a Chebyshev-based rectangular-polar solver.",
    "descriptor": "",
    "authors": [
      "Lu Zhang",
      "Liwei Xu",
      "Tao Yin"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Mathematical Physics (math-ph)"
    ],
    "url": "https://arxiv.org/abs/2202.04257"
  },
  {
    "id": "arXiv:2202.04259",
    "title": "Colouring the sculpture through corresponding area from 2D to 3D with  augmented reality",
    "abstract": "With the development of 3D modelling techniques and AR techniques, the\ntraditional methods of establishing 2D to 3D relation is no longer sufficient\nto meet the demand for complex models and rapid relation building. This\ndissertation presents a prototype development implemented that creating many-\nto-many correspondences by marking image and 3D model regions that can be used\nto colouring 3D model by colouring image for the end user. After comparing the\nthree methods in the conceptual design, I chose the creating render textures\nrelation to further development by changing to Zeus bust model and connecting\nthe AR environment. The results of testing each part of the prototype shows the\nviability of the creating render textures relation method. The advantages of it\nare easy to build many-to-many relations and adaptable for any model with\nproperly UV mapping. But there are still three main limitations and future work\nwill focus on solving them, building a database to store relation information\ndata and printing 3D coloured models in real world.",
    "descriptor": "",
    "authors": [
      "Yaozhong Zhang"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2202.04259"
  },
  {
    "id": "arXiv:2202.04261",
    "title": "The volcspeech system for the icassp 2022 multi-channel multi-party  meeting transcription challenge",
    "abstract": "This paper describes our submission to ICASSP 2022 Multi-channel Multi-party\nMeeting Transcription (M2MeT) Challenge. For Track 1, we propose several\napproaches to empower the clustering-based speaker diarization system to handle\noverlapped speech. Front-end dereverberation and the direction-of-arrival (DOA)\nestimation are used to improve the accuracy of speaker diarization.\nMulti-channel combination and overlap detection are applied to reduce the\nmissed speaker error. A modified DOVER-Lap is also proposed to fuse the results\nof different systems. We achieve the final DER of 5.79% on the Eval set and\n7.23% on the Test set. For Track 2, we develop our system using the Conformer\nmodel in a joint CTC-attention architecture. Serialized output training is\nadopted to multi-speaker overlapped speech recognition. We propose a neural\nfront-end module to model multi-channel audio and train the model end-to-end.\nVarious data augmentation methods are utilized to mitigate over-fitting in the\nmulti-channel multi-speaker E2E system. Transformer language model fusion is\ndeveloped to achieve better performance. The final CER is 19.2% on the Eval set\nand 20.8% on the Test set.",
    "descriptor": "",
    "authors": [
      "Chen Shen",
      "Yi Liu",
      "Wenzhi Fan",
      "Bin Wang",
      "Shixue Wen",
      "Yao Tian",
      "Jun Zhang",
      "Jingsheng Yang",
      "Zejun Ma"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2202.04261"
  },
  {
    "id": "arXiv:2202.04262",
    "title": "Parsimonious Learning-Augmented Caching",
    "abstract": "Learning-augmented algorithms -- in which, traditional algorithms are\naugmented with machine-learned predictions -- have emerged as a framework to go\nbeyond worst-case analysis. The overarching goal is to design algorithms that\nperform near-optimally when the predictions are accurate yet retain certain\nworst-case guarantees irrespective of the accuracy of the predictions. This\nframework has been successfully applied to online problems such as caching\nwhere the predictions can be used to alleviate uncertainties.\nIn this paper we introduce and study the setting in which the\nlearning-augmented algorithm can utilize the predictions parsimoniously. We\nconsider the caching problem -- which has been extensively studied in the\nlearning-augmented setting -- and show that one can achieve quantitatively\nsimilar results but only using a sublinear number of predictions.",
    "descriptor": "",
    "authors": [
      "Sungjin Im",
      "Ravi Kumar",
      "Aditya Petety",
      "Manish Purohit"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.04262"
  },
  {
    "id": "arXiv:2202.04266",
    "title": "MMLN: Leveraging Domain Knowledge for Multimodal Diagnosis",
    "abstract": "Recent studies show that deep learning models achieve good performance on\nmedical imaging tasks such as diagnosis prediction. Among the models,\nmultimodality has been an emerging trend, integrating different forms of data\nsuch as chest X-ray (CXR) images and electronic medical records (EMRs).\nHowever, most existing methods incorporate them in a model-free manner, which\nlacks theoretical support and ignores the intrinsic relations between different\ndata sources. To address this problem, we propose a knowledge-driven and\ndata-driven framework for lung disease diagnosis. By incorporating domain\nknowledge, machine learning models can reduce the dependence on labeled data\nand improve interpretability. We formulate diagnosis rules according to\nauthoritative clinical medicine guidelines and learn the weights of rules from\ntext data. Finally, a multimodal fusion consisting of text and image data is\ndesigned to infer the marginal probability of lung disease. We conduct\nexperiments on a real-world dataset collected from a hospital. The results show\nthat the proposed method outperforms the state-of-the-art multimodal baselines\nin terms of accuracy and interpretability.",
    "descriptor": "",
    "authors": [
      "Haodi Zhang",
      "Chenyu Xu",
      "Peirou Liang",
      "Ke Duan",
      "Hao Ren",
      "Weibin Cheng",
      "Kaishun Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Symbolic Computation (cs.SC)"
    ],
    "url": "https://arxiv.org/abs/2202.04266"
  },
  {
    "id": "arXiv:2202.04267",
    "title": "Efficiently Computable Converses for Finite-Blocklength Communication",
    "abstract": "This paper presents a method for computing a finite-blocklength converse for\nthe rate of fixed-length codes with feedback used on discrete memoryless\nchannels (DMCs). The new converse is expressed in terms of a stochastic control\nproblem whose solution can be efficiently computed using dynamic programming\nand Fourier methods. For channels such as the binary symmetric channel (BSC)\nand binary erasure channel (BEC), the accuracy of the proposed converse is\nsimilar to that of existing special-purpose converse bounds, but the new\nconverse technique can be applied to arbitrary DMCs. We provide example\napplications of the new converse technique to the binary asymmetric channel\n(BAC) and the quantized amplitude-constrained AWGN channel.",
    "descriptor": "\nComments: 6 pages, 7 figures\n",
    "authors": [
      "Felipe Areces",
      "Dan Song",
      "Richard Wesel",
      "Aaron B. Wagner"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.04267"
  },
  {
    "id": "arXiv:2202.04270",
    "title": "Inflated Bendable Eversion Cantilever Mechanism with Inner Skeleton for  Increased Payload Holding",
    "abstract": "Inflatable structures used in soft robotics applications exhibit unique\ncharacteristics. In particular, the tip-extension structure, which grows from\nthe tip, can grow without friction against the environment. However, these\ninflatable structures are inferior to rigid mechanisms in terms of their\nload-bearing capacity. The stiffness of the tip-extension structure can be\nincreased by pressurization, but the structure cannot maintain its curved shape\nand compliance. In this study, we proposed a mechanism that combines a skeleton\nstructure consisting of multi-joint links with functions to increase rigidity\nwhile keeping low pressure and realizing the functions of bending and shape\nfixation. We devised a design method for rigid articulated links and combined\nit with a membrane structure that utilizes the advantages of the tip-extension\nstructure. The experimental results show that the payload of the designed\nstructure increases compared to that of the membrane-only structure. The\nfindings of this research can be applied to long robots that can be extended in\nthe air without drooping and to mechanisms that can wrap around the human body.",
    "descriptor": "\nComments: This article is consist of 8 pages and 15 figures\n",
    "authors": [
      "Tomoya Takahashi",
      "Masahiro Watanabe",
      "Kenjiro Tadakuma",
      "Naoto Saiki",
      "Kazuki Abe Masashi Konyo",
      "Satoshi Tadokoro"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.04270"
  },
  {
    "id": "arXiv:2202.04271",
    "title": "Adversarial Detection without Model Information",
    "abstract": "Most prior state-of-the-art adversarial detection works assume that the\nunderlying vulnerable model is accessible, i,e., the model can be trained or\nits outputs are visible. However, this is not a practical assumption due to\nfactors like model encryption, model information leakage and so on. In this\nwork, we propose a model independent adversarial detection method using a\nsimple energy function to distinguish between adversarial and natural inputs.\nWe train a standalone detector independent of the underlying model, with\nsequential layer-wise training to increase the energy separation corresponding\nto natural and adversarial inputs. With this, we perform energy\ndistribution-based adversarial detection. Our method achieves state-of-the-art\ndetection performance (ROC-AUC > 0.9) across a wide range of gradient, score\nand decision-based adversarial attacks on CIFAR10, CIFAR100 and TinyImagenet\ndatasets. Compared to prior approaches, our method requires ~10-100x less\nnumber of operations and parameters for adversarial detection. Further, we show\nthat our detection method is transferable across different datasets and\nadversarial attacks. For reproducibility, we provide code in the supplementary\nmaterial.",
    "descriptor": "",
    "authors": [
      "Abhishek Moitra",
      "Youngeun Kim",
      "Priyadarshini Panda"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.04271"
  },
  {
    "id": "arXiv:2202.04277",
    "title": "A decision-tree framework to select optimal box-sizes for product  shipments",
    "abstract": "In package-handling facilities, boxes of varying sizes are used to ship\nproducts. Improperly sized boxes with box dimensions much larger than the\nproduct dimensions create wastage and unduly increase the shipping costs. Since\nit is infeasible to make unique, tailor-made boxes for each of the $N$\nproducts, the fundamental question that confronts e-commerce companies is: How\nmany $K << N$ cuboidal boxes need to manufactured and what should be their\ndimensions? In this paper, we propose a solution for the single-count shipment\ncontaining one product per box in two steps: (i) reduce it to a clustering\nproblem in the $3$ dimensional space of length, width and height where each\ncluster corresponds to the group of products that will be shipped in a\nparticular size variant, and (ii) present an efficient forward-backward\ndecision tree based clustering method with low computational complexity on $N$\nand $K$ to obtain these $K$ clusters and corresponding box dimensions. Our\nalgorithm has multiple constituent parts, each specifically designed to achieve\na high-quality clustering solution. As our method generates clusters in an\nincremental fashion without discarding the present solution, adding or deleting\na size variant is as simple as stopping the backward pass early or executing it\nfor one more iteration. We tested the efficacy of our approach by simulating\nactual single-count shipments that were transported during a month by Amazon\nusing the proposed box dimensions. Even by just modifying the existing box\ndimensions and not adding a new size variant, we achieved a reduction of\n$4.4\\%$ in the shipment volume, contributing to the decrease in non-utilized,\nair volume space by $2.2\\%$. The reduction in shipment volume and air volume\nimproved significantly to $10.3\\%$ and $6.1\\%$ when we introduced $4$\nadditional boxes.",
    "descriptor": "",
    "authors": [
      "Karthik S. Gurumoorthy",
      "Abhiraj Hinge"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.04277"
  },
  {
    "id": "arXiv:2202.04278",
    "title": "An algebra of alignment for relational verification",
    "abstract": "Relational verification encompasses information flow security, regression\nverification, translation validation for compilers, and more. Effective\nalignment of the programs and computations to be related facilitates use of\nsimpler relational invariants which in turn enables automation and modular\nreasoning. Alignment has been explored in terms of trace pairs, deductive rules\nof relational Hoare logics (RHL), and several forms of product automata. This\narticle shows how a simple extension of Kleene Algebra with Tests (KAT), called\nBiKAT, subsumes prior formulations, including alignment witnesses for\nforall-exists properties, which brings to light new RHL rules for such\nproperties. Alignments can be discovered algorithmically or devised manually\nbut, in either case, their adequacy with respect to the original programs must\nbe proved; an explicit algebra enables constructive proof by equational\nreasoning. Furthermore our approach inherits algorithmic benefits from existing\nKAT-based techniques and tools, which are applicable to a range of semantic\nmodels.",
    "descriptor": "",
    "authors": [
      "Timos Antonopoulos",
      "Eric Koskinen",
      "Ton Chanh Le",
      "Ramana Nagasamudram",
      "David A. Naumann",
      "Minh Ngo"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2202.04278"
  },
  {
    "id": "arXiv:2202.04287",
    "title": "Amplitude Spectrum Transformation for Open Compound Domain Adaptive  Semantic Segmentation",
    "abstract": "Open compound domain adaptation (OCDA) has emerged as a practical adaptation\nsetting which considers a single labeled source domain against a compound of\nmulti-modal unlabeled target data in order to generalize better on novel unseen\ndomains. We hypothesize that an improved disentanglement of domain-related and\ntask-related factors of dense intermediate layer features can greatly aid OCDA.\nPrior-arts attempt this indirectly by employing adversarial domain\ndiscriminators on the spatial CNN output. However, we find that latent features\nderived from the Fourier-based amplitude spectrum of deep CNN features hold a\nmore tractable mapping with domain discrimination. Motivated by this, we\npropose a novel feature space Amplitude Spectrum Transformation (AST). During\nadaptation, we employ the AST auto-encoder for two purposes. First, carefully\nmined source-target instance pairs undergo a simulation of cross-domain feature\nstylization (AST-Sim) at a particular layer by altering the AST-latent. Second,\nAST operating at a later layer is tasked to normalize (AST-Norm) the domain\ncontent by fixing its latent to a mean prototype. Our simplified adaptation\ntechnique is not only clustering-free but also free from complex adversarial\nalignment. We achieve leading performance against the prior arts on the OCDA\nscene segmentation benchmarks.",
    "descriptor": "\nComments: AAAI 2022. Project page: this http URL\n",
    "authors": [
      "Jogendra Nath Kundu",
      "Akshay Kulkarni",
      "Suvaansh Bhambri",
      "Varun Jampani",
      "R. Venkatesh Babu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.04287"
  },
  {
    "id": "arXiv:2202.04291",
    "title": "Learning to Bootstrap for Combating Label Noise",
    "abstract": "Deep neural networks are powerful tools for representation learning, but can\neasily overfit to noisy labels which are prevalent in many real-world\nscenarios. Generally, noisy supervision could stem from variation among\nlabelers, label corruption by adversaries, etc. To combat such label noises,\none popular line of approach is to apply customized weights to the training\ninstances, so that the corrupted examples contribute less to the model\nlearning. However, such learning mechanisms potentially erase important\ninformation about the data distribution and therefore yield suboptimal results.\nTo leverage useful information from the corrupted instances, an alternative is\nthe bootstrapping loss, which reconstructs new training targets on-the-fly by\nincorporating the network's own predictions (i.e., pseudo-labels).\nIn this paper, we propose a more generic learnable loss objective which\nenables a joint reweighting of instances and labels at once. Specifically, our\nmethod dynamically adjusts the per-sample importance weight between the real\nobserved labels and pseudo-labels, where the weights are efficiently determined\nin a meta process. Compared to the previous instance reweighting methods, our\napproach concurrently conducts implicit relabeling, and thereby yield\nsubstantial improvements with almost no extra cost. Extensive experimental\nresults demonstrated the strengths of our approach over existing methods on\nmultiple natural and medical image benchmark datasets, including CIFAR-10,\nCIFAR-100, ISIC2019 and Clothing 1M. The code is publicly available at\nhttps://github.com/yuyinzhou/L2B.",
    "descriptor": "\nComments: tech report; code is available at this https URL\n",
    "authors": [
      "Yuyin Zhou",
      "Xianhang Li",
      "Fengze Liu",
      "Xuxi Chen",
      "Lequan Yu",
      "Cihang Xie",
      "Matthew P. Lungren",
      "Lei Xing"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.04291"
  },
  {
    "id": "arXiv:2202.04294",
    "title": "Optimal Clustering with Bandit Feedback",
    "abstract": "This paper considers the problem of online clustering with bandit feedback. A\nset of arms (or items) can be partitioned into various groups that are unknown.\nWithin each group, the observations associated to each of the arms follow the\nsame distribution with the same mean vector. At each time step, the agent\nqueries or pulls an arm and obtains an independent observation from the\ndistribution it is associated to. Subsequent pulls depend on previous ones as\nwell as the previously obtained samples. The agent's task is to uncover the\nunderlying partition of the arms with the least number of arm pulls and with a\nprobability of error not exceeding a prescribed constant $\\delta$. The problem\nproposed finds numerous applications from clustering of variants of viruses to\nonline market segmentation. We present an instance-dependent\ninformation-theoretic lower bound on the expected sample complexity for this\ntask, and design a computationally efficient and asymptotically optimal\nalgorithm, namely Bandit Online Clustering (BOC). The algorithm includes a\nnovel stopping rule for adaptive sequential testing that circumvents the need\nto exactly solve any NP-hard weighted clustering problem as its subroutines. We\nshow through extensive simulations on synthetic and real-world datasets that\nBOC's performance matches the lower bound asymptotically, and significantly\noutperforms a non-adaptive baseline algorithm.",
    "descriptor": "\nComments: 54 pages, 4 figures\n",
    "authors": [
      "Junwen Yang",
      "Zixin Zhong",
      "Vincent Y. F. Tan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.04294"
  },
  {
    "id": "arXiv:2202.04295",
    "title": "On Almost Sure Convergence Rates of Stochastic Gradient Methods",
    "abstract": "The vast majority of convergence rates analysis for stochastic gradient\nmethods in the literature focus on convergence in expectation, whereas\ntrajectory-wise almost sure convergence is clearly important to ensure that any\ninstantiation of the stochastic algorithms would converge with probability one.\nHere we provide a unified almost sure convergence rates analysis for stochastic\ngradient descent (SGD), stochastic heavy-ball (SHB), and stochastic Nesterov's\naccelerated gradient (SNAG) methods. We show, for the first time, that the\nalmost sure convergence rates obtained for these stochastic gradient methods on\nstrongly convex functions, are arbitrarily close to their optimal convergence\nrates possible. For non-convex objective functions, we not only show that a\nweighted average of the squared gradient norms converges to zero almost surely,\nbut also the last iterates of the algorithms. We further provide last-iterate\nalmost sure convergence rates analysis for stochastic gradient methods on\nweakly convex smooth functions, in contrast with most existing results in the\nliterature that only provide convergence in expectation for a weighted average\nof the iterates.",
    "descriptor": "\nComments: 20 pages\n",
    "authors": [
      "Jun Liu",
      "Ye Yuan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2202.04295"
  },
  {
    "id": "arXiv:2202.04298",
    "title": "Image Difference Captioning with Pre-training and Contrastive Learning",
    "abstract": "The Image Difference Captioning (IDC) task aims to describe the visual\ndifferences between two similar images with natural language. The major\nchallenges of this task lie in two aspects: 1) fine-grained visual differences\nthat require learning stronger vision and language association and 2) high-cost\nof manual annotations that leads to limited supervised data. To address these\nchallenges, we propose a new modeling framework following the\npre-training-finetuning paradigm. Specifically, we design three self-supervised\ntasks and contrastive learning strategies to align visual differences and text\ndescriptions at a fine-grained level. Moreover, we propose a data expansion\nstrategy to utilize extra cross-task supervision information, such as data for\nfine-grained image classification, to alleviate the limitation of available\nsupervised IDC data. Extensive experiments on two IDC benchmark datasets,\nCLEVR-Change and Birds-to-Words, demonstrate the effectiveness of the proposed\nmodeling framework. The codes and models will be released at\nhttps://github.com/yaolinli/IDC.",
    "descriptor": "\nComments: Accepted to AAAI2022\n",
    "authors": [
      "Linli Yao",
      "Weiying Wang",
      "Qin Jin"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.04298"
  },
  {
    "id": "arXiv:2202.04300",
    "title": "STEC-IoT: A Security Tactic by Virtualizing Edge Computing on IoT",
    "abstract": "To a large extent, the deployment of edge computing (EC) can reduce the\nburden of the explosive growth of the Internet of things. As a powerful hub\nbetween the Internet of things and cloud servers, edge devices make the\ntransmission of cloud to things no longer complicated. However, edge nodes are\nfaced with a series of problems, such as large number, a wide range of\ndistribution, and complex environment, the security of edge computing should\nnot be underestimated. Based on this, we propose a tactic to improve the safety\nof edge computing by virtualizing edge nodes. In detail, first of all, we\npropose a strategy of edge node partition, virtualize the edge nodes dealing\nwith different types of things into various virtual networks, which are\ndeployed between the edge nodes and the cloud server. Second, considering that\ndifferent information transmission has different security requirement, we\npropose a security tactic based on security level measurement. Finally, through\nsimulation experiments, we compare with the existing advanced algorithms which\nare committed to virtual network security, and prove that the model proposed in\nthis paper has definite progressiveness in enhancing the security of edge\ncomputing.",
    "descriptor": "",
    "authors": [
      "Peiying Zhang",
      "Chunxiao Jiang",
      "Xue Pang",
      "Yi Qian"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2202.04300"
  },
  {
    "id": "arXiv:2202.04301",
    "title": "Log-based Anomaly Detection with Deep Learning: How Far Are We?",
    "abstract": "Software-intensive systems produce logs for troubleshooting purposes.\nRecently, many deep learning models have been proposed to automatically detect\nsystem anomalies based on log data. These models typically claim very high\ndetection accuracy. For example, most models report an F-measure greater than\n0.9 on the commonly-used HDFS dataset. To achieve a profound understanding of\nhow far we are from solving the problem of log-based anomaly detection, in this\npaper, we conduct an in-depth analysis of five state-of-the-art deep\nlearning-based models for detecting system anomalies on four public log\ndatasets. Our experiments focus on several aspects of model evaluation,\nincluding training data selection, data grouping, class distribution, data\nnoise, and early detection ability. Our results point out that all these\naspects have significant impact on the evaluation, and that all the studied\nmodels do not always work well. The problem of log-based anomaly detection has\nnot been solved yet. Based on our findings, we also suggest possible future\nwork.",
    "descriptor": "\nComments: Accepted by The 44th International Conference on Software Engineering (ICSE 2022)\n",
    "authors": [
      "Van Hoang Le",
      "Hongyu Zhang"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.04301"
  },
  {
    "id": "arXiv:2202.04302",
    "title": "On the Implicit Bias of Gradient Descent for Temporal Extrapolation",
    "abstract": "Common practice when using recurrent neural networks (RNNs) is to apply a\nmodel to sequences longer than those seen in training. This \"extrapolating\"\nusage deviates from the traditional statistical learning setup where guarantees\nare provided under the assumption that train and test distributions are\nidentical.\nHere we set out to understand when RNNs can extrapolate, focusing on a simple\ncase where the data generating distribution is memoryless. We first show that\neven with infinite training data, there exist RNN models that interpolate\nperfectly (i.e., they fit the training data) yet extrapolate poorly to longer\nsequences. We then show that if gradient descent is used for training, learning\nwill converge to perfect extrapolation under certain assumption on\ninitialization. Our results complement recent studies on the implicit bias of\ngradient descent, showing that it plays a key role in extrapolation when\nlearning temporal prediction models.",
    "descriptor": "\nComments: 8 pages, 8 figures (plus appendix), AISTATS2022\n",
    "authors": [
      "Edo Cohen-Karlik",
      "Avichai Ben David",
      "Nadav Cohen",
      "Amir Globerson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.04302"
  },
  {
    "id": "arXiv:2202.04303",
    "title": "TinyM$^2$Net: A Flexible System Algorithm Co-designed Multimodal  Learning Framework for Tiny Devices",
    "abstract": "With the emergence of Artificial Intelligence (AI), new attention has been\ngiven to implement AI algorithms on resource constrained tiny devices to expand\nthe application domain of IoT. Multimodal Learning has recently become very\npopular with the classification task due to its impressive performance for both\nimage and audio event classification. This paper presents TinyM$^2$Net -- a\nflexible system algorithm co-designed multimodal learning framework for\nresource constrained tiny devices. The framework was designed to be evaluated\non two different case-studies: COVID-19 detection from multimodal audio\nrecordings and battle field object detection from multimodal images and audios.\nIn order to compress the model to implement on tiny devices, substantial\nnetwork architecture optimization and mixed precision quantization were\nperformed (mixed 8-bit and 4-bit). TinyM$^2$Net shows that even a tiny\nmultimodal learning model can improve the classification performance than that\nof any unimodal frameworks. The most compressed TinyM$^2$Net achieves 88.4%\nCOVID-19 detection accuracy (14.5% improvement from unimodal base model) and\n96.8\\% battle field object detection accuracy (3.9% improvement from unimodal\nbase model). Finally, we test our TinyM$^2$Net models on a Raspberry Pi 4 to\nsee how they perform when deployed to a resource constrained tiny device.",
    "descriptor": "",
    "authors": [
      "Hasib-Al Rashid",
      "Pretom Roy Ovi",
      "Aryya Gangopadhyay",
      "Tinoosh Mohsenin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2202.04303"
  },
  {
    "id": "arXiv:2202.04305",
    "title": "Compiler Support for Sparse Tensor Computations in MLIR",
    "abstract": "Sparse tensors arise in problems in science, engineering, machine learning,\nand data analytics. Programs that operate on such tensors can exploit sparsity\nto reduce storage requirements and computational time. Developing and\nmaintaining sparse software by hand, however, is a complex and error-prone\ntask. Therefore, we propose treating sparsity as a property of tensors, not a\ntedious implementation task, and letting a sparse compiler generate sparse code\nautomatically from a sparsity-agnostic definition of the computation. This\npaper discusses integrating this idea into MLIR.",
    "descriptor": "",
    "authors": [
      "Aart J.C. Bik",
      "Penporn Koanantakool",
      "Tatiana Shpeisman",
      "Nicolas Vasilache",
      "Bixia Zheng",
      "Fredrik Kjolstad"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2202.04305"
  },
  {
    "id": "arXiv:2202.04306",
    "title": "Can Open Domain Question Answering Systems Answer Visual Knowledge  Questions?",
    "abstract": "The task of Outside Knowledge Visual Question Answering (OKVQA) requires an\nautomatic system to answer natural language questions about pictures and images\nusing external knowledge. We observe that many visual questions, which contain\ndeictic referential phrases referring to entities in the image, can be\nrewritten as \"non-grounded\" questions and can be answered by existing\ntext-based question answering systems. This allows for the reuse of existing\ntext-based Open Domain Question Answering (QA) Systems for visual question\nanswering. In this work, we propose a potentially data-efficient approach that\nreuses existing systems for (a) image analysis, (b) question rewriting, and (c)\ntext-based question answering to answer such visual questions. Given an image\nand a question pertaining to that image (a visual question), we first extract\nthe entities present in the image using pre-trained object and scene\nclassifiers. Using these detected entities, the visual questions can be\nrewritten so as to be answerable by open domain QA systems. We explore two\nrewriting strategies: (1) an unsupervised method using BERT for masking and\nrewriting, and (2) a weakly supervised approach that combines adaptive\nrewriting and reinforcement learning techniques to use the implicit feedback\nfrom the QA system. We test our strategies on the publicly available OKVQA\ndataset and obtain a competitive performance with state-of-the-art models while\nusing only 10% of the training data.",
    "descriptor": "\nComments: 9 pages (including references), 5 figures\n",
    "authors": [
      "Jiawen Zhang",
      "Abhijit Mishra",
      "Avinesh P.V.S",
      "Siddharth Patwardhan",
      "Sachin Agarwal"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.04306"
  },
  {
    "id": "arXiv:2202.04307",
    "title": "Conditional Motion In-betweening",
    "abstract": "Motion in-betweening (MIB) is a process of generating intermediate skeletal\nmovement between the given start and target poses while preserving the\nnaturalness of the motion, such as periodic footstep motion while walking.\nAlthough state-of-the-art MIB methods are capable of producing plausible\nmotions given sparse key-poses, they often lack the controllability to generate\nmotions satisfying the semantic contexts required in practical applications. We\nfocus on the method that can handle pose or semantic conditioned MIB tasks\nusing a unified model. We also present a motion augmentation method to improve\nthe quality of pose-conditioned motion generation via defining a distribution\nover smooth trajectories. Our proposed method outperforms the existing\nstate-of-the-art MIB method in pose prediction errors while providing\nadditional controllability.",
    "descriptor": "",
    "authors": [
      "Jihoon Kim",
      "Taehyun Byun",
      "Seungyoun Shin",
      "Jungdam Won",
      "Sungjoon Choi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2202.04307"
  },
  {
    "id": "arXiv:2202.04309",
    "title": "Vertical Federated Learning: Challenges, Methodologies and Experiments",
    "abstract": "Recently, federated learning (FL) has emerged as a promising distributed\nmachine learning (ML) technology, owing to the advancing computational and\nsensing capacities of end-user devices, however with the increasing concerns on\nusers' privacy. As a special architecture in FL, vertical FL (VFL) is capable\nof constructing a hyper ML model by embracing sub-models from different\nclients. These sub-models are trained locally by vertically partitioned data\nwith distinct attributes. Therefore, the design of VFL is fundamentally\ndifferent from that of conventional FL, raising new and unique research issues.\nIn this paper, we aim to discuss key challenges in VFL with effective\nsolutions, and conduct experiments on real-life datasets to shed light on these\nissues. Specifically, we first propose a general framework on VFL, and\nhighlight the key differences between VFL and conventional FL. Then, we discuss\nresearch challenges rooted in VFL systems under four aspects, i.e., security\nand privacy risks, expensive computation and communication costs, possible\nstructural damage caused by model splitting, and system heterogeneity.\nAfterwards, we develop solutions to addressing the aforementioned challenges,\nand conduct extensive experiments to showcase the effectiveness of our proposed\nsolutions.",
    "descriptor": "",
    "authors": [
      "Kang Wei",
      "Jun Li",
      "Chuan Ma",
      "Ming Ding",
      "Sha Wei",
      "Fan Wu",
      "Guihai Chen",
      "Thilina Ranbaduge"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2202.04309"
  },
  {
    "id": "arXiv:2202.04311",
    "title": "ARIBA: Towards Accurate and Robust Identification of Backdoor Attacks in  Federated Learning",
    "abstract": "The distributed nature and privacy-preserving characteristics of federated\nlearning make it prone to the threat of poisoning attacks, especially backdoor\nattacks, where the adversary implants backdoors to misguide the model on\ncertain attacker-chosen sub-tasks. In this paper, we present a novel method\nARIBA to accurately and robustly identify backdoor attacks in federated\nlearning. By empirical study, we observe that backdoor attacks are discernible\nby the filters of CNN layers. Based on this finding, we employ unsupervised\nanomaly detection to evaluate the pre-processed filters and calculate an\nanomaly score for each client. We then identify the most suspicious clients\naccording to their anomaly scores. Extensive experiments are conducted, which\nshow that our method ARIBA can effectively and robustly defend against multiple\nstate-of-the-art attacks without degrading model performance.",
    "descriptor": "\nComments: 17 pages, 11 figures\n",
    "authors": [
      "Yuxi Mi",
      "Jihong Guan",
      "Shuigeng Zhou"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.04311"
  },
  {
    "id": "arXiv:2202.04312",
    "title": "Using 5G in Smart Cities: A Systematic Mapping Study",
    "abstract": "5G is the fifth generation wireless network, with a set of characteristics,\ne.g., high bandwidth and data rates. The scenarios of using 5G include enhanced\nMobile Broadband (eMBB), massive Machine Type Communications (mMTC), and\nultra-Reliable and Low-Latency Communications (uRLLC). 5G is expected to\nsupport a wide variety of applications. We conducted a systematic mapping study\nthat covers the literature published between Jan 2012 and Dec 2019 regarding\nusing 5G in smart cities. The scenarios, architecture, technologies,\nchallenges, and lessons learned of using 5G in smart cities are summarized and\nfurther analyzed based on 32 selected studies, and the results are that: (1)\nThe studies are distributed over 27 publication venues. 17 studies report\nresults based on academic studies and 13 studies use demonstration or toy\nexamples. Only 2 studies report using 5G in smart cities based on industrial\nstudies. 16 studies include assumptions of 5G network design or smart city\nscenarios. (2) The most discussed smart city scenario is transportation,\nfollowed by public safety, healthcare, city tourism, entertainment, and\neducation. (3) 28 studies propose and/or discuss the architecture of 5G-enabled\nsmart cities, containing smart city architecture (treating 5G as a component),\n5G network architecture in smart cities, and business architecture of using 5G\nin smart cities. (4) The most mentioned 5G-related technologies are radio\naccess technologies, network slicing, and edge computing. (5) Challenges are\nmainly about complex context, challenging requirements, and network development\nof using 5G in smart cities. (6) Most of the lessons learned identified are\nbenefits regarding 5G itself or the proposed 5G-related methods in smart\ncities. This work provides a reflection of the past eight years of the state of\nthe art on using 5G in smart cities, which can benefit both researchers and\npractitioners.",
    "descriptor": "\nComments: Preprint accepted for publication in Intelligent Systems with Applications, 2022\n",
    "authors": [
      "Chen Yang",
      "Peng Liang",
      "Liming Fu",
      "Guorui Cui",
      "Fei Huang",
      "Feng Teng",
      "Yawar Abbas Bangash"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.04312"
  },
  {
    "id": "arXiv:2202.04313",
    "title": "Privacy Concerns Raised by Pervasive User Data Collection From  Cyberspace and Their Countermeasures",
    "abstract": "The virtual dimension called `Cyberspace' built on internet technologies has\nserved people's daily lives for decades. Now it offers advanced services and\nconnected experiences with the developing pervasive computing technologies that\ndigitise, collect, and analyse users' activity data. This changes how user\ninformation gets collected and impacts user privacy at traditional cyberspace\ngateways, including the devices carried by users for daily use. This work\ninvestigates the impacts and surveys privacy concerns caused by this data\ncollection, namely identity tracking from browsing activities, user input data\ndisclosure, data accessibility in mobile devices, security of delicate data\ntransmission, privacy in participating sensing, and identity privacy in\nopportunistic networks. Each of the surveyed privacy concerns is discussed in a\nwell-defined scope according to the impacts mentioned above. Existing\ncountermeasures are also surveyed and discussed, which identifies corresponding\nresearch gaps. To complete the perspectives, three complex open problems,\nnamely trajectory privacy, privacy in smart metering, and involuntary privacy\nleakage with ambient intelligence, are briefly discussed for future research\ndirections before a succinct conclusion to our survey at the end.",
    "descriptor": "\nComments: 32 pages, 3 figures\n",
    "authors": [
      "Yinhao Jiang",
      "Ba Dung Le",
      "Tanveer Zia",
      "Praveen Gauravaram"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2202.04313"
  },
  {
    "id": "arXiv:2202.04321",
    "title": "Optimal Congestion Control for Time-varying Wireless Links",
    "abstract": "Modern networks exhibit a high degree of variability in link rates. Cellular\nnetwork bandwidth inherently varies with receiver motion and orientation, while\nclass-based packet scheduling in datacenter and service provider networks\ninduces high variability in available capacity for network tenants. Recent work\nhas proposed numerous congestion control protocols to cope with this\nvariability, offering different tradeoffs between link utilization and queuing\ndelay. In this paper, we develop a formal model of congestion control over\ntime-varying links, and we use this model to derive a bound on the performance\nof any congestion control protocol running over a time-varying link with a\ngiven distribution of rate variation. Using the insights from this analysis, we\nderive an optimal control law that offers a smooth tradeoff between link\nutilization and queuing delay. We compare the performance of this control law\nto several existing control algorithms on cellular link traces to show that\nthere is significant room for optimization.",
    "descriptor": "",
    "authors": [
      "Prateesh Goyal",
      "Mohammad Alizadeh",
      "Thomas E. Anderson"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2202.04321"
  },
  {
    "id": "arXiv:2202.04327",
    "title": "Anchor Graph Structure Fusion Hashing for Cross-Modal Similarity Search",
    "abstract": "Cross-modal hashing still has some challenges needed to address: (1) most\nexisting CMH methods take graphs as input to model data distribution. These\nmethods omit to consider the correlation of graph structure among multiple\nmodalities; (2) most existing CMH methods ignores considering the fusion\naffinity among multi-modalities data; (3) most existing CMH methods relax the\ndiscrete constraints to solve the optimization objective, significantly\ndegrading the retrieval performance. To solve the above limitations, we propose\na novel Anchor Graph Structure Fusion Hashing (AGSFH). AGSFH constructs the\nanchor graph structure fusion matrix from different anchor graphs of multiple\nmodalities with the Hadamard product, which can fully exploit the geometric\nproperty of underlying data structure. Based on the anchor graph structure\nfusion matrix, AGSFH attempts to directly learn an intrinsic anchor graph,\nwhere the structure of the intrinsic anchor graph is adaptively tuned so that\nthe number of components of the intrinsic graph is exactly equal to the number\nof clusters. Besides, AGSFH preserves the anchor fusion affinity into the\ncommon binary Hamming space. Furthermore, a discrete optimization framework is\ndesigned to learn the unified binary codes. Extensive experimental results on\nthree public social datasets demonstrate the superiority of AGSFH.",
    "descriptor": "",
    "authors": [
      "Lu Wang",
      "Jie Yang",
      "Masoumeh Zareapoor",
      "Zhonglong Zheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2202.04327"
  },
  {
    "id": "arXiv:2202.04328",
    "title": "CAU_KU team's submission to ADD 2022 Challenge task 1: Low-quality fake  audio detection through frequency feature masking",
    "abstract": "This technical report describes Chung-Ang University and Korea University\n(CAU_KU) team's model participating in the Audio Deep Synthesis Detection (ADD)\n2022 Challenge, track 1: Low-quality fake audio detection. For track 1, we\npropose a frequency feature masking (FFM) augmentation technique to deal with a\nlow-quality audio environment. %detection that spectrogram-based models can be\napplied. We applied FFM and mixup augmentation on five spectrogram-based deep\nneural network architectures that performed well for spoofing detection using\nmel-spectrogram and constant Q transform (CQT) features. Our best submission\nachieved 23.8% of EER ranked 3rd on track 1.",
    "descriptor": "",
    "authors": [
      "Il-Youp Kwak",
      "Sunmook Choi",
      "Jonghoon Yang",
      "Yerin Lee",
      "Seungsang Oh"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2202.04328"
  },
  {
    "id": "arXiv:2202.04330",
    "title": "Reflexive tactics for algebra, revisited",
    "abstract": "Computational reflection allows us to turn verified decision procedures into\nefficient automated reasoning tools in proof assistants. The typical\napplications of such methodology include mathematical structures that have\ndecidable theory fragments, e.g., equational theories of commutative rings and\nlattices. However, such existing tools are known not to cooperate with packed\nclasses, a methodology to define mathematical structures in dependent type\ntheory, that allows for the sharing of vocabulary across the inheritance\nhierarchy. Additionally, such tools do not support homomorphisms whose domain\nand codomain types may differ. This paper demonstrates how to implement\nreflexive tactics that support packed classes and homomorphisms. As\napplications of our methodology, we adapt the ring and field tactics of Coq to\nthe commutative ring and field structures of the Mathematical Components\nlibrary, and apply the resulting tactics to the formal proof of the\nirrationality of $\\zeta(3)$ by Chyzak, Mahboubi, and Sibut-Pinote, to bring\nmore proof automation.",
    "descriptor": "\nComments: Under review\n",
    "authors": [
      "Kazuhiko Sakaguchi"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2202.04330"
  },
  {
    "id": "arXiv:2202.04332",
    "title": "Imitation Learning by State-Only Distribution Matching",
    "abstract": "Imitation Learning from observation describes policy learning in a similar\nway to human learning. An agent's policy is trained by observing an expert\nperforming a task. While many state-only imitation learning approaches are\nbased on adversarial imitation learning, one main drawback is that adversarial\ntraining is often unstable and lacks a reliable convergence estimator. If the\ntrue environment reward is unknown and cannot be used to select the\nbest-performing model, this can result in bad real-world policy performance. We\npropose a non-adversarial learning-from-observations approach, together with an\ninterpretable convergence and performance metric.\nOur training objective minimizes the Kulback-Leibler divergence (KLD) between\nthe policy and expert state transition trajectories which can be optimized in a\nnon-adversarial fashion. Such methods demonstrate improved robustness when\nlearned density models guide the optimization. We further improve the sample\nefficiency by rewriting the KLD minimization as the Soft Actor Critic objective\nbased on a modified reward using additional density models that estimate the\nenvironment's forward and backward dynamics. Finally, we evaluate the\neffectiveness of our approach on well-known continuous control environments and\nshow state-of-the-art performance while having a reliable performance estimator\ncompared to several recent learning-from-observation methods.",
    "descriptor": "",
    "authors": [
      "Damian Boborzi",
      "Christoph-Nikolas Straehle",
      "Jens S. Buchner",
      "Lars Mikelsons"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.04332"
  },
  {
    "id": "arXiv:2202.04333",
    "title": "Who to Watch Next: Two-side Interactive Networks for Live Broadcast  Recommendation",
    "abstract": "With the prevalence of live broadcast business nowadays, a new type of\nrecommendation service, called live broadcast recommendation, is widely used in\nmany mobile e-commerce Apps. Different from classical item recommendation, live\nbroadcast recommendation is to automatically recommend user anchors instead of\nitems considering the interactions among triple-objects (i.e., users, anchors,\nitems) rather than binary interactions between users and items. Existing\nmethods based on binary objects, ranging from early matrix factorization to\nrecently emerged deep learning, obtain objects' embeddings by mapping from\npre-existing features. Directly applying these techniques would lead to limited\nperformance, as they are failing to encode collaborative signals among\ntriple-objects. In this paper, we propose a novel TWo-side Interactive NetworkS\n(TWINS) for live broadcast recommendation. In order to fully use both static\nand dynamic information on user and anchor sides, we combine a product-based\nneural network with a recurrent neural network to learn the embedding of each\nobject. In addition, instead of directly measuring the similarity, TWINS\neffectively injects the collaborative effects into the embedding process in an\nexplicit manner by modeling interactive patterns between the user's browsing\nhistory and the anchor's broadcast history in both item and anchor aspects.\nFurthermore, we design a novel co-retrieval technique to select key items among\nmassive historic records efficiently. Offline experiments on real large-scale\ndata show the superior performance of the proposed TWINS, compared to\nrepresentative methods; and further results of online experiments on Diantao\nApp show that TWINS gains average performance improvement of around 8% on ACTR\nmetric, 3% on UCTR metric, 3.5% on UCVR metric.",
    "descriptor": "\nComments: WWW 2022\n",
    "authors": [
      "Jiarui Jin",
      "Xianyu Chen",
      "Yuanbo Chen",
      "Weinan Zhang",
      "Renting Rui",
      "Zaifan Jiang",
      "Zhewen Su",
      "Yong Yu"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2202.04333"
  },
  {
    "id": "arXiv:2202.04337",
    "title": "Scenario-Assisted Deep Reinforcement Learning",
    "abstract": "Deep reinforcement learning has proven remarkably useful in training agents\nfrom unstructured data. However, the opacity of the produced agents makes it\ndifficult to ensure that they adhere to various requirements posed by human\nengineers. In this work-in-progress report, we propose a technique for\nenhancing the reinforcement learning training process (specifically, its reward\ncalculation), in a way that allows human engineers to directly contribute their\nexpert knowledge, making the agent under training more likely to comply with\nvarious relevant constraints. Moreover, our proposed approach allows\nformulating these constraints using advanced model engineering techniques, such\nas scenario-based modeling. This mix of black-box learning-based tools with\nclassical modeling approaches could produce systems that are effective and\nefficient, but are also more transparent and maintainable. We evaluated our\ntechnique using a case-study from the domain of internet congestion control,\nobtaining promising results.",
    "descriptor": "",
    "authors": [
      "Raz Yerushalmi",
      "Guy Amir",
      "Achiya Elyasaf",
      "David Harel",
      "Guy Katz",
      "Assaf Marron"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Software Engineering (cs.SE)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.04337"
  },
  {
    "id": "arXiv:2202.04340",
    "title": "Efficient Construction of Reversible Transducers from Regular Transducer  Expressions",
    "abstract": "The class of regular transformations has several equivalent characterizations\nsuch as functional MSO transductions, deterministic two-way transducers,\nstreaming string transducers, as well as regular transducer expressions (RTE).\nFor algorithmic applications, it is very common and useful to transform a\nspecification, here, an RTE, to a machine, here, a transducer. In this paper,\nwe give an efficient construction of a two-way reversible transducer (2RFT)\nequivalent to a given RTE. 2RFTs are a well behaved class of transducers which\nare deterministic and co-deterministic (hence allows evaluation in linear time\n\\wrt the input word), and where composition has only polynomial complexity.\nWe show that, for full RTE, the constructed 2RFT has size doubly exponential\nin the size of the expression, while, if the RTE does not use Hadamard product\nor chained-star, the constructed\n2RFT has size exponential in the size of the RTE.",
    "descriptor": "",
    "authors": [
      "Luc Dartois",
      "Paul Gastin",
      "R. Govind",
      "Shankaranarayanan Krishna"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2202.04340"
  },
  {
    "id": "arXiv:2202.04345",
    "title": "Securing Smart Grids Through an Incentive Mechanism for Blockchain-Based  Data Sharing",
    "abstract": "Smart grids leverage the data collected from smart meters to make important\noperational decisions. However, they are vulnerable to False Data Injection\n(FDI) attacks in which an attacker manipulates meter data to disrupt the grid\noperations. Existing works on FDI are based on a simple threat model in which a\nsingle grid operator has access to all the data, and only some meters can be\ncompromised.\nOur goal is to secure smart grids against FDI under a realistic threat model.\nTo this end, we present a threat model in which there are multiple operators,\neach with a partial view of the grid, and each can be fully compromised. An\neffective defense against FDI in this setting is to share data between the\noperators. However, the main challenge here is to incentivize data sharing. We\naddress this by proposing an incentive mechanism that rewards operators for\nuploading data, but penalizes them if the data is missing or anomalous. We\nderive formal conditions under which our incentive mechanism is provably secure\nagainst operators who withhold or distort measurement data for profit. We then\nimplement the data sharing solution on a private blockchain, introducing\nseveral optimizations that overcome the inherent performance limitations of the\nblockchain. Finally, we conduct an experimental evaluation that demonstrates\nthat our implementation has practical performance.",
    "descriptor": "",
    "authors": [
      "Daniel Reijsbergen",
      "Aung Maw",
      "Tien Tuan Anh Dinh",
      "Wen-Tai Li",
      "Chau Yuen"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.04345"
  },
  {
    "id": "arXiv:2202.04347",
    "title": "Gradient Methods Provably Converge to Non-Robust Networks",
    "abstract": "Despite a great deal of research, it is still unclear why neural networks are\nso susceptible to adversarial examples. In this work, we identify natural\nsettings where depth-$2$ ReLU networks trained with gradient flow are provably\nnon-robust (susceptible to small adversarial $\\ell_2$-perturbations), even when\nrobust networks that classify the training dataset correctly exist. Perhaps\nsurprisingly, we show that the well-known implicit bias towards margin\nmaximization induces bias towards non-robust networks, by proving that every\nnetwork which satisfies the KKT conditions of the max-margin problem is\nnon-robust.",
    "descriptor": "",
    "authors": [
      "Gal Vardi",
      "Gilad Yehudai",
      "Ohad Shamir"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.04347"
  },
  {
    "id": "arXiv:2202.04348",
    "title": "MBCT: Tree-Based Feature-Aware Binning for Individual Uncertainty  Calibration",
    "abstract": "Most machine learning classifiers only concern classification accuracy, while\ncertain applications (such as medical diagnosis, meteorological forecasting,\nand computation advertising) require the model to predict the true probability,\nknown as a calibrated estimate. In previous work, researchers have developed\nseveral calibration methods to post-process the outputs of a predictor to\nobtain calibrated values, such as binning and scaling methods. Compared with\nscaling, binning methods are shown to have distribution-free theoretical\nguarantees, which motivates us to prefer binning methods for calibration.\nHowever, we notice that existing binning methods have several drawbacks: (a)\nthe binning scheme only considers the original prediction values, thus limiting\nthe calibration performance; and (b) the binning approach is non-individual,\nmapping multiple samples in a bin to the same value, and thus is not suitable\nfor order-sensitive applications. In this paper, we propose a feature-aware\nbinning framework, called Multiple Boosting Calibration Trees (MBCT), along\nwith a multi-view calibration loss to tackle the above issues. Our MBCT\noptimizes the binning scheme by the tree structures of features, and adopts a\nlinear function in a tree node to achieve individual calibration. Our MBCT is\nnon-monotonic, and has the potential to improve order accuracy, due to its\nlearnable binning scheme and the individual calibration. We conduct\ncomprehensive experiments on three datasets in different fields. Results show\nthat our method outperforms all competing models in terms of both calibration\nerror and order accuracy. We also conduct simulation experiments, justifying\nthat the proposed multi-view calibration loss is a better metric in modeling\ncalibration error.",
    "descriptor": "\nComments: WWW 2022\n",
    "authors": [
      "Siguang Huang",
      "Yunli Wang",
      "Lili Mou",
      "Huayue Zhang",
      "Han Zhu",
      "Chuan Yu",
      "Bo Zheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.04348"
  },
  {
    "id": "arXiv:2202.04349",
    "title": "Cartesian Tree Subsequence Matching",
    "abstract": "Park et al. [TCS 2020] observed that the similarity between two (numerical)\nstrings can be captured by the Cartesian trees: The Cartesian tree of a string\nis a binary tree recursively constructed by picking up the smallest value of\nthe string as the root of the tree. Two strings of equal length are said to\nCartesian-tree match if their Cartesian trees are isomorphic. Park et al. [TCS\n2020] introduced the following Cartesian tree substring matching (CTMStr)\nproblem: Given a text string $T$ of length $n$ and a pattern string of length\n$m$, find every consecutive substring $S = T[i..j]$ of a text string $T$ such\nthat $S$ and $P$ Cartesian-tree match. They showed how to solve this problem in\n$\\tilde{O}(n+m)$ time. In this paper, we introduce the Cartesian tree\nsubsequence matching (CTMSeq) problem, that asks to find every minimal\nsubstring $S = T[i..j]$ of $T$ such that $S$ contains a subsequence $S'$ which\nCartesian-tree matches $P$. We prove that the CTMSeq problem can be solved\nefficiently, in $O(m n p(n))$ time, where $p(n)$ denotes the update/query time\nfor dynamic predecessor queries. By using a suitable dynamic predecessor data\nstructure, we obtain $O(mn \\log \\log n)$-time $O(n \\log m)$-space solution for\nCTMSeq. This contrasts CTMSeq with closely related order-preserving subsequence\nmatching (OPMSeq) which was shown to be NP-hard by Bose et al. [IPL 1998].",
    "descriptor": "",
    "authors": [
      "Tsubasa Oizumi",
      "Takeshi Kai",
      "Takuya Mieno",
      "Shunsuke Inenaga",
      "Hiroki Arimura"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2202.04349"
  },
  {
    "id": "arXiv:2202.04350",
    "title": "pNLP-Mixer: an Efficient all-MLP Architecture for Language",
    "abstract": "Large pre-trained language models drastically changed the natural language\nprocessing(NLP) landscape. Nowadays, they represent the go-to framework to\ntackle diverse NLP tasks, even with a limited number of annotations. However,\nusing those models in production, either in the cloud or at the edge, remains a\nchallenge due to the memory footprint and/or inference costs. As an\nalternative, recent work on efficient NLP has shown that small weight-efficient\nmodels can reach competitive performance at a fraction of the costs. Here, we\nintroduce pNLP-Mixer, an embbedding-free model based on the MLP-Mixer\narchitecture that achieves high weight-efficiency thanks to a novel\nlinguistically informed projection layer. We evaluate our model on two\nmulti-lingual semantic parsing datasets, MTOP and multiATIS. On MTOP our\npNLP-Mixer almost matches the performance of mBERT, which has 38 times more\nparameters, and outperforms the state-of-the-art of tiny models (pQRNN) with 3\ntimes fewer parameters. On a long-sequence classification task (Hyperpartisan)\nour pNLP-Mixer without pretraining outperforms RoBERTa, which has 100 times\nmore parameters, demonstrating the potential of this architecture.",
    "descriptor": "\nComments: Preprint\n",
    "authors": [
      "Francesco Fusco",
      "Damian Pascual",
      "Peter Staar"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.04350"
  },
  {
    "id": "arXiv:2202.04357",
    "title": "Generalized Strategic Classification and the Case of Aligned Incentives",
    "abstract": "Predicative machine learning models are frequently being used by companies,\ninstitutes and organizations to make choices about humans. Strategic\nclassification studies learning in settings where self-interested users can\nstrategically modify their features to obtain favorable predictive outcomes. A\nkey working assumption, however, is that 'favorable' always means 'positive';\nthis may be appropriate in some applications (e.g., loan approval, university\nadmissions and hiring), but reduces to a fairly narrow view what user interests\ncan be. In this work we argue for a broader perspective on what accounts for\nstrategic user behavior, and propose and study a flexible model of generalized\nstrategic classification. Our generalized model subsumes most current models,\nbut includes other novel settings; among these, we identify and target one\nintriguing sub-class of problems in which the interests of users and the system\nare aligned. For this cooperative setting, we provide an in-depth analysis, and\npropose a practical learning approach that is effective and efficient. We\ncompare our approach to existing learning methods and show its statistical and\noptimization benefits. Returning to our fully generalized model, we show how\nour results and approach can extend to the most general case. We conclude with\na set of experiments that empirically demonstrate the utility of our approach.",
    "descriptor": "",
    "authors": [
      "Sagi Levanon",
      "Nir Rosenfeld"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.04357"
  },
  {
    "id": "arXiv:2202.04361",
    "title": "Molecular-scale Integration of Multi-modal Sensing and Neuromorphic  Computing with Organic Electrochemical Transistors",
    "abstract": "Abstract: Bionic learning with fused sensing, memory and processing functions\noutperforms artificial neural networks running on silicon chips in terms of\nefficiency and footprint. However, digital hardware implementation of bionic\nlearning suffers from device heterogeneity in sensors and processing cores,\nwhich incurs large hardware, energy and time overheads. Here, we present a\nuniversal solution to simultaneously perform multi-modal sensing, memory and\nprocessing using organic electrochemical transistors with designed architecture\nand tailored channel morphology, selective ion injection into the\ncrystalline/amorphous regions. The resultant device work as either a volatile\nreceptor that shows multi-modal sensing, or a non-volatile synapse that\nfeatures record-high 10-bit analog states, low switching stochasticity and good\nretention without the integration of any extra devices. Homogeneous integration\nof such devices enables bionic learning functions such as conditioned reflex\nand real-time cardiac disease diagnose via reservoir computing, illustrating\nthe promise for future smart edge health informatics.",
    "descriptor": "\nComments: 18 pages, 4 figures\n",
    "authors": [
      "Shijie Wang",
      "Xi Chen",
      "Chao Zhao",
      "Yuxin Kong",
      "Baojun Lin",
      "Yongyi Wu",
      "Zhaozhao Bi",
      "Ziyi Xuan",
      "Tao Li",
      "Yuxiang Li",
      "Wei Zhang",
      "En Ma",
      "Zhongrui Wang",
      "Wei Ma"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Materials Science (cond-mat.mtrl-sci)",
      "Soft Condensed Matter (cond-mat.soft)"
    ],
    "url": "https://arxiv.org/abs/2202.04361"
  },
  {
    "id": "arXiv:2202.04365",
    "title": "AIVC: Artificial Intelligence based Video Codec",
    "abstract": "This paper introduces AIVC, an end-to-end neural video codec. It is based on\ntwo conditional autoencoders MNet and CNet, for motion compensation and coding.\nAIVC learns to compress videos using any coding configurations through a single\nend-to-end rate-distortion optimization. Furthermore, it offers performance\ncompetitive with the recent video coder HEVC under several established test\nconditions. A comprehensive ablation study is performed to evaluate the\nbenefits of the different modules composing AIVC. The implementation is made\navailable at https://orange-opensource.github.io/AIVC/.",
    "descriptor": "",
    "authors": [
      "Th\u00e9o Ladune",
      "Pierrick Philippe"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.04365"
  },
  {
    "id": "arXiv:2202.04366",
    "title": "Increasing the Minimum Distance of Polar-Like Codes with  Pre-Transformation",
    "abstract": "Reed Muller (RM) codes are known for their good minimum distance. One can use\ntheir structure to construct polar-like codes with good distance properties by\nchoosing the information set as the rows of the polarization matrix with the\nhighest Hamming weight, instead of the most reliable synthetic channels.\nHowever, the information length options of RM codes are quite limited due to\ntheir specific structure. In this work, we present sufficient conditions to\nincrease the information length by at least one bit for some underlying RM\ncodes and in order to obtain pre-transformed polar-like codes with the same\nminimum distance than lower rate codes. Moreover, our findings are combined\nwith the method presented in [1] to further reduce the number of minimum weight\ncodewords. Numerical results show that the designed codes perform close to the\nmeta-converse bound at short blocklengths and better than the polarized\nadjusted convolutional polar codes with the same parameters.",
    "descriptor": "",
    "authors": [
      "Samet Gelincik",
      "Philippe Mary",
      "Anne Savard",
      "Jean-Yves Baudais"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.04366"
  },
  {
    "id": "arXiv:2202.04367",
    "title": "A Reinforcement Learning Approach to Domain-Knowledge Inclusion Using  Grammar Guided Symbolic Regression",
    "abstract": "In recent years, symbolic regression has been of wide interest to provide an\ninterpretable symbolic representation of potentially large data relationships.\nInitially circled to genetic algorithms, symbolic regression methods now\ninclude a variety of Deep Learning based alternatives. However, these methods\nstill do not generalize well to real-world data, mainly because they hardly\ninclude domain knowledge nor consider physical relationships between variables\nsuch as known equations and units. Regarding these issues, we propose a\nReinforcement-Based Grammar-Guided Symbolic Regression (RBG2-SR) method that\nconstrains the representational space with domain-knowledge using context-free\ngrammar as reinforcement action space. We detail a Partially-Observable Markov\nDecision Process (POMDP) modeling of the problem and benchmark our approach\nagainst state-of-the-art methods. We also analyze the POMDP state definition\nand propose a physical equation search use case on which we compare our\napproach to grammar-based and non-grammarbased symbolic regression methods. The\nexperiment results show that our method is competitive against other\nstate-of-the-art methods on the benchmarks and offers the best error-complexity\ntrade-off, highlighting the interest of using a grammar-based method in a\nreal-world scenario.",
    "descriptor": "",
    "authors": [
      "Laure Crochepierre",
      "Lydia Boudjeloud-Assala",
      "Vincent Barbesant"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.04367"
  },
  {
    "id": "arXiv:2202.04369",
    "title": "A new perspective on classification: optimally allocating limited  resources to uncertain tasks",
    "abstract": "A central problem in business concerns the optimal allocation of limited\nresources to a set of available tasks, where the payoff of these tasks is\ninherently uncertain. In credit card fraud detection, for instance, a bank can\nonly assign a small subset of transactions to their fraud investigations team.\nTypically, such problems are solved using a classification framework, where the\nfocus is on predicting task outcomes given a set of characteristics. Resources\nare then allocated to the tasks that are predicted to be the most likely to\nsucceed. However, we argue that using classification to address task\nuncertainty is inherently suboptimal as it does not take into account the\navailable capacity. Therefore, we first frame the problem as a type of\nassignment problem. Then, we present a novel solution using learning to rank by\ndirectly optimizing the assignment's expected profit given limited, stochastic\ncapacity. This is achieved by optimizing a specific instance of the net\ndiscounted cumulative gain, a commonly used class of metrics in learning to\nrank. Empirically, we demonstrate that our new method achieves higher expected\nprofit and expected precision compared to a classification approach for a wide\nvariety of application areas and data sets. This illustrates the benefit of an\nintegrated approach and of explicitly considering the available resources when\nlearning a predictive model.",
    "descriptor": "",
    "authors": [
      "Toon Vanderschueren",
      "Bart Baesens",
      "Tim Verdonck",
      "Wouter Verbeke"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.04369"
  },
  {
    "id": "arXiv:2202.04370",
    "title": "Simultaneous Transmit Diversity and Passive Beamforming with Large-Scale  Intelligent Reflecting Surface",
    "abstract": "Intelligent reflecting surface (IRS) has emerged as a cost-effective solution\nto enhance wireless communication performance via passive signal reflection.\nExisting works on IRS have mainly focused on investigating IRS's passive\nbeamforming/reflection design to boost the communication rate for users\nassuming that their channel state information (CSI) is fully or partially\nknown. However, how to exploit IRS to improve the wireless transmission\nreliability without any CSI, which is typical in high-mobility/delay-sensitive\ncommunication scenarios, remains largely open. In this paper, we study a new\nIRS-aided communication system with the IRS integrated to its aided access\npoint (AP) to achieve both functions of transmit diversity and passive\nbeamforming simultaneously. Specifically, we first show an interesting result\nthat the IRS's passive beamforming gain in any direction is invariant to the\ncommon phase-shift applied to all of its reflecting elements. Accordingly, we\ndesign the common phase-shift of IRS elements to achieve transmit diversity at\nthe AP side without the need of any CSI of the users. In addition, we propose a\npractical method for the users to estimate the CSI at the receiver side for\ninformation decoding. Meanwhile, we show that the conventional passive\nbeamforming gain of IRS can be retained for the other users with their CSI\nknown at the AP. Furthermore, we derive the asymptotic performance of both\nIRS-aided transmit diversity and passive beamforming in closed-form, by\nconsidering the large-scale IRS with an infinite number of elements. Numerical\nresults validate our analysis and show the performance gains of the proposed\nIRS-aided simultaneous transmit diversity and passive beamforming scheme over\nother benchmark schemes.",
    "descriptor": "\nComments: Large-scale IRS-aided simultaneous \"transmit diversity\" and \"passive beamforming\" (31 pages, 9 figures)\n",
    "authors": [
      "Beixiong Zheng",
      "Rui Zhang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.04370"
  },
  {
    "id": "arXiv:2202.04375",
    "title": "Temporal Logic Guided Motion Primitives for Complex Manipulation Tasks  with User Preferences",
    "abstract": "Dynamic movement primitives (DMPs) are a flexible trajectory learning scheme\nwidely used in motion generation of robotic systems. However, existing\nDMP-based methods mainly focus on simple go-to-goal tasks. Motivated to handle\ntasks beyond point-to-point motion planning, this work presents temporal logic\nguided optimization of motion primitives, namely PIBB-TL algorithm, for complex\nmanipulation tasks with user preferences. In particular, weighted truncated\nlinear temporal logic (wTLTL) is incorporated in the PIBB-TL algorithm, which\nnot only enables the encoding of complex tasks that involve a sequence of\nlogically organized action plans with user preferences, but also provides a\nconvenient and efficient means to design the cost function. The black-box\noptimization is then adapted to identify optimal shape parameters of DMPs to\nenable motion planning of robotic systems. The effectiveness of the PIBB-TL\nalgorithm is demonstrated via simulation and experime",
    "descriptor": "",
    "authors": [
      "Hao Wang",
      "Haoyuan He",
      "Weiwei Shang",
      "Zhen Kan"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.04375"
  },
  {
    "id": "arXiv:2202.04376",
    "title": "Improving short-term bike sharing demand forecast through an irregular  convolutional neural network",
    "abstract": "As an important task for the management of bike sharing systems, accurate\nforecast of travel demand could facilitate dispatch and relocation of bicycles\nto improve user satisfaction. In recent years, many deep learning algorithms\nhave been introduced to improve bicycle usage forecast. A typical practice is\nto integrate convolutional (CNN) and recurrent neural network (RNN) to capture\nspatial-temporal dependency in historical travel demand. For typical CNN, the\nconvolution operation is conducted through a kernel that moves across a\n\"matrix-format\" city to extract features over spatially adjacent urban areas.\nThis practice assumes that areas close to each other could provide useful\ninformation that improves prediction accuracy. However, bicycle usage in\nneighboring areas might not always be similar, given spatial variations in\nbuilt environment characteristics and travel behavior that affect cycling\nactivities. Yet, areas that are far apart can be relatively more similar in\ntemporal usage patterns. To utilize the hidden linkage among these distant\nurban areas, the study proposes an irregular convolutional Long-Short Term\nMemory model (IrConv+LSTM) to improve short-term bike sharing demand forecast.\nThe model modifies traditional CNN with irregular convolutional architecture to\nextract dependency among \"semantic neighbors\". The proposed model is evaluated\nwith a set of benchmark models in five study sites, which include one dockless\nbike sharing system in Singapore, and four station-based systems in Chicago,\nWashington, D.C., New York, and London. We find that IrConv+LSTM outperforms\nother benchmark models in the five cities. The model also achieves superior\nperformance in areas with varying levels of bicycle usage and during peak\nperiods. The findings suggest that \"thinking beyond spatial neighbors\" can\nfurther improve short-term travel demand prediction of urban bike sharing\nsystems.",
    "descriptor": "\nComments: 20 pages with 9 figures\n",
    "authors": [
      "Xinyu Li",
      "Yang Xu",
      "Xiaohu Zhang",
      "Wenzhong Shi",
      "Yang Yue",
      "Qingquan Li"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.04376"
  },
  {
    "id": "arXiv:2202.04377",
    "title": "Constant Approximating Parameterized $k$-SetCover is W[2]-hard",
    "abstract": "In this paper, we prove that it is W[2]-hard to approximate $k$-SetCover\nwithin any constant ratio. Our proof is built upon the recently developed\nthreshold graph composition technique. We propose a strong notion of threshold\ngraph and use a new composition method to prove this result. Our technique\ncould also be applied to rule out polynomial time $o\\left(\\frac{\\log n}{\\log\n\\log n}\\right)$ ratio approximation algorithms for the non-parameterized\n$k$-SetCover problem, assuming W[1]$\\ne$FPT.\nWe highlight that our proof does not depend on the well-known PCP theorem,\nand only involves simple combinatorial objects. Furthermore, our reduction\nresults in a $k$-SetCover instance with $k$ as small as $O\\left(\\log^2 n\\cdot\n\\log \\log n\\right)$.",
    "descriptor": "",
    "authors": [
      "Bingkai Lin",
      "Xuandi Ren",
      "Yican Sun",
      "Xiuhan Wang"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2202.04377"
  },
  {
    "id": "arXiv:2202.04382",
    "title": "Leveraging Experience in Lifelong Multi-Agent Pathfinding",
    "abstract": "In Lifelong Multi-Agent Path Finding (L-MAPF) a team of agents performs a\nstream of tasks consisting of multiple locations to be visited by the agents on\na shared graph while avoiding collisions with one another. L-MAPF is typically\ntackled by partitioning it into multiple consecutive, and hence similar,\n\"one-shot\" MAPF queries with a single task assigned to each agent, as in the\nRolling-Horizon Collision Resolution (RHCR) algorithm. Thus, a solution to one\nquery informs the next query, which leads to similarity with respect to the\nagents' start and goal positions, and how collisions need to be resolved from\none query to the next. Thus, experience from solving one MAPF query can\npotentially be used to speedup solving the next one. Despite this intuition,\ncurrent L-MAPF planners solve consecutive MAPF queries from scratch. In this\npaper, we introduce a new RHCR-inspired approach called exRHCR, which exploits\nexperience in its constituent MAPF queries. In particular, exRHCR employs a new\nextension of Priority-Based Search (PBS), a state-of-the-art MAPF solver. Our\nextension, called exPBS, allows to warm-start the search with the priorities\nbetween agents used by PBS in the previous MAPF instances. We demonstrate\nempirically that exRHCR solves L-MAPF up to 25% faster than RHCR, and allows to\nincrease throughput for given task streams by as much as 3%-16% by increasing\nthe number of agents we can cope with for a given time budget.",
    "descriptor": "",
    "authors": [
      "Nitzan Madar",
      "Kiril Solovey",
      "Oren Salzman"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.04382"
  },
  {
    "id": "arXiv:2202.04385",
    "title": "Empirical Risk Minimization with Relative Entropy Regularization:  Optimality and Sensitivity Analysis",
    "abstract": "The optimality and sensitivity of the empirical risk minimization problem\nwith relative entropy regularization (ERM-RER) are investigated for the case in\nwhich the reference is a sigma-finite measure instead of a probability measure.\nThis generalization allows for a larger degree of flexibility in the\nincorporation of prior knowledge over the set of models. In this setting, the\ninterplay of the regularization parameter, the reference measure, the risk\nfunction, and the empirical risk induced by the solution of the ERM-RER problem\nis characterized. This characterization yields necessary and sufficient\nconditions for the existence of a regularization parameter that achieves an\narbitrarily small empirical risk with arbitrarily high probability. The\nsensitivity of the expected empirical risk to deviations from the solution of\nthe ERM-RER problem is studied. The sensitivity is then used to provide upper\nand lower bounds on the expected empirical risk. Moreover, it is shown that the\nexpectation of the sensitivity is upper bounded, up to a constant factor, by\nthe square root of the lautum information between the models and the datasets.",
    "descriptor": "\nComments: Submitted to the IEEE International Symposium on Information Theory (ISIT), Aalto, Finland, Jul., 2022\n",
    "authors": [
      "Samir M. Perlaza",
      "Gaetan Bisson",
      "I\u00f1aki Esnaola",
      "Alain Jean-Marie",
      "Stefano Rini"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2202.04385"
  },
  {
    "id": "arXiv:2202.04390",
    "title": "Dual field structure-preserving discretization of port-Hamiltonian  systems using finite element exterior calculus",
    "abstract": "In this paper we propose a novel approach to discretize linear\nport-Hamiltonian systems while preserving the underlying structure. We present\na finite element exterior calculus formulation that is able to mimetically\nrepresent conservation laws and cope with mixed open boundary conditions using\na single computational mesh. The possibility of including open boundary\nconditions allows for modular composition of complex multi-physical systems\nwhereas the exterior calculus formulation provides a coordinate-free treatment.\nOur approach relies on a dual-field representation of the physical system that\nis redundant at the continuous level but eliminates the need of mimicking the\nHodge star operator at the discrete level. By considering the Stokes-Dirac\nstructure representing the system together with its adjoint, which embeds the\nmetric information directly in the codifferential, the need for an explicit\ndiscrete Hodge star is avoided altogether. By imposing the boundary conditions\nin a strong manner, the power balance characterizing the Stokes-Dirac structure\nis then retrieved at the discrete level via symplectic Runge-Kutta integrators\nbased on Gauss-Legendre collocation points. Numerical experiments validate the\nconvergence of the method and the conservation properties in terms of energy\nbalance both for the wave and Maxwell equations in a three dimensional domain.\nFor the latter example, the magnetic and electric fields preserve their\ndivergence free nature at the discrete level.",
    "descriptor": "\nComments: 43 pages, 19 figures\n",
    "authors": [
      "Andrea Brugnoli",
      "Ramy Rashad",
      "Stefano Stramigioli"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.04390"
  },
  {
    "id": "arXiv:2202.04392",
    "title": "Model Architecture Adaption for Bayesian Neural Networks",
    "abstract": "Bayesian Neural Networks (BNNs) offer a mathematically grounded framework to\nquantify the uncertainty of model predictions but come with a prohibitive\ncomputation cost for both training and inference. In this work, we show a novel\nnetwork architecture search (NAS) that optimizes BNNs for both accuracy and\nuncertainty while having a reduced inference latency. Different from canonical\nNAS that optimizes solely for in-distribution likelihood, the proposed scheme\nsearches for the uncertainty performance using both in- and out-of-distribution\ndata. Our method is able to search for the correct placement of Bayesian\nlayer(s) in a network. In our experiments, the searched models show comparable\nuncertainty quantification ability and accuracy compared to the\nstate-of-the-art (deep ensemble). In addition, the searched models use only a\nfraction of the runtime compared to many popular BNN baselines, reducing the\ninference runtime cost by $2.98 \\times$ and $2.92 \\times$ respectively on the\nCIFAR10 dataset when compared to MCDropout and deep ensemble.",
    "descriptor": "",
    "authors": [
      "Duo Wang",
      "Yiren Zhao",
      "Ilia Shumailov",
      "Robert Mullins"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.04392"
  },
  {
    "id": "arXiv:2202.04393",
    "title": "Binaural Audio Rendering in the Spherical Harmonic Domain: A Summary of  the Mathematics and its Pitfalls",
    "abstract": "The present document reviews the mathematics behind binaural rendering of\nsound fields that are available as spherical harmonic expansion coefficients.\nThis process is also known as binaural ambisonic decoding. We highlight that\nthe details entail some amount peculiarity so that one has to be well aware of\nthe precise definitions that are chosen for some of the involved quantities to\nobtain a consistent formulation.",
    "descriptor": "",
    "authors": [
      "Jens Ahrens"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2202.04393"
  },
  {
    "id": "arXiv:2202.04396",
    "title": "A Priori Error Estimates of a Discontinuous Galerkin Finite Element  Method for the Kelvin-Voigt Viscoelastic Fluid Motion Equations",
    "abstract": "This paper applies a discontinuous Galerkin finite element method to the\nKelvin-Voigt viscoelastic fluid motion equations when the forcing function is\nin $L^\\infty({\\bf L}^2)$-space. Optimal a priori error estimates in\n$L^\\infty({\\bf L}^2)$-norm for the velocity and in $L^\\infty(L^2)$-norm for the\npressure approximations for the semi-discrete discontinuous Galerkin method are\nderived here. The main ingredients for establishing the error estimates are the\nstandard elliptic duality argument and a modified version of the Sobolev-Stokes\noperator defined on appropriate broken Sobolev spaces. Further, under the\nsmallness assumption on the data, it has been proved that these estimates are\nvalid uniformly in time. Then, a first-order accurate backward Euler method is\nemployed to discretize the semi-discrete discontinuous Galerkin Kelvin-Voigt\nformulation completely. The fully discrete optimal error estimates for the\nvelocity and pressure are established. Finally, using the numerical\nexperiments, theoretical results are verified. It is worth highlighting here\nthat the error results in this article for the discontinuous Galerkin method\napplied to the Kelvin-Voigt model using finite element analysis are the first\nattempt in this direction.",
    "descriptor": "\nComments: 34 pages, 10 figures. arXiv admin note: text overlap with arXiv:2112.12414\n",
    "authors": [
      "Saumya Bajpai",
      "Deepjyoti Goswami",
      "Kallol Ray"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.04396"
  },
  {
    "id": "arXiv:2202.04411",
    "title": "A.I. and Data-Driven Mobility at Volkswagen Financial Services AG",
    "abstract": "Machine learning is being widely adapted in industrial applications owing to\nthe capabilities of commercially available hardware and rapidly advancing\nresearch. Volkswagen Financial Services (VWFS), as a market leader in vehicle\nleasing services, aims to leverage existing proprietary data and the latest\nresearch to enhance existing and derive new business processes. The\ncollaboration between Information Systems and Machine Learning Lab (ISMLL) and\nVWFS serves to realize this goal. In this paper, we propose methods in the\nfields of recommender systems, object detection, and forecasting that enable\ndata-driven decisions for the vehicle life-cycle at VWFS.",
    "descriptor": "",
    "authors": [
      "Shayan Jawed",
      "Mofassir ul Islam Arif",
      "Ahmed Rashed",
      "Kiran Madhusudhanan",
      "Shereen Elsayed",
      "Mohsan Jameel",
      "Alexei Volk",
      "Andre Hintsches",
      "Marlies Kornfeld",
      "Katrin Lange",
      "Lars Schmidt-Thieme"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.04411"
  },
  {
    "id": "arXiv:2202.04414",
    "title": "Agree to Disagree: Diversity through Disagreement for Better  Transferability",
    "abstract": "Gradient-based learning algorithms have an implicit simplicity bias which in\neffect can limit the diversity of predictors being sampled by the learning\nprocedure. This behavior can hinder the transferability of trained models by\n(i) favoring the learning of simpler but spurious features -- present in the\ntraining data but absent from the test data -- and (ii) by only leveraging a\nsmall subset of predictive features. Such an effect is especially magnified\nwhen the test distribution does not exactly match the train distribution --\nreferred to as the Out of Distribution (OOD) generalization problem. However,\ngiven only the training data, it is not always possible to apriori assess if a\ngiven feature is spurious or transferable. Instead, we advocate for learning an\nensemble of models which capture a diverse set of predictive features. Towards\nthis, we propose a new algorithm D-BAT (Diversity-By-disAgreement Training),\nwhich enforces agreement among the models on the training data, but\ndisagreement on the OOD data. We show how D-BAT naturally emerges from the\nnotion of generalized discrepancy, as well as demonstrate in multiple\nexperiments how the proposed method can mitigate shortcut-learning, enhance\nuncertainty and OOD detection, as well as improve transferability.",
    "descriptor": "\nComments: 14 pages, 11 figures\n",
    "authors": [
      "Matteo Pagliardini",
      "Martin Jaggi",
      "Fran\u00e7ois Fleuret",
      "Sai Praneeth Karimireddy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.04414"
  },
  {
    "id": "arXiv:2202.04426",
    "title": "Deep Feature Rotation for Multimodal Image Style Transfer",
    "abstract": "Recently, style transfer is a research area that attracts a lot of attention,\nwhich transfers the style of an image onto a content target. Extensive research\non style transfer has aimed at speeding up processing or generating\nhigh-quality stylized images. Most approaches only produce an output from a\ncontent and style image pair, while a few others use complex architectures and\ncan only produce a certain number of outputs. In this paper, we propose a\nsimple method for representing style features in many ways called Deep Feature\nRotation (DFR), while not only producing diverse outputs but also still\nachieving effective stylization compared to more complex methods. Our approach\nis representative of the many ways of augmentation for intermediate feature\nembedding without consuming too much computational expense. We also analyze our\nmethod by visualizing output in different rotation weights. Our code is\navailable at https://github.com/sonnguyen129/deep-feature-rotation.",
    "descriptor": "\nComments: Accepted to NICS'21\n",
    "authors": [
      "Son Truong Nguyen",
      "Nguyen Quang Tuyen",
      "Nguyen Hong Phuc"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.04426"
  },
  {
    "id": "arXiv:2202.04427",
    "title": "Revisiting QMIX: Discriminative Credit Assignment by Gradient Entropy  Regularization",
    "abstract": "In cooperative multi-agent systems, agents jointly take actions and receive a\nteam reward instead of individual rewards. In the absence of individual reward\nsignals, credit assignment mechanisms are usually introduced to discriminate\nthe contributions of different agents so as to achieve effective cooperation.\nRecently, the value decomposition paradigm has been widely adopted to realize\ncredit assignment, and QMIX has become the state-of-the-art solution. In this\npaper, we revisit QMIX from two aspects. First, we propose a new perspective on\ncredit assignment measurement and empirically show that QMIX suffers limited\ndiscriminability on the assignment of credits to agents. Second, we propose a\ngradient entropy regularization with QMIX to realize a discriminative credit\nassignment, thereby improving the overall performance. The experiments\ndemonstrate that our approach can comparatively improve learning efficiency and\nachieve better performance.",
    "descriptor": "",
    "authors": [
      "Jian Zhao",
      "Yue Zhang",
      "Xunhan Hu",
      "Weixun Wang",
      "Wengang Zhou",
      "Jianye Hao",
      "Jiangcheng Zhu",
      "Houqiang Li"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.04427"
  },
  {
    "id": "arXiv:2202.04428",
    "title": "Adapting to Mixing Time in Stochastic Optimization with Markovian Data",
    "abstract": "We consider stochastic optimization problems where data is drawn from a\nMarkov chain. Existing methods for this setting crucially rely on knowing the\nmixing time of the chain, which in real-world applications is usually unknown.\nWe propose the first optimization method that does not require the knowledge of\nthe mixing time, yet obtains the optimal asymptotic convergence rate when\napplied to convex problems. We further show that our approach can be extended\nto: (i) finding stationary points in non-convex optimization with Markovian\ndata, and (ii) obtaining better dependence on the mixing time in temporal\ndifference (TD) learning; in both cases, our method is completely oblivious to\nthe mixing time. Our method relies on a novel combination of multi-level Monte\nCarlo (MLMC) gradient estimation together with an adaptive learning method.",
    "descriptor": "",
    "authors": [
      "Ron Dorfman",
      "Kfir Y. Levy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.04428"
  },
  {
    "id": "arXiv:2202.04431",
    "title": "Assessing the alignment between the information needs of developers and  the documentation of programming languages: A case study on Rust",
    "abstract": "Programming language documentation refers to the set of technical documents\nthat provide application developers with a description of the high-level\nconcepts of a language. Such documentation is essential to support application\ndevelopers in the effective use of a programming language. One of the\nchallenges faced by documenters (i.e., personnel that produce documentation) is\nto ensure that documentation has relevant information that aligns with the\nconcrete needs of developers. In this paper, we present an automated approach\nto support documenters in evaluating the differences and similarities between\nthe concrete information need of developers and the current state of\ndocumentation (a problem that we refer to as the topical alignment of a\nprogramming language documentation). Our approach leverages semi-supervised\ntopic modelling to assess the similarities and differences between the topics\nof Q&A posts and the official documentation. To demonstrate the application of\nour approach, we perform a case study on the documentation of Rust. Our results\nshow that there is a relatively high level of topical alignment in Rust\ndocumentation. Still, information about specific topics is scarce in both the\nQ&A websites and the documentation, particularly related topics with\nprogramming niches such as network, game, and database development. For other\ntopics (e.g., related topics with language features such as structs, patterns\nand matchings, and foreign function interface), information is only available\non Q&A websites while lacking in the official documentation. Finally, we\ndiscuss implications for programming language documenters, particularly how to\nleverage our approach to prioritize topics that should be added to the\ndocumentation.",
    "descriptor": "",
    "authors": [
      "Filipe R. Cogo",
      "Xin Xia",
      "Ahmed E. Hassan"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2202.04431"
  },
  {
    "id": "arXiv:2202.04433",
    "title": "Co-WIN: Really Winning? Analysing Inequity in India's Vaccination  Response",
    "abstract": "The COVID-19 pandemic has so far accounted for reported 5.5M deaths\nworldwide, with 8.7% of these coming from India. The pandemic exacerbated the\nweakness of the Indian healthcare system. As of January 20, 2022, India is the\nsecond worst affected country with 38.2M reported cases and 487K deaths.\nAccording to epidemiologists, vaccines are an essential tool to prevent the\nspread of the pandemic. India's vaccination drive began on January 16, 2021\nwith governmental policies being introduced to prioritize different populations\nof the society. Through the course of the vaccination drive, multiple new\npolicies were also introduced to ensure that vaccines are readily available and\nvaccination coverage is increased. However, at the same time, some of the\ngovernment policies introduced led to unintended inequities in the populations\nbeing targeted. In this report, we enumerate and analyze the inequities that\nexisted in India's vaccination policy drive, and also compute the effect of the\nnew policies that were introduced. We analyze these potential inequities not\nonly qualitatively but also quantitatively by leveraging the data that was made\navailable through the government portals. Specifically, (a) we discover\ninequities that might exist in the policies, (b) we quantify the effect of new\npolicies introduced to increase vaccination coverage, and (c) we also point the\ndata discrepancies that exist across different data sources.",
    "descriptor": "",
    "authors": [
      "Tanvi Karandikar",
      "Avinash Prabhu",
      "Mehul Mathur",
      "Megha Arora",
      "Hemank Lamba",
      "Ponnurangam Kumaraguru"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2202.04433"
  },
  {
    "id": "arXiv:2202.04445",
    "title": "Object-Guided Day-Night Visual Localization in Urban Scenes",
    "abstract": "We introduce Object-Guided Localization (OGuL) based on a novel method of\nlocal-feature matching. Direct matching of local features is sensitive to\nsignificant changes in illumination. In contrast, object detection often\nsurvives severe changes in lighting conditions. The proposed method first\ndetects semantic objects and establishes correspondences of those objects\nbetween images. Object correspondences provide local coarse alignment of the\nimages in the form of a planar homography. These homographies are consequently\nused to guide the matching of local features. Experiments on standard urban\nlocalization datasets (Aachen, Extended-CMU-Season, RobotCar-Season) show that\nOGuL significantly improves localization results with as simple local features\nas SIFT, and its performance competes with the state-of-the-art CNN-based\nmethods trained for day-to-night localization.",
    "descriptor": "",
    "authors": [
      "Assia Benbihi",
      "C\u00e9dric Pradalier",
      "Ond\u0159ej Chum"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.04445"
  },
  {
    "id": "arXiv:2202.04454",
    "title": "Adjacent-Bits-Swapped Polar codes: A new code construction to speed up  polarization",
    "abstract": "The construction of polar codes with code length $n=2^m$ involves $m$ layers\nof polar transforms. In this paper, we observe that after each layer of polar\ntransforms, one can swap certain pairs of adjacent bits to accelerate the\npolarization process. More precisely, if the previous bit is more reliable than\nits next bit under the successive decoder, then switching the decoding order of\nthese two adjacent bits will make the reliable bit even more reliable and the\nnoisy bit even noisier.\nBased on this observation, we propose a new family of codes called the\nAdjacent-Bits-Swapped (ABS) polar codes. We add a permutation layer after each\npolar transform layer in the construction of the ABS polar codes. In order to\nchoose which pairs of adjacent bits to swap in the permutation layers, we rely\non a new polar transform that combines two independent channels with $4$-ary\ninputs. This new polar transform allows us to track the evolution of every pair\nof adjacent bits through different layers of polar transforms, and it also\nplays an essential role in the Successive Cancellation List (SCL) decoder for\nthe ABS polar codes. Extensive simulation results show that ABS polar codes\nconsistently outperform standard polar codes by 0.15dB -- 0.6dB when we use\nCRC-aided SCL decoder with list size $32$ for both codes. The implementations\nof all the algorithms in this paper are available at\nhttps://github.com/PlumJelly/ABS-Polar",
    "descriptor": "\nComments: The implementations of all the algorithms in this paper are available at this https URL\n",
    "authors": [
      "Guodong Li",
      "Min Ye",
      "Sihuang Hu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.04454"
  },
  {
    "id": "arXiv:2202.04456",
    "title": "AC-Feasible Power Transfer Regions of Virtual Power Plants:  Characterization and Application",
    "abstract": "Distributed energy resources (DERs) in distribution networks can participate\nin the transmission-level operation when they are aggregated as a virtual power\nplant (VPP). A critical challenge for such participation is the complexity of\nthe feasible power transfer region between a VPP and the transmission system at\ntheir point of common coupling. To overcome this challenge, this paper develops\na method to characterize the AC-feasible power transfer regions for VPPs. The\ndeveloped method constructed several convex polytopes in the domain of power\ntransfers by solving a series of optimization problems. These optimization\nproblems are established by combing the Brouwer fixed point theorem with the\nsecond-order Taylor expansion of the nonlinear Dist-Flow equations, which can\ntheoretically guarantee the AC feasibility of the convex polytopes, whose union\nserves as an inner approximation to the feasible region. Furthermore, a big-M\nformulation is developed to linearize the transmission-level operation problem\nwith VPP participation. The proposed method is verified by numerical\nexperiments in the IEEE 33-bus and IEEE 136-bus test systems.",
    "descriptor": "",
    "authors": [
      "Wei Lin",
      "Changhong Zhao"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.04456"
  },
  {
    "id": "arXiv:2202.04461",
    "title": "A Multi-Task Recurrent Neural Network for End-to-End Dynamic Occupancy  Grid Mapping",
    "abstract": "A common approach for modeling the environment of an autonomous vehicle are\ndynamic occupancy grid maps, in which the surrounding is divided into cells,\neach containing the occupancy and velocity state of its location. Despite the\nadvantage of modeling arbitrary shaped objects, the used algorithms rely on\nhand-designed inverse sensor models and semantic information is missing.\nTherefore, we introduce a multi-task recurrent neural network to predict grid\nmaps providing occupancies, velocity estimates, semantic information and the\ndriveable area. During training, our network architecture, which is a\ncombination of convolutional and recurrent layers, processes sequences of raw\nlidar data, that is represented as bird's eye view images with several height\nchannels. The multi-task network is trained in an end-to-end fashion to predict\noccupancy grid maps without the usual preprocessing steps consisting of\nremoving ground points and applying an inverse sensor model. In our\nevaluations, we show that our learned inverse sensor model is able to overcome\nsome limitations of a geometric inverse sensor model in terms of representing\nobject shapes and modeling freespace. Moreover, we report a better runtime\nperformance and more accurate semantic predictions for our end-to-end approach,\ncompared to our network relying on measurement grid maps as input data.",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Marcel Schreiber",
      "Vasileios Belagiannis",
      "Claudius Gl\u00e4ser",
      "Klaus Dietmayer"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.04461"
  },
  {
    "id": "arXiv:2202.04462",
    "title": "Merit-based Fusion of NLP Techniques for Instant Feedback on Water  Quality from Twitter Text",
    "abstract": "This paper focuses on an important environmental challenge; namely, water\nquality by analyzing the potential of social media as an immediate source of\nfeedback. The main goal of the work is to automatically analyze and retrieve\nsocial media posts relevant to water quality with particular attention to posts\ndescribing different aspects of water quality, such as watercolor, smell,\ntaste, and related illnesses. To this aim, we propose a novel framework\nincorporating different preprocessing, data augmentation, and classification\ntechniques. In total, three different Neural Networks (NNs) architectures,\nnamely (i) Bidirectional Encoder Representations from Transformers (BERT), (ii)\nRobustly Optimized BERT Pre-training Approach (XLM-RoBERTa), and (iii) custom\nLong short-term memory (LSTM) model, are employed in a merit-based fusion\nscheme. For merit-based weight assignment to the models, several optimization\nand search techniques are compared including a Particle Swarm Optimization\n(PSO), a Genetic Algorithm (GA), Brute Force (BF), Nelder-Mead, and Powell's\noptimization methods. We also provide an evaluation of the individual models\nwhere the highest F1-score of 0.81 is obtained with the BERT model. In\nmerit-based fusion, overall better results are obtained with BF achieving an\nF1-score score of 0.852.\nWe also provide comparison against existing methods, where a significant\nimprovement for our proposed solutions is obtained. We believe such rigorous\nanalysis of this relatively new topic will provide a baseline for future\nresearch.",
    "descriptor": "\nComments: 10 pages, 2 figures, 8 tables\n",
    "authors": [
      "Khubaib Ahmad",
      "Muhammad Asif Ayub",
      "Kashif Ahmad",
      "Jebran Khan",
      "Nasir Ahmad",
      "Ala Al-Fuqaha"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.04462"
  },
  {
    "id": "arXiv:2202.04464",
    "title": "Conditional Drums Generation using Compound Word Representations",
    "abstract": "The field of automatic music composition has seen great progress in recent\nyears, specifically with the invention of transformer-based architectures. When\nusing any deep learning model which considers music as a sequence of events\nwith multiple complex dependencies, the selection of a proper data\nrepresentation is crucial. In this paper, we tackle the task of conditional\ndrums generation using a novel data encoding scheme inspired by the Compound\nWord representation, a tokenization process of sequential data. Therefore, we\npresent a sequence-to-sequence architecture where a Bidirectional Long\nshort-term memory (BiLSTM) Encoder receives information about the conditioning\nparameters (i.e., accompanying tracks and musical attributes), while a\nTransformer-based Decoder with relative global attention produces the generated\ndrum sequences. We conducted experiments to thoroughly compare the\neffectiveness of our method to several baselines. Quantitative evaluation shows\nthat our model is able to generate drums sequences that have similar\nstatistical distributions and characteristics to the training corpus. These\nfeatures include syncopation, compression ratio, and symmetry among others. We\nalso verified, through a listening test, that generated drum sequences sound\npleasant, natural and coherent while they \"groove\" with the given\naccompaniment.",
    "descriptor": "\nComments: Accepted for the 11th International Conference on Artificial Intelligence in Music, Sound, Art and Design (EvoMUSART), 2022\n",
    "authors": [
      "Dimos Makris",
      "Guo Zixun",
      "Maximos Kaliakatsos-Papakostas",
      "Dorien Herremans"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2202.04464"
  },
  {
    "id": "arXiv:2202.04465",
    "title": "Allocation of Indivisible Items with Individual Preference Graphs",
    "abstract": "This paper studies the allocation of indivisible items to agents, when each\nagent's preferences are expressed by means of a directed acyclic graph. The\nvertices of each preference graph represent the subset of items approved of by\nthe respective agent. An arc $(a,b)$ in such a graph means that the respective\nagent prefers item $a$ over item $b$. We introduce a new measure of\ndissatisfaction of an agent by counting the number of non-assigned items which\nare approved of by the agent and for which no more preferred item is allocated\nto the agent. Considering two problem variants, we seek an allocation of the\nitems to the agents in a way that minimizes (i) the total dissatisfaction over\nall agents or (ii) the maximum dissatisfaction among the agents. For both\noptimization problems we study the status of computational complexity and\nobtain NP-hardness results as well as polynomial algorithms with respect to\nnatural underlying graph structures, such as stars, trees, paths, and\nmatchings. We also analyze the parameterized complexity of the two problems\nwith respect to various parameters related to the number of agents, the\ndissatisfaction threshold, the vertex degrees of the preference graphs, and the\ntreewidth.",
    "descriptor": "",
    "authors": [
      "Nina Chiarelli",
      "Cl\u00e9ment Dallard",
      "Andreas Darmann",
      "Stefan Lendl",
      "Martin Milani\u010d",
      "Peter Mur\u0161i\u010d",
      "Ulrich Pferschy",
      "Nevena Piva\u010d"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2202.04465"
  },
  {
    "id": "arXiv:2202.04466",
    "title": "Predicting the intended action using internal simulation of perception",
    "abstract": "This article proposes an architecture, which allows the prediction of\nintention by internally simulating perceptual states represented by action\npattern vectors. To this end, associative self-organising neural networks\n(A-SOM) is utilised to build a hierarchical cognitive architecture for\nrecognition and simulation of the skeleton based human actions. The abilities\nof the proposed architecture in recognising and predicting actions is evaluated\nin experiments using three different datasets of 3D actions. Based on the\nexperiments of this article, applying internally simulated perceptual states\nrepresented by action pattern vectors improves the performance of the\nrecognition task in all experiments. Furthermore, internal simulation of\nperception addresses the problem of having limited access to the sensory input,\nand also the future prediction of the consecutive perceptual sequences. The\nperformance of the system is compared and discussed with similar architecture\nusing self-organizing neural networks (SOM).",
    "descriptor": "",
    "authors": [
      "Zahra Gharaee"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.04466"
  },
  {
    "id": "arXiv:2202.04473",
    "title": "MapiFi: Using Wi-Fi Signals to Map Home Devices",
    "abstract": "Imagine a map of your home with all of your connected devices (computers,\nTVs, voice control devices, printers, security cameras, etc.), in their\nlocation. You could then easily group devices into user-profiles, monitor Wi-Fi\nquality and activity in different areas of your home, and even locate a lost\ntablet in your home. MapiFi is a method to generate that map of the devices in\na home. The first part of MapiFi involves the user (either a technician or the\nresident) walking around the home with a mobile device that listens to Wi-Fi\nradio channels. The mobile device detects Wi-Fi packets that come from all of\nthe home's devices that connect to the gateway and measures their signal\nstrengths (ignoring the content of the packets). The second part is an\nalgorithm that uses all the signal-strength measurements to estimate the\nlocations of all the devices in the home. Then, MapiFi visualizes the home's\nspace as a coordinate system with devices marked as points in this space. A\npatent has been filed based on this technology. This paper was published in\nSCTE Technical Journal (see published paper at\nhttps://wagtail-prod-storage.s3.amazonaws.com/documents/SCTE_Technical_Journal_V1N3.pdf).",
    "descriptor": "\nComments: 6 pages, 4 figures, published in SCTE Technical Journal, patent pending at US Patent and Trademark Office\n",
    "authors": [
      "Yonatan Vaizman",
      "Hongcheng Wang"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.04473"
  },
  {
    "id": "arXiv:2202.04476",
    "title": "Counting Kernels in Directed Graphs with Arbitrary Orientations",
    "abstract": "A kernel of a directed graph is a subset of vertices that is both independent\nand absorbing (every vertex not in the kernel has an out-neighbour in the\nkernel). Not all directed graphs contain kernels, and computing a kernel or\ndeciding that none exist is NP-complete even on low-degree planar digraphs. The\nexisting polynomial-time algorithms for this problem all restrict both the\nundirected structure and the edge orientations of the input: for example, to\nchordal graphs without bidirectional edges (Pass-Lanneau, Igarashi and Meunier,\nDiscrete Appl Math 2020) or to permutation graphs where each clique has a sink\n(Abbas and Saoula, 4OR 2005). By contrast, we count the kernels of a fuzzy\ncircular interval graph in polynomial time, regardless of its edge\norientations, and return a kernel when one exists. (Fuzzy circular graphs were\nintroduced by Chudnovsky and Seymour in their structure theorem for claw-free\ngraphs.) We also consider kernels on cographs, where we establish NP-hardness\nin general but linear running times on the subclass of threshold graphs.",
    "descriptor": "\nComments: 16 pages, 3 figures\n",
    "authors": [
      "Bruno Jartoux"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2202.04476"
  },
  {
    "id": "arXiv:2202.04478",
    "title": "Rethinking Goal-conditioned Supervised Learning and Its Connection to  Offline RL",
    "abstract": "Solving goal-conditioned tasks with sparse rewards using self-supervised\nlearning is promising because of its simplicity and stability over current\nreinforcement learning (RL) algorithms. A recent work, called Goal-Conditioned\nSupervised Learning (GCSL), provides a new learning framework by iteratively\nrelabeling and imitating self-generated experiences. In this paper, we revisit\nthe theoretical property of GCSL -- optimizing a lower bound of the goal\nreaching objective, and extend GCSL as a novel offline goal-conditioned RL\nalgorithm. The proposed method is named Weighted GCSL (WGCSL), in which we\nintroduce an advanced compound weight consisting of three parts (1) discounted\nweight for goal relabeling, (2) goal-conditioned exponential advantage weight,\nand (3) best-advantage weight. Theoretically, WGCSL is proved to optimize an\nequivalent lower bound of the goal-conditioned RL objective and generates\nmonotonically improved policies via an iterated scheme. The monotonic property\nholds for any behavior policies, and therefore WGCSL can be applied to both\nonline and offline settings. To evaluate algorithms in the offline\ngoal-conditioned RL setting, we provide a benchmark including a range of point\nand simulated robot domains. Experiments in the introduced benchmark\ndemonstrate that WGCSL can consistently outperform GCSL and existing\nstate-of-the-art offline methods in the fully offline goal-conditioned setting.",
    "descriptor": "\nComments: Accepted by International Conference on Learning Representations (ICLR) 2022\n",
    "authors": [
      "Rui Yang",
      "Yiming Lu",
      "Wenzhe Li",
      "Hao Sun",
      "Meng Fang",
      "Yali Du",
      "Xiu Li",
      "Lei Han",
      "Chongjie Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.04478"
  },
  {
    "id": "arXiv:2202.04479",
    "title": "False Memory Formation in Continual Learners Through Imperceptible  Backdoor Trigger",
    "abstract": "In this brief, we show that sequentially learning new information presented\nto a continual (incremental) learning model introduces new security risks: an\nintelligent adversary can introduce small amount of misinformation to the model\nduring training to cause deliberate forgetting of a specific task or class at\ntest time, thus creating \"false memory\" about that task. We demonstrate such an\nadversary's ability to assume control of the model by injecting \"backdoor\"\nattack samples to commonly used generative replay and regularization based\ncontinual learning approaches using continual learning benchmark variants of\nMNIST, as well as the more challenging SVHN and CIFAR 10 datasets. Perhaps most\ndamaging, we show this vulnerability to be very acute and exceptionally\neffective: the backdoor pattern in our attack model can be imperceptible to\nhuman eye, can be provided at any point in time, can be added into the training\ndata of even a single possibly unrelated task and can be achieved with as few\nas just 1\\% of total training dataset of a single task.",
    "descriptor": "",
    "authors": [
      "Muhammad Umer",
      "Robi Polikar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.04479"
  },
  {
    "id": "arXiv:2202.04481",
    "title": "Minimax Rate-Distortion",
    "abstract": "We show the existence of universal, variable-rate rate-distortion codes that\nmeet the distortion constraint almost surely and approach the rate-distortion\nfunction uniformly with respect to an unknown source distribution and a\ndistortion measure that is only revealed to the encoder and only at run-time.\nIf the convergence only needs to be uniform with respect to the source\ndistribution and not the distortion measure, then we provide an explicit bound\non the minimax rate of convergence. Our construction combines conventional\nrandom coding with a zero-rate uncoded transmission scheme. The proof uses\nexact asymptotics from large deviations, acceptance-rejection sampling, the VC\ndimension of distortion measures, and the identification of an explicit,\ncode-independent, finite-blocklength quantity, which converges to the\nrate-distortion function, that controls the performance of the best codes.",
    "descriptor": "",
    "authors": [
      "Adeel Mahmood",
      "Aaron B. Wagner"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.04481"
  },
  {
    "id": "arXiv:2202.04487",
    "title": "Finding Optimal Arms in Non-stochastic Combinatorial Bandits with  Semi-bandit Feedback and Finite Budget",
    "abstract": "We consider the combinatorial bandits problem with semi-bandit feedback under\nfinite sampling budget constraints, in which the learner can carry out its\naction only for a limited number of times specified by an overall budget. The\naction is to choose a set of arms, whereupon feedback for each arm in the\nchosen set is received. Unlike existing works, we study this problem in a\nnon-stochastic setting with subset-dependent feedback, i.e., the semi-bandit\nfeedback received could be generated by an oblivious adversary and also might\ndepend on the chosen set of arms. In addition, we consider a general feedback\nscenario covering both the numerical-based as well as preference-based case and\nintroduce a sound theoretical framework for this setting guaranteeing sensible\nnotions of optimal arms, which a learner seeks to find. We suggest a generic\nalgorithm suitable to cover the full spectrum of conceivable arm elimination\nstrategies from aggressive to conservative. Theoretical questions about the\nsufficient and necessary budget of the algorithm to find the best arm are\nanswered and complemented by deriving lower bounds for any learning algorithm\nfor this problem scenario.",
    "descriptor": "",
    "authors": [
      "Jasmin Brandt",
      "Bj\u00f6rn Haddenhorst",
      "Viktor Bengs",
      "Eyke H\u00fcllermeier"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.04487"
  },
  {
    "id": "arXiv:2202.04488",
    "title": "CRAT-Pred: Vehicle Trajectory Prediction with Crystal Graph  Convolutional Neural Networks and Multi-Head Self-Attention",
    "abstract": "Predicting the motion of surrounding vehicles is essential for autonomous\nvehicles, as it governs their own motion plan. Current state-of-the-art vehicle\nprediction models heavily rely on map information. In reality, however, this\ninformation is not always available. We therefore propose CRAT-Pred, a\nmulti-modal and non-rasterization-based trajectory prediction model,\nspecifically designed to effectively model social interactions between\nvehicles, without relying on map information. CRAT-Pred applies a graph\nconvolution method originating from the field of material science to vehicle\nprediction, allowing to efficiently leverage edge features, and combines it\nwith multi-head self-attention. Compared to other map-free approaches, the\nmodel achieves state-of-the-art performance with a significantly lower number\nof model parameters. In addition to that, we quantitatively show that the\nself-attention mechanism is able to learn social interactions between vehicles,\nwith the weights representing a measurable interaction score. The source code\nis publicly available.",
    "descriptor": "\nComments: To appear in the proceedings of 2022 IEEE International Conference on Robotics and Automation (ICRA)\n",
    "authors": [
      "Julian Schmidt",
      "Julian Jordan",
      "Franz Gritschneder",
      "Klaus Dietmayer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.04488"
  },
  {
    "id": "arXiv:2202.04494",
    "title": "A Circle Grid-based Approach for Obstacle Avoidance Motion Planning of  Unmanned Surface Vehicles",
    "abstract": "Aiming at an obstacle avoidance problem with dynamic constraints for Unmanned\nSurface Vehicle (USV), a method based on Circle Grid Trajectory Cell (CGTC) is\nproposed. Firstly, the ship model and standardization rules are constructed to\ndevelop and constrain the trajectory, respectively. Secondly, by analyzing the\nproperties of the circle grid, the circle grid tree is produced to guide the\nmotion of the USV. Then, the kinematics and dynamics of the USV are considered\nthrough the on-line trajectory generator by designing a relational function\nthat links the rudder angle, heading angle, and the central angle of the circle\ngrid. Finally, obstacle avoidance is achieved by leveraging the on-line\ntrajectory generator to choose a safe, smooth, and efficient path for the USV.\nThe experimental results indicate that the proposed method can avoid both\nstatic and dynamic obstacles, have better performance in terms of distance cost\nand steering cost comparing with the related methods, and our method only takes\n50% steering cost of the grid-based method; the collision avoidance path not\nonly conforms to the USV dynamic characteristic but also provides a reference\nof steering command.",
    "descriptor": "",
    "authors": [
      "Man Zhu",
      "Changshi Xiao",
      "Shangding Gu",
      "Zhe Du",
      "Yuanqiao Wen"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.04494"
  },
  {
    "id": "arXiv:2202.04495",
    "title": "Data-driven Safe Control of Linear Systems Under Epistemic and Aleatory  Uncertainties",
    "abstract": "Safe control of constrained linear systems under both epistemic and aleatory\nuncertainties is considered. The aleatory uncertainty characterizes random\nnoises and is modeled by a probability distribution function (PDF) and the\nepistemic uncertainty characterizes the lack of knowledge on the system\ndynamics. Data-based probabilistic safe controllers are designed for the cases\nwhere the noise PDF is 1) zero-mean Gaussian with a known covariance, 2)\nzero-mean Gaussian with an uncertain covariance, and 3) zero-mean non-Gaussian\nwith an unknown distribution. Easy-to-check model-based conditions for\nguaranteeing probabilistic safety are provided for the first case by\nintroducing probabilistic contractive sets. These results are then extended to\nthe second and third cases by leveraging distributionally-robust probabilistic\nsafe control and conditional value-at-risk (CVaR) based probabilistic safe\ncontrol, respectively. Data-based implementations of these probabilistic safe\ncontrollers are then considered. It is shown that data-richness requirements\nfor directly learning a safe controller is considerably weaker than\ndata-richness requirements for model-based safe control approaches that\nundertake a model identification. Moreover, an upper bound on the minimal risk\nlevel, under which the existence of a safe controller is guaranteed, is learned\nusing collected data. A simulation example is provided to show the\neffectiveness of the proposed approach.",
    "descriptor": "",
    "authors": [
      "Hamidreza Modares"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.04495"
  },
  {
    "id": "arXiv:2202.04500",
    "title": "Contextualize Me -- The Case for Context in Reinforcement Learning",
    "abstract": "While Reinforcement Learning (RL) has made great strides towards solving\nincreasingly complicated problems, many algorithms are still brittle to even\nslight changes in environments. Contextual Reinforcement Learning (cRL)\nprovides a theoretical framework to model such changes in a principled manner,\nthereby enabling flexible, precise and interpretable task specification and\ngeneration. Thus, cRL is an important formalization for studying generalization\nin RL. In this work, we reason about solving cRL in theory and practice. We\nshow that theoretically optimal behavior in contextual Markov Decision\nProcesses requires explicit context information. In addition, we empirically\nexplore context-based task generation, utilizing context information in\ntraining and propose cGate, our state-modulating policy architecture. To this\nend, we introduce the first benchmark library designed for generalization based\non cRL extensions of popular benchmarks, CARL. In short: Context matters!",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2110.02102\n",
    "authors": [
      "Carolin Benjamins",
      "Theresa Eimer",
      "Frederik Schubert",
      "Aditya Mohan",
      "Andr\u00e9 Biedenkapp",
      "Bodo Rosenhahn",
      "Frank Hutter",
      "Marius Lindauer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.04500"
  },
  {
    "id": "arXiv:2202.04504",
    "title": "Prediction Sensitivity: Continual Audit of Counterfactual Fairness in  Deployed Classifiers",
    "abstract": "As AI-based systems increasingly impact many areas of our lives, auditing\nthese systems for fairness is an increasingly high-stakes problem. Traditional\ngroup fairness metrics can miss discrimination against individuals and are\ndifficult to apply after deployment. Counterfactual fairness describes an\nindividualized notion of fairness but is even more challenging to evaluate\nafter deployment. We present prediction sensitivity, an approach for continual\naudit of counterfactual fairness in deployed classifiers. Prediction\nsensitivity helps answer the question: would this prediction have been\ndifferent, if this individual had belonged to a different demographic group --\nfor every prediction made by the deployed model. Prediction sensitivity can\nleverage correlations between protected status and other features and does not\nrequire protected status information at prediction time. Our empirical results\ndemonstrate that prediction sensitivity is effective for detecting violations\nof counterfactual fairness.",
    "descriptor": "\nComments: 16 pages, 7 figures\n",
    "authors": [
      "Krystal Maughan",
      "Ivoline C. Ngong",
      "Joseph P. Near"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2202.04504"
  },
  {
    "id": "arXiv:2202.04509",
    "title": "Optimal learning rate schedules in high-dimensional non-convex  optimization problems",
    "abstract": "Learning rate schedules are ubiquitously used to speed up and improve\noptimisation. Many different policies have been introduced on an empirical\nbasis, and theoretical analyses have been developed for convex settings.\nHowever, in many realistic problems the loss-landscape is high-dimensional and\nnon convex -- a case for which results are scarce. In this paper we present a\nfirst analytical study of the role of learning rate scheduling in this setting,\nfocusing on Langevin optimization with a learning rate decaying as\n$\\eta(t)=t^{-\\beta}$. We begin by considering models where the loss is a\nGaussian random function on the $N$-dimensional sphere ($N\\rightarrow \\infty$),\nfeaturing an extensive number of critical points. We find that to speed up\noptimization without getting stuck in saddles, one must choose a decay rate\n$\\beta<1$, contrary to convex setups where $\\beta=1$ is generally optimal. We\nthen add to the problem a signal to be recovered. In this setting, the dynamics\ndecompose into two phases: an \\emph{exploration} phase where the dynamics\nnavigates through rough parts of the landscape, followed by a\n\\emph{convergence} phase where the signal is detected and the dynamics enter a\nconvex basin. In this case, it is optimal to keep a large learning rate during\nthe exploration phase to escape the non-convex region as quickly as possible,\nthen use the convex criterion $\\beta=1$ to converge rapidly to the solution.\nFinally, we demonstrate that our conclusions hold in a common regression task\ninvolving neural networks.",
    "descriptor": "",
    "authors": [
      "St\u00e9phane d'Ascoli",
      "Maria Refinetti",
      "Giulio Biroli"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.04509"
  },
  {
    "id": "arXiv:2202.04513",
    "title": "The no-free-lunch theorems of supervised learning",
    "abstract": "The no-free-lunch theorems promote a skeptical conclusion that all possible\nmachine learning algorithms equally lack justification. But how could this\nleave room for a learning theory, that shows that some algorithms are better\nthan others? Drawing parallels to the philosophy of induction, we point out\nthat the no-free-lunch results presuppose a conception of learning algorithms\nas purely data-driven. On this conception, every algorithm must have an\ninherent inductive bias, that wants justification. We argue that many standard\nlearning algorithms should rather be understood as model-dependent: in each\napplication they also require for input a model, representing a bias. Generic\nalgorithms themselves, they can be given a model-relative justification.",
    "descriptor": "",
    "authors": [
      "Tom F. Sterkenburg",
      "Peter D. Gr\u00fcnwald"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.04513"
  },
  {
    "id": "arXiv:2202.04514",
    "title": "A Model-Agnostic Causal Learning Framework for Recommendation using  Search Data",
    "abstract": "Machine-learning based recommender systems(RSs) has become an effective means\nto help people automatically discover their interests. Existing models often\nrepresent the rich information for recommendation, such as items, users, and\ncontexts, as embedding vectors and leverage them to predict users' feedback. In\nthe view of causal analysis, the associations between these embedding vectors\nand users' feedback are a mixture of the causal part that describes why an item\nis preferred by a user, and the non-causal part that merely reflects the\nstatistical dependencies between users and items, for example, the exposure\nmechanism, public opinions, display position, etc. However, existing RSs mostly\nignored the striking differences between the causal parts and non-causal parts\nwhen using these embedding vectors. In this paper, we propose a model-agnostic\nframework named IV4Rec that can effectively decompose the embedding vectors\ninto these two parts, hence enhancing recommendation results. Specifically, we\njointly consider users' behaviors in search scenarios and recommendation\nscenarios. Adopting the concepts in causal analysis, we embed users' search\nbehaviors as instrumental variables (IVs), to help decompose original embedding\nvectors in recommendation, i.e., treatments. IV4Rec then combines the two parts\nthrough deep neural networks and uses the combined results for recommendation.\nIV4Rec is model-agnostic and can be applied to a number of existing RSs such as\nDIN and NRHUB. Experimental results on both public and proprietary industrial\ndatasets demonstrate that IV4Rec consistently enhances RSs and outperforms a\nframework that jointly considers search and recommendation.",
    "descriptor": "\nComments: 9 pages, 7 figures, accepted by The Web Conference 2022\n",
    "authors": [
      "Zihua Si",
      "Xueran Han",
      "Xiao Zhang",
      "Jun Xu",
      "Yue Yin",
      "Yang Song",
      "Ji-Rong Wen"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2202.04514"
  },
  {
    "id": "arXiv:2202.04515",
    "title": "Leverage Score Sampling for Tensor Product Matrices in Input Sparsity  Time",
    "abstract": "We give an input sparsity time sampling algorithm for spectrally\napproximating the Gram matrix corresponding to the $q$-fold column-wise tensor\nproduct of $q$ matrices using a nearly optimal number of samples, improving\nupon all previously known methods by poly$(q)$ factors. Furthermore, for the\nimportant special care of the $q$-fold self-tensoring of a dataset, which is\nthe feature matrix of the degree-$q$ polynomial kernel, the leading term of our\nmethod's runtime is proportional to the size of the dataset and has no\ndependence on $q$. Previous techniques either incur a poly$(q)$ factor slowdown\nin their runtime or remove the dependence on $q$ at the expense of having\nsub-optimal target dimension, and depend quadratically on the number of\ndata-points in their runtime. Our sampling technique relies on a collection of\n$q$ partially correlated random projections which can be simultaneously applied\nto a dataset $X$ in total time that only depends on the size of $X$, and at the\nsame time their $q$-fold Kronecker product acts as a near-isometry for any\nfixed vector in the column span of $X^{\\otimes q}$. We show that our sampling\nmethods generalize to other classes of kernels beyond polynomial, such as\nGaussian and Neural Tangent kernels.",
    "descriptor": "",
    "authors": [
      "David P. Woodruff",
      "Amir Zandieh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2202.04515"
  },
  {
    "id": "arXiv:2202.04516",
    "title": "An approximate $C^1$ multi-patch space for isogeometric analysis with a  comparison to Nitsche's method",
    "abstract": "We present an approximately $C^1$-smooth multi-patch spline construction\nwhich can be used in isogeometric analysis (IGA). A key property of IGA is that\nit is simple to achieve high order smoothness within a single patch. To\nrepresent more complex geometries one often uses a multi-patch construction. In\nthis case, the global continuity for the basis functions is in general only\n$C^0$. Therefore, to obtain $C^1$-smooth isogeometric functions, a special\nconstruction for the basis is needed. Such spaces are of interest when solving\nnumerically fourth-order problems, such as the biharmonic equation or\nKirchhoff-Love plate/shell formulations, using an isogeometric Galerkin method.\nIsogeometric spaces that are globally $C^1$ over multi-patch domains can be\nconstructed as in (Collin, Sangalli, Takacs; CAGD, 2016) and (Kapl, Sangalli,\nTakacs; CAGD, 2019). The constructions require so-called analysis-suitable\n$G^1$ parametrizations. To allow $C^1$ spaces over more general multi-patch\nparametrizations, we need to increase the polynomial degree and relax the $C^1$\nconditions. We adopt the approximate $C^1$ construction for two-patch domains,\nas developed in (Weinm\\\"uller, Takacs; CMAME, 2021), and extend it to more\ngeneral multi-patch domains.\nWe employ the construction for a biharmonic model problem and compare the\nresults with Nitsche's method. We compare both methods over complex multi-patch\ndomains with non-trivial interfaces. The numerical tests indicate that the\nproposed construction converges optimally under $h$-refinement, comparable to\nthe solution using Nitsche's method. In contrast to weakly imposing coupling\nconditions, the approximate $C^1$ construction is explicit and no additional\nterms need to be introduced to stabilize the method. Thus, the new proposed\nmethod can be used more easily as no parameters need to be estimated.",
    "descriptor": "",
    "authors": [
      "Pascal Weinm\u00fcller",
      "Thomas Takacs"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.04516"
  },
  {
    "id": "arXiv:2202.04518",
    "title": "Protocol Insecurity with Assertions",
    "abstract": "In the study of symbolic verification of cryptographic protocols, a central\nresult due to Rusinowitch and Turuani [2003] is that the insecurity problem\n(deciding whether a protocol admits an execution which leaks a designated\nsecret to the intruder) for security protocols with finitely many sessions is\nNP-complete. Central to their proof strategy is the observation that any\nexecution of a protocol can be simulated by one where the intruder only\ncommunicates terms of bounded size. They prove this by analyzing how variables\nused in the protocol can be instantiated in different contexts by the intruder.\nHowever, when we consider protocols where, in addition to terms, some logical\nstatements or \"assertions\" about the terms (as presented by Ramanujam,\nSundararajan, and Suresh [2017]) are also communicated, the analysis of the\ninsecurity problem becomes tricky. In this paper we consider the insecurity\nproblem for protocols with a class of assertions that includes equality on\nterms and existential quantification. The intruder can potentially exploit the\nfact that witnesses for existential quantifiers may be unbounded, and obtaining\nsmall witness terms while maintaining equality proofs complicates the analysis\nconsiderably. We use a notion of well-typed equality proofs that helps in\nbounding the sizes of the terms involved, and show that the insecurity problem\nfor assertions is in NP.",
    "descriptor": "",
    "authors": [
      "R Ramanujam",
      "Vaishnavi Sundararajan",
      "S P Suresh"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2202.04518"
  },
  {
    "id": "arXiv:2202.04520",
    "title": "Obtaining Dyadic Fairness by Optimal Transport",
    "abstract": "Fairness has been taken as a critical metric on machine learning models. Many\nworks studying how to obtain fairness for different tasks emerge. This paper\nconsiders obtaining fairness for link prediction tasks, which can be measured\nby dyadic fairness. We aim to propose a pre-processing methodology to obtain\ndyadic fairness through data repairing and optimal transport. To obtain dyadic\nfairness with satisfying flexibility and unambiguity requirements, we transform\nthe dyadic repairing to the conditional distribution alignment problem based on\noptimal transport and obtain theoretical results on the connection between the\nproposed alignment and dyadic fairness. The optimal transport-based dyadic\nfairness algorithm is proposed for graph link prediction. Our proposed\nalgorithm shows superior results on obtaining fairness compared with the other\npre-processing methods on two benchmark graph datasets.",
    "descriptor": "\nComments: 7 pages, 5 figures, Accepted in the 1st International Workshop on Optimal Transport and Structured Data Modeling\n",
    "authors": [
      "Moyi Yang",
      "Junjie Sheng",
      "Xiangfeng Wang",
      "Wenyan Liu",
      "Bo Jin",
      "Jun Wang",
      "Hongyuan Zha"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.04520"
  },
  {
    "id": "arXiv:2202.04522",
    "title": "Constructing and Analyzing the LSM Compaction Design Space",
    "abstract": "Log-structured merge (LSM) trees offer efficient ingestion by appending\nincoming data, and thus, are widely used as the storage layer of production\nNoSQL data stores. To enable competitive read performance, LSM-trees\nperiodically re-organize data to form a tree with levels of exponentially\nincreasing capacity, through iterative compactions. Compactions fundamentally\ninfluence the performance of an LSM-engine in terms of write amplification,\nwrite throughput, point and range lookup performance, space amplification, and\ndelete performance. Hence, choosing the appropriate compaction strategy is\ncrucial and, at the same time, hard as the LSM-compaction design space is vast,\nlargely unexplored, and has not been formally defined in the literature. As a\nresult, most LSM-based engines use a fixed compaction strategy, typically\nhand-picked by an engineer, which decides how and when to compact data.\nIn this paper, we present the design space of LSM-compactions, and evaluate\nstate-of-the-art compaction strategies with respect to key performance metrics.\nToward this goal, our first contribution is to introduce a set of four design\nprimitives that can formally define any compaction strategy: (i) the compaction\ntrigger, (ii) the data layout, (iii) the compaction granularity, and (iv) the\ndata movement policy. Together, these primitives can synthesize both existing\nand completely new compaction strategies. Our second contribution is to\nexperimentally analyze 10 compaction strategies. We present 12 observations and\n7 high-level takeaway messages, which show how LSM systems can navigate the\ncompaction design space.",
    "descriptor": "",
    "authors": [
      "Subhadeep Sarkar",
      "Dimitris Staratzis",
      "Zichen Zhu",
      "Manos Athanassoulis"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2202.04522"
  },
  {
    "id": "arXiv:2202.04526",
    "title": "Soundiation: A multi-functional GUI-based software in evaluation of the  acoustophoresis by the acoustic radiation force and torque on arbitrary  axisymmetric objects",
    "abstract": "Acoustic radiation force and torque arising from wave scattering are commonly\nused to manipulate micro-objects without contact. We applied the partial wave\nexpansion series and the conformal transformation approach to estimate the\nradiation force and torque exerted on an axisymmetric particle. Meanwhile,\ntranslational and rotational transformations are required to keep the\ncoordinate system consistent [1]. Although these theoretical derivations have\nbeen well established, coding the required systems, including generation of the\nwave function, implementation of the transformations, calculations between\nmodules, etc., is non-trivial and time-consuming. Here, a new open-source,\nMATLAB-based software, called Soundiation, is provided to address the radiation\nforce and torque while supporting the dynamic prediction of non-spherical\nparticles. The implementation is basically generic, and its applicability is\ndemonstrated through the validation of numerical methods. Furthermore, a\ngraphical user interface is provided so that it can be used and extended\neasily.",
    "descriptor": "\nComments: 22 pages, 6 figures\n",
    "authors": [
      "Tianquan Tang",
      "Lixi Huang"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Applied Physics (physics.app-ph)"
    ],
    "url": "https://arxiv.org/abs/2202.04526"
  },
  {
    "id": "arXiv:2202.04527",
    "title": "Explainable Predictive Modeling for Limited Spectral Data",
    "abstract": "Feature selection of high-dimensional labeled data with limited observations\nis critical for making powerful predictive modeling accessible, scalable, and\ninterpretable for domain experts. Spectroscopy data, which records the\ninteraction between matter and electromagnetic radiation, particularly holds a\nlot of information in a single sample. Since acquiring such high-dimensional\ndata is a complex task, it is crucial to exploit the best analytical tools to\nextract necessary information. In this paper, we investigate the most commonly\nused feature selection techniques and introduce applying recent explainable AI\ntechniques to interpret the prediction outcomes of high-dimensional and limited\nspectral data. Interpretation of the prediction outcome is beneficial for the\ndomain experts as it ensures the transparency and faithfulness of the ML models\nto the domain knowledge. Due to the instrument resolution limitations,\npinpointing important regions of the spectroscopy data creates a pathway to\noptimize the data collection process through the miniaturization of the\nspectrometer device. Reducing the device size and power and therefore cost is a\nrequirement for the real-world deployment of such a sensor-to-prediction system\nas a whole. We specifically design three different scenarios to ensure that the\nevaluation of ML models is robust for the real-time practice of the developed\nmethodologies and to uncover the hidden effect of noise sources on the final\noutcome.",
    "descriptor": "",
    "authors": [
      "Frantishek Akulich",
      "Hadis Anahideh",
      "Manaf Sheyyab",
      "Dhananjay Ambre"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.04527"
  },
  {
    "id": "arXiv:2202.04528",
    "title": "A Multimodal Canonical-Correlated Graph Neural Network for  Energy-Efficient Speech Enhancement",
    "abstract": "This paper proposes a novel multimodal self-supervised architecture for\nenergy-efficient AV speech enhancement by integrating graph neural networks\nwith canonical correlation analysis (CCA-GNN). This builds on a\nstate-of-the-art CCA-GNN that aims to learn representative embeddings by\nmaximizing the correlation between pairs of augmented views of the same input\nwhile decorrelating disconnected features. The key idea of the conventional\nCCA-GNN involves discarding augmentation-variant information and preserving\naugmentation-invariant information whilst preventing capturing of redundant\ninformation. Our proposed AV CCA-GNN model is designed to deal with the\nchallenging multimodal representation learning context. Specifically, our model\nimproves contextual AV speech processing by maximizing canonical correlation\nfrom augmented views of the same channel, as well as canonical correlation from\naudio and visual embeddings. In addition, we propose a positional encoding of\nthe nodes that considers a prior-frame sequence distance instead of a\nfeature-space representation while computing the node's nearest neighbors. This\nserves to introduce temporal information in the embeddings through the\nneighborhood's connectivity. Experiments conducted with the benchmark ChiME3\ndataset show that our proposed prior frame-based AV CCA-GNN reinforces better\nfeature learning in the temporal context, leading to more energy-efficient\nspeech reconstruction compared to state-of-the-art CCA-GNN and multi-layer\nperceptron models. The results demonstrate the potential of our proposed\napproach for exploitation in future assistive technology and energy-efficient\nmultimodal devices.",
    "descriptor": "",
    "authors": [
      "Leandro Aparecido Passos",
      "Jo\u00e3o Paulo Papa",
      "Amir Hussain",
      "Ahsan Adeel"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2202.04528"
  },
  {
    "id": "arXiv:2202.04530",
    "title": "An Exploration of Multicalibration Uniform Convergence Bounds",
    "abstract": "Recent works have investigated the sample complexity necessary for fair\nmachine learning. The most advanced of such sample complexity bounds are\ndeveloped by analyzing multicalibration uniform convergence for a given\npredictor class. We present a framework which yields multicalibration error\nuniform convergence bounds by reparametrizing sample complexities for Empirical\nRisk Minimization (ERM) learning. From this framework, we demonstrate that\nmulticalibration error exhibits dependence on the classifier architecture as\nwell as the underlying data distribution. We perform an experimental evaluation\nto investigate the behavior of multicalibration error for different families of\nclassifiers. We compare the results of this evaluation to multicalibration\nerror concentration bounds. Our investigation provides additional perspective\non both algorithmic fairness and multicalibration error convergence bounds.\nGiven the prevalence of ERM sample complexity bounds, our proposed framework\nenables machine learning practitioners to easily understand the convergence\nbehavior of multicalibration error for a myriad of classifier architectures.",
    "descriptor": "",
    "authors": [
      "Harrison Rosenberg",
      "Robi Bhattacharjee",
      "Kassem Fawaz",
      "Somesh Jha"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.04530"
  },
  {
    "id": "arXiv:2202.04533",
    "title": "NIMBLE: A Non-rigid Hand Model with Bones and Muscles",
    "abstract": "Emerging Metaverse applications demand reliable, accurate, and photorealistic\nreproductions of human hands to perform sophisticated operations as if in the\nphysical world. While real human hand represents one of the most intricate\ncoordination between bones, muscle, tendon, and skin, state-of-the-art\ntechniques unanimously focus on modeling only the skeleton of the hand. In this\npaper, we present NIMBLE, a novel parametric hand model that includes the\nmissing key components, bringing 3D hand model to a new level of realism. We\nfirst annotate muscles, bones and skins on the recent Magnetic Resonance\nImaging hand (MRI-Hand) dataset and then register a volumetric template hand\nonto individual poses and subjects within the dataset. NIMBLE consists of 20\nbones as triangular meshes, 7 muscle groups as tetrahedral meshes, and a skin\nmesh. Via iterative shape registration and parameter learning, it further\nproduces shape blend shapes, pose blend shapes, and a joint regressor. We\ndemonstrate applying NIMBLE to modeling, rendering, and visual inference tasks.\nBy enforcing the inner bones and muscles to match anatomic and kinematic rules,\nNIMBLE can animate 3D hands to new poses at unprecedented realism. To model the\nappearance of skin, we further construct a photometric HandStage to acquire\nhigh-quality textures and normal maps to model wrinkles and palm print.\nFinally, NIMBLE also benefits learning-based hand pose and shape estimation by\neither synthesizing rich data or acting directly as a differentiable layer in\nthe inference network.",
    "descriptor": "\nComments: 16 pages, 18 figures\n",
    "authors": [
      "Yuwei Li",
      "Longwen Zhang",
      "Zesong Qiu",
      "Yingwenqi Jiang",
      "Yuyao Zhang",
      "Nianyi Li",
      "Yuexin Ma",
      "Lan Xu",
      "Jingyi Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2202.04533"
  },
  {
    "id": "arXiv:2202.04537",
    "title": "Time complexity analysis of quantum difference methods for linear high  dimensional and multiscale partial differential equations",
    "abstract": "We investigate time complexities of finite difference methods for solving the\nhigh-dimensional linear heat equation, the high-dimensional linear hyperbolic\nequation and the multiscale hyperbolic heat system with quantum algorithms\n(hence referred to as the \"quantum difference methods\"). Our detailed analyses\nshow that for the heat and linear hyperbolic equations the quantum difference\nmethods provide exponential speedup over the classical difference method with\nrespect to the spatial dimension. For the multiscale problem, the time\ncomplexity of both the classical treatment and quantum treatment for the\nexplicit scheme scales as $O(1/\\varepsilon)$, where $\\varepsilon$ is the\nscaling parameter, while the scaling for the Asymptotic-Preserving (AP) schemes\ndoes not depend on $\\varepsilon$. This indicates that it is still of great\nimportance to develop AP schemes for multiscale problems in quantum computing.",
    "descriptor": "\nComments: quantum difference methods\n",
    "authors": [
      "Shi Jin",
      "Nana Liu",
      "Yue Yu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Mathematical Physics (math-ph)"
    ],
    "url": "https://arxiv.org/abs/2202.04537"
  },
  {
    "id": "arXiv:2202.04538",
    "title": "Generating Training Data with Language Models: Towards Zero-Shot  Language Understanding",
    "abstract": "Pretrained language models (PLMs) have demonstrated remarkable performance in\nvarious natural language processing tasks: Unidirectional PLMs (e.g., GPT) are\nwell known for their superior text generation capabilities; bidirectional PLMs\n(e.g., BERT) have been the prominent choice for natural language understanding\n(NLU) tasks. While both types of models have achieved promising few-shot\nlearning performance, their potential for zero-shot learning has been\nunderexplored. In this paper, we present a simple approach that uses both types\nof PLMs for fully zero-shot learning of NLU tasks without requiring any\ntask-specific data: A unidirectional PLM generates class-conditioned texts\nguided by prompts, which are used as the training data for fine-tuning a\nbidirectional PLM. With quality training data selected based on the generation\nprobability and regularization techniques (label smoothing and temporal\nensembling) applied to the fine-tuning stage for better generalization and\nstability, our approach demonstrates strong performance across seven\nclassification tasks of the GLUE benchmark (e.g., 72.3/73.8 on MNLI-m/mm and\n92.8 on SST-2), significantly outperforming zero-shot prompting methods and\nachieving even comparable results to strong few-shot approaches using 32\ntraining samples per class.",
    "descriptor": "\nComments: Code: this https URL\n",
    "authors": [
      "Yu Meng",
      "Jiaxin Huang",
      "Yu Zhang",
      "Jiawei Han"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.04538"
  },
  {
    "id": "arXiv:2202.04539",
    "title": "Dynamic self-triggered control for nonlinear systems with delays",
    "abstract": "Self-triggered control (STC) is a resource efficient approach to determine\nsampling instants for Networked Control Systems (NCS). Recently, a dynamic STC\nstrategy based on hybrid Lyapunov functions for nonlinear NCS has been proposed\nin Hertneck and Allg\\\"ower (2021b), however with the limitation to NCS without\ntransmission delays. In this paper, we extend this strategy for nonlinear NCS\nwith transmission delays. The capability to handle systems with delays makes it\npossible to use the resulting dynamic STC mechanism in many practical scenarios\nwhere instant transmissions without delays cannot be guaranteed. The proposed\ndynamic STC mechanism guarantees stability despite bounded transmission delays.\nThe effectiveness of the mechanism is illustrated with a numerical example and\ncompared to state-of-the art literature.",
    "descriptor": "",
    "authors": [
      "Michael Hertneck",
      "Frank Allg\u00f6wer"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.04539"
  },
  {
    "id": "arXiv:2202.04541",
    "title": "Sparse superposition codes under VAMP decoding with generic rotational  invariant coding matrices",
    "abstract": "Sparse superposition codes were originally proposed as a capacity-achieving\ncommunication scheme over the gaussian channel, whose coding matrices were made\nof i.i.d. gaussian entries.We extend this coding scheme to more generic\nensembles of rotational invariant coding matrices with arbitrary spectrum,\nwhich include the gaussian ensemble as a special case. We further introduce and\nanalyse a decoder based on vector approximate message-passing (VAMP).Our main\nfindings, based on both a standard replica symmetric potential theory and state\nevolution analysis, are the superiority of certain structured ensembles of\ncoding matrices (such as partial row-orthogonal) when compared to i.i.d.\nmatrices, as well as a spectrum-independent upper bound on VAMP's threshold.\nMost importantly, we derive a simple \"spectral criterion \" for the scheme to be\nat the same time capacity-achieving while having the best possible algorithmic\nthreshold, in the \"large section size\" asymptotic limit. Our results therefore\nprovide practical design principles for the coding matrices in this promising\ncommunication scheme.",
    "descriptor": "\nComments: Submitted to the 2022 IEEE International Symposium on Information Theory (ISIT)\n",
    "authors": [
      "TianQi Hou",
      "YuHao Liu",
      "Teng Fu",
      "Jean Barbier"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)"
    ],
    "url": "https://arxiv.org/abs/2202.04541"
  },
  {
    "id": "arXiv:2202.04546",
    "title": "Proving Non-Termination and Lower Runtime Bounds with LoAT (System  Description)",
    "abstract": "We present the new version of the Loop Acceleration Tool (LoAT), a powerful\ntool for proving non-termination and worst-case lower bounds for programs\noperating on integers. It is based on novel calculi for loop acceleration,\ni.e., transforming loops into non-deterministic straight-line code, and for\nfinding non-terminating configurations. To implement them efficiently, LoAT\nuses a new approach based on SMT solving and unsat cores. An extensive\nevaluation shows that LoAT is highly competitive with other state-of-the-art\ntools for proving non-termination. While no other tool is able to deduce\nworst-case lower bounds for full integer programs, we also demonstrate that\nLoAT significantly outperforms its predecessors.",
    "descriptor": "",
    "authors": [
      "Florian Frohn",
      "J\u00fcrgen Giesl"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2202.04546"
  },
  {
    "id": "arXiv:2202.04547",
    "title": "Self-Sensing Hysteresis-Type Bearingless Motor",
    "abstract": "Bearingless motors use a single stator assembly to apply torque and magnetic\nsuspension forces on the rotor, making these machines compact with frictionless\noperation and thus well suited to high-speed applications. One major challenge\nthat prevents wide usage of bearingless motors is the need for air-gap position\nsensors, which are typically expensive. Here we present a method to estimate\nthe radial position of a hysteresis-type bearingless motor using the inductance\nvariation of the stator coils amplified by an injected high-frequency signal.\nWe have carried out finite element (FE) simulations to demonstrate its\nfeasibility, and have constructed a prototype self-sensing bearingless motor\nfor experimental validations.",
    "descriptor": "",
    "authors": [
      "Laura Homiller",
      "Lei Zhou"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.04547"
  },
  {
    "id": "arXiv:2202.04550",
    "title": "Integrated routing for a vehicle-robot pickup and delivery system with  time constraints",
    "abstract": "This paper considers an unmanned vehicle-robot pickup and delivery system, in\nwhich a self-driving vehicle carrying multiple unmanned robots in the form of\nthe mother ship travels from a depot to a number of stations distributed in a\nneighborhood to perform multiple pickup and delivery services. First of all, we\npresent it as a Multi-modal Vehicle Routing Problem (MMVRP) with time\nconstraints, which are typical service requirements for grocery and food\ndelivery in practice. We then formulate it as a Mixed Integer Quadratically\nCon-strained Program (MIQCP) model to determine the optimal integrated routing\nplan (vehicle routing and robot routing) to minimize the total weighted\ntardiness of all services. Finally, a small-size and a medium-size problem\ninstance are solved using the Gurobi solver in Python to demonstrate the\nvalidity and the performance of the proposed MIQCP model.",
    "descriptor": "\nComments: Accepted by the IEEE 9th International Conference on Industrial Engineering and Applications (ICIEA 2022). Date: December 2021. Email: zhaoyuan@hi.is, zhaoyuan.epslab@gmail.com\n",
    "authors": [
      "Yongjian Li",
      "Yan Chen",
      "Gaicong Guo",
      "Huiwen Wu",
      "Zhao Yuan"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2202.04550"
  },
  {
    "id": "arXiv:2202.04551",
    "title": "Shortest Paths without a Map, but with an Entropic Regularizer",
    "abstract": "In a 1989 paper titled \"shortest paths without a map\", Papadimitriou and\nYannakakis introduced an online model of searching in a weighted layered graph\nfor a target node, while attempting to minimize the total length of the path\ntraversed by the searcher. This problem, later called layered graph traversal,\nis parametrized by the maximum cardinality $k$ of a layer of the input graph.\nIt is an online setting for dynamic programming, and it is known to be a rather\ngeneral and fundamental model of online computing, which includes as special\ncases other acclaimed models. The deterministic competitive ratio for this\nproblem was soon discovered to be exponential in $k$, and it is now nearly\nresolved: it lies between $\\Omega(2^k)$ and $O(k2^k)$. Regarding the randomized\ncompetitive ratio, in 1993 Ramesh proved, surprisingly, that this ratio has to\nbe at least $\\Omega(k^2 / \\log^{1+\\epsilon} k)$ (for any constant $\\epsilon >\n0$). In the same paper, Ramesh also gave an $O(k^{13})$-competitive randomized\nonline algorithm. Since 1993, no progress has been reported on the randomized\ncompetitive ratio of layered graph traversal. In this work we show how to apply\nthe mirror descent framework on a carefully selected evolving metric space, and\nobtain an $O(k^2)$-competitive randomized online algorithm, nearly matching the\nknown lower bound on the randomized competitive ratio.",
    "descriptor": "",
    "authors": [
      "S\u00e9bastien Bubeck",
      "Christian Coester",
      "Yuval Rabani"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2202.04551"
  },
  {
    "id": "arXiv:2202.04554",
    "title": "Real-time decision-making for autonomous vehicles under faults",
    "abstract": "This paper addresses the challenges of decision-making for autonomous\nvehicles under faults during a transport mission. A real-time decision-making\nproblem of vehicle routing planning considering maintenance management is\nformulated as an optimization problem. The goal is to minimize the total time\nto finish the transport mission by selecting the optimal workshop to conduct\nthe maintenance and the corresponding routes. Two methods are proposed to solve\nthe optimization problem based on two methods of fundamental solutions: (1)\nMixed Integer Programming; (2) Dijkstra's algorithm. We adapt these methods to\nsolve the optimization problem and consider improving the computation\nefficiency. Numerical studies of test cases of highway and urban scenarios are\npresented to demonstrate the proposed methods, which show the feasibility and\nhigh computational efficiency of both methods.",
    "descriptor": "\nComments: Accepted by the IEEE 9th International Conference on Industrial Engineering and Applications (ICIEA 2022). Date: November 2021. Email: taoxin@kth.se, zhaoyuan@hi.is, zhaoyuan.epslab@gmail.com\n",
    "authors": [
      "Xin Tao",
      "Zhao Yuan"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2202.04554"
  },
  {
    "id": "arXiv:2202.04557",
    "title": "Universal Hopfield Networks: A General Framework for Single-Shot  Associative Memory Models",
    "abstract": "A large number of neural network models of associative memory have been\nproposed in the literature. These include the classical Hopfield networks\n(HNs), sparse distributed memories (SDMs), and more recently the modern\ncontinuous Hopfield networks (MCHNs), which possesses close links with\nself-attention in machine learning. In this paper, we propose a general\nframework for understanding the operation of such memory networks as a sequence\nof three operations: similarity, separation, and projection. We derive all\nthese memory models as instances of our general framework with differing\nsimilarity and separation functions. We extend the mathematical framework of\nKrotov et al (2020) to express general associative memory models using neural\nnetwork dynamics with only second-order interactions between neurons, and\nderive a general energy function that is a Lyapunov function of the dynamics.\nFinally, using our framework, we empirically investigate the capacity of using\ndifferent similarity functions for these associative memory models, beyond the\ndot product similarity measure, and demonstrate empirically that Euclidean or\nManhattan distance similarity metrics perform substantially better in practice\non many tasks, enabling a more robust retrieval and higher memory capacity than\nexisting models.",
    "descriptor": "\nComments: 09/02/22 initial upload\n",
    "authors": [
      "Beren Millidge",
      "Tommaso Salvatori",
      "Yuhang Song",
      "Thomas Lukasiewicz",
      "Rafal Bogacz"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.04557"
  },
  {
    "id": "arXiv:2202.04560",
    "title": "The craft and coordination of data curation: complicating \"workflow\"  views of data science",
    "abstract": "Data curation is the process of making a dataset fit-for-use and archiveable.\nIt is critical to data-intensive science because it makes complex data\npipelines possible, makes studies reproducible, and makes data (re)usable. Yet\nthe complexities of the hands-on, technical and intellectual work of data\ncuration is frequently overlooked or downplayed. Obscuring the work of data\ncuration not only renders the labor and contributions of the data curators\ninvisible; it also makes it harder to tease out the impact curators' work has\non the later usability, reliability, and reproducibility of data. To better\nunderstand the specific work of data curation -- and thereby, explore ways of\nshowing curators' impact -- we conducted a close examination of data curation\nat a large social science data repository, the Inter-university Consortium of\nPolitical and Social Research (ICPSR). We asked, What does curatorial work\nentail at ICPSR, and what work is more or less visible to different\nstakeholders and in different contexts? And, how is that curatorial work\ncoordinated across the organization? We triangulate accounts of data curation\nfrom interviews and records of curation in Jira tickets to develop a rich and\ndetailed account of curatorial work. We find that curators describe a number of\ncraft practices needed to perform their work, which defies the rote sequence of\nevents implied by many lifecycle or workflow models. Further, we show how best\npractices and craft practices are deeply intertwined.",
    "descriptor": "\nComments: submitted to CSCW 2022 (Feb revision cycle)\n",
    "authors": [
      "Andrea K. Thomer",
      "Dharma Akmon",
      "Jeremy York",
      "Allison R. B. Tyler",
      "Faye Polasek",
      "Sara Lafia",
      "Libby Hemphill",
      "Elizabeth Yakel"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Databases (cs.DB)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2202.04560"
  },
  {
    "id": "arXiv:2202.04561",
    "title": "Erasing Labor with Labor: Dark Patterns and Lockstep Behaviors on the  Google Play Store",
    "abstract": "Google Play Store's policy forbids the use of incentivized installs, ratings,\nand reviews to manipulate the placement of apps. However, there still exist\napps that incentivize installs for other apps on the platform. To understand\nhow install-incentivizing apps affect their users, we examine their ecosystem\nthrough a socio-technical lens and perform a longitudinal mixed-methods\nanalysis of their reviews. We shortlist 60 install-incentivizing apps which\ncollectively account for over 160.5M installs on the Google Play Store. We\ncollect 1,000 most relevant reviews on these apps every day for a period of 52\ndays. First, our qualitative analysis reveals various types of dark patterns\nthat developers incorporate in install-incentivizing apps to extort services\nand build market at the expense of their users. Second, we highlight the\nnormative concerns of these dark patterns at both the individual and collective\nlevels, elaborating on their detrimental effects on the price transparency and\ntrust in the market of Google Play Store. Third, we uncover evidence of\ninstall-incentivizing apps indulging in review and rating fraud. Building upon\nour findings, we model apps and reviewers as networks and discover lockstep\nbehaviors in the reviewing patterns that are strong indicators of review fraud.\nFourth, we leverage the content information of reviews to find that reviewers\nwho co-review more apps also show greater similarity in the content of their\nreviews, making them more suspicious. Finally, we conclude with a discussion on\nhow our future work will generate implications for Google Play Store to prevent\nthe exploitation of users while preserving transparency and trust in its\nmarket.",
    "descriptor": "",
    "authors": [
      "Ashwin S",
      "Arvindh A",
      "Ayushi Jain",
      "Pooja Desur",
      "Pulak Malhotra",
      "Duen Horng Chau",
      "Ponnurangam Kumaraguru"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2202.04561"
  },
  {
    "id": "arXiv:2202.04567",
    "title": "Optimal Hyperparameters and Structure Setting of Multi-Objective Robust  CNN Systems via Generalized Taguchi Method and Objective Vector Norm",
    "abstract": "Recently, Machine Learning (ML), Artificial Intelligence (AI), and\nConvolutional Neural Network (CNN) have made huge progress with broad\napplications, where their systems have deep learning structures and a large\nnumber of hyperparameters that determine the quality and performance of the\nCNNs and AI systems. These systems may have multi-objective ML and AI\nperformance needs. There is a key requirement to find the optimal\nhyperparameters and structures for multi-objective robust optimal CNN systems.\nThis paper proposes a generalized Taguchi approach to effectively determine the\noptimal hyperparameters and structure for the multi-objective robust optimal\nCNN systems via their objective performance vector norm. The proposed approach\nand methods are applied to a CNN classification system with the original ResNet\nfor CIFAR-10 dataset as a demonstration and validation, which shows the\nproposed methods are highly effective to achieve an optimal accuracy rate of\nthe original ResNet on CIFAR-10.",
    "descriptor": "\nComments: 10 pages. Corresponding Author: Sheng-Guo Wang, swang@uncc.edu\n",
    "authors": [
      "Sheng-Guo Wang",
      "Shanshan Jiang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2202.04567"
  },
  {
    "id": "arXiv:2202.04568",
    "title": "A note on the conservation properties of the generalized-$\u03b1$ method",
    "abstract": "We show that the second-order accurate generalized-$\\alpha$ method on a\nuniform temporal mesh may be viewed as an implicit midpoint method on a shifted\ntemporal mesh. With this insight, we demonstrate generalized-$\\alpha$ time\nintegration of a finite element spatial discretization of a conservation law\nsystem results in a fully-discrete method admitting discrete balance laws when\n(i) the time integration is second-order accurate, (ii) a uniform temporal mesh\nis employed, (iii) the spatial discretization is conservative, and (iv)\nconservation variables are discretized.",
    "descriptor": "",
    "authors": [
      "DeAnna S. Gilchrist",
      "John A. Evans"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.04568"
  },
  {
    "id": "arXiv:2202.04575",
    "title": "Soft Robots Learn to Crawl: Jointly Optimizing Design and Control with  Sim-to-Real Transfer",
    "abstract": "This work provides a complete framework for the simulation, co-optimization,\nand sim-to-real transfer of the design and control of soft legged robots. The\ncompliance of soft robots provides a form of \"mechanical intelligence\" -- the\nability to passively exhibit behaviors that would otherwise be difficult to\nprogram. Exploiting this capacity requires careful consideration of the\ncoupling between mechanical design and control. Co-optimization provides a\npromising means to generate sophisticated soft robots by reasoning over this\ncoupling. However, the complex nature of soft robot dynamics makes it difficult\nto provide a simulation environment that is both sufficiently accurate to allow\nfor sim-to-real transfer, while also being fast enough for contemporary\nco-optimization algorithms. In this work, we show that finite element\nsimulation combined with recent model order reduction techniques provide both\nthe efficiency and the accuracy required to successfully learn effective soft\nrobot design-control pairs that transfer to reality. We propose a reinforcement\nlearning-based framework for co-optimization and demonstrate successful\noptimization, construction, and zero-shot sim-to-real transfer of several soft\ncrawling robots. Our learned robot outperforms an expert-designed crawling\nrobot, showing that our approach can generate novel, high-performing designs\neven in well-understood domains.",
    "descriptor": "",
    "authors": [
      "Charles Schaff",
      "Audrey Sedal",
      "Matthew R. Walter"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.04575"
  },
  {
    "id": "arXiv:2202.04579",
    "title": "Neural Sheaf Diffusion: A Topological Perspective on Heterophily and  Oversmoothing in GNNs",
    "abstract": "Cellular sheaves equip graphs with \"geometrical\" structure by assigning\nvector spaces and linear maps to nodes and edges. Graph Neural Networks (GNNs)\nimplicitly assume a graph with a trivial underlying sheaf. This choice is\nreflected in the structure of the graph Laplacian operator, the properties of\nthe associated diffusion equation, and the characteristics of the convolutional\nmodels that discretise this equation. In this paper, we use cellular sheaf\ntheory to show that the underlying geometry of the graph is deeply linked with\nthe performance of GNNs in heterophilic settings and their oversmoothing\nbehaviour. By considering a hierarchy of increasingly general sheaves, we study\nhow the ability of the sheaf diffusion process to achieve linear separation of\nthe classes in the infinite time limit expands. At the same time, we prove that\nwhen the sheaf is non-trivial, discretised parametric diffusion processes have\ngreater control than GNNs over their asymptotic behaviour. On the practical\nside, we study how sheaves can be learned from data. The resulting sheaf\ndiffusion models have many desirable properties that address the limitations of\nclassical graph diffusion equations (and corresponding GNN models) and obtain\nstate-of-the-art results in heterophilic settings. Overall, our work provides\nnew connections between GNNs and algebraic topology and would be of interest to\nboth fields.",
    "descriptor": "\nComments: 23 pages, 8 figures\n",
    "authors": [
      "Cristian Bodnar",
      "Francesco Di Giovanni",
      "Benjamin Paul Chamberlain",
      "Pietro Li\u00f2",
      "Michael M. Bronstein"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Algebraic Topology (math.AT)"
    ],
    "url": "https://arxiv.org/abs/2202.04579"
  },
  {
    "id": "arXiv:2202.04582",
    "title": "Topic Discovery via Latent Space Clustering of Pretrained Language Model  Representations",
    "abstract": "Topic models have been the prominent tools for automatic topic discovery from\ntext corpora. Despite their effectiveness, topic models suffer from several\nlimitations including the inability of modeling word ordering information in\ndocuments, the difficulty of incorporating external linguistic knowledge, and\nthe lack of both accurate and efficient inference methods for approximating the\nintractable posterior. Recently, pretrained language models (PLMs) have brought\nastonishing performance improvements to a wide variety of tasks due to their\nsuperior representations of text. Interestingly, there have not been standard\napproaches to deploy PLMs for topic discovery as better alternatives to topic\nmodels. In this paper, we begin by analyzing the challenges of using PLM\nrepresentations for topic discovery, and then propose a joint latent space\nlearning and clustering framework built upon PLM embeddings. In the latent\nspace, topic-word and document-topic distributions are jointly modeled so that\nthe discovered topics can be interpreted by coherent and distinctive terms and\nmeanwhile serve as meaningful summaries of the documents. Our model effectively\nleverages the strong representation power and superb linguistic features\nbrought by PLMs for topic discovery, and is conceptually simpler than topic\nmodels. On two benchmark datasets in different domains, our model generates\nsignificantly more coherent and diverse topics than strong topic models, and\noffers better topic-wise document representations, based on both automatic and\nhuman evaluations.",
    "descriptor": "\nComments: WWW 2022. (Code: this https URL)\n",
    "authors": [
      "Yu Meng",
      "Yunyi Zhang",
      "Jiaxin Huang",
      "Yu Zhang",
      "Jiawei Han"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.04582"
  },
  {
    "id": "arXiv:2202.04586",
    "title": "Supporting Developers in Vulnerability Detection during Code Review:  Mental Attitude and Security Checklists",
    "abstract": "Reviewing source code from a security perspective has proven to be a\ndifficult task. Indeed, previous research has shown that developers often miss\neven popular and easy-to-detect vulnerabilities during code review. Initial\nevidence suggests that a significant cause may lie in the reviewers' mental\nattitude and common practices. In this study, we investigate whether and how\nexplicitly asking developers to focus on security during a code review affects\nthe detection of vulnerabilities. Furthermore, we evaluate the effect of\nproviding a security checklist to guide the security review. To this aim, we\nconduct an online experiment with 150 participants, of which 71% report to have\nthree or more years of professional development experience. Our results show\nthat simply asking reviewers to focus on security during the code review\nincreases eight times the probability of vulnerability detection. The presence\nof a security checklist does not significantly improve the outcome further,\neven when the checklist is tailored to the change under review and the existing\nvulnerabilities in the change. These results provide evidence supporting the\nmental attitude hypothesis and call for further work on security checklists'\neffectiveness and design. Data and materials:\nhttps://doi.org/10.5281/zenodo.6026291",
    "descriptor": "\nComments: This paper has been accepted at ICSE 2022 (44th ACM/IEEE International Conference on Software Engineering)\n",
    "authors": [
      "Larissa Braz",
      "Christian Aeberhard",
      "G\u00fcl \u00c7alikli",
      "Alberto Bacchelli"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2202.04586"
  },
  {
    "id": "arXiv:2202.04593",
    "title": "Stochastic Contextual Dueling Bandits under Linear Stochastic  Transitivity Models",
    "abstract": "We consider the regret minimization task in a dueling bandits problem with\ncontext information. In every round of the sequential decision problem, the\nlearner makes a context-dependent selection of two choice alternatives (arms)\nto be compared with each other and receives feedback in the form of noisy\npreference information. We assume that the feedback process is determined by a\nlinear stochastic transitivity model with contextualized utilities (CoLST), and\nthe learner's task is to include the best arm (with highest latent\ncontext-dependent utility) in the duel. We propose a computationally efficient\nalgorithm, $\\texttt{CoLSTIM}$, which makes its choice based on imitating the\nfeedback process using perturbed context-dependent utility estimates of the\nunderlying CoLST model. If each arm is associated with a $d$-dimensional\nfeature vector, we show that $\\texttt{CoLSTIM}$ achieves a regret of order\n$\\tilde O( \\sqrt{dT})$ after $T$ learning rounds. Additionally, we also\nestablish the optimality of $\\texttt{CoLSTIM}$ by showing a lower bound for the\nweak regret that refines the existing average regret analysis. Our experiments\ndemonstrate its superiority over state-of-art algorithms for special cases of\nCoLST models.",
    "descriptor": "",
    "authors": [
      "Viktor Bengs",
      "Aadirupa Saha",
      "Eyke H\u00fcllermeier"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.04593"
  },
  {
    "id": "arXiv:2202.04594",
    "title": "A Nonlinear Proportional Integral Disturbance Observer and Motion  Control Technique for Permanent Magnet Synchronous Motors",
    "abstract": "In this paper, we present a Nonlinear-Proportional Integrator (N-PI)\ndisturbance observer (DOB) to enhance the motion tracking of the performance of\na surface-mounted Permanent Magnet Synchronous Motor (SPMSM) in rapidly speed\nvarying regions. By presenting an N-PI-DOB for load torque estimation with\ntorque modulation technique, we show that the tracking error dynamics of\nangular position/velocity are coupled with tracking errors of currents loop and\nestimation errors. After analyzing disturbances of currents tracking error\ndynamics, we design the N-PI-DOB and Lyapunov-based nonlinear currents\ncontroller to enhance the motion tracking performances. With these N-PI-DOBs\nand motion controllers, we analyze the stability of motion tracking error\ndynamics and estimation error dynamics. We experimentally perform a comparative\nstudy with/without the N-PI-DOB to verify the effectiveness of the proposed\nmethod in the condition of the unknown load torque and rapidly speed-varying.",
    "descriptor": "",
    "authors": [
      "Yong Woo Jeong",
      "Chung Choo Chung"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.04594"
  },
  {
    "id": "arXiv:2202.04599",
    "title": "Missing Data Imputation and Acquisition with Deep Hierarchical Models  and Hamiltonian Monte Carlo",
    "abstract": "Variational Autoencoders (VAEs) have recently been highly successful at\nimputing and acquiring heterogeneous missing data and identifying outliers.\nHowever, within this specific application domain, existing VAE methods are\nrestricted by using only one layer of latent variables and strictly Gaussian\nposterior approximations. To address these limitations, we present HH-VAEM, a\nHierarchical VAE model for mixed-type incomplete data that uses Hamiltonian\nMonte Carlo with automatic hyper-parameter tuning for improved approximate\ninference. Our experiments show that HH-VAEM outperforms existing baselines in\nthe tasks of missing data imputation, supervised learning and outlier\nidentification with missing features. Finally, we also present a sampling-based\napproach for efficiently computing the information gain when missing features\nare to be acquired with HH-VAEM. Our experiments show that this sampling-based\napproach is superior to alternatives based on Gaussian approximations.",
    "descriptor": "",
    "authors": [
      "Ignacio Peis",
      "Chao Ma",
      "Jos\u00e9 Miguel Hern\u00e1ndez-Lobato"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.04599"
  },
  {
    "id": "arXiv:2202.04606",
    "title": "New hard benchmark functions for global optimization",
    "abstract": "In this paper, we present some new unimodal, multimodal and noise test\nfunctions to assess the performance of global optimization algorithms. All the\ntest functions are multidimensional problems. The 2-dimension landscape of the\nproposed function has been graphically presented in 3D space to show their\ngeometry, however these functions are more complicated in dimensions greater\nthan 3. To show the hardness of these function, we have made an experimental\nstudy with some powerful algorithms such as CEC competition winners: LSHADE,\nMadDe, and LSHADE-SPACMA algorithms. Besides the novel algorithm Tangent search\nalgorithm (TSA) and its modified Tangent search algorithm (mTSA) were also used\nin the experimental study. The results found demonstrate the hardness of the\nproposed functions.",
    "descriptor": "",
    "authors": [
      "Abdesslem Layeb"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2202.04606"
  },
  {
    "id": "arXiv:2202.04611",
    "title": "Task Modifiers for HTN Planning and Acting",
    "abstract": "The ability of an agent to change its objectives in response to unexpected\nevents is desirable in dynamic environments. In order to provide this\ncapability to hierarchical task network (HTN) planning, we propose an extension\nof the paradigm called task modifiers, which are functions that receive a task\nlist and a state and produce a new task list. We focus on a particular type of\nproblems in which planning and execution are interleaved and the ability to\nhandle exogenous events is crucial. To determine the efficacy of this approach,\nwe evaluate the performance of our task modifier implementation in two\nenvironments, one of which is a simulation that differs substantially from\ntraditional HTN domains.",
    "descriptor": "\nComments: Presented at The Ninth Advances in Cognitive Systems (ACS) Conference 2021 (arXiv:2201.06134)\n",
    "authors": [
      "Weihang Yuan",
      "Hector Munoz-Avila",
      "Venkatsampath Raja Gogineni",
      "Sravya Kondrakunta",
      "Michael Cox",
      "Lifang He"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.04611"
  },
  {
    "id": "arXiv:2202.04613",
    "title": "Distance Estimation and Animal Tracking for Wildlife Camera Trapping",
    "abstract": "The ongoing biodiversity crysis calls for accurate estimation of animal\ndensity and abundance to identify, for example, sources of biodiversity decline\nand effectiveness of conservation interventions. Camera traps together with\nabundance estimation methods are often employed for this purpose. The necessary\ndistances between camera and observed animal are traditionally derived in a\nlaborious, fully manual or semi-automatic process. Both approaches require\nreference image material, which is both difficult to acquire and not available\nfor existing datasets. In this study, we propose a fully automatic approach to\nestimate camera-to-animal distances, based on monocular depth estimation (MDE),\nand without the need of reference image material. We leverage state-of-the-art\nrelative MDE and a novel alignment procedure to estimate metric distances. We\nevaluate the approach on a zoo scenario dataset unseen during training. We\nachieve a mean absolute distance estimation error of only 0.9864 meters at a\nprecision of 90.3% and recall of 63.8%, while completely eliminating the\npreviously required manual effort for biodiversity researchers. The code will\nbe made available.",
    "descriptor": "",
    "authors": [
      "Peter Johanns",
      "Timm Haucke",
      "Volker Steinhage"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.04613"
  },
  {
    "id": "arXiv:2202.04617",
    "title": "Outside Looking In: Approaches to Content Moderation in End-to-End  Encrypted Systems",
    "abstract": "In this paper, we assess existing technical proposals for content moderation\nin End-to-End Encryption (E2EE) services. First, we explain the various tools\nin the content moderation toolbox, how they are used, and the different phases\nof the moderation cycle, including detection of unwanted content. We then lay\nout a definition of encryption and E2EE, which includes privacy and security\nguarantees for end-users, before assessing current technical proposals for the\ndetection of unwanted content in E2EE services against those guarantees.\nWe find that technical approaches for user-reporting and meta-data analysis\nare the most likely to preserve privacy and security guarantees for end-users.\nBoth provide effective tools that can detect significant amounts of different\ntypes of problematic content on E2EE services, including abusive and harassing\nmessages, spam, mis- and disinformation, and CSAM, although more research is\nrequired to improve these tools and better measure their effectiveness.\nConversely, we find that other techniques that purport to facilitate content\ndetection in E2EE systems have the effect of undermining key security\nguarantees of E2EE systems.",
    "descriptor": "",
    "authors": [
      "Seny Kamara",
      "Mallory Knodel",
      "Emma Llans\u00f3",
      "Greg Nojeim",
      "Lucy Qin",
      "Dhanaraj Thakur",
      "Caitlin Vogus"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.04617"
  },
  {
    "id": "arXiv:2202.04620",
    "title": "IoTMonitor: A Hidden Markov Model-based Security System to Identify  Crucial Attack Nodes in Trigger-action IoT Platforms",
    "abstract": "With the emergence and fast development of trigger-action platforms in IoT\nsettings, security vulnerabilities caused by the interactions among IoT devices\nbecome more prevalent. The event occurrence at one device triggers an action in\nanother device, which may eventually contribute to the creation of a chain of\nevents in a network. Adversaries exploit the chain effect to compromise IoT\ndevices and trigger actions of interest remotely just by injecting malicious\nevents into the chain. To address security vulnerabilities caused by\ntrigger-action scenarios, existing research efforts focus on the validation of\nthe security properties of devices or verification of the occurrence of certain\nevents based on their physical fingerprints on a device. We propose IoTMonitor,\na security analysis system that discerns the underlying chain of event\noccurrences with the highest probability by observing a chain of physical\nevidence collected by sensors. We use the Baum-Welch algorithm to estimate\ntransition and emission probabilities and the Viterbi algorithm to discern the\nevent sequence. We can then identify the crucial nodes in the trigger-action\nsequence whose compromise allows attackers to reach their final goals. The\nexperiment results of our designed system upon the PEEVES datasets show that we\ncan rebuild the event occurrence sequence with high accuracy from the\nobservations and identify the crucial nodes on the attack paths.",
    "descriptor": "\nComments: This paper appears in the 2022 IEEE Wireless Communications and Networking Conference (WCNC 2022). Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses\n",
    "authors": [
      "Md Morshed Alam",
      "Md Sajidul Islam Sajid",
      "Weichao Wang",
      "Jinpeng Wei"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.04620"
  },
  {
    "id": "arXiv:2202.04623",
    "title": "Graph Spectrum Based Seismic Survey Design",
    "abstract": "Randomized sampling techniques have become increasingly useful in seismic\ndata acquisition and processing, allowing practitioners to achieve dense\nwavefield reconstruction from a substantially reduced number of field samples.\nHowever, typical designs studied in the low-rank matrix recovery and\ncompressive sensing literature are difficult to achieve by standard industry\nhardware. For practical purposes, a compromise between stochastic and\nrealizable samples is needed. In this paper, we propose a deterministic and\ncomputationally cheap tool to alleviate randomized acquisition design, prior to\nsurvey deployment and large-scale optimization. We consider universal and\ndeterministic matrix completion results in the context of seismology, where a\nbipartite graph representation of the source-receiver layout allows for the\nrespective spectral gap to act as a quality metric for wavefield\nreconstruction. We provide realistic survey design scenarios to demonstrate the\nutility of the spectral gap for successful seismic data acquisition via\nlow-rank and sparse signal recovery.",
    "descriptor": "",
    "authors": [
      "Oscar L\u00f3pez",
      "Rajiv Kumar",
      "Nick Moldoveanu",
      "Felix Herrmann"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.04623"
  },
  {
    "id": "arXiv:2202.04625",
    "title": "Analyzing Medical Data with Process Mining: a COVID-19 Case Study",
    "abstract": "The recent increase in the availability of medical data, possible through\nautomation and digitization of medical equipment, has enabled more accurate and\ncomplete analysis on patients' medical data through many branches of data\nscience. In particular, medical records that include timestamps showing the\nhistory of a patient have enabled the representation of medical information as\nsequences of events, effectively allowing to perform process mining analyses.\nIn this paper, we will present some preliminary findings obtained with\nestablished process mining techniques in regard of the medical data of patients\nof the Uniklinik Aachen hospital affected by the recent epidemic of COVID-19.\nWe show that process mining techniques are able to reconstruct a model of the\nICU treatments for COVID patients.",
    "descriptor": "\nComments: 9 pages, 5 figures, 11 references\n",
    "authors": [
      "Marco Pegoraro",
      "Madhavi Bangalore Shankara Narayana",
      "Elisabetta Benevento",
      "Wil M.P. van der Aalst",
      "Lukas Martin",
      "Gernot Marx"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2202.04625"
  },
  {
    "id": "arXiv:2202.04626",
    "title": "Symbolic Comparison of Geometric Quantities in GeoGebra",
    "abstract": "Comparison of geometric quantities usually means obtaining generally true\nequalities of different algebraic expressions of a given geometric figure.\nToday's technical possibilities already support symbolic proofs of a\nconjectured theorem, by exploiting computer algebra capabilities of some\ndynamic geometry systems as well. We introduce GeoGebra's new feature, the\nCompare command, that helps the users in experiments in planar geometry. We\nfocus on automatically obtaining conjectures and their proofs at the same time,\nincluding not just equalities but inequalities too. Our contribution can\nalready be successfully used to support teaching geometry classes at secondary\nlevel, by getting several well-known and some previously unpublished result\nwithin seconds on a modern personal computer.",
    "descriptor": "\nComments: In Proceedings ThEdu'21, arXiv:2202.02144\n",
    "authors": [
      "Zolt\u00e1n Kov\u00e1cs",
      "R\u00f3bert Vajda"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Algebraic Geometry (math.AG)"
    ],
    "url": "https://arxiv.org/abs/2202.04626"
  },
  {
    "id": "arXiv:2202.04627",
    "title": "Automated Discovery of Geometrical Theorems in GeoGebra",
    "abstract": "We describe a prototype of a new experimental GeoGebra command and tool,\nDiscover, that analyzes geometric figures for salient patterns, properties, and\ntheorems. This tool is a basic implementation of automated discovery in\nelementary planar geometry. The paper focuses on the mathematical background of\nthe implementation, as well as methods to avoid combinatorial explosion when\nstoring the interesting properties of a geometric figure.",
    "descriptor": "\nComments: In Proceedings ThEdu'21, arXiv:2202.02144. arXiv admin note: substantial text overlap with arXiv:2007.12447\n",
    "authors": [
      "Zolt\u00e1n Kov\u00e1cs",
      "Jonathan H. Yu"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Algebraic Geometry (math.AG)"
    ],
    "url": "https://arxiv.org/abs/2202.04627"
  },
  {
    "id": "arXiv:2202.04628",
    "title": "Reinforcement Learning with Sparse Rewards using Guidance from Offline  Demonstration",
    "abstract": "A major challenge in real-world reinforcement learning (RL) is the sparsity\nof reward feedback. Often, what is available is an intuitive but sparse reward\nfunction that only indicates whether the task is completed partially or fully.\nHowever, the lack of carefully designed, fine grain feedback implies that most\nexisting RL algorithms fail to learn an acceptable policy in a reasonable time\nframe. This is because of the large number of exploration actions that the\npolicy has to perform before it gets any useful feedback that it can learn\nfrom. In this work, we address this challenging problem by developing an\nalgorithm that exploits the offline demonstration data generated by a\nsub-optimal behavior policy for faster and efficient online RL in such sparse\nreward settings. The proposed algorithm, which we call the Learning Online with\nGuidance Offline (LOGO) algorithm, merges a policy improvement step with an\nadditional policy guidance step by using the offline demonstration data. The\nkey idea is that by obtaining guidance from - not imitating - the offline data,\nLOGO orients its policy in the manner of the sub-optimal {policy}, while yet\nbeing able to learn beyond and approach optimality. We provide a theoretical\nanalysis of our algorithm, and provide a lower bound on the performance\nimprovement in each learning episode. We also extend our algorithm to the even\nmore challenging incomplete observation setting, where the demonstration data\ncontains only a censored version of the true state observation. We demonstrate\nthe superior performance of our algorithm over state-of-the-art approaches on a\nnumber of benchmark environments with sparse rewards and censored state.\nFurther, we demonstrate the value of our approach via implementing LOGO on a\nmobile robot for trajectory tracking and obstacle avoidance, where it shows\nexcellent performance.",
    "descriptor": "",
    "authors": [
      "Desik Rengarajan",
      "Gargi Vaidya",
      "Akshay Sarvesh",
      "Dileep Kalathil",
      "Srinivas Shakkottai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.04628"
  },
  {
    "id": "arXiv:2202.04629",
    "title": "Reducing Redundancy in the Bottleneck Representation of the Autoencoders",
    "abstract": "Autoencoders are a type of unsupervised neural networks, which can be used to\nsolve various tasks, e.g., dimensionality reduction, image compression, and\nimage denoising. An AE has two goals: (i) compress the original input to a\nlow-dimensional space at the bottleneck of the network topology using an\nencoder, (ii) reconstruct the input from the representation at the bottleneck\nusing a decoder. Both encoder and decoder are optimized jointly by minimizing a\ndistortion-based loss which implicitly forces the model to keep only those\nvariations of input data that are required to reconstruct the and to reduce\nredundancies. In this paper, we propose a scheme to explicitly penalize feature\nredundancies in the bottleneck representation. To this end, we propose an\nadditional loss term, based on the pair-wise correlation of the neurons, which\ncomplements the standard reconstruction loss forcing the encoder to learn a\nmore diverse and richer representation of the input. We tested our approach\nacross different tasks: dimensionality reduction using three different dataset,\nimage compression using the MNIST dataset, and image denoising using fashion\nMNIST. The experimental results show that the proposed loss leads consistently\nto superior performance compared to the standard AE loss.",
    "descriptor": "\nComments: 6 pages,4 figures\n",
    "authors": [
      "Firas Laakom",
      "Jenni Raitoharju",
      "Alexandros Iosifidis",
      "Moncef Gabbouj"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2202.04629"
  },
  {
    "id": "arXiv:2202.04631",
    "title": "Security of EV-Charging Protocols",
    "abstract": "The field of electric vehicle charging involves a complex combination of\nactors, devices, networks, and protocols. These protocols are being developed\nwithout a clear focus on security. In this paper, we give an overview of the\nmain roles and protocols in use in the Netherlands. We describe a clear\nattacker model and security requirements, show that in light of this many of\nthe protocols have security issues, and provide suggestions on how to address\nthese issues. The most important conclusion is the need for end-to-end security\nfor data in transit and long-term authenticity for data at rest. In addition,\nwe highlight the need for improved authentication of the EV driver, e.g. by\nusing banking cards. For the communication links we advise mandatory use of\nTLS, standardization of TLS options and configurations, and improved\nauthentication using TLS client certificates.",
    "descriptor": "\nComments: 19 pages, 1 figure\n",
    "authors": [
      "Pol Van Aubel",
      "Erik Poll"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.04631"
  },
  {
    "id": "arXiv:2202.04632",
    "title": "A Local Geometric Interpretation of Feature Extraction in Deep  Feedforward Neural Networks",
    "abstract": "In this paper, we present a local geometric analysis to interpret how deep\nfeedforward neural networks extract low-dimensional features from\nhigh-dimensional data. Our study shows that, in a local geometric region, the\noptimal weight in one layer of the neural network and the optimal feature\ngenerated by the previous layer comprise a low-rank approximation of a matrix\nthat is determined by the Bayes action of this layer. This result holds (i) for\nanalyzing both the output layer and the hidden layers of the neural network,\nand (ii) for neuron activation functions that are locally strictly increasing\nand continuously differentiable. We use two supervised learning problems to\nillustrate our results: neural network based maximum likelihood classification\n(i.e., logistic regression) and neural network based minimum mean square\nestimation. Experimental validation of these theoretical results will be\nconducted in our future work.",
    "descriptor": "",
    "authors": [
      "Md Kamran Chowdhury Shisher",
      "Tasmeen Zaman Ornee",
      "Yin Sun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.04632"
  },
  {
    "id": "arXiv:2202.04634",
    "title": "Offline Reinforcement Learning with Realizability and Single-policy  Concentrability",
    "abstract": "Sample-efficiency guarantees for offline reinforcement learning (RL) often\nrely on strong assumptions on both the function classes (e.g.,\nBellman-completeness) and the data coverage (e.g., all-policy concentrability).\nDespite the recent efforts on relaxing these assumptions, existing works are\nonly able to relax one of the two factors, leaving the strong assumption on the\nother factor intact. As an important open problem, can we achieve\nsample-efficient offline RL with weak assumptions on both factors?\nIn this paper we answer the question in the positive. We analyze a simple\nalgorithm based on the primal-dual formulation of MDPs, where the dual\nvariables (discounted occupancy) are modeled using a density-ratio function\nagainst offline data. With proper regularization, we show that the algorithm\nenjoys polynomial sample complexity, under only realizability and single-policy\nconcentrability. We also provide alternative analyses based on different\nassumptions to shed light on the nature of primal-dual algorithms for offline\nRL.",
    "descriptor": "",
    "authors": [
      "Wenhao Zhan",
      "Baihe Huang",
      "Audrey Huang",
      "Nan Jiang",
      "Jason D. Lee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.04634"
  },
  {
    "id": "arXiv:2202.04639",
    "title": "Point-Level Region Contrast for Object Detection Pre-Training",
    "abstract": "In this work we present point-level region contrast, a self-supervised\npre-training approach for the task of object detection. This approach is\nmotivated by the two key factors in detection: localization and recognition.\nWhile accurate localization favors models that operate at the pixel- or\npoint-level, correct recognition typically relies on a more holistic,\nregion-level view of objects. Incorporating this perspective in pre-training,\nour approach performs contrastive learning by directly sampling individual\npoint pairs from different regions. Compared to an aggregated representation\nper region, our approach is more robust to the change in input region quality,\nand further enables us to implicitly improve initial region assignments via\nonline knowledge distillation during training. Both advantages are important\nwhen dealing with imperfect regions encountered in the unsupervised setting.\nExperiments show point-level region contrast improves on state-of-the-art\npre-training methods for object detection and segmentation across multiple\ntasks and datasets, and we provide extensive ablation studies and\nvisualizations to aid understanding. Code will be made available.",
    "descriptor": "",
    "authors": [
      "Yutong Bai",
      "Xinlei Chen",
      "Alexander Kirillov",
      "Alan Yuille",
      "Alexander C. Berg"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.04639"
  },
  {
    "id": "arXiv:2108.05623",
    "title": "Existence, Stability and Scalability of Orthogonal Convolutional Neural  Networks",
    "abstract": "Imposing orthogonality on the layers of neural networks is known to\nfacilitate the learning by limiting the exploding/vanishing of the gradient;\ndecorrelate the features; improve the robustness. This paper studies\ntheoretical properties of orthogonal convolutional layers. We establish\nnecessary and sufficient conditions on the layer architecture guaranteeing the\nexistence of an orthogonal convolutional transform. The conditions prove that\northogonal convolutional transforms exist for almost all architectures used in\npractice for 'circular' padding.We also exhibit limitations with 'valid'\nboundary condition and 'same' boundary condition with zero padding. Recently, a\nregularization term imposing the orthogonality of convolutional layers has been\nproposed, and impressive empirical results have been obtained in different\napplications (Wang et al. 2020).The second motivation of the present paper is\nto specify the theory behind this.We make the link between this regularization\nterm and orthogonality measures. In doing so, we show that this regularization\nstrategy is stable with respect to numerical and optimization errors and that,\nin the presence of small errors and when the size of the signal/image is large,\nthe convolutional layers remain close to isometric.The theoretical results are\nconfirmed with experiments, the landscape of the regularization term is studied\nand the regularization strategy is validated on real datasets. Altogether, the\nstudy guarantees that the regularization with L_{orth} (Wang et al. 2020) is an\nefficient, flexible and stable numerical strategy to learn orthogonal\nconvolutional layers.",
    "descriptor": "",
    "authors": [
      "El Mehdi Achour",
      "Fran\u00e7ois Malgouyres",
      "Franck Mamalet"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2108.05623"
  },
  {
    "id": "arXiv:2202.03751",
    "title": "InferGrad: Improving Diffusion Models for Vocoder by Considering  Inference in Training",
    "abstract": "Denoising diffusion probabilistic models (diffusion models for short) require\na large number of iterations in inference to achieve the generation quality\nthat matches or surpasses the state-of-the-art generative models, which\ninvariably results in slow inference speed. Previous approaches aim to optimize\nthe choice of inference schedule over a few iterations to speed up inference.\nHowever, this results in reduced generation quality, mainly because the\ninference process is optimized separately, without jointly optimizing with the\ntraining process. In this paper, we propose InferGrad, a diffusion model for\nvocoder that incorporates inference process into training, to reduce the\ninference iterations while maintaining high generation quality. More\nspecifically, during training, we generate data from random noise through a\nreverse process under inference schedules with a few iterations, and impose a\nloss to minimize the gap between the generated and ground-truth data samples.\nThen, unlike existing approaches, the training of InferGrad considers the\ninference process. The advantages of InferGrad are demonstrated through\nexperiments on the LJSpeech dataset showing that InferGrad achieves better\nvoice quality than the baseline WaveGrad under same conditions while\nmaintaining the same voice quality as the baseline but with $3$x speedup ($2$\niterations for InferGrad vs $6$ iterations for WaveGrad).",
    "descriptor": "\nComments: 5 Pages, 2 figures. Accepted to ICASSP 2022\n",
    "authors": [
      "Zehua Chen",
      "Xu Tan",
      "Ke Wang",
      "Shifeng Pan",
      "Danilo Mandic",
      "Lei He",
      "Sheng Zhao"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2202.03751"
  },
  {
    "id": "arXiv:2202.04073",
    "title": "The EMory BrEast imaging Dataset (EMBED): A Racially Diverse, Granular  Dataset of 3.5M Screening and Diagnostic Mammograms",
    "abstract": "Developing and validating artificial intelligence models in medical imaging\nrequires datasets that are large, granular, and diverse. To date, the majority\nof publicly available breast imaging datasets lack in one or more of these\nareas. Models trained on these data may therefore underperform on patient\npopulations or pathologies that have not previously been encountered. The EMory\nBrEast imaging Dataset (EMBED) addresses these gaps by providing 3650,000 2D\nand DBT screening and diagnostic mammograms for 116,000 women divided equally\nbetween White and African American patients. The dataset also contains 40,000\nannotated lesions linked to structured imaging descriptors and 61 ground truth\npathologic outcomes grouped into six severity classes. Our goal is to share\nthis dataset with research partners to aid in development and validation of\nbreast AI models that will serve all patients fairly and help decrease bias in\nmedical AI.",
    "descriptor": "",
    "authors": [
      "Jiwoong J. Jeong",
      "Brianna L. Vey",
      "Ananth Reddy",
      "Thomas Kim",
      "Thiago Santos",
      "Ramon Correa",
      "Raman Dutt",
      "Marina Mosunjac",
      "Gabriela Oprea-Ilies",
      "Geoffrey Smith",
      "Minjae Woo",
      "Christopher R. McAdams",
      "Mary S. Newell",
      "Imon Banerjee",
      "Judy Gichoya",
      "Hari Trivedi"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.04073"
  },
  {
    "id": "arXiv:2202.04074",
    "title": "Cross-level Contrastive Learning and Consistency Constraint for  Semi-supervised Medical Image Segmentation",
    "abstract": "Semi-supervised learning (SSL), which aims at leveraging a few labeled images\nand a large number of unlabeled images for network training, is beneficial for\nrelieving the burden of data annotation in medical image segmentation.\nAccording to the experience of medical imaging experts, local attributes such\nas texture, luster and smoothness are very important factors for identifying\ntarget objects like lesions and polyps in medical images. Motivated by this, we\npropose a cross-level constrastive learning scheme to enhance representation\ncapacity for local features in semi-supervised medical image segmentation.\nCompared to existing image-wise, patch-wise and point-wise constrastive\nlearning algorithms, our devised method is capable of exploring more complex\nsimilarity cues, namely the relational characteristics between global\npoint-wise and local patch-wise representations. Additionally, for fully making\nuse of cross-level semantic relations, we devise a novel consistency constraint\nthat compares the predictions of patches against those of the full image. With\nthe help of the cross-level contrastive learning and consistency constraint,\nthe unlabelled data can be effectively explored to improve segmentation\nperformance on two medical image datasets for polyp and skin lesion\nsegmentation respectively. Code of our approach is available.",
    "descriptor": "",
    "authors": [
      "Xinkai Zhao",
      "Chaowei Fang",
      "De-Jun Fan",
      "Xutao Lin",
      "Feng Gao",
      "Guanbin Li"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.04074"
  },
  {
    "id": "arXiv:2202.04150",
    "title": "Time-varying harmonic models for voice signal analysis",
    "abstract": "Assessment of voice signals has long been performed with the assumption of\nperiodicity as this facilitates analysis. Near periodicity of normal voice\nsignals makes short-time harmonic modeling an appealing choice to extract vocal\nfeature parameters. For dysphonic voice, however, a fixed harmonic structure\ncould be too constrained as it strictly enforces periodicity in the model.\nSlight variation in amplitude or frequency in the signal may cause the model to\nmisrepresent the observed signal. To address these issues, this paper presents\na time-varying harmonic model, which allows its fundamental frequency and\nharmonic amplitudes to be polynomial functions of time. The model decouples the\nslow deviations of frequency and amplitude from fast irregular vocal fold\nvibratory behaviors such as subharmonics and diplophonia. The time-varying\nmodel is shown to track the frequency and amplitude modulations present in\nvoice with severe tremor. This reduces the sensitivity of the model-based\nharmonics-to-noise ratio measures to slow frequency and amplitude variations\nwhile maintaining its sensitivity to increase in turbulent noise or the\npresence of irregular vibration. Other uses of the model include the vocal\ntract filter estimation and the rates of frequency and intensity changes. These\nuse cases are experimentally demonstrated along with the modeling accuracy.",
    "descriptor": "\nComments: 12 pages, 12 figures, submitted to JASA\n",
    "authors": [
      "Takeshi Ikuma",
      "Andrew J. McWhorter",
      "Lacey Adkins",
      "Melda Kunduk"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.04150"
  },
  {
    "id": "arXiv:2202.04167",
    "title": "Understanding the bias-variance tradeoff of Bregman divergences",
    "abstract": "This paper builds upon the work of Pfau (2013), which generalized the bias\nvariance tradeoff to any Bregman divergence loss function. Pfau (2013) showed\nthat for Bregman divergences, the bias and variances are defined with respect\nto a central label, defined as the expected mean of the label, and a central\nprediction, of a more complex form. We show that, similarly to the label, the\ncentral prediction can be interpreted as the mean of a random variable, where\nthe mean operates in a dual space defined by the loss function itself. Viewing\nthe bias-variance tradeoff through operations taken in dual space, we\nsubsequently derive several results of interest. In particular, (a) the\nvariance terms satisfy a generalized law of total variance; (b) if a source of\nrandomness cannot be controlled, its contribution to the bias and variance has\na closed form; (c) there exist natural ensembling operations in the label and\nprediction spaces which reduce the variance and do not affect the bias.",
    "descriptor": "",
    "authors": [
      "Ben Adlam",
      "Neha Gupta",
      "Zelda Mariet",
      "Jamie Smith"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2202.04167"
  },
  {
    "id": "arXiv:2202.04172",
    "title": "A Speech Intelligibility Enhancement Model based on Canonical  Correlation and Deep Learning for Hearing-Assistive Technologies",
    "abstract": "Current deep learning (DL) based approaches to speech intelligibility\nenhancement in noisy environments are generally trained to minimise the\ndistance between clean and enhanced speech features. These often result in\nimproved speech quality however they suffer from a lack of generalisation and\nmay not deliver the required speech intelligibility in everyday noisy\nsituations. In an attempt to address these challenges, researchers have\nexplored intelligibility-oriented (I-O) loss functions to train DL approaches\nfor robust speech enhancement (SE). In this paper, we formulate a novel\ncanonical correlation-based I-O loss function to more effectively train DL\nalgorithms. Specifically, we present a fully convolutional SE model that uses a\nmodified canonical-correlation based short-time objective intelligibility\n(CC-STOI) metric as a training cost function. To the best of our knowledge,\nthis is the first work that exploits the integration of canonical correlation\nin an I-O based loss function for SE. Comparative experimental results\ndemonstrate that our proposed CC-STOI based SE framework outperforms DL models\ntrained with conventional STOI and distance-based loss functions, in terms of\nboth standard objective and subjective evaluation measures when dealing with\nunseen speakers and noises.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2111.09642\n",
    "authors": [
      "Tassadaq Hussain",
      "Muhammad Diyan",
      "Mandar Gogate",
      "Kia Dashtipour",
      "Ahsan Adeel",
      "Yu Tsao",
      "Amir Hussain"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2202.04172"
  },
  {
    "id": "arXiv:2202.04175",
    "title": "Federated Learning of Generative Image Priors for MRI Reconstruction",
    "abstract": "Multi-institutional efforts can facilitate training of deep MRI\nreconstruction models, albeit privacy risks arise during cross-site sharing of\nimaging data. Federated learning (FL) has recently been introduced to address\nprivacy concerns by enabling distributed training without transfer of imaging\ndata. Existing FL methods for MRI reconstruction employ conditional models to\nmap from undersampled to fully-sampled acquisitions via explicit knowledge of\nthe imaging operator. Since conditional models generalize poorly across\ndifferent acceleration rates or sampling densities, imaging operators must be\nfixed between training and testing, and they are typically matched across\nsites. To improve generalization and flexibility in multi-institutional\ncollaborations, here we introduce a novel method for MRI reconstruction based\non Federated learning of Generative IMage Priors (FedGIMP). FedGIMP leverages a\ntwo-stage approach: cross-site learning of a generative MRI prior, and\nsubject-specific injection of the imaging operator. The global MRI prior is\nlearned via an unconditional adversarial model that synthesizes high-quality MR\nimages based on latent variables. Specificity in the prior is preserved via a\nmapper subnetwork that produces site-specific latents. During inference, the\nprior is combined with subject-specific imaging operators to enable\nreconstruction, and further adapted to individual test samples by minimizing\ndata-consistency loss. Comprehensive experiments on multi-institutional\ndatasets clearly demonstrate enhanced generalization performance of FedGIMP\nagainst site-specific and federated methods based on conditional models, as\nwell as traditional reconstruction methods.",
    "descriptor": "\nComments: To be submitted to IEEE TMI Special Issue on Federated Learning for Medical Imaging\n",
    "authors": [
      "Gokberk Elmas",
      "Salman UH Dar",
      "Yilmaz Korkmaz",
      "Emir Ceyani",
      "Burak Susam",
      "Muzaffer \u00d6zbey",
      "Salman Avestimehr",
      "Tolga \u00c7ukur"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.04175"
  },
  {
    "id": "arXiv:2202.04202",
    "title": "RECOVER: sequential model optimization platform for combination drug  repurposing identifies novel synergistic compounds in vitro",
    "abstract": "Selecting optimal drug repurposing combinations for further preclinical\ndevelopment is a challenging technical feat. Due to the toxicity of many\ntherapeutic agents (e.g., chemotherapy), practitioners have favoured selection\nof synergistic compounds whereby lower doses can be used whilst maintaining\nhigh efficacy. For a fixed small molecule library, an exhaustive combinatorial\nchemical screen becomes infeasible to perform for academic and industry\nlaboratories alike. Deep learning models have achieved state-of-the-art results\nin silico for the prediction of synergy scores. However, databases of drug\ncombinations are highly biased towards synergistic agents and these results do\nnot necessarily generalise out of distribution. We employ a sequential model\noptimization search applied to a deep learning model to quickly discover highly\nsynergistic drug combinations active against a cancer cell line, while\nrequiring substantially less screening than an exhaustive evaluation. Through\niteratively adapting the model to newly acquired data, after only 3 rounds of\nML-guided experimentation (including a calibration round), we find that the set\nof combinations queried by our model is enriched for highly synergistic\ncombinations. Remarkably, we rediscovered a synergistic drug combination that\nwas later confirmed to be under study within clinical trials.",
    "descriptor": "",
    "authors": [
      "Paul Bertin",
      "Jarrid Rector-Brooks",
      "Deepak Sharma",
      "Thomas Gaudelet",
      "Andrew Anighoro",
      "Torsten Gross",
      "Francisco Martinez-Pena",
      "Eileen L. Tang",
      "Suraj M S",
      "Cristian Regep",
      "Jeremy Hayter",
      "Maksym Korablyov",
      "Nicholas Valiante",
      "Almer van der Sloot",
      "Mike Tyers",
      "Charles Roberts",
      "Michael M. Bronstein",
      "Luke L. Lairson",
      "Jake P. Taylor-King",
      "Yoshua Bengio"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.04202"
  },
  {
    "id": "arXiv:2202.04206",
    "title": "Covariate-informed Representation Learning with Samplewise Optimal  Identifiable Variational Autoencoders",
    "abstract": "Recently proposed identifiable variational autoencoder (iVAE, Khemakhem et\nal. (2020)) framework provides a promising approach for learning latent\nindependent components of the data. Although the identifiability is appealing,\nthe objective function of iVAE does not enforce the inverse relation between\nencoders and decoders. Without the inverse relation, representations from the\nencoder in iVAE may not reconstruct observations,i.e., representations lose\ninformation in observations. To overcome this limitation, we develop a new\napproach, covariate-informed identifiable VAE (CI-iVAE). Different from\nprevious iVAE implementations, our method critically leverages the posterior\ndistribution of latent variables conditioned only on observations. In doing so,\nthe objective function enforces the inverse relation, and learned\nrepresentation contains more information of observations. Furthermore, CI-iVAE\nextends the original iVAE objective function to a larger class and finds the\noptimal one among them, thus providing a better fit to the data. Theoretically,\nour method has tighter evidence lower bounds (ELBOs) than the original iVAE. We\ndemonstrate that our approach can more reliably learn features of various\nsynthetic datasets, two benchmark image datasets (EMNIST and Fashion MNIST),\nand a large-scale brain imaging dataset for adolescent mental health research.",
    "descriptor": "",
    "authors": [
      "Young-geun Kim",
      "Ying Liu",
      "Xuexin Wei"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.04206"
  },
  {
    "id": "arXiv:2202.04208",
    "title": "Evaluating Causal Inference Methods",
    "abstract": "The fundamental challenge of drawing causal inference is that counterfactual\noutcomes are not fully observed for any unit. Furthermore, in observational\nstudies, treatment assignment is likely to be confounded. Many statistical\nmethods have emerged for causal inference under unconfoundedness conditions\ngiven pre-treatment covariates, including propensity score-based methods,\nprognostic score-based methods, and doubly robust methods. Unfortunately for\napplied researchers, there is no `one-size-fits-all' causal method that can\nperform optimally universally. In practice, causal methods are primarily\nevaluated quantitatively on handcrafted simulated data. Such data-generative\nprocedures can be of limited value because they are typically stylized models\nof reality. They are simplified for tractability and lack the complexities of\nreal-world data. For applied researchers, it is critical to understand how well\na method performs for the data at hand. Our work introduces a deep generative\nmodel-based framework, Credence, to validate causal inference methods. The\nframework's novelty stems from its ability to generate synthetic data anchored\nat the empirical distribution for the observed sample, and therefore virtually\nindistinguishable from the latter. The approach allows the user to specify\nground truth for the form and magnitude of causal effects and confounding bias\nas functions of covariates. Thus simulated data sets are used to evaluate the\npotential performance of various causal estimation methods when applied to data\nsimilar to the observed sample. We demonstrate Credence's ability to accurately\nassess the relative performance of causal estimation techniques in an extensive\nsimulation study and two real-world data applications from Lalonde and Project\nSTAR studies.",
    "descriptor": "\nComments: 4 figures, 12 pages\n",
    "authors": [
      "Harsh Parikh",
      "Carlos Varjao",
      "Louise Xu",
      "Eric Tchetgen Tchetgen"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)",
      "Econometrics (econ.EM)"
    ],
    "url": "https://arxiv.org/abs/2202.04208"
  },
  {
    "id": "arXiv:2202.04218",
    "title": "Managers versus Machines: Do Algorithms Replicate Human Intuition in  Credit Ratings?",
    "abstract": "We use machine learning techniques to investigate whether it is possible to\nreplicate the behavior of bank managers who assess the risk of commercial loans\nmade by a large commercial US bank. Even though a typical bank already relies\non an algorithmic scorecard process to evaluate risk, bank managers are given\nsignificant latitude in adjusting the risk score in order to account for other\nholistic factors based on their intuition and experience. We show that it is\npossible to find machine learning algorithms that can replicate the behavior of\nthe bank managers. The input to the algorithms consists of a combination of\nstandard financials and soft information available to bank managers as part of\nthe typical loan review process. We also document the presence of significant\nheterogeneity in the adjustment process that can be traced to differences\nacross managers and industries. Our results highlight the effectiveness of\nmachine learning based analytic approaches to banking and the potential\nchallenges to high-skill jobs in the financial sector.",
    "descriptor": "",
    "authors": [
      "Matthew Harding",
      "Gabriel F. R. Vasconcelos"
    ],
    "subjectives": [
      "Econometrics (econ.EM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.04218"
  },
  {
    "id": "arXiv:2202.04219",
    "title": "Improving Computational Complexity in Statistical Models with  Second-Order Information",
    "abstract": "It is known that when the statistical models are singular, i.e., the Fisher\ninformation matrix at the true parameter is degenerate, the fixed step-size\ngradient descent algorithm takes polynomial number of steps in terms of the\nsample size $n$ to converge to a final statistical radius around the true\nparameter, which can be unsatisfactory for the application. To further improve\nthat computational complexity, we consider the utilization of the second-order\ninformation in the design of optimization algorithms. Specifically, we study\nthe normalized gradient descent (NormGD) algorithm for solving parameter\nestimation in parametric statistical models, which is a variant of gradient\ndescent algorithm whose step size is scaled by the maximum eigenvalue of the\nHessian matrix of the empirical loss function of statistical models. When the\npopulation loss function, i.e., the limit of the empirical loss function when\n$n$ goes to infinity, is homogeneous in all directions, we demonstrate that the\nNormGD iterates reach a final statistical radius around the true parameter\nafter a logarithmic number of iterations in terms of $n$. Therefore, for fixed\ndimension $d$, the NormGD algorithm achieves the optimal overall computational\ncomplexity $\\mathcal{O}(n)$ to reach the final statistical radius. This\ncomputational complexity is cheaper than that of the fixed step-size gradient\ndescent algorithm, which is of the order $\\mathcal{O}(n^{\\tau})$ for some $\\tau\n> 1$, to reach the same statistical radius. We illustrate our general theory\nunder two statistical models: generalized linear models and mixture models, and\nexperimental results support our prediction with general theory.",
    "descriptor": "\nComments: 36 pages, 2 figures. arXiv admin note: text overlap with arXiv:2110.07810\n",
    "authors": [
      "Tongzheng Ren",
      "Jiacheng Zhuo",
      "Sujay Sanghavi",
      "Nhat Ho"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2202.04219"
  },
  {
    "id": "arXiv:2202.04233",
    "title": "Deep Neural Networks to Correct Sub-Precision Errors in CFD",
    "abstract": "Loss of information in numerical simulations can arise from various sources\nwhile solving discretized partial differential equations. In particular,\nprecision-related errors can accumulate in the quantities of interest when the\nsimulations are performed using low-precision 16-bit floating-point arithmetic\ncompared to an equivalent 64-bit simulation. Here, low-precision computation\nrequires much lower resources than high-precision computation. Several machine\nlearning (ML) techniques proposed recently have been successful in correcting\nthe errors arising from spatial discretization. In this work, we extend these\ntechniques to improve Computational Fluid Dynamics (CFD) simulations performed\nusing low numerical precision. We first quantify the precision related errors\naccumulated in a Kolmogorov forced turbulence test case. Subsequently, we\nemploy a Convolutional Neural Network together with a fully differentiable\nnumerical solver performing 16-bit arithmetic to learn a tightly-coupled ML-CFD\nhybrid solver. Compared to the 16-bit solver, we demonstrate the efficacy of\nthe ML-CFD hybrid solver towards reducing the error accumulation in the\nvelocity field and improving the kinetic energy spectrum at higher frequencies.",
    "descriptor": "",
    "authors": [
      "Akash Haridas",
      "Nagabhushana Rao Vadlamani",
      "Yuki Minamoto"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2202.04233"
  },
  {
    "id": "arXiv:2202.04238",
    "title": "Parametric t-Stochastic Neighbor Embedding With Quantum Neural Network",
    "abstract": "t-Stochastic Neighbor Embedding (t-SNE) is a non-parametric data\nvisualization method in classical machine learning. It maps the data from the\nhigh-dimensional space into a low-dimensional space, especially a\ntwo-dimensional plane, while maintaining the relationship, or similarities,\nbetween the surrounding points. In t-SNE, the initial position of the\nlow-dimensional data is randomly determined, and the visualization is achieved\nby moving the low-dimensional data to minimize a cost function. Its variant\ncalled parametric t-SNE uses neural networks for this mapping. In this paper,\nwe propose to use quantum neural networks for parametric t-SNE to reflect the\ncharacteristics of high-dimensional quantum data on low-dimensional data. We\nuse fidelity-based metrics instead of Euclidean distance in calculating\nhigh-dimensional data similarity. We visualize both classical (Iris dataset)\nand quantum (time-depending Hamiltonian dynamics) data for classification\ntasks. Since this method allows us to represent a quantum dataset in a higher\ndimensional Hilbert space by a quantum dataset in a lower dimension while\nkeeping their similarity, the proposed method can also be used to compress\nquantum data for further quantum machine learning.",
    "descriptor": "\nComments: 9 pages, 7 figures\n",
    "authors": [
      "Yoshiaki Kawase",
      "Kosuke Mitarai",
      "Keisuke Fujii"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.04238"
  },
  {
    "id": "arXiv:2202.04246",
    "title": "The decision problem for perfect matchings in dense hypergraphs",
    "abstract": "Given $1\\le \\ell <k$ and $\\delta>0$, let $\\textbf{PM}(k,\\ell,\\delta)$ be the\ndecision problem for the existence of perfect matchings in $n$-vertex\n$k$-uniform hypergraphs with minimum $\\ell$-degree at least\n$\\delta\\binom{n-\\ell}{k-\\ell}$. For $k\\ge 3$, the decision problem in general\n$k$-uniform hypergraphs, equivalently $\\textbf{PM}(k,\\ell,0)$, is one of Karp's\n21 NP-complete problems. Moreover, a reduction of Szyma\\'{n}ska showed that\n$PM(k, \\ell, \\delta)$ is NP-complete for $\\delta < 1-(1-1/k)^{k-\\ell}$. A\nbreakthrough by Keevash, Knox and Mycroft [STOC '13] resolved this problem for\n$\\ell=k-1$ by showing that $PM(k, k-1, \\delta)$ is in P for $\\delta > 1/k$.\nBased on their result for $\\ell=k-1$, Keevash, Knox and Mycroft conjectured\nthat $PM(k, \\ell, \\delta)$ is in P for every $\\delta > 1-(1-1/k)^{k-\\ell}$.\nIn this paper it is shown that this decision problem for perfect matchings\ncan be reduced to the study of the minimum $\\ell$-degree condition forcing the\nexistence of fractional perfect matchings. That is, we hopefully solve the\n\"computational complexity\" aspect of the problem by reducing it to a well-known\nextremal problem in hypergraph theory. In particular, together with existing\nresults on fractional perfect matchings, this solves the conjecture of Keevash,\nKnox and Mycroft for $\\ell\\ge 0.4k$.",
    "descriptor": "\nComments: 15 pages\n",
    "authors": [
      "Luyining Gan",
      "Jie Han"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2202.04246"
  },
  {
    "id": "arXiv:2202.04258",
    "title": "A Data-Driven Approach to Robust Hypothesis Testing Using Sinkhorn  Uncertainty Sets",
    "abstract": "This paper is eligible for the Jack Keil Wolf ISIT Student Paper Award.\nHypothesis testing for small-sample scenarios is a practically important\nproblem. In this paper, we investigate the robust hypothesis testing problem in\na data-driven manner, where we seek the worst-case detector over distributional\nuncertainty sets centered around the empirical distribution from samples using\nSinkhorn distance. Compared with the Wasserstein robust test, the corresponding\nleast favorable distributions are supported beyond the training samples, which\nprovides a more flexible detector. Various numerical experiments are conducted\non both synthetic and real datasets to validate the competitive performances of\nour proposed method.",
    "descriptor": "\nComments: 22 pages, 7 figures\n",
    "authors": [
      "Jie Wang",
      "Yao Xie"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.04258"
  },
  {
    "id": "arXiv:2202.04358",
    "title": "House Price Valuation Model Based on Geographically Neural Network  Weighted Regression: The Case Study of Shenzhen, China",
    "abstract": "Confronted with the spatial heterogeneity of real estate market, some\ntraditional research utilized Geographically Weighted Regression (GWR) to\nestimate the house price. However, its kernel function is non-linear, elusive,\nand complex to opt bandwidth, the predictive power could also be improved.\nConsequently, a novel technique, Geographical Neural Network Weighted\nRegression (GNNWR), has been applied to improve the accuracy of real estate\nappraisal with the help of neural networks. Based on Shenzhen house price\ndataset, this work conspicuously captures the weight distribution of different\nvariants at Shenzhen real estate market, which GWR is difficult to materialize.\nMoreover, we focus on the performance of GNNWR, verify its robustness and\nsuperiority, refine the experiment process with 10-fold cross-validation,\nextend its application area from natural to socioeconomic geospatial data. It's\na practical and trenchant way to assess house price, and we demonstrate the\neffectiveness of GNNWR on a complex socioeconomic dataset.",
    "descriptor": "",
    "authors": [
      "Zimo Wang",
      "Yicheng Wang",
      "Sensen Wu"
    ],
    "subjectives": [
      "Applications (stat.AP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.04358"
  },
  {
    "id": "arXiv:2202.04359",
    "title": "Cost-effective Framework for Gradual Domain Adaptation with  Multifidelity",
    "abstract": "In domain adaptation, when there is a large distance between the source and\ntarget domains, the prediction performance will degrade. Gradual domain\nadaptation is one of the solutions to such an issue, assuming that we have\naccess to intermediate domains, which shift gradually from the source to target\ndomains. In previous works, it was assumed that the number of samples in the\nintermediate domains is sufficiently large; hence, self-training was possible\nwithout the need for labeled data. If access to an intermediate domain is\nrestricted, self-training will fail. Practically, the cost of samples in\nintermediate domains will vary, and it is natural to consider that the closer\nan intermediate domain is to the target domain, the higher the cost of\nobtaining samples from the intermediate domain is. To solve the trade-off\nbetween cost and accuracy, we propose a framework that combines multifidelity\nand active domain adaptation. The effectiveness of the proposed method is\nevaluated by experiments with both artificial and real-world datasets. Codes\nare available at https://github.com/ssgw320/gdamf.",
    "descriptor": "\nComments: 18 pages, 7 figures\n",
    "authors": [
      "Shogo Sagawa",
      "Hideitsu Hino"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.04359"
  },
  {
    "id": "arXiv:2202.04371",
    "title": "Hypergraph characterization of split matroids",
    "abstract": "We provide a combinatorial study of split matroids, a class that was\nmotivated by the study of matroid polytopes from a tropical geometry point of\nview. A nice feature of split matroids is that they generalize paving matroids,\nwhile being closed under duality and taking minors. Furthermore, these matroids\nproved to be useful in giving exact asymptotic bounds for the dimension of the\nDressian, and also implied new results on the rays of the tropical\nGrassmannians.\nIn the present paper, we introduce the notion of elementary split matroids, a\nsubclass of split matroids that contains all connected split matroids. We give\na hypergraph characterization of elementary split matroids in terms of\nindependent sets, and show that the proposed class is closed not only under\nduality and taking minors but also truncation. We further show that, in\ncontrast to split matroids, the proposed class can be characterized by a single\nforbidden minor. As an application, we provide a complete list of binary split\nmatroids.",
    "descriptor": "\nComments: 12 pages, 1 figure\n",
    "authors": [
      "Krist\u00f3f B\u00e9rczi",
      "Tam\u00e1s Kir\u00e1ly",
      "Tam\u00e1s Schwarcz",
      "Yutaro Yamaguchi",
      "Yu Yokoi"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2202.04371"
  },
  {
    "id": "arXiv:2202.04378",
    "title": "A Measurement-Based Robust Non-Gaussian Process Emulator Applied to  Data-Driven Stochastic Power Flow",
    "abstract": "In this paper, we propose a robust non-Gaussian process emulator based on the\nSchweppe-type generalized maximum likelihood estimator, which is trained on\nmetered time series of voltage phasors and power injections to perform\nstochastic power flow. Power system data are often corrupted with outliers\ncaused by fault conditions, power outages, and extreme weather, to name a few.\nThe proposed emulator bounds the influence of the outliers using weights\ncalculated based on projection statistics, which are robust distances of the\ndata points associated with the rows vectors of the factor space. Specifically,\nthe developed estimator is robust to vertical outliers and bad leverage points\nwhile retaining good leverage points in the measurements of the training\ndataset. The proposed method is demonstrated on an unbalanced radial IEEE\n33-Bus system heavily integrated with renewable energy sources.",
    "descriptor": "\nComments: IEEE PES GM 2022\n",
    "authors": [
      "Pooja Algikar",
      "Yijun Xu",
      "Lamine Mili"
    ],
    "subjectives": [
      "Applications (stat.AP)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.04378"
  },
  {
    "id": "arXiv:2202.04397",
    "title": "A hypothesis-driven method based on machine learning for neuroimaging  data analysis",
    "abstract": "There remains an open question about the usefulness and the interpretation of\nMachine learning (MLE) approaches for discrimination of spatial patterns of\nbrain images between samples or activation states. In the last few decades,\nthese approaches have limited their operation to feature extraction and linear\nclassification tasks for between-group inference. In this context, statistical\ninference is assessed by randomly permuting image labels or by the use of\nrandom effect models that consider between-subject variability. These\nmultivariate MLE-based statistical pipelines, whilst potentially more effective\nfor detecting activations than hypotheses-driven methods, have lost their\nmathematical elegance, ease of interpretation, and spatial localization of the\nubiquitous General linear Model (GLM). Recently, the estimation of the\nconventional GLM has been demonstrated to be connected to an univariate\nclassification task when the design matrix is expressed as a binary indicator\nmatrix. In this paper we explore the complete connection between the univariate\nGLM and MLE \\emph{regressions}. To this purpose we derive a refined statistical\ntest with the GLM based on the parameters obtained by a linear Support Vector\nRegression (SVR) in the \\emph{inverse} problem (SVR-iGLM). Subsequently, random\nfield theory (RFT) is employed for assessing statistical significance following\na conventional GLM benchmark. Experimental results demonstrate how parameter\nestimations derived from each model (mainly GLM and SVR) result in different\nexperimental design estimates that are significantly related to the predefined\nfunctional task. Moreover, using real data from a multisite initiative the\nproposed MLE-based inference demonstrates statistical power and the control of\nfalse positives, outperforming the regular GLM.",
    "descriptor": "\nComments: 11 figures\n",
    "authors": [
      "JM Gorriz",
      "R. Martin-Clemente",
      "C.G. Puntonet",
      "A. Ortiz",
      "J. Ramirez",
      "J. Suckling"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2202.04397"
  },
  {
    "id": "arXiv:2202.04405",
    "title": "Time-Frequency Mask Aware Bi-directional LSTM: A Deep Learning Approach  for Underwater Acoustic Signal Separation",
    "abstract": "The underwater acoustic signals separation is a key technique for the\nunderwater communications. The existing methods are mostly model-based, and\ncould not accurately characterise the practical underwater acoustic\ncommunication environment. They are only suitable for binary signal separation,\nbut cannot handle multivariate signal separation. On the other hand, the\nrecurrent neural network (RNN) shows powerful capability in extracting the\nfeatures of the temporal sequences. Inspired by this, in this paper, we present\na data-driven approach for underwater acoustic signals separation using deep\nlearning technology. We use the Bi-directional Long Short-Term Memory (Bi-LSTM)\nto explore the features of Time-Frequency (T-F) mask, and propose a T-F mask\naware Bi-LSTM for signal separation. Taking advantage of the sparseness of the\nT-F image, the designed Bi-LSTM network is able to extract the discriminative\nfeatures for separation, which further improves the separation performance. In\nparticular, this method breaks through the limitations of the existing methods,\nnot only achieves good results in multivariate separation, but also effectively\nseparates signals when mixed with 40dB Gaussian noise signals. The experimental\nresults show that this method can achieve a $97\\%$ guarantee ratio (PSR), and\nthe average similarity coefficient of the multivariate signal separation is\nstable above 0.8 under high noise conditions.",
    "descriptor": "\nComments: 28 pages, 14 figures\n",
    "authors": [
      "Jie Chen",
      "Chang Liu",
      "Jiawu Xie",
      "Jie An",
      "Nan Huang"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2202.04405"
  },
  {
    "id": "arXiv:2202.04497",
    "title": "Recurrent Spectral Network (RSN): shaping the basin of attraction of a  discrete map to reach automated classification",
    "abstract": "A novel strategy to automated classification is introduced which exploits a\nfully trained dynamical system to steer items belonging to different categories\ntoward distinct asymptotic attractors. These latter are incorporated into the\nmodel by taking advantage of the spectral decomposition of the operator that\nrules the linear evolution across the processing network. Non-linear terms act\nfor a transient and allow to disentangle the data supplied as initial condition\nto the discrete dynamical system, shaping the boundaries of different\nattractors. The network can be equipped with several memory kernels which can\nbe sequentially activated for serial datasets handling. Our novel approach to\nclassification, that we here term Recurrent Spectral Network (RSN), is\nsuccessfully challenged against a simple test-bed model, created for\nillustrative purposes, as well as a standard dataset for image processing\ntraining.",
    "descriptor": "",
    "authors": [
      "Lorenzo Chicchi",
      "Duccio Fanelli",
      "Lorenzo Giambagli",
      "Lorenzo Buffoni",
      "Timoteo Carletti"
    ],
    "subjectives": [
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.04497"
  },
  {
    "id": "arXiv:2202.04499",
    "title": "Lightweight Jet Reconstruction and Identification as an Object Detection  Task",
    "abstract": "We apply object detection techniques based on deep convolutional blocks to\nend-to-end jet identification and reconstruction tasks encountered at the CERN\nLarge Hadron Collider (LHC). Collision events produced at the LHC and\nrepresented as an image composed of calorimeter and tracker cells are given as\nan input to a Single Shot Detection network. The algorithm, named PFJet-SSD\nperforms simultaneous localization, classification and regression tasks to\ncluster jets and reconstruct their features. This all-in-one single\nfeed-forward pass gives advantages in terms of execution time and an improved\naccuracy w.r.t. traditional rule-based methods. A further gain is obtained from\nnetwork slimming, homogeneous quantization, and optimized runtime for meeting\nmemory and latency constraints of a typical real-time processing environment.\nWe experiment with 8-bit and ternary quantization, benchmarking their accuracy\nand inference latency against a single-precision floating-point. We show that\nthe ternary network closely matches the performance of its full-precision\nequivalent and outperforms the state-of-the-art rule-based algorithm. Finally,\nwe report the inference latency on different hardware platforms and discuss\nfuture applications.",
    "descriptor": "",
    "authors": [
      "Adrian Alan Pol",
      "Thea Aarrestad",
      "Ekaterina Govorkova",
      "Roi Halily",
      "Anat Klempner",
      "Tal Kopetz",
      "Vladimir Loncar",
      "Jennifer Ngadiuba",
      "Maurizio Pierini",
      "Olya Sirkin",
      "Sioni Summers"
    ],
    "subjectives": [
      "High Energy Physics - Experiment (hep-ex)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.04499"
  },
  {
    "id": "arXiv:2202.04506",
    "title": "Optimising hadronic collider simulations using amplitude neural networks",
    "abstract": "Precision phenomenological studies of high-multiplicity scattering processes\nat collider experiments present a substantial theoretical challenge and are\nvitally important ingredients in experimental measurements. Machine learning\ntechnology has the potential to dramatically optimise simulations for\ncomplicated final states. We investigate the use of neural networks to\napproximate matrix elements, studying the case of loop-induced diphoton\nproduction through gluon fusion. We train neural network models on one-loop\namplitudes from the NJet C++ library and interface them with the Sherpa Monte\nCarlo event generator to provide the matrix element within a realistic hadronic\ncollider simulation. Computing some standard observables with the models and\ncomparing to conventional techniques, we find excellent agreement in the\ndistributions and a reduced total simulation time by a factor of thirty.",
    "descriptor": "\nComments: 6 pages, 6 figures, Proceedings of the 20th International Workshop on Advanced Computing and Analysis Techniques in Physics Research (ACAT 2021)\n",
    "authors": [
      "Ryan Moodie"
    ],
    "subjectives": [
      "High Energy Physics - Phenomenology (hep-ph)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.04506"
  },
  {
    "id": "arXiv:2202.04517",
    "title": "End-to-End Blind Quality Assessment for Laparoscopic Videos using Neural  Networks",
    "abstract": "Video quality assessment is a challenging problem having a critical\nsignificance in the context of medical imaging. For instance, in laparoscopic\nsurgery, the acquired video data suffers from different kinds of distortion\nthat not only hinder surgery performance but also affect the execution of\nsubsequent tasks in surgical navigation and robotic surgeries. For this reason,\nwe propose in this paper neural network-based approaches for distortion\nclassification as well as quality prediction. More precisely, a Residual\nNetwork (ResNet) based approach is firstly developed for simultaneous ranking\nand classification task. Then, this architecture is extended to make it\nappropriate for the quality prediction task by using an additional Fully\nConnected Neural Network (FCNN). To train the overall architecture (ResNet and\nFCNN models), transfer learning and end-to-end learning approaches are\ninvestigated. Experimental results, carried out on a new laparoscopic video\nquality database, have shown the efficiency of the proposed methods compared to\nrecent conventional and deep learning based approaches.",
    "descriptor": "",
    "authors": [
      "Zohaib Amjad Khan",
      "Azeddine Beghdadi",
      "Mounir Kaaniche",
      "Faouzi Alaya Cheikh",
      "Osama Gharbi"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.04517"
  },
  {
    "id": "arXiv:2202.04542",
    "title": "Spectrally Adaptive Common Spatial Patterns",
    "abstract": "The method of Common Spatial Patterns (CSP) is widely used for feature\nextraction of electroencephalography (EEG) data, such as in motor imagery\nbrain-computer interface (BCI) systems. It is a data-driven method estimating a\nset of spatial filters so that the power of the filtered EEG signal is\nmaximized for one motor imagery class and minimized for the other. This method,\nhowever, is prone to overfitting and is known to suffer from poor\ngeneralization especially with limited calibration data. Additionally, due to\nthe high heterogeneity in brain data and the non-stationarity of brain\nactivity, CSP is usually trained for each user separately resulting in long\ncalibration sessions or frequent re-calibrations that are tiring for the user.\nIn this work, we propose a novel algorithm called Spectrally Adaptive Common\nSpatial Patterns (SACSP) that improves CSP by learning a temporal/spectral\nfilter for each spatial filter so that the spatial filters are concentrated on\nthe most relevant temporal frequencies for each user. We show the efficacy of\nSACSP in providing better generalizability and higher classification accuracy\nfrom calibration to online control compared to existing methods. Furthermore,\nwe show that SACSP provides neurophysiologically relevant information about the\ntemporal frequencies of the filtered signals. Our results highlight the\ndifferences in the motor imagery signal among BCI users as well as spectral\ndifferences in the signals generated for each class, and show the importance of\nlearning robust user-specific features in a data-driven manner.",
    "descriptor": "",
    "authors": [
      "Mahta Mousavi",
      "Eric Lybrand",
      "Shuangquan Feng",
      "Shuai Tang",
      "Rayan Saab",
      "Virginia de Sa"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2202.04542"
  },
  {
    "id": "arXiv:2202.04565",
    "title": "Precision Radiotherapy via Information Integration of Expert Human  Knowledge and AI Recommendation to Optimize Clinical Decision Making",
    "abstract": "In the precision medicine era, there is a growing need for precision\nradiotherapy where the planned radiation dose needs to be optimally determined\nby considering a myriad of patient-specific information in order to ensure\ntreatment efficacy. Existing artificial-intelligence (AI) methods can recommend\nradiation dose prescriptions within the scope of this available information.\nHowever, treating physicians may not fully entrust the AI's recommended\nprescriptions due to known limitations or when the AI recommendation may go\nbeyond physicians' current knowledge. This paper lays out a systematic method\nto integrate expert human knowledge with AI recommendations for optimizing\nclinical decision making. Towards this goal, Gaussian process (GP) models are\nintegrated with deep neural networks (DNNs) to quantify the uncertainty of the\ntreatment outcomes given by physicians and AI recommendations, respectively,\nwhich are further used as a guideline to educate clinical physicians and\nimprove AI models performance. The proposed method is demonstrated in a\ncomprehensive dataset where patient-specific information and treatment outcomes\nare prospectively collected during radiotherapy of $67$ non-small cell lung\ncancer patients and retrospectively analyzed.",
    "descriptor": "",
    "authors": [
      "Wenbo Sun",
      "Dipesh Niraula",
      "Issam El Naqa",
      "Randall K Ten Haken",
      "Ivo D Dinov",
      "Kyle Cuneo",
      "Judy Jin"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.04565"
  },
  {
    "id": "arXiv:2202.04581",
    "title": "Noise fingerprints in quantum computers: Machine learning software tools",
    "abstract": "In this paper we present the high-level functionalities of a\nquantum-classical machine learning software, whose purpose is to learn the main\nfeatures (the fingerprint) of quantum noise sources affecting a quantum device,\nas a quantum computer. Specifically, the software architecture is designed to\nclassify successfully (more than 99% of accuracy) the noise fingerprints in\ndifferent quantum devices with similar technical specifications, or distinct\ntime-dependences of a noise fingerprint in single quantum machines.",
    "descriptor": "\nComments: 9 pages, 2 figures\n",
    "authors": [
      "Stefano Martina",
      "Stefano Gherardini",
      "Lorenzo Buffoni",
      "Filippo Caruso"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.04581"
  },
  {
    "id": "arXiv:2202.04589",
    "title": "Adjoint-aided inference of Gaussian process driven differential  equations",
    "abstract": "Linear systems occur throughout engineering and the sciences, most notably as\ndifferential equations. In many cases the forcing function for the system is\nunknown, and interest lies in using noisy observations of the system to infer\nthe forcing, as well as other unknown parameters. In differential equations,\nthe forcing function is an unknown function of the independent variables\n(typically time and space), and can be modelled as a Gaussian process (GP). In\nthis paper we show how the adjoint of a linear system can be used to\nefficiently infer forcing functions modelled as GPs, after using a truncated\nbasis expansion of the GP kernel. We show how exact conjugate Bayesian\ninference for the truncated GP can be achieved, in many cases with\nsubstantially lower computation than would be required using MCMC methods. We\ndemonstrate the approach on systems of both ordinary and partial differential\nequations, and by testing on synthetic data, show that the basis expansion\napproach approximates well the true forcing with a modest number of basis\nvectors. Finally, we show how to infer point estimates for the non-linear model\nparameters, such as the kernel length-scales, using Bayesian optimisation.",
    "descriptor": "",
    "authors": [
      "Paterne Gahungu",
      "Christopher W Lanyon",
      "Mauricio A Alvarez",
      "Engineer Bainomugisha",
      "Michael Smith",
      "Richard D. Wilkinson"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.04589"
  },
  {
    "id": "arXiv:2202.04592",
    "title": "Stability Analysis of Recurrent Neural Networks by IQC with Copositive  Mutipliers",
    "abstract": "This paper is concerned with the stability analysis of the recurrent neural\nnetworks (RNNs) by means of the integral quadratic constraint (IQC) framework.\nThe rectified linear unit (ReLU) is typically employed as the activation\nfunction of the RNN, and the ReLU has specific nonnegativity properties\nregarding its input and output signals. Therefore, it is effective if we can\nderive IQC-based stability conditions with multipliers taking care of such\nnonnegativity properties. However, such nonnegativity (linear) properties are\nhardly captured by the existing multipliers defined on the positive\nsemidefinite cone. To get around this difficulty, we loosen the standard\npositive semidefinite cone to the copositive cone, and employ copositive\nmultipliers to capture the nonnegativity properties. We show that, within the\nframework of the IQC, we can employ copositive multipliers (or their inner\napproximation) together with existing multipliers such as Zames-Falb\nmultipliers and polytopic bounding multipliers, and this directly enables us to\nensure that the introduction of the copositive multipliers leads to better (no\nmore conservative) results. We finally illustrate the effectiveness of the\nIQC-based stability conditions with the copositive multipliers by numerical\nexamples.",
    "descriptor": "\nComments: 6 pages, 2 figures. arXiv admin note: text overlap with arXiv:2011.12726\n",
    "authors": [
      "Yoshio Ebihara",
      "Hayato Waki",
      "Victor Magron",
      "Ngoc Hoang Anh Mai",
      "Dimitri Peaucelle",
      "Sophie Tarbouriech"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.04592"
  },
  {
    "id": "arXiv:2202.04595",
    "title": "Exploring Structural Sparsity in Neural Image Compression",
    "abstract": "Neural image compression have reached or out-performed traditional methods\n(such as JPEG, BPG, WebP). However,their sophisticated network structures with\ncascaded convolution layers bring heavy computational burden for practical\ndeployment. In this paper, we explore the structural sparsity in neural image\ncompression network to obtain real-time acceleration without any specialized\nhardware design or algorithm. We propose a simple plug-in adaptive binary\nchannel masking(ABCM) to judge the importance of each convolution channel and\nintroduce sparsity during training. During inference, the unimportant channels\nare pruned to obtain slimmer network and less computation. We implement our\nmethod into three neural image compression networks with different entropy\nmodels to verify its effectiveness and generalization, the experiment results\nshow that up to 7x computation reduction and 3x acceleration can be achieved\nwith negligible performance drop.",
    "descriptor": "\nComments: 5 pages, 5 figures, submitted to ICIP 2022\n",
    "authors": [
      "Shanzhi Yin",
      "Fanyang Meng",
      "Wen Tan",
      "Chao Li",
      "Youneng Bao",
      "Yongsheng Liang",
      "Wei Liu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.04595"
  },
  {
    "id": "arXiv:2202.04598",
    "title": "Reproducibility in Optimization: Theoretical Framework and Limits",
    "abstract": "We initiate a formal study of reproducibility in optimization. We define a\nquantitative measure of reproducibility of optimization procedures in the face\nof noisy or error-prone operations such as inexact or stochastic gradient\ncomputations or inexact initialization. We then analyze several convex\noptimization settings of interest such as smooth, non-smooth, and\nstrongly-convex objective functions and establish tight bounds on the limits of\nreproducibility in each setting. Our analysis reveals a fundamental trade-off\nbetween computation and reproducibility: more computation is necessary (and\nsufficient) for better reproducibility.",
    "descriptor": "\nComments: 51 pages\n",
    "authors": [
      "Kwangjun Ahn",
      "Prateek Jain",
      "Ziwei Ji",
      "Satyen Kale",
      "Praneeth Netrapalli",
      "Gil I. Shamir"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.04598"
  },
  {
    "id": "arXiv:2202.04602",
    "title": "An Experimental Proof of Concept for Integrated Sensing and  Communications Waveform Design",
    "abstract": "The integration of sensing and communication (ISAC) functionalities have\nrecently gained significant research interest as a hardware-, power-, spectrum-\nand cost- efficient solution. This experimental work focuses on a\ndual-functional radar sensing and communication framework where a single\nradiation waveform, either omnidirectional or directional, can realize both\nradar sensing and communication functions. We study a trade-off approach that\ncan balance the performance of communications and radar sensing. We design an\northogonal frequency division multiplexing (OFDM) based multi-user multiple\ninput multiple output (MIMO) software-defined radio (SDR) testbed to validate\nthe dual-functional model. We carry out over-the-air experiments to investigate\nthe optimal trade-off factor to balance the performance for both functions. On\nthe radar performance, we measure the output beampatterns of our transmission\nto examine their similarity to simulation based beampatterns. On the\ncommunication side, we obtain bit error rate (BER) results from the testbed to\nshow the communication performance using the dual-functional waveform. Our\nexperiment reveals that the dual-functional approach can achieve comparable BER\nperformance with pure communication-based solutions while maintaining fine\nradar beampatterns simultaneously.",
    "descriptor": "",
    "authors": [
      "Tongyang Xu",
      "Fan Liu",
      "Christos Masouros",
      "Izzat Darwazeh"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.04602"
  },
  {
    "id": "arXiv:2202.04610",
    "title": "Anti-windup-like Compensator Synthesis for Discrete-Time Quantized  Control Systems",
    "abstract": "This paper addresses the problem of designing an anti-windup like compensator\nfor discrete-time linear control systems with quantized input. The proposed\ncompensator provides a correction signal proportional to the quantization error\nthat fed to the controller. The compensator is designed to ensure that\nsolutions to the closed-loop systems converge in finite time into a compact set\ncontaining the origin that can be tuned by the designer. A numerically\ntractable algorithm with feasibility guarantees is provided for the design of\nthe compensator. The proposed results are illustrated on an academic example\nand an open-loop unstable aircraft system.",
    "descriptor": "\nComments: V1 is submitted for presentation at the 10th IFAC Symposium on Robust Control Design ROCOND 2022\n",
    "authors": [
      "Samer AlSamadi",
      "Francesco Ferrante",
      "Sophie Tarbouriech"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.04610"
  },
  {
    "id": "arXiv:2202.04640",
    "title": "Sharper Rates for Separable Minimax and Finite Sum Optimization via  Primal-Dual Extragradient Methods",
    "abstract": "We design accelerated algorithms with improved rates for several fundamental\nclasses of optimization problems. Our algorithms all build upon techniques\nrelated to the analysis of primal-dual extragradient methods via relative\nLipschitzness proposed recently by [CST21].\n(1) Separable minimax optimization. We study separable minimax optimization\nproblems $\\min_x \\max_y f(x) - g(y) + h(x, y)$, where $f$ and $g$ have\nsmoothness and strong convexity parameters $(L^x, \\mu^x)$, $(L^y, \\mu^y)$, and\n$h$ is convex-concave with a $(\\Lambda^{xx}, \\Lambda^{xy},\n\\Lambda^{yy})$-blockwise operator norm bounded Hessian. We provide an algorithm\nwith gradient query complexity $\\tilde{O}\\left(\\sqrt{\\frac{L^{x}}{\\mu^{x}}} +\n\\sqrt{\\frac{L^{y}}{\\mu^{y}}} + \\frac{\\Lambda^{xx}}{\\mu^{x}} +\n\\frac{\\Lambda^{xy}}{\\sqrt{\\mu^{x}\\mu^{y}}} +\n\\frac{\\Lambda^{yy}}{\\mu^{y}}\\right)$. Notably, for convex-concave minimax\nproblems with bilinear coupling (e.g.\\ quadratics), where $\\Lambda^{xx} =\n\\Lambda^{yy} = 0$, our rate matches a lower bound of [ZHZ19].\n(2) Finite sum optimization. We study finite sum optimization problems\n$\\min_x \\frac{1}{n}\\sum_{i\\in[n]} f_i(x)$, where each $f_i$ is $L_i$-smooth and\nthe overall problem is $\\mu$-strongly convex. We provide an algorithm with\ngradient query complexity $\\tilde{O}\\left(n + \\sum_{i\\in[n]}\n\\sqrt{\\frac{L_i}{n\\mu}} \\right)$. Notably, when the smoothness bounds\n$\\{L_i\\}_{i\\in[n]}$ are non-uniform, our rate improves upon accelerated SVRG\n[LMH15, FGKS15] and Katyusha [All17] by up to a $\\sqrt{n}$ factor.\n(3) Minimax finite sums. We generalize our algorithms for minimax and finite\nsum optimization to solve a natural family of minimax finite sum optimization\nproblems at an accelerated rate, encapsulating both above results up to a\nlogarithmic factor.",
    "descriptor": "",
    "authors": [
      "Yujia Jin",
      "Aaron Sidford",
      "Kevin Tian"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.04640"
  },
  {
    "id": "arXiv:2202.04641",
    "title": "Unconditionally secure digital signatures implemented in an 8-user  quantum network",
    "abstract": "The ability to know and verifiably demonstrate the origins of messages can\noften be as important as encrypting the message itself. Here we present an\nexperimental demonstration of an unconditionally secure digital signature (USS)\nprotocol implemented for the first time, to the best of our knowledge, on a\nfully connected quantum network without trusted nodes. Our USS protocol is\nsecure against forging, repudiation and messages are transferrable. We show the\nfeasibility of unconditionally secure signatures using only bi-partite\nentangled states distributed throughout the network and experimentally evaluate\nthe performance of the protocol in real world scenarios with varying message\nlengths.",
    "descriptor": "\nComments: 9 pages, 7 figures, 1 table\n",
    "authors": [
      "Yoann Pelet",
      "Ittoop Vergheese Puthoor",
      "Natarajan Venkatachalam",
      "S\u00f6ren Wengerowsky",
      "Martin Lon\u010dari\u0107",
      "Sebastian Philipp Neumann",
      "Bo Liu",
      "\u017deljko Samec",
      "Mario Stip\u010devi\u0107",
      "Rupert Ursin",
      "Erika Andersson",
      "John G. Rarity",
      "Djeylan Aktas",
      "Siddarth Koduru Joshi"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.04641"
  },
  {
    "id": "arXiv:1503.03170",
    "title": "Min Morse: Approximability & Applications",
    "abstract": "Comments: There is a fatal flaw in section 6.6. The correct versions of (in)approximability results for Morse matching appear in: 1. this https URL 2. this https URL and 3. arXiv:1503.03170",
    "descriptor": "\nComments: There is a fatal flaw in section 6.6. The correct versions of (in)approximability results for Morse matching appear in: 1. this https URL 2. this https URL and 3. arXiv:1503.03170\n",
    "authors": [
      "Abhishek Rathore"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/1503.03170"
  },
  {
    "id": "arXiv:1606.06361",
    "title": "A Probabilistic Generative Grammar for Semantic Parsing",
    "abstract": "A Probabilistic Generative Grammar for Semantic Parsing",
    "descriptor": "",
    "authors": [
      "Abulhair Saparov"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1606.06361"
  },
  {
    "id": "arXiv:1810.01538",
    "title": "A Practical Approach to Proper Inference with Linked Data",
    "abstract": "Comments: 31 pages, 2 figures",
    "descriptor": "\nComments: 31 pages, 2 figures\n",
    "authors": [
      "Andee Kaplan",
      "Brenda Betancourt",
      "Rebecca C. Steorts"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Databases (cs.DB)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/1810.01538"
  },
  {
    "id": "arXiv:1905.11866",
    "title": "When can unlabeled data improve the learning rate?",
    "abstract": "Comments: Small correction in proof of Theorem 1",
    "descriptor": "\nComments: Small correction in proof of Theorem 1\n",
    "authors": [
      "Christina G\u00f6pfert",
      "Shai Ben-David",
      "Olivier Bousquet",
      "Sylvain Gelly",
      "Ilya Tolstikhin",
      "Ruth Urner"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1905.11866"
  },
  {
    "id": "arXiv:1906.10462",
    "title": "Policy Optimization with Stochastic Mirror Descent",
    "abstract": "Policy Optimization with Stochastic Mirror Descent",
    "descriptor": "",
    "authors": [
      "Long Yang",
      "Yu Zhang",
      "Gang Zheng",
      "Qian Zheng",
      "Pengfei Li",
      "Jianhang Huang",
      "Jun Wen",
      "Gang Pan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1906.10462"
  },
  {
    "id": "arXiv:1908.11230",
    "title": "Defeating Misclassification Attacks Against Transfer Learning",
    "abstract": "Comments: This paper has been published in IEEE Transactions on Dependable and Secure Computing. this https URL",
    "descriptor": "\nComments: This paper has been published in IEEE Transactions on Dependable and Secure Computing. this https URL\n",
    "authors": [
      "Bang Wu",
      "Shuo Wang",
      "Xingliang Yuan",
      "Cong Wang",
      "Carsten Rudolph",
      "Xiangwen Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/1908.11230"
  },
  {
    "id": "arXiv:1909.05912",
    "title": "Joint Inference of Reward Machines and Policies for Reinforcement  Learning",
    "abstract": "Comments: Fixed incorrect references in proof of Lemma 4",
    "descriptor": "\nComments: Fixed incorrect references in proof of Lemma 4\n",
    "authors": [
      "Zhe Xu",
      "Ivan Gavran",
      "Yousef Ahmad",
      "Rupak Majumdar",
      "Daniel Neider",
      "Ufuk Topcu",
      "Bo Wu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/1909.05912"
  },
  {
    "id": "arXiv:1911.06226",
    "title": "Beyond Pairwise Comparisons in Social Choice: A Setwise Kemeny  Aggregation Problem",
    "abstract": "Comments: 36 pages, extends a work published at AAAI 2020. Compared to the previous version on arXiv, some notations have been changed, and section 5 has been added",
    "descriptor": "\nComments: 36 pages, extends a work published at AAAI 2020. Compared to the previous version on arXiv, some notations have been changed, and section 5 has been added\n",
    "authors": [
      "Hugo Gilbert",
      "Tom Portoleau",
      "Olivier Spanjaard"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/1911.06226"
  },
  {
    "id": "arXiv:1912.01473",
    "title": "Age of Information in Random Access Channels",
    "abstract": "Age of Information in Random Access Channels",
    "descriptor": "",
    "authors": [
      "Xingran Chen",
      "Konstantinos Gatsis",
      "Hamed Hassani",
      "Shirin Saeedi Bidokhti"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/1912.01473"
  },
  {
    "id": "arXiv:1912.12090",
    "title": "Polynomial-Time Exact MAP Inference on Discrete Models with Global  Dependencies",
    "abstract": "Polynomial-Time Exact MAP Inference on Discrete Models with Global  Dependencies",
    "descriptor": "",
    "authors": [
      "Alexander Bauer",
      "Shinichi Nakajima"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/1912.12090"
  },
  {
    "id": "arXiv:2001.02658",
    "title": "Distributionally Robust Deep Learning using Hardness Weighted Sampling",
    "abstract": "Distributionally Robust Deep Learning using Hardness Weighted Sampling",
    "descriptor": "",
    "authors": [
      "Lucas Fidon",
      "Michael Aertsen",
      "Thomas Deprest",
      "Doaa Emam",
      "Fr\u00e9d\u00e9ric Guffens",
      "Nada Mufti",
      "Esther Van Elslander",
      "Ernst Schwartz",
      "Michael Ebner",
      "Daniela Prayer",
      "Gregor Kasprian",
      "Anna L. David",
      "Andrew Melbourne",
      "S\u00e9bastien Ourselin",
      "Jan Deprest",
      "Georg Langs",
      "Tom Vercauteren"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2001.02658"
  },
  {
    "id": "arXiv:2004.07650",
    "title": "Fully Dynamic s-t Edge Connectivity in Subpolynomial Time",
    "abstract": "Fully Dynamic s-t Edge Connectivity in Subpolynomial Time",
    "descriptor": "",
    "authors": [
      "Wenyu Jin",
      "Xiaorui Sun"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2004.07650"
  },
  {
    "id": "arXiv:2004.10888",
    "title": "Mean-Variance Policy Iteration for Risk-Averse Reinforcement Learning",
    "abstract": "Comments: AAAI 2021",
    "descriptor": "\nComments: AAAI 2021\n",
    "authors": [
      "Shangtong Zhang",
      "Bo Liu",
      "Shimon Whiteson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2004.10888"
  },
  {
    "id": "arXiv:2007.15227",
    "title": "Federated Visualization: A Privacy-preserving Strategy for Aggregated  Visual Query",
    "abstract": "Federated Visualization: A Privacy-preserving Strategy for Aggregated  Visual Query",
    "descriptor": "",
    "authors": [
      "Wei Chen",
      "Yating Wei",
      "Zhiyong Wang",
      "Shuyue Zhou",
      "Bingru Lin",
      "Zhiguang Zhou"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Cryptography and Security (cs.CR)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2007.15227"
  },
  {
    "id": "arXiv:2009.01498",
    "title": "Physarum-Inspired Multi-Commodity Flow Dynamics",
    "abstract": "Comments: to appear in Theoretical Computer Science",
    "descriptor": "\nComments: to appear in Theoretical Computer Science\n",
    "authors": [
      "Vincenzo Bonifaci",
      "Enrico Facca",
      "Frederic Folz",
      "Andreas Karrenbauer",
      "Pavel Kolev",
      "Kurt Mehlhorn",
      "Giovanna Morigi",
      "Golnoosh Shahkarami",
      "Quentin Vermande"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2009.01498"
  },
  {
    "id": "arXiv:2009.04938",
    "title": "Dune-CurvedGrid -- A Dune module for surface parametrization",
    "abstract": "Comments: 26 pages",
    "descriptor": "\nComments: 26 pages\n",
    "authors": [
      "Simon Praetorius",
      "Florian Stenger"
    ],
    "subjectives": [
      "Mathematical Software (cs.MS)",
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2009.04938"
  },
  {
    "id": "arXiv:2010.00042",
    "title": "Sampling possible reconstructions of undersampled acquisitions in MR  imaging",
    "abstract": "Comments: Accepted to IEEE Transactions in Medical Imaging. Main article and appendix together. GIFs and code can be found on this https URL",
    "descriptor": "\nComments: Accepted to IEEE Transactions in Medical Imaging. Main article and appendix together. GIFs and code can be found on this https URL\n",
    "authors": [
      "Kerem C. Tezcan",
      "Neerav Karani",
      "Christian F. Baumgartner",
      "Ender Konukoglu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2010.00042"
  },
  {
    "id": "arXiv:2010.09343",
    "title": "SelfVoxeLO: Self-supervised LiDAR Odometry with Voxel-based Deep Neural  Networks",
    "abstract": "Comments: Accepted to CoRL 2020",
    "descriptor": "\nComments: Accepted to CoRL 2020\n",
    "authors": [
      "Yan Xu",
      "Zhaoyang Huang",
      "Kwan-Yee Lin",
      "Xinge Zhu",
      "Jianping Shi",
      "Hujun Bao",
      "Guofeng Zhang",
      "Hongsheng Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2010.09343"
  },
  {
    "id": "arXiv:2010.12543",
    "title": "Performance Analysis of Distributed Intelligent Reflective Surfaces for  Wireless Communications",
    "abstract": "Comments: 31 pages, 10 Figures, Journal version",
    "descriptor": "\nComments: 31 pages, 10 Figures, Journal version\n",
    "authors": [
      "Diluka Loku Galappaththige",
      "Dhanushka Kudathanthirige",
      "Gayan Amarasuriya Aruma Baduge"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2010.12543"
  },
  {
    "id": "arXiv:2011.05703",
    "title": "Heavy-tailed distribution of the number of publications within  scientific journals",
    "abstract": "Comments: Main text: 8 pages, 5 figures, 4 tables. 2 supplementary figures",
    "descriptor": "\nComments: Main text: 8 pages, 5 figures, 4 tables. 2 supplementary figures\n",
    "authors": [
      "Robin Delabays",
      "Melvyn Tyloo"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2011.05703"
  },
  {
    "id": "arXiv:2011.14195",
    "title": "A Recursive Algorithm for Mining Association Rules",
    "abstract": "A Recursive Algorithm for Mining Association Rules",
    "descriptor": "",
    "authors": [
      "Abdelkader Mokkadem",
      "Mariane Pelletier",
      "Louis Raimbault"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2011.14195"
  },
  {
    "id": "arXiv:2012.02513",
    "title": "Complexity of fixed point counting problems in Boolean Networks",
    "abstract": "Comments: 47 pages",
    "descriptor": "\nComments: 47 pages\n",
    "authors": [
      "Florian Bridoux",
      "Am\u00e9lia Durbec",
      "K\u00e9vin Perrot",
      "Adrien Richard"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Computational Complexity (cs.CC)",
      "Discrete Mathematics (cs.DM)",
      "Molecular Networks (q-bio.MN)"
    ],
    "url": "https://arxiv.org/abs/2012.02513"
  },
  {
    "id": "arXiv:2012.05473",
    "title": "Tensor Composition Net for Visual Relationship Prediction",
    "abstract": "Tensor Composition Net for Visual Relationship Prediction",
    "descriptor": "",
    "authors": [
      "Yuting Qiang",
      "Yongxin Yang",
      "Xueting Zhang",
      "Yanwen Guo",
      "Timothy M. Hospedales"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2012.05473"
  },
  {
    "id": "arXiv:2101.00078",
    "title": "Controlled Analyses of Social Biases in Wikipedia Bios",
    "abstract": "Comments: Accepted to the Web Conference 2022 (WWW '22)",
    "descriptor": "\nComments: Accepted to the Web Conference 2022 (WWW '22)\n",
    "authors": [
      "Anjalie Field",
      "Chan Young Park",
      "Kevin Z. Lin",
      "Yulia Tsvetkov"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2101.00078"
  },
  {
    "id": "arXiv:2102.02029",
    "title": "Frank-Wolfe with a Nearest Extreme Point Oracle",
    "abstract": "Comments: Appeared in Conference on Learning Theory (COLT), 2021",
    "descriptor": "\nComments: Appeared in Conference on Learning Theory (COLT), 2021\n",
    "authors": [
      "Dan Garber",
      "Noam Wolf"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2102.02029"
  },
  {
    "id": "arXiv:2102.07120",
    "title": "Long-Term Resource Allocation Fairness in Average Markov Decision  Process (AMDP) Environment",
    "abstract": "Comments: AAMAS 2022",
    "descriptor": "\nComments: AAMAS 2022\n",
    "authors": [
      "Ganesh Ghalme",
      "Vineet Nair",
      "Vishakha Patil",
      "Yilun Zhou"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2102.07120"
  },
  {
    "id": "arXiv:2102.11605",
    "title": "A tier-based typed programming language characterizing Feasible  Functionals",
    "abstract": "A tier-based typed programming language characterizing Feasible  Functionals",
    "descriptor": "",
    "authors": [
      "Emmanuel Hainry",
      "Bruce M. Kapron",
      "Jean-Yves Marion",
      "Romain P\u00e9choux"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2102.11605"
  },
  {
    "id": "arXiv:2103.02550",
    "title": "Methodology to Assess Quality, Presence, Empathy, Attitude, and  Attention in 360-degree Videos for Immersive Communications",
    "abstract": "Comments: IEEE Transactions on Affective Computing, Early Access",
    "descriptor": "\nComments: IEEE Transactions on Affective Computing, Early Access\n",
    "authors": [
      "Marta Orduna",
      "Pablo P\u00e9rez",
      "Jes\u00fas Guti\u00e9rrez",
      "Narciso Garc\u00eda"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2103.02550"
  },
  {
    "id": "arXiv:2103.03843",
    "title": "Finite element discretization methods for velocity-pressure and stream  function formulations of surface Stokes equations",
    "abstract": "Comments: 28 pages",
    "descriptor": "\nComments: 28 pages\n",
    "authors": [
      "Philip Brandner",
      "Thomas Jankuhn",
      "Simon Praetorius",
      "Arnold Reusken",
      "Axel Voigt"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2103.03843"
  },
  {
    "id": "arXiv:2103.05244",
    "title": "ModelingToolkit: A Composable Graph Transformation System For  Equation-Based Modeling",
    "abstract": "Comments: 10 pages, 3 figures, 1 table",
    "descriptor": "\nComments: 10 pages, 3 figures, 1 table\n",
    "authors": [
      "Yingbo Ma",
      "Shashi Gowda",
      "Ranjan Anantharaman",
      "Chris Laughman",
      "Viral Shah",
      "Chris Rackauckas"
    ],
    "subjectives": [
      "Mathematical Software (cs.MS)",
      "Symbolic Computation (cs.SC)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2103.05244"
  },
  {
    "id": "arXiv:2103.07809",
    "title": "Fooling Gaussian PTFs via Local Hyperconcentration",
    "abstract": "Comments: Added mention of independent and concurrent work of Kelley and Meka",
    "descriptor": "\nComments: Added mention of independent and concurrent work of Kelley and Meka\n",
    "authors": [
      "Ryan O'Donnell",
      "Rocco A. Servedio",
      "Li-Yang Tan",
      "Daniel Kane"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2103.07809"
  },
  {
    "id": "arXiv:2103.09316",
    "title": "Are deep learning models superior for missing data imputation in large  surveys? Evidence from an empirical comparison",
    "abstract": "Are deep learning models superior for missing data imputation in large  surveys? Evidence from an empirical comparison",
    "descriptor": "",
    "authors": [
      "Zhenhua Wang",
      "Olanrewaju Akande",
      "Jason Poulos",
      "Fan Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2103.09316"
  },
  {
    "id": "arXiv:2103.10698",
    "title": "AutoTune: Controller Tuning for High-Speed Flight",
    "abstract": "Comments: Video: this https URL; Code: this https URL",
    "descriptor": "\nComments: Video: this https URL; Code: this https URL\n",
    "authors": [
      "Antonio Loquercio",
      "Alessandro Saviolo",
      "Davide Scaramuzza"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.10698"
  },
  {
    "id": "arXiv:2103.12532",
    "title": "Balanced softmax cross-entropy for incremental learning with and without  memory",
    "abstract": "Comments: Journal extension of the ICANN 2021 paper (arXiv:2103.12532v3), under consideration at Computer Vision and Image Understanding",
    "descriptor": "\nComments: Journal extension of the ICANN 2021 paper (arXiv:2103.12532v3), under consideration at Computer Vision and Image Understanding\n",
    "authors": [
      "Quentin Jodelet",
      "Xin Liu",
      "Tsuyoshi Murata"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.12532"
  },
  {
    "id": "arXiv:2103.14210",
    "title": "Leaning Compact and Representative Features for Cross-Modality Person  Re-Identification",
    "abstract": "Comments: World Wide Web Journal, 20 pages, 6 figures",
    "descriptor": "\nComments: World Wide Web Journal, 20 pages, 6 figures\n",
    "authors": [
      "Guangwei Gao",
      "Hao Shao",
      "Fei Wu",
      "Meng Yang",
      "Yi Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.14210"
  },
  {
    "id": "arXiv:2104.00098",
    "title": "Balancing Fairness and Efficiency in Traffic Routing via Interpolated  Traffic Assignment",
    "abstract": "Balancing Fairness and Efficiency in Traffic Routing via Interpolated  Traffic Assignment",
    "descriptor": "",
    "authors": [
      "Devansh Jalota",
      "Kiril Solovey",
      "Matthew Tsao",
      "Stephen Zoepf",
      "Marco Pavone"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2104.00098"
  },
  {
    "id": "arXiv:2104.02951",
    "title": "A Hybrid Inference System for Improved Curvature Estimation in the  Level-Set Method Using Machine Learning",
    "abstract": "Comments: Submitted",
    "descriptor": "\nComments: Submitted\n",
    "authors": [
      "Luis \u00c1ngel Larios-C\u00e1rdenas",
      "Fr\u00e9d\u00e9ric Gibou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2104.02951"
  },
  {
    "id": "arXiv:2104.06262",
    "title": "On Determinism of Game Engines used for Simulation-based Autonomous  Vehicle Verification",
    "abstract": "Comments: 16 pages, 9 figures, 1 table",
    "descriptor": "\nComments: 16 pages, 9 figures, 1 table\n",
    "authors": [
      "Greg Chance",
      "Abanoub Ghobrial",
      "Kevin McAreavey",
      "Severin Lemaignan",
      "Tony Pipe",
      "Kerstin Eder"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Performance (cs.PF)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2104.06262"
  },
  {
    "id": "arXiv:2104.08740",
    "title": "On the $\u03a6$-Stability and Related Conjectures",
    "abstract": "Comments: 36 pages, 1 figure",
    "descriptor": "\nComments: 36 pages, 1 figure\n",
    "authors": [
      "Lei Yu"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Information Theory (cs.IT)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2104.08740"
  },
  {
    "id": "arXiv:2105.02359",
    "title": "MODS -- A USV-oriented object detection and obstacle segmentation  benchmark",
    "abstract": "Comments: 16 pages, 15 figures. The dataset, as well as the proposed evaluation protocols, are published on our website: this https URL",
    "descriptor": "\nComments: 16 pages, 15 figures. The dataset, as well as the proposed evaluation protocols, are published on our website: this https URL\n",
    "authors": [
      "Borja Bovcon",
      "Jon Muhovi\u010d",
      "Du\u0161ko Vranac",
      "Dean Mozeti\u010d",
      "Janez Per\u0161",
      "Matej Kristan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.02359"
  },
  {
    "id": "arXiv:2105.03595",
    "title": "Static Inference Meets Deep Learning: A Hybrid Type Inference Approach  for Python",
    "abstract": "Comments: This paper has been accepted by 44th International Conference on Software Engineering (ICSE 2022)",
    "descriptor": "\nComments: This paper has been accepted by 44th International Conference on Software Engineering (ICSE 2022)\n",
    "authors": [
      "Yun Peng",
      "Cuiyun Gao",
      "Zongjie Li",
      "Bowei Gao",
      "David Lo",
      "Qirun Zhang",
      "Michael Lyu"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2105.03595"
  },
  {
    "id": "arXiv:2105.11166",
    "title": "AirNet: Neural Network Transmission over the Air",
    "abstract": "AirNet: Neural Network Transmission over the Air",
    "descriptor": "",
    "authors": [
      "Mikolaj Jankowski",
      "Deniz Gunduz",
      "Krystian Mikolajczyk"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.11166"
  },
  {
    "id": "arXiv:2105.14391",
    "title": "Data-driven 6D Pose Tracking by Calibrating Image Residuals in Synthetic  Domains",
    "abstract": "Comments: CVPR 2021 Workshop on 3D Vision and Robotics. arXiv admin note: substantial text overlap with arXiv:2007.13866",
    "descriptor": "\nComments: CVPR 2021 Workshop on 3D Vision and Robotics. arXiv admin note: substantial text overlap with arXiv:2007.13866\n",
    "authors": [
      "Bowen Wen",
      "Chaitanya Mitash",
      "Kostas Bekris"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2105.14391"
  },
  {
    "id": "arXiv:2105.14709",
    "title": "Joint Stabilization and Regret Minimization through Switching in  Over-Actuated Systems (extended version)",
    "abstract": "Joint Stabilization and Regret Minimization through Switching in  Over-Actuated Systems (extended version)",
    "descriptor": "",
    "authors": [
      "Jafar Abbaszadeh Chekan",
      "Kamyar Azizzadenesheli",
      "Cedric Langbort"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2105.14709"
  },
  {
    "id": "arXiv:2106.05200",
    "title": "Independent mechanism analysis, a new concept?",
    "abstract": "Comments: NeurIPS 2021 final camera-ready version",
    "descriptor": "\nComments: NeurIPS 2021 final camera-ready version\n",
    "authors": [
      "Luigi Gresele",
      "Julius von K\u00fcgelgen",
      "Vincent Stimper",
      "Bernhard Sch\u00f6lkopf",
      "Michel Besserve"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.05200"
  },
  {
    "id": "arXiv:2106.05824",
    "title": "Rare event estimation using stochastic spectral embedding",
    "abstract": "Rare event estimation using stochastic spectral embedding",
    "descriptor": "",
    "authors": [
      "P.-R. Wagner",
      "S. Marelli",
      "I. Papaioannou",
      "D. Straub",
      "B. Sudret"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.05824"
  },
  {
    "id": "arXiv:2106.06042",
    "title": "FedBABU: Towards Enhanced Representation for Federated Image  Classification",
    "abstract": "Comments: Published at ICLR 2022",
    "descriptor": "\nComments: Published at ICLR 2022\n",
    "authors": [
      "Jaehoon Oh",
      "Sangmook Kim",
      "Se-Young Yun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.06042"
  },
  {
    "id": "arXiv:2106.06733",
    "title": "LENAS: Learning-based Neural Architecture Search and Ensemble for 3D  Radiotherapy Dose Prediction",
    "abstract": "LENAS: Learning-based Neural Architecture Search and Ensemble for 3D  Radiotherapy Dose Prediction",
    "descriptor": "",
    "authors": [
      "Yi Lin",
      "Yanfei Liu",
      "Hao Chen",
      "Xin Yang",
      "Kai Ma",
      "Yefeng Zheng",
      "Kwang-Ting Cheng"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.06733"
  },
  {
    "id": "arXiv:2106.11514",
    "title": "Rethinking Adam: A Twofold Exponential Moving Average Approach",
    "abstract": "Rethinking Adam: A Twofold Exponential Moving Average Approach",
    "descriptor": "",
    "authors": [
      "Yizhou Wang",
      "Yue Kang",
      "Can Qin",
      "Huan Wang",
      "Yi Xu",
      "Yulun Zhang",
      "Yun Fu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.11514"
  },
  {
    "id": "arXiv:2106.11813",
    "title": "Enabling hyper-differential sensitivity analysis for ill-posed inverse  problems",
    "abstract": "Comments: 24 pages",
    "descriptor": "\nComments: 24 pages\n",
    "authors": [
      "Joseph Hart",
      "Bart van Bloemen Waanders"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.11813"
  },
  {
    "id": "arXiv:2106.12329",
    "title": "Games in the Time of COVID-19: Promoting Mechanism Design for Pandemic  Response",
    "abstract": "Comments: Extended version of arXiv:2006.06674: Corona Games: Masks, Social Distancing and Mechanism Design",
    "descriptor": "\nComments: Extended version of arXiv:2006.06674: Corona Games: Masks, Social Distancing and Mechanism Design\n",
    "authors": [
      "Bal\u00e1zs Pej\u00f3",
      "Gergely Bicz\u00f3k"
    ],
    "subjectives": [
      "Theoretical Economics (econ.TH)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2106.12329"
  },
  {
    "id": "arXiv:2106.13797",
    "title": "PVTv2: Improved Baselines with Pyramid Vision Transformer",
    "abstract": "Comments: Accepted to CVMJ 2022",
    "descriptor": "\nComments: Accepted to CVMJ 2022\n",
    "authors": [
      "Wenhai Wang",
      "Enze Xie",
      "Xiang Li",
      "Deng-Ping Fan",
      "Kaitao Song",
      "Ding Liang",
      "Tong Lu",
      "Ping Luo",
      "Ling Shao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.13797"
  },
  {
    "id": "arXiv:2106.15499",
    "title": "Self-Contrastive Learning: An Efficient Supervised Contrastive Framework  with Single-view and Sub-network",
    "abstract": "Comments: 23 pages, 7 figures, and 21 tables",
    "descriptor": "\nComments: 23 pages, 7 figures, and 21 tables\n",
    "authors": [
      "Sangmin Bae",
      "Sungnyun Kim",
      "Jongwoo Ko",
      "Gihun Lee",
      "Seungjong Noh",
      "Se-Young Yun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.15499"
  },
  {
    "id": "arXiv:2107.01700",
    "title": "End-to-end Neural Coreference Resolution Revisited: A Simple yet  Effective Baseline",
    "abstract": "Comments: Accepted by ICASSP 2022",
    "descriptor": "\nComments: Accepted by ICASSP 2022\n",
    "authors": [
      "Tuan Manh Lai",
      "Trung Bui",
      "Doo Soon Kim"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2107.01700"
  },
  {
    "id": "arXiv:2107.04422",
    "title": "Policy gradient methods for distortion risk measures",
    "abstract": "Policy gradient methods for distortion risk measures",
    "descriptor": "",
    "authors": [
      "Nithia Vijayan",
      "Prashanth L.A"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.04422"
  },
  {
    "id": "arXiv:2107.05893",
    "title": "PU-Flow: a Point Cloud Upsampling Networkwith Normalizing Flows",
    "abstract": "PU-Flow: a Point Cloud Upsampling Networkwith Normalizing Flows",
    "descriptor": "",
    "authors": [
      "Aihua Mao",
      "Zihui Du",
      "Junhui Hou",
      "Yaqi Duan",
      "Yong-jin Liu",
      "Ying He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.05893"
  },
  {
    "id": "arXiv:2107.08509",
    "title": "Enhancing synchronization by optimal correlated noise",
    "abstract": "Comments: 5 pages, 4 figures, including supplemental material. Accepted at Physical Review Letters",
    "descriptor": "\nComments: 5 pages, 4 figures, including supplemental material. Accepted at Physical Review Letters\n",
    "authors": [
      "Sherwood Martineau",
      "Tim Saffold",
      "Timothy Chang",
      "Henrik Ronellenfitsch"
    ],
    "subjectives": [
      "Adaptation and Self-Organizing Systems (nlin.AO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2107.08509"
  },
  {
    "id": "arXiv:2107.08966",
    "title": "Decoupled Reinforcement Learning to Stabilise Intrinsically-Motivated  Exploration",
    "abstract": "Comments: Published at the International Conference on Autonomous Agents and Multi-Agent Systems (AAMAS) 2022",
    "descriptor": "\nComments: Published at the International Conference on Autonomous Agents and Multi-Agent Systems (AAMAS) 2022\n",
    "authors": [
      "Lukas Sch\u00e4fer",
      "Filippos Christianos",
      "Josiah P. Hanna",
      "Stefano V. Albrecht"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.08966"
  },
  {
    "id": "arXiv:2107.10984",
    "title": "Human Pose Transfer with Augmented Disentangled Feature Consistency",
    "abstract": "Comments: 12 pages, 5 figures",
    "descriptor": "\nComments: 12 pages, 5 figures\n",
    "authors": [
      "Kun Wu",
      "Chengxiang Yin",
      "Zhengping Che",
      "Bo Jiang",
      "Jian Tang",
      "Zheng Guan",
      "Gangyi Ding"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.10984"
  },
  {
    "id": "arXiv:2107.13405",
    "title": "Automatic Unstructured Handwashing Recognition using Smartwatch to  Reduce Contact Transmission of Pathogens",
    "abstract": "Automatic Unstructured Handwashing Recognition using Smartwatch to  Reduce Contact Transmission of Pathogens",
    "descriptor": "",
    "authors": [
      "Emanuele Lattanzi",
      "Lorenzo Calisti",
      "Valerio Freschi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Human-Computer Interaction (cs.HC)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2107.13405"
  },
  {
    "id": "arXiv:2107.14226",
    "title": "Learning more skills through optimistic exploration",
    "abstract": "Comments: Accepted at ICLR 2022 (spotlight)",
    "descriptor": "\nComments: Accepted at ICLR 2022 (spotlight)\n",
    "authors": [
      "DJ Strouse",
      "Kate Baumli",
      "David Warde-Farley",
      "Vlad Mnih",
      "Steven Hansen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.14226"
  },
  {
    "id": "arXiv:2108.01434",
    "title": "Wavelet-Based Network For High Dynamic Range Imaging",
    "abstract": "Wavelet-Based Network For High Dynamic Range Imaging",
    "descriptor": "",
    "authors": [
      "Tianhong Dai",
      "Wei Li",
      "Xilei Cao",
      "Jianzhuang Liu",
      "Xu Jia",
      "Ales Leonardis",
      "Youliang Yan",
      "Shanxin Yuan"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.01434"
  },
  {
    "id": "arXiv:2108.02167",
    "title": "Acyclic and Cyclic Reversing Computations in Petri Nets",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:2101.07066 by other authors",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2101.07066 by other authors\n",
    "authors": [
      "Kamila Barylska",
      "Anna Gogoli\u0144ska"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2108.02167"
  },
  {
    "id": "arXiv:2108.04342",
    "title": "Near optimal efficient decoding from pooled data",
    "abstract": "Near optimal efficient decoding from pooled data",
    "descriptor": "",
    "authors": [
      "Max Hahn-Klimroth",
      "Noela M\u00fcller"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Discrete Mathematics (cs.DM)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2108.04342"
  },
  {
    "id": "arXiv:2108.06975",
    "title": "Successful New-entry Prediction for Multi-Party Online Conversations via  Latent Topics and Discourse Modeling",
    "abstract": "Comments: Accepted by WWW 2022",
    "descriptor": "\nComments: Accepted by WWW 2022\n",
    "authors": [
      "Lingzhi Wang",
      "Jing Li",
      "Xingshan Zeng",
      "Kam-Fai Wong"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2108.06975"
  },
  {
    "id": "arXiv:2108.07898",
    "title": "Informed Crowds Can Effectively Identify Misinformation",
    "abstract": "Informed Crowds Can Effectively Identify Misinformation",
    "descriptor": "",
    "authors": [
      "Paul Resnick",
      "Aljohara Alfayez",
      "Jane Im",
      "Eric Gilbert"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2108.07898"
  },
  {
    "id": "arXiv:2109.00699",
    "title": "FBSNet: A Fast Bilateral Symmetrical Network for Real-Time Semantic  Segmentation",
    "abstract": "Comments: 11 pages, 7 figures, 5 tables",
    "descriptor": "\nComments: 11 pages, 7 figures, 5 tables\n",
    "authors": [
      "Guangwei Gao",
      "Guoan Xu",
      "Juncheng Li",
      "Yi Yu",
      "Huimin Lu",
      "Jian Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.00699"
  },
  {
    "id": "arXiv:2109.01475",
    "title": "The typical set and entropy in stochastic systems with arbitrary phase  space growth",
    "abstract": "Comments: 15 pages, 4 figures",
    "descriptor": "\nComments: 15 pages, 4 figures\n",
    "authors": [
      "Rudolf Hanel",
      "Bernat Corominas-Murtra"
    ],
    "subjectives": [
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2109.01475"
  },
  {
    "id": "arXiv:2109.01652",
    "title": "Finetuned Language Models Are Zero-Shot Learners",
    "abstract": "Comments: Version 5. Find list of changes in Appendix F (page 35)",
    "descriptor": "\nComments: Version 5. Find list of changes in Appendix F (page 35)\n",
    "authors": [
      "Jason Wei",
      "Maarten Bosma",
      "Vincent Y. Zhao",
      "Kelvin Guu",
      "Adams Wei Yu",
      "Brian Lester",
      "Nan Du",
      "Andrew M. Dai",
      "Quoc V. Le"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.01652"
  },
  {
    "id": "arXiv:2109.04786",
    "title": "Wi-Fi Meets ML: A Survey on Improving IEEE 802.11 Performance with  Machine Learning",
    "abstract": "Comments: 57 pages, 23 figures, 383 references",
    "descriptor": "\nComments: 57 pages, 23 figures, 383 references\n",
    "authors": [
      "Szymon Szott",
      "Katarzyna Kosek-Szott",
      "Piotr Gaw\u0142owicz",
      "Jorge Torres G\u00f3mez",
      "Boris Bellalta",
      "Anatolij Zubow",
      "Falko Dressler"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2109.04786"
  },
  {
    "id": "arXiv:2109.06160",
    "title": "Augmenting Decision Making via Interactive What-If Analysis",
    "abstract": "Comments: CIDR'22",
    "descriptor": "\nComments: CIDR'22\n",
    "authors": [
      "Sneha Gathani",
      "Madelon Hulsebos",
      "James Gale",
      "Peter J. Haas",
      "\u00c7a\u011fatay Demiralp"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.06160"
  },
  {
    "id": "arXiv:2109.10436",
    "title": "Classification with Nearest Disjoint Centroids",
    "abstract": "Classification with Nearest Disjoint Centroids",
    "descriptor": "",
    "authors": [
      "Nicolas Fraiman",
      "Zichao Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2109.10436"
  },
  {
    "id": "arXiv:2109.10581",
    "title": "Deep Augmented MUSIC Algorithm for Data-Driven DoA Estimation",
    "abstract": "Comments: Accepted to ICASSP 2022 - IEEE International Conference on Acoustics, Speech and Signal Processing",
    "descriptor": "\nComments: Accepted to ICASSP 2022 - IEEE International Conference on Acoustics, Speech and Signal Processing\n",
    "authors": [
      "Julian P. Merkofer",
      "Guy Revach",
      "Nir Shlezinger",
      "Ruud J. G. van Sloun"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.10581"
  },
  {
    "id": "arXiv:2109.14391",
    "title": "Computing the average inter-sample time of event-triggered control using  quantitative automata",
    "abstract": "Comments: Submitted to Nonlinear Analysis: Hybrid Systems v2: fixing plant and controller data of numerical example in Sec. 6.2",
    "descriptor": "\nComments: Submitted to Nonlinear Analysis: Hybrid Systems v2: fixing plant and controller data of numerical example in Sec. 6.2\n",
    "authors": [
      "Gabriel de Albuquerque Gleizer",
      "Manuel Mazo Jr"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2109.14391"
  },
  {
    "id": "arXiv:2110.01732",
    "title": "Faster algorithm for counting of the integer points number in  $\u0394$-modular polyhedra",
    "abstract": "Faster algorithm for counting of the integer points number in  $\u0394$-modular polyhedra",
    "descriptor": "",
    "authors": [
      "D. V. Gribanov",
      "D. S. Malyshev"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Computational Geometry (cs.CG)",
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2110.01732"
  },
  {
    "id": "arXiv:2110.01878",
    "title": "On the Properties of Error Patterns in the Constant Lee Weight Channel",
    "abstract": "On the Properties of Error Patterns in the Constant Lee Weight Channel",
    "descriptor": "",
    "authors": [
      "Jessica Bariffi",
      "Hannes Bartz",
      "Gianluigi Liva",
      "Joachim Rosenthal"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2110.01878"
  },
  {
    "id": "arXiv:2110.02732",
    "title": "On Margin Maximization in Linear and ReLU Networks",
    "abstract": "Comments: This version includes: Some updates to the introduction; Focuses only on homogeneous networks",
    "descriptor": "\nComments: This version includes: Some updates to the introduction; Focuses only on homogeneous networks\n",
    "authors": [
      "Gal Vardi",
      "Ohad Shamir",
      "Nathan Srebro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.02732"
  },
  {
    "id": "arXiv:2110.03303",
    "title": "Universal Approximation Under Constraints is Possible with Transformers",
    "abstract": "Comments: 9.5 Pages + 14 Page Append + References, 3 Tables, 5 Figures",
    "descriptor": "\nComments: 9.5 Pages + 14 Page Append + References, 3 Tables, 5 Figures\n",
    "authors": [
      "Anastasis Kratsios",
      "Behnoosh Zamanlooy",
      "Tianlin Liu",
      "Ivan Dokmani\u0107"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Functional Analysis (math.FA)",
      "Metric Geometry (math.MG)"
    ],
    "url": "https://arxiv.org/abs/2110.03303"
  },
  {
    "id": "arXiv:2110.03372",
    "title": "Unifying Likelihood-free Inference with Black-box Optimization and  Beyond",
    "abstract": "Comments: ICLR 2022 spotlight",
    "descriptor": "\nComments: ICLR 2022 spotlight\n",
    "authors": [
      "Dinghuai Zhang",
      "Jie Fu",
      "Yoshua Bengio",
      "Aaron Courville"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Biomolecules (q-bio.BM)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.03372"
  },
  {
    "id": "arXiv:2110.03442",
    "title": "A Comparison of Neural Network Architectures for Data-Driven  Reduced-Order Modeling",
    "abstract": "A Comparison of Neural Network Architectures for Data-Driven  Reduced-Order Modeling",
    "descriptor": "",
    "authors": [
      "Anthony Gruber",
      "Max Gunzburger",
      "Lili Ju",
      "Zhu Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.03442"
  },
  {
    "id": "arXiv:2110.04004",
    "title": "Trident Pyramid Networks: The importance of processing at the feature  pyramid level for better object detection",
    "abstract": "Trident Pyramid Networks: The importance of processing at the feature  pyramid level for better object detection",
    "descriptor": "",
    "authors": [
      "C\u00e9dric Picron",
      "Tinne Tuytelaars"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.04004"
  },
  {
    "id": "arXiv:2110.04677",
    "title": "Interpretable Aesthetic Analysis Model for Intelligent Photography  Guidance Systems",
    "abstract": "Interpretable Aesthetic Analysis Model for Intelligent Photography  Guidance Systems",
    "descriptor": "",
    "authors": [
      "Xiaoran Wu"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2110.04677"
  },
  {
    "id": "arXiv:2110.04738",
    "title": "Uncertainty in Data-Driven Kalman Filtering for Partially Known  State-Space Models",
    "abstract": "Comments: Accepted to ICASSP 2022 - IEEE International Conference on Acoustics, Speech and Signal Processing",
    "descriptor": "\nComments: Accepted to ICASSP 2022 - IEEE International Conference on Acoustics, Speech and Signal Processing\n",
    "authors": [
      "Itzik Klein",
      "Guy Revach",
      "Nir Shlezinger",
      "Jonas E. Mehr",
      "Ruud J. G. van Sloun",
      "Yonina. C. Eldar"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.04738"
  },
  {
    "id": "arXiv:2110.05038",
    "title": "Recurrent Model-Free RL can be a Strong Baseline for Many POMDPs",
    "abstract": "Comments: Code: this https URL Project site: this https URL",
    "descriptor": "\nComments: Code: this https URL Project site: this https URL\n",
    "authors": [
      "Tianwei Ni",
      "Benjamin Eysenbach",
      "Ruslan Salakhutdinov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.05038"
  },
  {
    "id": "arXiv:2110.05428",
    "title": "Learning Temporally Causal Latent Processes from General Temporal Data",
    "abstract": "Comments: ICLR 2022: this https URL",
    "descriptor": "\nComments: ICLR 2022: this https URL\n",
    "authors": [
      "Weiran Yao",
      "Yuewen Sun",
      "Alex Ho",
      "Changyin Sun",
      "Kun Zhang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.05428"
  },
  {
    "id": "arXiv:2110.05558",
    "title": "Algebraic and Puiseux series solutions of systems of autonomous  algebraic ODEs of dimension one in several variables",
    "abstract": "Algebraic and Puiseux series solutions of systems of autonomous  algebraic ODEs of dimension one in several variables",
    "descriptor": "",
    "authors": [
      "Jose Cano",
      "Sebastian Falkensteiner",
      "Daniel Robertz",
      "Rafael Sendra"
    ],
    "subjectives": [
      "Algebraic Geometry (math.AG)",
      "Symbolic Computation (cs.SC)"
    ],
    "url": "https://arxiv.org/abs/2110.05558"
  },
  {
    "id": "arXiv:2110.06986",
    "title": "ADMM-DAD net: a deep unfolding network for analysis compressed sensing",
    "abstract": "Comments: to appear in 2022 International Conference on Acoustics, Speech and Signal Processing (ICASSP)",
    "descriptor": "\nComments: to appear in 2022 International Conference on Acoustics, Speech and Signal Processing (ICASSP)\n",
    "authors": [
      "Vasiliki Kouni",
      "Georgios Paraskevopoulos",
      "Holger Rauhut",
      "George C. Alexandropoulos"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.06986"
  },
  {
    "id": "arXiv:2110.07022",
    "title": "Lossy Compression with Universal Distortion",
    "abstract": "Lossy Compression with Universal Distortion",
    "descriptor": "",
    "authors": [
      "Adeel Mahmood",
      "Aaron B. Wagner"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2110.07022"
  },
  {
    "id": "arXiv:2110.08923",
    "title": "A Dual Approach to Constrained Markov Decision Processes with Entropy  Regularization",
    "abstract": "Comments: 23 pages, AISTATS22",
    "descriptor": "\nComments: 23 pages, AISTATS22\n",
    "authors": [
      "Donghao Ying",
      "Yuhao Ding",
      "Javad Lavaei"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2110.08923"
  },
  {
    "id": "arXiv:2110.08935",
    "title": "InfAnFace: Bridging the infant-adult domain gap in facial landmark  estimation in the wild",
    "abstract": "InfAnFace: Bridging the infant-adult domain gap in facial landmark  estimation in the wild",
    "descriptor": "",
    "authors": [
      "Michael Wan",
      "Shaotong Zhu",
      "Lingfei Luan",
      "Gulati Prateek",
      "Xiaofei Huang",
      "Rebecca Schwartz-Mette",
      "Marie Hayes",
      "Emily Zimmerman",
      "Sarah Ostadabbas"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.08935"
  },
  {
    "id": "arXiv:2110.09215",
    "title": "A Primer on the Statistical Relation between Wireless Ultra-Reliability  and Location Estimation",
    "abstract": "Comments: 5 pages and 4 figures. Has been submitted in IEEE Wireless Communication Letters. This is a resubmission of the original letter which is currently in the review process",
    "descriptor": "\nComments: 5 pages and 4 figures. Has been submitted in IEEE Wireless Communication Letters. This is a resubmission of the original letter which is currently in the review process\n",
    "authors": [
      "Tobias Kallehauge",
      "Pablo Ram\u00edrez-Espinosa",
      "Kimmo Kansanen",
      "Henk Wymeersch",
      "Petar Popovski"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.09215"
  },
  {
    "id": "arXiv:2110.10234",
    "title": "Collaboration Challenges in Building ML-Enabled Systems: Communication,  Documentation, Engineering, and Process",
    "abstract": "Comments: 22 pages, 10 figures, 5 tables",
    "descriptor": "\nComments: 22 pages, 10 figures, 5 tables\n",
    "authors": [
      "Nadia Nahar",
      "Shurui Zhou",
      "Grace Lewis",
      "Christian K\u00e4stner"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.10234"
  },
  {
    "id": "arXiv:2110.10827",
    "title": "How to pose material design problems for flow through porous media  applications?: Sensitivity of dissipation rate to medium's permeability holds  the key",
    "abstract": "How to pose material design problems for flow through porous media  applications?: Sensitivity of dissipation rate to medium's permeability holds  the key",
    "descriptor": "",
    "authors": [
      "K. B. Nakshatrala"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.10827"
  },
  {
    "id": "arXiv:2110.15545",
    "title": "Improving Fairness via Federated Learning",
    "abstract": "Comments: 39 pages, 7 figures",
    "descriptor": "\nComments: 39 pages, 7 figures\n",
    "authors": [
      "Yuchen Zeng",
      "Hongxu Chen",
      "Kangwook Lee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.15545"
  },
  {
    "id": "arXiv:2110.15777",
    "title": "GBK-GNN: Gated Bi-Kernel Graph Neural Networks for Modeling Both  Homophily and Heterophily",
    "abstract": "Comments: 9 pages, accepted by WWW'22",
    "descriptor": "\nComments: 9 pages, accepted by WWW'22\n",
    "authors": [
      "Lun Du",
      "Xiaozhou Shi",
      "Qiang Fu",
      "Xiaojun Ma",
      "Hengyu Liu",
      "Shi Han",
      "Dongmei Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.15777"
  },
  {
    "id": "arXiv:2111.00108",
    "title": "High-dimensional multi-trait GWAS by reverse prediction of genotypes",
    "abstract": "High-dimensional multi-trait GWAS by reverse prediction of genotypes",
    "descriptor": "",
    "authors": [
      "Muhammad Ammar Malik",
      "Adriaan-Alexander Ludl",
      "Tom Michoel"
    ],
    "subjectives": [
      "Genomics (q-bio.GN)",
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2111.00108"
  },
  {
    "id": "arXiv:2111.02318",
    "title": "Nearly Tight Lower Bounds for Succinct Range Minimum Query",
    "abstract": "Nearly Tight Lower Bounds for Succinct Range Minimum Query",
    "descriptor": "",
    "authors": [
      "Mingmou Liu"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2111.02318"
  },
  {
    "id": "arXiv:2111.02671",
    "title": "GraphSearchNet: Enhancing GNNs via Capturing Global Dependency for  Semantic Code Search",
    "abstract": "GraphSearchNet: Enhancing GNNs via Capturing Global Dependency for  Semantic Code Search",
    "descriptor": "",
    "authors": [
      "Shangqing Liu",
      "Xiaofei Xie",
      "Jingkai Siow",
      "Lei Ma",
      "Guozhu Meng",
      "Yang Liu"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.02671"
  },
  {
    "id": "arXiv:2111.05080",
    "title": "Residual Quantity in Percentage of Factory Machines Using Computer  Vision and Mathematical Methods",
    "abstract": "Comments: 4 pages, 13 figures",
    "descriptor": "\nComments: 4 pages, 13 figures\n",
    "authors": [
      "Seunghyeon Kim",
      "Jihoon Ryoo",
      "Dongyeob Lee",
      "Youngho Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.05080"
  },
  {
    "id": "arXiv:2111.05578",
    "title": "Conversational Recommendation: Theoretical Model and Complexity Analysis",
    "abstract": "Conversational Recommendation: Theoretical Model and Complexity Analysis",
    "descriptor": "",
    "authors": [
      "Tommaso Di Noia",
      "Francesco Donini",
      "Dietmar Jannach",
      "Fedelucio Narducci",
      "Claudio Pomo"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computational Complexity (cs.CC)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2111.05578"
  },
  {
    "id": "arXiv:2111.07658",
    "title": "Calculating Question Similarity is Enough: A New Method for KBQA Tasks",
    "abstract": "Calculating Question Similarity is Enough: A New Method for KBQA Tasks",
    "descriptor": "",
    "authors": [
      "Hanyu Zhao",
      "Sha Yuan",
      "Jiahong Leng",
      "Xiang Pan",
      "Guoqiang Wang",
      "Ledell Wu",
      "Jie Tang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.07658"
  },
  {
    "id": "arXiv:2111.10639",
    "title": "Implicit Acoustic Echo Cancellation for Keyword Spotting and  Device-Directed Speech Detection",
    "abstract": "Comments: Submitted to INTERSPEECH 2022",
    "descriptor": "\nComments: Submitted to INTERSPEECH 2022\n",
    "authors": [
      "Samuele Cornell",
      "Thomas Balestri",
      "Thibaud S\u00e9n\u00e9chal"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2111.10639"
  },
  {
    "id": "arXiv:2111.13207",
    "title": "Characteristic Neural Ordinary Differential Equations",
    "abstract": "Characteristic Neural Ordinary Differential Equations",
    "descriptor": "",
    "authors": [
      "Xingzi Xu",
      "Ali Hasan",
      "Khalil Elkhalil",
      "Jie Ding",
      "Vahid Tarokh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.13207"
  },
  {
    "id": "arXiv:2111.13400",
    "title": "An Exact Method for Fortification Games",
    "abstract": "Comments: New computations with the benchmark method added",
    "descriptor": "\nComments: New computations with the benchmark method added\n",
    "authors": [
      "Markus Leitner",
      "Ivana Ljubi\u0107",
      "Michele Monaci",
      "Markus Sinnl",
      "K\u00fcbra Tan\u0131nm\u0131\u015f"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2111.13400"
  },
  {
    "id": "arXiv:2112.03805",
    "title": "Learning nonlinear feedforward: a Gaussian Process Approach Applied to a  Printer with Friction",
    "abstract": "Comments: 7 pages, 9 figures",
    "descriptor": "\nComments: 7 pages, 9 figures\n",
    "authors": [
      "Max van Meer",
      "Maurice Poot",
      "Jim Portegies",
      "Tom Oomen"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.03805"
  },
  {
    "id": "arXiv:2112.04075",
    "title": "Active Sensing for Communications by Learning",
    "abstract": "Comments: 14 Pages, 9 Figures; accepted in JSAC-SI-ISAC (IEEE Journal on Selected Areas in Communications Special Issue on Integrated Sensing and Communication). The source code for this paper is available at: this https URL",
    "descriptor": "\nComments: 14 Pages, 9 Figures; accepted in JSAC-SI-ISAC (IEEE Journal on Selected Areas in Communications Special Issue on Integrated Sensing and Communication). The source code for this paper is available at: this https URL\n",
    "authors": [
      "Foad Sohrabi",
      "Tao Jiang",
      "Wei Cui",
      "Wei Yu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.04075"
  },
  {
    "id": "arXiv:2112.05433",
    "title": "Improved Soft-aided Error-and-erasure Decoding of Product Codes with  Dynamic Reliability Scores",
    "abstract": "Comments: Optical Fiber Communication (OFC) Conference 2022",
    "descriptor": "\nComments: Optical Fiber Communication (OFC) Conference 2022\n",
    "authors": [
      "Sisi Miao",
      "Lukas Rapp",
      "Laurent Schmalen"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2112.05433"
  },
  {
    "id": "arXiv:2112.05848",
    "title": "Proximal Iteration for Deep Reinforcement Learning",
    "abstract": "Proximal Iteration for Deep Reinforcement Learning",
    "descriptor": "",
    "authors": [
      "Kavosh Asadi",
      "Rasool Fakoor",
      "Omer Gottesman",
      "Taesup Kim",
      "Michael L. Littman",
      "Alexander J. Smola"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.05848"
  },
  {
    "id": "arXiv:2112.05872",
    "title": "SLOSH: Set LOcality Sensitive Hashing via Sliced-Wasserstein Embeddings",
    "abstract": "SLOSH: Set LOcality Sensitive Hashing via Sliced-Wasserstein Embeddings",
    "descriptor": "",
    "authors": [
      "Yuzhe Lu",
      "Xinran Liu",
      "Andrea Soltoggio",
      "Soheil Kolouri"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.05872"
  },
  {
    "id": "arXiv:2112.06809",
    "title": "Persistent Object Identification Leveraging Non-Visual Markers",
    "abstract": "Persistent Object Identification Leveraging Non-Visual Markers",
    "descriptor": "",
    "authors": [
      "Michael P. J. Camilleri",
      "Li Zhang",
      "Rasneer S. Bains",
      "Andrew Zisserman",
      "Christopher K. I. Williams"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2112.06809"
  },
  {
    "id": "arXiv:2112.08839",
    "title": "Topology optimization with a closed cavity exclusion constraint for  additive manufacturing based on the fictitious physical model approach",
    "abstract": "Comments: 29 pages, 14 figures",
    "descriptor": "\nComments: 29 pages, 14 figures\n",
    "authors": [
      "Takayuki Yamada",
      "Yuki Noguchi"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2112.08839"
  },
  {
    "id": "arXiv:2112.08866",
    "title": "BayesFlow Can Reliably Detect Model Misspecification and Posterior  Errors in Amortized Bayesian Inference",
    "abstract": "Comments: 14 pages, 7 figures",
    "descriptor": "\nComments: 14 pages, 7 figures\n",
    "authors": [
      "Marvin Schmitt",
      "Paul-Christian B\u00fcrkner",
      "Ullrich K\u00f6the",
      "Stefan T. Radev"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.08866"
  },
  {
    "id": "arXiv:2112.09071",
    "title": "Multitask Network for Respiration Rate Estimation -- A Practical  Perspective",
    "abstract": "Comments: Preprint",
    "descriptor": "\nComments: Preprint\n",
    "authors": [
      "Kapil Singh Rathore",
      "Sricharan Vijayarangan",
      "Preejith SP",
      "Mohanasankar Sivaprakasam"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.09071"
  },
  {
    "id": "arXiv:2112.09746",
    "title": "Supervised Multivariate Learning with Simultaneous Feature Auto-grouping  and Dimension Reduction",
    "abstract": "Supervised Multivariate Learning with Simultaneous Feature Auto-grouping  and Dimension Reduction",
    "descriptor": "",
    "authors": [
      "Yiyuan She",
      "Jiahui Shen",
      "Chao Zhang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2112.09746"
  },
  {
    "id": "arXiv:2112.11052",
    "title": "Predicting Job Titles from Job Descriptions with Multi-label Text  Classification",
    "abstract": "Comments: Published in the 2021 NAFOSTED Conference on Information and Computer Science (NICS 2021)",
    "descriptor": "\nComments: Published in the 2021 NAFOSTED Conference on Information and Computer Science (NICS 2021)\n",
    "authors": [
      "Hieu Trung Tran",
      "Hanh Hong Phuc Vo",
      "Son T. Luu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.11052"
  },
  {
    "id": "arXiv:2112.15358",
    "title": "Conditional generative data-free knowledge distillation",
    "abstract": "Conditional generative data-free knowledge distillation",
    "descriptor": "",
    "authors": [
      "Xinyi Yu",
      "Ling Yan",
      "Yang Yang",
      "Libo Zhou",
      "Linlin Ou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.15358"
  },
  {
    "id": "arXiv:2201.03981",
    "title": "Demystifying the Vulnerability Propagation and Its Evolution via  Dependency Trees in the NPM Ecosystem",
    "abstract": "Demystifying the Vulnerability Propagation and Its Evolution via  Dependency Trees in the NPM Ecosystem",
    "descriptor": "",
    "authors": [
      "Chengwei Liu",
      "Sen Chen",
      "Lingling Fan",
      "Bihuan Chen",
      "Yang Liu",
      "Xin Peng"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2201.03981"
  },
  {
    "id": "arXiv:2201.04584",
    "title": "ECONet: Efficient Convolutional Online Likelihood Network for  Scribble-based Interactive Segmentation",
    "abstract": "Comments: Under review at MIDL 2022",
    "descriptor": "\nComments: Under review at MIDL 2022\n",
    "authors": [
      "Muhammad Asad",
      "Lucas Fidon",
      "Tom Vercauteren"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.04584"
  },
  {
    "id": "arXiv:2201.04933",
    "title": "Machine Learning-enhanced Efficient Spectroscopic Ellipsometry Modeling",
    "abstract": "Machine Learning-enhanced Efficient Spectroscopic Ellipsometry Modeling",
    "descriptor": "",
    "authors": [
      "Ayush Arunachalam",
      "S. Novia Berriel",
      "Parag Banerjee",
      "Kanad Basu"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.04933"
  },
  {
    "id": "arXiv:2201.05995",
    "title": "The Secure Storage Capacity of a DNA Wiretap Channel Model",
    "abstract": "Comments: 13 pages, 4 figures, long version of paper submitted to ISIT 2022. Version v2 contains a reasoning for the strictness of an inequality in Lemma 2",
    "descriptor": "\nComments: 13 pages, 4 figures, long version of paper submitted to ISIT 2022. Version v2 contains a reasoning for the strictness of an inequality in Lemma 2\n",
    "authors": [
      "Praneeth Kumar Vippathalla",
      "Navin Kashyap"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2201.05995"
  },
  {
    "id": "arXiv:2201.07076",
    "title": "Mitigating Misinformation Spread on Blockchain Enabled Social Media  Networks",
    "abstract": "Mitigating Misinformation Spread on Blockchain Enabled Social Media  Networks",
    "descriptor": "",
    "authors": [
      "Rui Luo",
      "Vikram Krishnamurthy",
      "Erik Blasch"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2201.07076"
  },
  {
    "id": "arXiv:2201.08226",
    "title": "Sketch-and-Lift: Scalable Subsampled Semidefinite Program for $K$-means  Clustering",
    "abstract": "Comments: Accepted at AISTATS 2022",
    "descriptor": "\nComments: Accepted at AISTATS 2022\n",
    "authors": [
      "Yubo Zhuang",
      "Xiaohui Chen",
      "Yun Yang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.08226"
  },
  {
    "id": "arXiv:2201.08315",
    "title": "Predictive Inference with Weak Supervision",
    "abstract": "Predictive Inference with Weak Supervision",
    "descriptor": "",
    "authors": [
      "Maxime Cauchois",
      "Suyash Gupta",
      "Alnur Ali",
      "John Duchi"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.08315"
  },
  {
    "id": "arXiv:2201.08538",
    "title": "Computation of Regions of Attraction for Hybrid Limit Cycles Using  Reachability: An Application to Walking Robots",
    "abstract": "Comments: Accepted to IEEE RA-L & ICRA, 2022",
    "descriptor": "\nComments: Accepted to IEEE RA-L & ICRA, 2022\n",
    "authors": [
      "Jason J. Choi",
      "Ayush Agrawal",
      "Koushil Sreenath",
      "Claire J. Tomlin",
      "Somil Bansal"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2201.08538"
  },
  {
    "id": "arXiv:2201.08954",
    "title": "Change Detection from Synthetic Aperture Radar Images via Graph-Based  Knowledge Supplement Network",
    "abstract": "Comments: Accepted by IEEE JSTARS",
    "descriptor": "\nComments: Accepted by IEEE JSTARS\n",
    "authors": [
      "Junjie Wang",
      "Feng Gao",
      "Junyu Dong",
      "Shan Zhang",
      "Qian Du"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2201.08954"
  },
  {
    "id": "arXiv:2201.09144",
    "title": "Background Invariant Classification on Infrared Imagery by Data  Efficient Training and Reducing Bias in CNNs",
    "abstract": "Comments: Accepted in AAAI-22 Workshop",
    "descriptor": "\nComments: Accepted in AAAI-22 Workshop\n",
    "authors": [
      "Maliha Arif",
      "Calvin Yong",
      "Abhijit Mahalanobis"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.09144"
  },
  {
    "id": "arXiv:2201.11619",
    "title": "Positive First-order Logic on Words and Graphs",
    "abstract": "Comments: LMCS, extended version of LICS 2021. arXiv admin note: substantial text overlap with arXiv:2101.01968",
    "descriptor": "\nComments: LMCS, extended version of LICS 2021. arXiv admin note: substantial text overlap with arXiv:2101.01968\n",
    "authors": [
      "Denis Kuperberg"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Logic in Computer Science (cs.LO)",
      "Logic (math.LO)"
    ],
    "url": "https://arxiv.org/abs/2201.11619"
  },
  {
    "id": "arXiv:2201.11803",
    "title": "On the Convergence of Heterogeneous Federated Learning with Arbitrary  Adaptive Online Model Pruning",
    "abstract": "On the Convergence of Heterogeneous Federated Learning with Arbitrary  Adaptive Online Model Pruning",
    "descriptor": "",
    "authors": [
      "Hanhan Zhou",
      "Tian Lan",
      "Guru Venkataramani",
      "Wenbo Ding"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2201.11803"
  },
  {
    "id": "arXiv:2201.12328",
    "title": "Toward Training at ImageNet Scale with Differential Privacy",
    "abstract": "Comments: 25 pages, 7 figures. Code available at this https URL",
    "descriptor": "\nComments: 25 pages, 7 figures. Code available at this https URL\n",
    "authors": [
      "Alexey Kurakin",
      "Shuang Song",
      "Steve Chien",
      "Roxana Geambasu",
      "Andreas Terzis",
      "Abhradeep Thakurta"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.12328"
  },
  {
    "id": "arXiv:2201.13425",
    "title": "Don't Change the Algorithm, Change the Data: Exploratory Data for  Offline Reinforcement Learning",
    "abstract": "Don't Change the Algorithm, Change the Data: Exploratory Data for  Offline Reinforcement Learning",
    "descriptor": "",
    "authors": [
      "Denis Yarats",
      "David Brandfonbrener",
      "Hao Liu",
      "Michael Laskin",
      "Pieter Abbeel",
      "Alessandro Lazaric",
      "Lerrel Pinto"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2201.13425"
  },
  {
    "id": "arXiv:2202.00633",
    "title": "Efficient Policy Space Response Oracles",
    "abstract": "Comments: 14 pages, 8 figures",
    "descriptor": "\nComments: 14 pages, 8 figures\n",
    "authors": [
      "Ming Zhou",
      "Jingxiao Chen",
      "Ying Wen",
      "Weinan Zhang",
      "Yaodong Yang",
      "Yong Yu"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2202.00633"
  },
  {
    "id": "arXiv:2202.01169",
    "title": "Unified Scaling Laws for Routed Language Models",
    "abstract": "Comments: Fixing typos and affiliation clarity",
    "descriptor": "\nComments: Fixing typos and affiliation clarity\n",
    "authors": [
      "Aidan Clark",
      "Diego de las Casas",
      "Aurelia Guy",
      "Arthur Mensch",
      "Michela Paganini",
      "Jordan Hoffmann",
      "Bogdan Damoc",
      "Blake Hechtman",
      "Trevor Cai",
      "Sebastian Borgeaud",
      "George van den Driessche",
      "Eliza Rutherford",
      "Tom Hennigan",
      "Matthew Johnson",
      "Katie Millican",
      "Albin Cassirer",
      "Chris Jones",
      "Elena Buchatskaya",
      "David Budden",
      "Laurent Sifre",
      "Simon Osindero",
      "Oriol Vinyals",
      "Jack Rae",
      "Erich Elsen",
      "Koray Kavukcuoglu",
      "Karen Simonyan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.01169"
  },
  {
    "id": "arXiv:2202.01383",
    "title": "Machine Learning Solar Wind Driving Magnetospheric Convection in Tail  Lobes",
    "abstract": "Machine Learning Solar Wind Driving Magnetospheric Convection in Tail  Lobes",
    "descriptor": "",
    "authors": [
      "Xin Cao",
      "Jasper S. Halekas",
      "Stein Haaland",
      "Suranga Ruhunusiri",
      "Karl-Heinz Glassmeier"
    ],
    "subjectives": [
      "Solar and Stellar Astrophysics (astro-ph.SR)",
      "Earth and Planetary Astrophysics (astro-ph.EP)",
      "Machine Learning (cs.LG)",
      "Space Physics (physics.space-ph)"
    ],
    "url": "https://arxiv.org/abs/2202.01383"
  },
  {
    "id": "arXiv:2202.01645",
    "title": "AI-as-a-Service Toolkit for Human-Centered Intelligence in Autonomous  Driving",
    "abstract": "AI-as-a-Service Toolkit for Human-Centered Intelligence in Autonomous  Driving",
    "descriptor": "",
    "authors": [
      "Valerio De Caro",
      "Saira Bano",
      "Achilles Machumilane",
      "Alberto Gotta",
      "Pietro Cassar\u00e1",
      "Antonio Carta",
      "Rudy Semola",
      "Christos Sardianos",
      "Christos Chronis",
      "Iraklis Varlamis",
      "Konstantinos Tserpes",
      "Vincenzo Lomonaco",
      "Claudio Gallicchio",
      "Davide Bacciu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2202.01645"
  },
  {
    "id": "arXiv:2202.01919",
    "title": "Theoretical Exploration of Solutions of Feedforward ReLU networks",
    "abstract": "Comments: v2,v3: hyperlink mode modified",
    "descriptor": "\nComments: v2,v3: hyperlink mode modified\n",
    "authors": [
      "Changcun Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.01919"
  },
  {
    "id": "arXiv:2202.02602",
    "title": "Connected and Automated Vehicle Platoon Formation Control via  Differential Games",
    "abstract": "Comments: 18 pages, 7 figures, 3 tables",
    "descriptor": "\nComments: 18 pages, 7 figures, 3 tables\n",
    "authors": [
      "Hossein B. Jond",
      "Aykut Y\u0131ld\u0131z"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.02602"
  },
  {
    "id": "arXiv:2202.02805",
    "title": "Formulating Connectedness in Security-Constrained Optimal Transmission  Switching Problems",
    "abstract": "Comments: 4 pages, latex; removed detailed SCOTS formulation",
    "descriptor": "\nComments: 4 pages, latex; removed detailed SCOTS formulation\n",
    "authors": [
      "Tong Han",
      "David J. Hill",
      "Yue Song"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.02805"
  },
  {
    "id": "arXiv:2202.02832",
    "title": "Detecting Melanoma Fairly: Skin Tone Detection and Debiasing for Skin  Lesion Classification",
    "abstract": "Comments: 8 pages",
    "descriptor": "\nComments: 8 pages\n",
    "authors": [
      "Peter J. Bevan",
      "Amir Atapour-Abarghouei"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.02832"
  },
  {
    "id": "arXiv:2202.02958",
    "title": "Comprehensive survey of computational learning methods for analysis of  gene expression data in genomics",
    "abstract": "Comments: 51 pages, 9 figures, 5 tables",
    "descriptor": "\nComments: 51 pages, 9 figures, 5 tables\n",
    "authors": [
      "Nikita Bhandari",
      "Rahee Walambe",
      "Ketan Kotecha",
      "Satyajeet Khare"
    ],
    "subjectives": [
      "Genomics (q-bio.GN)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.02958"
  },
  {
    "id": "arXiv:2202.03013",
    "title": "$\u03bc$AFL: Non-intrusive Feedback-driven Fuzzing for Microcontroller  Firmware",
    "abstract": "Comments: 44th International Conference on Software Engineering (ICSE 2022)",
    "descriptor": "\nComments: 44th International Conference on Software Engineering (ICSE 2022)\n",
    "authors": [
      "Wenqiang Li",
      "Jiameng Shi",
      "Fengjun Li",
      "Jingqiang Lin",
      "Wei Wang",
      "Le Guan"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2202.03013"
  },
  {
    "id": "arXiv:2202.03126",
    "title": "Reasoning for Complex Data through Ensemble-based Self-Supervised  Learning",
    "abstract": "Comments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Gabriel Bertocco",
      "Ant\u00f4nio The\u00f3filo",
      "Fernanda Andal\u00f3",
      "Anderson Rocha"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.03126"
  },
  {
    "id": "arXiv:2202.03140",
    "title": "OPP-Miner: Order-preserving sequential pattern mining",
    "abstract": "OPP-Miner: Order-preserving sequential pattern mining",
    "descriptor": "",
    "authors": [
      "Youxi Wu",
      "Qian Hu",
      "Yan Li",
      "Lei Guo",
      "Xingquan Zhu",
      "Xindong Wu"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.03140"
  },
  {
    "id": "arXiv:2202.03192",
    "title": "Reward is not enough: can we liberate AI from the reinforcement learning  paradigm?",
    "abstract": "Comments: 25 pages, 1 figure",
    "descriptor": "\nComments: 25 pages, 1 figure\n",
    "authors": [
      "Vacslav Glukhov"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.03192"
  },
  {
    "id": "arXiv:2202.03209",
    "title": "PSSNet: Planarity-sensible Semantic Segmentation of Large-scale Urban  Meshes",
    "abstract": "Comments: 8 pages,9 figures",
    "descriptor": "\nComments: 8 pages,9 figures\n",
    "authors": [
      "Weixiao Gao",
      "Liangliang Nan",
      "Bas Boom",
      "Hugo Ledoux"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.03209"
  },
  {
    "id": "arXiv:2202.03289",
    "title": "Approximation error of single hidden layer neural networks with fixed  weights",
    "abstract": "Comments: 13 pages, main theorem's proof shortened, content improved",
    "descriptor": "\nComments: 13 pages, main theorem's proof shortened, content improved\n",
    "authors": [
      "Vugar Ismailov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Classical Analysis and ODEs (math.CA)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.03289"
  },
  {
    "id": "arXiv:2202.03349",
    "title": "Conditional Gradients for the Approximately Vanishing Ideal",
    "abstract": "Comments: 22 pages",
    "descriptor": "\nComments: 22 pages\n",
    "authors": [
      "E. Wirth",
      "S. Pokutta"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.03349"
  },
  {
    "id": "arXiv:2202.03457",
    "title": "Selecting Seed Words for Wordle using Character Statistics",
    "abstract": "Selecting Seed Words for Wordle using Character Statistics",
    "descriptor": "",
    "authors": [
      "Nisansa de Silva"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.03457"
  },
  {
    "id": "arXiv:2202.03466",
    "title": "Reward-Respecting Subtasks for Model-Based Reinforcement Learning",
    "abstract": "Reward-Respecting Subtasks for Model-Based Reinforcement Learning",
    "descriptor": "",
    "authors": [
      "Richard S. Sutton",
      "Marlos C. Machado",
      "G. Zacharias Holland",
      "David Szepesvari",
      "Finbarr Timbers",
      "Brian Tanner",
      "Adam White"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.03466"
  },
  {
    "id": "arXiv:2202.03469",
    "title": "Locally Random P-adic Alloy Codes with Channel Coding Theorems for  Distributed Coded Tensors",
    "abstract": "Comments: 6 pages, preprint",
    "descriptor": "\nComments: 6 pages, preprint\n",
    "authors": [
      "Pedro Soto",
      "Haibin Guan",
      "Jun Li"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)",
      "Symbolic Computation (cs.SC)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.03469"
  },
  {
    "id": "arXiv:2202.03586",
    "title": "Fair SA: Sensitivity Analysis for Fairness in Face Recognition",
    "abstract": "Comments: 8 pages, 5 figures, to be published in NeurIPS 2021 Workshop, Algorithmic Fairness through the Lens of Causality and Robustness",
    "descriptor": "\nComments: 8 pages, 5 figures, to be published in NeurIPS 2021 Workshop, Algorithmic Fairness through the Lens of Causality and Robustness\n",
    "authors": [
      "Aparna R. Joshi",
      "Xavier Suau",
      "Nivedha Sivakumar",
      "Luca Zappella",
      "Nicholas Apostoloff"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.03586"
  },
  {
    "id": "arXiv:2202.03670",
    "title": "How to Understand Masked Autoencoders",
    "abstract": "How to Understand Masked Autoencoders",
    "descriptor": "",
    "authors": [
      "Shuhao Cao",
      "Peng Xu",
      "David A. Clifton"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.03670"
  },
  {
    "id": "arXiv:2202.03792",
    "title": "Counterfactual Multi-Token Fairness in Text Classification",
    "abstract": "Counterfactual Multi-Token Fairness in Text Classification",
    "descriptor": "",
    "authors": [
      "Pranay Lohia"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.03792"
  },
  {
    "id": "arXiv:2202.03805",
    "title": "Quantifying the topic disparity of scientific articles",
    "abstract": "Comments: 5 pages, 2 figures, Submitted to the 2nd International Workshop on Scientific Knowledge: Representation, Discovery, and Assessment",
    "descriptor": "\nComments: 5 pages, 2 figures, Submitted to the 2nd International Workshop on Scientific Knowledge: Representation, Discovery, and Assessment\n",
    "authors": [
      "Munjung Kim",
      "Jisung Yoon",
      "Woo-Sung Jung",
      "Hyunuk Kim"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2202.03805"
  },
  {
    "id": "arXiv:2202.03865",
    "title": "Backtrack Tie-Breaking for Decision Trees: A Note on Deodata Predictors",
    "abstract": "Backtrack Tie-Breaking for Decision Trees: A Note on Deodata Predictors",
    "descriptor": "",
    "authors": [
      "Cristian Alb"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.03865"
  },
  {
    "id": "arXiv:2202.03881",
    "title": "Robust Hybrid Learning With Expert Augmentation",
    "abstract": "Robust Hybrid Learning With Expert Augmentation",
    "descriptor": "",
    "authors": [
      "Antoine Wehenkel",
      "Jens Behrmann",
      "Hsiang Hsu",
      "Guillermo Sapiro",
      "Gilles Louppe",
      "J\u00f6rn-Henrik Jacobsen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.03881"
  },
  {
    "id": "arXiv:2202.03884",
    "title": "GraphDCA -- a Framework for Node Distribution Comparison in Real and  Synthetic Graphs",
    "abstract": "GraphDCA -- a Framework for Node Distribution Comparison in Real and  Synthetic Graphs",
    "descriptor": "",
    "authors": [
      "Ciwan Ceylan",
      "Petra Poklukar",
      "Hanna Hultin",
      "Alexander Kravchenko",
      "Anastasia Varava",
      "Danica Kragic"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.03884"
  },
  {
    "id": "arXiv:2202.03903",
    "title": "KENN: Enhancing Deep Neural Networks by Leveraging Knowledge for Time  Series Forecasting",
    "abstract": "KENN: Enhancing Deep Neural Networks by Leveraging Knowledge for Time  Series Forecasting",
    "descriptor": "",
    "authors": [
      "Muhammad Ali Chattha",
      "Ludger van Elst",
      "Muhammad Imran Malik",
      "Andreas Dengel",
      "Sheraz Ahmed"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.03903"
  },
  {
    "id": "arXiv:2202.03934",
    "title": "Alexa, in you, I trust! Fairness and Interpretability Issues in  E-commerce Search through Smart Speakers",
    "abstract": "Comments: This work has been accepted at The Web Conference 2022 (WWW'22)",
    "descriptor": "\nComments: This work has been accepted at The Web Conference 2022 (WWW'22)\n",
    "authors": [
      "Abhisek Dash",
      "Abhijnan Chakraborty",
      "Saptarshi Ghosh",
      "Animesh Mukherjee",
      "Krishna P. Gummadi"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2202.03934"
  },
  {
    "id": "arXiv:2202.03984",
    "title": "CausPref: Causal Preference Learning for Out-of-Distribution  Recommendation",
    "abstract": "Comments: WWW '22: The ACM Web Conference Proceedings",
    "descriptor": "\nComments: WWW '22: The ACM Web Conference Proceedings\n",
    "authors": [
      "Yue He",
      "Zimu Wang",
      "Peng Cui",
      "Hao Zou",
      "Yafeng Zhang",
      "Qiang Cui",
      "Yong Jiang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.03984"
  },
  {
    "id": "arXiv:2202.03986",
    "title": "Analysis of Voltage Stability in Terms of Interactions of  Q(U)-Characteristic Control in Distribution Grids",
    "abstract": "Comments: 7 pages Submitted to 5th International Conference on Smart Energy Systems and Technologies (SEST)",
    "descriptor": "\nComments: 7 pages Submitted to 5th International Conference on Smart Energy Systems and Technologies (SEST)\n",
    "authors": [
      "Sebastian Krahmer",
      "Stefan Ecklebe",
      "Peter Schegner",
      "Klaus R\u00f6benack"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.03986"
  },
  {
    "id": "arXiv:2202.04000",
    "title": "Learning Sinkhorn divergences for supervised change point detection",
    "abstract": "Comments: 19 pages, 13 figures",
    "descriptor": "\nComments: 19 pages, 13 figures\n",
    "authors": [
      "Nauman Ahad",
      "Eva L. Dyer",
      "Keith B. Hengen",
      "Yao Xie",
      "Mark A. Davenport"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.04000"
  },
  {
    "id": "arXiv:2202.04003",
    "title": "Differentiable N-gram Objective on Abstractive Summarization",
    "abstract": "Differentiable N-gram Objective on Abstractive Summarization",
    "descriptor": "",
    "authors": [
      "Yunqi Zhu",
      "Wensheng Zhang",
      "Mingjin Zhu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.04003"
  },
  {
    "id": "arXiv:2202.04058",
    "title": "PrivFair: a Library for Privacy-Preserving Fairness Auditing",
    "abstract": "PrivFair: a Library for Privacy-Preserving Fairness Auditing",
    "descriptor": "",
    "authors": [
      "Sikha Pentyala",
      "David Melanson",
      "Martine De Cock",
      "Golnoosh Farnadi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.04058"
  }
]
[
  {
    "id": "arXiv:2204.07167",
    "title": "Towards Porting Operating Systems with Program Synthesis",
    "abstract": "The end of Moore's Law has ushered in a diversity of hardware not seen in\ndecades. Operating system (and system software) portability is accordingly\nbecoming increasingly critical. Simultaneously, there has been tremendous\nprogress in program synthesis. We set out to explore the feasibility of using\nmodern program synthesis to generate the machine-dependent parts of an\noperating system. Our ultimate goal is to generate new ports automatically from\ndescriptions of new machines. One of the issues involved is writing\nspecifications, both for machine-dependent operating system functionality and\nfor instruction set architectures. We designed two domain-specific languages:\nAlewife for machine-independent specifications of machine-dependent operating\nsystem functionality, and Cassiopea for describing instruction set architecture\nsemantics. Automated porting also requires an implementation. We developed a\ntoolchain that, given an Alewife specification and a Cassiopea machine\ndescription, specializes the machine-independent specification to the target\ninstruction set architecture and synthesizes an implementation in assembly\nlanguage. Using this approach, we demonstrate successful synthesis of a total\nof 140 OS components from two pre-existing OSes for four real hardware\nplatforms. We also developed several optimization methods for OS-related\nassembly synthesis to improve scalability. The effectiveness of our languages\nand ability to synthesize code for all 140 specifications is evidence of the\nfeasibility of program synthesis for machine-dependent OS code. However, many\nresearch challenges remain; we also discuss the benefits and limitations of our\nsynthesis-based approach to automated OS porting.",
    "descriptor": "\nComments: submitted to TOPLAS (under revision)\n",
    "authors": [
      "Jingmei Hu",
      "Eric Lu",
      "David A. Holland",
      "Ming Kawaguchi",
      "Stephen Chong",
      "Margo I. Seltzer"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Operating Systems (cs.OS)"
    ],
    "url": "https://arxiv.org/abs/2204.07167"
  },
  {
    "id": "arXiv:2204.07175",
    "title": "Fundamentals of Compositional Rewriting Theory",
    "abstract": "A foundational theory of compositional categorical rewriting theory is\npresented, based on a collection of fibration-like properties that collectively\ninduce and structure intrinsically the large collection of lemmata used in the\nproofs of theorems such as concurrency and associativity. The resulting highly\ngeneric proofs of these theorems are given; it is noteworthy that the proof of\nthe concurrency theorem takes only a few lines and, while that of associativity\nremains somewhat longer, it would be unreadably long if written directly in\nterms of the basic lemmata. In addition to improving, or even enabling, the\nreadability of human-written proofs, we anticipate that this more generic and\nmodular style of writing proofs should organize and inform the production of\nformalized proofs in a proof assistant such as Coq or Isabelle. A curated list\nof known instances of our framework is used to conclude the paper with a\ndetailed discussion of the conditions under which the Double Pushout and\nSesqui-Pushout semantics of graph transformation are compositional.",
    "descriptor": "\nComments: 86 pages; invited and substantially extended journal version of arXiv:2105.02842\n",
    "authors": [
      "Nicolas Behr",
      "Russ Harmer",
      "Jean Krivine"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2204.07175"
  },
  {
    "id": "arXiv:2204.07176",
    "title": "A collaborative decomposition-based evolutionary algorithm integrating  normal and penalty-based boundary intersection for many-objective  optimization",
    "abstract": "Decomposition-based evolutionary algorithms have become fairly popular for\nmany-objective optimization in recent years. However, the existing\ndecomposition methods still are quite sensitive to the various shapes of\nfrontiers of many-objective optimization problems (MaOPs). On the one hand, the\ncone decomposition methods such as the penalty-based boundary intersection\n(PBI) are incapable of acquiring uniform frontiers for MaOPs with very convex\nfrontiers. On the other hand, the parallel reference lines of the parallel\ndecomposition methods including the normal boundary intersection (NBI) might\nresult in poor diversity because of under-sampling near the boundaries for\nMaOPs with concave frontiers. In this paper, a collaborative decomposition\nmethod is first proposed to integrate the advantages of parallel decomposition\nand cone decomposition to overcome their respective disadvantages. This method\ninherits the NBI-style Tchebycheff function as a convergence measure to\nheighten the convergence and uniformity of distribution of the PBI method.\nMoreover, this method also adaptively tunes the extent of rotating an NBI\nreference line towards a PBI reference line for every subproblem to enhance the\ndiversity of distribution of the NBI method. Furthermore, a collaborative\ndecomposition-based evolutionary algorithm (CoDEA) is presented for\nmany-objective optimization. A collaborative decomposition-based environmental\nselection mechanism is primarily designed in CoDEA to rank all the individuals\nassociated with the same PBI reference line in the boundary layer and pick out\nthe best ranks. CoDEA is compared with several popular algorithms on 85\nbenchmark test instances. The experimental results show that CoDEA achieves\nhigh competitiveness benefiting from the collaborative decomposition\nmaintaining a good balance among the convergence, uniformity, and diversity of\ndistribution.",
    "descriptor": "",
    "authors": [
      "Yu Wu",
      "Jianle Wei",
      "Weiqin Ying",
      "Yanqi Lan",
      "Zhen Cui",
      "Zhenyu Wang"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.07176"
  },
  {
    "id": "arXiv:2204.07177",
    "title": "Active Learning for Regression and Classification by Inverse Distance  Weighting",
    "abstract": "This paper proposes an active learning algorithm for solving regression and\nclassification problems based on inverse-distance weighting functions for\nselecting the feature vectors to query. The algorithm has the following\nfeatures: (i) supports both pool-based and population-based sampling; (ii) is\nindependent of the type of predictor used; (iii) can handle known and unknown\nconstraints on the queryable feature vectors; and (iv) can run either\nsequentially, or in batch mode, depending on how often the predictor is\nretrained. The method's potential is shown in numerical tests on illustrative\nsynthetic problems and real-world regression and classification datasets from\nthe UCI repository. A Python implementation of the algorithm that we call IDEAL\n(Inverse-Distance based Exploration for Active Learning), is available at\n\\url{this http URL}.",
    "descriptor": "\nComments: 17 pages, 8 figures. Submitted for publication\n",
    "authors": [
      "Alberto Bemporad"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.07177"
  },
  {
    "id": "arXiv:2204.07178",
    "title": "Relaxing Equivariance Constraints with Non-stationary Continuous Filters",
    "abstract": "Equivariances provide useful inductive biases in neural network modeling,\nwith the translation equivariance of convolutional neural networks being a\ncanonical example. Equivariances can be embedded in architectures through\nweight-sharing and place symmetry constraints on the functions a neural network\ncan represent. The type of symmetry is typically fixed and has to be chosen in\nadvance. Although some tasks are inherently equivariant, many tasks do not\nstrictly follow such symmetries. In such cases, equivariance constraints can be\noverly restrictive. In this work, we propose a parameter-efficient relaxation\nof equivariance that can effectively interpolate between a (i) non-equivariant\nlinear product, (ii) a strict-equivariant convolution, and (iii) a\nstrictly-invariant mapping. The proposed parameterization can be thought of as\na building block to allow adjustable symmetry structure in neural networks.\nCompared to non-equivariant or strict-equivariant baselines, we experimentally\nverify that soft equivariance leads to improved performance in terms of test\naccuracy on CIFAR-10 and CIFAR-100 image classification tasks.",
    "descriptor": "",
    "authors": [
      "Tycho F.A. van der Ouderaa",
      "David W. Romero",
      "Mark van der Wilk"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.07178"
  },
  {
    "id": "arXiv:2204.07182",
    "title": "Brazilian Court Documents Clustered by Similarity Together Using Natural  Language Processing Approaches with Transformers",
    "abstract": "Recent advances in Artificial intelligence (AI) have leveraged promising\nresults in solving complex problems in the area of Natural Language Processing\n(NLP), being an important tool to help in the expeditious resolution of\njudicial proceedings in the legal area. In this context, this work targets the\nproblem of detecting the degree of similarity between judicial documents that\ncan be achieved in the inference group, by applying six NLP techniques based on\ntransformers, namely BERT, GPT-2 and RoBERTa pre-trained in the Brazilian\nPortuguese language and the same specialized using 210,000 legal proceedings.\nDocuments were pre-processed and had their content transformed into a vector\nrepresentation using these NLP techniques. Unsupervised learning was used to\ncluster the lawsuits, calculating the quality of the model based on the cosine\nof the distance between the elements of the group to its centroid. We noticed\nthat models based on transformers present better performance when compared to\nprevious research, highlighting the RoBERTa model specialized in the Brazilian\nPortuguese language, making it possible to advance in the current state of the\nart in the area of NLP applied to the legal sector.",
    "descriptor": "",
    "authors": [
      "Raphael Souza de Oliveira",
      "Erick Giovani Sperandio Nascimento"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.07182"
  },
  {
    "id": "arXiv:2204.07183",
    "title": "Interactive Object Segmentation in 3D Point Clouds",
    "abstract": "Deep learning depends on large amounts of labeled training data. Manual\nlabeling is expensive and represents a bottleneck, especially for tasks such as\nsegmentation, where labels must be assigned down to the level of individual\npoints. That challenge is even more daunting for 3D data: 3D point clouds\ncontain millions of points per scene, and their accurate annotation is markedly\nmore time-consuming. The situation is further aggravated by the added\ncomplexity of user interfaces for 3D point clouds, which slows down annotation\neven more. For the case of 2D image segmentation, interactive techniques have\nbecome common, where user feedback in the form of a few clicks guides a\nsegmentation algorithm -- nowadays usually a neural network -- to achieve an\naccurate labeling with minimal effort. Surprisingly, interactive segmentation\nof 3D scenes has not been explored much. Previous work has attempted to obtain\naccurate 3D segmentation masks using human feedback from the 2D domain, which\nis only possible if correctly aligned images are available together with the 3D\npoint cloud, and it involves switching between the 2D and 3D domains. Here, we\npresent an interactive 3D object segmentation method in which the user\ninteracts directly with the 3D point cloud. Importantly, our model does not\nrequire training data from the target domain: when trained on ScanNet, it\nperforms well on several other datasets with different data characteristics as\nwell as different object classes. Moreover, our method is orthogonal to\nsupervised (instance) segmentation methods and can be combined with them to\nrefine automatic segmentations with minimal human effort.",
    "descriptor": "",
    "authors": [
      "Theodora Kontogianni",
      "Ekin Celikkan",
      "Siyu Tang",
      "Konrad Schindler"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.07183"
  },
  {
    "id": "arXiv:2204.07184",
    "title": "Separating the World and Ego Models for Self-Driving",
    "abstract": "Training self-driving systems to be robust to the long-tail of driving\nscenarios is a critical problem. Model-based approaches leverage simulation to\nemulate a wide range of scenarios without putting users at risk in the real\nworld. One promising path to faithful simulation is to train a forward model of\nthe world to predict the future states of both the environment and the\nego-vehicle given past states and a sequence of actions. In this paper, we\nargue that it is beneficial to model the state of the ego-vehicle, which often\nhas simple, predictable and deterministic behavior, separately from the rest of\nthe environment, which is much more complex and highly multimodal. We propose\nto model the ego-vehicle using a simple and differentiable kinematic model,\nwhile training a stochastic convolutional forward model on raster\nrepresentations of the state to predict the behavior of the rest of the\nenvironment. We explore several configurations of such decoupled models, and\nevaluate their performance both with Model Predictive Control (MPC) and direct\npolicy learning. We test our methods on the task of highway driving and\ndemonstrate lower crash rates and better stability. The code is available at\nhttps://github.com/vladisai/pytorch-PPUU/tree/ICLR2022.",
    "descriptor": "\nComments: 8 pages main content, 14 with references and appendix. 5 figures in total. Submitted and accepted to ICLR 2022 workshop on Generalizable Policy Learning in the Physical World (this https URL)\n",
    "authors": [
      "Vlad Sobal",
      "Alfredo Canziani",
      "Nicolas Carion",
      "Kyunghyun Cho",
      "Yann LeCun"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2204.07184"
  },
  {
    "id": "arXiv:2204.07185",
    "title": "This is the Moment for Probabilistic Loops",
    "abstract": "We present a novel static analysis technique to derive higher moments for\nprogram variables for a large class of probabilistic loops with potentially\nuncountable state spaces. Our approach is fully automatic, meaning it does not\nrely on externally provided invariants or templates. We employ algebraic\ntechniques based on linear recurrences and introduce program transformations to\nsimplify probabilistic programs while preserving their statistical properties.\nWe develop power reduction techniques to further simplify the polynomial\narithmetic of probabilistic programs and define the theory of moment-computable\nprobabilistic loops for which higher moments can precisely be computed. Our\nwork has applications towards recovering probability distributions of random\nvariables and computing tail probabilities. The empirical evaluation of our\nresults demonstrates the applicability of our work on many challenging\nexamples.",
    "descriptor": "",
    "authors": [
      "Marcel Moosbrugger",
      "Miroslav Stankovi\u010d",
      "Ezio Bartocci",
      "Laura Kov\u00e1cs"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2204.07185"
  },
  {
    "id": "arXiv:2204.07190",
    "title": "Measuring Compositional Consistency for Video Question Answering",
    "abstract": "Recent video question answering benchmarks indicate that state-of-the-art\nmodels struggle to answer compositional questions. However, it remains unclear\nwhich types of compositional reasoning cause models to mispredict. Furthermore,\nit is difficult to discern whether models arrive at answers using compositional\nreasoning or by leveraging data biases. In this paper, we develop a question\ndecomposition engine that programmatically deconstructs a compositional\nquestion into a directed acyclic graph of sub-questions. The graph is designed\nsuch that each parent question is a composition of its children. We present\nAGQA-Decomp, a benchmark containing $2.3M$ question graphs, with an average of\n$11.49$ sub-questions per graph, and $4.55M$ total new sub-questions. Using\nquestion graphs, we evaluate three state-of-the-art models with a suite of\nnovel compositional consistency metrics. We find that models either cannot\nreason correctly through most compositions or are reliant on incorrect\nreasoning to reach answers, frequently contradicting themselves or achieving\nhigh accuracies when failing at intermediate reasoning steps.",
    "descriptor": "\nComments: To appear in CVPR 2022. 23 pages, 12 figures and 12 tables\n",
    "authors": [
      "Mona Gandhi",
      "Mustafa Omer Gul",
      "Eva Prakash",
      "Madeleine Grunde-McLaughlin",
      "Ranjay Krishna",
      "Maneesh Agrawala"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.07190"
  },
  {
    "id": "arXiv:2204.07195",
    "title": "Hierarchical Control of Smart Particle Swarms",
    "abstract": "We present a method for the control of robot swarms which allows the shaping\nand the translation of patterns of simple robots (\"smart particles\"), using two\ntypes of devices. These two types represent a hierarchy: a larger group of\nsimple, oblivious robots (which we call the workers) that is governed by simple\nlocal attraction forces, and a smaller group (the guides) with sufficient\nmission knowledge to create and maintain a desired pattern by operating on the\nlocal forces of the former. This framework exploits the knowledge of the\nguides, which coordinate to shape the workers like smart particles by changing\ntheir interaction parameters. We study the approach with a large scale\nsimulation experiment in a physics based simulator with up to 1000 robots\nforming three different patterns. Our experiments reveal that the approach\nscales well with increasing robot numbers, and presents little pattern\ndistortion for a set of target moving shapes. We evaluate the approach on a\nphysical swarm of robots that use visual inertial odometry to compute their\nrelative positions and obtain results that are comparable with simulation. This\nwork lays foundation for designing and coordinating configurable smart\nparticles, with applications in smart materials and nanomedicine.",
    "descriptor": "\nComments: 10 pages, 8 figures\n",
    "authors": [
      "Vivek Shankar Varadharajan",
      "Sepand Dyanatkar",
      "Giovanni Beltrame"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2204.07195"
  },
  {
    "id": "arXiv:2204.07196",
    "title": "Testing distributional assumptions of learning algorithms",
    "abstract": "There are many important high dimensional function classes that have fast\nagnostic learning algorithms when strong assumptions on the distribution of\nexamples can be made, such as Gaussianity or uniformity over the domain. But\nhow can one be sufficiently confident that the data indeed satisfies the\ndistributional assumption, so that one can trust in the output quality of the\nagnostic learning algorithm? We propose a model by which to systematically\nstudy the design of tester-learner pairs $(\\mathcal{A},\\mathcal{T})$, such that\nif the distribution on examples in the data passes the tester $\\mathcal{T}$\nthen one can safely trust the output of the agnostic learner $\\mathcal{A}$ on\nthe data.\nTo demonstrate the power of the model, we apply it to the classical problem\nof agnostically learning halfspaces under the standard Gaussian distribution\nand present a tester-learner pair with a combined run-time of\n$n^{\\tilde{O}(1/\\epsilon^4)}$. This qualitatively matches that of the best\nknown ordinary agnostic learning algorithms for this task. In contrast, finite\nsample Gaussian distribution testers do not exist for the $L_1$ and EMD\ndistance measures. A key step in the analysis is a novel characterization of\nconcentration and anti-concentration properties of a distribution whose\nlow-degree moments approximately match those of a Gaussian. We also use tools\nfrom polynomial approximation theory.\nIn contrast, we show strong lower bounds on the combined run-times of\ntester-learner pairs for the problems of agnostically learning convex sets\nunder the Gaussian distribution and for monotone Boolean functions under the\nuniform distribution over $\\{0,1\\}^n$. Through these lower bounds we exhibit\nnatural problems where there is a dramatic gap between standard agnostic\nlearning run-time and the run-time of the best tester-learner pair.",
    "descriptor": "",
    "authors": [
      "Ronitt Rubinfeld",
      "Arsen Vasilyan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2204.07196"
  },
  {
    "id": "arXiv:2204.07197",
    "title": "RobustScaler: QoS-Aware Autoscaling for Complex Workloads",
    "abstract": "Autoscaling is a critical component for efficient resource utilization with\nsatisfactory quality of service (QoS) in cloud computing. This paper\ninvestigates proactive autoscaling for widely-used scaling-per-query\napplications where scaling is required for each query, such as container\nregistry and function-as-a-service (FaaS). In these scenarios, the workload\noften exhibits high uncertainty with complex temporal patterns like\nperiodicity, noises and outliers. Conservative strategies that scale out\nunnecessarily many instances lead to high resource costs whereas aggressive\nstrategies may result in poor QoS. We present RobustScaler to achieve superior\ntrade-off between cost and QoS. Specifically, we design a novel autoscaling\nframework based on non-homogeneous Poisson processes (NHPP) modeling and\nstochastically constrained optimization. Furthermore, we develop a specialized\nalternating direction method of multipliers (ADMM) to efficiently train the\nNHPP model, and rigorously prove the QoS guarantees delivered by our\noptimization-based proactive strategies. Extensive experiments show that\nRobustScaler outperforms common baseline autoscaling strategies in various\nreal-world traces, with large margins for complex workload patterns.",
    "descriptor": "",
    "authors": [
      "Huajie Qian",
      "Qingsong Wen",
      "Liang Sun",
      "Jing Gu",
      "Qiulin Niu",
      "Zhimin Tang"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2204.07197"
  },
  {
    "id": "arXiv:2204.07199",
    "title": "Ear Wearable (Earable) User Authentication via Acoustic Toothprint",
    "abstract": "Earables (ear wearables) is rapidly emerging as a new platform encompassing a\ndiverse range of personal applications. The traditional authentication methods\nhence become less applicable and inconvenient for earables due to their limited\ninput interface. Nevertheless, earables often feature rich around-the-head\nsensing capability that can be leveraged to capture new types of biometrics. In\nthis work, we proposeToothSonic which leverages the toothprint-induced sonic\neffect produced by users performing teeth gestures for earable authentication.\nIn particular, we design representative teeth gestures that can produce\neffective sonic waves carrying the information of the toothprint. To reliably\ncapture the acoustic toothprint, it leverages the occlusion effect of the ear\ncanal and the inward-facing microphone of the earables. It then extracts\nmulti-level acoustic features to reflect the intrinsic toothprint information\nfor authentication. The key advantages of ToothSonic are that it is suitable\nfor earables and is resistant to various spoofing attacks as the acoustic\ntoothprint is captured via the user's private teeth-ear channel that modulates\nand encrypts the sonic waves. Our experiment studies with 25 participants show\nthat ToothSonic achieves up to 95% accuracy with only one of the users' tooth\ngestures.",
    "descriptor": "",
    "authors": [
      "Zi Wang",
      "Jie Yang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2204.07199"
  },
  {
    "id": "arXiv:2204.07203",
    "title": "EXPERT: Public Benchmarks for Dynamic Heterogeneous Academic Graphs",
    "abstract": "Machine learning models that learn from dynamic graphs face nontrivial\nchallenges in learning and inference as both nodes and edges change over time.\nThe existing large-scale graph benchmark datasets that are widely used by the\ncommunity primarily focus on homogeneous node and edge attributes and are\nstatic. In this work, we present a variety of large scale, dynamic\nheterogeneous academic graphs to test the effectiveness of models developed for\nmulti-step graph forecasting tasks. Our novel datasets cover both context and\ncontent information extracted from scientific publications across two\ncommunities: Artificial Intelligence (AI) and Nuclear Nonproliferation (NN). In\naddition, we propose a systematic approach to improve the existing evaluation\nprocedures used in the graph forecasting models.",
    "descriptor": "",
    "authors": [
      "Sameera Horawalavithana",
      "Ellyn Ayton",
      "Anastasiya Usenko",
      "Shivam Sharma",
      "Jasmine Eshun",
      "Robin Cosbey",
      "Maria Glenski",
      "Svitlana Volkova"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.07203"
  },
  {
    "id": "arXiv:2204.07205",
    "title": "Expanding the Reach of Research Computing: A Landscape Study",
    "abstract": "Research-computing continues to play an ever increasing role in academia.\nAccess to computing resources, however, varies greatly between institutions.\nSustaining the growing need for computing skills and access to advanced\ncyberinfrastructure requires that computing resources be available to students\nat all levels of scholarship, including community colleges. The National\nScience Foundation-funded Building Research Innovation in Community Colleges\n(BRICCs) community set out to understand the challenges faced by\nadministrators, researchers and faculty in building a sustainable research\ncomputing continuum that extends to smaller and two-year terminal degree\ngranting institutions. BRICCs purpose is to address the technology gaps, and\nencourage the development of curriculum needed to grow a computationally\nproficient research workforce. Toward addressing these goals, we performed a\nlandscape study that culminated with a community workshop. Here, we present our\nkey findings from workshop discussions and identify next steps to be taken by\nBRICCs, funding agencies, and the broader cyberinfrastructure community.",
    "descriptor": "",
    "authors": [
      "Dhruva K. Chakravorty",
      "Sarah K. Janes",
      "James V. Howell",
      "Lisa M. Perez",
      "Amy Schultz",
      "Marie Goldie",
      "Austin L. Gamble",
      "Rajiv Malkan",
      "Honggao Liu",
      "Daniel Mireles",
      "Yuanqi Jing",
      "Zhenhua He",
      "Tim Cockrill"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2204.07205"
  },
  {
    "id": "arXiv:2204.07208",
    "title": "Alternating Mahalanobis Distance Minimization for Stable and Accurate CP  Decomposition",
    "abstract": "CP decomposition (CPD) is prevalent in chemometrics, signal processing, data\nmining and many more fields. While many algorithms have been proposed to\ncompute the CPD, alternating least squares (ALS) remains one of the most widely\nused algorithm for computing the decomposition. Recent works have introduced\nthe notion of eigenvalues and singular values of a tensor and explored\napplications of eigenvectors and singular vectors in areas like signal\nprocessing, data analytics and in various other fields. We introduce a new\nformulation for deriving singular values and vectors of a tensor by considering\nthe critical points of a function different from what is used in the previous\nwork. Computing these critical points in an alternating manner motivates an\nalternating optimization algorithm which corresponds to alternating least\nsquares algorithm in the matrix case. However, for tensors with order greater\nthan equal to $3$, it minimizes an objective function which is different from\nthe commonly used least squares loss. Alternating optimization of this new\nobjective leads to simple updates to the factor matrices with the same\nasymptotic computational cost as ALS. We show that a subsweep of this algorithm\ncan achieve a superlinear convergence rate for exact CPD with known rank and\nverify it experimentally. We then view the algorithm as optimizing a\nMahalanobis distance with respect to each factor with ground metric dependent\non the other factors. This perspective allows us to generalize our approach to\ninterpolate between updates corresponding to the ALS and the new algorithm to\nmanage the tradeoff between stability and fitness of the decomposition. Our\nexperimental results show that for approximating synthetic and real-world\ntensors, this algorithm and its variants converge to a better conditioned\ndecomposition with comparable and sometimes better fitness as compared to the\nALS algorithm.",
    "descriptor": "",
    "authors": [
      "Navjot Singh",
      "Edgar Solomonik"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2204.07208"
  },
  {
    "id": "arXiv:2204.07210",
    "title": "A Case for Microservices Orchestration Using Workflow Engines",
    "abstract": "Microservices have become the de-facto software architecture for cloud-native\napplications. A contentious architectural decision in microservices is to\ncompose them using choreography or orchestration. In choreography, every\nservice works independently, whereas, in orchestration, there is a controller\nthat coordinates service interactions. This paper makes a case for\norchestration. The promise of microservices is that each microservice can be\nindependently developed, deployed, tested, upgraded, and scaled. This makes\nthem suitable for systems running on cloud infrastructures. However,\nmicroservice-based systems become complicated due to the complex interactions\nof various services, concurrent events, failing components, developers' lack of\nglobal view, and configurations of the environment. This makes maintaining and\ndebugging such systems very challenging. We hypothesize that orchestrated\nservices are easier to debug and to test this we ported the largest publicly\navailable microservices' benchmark TrainTicket, which is implemented using\nchoreography, to a fault-oblivious stateful workflow framework Temporal. We\nreport our experience in porting the code from traditional choreographed\nmicroservice architecture to one orchestrated by Temporal and present our\ninitial findings of time to debug the 22 bugs present in the benchmark. Our\nfindings suggest that an effort towards making a transition to orchestrated\napproach is worthwhile, making the ported code easier to debug.",
    "descriptor": "\nComments: 5 pages, International Conference on Software Engineering 2022 (NIER) Track\n",
    "authors": [
      "Anas Nadeem",
      "Muhammad Zubair Malik"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2204.07210"
  },
  {
    "id": "arXiv:2204.07211",
    "title": "Analysis of Workflow Schedulers in Simulated Distributed Environments",
    "abstract": "Task graphs provide a simple way to describe scientific workflows (sets of\ntasks with dependencies) that can be executed on both HPC clusters and in the\ncloud. An important aspect of executing such graphs is the used scheduling\nalgorithm. Many scheduling heuristics have been proposed in existing works;\nnevertheless, they are often tested in oversimplified environments. We provide\nan extensible simulation environment designed for prototyping and benchmarking\ntask schedulers, which contains implementations of various scheduling\nalgorithms and is open-sourced, in order to be fully reproducible. We use this\nenvironment to perform a comprehensive analysis of workflow scheduling\nalgorithms with a focus on quantifying the effect of scheduling challenges that\nhave so far been mostly neglected, such as delays between scheduler invocations\nor partially unknown task durations. Our results indicate that network models\nused by many previous works might produce results that are off by an order of\nmagnitude in comparison to a more realistic model. Additionally, we show that\ncertain implementation details of scheduling algorithms which are often\nneglected can have a large effect on the scheduler's performance, and they\nshould thus be described in great detail to enable proper evaluation.",
    "descriptor": "",
    "authors": [
      "Jakub Ber\u00e1nek",
      "Stanislav B\u00f6hm",
      "Vojt\u011bch Cima"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2204.07211"
  },
  {
    "id": "arXiv:2204.07212",
    "title": "Reputation and Audit Bit Based Distributed Detection in the Presence of  Byzantine",
    "abstract": "In this paper, two reputation based algorithms called Reputation and audit\nbased clustering (RAC) algorithm and Reputation and audit based clustering with\nauxiliary anchor node (RACA) algorithm are proposed to defend against Byzantine\nattacks in distributed detection networks when the fusion center (FC) has no\nprior knowledge of the attacking strategy of Byzantine nodes. By updating the\nreputation index of the sensors in cluster-based networks, the system can\naccurately identify Byzantine nodes. The simulation results show that both\nproposed algorithms have superior detection performance compared with other\nalgorithms. The proposed RACA algorithm works well even when the number of\nByzantine nodes exceeds half of the total number of sensors in the network.\nFurthermore, the robustness of our proposed algorithms is evaluated in a\ndynamically changing scenario, where the attacking parameters change over time.\nWe show that our algorithms can still achieve superior detection performance.",
    "descriptor": "",
    "authors": [
      "Chen Quan",
      "Yunghsiang S. Han",
      "Baocheng Geng",
      "Pramod K. Varshney"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2204.07212"
  },
  {
    "id": "arXiv:2204.07221",
    "title": "Causal Disentanglement with Network Information for Debiased  Recommendations",
    "abstract": "Recommender systems aim to recommend new items to users by learning user and\nitem representations. In practice, these representations are highly entangled\nas they consist of information about multiple factors, including user's\ninterests, item attributes along with confounding factors such as user\nconformity, and item popularity. Considering these entangled representations\nfor inferring user preference may lead to biased recommendations (e.g., when\nthe recommender model recommends popular items even if they do not align with\nthe user's interests).\nRecent research proposes to debias by modeling a recommender system from a\ncausal perspective. The exposure and the ratings are analogous to the treatment\nand the outcome in the causal inference framework, respectively. The critical\nchallenge in this setting is accounting for the hidden confounders. These\nconfounders are unobserved, making it hard to measure them. On the other hand,\nsince these confounders affect both the exposure and the ratings, it is\nessential to account for them in generating debiased recommendations. To better\napproximate hidden confounders, we propose to leverage network information\n(i.e., user-social and user-item networks), which are shown to influence how\nusers discover and interact with an item. Aside from the user conformity,\naspects of confounding such as item popularity present in the network\ninformation is also captured in our method with the aid of \\textit{causal\ndisentanglement} which unravels the learned representations into independent\nfactors that are responsible for (a) modeling the exposure of an item to the\nuser, (b) predicting the ratings, and (c) controlling the hidden confounders.\nExperiments on real-world datasets validate the effectiveness of the proposed\nmodel for debiasing recommender systems.",
    "descriptor": "",
    "authors": [
      "Paras Sheth",
      "Ruocheng Guo",
      "Lu Cheng",
      "Huan Liu",
      "K. Sel\u00e7uk Candan"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2204.07221"
  },
  {
    "id": "arXiv:2204.07223",
    "title": "On Scheduling Mechanisms Beyond the Worst Case",
    "abstract": "The problem of scheduling unrelated machines has been studied since the\ninception of algorithmic mechanism design~\\cite{NR99}. It is a resource\nallocation problem that entails assigning $m$ tasks to $n$ machines for\nexecution. Machines are regarded as strategic agents who may lie about their\nexecution costs so as to minimize their allocated workload. To address the\nsituation when monetary payment is not an option to compensate the machines'\ncosts, \\citeauthor{DBLP:journals/mst/Koutsoupias14} [2014] devised two\n\\textit{truthful} mechanisms, K and P respectively, that achieve an\napproximation ratio of $\\frac{n+1}{2}$ and $n$, for social cost minimization.\nIn addition, no truthful mechanism can achieve an approximation ratio better\nthan $\\frac{n+1}{2}$. Hence, mechanism K is optimal. While approximation ratio\nprovides a strong worst-case guarantee, it also limits us to a comprehensive\nunderstanding of mechanism performance on various inputs. This paper\ninvestigates these two scheduling mechanisms beyond the worst case. We first\nshow that mechanism K achieves a smaller social cost than mechanism P on every\ninput. That is, mechanism K is pointwise better than mechanism P. Next, for\neach task $j$, when machines' execution costs $t_i^j$ are independent and\nidentically drawn from a task-specific distribution $F^j(t)$, we show that the\naverage-case approximation ratio of mechanism K converges to a constant. This\nbound is tight for mechanism K. For a better understanding of this distribution\ndependent constant, on the one hand, we estimate its value by plugging in a few\ncommon distributions; on the other, we show that this converging bound improves\na known bound \\cite{DBLP:conf/aaai/Zhang18} which only captures the single-task\nsetting. Last, we find that the average-case approximation ratio of mechanism P\nconverges to the same constant.",
    "descriptor": "",
    "authors": [
      "Yansong Gao",
      "JIe Zhang"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2204.07223"
  },
  {
    "id": "arXiv:2204.07225",
    "title": "MP-CodeCheck: Evolving Logical Expression Code Anomaly Learning with  Iterative Self-Supervision",
    "abstract": "Machine programming (MP) is concerned with automating software development.\nAccording to studies, software engineers spend upwards of 50% of their\ndevelopment time debugging software. To help accelerate debugging, we present\nMP-CodeCheck (MPCC). MPCC is an MP system that attempts to identify anomalous\ncode patterns within logical program expressions. In designing MPCC, we\ndeveloped two novel programming language representations, the formations of\nwhich are critical in its ability to exhaustively and efficiently process the\nbillions of lines of code that are used in its self-supervised training. To\nquantify MPCC's performance, we compare it against ControlFlag, a\nstate-of-the-art self-supervised code anomaly detection system; we find that\nMPCC is more spatially and temporally efficient. We demonstrate MPCC's\nanomalous code detection capabilities by exercising it on a variety of\nopen-source GitHub repositories and one proprietary code base. We also provide\na brief qualitative study on some of the different classes of code anomalies\nthat MPCC can detect to provide an abbreviated insight into its capabilities.",
    "descriptor": "",
    "authors": [
      "Urs C. Muff",
      "Celine Lee",
      "Paul Gottschlich",
      "Justin Gottschlich"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2204.07225"
  },
  {
    "id": "arXiv:2204.07227",
    "title": "A deep first-order system least squares method for solving elliptic PDEs",
    "abstract": "We propose a First-Order System Least Squares (FOSLS) method based on\ndeep-learning for numerically solving second-order elliptic PDEs. The method we\npropose is capable of dealing with either variational and non-variational\nproblems, and because of its meshless nature, it can also deal with problems\nposed in high-dimensional domains. We prove the $\\Gamma$-convergence of the\nneural network approximation towards the solution of the continuous problem,\nand extend the convergence proof to some well-known related methods. Finally,\nwe present several numerical examples illustrating the performance of our\ndiscretization.",
    "descriptor": "",
    "authors": [
      "Francisco M. Bersetche",
      "Juan Pablo Borthagaray"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2204.07227"
  },
  {
    "id": "arXiv:2204.07228",
    "title": "Applying Feature Underspecified Lexicon Phonological Features in  Multilingual Text-to-Speech",
    "abstract": "This study investigates whether the phonological features derived from the\nFeaturally Underspecified Lexicon model can be applied in text-to-speech\nsystems to generate native and non-native speech in English and Mandarin. We\npresent a mapping of ARPABET/pinyin to SAMPA/SAMPA-SC and then to phonological\nfeatures. This mapping was tested for whether it could lead to the successful\ngeneration of native, non-native, and code-switched speech in the two\nlanguages. We ran two experiments, one with a small dataset and one with a\nlarger dataset. The results supported that phonological features could be used\nas a feasible input system for languages in or not in the train data, although\nfurther investigation is needed to improve model performance. The results lend\nsupport to FUL by presenting successfully synthesised output, and by having the\noutput carrying a source-language accent when synthesising a language not in\nthe training data. The TTS process stimulated human second language acquisition\nprocess and thus also confirm FUL's ability to account for acquisition.",
    "descriptor": "\nComments: submitted to Interspeech 2022. arXiv admin note: substantial text overlap with arXiv:2110.03609\n",
    "authors": [
      "Cong Zhang",
      "Huinan Zeng",
      "Huang Liu",
      "Jiewen Zheng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2204.07228"
  },
  {
    "id": "arXiv:2204.07229",
    "title": "Automatic Fake News Detection: Are current models \"fact-checking\" or  \"gut-checking\"?",
    "abstract": "Automatic fake news detection models are ostensibly based on logic, where the\ntruth of a claim made in a headline can be determined by supporting or refuting\nevidence found in a resulting web query. These models are believed to be\nreasoning in some way; however, it has been shown that these same results, or\nbetter, can be achieved without considering the claim at all -- only the\nevidence. This implies that other signals are contained within the examined\nevidence, and could be based on manipulable factors such as emotion, sentiment,\nor part-of-speech (POS) frequencies, which are vulnerable to adversarial\ninputs. We neutralize some of these signals through multiple forms of both\nneural and non-neural pre-processing and style transfer, and find that this\nflattening of extraneous indicators can induce the models to actually require\nboth claims and evidence to perform well. We conclude with the construction of\na model using emotion vectors built off a lexicon and passed through an\n\"emotional attention\" mechanism to appropriately weight certain emotions. We\nprovide quantifiable results that prove our hypothesis that manipulable\nfeatures are being used for fact-checking.",
    "descriptor": "\nComments: 8 pages, 4 figures, 1 table, To appear in The Fifth FEVER Workshop 26th May 2022 Co-located with ACL 2022\n",
    "authors": [
      "Ian Kelk",
      "Benjamin Basseri",
      "Wee Yi Lee",
      "Richard Qiu",
      "Chris Tanner"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.07229"
  },
  {
    "id": "arXiv:2204.07233",
    "title": "How Different are Pre-trained Transformers for Text Ranking?",
    "abstract": "In recent years, large pre-trained transformers have led to substantial gains\nin performance over traditional retrieval models and feedback approaches.\nHowever, these results are primarily based on the MS Marco/TREC Deep Learning\nTrack setup, with its very particular setup, and our understanding of why and\nhow these models work better is fragmented at best. We analyze effective\nBERT-based cross-encoders versus traditional BM25 ranking for the passage\nretrieval task where the largest gains have been observed, and investigate two\nmain questions. On the one hand, what is similar? To what extent does the\nneural ranker already encompass the capacity of traditional rankers? Is the\ngain in performance due to a better ranking of the same documents (prioritizing\nprecision)? On the other hand, what is different? Can it retrieve effectively\ndocuments missed by traditional systems (prioritizing recall)? We discover\nsubstantial differences in the notion of relevance identifying strengths and\nweaknesses of BERT that may inspire research for future improvement. Our\nresults contribute to our understanding of (black-box) neural rankers relative\nto (well-understood) traditional rankers, help understand the particular\nexperimental setting of MS-Marco-based test collections.",
    "descriptor": "\nComments: ECIR 2022\n",
    "authors": [
      "David Rau",
      "Jaap Kamps"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.07233"
  },
  {
    "id": "arXiv:2204.07236",
    "title": "A* shortest string decoding for non-idempotent semirings",
    "abstract": "The single shortest path algorithm is undefined for weighted finite-state\nautomata over non-idempotent semirings because such semirings do not guarantee\nthe existence of a shortest path. However, in non-idempotent semirings\nadmitting an order satisfying a monotonicity condition (such as the plus-times\nor log semirings), the notion of shortest string is well-defined. We describe\nan algorithm which finds the shortest string for a weighted non-deterministic\nautomaton over such semirings using the backwards shortest distance of an\nequivalent deterministic automaton (DFA) as a heuristic for A* search performed\nover a companion idempotent semiring, which is proven to return the shortest\nstring. While there may be exponentially more states in the DFA, this algorithm\nneeds to visit only a small fraction of them if determinization is performed\n\"on the fly\".",
    "descriptor": "\nComments: Ten pages, two figures\n",
    "authors": [
      "Kyle Gorman",
      "Cyril Allauzen"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.07236"
  },
  {
    "id": "arXiv:2204.07237",
    "title": "Constructing Open Cloze Tests Using Generation and Discrimination  Capabilities of Transformers",
    "abstract": "This paper presents the first multi-objective transformer model for\nconstructing open cloze tests that exploits generation and discrimination\ncapabilities to improve performance. Our model is further enhanced by tweaking\nits loss function and applying a post-processing re-ranking algorithm that\nimproves overall test structure. Experiments using automatic and human\nevaluation show that our approach can achieve up to 82% accuracy according to\nexperts, outperforming previous work and baselines. We also release a\ncollection of high-quality open cloze tests along with sample system output and\nhuman annotations that can serve as a future benchmark.",
    "descriptor": "\nComments: Accepted at Findings of ACL 2022\n",
    "authors": [
      "Mariano Felice",
      "Shiva Taslimipoor",
      "Paula Buttery"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.07237"
  },
  {
    "id": "arXiv:2204.07241",
    "title": "The Art of Prompting: Event Detection based on Type Specific Prompts",
    "abstract": "We compare various forms of prompts to represent event types and develop a\nunified framework to incorporate the event type specific prompts for\nsupervised, few-shot, and zero-shot event detection. The experimental results\ndemonstrate that a well-defined and comprehensive event type prompt can\nsignificantly improve the performance of event detection, especially when the\nannotated data is scarce (few-shot event detection) or not available (zero-shot\nevent detection). By leveraging the semantics of event types, our unified\nframework shows up to 24.3\\% F-score gain over the previous state-of-the-art\nbaselines.",
    "descriptor": "",
    "authors": [
      "Sijia Wang",
      "Mo Yu",
      "Lifu Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.07241"
  },
  {
    "id": "arXiv:2204.07243",
    "title": "PLGAN: Generative Adversarial Networks for Power-Line Segmentation in  Aerial Images",
    "abstract": "Accurate segmentation of power lines in various aerial images is very\nimportant for UAV flight safety. The complex background and very thin\nstructures of power lines, however, make it an inherently difficult task in\ncomputer vision. This paper presents PLGAN, a simple yet effective method based\non generative adversarial networks, to segment power lines from aerial images\nwith different backgrounds. Instead of directly using the adversarial networks\nto generate the segmentation, we take their certain decoding features and embed\nthem into another semantic segmentation network by considering more context,\ngeometry, and appearance information of power lines. We further exploit the\nappropriate form of the generated images for high-quality feature embedding and\ndefine a new loss function in the Hough-transform parameter space to enhance\nthe segmentation of very thin power lines. Extensive experiments and\ncomprehensive analysis demonstrate that our proposed PLGAN outperforms the\nprior state-of-the-art methods for semantic segmentation and line detection.",
    "descriptor": "",
    "authors": [
      "Rabab Abdelfattah",
      "Xiaofeng Wang",
      "Song Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.07243"
  },
  {
    "id": "arXiv:2204.07246",
    "title": "Robotic and Generative Adversarial Attacks in Offline Writer-independent  Signature Verification",
    "abstract": "This study explores how robots and generative approaches can be used to mount\nsuccessful false-acceptance adversarial attacks on signature verification\nsystems. Initially, a convolutional neural network topology and data\naugmentation strategy are explored and tuned, producing an 87.12% accurate\nmodel for the verification of 2,640 human signatures. Two robots are then\ntasked with forging 50 signatures, where 25 are used for the verification\nattack, and the remaining 25 are used for tuning of the model to defend against\nthem. Adversarial attacks on the system show that there exists an information\nsecurity risk; the Line-us robotic arm can fool the system 24% of the time and\nthe iDraw 2.0 robot 32% of the time. A conditional GAN finds similar success,\nwith around 30% forged signatures misclassified as genuine. Following fine-tune\ntransfer learning of robotic and generative data, adversarial attacks are\nreduced below the model threshold by both robots and the GAN. It is observed\nthat tuning the model reduces the risk of attack by robots to 8% and 12%, and\nthat conditional generative adversarial attacks can be reduced to 4% when 25\nimages are presented and 5% when 1000 images are presented.",
    "descriptor": "",
    "authors": [
      "Jordan J. Bird"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.07246"
  },
  {
    "id": "arXiv:2204.07247",
    "title": "Benchmark computations of the phase field crystal and functionalized  Cahn-Hilliard equations via fully implicit, Nesterov accelerated schemes",
    "abstract": "We introduce a fast solver for the phase field crystal (PFC) and\nfunctionalized Cahn-Hilliard (FCH) equations with periodic boundary conditions\non a rectangular domain that features the preconditioned Nesterov accelerated\ngradient descent (PAGD) method. We discretize these problems with a Fourier\ncollocation method in space, and employ various second-order schemes in time.\nWe observe a significant speedup with this solver when compared to the\npreconditioned gradient descent (PGD) method. With the PAGD solver, fully\nimplicit, second-order-in-time schemes are not only feasible to solve the PFC\nand FCH equations, but also do so more efficiently than some semi-implicit\nschemes in some cases where accuracy issues are taken into account. Benchmark\ncomputations of five different schemes for the PFC and FCH equations are\nconducted and the results indicate that, for the FCH experiments, the fully\nimplicit schemes (midpoint rule and BDF2 equipped with the PAGD as a nonlinear\ntime marching solver) perform better than their IMEX versions in terms of\ncomputational cost needed to achieve a certain precision. For the PFC, the\nresults are not as conclusive as in the FCH experiments, which, we believe, is\ndue to the fact that the nonlinearity in the PFC is milder nature compared to\nthe FCH equation. We also discuss some practical matters in applying the PAGD.\nWe introduce an averaged Newton preconditioner and a sweeping-friction strategy\nas heuristic ways to choose good preconditioner parameters. The\nsweeping-friction strategy exhibits almost as good a performance as the case of\nthe best manually tuned parameters.",
    "descriptor": "",
    "authors": [
      "Jea-Hyun Park",
      "Abner Salgado",
      "Steven Wise"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2204.07247"
  },
  {
    "id": "arXiv:2204.07249",
    "title": "Minimizing Control for Credit Assignment with Strong Feedback",
    "abstract": "The success of deep learning attracted interest in whether the brain learns\nhierarchical representations using gradient-based learning. However, current\nbiologically plausible methods for gradient-based credit assignment in deep\nneural networks need infinitesimally small feedback signals, which is\nproblematic in biologically realistic noisy environments and at odds with\nexperimental evidence in neuroscience showing that top-down feedback can\nsignificantly influence neural activity. Building upon deep feedback control\n(DFC), a recently proposed credit assignment method, we combine strong feedback\ninfluences on neural activity with gradient-based learning and show that this\nnaturally leads to a novel view on neural network optimization. Instead of\ngradually changing the network weights towards configurations with low output\nloss, weight updates gradually minimize the amount of feedback required from a\ncontroller that drives the network to the supervised output label. Moreover, we\nshow that the use of strong feedback in DFC allows learning forward and\nfeedback connections simultaneously, using a learning rule fully local in space\nand time. We complement our theoretical results with experiments on standard\ncomputer-vision benchmarks, showing competitive performance to backpropagation\nas well as robustness to noise. Overall, our work presents a fundamentally\nnovel view of learning as control minimization, while sidestepping biologically\nunrealistic assumptions.",
    "descriptor": "\nComments: 25 pages, 3 figures\n",
    "authors": [
      "Alexander Meulemans",
      "Matilde Tristany Farinha",
      "Maria R. Cervera",
      "Jo\u00e3o Sacramento",
      "Benjamin F. Grewe"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.07249"
  },
  {
    "id": "arXiv:2204.07254",
    "title": "Methodical Advice Collection and Reuse in Deep Reinforcement Learning",
    "abstract": "Reinforcement learning (RL) has shown great success in solving many\nchallenging tasks via use of deep neural networks. Although using deep learning\nfor RL brings immense representational power, it also causes a well-known\nsample-inefficiency problem. This means that the algorithms are data-hungry and\nrequire millions of training samples to converge to an adequate policy. One way\nto combat this issue is to use action advising in a teacher-student framework,\nwhere a knowledgeable teacher provides action advice to help the student. This\nwork considers how to better leverage uncertainties about when a student should\nask for advice and if the student can model the teacher to ask for less advice.\nThe student could decide to ask for advice when it is uncertain or when both it\nand its model of the teacher are uncertain. In addition to this investigation,\nthis paper introduces a new method to compute uncertainty for a deep RL agent\nusing a secondary neural network. Our empirical results show that using dual\nuncertainties to drive advice collection and reuse may improve learning\nperformance across several Atari games.",
    "descriptor": "\nComments: To be published in ALA2022: Adaptive and Learning Agents Workshop 2022 at AAMAS\n",
    "authors": [
      "Sahir",
      "Erc\u00fcment \u0130lhan",
      "Srijita Das",
      "Matthew E. Taylor"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2204.07254"
  },
  {
    "id": "arXiv:2204.07258",
    "title": "Causal Transformer for Estimating Counterfactual Outcomes",
    "abstract": "Estimating counterfactual outcomes over time from observational data is\nrelevant for many applications (e.g., personalized medicine). Yet,\nstate-of-the-art methods build upon simple long short-term memory (LSTM)\nnetworks, thus rendering inferences for complex, long-range dependencies\nchallenging. In this paper, we develop a novel Causal Transformer for\nestimating counterfactual outcomes over time. Our model is specifically\ndesigned to capture complex, long-range dependencies among time-varying\nconfounders. For this, we combine three transformer subnetworks with separate\ninputs for time-varying covariates, previous treatments, and previous outcomes\ninto a joint network with in-between cross-attentions. We further develop a\ncustom, end-to-end training procedure for our Causal Transformer. Specifically,\nwe propose a novel counterfactual domain confusion loss to address confounding\nbias: it aims to learn adversarial balanced representations, so that they are\npredictive of the next outcome but non-predictive of the current treatment\nassignment. We evaluate our Causal Transformer based on synthetic and\nreal-world datasets, where it achieves superior performance over current\nbaselines. To the best of our knowledge, this is the first work proposing\ntransformer-based architecture for estimating counterfactual outcomes from\nlongitudinal data.",
    "descriptor": "",
    "authors": [
      "Valentyn Melnychuk",
      "Dennis Frauen",
      "Stefan Feuerriegel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2204.07258"
  },
  {
    "id": "arXiv:2204.07261",
    "title": "Convergence and Implicit Regularization Properties of Gradient Descent  for Deep Residual Networks",
    "abstract": "We prove linear convergence of gradient descent to a global minimum for the\ntraining of deep residual networks with constant layer width and smooth\nactivation function. We further show that the trained weights, as a function of\nthe layer index, admits a scaling limit which is H\\\"older continuous as the\ndepth of the network tends to infinity. The proofs are based on non-asymptotic\nestimates of the loss function and of norms of the network weights along the\ngradient descent path. We illustrate the relevance of our theoretical results\nto practical settings using detailed numerical experiments on supervised\nlearning problems.",
    "descriptor": "",
    "authors": [
      "Rama Cont",
      "Alain Rossier",
      "RenYuan Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2204.07261"
  },
  {
    "id": "arXiv:2204.07262",
    "title": "Imposing Consistency for Optical Flow Estimation",
    "abstract": "Imposing consistency through proxy tasks has been shown to enhance\ndata-driven learning and enable self-supervision in various tasks. This paper\nintroduces novel and effective consistency strategies for optical flow\nestimation, a problem where labels from real-world data are very challenging to\nderive. More specifically, we propose occlusion consistency and zero forcing in\nthe forms of self-supervised learning and transformation consistency in the\nform of semi-supervised learning. We apply these consistency techniques in a\nway that the network model learns to describe pixel-level motions better while\nrequiring no additional annotations. We demonstrate that our consistency\nstrategies applied to a strong baseline network model using the original\ndatasets and labels provide further improvements, attaining the\nstate-of-the-art results on the KITTI-2015 scene flow benchmark in the\nnon-stereo category. Our method achieves the best foreground accuracy (4.33% in\nFl-all) over both the stereo and non-stereo categories, even though using only\nmonocular image inputs.",
    "descriptor": "\nComments: CVPR 2022\n",
    "authors": [
      "Jisoo Jeong",
      "Jamie Menjay Lin",
      "Fatih Porikli",
      "Nojun Kwak"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.07262"
  },
  {
    "id": "arXiv:2204.07268",
    "title": "Visual Pressure Estimation and Control for Soft Robotic Grippers",
    "abstract": "Soft robotic grippers facilitate contact-rich manipulation, including robust\ngrasping of varied objects. Yet the beneficial compliance of a soft gripper\nalso results in significant deformation that can make precision manipulation\nchallenging. We present visual pressure estimation & control (VPEC), a method\nthat uses a single RGB image of an unmodified soft gripper from an external\ncamera to directly infer pressure applied to the world by the gripper. We\npresent inference results for a pneumatic gripper and a tendon-actuated gripper\nmaking contact with a flat surface. We also show that VPEC enables precision\nmanipulation via closed-loop control of inferred pressure. We present results\nfor a mobile manipulator (Stretch RE1 from Hello Robot) using visual servoing\nto do the following: achieve target pressures when making contact; follow a\nspatial pressure trajectory; and grasp small objects, including a microSD card,\na washer, a penny, and a pill. Overall, our results show that VPEC enables\ngrippers with high compliance to perform precision manipulation.",
    "descriptor": "",
    "authors": [
      "Patrick Grady",
      "Jeremy A. Collins",
      "Samarth Brahmbhatt",
      "Christopher D. Twigg",
      "Chengcheng Tang",
      "James Hays",
      "Charles C. Kemp"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2204.07268"
  },
  {
    "id": "arXiv:2204.07270",
    "title": "Model-agnostic Multi-Domain Learning with Domain-Specific Adapters for  Action Recognition",
    "abstract": "In this paper, we propose a multi-domain learning model for action\nrecognition. The proposed method inserts domain-specific adapters between\nlayers of domain-independent layers of a backbone network. Unlike a multi-head\nnetwork that switches classification heads only, our model switches not only\nthe heads, but also the adapters for facilitating to learn feature\nrepresentations universal to multiple domains. Unlike prior works, the proposed\nmethod is model-agnostic and doesn't assume model structures unlike prior\nworks. Experimental results on three popular action recognition datasets\n(HMDB51, UCF101, and Kinetics-400) demonstrate that the proposed method is more\neffective than a multi-head architecture and more efficient than separately\ntraining models for each domain.",
    "descriptor": "\nComments: 8 pages\n",
    "authors": [
      "Kazuki Omi",
      "Toru Tamaki"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.07270"
  },
  {
    "id": "arXiv:2204.07272",
    "title": "Automated speech tools for helping communities process restricted-access  corpora for language revival efforts",
    "abstract": "Many archival recordings of speech from endangered languages remain\nunannotated and inaccessible to community members and language learning\nprograms. One bottleneck is the time-intensive nature of annotation. An even\nnarrower bottleneck occurs for recordings with access constraints, such as\nlanguage that must be vetted or filtered by authorised community members before\nannotation can begin. We propose a privacy-preserving workflow to widen both\nbottlenecks for recordings where speech in the endangered language is\nintermixed with a more widely-used language such as English for meta-linguistic\ncommentary and questions (e.g. What is the word for 'tree'?). We integrate\nvoice activity detection (VAD), spoken language identification (SLI), and\nautomatic speech recognition (ASR) to transcribe the metalinguistic content,\nwhich an authorised person can quickly scan to triage recordings that can be\nannotated by people with lower levels of access. We report work-in-progress\nprocessing 136 hours archival audio containing a mix of English and Muruwari.\nOur collaborative work with the Muruwari custodian of the archival materials\nshow that this workflow reduces metalanguage transcription time by 20% even\ngiven only minimal amounts of annotated training data: 10 utterances per\nlanguage for SLI and 39 minutes of the English for ASR.",
    "descriptor": "\nComments: Accepted at ComputEL-5\n",
    "authors": [
      "Nay San",
      "Martijn Bartelds",
      "Tol\u00fal\\d{o}p\\d\u00e9 \u00d2g\u00fanr\\d\u00e8m\u00ed",
      "Alison Mount",
      "Ruben Thompson",
      "Michael Higgins",
      "Roy Barker",
      "Jane Simpson",
      "Dan Jurafsky"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2204.07272"
  },
  {
    "id": "arXiv:2204.07275",
    "title": "Incremental Prompting: Episodic Memory Prompt for Lifelong Event  Detection",
    "abstract": "Lifelong event detection aims to incrementally update a model with new event\ntypes and data while retaining the capability on previously learned old types.\nOne critical challenge is that the model would catastrophically forget old\ntypes when continually trained on new data. In this paper, we introduce\nEpisodic Memory Prompts (EMP) to explicitly preserve the learned task-specific\nknowledge. Our method adopts continuous prompt for each task and they are\noptimized to instruct the model prediction and learn event-specific\nrepresentation. The EMPs learned in previous tasks are carried along with the\nmodel in subsequent tasks, and can serve as a memory module that keeps the old\nknowledge and transferring to new tasks. Experiment results demonstrate the\neffectiveness of our method. Furthermore, we also conduct a comprehensive\nanalysis of the new and old event types in lifelong learning.",
    "descriptor": "\nComments: 8 pages, 2 figures\n",
    "authors": [
      "Minqian Liu",
      "Shiyu Chang",
      "Lifu Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.07275"
  },
  {
    "id": "arXiv:2204.07276",
    "title": "auton-survival: an Open-Source Package for Regression, Counterfactual  Estimation, Evaluation and Phenotyping with Censored Time-to-Event Data",
    "abstract": "Applications of machine learning in healthcare often require working with\ntime-to-event prediction tasks including prognostication of an adverse event,\nre-hospitalization or death. Such outcomes are typically subject to censoring\ndue to loss of follow up. Standard machine learning methods cannot be applied\nin a straightforward manner to datasets with censored outcomes. In this paper,\nwe present auton-survival, an open-source repository of tools to streamline\nworking with censored time-to-event or survival data. auton-survival includes\ntools for survival regression, adjustment in the presence of domain shift,\ncounterfactual estimation, phenotyping for risk stratification, evaluation, as\nwell as estimation of treatment effects. Through real world case studies\nemploying a large subset of the SEER oncology incidence data, we demonstrate\nthe ability of auton-survival to rapidly support data scientists in answering\ncomplex health and epidemiological questions.",
    "descriptor": "",
    "authors": [
      "Chirag Nagpal",
      "Willa Potosnak",
      "Artur Dubrawski"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Mathematical Software (cs.MS)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2204.07276"
  },
  {
    "id": "arXiv:2204.07280",
    "title": "Invisible-to-Visible: Privacy-Aware Human Instance Segmentation using  Airborne Ultrasound via Collaborative Learning Variational Autoencoder",
    "abstract": "In action understanding in indoor, we have to recognize human pose and action\nconsidering privacy. Although camera images can be used for highly accurate\nhuman action recognition, camera images do not preserve privacy. Therefore, we\npropose a new task for human instance segmentation from invisible information,\nespecially airborne ultrasound, for action recognition. To perform instance\nsegmentation from invisible information, we first convert sound waves to\nreflected sound directional images (sound images). Although the sound images\ncan roughly identify the location of a person, the detailed shape is ambiguous.\nTo address this problem, we propose a collaborative learning variational\nautoencoder (CL-VAE) that simultaneously uses sound and RGB images during\ntraining. In inference, it is possible to obtain instance segmentation results\nonly from sound images. As a result of performance verification, CL-VAE could\nestimate human instance segmentations more accurately than conventional\nvariational autoencoder and some other models. Since this method can obtain\nhuman segmentations individually, it could be applied to human action\nrecognition tasks with privacy protection.",
    "descriptor": "",
    "authors": [
      "Risako Tanigawa",
      "Yasunori Ishii",
      "Kazuki Kozuka",
      "Takayoshi Yamashita"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.07280"
  },
  {
    "id": "arXiv:2204.07281",
    "title": "Pricing and Remunerating Electricity Storage Flexibility Using Virtual  Links",
    "abstract": "Ambitious renewable portfolio standards motivate the incorporation of energy\nstorage resources (ESR) as sources of flexibility. While the United States\ngovernment aims to promote ESR participation in electricity markets, work on\nmarket designs for properly remunerating ESRs is still lacking. In this paper,\nwe propose a new energy market clearing framework that incorporates ESR\nsystems. The new market design is computationally attractive in that it avoids\nmixed-integer formulations and formulations with complementarity constraints.\nMoreover, compared to previous market designs, our market decomposes the\noperations of ESRs using the concept of virtual links, which capture the\ntransfer of energy across time. The virtual link representation reveals\neconomic incentives available for ESR operations and sheds light into how\nelectricity markets should remunerate ESRs. We also explore the roles of ESR\nphysical parameters on market behavior; we show that, while energy and power\ncapacity defines the amount of flexibility each ESR can provide, storage\ncharge/discharge efficiencies play a fundamental role in ESR remuneration and\nin mitigating market price volatility. We use our proposed framework to analyze\nthe interplay between ESRs and independent system operators (ISOs) and to\nprovide insights into optimal deployment strategies of ESRs in power grids.",
    "descriptor": "\nComments: 28 pages, 8 figures\n",
    "authors": [
      "Weiqi Zhang",
      "Victor M. Zavala"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2204.07281"
  },
  {
    "id": "arXiv:2204.07286",
    "title": "Guided Co-Modulated GAN for 360\u00b0 Field of View Extrapolation",
    "abstract": "We propose a method to extrapolate a 360{\\deg} field of view from a single\nimage that allows for user-controlled synthesis of the out-painted content. To\ndo so, we propose improvements to an existing GAN-based in-painting\narchitecture for out-painting panoramic image representation. Our method\nobtains state-of-the-art results and outperforms previous methods on standard\nimage quality metrics. To allow controlled synthesis of out-painting, we\nintroduce a novel guided co-modulation framework, which drives the image\ngeneration process with a common pretrained discriminative model. Doing so\nmaintains the high visual quality of generated panoramas while enabling\nuser-controlled semantic content in the extrapolated field of view. We\ndemonstrate the state-of-the-art results of our method on field of view\nextrapolation both qualitatively and quantitatively, providing thorough\nanalysis of our novel editing capabilities. Finally, we demonstrate that our\napproach benefits the photorealistic virtual insertion of highly glossy objects\nin photographs.",
    "descriptor": "\nComments: 18 pages, 9 figures\n",
    "authors": [
      "Mohammad Reza Karimi Dastjerdi",
      "Yannick Hold-Geoffroy",
      "Jonathan Eisenmann",
      "Siavash Khodadadeh",
      "Jean-Fran\u00e7ois Lalonde"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.07286"
  },
  {
    "id": "arXiv:2204.07288",
    "title": "Characterizing the Efficiency vs. Accuracy Trade-off for Long-Context  NLP Models",
    "abstract": "With many real-world applications of Natural Language Processing (NLP)\ncomprising of long texts, there has been a rise in NLP benchmarks that measure\nthe accuracy of models that can handle longer input sequences. However, these\nbenchmarks do not consider the trade-offs between accuracy, speed, and power\nconsumption as input sizes or model sizes are varied. In this work, we perform\na systematic study of this accuracy vs. efficiency trade-off on two widely used\nlong-sequence models - Longformer-Encoder-Decoder (LED) and Big Bird - during\nfine-tuning and inference on four datasets from the SCROLLS benchmark. To study\nhow this trade-off differs across hyperparameter settings, we compare the\nmodels across four sequence lengths (1024, 2048, 3072, 4096) and two model\nsizes (base and large) under a fixed resource budget. We find that LED\nconsistently achieves better accuracy at lower energy costs than Big Bird. For\nsummarization, we find that increasing model size is more energy efficient than\nincreasing sequence length for higher accuracy. However, this comes at the cost\nof a large drop in inference speed. For question answering, we find that\nsmaller models are both more efficient and more accurate due to the larger\ntraining batch sizes possible under a fixed resource budget.",
    "descriptor": "\nComments: Accepted at NLP Power! Workshop on Efficient Benchmarking in NLP at ACL2022\n",
    "authors": [
      "Phyllis Ang",
      "Bhuwan Dhingra",
      "Lisa Wu Wills"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.07288"
  },
  {
    "id": "arXiv:2204.07289",
    "title": "Identifying and Measuring Token-Level Sentiment Bias in Pre-trained  Language Models with Prompts",
    "abstract": "Due to the superior performance, large-scale pre-trained language models\n(PLMs) have been widely adopted in many aspects of human society. However, we\nstill lack effective tools to understand the potential bias embedded in the\nblack-box models. Recent advances in prompt tuning show the possibility to\nexplore the internal mechanism of the PLMs. In this work, we propose two\ntoken-level sentiment tests: Sentiment Association Test (SAT) and Sentiment\nShift Test (SST) which utilize the prompt as a probe to detect the latent bias\nin the PLMs. Our experiments on the collection of sentiment datasets show that\nboth SAT and SST can identify sentiment bias in PLMs and SST is able to\nquantify the bias. The results also suggest that fine-tuning can possibly\naugment the existing bias in PLMs.",
    "descriptor": "\nComments: 5 pages, 2 figures\n",
    "authors": [
      "Apoorv Garg",
      "Deval Srivastava",
      "Zhiyang Xu",
      "Lifu Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.07289"
  },
  {
    "id": "arXiv:2204.07292",
    "title": "Unsupervised Probabilistic Models for Sequential Electronic Health  Records",
    "abstract": "We develop an unsupervised probabilistic model for heterogeneous Electronic\nHealth Record (EHR) data. Utilizing a mixture model formulation, our approach\ndirectly models sequences of arbitrary length, such as medications and\nlaboratory results. This allows for subgrouping and incorporation of the\ndynamics underlying heterogeneous data types. The model consists of a layered\nset of latent variables that encode underlying structure in the data. These\nvariables represent subject subgroups at the top layer, and unobserved states\nfor sequences in the second layer. We train this model on episodic data from\nsubjects receiving medical care in the Kaiser Permanente Northern California\nintegrated healthcare delivery system. The resulting properties of the trained\nmodel generate novel insight from these complex and multifaceted data. In\naddition, we show how the model can be used to analyze sequences that\ncontribute to assessment of mortality likelihood.",
    "descriptor": "",
    "authors": [
      "Alan D. Kaplan",
      "John D. Greene",
      "Vincent X. Liu",
      "Priyadip Ray"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2204.07292"
  },
  {
    "id": "arXiv:2204.07299",
    "title": "Where to Go for the Holidays: Towards Mixed-Type Dialogs for  Clarification of User Goals",
    "abstract": "Most dialog systems posit that users have figured out clear and specific\ngoals before starting an interaction. For example, users have determined the\ndeparture, the destination, and the travel time for booking a flight. However,\nin many scenarios, limited by experience and knowledge, users may know what\nthey need, but still struggle to figure out clear and specific goals by\ndetermining all the necessary slots.\nIn this paper, we identify this challenge and make a step forward by\ncollecting a new human-to-human mixed-type dialog corpus. It contains 5k dialog\nsessions and 168k utterances for 4 dialog types and 5 domains. Within each\nsession, an agent first provides user-goal-related knowledge to help figure out\nclear and specific goals, and then help achieve them.\nFurthermore, we propose a mixed-type dialog model with a novel Prompt-based\ncontinual learning mechanism. Specifically, the mechanism enables the model to\ncontinually strengthen its ability on any specific type by utilizing existing\ndialog corpora effectively.",
    "descriptor": "\nComments: ACL2022 Main conference. First two authors contributed equally to this work\n",
    "authors": [
      "Zeming Liu",
      "Jun Xu",
      "Zeyang Lei",
      "Haifeng Wang",
      "Zheng-Yu Niu",
      "Hua Wu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.07299"
  },
  {
    "id": "arXiv:2204.07300",
    "title": "Dense Learning based Semi-Supervised Object Detection",
    "abstract": "Semi-supervised object detection (SSOD) aims to facilitate the training and\ndeployment of object detectors with the help of a large amount of unlabeled\ndata. Though various self-training based and consistency-regularization based\nSSOD methods have been proposed, most of them are anchor-based detectors,\nignoring the fact that in many real-world applications anchor-free detectors\nare more demanded. In this paper, we intend to bridge this gap and propose a\nDenSe Learning (DSL) based anchor-free SSOD algorithm. Specifically, we achieve\nthis goal by introducing several novel techniques, including an Adaptive\nFiltering strategy for assigning multi-level and accurate dense pixel-wise\npseudo-labels, an Aggregated Teacher for producing stable and precise\npseudo-labels, and an uncertainty-consistency-regularization term among scales\nand shuffled patches for improving the generalization capability of the\ndetector. Extensive experiments are conducted on MS-COCO and PASCAL-VOC, and\nthe results show that our proposed DSL method records new state-of-the-art SSOD\nperformance, surpassing existing methods by a large margin. Codes can be found\nat \\textcolor{blue}{https://github.com/chenbinghui1/DSL}.",
    "descriptor": "\nComments: CVPR 2022\n",
    "authors": [
      "Binghui Chen",
      "Pengyu Li",
      "Xiang Chen",
      "Biao Wang",
      "Lei Zhang",
      "Xian-Sheng Hua"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.07300"
  },
  {
    "id": "arXiv:2204.07302",
    "title": "Improving Cross-Modal Understanding in Visual Dialog via Contrastive  Learning",
    "abstract": "Visual Dialog is a challenging vision-language task since the visual dialog\nagent needs to answer a series of questions after reasoning over both the image\ncontent and dialog history. Though existing methods try to deal with the\ncross-modal understanding in visual dialog, they are still not enough in\nranking candidate answers based on their understanding of visual and textual\ncontexts. In this paper, we analyze the cross-modal understanding in visual\ndialog based on the vision-language pre-training model VD-BERT and propose a\nnovel approach to improve the cross-modal understanding for visual dialog,\nnamed ICMU. ICMU enhances cross-modal understanding by distinguishing different\npulled inputs (i.e. pulled images, questions or answers) based on four-way\ncontrastive learning. In addition, ICMU exploits the single-turn visual\nquestion answering to enhance the visual dialog model's cross-modal\nunderstanding to handle a multi-turn visually-grounded conversation.\nExperiments show that the proposed approach improves the visual dialog model's\ncross-modal understanding and brings satisfactory gain to the VisDial dataset.",
    "descriptor": "\nComments: ICASSP 2022\n",
    "authors": [
      "Feilong Chen",
      "Xiuyi Chen",
      "Shuang Xu",
      "Bo Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.07302"
  },
  {
    "id": "arXiv:2204.07304",
    "title": "On Variants of Root Normalised Order-aware Divergence and a Divergence  based on Kendall's Tau",
    "abstract": "This paper reports on a follow-up study of the work reported in Sakai, which\nexplored suitable evaluation measures for ordinal quantification tasks. More\nspecifically, the present study defines and evaluates, in addition to the\nquantification measures considered earlier, a few variants of an ordinal\nquantification measure called Root Normalised Order-aware Divergence (RNOD), as\nwell as a measure which we call Divergence based on Kendall's $\\tau$ (DNKT).\nThe RNOD variants represent alternative design choices based on the idea of\nSakai's Distance-Weighted sum of squares (DW), while DNKT is designed to ensure\nthat the system's estimated distribution over classes is faithful to the target\npriorities over classes. As this Priority Preserving Property (PPP) of DNKT may\nbe useful in some applications, we also consider combining some of the existing\nquantification measures with DNKT. Our experiments with eight ordinal\nquantification data sets suggest that the variants of RNOD do not offer any\nbenefit over the original RNOD at least in terms of system ranking consistency,\ni.e., robustness of the system ranking to the choice of test data. Of all\nordinal quantification measures considered in this study (including Normalised\nMatch Distance, a.k.a. Earth Mover's Distance), RNOD is the most robust measure\noverall. Hence the design choice of RNOD is a good one from this viewpoint.\nAlso, DNKT is the worst performer in terms of system ranking consistency.\nHence, if DNKT seems appropriate for a task, sample size design should take its\nstatistical instability into account.",
    "descriptor": "",
    "authors": [
      "Tetsuya Sakai"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2204.07304"
  },
  {
    "id": "arXiv:2204.07305",
    "title": "Pushing the Limits of Simple Pipelines for Few-Shot Learning: External  Data and Fine-Tuning Make a Difference",
    "abstract": "Few-shot learning (FSL) is an important and topical problem in computer\nvision that has motivated extensive research into numerous methods spanning\nfrom sophisticated meta-learning methods to simple transfer learning baselines.\nWe seek to push the limits of a simple-but-effective pipeline for more\nrealistic and practical settings of few-shot image classification. To this end,\nwe explore few-shot learning from the perspective of neural network\narchitecture, as well as a three stage pipeline of network updates under\ndifferent data supplies, where unsupervised external data is considered for\npre-training, base categories are used to simulate few-shot tasks for\nmeta-training, and the scarcely labelled data of an novel task is taken for\nfine-tuning. We investigate questions such as: (1) How pre-training on external\ndata benefits FSL? (2) How state-of-the-art transformer architectures can be\nexploited? and (3) How fine-tuning mitigates domain shift? Ultimately, we show\nthat a simple transformer-based pipeline yields surprisingly good performance\non standard benchmarks such as Mini-ImageNet, CIFAR-FS, CDFSL and Meta-Dataset.\nOur code and demo are available at https://hushell.github.io/pmf.",
    "descriptor": "\nComments: Accepted by CVPR2022\n",
    "authors": [
      "Shell Xu Hu",
      "Da Li",
      "Jan St\u00fchmer",
      "Minyoung Kim",
      "Timothy M. Hospedales"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.07305"
  },
  {
    "id": "arXiv:2204.07308",
    "title": "Ensemble diverse hypotheses and knowledge distillation for unsupervised  cross-subject adaptation",
    "abstract": "Recognizing human locomotion intent and activities is important for\ncontrolling the wearable robots while walking in complex environments. However,\nhuman-robot interface signals are usually user-dependent, which causes that the\nclassifier trained on source subjects performs poorly on new subjects. To\naddress this issue, this paper designs the ensemble diverse hypotheses and\nknowledge distillation (EDHKD) method to realize unsupervised cross-subject\nadaptation. EDH mitigates the divergence between labeled data of source\nsubjects and unlabeled data of target subjects to accurately classify the\nlocomotion modes of target subjects without labeling data. Compared to previous\ndomain adaptation methods based on the single learner, which may only learn a\nsubset of features from input signals, EDH can learn diverse features by\nincorporating multiple diverse feature generators and thus increases the\naccuracy and decreases the variance of classifying target data, but it\nsacrifices the efficiency. To solve this problem, EDHKD (student) distills the\nknowledge from the EDH (teacher) to a single network to remain efficient and\naccurate. The performance of the EDHKD is theoretically proved and\nexperimentally validated on a 2D moon dataset and two public human locomotion\ndatasets. Experimental results show that the EDHKD outperforms all other\nmethods. The EDHKD can classify target data with 96.9%, 94.4%, and 97.4%\naverage accuracy on the above three datasets with a short computing time (1\nms). Compared to a benchmark (BM) method, the EDHKD increases 1.3% and 7.1%\naverage accuracy for classifying the locomotion modes of target subjects. The\nEDHKD also stabilizes the learning curves. Therefore, the EDHKD is significant\nfor increasing the generalization ability and efficiency of the human intent\nprediction and human activity recognition system, which will improve\nhuman-robot interactions.",
    "descriptor": "\nComments: This preprint was submitted to Information Fusion on December 20, 2021 and is under review\n",
    "authors": [
      "Kuangen Zhang",
      "Jiahong Chen",
      "Jing Wang",
      "Xinxing Chen",
      "Yuquan Leng",
      "Clarence W. de Silva",
      "Chenglong Fu"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.07308"
  },
  {
    "id": "arXiv:2204.07309",
    "title": "Saga: A Platform for Continuous Construction and Serving of Knowledge At  Scale",
    "abstract": "We introduce Saga, a next-generation knowledge construction and serving\nplatform for powering knowledge-based applications at industrial scale. Saga\nfollows a hybrid batch-incremental design to continuously integrate billions of\nfacts about real-world entities and construct a central knowledge graph that\nsupports multiple production use cases with diverse requirements around data\nfreshness, accuracy, and availability. In this paper, we discuss the unique\nchallenges associated with knowledge graph construction at industrial scale,\nand review the main components of Saga and how they address these challenges.\nFinally, we share lessons-learned from a wide array of production use cases\npowered by Saga.",
    "descriptor": "",
    "authors": [
      "Ihab F. Ilyas",
      "Theodoros Rekatsinas",
      "Vishnu Konda",
      "Jeffrey Pound",
      "Xiaoguang Qi",
      "Mohamed Soliman"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.07309"
  },
  {
    "id": "arXiv:2204.07311",
    "title": "MetaSets: Meta-Learning on Point Sets for Generalizable Representations",
    "abstract": "Deep learning techniques for point clouds have achieved strong performance on\na range of 3D vision tasks. However, it is costly to annotate large-scale point\nsets, making it critical to learn generalizable representations that can\ntransfer well across different point sets. In this paper, we study a new\nproblem of 3D Domain Generalization (3DDG) with the goal to generalize the\nmodel to other unseen domains of point clouds without any access to them in the\ntraining process. It is a challenging problem due to the substantial geometry\nshift from simulated to real data, such that most existing 3D models\nunderperform due to overfitting the complete geometries in the source domain.\nWe propose to tackle this problem via MetaSets, which meta-learns point cloud\nrepresentations from a group of classification tasks on carefully-designed\ntransformed point sets containing specific geometry priors. The learned\nrepresentations are more generalizable to various unseen domains of different\ngeometries. We design two benchmarks for Sim-to-Real transfer of 3D point\nclouds. Experimental results show that MetaSets outperforms existing 3D deep\nlearning methods by large margins.",
    "descriptor": "\nComments: 13 pages, CVPR 2021\n",
    "authors": [
      "Chao Huang",
      "Zhangjie Cao",
      "Yunbo Wang",
      "Jianmin Wang",
      "Mingsheng Long"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.07311"
  },
  {
    "id": "arXiv:2204.07315",
    "title": "Machine Learning Approaches to Automated Mechanism Design for Public  Project Problem",
    "abstract": "Mechanism design is a central research branch in microeconomics. An effective\nmechanism can significantly improve performance and efficiency of social\ndecisions under desired objectives, such as to maximize social welfare or to\nmaximize revenue for agents. However, mechanism design is challenging for many\ncommon models including the public project problem model which we study in this\nthesis. A typical public project problem is a group of agents crowdfunding a\npublic project (e.g., building a bridge). The mechanism will decide the payment\nand allocation for each agent (e.g., how much the agent pays, and whether the\nagent can use it) according to their valuations. The mechanism can be applied\nto various economic scenarios, including those related to cyber security. There\nare different constraints and optimized objectives for different public project\nscenarios (sub-problems), making it unrealistic to design a universal mechanism\nthat fits all scenarios, and designing mechanisms for different settings\nmanually is a taxing job. Therefore, we explore automated mechanism design\n(AMD) of public project problems under different constraints.\nIn this thesis, we focus on the public project problem, which includes many\nsub-problems (excludable/non-excludable, divisible/indivisible,\nbinary/non-binary). We study the classical public project model and extend this\nmodel to other related areas such as the zero-day exploit markets. For\ndifferent sub-problems of the public project problem, we adopt different novel\nmachine learning techniques to design optimal or near-optimal mechanisms via\nautomated mechanism design. We evaluate our mechanisms by theoretical analysis\nor experimentally comparing our mechanisms against existing mechanisms. The\nexperiments and theoretical results show that our mechanisms are better than\nstate-of-the-art automated or manual mechanisms.",
    "descriptor": "\nComments: Phd Thesis\n",
    "authors": [
      "Guanhua Wang"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2204.07315"
  },
  {
    "id": "arXiv:2204.07316",
    "title": "XDBERT: Distilling Visual Information to BERT from Cross-Modal Systems  to Improve Language Understanding",
    "abstract": "Transformer-based models are widely used in natural language understanding\n(NLU) tasks, and multimodal transformers have been effective in visual-language\ntasks. This study explores distilling visual information from pretrained\nmultimodal transformers to pretrained language encoders. Our framework is\ninspired by cross-modal encoders' success in visual-language tasks while we\nalter the learning objective to cater to the language-heavy characteristics of\nNLU. After training with a small number of extra adapting steps and finetuned,\nthe proposed XDBERT (cross-modal distilled BERT) outperforms pretrained-BERT in\ngeneral language understanding evaluation (GLUE), situations with adversarial\ngenerations (SWAG) benchmarks, and readability benchmarks. We analyze the\nperformance of XDBERT on GLUE to show that the improvement is likely visually\ngrounded.",
    "descriptor": "\nComments: ACL 2022\n",
    "authors": [
      "Chan-Jan Hsu",
      "Hung-yi Lee",
      "Yu Tsao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.07316"
  },
  {
    "id": "arXiv:2204.07319",
    "title": "A review of path following control strategies for autonomous robotic  vehicles: theory, simulations, and experiments",
    "abstract": "This article presents an in-depth review of the topic of path following for\nautonomous robotic vehicles, with a specific focus on vehicle motion in two\ndimensional space (2D). From a control system standpoint, path following can be\nformulated as the problem of stabilizing a path following error system that\ndescribes the dynamics of position and possibly orientation errors of a vehicle\nwith respect to a path, with the errors defined in an appropriate reference\nframe. In spite of the large variety of path following methods described in the\nliterature we show that, in principle, most of them can be categorized in two\ngroups: stabilization of the path following error system expressed either in\nthe vehicle's body frame or in a frame attached to a \"reference point\" moving\nalong the path, such as a Frenet-Serret (F-S) frame or a Parallel Transport\n(P-T) frame. With this observation, we provide a unified formulation that is\nsimple but general enough to cover many methods available in the literature. We\nthen discuss the advantages and disadvantages of each method, comparing them\nfrom the design and implementation standpoint. We further show experimental\nresults of the path following methods obtained from field trials testing with\nunder-actuated and fully-actuated autonomous marine vehicles. In addition, we\nintroduce open-source Matlab and Gazebo/ROS simulation toolboxes that are\nhelpful in testing path following methods prior to their integration in the\ncombined guidance, navigation, and control systems of autonomous vehicles.",
    "descriptor": "",
    "authors": [
      "Nguyen Hung",
      "Francisco Rego",
      "Joao Quintas",
      "Joao Cruz",
      "Marcelo Jacinto",
      "David Souto",
      "Andre Potes",
      "Luis Sebastiao",
      "Antonio Pascoal"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2204.07319"
  },
  {
    "id": "arXiv:2204.07321",
    "title": "Graph Pooling for Graph Neural Networks: Progress, Challenges, and  Opportunities",
    "abstract": "Graph neural networks have emerged as a leading architecture for many\ngraph-level tasks such as graph classification and graph generation with a\nnotable improvement. Among these tasks, graph pooling is an essential component\nof graph neural network architectures for obtaining a holistic graph-level\nrepresentation of the entire graph. Although a great variety of methods have\nbeen proposed in this promising and fast-developing research field, to the best\nof our knowledge, little effort has been made to systematically summarize these\nmethods. To set the stage for the development of future works, in this paper,\nwe attempt to fill this gap by providing a broad review of recent methods on\ngraph pooling. Specifically, 1) we first propose a taxonomy of existing graph\npooling methods and provide a mathematical summary for each category; 2) next,\nwe provide an overview of the libraries related to graph pooling, including the\ncommonly used datasets, model architectures for downstream tasks, and\nopen-source implementations; 3) then, we further outline in brief the\napplications that incorporate the idea of graph pooling in a number of domains;\n4) and finally, we discuss some critical challenges faced by the current\nstudies and share our insights on potential directions for improving graph\npooling in the future.",
    "descriptor": "\nComments: 9 pages, 2 figures\n",
    "authors": [
      "Chuang Liu",
      "Yibing Zhan",
      "Chang Li",
      "Bo Du",
      "Jia Wu",
      "Wenbin Hu",
      "Tongliang Liu",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.07321"
  },
  {
    "id": "arXiv:2204.07327",
    "title": "Shortest Unique Palindromic Substring Queries in Semi-dynamic Settings",
    "abstract": "A palindromic substring $T[i.. j]$ of a string $T$ is said to be a shortest\nunique palindromic substring (SUPS) in $T$ for an interval $[p, q]$ if $T[i..\nj]$ is a shortest one such that $T[i.. j]$ occurs only once in $T$, and $[i,\nj]$ contains $[p, q]$. The SUPS problem is, given a string $T$ of length $n$,\nto construct a data structure that can compute all the SUPSs for any given\nquery interval. It is known that any SUPS query can be answered in $O(\\alpha)$\ntime after $O(n)$-time preprocessing, where $\\alpha$ is the number of SUPSs to\noutput [Inoue et al., 2018]. In this paper, we first show that $\\alpha$ is at\nmost $4$, and the upper bound is tight. Also, we present an algorithm to solve\nthe SUPS problem for a sliding window that can answer any query in $O(\\log\\log\nW)$ time and update data structures in amortized $O(\\log\\sigma)$ time, where\n$W$ is the size of the window, and $\\sigma$ is the alphabet size. Furthermore,\nwe consider the SUPS problem in the after-edit model and present an efficient\nalgorithm. Namely, we present an algorithm that uses $O(n)$ time for\npreprocessing and answers any $k$ SUPS queries in $O(\\log n\\log\\log n +\nk\\log\\log n)$ time after single character substitution. As a by-product, we\npropose a fully-dynamic data structure for range minimum queries (RmQs) with a\nconstraint where the width of each query range is limited to polylogarithmic.\nThe constrained RmQ data structure can answer such a query in constant time and\nsupport a single-element edit operation in amortized constant time.",
    "descriptor": "",
    "authors": [
      "Takuya Mieno",
      "Mitsuru Funakoshi"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2204.07327"
  },
  {
    "id": "arXiv:2204.07328",
    "title": "Knowledgebra: An Algebraic Learning Framework for Knowledge Graph",
    "abstract": "Knowledge graph (KG) representation learning aims to encode entities and\nrelations into dense continuous vector spaces such that knowledge contained in\na dataset could be consistently represented. Dense embeddings trained from KG\ndatasets benefit a variety of downstream tasks such as KG completion and link\nprediction. However, existing KG embedding methods fell short to provide a\nsystematic solution for the global consistency of knowledge representation. We\ndeveloped a mathematical language for KG based on an observation of their\ninherent algebraic structure, which we termed as Knowledgebra. By analyzing\nfive distinct algebraic properties, we proved that the semigroup is the most\nreasonable algebraic structure for the relation embedding of a general\nknowledge graph. We implemented an instantiation model, SemE, using simple\nmatrix semigroups, which exhibits state-of-the-art performance on standard\ndatasets. Moreover, we proposed a regularization-based method to integrate\nchain-like logic rules derived from human knowledge into embedding training,\nwhich further demonstrates the power of the developed language. As far as we\nknow, by applying abstract algebra in statistical learning, this work develops\nthe first formal language for general knowledge graphs, and also sheds light on\nthe problem of neural-symbolic integration from an algebraic perspective.",
    "descriptor": "\nComments: 12 pages\n",
    "authors": [
      "Tong Yang",
      "Yifei Wang",
      "Long Sha",
      "Jan Engelbrecht",
      "Pengyu Hong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.07328"
  },
  {
    "id": "arXiv:2204.07333",
    "title": "Topology optimization for additive manufacturing with length scale,  overhang, and building orientation constraints",
    "abstract": "This paper presents a density-based topology optimization approach\nconsidering additive manufacturing limitations. The presented method considers\nthe minimum size of parts, the minimum size of cavities, the inability of\nprinting overhanging parts without the use of sacrificial supporting\nstructures, and the printing directions. These constraints are geometrically\naddressed and implemented. The minimum size on solid and void zones is imposed\nthrough a well-known filtering technique. The sacrificial support material is\nreduced using a constraint that limits the maximum overhang angle of parts by\ncomparing the structural gradient with a critical reference slope. Due to the\nlocal nature of the gradient, the chosen restriction is prone to introduce\nparts that meet the structural slope but that may not be self-supporting. The\nrestriction limits the maximum overhang angle for a user-defined printing\ndirection, which could reduce structural performance if the orientation is not\nproperly selected. To ease these challenges, a new approach to reduce the\nintroduction of such non-self-supporting parts and a novel method that includes\ndifferent printing directions in the maximum overhang angle constraint are\npresented. The proposed strategy for considering the minimum size of solid and\nvoid phases, maximum overhang angle, and printing direction, is illustrated by\nsolving a set of 2D benchmark design problems including stiff structures and\ncompliant mechanisms. We also provide MATLAB codes in the appendix for\neducational purposes and for replication of the results.",
    "descriptor": "",
    "authors": [
      "Prabhat Kumar",
      "Eduardo Fern\u00e1ndez"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2204.07333"
  },
  {
    "id": "arXiv:2204.07335",
    "title": "A Keypoint-based Global Association Network for Lane Detection",
    "abstract": "Lane detection is a challenging task that requires predicting complex\ntopology shapes of lane lines and distinguishing different types of lanes\nsimultaneously. Earlier works follow a top-down roadmap to regress predefined\nanchors into various shapes of lane lines, which lacks enough flexibility to\nfit complex shapes of lanes due to the fixed anchor shapes. Lately, some works\npropose to formulate lane detection as a keypoint estimation problem to\ndescribe the shapes of lane lines more flexibly and gradually group adjacent\nkeypoints belonging to the same lane line in a point-by-point manner, which is\ninefficient and time-consuming during postprocessing. In this paper, we propose\na Global Association Network (GANet) to formulate the lane detection problem\nfrom a new perspective, where each keypoint is directly regressed to the\nstarting point of the lane line instead of point-by-point extension.\nConcretely, the association of keypoints to their belonged lane line is\nconducted by predicting their offsets to the corresponding starting points of\nlanes globally without dependence on each other, which could be done in\nparallel to greatly improve efficiency. In addition, we further propose a\nLane-aware Feature Aggregator (LFA), which adaptively captures the local\ncorrelations between adjacent keypoints to supplement local information to the\nglobal association. Extensive experiments on two popular lane detection\nbenchmarks show that our method outperforms previous methods with F1 score of\n79.63% on CULane and 97.71% on Tusimple dataset with high FPS. The code will be\nreleased at https://github.com/Wolfwjs/GANet.",
    "descriptor": "\nComments: Accepted by CVPR2022\n",
    "authors": [
      "Jinsheng Wang",
      "Yinchao Ma",
      "Shaofei Huang",
      "Tianrui Hui",
      "Fei Wang",
      "Chen Qian",
      "Tianzhu Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.07335"
  },
  {
    "id": "arXiv:2204.07336",
    "title": "Preparing for the Future -- Rethinking Proxy Apps",
    "abstract": "A considerable amount of research and engineering went into designing proxy\napplications, which represent common high-performance computing workloads, to\nco-design and evaluate the current generation of supercomputers, e.g., RIKEN's\nSupercomputer Fugaku, ANL's Aurora, or ORNL's Frontier. This process was\nnecessary to standardize the procurement while avoiding duplicated effort at\neach HPC center to develop their own benchmarks. Unfortunately, proxy\napplications force HPC centers and providers (vendors) into a an undesirable\nstate of rigidity, in contrast to the fast-moving trends of current technology\nand future heterogeneity. To accommodate an extremely-heterogeneous future, we\nhave to reconsider how to co-design supercomputers during the next decade, and\navoid repeating the past mistakes. This position paper outlines the current\nstate-of-the-art in system co-design, challenges encountered over the past\nyears, and a proposed plan to move forward.",
    "descriptor": "",
    "authors": [
      "Satoshi Matsuoka",
      "Jens Domke",
      "Mohamed Wahib",
      "Aleksandr Drozd",
      "Ray Bair",
      "Andrew A. Chien",
      "Jeffrey S. Vetter",
      "John Shalf"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2204.07336"
  },
  {
    "id": "arXiv:2204.07337",
    "title": "Training Entire-Space Models for Target-oriented Opinion Words  Extraction",
    "abstract": "Target-oriented opinion words extraction (TOWE) is a subtask of aspect-based\nsentiment analysis (ABSA). Given a sentence and an aspect term occurring in the\nsentence, TOWE extracts the corresponding opinion words for the aspect term.\nTOWE has two types of instance. In the first type, aspect terms are associated\nwith at least one opinion word, while in the second type, aspect terms do not\nhave corresponding opinion words. However, previous researches trained and\nevaluated their models with only the first type of instance, resulting in a\nsample selection bias problem. Specifically, TOWE models were trained with only\nthe first type of instance, while these models would be utilized to make\ninference on the entire space with both the first type of instance and the\nsecond type of instance. Thus, the generalization performance will be hurt.\nMoreover, the performance of these models on the first type of instance cannot\nreflect their performance on entire space. To validate the sample selection\nbias problem, four popular TOWE datasets containing only aspect terms\nassociated with at least one opinion word are extended and additionally include\naspect terms without corresponding opinion words. Experimental results on these\ndatasets show that training TOWE models on entire space will significantly\nimprove model performance and evaluating TOWE models only on the first type of\ninstance will overestimate model performance.",
    "descriptor": "\nComments: SIGIR 2022 (Short Paper)\n",
    "authors": [
      "Yuncong Li",
      "Fang Wang",
      "Sheng-Hua Zhong"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.07337"
  },
  {
    "id": "arXiv:2204.07341",
    "title": "LaMemo: Language Modeling with Look-Ahead Memory",
    "abstract": "Although Transformers with fully connected self-attentions are powerful to\nmodel long-term dependencies, they are struggling to scale to long texts with\nthousands of words in language modeling. One of the solutions is to equip the\nmodel with a recurrence memory. However, existing approaches directly reuse\nhidden states from the previous segment that encodes contexts in a\nuni-directional way. As a result, this prohibits the memory to dynamically\ninteract with the current context that provides up-to-date information for\ntoken prediction. To remedy this issue, we propose Look-Ahead Memory (LaMemo)\nthat enhances the recurrence memory by incrementally attending to the\nright-side tokens, and interpolating with the old memory states to maintain\nlong-term information in the history. LaMemo embraces bi-directional attention\nand segment recurrence with an additional computation overhead only linearly\nproportional to the memory length. Experiments on widely used language modeling\nbenchmarks demonstrate its superiority over the baselines equipped with\ndifferent types of memory.",
    "descriptor": "\nComments: Accepted by NAACL 2022\n",
    "authors": [
      "Haozhe Ji",
      "Rongsheng Zhang",
      "Zhenyu Yang",
      "Zhipeng Hu",
      "Minlie Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.07341"
  },
  {
    "id": "arXiv:2204.07346",
    "title": "MVSTER: Epipolar Transformer for Efficient Multi-View Stereo",
    "abstract": "Learning-based Multi-View Stereo (MVS) methods warp source images into the\nreference camera frustum to form 3D volumes, which are fused as a cost volume\nto be regularized by subsequent networks. The fusing step plays a vital role in\nbridging 2D semantics and 3D spatial associations. However, previous methods\nutilize extra networks to learn 2D information as fusing cues, underusing 3D\nspatial correlations and bringing additional computation costs. Therefore, we\npresent MVSTER, which leverages the proposed epipolar Transformer to learn both\n2D semantics and 3D spatial associations efficiently. Specifically, the\nepipolar Transformer utilizes a detachable monocular depth estimator to enhance\n2D semantics and uses cross-attention to construct data-dependent 3D\nassociations along epipolar line. Additionally, MVSTER is built in a cascade\nstructure, where entropy-regularized optimal transport is leveraged to\npropagate finer depth estimations in each stage. Extensive experiments show\nMVSTER achieves state-of-the-art reconstruction performance with significantly\nhigher efficiency: Compared with MVSNet and CasMVSNet, our MVSTER achieves 34%\nand 14% relative improvements on the DTU benchmark, with 80% and 51% relative\nreductions in running time. MVSTER also ranks first on Tanks&Temples-Advanced\namong all published works. Code is released at https://github.com/JeffWang987.",
    "descriptor": "\nComments: Code: this https URL\n",
    "authors": [
      "Xiaofeng Wang",
      "Zheng Zhu",
      "Fangbo Qin",
      "Yun Ye",
      "Guan Huang",
      "Xu Chi",
      "Yijia He",
      "Xingang Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.07346"
  },
  {
    "id": "arXiv:2204.07347",
    "title": "Crowd counting with crowd attention convolutional neural network",
    "abstract": "Crowd counting is a challenging problem due to the scene complexity and scale\nvariation. Although deep learning has achieved great improvement in crowd\ncounting, scene complexity affects the judgement of these methods and they\nusually regard some objects as people mistakenly; causing potentially enormous\nerrors in the crowd counting result. To address the problem, we propose a novel\nend-to-end model called Crowd Attention Convolutional Neural Network (CAT-CNN).\nOur CAT-CNN can adaptively assess the importance of a human head at each pixel\nlocation by automatically encoding a confidence map. With the guidance of the\nconfidence map, the position of human head in estimated density map gets more\nattention to encode the final density map, which can avoid enormous\nmisjudgements effectively. The crowd count can be obtained by integrating the\nfinal density map. To encode a highly refined density map, the total crowd\ncount of each image is classified in a designed classification task and we\nfirst explicitly map the prior of the population-level category to feature\nmaps. To verify the efficiency of our proposed method, extensive experiments\nare conducted on three highly challenging datasets. Results establish the\nsuperiority of our method over many state-of-the-art methods.",
    "descriptor": "\nComments: Accepted by Neurocomputing\n",
    "authors": [
      "Jiwei Chen",
      "Wen Su",
      "Zengfu Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.07347"
  },
  {
    "id": "arXiv:2204.07350",
    "title": "Condition-Invariant and Compact Visual Place Description by  Convolutional Autoencoder",
    "abstract": "Visual place recognition (VPR) in condition-varying environments is still an\nopen problem. Popular solutions are CNN-based image descriptors, which have\nbeen shown to outperform traditional image descriptors based on hand-crafted\nvisual features. However, there are two drawbacks of current CNN-based\ndescriptors: a) their high dimension and b) lack of generalization, leading to\nlow efficiency and poor performance in applications. In this paper, we propose\nto use a convolutional autoencoder (CAE) to tackle this problem. We employ a\nhigh-level layer of a pre-trained CNN to generate features, and train a CAE to\nmap the features to a low-dimensional space to improve the condition invariance\nproperty of the descriptor and reduce its dimension at the same time. We verify\nour method in three challenging datasets involving significant illumination\nchanges, and our method is shown to be superior to the state-of-the-art. For\nthe benefit of the community, we make public the source code.",
    "descriptor": "\nComments: under review in Journal Intelligent and Robotic Systems (JINT), 2022\n",
    "authors": [
      "Hanjing Ye",
      "Weinan Chen",
      "Jingwen Yu",
      "Li He",
      "Yisheng Guan",
      "Hong Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2204.07350"
  },
  {
    "id": "arXiv:2204.07352",
    "title": "A Differentially Private Probabilistic Framework for Modeling the  Variability Across Federated Datasets of Heterogeneous Multi-View  Observations",
    "abstract": "We propose a novel federated learning paradigm to model data variability\namong heterogeneous clients in multi-centric studies. Our method is expressed\nthrough a hierarchical Bayesian latent variable model, where client-specific\nparameters are assumed to be realization from a global distribution at the\nmaster level, which is in turn estimated to account for data bias and\nvariability across clients. We show that our framework can be effectively\noptimized through expectation maximization (EM) over latent master's\ndistribution and clients' parameters. We also introduce formal differential\nprivacy (DP) guarantees compatibly with our EM optimization scheme. We tested\nour method on the analysis of multi-modal medical imaging data and clinical\nscores from distributed clinical datasets of patients affected by Alzheimer's\ndisease. We demonstrate that our method is robust when data is distributed\neither in iid and non-iid manners, even when local parameters perturbation is\nincluded to provide DP guarantees. Moreover, the variability of data, views and\ncenters can be quantified in an interpretable manner, while guaranteeing\nhigh-quality data reconstruction as compared to state-of-the-art autoencoding\nmodels and federated learning schemes. The code is available at\nhttps://gitlab.inria.fr/epione/federated-multi-views-ppca.",
    "descriptor": "",
    "authors": [
      "Irene Balelli",
      "Santiago Silva",
      "Marco Lorenzi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Applications (stat.AP)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2204.07352"
  },
  {
    "id": "arXiv:2204.07354",
    "title": "WIP: Achieving Self-Interference-Free Operation on SDR Platform with  Critical TDD Turnaround Time",
    "abstract": "Software Defined Radio (SDR) platforms are valuable for research and\ndevelopment activities or high-end systems that demand real-time adaptable\nwireless protocols. While low latency can be achieved using the dedicated\ndigital processing unit of a state-of-the-art SDR platform, its Radio Frequency\n(RF) front-end often poses a limitation in terms of turnaround time (TT), the\ntime needed for switching from the receiving to the transmitting mode (or vice\nversa). Zero Intermediate Frequency (ZIF) transceivers are favorable for SDR,\nbut suffer from self-interference even if the device is not currently\ntransmitting. The strict MAC-layer requirements of Time Division Duplex (TDD)\nprotocols like Wi-Fi cannot be achieved using configurable ZIF transceivers\nwithout having to compromise receiver sensitivity. Using a novel approach, we\nshow that the TT using the AD9361 RF front-end can be as low as 640 ns, while\nthe self-interference is at the same level as achieved by the conventional TDD\nmode, which has a TT of at least 55 {\\mu}s. As compared to Frequency Division\nDuplex (FDD) mode, a decrease of receiver noise floor by about 13 dB in the 2.4\nGHz band and by about 4.5 dB in the 5 GHz band is achieved.",
    "descriptor": "\nComments: Accepted by IEEE International Symposium on a World of Wireless, Mobile and Multimedia Networks (WoWMoM 2022) as Work-In-Progress paper\n",
    "authors": [
      "Thijs Havinga",
      "Xianjun Jiao",
      "Muhammad Aslam",
      "Wei Liu",
      "Ingrid Moerman"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2204.07354"
  },
  {
    "id": "arXiv:2204.07356",
    "title": "Vision-and-Language Pretrained Models: A Survey",
    "abstract": "Pretrained models have produced great success in both Computer Vision (CV)\nand Natural Language Processing (NLP). This progress leads to learning joint\nrepresentations of vision and language pretraining by feeding visual and\nlinguistic contents into a multi-layer transformer, Visual-Language Pretrained\nModels (VLPMs). In this paper, we present an overview of the major advances\nachieved in VLPMs for producing joint representations of vision and language.\nAs the preliminaries, we briefly describe the general task definition and\ngenetic architecture of VLPMs. We first discuss the language and vision data\nencoding methods and then present the mainstream VLPM structure as the core\ncontent. We further summarise several essential pretraining and fine-tuning\nstrategies. Finally, we highlight three future directions for both CV and NLP\nresearchers to provide insightful guidance.",
    "descriptor": "\nComments: Accepted in IJCAI 2022\n",
    "authors": [
      "Siqu Long",
      "Feiqi Cao",
      "Soyeon Caren Han",
      "Haiqing Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.07356"
  },
  {
    "id": "arXiv:2204.07359",
    "title": "Text Revision by On-the-Fly Representation Optimization",
    "abstract": "Text revision refers to a family of natural language generation tasks, where\nthe source and target sequences share moderate resemblance in surface form but\ndifferentiate in attributes, such as text formality and simplicity. Current\nstate-of-the-art methods formulate these tasks as sequence-to-sequence learning\nproblems, which rely on large-scale parallel training corpus. In this paper, we\npresent an iterative in-place editing approach for text revision, which\nrequires no parallel data. In this approach, we simply fine-tune a pre-trained\nTransformer with masked language modeling and attribute classification. During\ninference, the editing at each iteration is realized by two-step span\nreplacement. At the first step, the distributed representation of the text\noptimizes on the fly towards an attribute function. At the second step, a text\nspan is masked and another new one is proposed conditioned on the optimized\nrepresentation. The empirical experiments on two typical and important text\nrevision tasks, text formalization and text simplification, show the\neffectiveness of our approach. It achieves competitive and even better\nperformance than state-of-the-art supervised methods on text simplification,\nand gains better performance than strong unsupervised methods on text\nformalization \\footnote{Code and model are available at\n\\url{https://github.com/jingjingli01/OREO}}.",
    "descriptor": "\nComments: AAAI 2022\n",
    "authors": [
      "Jingjing Li",
      "Zichao Li",
      "Tao Ge",
      "Irwin King",
      "Michael R. Lyu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.07359"
  },
  {
    "id": "arXiv:2204.07363",
    "title": "Is Surprisal in Issue Trackers Actionable?",
    "abstract": "Background. From information theory, surprisal is a measurement of how\nunexpected an event is. Statistical language models provide a probabilistic\napproximation of natural languages, and because surprisal is constructed with\nthe probability of an event occuring, it is therefore possible to determine the\nsurprisal associated with English sentences. The issues and pull requests of\nsoftware repository issue trackers give insight into the development process\nand likely contain the surprising events of this process.\nObjective. Prior works have identified that unusual events in software\nrepositories are of interest to developers, and use simple code metrics-based\nmethods for detecting them. In this study we will propose a new method for\nunusual event detection in software repositories using surprisal. With the\nability to find surprising issues and pull requests, we intend to further\nanalyse them to determine if they actually hold importance in a repository, or\nif they pose a significant challenge to address. If it is possible to find bad\nsurprises early, or before they cause additional troubles, it is plausible that\neffort, cost and time will be saved as a result.\nMethod. After extracting the issues and pull requests from 5000 of the most\npopular software repositories on GitHub, we will train a language model to\nrepresent these issues. We will measure their perceived importance in the\nrepository, measure their resolution difficulty using several analogues,\nmeasure the surprisal of each, and finally generate inferential statistics to\ndescribe any correlations.",
    "descriptor": "\nComments: 8 pages, 1 figure. Submitted to 2022 International Conference on Mining Software Repositories Registered Reports track\n",
    "authors": [
      "James Caddy",
      "Markus Wagner",
      "Christoph Treude",
      "Earl T. Barr",
      "Miltiadis Allamanis"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2204.07363"
  },
  {
    "id": "arXiv:2204.07366",
    "title": "ResT V2: Simpler, Faster and Stronger",
    "abstract": "This paper proposes ResTv2, a simpler, faster, and stronger multi-scale\nvision Transformer for visual recognition. ResTv2 simplifies the EMSA structure\nin ResTv1 (i.e., eliminating the multi-head interaction part) and employs an\nupsample operation to reconstruct the lost medium- and high-frequency\ninformation caused by the downsampling operation. In addition, we explore\ndifferent techniques for better apply ResTv2 backbones to downstream tasks. We\nfound that although combining EMSAv2 and window attention can greatly reduce\nthe theoretical matrix multiply FLOPs, it may significantly decrease the\ncomputation density, thus causing lower actual speed. We comprehensively\nvalidate ResTv2 on ImageNet classification, COCO detection, and ADE20K semantic\nsegmentation. Experimental results show that the proposed ResTv2 can outperform\nthe recently state-of-the-art backbones by a large margin, demonstrating the\npotential of ResTv2 as solid backbones. The code and models will be made\npublicly available at \\url{https://github.com/wofmanaf/ResT}",
    "descriptor": "",
    "authors": [
      "Qing-Long Zhang",
      "Yu-Bin Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.07366"
  },
  {
    "id": "arXiv:2204.07367",
    "title": "On the Role of Pre-trained Language Models in Word Ordering: A Case  Study with BART",
    "abstract": "Word ordering is a constrained language generation task taking unordered\nwords as input. Existing work uses linear models and neural networks for the\ntask, yet pre-trained language models have not been studied in word ordering,\nlet alone why they help. We use BART as an instance and show its effectiveness\nin the task. To explain why BART helps word ordering, we extend analysis with\nprobing and empirically identify that syntactic dependency knowledge in BART is\na reliable explanation. We also report performance gains with BART in the\nrelated partial tree linearization task, which readily extends our analysis.",
    "descriptor": "",
    "authors": [
      "Zebin Ou",
      "Meishan Zhang",
      "Yue Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.07367"
  },
  {
    "id": "arXiv:2204.07370",
    "title": "2D Human Pose Estimation: A Survey",
    "abstract": "Human pose estimation aims at localizing human anatomical keypoints or body\nparts in the input data (e.g., images, videos, or signals). It forms a crucial\ncomponent in enabling machines to have an insightful understanding of the\nbehaviors of humans, and has become a salient problem in computer vision and\nrelated fields. Deep learning techniques allow learning feature representations\ndirectly from the data, significantly pushing the performance boundary of human\npose estimation. In this paper, we reap the recent achievements of 2D human\npose estimation methods and present a comprehensive survey. Briefly, existing\napproaches put their efforts in three directions, namely network architecture\ndesign, network training refinement, and post processing. Network architecture\ndesign looks at the architecture of human pose estimation models, extracting\nmore robust features for keypoint recognition and localization. Network\ntraining refinement tap into the training of neural networks and aims to\nimprove the representational ability of models. Post processing further\nincorporates model-agnostic polishing strategies to improve the performance of\nkeypoint detection. More than 200 research contributions are involved in this\nsurvey, covering methodological frameworks, common benchmark datasets,\nevaluation metrics, and performance comparisons. We seek to provide researchers\nwith a more comprehensive and systematic review on human pose estimation,\nallowing them to acquire a grand panorama and better identify future\ndirections.",
    "descriptor": "",
    "authors": [
      "Haoming Chen",
      "Runyang Feng",
      "Sifan Wu",
      "Hao Xu",
      "Fengcheng Zhou",
      "Zhenguang Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.07370"
  },
  {
    "id": "arXiv:2204.07371",
    "title": "How to Save Lives with Microblogs? Lessons From the Usage of Weibo for  Requests for Medical Assistance During COVID-19",
    "abstract": "During recent crises like COVID-19, microblogging platforms have become\npopular channels for affected people seeking assistance such as medical\nsupplies and rescue operations from emergency responders and the public.\nDespite this common practice, the affordances of microblogging services for\nhelp-seeking during crises that needs immediate attention are not well\nunderstood. To fill this gap, we analyzed 8K posts from COVID-19 patients or\ncaregivers requesting urgent medical assistance on Weibo, the largest\nmicroblogging site in China. Our mixed-methods analyses suggest that existing\nmicroblogging functions need to be improved in multiple aspects to sufficiently\nfacilitate help-seeking in emergencies, including capabilities of search and\ntracking requests, ease of use, and privacy protection. We also find that\npeople tend to stick to certain well-established functions for publishing\nrequests, even after better alternatives emerge. These findings have\nimplications for designing microblogging tools to better support help\nrequesting and responding during crises.",
    "descriptor": "\nComments: CHI 2022\n",
    "authors": [
      "Wenjie Yang",
      "Zhiyang Wu",
      "Nga Yiu Mok",
      "Xiaojuan Ma"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2204.07371"
  },
  {
    "id": "arXiv:2204.07372",
    "title": "Towards Building a Personalized Dialogue Generator via Implicit User  Persona Detection",
    "abstract": "Current works in the generation of personalized dialogue primarily contribute\nto the agent avoiding contradictory persona and driving the response more\ninformative. However, we found that the generated responses from these models\nare mostly self-centered with little care for the other party since they ignore\nthe user's persona. Moreover, we consider high-quality transmission is\nessentially built based on apprehending the persona of the other party.\nMotivated by this, we propose a novel personalized dialogue generator by\ndetecting implicit user persona. Because it's difficult to collect a large\nnumber of personas for each user, we attempt to model the user's potential\npersona and its representation from the dialogue absence of any external\ninformation. Perception variable and fader variable are conceived utilizing\nConditional Variational Inference. The two latent variables simulate the\nprocess of people being aware of the other party's persona and producing the\ncorresponding expression in conversation. Finally, Posterior-discriminated\nRegularization is presented to enhance the training procedure. Empirical\nstudies demonstrate that compared with the state-of-the-art methods, ours is\nmore concerned with the user's persona and outperforms in evaluations.",
    "descriptor": "\nComments: 7 pages, 6 figures, conference, no conference submit\n",
    "authors": [
      "Itsugun Cho",
      "Dongyang Wang",
      "Ryota Takahashi",
      "Hiroaki Saito"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.07372"
  },
  {
    "id": "arXiv:2204.07373",
    "title": "Revisiting the Adversarial Robustness-Accuracy Tradeoff in Robot  Learning",
    "abstract": "Adversarial training (i.e., training on adversarially perturbed input data)\nis a well-studied method for making neural networks robust to potential\nadversarial attacks during inference. However, the improved robustness does not\ncome for free but rather is accompanied by a decrease in overall model accuracy\nand performance. Recent work has shown that, in practical robot learning\napplications, the effects of adversarial training do not pose a fair trade-off\nbut inflict a net loss when measured in holistic robot performance. This work\nrevisits the robustness-accuracy trade-off in robot learning by systematically\nanalyzing if recent advances in robust training methods and theory in\nconjunction with adversarial robot learning can make adversarial training\nsuitable for real-world robot applications. We evaluate a wide variety of robot\nlearning tasks ranging from autonomous driving in a high-fidelity environment\namenable to sim-to-real deployment, to mobile robot gesture recognition. Our\nresults demonstrate that, while these techniques make incremental improvements\non the trade-off on a relative scale, the negative side-effects caused by\nadversarial training still outweigh the improvements by an order of magnitude.\nWe conclude that more substantial advances in robust learning methods are\nnecessary before they can benefit robot learning tasks in practice.",
    "descriptor": "",
    "authors": [
      "Mathias Lechner",
      "Alexander Amini",
      "Daniela Rus",
      "Thomas A. Henzinger"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.07373"
  },
  {
    "id": "arXiv:2204.07374",
    "title": "Image Captioning In the Transformer Age",
    "abstract": "Image Captioning (IC) has achieved astonishing developments by incorporating\nvarious techniques into the CNN-RNN encoder-decoder architecture. However,\nsince CNN and RNN do not share the basic network component, such a\nheterogeneous pipeline is hard to be trained end-to-end where the visual\nencoder will not learn anything from the caption supervision. This drawback\ninspires the researchers to develop a homogeneous architecture that facilitates\nend-to-end training, for which Transformer is the perfect one that has proven\nits huge potential in both vision and language domains and thus can be used as\nthe basic component of the visual encoder and language decoder in an IC\npipeline. Meantime, self-supervised learning releases the power of the\nTransformer architecture that a pre-trained large-scale one can be generalized\nto various tasks including IC. The success of these large-scale models seems to\nweaken the importance of the single IC task. However, we demonstrate that IC\nstill has its specific significance in this age by analyzing the connections\nbetween IC with some popular self-supervised learning paradigms. Due to the\npage limitation, we only refer to highly important papers in this short survey\nand more related works can be found at\nhttps://github.com/SjokerLily/awesome-image-captioning.",
    "descriptor": "\nComments: 8pages,2 figures\n",
    "authors": [
      "Yang Xu",
      "Li Li",
      "Haiyang Xu",
      "Songfang Huang",
      "Fei Huang",
      "Jianfei Cai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.07374"
  },
  {
    "id": "arXiv:2204.07380",
    "title": "Crowd counting with segmentation attention convolutional neural network",
    "abstract": "Deep learning occupies an undisputed dominance in crowd counting. In this\npaper, we propose a novel convolutional neural network (CNN) architecture\ncalled SegCrowdNet. Despite the complex background in crowd scenes, the\nproposeSegCrowdNet still adaptively highlights the human head region and\nsuppresses the non-head region by segmentation. With the guidance of an\nattention mechanism, the proposed SegCrowdNet pays more attention to the human\nhead region and automatically encodes the highly refined density map. The crowd\ncount can be obtained by integrating the density map. To adapt the variation of\ncrowd counts, SegCrowdNet intelligently classifies the crowd count of each\nimage into several groups. In addition, the multi-scale features are learned\nand extracted in the proposed SegCrowdNet to overcome the scale variations of\nthe crowd. To verify the effectiveness of our proposed method, extensive\nexperiments are conducted on four challenging datasets. The results demonstrate\nthat our proposed SegCrowdNet achieves excellent performance compared with the\nstate-of-the-art methods.",
    "descriptor": "\nComments: Accepted by IET Image Processing\n",
    "authors": [
      "Jiwei Chen",
      "Zengfu Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.07380"
  },
  {
    "id": "arXiv:2204.07387",
    "title": "AID: Accuracy Improvement of Analog Discharge-Based in-SRAM  Multiplication Accelerator",
    "abstract": "This paper presents a novel circuit (AID) to improve the accuracy of an\nenergy-efficient in-memory multiplier using a standard 6T-SRAM. The\nstate-of-the-art discharge-based in-SRAM multiplication accelerators suffer\nfrom a non-linear behavior in their bit-line (BL, BLB) due to the quadratic\nnature of the access transistor that leads to a poor signal-to-noise ratio\n(SNR). In order to achieve linearity in the BLB voltage, we propose a novel\nroot function technique on the access transistor's gate that results in\naccuracy improvement of on average 10.77 dB SNR compared to state-of-the-art\ndischarge-based topologies. Our analytical methods and a circuit simulation in\na 65 nm CMOS technology verify that the proposed technique consumes 0.523 pJ\nper computation (multiplication, accumulation, and preset) from a power supply\nof 1V, which is 51.18% lower compared to other state-of-the-art techniques. We\nhave performed an extensive Monte Carlo based simulation for a 4x4\nmultiplication operation, and our novel technique presents less than 0.086\nstandard deviations for the worst-case incorrect output scenario.",
    "descriptor": "",
    "authors": [
      "Saeed Seyedfaraji",
      "Baset Mesgari",
      "Semeen Rehman"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2204.07387"
  },
  {
    "id": "arXiv:2204.07390",
    "title": "Email Spam Detection Using Hierarchical Attention Hybrid Deep Learning  Method",
    "abstract": "Email is one of the most widely used ways to communicate, with millions of\npeople and businesses relying on it to communicate and share knowledge and\ninformation on a daily basis. Nevertheless, the rise in email users has\noccurred a dramatic increase in spam emails in recent years. Processing and\nmanaging emails properly for individuals and companies are getting increasingly\ndifficult. This article proposes a novel technique for email spam detection\nthat is based on a combination of convolutional neural networks, gated\nrecurrent units, and attention mechanisms. During system training, the network\nis selectively focused on necessary parts of the email text. The usage of\nconvolution layers to extract more meaningful, abstract, and generalizable\nfeatures by hierarchical representation is the major contribution of this\nstudy. Additionally, this contribution incorporates cross-dataset evaluation,\nwhich enables the generation of more independent performance results from the\nmodel's training dataset. According to cross-dataset evaluation results, the\nproposed technique advances the results of the present attention-based\ntechniques by utilizing temporal convolutions, which give us more flexible\nreceptive field sizes are utilized. The suggested technique's findings are\ncompared to those of state-of-the-art models and show that our approach\noutperforms them.",
    "descriptor": "",
    "authors": [
      "Sultan Zavrak",
      "Seyhmus Yilmaz"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2204.07390"
  },
  {
    "id": "arXiv:2204.07394",
    "title": "FasterVideo: Efficient Online Joint Object Detection And Tracking",
    "abstract": "Object detection and tracking in videos represent essential and\ncomputationally demanding building blocks for current and future visual\nperception systems. In order to reduce the efficiency gap between available\nmethods and computational requirements of real-world applications, we propose\nto re-think one of the most successful methods for image object detection,\nFaster R-CNN, and extend it to the video domain. Specifically, we extend the\ndetection framework to learn instance-level embeddings which prove beneficial\nfor data association and re-identification purposes. Focusing on the\ncomputational aspects of detection and tracking, our proposed method reaches a\nvery high computational efficiency necessary for relevant applications, while\nstill managing to compete with recent and state-of-the-art methods as shown in\nthe experiments we conduct on standard object tracking benchmarks",
    "descriptor": "\nComments: Accepted at 21st International Conference on Image Analysis and Processing (ICIAP 2021)\n",
    "authors": [
      "Issa Mouawad",
      "Francesca Odone"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.07394"
  },
  {
    "id": "arXiv:2204.07398",
    "title": "Generalized Universal Coding of Integers",
    "abstract": "Universal coding of integers~(UCI) is a class of variable-length code, such\nthat the ratio of the expected codeword length to $\\max\\{1,H(P)\\}$ is within a\nconstant factor, where $H(P)$ is the Shannon entropy of the decreasing\nprobability distribution $P$. However, if we consider the ratio of the expected\ncodeword length to $H(P)$, the ratio tends to infinity by using UCI, when\n$H(P)$ tends to zero. To solve this issue, this paper introduces a class of\ncodes, termed generalized universal coding of integers~(GUCI), such that the\nratio of the expected codeword length to $H(P)$ is within a constant factor\n$K$. First, the definition of GUCI is proposed and the coding structure of GUCI\nis introduced. Next, we propose a class of GUCI $\\mathcal{C}$ to achieve the\nexpansion factor $K_{\\mathcal{C}}=2$ and show that the optimal GUCI is in the\nrange $1\\leq K_{\\mathcal{C}}^{*}\\leq 2$. Then, by comparing UCI and GUCI, we\nshow that when the entropy is very large or $P(0)$ is not large, there are also\ncases where the average codeword length of GUCI is shorter. Finally, the\nasymptotically optimal GUCI is presented.",
    "descriptor": "",
    "authors": [
      "Wei Yan",
      "Sian-Jheng Lin",
      "Yunghsiang S. Han"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2204.07398"
  },
  {
    "id": "arXiv:2204.07403",
    "title": "Deep learning model solves change point detection for multiple change  types",
    "abstract": "A change points detection aims to catch an abrupt disorder in data\ndistribution. Common approaches assume that there are only two fixed\ndistributions for data: one before and another after a change point. Real-world\ndata are richer than this assumption. There can be multiple different\ndistributions before and after a change. We propose an approach that works in\nthe multiple-distributions scenario. Our approach learn representations for\nsemi-structured data suitable for change point detection, while a common\nclassifiers-based approach fails. Moreover, our model is more robust, when\npredicting change points. The datasets used for benchmarking are sequences of\nimages with and without change points in them.",
    "descriptor": "",
    "authors": [
      "Alexander Stepikin",
      "Evgenia Romanenkova",
      "Alexey Zaytsev"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.07403"
  },
  {
    "id": "arXiv:2204.07404",
    "title": "Divide & Conquer Imitation Learning",
    "abstract": "When cast into the Deep Reinforcement Learning framework, many robotics tasks\nrequire solving a long horizon and sparse reward problem, where learning\nalgorithms struggle. In such context, Imitation Learning (IL) can be a powerful\napproach to bootstrap the learning process. However, most IL methods require\nseveral expert demonstrations which can be prohibitively difficult to acquire.\nOnly a handful of IL algorithms have shown efficiency in the context of an\nextreme low expert data regime where a single expert demonstration is\navailable. In this paper, we present a novel algorithm designed to imitate\ncomplex robotic tasks from the states of an expert trajectory. Based on a\nsequential inductive bias, our method divides the complex task into smaller\nskills. The skills are learned into a goal-conditioned policy that is able to\nsolve each skill individually and chain skills to solve the entire task. We\nshow that our method imitates a non-holonomic navigation task and scales to a\ncomplex simulated robotic manipulation task with very high sample efficiency.",
    "descriptor": "",
    "authors": [
      "Alexandre Chenu",
      "Nicolas Perrin-Gilbert",
      "Olivier Sigaud"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2204.07404"
  },
  {
    "id": "arXiv:2204.07406",
    "title": "SSR-HEF: Crowd Counting with Multi-Scale Semantic Refining and Hard  Example Focusing",
    "abstract": "Crowd counting based on density maps is generally regarded as a regression\ntask.Deep learning is used to learn the mapping between image content and crowd\ndensity distribution. Although great success has been achieved, some\npedestrians far away from the camera are difficult to be detected. And the\nnumber of hard examples is often larger. Existing methods with simple Euclidean\ndistance algorithm indiscriminately optimize the hard and easy examples so that\nthe densities of hard examples are usually incorrectly predicted to be lower or\neven zero, which results in large counting errors. To address this problem, we\nare the first to propose the Hard Example Focusing(HEF) algorithm for the\nregression task of crowd counting. The HEF algorithm makes our model rapidly\nfocus on hard examples by attenuating the contribution of easy examples.Then\nhigher importance will be given to the hard examples with wrong estimations.\nMoreover, the scale variations in crowd scenes are large, and the scale\nannotations are labor-intensive and expensive. By proposing a multi-Scale\nSemantic Refining (SSR) strategy, lower layers of our model can break through\nthe limitation of deep learning to capture semantic features of different\nscales to sufficiently deal with the scale variation. We perform extensive\nexperiments on six benchmark datasets to verify the proposed method. Results\nindicate the superiority of our proposed method over the state-of-the-art\nmethods. Moreover, our designed model is smaller and faster.",
    "descriptor": "\nComments: Accepted by IEEE TRANSACTIONS ON INDUSTRIAL INFORMATICS\n",
    "authors": [
      "Jiwei Chen",
      "Kewei Wang",
      "Wen Su",
      "Zengfu Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.07406"
  },
  {
    "id": "arXiv:2204.07408",
    "title": "Towards Fine-grained Causal Reasoning and QA",
    "abstract": "Understanding causality is key to the success of NLP applications, especially\nin high-stakes domains. Causality comes in various perspectives such as enable\nand prevent that, despite their importance, have been largely ignored in the\nliterature. This paper introduces a novel fine-grained causal reasoning dataset\nand presents a series of novel predictive tasks in NLP, such as causality\ndetection, event causality extraction, and Causal QA. Our dataset contains\nhuman annotations of 25K cause-effect event pairs and 24K question-answering\npairs within multi-sentence samples, where each can have multiple causal\nrelationships. Through extensive experiments and analysis, we show that the\ncomplex relations in our dataset bring unique challenges to state-of-the-art\nmethods across all three tasks and highlight potential research opportunities,\nespecially in developing \"causal-thinking\" methods.",
    "descriptor": "",
    "authors": [
      "Linyi Yang",
      "Zhen Wang",
      "Yuxiang Wu",
      "Jie Yang",
      "Yue Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2204.07408"
  },
  {
    "id": "arXiv:2204.07410",
    "title": "Initialisation and Grammar Design in Grammar-Guided Evolutionary  Computation",
    "abstract": "Grammars provide a convenient and powerful mechanism to define the space of\npossible solutions for a range of problems. However, when used in grammatical\nevolution (GE), great care must be taken in the design of a grammar to ensure\nthat the polymorphic nature of the genotype-to-phenotype mapping does not\nimpede search. Additionally, recent work has highlighted the importance of the\ninitialisation method on GE's performance. While recent work has shed light on\nthe matters of initialisation and grammar design with respect to GE, their\nimpact on other methods, such as random search and context-free grammar genetic\nprogramming (CFG-GP), is largely unknown. This paper examines GE, random search\nand CFG-GP under a range of benchmark problems using several different\ninitialisation routines and grammar designs. The results suggest that CFG-GP is\nless sensitive to initialisation and grammar design than both GE and random\nsearch: we also demonstrate that observed cases of poor performance by CFG-GP\nare managed through simple adjustment of tuning parameters. We conclude that\nCFG-GP is a strong base from which to conduct grammar-guided evolutionary\nsearch, and that future work should focus on understanding the parameter space\nof CFG-GP for better application.",
    "descriptor": "",
    "authors": [
      "Grant Dick",
      "Peter A. Whigham"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2204.07410"
  },
  {
    "id": "arXiv:2204.07412",
    "title": "End-to-End Sensitivity-Based Filter Pruning",
    "abstract": "In this paper, we present a novel sensitivity-based filter pruning algorithm\n(SbF-Pruner) to learn the importance scores of filters of each layer\nend-to-end. Our method learns the scores from the filter weights, enabling it\nto account for the correlations between the filters of each layer. Moreover, by\ntraining the pruning scores of all layers simultaneously our method can account\nfor layer interdependencies, which is essential to find a performant sparse\nsub-network. Our proposed method can train and generate a pruned network from\nscratch in a straightforward, one-stage training process without requiring a\npretrained network. Ultimately, we do not need layer-specific hyperparameters\nand pre-defined layer budgets, since SbF-Pruner can implicitly determine the\nappropriate number of channels in each layer. Our experimental results on\ndifferent network architectures suggest that SbF-Pruner outperforms advanced\npruning methods. Notably, on CIFAR-10, without requiring a pretrained baseline\nnetwork, we obtain 1.02% and 1.19% accuracy gain on ResNet56 and ResNet110,\ncompared to the baseline reported for state-of-the-art pruning algorithms. This\nis while SbF-Pruner reduces parameter-count by 52.3% (for ResNet56) and 54%\n(for ResNet101), which is better than the state-of-the-art pruning algorithms\nwith a high margin of 9.5% and 6.6%.",
    "descriptor": "",
    "authors": [
      "Zahra Babaiee",
      "Lucas Liebenwein",
      "Ramin Hasani",
      "Daniela Rus",
      "Radu Grosu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.07412"
  },
  {
    "id": "arXiv:2204.07413",
    "title": "Super Resolution for Turbulent Flows in 2D: Stabilized Physics Informed  Neural Networks",
    "abstract": "We propose a new design of a neural network for solving a zero shot super\nresolution problem for turbulent flows. We embed Luenberger-type observer into\nthe network's architecture to inform the network of the physics of the process,\nand to provide error correction and stabilization mechanisms. In addition, to\ncompensate for decrease of observer's performance due to the presence of\nunknown destabilizing forcing, the network is designed to estimate the\ncontribution of the unknown forcing implicitly from the data over the course of\ntraining. By running a set of numerical experiments, we demonstrate that the\nproposed network does recover unknown forcing from data and is capable of\npredicting turbulent flows in high resolution from low resolution noisy\nobservations.",
    "descriptor": "",
    "authors": [
      "Mykhaylo Zayats",
      "Ma\u0142gorzata J. Zimo\u0144",
      "Kyongmin Yeo",
      "Sergiy Zhuk"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2204.07413"
  },
  {
    "id": "arXiv:2204.07414",
    "title": "SOTVerse: A User-defined Task Space of Single Object Tracking",
    "abstract": "Single object tracking (SOT) research falls into a cycle - trackers perform\nwell on most benchmarks but quickly fail in challenging scenarios, causing\nresearchers to doubt the insufficient data content and take more effort\nconstructing larger datasets with more challenging situations. However,\nisolated experimental environments and limited evaluation methods more\nseriously hinder the SOT research. The former causes existing datasets can not\nbe exploited comprehensively, while the latter neglects challenging factors in\nthe evaluation process. In this article, we systematize the representative\nbenchmarks and form a single object tracking metaverse (SOTVerse) - a\nuser-defined SOT task space to break through the bottleneck. We first propose a\n3E Paradigm to describe tasks by three components (i.e., environment,\nevaluation, and executor). Then, we summarize task characteristics, clarify the\norganization standards, and construct SOTVerse with 12.56 million frames.\nSpecifically, SOTVerse automatically labels challenging factors per frame,\nallowing users to generate user-defined spaces efficiently via construction\nrules. Besides, SOTVerse provides two mechanisms with new indicators and\nsuccessfully evaluates trackers under various subtasks. Consequently, SOTVerse\nfirstly provides a strategy to improve resource utilization in the computer\nvision area, making research more standardized and scientific. The SOTVerse,\ntoolkit, evaluation server, and results are available at\nthis http URL",
    "descriptor": "\nComments: This paper is submitted to IEEE TPAMI\n",
    "authors": [
      "Shiyu Hu",
      "Xin Zhao",
      "Kaiqi Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.07414"
  },
  {
    "id": "arXiv:2204.07415",
    "title": "Universal approximation property of invertible neural networks",
    "abstract": "Invertible neural networks (INNs) are neural network architectures with\ninvertibility by design. Thanks to their invertibility and the tractability of\nJacobian, INNs have various machine learning applications such as probabilistic\nmodeling, generative modeling, and representation learning. However, their\nattractive properties often come at the cost of restricting the layer designs,\nwhich poses a question on their representation power: can we use these models\nto approximate sufficiently diverse functions? To answer this question, we have\ndeveloped a general theoretical framework to investigate the representation\npower of INNs, building on a structure theorem of differential geometry. The\nframework simplifies the approximation problem of diffeomorphisms, which\nenables us to show the universal approximation properties of INNs. We apply the\nframework to two representative classes of INNs, namely Coupling-Flow-based\nINNs (CF-INNs) and Neural Ordinary Differential Equations (NODEs), and\nelucidate their high representation power despite the restrictions on their\narchitectures.",
    "descriptor": "\nComments: This paper extends our previous work of the following two papers: \"Coupling-based invertible neural networks are universal diffeomorphism approximators\" [arXiv:2006.11469] (published as a conference paper in NeurIPS 2020) and \"Universal approximation property of neural ordinary differential equations\" [arXiv:2012.02414] (presented at DiffGeo4DL Workshop in NeurIPS 2020)\n",
    "authors": [
      "Isao Ishikawa",
      "Takeshi Teshima",
      "Koichi Tojo",
      "Kenta Oono",
      "Masahiro Ikeda",
      "Masashi Sugiyama"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2204.07415"
  },
  {
    "id": "arXiv:2204.07417",
    "title": "Safe Reinforcement Learning Using Black-Box Reachability Analysis",
    "abstract": "Reinforcement learning (RL) is capable of sophisticated motion planning and\ncontrol for robots in uncertain environments. However, state-of-the-art deep RL\napproaches typically lack safety guarantees, especially when the robot and\nenvironment models are unknown. To justify widespread deployment, robots must\nrespect safety constraints without sacrificing performance. Thus, we propose a\nBlack-box Reachability-based Safety Layer (BRSL) with three main components:\n(1) data-driven reachability analysis for a black-box robot model, (2) a\ntrajectory rollout planner that predicts future actions and observations using\nan ensemble of neural networks trained online, and (3) a differentiable\npolytope collision check between the reachable set and obstacles that enables\ncorrecting unsafe actions. In simulation, BRSL outperforms other\nstate-of-the-art safe RL methods on a Turtlebot 3, a quadrotor, and a\ntrajectory-tracking point mass with an unsafe set adjacent to the area of\nhighest reward.",
    "descriptor": "",
    "authors": [
      "Mahmoud Selim",
      "Amr Alanwar",
      "Shreyas Kousik",
      "Grace Gao",
      "Marco Pavone",
      "Karl H. Johansson"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2204.07417"
  },
  {
    "id": "arXiv:2204.07420",
    "title": "Deep CardioSound: An Ensembled Deep Learning Model for Heart Sound  MultiLabelling",
    "abstract": "Heart sound diagnosis and classification play an essential role in detecting\ncardiovascular disorders, especially when the remote diagnosis becomes standard\nclinical practice. Most of the current work is designed for single category\nbased heard sound classification tasks. To further extend the landscape of the\nautomatic heart sound diagnosis landscape, this work proposes a deep multilabel\nlearning model that can automatically annotate heart sound recordings with\nlabels from different label groups, including murmur's timing, pitch, grading,\nquality, and shape. Our experiment results show that the proposed method has\nachieved outstanding performance on the holdout data for the multi-labelling\ntask with sensitivity=0.990, specificity=0.999, F1=0.990 at the segments level,\nand an overall accuracy=0.969 at the patient's recording level.",
    "descriptor": "",
    "authors": [
      "Li Guo",
      "Steven Davenport",
      "Yonghong Peng"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2204.07420"
  },
  {
    "id": "arXiv:2204.07421",
    "title": "An interpretable machine learning approach for ferroalloys consumptions",
    "abstract": "This paper is devoted to a practical method for ferroalloys consumption\nmodeling and optimization. We consider the problem of selecting the optimal\nprocess control parameters based on the analysis of historical data from\nsensors. We developed approach, which predicts results of chemical reactions\nand give ferroalloys consumption recommendation. The main features of our\nmethod are easy interpretation and noise resistance. Our approach is based on\nk-means clustering algorithm, decision trees and linear regression. The main\nidea of the method is to identify situations where processes go similarly. For\nthis, we propose using a k-means based dataset clustering algorithm and a\nclassification algorithm to determine the cluster. This algorithm can be also\napplied to various technological processes, in this article, we demonstrate its\napplication in metallurgy. To test the application of the proposed method, we\nused it to optimize ferroalloys consumption in Basic Oxygen Furnace steelmaking\nwhen finishing steel in a ladle furnace. The minimum required element content\nfor a given steel grade was selected as the predictive model's target variable,\nand the required amount of the element to be added to the melt as the optimized\nvariable. Keywords: Clustering, Machine Learning, Linear Regression,\nSteelmaking, Optimization, Gradient Boosting, Artificial Intelligence, Decision\nTrees, Recommendation services",
    "descriptor": "\nComments: 4 pages\n",
    "authors": [
      "Nick Knyazev"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.07421"
  },
  {
    "id": "arXiv:2204.07424",
    "title": "Singular quadratic eigenvalue problems: Linearization and weak condition  numbers",
    "abstract": "The numerical solution of singular eigenvalue problems is complicated by the\nfact that small perturbations of the coefficients may have an arbitrarily bad\neffect on eigenvalue accuracy. However, it has been known for a long time that\nsuch perturbations are exceptional and standard eigenvalue solvers, such as the\nQZ algorithm, tend to yield good accuracy despite the inevitable presence of\nroundoff error. Recently, Lotz and Noferini quantified this phenomenon by\nintroducing the concept of $\\delta$-weak eigenvalue condition numbers. In this\nwork, we consider singular quadratic eigenvalue problems and two popular\nlinearizations. Our results show that a correctly chosen linearization\nincreases $\\delta$-weak eigenvalue condition numbers only marginally,\njustifying the use of these linearizations in numerical solvers also in the\nsingular case. We propose a very simple but often effective algorithm for\ncomputing well-conditioned eigenvalues of a singular quadratic eigenvalue\nproblems by adding small random perturbations to the coefficients. We prove\nthat the eigenvalue condition number is, with high probability, a reliable\ncriterion for detecting and excluding spurious eigenvalues created from the\nsingular part.",
    "descriptor": "",
    "authors": [
      "Daniel Kressner",
      "Ivana \u0160ain Glibi\u0107"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2204.07424"
  },
  {
    "id": "arXiv:2204.07425",
    "title": "Finding Hall blockers by matrix scaling",
    "abstract": "For a given nonnegative matrix $A=(A_{ij})$, the matrix scaling problem asks\nwhether $A$ can be scaled to a doubly stochastic matrix $XAY$ for some positive\ndiagonal matrices $X,Y$. The Sinkhorn algorithm is a simple iterative\nalgorithm, which repeats row-normalization $A_{ij} \\leftarrow\nA_{ij}/\\sum_{j}A_{ij}$ and column-normalization $A_{ij} \\leftarrow\nA_{ij}/\\sum_{i}A_{ij}$ alternatively. By this algorithm, $A$ converges to a\ndoubly stochastic matrix in limit if and only if the bipartite graph associated\nwith $A$ has a perfect matching. This property can decide the existence of a\nperfect matching in a given bipartite graph $G$, which is identified with the\n$0,1$-matrix $A_G$. Linial, Samorodnitsky, and Wigderson showed that a\npolynomial number of the Sinkhorn iterations for $A_G$ decides whether $G$ has\na perfect matching.\nIn this paper, we show an extension of this result: If $G$ has no perfect\nmatching, then a polynomial number of the Sinkhorn iterations identifies a Hall\nblocker -- a certificate of the nonexistence of a perfect matching. Our\nanalysis is based on an interpretation of the Sinkhorn algorithm as alternating\nKL-divergence minimization (Csisz\\'{a}r and Tusn\\'{a}dy 1984, Gietl and Reffel\n2013) and its limiting behavior for a nonscalable matrix (Aas 2014). We also\nrelate the Sinkhorn limit with parametric network flow, principal partition of\npolymatroids, and the Dulmage-Mendelsohn decomposition of a bipartite graph.",
    "descriptor": "",
    "authors": [
      "Koyo Hayashi",
      "Hiroshi Hirai"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Combinatorics (math.CO)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2204.07425"
  },
  {
    "id": "arXiv:2204.07428",
    "title": "Decision-making with E-admissibility given a finite assessment of  choices",
    "abstract": "Given information about which options a decision-maker definitely rejects\nfrom given finite sets of options, we study the implications for\ndecision-making with E-admissibility. This means that from any finite set of\noptions, we reject those options that no probability mass function compatible\nwith the given information gives the highest expected utility. We use the\nmathematical framework of choice functions to specify choices and rejections,\nand specify the available information in the form of conditions on such\nfunctions. We characterise the most conservative extension of the given\ninformation to a choice function that makes choices based on E-admissibility,\nand provide an algorithm that computes this extension by solving linear\nfeasibility problems.",
    "descriptor": "\nComments: 11 pages, 1 figure, extended version of conference paper\n",
    "authors": [
      "Arne Decadt",
      "Alexander Erreygers",
      "Jasper De Bock",
      "Gert de Cooman"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2204.07428"
  },
  {
    "id": "arXiv:2204.07429",
    "title": "Experimentally realized memristive memory augmented neural network",
    "abstract": "Lifelong on-device learning is a key challenge for machine intelligence, and\nthis requires learning from few, often single, samples. Memory augmented neural\nnetwork has been proposed to achieve the goal, but the memory module has to be\nstored in an off-chip memory due to its size. Therefore the practical use has\nbeen heavily limited. Previous works on emerging memory-based implementation\nhave difficulties in scaling up because different modules with various\nstructures are difficult to integrate on the same chip and the small sense\nmargin of the content addressable memory for the memory module heavily limited\nthe degree of mismatch calculation. In this work, we implement the entire\nmemory augmented neural network architecture in a fully integrated memristive\ncrossbar platform and achieve an accuracy that closely matches standard\nsoftware on digital hardware for the Omniglot dataset. The successful\ndemonstration is supported by implementing new functions in crossbars in\naddition to widely reported matrix multiplications. For example, the\nlocality-sensitive hashing operation is implemented in crossbar arrays by\nexploiting the intrinsic stochasticity of memristor devices. Besides, the\ncontent-addressable memory module is realized in crossbars, which also supports\nthe degree of mismatches. Simulations based on experimentally validated models\nshow such an implementation can be efficiently scaled up for one-shot learning\non the Mini-ImageNet dataset. The successful demonstration paves the way for\npractical on-device lifelong learning and opens possibilities for novel\nattention-based algorithms not possible in conventional hardware.",
    "descriptor": "\nComments: 54 pages, 21 figures, 3 tables\n",
    "authors": [
      "Ruibin Mao",
      "Bo Wen",
      "Yahui Zhao",
      "Arman Kazemi",
      "Ann Franchesca Laguna",
      "Michael Neimier",
      "X. Sharon Hu",
      "Xia Sheng",
      "Catherine E. Graves",
      "John Paul Strachan",
      "Can Li"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Hardware Architecture (cs.AR)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2204.07429"
  },
  {
    "id": "arXiv:2204.07430",
    "title": "Stateless and Rule-Based Verification For Compliance Checking  Applications",
    "abstract": "Underlying computational model has an important role in any computation. The\nstate and transition (such as in automata) and rule and value (such as in Lisp\nand logic programming) are two comparable and counterpart computational models.\nBoth of deductive and model checking verification techniques are relying on a\nnotion of state and as a result, their underlying computational models are\nstate dependent. Some verification problems (such as compliance checking by\nwhich an under compliance system is verified against some regulations and\nrules) have not a strong notion of state nor transition. Behalf of it, these\nsystems have a strong notion of value symbols and declarative rules defined on\nthem. SARV (Stateless And Rule-Based Verification) is a verification framework\nthat designed to simplify the overall process of verification for stateless and\nrule-based verification problems (e.g. compliance checking). In this paper, a\nformal logic-based framework for creating intelligent compliance checking\nsystems is presented. We define and introduce this framework, report a case\nstudy and present results of an experiment on it. The case study is about\nprotocol compliance checking for smart cities. Using this solution, a Rescue\nScenario use case and its compliance checking are sketched and modeled. An\nautomation engine for and a compliance solution with SARV are introduced. Based\non 300 data experiments, the SARV-based compliance solution outperforms famous\nmachine learning methods on a 3125-records software quality dataset.",
    "descriptor": "",
    "authors": [
      "Mohammad Reza Besharati",
      "Mohammad Izadi",
      "Ehsaneddin Asgari"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2204.07430"
  },
  {
    "id": "arXiv:2204.07431",
    "title": "The Importance of Landscape Features for Performance Prediction of  Modular CMA-ES Variants",
    "abstract": "Selecting the most suitable algorithm and determining its hyperparameters for\na given optimization problem is a challenging task. Accurately predicting how\nwell a certain algorithm could solve the problem is hence desirable. Recent\nstudies in single-objective numerical optimization show that supervised machine\nlearning methods can predict algorithm performance using landscape features\nextracted from the problem instances.\nExisting approaches typically treat the algorithms as black-boxes, without\nconsideration of their characteristics. To investigate in this work if a\nselection of landscape features that depends on algorithms properties could\nfurther improve regression accuracy, we regard the modular CMA-ES framework and\nestimate how much each landscape feature contributes to the best algorithm\nperformance regression models. Exploratory data analysis performed on this data\nindicate that the set of most relevant features does not depend on the\nconfiguration of individual modules, but the influence that these features have\non regression accuracy does. In addition, we have shown that by using\nclassifiers that take the features relevance on the model accuracy, we are able\nto predict the status of individual modules in the CMA-ES configurations.",
    "descriptor": "",
    "authors": [
      "Ana Kostovska",
      "Diederick Vermetten",
      "Sa\u0161o D\u017eeroski",
      "Carola Doerr",
      "Peter Koro\u0161ec",
      "Tome Eftimov"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.07431"
  },
  {
    "id": "arXiv:2204.07432",
    "title": "ML_LTU at SemEval-2022 Task 4: T5 Towards Identifying Patronizing and  Condescending Language",
    "abstract": "This paper describes the system used by the Machine Learning Group of LTU in\nsubtask 1 of the SemEval-2022 Task 4: Patronizing and Condescending Language\n(PCL) Detection. Our system consists of finetuning a pretrained\nText-to-Text-Transfer Transformer (T5) and innovatively reducing its\nout-of-class predictions. The main contributions of this paper are 1) the\ndescription of the implementation details of the T5 model we used, 2) analysis\nof the successes & struggles of the model in this task, and 3) ablation studies\nbeyond the official submission to ascertain the relative importance of data\nsplit. Our model achieves an F1 score of 0.5452 on the official test set.",
    "descriptor": "\nComments: Accepted at the International Workshop on Semantic Evaluation (2022) co-located with NAACL\n",
    "authors": [
      "Tosin Adewumi",
      "Lama Alkhaled",
      "Hamam Alkhaled",
      "Foteini Liwicki",
      "Marcus Liwicki"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.07432"
  },
  {
    "id": "arXiv:2204.07433",
    "title": "Interacting with Non-Cooperative User: A New Paradigm for Proactive  Dialogue Policy",
    "abstract": "Proactive dialogue system is able to lead the conversation to a goal topic\nand has advantaged potential in bargain, persuasion and negotiation. Current\ncorpus-based learning manner limits its practical application in real-world\nscenarios. To this end, we contribute to advance the study of the proactive\ndialogue policy to a more natural and challenging setting, i.e., interacting\ndynamically with users. Further, we call attention to the non-cooperative user\nbehavior -- the user talks about off-path topics when he/she is not satisfied\nwith the previous topics introduced by the agent. We argue that the targets of\nreaching the goal topic quickly and maintaining a high user satisfaction are\nnot always converge, because the topics close to the goal and the topics user\npreferred may not be the same. Towards this issue, we propose a new solution\nnamed I-Pro that can learn Proactive policy in the Interactive setting.\nSpecifically, we learn the trade-off via a learned goal weight, which consists\nof four factors (dialogue turn, goal completion difficulty, user satisfaction\nestimation, and cooperative degree). The experimental results demonstrate I-Pro\nsignificantly outperforms baselines in terms of effectiveness and\ninterpretability.",
    "descriptor": "\nComments: Accepted to SIGIR 2022\n",
    "authors": [
      "Wenqiang Lei",
      "Yao Zhang",
      "Feifan Song",
      "Hongru Liang",
      "Jiaxin Mao",
      "Jiancheng Lv",
      "Zhenglu Yang",
      "Tat-Seng Chua"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.07433"
  },
  {
    "id": "arXiv:2204.07434",
    "title": "ERGO: Event Relational Graph Transformer for Document-level Event  Causality Identification",
    "abstract": "Document-level Event Causality Identification (DECI) aims to identify causal\nrelations between event pairs in a document. It poses a great challenge of\nacross-sentence reasoning without clear causal indicators. In this paper, we\npropose a novel Event Relational Graph TransfOrmer (ERGO) framework for DECI,\nwhich improves existing state-of-the-art (SOTA) methods upon two aspects.\nFirst, we formulate DECI as a node classification problem by constructing an\nevent relational graph, without the needs of prior knowledge or tools. Second,\nERGO seamlessly integrates event-pair relation classification and global\ninference, which leverages a Relational Graph Transformer (RGT) to capture the\npotential causal chain. Besides, we introduce edge-building strategies and\nadaptive focal loss to deal with the massive false positives caused by common\nspurious correlation. Extensive experiments on two benchmark datasets show that\nERGO significantly outperforms previous SOTA methods (13.1% F1 gains on\naverage). We have conducted extensive quantitative analysis and case studies to\nprovide insights for future research directions (Section 4.8).",
    "descriptor": "",
    "authors": [
      "Meiqi Chen",
      "Yixin Cao",
      "Kunquan Deng",
      "Mukai Li",
      "Kun Wang",
      "Jing Shao",
      "Yan Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.07434"
  },
  {
    "id": "arXiv:2204.07435",
    "title": "Performance and Construction of Polar Codes: The Perspective of Bit  Error Probability",
    "abstract": "Most existing works of polar codes focus on the analysis of block error\nprobability. However, in many scenarios, bit error probability is also\nimportant for evaluating the performance of channel codes. In this paper, we\nestablish a new framework to analyze the bit error probability of polar codes.\nSpecifically, by revisiting the error event of bit-channel, we first introduce\nthe conditional bit error probability as a metric to evaluate the reliability\nof bit-channel for both systematic and non-systematic polar codes. Guided by\nthe concept of polar subcode, we then derive an upper bound on the conditional\nbit error probability of each bit-channel, and accordingly, an upper bound on\nthe bit error probability of polar codes. Based on these, two types of\nconstruction metrics aiming at minimizing the bit error probability of polar\ncodes are proposed, which are of linear computational complexity and explicit\nforms. Simulation results show that the polar codes constructed by the proposed\nmethods can outperform those constructed by the conventional methods.",
    "descriptor": "",
    "authors": [
      "Bolin Wu",
      "Kai Niu",
      "Jincheng Dai"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2204.07435"
  },
  {
    "id": "arXiv:2204.07436",
    "title": "Political Communities on Twitter: Case Study of the 2022 French  Presidential Election",
    "abstract": "With the significant increase in users on social media platforms, a new means\nof political campaigning has appeared. Twitter and Facebook are now notable\ncampaigning tools during elections. Indeed, the candidates and their parties\nnow take to the internet to interact and spread their ideas. In this paper, we\naim to identify political communities formed on Twitter during the 2022 French\npresidential election and analyze each respective community. We create a\nlarge-scale Twitter dataset containing 1.2 million users and 62.6 million\ntweets that mention keywords relevant to the election. We perform community\ndetection on a retweet graph of users and propose an in-depth analysis of the\nstance of each community. Finally, we attempt to detect offensive tweets and\nautomatic bots, comparing across communities in order to gain insight into each\ncandidate's supporter demographics and online campaign strategy.",
    "descriptor": "",
    "authors": [
      "Hadi Abdine",
      "Yanzhu Guo",
      "Virgile Rennard",
      "Michalis Vazirgiannis"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.07436"
  },
  {
    "id": "arXiv:2204.07437",
    "title": "Transfer Learning for Instance Segmentation of Waste Bottles using Mask  R-CNN Algorithm",
    "abstract": "This paper proposes a methodological approach with a transfer learning scheme\nfor plastic waste bottle detection and instance segmentation using the\n\\textit{mask region proposal convolutional neural network} (Mask R-CNN).\nPlastic bottles constitute one of the major pollutants posing a serious threat\nto the environment both in oceans and on land. The automated identification and\nsegregation of bottles can facilitate plastic waste recycling. We prepare a\ncustom-made dataset of 192 bottle images with pixel-by pixel-polygon annotation\nfor the automatic segmentation task. The proposed transfer learning scheme\nmakes use of a Mask R-CNN model pre-trained on the Microsoft COCO dataset. We\npresent a comprehensive scheme for fine-tuning the base pre-trained Mask-RCNN\nmodel on our custom dataset. Our final fine-tuned model has achieved 59.4\n\\textit{mean average precision} (mAP), which corresponds to the MS COCO metric.\nThe results indicate a promising application of deep learning for detecting\nwaste bottles.",
    "descriptor": "",
    "authors": [
      "Punitha Jaikumar",
      "Remy Vandaele",
      "Varun Ojha"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.07437"
  },
  {
    "id": "arXiv:2204.07439",
    "title": "INSTA-BNN: Binary Neural Network with INSTAnce-aware Threshold",
    "abstract": "Binary Neural Networks (BNNs) have emerged as a promising solution for\nreducing the memory footprint and compute costs of deep neural networks. BNNs,\non the other hand, suffer from information loss because binary activations are\nlimited to only two values, resulting in reduced accuracy. To improve the\naccuracy, previous studies have attempted to control the distribution of binary\nactivation by manually shifting the threshold of the activation function or\nmaking the shift amount trainable. During the process, they usually depended on\nstatistical information computed from a batch. We argue that using statistical\ndata from a batch fails to capture the crucial information for each input\ninstance in BNN computations, and the differences between statistical\ninformation computed from each instance need to be considered when determining\nthe binary activation threshold of each instance. Based on the concept, we\npropose the Binary Neural Network with INSTAnce-aware threshold (INSTA-BNN),\nwhich decides the activation threshold value considering the difference between\nstatistical data computed from a batch and each instance. The proposed\nINSTA-BNN outperforms the baseline by 2.5% and 2.3% on the ImageNet\nclassification task with comparable computing cost, achieving 68.0% and 71.7%\ntop-1 accuracy on ResNet-18 and MobileNetV1 based models, respectively.",
    "descriptor": "\nComments: 19 pages, 7 figures\n",
    "authors": [
      "Changhun Lee",
      "Hyungjun Kim",
      "Eunhyeok Park",
      "Jae-Joon Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.07439"
  },
  {
    "id": "arXiv:2204.07441",
    "title": "COTS: Collaborative Two-Stream Vision-Language Pre-Training Model for  Cross-Modal Retrieval",
    "abstract": "Large-scale single-stream pre-training has shown dramatic performance in\nimage-text retrieval. Regrettably, it faces low inference efficiency due to\nheavy attention layers. Recently, two-stream methods like CLIP and ALIGN with\nhigh inference efficiency have also shown promising performance, however, they\nonly consider instance-level alignment between the two streams (thus there is\nstill room for improvement). To overcome these limitations, we propose a novel\nCOllaborative Two-Stream vision-language pretraining model termed COTS for\nimage-text retrieval by enhancing cross-modal interaction. In addition to\ninstance level alignment via momentum contrastive learning, we leverage two\nextra levels of cross-modal interactions in our COTS: (1) Token-level\ninteraction - a masked visionlanguage modeling (MVLM) learning objective is\ndevised without using a cross-stream network module, where variational\nautoencoder is imposed on the visual encoder to generate visual tokens for each\nimage. (2) Task-level interaction - a KL-alignment learning objective is\ndevised between text-to-image and image-to-text retrieval tasks, where the\nprobability distribution per task is computed with the negative queues in\nmomentum contrastive learning. Under a fair comparison setting, our COTS\nachieves the highest performance among all two-stream methods and comparable\nperformance (but with 10,800X faster in inference) w.r.t. the latest\nsingle-stream methods. Importantly, our COTS is also applicable to\ntext-to-video retrieval, yielding new state-ofthe-art on the widely-used\nMSR-VTT dataset.",
    "descriptor": "",
    "authors": [
      "Haoyu Lu",
      "Nanyi Fei",
      "Yuqi Huo",
      "Yizhao Gao",
      "Zhiwu Lu",
      "Ji-Rong Wen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2204.07441"
  },
  {
    "id": "arXiv:2204.07442",
    "title": "Scalable and Real-time Multi-Camera Vehicle Detection,  Re-Identification, and Tracking",
    "abstract": "Multi-camera vehicle tracking is one of the most complicated tasks in\nComputer Vision as it involves distinct tasks including Vehicle Detection,\nTracking, and Re-identification. Despite the challenges, multi-camera vehicle\ntracking has immense potential in transportation applications including speed,\nvolume, origin-destination (O-D), and routing data generation. Several recent\nworks have addressed the multi-camera tracking problem. However, most of the\neffort has gone towards improving accuracy on high-quality benchmark datasets\nwhile disregarding lower camera resolutions, compression artifacts and the\noverwhelming amount of computational power and time needed to carry out this\ntask on its edge and thus making it prohibitive for large-scale and real-time\ndeployment. Therefore, in this work we shed light on practical issues that\nshould be addressed for the design of a multi-camera tracking system to provide\nactionable and timely insights. Moreover, we propose a real-time city-scale\nmulti-camera vehicle tracking system that compares favorably to computationally\nintensive alternatives and handles real-world, low-resolution CCTV instead of\nidealized and curated video streams. To show its effectiveness, in addition to\nintegration into the Regional Integrated Transportation Information System\n(RITIS), we participated in the 2021 NVIDIA AI City multi-camera tracking\nchallenge and our method is ranked among the top five performers on the public\nleaderboard.",
    "descriptor": "",
    "authors": [
      "Pirazh Khorramshahi",
      "Vineet Shenoy",
      "Michael Pack",
      "Rama Chellappa"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.07442"
  },
  {
    "id": "arXiv:2204.07443",
    "title": "Detecting Violence in Video Based on Deep Features Fusion Technique",
    "abstract": "With the rapid growth of surveillance cameras in many public places to\nmon-itor human activities such as in malls, streets, schools and, prisons,\nthere is a strong demand for such systems to detect violence events\nautomatically. Au-tomatic analysis of video to detect violence is significant\nfor law enforce-ment. Moreover, it helps to avoid any social, economic and\nenvironmental damages. Mostly, all systems today require manual human\nsupervisors to de-tect violence scenes in the video which is inefficient and\ninaccurate. in this work, we interest in physical violence that involved two\npersons or more. This work proposed a novel method to detect violence using a\nfusion tech-nique of two significantly different convolutional neural networks\n(CNNs) which are AlexNet and SqueezeNet networks. Each network followed by\nseparate Convolution Long Short Term memory (ConvLSTM) to extract ro-bust and\nricher features from a video in the final hidden state. Then, making a fusion\nof these two obtained states and fed to the max-pooling layer. Final-ly,\nfeatures were classified using a series of fully connected layers and soft-max\nclassifier. The performance of the proposed method is evaluated using three\nstandard benchmark datasets in terms of detection accuracy: Hockey Fight\ndataset, Movie dataset and Violent Flow dataset. The results show an accuracy\nof 97%, 100%, and 96% respectively. A comparison of the results with the state\nof the art techniques revealed the promising capability of the proposed method\nin recognizing violent videos.",
    "descriptor": "\nComments: The IIXth International Workshop on Representation, analysis and recognition of shape and motion FroM Imaging data (RFMI 2019), December 11-13, 2019, Sidi Bou Said, Tunis\n",
    "authors": [
      "Heyam M. Bin Jahlan",
      "Lamiaa A. Elrefaei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.07443"
  },
  {
    "id": "arXiv:2204.07447",
    "title": "Stretching Sentence-pair NLI Models to Reason over Long Documents and  Clusters",
    "abstract": "Natural Language Inference (NLI) has been extensively studied by the NLP\ncommunity as a framework for estimating the semantic relation between sentence\npairs. While early work identified certain biases in NLI models, recent\nadvancements in modeling and datasets demonstrated promising performance. In\nthis work, we further explore the direct zero-shot applicability of NLI models\nto real applications, beyond the sentence-pair setting they were trained on.\nFirst, we analyze the robustness of these models to longer and out-of-domain\ninputs. Then, we develop new aggregation methods to allow operating over full\ndocuments, reaching state-of-the-art performance on the ContractNLI dataset.\nInterestingly, we find NLI scores to provide strong retrieval signals, leading\nto more relevant evidence extractions compared to common similarity-based\nmethods. Finally, we go further and investigate whole document clusters to\nidentify both discrepancies and consensus among sources. In a test case, we\nfind real inconsistencies between Wikipedia pages in different languages about\nthe same topic.",
    "descriptor": "",
    "authors": [
      "Tal Schuster",
      "Sihao Chen",
      "Senaka Buthpitiya",
      "Alex Fabrikant",
      "Donald Metzler"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.07447"
  },
  {
    "id": "arXiv:2204.07449",
    "title": "Semantic-Aware Pretraining for Dense Video Captioning",
    "abstract": "This report describes the details of our approach for the event\ndense-captioning task in ActivityNet Challenge 2021. We present a\nsemantic-aware pretraining method for dense video captioning, which empowers\nthe learned features to recognize high-level semantic concepts. Diverse video\nfeatures of different modalities are fed into an event captioning module to\ngenerate accurate and meaningful sentences. Our final ensemble model achieves a\n10.00 METEOR score on the test set.",
    "descriptor": "\nComments: The 2nd place solution to ActivityNet Event Dense-Captioning Challenge 2021\n",
    "authors": [
      "Teng Wang",
      "Zhu Liu",
      "Feng Zheng",
      "Zhichao Lu",
      "Ran Cheng",
      "Ping Luo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.07449"
  },
  {
    "id": "arXiv:2204.07452",
    "title": "A Framework to capture and reproduce the Absolute State of Jupyter  Notebooks",
    "abstract": "Jupyter Notebooks are an enormously popular tool for creating and narrating\ncomputational research projects. They also have enormous potential for creating\nreproducible scientific research artifacts. Capturing the complete state of a\nnotebook has additional benefits; for instance, the notebook execution may be\nsplit between local and remote resources, where the latter may have more\npowerful processing capabilities or store large or access-limited data. There\nare several challenges for making notebooks fully reproducible when examined in\ndetail. The notebook code must be replicated entirely, and the underlying\nPython runtime environments must be identical. More subtle problems arise in\nreplicating referenced data, external library dependencies, and runtime\nvariable states. This paper presents solutions to these problems using\nJuptyer's standard extension mechanisms to create an archivable system state\nfor a running notebook. We show that the overhead for these additional\nmechanisms, which involve interacting with the underlying Linux kernel, does\nnot introduce substantial execution time overheads, demonstrating the\napproach's feasibility.",
    "descriptor": "\nComments: Accepted at Practice & Experience in Advanced Research Computing (PEARC) 2022\n",
    "authors": [
      "Dimuthu Wannipurage",
      "Suresh Marru",
      "Marlon Pierce"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2204.07452"
  },
  {
    "id": "arXiv:2204.07454",
    "title": "Formalizing $\\varphi$-calculus: a purely object-oriented calculus of  decorated objects",
    "abstract": "Many calculi exist for modelling various features of object-oriented\nlanguages. Many of them are based on $\\lambda$-calculus and focus either on\nstatically typed class-based languages or dynamic prototype-based languages. We\nformalize untyped calculus of decorated objects, informally presented by\nBugayenko, which is defined in terms of objects and relies on decoration as a\nprimary mechanism of object extension. It is not based on $\\lambda$-calculus,\nyet with only four basic syntactic constructions is just as complete. We prove\nthe calculus is confluent (i.e. possesses Church-Rosser property), and\nintroduce an abstract machine for call-by-name evaluation. Finally, we provide\na sound translation to $\\lambda$-calculus with records.",
    "descriptor": "",
    "authors": [
      "Nikolai Kudasov",
      "Violetta Sim"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2204.07454"
  },
  {
    "id": "arXiv:2204.07456",
    "title": "ORCNet: A context-based network to simultaneously segment the ocular  region components",
    "abstract": "Accurate extraction of the Region of Interest is critical for successful\nocular region-based biometrics. In this direction, we propose a new\ncontext-based segmentation approach, entitled Ocular Region Context Network\n(ORCNet), introducing a specific loss function, i.e., he Punish Context Loss\n(PC-Loss). The PC-Loss punishes the segmentation losses of a network by using a\npercentage difference value between the ground truth and the segmented masks.\nWe obtain the percentage difference by taking into account Biederman's semantic\nrelationship concepts, in which we use three contexts (semantic, spatial, and\nscale) to evaluate the relationships of the objects in an image. Our proposal\nachieved promising results in the evaluated scenarios: iris, sclera, and ALL\n(iris + sclera) segmentations, utperforming the literature baseline techniques.\nThe ORCNet with ResNet-152 outperforms the best baseline (EncNet with\nResNet-152) on average by 2.27%, 28.26% and 6.43% in terms of F-Score, Error\nRate and Intersection Over Union, respectively. We also provide (for research\npurposes) 3,191 manually labeled masks for the MICHE-I database, as another\ncontribution of our work.",
    "descriptor": "",
    "authors": [
      "Diego Rafael Lucio",
      "Luiz A. Zanlorensi",
      "Yandre Maldonado e Gomes da Costa",
      "David Menotti"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.07456"
  },
  {
    "id": "arXiv:2204.07459",
    "title": "Qtrade AI at SemEval-2022 Task 11: An Unified Framework for Multilingual  NER Task",
    "abstract": "This paper describes our system, which placed third in the Multilingual Track\n(subtask 11), fourth in the Code-Mixed Track (subtask 12), and seventh in the\nChinese Track (subtask 9) in the SemEval 2022 Task 11: MultiCoNER Multilingual\nComplex Named Entity Recognition. Our system's key contributions are as\nfollows: 1) For multilingual NER tasks, we offer an unified framework with\nwhich one can easily execute single-language or multilingual NER tasks, 2) for\nlow-resource code-mixed NER task, one can easily enhance his or her dataset\nthrough implementing several simple data augmentation methods and 3) for\nChinese tasks, we propose a model that can capture Chinese lexical semantic,\nlexical border, and lexical graph structural information. Finally, our system\nachieves macro-f1 scores of 77.66, 84.35, and 74.00 on subtasks 11, 12, and 9,\nrespectively, during the testing phase.",
    "descriptor": "",
    "authors": [
      "Weichao Gan",
      "Yuanping Lin",
      "Guangbo Yu",
      "Guimin Chen",
      "Qian Ye"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.07459"
  },
  {
    "id": "arXiv:2204.07462",
    "title": "A new family of APN functions from biprojective polynomials",
    "abstract": "In this work, we present a new family of quadratic APN functions constructed\nvia biprojective polynomials. Our family includes one of the two APN families\nintroduced by G\\\"olo\\v{g}lu in 2022. Moreover, we show that for n = 12, from\nour construction, we can obtain APN functions that are CCZ-inequivalent to any\nother known APN function over $\\mathbb{F}_{2^{12}}$.",
    "descriptor": "",
    "authors": [
      "Marco Calderini",
      "Irene Villa"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Number Theory (math.NT)"
    ],
    "url": "https://arxiv.org/abs/2204.07462"
  },
  {
    "id": "arXiv:2204.07464",
    "title": "Improving Pre-trained Language Models with Syntactic Dependency  Prediction Task for Chinese Semantic Error Recognition",
    "abstract": "Existing Chinese text error detection mainly focuses on spelling and simple\ngrammatical errors. These errors have been studied extensively and are\nrelatively simple for humans. On the contrary, Chinese semantic errors are\nunderstudied and more complex that humans cannot easily recognize. The task of\nthis paper is Chinese Semantic Error Recognition (CSER), a binary\nclassification task to determine whether a sentence contains semantic errors.\nThe current research has no effective method to solve this task. In this paper,\nwe inherit the model structure of BERT and design several syntax-related\npre-training tasks so that the model can learn syntactic knowledge. Our\npre-training tasks consider both the directionality of the dependency structure\nand the diversity of the dependency relationship. Due to the lack of a\npublished dataset for CSER, we build a high-quality dataset for CSER for the\nfirst time named Corpus of Chinese Linguistic Semantic Acceptability (CoCLSA).\nThe experimental results on the CoCLSA show that our methods outperform\nuniversal pre-trained models and syntax-infused models.",
    "descriptor": "\nComments: 12 pages, 4 figures\n",
    "authors": [
      "Bo Sun",
      "Baoxin Wang",
      "Wanxiang Che",
      "Dayong Wu",
      "Zhigang Chen",
      "Ting Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.07464"
  },
  {
    "id": "arXiv:2204.07466",
    "title": "Sensitivity of sparse codes to image distortions",
    "abstract": "Sparse coding has been proposed as a theory of visual cortex and as an\nunsupervised algorithm for learning representations. We show empirically with\nthe MNIST dataset that sparse codes can be very sensitive to image distortions,\na behavior that may hinder invariant object recognition. A locally linear\nanalysis suggests that the sensitivity is due to the existence of linear\ncombinations of active dictionary elements with high cancellation. A nearest\nneighbor classifier is shown to perform worse on sparse codes than original\nimages. For a linear classifier with a sufficiently large number of labeled\nexamples, sparse codes are shown to yield higher accuracy than original images,\nbut no higher than a representation computed by a random feedforward net.\nSensitivity to distortions seems to be a basic property of sparse codes, and\none should be aware of this property when applying sparse codes to invariant\nobject recognition.",
    "descriptor": "",
    "authors": [
      "Kyle Luther",
      "H. Sebastian Seung"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.07466"
  },
  {
    "id": "arXiv:2204.07467",
    "title": "Convergence of the Discrete Minimum Energy Path",
    "abstract": "The minimum energy path (MEP) describes the mechanism of reaction, and the\nenergy barrier along the path can be used to calculate the reaction rate in\nthermal systems. The nudged elastic band (NEB) method is one of the most\ncommonly used schemes to compute MEPs numerically. It approximates an MEP by a\ndiscrete set of configuration images, where the discretization size determines\nboth computational cost and accuracy of the simulations. In this paper, we\nconsider a discrete MEP to be a stationary state of the NEB method and prove an\noptimal convergence rate of the discrete MEP with respect to the number of\nimages. Numerical simulations for the transitions of some several proto-typical\nmodel systems are performed to support the theory.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2204.00984\n",
    "authors": [
      "Xuanyu Liu",
      "Huajie Chen",
      "Christoph Ortner"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2204.07467"
  },
  {
    "id": "arXiv:2204.07469",
    "title": "Mixture of Experts for Biomedical Question Answering",
    "abstract": "Biomedical Question Answering (BQA) has attracted increasing attention in\nrecent years due to its promising application prospect. It is a challenging\ntask because the biomedical questions are professional and usually vary widely.\nExisting question answering methods answer all questions with a homogeneous\nmodel, leading to various types of questions competing for the shared\nparameters, which will confuse the model decision for each single type of\nquestions. In this paper, in order to alleviate the parameter competition\nproblem, we propose a Mixture-of-Expert (MoE) based question answering method\ncalled MoEBQA that decouples the computation for different types of questions\nby sparse routing. To be specific, we split a pretrained Transformer model into\nbottom and top blocks. The bottom blocks are shared by all the examples, aiming\nto capture the general features. The top blocks are extended to an MoE version\nthat consists of a series of independent experts, where each example is\nassigned to a few experts according to its underlying question type. MoEBQA\nautomatically learns the routing strategy in an end-to-end manner so that each\nexpert tends to deal with the question types it is expert in. We evaluate\nMoEBQA on three BQA datasets constructed based on real examinations. The\nresults show that our MoE extension significantly boosts the performance of\nquestion answering models and achieves new state-of-the-art performance. In\naddition, we elaborately analyze our MoE modules to reveal how MoEBQA works and\nfind that it can automatically group the questions into human-readable\nclusters.",
    "descriptor": "",
    "authors": [
      "Damai Dai",
      "Wenbin Jiang",
      "Jiyuan Zhang",
      "Weihua Peng",
      "Yajuan Lyu",
      "Zhifang Sui",
      "Baobao Chang",
      "Yong Zhu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.07469"
  },
  {
    "id": "arXiv:2204.07471",
    "title": "The Importance of Credo in Multiagent Learning",
    "abstract": "We propose a model for multi-objective optimization, a credo, for agents in a\nsystem that are configured into multiple groups (i.e., teams). Our model of\ncredo regulates how agents optimize their behavior for the component groups\nthey belong to. We evaluate credo in the context of challenging social dilemmas\nwith reinforcement learning agents. Our results indicate that the interests of\nteammates, or the entire system, are not required to be fully aligned for\nglobally beneficial outcomes. We identify two scenarios without full common\ninterest that achieve high equality and significantly higher mean population\nrewards compared to when the interests of all agents are aligned.",
    "descriptor": "\nComments: 8 pages, 7 figures, Proceedings of the Adaptive and Learning Agents Workshop (ALA 2022) at AAMAS 2022\n",
    "authors": [
      "David Radke",
      "Kate Larson",
      "Tim Brecht"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.07471"
  },
  {
    "id": "arXiv:2204.07475",
    "title": "Kernel similarity matching with Hebbian neural networks",
    "abstract": "Recent works have derived neural networks with online correlation-based\nlearning rules to perform \\textit{kernel similarity matching}. These works\napplied existing linear similarity matching algorithms to nonlinear features\ngenerated with random Fourier methods. In this paper attempt to perform kernel\nsimilarity matching by directly learning the nonlinear features. Our algorithm\nproceeds by deriving and then minimizing an upper bound for the sum of squared\nerrors between output and input kernel similarities. The construction of our\nupper bound leads to online correlation-based learning rules which can be\nimplemented with a 1 layer recurrent neural network. In addition to generating\nhigh-dimensional linearly separable representations, we show that our upper\nbound naturally yields representations which are sparse and selective for\nspecific input patterns. We compare the approximation quality of our method to\nneural random Fourier method and variants of the popular but non-biological\n\"Nystr{\\\"o}m\" method for approximating the kernel matrix. Our method appears to\nbe comparable or better than randomly sampled Nystr{\\\"o}m methods when the\noutputs are relatively low dimensional (although still potentially higher\ndimensional than the inputs) but less faithful when the outputs are very high\ndimensional.",
    "descriptor": "",
    "authors": [
      "Kyle Luther",
      "H. Sebastian Seung"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.07475"
  },
  {
    "id": "arXiv:2204.07476",
    "title": "Guiding Attention using Partial-Order Relationships for Image Captioning",
    "abstract": "The use of attention models for automated image captioning has enabled many\nsystems to produce accurate and meaningful descriptions for images. Over the\nyears, many novel approaches have been proposed to enhance the attention\nprocess using different feature representations. In this paper, we extend this\napproach by creating a guided attention network mechanism, that exploits the\nrelationship between the visual scene and text-descriptions using spatial\nfeatures from the image, high-level information from the topics, and temporal\ncontext from caption generation, which are embedded together in an ordered\nembedding space. A pairwise ranking objective is used for training this\nembedding space which allows similar images, topics and captions in the shared\nsemantic space to maintain a partial order in the visual-semantic hierarchy and\nhence, helps the model to produce more visually accurate captions. The\nexperimental results based on MSCOCO dataset shows the competitiveness of our\napproach, with many state-of-the-art models on various evaluation metrics.",
    "descriptor": "\nComments: Accepted at CVPRW\n",
    "authors": [
      "Murad Popattia",
      "Muhammad Rafi",
      "Rizwan Qureshi",
      "Shah Nawaz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.07476"
  },
  {
    "id": "arXiv:2204.07480",
    "title": "Finite element methods respecting the discrete maximum principle for  convection-diffusion equations",
    "abstract": "Convection-diffusion-reaction equations model the conservation of scalar\nquantities. From the analytic point of view, solution of these equations\nsatisfy under certain conditions maximum principles, which represent physical\nbounds of the solution. That the same bounds are respected by numerical\napproximations of the solution is often of utmost importance in practice. The\nmathematical formulation of this property, which contributes to the physical\nconsistency of a method, is called Discrete Maximum Principle (DMP). In many\napplications, convection dominates diffusion by several orders of magnitude. It\nis well known that standard discretizations typically do not satisfy the DMP in\nthis convection-dominated regime. In fact, in this case, it turns out to be a\nchallenging problem to construct discretizations that, on the one hand, respect\nthe DMP and, on the other hand, compute accurate solutions. This paper presents\na survey on finite element methods, with a main focus on the\nconvection-dominated regime, that satisfy a local or a global DMP. The concepts\nof the underlying numerical analysis are discussed. The survey reveals that for\nthe steady-state problem there are only a few discretizations, all of them\nnonlinear, that at the same time satisfy the DMP and compute reasonably\naccurate solutions, e.g., algebraically stabilized schemes. Moreover, most of\nthese discretizations have been developed in recent years, showing the enormous\nprogress that has been achieved lately. Methods based on algebraic\nstabilization, nonlinear and linear ones, are currently as well the only finite\nelement methods that combine the satisfaction of the global DMP and accurate\nnumerical results for the evolutionary equations in the convection-dominated\nsituation.",
    "descriptor": "\nComments: 77 pages; 7 figures\n",
    "authors": [
      "Gabriel R. Barrenechea",
      "Volker John",
      "Petr Knobloch"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2204.07480"
  },
  {
    "id": "arXiv:2204.07481",
    "title": "Knowledge Equivalence in Digital Twins of Intelligent Systems",
    "abstract": "A digital twin contains up-to-date data-driven models of the physical world\nbeing studied and can use simulation to optimise the physical world. However,\nthe analysis made by the digital twin is valid and reliable only when the model\nis equivalent to the physical world. Maintaining such an equivalent model is\nchallenging, especially when the physical systems being modelled are\nintelligent and autonomous. The paper focuses in particular on digital twin\nmodels of intelligent systems where the systems are knowledge-aware but with\nlimited capability. The digital twin improves the acting of the physical system\nat a meta-level by accumulating more knowledge in the simulated environment.\nThe modelling of such an intelligent physical system requires replicating the\nknowledge-awareness capability in the virtual space. Novel equivalence\nmaintaining techniques are needed, especially in synchronising the knowledge\nbetween the model and the physical system. This paper proposes the notion of\nknowledge equivalence and an equivalence maintaining approach by knowledge\ncomparison and updates. A quantitative analysis of the proposed approach\nconfirms that compared to state equivalence, knowledge equivalence maintenance\ncan tolerate deviation thus reducing unnecessary updates and achieve more\nPareto efficient solutions for the trade-off between update overhead and\nsimulation reliability.",
    "descriptor": "\nComments: 27 pages, 16 figures. Under review\n",
    "authors": [
      "Nan Zhang",
      "Rami Bahsoon",
      "Nikos Tziritas",
      "Georgios Theodoropoulos"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2204.07481"
  },
  {
    "id": "arXiv:2204.07482",
    "title": "Towards PAC Multi-Object Detection and Tracking",
    "abstract": "Accurately detecting and tracking multi-objects is important for\nsafety-critical applications such as autonomous navigation. However, it remains\nchallenging to provide guarantees on the performance of state-of-the-art\ntechniques based on deep learning. We consider a strategy known as conformal\nprediction, which predicts sets of labels instead of a single label; in the\nclassification and regression settings, these algorithms can guarantee that the\ntrue label lies within the prediction set with high probability. Building on\nthese ideas, we propose multi-object detection and tracking algorithms that\ncome with probably approximately correct (PAC) guarantees. They do so by\nconstructing both a prediction set around each object detection as well as\naround the set of edge transitions; given an object, the detection prediction\nset contains its true bounding box with high probability, and the edge\nprediction set contains its true transition across frames with high\nprobability. We empirically demonstrate that our method can detect and track\nobjects with PAC guarantees on the COCO and MOT-17 datasets.",
    "descriptor": "\nComments: 15 pages, 4 figures, 2 tables\n",
    "authors": [
      "Shuo Li",
      "Sangdon Park",
      "Xiayan Ji",
      "Insup Lee",
      "Osbert Bastani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.07482"
  },
  {
    "id": "arXiv:2204.07483",
    "title": "Polling Latent Opinions: A Method for Computational Sociolinguistics  Using Transformer Language Models",
    "abstract": "Text analysis of social media for sentiment, topic analysis, and other\nanalysis depends initially on the selection of keywords and phrases that will\nbe used to create the research corpora. However, keywords that researchers\nchoose may occur infrequently, leading to errors that arise from using small\nsamples. In this paper, we use the capacity for memorization, interpolation,\nand extrapolation of Transformer Language Models such as the GPT series to\nlearn the linguistic behaviors of a subgroup within larger corpora of Yelp\nreviews. We then use prompt-based queries to generate synthetic text that can\nbe analyzed to produce insights into specific opinions held by the populations\nthat the models were trained on. Once learned, more specific sentiment queries\ncan be made of the model with high levels of accuracy when compared to\ntraditional keyword searches. We show that even in cases where a specific\nkeyphrase is limited or not present at all in the training corpora, the GPT is\nable to accurately generate large volumes of text that have the correct\nsentiment.",
    "descriptor": "\nComments: 10 pages, 9 figures, 7 tables\n",
    "authors": [
      "Philip Feldman. Aaron Dant",
      "James R. Foulds",
      "Shemei Pan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2204.07483"
  },
  {
    "id": "arXiv:2204.07485",
    "title": "Big-means: Less is More for K-means Clustering",
    "abstract": "K-means clustering plays a vital role in data mining. However, its\nperformance drastically drops when applied to huge amounts of data. We propose\na new heuristic that is built on the basis of regular K-means for faster and\nmore accurate big data clustering using the \"less is more\" and MSSC\ndecomposition approaches. The main advantage of the proposed algorithm is that\nit naturally turns the K-means local search into global one through the process\nof decomposition of the MSSC problem. On one hand, decomposition of the MSSC\nproblem into smaller subproblems reduces the computational complexity and\nallows for their parallel processing. On the other hand, the MSSC decomposition\nprovides a new method for the natural data-driven shaking of the incumbent\nsolution while introducing a new neighborhood structure for the solution of the\nMSSC problem. This leads to a new heuristic that improves K-means in big data\nconditions. The scalability of the algorithm to big data can be easily adjusted\nby choosing the appropriate number of subproblems and their size. The proposed\nalgorithm is both scalable and accurate. In our experiments it outperforms all\nrecent state-of-the-art algorithms for the MSSC in terms of time as well as the\nsolution quality.",
    "descriptor": "",
    "authors": [
      "Rustam Mussabayev",
      "Nenad Mladenovic",
      "Bassem Jarboui",
      "Ravil Mussabayev"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.07485"
  },
  {
    "id": "arXiv:2204.07486",
    "title": "Patch-wise Contrastive Style Learning for Instagram Filter Removal",
    "abstract": "Image-level corruptions and perturbations degrade the performance of CNNs on\ndifferent downstream vision tasks. Social media filters are one of the most\ncommon resources of various corruptions and perturbations for real-world visual\nanalysis applications. The negative effects of these distractive factors can be\nalleviated by recovering the original images with their pure style for the\ninference of the downstream vision tasks. Assuming these filters substantially\ninject a piece of additional style information to the social media images, we\ncan formulate the problem of recovering the original versions as a reverse\nstyle transfer problem. We introduce Contrastive Instagram Filter Removal\nNetwork (CIFR), which enhances this idea for Instagram filter removal by\nemploying a novel multi-layer patch-wise contrastive style learning mechanism.\nExperiments show our proposed strategy produces better qualitative and\nquantitative results than the previous studies. Moreover, we present the\nresults of our additional experiments for proposed architecture within\ndifferent settings. Finally, we present the inference outputs and quantitative\ncomparison of filtered and recovered images on localization and segmentation\ntasks to encourage the main motivation for this problem.",
    "descriptor": "\nComments: Accepted to NTIRE: New Trends in Image Restoration and Enhancement workshop and challenges at CVPR 2022\n",
    "authors": [
      "Furkan K\u0131nl\u0131",
      "Bar\u0131\u015f \u00d6zcan",
      "Furkan K\u0131ra\u00e7"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.07486"
  },
  {
    "id": "arXiv:2204.07491",
    "title": "Distributed Reconstruction of Noisy Pooled Data",
    "abstract": "In the pooled data problem we are given a set of $n$ agents, each of which\nholds a hidden state bit, either $0$ or $1$. A querying procedure returns for a\nquery set the sum of the states of the queried agents. The goal is to\nreconstruct the states using as few queries as possible. In this paper we\nconsider two noise models for the pooled data problem. In the noisy channel\nmodel, the result for each agent flips with a certain probability. In the noisy\nquery model, each query result is subject to random Gaussian noise. Our results\nare twofold. First, we present and analyze for both error models a simple and\nefficient distributed algorithm that reconstructs the initial states in a\ngreedy fashion. Our novel analysis pins down the range of error probabilities\nand distributions for which our algorithm reconstructs the exact initial states\nwith high probability. Secondly, we present simulation results of our algorithm\nand compare its performance with approximate message passing (AMP) algorithms\nthat are conjectured to be optimal in a number of related problems.",
    "descriptor": "\nComments: Accepted at 42nd IEEE International Conference on Distributed Computing Systems (ICDCS)\n",
    "authors": [
      "Max Hahn-Klimroth",
      "Dominik Kaaser"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Discrete Mathematics (cs.DM)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2204.07491"
  },
  {
    "id": "arXiv:2204.07496",
    "title": "Improving Passage Retrieval with Zero-Shot Question Generation",
    "abstract": "We propose a simple and effective re-ranking method for improving passage\nretrieval in open question answering. The re-ranker re-scores retrieved\npassages with a zero-shot question generation model, which uses a pre-trained\nlanguage model to compute the probability of the input question conditioned on\na retrieved passage. This approach can be applied on top of any retrieval\nmethod (e.g. neural or keyword-based), does not require any domain- or\ntask-specific training (and therefore is expected to generalize better to data\ndistribution shifts), and provides rich cross-attention between query and\npassage (i.e. it must explain every token in the question). When evaluated on a\nnumber of open-domain retrieval datasets, our re-ranker improves strong\nunsupervised retrieval models by 6%-18% absolute and strong supervised models\nby up to 12% in terms of top-20 passage retrieval accuracy. We also obtain new\nstate-of-the-art results on full open-domain question answering by simply\nadding the new re-ranker to existing models with no further changes.",
    "descriptor": "",
    "authors": [
      "Devendra Singh Sachan",
      "Mike Lewis",
      "Mandar Joshi",
      "Armen Aghajanyan",
      "Wen-tau Yih",
      "Joelle Pineau",
      "Luke Zettlemoyer"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2204.07496"
  },
  {
    "id": "arXiv:2204.07501",
    "title": "Evaluating few shot and Contrastive learning Methods for Code Clone  Detection",
    "abstract": "Context: Code Clone Detection (CCD) is a software engineering task that is\nused for plagiarism detection, code search, and code comprehension. Recently,\ndeep learning-based models have achieved an F1 score (a metric used to assess\nclassifiers) of $\\sim$95\\% on the CodeXGLUE benchmark. These models require\nmany training data, mainly fine-tuned on Java or C++ datasets. However, no\nprevious study evaluates the generalizability of these models where a limited\namount of annotated data is available.\nObjective: The main objective of this research is to assess the ability of\nthe CCD models as well as few shot learning algorithms for unseen programming\nproblems and new languages (i.e., the model is not trained on these\nproblems/languages).\nMethod: We assess the generalizability of the state of the art models for CCD\nin few shot settings (i.e., only a few samples are available for fine-tuning)\nby setting three scenarios: i) unseen problems, ii) unseen languages, iii)\ncombination of new languages and new problems. We choose three datasets of\nBigCloneBench, POJ-104, and CodeNet and Java, C++, and Ruby languages. Then, we\nemploy Model Agnostic Meta-learning (MAML), where the model learns a\nmeta-learner capable of extracting transferable knowledge from the train set;\nso that the model can be fine-tuned using a few samples. Finally, we combine\ncontrastive learning with MAML to further study whether it can improve the\nresults of MAML.",
    "descriptor": "",
    "authors": [
      "Mohamad Khajezade",
      "Fatemeh Hendijani Fard",
      "Mohamed S. Shehata"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2204.07501"
  },
  {
    "id": "arXiv:2204.07503",
    "title": "Cryogenic Neuromorphic Hardware",
    "abstract": "The revolution in artificial intelligence (AI) brings up an enormous storage\nand data processing requirement. Large power consumption and hardware overhead\nhave become the main challenges for building next-generation AI hardware.\nTherefore, it is imperative to look for a new architecture capable of\ncircumventing these bottlenecks of conventional von Neumann architecture. Since\nthe human brain is the most compact and energy-efficient intelligent device\nknown, it was intuitive to attempt to build an architecture that could mimic\nour brain, and so the chase for neuromorphic computing began. While relentless\nresearch has been underway for years to minimize the power consumption in\nneuromorphic hardware, we are still a long way off from reaching the energy\nefficiency of the human brain. Besides, design complexity, process variation,\netc. hinder the large-scale implementation of current neuromorphic platforms.\nRecently, the concept of implementing neuromorphic computing systems in\ncryogenic temperature has garnered immense attention. Several cryogenic devices\ncan be engineered to work as neuromorphic primitives with ultra-low demand for\npower. Cryogenic electronics has therefore become a promising exploratory\nplatform for an energy-efficient and bio-realistic neuromorphic system. Here we\nprovide a comprehensive overview of the reported cryogenic neuromorphic\nhardware. We carefully classify the existing cryogenic neuromorphic hardware\ninto different categories and draw a comparative analysis based on several\nperformance metrics. Finally, we explore the future research prospects to\ncircumvent the challenges associated with the current technologies.",
    "descriptor": "",
    "authors": [
      "Md Mazharul Islam",
      "Shamiul Alam",
      "Md Shafayat Hossain",
      "Kaushik Roy",
      "Ahmedullah Aziz"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2204.07503"
  },
  {
    "id": "arXiv:2204.07504",
    "title": "Systematic review of development literature from Latin America between  2010- 2021",
    "abstract": "The purpose of this systematic review is to identify and describe the state\nof development literature published in Latin America, in Spanish and English,\nsince 2010. For this, we carried out a topographic review of 44 articles\navailable in the most important bibliographic indexes of Latin America,\npublished in journals of diverse disciplines. Our analysis focused on analyzing\nthe nature and composition of literature, finding a large proportion of\narticles coming from Mexico and Colombia, as well as specialized in the\neconomic discipline. The most relevant articles reviewed show methodological\nand thematic diversity, with special attention to the problem of growth in\nLatin American development. An important limitation of this review is the\nexclusion of articles published in Portuguese, as well as non-indexed\nliterature (such as theses and dissertations). This leads to various\nrecommendations for future reviews of the development literature produced in\nLatin America.",
    "descriptor": "\nComments: Working paper, in Spanish language\n",
    "authors": [
      "Pedro Alfonso de la Puente",
      "Juan Jos\u00e9 Berdugo Cepeda",
      "Mar\u00eda Jos\u00e9 P\u00e9rez Pacheco"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2204.07504"
  },
  {
    "id": "arXiv:2204.07513",
    "title": "Synthesizing Informative Training Samples with GAN",
    "abstract": "Remarkable progress has been achieved in synthesizing photo-realistic images\nwith generative adversarial neural networks (GANs). Recently, GANs are utilized\nas the training sample generator when obtaining or storing real training data\nis expensive even infeasible. However, traditional GANs generated images are\nnot as informative as the real training samples when being used to train deep\nneural networks. In this paper, we propose a novel method to synthesize\nInformative Training samples with GAN (IT-GAN). Specifically, we freeze a\npre-trained GAN model and learn the informative latent vectors that corresponds\nto informative training samples. The synthesized images are required to\npreserve information for training deep neural networks rather than visual\nreality or fidelity. Experiments verify that the deep neural networks can learn\nfaster and achieve better performance when being trained with our IT-GAN\ngenerated images. We also show that our method is a promising solution to\ndataset condensation problem.",
    "descriptor": "",
    "authors": [
      "Bo Zhao",
      "Hakan Bilen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.07513"
  },
  {
    "id": "arXiv:2204.07518",
    "title": "Random Access in Distributed Source Coding",
    "abstract": "The lossless compression of a single source $X^n$ was recently shown to be\nachievable with a notion of strong locality; any $X_i$ can be decoded from a\n{\\emph{constant}} number of compressed bits, with a vanishing in $n$\nprobability of error. In contrast with the single source setup, we show that\nfor two separately encoded sources $(X^n,Y^n)$, lossless compression and strong\nlocality is generally not possible. More precisely, we show that for the class\nof \"confusable\" sources strong locality cannot be achieved whenever one of the\nsources is compressed below its entropy. In this case, irrespectively of $n$,\nthe probability of error of decoding any $(X_i,Y_i)$ is lower bounded by\n$2^{-O(d_{\\mathrm{loc}})}$, where $d_{\\mathrm{loc}}$ denotes the number of\ncompressed bits accessed by the local decoder. Conversely, if the source is not\nconfusable, strong locality is possible even if one of the sources is\ncompressed below its entropy. Results extend to any number of sources.",
    "descriptor": "\nComments: 13 pages\n",
    "authors": [
      "Shashank Vatedka",
      "Venkat Chandar",
      "Aslan Tchamkerten"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2204.07518"
  },
  {
    "id": "arXiv:2204.07519",
    "title": "An Introductory Review of Spiking Neural Network and Artificial Neural  Network: From Biological Intelligence to Artificial Intelligence",
    "abstract": "Recently, stemming from the rapid development of artificial intelligence,\nwhich has gained expansive success in pattern recognition, robotics, and\nbioinformatics, neuroscience is also gaining tremendous progress. A kind of\nspiking neural network with biological interpretability is gradually receiving\nwide attention, and this kind of neural network is also regarded as one of the\ndirections toward general artificial intelligence. This review introduces the\nfollowing sections, the biological background of spiking neurons and the\ntheoretical basis, different neuronal models, the connectivity of neural\ncircuits, the mainstream neural network learning mechanisms and network\narchitectures, etc. This review hopes to attract different researchers and\nadvance the development of brain-inspired intelligence and artificial\nintelligence.",
    "descriptor": "\nComments: 12 pages, 24 figures\n",
    "authors": [
      "Shengjie Zheng",
      "Lang Qian",
      "Pingsheng Li",
      "Chenggang He",
      "Xiaoqin Qin",
      "Xiaojian Li"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.07519"
  },
  {
    "id": "arXiv:2204.07524",
    "title": "Neural Structured Prediction for Inductive Node Classification",
    "abstract": "This paper studies node classification in the inductive setting, i.e., aiming\nto learn a model on labeled training graphs and generalize it to infer node\nlabels on unlabeled test graphs. This problem has been extensively studied with\ngraph neural networks (GNNs) by learning effective node representations, as\nwell as traditional structured prediction methods for modeling the structured\noutput of node labels, e.g., conditional random fields (CRFs). In this paper,\nwe present a new approach called the Structured Proxy Network (SPN), which\ncombines the advantages of both worlds. SPN defines flexible potential\nfunctions of CRFs with GNNs. However, learning such a model is nontrivial as it\ninvolves optimizing a maximin game with high-cost inference. Inspired by the\nunderlying connection between joint and marginal distributions defined by\nMarkov networks, we propose to solve an approximate version of the optimization\nproblem as a proxy, which yields a near-optimal solution, making learning more\nefficient. Extensive experiments on two settings show that our approach\noutperforms many competitive baselines.",
    "descriptor": "\nComments: iclr 2022\n",
    "authors": [
      "Meng Qu",
      "Huiyu Cai",
      "Jian Tang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.07524"
  },
  {
    "id": "arXiv:2204.07531",
    "title": "Understanding Game-Playing Agents with Natural Language Annotations",
    "abstract": "We present a new dataset containing 10K human-annotated games of Go and show\nhow these natural language annotations can be used as a tool for model\ninterpretability. Given a board state and its associated comment, our approach\nuses linear probing to predict mentions of domain-specific terms (e.g., ko,\natari) from the intermediate state representations of game-playing agents like\nAlphaGo Zero. We find these game concepts are nontrivially encoded in two\ndistinct policy networks, one trained via imitation learning and another\ntrained via reinforcement learning. Furthermore, mentions of domain-specific\nterms are most easily predicted from the later layers of both models,\nsuggesting that these policy networks encode high-level abstractions similar to\nthose used in the natural language annotations.",
    "descriptor": "",
    "authors": [
      "Nicholas Tomlin",
      "Andre He",
      "Dan Klein"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.07531"
  },
  {
    "id": "arXiv:2204.07537",
    "title": "Unconditional Image-Text Pair Generation with Multimodal Cross Quantizer",
    "abstract": "Though deep generative models have gained a lot of attention, most of the\nexisting works are designed for the unimodal generation task. In this paper, we\nexplore a new method for unconditional image-text pair generation. We propose\nMXQ-VAE, a vector quantization method for multimodal image-text representation.\nMXQ-VAE accepts a paired image and text as input, and learns a joint quantized\nrepresentation space, so that the image-text pair can be converted to a\nsequence of unified indices. Then we can use autoregressive generative models\nto model the joint image-text representation, and even perform unconditional\nimage-text pair generation. Extensive experimental results demonstrate that our\napproach effectively generates semantically consistent image-text pair and also\nenhances meaningful alignment between image and text.",
    "descriptor": "\nComments: ICLR 2022 workshop on Deep Generative Models for Highly Structured Data\n",
    "authors": [
      "Hyungyung Lee",
      "Sungjin Park",
      "Edward Choi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.07537"
  },
  {
    "id": "arXiv:2204.07539",
    "title": "Stability and Robustness of a Hybrid Control Law for the Half-bridge  Inverter",
    "abstract": "Hybrid systems combine both discrete and continuous state dynamics. Power\nelectronic inverters are inherently hybrid systems: they are controlled via\ndiscrete-valued switching inputs which determine the evolution of the\ncontinuous-valued current and voltage state dynamics.\nHybrid systems analysis could prove increasingly useful as large numbers of\nrenewable energy sources are incorporated to the grid with inverters as their\ninterface. In this work, we explore a hybrid systems approach for the stability\nanalysis of power and power electronic systems. We provide an analytical proof\nshowing that the use of a hybrid model for the half-bridge inverter allows the\nderivation of a control law that drives the system states to desired sinusoidal\nvoltage and current references. We derive an analytical expression for a global\nLyapunov function for the dynamical system in terms of the system parameters,\nwhich proves uniform, global, and asymptotic stability of the origin in error\ncoordinates. Moreover, we demonstrate robustness to parameter changes through\nthis Lyapunov function. We validate these results via simulation.\nFinally, we show empirically the incorporation of droop control with this\nhybrid systems approach. In the low-inertia grid community, the juxtaposition\nof droop control with the hybrid switching control can be considered a\ngrid-forming control strategy using a switched inverter model.",
    "descriptor": "",
    "authors": [
      "Gabriel E. Col\u00f3n-Reyes",
      "Kaylene C. Stocking",
      "Duncan S. Callaway",
      "Claire J. Tomlin"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2204.07539"
  },
  {
    "id": "arXiv:2204.07541",
    "title": "Selecting Continuous Life-Like Cellular Automata for Halting  Unpredictability: Evolving for Abiogenesis",
    "abstract": "Substantial efforts have been applied to engineer CA with desired emergent\nproperties, such as supporting gliders. Recent work in continuous CA has\ngenerated a wide variety of compelling bioreminescent patterns, and the\nexpansion of CA research into continuous numbers, multiple channels, and higher\ndimensions complicates their study. In this work we devise a strategy for\nevolving CA and CA patterns in two steps, based on the simple idea that CA are\nlikely to be complex and computationally capable if they support patterns that\ngrow indefinitely as well as patterns that vanish completely, and are difficult\nto predict the difference in advance. The second part of our strategy evolves\npatterns by selecting for mobility and conservation of mean cell value. We\nvalidate our pattern evolution method by re-discovering gliders in 17 of 17\nLenia CA, and also report 5 new evolved CA that support evolved glider\npatterns, differing from previously reported Lenia patterns. The CA reported\nhere share neighborhood kernels with previously described Lenia CA, but exhibit\na wider range of typical dynamics than their Lenia counterparts. Code for\nevolving continuous CA is made available under an MIT License.",
    "descriptor": "\nComments: Accepted to GECCO 2022\n",
    "authors": [
      "Q. Tyrell Davis",
      "Josh Bongard"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)",
      "Cellular Automata and Lattice Gases (nlin.CG)"
    ],
    "url": "https://arxiv.org/abs/2204.07541"
  },
  {
    "id": "arXiv:2204.07543",
    "title": "CryoRL: Reinforcement Learning Enables Efficient Cryo-EM Data Collection",
    "abstract": "Single-particle cryo-electron microscopy (cryo-EM) has become one of the\nmainstream structural biology techniques because of its ability to determine\nhigh-resolution structures of dynamic bio-molecules. However, cryo-EM data\nacquisition remains expensive and labor-intensive, requiring substantial\nexpertise. Structural biologists need a more efficient and objective method to\ncollect the best data in a limited time frame. We formulate the cryo-EM data\ncollection task as an optimization problem in this work. The goal is to\nmaximize the total number of good images taken within a specified period. We\nshow that reinforcement learning offers an effective way to plan cryo-EM data\ncollection, successfully navigating heterogenous cryo-EM grids. The approach we\ndeveloped, cryoRL, demonstrates better performance than average users for data\ncollection under similar settings.",
    "descriptor": "",
    "authors": [
      "Quanfu Fan",
      "Yilai Li",
      "Yuguang Yao",
      "John Cohn",
      "Sijia Liu",
      "Seychelle M. Vos",
      "Michael A. Cianfrocco"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2204.07543"
  },
  {
    "id": "arXiv:2204.07546",
    "title": "Semi-supervised atmospheric component learning in low-light image  problem",
    "abstract": "Ambient lighting conditions play a crucial role in determining the perceptual\nquality of images from photographic devices. In general, inadequate\ntransmission light and undesired atmospheric conditions jointly degrade the\nimage quality. If we know the desired ambient factors associated with the given\nlow-light image, we can recover the enhanced image easily \\cite{b1}. Typical\ndeep networks perform enhancement mappings without investigating the light\ndistribution and color formulation properties. This leads to a lack of image\ninstance-adaptive performance in practice. On the other hand, physical\nmodel-driven schemes suffer from the need for inherent decompositions and\nmultiple objective minimizations. Moreover, the above approaches are rarely\ndata efficient or free of postprediction tuning. Influenced by the above\nissues, this study presents a semisupervised training method using no-reference\nimage quality metrics for low-light image restoration. We incorporate the\nclassical haze distribution model \\cite{b2} to explore the physical properties\nof the given image in order to learn the effect of atmospheric components and\nminimize a single objective for restoration. We validate the performance of our\nnetwork for six widely used low-light datasets. The experiments show that the\nproposed study achieves state-of-the-art or comparable performance.",
    "descriptor": "",
    "authors": [
      "Masud An Nur Islam Fahim",
      "Nazmus Saqib",
      "Jung Ho Yub"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.07546"
  },
  {
    "id": "arXiv:2204.07548",
    "title": "Learning Multi-View Aggregation In the Wild for Large-Scale 3D Semantic  Segmentation",
    "abstract": "Recent works on 3D semantic segmentation propose to exploit the synergy\nbetween images and point clouds by processing each modality with a dedicated\nnetwork and projecting learned 2D features onto 3D points. Merging large-scale\npoint clouds and images raises several challenges, such as constructing a\nmapping between points and pixels, and aggregating features between multiple\nviews. Current methods require mesh reconstruction or specialized sensors to\nrecover occlusions, and use heuristics to select and aggregate available\nimages. In contrast, we propose an end-to-end trainable multi-view aggregation\nmodel leveraging the viewing conditions of 3D points to merge features from\nimages taken at arbitrary positions. Our method can combine standard 2D and 3D\nnetworks and outperforms both 3D models operating on colorized point clouds and\nhybrid 2D/3D networks without requiring colorization, meshing, or true depth\nmaps. We set a new state-of-the-art for large-scale indoor/outdoor semantic\nsegmentation on S3DIS (74.7 mIoU 6-Fold) and on KITTI-360 (58.3 mIoU). Our full\npipeline is accessible at https://github.com/drprojects/DeepViewAgg, and only\nrequires raw 3D scans and a set of images and poses.",
    "descriptor": "\nComments: Accepted to CVPR 2022 with an Oral presentation; camera ready version. 17 pages, 11 figures. Code and data available at this https URL\n",
    "authors": [
      "Damien Robert",
      "Bruno Vallet",
      "Loic Landrieu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.07548"
  },
  {
    "id": "arXiv:2204.07549",
    "title": "Human Judgement as a Compass to Navigate Automatic Metrics for Formality  Transfer",
    "abstract": "Although text style transfer has witnessed rapid development in recent years,\nthere is as yet no established standard for evaluation, which is performed\nusing several automatic metrics, lacking the possibility of always resorting to\nhuman judgement. We focus on the task of formality transfer, and on the three\naspects that are usually evaluated: style strength, content preservation, and\nfluency. To cast light on how such aspects are assessed by common and new\nmetrics, we run a human-based evaluation and perform a rich correlation\nanalysis. We are then able to offer some recommendations on the use of such\nmetrics in formality transfer, also with an eye to their generalisability (or\nnot) to related tasks.",
    "descriptor": "\nComments: Accepted to HumEval 2022\n",
    "authors": [
      "Huiyuan Lai",
      "Jiali Mao",
      "Antonio Toral",
      "Malvina Nissim"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.07549"
  },
  {
    "id": "arXiv:2204.07551",
    "title": "Summarization with Graphical Elements",
    "abstract": "Automatic text summarization has experienced substantial progress in recent\nyears. With this progress, the question has arisen whether the types of\nsummaries that are typically generated by automatic summarization models align\nwith users' needs. Ter Hoeve et al (2020) answer this question negatively.\nAmongst others, they recommend focusing on generating summaries with more\ngraphical elements. This is in line with what we know from the\npsycholinguistics literature about how humans process text. Motivated from\nthese two angles, we propose a new task: summarization with graphical elements,\nand we verify that these summaries are helpful for a critical mass of people.\nWe collect a high quality human labeled dataset to support research into the\ntask. We present a number of baseline methods that show that the task is\ninteresting and challenging. Hence, with this work we hope to inspire a new\nline of research within the automatic summarization community.",
    "descriptor": "",
    "authors": [
      "Maartje ter Hoeve",
      "Julia Kiseleva",
      "Maarten de Rijke"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.07551"
  },
  {
    "id": "arXiv:2204.07553",
    "title": "Improving Rare Word Recognition with LM-aware MWER Training",
    "abstract": "Language models (LMs) significantly improve the recognition accuracy of\nend-to-end (E2E) models on words rarely seen during training, when used in\neither the shallow fusion or the rescoring setups. In this work, we introduce\nLMs in the learning of hybrid autoregressive transducer (HAT) models in the\ndiscriminative training framework, to mitigate the training versus inference\ngap regarding the use of LMs. For the shallow fusion setup, we use LMs during\nboth hypotheses generation and loss computation, and the LM-aware MWER-trained\nmodel achieves 10\\% relative improvement over the model trained with standard\nMWER on voice search test sets containing rare words. For the rescoring setup,\nwe learn a small neural module to generate per-token fusion weights in a\ndata-dependent manner. This model achieves the same rescoring WER as regular\nMWER-trained model, but without the need for sweeping fusion weights.",
    "descriptor": "\nComments: In submission to INTERSPEECH 2022\n",
    "authors": [
      "Weiran Wang",
      "Tongzhou Chen",
      "Tara N. Sainath",
      "Ehsan Variani",
      "Rohit Prabhavalkar",
      "Ronny Huang",
      "Bhuvana Ramabhadran",
      "Neeraj Gaur",
      "Sepand Mavandadi",
      "Cal Peyser",
      "Trevor Strohman",
      "Yanzhang He",
      "David Rybach"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2204.07553"
  },
  {
    "id": "arXiv:2204.07554",
    "title": "Efficient Architecture Search for Diverse Tasks",
    "abstract": "While neural architecture search (NAS) has enabled automated machine learning\n(AutoML) for well-researched areas, its application to tasks beyond computer\nvision is still under-explored. As less-studied domains are precisely those\nwhere we expect AutoML to have the greatest impact, in this work we study NAS\nfor efficiently solving diverse problems. Seeking an approach that is fast,\nsimple, and broadly applicable, we fix a standard convolutional network (CNN)\ntopology and propose to search for the right kernel sizes and dilations its\noperations should take on. This dramatically expands the model's capacity to\nextract features at multiple resolutions for different types of data while only\nrequiring search over the operation space. To overcome the efficiency\nchallenges of naive weight-sharing in this search space, we introduce DASH, a\ndifferentiable NAS algorithm that computes the mixture-of-operations using the\nFourier diagonalization of convolution, achieving both a better asymptotic\ncomplexity and an up-to-10x search time speedup in practice. We evaluate DASH\non NAS-Bench-360, a suite of ten tasks designed for benchmarking NAS in diverse\ndomains. DASH outperforms state-of-the-art methods in aggregate, attaining the\nbest-known automated performance on seven tasks. Meanwhile, on six of the ten\ntasks, the combined search and retraining time is less than 2x slower than\nsimply training a CNN backbone that is far less accurate.",
    "descriptor": "\nComments: Code available at this https URL\n",
    "authors": [
      "Junhong Shen",
      "Mikhail Khodak",
      "Ameet Talwalkar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.07554"
  },
  {
    "id": "arXiv:2204.07555",
    "title": "Chinese Idiom Paraphrasing",
    "abstract": "Idioms, are a kind of idiomatic expression in Chinese, most of which consist\nof four Chinese characters. Due to the properties of non-compositionality and\nmetaphorical meaning, Chinese Idioms are hard to be understood by children and\nnon-native speakers. This study proposes a novel task, denoted as Chinese Idiom\nParaphrasing (CIP). CIP aims to rephrase idioms-included sentences to\nnon-idiomatic ones under the premise of preserving the original sentence's\nmeaning. Since the sentences without idioms are easier handled by Chinese NLP\nsystems, CIP can be used to pre-process Chinese datasets, thereby facilitating\nand improving the performance of Chinese NLP tasks, e.g., machine translation\nsystem, Chinese idiom cloze, and Chinese idiom embeddings. In this study, CIP\ntask is treated as a special paraphrase generation task. To circumvent\ndifficulties in acquiring annotations, we first establish a large-scale CIP\ndataset based on human and machine collaboration, which consists of 115,530\nsentence pairs. We further deploy three baselines and two novel CIP approaches\nto deal with CIP problems. The results show that the proposed methods have\nbetter performances than the baselines based on the established CIP dataset.",
    "descriptor": "",
    "authors": [
      "Jipeng Qiang",
      "Yang Li",
      "Chaowei Zhang",
      "Yun Li",
      "Yunhao Yuan",
      "Yi Zhu",
      "Xindong Wu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.07555"
  },
  {
    "id": "arXiv:2204.07556",
    "title": "Streaming Align-Refine for Non-autoregressive Deliberation",
    "abstract": "We propose a streaming non-autoregressive (non-AR) decoding algorithm to\ndeliberate the hypothesis alignment of a streaming RNN-T model. Our algorithm\nfacilitates a simple greedy decoding procedure, and at the same time is capable\nof producing the decoding result at each frame with limited right context, thus\nenjoying both high efficiency and low latency. These advantages are achieved by\nconverting the offline Align-Refine algorithm to be streaming-compatible, with\na novel transformer decoder architecture that performs local self-attentions\nfor both text and audio, and a time-aligned cross-attention at each layer.\nFurthermore, we perform discriminative training of our model with the minimum\nword error rate (MWER) criterion, which has not been done in the non-AR\ndecoding literature. Experiments on voice search datasets and Librispeech show\nthat with reasonable right context, our streaming model performs as well as the\noffline counterpart, and discriminative training leads to further WER gain when\nthe first-pass model has small capacity.",
    "descriptor": "\nComments: In submission to INTERSPEECH 2022\n",
    "authors": [
      "Weiran Wang",
      "Ke Hu",
      "Tara N. Sainath"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2204.07556"
  },
  {
    "id": "arXiv:2204.07560",
    "title": "AI-driven Development Is Here: Should You Worry?",
    "abstract": "AI-Driven Development Environments (AIDEs) Integrate the power of modern AI\ninto IDEs like Visual Studio Code and JetBrains IntelliJ. By leveraging massive\nlanguage models and the plethora of openly available source code, AIDEs promise\nto automate many of the obvious, routine tasks in programming. At the same\ntime, AIDEs come with new challenges to think about, such as bias, legal\ncompliance, security vulnerabilities, and their impact on learning programming.",
    "descriptor": "",
    "authors": [
      "Neil Ernst",
      "Gabriele Bavota"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2204.07560"
  },
  {
    "id": "arXiv:2204.07562",
    "title": "Evaluating Factuality in Text Simplification",
    "abstract": "Automated simplification models aim to make input texts more readable. Such\nmethods have the potential to make complex information accessible to a wider\naudience, e.g., providing access to recent medical literature which might\notherwise be impenetrable for a lay reader. However, such models risk\nintroducing errors into automatically simplified texts, for instance by\ninserting statements unsupported by the corresponding original text, or by\nomitting key information. Providing more readable but inaccurate versions of\ntexts may in many cases be worse than providing no such access at all. The\nproblem of factual accuracy (and the lack thereof) has received heightened\nattention in the context of summarization models, but the factuality of\nautomatically simplified texts has not been investigated. We introduce a\ntaxonomy of errors that we use to analyze both references drawn from standard\nsimplification datasets and state-of-the-art model outputs. We find that errors\noften appear in both that are not captured by existing evaluation metrics,\nmotivating a need for research into ensuring the factual accuracy of automated\nsimplification models.",
    "descriptor": "\nComments: ACL 2022\n",
    "authors": [
      "Ashwin Devaraj",
      "William Sheffield",
      "Byron C. Wallace",
      "Junyi Jessy Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.07562"
  },
  {
    "id": "arXiv:2204.07566",
    "title": "Improving Frame-Online Neural Speech Enhancement with Overlapped-Frame  Prediction",
    "abstract": "Frame-online speech enhancement systems in the short-time Fourier transform\n(STFT) domain usually have an algorithmic latency equal to the window size due\nto the use of the overlap-add algorithm in the inverse STFT (iSTFT). This\nalgorithmic latency allows the enhancement models to leverage future contextual\ninformation up to a length equal to the window size. However, current\nframe-online systems only partially leverage this future information. To fully\nexploit this information, this study proposes an overlapped-frame prediction\ntechnique for deep learning based frame-online speech enhancement, where at\neach frame our deep neural network (DNN) predicts the current and several past\nframes that are necessary for overlap-add, instead of only predicting the\ncurrent frame. In addition, we propose a novel loss function to account for the\nscale difference between predicted and oracle target signals. Evaluations\nresults on a noisy-reverberant speech enhancement task show the effectiveness\nof the proposed algorithms.",
    "descriptor": "\nComments: in submission\n",
    "authors": [
      "Zhong-Qiu Wang",
      "Shinji Watanabe"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2204.07566"
  },
  {
    "id": "arXiv:2204.07569",
    "title": "Deep Learning-based List Sphere Decoding for Faster-than-Nyquist (FTN)  Signaling Detection",
    "abstract": "Faster-than-Nyquist (FTN) signaling is a candidate non-orthonormal\ntransmission technique to improve the spectral efficiency (SE) of future\ncommunication systems. However, such improvements of the SE are at the cost of\nadditional computational complexity to remove the intentionally introduced\nintersymbol interference. In this paper, we investigate the use of deep\nlearning (DL) to reduce the detection complexity of FTN signaling. To eliminate\nthe need of having a noise whitening filter at the receiver, we first present\nan equivalent FTN signaling model based on using a set of orthonormal basis\nfunctions and identify its operation region. Second, we propose a DL-based list\nsphere decoding (DL-LSD) algorithm that selects and updates the initial radius\nof the original LSD to guarantee a pre-defined number $N_{\\text{L}}$ of lattice\npoints inside the hypersphere. This is achieved by training a neural network to\noutput an approximate initial radius that includes $N_{\\text{L}}$ lattice\npoints. At the testing phase, if the hypersphere has more than $N_{\\text{L}}$\nlattice points, we keep the $N_{\\text{L}}$ closest points to the point\ncorresponding to the received FTN signal; however, if the hypersphere has less\nthan $N_{\\text{L}}$ points, we increase the approximate initial radius by a\nvalue that depends on the standard deviation of the distribution of the output\nradii from the training phase. Then, the approximate value of the\nlog-likelihood ratio (LLR) is calculated based on the obtained $N_{\\text{L}}$\npoints. Simulation results show that the computational complexity of the\nproposed DL-LSD is lower than its counterpart of the original LSD by orders of\nmagnitude.",
    "descriptor": "\nComments: Accepted to IEEE VTC-Spring 2022\n",
    "authors": [
      "Sina Abbasi",
      "Ebrahim Bedeer"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2204.07569"
  },
  {
    "id": "arXiv:2204.07570",
    "title": "TreeStep: Tree Search for Vector Perturbation Precoding under  per-Antenna Power Constraint",
    "abstract": "Vector Perturbation Precoding (VPP) can speed up downlink data transmissions\nin Large and Massive Multi-User MIMO systems but is known to be NP-hard. While\nthere are several algorithms in the literature for VPP under total power\nconstraint, they are not applicable for VPP under per-antenna power constraint.\nThis paper proposes a novel, parallel tree search algorithm for VPP under\nper-antenna power constraint, called \\emph{\\textbf{TreeStep}}, to find good\nquality solutions to the VPP problem with practical computational complexity.\nWe show that our method can provide huge performance gain over simple linear\nprecoding like Regularised Zero Forcing. We evaluate TreeStep for several large\nMIMO~($16\\times16$ and $24\\times24$) and massive MIMO~($16\\times32$ and\n$24\\times 48$) and demonstrate that TreeStep outperforms the popular\npolynomial-time VPP algorithm, the Fixed Complexity Sphere Encoder, by\nachieving the extremely low BER of $10^{-6}$ at a much lower SNR.",
    "descriptor": "\nComments: Article under review for IEEE Globecom 22\n",
    "authors": [
      "Abhishek Kumar Singh",
      "Kyle Jamieson"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2204.07570"
  },
  {
    "id": "arXiv:2204.07571",
    "title": "Evaluation Benchmarks for Spanish Sentence Representations",
    "abstract": "Due to the success of pre-trained language models, versions of languages\nother than English have been released in recent years. This fact implies the\nneed for resources to evaluate these models. In the case of Spanish, there are\nfew ways to systematically assess the models' quality. In this paper, we narrow\nthe gap by building two evaluation benchmarks. Inspired by previous work\n(Conneau and Kiela, 2018; Chen et al., 2019), we introduce Spanish SentEval and\nSpanish DiscoEval, aiming to assess the capabilities of stand-alone and\ndiscourse-aware sentence representations, respectively. Our benchmarks include\nconsiderable pre-existing and newly constructed datasets that address different\ntasks from various domains. In addition, we evaluate and analyze the most\nrecent pre-trained Spanish language models to exhibit their capabilities and\nlimitations. As an example, we discover that for the case of discourse\nevaluation tasks, mBERT, a language model trained on multiple languages,\nusually provides a richer latent representation than models trained only with\ndocuments in Spanish. We hope our contribution will motivate a fairer, more\ncomparable, and less cumbersome way to evaluate future Spanish language models.",
    "descriptor": "\nComments: Accepted paper at LREC2022\n",
    "authors": [
      "Vladimir Araujo",
      "Andr\u00e9s Carvallo",
      "Souvik Kundu",
      "Jos\u00e9 Ca\u00f1ete",
      "Marcelo Mendoza",
      "Robert E. Mercer",
      "Felipe Bravo-Marquez",
      "Marie-Francine Moens",
      "Alvaro Soto"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.07571"
  },
  {
    "id": "arXiv:2204.07576",
    "title": "The Distributed Information Bottleneck reveals the explanatory structure  of complex systems",
    "abstract": "The fruits of science are relationships made comprehensible, often by way of\napproximation. While deep learning is an extremely powerful way to find\nrelationships in data, its use in science has been hindered by the difficulty\nof understanding the learned relationships. The Information Bottleneck (IB) is\nan information theoretic framework for understanding a relationship between an\ninput and an output in terms of a trade-off between the fidelity and complexity\nof approximations to the relationship. Here we show that a crucial modification\n-- distributing bottlenecks across multiple components of the input -- opens\nfundamentally new avenues for interpretable deep learning in science. The\nDistributed Information Bottleneck throttles the downstream complexity of\ninteractions between the components of the input, deconstructing a relationship\ninto meaningful approximations found through deep learning without requiring\ncustom-made datasets or neural network architectures. Applied to a complex\nsystem, the approximations illuminate aspects of the system's nature by\nrestricting -- and monitoring -- the information about different components\nincorporated into the approximation. We demonstrate the Distributed IB's\nexplanatory utility in systems drawn from applied mathematics and condensed\nmatter physics. In the former, we deconstruct a Boolean circuit into\napproximations that isolate the most informative subsets of input components\nwithout requiring exhaustive search. In the latter, we localize information\nabout future plastic rearrangement in the static structure of a sheared glass,\nand find the information to be more or less diffuse depending on the system's\npreparation. By way of a principled scheme of approximations, the Distributed\nIB brings much-needed interpretability to deep learning and enables\nunprecedented analysis of information flow through a system.",
    "descriptor": "",
    "authors": [
      "Kieran A. Murphy",
      "Dani S. Bassett"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Soft Condensed Matter (cond-mat.soft)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2204.07576"
  },
  {
    "id": "arXiv:2204.07162",
    "title": "Spatio-Temporal Analysis of Transformer based Architecture for Attention  Estimation from EEG",
    "abstract": "For many years now, understanding the brain mechanism has been a great\nresearch subject in many different fields. Brain signal processing and\nespecially electroencephalogram (EEG) has recently known a growing interest\nboth in academia and industry. One of the main examples is the increasing\nnumber of Brain-Computer Interfaces (BCI) aiming to link brains and computers.\nIn this paper, we present a novel framework allowing us to retrieve the\nattention state, i.e degree of attention given to a specific task, from EEG\nsignals. While previous methods often consider the spatial relationship in EEG\nthrough electrodes and process them in recurrent or convolutional based\narchitecture, we propose here to also exploit the spatial and temporal\ninformation with a transformer-based network that has already shown its\nsupremacy in many machine-learning (ML) related studies, e.g. machine\ntranslation. In addition to this novel architecture, an extensive study on the\nfeature extraction methods, frequential bands and temporal windows length has\nalso been carried out. The proposed network has been trained and validated on\ntwo public datasets and achieves higher results compared to state-of-the-art\nmodels. As well as proposing better results, the framework could be used in\nreal applications, e.g. Attention Deficit Hyperactivity Disorder (ADHD)\nsymptoms or vigilance during a driving assessment.",
    "descriptor": "",
    "authors": [
      "Victor Delvigne",
      "Hazem Wannous",
      "Jean-Philippe Vandeborre",
      "Laurence Ris",
      "Thierry Dutoit"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2204.07162"
  },
  {
    "id": "arXiv:2204.07163",
    "title": "Cross-Frequency Coupling Increases Memory Capacity in Oscillatory Neural  Networks",
    "abstract": "An open problem in neuroscience is to explain the functional role of\noscillations in neural networks, contributing, for example, to perception,\nattention, and memory. Cross-frequency coupling (CFC) is associated with\ninformation integration across populations of neurons. Impaired CFC is linked\nto neurological disease. It is unclear what role CFC has in information\nprocessing and brain functional connectivity. We construct a model of CFC which\npredicts a computational role for observed $\\theta - \\gamma$ oscillatory\ncircuits in the hippocampus and cortex. Our model predicts that the complex\ndynamics in recurrent and feedforward networks of coupled oscillators performs\nrobust information storage and pattern retrieval. Based on phasor associative\nmemories (PAM), we present a novel oscillator neural network (ONN) model that\nincludes subharmonic injection locking (SHIL) and which reproduces experimental\nobservations of CFC. We show that the presence of CFC increases the memory\ncapacity of a population of neurons connected by plastic synapses. CFC enables\nerror-free pattern retrieval whereas pattern retrieval fails without CFC. In\naddition, the trade-offs between sparse connectivity, capacity, and information\nper connection are identified. The associative memory is based on a\ncomplex-valued neural network, or phasor neural network (PNN). We show that for\nvalues of $Q$ which are the same as the ratio of $\\gamma$ to $\\theta$\noscillations observed in the hippocampus and the cortex, the associative memory\nachieves greater capacity and information storage than previous models. The\nnovel contributions of this work are providing a computational framework based\non oscillator dynamics which predicts the functional role of neural\noscillations and connecting concepts in neural network theory and dynamical\nsystem theory.",
    "descriptor": "\nComments: 4 pages, one figure, Presented at Computation and Systems Neuroscience (COSYNE) 2022\n",
    "authors": [
      "Connor Bybee",
      "Alexander Belsten",
      "Friedrich T. Sommer"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2204.07163"
  },
  {
    "id": "arXiv:2204.07172",
    "title": "Diagnosing and Fixing Manifold Overfitting in Deep Generative Models",
    "abstract": "Likelihood-based, or explicit, deep generative models use neural networks to\nconstruct flexible high-dimensional densities. This formulation directly\ncontradicts the manifold hypothesis, which states that observed data lies on a\nlow-dimensional manifold embedded in high-dimensional ambient space. In this\npaper we investigate the pathologies of maximum-likelihood training in the\npresence of this dimensionality mismatch. We formally prove that degenerate\noptima are achieved wherein the manifold itself is learned but not the\ndistribution on it, a phenomenon we call manifold overfitting. We propose a\nclass of two-step procedures consisting of a dimensionality reduction step\nfollowed by maximum-likelihood density estimation, and prove that they recover\nthe data-generating distribution in the nonparametric regime, thus avoiding\nmanifold overfitting. We also show that these procedures enable density\nestimation on the manifolds learned by implicit models, such as generative\nadversarial networks, hence addressing a major shortcoming of these models.\nSeveral recently proposed methods are instances of our two-step procedures; we\nthus unify, extend, and theoretically justify a large class of models.",
    "descriptor": "",
    "authors": [
      "Gabriel Loaiza-Ganem",
      "Brendan Leigh Ross",
      "Jesse C. Cresswell",
      "Anthony L. Caterini"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2204.07172"
  },
  {
    "id": "arXiv:2204.07186",
    "title": "Optimal quadratic binding for relational reasoning in vector symbolic  neural architectures",
    "abstract": "Binding operation is fundamental to many cognitive processes, such as\ncognitive map formation, relational reasoning, and language comprehension. In\nthese processes, two different modalities, such as location and objects, events\nand their contextual cues, and words and their roles, need to be bound\ntogether, but little is known about the underlying neural mechanisms. Previous\nworks introduced a binding model based on quadratic functions of bound pairs,\nfollowed by vector summation of multiple pairs. Based on this framework, we\naddress following questions: Which classes of quadratic matrices are optimal\nfor decoding relational structures? And what is the resultant accuracy? We\nintroduce a new class of binding matrices based on a matrix representation of\noctonion algebra, an eight-dimensional extension of complex numbers. We show\nthat these matrices enable a more accurate unbinding than previously known\nmethods when a small number of pairs are present. Moreover, numerical\noptimization of a binding operator converges to this octonion binding. We also\nshow that when there are a large number of bound pairs, however, a random\nquadratic binding performs as well as the octonion and previously-proposed\nbinding methods. This study thus provides new insight into potential neural\nmechanisms of binding operations in the brain.",
    "descriptor": "\nComments: 32 pages, 9 figures\n",
    "authors": [
      "Naoki Hiratani",
      "Haim Sompolinsky"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.07186"
  },
  {
    "id": "arXiv:2204.07207",
    "title": "Hierarchical Embedded Bayesian Additive Regression Trees",
    "abstract": "We propose a simple yet powerful extension of Bayesian Additive Regression\nTrees which we name Hierarchical Embedded BART (HE-BART). The model allows for\nrandom effects to be included at the terminal node level of a set of regression\ntrees, making HE-BART a non-parametric alternative to mixed effects models\nwhich avoids the need for the user to specify the structure of the random\neffects in the model, whilst maintaining the prediction and uncertainty\ncalibration properties of standard BART. Using simulated and real-world\nexamples, we demonstrate that this new extension yields superior predictions\nfor many of the standard mixed effects models' example data sets, and yet still\nprovides consistent estimates of the random effect variances. In a future\nversion of this paper, we outline its use in larger, more advanced data sets\nand structures.",
    "descriptor": "",
    "authors": [
      "Bruna Wundervald",
      "Andrew Parnell",
      "Katarina Domijan"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.07207"
  },
  {
    "id": "arXiv:2204.07230",
    "title": "Learning two-phase microstructure evolution using neural operators and  autoencoder architectures",
    "abstract": "Phase-field modeling is an effective mesoscale method for capturing the\nevolution dynamics of materials, e.g., in spinodal decomposition of a two-phase\nmixture. However, the accuracy of high-fidelity phase field models comes at a\nsubstantial computational cost. Hence, fast and generalizable surrogate models\nare needed to alleviate the cost in computationally taxing processes such as in\noptimization and design of materials. The intrinsic discontinuous nature of the\nphysical phenomena incurred by the presence of sharp phase boundaries makes the\ntraining of the surrogate model cumbersome. We develop a new framework that\nintegrates a convolutional autoencoder architecture with a deep neural operator\n(DeepONet) to learn the dynamic evolution of a two-phase mixture. We utilize\nthe convolutional autoencoder to provide a compact representation of the\nmicrostructure data in a low-dimensional latent space. DeepONet, which consists\nof two sub-networks, one for encoding the input function at a fixed number of\nsensors locations (branch net) and another for encoding the locations for the\noutput functions (trunk net), learns the mesoscale dynamics of the\nmicrostructure evolution in the latent space. The decoder part of the\nconvolutional autoencoder can then reconstruct the time-evolved microstructure\nfrom the DeepONet predictions. The result is an efficient and accurate\naccelerated phase-field framework that outperforms other neural-network-based\napproaches while at the same time being robust to noisy inputs.",
    "descriptor": "",
    "authors": [
      "Vivek Oommen",
      "Khemraj Shukla",
      "Somdatta Goswami",
      "Remi Dingreville",
      "George Em Karniadakis"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2204.07230"
  },
  {
    "id": "arXiv:2204.07234",
    "title": "Physics-Aware Recurrent Convolutional (PARC) Neural Networks to  Assimilate Meso-scale Reactive Mechanics of Energetic Materials",
    "abstract": "The thermomechanical properties of energetic materials (EM) are known to be a\nfunction of their microscopic structures, i.e., morphological configurations of\ncrystals and pores. This microstructural dependency has motivated vigorous\nresearch in the EM community, seeking to engineer material microstructures with\ntargeted properties and performance under the materials-by-design paradigm.\nHowever, establishing the complex structure-property-performance (SPP)\nrelationships of EMs demands extensive experimental and simulation efforts, and\nassimilating and encapsulating these relationships in usable models is a\nchallenge. Here, we present a novel deep learning method, Physics-Aware\nRecurrent Convolutional (PARC) Neural Network, that can \"learn\" the mesoscale\nthermo-mechanics of EM microstructures during the shock-to-detonation\ntransition (SDT). We show that this new approach can produce accurate\nhigh-fidelity predictions of time-evolving temperature and pressure fields of\nthe same quality as the state-of-the-art direct numerical simulations (DNS),\ndespite the dramatic reduction of computing time, from hours and days on a\nhigh-performance computing cluster (HPC) to a little more than a second on a\ncommodity laptop. We also demonstrate that PARC can provide physical insights,\ni.e., the artificial neurons can illuminate the underlying physics by\nidentifying which microstructural features led to critical hotspots and what\nare the characteristics of \"critical\" versus \"non-critical\" microstructures.\nThis new knowledge generated alongside the capacity to conduct high-throughput\nexperiments will broaden our theoretical understanding of the initiation\nmechanisms of EM detonation, as a step towards engineering EMs with specific\nproperties.",
    "descriptor": "",
    "authors": [
      "Phong C.H. Nguyen",
      "Joseph B. Choi",
      "Yen-Thi Nguyen",
      "Pradeep K. Seshadri",
      "H.S. Udaykumar",
      "Stephen Baek"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.07234"
  },
  {
    "id": "arXiv:2204.07235",
    "title": "Harnessing Interpretable Machine Learning for Origami Feature Design and  Pattern Selection",
    "abstract": "Engineering design of origami systems is challenging because comparing\ndifferent origami patterns requires using categorical features and evaluating\nmulti-physics behavior targets introduces multi-objective problems. This work\nshows that a decision tree machine learning method is particularly suitable for\nthe inverse design of origami. This interpretable machine learning method can\nreveal complex interactions between categorical features and continuous\nfeatures for comparing different origami patterns, can tackle multi-objective\nproblems for designing active origami with multi-physics performance targets,\nand can extend existing origami shape fitting algorithms to further consider\nnon-geometrical performances of origami systems. The proposed framework shows a\nholistic way of designing active origami systems for various applications such\nas metamaterials, deployable structures, soft robots, biomedical devices, and\nmany more.",
    "descriptor": "",
    "authors": [
      "Yi Zhu",
      "Evgueni T. Filipov"
    ],
    "subjectives": [
      "Soft Condensed Matter (cond-mat.soft)",
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2204.07235"
  },
  {
    "id": "arXiv:2204.07253",
    "title": "Early Myocardial Infarction Detection with One-Class Classification over  Multi-view Echocardiography",
    "abstract": "Myocardial infarction (MI) is the leading cause of mortality and morbidity in\nthe world. Early therapeutics of MI can ensure the prevention of further\nmyocardial necrosis. Echocardiography is the fundamental imaging technique that\ncan reveal the earliest sign of MI. However, the scarcity of echocardiographic\ndatasets for the MI detection is the major issue for training data-driven\nclassification algorithms. In this study, we propose a framework for early\ndetection of MI over multi-view echocardiography that leverages one-class\nclassification (OCC) techniques. The OCC techniques are used to train a model\nfor detecting a specific target class using instances from that particular\ncategory only. We investigated the usage of uni-modal and multi-modal one-class\nclassification techniques in the proposed framework using the HMC-QU dataset\nthat includes apical 4-chamber (A4C) and apical 2-chamber (A2C) views in a\ntotal of 260 echocardiography recordings. Experimental results show that the\nmulti-modal approach achieves a sensitivity level of 85.23% and F1-Score of\n80.21%.",
    "descriptor": "",
    "authors": [
      "Aysen Degerli",
      "Fahad Sohrab",
      "Serkan Kiranyaz",
      "Moncef Gabbouj"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.07253"
  },
  {
    "id": "arXiv:2204.07265",
    "title": "The Rise of Intelligent Reflecting Surfaces in Integrated Sensing and  Communications Paradigms",
    "abstract": "The intelligent reflecting surface (IRS) alters the behavior of wireless\nmedia and, consequently, has potential to improve the performance and\nreliability of wireless systems such as communications and radar remote\nsensing. Recently, integrated sensing and communications (ISAC) has been widely\nstudied as a means to efficiently utilize spectrum and thereby save cost and\npower. This article investigates the role of IRS in the future ISAC paradigms.\nWhile there is a rich heritage of recent research into IRS-assisted\ncommunications, the IRS-assisted radars and ISAC remain relatively unexamined.\nWe discuss the putative advantages of IRS deployment, such as coverage\nextension, interference suppression, and enhanced parameter estimation, for\nboth communications and radar. We introduce possible IRS-assisted ISAC\nscenarios with common and dedicated surfaces. The article provides an overview\nof related signal processing techniques and the design challenges, such as\nwireless channel acquisition, waveform design, and security.",
    "descriptor": "\nComments: 7pages5figures\n",
    "authors": [
      "Ahmet M. Elbir",
      "Kumar Vijay Mishra",
      "M. R. Bhavani Shankar",
      "Symeon Chatzinotas"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2204.07265"
  },
  {
    "id": "arXiv:2204.07267",
    "title": "Learning Spatially Varying Pixel Exposures for Motion Deblurring",
    "abstract": "Computationally removing the motion blur introduced by camera shake or object\nmotion in a captured image remains a challenging task in computational\nphotography. Deblurring methods are often limited by the fixed global exposure\ntime of the image capture process. The post-processing algorithm either must\ndeblur a longer exposure that contains relatively little noise or denoise a\nshort exposure that intentionally removes the opportunity for blur at the cost\nof increased noise. We present a novel approach of leveraging spatially varying\npixel exposures for motion deblurring using next-generation focal-plane\nsensor--processors along with an end-to-end design of these exposures and a\nmachine learning--based motion-deblurring framework. We demonstrate in\nsimulation and a physical prototype that learned spatially varying pixel\nexposures (L-SVPE) can successfully deblur scenes while recovering high\nfrequency detail. Our work illustrates the promising role that focal-plane\nsensor--processors can play in the future of computational imaging.",
    "descriptor": "\nComments: Project page with code: this https URL\n",
    "authors": [
      "Cindy M. Nguyen",
      "Julien N.P. Martel",
      "Gordon Wetzstein"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.07267"
  },
  {
    "id": "arXiv:2204.07278",
    "title": "A Fictitious-play Finite-difference Method for Linearly Solvable Mean  Field Games",
    "abstract": "A new numerical method for mean field games (MFGs) is proposed. The target\nMFGs are derived from optimal control problems for multidimensional systems\nwith advection terms, which are difficult to solve numerically with existing\nmethods. For such MFGs, linearization using the Cole-Hopf transformation and\niterative computation using fictitious play are introduced. This leads to an\nimplementation-friendly algorithm that iteratively solves explicit schemes. The\nconvergence properties of the proposed scheme are mathematically proved by\ntracking the error of the variable through iterations. Numerical calculations\nshow that the proposed method works stably for both one- and two-dimensional\ncontrol problems.",
    "descriptor": "\nComments: 26 pages, 10 figures\n",
    "authors": [
      "Daisuke Inoue",
      "Yuji Ito",
      "Takahito Kashiwabara",
      "Norikazu Saito",
      "Hiroaki Yoshida"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Analysis of PDEs (math.AP)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2204.07278"
  },
  {
    "id": "arXiv:2204.07291",
    "title": "The training response law explains how deep neural networks learn",
    "abstract": "Deep neural network is the widely applied technology in this decade. In spite\nof the fruitful applications, the mechanism behind that is still to be\nelucidated. We study the learning process with a very simple supervised\nlearning encoding problem. As a result, we found a simple law, in the training\nresponse, which describes neural tangent kernel. The response consists of a\npower law like decay multiplied by a simple response kernel. We can construct a\nsimple mean-field dynamical model with the law, which explains how the network\nlearns. In the learning, the input space is split into sub-spaces along\ncompetition between the kernels. With the iterated splits and the aging, the\nnetwork gets more complexity, but finally loses its plasticity.",
    "descriptor": "",
    "authors": [
      "Kenichi Nakazato"
    ],
    "subjectives": [
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.07291"
  },
  {
    "id": "arXiv:2204.07293",
    "title": "Towards a Unified Framework for Uncertainty-aware Nonlinear Variable  Selection with Theoretical Guarantees",
    "abstract": "We develop a simple and unified framework for nonlinear variable selection\nthat incorporates model uncertainty and is compatible with a wide range of\nmachine learning models (e.g., tree ensembles, kernel methods and neural\nnetwork). In particular, for a learned nonlinear model $f(\\mathbf{x})$, we\nconsider quantifying the importance of an input variable $\\mathbf{x}^j$ using\nthe integrated gradient measure $\\psi_j = \\Vert \\frac{\\partial}{\\partial\n\\mathbf{x}^j} f(\\mathbf{x})\\Vert^2_2$. We then (1) provide a principled\napproach for quantifying variable selection uncertainty by deriving its\nposterior distribution, and (2) show that the approach is generalizable even to\nnon-differentiable models such as tree ensembles. Rigorous Bayesian\nnonparametric theorems are derived to guarantee the posterior consistency and\nasymptotic uncertainty of the proposed approach. Extensive simulation confirms\nthat the proposed algorithm outperforms existing classic and recent variable\nselection methods.",
    "descriptor": "\nComments: 11 pages, 3 figures\n",
    "authors": [
      "Wenying Deng",
      "Beau Coker",
      "Jeremiah Zhe Liu",
      "Brent A. Coull"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.07293"
  },
  {
    "id": "arXiv:2204.07312",
    "title": "Structural Analysis of Branch-and-Cut and the Learnability of Gomory  Mixed Integer Cuts",
    "abstract": "The incorporation of cutting planes within the branch-and-bound algorithm,\nknown as branch-and-cut, forms the backbone of modern integer programming\nsolvers. These solvers are the foremost method for solving discrete\noptimization problems and thus have a vast array of applications in machine\nlearning, operations research, and many other fields. Choosing cutting planes\neffectively is a major research topic in the theory and practice of integer\nprogramming. We conduct a novel structural analysis of branch-and-cut that pins\ndown how every step of the algorithm is affected by changes in the parameters\ndefining the cutting planes added to the input integer program. Our main\napplication of this analysis is to derive sample complexity guarantees for\nusing machine learning to determine which cutting planes to apply during\nbranch-and-cut. These guarantees apply to infinite families of cutting planes,\nsuch as the family of Gomory mixed integer cuts, which are responsible for the\nmain breakthrough speedups of integer programming solvers. We exploit geometric\nand combinatorial structure of branch-and-cut in our analysis, which provides a\nkey missing piece for the recent generalization theory of branch-and-cut.",
    "descriptor": "",
    "authors": [
      "Maria-Florina Balcan",
      "Siddharth Prasad",
      "Tuomas Sandholm",
      "Ellen Vitercik"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.07312"
  },
  {
    "id": "arXiv:2204.07314",
    "title": "Feature Compression for Rate Constrained Object Detection on the Edge",
    "abstract": "Recent advances in computer vision has led to a growth of interest in\ndeploying visual analytics model on mobile devices. However, most mobile\ndevices have limited computing power, which prohibits them from running large\nscale visual analytics neural networks. An emerging approach to solve this\nproblem is to offload the computation of these neural networks to computing\nresources at an edge server. Efficient computation offloading requires\noptimizing the trade-off between multiple objectives including compressed data\nrate, analytics performance, and computation speed. In this work, we consider a\n\"split computation\" system to offload a part of the computation of the YOLO\nobject detection model. We propose a learnable feature compression approach to\ncompress the intermediate YOLO features with light-weight computation. We train\nthe feature compression and decompression module together with the YOLO model\nto optimize the object detection accuracy under a rate constraint. Compared to\nbaseline methods that apply either standard image compression or learned image\ncompression at the mobile and perform image decompression and YOLO at the edge,\nthe proposed system achieves higher detection accuracy at the low to medium\nrate range. Furthermore, the proposed system requires substantially lower\ncomputation time on the mobile device with CPU only.",
    "descriptor": "",
    "authors": [
      "Zhongzheng Yuan",
      "Samyak Rawlekar",
      "Siddharth Garg",
      "Elza Erkip",
      "Yao Wang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2204.07314"
  },
  {
    "id": "arXiv:2204.07329",
    "title": "Risk-Aware Stability, Ultimate Boundedness, and Positive Invariance",
    "abstract": "This paper introduces the notions of stability, ultimate boundedness, and\npositive invariance for stochastic systems in the view of risk. More\nspecifically, those notions are defined in terms of the worst-case Conditional\nValue-at-Risk (CVaR), which quantifies the worst-case conditional expectation\nof losses exceeding a certain threshold over a set of possible uncertainties.\nThose notions allow us to focus our attention on the tail behavior of\nstochastic systems in the analysis of dynamical systems and the design of\ncontrollers. Furthermore, some event-triggered control strategies that\nguarantee ultimate boundedness and positive invariance with specified bounds\nare derived using the obtained results and illustrated using numerical\nexamples.",
    "descriptor": "\nComments: under review\n",
    "authors": [
      "Masako Kishida"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2204.07329"
  },
  {
    "id": "arXiv:2204.07330",
    "title": "Differentially Private Distributed Mismatch Tracking Algorithm for  Constraint-Coupled Resource Allocation Problems",
    "abstract": "This paper considers privacy-concerned distributed constraint-coupled\nresource allocation problems over an undirected network, where each agent holds\na private cost function and obtains the solution via only local communication.\nWith privacy concerns, we mask the exchanged information with independent\nLaplace noise against a potential attacker with potential access to all network\ncommunications. We propose a differentially private distributed mismatch\ntracking algorithm (diff-DMAC) to achieve cost-optimal distribution of\nresources while preserving privacy. Adopting constant stepsizes, the linear\nconvergence property of diff-DMAC in mean square is established under the\nstandard assumptions of Lipschitz gradients and strong convexity. Moreover, it\nis theoretically proven that the proposed algorithm is\n{\\epsilon}-differentially private.And we also show the trade-off between\nconvergence accuracy and privacy level. Finally, a numerical example is\nprovided for verification.",
    "descriptor": "",
    "authors": [
      "Wenwen Wu",
      "Shanying Zhu",
      "Shuai Liu",
      "Xinping Guan"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2204.07330"
  },
  {
    "id": "arXiv:2204.07344",
    "title": "CAiD: Context-Aware Instance Discrimination for Self-supervised Learning  in Medical Imaging",
    "abstract": "Recently, self-supervised instance discrimination methods have achieved\nsignificant success in learning visual representations from unlabeled\nphotographic images. However, given the marked differences between photographic\nand medical images, the efficacy of instance-based objectives, focusing on\nlearning the most discriminative global features in the image (i.e., wheels in\nbicycle), remains unknown in medical imaging. Our preliminary analysis showed\nthat high global similarity of medical images in terms of anatomy hampers\ninstance discrimination methods for capturing a set of distinct features,\nnegatively impacting their performance on medical downstream tasks. To\nalleviate this limitation, we have developed a simple yet effective\nself-supervised framework, called Context-Aware instance Discrimination (CAiD).\nCAiD aims to improve instance discrimination learning by providing finer and\nmore discriminative information encoded from a diverse local context of\nunlabeled medical images. We conduct a systematic analysis to investigate the\nutility of the learned features from a three-pronged perspective: (i)\ngeneralizability and transferability, (ii) separability in the embedding space,\nand (iii) reusability. Our extensive experiments demonstrate that CAiD (1)\nenriches representations learned from existing instance discrimination methods;\n(2) delivers more discriminative features by adequately capturing finer\ncontextual information from individual medial images; and (3) improves\nreusability of low/mid-level features compared to standard instance\ndiscriminative methods. As open science, all codes and pre-trained models are\navailable on our GitHub page: https://github.com/JLiangLab/CAiD.",
    "descriptor": "\nComments: Accepted at MIDL 2022 [main conference]\n",
    "authors": [
      "Mohammad Reza Hosseinzadeh Taher",
      "Fatemeh Haghighi",
      "Michael B. Gotway",
      "Jianming Liang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.07344"
  },
  {
    "id": "arXiv:2204.07353",
    "title": "Anomalous Sound Detection Based on Machine Activity Detection",
    "abstract": "We have developed an unsupervised anomalous sound detection method for\nmachine condition monitoring that utilizes an auxiliary task -- detecting when\nthe target machine is active. First, we train a model that detects machine\nactivity by using normal data with machine activity labels and then use the\nactivity-detection error as the anomaly score for a given sound clip if we have\naccess to the ground-truth activity labels in the inference phase. If these\nlabels are not available, the anomaly score is calculated through outlier\ndetection on the embedding vectors obtained by the activity-detection model.\nSolving this auxiliary task enables the model to learn the difference between\nthe target machine sounds and similar background noise, which makes it possible\nto identify small deviations in the target sounds. Experimental results showed\nthat the proposed method improves the anomaly-detection performance of the\nconventional method complementarily by means of an ensemble.",
    "descriptor": "\nComments: 5 pages, 2 figures, 1 table\n",
    "authors": [
      "Tomoya Nishida",
      "Kota Dohi",
      "Takashi Endo",
      "Masaaki Yamamoto",
      "Yohei Kawaguchi"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2204.07353"
  },
  {
    "id": "arXiv:2204.07358",
    "title": "Prototype-based Domain Generalization Framework for Subject-Independent  Brain-Computer Interfaces",
    "abstract": "Brain-computer interface (BCI) is challenging to use in practice due to the\ninter/intra-subject variability of electroencephalography (EEG). The BCI\nsystem, in general, necessitates a calibration technique to obtain\nsubject/session-specific data in order to tune the model each time the system\nis utilized. This issue is acknowledged as a key hindrance to BCI, and a new\nstrategy based on domain generalization has recently evolved to address it. In\nlight of this, we've concentrated on developing an EEG classification framework\nthat can be applied directly to data from unknown domains (i.e. subjects),\nusing only data acquired from separate subjects previously. For this purpose,\nin this paper, we proposed a framework that employs the open-set recognition\ntechnique as an auxiliary task to learn subject-specific style features from\nthe source dataset while helping the shared feature extractor with mapping the\nfeatures of the unseen target dataset as a new unseen domain. Our aim is to\nimpose cross-instance style in-variance in the same domain and reduce the open\nspace risk on the potential unseen subject in order to improve the\ngeneralization ability of the shared feature extractor. Our experiments showed\nthat using the domain information as an auxiliary network increases the\ngeneralization performance.",
    "descriptor": "\nComments: Accepted in EMBC 2022\n",
    "authors": [
      "Serkan Musellim",
      "Dong-Kyun Han",
      "Ji-Hoon Jeong",
      "Seong-Whan Lee"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.07358"
  },
  {
    "id": "arXiv:2204.07360",
    "title": "Spatio-Temporal-Frequency Graph Attention Convolutional Network for  Aircraft Recognition Based on Heterogeneous Radar Network",
    "abstract": "This paper proposes a knowledge-and-data-driven graph neural network-based\ncollaboration learning model for reliable aircraft recognition in a\nheterogeneous radar network. The aircraft recognizability analysis shows that:\n(1) the semantic feature of an aircraft is motion patterns driven by the\nkinetic characteristics, and (2) the grammatical features contained in the\nradar cross-section (RCS) signals present spatial-temporal-frequency (STF)\ndiversity decided by both the electromagnetic radiation shape and motion\npattern of the aircraft. Then a STF graph attention convolutional network\n(STFGACN) is developed to distill semantic features from the RCS signals\nreceived by the heterogeneous radar network. Extensive experiment results\nverify that the STFGACN outperforms the baseline methods in terms of detection\naccuracy, and ablation experiments are carried out to further show that the\nexpansion of the information dimension can gain considerable benefits to\nperform robustly in the low signal-to-noise ratio region.",
    "descriptor": "\nComments: 11 pages, 17 figures\n",
    "authors": [
      "Han Meng",
      "Yuexing Peng",
      "Wenbo Wang",
      "Peng Cheng",
      "Yonghui Li",
      "Wei Xiang"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.07360"
  },
  {
    "id": "arXiv:2204.07362",
    "title": "Decoding Neural Correlation of Language-Specific Imagined Speech using  EEG Signals",
    "abstract": "Speech impairments due to cerebral lesions and degenerative disorders can be\ndevastating. For humans with severe speech deficits, imagined speech in the\nbrain-computer interface has been a promising hope for reconstructing the\nneural signals of speech production. However, studies in the EEG-based imagined\nspeech domain still have some limitations due to high variability in spatial\nand temporal information and low signal-to-noise ratio. In this paper, we\ninvestigated the neural signals for two groups of native speakers with two\ntasks with different languages, English and Chinese. Our assumption was that\nEnglish, a non-tonal and phonogram-based language, would have spectral\ndifferences in neural computation compared to Chinese, a tonal and\nideogram-based language. The results showed the significant difference in the\nrelative power spectral density between English and Chinese in specific\nfrequency band groups. Also, the spatial evaluation of Chinese native speakers\nin the theta band was distinctive during the imagination task. Hence, this\npaper would suggest the key spectral and spatial information of word\nimagination with specialized language while decoding the neural signals of\nspeech.",
    "descriptor": "\nComments: Accepted in EMBC 2022\n",
    "authors": [
      "Keon-Woo Lee",
      "Dae-Hyeok Lee",
      "Sung-Jin Kim",
      "Seong-Whan Lee"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Human-Computer Interaction (cs.HC)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2204.07362"
  },
  {
    "id": "arXiv:2204.07375",
    "title": "Speaker-Aware Mixture of Mixtures Training for Weakly Supervised Speaker  Extraction",
    "abstract": "Dominant researches adopt supervised training for speaker extraction, while\nthe scarcity of ideally clean corpus and channel mismatch problem are rarely\nconsidered. To this end, we propose speaker-aware mixture of mixtures training\n(SAMoM), utilizing the consistency of speaker identity among target source,\nenrollment utterance and target estimate to weakly supervise the training of a\ndeep speaker extractor. In SAMoM, the input is constructed by mixing up\ndifferent speaker-aware mixtures (SAMs), each contains multiple speakers with\ntheir identities known and enrollment utterances available. Informed by\nenrollment utterances, target speech is extracted from the input one by one,\nsuch that the estimated targets can approximate the original SAMs after a remix\nin accordance with the identity consistency. Moreover, using SAMoM in a\nsemi-supervised setting with a certain amount of clean sources enables\napplication in noisy scenarios. Extensive experiments on Libri2Mix show that\nthe proposed method achieves promising results without access to any clean\nsources (11.06dB SI-SDRi). With a domain adaptation, our approach even\noutperformed supervised framework in a cross-domain evaluation on AISHELL-1.",
    "descriptor": "\nComments: 5 pages, 4 tables, 4 figures. Submitted to INTERSPEECH 2022\n",
    "authors": [
      "Zifeng Zhao",
      "Rongzhi Gu",
      "Dongchao Yang",
      "Jinchuan Tian",
      "Yuexian Zou"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2204.07375"
  },
  {
    "id": "arXiv:2204.07391",
    "title": "Characterizing metastable states with the help of machine learning",
    "abstract": "Present-day atomistic simulations generate long trajectories of ever more\ncomplex systems. Analyzing these data, discovering metastable states, and\nuncovering their nature is becoming increasingly challenging. In this paper, we\nfirst use the variational approach to conformation dynamics to discover the\nslowest dynamical modes of the simulations. This allows the different\nmetastable states of the system to be located and organized hierarchically. The\nphysical descriptors that characterize metastable states are discovered by\nmeans of a machine learning method. We show in the cases of two proteins,\nChignolin and Bovine Pancreatic Trypsin Inhibitor, how such analysis can be\neffortlessly performed in a matter of seconds. Another strength of our approach\nis that it can be applied to the analysis of both unbiased and biased\nsimulations.",
    "descriptor": "\nComments: Main text: 10 pages, 4 figures. Supplementary Info: 4 pages, 5, figures\n",
    "authors": [
      "Pietro Novelli",
      "Luigi Bonati",
      "Massimiliano Pontil",
      "Michele Parrinello"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Machine Learning (cs.LG)",
      "Chemical Physics (physics.chem-ph)"
    ],
    "url": "https://arxiv.org/abs/2204.07391"
  },
  {
    "id": "arXiv:2204.07402",
    "title": "BYOL for Audio: Exploring Pre-trained General-purpose Audio  Representations",
    "abstract": "Pre-trained models are essential as feature extractors in modern machine\nlearning systems in various domains. In this study, we hypothesize that\nrepresentations effective for general audio tasks should provide multiple\naspects of robust features of the input sound. For recognizing sounds\nregardless of perturbations such as varying pitch or timbre, features should be\nrobust to these perturbations. For serving the diverse needs of tasks such as\nrecognition of emotions or music genres, representations should provide\nmultiple aspects of these robust features, such as local and global features\nand their statistics. To implement our principle, we propose a self-supervised\nlearning method: Bootstrap Your Own Latent (BYOL) for Audio (BYOL-A, pronounced\n\"viola\"). BYOL-A pre-trains representations of the input sound themselves\ninvariant to audio data augmentations by minimizing the difference between a\npair of augmented input variants, which makes the learned representations\nrobust to the perturbations of sounds. In the BYOL-A encoder, the global\npooling calculates representations to form multi-aspect information by\ncombining statistics of frequency- and channel-wise, local, and global\nfeatures. As a result, the learned representations should provide multi-aspect\nrobust features of the input and serve various needs of diverse tasks. We\nevaluated general audio task performance among previous state-of-the-art\nmethods, and BYOL-A showed competitive results in all tasks with the best\naverage result of 72.4 %. Besides, BYOL-A sets new records of 57.6 % on\nVoxCeleb1 and 63.8 % on CREMA-D. We also conducted extensive ablation\nexperiments and validated the contributions of BYOL-A components. Our code is\navailable online.",
    "descriptor": "\nComments: 13 pages, 6 figures. Under the review process\n",
    "authors": [
      "Daisuke Niizumi",
      "Daiki Takeuchi",
      "Yasunori Ohishi",
      "Noboru Harada",
      "Kunio Kashino"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2204.07402"
  },
  {
    "id": "arXiv:2204.07446",
    "title": "Wi-Fi and Bluetooth Contact Tracing Without User Intervention",
    "abstract": "A custom Wi-Fi and Bluetooth indoor contact tracing system is created to find\ndetailed paths of infected individuals without any user intervention. The\nsystem tracks smartphones, but it does not require smartphone applications,\nconnecting to the routers, or any other extraneous devices on the users. A\ncustom Turtlebot3 is used for site surveying, where it simulates mobile device\nmovement and packet transmission. Transmit power, receive power, and round trip\ntime are collected by a custom ESP32C3 router. MAC randomization is defeated to\nidentify unique smartphones. Subsequently, the wireless parameters above are\nconverted to signal path loss and time of flight. Bidirectional long short term\nmemory takes the wireless parameters and predicts the detailed paths of the\nusers within 1 m. Public health authorities can use the contact tracing website\nto find the detailed paths of the suspected cases using the smartphone models\nand initial positions of confirm cases. The system can also track indirect\ncontact transmissions originating from surfaces and droplets due to having\nabsolute positions of users.",
    "descriptor": "",
    "authors": [
      "Brosnan Yuen",
      "Yifeng Bie",
      "Duncan Cairns",
      "Geoffrey Harper",
      "Jason Xu",
      "Charles Chang",
      "Xiaodai Dong",
      "Tao Lu"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2204.07446"
  },
  {
    "id": "arXiv:2204.07457",
    "title": "Model-Based Deep Learning of Joint Probabilistic and Geometric Shaping  for Optical Communication",
    "abstract": "Autoencoder-based deep learning is applied to jointly optimize geometric and\nprobabilistic constellation shaping for optical coherent communication. The\noptimized constellation shaping outperforms the 256 QAM Maxwell-Boltzmann\nprobabilistic distribution with extra 0.05 bits/4D-symbol mutual information\nfor 64 GBd transmission over 170 km SMF link.",
    "descriptor": "\nComments: 2 pages; accepted for oral presentation at CLEO 2022 in May 2022\n",
    "authors": [
      "Vladislav Neskorniuk",
      "Andrea Carnio",
      "Domenico Marsella",
      "Sergei K. Turitsyn",
      "Jaroslaw E. Prilepsky",
      "Vahid Aref"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.07457"
  },
  {
    "id": "arXiv:2204.07478",
    "title": "Signal Reception With Generic Three-State Receptors in Synaptic MC",
    "abstract": "Synaptic communication is studied by communication engineers for two main\nreasons. One is to enable novel neuroengineering applications that require\ninterfacing with neurons. The other reason is to draw inspiration for the\ndesign of synthetic molecular communication systems. Both of these goals\nrequire understanding of how the chemical synaptic signal is sensed and\ntransduced at the synaptic receiver (Rx). While signal reception in synaptic\nmolecular communication (SMC) depends heavily on the kinetics of the receptors\nemployed by the synaptic Rxs, existing channel models for SMC either\noversimplify the receptor kinetics or employ complex, high-dimensional kinetic\nschemes limited to specific types of receptors. Both approaches do not\nfacilitate a comparative analysis of different types of natural synapses. In\nthis paper, we propose a novel deterministic channel model for SMC which\nemploys a generic three-state receptor model that captures the characteristics\nof the most important receptor types in SMC. The model is based on a transfer\nfunction expansion of Fick's diffusion equation and accounts for release,\ndiffusion, and degradation of neurotransmitters as well as their reversible\nbinding to finitely many generic postsynaptic receptors. The proposed SMC model\nis the first that allows studying the impact of the characteristic dynamics of\nthe main postsynaptic receptor types on synaptic signal transmission. Numerical\nresults indicate that the proposed model indeed exhibits a wide range of\nbiologically plausible dynamics when specialized to specific natural receptor\ntypes.",
    "descriptor": "\nComments: 6 pages, 6 figures. Submitted for possible publication in Proc. IEEE Global Communications Conference (GLOBECOM)\n",
    "authors": [
      "Sebastian Lotter",
      "Michael T. Barros",
      "Robert Schober",
      "Maximilian Sch\u00e4fer"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2204.07478"
  },
  {
    "id": "arXiv:2204.07492",
    "title": "A Machine Learning Tutorial for Operational Meteorology, Part I:  Traditional Machine Learning",
    "abstract": "Recently, the use of machine learning in meteorology has increased greatly.\nWhile many machine learning methods are not new, university classes on machine\nlearning are largely unavailable to meteorology students and are not required\nto become a meteorologist. The lack of formal instruction has contributed to\nperception that machine learning methods are 'black boxes' and thus end-users\nare hesitant to apply the machine learning methods in their every day workflow.\nTo reduce the opaqueness of machine learning methods and lower hesitancy\ntowards machine learning in meteorology, this paper provides a survey of some\nof the most common machine learning methods. A familiar meteorological example\nis used to contextualize the machine learning methods while also discussing\nmachine learning topics using plain language. The following machine learning\nmethods are demonstrated: linear regression; logistic regression; decision\ntrees; random forest; gradient boosted decision trees; naive Bayes; and support\nvector machines. Beyond discussing the different methods, the paper also\ncontains discussions on the general machine learning process as well as best\npractices to enable readers to apply machine learning to their own datasets.\nFurthermore, all code (in the form of Jupyter notebooks and Google Colaboratory\nnotebooks) used to make the examples in the paper is provided in an effort to\ncatalyse the use of machine learning in meteorology.",
    "descriptor": "",
    "authors": [
      "Randy J. Chase",
      "David R. Harrison",
      "Amanda Burke",
      "Gary M. Lackmann",
      "Amy McGovern"
    ],
    "subjectives": [
      "Atmospheric and Oceanic Physics (physics.ao-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.07492"
  },
  {
    "id": "arXiv:2204.07497",
    "title": "Helicity-conservative Physics-informed Neural Network Model for  Navier-Stokes Equations",
    "abstract": "We design the helicity-conservative physics-informed neural network model for\nthe Navier-Stokes equation in the ideal case. The key is to provide an\nappropriate PDE model as loss function so that its neural network solutions\nproduce helicity conservation. Physics-informed neural network model is based\non the strong form of PDE. We show that the relevant helicity-conservative\nfinite element method based on the weak formulation of PDE can be somewhat\ndifferent. More precisely, we compares the PINN formulation and the finite\nelement method based on the weak formulation for conserving helicity and argues\nthat for the conservation, strong PDE is more natural. Our result is justified\nby theory as well. Furthermore, a couple of numerical calculations are\ndemonstrated to confirm our theoretical finding.",
    "descriptor": "\nComments: 17 pages, 9 figures, 3 tables\n",
    "authors": [
      "Ziqian Li",
      "Jiwei Jia",
      "Young Ju Lee",
      "Zheng Lu"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2204.07497"
  },
  {
    "id": "arXiv:2204.07508",
    "title": "Initial analysis of the impact of the Ukrainian power grid  synchronization with Continental Europe",
    "abstract": "When Russia invaded Ukraine on the 24th of February 2022, this lead to many\nacts of solidarity with Ukraine, including support for its electricity system.\nJust 20 days after the invasion started, the Ukrainian and Moldovan power grids\nwere synchronized to the Continental European power grid to provide stability\nto these grids. Here, we present an initial analysis of how this\nsynchronization affected the statistics of the power grid frequency and\ncross-border flows of electric power within Continental Europe. We observe\nmostly small changes in the system, such as an increase in fluctuations, kept\nin check by an increase in control. We also observe changes in cross-border\nflows in and out of Ukraine and surrounding countries and the effect of the\nsynchronization with Continental Europe.",
    "descriptor": "\nComments: 7 pages, 6 figures\n",
    "authors": [
      "Philipp C. B\u00f6ttcher",
      "Leonardo Rydin Gorj\u00e3o",
      "Christian Beck",
      "Richard Jumar",
      "Heiko Maass",
      "Veit Hagenmeyer",
      "Dirk Witthaut",
      "Benjamin Sch\u00e4fer"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2204.07508"
  },
  {
    "id": "arXiv:2204.07520",
    "title": "Resource-Aware Distributed Submodular Maximization: A Paradigm for  Multi-Robot Decision-Making",
    "abstract": "We introduce the first algorithm for distributed decision-making that\nprovably balances the trade-off of centralization, for global near-optimality,\nvs. decentralization, for near-minimal on-board computation, communication, and\nmemory resources. We are motivated by the future of autonomy that involves\nheterogeneous robots collaborating in complex~tasks, such as image covering,\ntarget tracking, and area monitoring. Current algorithms, such as consensus\nalgorithms, are insufficient to fulfill this future: they achieve distributed\ncommunication only, at the expense of high communication, computation, and\nmemory overloads. A shift to resource-aware algorithms is needed, that can\naccount for each robot's on-board resources, independently. We provide the\nfirst resource-aware algorithm, Resource-Aware distributed Greedy (RAG). We\nfocus on maximization problems involving monotone and \"doubly\" submodular\nfunctions, a diminishing returns property. RAG has near-minimal on-board\nresource requirements. Each agent can afford to run the algorithm by adjusting\nthe size of its neighborhood, even if that means selecting actions in complete\nisolation. RAG has provable approximation performance, where each agent can\nindependently determine its contribution. All in all, RAG is the first\nalgorithm to quantify the trade-off of centralization, for global\nnear-optimality, vs. decentralization, for near-minimal on-board resource\nrequirements. To capture the trade-off, we introduce the notion of\nCentralization Of Information among non-Neighbors (COIN). We validate RAG in\nsimulated scenarios of image covering with mobile robots.",
    "descriptor": "\nComments: submitted for conference publication in March 2022\n",
    "authors": [
      "Zirui Xu",
      "Vasileios Tzoumas"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)",
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2204.07520"
  },
  {
    "id": "arXiv:2204.07526",
    "title": "Statistical-Computational Trade-offs in Tensor PCA and Related Problems  via Communication Complexity",
    "abstract": "Tensor PCA is a stylized statistical inference problem introduced by\nMontanari and Richard to study the computational difficulty of estimating an\nunknown parameter from higher-order moment tensors. Unlike its matrix\ncounterpart, Tensor PCA exhibits a statistical-computational gap, i.e., a\nsample size regime where the problem is information-theoretically solvable but\nconjectured to be computationally hard. This paper derives computational lower\nbounds on the run-time of memory bounded algorithms for Tensor PCA using\ncommunication complexity. These lower bounds specify a trade-off among the\nnumber of passes through the data sample, the sample size, and the memory\nrequired by any algorithm that successfully solves Tensor PCA. While the lower\nbounds do not rule out polynomial-time algorithms, they do imply that many\ncommonly-used algorithms, such as gradient descent and power method, must have\na higher iteration count when the sample size is not large enough. Similar\nlower bounds are obtained for Non-Gaussian Component Analysis, a family of\nstatistical estimation problems in which low-order moment tensors carry no\ninformation about the unknown parameter. Finally, stronger lower bounds are\nobtained for an asymmetric variant of Tensor PCA and related statistical\nestimation problems. These results explain why many estimators for these\nproblems use a memory state that is significantly larger than the effective\ndimensionality of the parameter of interest.",
    "descriptor": "",
    "authors": [
      "Rishabh Dudeja",
      "Daniel Hsu"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2204.07526"
  },
  {
    "id": "arXiv:2204.07532",
    "title": "Accurate ADMET Prediction with XGBoost",
    "abstract": "The absorption, distribution, metabolism, excretion, and toxicity (ADMET)\nproperties are important in drug discovery as they define efficacy and safety.\nHere, we apply an ensemble of features, including fingerprints and descriptors,\nand a tree-based machine learning model, extreme gradient boosting, for\naccurate ADMET prediction. Our model performs well in the Therapeutics Data\nCommons ADMET benchmark group. For 22 tasks, our model is ranked first in 10\ntasks and top 3 in 18 tasks.",
    "descriptor": "",
    "authors": [
      "Hao Tian",
      "Rajas Ketkar",
      "Peng Tao"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2204.07532"
  },
  {
    "id": "arXiv:2204.07550",
    "title": "Cryptographic Strain-Dependent Light Pattern Generators",
    "abstract": "Refractive freeform components are becoming increasingly relevant for\ngenerating controlled patterns of light, because of their capability to\nspatially-modulate optical signals with high efficiency and low background.\nHowever, the use of these devices is still limited by difficulties in\nmanufacturing macroscopic elements with complex, 3-dimensional (3D) surface\nreliefs. Here, 3D-printed and stretchable magic windows generating light\npatterns by refraction are introduced. The shape and, consequently, the light\ntexture achieved can be changed through controlled device strain. Cryptographic\nmagic windows are demonstrated through exemplary light patterns, including\nmicro-QR-codes, that are correctly projected and recognized upon strain gating\nwhile remaining cryptic for as-produced devices. The light pattern of\nmicro-QR-codes can also be projected by two coupled magic windows, with one of\nthem acting as the decryption key. Such novel, freeform elements with 3D shape\nand tailored functionalities is relevant for applications in illumination\ndesign, smart labels, anti-counterfeiting systems, and cryptographic\ncommunication.",
    "descriptor": "\nComments: 31 pages, 22 figures, Advanced Materials Technologies 2022\n",
    "authors": [
      "Francesca D'Elia",
      "Francesco Pisani",
      "Alessandro Tredicucci",
      "Dario Pisignano",
      "Andrea Camposeo"
    ],
    "subjectives": [
      "Optics (physics.optics)",
      "Materials Science (cond-mat.mtrl-sci)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2204.07550"
  },
  {
    "id": "arXiv:1811.02769",
    "title": "Online Exploration of an Unknown Region of Interest with a Team of  Aerial Robots",
    "abstract": "Comments: 24 pages, 11 figures",
    "descriptor": "\nComments: 24 pages, 11 figures\n",
    "authors": [
      "Yoonchang Sung",
      "Deeksha Dixit",
      "Pratap Tokekar"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/1811.02769"
  },
  {
    "id": "arXiv:1909.04746",
    "title": "Tighter Theory for Local SGD on Identical and Heterogeneous Data",
    "abstract": "Comments: AISTATS 2020. 31 pages, 1 algorithm, 5 theorems, 6 figures",
    "descriptor": "\nComments: AISTATS 2020. 31 pages, 1 algorithm, 5 theorems, 6 figures\n",
    "authors": [
      "Ahmed Khaled",
      "Konstantin Mishchenko",
      "Peter Richt\u00e1rik"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1909.04746"
  },
  {
    "id": "arXiv:1911.12426",
    "title": "Conditional Hierarchical Bayesian Tucker Decomposition for Genetic Data  Analysis",
    "abstract": "Comments: 32 pages",
    "descriptor": "\nComments: 32 pages\n",
    "authors": [
      "Adam Sandler",
      "Diego Klabjan",
      "Yuan Luo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1911.12426"
  },
  {
    "id": "arXiv:2001.11419",
    "title": "Grassmannian Optimization for Online Tensor Completion and Tracking with  the t-SVD",
    "abstract": "Comments: 19 pages, 4 figures, 3 tables",
    "descriptor": "\nComments: 19 pages, 4 figures, 3 tables\n",
    "authors": [
      "Kyle Gilman",
      "Davoud Ataee Tarzanagh",
      "Laura Balzano"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2001.11419"
  },
  {
    "id": "arXiv:2004.12187",
    "title": "Cost Automata, Safe Schemes, and Downward Closures",
    "abstract": "Comments: journal submission (revised version)",
    "descriptor": "\nComments: journal submission (revised version)\n",
    "authors": [
      "David Barozzini",
      "Lorenzo Clemente",
      "Thomas Colcombet",
      "Pawe\u0142 Parys"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2004.12187"
  },
  {
    "id": "arXiv:2006.05624",
    "title": "Adjoined Networks: A Training Paradigm with Applications to Network  Compression",
    "abstract": "Comments: Published at AAAI 2022 Spring Symposium on Machine Learning and Knowledge Engineering for Hybrid Intelligence Code available at: this https URL",
    "descriptor": "\nComments: Published at AAAI 2022 Spring Symposium on Machine Learning and Knowledge Engineering for Hybrid Intelligence Code available at: this https URL\n",
    "authors": [
      "Utkarsh Nath",
      "Shrinu Kushagra",
      "Yingzhen Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.05624"
  },
  {
    "id": "arXiv:2009.07462",
    "title": "PL-VINS: Real-Time Monocular Visual-Inertial SLAM with Point and Line  Features",
    "abstract": "Comments: Visual-Inertial SLAM, LSD, Lines, SLAM, VINS-Mono",
    "descriptor": "\nComments: Visual-Inertial SLAM, LSD, Lines, SLAM, VINS-Mono\n",
    "authors": [
      "Qiang Fu",
      "Jialong Wang",
      "Hongshan Yu",
      "Islam Ali",
      "Feng Guo",
      "Yijia He",
      "Hong Zhang"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2009.07462"
  },
  {
    "id": "arXiv:2009.09258",
    "title": "Can You Spot the Chameleon? Adversarially Camouflaging Images from  Co-Salient Object Detection",
    "abstract": "Can You Spot the Chameleon? Adversarially Camouflaging Images from  Co-Salient Object Detection",
    "descriptor": "",
    "authors": [
      "Ruijun Gao",
      "Qing Guo",
      "Felix Juefei-Xu",
      "Hongkai Yu",
      "Huazhu Fu",
      "Wei Feng",
      "Yang Liu",
      "Song Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2009.09258"
  },
  {
    "id": "arXiv:2009.09737",
    "title": "Consecutive Decoding for Speech-to-text Translation",
    "abstract": "Comments: Accepted by AAAI 2021, 11 pages, 3 figures, 13 tables",
    "descriptor": "\nComments: Accepted by AAAI 2021, 11 pages, 3 figures, 13 tables\n",
    "authors": [
      "Qianqian Dong",
      "Mingxuan Wang",
      "Hao Zhou",
      "Shuang Xu",
      "Bo Xu",
      "Lei Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2009.09737"
  },
  {
    "id": "arXiv:2009.13579",
    "title": "Novelty Search in Representational Space for Sample Efficient  Exploration",
    "abstract": "Comments: 10 pages + references + appendix. Oral presentation at NeurIPS 2020",
    "descriptor": "\nComments: 10 pages + references + appendix. Oral presentation at NeurIPS 2020\n",
    "authors": [
      "Ruo Yu Tao",
      "Vincent Fran\u00e7ois-Lavet",
      "Joelle Pineau"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2009.13579"
  },
  {
    "id": "arXiv:2011.10545",
    "title": "Two-Step Meta-Learning for Time-Series Forecasting Ensemble",
    "abstract": "Comments: Accepted to IEEE Access journal in April 22, 2021",
    "descriptor": "\nComments: Accepted to IEEE Access journal in April 22, 2021\n",
    "authors": [
      "Evaldas Vaiciukynas",
      "Paulius Danenas",
      "Vilius Kontrimas",
      "Rimantas Butleris"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2011.10545"
  },
  {
    "id": "arXiv:2012.12438",
    "title": "State of the Art of Adaptive Cruise Control and Stop and Go Systems",
    "abstract": "Comments: 26 pages, 5 figures",
    "descriptor": "\nComments: 26 pages, 5 figures\n",
    "authors": [
      "Emre Kural",
      "Tahsin Hacibekir",
      "Bilin Aksun-Guvenc"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2012.12438"
  },
  {
    "id": "arXiv:2101.08767",
    "title": "Undecidability and non-axiomatizability of modal many-valued logics",
    "abstract": "Undecidability and non-axiomatizability of modal many-valued logics",
    "descriptor": "",
    "authors": [
      "Amanda Vidal"
    ],
    "subjectives": [
      "Logic (math.LO)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2101.08767"
  },
  {
    "id": "arXiv:2102.03004",
    "title": "The Critical Mean-field Chayes-Machta Dynamics",
    "abstract": "The Critical Mean-field Chayes-Machta Dynamics",
    "descriptor": "",
    "authors": [
      "Antonio Blanca",
      "Alistair Sinclair",
      "Xusheng Zhang"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)",
      "Mathematical Physics (math-ph)"
    ],
    "url": "https://arxiv.org/abs/2102.03004"
  },
  {
    "id": "arXiv:2102.06200",
    "title": "Efficient neural networks for real-time modeling of analog dynamic range  compression",
    "abstract": "Comments: Updated and will appear at 152nd AES Convention (note title change)",
    "descriptor": "\nComments: Updated and will appear at 152nd AES Convention (note title change)\n",
    "authors": [
      "Christian J. Steinmetz",
      "Joshua D. Reiss"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2102.06200"
  },
  {
    "id": "arXiv:2102.08864",
    "title": "Automated Test-Case Generation for Solidity Smart Contracts: the AGSolT  Approach and its Evaluation",
    "abstract": "Comments: Currently under review at Journal of Software Testing, Verification and Reliability",
    "descriptor": "\nComments: Currently under review at Journal of Software Testing, Verification and Reliability\n",
    "authors": [
      "Stefan Driessen",
      "Dario Di Nucci",
      "Geert Monsieur",
      "Damian A. Tamburri",
      "Willem-Jan van den Heuvel"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2102.08864"
  },
  {
    "id": "arXiv:2102.10892",
    "title": "Non-Crossing Shortest Paths in Undirected Unweighted Planar Graphs in  Linear Time",
    "abstract": "Comments: 12 pages, 7 figures",
    "descriptor": "\nComments: 12 pages, 7 figures\n",
    "authors": [
      "Lorenzo Balzotti",
      "Paolo G. Franciosa"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2102.10892"
  },
  {
    "id": "arXiv:2104.00969",
    "title": "TubeR: Tubelet Transformer for Video Action Detection",
    "abstract": "Comments: Accepted at CVPR 2022 (Oral)",
    "descriptor": "\nComments: Accepted at CVPR 2022 (Oral)\n",
    "authors": [
      "Jiaojiao Zhao",
      "Yanyi Zhang",
      "Xinyu Li",
      "Hao Chen",
      "Shuai Bing",
      "Mingze Xu",
      "Chunhui Liu",
      "Kaustav Kundu",
      "Yuanjun Xiong",
      "Davide Modolo",
      "Ivan Marsic",
      "Cees G.M. Snoek",
      "Joseph Tighe"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2104.00969"
  },
  {
    "id": "arXiv:2104.01385",
    "title": "A Specification-Guided Framework for Temporal Logic Control of Nonlinear  Systems",
    "abstract": "Comments: To appear in IEEE Transactions on Automatic Control",
    "descriptor": "\nComments: To appear in IEEE Transactions on Automatic Control\n",
    "authors": [
      "Yinan Li",
      "Zhibing Sun",
      "Jun Liu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2104.01385"
  },
  {
    "id": "arXiv:2104.03461",
    "title": "Sublinear Time Spectral Density Estimation",
    "abstract": "Comments: Accepted to STOC'22",
    "descriptor": "\nComments: Accepted to STOC'22\n",
    "authors": [
      "Vladimir Braverman",
      "Aditya Krishnan",
      "Christopher Musco"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2104.03461"
  },
  {
    "id": "arXiv:2105.06912",
    "title": "QAConv: Question Answering on Informative Conversations",
    "abstract": "Comments: ACL 2022. Data and code are available at this https URL",
    "descriptor": "\nComments: ACL 2022. Data and code are available at this https URL\n",
    "authors": [
      "Chien-Sheng Wu",
      "Andrea Madotto",
      "Wenhao Liu",
      "Pascale Fung",
      "Caiming Xiong"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2105.06912"
  },
  {
    "id": "arXiv:2105.08966",
    "title": "Latent Gaussian Model Boosting",
    "abstract": "Latent Gaussian Model Boosting",
    "descriptor": "",
    "authors": [
      "Fabio Sigrist"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation (stat.CO)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.08966"
  },
  {
    "id": "arXiv:2106.05527",
    "title": "Soft Truncation: A Universal Training Technique of Score-based Diffusion  Model for High Precision Score Estimation",
    "abstract": "Comments: 25 pages, 17 figures",
    "descriptor": "\nComments: 25 pages, 17 figures\n",
    "authors": [
      "Dongjun Kim",
      "Seungjae Shin",
      "Kyungwoo Song",
      "Wanmo Kang",
      "Il-Chul Moon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.05527"
  },
  {
    "id": "arXiv:2106.07258",
    "title": "GitTables: A Large-Scale Corpus of Relational Tables",
    "abstract": "GitTables: A Large-Scale Corpus of Relational Tables",
    "descriptor": "",
    "authors": [
      "Madelon Hulsebos",
      "\u00c7a\u011fatay Demiralp",
      "Paul Groth"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.07258"
  },
  {
    "id": "arXiv:2106.11840",
    "title": "Quantum Computing -- from NISQ to PISQ",
    "abstract": "Comments: 11 pages, 5 figures",
    "descriptor": "\nComments: 11 pages, 5 figures\n",
    "authors": [
      "Koen Bertels",
      "Tamara Sarac",
      "Aritra Sarkar",
      "Imran Ashraf"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2106.11840"
  },
  {
    "id": "arXiv:2106.13927",
    "title": "Investigation of Bare-bones Algorithms from Quantum Perspective: A  Quantum Dynamical Global Optimizer",
    "abstract": "Comments: The paper may provide a new quantum perspective for studying a bare-bones intelligence algorithms",
    "descriptor": "\nComments: The paper may provide a new quantum perspective for studying a bare-bones intelligence algorithms\n",
    "authors": [
      "Peng Wang",
      "Gang Xin",
      "Fang Wang"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2106.13927"
  },
  {
    "id": "arXiv:2107.00329",
    "title": "Dispatchable Region for Active Distribution Networks Using Approximate  Second-Order Cone Relaxation",
    "abstract": "Dispatchable Region for Active Distribution Networks Using Approximate  Second-Order Cone Relaxation",
    "descriptor": "",
    "authors": [
      "Zhigang Li",
      "Wenjing Huang",
      "J. H. Zheng",
      "Q. H. Wu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2107.00329"
  },
  {
    "id": "arXiv:2107.01724",
    "title": "Scalable Zonotopic Under-approximation of Backward Reachable Sets for  Uncertain Linear Systems",
    "abstract": "Scalable Zonotopic Under-approximation of Backward Reachable Sets for  Uncertain Linear Systems",
    "descriptor": "",
    "authors": [
      "Liren Yang",
      "Necmiye Ozay"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2107.01724"
  },
  {
    "id": "arXiv:2107.08939",
    "title": "DHNet: Double MPEG-4 Compression Detection via Multiple DCT Histograms",
    "abstract": "Comments: Accepted to IEEE MultiMedia",
    "descriptor": "\nComments: Accepted to IEEE MultiMedia\n",
    "authors": [
      "Seung-Hun Nam",
      "Wonhyuk Ahn",
      "Myung-Joon Kwon",
      "Jihyeon Kang",
      "In-Jae Yu"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.08939"
  },
  {
    "id": "arXiv:2108.04108",
    "title": "Team Power Dynamics and Team Impact: New Perspectives on Scientific  Collaboration using Career Age as a Proxy for Team Power",
    "abstract": "Team Power Dynamics and Team Impact: New Perspectives on Scientific  Collaboration using Career Age as a Proxy for Team Power",
    "descriptor": "",
    "authors": [
      "Huimin Xu",
      "Yi Bu",
      "Meijun Liu",
      "Chenwei Zhang",
      "Mengyi Sun",
      "Yi Zhang",
      "Eric Meyer",
      "Eduardo Salas",
      "Ying Ding"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2108.04108"
  },
  {
    "id": "arXiv:2108.08406",
    "title": "Estimating distinguishability measures on quantum computers",
    "abstract": "Comments: v2: 36 pages, 16 figures, includes simulations of several algorithms using IBM Qiskit noiseless and noisy simulators",
    "descriptor": "\nComments: v2: 36 pages, 16 figures, includes simulations of several algorithms using IBM Qiskit noiseless and noisy simulators\n",
    "authors": [
      "Rochisha Agarwal",
      "Soorya Rethinasamy",
      "Kunal Sharma",
      "Mark M. Wilde"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2108.08406"
  },
  {
    "id": "arXiv:2109.00909",
    "title": "Sparsifying the Update Step in Graph Neural Networks",
    "abstract": "Comments: 11 pages",
    "descriptor": "\nComments: 11 pages\n",
    "authors": [
      "Johannes F. Lutzeyer",
      "Changmin Wu",
      "Michalis Vazirgiannis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2109.00909"
  },
  {
    "id": "arXiv:2109.06629",
    "title": "Investigation of condominium building collapse in Surfside, Florida: A  video feature tracking approach",
    "abstract": "Investigation of condominium building collapse in Surfside, Florida: A  video feature tracking approach",
    "descriptor": "",
    "authors": [
      "Xiangxiong Kong",
      "Danny Smyl"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2109.06629"
  },
  {
    "id": "arXiv:2109.08604",
    "title": "Enforcing fairness in private federated learning via the modified method  of differential multipliers",
    "abstract": "Comments: Presented at PriML workshop at NeurIPS 2021. 20 pages: 11 of main content, 3 of references, and 6 of supplementary material",
    "descriptor": "\nComments: Presented at PriML workshop at NeurIPS 2021. 20 pages: 11 of main content, 3 of references, and 6 of supplementary material\n",
    "authors": [
      "Borja Rodr\u00edguez-G\u00e1lvez",
      "Filip Granqvist",
      "Rogier van Dalen",
      "Matt Seigel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2109.08604"
  },
  {
    "id": "arXiv:2109.09574",
    "title": "On the representation of non-holonomic univariate power series",
    "abstract": "Comments: 20 pages; 26 references. Update: revised version",
    "descriptor": "\nComments: 20 pages; 26 references. Update: revised version\n",
    "authors": [
      "Bertrand Teguia Tabuguia",
      "Wolfram Koepf"
    ],
    "subjectives": [
      "Symbolic Computation (cs.SC)"
    ],
    "url": "https://arxiv.org/abs/2109.09574"
  },
  {
    "id": "arXiv:2109.09665",
    "title": "A Flexible Proof Format for SAT Solver-Elaborator Communication",
    "abstract": "A Flexible Proof Format for SAT Solver-Elaborator Communication",
    "descriptor": "",
    "authors": [
      "Seulkee Baek",
      "Mario Carneiro",
      "Marijn J.H. Heule"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2109.09665"
  },
  {
    "id": "arXiv:2109.11047",
    "title": "Cross-Modal Coherence for Text-to-Image Retrieval",
    "abstract": "Comments: This paper is published in AAAI-2022",
    "descriptor": "\nComments: This paper is published in AAAI-2022\n",
    "authors": [
      "Malihe Alikhani",
      "Fangda Han",
      "Hareesh Ravi",
      "Mubbasir Kapadia",
      "Vladimir Pavlovic",
      "Matthew Stone"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.11047"
  },
  {
    "id": "arXiv:2109.12171",
    "title": "NICE: Robust Scheduling through Reinforcement Learning-Guided Integer  Programming",
    "abstract": "Comments: Accepted in 36th AAAI Conference. 7 pages + 2 pages appendix, 1 figure. Code available at this https URL",
    "descriptor": "\nComments: Accepted in 36th AAAI Conference. 7 pages + 2 pages appendix, 1 figure. Code available at this https URL\n",
    "authors": [
      "Luke Kenworthy",
      "Siddharth Nayak",
      "Christopher Chin",
      "Hamsa Balakrishnan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.12171"
  },
  {
    "id": "arXiv:2110.01746",
    "title": "Effects of Multi-Aspect Online Reviews with Unobserved Confounders:  Estimation and Implication",
    "abstract": "Comments: 12 pages, 4 figures, 10 tables. Accepted to ICWSM'22",
    "descriptor": "\nComments: 12 pages, 4 figures, 10 tables. Accepted to ICWSM'22\n",
    "authors": [
      "Lu Cheng",
      "Ruocheng Guo",
      "Kasim Selcuk Candan",
      "Huan Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2110.01746"
  },
  {
    "id": "arXiv:2110.01775",
    "title": "Deep Instance Segmentation with Automotive Radar Detection Points",
    "abstract": "Deep Instance Segmentation with Automotive Radar Detection Points",
    "descriptor": "",
    "authors": [
      "Jianan Liu",
      "Weiyi Xiong",
      "Liping Bai",
      "Yuxuan Xia",
      "Tao Huang",
      "Wanli Ouyang",
      "Bing Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.01775"
  },
  {
    "id": "arXiv:2110.02529",
    "title": "On the Importance of Firth Bias Reduction in Few-Shot Classification",
    "abstract": "On the Importance of Firth Bias Reduction in Few-Shot Classification",
    "descriptor": "",
    "authors": [
      "Saba Ghaffari",
      "Ehsan Saleh",
      "David Forsyth",
      "Yu-xiong Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.02529"
  },
  {
    "id": "arXiv:2110.03310",
    "title": "Solving the Dirichlet problem for the Monge-Amp\u00e8re equation using  neural networks",
    "abstract": "Comments: 22 pages, 7 figures, 3 tables",
    "descriptor": "\nComments: 22 pages, 7 figures, 3 tables\n",
    "authors": [
      "Kaj Nystr\u00f6m",
      "Matias Vestberg"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.03310"
  },
  {
    "id": "arXiv:2110.04331",
    "title": "MusicNet: Compact Convolutional Neural Network for Real-time Background  Music Detection",
    "abstract": "MusicNet: Compact Convolutional Neural Network for Real-time Background  Music Detection",
    "descriptor": "",
    "authors": [
      "Chandan K.A. Reddy",
      "Vishak Gopa",
      "Harishchandra Dubey",
      "Sergiy Matusevych",
      "Ross Cutler",
      "Robert Aichner"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2110.04331"
  },
  {
    "id": "arXiv:2110.04391",
    "title": "Aura: Privacy-preserving augmentation to improve test set diversity in  noise suppression applications",
    "abstract": "Aura: Privacy-preserving augmentation to improve test set diversity in  noise suppression applications",
    "descriptor": "",
    "authors": [
      "Xavier Gitiaux",
      "Aditya Khant",
      "Ebrahim Beyrami",
      "Chandan Reddy",
      "Jayant Gupchup",
      "Ross Cutler"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Cryptography and Security (cs.CR)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2110.04391"
  },
  {
    "id": "arXiv:2110.11991",
    "title": "A Reinforcement Learning Approach to Parameter Selection for Distributed  Optimal Power Flow",
    "abstract": "A Reinforcement Learning Approach to Parameter Selection for Distributed  Optimal Power Flow",
    "descriptor": "",
    "authors": [
      "Sihan Zeng",
      "Alyssa Kody",
      "Youngdae Kim",
      "Kibaek Kim",
      "Daniel K. Molzahn"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.11991"
  },
  {
    "id": "arXiv:2110.14396",
    "title": "Multi-fidelity data fusion through parameter space reduction with  applications to automotive engineering",
    "abstract": "Comments: extended version",
    "descriptor": "\nComments: extended version\n",
    "authors": [
      "Francesco Romor",
      "Marco Tezzele",
      "Markus Mrosek",
      "Carsten Othmer",
      "Gianluigi Rozza"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.14396"
  },
  {
    "id": "arXiv:2110.14419",
    "title": "Towards a Theory of Justice for Artificial Intelligence",
    "abstract": "Comments: 12 pages",
    "descriptor": "\nComments: 12 pages\n",
    "authors": [
      "Iason Gabriel"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2110.14419"
  },
  {
    "id": "arXiv:2111.00009",
    "title": "Revisiting joint decoding based multi-talker speech recognition with DNN  acoustic model",
    "abstract": "Comments: submitted to Interspeech 2022",
    "descriptor": "\nComments: submitted to Interspeech 2022\n",
    "authors": [
      "Martin Kocour",
      "Kate\u0159ina \u017dmol\u00edkov\u00e1",
      "Lucas Ondel",
      "J\u00e1n \u0160vec",
      "Marc Delcroix",
      "Tsubasa Ochiai",
      "Luk\u00e1\u0161 Burget",
      "Jan \u010cernock\u00fd"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2111.00009"
  },
  {
    "id": "arXiv:2111.06483",
    "title": "Sequential Aggregation and Rematerialization: Distributed Full-batch  Training of Graph Neural Networks on Large Graphs",
    "abstract": "Sequential Aggregation and Rematerialization: Distributed Full-batch  Training of Graph Neural Networks on Large Graphs",
    "descriptor": "",
    "authors": [
      "Hesham Mostafa"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.06483"
  },
  {
    "id": "arXiv:2111.09888",
    "title": "Simple but Effective: CLIP Embeddings for Embodied AI",
    "abstract": "Comments: Published in CVPR 2022",
    "descriptor": "\nComments: Published in CVPR 2022\n",
    "authors": [
      "Apoorv Khandelwal",
      "Luca Weihs",
      "Roozbeh Mottaghi",
      "Aniruddha Kembhavi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.09888"
  },
  {
    "id": "arXiv:2111.10518",
    "title": "Towards Safe, Explainable, and Regulated Autonomous Driving",
    "abstract": "Comments: 8 pages",
    "descriptor": "\nComments: 8 pages\n",
    "authors": [
      "Shahin Atakishiyev",
      "Mohammad Salameh",
      "Hengshuai Yao",
      "Randy Goebel"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.10518"
  },
  {
    "id": "arXiv:2111.10541",
    "title": "Retrieve-then-extract Based Knowledge Graph Querying Using Graph Neural  Networks",
    "abstract": "Retrieve-then-extract Based Knowledge Graph Querying Using Graph Neural  Networks",
    "descriptor": "",
    "authors": [
      "Hanning Gao",
      "Lingfei Wu",
      "Po Hu",
      "Zhihua Wei",
      "Fangli Xu",
      "Bo Long"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2111.10541"
  },
  {
    "id": "arXiv:2111.11210",
    "title": "GCR: Gradient Coreset Based Replay Buffer Selection For Continual  Learning",
    "abstract": "Comments: Published at CVPR 2022 | Project Page: this https URL",
    "descriptor": "\nComments: Published at CVPR 2022 | Project Page: this https URL\n",
    "authors": [
      "Rishabh Tiwari",
      "Krishnateja Killamsetty",
      "Rishabh Iyer",
      "Pradeep Shenoy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.11210"
  },
  {
    "id": "arXiv:2111.11236",
    "title": "Nanorobot queue: Cooperative treatment of cancer based on team member  communication and image processing",
    "abstract": "Comments: 7pages,2figures",
    "descriptor": "\nComments: 7pages,2figures\n",
    "authors": [
      "Xinyu Zhou"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.11236"
  },
  {
    "id": "arXiv:2111.13853",
    "title": "Pre-training Methods in Information Retrieval",
    "abstract": "Pre-training Methods in Information Retrieval",
    "descriptor": "",
    "authors": [
      "Yixing Fan",
      "Xiaohui Xie",
      "Yinqiong Cai",
      "Jia Chen",
      "Xinyu Ma",
      "Xiangsheng Li",
      "Ruqing Zhang",
      "Jiafeng Guo",
      "Yiqun Liu"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2111.13853"
  },
  {
    "id": "arXiv:2111.14673",
    "title": "3D Compositional Zero-shot Learning with DeCompositional Consensus",
    "abstract": "3D Compositional Zero-shot Learning with DeCompositional Consensus",
    "descriptor": "",
    "authors": [
      "Muhammad Ferjad Naeem",
      "Evin P\u0131nar \u00d6rnek",
      "Yongqin Xian",
      "Luc Van Gool",
      "Federico Tombari"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.14673"
  },
  {
    "id": "arXiv:2112.00798",
    "title": "Fast Sparse Decision Tree Optimization via Reference Ensembles",
    "abstract": "Comments: Accepted by AAAI 2022",
    "descriptor": "\nComments: Accepted by AAAI 2022\n",
    "authors": [
      "Hayden McTavish",
      "Chudi Zhong",
      "Reto Achermann",
      "Ilias Karimalis",
      "Jacques Chen",
      "Cynthia Rudin",
      "Margo Seltzer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.00798"
  },
  {
    "id": "arXiv:2112.03184",
    "title": "HIVE: Evaluating the Human Interpretability of Visual Explanations",
    "abstract": "Comments: HIVE can be found at this https URL",
    "descriptor": "\nComments: HIVE can be found at this https URL\n",
    "authors": [
      "Sunnie S. Y. Kim",
      "Nicole Meister",
      "Vikram V. Ramaswamy",
      "Ruth Fong",
      "Olga Russakovsky"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.03184"
  },
  {
    "id": "arXiv:2112.04629",
    "title": "Transferability Properties of Graph Neural Networks",
    "abstract": "Comments: Submitted to IEEE TSP",
    "descriptor": "\nComments: Submitted to IEEE TSP\n",
    "authors": [
      "Luana Ruiz",
      "Luiz F. O. Chamon",
      "Alejandro Ribeiro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2112.04629"
  },
  {
    "id": "arXiv:2112.05744",
    "title": "More Control for Free! Image Synthesis with Semantic Diffusion Guidance",
    "abstract": "Comments: Project page this https URL",
    "descriptor": "\nComments: Project page this https URL\n",
    "authors": [
      "Xihui Liu",
      "Dong Huk Park",
      "Samaneh Azadi",
      "Gong Zhang",
      "Arman Chopikyan",
      "Yuxiao Hu",
      "Humphrey Shi",
      "Anna Rohrbach",
      "Trevor Darrell"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2112.05744"
  },
  {
    "id": "arXiv:2112.06197",
    "title": "Video as Conditional Graph Hierarchy for Multi-Granular Question  Answering",
    "abstract": "Comments: AAAI'22 (Oral)",
    "descriptor": "\nComments: AAAI'22 (Oral)\n",
    "authors": [
      "Junbin Xiao",
      "Angela Yao",
      "Zhiyuan Liu",
      "Yicong Li",
      "Wei Ji",
      "Tat-Seng Chua"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2112.06197"
  },
  {
    "id": "arXiv:2112.07115",
    "title": "Dynamic Coherence-Based EM Ray Tracing Simulations in Vehicular  Environments",
    "abstract": "Comments: 7 pages, 15 figures, conference",
    "descriptor": "\nComments: 7 pages, 15 figures, conference\n",
    "authors": [
      "Ruichen Wang",
      "Dinesh Manocha"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2112.07115"
  },
  {
    "id": "arXiv:2112.07910",
    "title": "Decoupling Zero-Shot Semantic Segmentation",
    "abstract": "Comments: Accepted by CVPR 2022",
    "descriptor": "\nComments: Accepted by CVPR 2022\n",
    "authors": [
      "Jian Ding",
      "Nan Xue",
      "Gui-Song Xia",
      "Dengxin Dai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.07910"
  },
  {
    "id": "arXiv:2112.08526",
    "title": "Invariance Through Inference",
    "abstract": "Comments: To appear in RSS 2022. Here's our project page: this https URL",
    "descriptor": "\nComments: To appear in RSS 2022. Here's our project page: this https URL\n",
    "authors": [
      "Takuma Yoneda",
      "Ge Yang",
      "Matthew R. Walter",
      "Bradly Stadie"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2112.08526"
  },
  {
    "id": "arXiv:2112.08879",
    "title": "Looking Outside the Box to Ground Language in 3D Scenes",
    "abstract": "Comments: First two authors contributed equally",
    "descriptor": "\nComments: First two authors contributed equally\n",
    "authors": [
      "Ayush Jain",
      "Nikolaos Gkanatsios",
      "Ishita Mediratta",
      "Katerina Fragkiadaki"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.08879"
  },
  {
    "id": "arXiv:2112.13194",
    "title": "Network-Aware 5G Edge Computing for Object Detection: Augmenting  Wearables to \"See\" More, Farther and Faster",
    "abstract": "Comments: Published in: IEEE Access ( Volume: 10)",
    "descriptor": "\nComments: Published in: IEEE Access ( Volume: 10)\n",
    "authors": [
      "Zhongzheng Yuan",
      "Tommy Azzino",
      "Yu Hao",
      "Yixuan Lyu",
      "Haoyang Pei",
      "Alain Boldini",
      "Marco Mezzavilla",
      "Mahya Beheshti",
      "Maurizio Porfiri",
      "Todd Hudson",
      "William Seiple",
      "Yi Fang",
      "Sundeep Rangan",
      "Yao Wang",
      "J.R. Rizzo"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2112.13194"
  },
  {
    "id": "arXiv:2201.11838",
    "title": "Clinical-Longformer and Clinical-BigBird: Transformers for long clinical  sequences",
    "abstract": "Clinical-Longformer and Clinical-BigBird: Transformers for long clinical  sequences",
    "descriptor": "",
    "authors": [
      "Yikuan Li",
      "Ramsey M. Wehbe",
      "Faraz S. Ahmad",
      "Hanyin Wang",
      "Yuan Luo"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2201.11838"
  },
  {
    "id": "arXiv:2202.02886",
    "title": "Leveraging Approximate Symbolic Models for Reinforcement Learning via  Skill Diversity",
    "abstract": "Leveraging Approximate Symbolic Models for Reinforcement Learning via  Skill Diversity",
    "descriptor": "",
    "authors": [
      "Lin Guan",
      "Sarath Sreedharan",
      "Subbarao Kambhampati"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.02886"
  },
  {
    "id": "arXiv:2202.03259",
    "title": "Theory-inspired Parameter Control Benchmarks for Dynamic Algorithm  Configuration",
    "abstract": "Theory-inspired Parameter Control Benchmarks for Dynamic Algorithm  Configuration",
    "descriptor": "",
    "authors": [
      "Andr\u00e9 Biedenkapp",
      "Nguyen Dang",
      "Martin S. Krejca",
      "Frank Hutter",
      "Carola Doerr"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.03259"
  },
  {
    "id": "arXiv:2202.03666",
    "title": "Approximating Gradients for Differentiable Quality Diversity in  Reinforcement Learning",
    "abstract": "Comments: Published as a conference paper at the 2022 Genetic and Evolutionary Computation Conference (GECCO '22); Online article available at this http URL",
    "descriptor": "\nComments: Published as a conference paper at the 2022 Genetic and Evolutionary Computation Conference (GECCO '22); Online article available at this http URL\n",
    "authors": [
      "Bryon Tjanaka",
      "Matthew C. Fontaine",
      "Julian Togelius",
      "Stefanos Nikolaidis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2202.03666"
  },
  {
    "id": "arXiv:2202.04349",
    "title": "Cartesian Tree Subsequence Matching",
    "abstract": "Cartesian Tree Subsequence Matching",
    "descriptor": "",
    "authors": [
      "Tsubasa Oizumi",
      "Takeshi Kai",
      "Takuya Mieno",
      "Shunsuke Inenaga",
      "Hiroki Arimura"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2202.04349"
  },
  {
    "id": "arXiv:2202.04981",
    "title": "Barwise Compression Schemes for Audio-Based Music Structure Analysis",
    "abstract": "Comments: Published at the 2022 Sound and Music Computing (SMC) conference, 8 pages, 6 figures, 1 table, code available at this https URL arXiv admin note: substantial text overlap with arXiv:2110.14437",
    "descriptor": "\nComments: Published at the 2022 Sound and Music Computing (SMC) conference, 8 pages, 6 figures, 1 table, code available at this https URL arXiv admin note: substantial text overlap with arXiv:2110.14437\n",
    "authors": [
      "Axel Marmoret",
      "J\u00e9r\u00e9my E. Cohen",
      "Fr\u00e9d\u00e9ric Bimbot"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2202.04981"
  },
  {
    "id": "arXiv:2202.08447",
    "title": "RePair Grammars are the Smallest Grammars for Fibonacci Words",
    "abstract": "RePair Grammars are the Smallest Grammars for Fibonacci Words",
    "descriptor": "",
    "authors": [
      "Takuya Mieno",
      "Shunsuke Inenaga",
      "Takashi Horiyama"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2202.08447"
  },
  {
    "id": "arXiv:2202.08952",
    "title": "An Energy-Efficient and Runtime-Reconfigurable FPGA-Based Accelerator  for Robotic Localization Systems",
    "abstract": "Comments: First three authors contributed equally. 2 pages, 6 figures, IEEE Custom Integrated Circuits Conference (CICC), April 24-27, 2022, Newport Beach, CA, USA",
    "descriptor": "\nComments: First three authors contributed equally. 2 pages, 6 figures, IEEE Custom Integrated Circuits Conference (CICC), April 24-27, 2022, Newport Beach, CA, USA\n",
    "authors": [
      "Qiang Liu",
      "Zishen Wan",
      "Bo Yu",
      "Weizhuang Liu",
      "Shaoshan Liu",
      "Arijit Raychowdhury"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2202.08952"
  },
  {
    "id": "arXiv:2202.10629",
    "title": "Model Reprogramming: Resource-Efficient Cross-Domain Machine Learning",
    "abstract": "Comments: Survey paper on model reprogramming; Project repository: this https URL",
    "descriptor": "\nComments: Survey paper on model reprogramming; Project repository: this https URL\n",
    "authors": [
      "Pin-Yu Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.10629"
  },
  {
    "id": "arXiv:2202.13591",
    "title": "Minimal Absent Words on Run-Length Encoded Strings",
    "abstract": "Comments: Accepted for CPM 2022",
    "descriptor": "\nComments: Accepted for CPM 2022\n",
    "authors": [
      "Tooru Akagi",
      "Kouta Okabe",
      "Takuya Mieno",
      "Yuto Nakashima",
      "Shunsuke Inenaga"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2202.13591"
  },
  {
    "id": "arXiv:2203.00145",
    "title": "Getting There and Back Again",
    "abstract": "Comments: 69 pages (final version with complete acknowledgments)",
    "descriptor": "\nComments: 69 pages (final version with complete acknowledgments)\n",
    "authors": [
      "Olivier Danvy"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2203.00145"
  },
  {
    "id": "arXiv:2203.05744",
    "title": "Semi-constraint Optimal Transport for Entity Alignment with Dangling  Cases",
    "abstract": "Comments: A fully revised version of \"An Accurate Unsupervised Method for Joint Entity Alignment and Dangling Entity Detection\", arXiv:2203.05147",
    "descriptor": "\nComments: A fully revised version of \"An Accurate Unsupervised Method for Joint Entity Alignment and Dangling Entity Detection\", arXiv:2203.05147\n",
    "authors": [
      "Shengxuan Luo",
      "Pengyu Cheng",
      "Sheng Yu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.05744"
  },
  {
    "id": "arXiv:2203.06558",
    "title": "AutoGPart: Intermediate Supervision Search for Generalizable 3D Part  Segmentation",
    "abstract": "Comments: 22 pages, CVPR 2022",
    "descriptor": "\nComments: 22 pages, CVPR 2022\n",
    "authors": [
      "Xueyi Liu",
      "Xiaomeng Xu",
      "Anyi Rao",
      "Chuang Gan",
      "Li Yi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.06558"
  },
  {
    "id": "arXiv:2203.06918",
    "title": "Uncertainty-Aware Text-to-Program for Question Answering on Structured  Electronic Health Records",
    "abstract": "Comments: In Proceedings of the Conference on Health, Inference, and Learning (CHIL 2022)",
    "descriptor": "\nComments: In Proceedings of the Conference on Health, Inference, and Learning (CHIL 2022)\n",
    "authors": [
      "Daeyoung Kim",
      "Seongsu Bae",
      "Seungho Kim",
      "Edward Choi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.06918"
  },
  {
    "id": "arXiv:2203.07029",
    "title": "SuperCone: Unified User Segmentation over Heterogeneous Experts via  Concept Meta-learning",
    "abstract": "SuperCone: Unified User Segmentation over Heterogeneous Experts via  Concept Meta-learning",
    "descriptor": "",
    "authors": [
      "Keqian Li",
      "Yifan Hu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.07029"
  },
  {
    "id": "arXiv:2203.08215",
    "title": "Auto-Gait: Automatic Ataxia Risk Assessment with Computer Vision on Gait  Task Videos",
    "abstract": "Auto-Gait: Automatic Ataxia Risk Assessment with Computer Vision on Gait  Task Videos",
    "descriptor": "",
    "authors": [
      "Wasifur Rahman",
      "Masum Hasan",
      "Md Saiful Islam",
      "Titilayo Olubajo",
      "Jeet Thaker",
      "Abdelrahman Abdelkader",
      "Phillip Yang",
      "Tetsuo Ashizawa",
      "Ehsan Hoque"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.08215"
  },
  {
    "id": "arXiv:2203.09047",
    "title": "Three-dimensional third-order gas-kinetic scheme on hybrid unstructured  meshes for Euler and Navier-Stokes equations",
    "abstract": "Three-dimensional third-order gas-kinetic scheme on hybrid unstructured  meshes for Euler and Navier-Stokes equations",
    "descriptor": "",
    "authors": [
      "Yaqing Yang",
      "Liang Pan",
      "Kun Xu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2203.09047"
  },
  {
    "id": "arXiv:2203.11675",
    "title": "Subset Sum in $O(n^{16}\\log(n))$",
    "abstract": "Comments: 7 pages, expands on Section 5.4 to replace and simplify large portions of the algorithm",
    "descriptor": "\nComments: 7 pages, expands on Section 5.4 to replace and simplify large portions of the algorithm\n",
    "authors": [
      "Rion Tolchin"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2203.11675"
  },
  {
    "id": "arXiv:2203.14463",
    "title": "Large-scale Bilingual Language-Image Contrastive Learning",
    "abstract": "Comments: Accepted by ICLRW2022",
    "descriptor": "\nComments: Accepted by ICLRW2022\n",
    "authors": [
      "Byungsoo Ko",
      "Geonmo Gu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.14463"
  },
  {
    "id": "arXiv:2203.16110",
    "title": "Weakly-supervised Temporal Path Representation Learning with Contrastive  Curriculum Learning -- Extended Version",
    "abstract": "Comments: This paper has been accepted by IEEE ICDE-22",
    "descriptor": "\nComments: This paper has been accepted by IEEE ICDE-22\n",
    "authors": [
      "Sean Bin Yang",
      "Chenjuan Guo",
      "Jilin Hu",
      "Bin Yang",
      "Jian Tang",
      "Christian S. Jensen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.16110"
  },
  {
    "id": "arXiv:2204.00036",
    "title": "A Statistical Decision-Theoretical Perspective on the Two-Stage Approach  to Parameter Estimation",
    "abstract": "Comments: 7 pages, 6 figures, 1 table",
    "descriptor": "\nComments: 7 pages, 6 figures, 1 table\n",
    "authors": [
      "Braghadeesh Lakshminarayanan",
      "Cristian R. Rojas"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Systems and Control (eess.SY)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2204.00036"
  },
  {
    "id": "arXiv:2204.00588",
    "title": "Prefix-Free Coding for LQG Control",
    "abstract": "Comments: Under submission to the IEEE Journal on Selected Areas in Information Theory (Modern Compression Issue)",
    "descriptor": "\nComments: Under submission to the IEEE Journal on Selected Areas in Information Theory (Modern Compression Issue)\n",
    "authors": [
      "Travis Cuvelier",
      "Takashi Tanaka",
      "Robert W. Heath Jr"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2204.00588"
  },
  {
    "id": "arXiv:2204.00804",
    "title": "Diffusion dynamics of competing information on networks",
    "abstract": "Comments: 5 pages + supplemental material",
    "descriptor": "\nComments: 5 pages + supplemental material\n",
    "authors": [
      "Teruyoshi Kobayashi"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2204.00804"
  },
  {
    "id": "arXiv:2204.01671",
    "title": "Exemplar-based Pattern Synthesis with Implicit Periodic Field Network",
    "abstract": "Comments: 8 pages, CVPR 2022",
    "descriptor": "\nComments: 8 pages, CVPR 2022\n",
    "authors": [
      "Haiwei Chen",
      "Jiayi Liu",
      "Weikai Chen",
      "Shichen Liu",
      "Yajie Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.01671"
  },
  {
    "id": "arXiv:2204.01705",
    "title": "Learning to Accelerate by the Methods of Step-size Planning",
    "abstract": "Learning to Accelerate by the Methods of Step-size Planning",
    "descriptor": "",
    "authors": [
      "Hengshuai Yao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2204.01705"
  },
  {
    "id": "arXiv:2204.03227",
    "title": "Accelerating Attention through Gradient-Based Learned Runtime Pruning",
    "abstract": "Comments: First three authors contributed equally; published at ISCA 2022",
    "descriptor": "\nComments: First three authors contributed equally; published at ISCA 2022\n",
    "authors": [
      "Zheng Li",
      "Soroush Ghodrati",
      "Amir Yazdanbakhsh",
      "Hadi Esmaeilzadeh",
      "Mingu Kang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Hardware Architecture (cs.AR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.03227"
  },
  {
    "id": "arXiv:2204.03281",
    "title": "Single-shot Embedding Dimension Search in Recommender System",
    "abstract": "Single-shot Embedding Dimension Search in Recommender System",
    "descriptor": "",
    "authors": [
      "Liang Qu",
      "Yonghong Ye",
      "Ningzhi Tang",
      "Lixin Zhang",
      "Yuhui Shi",
      "Hongzhi Yin"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2204.03281"
  },
  {
    "id": "arXiv:2204.03316",
    "title": "Structured Gradient Descent for Fast Robust Low-Rank Hankel Matrix  Completion",
    "abstract": "Structured Gradient Descent for Fast Robust Low-Rank Hankel Matrix  Completion",
    "descriptor": "",
    "authors": [
      "HanQin Cai",
      "Jian-Feng Cai",
      "Juntao You"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2204.03316"
  },
  {
    "id": "arXiv:2204.03331",
    "title": "Sparse Optical Flow-Based Line Feature Tracking",
    "abstract": "Sparse Optical Flow-Based Line Feature Tracking",
    "descriptor": "",
    "authors": [
      "Qiang Fu",
      "Hongshan Yu",
      "Islam Ali",
      "Hong Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.03331"
  },
  {
    "id": "arXiv:2204.03550",
    "title": "Capacity Analysis of Intersections When CAVs Crossing in a Collaborative  and Lane-Free Order",
    "abstract": "Comments: 11 pages, 13 figures, Journal paper",
    "descriptor": "\nComments: 11 pages, 13 figures, Journal paper\n",
    "authors": [
      "Mahdi Amouzadi",
      "Mobolaji Olawumi Orisatoki",
      "Arash M. Dizqah"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Multiagent Systems (cs.MA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2204.03550"
  },
  {
    "id": "arXiv:2204.04358",
    "title": "Segmenting across places: The need for fair transfer learning with  satellite imagery",
    "abstract": "Segmenting across places: The need for fair transfer learning with  satellite imagery",
    "descriptor": "",
    "authors": [
      "Miao Zhang",
      "Harvineet Singh",
      "Lazarus Chok",
      "Rumi Chunara"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.04358"
  },
  {
    "id": "arXiv:2204.05033",
    "title": "Information in probability: Another information-theoretic proof of a  finite de Finetti theorem",
    "abstract": "Comments: Small changes from the previous version, including a few more references and clarifications in the Introduction",
    "descriptor": "\nComments: Small changes from the previous version, including a few more references and clarifications in the Introduction\n",
    "authors": [
      "Lampros Gavalakis",
      "Ioannis Kontoyiannis"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2204.05033"
  },
  {
    "id": "arXiv:2204.05205",
    "title": "Rethinking Machine Learning Model Evaluation in Pathology",
    "abstract": "Comments: ICLR 2022 ML Evaluation Workshop",
    "descriptor": "\nComments: ICLR 2022 ML Evaluation Workshop\n",
    "authors": [
      "Syed Ashar Javed",
      "Dinkar Juyal",
      "Zahil Shanis",
      "Shreya Chakraborty",
      "Harsha Pokkalla",
      "Aaditya Prakash"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.05205"
  },
  {
    "id": "arXiv:2204.05255",
    "title": "Narcissus: A Practical Clean-Label Backdoor Attack with Limited  Information",
    "abstract": "Comments: 13 pages of the main text",
    "descriptor": "\nComments: 13 pages of the main text\n",
    "authors": [
      "Yi Zeng",
      "Minzhou Pan",
      "Hoang Anh Just",
      "Lingjuan Lyu",
      "Meikang Qiu",
      "Ruoxi Jia"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.05255"
  },
  {
    "id": "arXiv:2204.05423",
    "title": "Automated Task Updates of Temporal Logic Specifications for  Heterogeneous Robots",
    "abstract": "Comments: Fixed formatting",
    "descriptor": "\nComments: Fixed formatting\n",
    "authors": [
      "Amy Fang",
      "Hadas Kress-Gazit"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2204.05423"
  },
  {
    "id": "arXiv:2204.06357",
    "title": "Linear Programs with Polynomial Coefficients and Applications to 1D  Cellular Automata",
    "abstract": "Linear Programs with Polynomial Coefficients and Applications to 1D  Cellular Automata",
    "descriptor": "",
    "authors": [
      "Guy Bresler",
      "Chenghao Guo",
      "Yury Polyanskiy"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Complexity (cs.CC)",
      "Formal Languages and Automata Theory (cs.FL)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2204.06357"
  },
  {
    "id": "arXiv:2204.06677",
    "title": "Dynamic Schema Graph Fusion Network for Multi-Domain Dialogue State  Tracking",
    "abstract": "Comments: Accepted by ACL 2022",
    "descriptor": "\nComments: Accepted by ACL 2022\n",
    "authors": [
      "Yue Feng",
      "Aldo Lipani",
      "Fanghua Ye",
      "Qiang Zhang",
      "Emine Yilmaz"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2204.06677"
  },
  {
    "id": "arXiv:2204.06718",
    "title": "Learning Convolutional Neural Networks in the Frequency Domain",
    "abstract": "Learning Convolutional Neural Networks in the Frequency Domain",
    "descriptor": "",
    "authors": [
      "Hengyue Pan",
      "Yixin Chen",
      "Xin Niu",
      "Wenbo Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.06718"
  },
  {
    "id": "arXiv:2204.06878",
    "title": "Accumulate: An identity-based blockchain protocol with cross-chain  support, human-readable addresses, and key management capabilities",
    "abstract": "Comments: Accumulate Whitepaper",
    "descriptor": "\nComments: Accumulate Whitepaper\n",
    "authors": [
      "Kyle Michelson",
      "Anjali Sridharan",
      "Umut Can Cabuk",
      "Ethan Reesor",
      "Ben Stolman",
      "Drew Mailen",
      "Dennis Bunfield",
      "Jay Smith",
      "Paul Snow"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Databases (cs.DB)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2204.06878"
  },
  {
    "id": "arXiv:2204.06893",
    "title": "Challenges for Open-domain Targeted Sentiment Analysis",
    "abstract": "Challenges for Open-domain Targeted Sentiment Analysis",
    "descriptor": "",
    "authors": [
      "Yun Luo",
      "Hongjie Cai",
      "Linyi Yang",
      "Yanxia Qin",
      "Rui Xia",
      "Yue Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.06893"
  },
  {
    "id": "arXiv:2204.06969",
    "title": "Manually Acquiring Targets from Multiple Viewpoints Using Video Feedback",
    "abstract": "Comments: Accepted for publication in Human Factors",
    "descriptor": "\nComments: Accepted for publication in Human Factors\n",
    "authors": [
      "Bailey Ramesh",
      "Anna Konstant",
      "Pragathi Praveena",
      "Emmanuel Senft",
      "Michael Gleicher",
      "Bilge Mutlu",
      "Michael Zinn",
      "Robert G. Radwin"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2204.06969"
  },
  {
    "id": "arXiv:2204.07028",
    "title": "Exploring the Distributed Knowledge Congruence in Proxy-data-free  Federated Distillation",
    "abstract": "Comments: 19 pages, 7 tables, 8 figures",
    "descriptor": "\nComments: 19 pages, 7 tables, 8 figures\n",
    "authors": [
      "Zhiyuan Wu",
      "Sheng Sun",
      "Yuwei Wang",
      "Min Liu",
      "Qingxiang Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.07028"
  }
]
[
  {
    "id": "arXiv:2203.16535",
    "title": "Parallel framework for Dynamic Domain Decomposition of Data Assimilation  problems a case study on Kalman Filter algorithm",
    "abstract": "We focus on Partial Differential Equation (PDE) based Data Assimilatio\nproblems (DA) solved by means of variational approaches and Kalman filter\nalgorithm. Recently, we presented a Domain Decomposition framework (we call it\nDD-DA, for short) performing a decomposition of the whole physical domain along\nspace and time directions, and joining the idea of Schwarz' methods and\nparallel in time approaches. For effective parallelization of DD-DA algorithms,\nthe computational load assigned to subdomains must be equally distributed.\nUsually computational cost is proportional to the amount of data entities\nassigned to partitions. Good quality partitioning also requires the volume of\ncommunication during calculation to be kept at its minimum. In order to deal\nwith DD-DA problems where the observations are nonuniformly distributed and\ngeneral sparse, in the present work we employ a parallel load balancing\nalgorithm based on adaptive and dynamic defining of boundaries of DD -- which\nis aimed to balance workload according to data location. We call it DyDD. As\nthe numerical model underlying DA problems arising from the so-called\ndiscretize-then-optimize approach is the constrained least square model (CLS),\nwe will use CLS as a reference state estimation problem and we validate DyDD on\ndifferent scenarios.",
    "descriptor": "",
    "authors": [
      "Rosalba Cacciapuoti",
      "Luisa D'Amore"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.16535"
  },
  {
    "id": "arXiv:2203.16536",
    "title": "Recent improvements of ASR models in the face of adversarial attacks",
    "abstract": "Like many other tasks involving neural networks, Speech Recognition models\nare vulnerable to adversarial attacks. However recent research has pointed out\ndifferences between attacks and defenses on ASR models compared to image\nmodels. Improving the robustness of ASR models requires a paradigm shift from\nevaluating attacks on one or a few models to a systemic approach in evaluation.\nWe lay the ground for such research by evaluating on various architectures a\nrepresentative set of adversarial attacks: targeted and untargeted,\noptimization and speech processing-based, white-box, black-box and targeted\nattacks. Our results show that the relative strengths of different attack\nalgorithms vary considerably when changing the model architecture, and that the\nresults of some attacks are not to be blindly trusted. They also indicate that\ntraining choices such as self-supervised pretraining can significantly impact\nrobustness by enabling transferable perturbations. We release our source code\nas a package that should help future research in evaluating their attacks and\ndefenses.",
    "descriptor": "\nComments: Submitted to Interspeech 2022\n",
    "authors": [
      "Raphael Olivier",
      "Bhiksha Raj"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.16536"
  },
  {
    "id": "arXiv:2203.16537",
    "title": "Efficient Localness Transformer for Smart Sensor-Based Energy  Disaggregation",
    "abstract": "Modern smart sensor-based energy management systems leverage non-intrusive\nload monitoring (NILM) to predict and optimize appliance load distribution in\nreal-time. NILM, or energy disaggregation, refers to the decomposition of\nelectricity usage conditioned on the aggregated power signals (i.e., smart\nsensor on the main channel). Based on real-time appliance power prediction\nusing sensory technology, energy disaggregation has great potential to increase\nelectricity efficiency and reduce energy expenditure. With the introduction of\ntransformer models, NILM has achieved significant improvements in predicting\ndevice power readings. Nevertheless, transformers are less efficient due to\nO(l^2) complexity w.r.t. sequence length l. Moreover, transformers can fail to\ncapture local signal patterns in sequence-to-point settings due to the lack of\ninductive bias in local context. In this work, we propose an efficient\nlocalness transformer for non-intrusive load monitoring (ELTransformer).\nSpecifically, we leverage normalization functions and switch the order of\nmatrix multiplication to approximate self-attention and reduce computational\ncomplexity. Additionally, we introduce localness modeling with sparse local\nattention heads and relative position encodings to enhance the model capacity\nin extracting short-term local patterns. To the best of our knowledge,\nELTransformer is the first NILM model that addresses computational complexity\nand localness modeling in NILM. With extensive experiments and quantitative\nanalyses, we demonstrate the efficiency and effectiveness of the the proposed\nELTransformer with considerable improvements compared to state-of-the-art\nbaselines.",
    "descriptor": "\nComments: Accepted to DCOSS 2022\n",
    "authors": [
      "Zhenrui Yue",
      "Huimin Zeng",
      "Ziyi Kou",
      "Lanyu Shang",
      "Dong Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2203.16537"
  },
  {
    "id": "arXiv:2203.16538",
    "title": "Machine Learning Approaches for Non-Intrusive Home Absence Detection  Based on Appliance Electrical Use",
    "abstract": "Home absence detection is an emerging field on smart home installations.\nIdentifying whether or not the residents of the house are present, is important\nin numerous scenarios. Possible scenarios include but are not limited to:\nelderly people living alone, people suffering from dementia, home quarantine.\nThe majority of published papers focus on either pressure / door sensors or\ncameras in order to detect outing events. Although the aforementioned\napproaches provide solid results, they are intrusive and require modifications\nfor sensor placement. In our work, appliance electrical use is investigated as\na means for detecting the presence or absence of residents. The energy use is\nthe result of power disaggregation, a non intrusive / non invasive sensing\nmethod. Since a dataset providing energy data and ground truth for home absence\nis not available, artificial outing events were introduced on the UK-DALE\ndataset, a well known dataset for Non Intrusive Load Monitoring (NILM). Several\nmachine learning algorithms were evaluated using the generated dataset.\nBenchmark results have shown that home absence detection using appliance power\nconsumption is feasible.",
    "descriptor": "\nComments: 20 pages,submitted to \"Expert Systems with Applications\"\n",
    "authors": [
      "Athanasios Lentzas",
      "Dimitris Vrakas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2203.16538"
  },
  {
    "id": "arXiv:2203.16539",
    "title": "Identification of diffracted vortex beams at different propagation  distances using deep learning",
    "abstract": "Orbital angular momentum of light is regarded as a valuable resource in\nquantum technology, especially in quantum communication and quantum sensing and\nranging. However, the OAM state of light is susceptible to undesirable\nexperimental conditions such as propagation distance and phase distortions,\nwhich hinders the potential for the realistic implementation of relevant\ntechnologies. In this article, we exploit an enhanced deep learning neural\nnetwork to identify different OAM modes of light at multiple propagation\ndistances with phase distortions. Specifically, our trained deep learning\nneural network can efficiently identify the vortex beam's topological charge\nand propagation distance with 97% accuracy. Our technique has important\nimplications for OAM based communication and sensing protocols.",
    "descriptor": "\nComments: 9 pages, 4 figures\n",
    "authors": [
      "Heng Lv",
      "Yan Guo",
      "Zi-Xiang Yang",
      "Chunling Ding",
      "Wu-Hao Cai",
      "Chenglong You",
      "Rui-Bo Jin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Optics (physics.optics)"
    ],
    "url": "https://arxiv.org/abs/2203.16539"
  },
  {
    "id": "arXiv:2203.16540",
    "title": "Mind the gap: Challenges of deep learning approaches to Theory of Mind",
    "abstract": "Theory of Mind is an essential ability of humans to infer the mental states\nof others. Here we provide a coherent summary of the potential, current\nprogress, and problems of deep learning approaches to Theory of Mind. We\nhighlight that many current findings can be explained through shortcuts. These\nshortcuts arise because the tasks used to investigate Theory of Mind in deep\nlearning systems have been too narrow. Thus, we encourage researchers to\ninvestigate Theory of Mind in complex open-ended environments. Furthermore, to\ninspire future deep learning systems we provide a concise overview of prior\nwork done in humans. We further argue that when studying Theory of Mind with\ndeep learning, the research's main focus and contribution ought to be opening\nup the network's representations. We recommend researchers use tools from the\nfield of interpretability of AI to study the relationship between different\nnetwork components and aspects of Theory of Mind.",
    "descriptor": "",
    "authors": [
      "Jaan Aru",
      "Aqeel Labash",
      "Oriol Corcoll",
      "Raul Vicente"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2203.16540"
  },
  {
    "id": "arXiv:2203.16542",
    "title": "Towards Multimodal Depth Estimation from Light Fields",
    "abstract": "Light field applications, especially light field rendering and depth\nestimation, developed rapidly in recent years. While state-of-the-art light\nfield rendering methods handle semi-transparent and reflective objects well,\ndepth estimation methods either ignore these cases altogether or only deliver a\nweak performance. We argue that this is due current methods only considering a\nsingle \"true\" depth, even when multiple objects at different depths contributed\nto the color of a single pixel. Based on the simple idea of outputting a\nposterior depth distribution instead of only a single estimate, we develop and\nexplore several different deep-learning-based approaches to the problem.\nAdditionally, we contribute the first \"multimodal light field depth dataset\"\nthat contains the depths of all objects which contribute to the color of a\npixel. This allows us to supervise the multimodal depth prediction and also\nvalidate all methods by measuring the KL divergence of the predicted\nposteriors. With our thorough analysis and novel dataset, we aim to start a new\nline of depth estimation research that overcomes some of the long-standing\nlimitations of this field.",
    "descriptor": "",
    "authors": [
      "Titus Leistner",
      "Radek Mackowiak",
      "Lynton Ardizzone",
      "Ullrich K\u00f6the",
      "Carsten Rother"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.16542"
  },
  {
    "id": "arXiv:2203.16569",
    "title": "Generating Scientific Articles with Machine Learning",
    "abstract": "In recent years, the field of machine learning has seen rapid growth, with\napplications in a variety of domains, including image recognition, natural\nlanguage processing, and predictive modeling. In this paper, we explore the\napplication of machine learning to the generation of scientific articles. We\npresent a method for using machine learning to generate scientific articles\nbased on a data set of scientific papers. The method uses a machine-learning\nalgorithm to learn the structure of a scientific article and a set of training\ndata consisting of scientific papers. The machine-learning algorithm is used to\ngenerate a scientific article based on the data set of scientific papers. We\nevaluate the performance of the method by comparing the generated article to a\nset of manually written articles. The results show that the machine-generated\narticle is of similar quality to the manually written articles.",
    "descriptor": "\nComments: Happy April Fools!\n",
    "authors": [
      "Eliot H. Ayache",
      "Conor M.B. Omand"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.16569"
  },
  {
    "id": "arXiv:2203.16573",
    "title": "Efficient Computation of Extended Surface Sources",
    "abstract": "Source extension is a reformulation of inverse problems in wave propagation,\nthat at least in some cases leads to computationally tractable iterative\nsolution methods. The core subproblem in all source extension methods is the\nsolution of a linear inverse problem for a source (right hand side in a system\nof wave equations) through minimization of data error in the least squares\nsense with soft imposition of physical constraints on the source via an\nadditive quadratic penalty. A variant of the time reversal method from\nphotoacoustic tomography provides an approximate solution that can be used to\nprecondition Krylov space iteration for rapid convergence to the solution of\nthis subproblem. An acoustic 2D example for sources supported on a surface,\nwith a soft contraint enforcing point support, illustrates the effectiveness of\nthis preconditioner.",
    "descriptor": "\nComments: 53 pages, 28 figures\n",
    "authors": [
      "William W. Symes"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2203.16573"
  },
  {
    "id": "arXiv:2203.16574",
    "title": "Graph Refinement for Coreference Resolution",
    "abstract": "The state-of-the-art models for coreference resolution are based on\nindependent mention pair-wise decisions. We propose a modelling approach that\nlearns coreference at the document-level and takes global decisions. For this\npurpose, we model coreference links in a graph structure where the nodes are\ntokens in the text, and the edges represent the relationship between them. Our\nmodel predicts the graph in a non-autoregressive manner, then iteratively\nrefines it based on previous predictions, allowing global dependencies between\ndecisions. The experimental results show improvements over various baselines,\nreinforcing the hypothesis that document-level information improves conference\nresolution.",
    "descriptor": "",
    "authors": [
      "Lesly Miculicich",
      "James Henderson"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.16574"
  },
  {
    "id": "arXiv:2203.16577",
    "title": "Calibrating constitutive models with full-field data via physics  informed neural networks",
    "abstract": "The calibration of solid constitutive models with full-field experimental\ndata is a long-standing challenge, especially in materials which undergo large\ndeformation. In this paper, we propose a physics-informed deep-learning\nframework for the discovery of constitutive model parameterizations given\nfull-field displacement data and global force-displacement data. Contrary to\nthe majority of recent literature in this field, we work with the weak form of\nthe governing equations rather than the strong form to impose physical\nconstraints upon the neural network predictions. The approach presented in this\npaper is computationally efficient, suitable for irregular geometric domains,\nand readily ingests displacement data without the need for interpolation onto a\ncomputational grid. A selection of canonical hyperelastic materials models\nsuitable for different material classes is considered including the\nNeo-Hookean, Gent, and Blatz-Ko constitutive models as exemplars for general\nhyperelastic behavior, polymer behavior with lock-up, and compressible foam\nbehavior respectively. We demonstrate that physics informed machine learning is\nan enabling technology and may shift the paradigm of how full-field\nexperimental data is utilized to calibrate constitutive models under finite\ndeformations.",
    "descriptor": "",
    "authors": [
      "Craig M. Hamel",
      "Kevin N. Long",
      "Sharlotte L.B. Kramer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.16577"
  },
  {
    "id": "arXiv:2203.16578",
    "title": "Code Switched and Code Mixed Speech Recognition for Indic languages",
    "abstract": "Training multilingual automatic speech recognition (ASR) systems is\nchallenging because acoustic and lexical information is typically language\nspecific. Training multilingual system for Indic languages is even more tougher\ndue to lack of open source datasets and results on different approaches. We\ncompare the performance of end to end multilingual speech recognition system to\nthe performance of monolingual models conditioned on language identification\n(LID). The decoding information from a multilingual model is used for language\nidentification and then combined with monolingual models to get an improvement\nof 50% WER across languages. We also propose a similar technique to solve the\nCode Switched problem and achieve a WER of 21.77 and 28.27 over Hindi-English\nand Bengali-English respectively. Our work talks on how transformer based ASR\nespecially wav2vec 2.0 can be applied in developing multilingual ASR and code\nswitched ASR for Indic languages.",
    "descriptor": "\nComments: This paper for submitted to Interspeech 2022\n",
    "authors": [
      "Harveen Singh Chadha",
      "Priyanshi Shah",
      "Ankur Dhuriya",
      "Neeraj Chhimwal",
      "Anirudh Gupta",
      "Vivek Raghavan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.16578"
  },
  {
    "id": "arXiv:2203.16582",
    "title": "Factored Adaptation for Non-Stationary Reinforcement Learning",
    "abstract": "Dealing with non-stationarity in environments (i.e., transition dynamics) and\nobjectives (i.e., reward functions) is a challenging problem that is crucial in\nreal-world applications of reinforcement learning (RL). Most existing\napproaches only focus on families of stationary MDPs, in which the\nnon-stationarity is episodic, i.e., the change is only possible across\nepisodes. The few works that do consider non-stationarity without a specific\nboundary, i.e., also allow for changes within an episode, model the changes\nmonolithically in a single shared embedding vector. In this paper, we propose\nFactored Adaptation for Non-Stationary RL (FANS-RL), a factored adaption\napproach that explicitly learns the individual latent change factors affecting\nthe transition dynamics and reward functions. FANS-RL learns jointly the\nstructure of a factored MDP and a factored representation of the time-varying\nchange factors, as well as the specific state components that they affect, via\na factored non-stationary variational autoencoder. Through this general\nframework, we can consider general non-stationary scenarios with different\nchanging function types and changing frequency. Experimental results\ndemonstrate that FANS-RL outperforms existing approaches in terms of rewards,\ncompactness of the latent state representation and robustness to varying\ndegrees of non-stationarity.",
    "descriptor": "\nComments: 20 pages, 11 figures\n",
    "authors": [
      "Fan Feng",
      "Biwei Huang",
      "Kun Zhang",
      "Sara Magliacane"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.16582"
  },
  {
    "id": "arXiv:2203.16586",
    "title": "Counterfactual Cycle-Consistent Learning for Instruction Following and  Generation in Vision-Language Navigation",
    "abstract": "Since the rise of vision-language navigation (VLN), great progress has been\nmade in instruction following -- building a follower to navigate environments\nunder the guidance of instructions. However, far less attention has been paid\nto the inverse task: instruction generation -- learning a speaker~to generate\ngrounded descriptions for navigation routes. Existing VLN methods train a\nspeaker independently and often treat it as a data augmentation tool to\nstrengthen the follower while ignoring rich cross-task relations. Here we\ndescribe an approach that learns the two tasks simultaneously and exploits\ntheir intrinsic correlations to boost the training of each: the follower judges\nwhether the speaker-created instruction explains the original navigation route\ncorrectly, and vice versa. Without the need of aligned instruction-path pairs,\nsuch cycle-consistent learning scheme is complementary to task-specific\ntraining targets defined on labeled data, and can also be applied over\nunlabeled paths (sampled without paired instructions). Another agent,\ncalled~creator is added to generate counterfactual environments. It greatly\nchanges current scenes yet leaves novel items -- which are vital for the\nexecution of original instructions -- unchanged. Thus more informative training\nscenes are synthesized and the three agents compose a powerful VLN learning\nsystem. Extensive experiments on a standard benchmark show that our approach\nimproves the performance of various follower models and produces accurate\nnavigation instructions.",
    "descriptor": "\nComments: Accepted to CVPR 2022\n",
    "authors": [
      "Hanqing Wang",
      "Wei Liang",
      "Jianbing Shen",
      "Luc Van Gool",
      "Wenguan Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.16586"
  },
  {
    "id": "arXiv:2203.16588",
    "title": "Constrained Few-shot Class-incremental Learning",
    "abstract": "Continually learning new classes from fresh data without forgetting previous\nknowledge of old classes is a very challenging research problem. Moreover, it\nis imperative that such learning must respect certain memory and computational\nconstraints such as (i) training samples are limited to only a few per class,\n(ii) the computational cost of learning a novel class remains constant, and\n(iii) the memory footprint of the model grows at most linearly with the number\nof classes observed. To meet the above constraints, we propose C-FSCIL, which\nis architecturally composed of a frozen meta-learned feature extractor, a\ntrainable fixed-size fully connected layer, and a rewritable dynamically\ngrowing memory that stores as many vectors as the number of encountered\nclasses. C-FSCIL provides three update modes that offer a trade-off between\naccuracy and compute-memory cost of learning novel classes. C-FSCIL exploits\nhyperdimensional embedding that allows to continually express many more classes\nthan the fixed dimensions in the vector space, with minimal interference. The\nquality of class vector representations is further improved by aligning them\nquasi-orthogonally to each other by means of novel loss functions. Experiments\non the CIFAR100, miniImageNet, and Omniglot datasets show that C-FSCIL\noutperforms the baselines with remarkable accuracy and compression. It also\nscales up to the largest problem size ever tried in this few-shot setting by\nlearning 423 novel classes on top of 1200 base classes with less than 1.6%\naccuracy drop. Our code is available at\nhttps://github.com/IBM/constrained-FSCIL.",
    "descriptor": "\nComments: CVPR 2022 camera-ready version\n",
    "authors": [
      "Michael Hersche",
      "Geethan Karunaratne",
      "Giovanni Cherubini",
      "Luca Benini",
      "Abu Sebastian",
      "Abbas Rahimi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.16588"
  },
  {
    "id": "arXiv:2203.16595",
    "title": "Improving Speech Recognition for Indic Languages using Language Model",
    "abstract": "We study the effect of applying a language model (LM) on the output of\nAutomatic Speech Recognition (ASR) systems for Indic languages. We fine-tune\nwav2vec $2.0$ models for $18$ Indic languages and adjust the results with\nlanguage models trained on text derived from a variety of sources. Our findings\ndemonstrate that the average Character Error Rate (CER) decreases by over $28$\n\\% and the average Word Error Rate (WER) decreases by about $36$ \\% after\ndecoding with LM. We show that a large LM may not provide a substantial\nimprovement as compared to a diverse one. We also demonstrate that high quality\ntranscriptions can be obtained on domain-specific data without retraining the\nASR model and show results on biomedical domain.",
    "descriptor": "\nComments: This paper was submitted to Interspeech 2022\n",
    "authors": [
      "Ankur Dhuriya",
      "Harveen Singh Chadha",
      "Anirudh Gupta",
      "Priyanshi Shah",
      "Neeraj Chhimwal",
      "Rishabh Gaur",
      "Vivek Raghavan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.16595"
  },
  {
    "id": "arXiv:2203.16597",
    "title": "NGSO Constellation Design for Global Connectivity",
    "abstract": "Non-geostationary orbit (NGSO) satellite constellations represent a\ncornerstone in the NewSpace paradigm and thus have become one of the hottest\ntopics for the industry, academia, but also for national space agencies and\nregulators. For instance, numerous companies worldwide, including Starlink,\nOneWeb, Kepler, SPUTNIX, and Amazon have started or will soon start to deploy\ntheir own NGSO constellations, which aim to provide either broadband or IoT\nservices. One of the major drivers for such a high interest on NGSO\nconstellations is that, with an appropriate design, they are capable of\nproviding global coverage and connectivity.",
    "descriptor": "\nComments: Book chapter submitted to IET Non-Geostationary Satellite Communications Systems\n",
    "authors": [
      "Israel Leyva-Mayorga",
      "Beatriz Soret",
      "Bho Matthiesen",
      "Maik R\u00f6per",
      "Dirk W\u00fcbben",
      "Armin Dekorsy",
      "Petar Popovski"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2203.16597"
  },
  {
    "id": "arXiv:2203.16599",
    "title": "Autonomous Navigation of AGVs in Unknown Cluttered Environments:  log-MPPI Control Strategy",
    "abstract": "Sampling-based model predictive control (MPC) optimization methods, such as\nModel Predictive Path Integral (MPPI), have recently shown promising results in\nvarious robotic tasks. However, it might produce an infeasible trajectory when\nthe distributions of all sampled trajectories are concentrated within high-cost\neven infeasible regions. In this study, we propose a new method called log-MPPI\nequipped with a more effective trajectory sampling distribution policy which\nsignificantly improves the trajectory feasibility in terms of satisfying system\nconstraints. The key point is to draw the trajectory samples from the normal\nlog-normal (NLN) mixture distribution, rather than from Gaussian distribution.\nFurthermore, this work presents a method for collision-free navigation in\nunknown cluttered environments by incorporating the 2D occupancy grid map into\nthe optimization problem of the sampling-based MPC algorithm. We first validate\nthe efficiency and robustness of our proposed control strategy through\nextensive simulations of 2D autonomous navigation in different types of\ncluttered environments as well as the cart-pole swing-up task. We further\ndemonstrate, through real-world experiments, the applicability of log-MPPI for\nperforming a 2D grid-based collision-free navigation in an unknown cluttered\nenvironment, showing its superiority to be utilized with the local costmap\nwithout adding additional complexity to the optimization problem. A video\ndemonstrating the real-world and simulation results is available at\nhttps://youtu.be/_uGWQEFJSN0.",
    "descriptor": "\nComments: 8 pages, 7 figures, 3 tables\n",
    "authors": [
      "Ihab S. Mohamed",
      "Kai Yin",
      "Lantao Liu"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.16599"
  },
  {
    "id": "arXiv:2203.16600",
    "title": "Learning Local Displacements for Point Cloud Completion",
    "abstract": "We propose a novel approach aimed at object and semantic scene completion\nfrom a partial scan represented as a 3D point cloud. Our architecture relies on\nthree novel layers that are used successively within an encoder-decoder\nstructure and specifically developed for the task at hand. The first one\ncarries out feature extraction by matching the point features to a set of\npre-trained local descriptors. Then, to avoid losing individual descriptors as\npart of standard operations such as max-pooling, we propose an alternative\nneighbor-pooling operation that relies on adopting the feature vectors with the\nhighest activations. Finally, up-sampling in the decoder modifies our feature\nextraction in order to increase the output dimension. While this model is\nalready able to achieve competitive results with the state of the art, we\nfurther propose a way to increase the versatility of our approach to process\npoint clouds. To this aim, we introduce a second model that assembles our\nlayers within a transformer architecture. We evaluate both architectures on\nobject and indoor scene completion tasks, achieving state-of-the-art\nperformance.",
    "descriptor": "\nComments: Conference on Computer Vision and Pattern Recognition (CVPR) 2022\n",
    "authors": [
      "Yida Wang",
      "David Joseph Tan",
      "Nassir Navab",
      "Federico Tombari"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.16600"
  },
  {
    "id": "arXiv:2203.16601",
    "title": "Is Word Error Rate a good evaluation metric for Speech Recognition in  Indic Languages?",
    "abstract": "We propose a new method for the calculation of error rates in Automatic\nSpeech Recognition (ASR). This new metric is for languages that contain half\ncharacters and where the same character can be written in different forms. We\nimplement our methodology in Hindi which is one of the main languages from\nIndic context and we think this approach is scalable to other similar languages\ncontaining a large character set. We call our metrics Alternate Word Error Rate\n(AWER) and Alternate Character Error Rate (ACER).\nWe train our ASR models using wav2vec 2.0\\cite{baevski2020wav2vec} for Indic\nlanguages. Additionally we use language models to improve our model\nperformance. Our results show a significant improvement in analyzing the error\nrates at word and character level and the interpretability of the ASR system is\nimproved upto $3$\\% in AWER and $7$\\% in ACER for Hindi. Our experiments\nsuggest that in languages which have complex pronunciation, there are multiple\nways of writing words without changing their meaning. In such cases AWER and\nACER will be more useful rather than WER and CER as metrics. Furthermore, we\nopen source a new benchmarking dataset of 21 hours for Hindi with the new\nmetric scripts.",
    "descriptor": "\nComments: This paper was submitted to Interspeech 2022\n",
    "authors": [
      "Priyanshi Shah",
      "Harveen Singh Chadha",
      "Anirudh Gupta",
      "Ankur Dhuriya",
      "Neeraj Chhimwal",
      "Rishabh Gaur",
      "Vivek Raghavan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.16601"
  },
  {
    "id": "arXiv:2203.16603",
    "title": "Perfectly Perform Machine Learning Task with Imperfect Optical Hardware  Accelerator",
    "abstract": "Optical architectures have been emerging as an energy-efficient and\nhigh-throughput hardware platform to accelerate computationally intensive\ngeneral matrix-matrix multiplications (GEMMs) in modern machine learning (ML)\nalgorithms. However, the inevitable imperfection and non-uniformity in\nlarge-scale optoelectronic devices prevent the scalable deployment of optical\narchitectures, particularly those with innovative nano-devices. Here, we report\nan optical ML hardware to accelerate GEMM operations based on cascaded spatial\nlight modulators and present a calibration procedure that enables accurate\ncalculations despite the non-uniformity and imperfection in devices and system.\nWe further characterize the hardware calculation accuracy under different\nconfigurations of electrical-optical interfaces. Finally, we deploy the\ndeveloped optical hardware and calibration procedure to perform a ML task of\npredicting the intersubband plasmon frequency in single-wall carbon nanotubes.\nThe obtained prediction accuracy from the optical hardware agrees well with\nthat obtained using a general purpose electronic graphic process unit.",
    "descriptor": "\nComments: 5 figures\n",
    "authors": [
      "Jichao Fan",
      "Yingheng Tang",
      "Weilu Gao"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Optics (physics.optics)"
    ],
    "url": "https://arxiv.org/abs/2203.16603"
  },
  {
    "id": "arXiv:2203.16604",
    "title": "Understanding the role of single-board computers in engineering and  computer science education: A systematic literature review",
    "abstract": "In the last decade, Single-Board Computers (SBCs) have been employed more\nfrequently in engineering and computer science both to technical and\neducational levels. Several factors such as the versatility, the low-cost, and\nthe possibility to enhance the learning process through technology have\ncontributed to the educators and students usually employ these devices.\nHowever, the implications, possibilities, and constraints of these devices in\nengineering and Computer Science (CS) education have not been explored in\ndetail. In this systematic literature review, we explore how the SBCs are\nemployed in engineering and computer science and what educational results are\nderived from their usage in the period 2010-2020 at tertiary education. For\nthat, 154 studies were selected out of n=605 collected from the academic\ndatabases Ei Compendex, ERIC, and Inspec. The analysis was carried-out in two\nphases, identifying, e.g., areas of application, learning outcomes, and\nstudents and researchers' perceptions. The results mainly indicate the\nfollowing aspects: (1) The areas of laboratories and e-learning, computing\neducation, robotics, Internet of Things (IoT), and persons with disabilities\ngather the studies in the review. (2) Researchers highlight the importance of\nthe SBCs to transform the curricula in engineering and CS for the students to\nlearn complex topics through experimentation in hands-on activities. (3) The\ntypical cognitive learning outcomes reported by the authors are the improvement\nof the students' grades and the technical skills regarding the topics in the\ncourses. Concerning the affective learning outcomes, the increase of interest,\nmotivation, and engagement are commonly reported by the authors.",
    "descriptor": "\nComments: 27 pages\n",
    "authors": [
      "Jonathan \u00c1lvarez Ariza",
      "Heyson Baez"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Programming Languages (cs.PL)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.16604"
  },
  {
    "id": "arXiv:2203.16612",
    "title": "Decentralization illusion in DeFi: Evidence from MakerDAO",
    "abstract": "Decentralized Autonomous Organization (DAO) is very popular in Decentralized\nFinance (DeFi) applications as it provides a decentralized governance solution\nthrough blockchain. We analyze the governance characteristics in the relevant\nMaker protocol and its stablecoin Dai (DAI) and governance token Maker (MKR).\nTo achieve that, we establish several measurements of centralized governance.\nOur empirical analysis investigates the effect of centralized governance over a\nseries of factors related to MKR, DAI and Ethereum, such as financial,\ntransaction, exchange, network and twitter sentiment indicators. Our results\nshow that governance centralization influences both the Maker protocol and\nEthereum blockchain. The main implication of this study is that centralized\ngovernance in MakerDAO very much exists, while DeFi investors face a trade-off\nbetween efficiency and decentralization. This further contributes to the\ncontemporary debate on whether DeFi can be truly decentralized.",
    "descriptor": "",
    "authors": [
      "Xiaotong Sun",
      "Charalampos Stasinakis",
      "Georigios Sermpinis"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computational Finance (q-fin.CP)"
    ],
    "url": "https://arxiv.org/abs/2203.16612"
  },
  {
    "id": "arXiv:2203.16615",
    "title": "A Fast and Convergent Proximal Algorithm for Regularized Nonconvex and  Nonsmooth Bi-level Optimization",
    "abstract": "Many important machine learning applications involve regularized nonconvex\nbi-level optimization. However, the existing gradient-based bi-level\noptimization algorithms cannot handle nonconvex or nonsmooth regularizers, and\nthey suffer from a high computation complexity in nonconvex bi-level\noptimization. In this work, we study a proximal gradient-type algorithm that\nadopts the approximate implicit differentiation (AID) scheme for nonconvex\nbi-level optimization with possibly nonconvex and nonsmooth regularizers. In\nparticular, the algorithm applies the Nesterov's momentum to accelerate the\ncomputation of the implicit gradient involved in AID. We provide a\ncomprehensive analysis of the global convergence properties of this algorithm\nthrough identifying its intrinsic potential function. In particular, we\nformally establish the convergence of the model parameters to a critical point\nof the bi-level problem, and obtain an improved computation complexity\n$\\mathcal{O}(\\kappa^{3.5}\\epsilon^{-2})$ over the state-of-the-art result.\nMoreover, we analyze the asymptotic convergence rates of this algorithm under a\nclass of local nonconvex geometries characterized by a {\\L}ojasiewicz-type\ngradient inequality. Experiment on hyper-parameter optimization demonstrates\nthe effectiveness of our algorithm.",
    "descriptor": "\nComments: 20 pages, 1 figure, 1 table\n",
    "authors": [
      "Ziyi Chen",
      "Bhavya Kailkhura",
      "Yi Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2203.16615"
  },
  {
    "id": "arXiv:2203.16616",
    "title": "Knowledge-based Entity Prediction for Improved Machine Perception in  Autonomous Systems",
    "abstract": "Knowledge-based entity prediction (KEP) is a novel task that aims to improve\nmachine perception in autonomous systems. KEP leverages relational knowledge\nfrom heterogeneous sources in predicting potentially unrecognized entities. In\nthis paper, we provide a formal definition of KEP as a knowledge completion\ntask. Three potential solutions are then introduced, which employ several\nmachine learning and data mining techniques. Finally, the applicability of KEP\nis demonstrated on two autonomous systems from different domains; namely,\nautonomous driving and smart manufacturing. We argue that in complex real-world\nsystems, the use of KEP would significantly improve machine perception while\npushing the current technology one step closer to achieving the full autonomy.",
    "descriptor": "\nComments: 6 pages, 4 figures\n",
    "authors": [
      "Ruwan Wickramarachchi",
      "Cory Henson",
      "Amit Sheth"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.16616"
  },
  {
    "id": "arXiv:2203.16618",
    "title": "End-to-end Document Recognition and Understanding with Dessurt",
    "abstract": "We introduce Dessurt, a relatively simple document understanding transformer\ncapable of being fine-tuned on a greater variety of document tasks than prior\nmethods. It receives a document image and task string as input and generates\narbitrary text autoregressively as output. Because Dessurt is an end-to-end\narchitecture that performs text recognition in addition to the document\nunderstanding, it does not require an external recognition model as prior\nmethods do, making it easier to fine-tune to new visual domains. We show that\nthis model is effective at 9 different dataset-task combinations.",
    "descriptor": "",
    "authors": [
      "Brian Davis",
      "Bryan Morse",
      "Bryan Price",
      "Chris Tensmeyer",
      "Curtis Wigington",
      "Vlad Morariu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.16618"
  },
  {
    "id": "arXiv:2203.16620",
    "title": "Quantifying the presence/absence of meso-scale structures in networks",
    "abstract": "Meso-scale structures are network features where nodes with similar\nproperties are grouped together instead of being treated individually. In this\nwork, we provide formal and mathematical definitions of three such structures:\nassortative communities, disassortative communities and core-periphery. We then\nleverage these definitions and a Bayesian framework to quantify the\npresence/absence of each structure in a network. This allows for probabilistic\nstatements about the network structure as well as uncertainty estimates of the\ngroup labels and edge probabilities. The method is applied to real-world\nnetworks, yielding provocative results about well-known network data sets.",
    "descriptor": "",
    "authors": [
      "Eric Yanchenko"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2203.16620"
  },
  {
    "id": "arXiv:2203.16621",
    "title": "TR-MOT: Multi-Object Tracking by Reference",
    "abstract": "Multi-object Tracking (MOT) generally can be split into two sub-tasks, i.e.,\ndetection and association. Many previous methods follow the tracking by\ndetection paradigm, which first obtain detections at each frame and then\nassociate them between adjacent frames. Though with an impressive performance\nby utilizing a strong detector, it will degrade their detection and association\nperformance under scenes with many occlusions and large motion if not using\ntemporal information. In this paper, we propose a novel Reference Search (RS)\nmodule to provide a more reliable association based on the deformable\ntransformer structure, which is natural to learn the feature alignment for each\nobject among frames. RS takes previous detected results as references to\naggregate the corresponding features from the combined features of the adjacent\nframes and makes a one-to-one track state prediction for each reference in\nparallel. Therefore, RS can attain a reliable association coping with\nunexpected motions by leveraging visual temporal features while maintaining the\nstrong detection performance by decoupling from the detector. Our RS module can\nalso be compatible with the structure of the other tracking by detection\nframeworks. Furthermore, we propose a joint training strategy and an effective\nmatching pipeline for our online MOT framework with the RS module. Our method\nachieves competitive results on MOT17 and MOT20 datasets.",
    "descriptor": "\nComments: 10 pages, 3 figures, 2 tables\n",
    "authors": [
      "Mingfei Chen",
      "Yue Liao",
      "Si Liu",
      "Fei Wang",
      "Jenq-Neng Hwang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.16621"
  },
  {
    "id": "arXiv:2203.16626",
    "title": "DDNeRF: Depth Distribution Neural Radiance Fields",
    "abstract": "In recent years, the field of implicit neural representation has progressed\nsignificantly. Models such as neural radiance fields (NeRF), which uses\nrelatively small neural networks, can represent high-quality scenes and achieve\nstate-of-the-art results for novel view synthesis. Training these types of\nnetworks, however, is still computationally very expensive. We present depth\ndistribution neural radiance field (DDNeRF), a new method that significantly\nincreases sampling efficiency along rays during training while achieving\nsuperior results for a given sampling budget. DDNeRF achieves this by learning\na more accurate representation of the density distribution along rays. More\nspecifically, we train a coarse model to predict the internal distribution of\nthe transparency of an input volume in addition to the volume's total density.\nThis finer distribution then guides the sampling procedure of the fine model.\nThis method allows us to use fewer samples during training while reducing\ncomputational resources.",
    "descriptor": "",
    "authors": [
      "David Dadon",
      "Ohad Fried",
      "Yacov Hel-Or"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2203.16626"
  },
  {
    "id": "arXiv:2203.16628",
    "title": "Physics-constrained Unsupervised Learning of Partial Differential  Equations using Meshes",
    "abstract": "Enhancing neural networks with knowledge of physical equations has become an\nefficient way of solving various physics problems, from fluid flow to\nelectromagnetism. Graph neural networks show promise in accurately representing\nirregularly meshed objects and learning their dynamics, but have so far\nrequired supervision through large datasets. In this work, we represent meshes\nnaturally as graphs, process these using Graph Networks, and formulate our\nphysics-based loss to provide an unsupervised learning framework for partial\ndifferential equations (PDE). We quantitatively compare our results to a\nclassical numerical PDE solver, and show that our computationally efficient\napproach can be used as an interactive PDE solver that is adjusting boundary\nconditions in real-time and remains sufficiently close to the baseline\nsolution. Our inherently differentiable framework will enable the application\nof PDE solvers in interactive settings, such as model-based control of\nsoft-body deformations, or in gradient-based optimization methods that require\na fully differentiable pipeline.",
    "descriptor": "",
    "authors": [
      "Mike Y. Michelis",
      "Robert K. Katzschmann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.16628"
  },
  {
    "id": "arXiv:2203.16632",
    "title": "Controllable Augmentations for Video Representation Learning",
    "abstract": "This paper focuses on self-supervised video representation learning. Most\nexisting approaches follow the contrastive learning pipeline to construct\npositive and negative pairs by sampling different clips. However, this\nformulation tends to bias to static background and have difficulty establishing\nglobal temporal structures. The major reason is that the positive pairs, i.e.,\ndifferent clips sampled from the same video, have limited temporal receptive\nfield, and usually share similar background but differ in motions. To address\nthese problems, we propose a framework to jointly utilize local clips and\nglobal videos to learn from detailed region-level correspondence as well as\ngeneral long-term temporal relations. Based on a set of controllable\naugmentations, we achieve accurate appearance and motion pattern alignment\nthrough soft spatio-temporal region contrast. Our formulation is able to avoid\nthe low-level redundancy shortcut by mutual information minimization to improve\nthe generalization. We also introduce local-global temporal order dependency to\nfurther bridge the gap between clip-level and video-level representations for\nrobust temporal modeling. Extensive experiments demonstrate that our framework\nis superior on three video benchmarks in action recognition and video\nretrieval, capturing more accurate temporal dynamics.",
    "descriptor": "",
    "authors": [
      "Rui Qian",
      "Weiyao Lin",
      "John See",
      "Dian Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.16632"
  },
  {
    "id": "arXiv:2203.16633",
    "title": "Model Predictive Optimized Path Integral Strategies",
    "abstract": "We generalize the derivation of model predictive path integral control (MPPI)\nto allow for a single joint distribution across controls in the control\nsequence. This reformation allows for the implementation of adaptive importance\nsampling (AIS) algorithms into the original importance sampling step while\nstill maintaining the benefits of MPPI such as working with arbitrary system\ndynamics and cost functions. The benefit of optimizing the proposal\ndistribution by integrating AIS at each control step is demonstrated in\nsimulated environments including controlling multiple cars around a track. The\nnew algorithm is more sample efficient than MPPI, achieving better performance\nwith fewer samples. This performance disparity grows as the dimension of the\naction space increases. Results from simulations suggest the new algorithm can\nbe used as an anytime algorithm, increasing the value of control at each\niteration versus relying on a large set of samples.",
    "descriptor": "\nComments: 6 pages, 5 figures, 1 table, 1 algorithm. Repository: this https URL This work has been submitted for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Dylan M. Asmar",
      "Ransalu Senanayake",
      "Shawn Manuel",
      "Mykel J. Kochenderfer"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.16633"
  },
  {
    "id": "arXiv:2203.16634",
    "title": "Transformer Language Models without Positional Encodings Still Learn  Positional Information",
    "abstract": "Transformers typically require some form of positional encoding, such as\npositional embeddings, to process natural language sequences. Surprisingly, we\nfind that transformer language models without any explicit positional encoding\nare still competitive with standard models, and that this phenomenon is robust\nacross different datasets, model sizes, and sequence lengths. Probing\nexperiments reveal that such models acquire an implicit notion of absolute\npositions throughout the network, effectively compensating for the missing\ninformation. We conjecture that causal attention enables the model to infer the\nnumber of predecessors that each token can attend to, thereby approximating its\nabsolute position.",
    "descriptor": "",
    "authors": [
      "Adi Haviv",
      "Ori Ram",
      "Ofir Press",
      "Peter Izsak",
      "Omer Levy"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.16634"
  },
  {
    "id": "arXiv:2203.16637",
    "title": "Hybrid Handcrafted and Learnable Audio Representation for Analysis of  Speech Under Cognitive and Physical Load",
    "abstract": "As a neurophysiological response to threat or adverse conditions, stress can\naffect cognition, emotion and behaviour with potentially detrimental effects on\nhealth in the case of sustained exposure. Since the affective content of speech\nis inherently modulated by an individual's physical and mental state, a\nsubstantial body of research has been devoted to the study of paralinguistic\ncorrelates of stress-inducing task load. Historically, voice stress analysis\n(VSA) has been conducted using conventional digital signal processing (DSP)\ntechniques. Despite the development of modern methods based on deep neural\nnetworks (DNNs), accurately detecting stress in speech remains difficult due to\nthe wide variety of stressors and considerable variability in the individual\nstress perception. To that end, we introduce a set of five datasets for task\nload detection in speech. The voice recordings were collected as either\ncognitive or physical stress was induced in the cohort of volunteers, with a\ncumulative number of more than a hundred speakers. We used the datasets to\ndesign and evaluate a novel self-supervised audio representation that leverages\nthe effectiveness of handcrafted features (DSP-based) and the complexity of\ndata-driven DNN representations. Notably, the proposed approach outperformed\nboth extensive handcrafted feature sets and novel DNN-based audio\nrepresentation learning approaches.",
    "descriptor": "\nComments: Submitted to InterSpeech 2022\n",
    "authors": [
      "Gasser Elbanna",
      "Alice Biryukov",
      "Neil Scheidwasser-Clow",
      "Lara Orlandic",
      "Pablo Mainar",
      "Mikolaj Kegler",
      "Pierre Beckmann",
      "Milos Cernak"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.16637"
  },
  {
    "id": "arXiv:2203.16639",
    "title": "FALCON: Fast Visual Concept Learning by Integrating Images, Linguistic  descriptions, and Conceptual Relations",
    "abstract": "We present a meta-learning framework for learning new visual concepts\nquickly, from just one or a few examples, guided by multiple naturally\noccurring data streams: simultaneously looking at images, reading sentences\nthat describe the objects in the scene, and interpreting supplemental sentences\nthat relate the novel concept with other concepts. The learned concepts support\ndownstream applications, such as answering questions by reasoning about unseen\nimages. Our model, namely FALCON, represents individual visual concepts, such\nas colors and shapes, as axis-aligned boxes in a high-dimensional space (the\n\"box embedding space\"). Given an input image and its paired sentence, our model\nfirst resolves the referential expression in the sentence and associates the\nnovel concept with particular objects in the scene. Next, our model interprets\nsupplemental sentences to relate the novel concept with other known concepts,\nsuch as \"X has property Y\" or \"X is a kind of Y\". Finally, it infers an optimal\nbox embedding for the novel concept that jointly 1) maximizes the likelihood of\nthe observed instances in the image, and 2) satisfies the relationships between\nthe novel concepts and the known ones. We demonstrate the effectiveness of our\nmodel on both synthetic and real-world datasets.",
    "descriptor": "\nComments: First two authors contributed equally. Project page: this http URL\n",
    "authors": [
      "Lingjie Mei",
      "Jiayuan Mao",
      "Ziqi Wang",
      "Chuang Gan",
      "Joshua B. Tenenbaum"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.16639"
  },
  {
    "id": "arXiv:2203.16640",
    "title": "Task-driven Modular Co-design of Vehicle Control Systems",
    "abstract": "When designing autonomous systems, we need to consider multiple trade-offs at\nvarious abstraction levels, and the choices of single (hardware and software)\ncomponents need to be studied jointly. In this work we consider the problem of\ndesigning the control algorithm as well as the platform on which it is\nexecuted. In particular, we focus on vehicle control systems, and formalize\nstate-of-the-art control schemes as monotone feasibility relations. We then\nshow how, leveraging a monotone theory of co-design, we can study the embedding\nof control synthesis problems into the task-driven co-design problem of a\nrobotic platform. The properties of the proposed approach are illustrated by\nconsidering urban driving scenarios. We show how, given a particular task, we\ncan efficiently compute Pareto optimal design solutions.",
    "descriptor": "\nComments: 8 pages, 7 figures, under review\n",
    "authors": [
      "Gioele Zardini",
      "Zelio Suter",
      "Andrea Censi",
      "Emilio Frazzoli"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.16640"
  },
  {
    "id": "arXiv:2203.16643",
    "title": "Adaptive Observer for a Class of Systems with Switched Unknown  Parameters Using DREM",
    "abstract": "In this note, we develop an adaptive observer for a class of nonlinear\nsystems with switched unknown parameters to estimate the states and parameters\nsimultaneously. The main challenge lies in how to eliminate the disturbance\neffect of zero-input responses caused by the switching on the parameter\nestimation. These responses depend on the unknown states at switching instants\n(SASI) and constitute an additive disturbance to the parameter estimation,\nwhich obstructs parameter convergence to zero. Our solution is to treat the\nzero-input responses as excitations instead of disturbances. This is realized\nby first augmenting the system parameter with the SASI and then developing an\nestimator for the augmented parameter using the \\textit{dynamic regression\nextension and mixing} (DREM) technique. Thanks to its property of element-wise\nparameter adaptation, the system parameter estimation is decoupled from the\nSASI. As a result, the estimation errors of system states and parameters\nconverge to zero asymptotically. Furthermore, the robustness of the proposed\nadaptive observer is guaranteed in the presence of disturbances and noise. A\nnumerical example validates the effectiveness of the proposed approach.",
    "descriptor": "",
    "authors": [
      "Tong Liu",
      "Zengjie Zhang",
      "Fangzhou Liu",
      "Martin Buss"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.16643"
  },
  {
    "id": "arXiv:2203.16646",
    "title": "Generation of Speaker Representations Using Heterogeneous Training Batch  Assembly",
    "abstract": "In traditional speaker diarization systems, a well-trained speaker model is a\nkey component to extract representations from consecutive and partially\noverlapping segments in a long speech session. To be more consistent with the\nback-end segmentation and clustering, we propose a new CNN-based speaker\nmodeling scheme, which takes into account the heterogeneity of the speakers in\neach training segment and batch. We randomly and synthetically augment the\ntraining data into a set of segments, each of which contains more than one\nspeaker and some overlapping parts. A soft label is imposed on each segment\nbased on its speaker occupation ratio, and the standard cross entropy loss is\nimplemented in model training. In this way, the speaker model should have the\nability to generate a geometrically meaningful embedding for each multi-speaker\nsegment. Experimental results show that our system is superior to the baseline\nsystem using x-vectors in two speaker diarization tasks. In the CALLHOME task\ntrained on the NIST SRE and Switchboard datasets, our system achieves a\nrelative reduction of 12.93% in DER. In Track 2 of CHiME-6, our system provides\n13.24%, 12.60%, and 5.65% relative reductions in DER, JER, and WER,\nrespectively.",
    "descriptor": "\nComments: Published in APSIPA ASC 2021\n",
    "authors": [
      "Yu-Huai Peng",
      "Hung-Shin Lee",
      "Pin-Tuan Huang",
      "Hsin-Min Wang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.16646"
  },
  {
    "id": "arXiv:2203.16648",
    "title": "Predicting Winners of the Reality TV Dating Show $\\textit{The Bachelor}$  Using Machine Learning Algorithms",
    "abstract": "$\\textit{The Bachelor}$ is a reality TV dating show in which a single\nbachelor selects his wife from a pool of approximately 30 female contestants\nover eight weeks of filming (American Broadcasting Company 2002). We collected\nthe following data on all 422 contestants that participated in seasons 11\nthrough 25: their Age, Hometown, Career, Race, Week they got their first 1-on-1\ndate, whether they got the first impression rose, and what \"place\" they ended\nup getting. We then trained three machine learning models to predict the ideal\ncharacteristics of a successful contestant on $\\textit{The Bachelor}$. The\nthree algorithms that we tested were: random forest classification, neural\nnetworks, and linear regression. We found consistency across all three models,\nalthough the neural network performed the best overall. Our models found that a\nwoman has the highest probability of progressing far on $\\textit{The Bachelor}$\nif she is: 26 years old, white, from the Northwest, works as an dancer,\nreceived a 1-on-1 in week 6, and did not receive the First Impression Rose. Our\nmethodology is broadly applicable to all romantic reality television, and our\nresults will inform future $\\textit{The Bachelor}$ production and contestant\nstrategies. While our models were relatively successful, we still encountered\nhigh misclassification rates. This may be because: (1) Our training dataset had\nfewer than 400 points or (2) Our models were too simple to parameterize the\ncomplex romantic connections contestants forge over the course of a season.",
    "descriptor": "\nComments: 6 Pages, 5 Figures. Submitted to Acta Prima Aprila. Code used in this work available at this http URL\n",
    "authors": [
      "Abigail J. Lee",
      "Grace E. Chesmore",
      "Kyle A. Rocha",
      "Amanda Farah",
      "Maryum Sayeed",
      "Justin Myles"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Popular Physics (physics.pop-ph)"
    ],
    "url": "https://arxiv.org/abs/2203.16648"
  },
  {
    "id": "arXiv:2203.16650",
    "title": "Robust Beamforming for Localization-Aided Millimeter Wave Communication  Systems",
    "abstract": "In this letter, we investigate a robust beamforming problem for\nlocalization-aided millimeter wave (mmWave) communication systems. To handle\nthis problem, we propose a novel restriction and relaxation (R&R) method. The\nproposed R&R method aims at minimizing the total transmit power while the\npositioning error follows a Gaussian distribution. Specifically, in the\nrestriction phase of R&R, the probabilistic constraint is transformed into the\ndeterministic form by using the Bernsteintype inequality. In the relaxation\nphase of R&R, the non-convex optimization problem is reformulated into a convex\nsemidefinite program (SDP) by using semidefinite relaxation (SDR) and\nfirstorder Taylor expansion methods. To the best of our knowledge, we first\nconsider the impact of the distribution of the positioning error on the channel\nstate information (CSI), which further influences the data rate. Numerical\nresults present the trade-off of the beamforming between the communication and\npositioning.",
    "descriptor": "",
    "authors": [
      "Junchang Sun",
      "Shuai Ma",
      "Shiyin Li",
      "Ruixin Yang",
      "Minghui Min",
      "Gonzalo Seco-Granados"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.16650"
  },
  {
    "id": "arXiv:2203.16653",
    "title": "Error Identification Strategies for Python Jupyter Notebooks",
    "abstract": "Computational notebooks-such as Jupyter or Colab-combine text and data\nanalysis code. They have become ubiquitous in the world of data science and\nexploratory data analysis. Since these notebooks present a different\nprogramming paradigm than conventional IDE-driven programming, it is plausible\nthat debugging in computational notebooks might also be different. More\nspecifically, since creating notebooks blends domain knowledge, statistical\nanalysis, and programming, the ways in which notebook users find and fix errors\nin these different forms might be different. In this paper, we present an\nexploratory, observational study into how notebook users find and understand\npotential errors in notebooks. We presented users with notebooks pre-populated\nwith common notebook errors-errors rooted in either the statistical data\nanalysis, the knowledge of domain concepts, or in the programming. We then\nanalyzed the strategies our study participants used to find these errors and\ndetermined how successful each strategy was at identifying errors. Our findings\nindicate that while the notebook programming environment is different from the\nenvironments used for traditional programming, debugging strategies remain\nquite similar. It is our hope that the insights presented in this paper will\nhelp both notebook tool designers and educators make changes to improve how\ndata scientists discover errors more easily in the notebooks they write.",
    "descriptor": "\nComments: 11 pages, 5 listings, 7 tables, to be published at ICPC 2022\n",
    "authors": [
      "Derek Robinson",
      "Neil A. Ernst",
      "Enrique Larios Vargas",
      "Margaret-Anne D. Storey"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2203.16653"
  },
  {
    "id": "arXiv:2203.16654",
    "title": "Geographic Spines in the 2020 Census Disclosure Avoidance System TopDown  Algorithm",
    "abstract": "The TopDown Algorithm (TDA) first produces differentially private counts at\nthe nation and then produces counts at lower geolevels (e.g.: state, county,\netc.) subject to the constraint that all query answers in lower geolevels are\nconsistent with those at previously estimated geolevels. This paper describes\nthe three sets of definitions of these geolevels, or the geographic spines,\nthat are implemented within TDA. These include the standard Census geographic\nspine and two other spines that improve accuracy in geographic areas that are\nfar from the standard Census spine, such as cities, towns, and/or AIAN areas.\nThe third such spine, which is called the optimized spine, also modifies the\nprivacy-loss budget allocated to the entities within the geolevels, or the\ngeounits, to ensure the privacy-loss budget is used efficiently within TDA.",
    "descriptor": "",
    "authors": [
      "John M. Abowd",
      "Robert Ashmead",
      "Ryan Cumings-Menon",
      "Daniel Kifer",
      "Philip Leclerc",
      "Jeffrey Ocker",
      "Michael Ratcliffe",
      "Pavel Zhuravlev"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2203.16654"
  },
  {
    "id": "arXiv:2203.16657",
    "title": "Community Integration Algorithms (CIAs) for Dynamical Systems on  Networks",
    "abstract": "Dynamics of large-scale network processes underlies crucial phenomena ranging\nacross all sciences. Forward simulation of large network models is often\ncomputationally prohibitive. Yet, most networks have intrinsic community\nstructure. We exploit these communities and propose a fast simulation algorithm\nfor network dynamics. In particular, aggregating the inputs a node receives\nconstitutes the limiting factor in numerically simulating large-scale network\ndynamics. We develop community integration algorithms (CIAs) significantly\nreducing function-evaluations. We obtain a substantial reduction from\npolynomial to linear computational complexity. We illustrate our results in\nmultiple applications including classical and higher-order Kuramoto-type\nsystems for synchronisation and Cucker--Smale systems exhibiting flocking\nbehaviour on synthetic as well as real-world networks. Numerical comparison and\ntheoretical analysis confirm the robustness and efficiency of CIAs.",
    "descriptor": "\nComments: 12 pages, 6 figures\n",
    "authors": [
      "Tobias B\u00f6hle",
      "Mechthild Thalhammer",
      "Christian Kuehn"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2203.16657"
  },
  {
    "id": "arXiv:2203.16660",
    "title": "On The Role of Social Identity in the Market for (Mis)information",
    "abstract": "Motivated by recent works in the communication and psychology literature, we\nmodel and study the role social identity -- a person's sense of belonging to a\ngroup -- plays in human information consumption. A hallmark of Social Identity\nTheory (SIT) is the notion of 'status', i.e., an individual's desire to enhance\ntheir and their 'in-group's' utility relative to that of an 'out-group'. In the\ncontext of belief formation, this comes off as a desire to believe positive\nnews about the in-group and negative news about the out-group, which has been\nempirically shown to support belief in misinformation and false news.\nWe model this phenomenon as a Stackelberg game being played over an\ninformation channel between a news-source (sender) and news-consumer\n(receiver), with the receiver incorporating the 'status' associated with social\nidentity in their utility, in addition to accuracy. We characterize the\nstrategy that must be employed by the sender to ensure that its message is\ntrusted by receivers of all identities while maximizing their overall quality\nof information. We show that, as a rule, this optimal quality of information at\nequilibrium decreases when a receiver's sense of identity increases. We further\ndemonstrate how extensions of our model can be used to quantitatively estimate\nthe level of importance given to identity in a population.",
    "descriptor": "\nComments: Submitted to CDC 2022\n",
    "authors": [
      "Vijeth Hebbar",
      "Cedric Langbort"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.16660"
  },
  {
    "id": "arXiv:2203.16663",
    "title": "Robust Reputation Independence in Ranking Systems for Multiple Sensitive  Attributes",
    "abstract": "Ranking systems have an unprecedented influence on how and what information\npeople access, and their impact on our society is being analyzed from different\nperspectives, such as users' discrimination. A notable example is represented\nby reputation-based ranking systems, a class of systems that rely on users'\nreputation to generate a non-personalized item-ranking, proved to be biased\nagainst certain demographic classes. To safeguard that a given sensitive user's\nattribute does not systematically affect the reputation of that user, prior\nwork has operationalized a reputation independence constraint on this class of\nsystems. In this paper, we uncover that guaranteeing reputation independence\nfor a single sensitive attribute is not enough. When mitigating biases based on\none sensitive attribute (e.g., gender), the final ranking might still be biased\nagainst certain demographic groups formed based on another attribute (e.g.,\nage). Hence, we propose a novel approach to introduce reputation independence\nfor multiple sensitive attributes simultaneously. We then analyze the extent to\nwhich our approach impacts on discrimination and other important properties of\nthe ranking system, such as its quality and robustness against attacks.\nExperiments on two real-world datasets show that our approach leads to less\nbiased rankings with respect to multiple users' sensitive attributes, without\naffecting the system's quality and robustness.",
    "descriptor": "\nComments: Accepted in the Machine Learning journal\n",
    "authors": [
      "Guilherme Ramos",
      "Ludovico Boratto",
      "Mirko Marras"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2203.16663"
  },
  {
    "id": "arXiv:2203.16664",
    "title": "Semi-explicit integration of second order for weakly coupled  poroelasticity",
    "abstract": "We introduce a semi-explicit time-stepping scheme of second order for linear\nporoelasticity satisfying a weak coupling condition. Here, semi-explicit means\nthat the system, which needs to be solved in each step, decouples and hence\nimproves the computational efficiency. The construction and the convergence\nproof are based on the connection to a differential equation with two time\ndelays, namely one and two times the step size. Numerical experiments confirm\nthe theoretical results and indicate the applicability to higher-order schemes.",
    "descriptor": "",
    "authors": [
      "R. Altmann",
      "R. Maier",
      "B. Unger"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2203.16664"
  },
  {
    "id": "arXiv:2203.16666",
    "title": "Hawkes Process Modeling of Block Arrivals in Bitcoin Blockchain",
    "abstract": "The paper constructs a multi-variate Hawkes process model of Bitcoin block\narrivals and price jumps. Hawkes processes are selfexciting point processes\nthat can capture the self- and cross-excitation effects of block mining and\nBitcoin price volatility. We use publicly available blockchain datasets to\nestimate the model parameters via maximum likelihood estimation. The results\nshow that Bitcoin price volatility boost block mining rate and Bitcoin\ninvestment return demonstrates mean reversion. Quantile-Quantile plots show\nthat the proposed Hawkes process model is a better fit to the blockchain\ndatasets than a Poisson process model.",
    "descriptor": "",
    "authors": [
      "Rui Luo",
      "Vikram Krishnamurthy",
      "Erik Blasch"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2203.16666"
  },
  {
    "id": "arXiv:2203.16668",
    "title": "Flexible and Efficient Contextual Bandits with Heterogeneous Treatment  Effect Oracle",
    "abstract": "Many popular contextual bandit algorithms estimate reward models to inform\ndecision making. However, true rewards can contain action-independent\nredundancies that are not relevant for decision making and only increase the\nstatistical complexity of accurate estimation. It is sufficient and more\ndata-efficient to estimate the simplest function that explains the reward\ndifferences between actions, that is, the heterogeneous treatment effect,\ncommonly understood to be more structured and simpler than the reward.\nMotivated by this observation, building on recent work on oracle-based\nalgorithms, we design a statistically optimal and computationally efficient\nalgorithm using heterogeneous treatment effect estimation oracles. Our results\nprovide the first universal reduction of contextual bandits to a\ngeneral-purpose heterogeneous treatment effect estimation method. We show that\nour approach is more robust to model misspecification than reward estimation\nmethods based on squared error regression oracles. Experimentally, we show the\nbenefits of heterogeneous treatment effect estimation in contextual bandits\nover reward estimation.",
    "descriptor": "",
    "authors": [
      "Aldo Gael Carranza",
      "Sanath Kumar Krishnamurthy",
      "Susan Athey"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.16668"
  },
  {
    "id": "arXiv:2203.16669",
    "title": "Escaping Data Scarcity for High-Resolution Heterogeneous Face  Hallucination",
    "abstract": "In Heterogeneous Face Recognition (HFR), the objective is to match faces\nacross two different domains such as visible and thermal. Large domain\ndiscrepancy makes HFR a difficult problem. Recent methods attempting to fill\nthe gap via synthesis have achieved promising results, but their performance is\nstill limited by the scarcity of paired training data. In practice, large-scale\nheterogeneous face data are often inaccessible due to the high cost of\nacquisition and annotation process as well as privacy regulations. In this\npaper, we propose a new face hallucination paradigm for HFR, which not only\nenables data-efficient synthesis but also allows to scale up model training\nwithout breaking any privacy policy. Unlike existing methods that learn face\nsynthesis entirely from scratch, our approach is particularly designed to take\nadvantage of rich and diverse facial priors from visible domain for more\nfaithful hallucination. On the other hand, large-scale training is enabled by\nintroducing a new federated learning scheme to allow institution-wise\ncollaborations while avoiding explicit data sharing. Extensive experiments\ndemonstrate the advantages of our approach in tackling HFR under current data\nlimitations. In a unified framework, our method yields the state-of-the-art\nhallucination results on multiple HFR datasets.",
    "descriptor": "\nComments: CVPR2022\n",
    "authors": [
      "Yiqun Mei",
      "Pengfei Guo",
      "Vishal M. Patel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.16669"
  },
  {
    "id": "arXiv:2203.16670",
    "title": "PIE-Net: Photometric Invariant Edge Guided Network for Intrinsic Image  Decomposition",
    "abstract": "Intrinsic image decomposition is the process of recovering the image\nformation components (reflectance and shading) from an image. Previous methods\nemploy either explicit priors to constrain the problem or implicit constraints\nas formulated by their losses (deep learning). These methods can be negatively\ninfluenced by strong illumination conditions causing shading-reflectance\nleakages.\nTherefore, in this paper, an end-to-end edge-driven hybrid CNN approach is\nproposed for intrinsic image decomposition. Edges correspond to illumination\ninvariant gradients. To handle hard negative illumination transitions, a\nhierarchical approach is taken including global and local refinement layers. We\nmake use of attention layers to further strengthen the learning process.\nAn extensive ablation study and large scale experiments are conducted showing\nthat it is beneficial for edge-driven hybrid IID networks to make use of\nillumination invariant descriptors and that separating global and local cues\nhelps in improving the performance of the network. Finally, it is shown that\nthe proposed method obtains state of the art performance and is able to\ngeneralise well to real world images. The project page with pretrained models,\nfinetuned models and network code can be found at\nhttps://ivi.fnwi.uva.nl/cv/pienet/.",
    "descriptor": "",
    "authors": [
      "Partha Das",
      "Sezer Karaoglu",
      "Theo Gevers"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.16670"
  },
  {
    "id": "arXiv:2203.16678",
    "title": "Knowledge-Spreader: Learning Facial Action Unit Dynamics with Extremely  Limited Labels",
    "abstract": "Recent studies on the automatic detection of facial action unit (AU) have\nextensively relied on large-sized annotations. However, manually AU labeling is\ndifficult, time-consuming, and costly. Most existing semi-supervised works\nignore the informative cues from the temporal domain, and are highly dependent\non densely annotated videos, making the learning process less efficient. To\nalleviate these problems, we propose a deep semi-supervised framework\nKnowledge-Spreader (KS), which differs from conventional methods in two\naspects. First, rather than only encoding human knowledge as constraints, KS\nalso learns the Spatial-Temporal AU correlation knowledge in order to\nstrengthen its out-of-distribution generalization ability. Second, we approach\nKS by applying consistency regularization and pseudo-labeling in multiple\nstudent networks alternately and dynamically. It spreads the spatial knowledge\nfrom labeled frames to unlabeled data, and completes the temporal information\nof partially labeled video clips. Thus, the design allows KS to learn AU\ndynamics from video clips with only one label allocated, which significantly\nreduce the requirements of using annotations. Extensive experiments demonstrate\nthat the proposed KS achieves competitive performance as compared to the state\nof the arts under the circumstances of using only 2% labels on BP4D and 5%\nlabels on DISFA. In addition, we test it on our newly developed large-scale\ncomprehensive emotion database, which contains considerable samples across\nwell-synchronized and aligned sensor modalities for easing the scarcity issue\nof annotations and identities in human affective computing. The new database\nwill be released to the research community.",
    "descriptor": "",
    "authors": [
      "Xiaotian Li",
      "Xiang Zhang",
      "Taoyue Wang",
      "Lijun Yin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.16678"
  },
  {
    "id": "arXiv:2203.16680",
    "title": "Learning the Effect of Registration Hyperparameters with HyperMorph",
    "abstract": "We introduce HyperMorph, a framework that facilitates efficient\nhyperparameter tuning in learning-based deformable image registration.\nClassical registration algorithms perform an iterative pair-wise optimization\nto compute a deformation field that aligns two images. Recent learning-based\napproaches leverage large image datasets to learn a function that rapidly\nestimates a deformation for a given image pair. In both strategies, the\naccuracy of the resulting spatial correspondences is strongly influenced by the\nchoice of certain hyperparameter values. However, an effective hyperparameter\nsearch consumes substantial time and human effort as it often involves training\nmultiple models for different fixed hyperparameter values and may lead to\nsuboptimal registration. We propose an amortized hyperparameter learning\nstrategy to alleviate this burden by learning the impact of hyperparameters on\ndeformation fields. We design a meta network, or hypernetwork, that predicts\nthe parameters of a registration network for input hyperparameters, thereby\ncomprising a single model that generates the optimal deformation field\ncorresponding to given hyperparameter values. This strategy enables fast,\nhigh-resolution hyperparameter search at test-time, reducing the inefficiency\nof traditional approaches while increasing flexibility. We also demonstrate\nadditional benefits of HyperMorph, including enhanced robustness to model\ninitialization and the ability to rapidly identify optimal hyperparameter\nvalues specific to a dataset, image contrast, task, or even anatomical region,\nall without the need to retrain models. We make our code publicly available at\nthis http URL",
    "descriptor": "\nComments: Accepted for publication at the Journal of Machine Learning for Biomedical Imaging (MELBA) at this https URL\n",
    "authors": [
      "Andrew Hoopes",
      "Malte Hoffmann",
      "Douglas N. Greve",
      "Bruce Fischl",
      "John Guttag",
      "Adrian V. Dalca"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2203.16680"
  },
  {
    "id": "arXiv:2203.16681",
    "title": "Face Relighting with Geometrically Consistent Shadows",
    "abstract": "Most face relighting methods are able to handle diffuse shadows, but struggle\nto handle hard shadows, such as those cast by the nose. Methods that propose\ntechniques for handling hard shadows often do not produce geometrically\nconsistent shadows since they do not directly leverage the estimated face\ngeometry while synthesizing them. We propose a novel differentiable algorithm\nfor synthesizing hard shadows based on ray tracing, which we incorporate into\ntraining our face relighting model. Our proposed algorithm directly utilizes\nthe estimated face geometry to synthesize geometrically consistent hard\nshadows. We demonstrate through quantitative and qualitative experiments on\nMulti-PIE and FFHQ that our method produces more geometrically consistent\nshadows than previous face relighting methods while also achieving\nstate-of-the-art face relighting performance under directional lighting. In\naddition, we demonstrate that our differentiable hard shadow modeling improves\nthe quality of the estimated face geometry over diffuse shading models.",
    "descriptor": "\nComments: Accepted to CVPR 2022\n",
    "authors": [
      "Andrew Hou",
      "Michel Sarkis",
      "Ning Bi",
      "Yiying Tong",
      "Xiaoming Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.16681"
  },
  {
    "id": "arXiv:2203.16682",
    "title": "To Find Waldo You Need Contextual Cues: Debiasing Who's Waldo",
    "abstract": "We present a debiased dataset for the Person-centric Visual Grounding (PCVG)\ntask first proposed by Cui et al. (2021) in the Who's Waldo dataset. Given an\nimage and a caption, PCVG requires pairing up a person's name mentioned in a\ncaption with a bounding box that points to the person in the image. We find\nthat the original Who's Waldo dataset compiled for this task contains a large\nnumber of biased samples that are solvable simply by heuristic methods; for\ninstance, in many cases the first name in the sentence corresponds to the\nlargest bounding box, or the sequence of names in the sentence corresponds to\nan exact left-to-right order in the image. Naturally, models trained on these\nbiased data lead to over-estimation of performance on the benchmark. To enforce\nmodels being correct for the correct reasons, we design automated tools to\nfilter and debias the original dataset by ruling out all examples of\ninsufficient context, such as those with no verb or with a long chain of\nconjunct names in their captions. Our experiments show that our new sub-sampled\ndataset contains less bias with much lowered heuristic performances and widened\ngaps between heuristic and supervised methods. We also demonstrate the same\nbenchmark model trained on our debiased training set outperforms that trained\non the original biased (and larger) training set on our debiased test set. We\nargue our debiased dataset offers the PCVG task a more practical baseline for\nreliable benchmarking and future improvements.",
    "descriptor": "\nComments: Accepted at ACL 2022 (Short Paper)\n",
    "authors": [
      "Yiran Luo",
      "Pratyay Banerjee",
      "Tejas Gokhale",
      "Yezhou Yang",
      "Chitta Baral"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.16682"
  },
  {
    "id": "arXiv:2203.16684",
    "title": "DBSP: Automatic Incremental View Maintenance for Rich Query Languages",
    "abstract": "Incremental view maintenance has been for a long time a central problem in\ndatabase theory. Many solutions have been proposed for restricted classes of\ndatabase languages, such as the relational algebra, or Datalog. These\ntechniques do not naturally generalize to richer languages. In this paper we\ngive a general solution to this problem in 3 steps: (1) we describe a simple\nbut expressive language called DBSP for describing computations over data\nstreams; (2) we give a general algorithm for solving the incremental view\nmaintenance problem for arbitrary DBSP programs, and (3) we show how to model\nmany rich database query languages (including the full relational queries,\ngrouping and aggregation, monotonic and non-monotonic recursion, and streaming\naggregation) using DBSP. As a consequence, we obtain efficient incremental view\nmaintenance techniques for all these rich languages.",
    "descriptor": "",
    "authors": [
      "Mihai Budiu",
      "Frank McSherry",
      "Leonid Ryzhyk",
      "Val Tannen"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2203.16684"
  },
  {
    "id": "arXiv:2203.16687",
    "title": "Quasi-orthogonality and intrinsic dimensions as measures of learning and  generalisation",
    "abstract": "Finding best architectures of learning machines, such as deep neural\nnetworks, is a well-known technical and theoretical challenge. Recent work by\nMellor et al (2021) showed that there may exist correlations between the\naccuracies of trained networks and the values of some easily computable\nmeasures defined on randomly initialised networks which may enable to search\ntens of thousands of neural architectures without training. Mellor et al used\nthe Hamming distance evaluated over all ReLU neurons as such a measure.\nMotivated by these findings, in our work, we ask the question of the existence\nof other and perhaps more principled measures which could be used as\ndeterminants of success of a given neural architecture. In particular, we\nexamine, if the dimensionality and quasi-orthogonality of neural networks'\nfeature space could be correlated with the network's performance after\ntraining. We showed, using the setup as in Mellor et al, that dimensionality\nand quasi-orthogonality may jointly serve as network's performance\ndiscriminants. In addition to offering new opportunities to accelerate neural\narchitecture search, our findings suggest important relationships between the\nnetworks' final performance and properties of their randomly initialised\nfeature spaces: data dimension and quasi-orthogonality.",
    "descriptor": "",
    "authors": [
      "Qinghua Zhou",
      "Alexander N. Gorban",
      "Evgeny M. Mirkes",
      "Jonathan Bac",
      "Andrei Zinovyev",
      "Ivan Y. Tyukin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.16687"
  },
  {
    "id": "arXiv:2203.16690",
    "title": "GTP-SLAM: Game-Theoretic Priors for Simultaneous Localization and  Mapping in Multi-Agent Scenarios",
    "abstract": "Robots operating in complex, multi-player settings must simultaneously model\nthe environment and the behavior of human or robotic agents who share that\nenvironment. Environmental modeling is often approached using Simultaneous\nLocalization and Mapping (SLAM) techniques; however, SLAM algorithms usually\nneglect multi-player interactions. In contrast, a recent branch of the motion\nplanning literature uses dynamic game theory to explicitly model noncooperative\ninteractions of multiple agents in a known environment with perfect\nlocalization. In this work, we fuse ideas from these disparate communities to\nsolve SLAM problems with game theoretic priors. We present GTP-SLAM, a novel,\niterative best response-based SLAM algorithm that accurately performs state\nlocalization and map reconstruction in an uncharted scene, while capturing the\ninherent game-theoretic interactions among multiple agents in that scene. By\nformulating the underlying SLAM problem as a potential game, we inherit a\nstrong convergence guarantee. Empirical results indicate that, when deployed in\na realistic traffic simulation, our approach performs localization and mapping\nmore accurately than a standard bundle adjustment algorithm across a wide range\nof noise levels.",
    "descriptor": "\nComments: 6 pages, 3 figures\n",
    "authors": [
      "Chih-Yuan Chiu",
      "David Fridovich-Keil"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.16690"
  },
  {
    "id": "arXiv:2203.16697",
    "title": "Type-Directed Program Synthesis for RESTful APIs",
    "abstract": "With the rise of software-as-a-service and microservice architectures,\nRESTful APIs are now ubiquitous in mobile and web applications. A service can\nhave tens or hundreds of API methods, making it a challenge for programmers to\nfind the right combination of methods to solve their task.\nWe present APIphany, a component-based synthesizer for programs that compose\ncalls to RESTful APIs. The main innovation behind APIphany is the use of\nprecise semantic types, both to specify user intent and to direct the search.\nAPIphany contributes three novel mechanisms to overcome challenges in adapting\ncomponent-based synthesis to the REST domain: (1) a type inference algorithm\nfor augmenting REST specifications with semantic types; (2) an efficient\nsynthesis technique for \"wrangling\" semi-structured data, which is commonly\nrequired in working with RESTful APIs; and (3) a new form of simulated\nexecution to avoid executing APIs calls during synthesis. We evaluate APIphany\non three real-world APIs and 32 tasks extracted from GitHub repositories and\nStackOverflow. In our experiments, APIphany found correct solutions to 29\ntasks, with 23 of them reported among top ten synthesis results.",
    "descriptor": "",
    "authors": [
      "Zheng Guo",
      "David Cao",
      "Davin Tjong",
      "Jean Yang",
      "Cole Schlesinger",
      "Nadia Polikarpova"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2203.16697"
  },
  {
    "id": "arXiv:2203.16699",
    "title": "Excitation and Measurement Patterns for the Identifiability of Directed  Acyclic Graphs",
    "abstract": "This paper deals with the design of Excitation and Measurement Patterns (EMP)\nfor the identification of a class of dynamical networks whose topology has the\nstructure of a Directed Acyclic Graph (DAG). In addition to the by now well\nknown condition that the identifiabiltiy of any dynamical network requires that\nthe sources be excited, the sinks be measured, and all other nodes be either\nexcited or measured, we show that for DAGs two other types of nodes have\nspecial excitation and measurement requirements. Armed with this result, we\npropose a systematic procedure for the design of EMPs that guarantee\nidentifiability of a network with DAG topology.",
    "descriptor": "\nComments: Submitted to the 61st IEEE Conference on Decision and Control\n",
    "authors": [
      "Eduardo Mapurunga",
      "Michel Gevers",
      "Alexandre S. Bazanella"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2203.16699"
  },
  {
    "id": "arXiv:2203.16701",
    "title": "Towards Differential Relational Privacy and its use in Question  Answering",
    "abstract": "Memorization of the relation between entities in a dataset can lead to\nprivacy issues when using a trained model for question answering. We introduce\nRelational Memorization (RM) to understand, quantify and control this\nphenomenon. While bounding general memorization can have detrimental effects on\nthe performance of a trained model, bounding RM does not prevent effective\nlearning. The difference is most pronounced when the data distribution is\nlong-tailed, with many queries having only few training examples: Impeding\ngeneral memorization prevents effective learning, while impeding only\nrelational memorization still allows learning general properties of the\nunderlying concepts. We formalize the notion of Relational Privacy (RP) and,\ninspired by Differential Privacy (DP), we provide a possible definition of\nDifferential Relational Privacy (DrP). These notions can be used to describe\nand compute bounds on the amount of RM in a trained model. We illustrate\nRelational Privacy concepts in experiments with large-scale models for Question\nAnswering.",
    "descriptor": "",
    "authors": [
      "Simone Bombari",
      "Alessandro Achille",
      "Zijian Wang",
      "Yu-Xiang Wang",
      "Yusheng Xie",
      "Kunwar Yashraj Singh",
      "Srikar Appalaraju",
      "Vijay Mahadevan",
      "Stefano Soatto"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.16701"
  },
  {
    "id": "arXiv:2203.16708",
    "title": "Task Adaptive Parameter Sharing for Multi-Task Learning",
    "abstract": "Adapting pre-trained models with broad capabilities has become standard\npractice for learning a wide range of downstream tasks. The typical approach of\nfine-tuning different models for each task is performant, but incurs a\nsubstantial memory cost. To efficiently learn multiple downstream tasks we\nintroduce Task Adaptive Parameter Sharing (TAPS), a general method for tuning a\nbase model to a new task by adaptively modifying a small, task-specific subset\nof layers. This enables multi-task learning while minimizing resources used and\ncompetition between tasks. TAPS solves a joint optimization problem which\ndetermines which layers to share with the base model and the value of the\ntask-specific weights. Further, a sparsity penalty on the number of active\nlayers encourages weight sharing with the base model. Compared to other\nmethods, TAPS retains high accuracy on downstream tasks while introducing few\ntask-specific parameters. Moreover, TAPS is agnostic to the model architecture\nand requires only minor changes to the training scheme. We evaluate our method\non a suite of fine-tuning tasks and architectures (ResNet, DenseNet, ViT) and\nshow that it achieves state-of-the-art performance while being simple to\nimplement.",
    "descriptor": "\nComments: CVPR 2022 Camera Ready. 15 pages, 11 figures\n",
    "authors": [
      "Matthew Wallingford",
      "Hao Li",
      "Alessandro Achille",
      "Avinash Ravichandran",
      "Charless Fowlkes",
      "Rahul Bhotika",
      "Stefano Soatto"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.16708"
  },
  {
    "id": "arXiv:2203.16713",
    "title": "Wordle is NP-hard",
    "abstract": "Wordle is a single player word-guessing game where the goal is to discover a\nsecret word $w$ that has been chosen from a dictionary $D$. In order to\ndiscover $w$, the player can make at most $\\ell$ guesses, which must also be\nwords from $D$, all words in $D$ having the same length $k$. After each guess,\nthe player is notified of the positions in which their guess matches the secret\nword, as well as letters in the guess that appear in the secret word in a\ndifferent position. We study the game of Wordle from a complexity perspective,\nproving NP-hardness of its natural formalization: to decide given a dictionary\n$D$ and an integer $\\ell$ if the player can guarantee to discover the secret\nword within $\\ell$ guesses. Moreover, we prove that hardness holds even over\ninstances where words have length $k = 5$, and that even in this case it is\nNP-hard to approximate the minimum number of guesses required to guarantee\ndiscovering the secret word (beyond a certain constant). We also present\nresults regarding its parameterized complexity and offer some related open\nproblems.",
    "descriptor": "\nComments: Accepted at FUN2022\n",
    "authors": [
      "Daniel Lokshtanov",
      "Bernardo Subercaseaux"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2203.16713"
  },
  {
    "id": "arXiv:2203.16714",
    "title": "End-to-End Table Question Answering via Retrieval-Augmented Generation",
    "abstract": "Most existing end-to-end Table Question Answering (Table QA) models consist\nof a two-stage framework with a retriever to select relevant table candidates\nfrom a corpus and a reader to locate the correct answers from table candidates.\nEven though the accuracy of the reader models is significantly improved with\nthe recent transformer-based approaches, the overall performance of such\nframeworks still suffers from the poor accuracy of using traditional\ninformation retrieval techniques as retrievers. To alleviate this problem, we\nintroduce T-RAG, an end-to-end Table QA model, where a non-parametric dense\nvector index is fine-tuned jointly with BART, a parametric sequence-to-sequence\nmodel to generate answer tokens. Given any natural language question, T-RAG\nutilizes a unified pipeline to automatically search through a table corpus to\ndirectly locate the correct answer from the table cells. We apply T-RAG to\nrecent open-domain Table QA benchmarks and demonstrate that the fine-tuned\nT-RAG model is able to achieve state-of-the-art performance in both the\nend-to-end Table QA and the table retrieval tasks.",
    "descriptor": "",
    "authors": [
      "Feifei Pan",
      "Mustafa Canim",
      "Michael Glass",
      "Alfio Gliozzo",
      "James Hendler"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.16714"
  },
  {
    "id": "arXiv:2203.16715",
    "title": "Cyberattack Detection for Nonlinear Leader-Following Multi-Agent Systems  Using Set-Membership Fuzzy Filtering",
    "abstract": "This paper is concerned with cyberattack detection in discrete-time,\nleader-following, nonlinear, multi-agent systems subject to unknown but bounded\n(UBB) system noises. The Takagi-Sugeno (T-S) fuzzy model is employed to\napproximate the nonlinear systems over the true value of the state. A\ndistributed cyberattack detection method, based on a new fuzzy set-membership\nfiltering method, which consists of two steps, namely a prediction step and a\nmeasurement update step, is developed for each agent to identify two types of\ncyberattacks at the time of their occurrence. The attacks are replay attacks\nand false data injection attacks affecting the leader-following consensus. We\ncalculate an estimation ellipsoid set by updating the prediction ellipsoid set\nwith the current sensor measurement data. Two criteria are provided to detect\ncyberattacks based on the intersection between the ellipsoid sets. If there is\nno intersection between the prediction set and the estimation set of an agent\nat the current time instant, a cyberattack on its sensors is declared. Control\nsignal or communication signal data of an agent are under a cyberattack if its\nprediction set has no intersection with the estimation set updated at the\nprevious time instant. Recursive algorithms for solving the consensus protocol\nand calculating the two ellipsoid sets for detecting attacks are proposed.\nSimulation results are provided to demonstrate the effectiveness of the\nproposed method.",
    "descriptor": "",
    "authors": [
      "Mahshid Rahimifard",
      "Amir M. Moradi Sizkouhi",
      "Rastko R. Selmic"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.16715"
  },
  {
    "id": "arXiv:2203.16718",
    "title": "A Large-Scale Comparison of Python Code in Jupyter Notebooks and Scripts",
    "abstract": "In recent years, Jupyter notebooks have grown in popularity in several\ndomains of software engineering, such as data science, machine learning, and\ncomputer science education. Their popularity has to do with their rich features\nfor presenting and visualizing data, however, recent studies show that\nnotebooks also share a lot of drawbacks: high number of code clones, low\nreproducibility, etc.\nIn this work, we carry out a comparison between Python code written in\nJupyter Notebooks and in traditional Python scripts. We compare the code from\ntwo perspectives: structural and stylistic. In the first part of the analysis,\nwe report the difference in the number of lines, the usage of functions, as\nwell as various complexity metrics. In the second part, we show the difference\nin the number of stylistic issues and provide an extensive overview of the 15\nmost frequent stylistic issues in the studied mediums. Overall, we demonstrate\nthat notebooks are characterized by the lower code complexity, however, their\ncode could be perceived as more entangled than in the scripts. As for the\nstyle, notebooks tend to have 1.4 times more stylistic issues, but at the same\ntime, some of them are caused by specific coding practices in notebooks and\nshould be considered as false positives. With this research, we want to pave\nthe way to studying specific problems of notebooks that should be addressed by\nthe development of notebook-specific tools, and provide various insights that\ncan be useful in this regard.",
    "descriptor": "\nComments: 12 pages, 3 figures\n",
    "authors": [
      "Konstantin Grotov",
      "Sergey Titov",
      "Vladimir Sotnikov",
      "Yaroslav Golubev",
      "Timofey Bryksin"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2203.16718"
  },
  {
    "id": "arXiv:2203.16723",
    "title": "Exploiting Explainable Metrics for Augmented SGD",
    "abstract": "Explaining the generalization characteristics of deep learning is an emerging\ntopic in advanced machine learning. There are several unanswered questions\nabout how learning under stochastic optimization really works and why certain\nstrategies are better than others. In this paper, we address the following\nquestion: \\textit{can we probe intermediate layers of a deep neural network to\nidentify and quantify the learning quality of each layer?} With this question\nin mind, we propose new explainability metrics that measure the redundant\ninformation in a network's layers using a low-rank factorization framework and\nquantify a complexity measure that is highly correlated with the generalization\nperformance of a given optimizer, network, and dataset. We subsequently exploit\nthese metrics to augment the Stochastic Gradient Descent (SGD) optimizer by\nadaptively adjusting the learning rate in each layer to improve in\ngeneralization performance. Our augmented SGD -- dubbed RMSGD -- introduces\nminimal computational overhead compared to SOTA methods and outperforms them by\nexhibiting strong generalization characteristics across application,\narchitecture, and dataset.",
    "descriptor": "\nComments: Accepted in IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR2022)\n",
    "authors": [
      "Mahdi S. Hosseini",
      "Mathieu Tuli",
      "Konstantinos N. Plataniotis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.16723"
  },
  {
    "id": "arXiv:2203.16730",
    "title": "Cancellable Template Design for Privacy-Preserving EEG Biometric  Authentication Systems",
    "abstract": "As a promising candidate to complement traditional biometric modalities,\nbrain biometrics using electroencephalography (EEG) data has received a\nwidespread attention in recent years. However, compared with existing\nbiometrics such as fingerprints and face recognition, research on EEG\nbiometrics is still in its infant stage. Most of the studies focus on either\ndesigning signal elicitation protocols from the perspective of neuroscience or\ndeveloping feature extraction and classification algorithms from the viewpoint\nof machine learning. These studies have laid the ground for the feasibility of\nusing EEG as a biometric authentication modality, but they have also raised\nsecurity and privacy concerns as EEG data contains sensitive information.\nExisting research has used hash functions and cryptographic schemes to protect\nEEG data, but they do not provide functions for revoking compromised templates\nas in cancellable template design. This paper proposes the first cancellable\nEEG template design for privacy-preserving EEG-based authentication systems,\nwhich can protect raw EEG signals containing sensitive privacy information\n(e.g., identity, health and cognitive status). A novel cancellable EEG template\nis developed based on EEG graph features and a non-invertible transform. The\nproposed transformation provides cancellable templates, while taking advantage\nof EEG elicitation protocol fusion to enhance biometric performance. The\nproposed authentication system offers equivalent authentication performance\n(8.58\\% EER on a public database) as in the non-transformed domain, while\nprotecting raw EEG data. Furthermore, we analyze the system's capacity for\nresisting multiple attacks, and discuss some overlooked but critical issues and\npossible pitfalls involving hill-climbing attacks, second attacks, and\nclassification-based authentication systems.",
    "descriptor": "",
    "authors": [
      "Min Wang",
      "Song Wang",
      "Jiankun Hu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2203.16730"
  },
  {
    "id": "arXiv:2203.16732",
    "title": "Deep Reinforcement Learning with Graph ConvNets for Distribution Network  Voltage Control",
    "abstract": "This paper proposes a model-free Volt-VAR control (VVC) algorithm via the\nspatio-temporal graph ConvNet-based deep reinforcement learning (STGCN-DRL)\nframework, whose goal is to control smart inverters in an unbalanced\ndistribution system. We first identify the graph shift operator (GSO) based on\nthe power flow equations. Then, we develop a spatio-temporal graph ConvNet\n(STGCN), testing both recurrent graph ConvNets (RGCN) and convolutional graph\nConvNets (CGCN) architectures, aimed at capturing the spatiotemporal\ncorrelation of voltage phasors. The STGCN layer performs the feature extraction\ntask for the policy function and the value function of the reinforcement\nlearning architecture, and then we utilize the proximal policy optimization\n(PPO) to search the action spaces for an optimum policy function and to\napproximate an optimum value function. We further utilize the low-pass property\nof voltage graph signal to introduce an GCN architecture for the the policy\nwhose input is a decimated state vector, i.e. a partial observation. Case\nstudies on the unbalanced 123-bus systems validate the excellent performance of\nthe proposed method in mitigating instabilities and maintaining nodal voltage\nprofiles within a desirable range.",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Tong Wu",
      "Ignacio Losada Carreno",
      "Anna Scaglione",
      "Daniel Arnold"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.16732"
  },
  {
    "id": "arXiv:2203.16738",
    "title": "Improving speaker de-identification with functional data analysis of f0  trajectories",
    "abstract": "Due to a constantly increasing amount of speech data that is stored in\ndifferent types of databases, voice privacy has become a major concern. To\nrespond to such concern, speech researchers have developed various methods for\nspeaker de-identification. The state-of-the-art solutions utilize deep learning\nsolutions which can be effective but might be unavailable or impractical to\napply for, for example, under-resourced languages. Formant modification is a\nsimpler, yet effective method for speaker de-identification which requires no\ntraining data. Still, remaining intonational patterns in formant-anonymized\nspeech may contain speaker-dependent cues. This study introduces a novel\nspeaker de-identification method, which, in addition to simple formant shifts,\nmanipulates f0 trajectories based on functional data analysis. The proposed\nspeaker de-identification method will conceal plausibly identifying pitch\ncharacteristics in a phonetically controllable manner and improve formant-based\nspeaker de-identification up to 25%.",
    "descriptor": "\nComments: Accepted to Speech Communication. March 2022\n",
    "authors": [
      "Lauri Tavi",
      "Tomi Kinnunen",
      "Rosa Gonz\u00e1lez Hautam\u00e4ki"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.16738"
  },
  {
    "id": "arXiv:2203.16743",
    "title": "A Peek into the Political Biases in Email Spam Filtering Algorithms  During US Election 2020",
    "abstract": "Email services use spam filtering algorithms (SFAs) to filter emails that are\nunwanted by the user. However, at times, the emails perceived by an SFA as\nunwanted may be important to the user. Such incorrect decisions can have\nsignificant implications if SFAs treat emails of user interest as spam on a\nlarge scale. This is particularly important during national elections. To study\nwhether the SFAs of popular email services have any biases in treating the\ncampaign emails, we conducted a large-scale study of the campaign emails of the\nUS elections 2020 by subscribing to a large number of Presidential, Senate, and\nHouse candidates using over a hundred email accounts on Gmail, Outlook, and\nYahoo. We analyzed the biases in the SFAs towards the left and the right\ncandidates and further studied the impact of the interactions (such as reading\nor marking emails as spam) of email recipients on these biases. We observed\nthat the SFAs of different email services indeed exhibit biases towards\ndifferent political affiliations. We present this and several other important\nobservations in this paper.",
    "descriptor": "\nComments: 10 pages, Published in WWW'22\n",
    "authors": [
      "Hassan Iqbal",
      "Usman Mahmood Khan",
      "Hassan Ali Khan",
      "Muhammad Shahzad"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2203.16743"
  },
  {
    "id": "arXiv:2203.16745",
    "title": "Channel Measurement and Characterization with Modified SAGE Algorithm in  an Indoor Corridor at 300 GHz",
    "abstract": "The much higher frequencies in the Terahertz (THz) band prevent the effective\nutilization of channel models dedicated for microwave or millimeter-wave\nfrequency bands. In this paper, a measurement campaign is conducted in an\nindoor corridor scenario at 306-321 GHz with a frequency-domain Vector Network\nAnalyzer (VNA)-based sounder. To realize high-resolution multipath component\n(MPC) extraction for the direction-scan measurement campaigns in the THz band,\na novel modified space-alternating generalized expectation-maximization (SAGE)\nalgorithm is further proposed. Moreover, critical channel characteristics,\nincluding the path loss, shadow fading, K-factor, delay spread, angular\nspreads, cluster parameters, and cross correlations are calculated and analyzed\nin the LoS case. Besides, two contrasted measurement campaigns in the NLoS case\nare conducted, with and without additional reflective foils on walls to serve\nas effective scatterers. Comparison results indicate that the reflective foils\nare useful to improve the channel conditions in the NLoS case by nearly 6 dB,\nwhich is potential to be utilized as alternative of intelligent reflecting\nsurfaces (IRS) to enhance the coverage ability of THz communications.",
    "descriptor": "\nComments: 12 pages, 8 figures\n",
    "authors": [
      "Li Yuanbo",
      "Wang Yiqin",
      "Chen Yi",
      "Yu Ziming",
      "Han Chong"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2203.16745"
  },
  {
    "id": "arXiv:2203.16746",
    "title": "Resilient Distribution System Restoration with Communication Recovery by  Drone Small Cells",
    "abstract": "Distribution system (DS) restoration after natural disasters often faces the\nchallenge of communication failures to feeder automation (FA) facilities,\nresulting in prolonged load pick-up process. This letter discusses the\nutilization of drone small cells for wireless communication recovery of FA, and\nproposes an integrated DS restoration strategy with communication recovery.\nDemonstrative case studies are conducted to validate the proposed model, and\nits advantages are illustrated by comparing to benchmark strategies.",
    "descriptor": "",
    "authors": [
      "Haochen Zhang",
      "Chen Chen",
      "Shunbo Lei",
      "Zhaohong Bie"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.16746"
  },
  {
    "id": "arXiv:2203.16747",
    "title": "How Pre-trained Language Models Capture Factual Knowledge? A  Causal-Inspired Analysis",
    "abstract": "Recently, there has been a trend to investigate the factual knowledge\ncaptured by Pre-trained Language Models (PLMs). Many works show the PLMs'\nability to fill in the missing factual words in cloze-style prompts such as\n\"Dante was born in [MASK].\" However, it is still a mystery how PLMs generate\nthe results correctly: relying on effective clues or shortcut patterns? We try\nto answer this question by a causal-inspired analysis that quantitatively\nmeasures and evaluates the word-level patterns that PLMs depend on to generate\nthe missing words. We check the words that have three typical associations with\nthe missing words: knowledge-dependent, positionally close, and highly\nco-occurred. Our analysis shows: (1) PLMs generate the missing factual words\nmore by the positionally close and highly co-occurred words than the\nknowledge-dependent words; (2) the dependence on the knowledge-dependent words\nis more effective than the positionally close and highly co-occurred words.\nAccordingly, we conclude that the PLMs capture the factual knowledge\nineffectively because of depending on the inadequate associations.",
    "descriptor": "\nComments: Accepted at Findings of ACL 2022\n",
    "authors": [
      "Shaobo Li",
      "Xiaoguang Li",
      "Lifeng Shang",
      "Zhenhua Dong",
      "Chengjie Sun",
      "Bingquan Liu",
      "Zhenzhou Ji",
      "Xin Jiang",
      "Qun Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.16747"
  },
  {
    "id": "arXiv:2203.16748",
    "title": "Topological Optimization with Big Steps",
    "abstract": "Using persistent homology to guide optimization has emerged as a novel\napplication of topological data analysis. Existing methods treat persistence\ncalculation as a black box and backpropagate gradients only onto the simplices\ninvolved in particular pairs. We show how the cycles and chains used in the\npersistence calculation can be used to prescribe gradients to larger subsets of\nthe domain. In particular, we show that in a special case, which serves as a\nbuilding block for general losses, the problem can be solved exactly in linear\ntime. This relies on another contribution of this paper, which eliminates the\nneed to examine a factorial number of permutations of simplices with the same\nvalue. We present empirical experiments that show the practical benefits of our\nalgorithm: the number of steps required for the optimization is reduced by an\norder of magnitude.",
    "descriptor": "\nComments: 10 pages, 10 figures\n",
    "authors": [
      "Arnur Nigmetov",
      "Dmitriy Morozov"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Algebraic Topology (math.AT)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2203.16748"
  },
  {
    "id": "arXiv:2203.16751",
    "title": "An unsupervised cluster-level based method for learning node  representations of heterogeneous graphs in scientific papers",
    "abstract": "Learning knowledge representation of scientific paper data is a problem to be\nsolved, and how to learn the representation of paper nodes in scientific paper\nheterogeneous network is the core to solve this problem. This paper proposes an\nunsupervised cluster-level scientific paper heterogeneous graph node\nrepresentation learning method (UCHL), aiming at obtaining the representation\nof nodes (authors, institutions, papers, etc.) in the heterogeneous graph of\nscientific papers. Based on the heterogeneous graph representation, this paper\nperforms link prediction on the entire heterogeneous graph and obtains the\nrelationship between the edges of the nodes, that is, the relationship between\npapers and papers. Experiments results show that the proposed method achieves\nexcellent performance on multiple evaluation metrics on real scientific paper\ndatasets.",
    "descriptor": "\nComments: 10 pages,3 pages\n",
    "authors": [
      "Jie Song",
      "Meiyu Liang",
      "Zhe Xue",
      "Junping Du",
      "Kou Feifei"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.16751"
  },
  {
    "id": "arXiv:2203.16754",
    "title": "Personalized Image Aesthetics Assessment with Rich Attributes",
    "abstract": "Personalized image aesthetics assessment (PIAA) is challenging due to its\nhighly subjective nature. People's aesthetic tastes depend on diversified\nfactors, including image characteristics and subject characters. The existing\nPIAA databases are limited in terms of annotation diversity, especially the\nsubject aspect, which can no longer meet the increasing demands of PIAA\nresearch. To solve the dilemma, we conduct so far, the most comprehensive\nsubjective study of personalized image aesthetics and introduce a new\nPersonalized image Aesthetics database with Rich Attributes (PARA), which\nconsists of 31,220 images with annotations by 438 subjects. PARA features\nwealthy annotations, including 9 image-oriented objective attributes and 4\nhuman-oriented subjective attributes. In addition, desensitized subject\ninformation, such as personality traits, is also provided to support study of\nPIAA and user portraits. A comprehensive analysis of the annotation data is\nprovided and statistic study indicates that the aesthetic preferences can be\nmirrored by proposed subjective attributes. We also propose a conditional PIAA\nmodel by utilizing subject information as conditional prior. Experimental\nresults indicate that the conditional PIAA model can outperform the control\ngroup, which is also the first attempt to demonstrate how image aesthetics and\nsubject characters interact to produce the intricate personalized tastes on\nimage aesthetics. We believe the database and the associated analysis would be\nuseful for conducting next-generation PIAA study. The project page of PARA can\nbe found at: https://cv-datasets.institutecv.com/#/data-sets.",
    "descriptor": "\nComments: Accepted to CVPR2022\n",
    "authors": [
      "Yuzhe Yang",
      "Liwu Xu",
      "Leida Li",
      "Nan Qie",
      "Yaqian Li",
      "Peng Zhang",
      "Yandong Guo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.16754"
  },
  {
    "id": "arXiv:2203.16755",
    "title": "Stochastic Backpropagation: A Memory Efficient Strategy for Training  Video Models",
    "abstract": "We propose a memory efficient method, named Stochastic Backpropagation (SBP),\nfor training deep neural networks on videos. It is based on the finding that\ngradients from incomplete execution for backpropagation can still effectively\ntrain the models with minimal accuracy loss, which attributes to the high\nredundancy of video. SBP keeps all forward paths but randomly and independently\nremoves the backward paths for each network layer in each training step. It\nreduces the GPU memory cost by eliminating the need to cache activation values\ncorresponding to the dropped backward paths, whose amount can be controlled by\nan adjustable keep-ratio. Experiments show that SBP can be applied to a wide\nrange of models for video tasks, leading to up to 80.0% GPU memory saving and\n10% training speedup with less than 1% accuracy drop on action recognition and\ntemporal action detection.",
    "descriptor": "\nComments: CVPR 2022 Oral\n",
    "authors": [
      "Feng Cheng",
      "Mingze Xu",
      "Yuanjun Xiong",
      "Hao Chen",
      "Xinyu Li",
      "Wei Li",
      "Wei Xia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.16755"
  },
  {
    "id": "arXiv:2203.16756",
    "title": "Casual 6-DoF: free-viewpoint panorama using a handheld 360 camera",
    "abstract": "Six degrees-of-freedom (6-DoF) video provides telepresence by enabling users\nto move around in the captured scene with a wide field of regard. Compared to\nmethods requiring sophisticated camera setups, the image-based rendering method\nbased on photogrammetry can work with images captured with any poses, which is\nmore suitable for casual users. However, existing image-based rendering methods\nare based on perspective images. When used to reconstruct 6-DoF views, it often\nrequires capturing hundreds of images, making data capture a tedious and\ntime-consuming process. In contrast to traditional perspective images,\n360{\\deg} images capture the entire surrounding view in a single shot, thus,\nproviding a faster capturing process for 6-DoF view reconstruction. This paper\npresents a novel method to provide 6-DoF experiences over a wide area using an\nunstructured collection of 360{\\deg} panoramas captured by a conventional\n360{\\deg} camera. Our method consists of 360{\\deg} data capturing, novel depth\nestimation to produce a high-quality spherical depth panorama, and\nhigh-fidelity free-viewpoint generation. We compared our method against\nstate-of-the-art methods, using data captured in various environments. Our\nmethod shows better visual quality and robustness in the tested scenes.",
    "descriptor": "\nComments: 12 pages, 13 figures\n",
    "authors": [
      "Rongsen Chen",
      "Fang-Lue Zhang",
      "Simon Finnie",
      "Andrew Chalmers",
      "Teahyun Rhee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.16756"
  },
  {
    "id": "arXiv:2203.16760",
    "title": "Subjective intelligibility of speech sounds enhanced by ideal ratio mask  via crowdsourced remote experiments with effective data screening",
    "abstract": "It is essential to perform speech intelligibility (SI) experiments with human\nlisteners to evaluate the effectiveness of objective intelligibility measures.\nRecently crowdsourced remote testing has become popular to collect a massive\namount and variety of data with relatively small cost and in short time.\nHowever, careful data screening is essential for attaining reliable SI data. We\ncompared the results of laboratory and crowdsourced remote experiments to\nestablish an effective data screening technique. We evaluated the SI of noisy\nspeech sounds enhanced by a single-channel ideal ratio mask (IRM) and\nmulti-channel mask-based beamformers. The results demonstrated that the SI\nscores were improved by these enhancement methods. In particular, the\nIRM-enhanced sounds were much better than the unprocessed and other enhanced\nsounds, indicating IRM enhancement may give the upper limit of speech\nenhancement performance. Moreover, tone pip tests, for which participants were\nasked to report the number of audible tone pips, reduced the variability of\ncrowdsourced remote results so that the laboratory results became similar. Tone\npip tests could be useful for future crowdsourced experiments because of their\nsimplicity and effectiveness for data screening.",
    "descriptor": "\nComments: This paper was submitted to Interspeech 2022 (this http URL)\n",
    "authors": [
      "Ayako Yamamoto",
      "Toshio Irino",
      "Shoko Araki",
      "Kenichi Arai",
      "Atsunori Ogawa",
      "Keisuke Kinoshita",
      "Tomohiro Nakatani"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.16760"
  },
  {
    "id": "arXiv:2203.16761",
    "title": "MeMOT: Multi-Object Tracking with Memory",
    "abstract": "We propose an online tracking algorithm that performs the object detection\nand data association under a common framework, capable of linking objects after\na long time span. This is realized by preserving a large spatio-temporal memory\nto store the identity embeddings of the tracked objects, and by adaptively\nreferencing and aggregating useful information from the memory as needed. Our\nmodel, called MeMOT, consists of three main modules that are all\nTransformer-based: 1) Hypothesis Generation that produce object proposals in\nthe current video frame; 2) Memory Encoding that extracts the core information\nfrom the memory for each tracked object; and 3) Memory Decoding that solves the\nobject detection and data association tasks simultaneously for multi-object\ntracking. When evaluated on widely adopted MOT benchmark datasets, MeMOT\nobserves very competitive performance.",
    "descriptor": "\nComments: CVPR 2022 Oral\n",
    "authors": [
      "Jiarui Cai",
      "Mingze Xu",
      "Wei Li",
      "Yuanjun Xiong",
      "Wei Xia",
      "Zhuowen Tu",
      "Stefano Soatto"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.16761"
  },
  {
    "id": "arXiv:2203.16762",
    "title": "Mapping Topics in 100,000 Real-life Moral Dilemmas",
    "abstract": "Moral dilemmas play an important role in theorizing both about ethical norms\nand moral psychology. Yet thought experiments borrowed from the philosophical\nliterature often lack the nuances and complexity of real life. We leverage\n100,000 threads -- the largest collection to date -- from Reddit's\nr/AmItheAsshole to examine the features of everyday moral dilemmas. Combining\ntopic modeling with evaluation from both expert and crowd-sourced workers, we\ndiscover 47 finer-grained, meaningful topics and group them into five\nmeta-categories. We show that most dilemmas combine at least two topics, such\nas family and money. We also observe that the pattern of topic co-occurrence\ncarries interesting information about the structure of everyday moral concerns:\nfor example, the generation of moral dilemmas from nominally neutral topics,\nand interaction effects in which final verdicts do not line up with the moral\nconcerns in the original stories in any simple way. Our analysis demonstrates\nthe utility of a fine-grained data-driven approach to online moral dilemmas,\nand provides a valuable resource for researchers aiming to explore the\nintersection of practical and theoretical ethics.",
    "descriptor": "\nComments: To be published in ICWSM 2022\n",
    "authors": [
      "Tuan Dung Nguyen",
      "Georgiana Lyall",
      "Alasdair Tran",
      "Minjeong Shin",
      "Nicholas George Carroll",
      "Colin Klein",
      "Lexing Xie"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2203.16762"
  },
  {
    "id": "arXiv:2203.16763",
    "title": "CREATE: A Benchmark for Chinese Short Video Retrieval and Title  Generation",
    "abstract": "Previous works of video captioning aim to objectively describe the video's\nactual content, which lacks subjective and attractive expression, limiting its\npractical application scenarios. Video titling is intended to achieve this\ngoal, but there is a lack of a proper benchmark. In this paper, we propose to\nCREATE, the first large-scale Chinese shoRt vidEo retrievAl and Title\ngEneration benchmark, to facilitate research and application in video titling\nand video retrieval in Chinese. CREATE consists of a high-quality labeled 210K\ndataset and two large-scale 3M/10M pre-training datasets, covering 51\ncategories, 50K+ tags, 537K manually annotated titles and captions, and 10M+\nshort videos. Based on CREATE, we propose a novel model ALWIG which combines\nvideo retrieval and video titling tasks to achieve the purpose of multi-modal\nALignment WIth Generation with the help of video tags and a GPT pre-trained\nmodel. CREATE opens new directions for facilitating future research and\napplications on video titling and video retrieval in the field of Chinese short\nvideos.",
    "descriptor": "",
    "authors": [
      "Ziqi Zhang",
      "Yuxin Chen",
      "Zongyang Ma",
      "Zhongang Qi",
      "Chunfeng Yuan",
      "Bing Li",
      "Ying Shan",
      "Weiming Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.16763"
  },
  {
    "id": "arXiv:2203.16765",
    "title": "System Level Synthesis Beyond Finite Impulse Response Using  Approximation by Simple Poles",
    "abstract": "Optimal linear feedback control design is valuable but challenging. The\nsystem level synthesis approach uses a reparameterization to expand the class\nof problems that can be solved using convex reformulations, among other\nbenefits. However, to solve system level synthesis problems prior work relies\non finite impulse response approximations that lead to deadbeat control, and\nthat can experience infeasibility and increased suboptimality, especially in\nsystems with large separation of time scales. This work develops a new\ntechnique by combining system level synthesis with a new approximation based on\nsimple poles. The result is a new design method which does not result in\ndeadbeat control, is convex and tractable, always feasible, can incorporate\nprior knowledge, and works well for systems with large separation of time\nscales. A general suboptimality result is provided which bounds the\napproximation error based on the geometry of the pole selection. The bound is\nthen specialized to a particularly interesting pole selection to obtain a\nnon-asymptotic convergence rate. An example demonstrates superior performance\nof the method.",
    "descriptor": "\nComments: 25 pages\n",
    "authors": [
      "Michael W. Fisher",
      "Gabriela Hug",
      "Florian D\u00f6rfler"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.16765"
  },
  {
    "id": "arXiv:2203.16767",
    "title": "SpatioTemporal Focus for Skeleton-based Action Recognition",
    "abstract": "Graph convolutional networks (GCNs) are widely adopted in skeleton-based\naction recognition due to their powerful ability to model data topology. We\nargue that the performance of recent proposed skeleton-based action recognition\nmethods is limited by the following factors. First, the predefined graph\nstructures are shared throughout the network, lacking the flexibility and\ncapacity to model the multi-grain semantic information. Second, the relations\namong the global joints are not fully exploited by the graph local convolution,\nwhich may lose the implicit joint relevance. For instance, actions such as\nrunning and waving are performed by the co-movement of body parts and joints,\ne.g., legs and arms, however, they are located far away in physical connection.\nInspired by the recent attention mechanism, we propose a multi-grain contextual\nfocus module, termed MCF, to capture the action associated relation information\nfrom the body joints and parts. As a result, more explainable representations\nfor different skeleton action sequences can be obtained by MCF. In this study,\nwe follow the common practice that the dense sample strategy of the input\nskeleton sequences is adopted and this brings much redundancy since number of\ninstances has nothing to do with actions. To reduce the redundancy, a temporal\ndiscrimination focus module, termed TDF, is developed to capture the local\nsensitive points of the temporal dynamics. MCF and TDF are integrated into the\nstandard GCN network to form a unified architecture, named STF-Net. It is noted\nthat STF-Net provides the capability to capture robust movement patterns from\nthese skeleton topology structures, based on multi-grain context aggregation\nand temporal dependency. Extensive experimental results show that our STF-Net\nsignificantly achieves state-of-the-art results on three challenging benchmarks\nNTU RGB+D 60, NTU RGB+D 120, and Kinetics-skeleton.",
    "descriptor": "\nComments: Submitted to TCSVT\n",
    "authors": [
      "Liyu Wu",
      "Can Zhang",
      "Yuexian Zou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.16767"
  },
  {
    "id": "arXiv:2203.16768",
    "title": "ReSTR: Convolution-free Referring Image Segmentation Using Transformers",
    "abstract": "Referring image segmentation is an advanced semantic segmentation task where\ntarget is not a predefined class but is described in natural language. Most of\nexisting methods for this task rely heavily on convolutional neural networks,\nwhich however have trouble capturing long-range dependencies between entities\nin the language expression and are not flexible enough for modeling\ninteractions between the two different modalities. To address these issues, we\npresent the first convolution-free model for referring image segmentation using\ntransformers, dubbed ReSTR. Since it extracts features of both modalities\nthrough transformer encoders, it can capture long-range dependencies between\nentities within each modality. Also, ReSTR fuses features of the two modalities\nby a self-attention encoder, which enables flexible and adaptive interactions\nbetween the two modalities in the fusion process. The fused features are fed to\na segmentation module, which works adaptively according to the image and\nlanguage expression in hand. ReSTR is evaluated and compared with previous work\non all public benchmarks, where it outperforms all existing models.",
    "descriptor": "\nComments: CVPR 2022 accepted\n",
    "authors": [
      "Namyup Kim",
      "Dongwon Kim",
      "Cuiling Lan",
      "Wenjun Zeng",
      "Suha Kwak"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.16768"
  },
  {
    "id": "arXiv:2203.16771",
    "title": "LAKe-Net: Topology-Aware Point Cloud Completion by Localizing Aligned  Keypoints",
    "abstract": "Point cloud completion aims at completing geometric and topological shapes\nfrom a partial observation. However, some topology of the original shape is\nmissing, existing methods directly predict the location of complete points,\nwithout predicting structured and topological information of the complete\nshape, which leads to inferior performance. To better tackle the missing\ntopology part, we propose LAKe-Net, a novel topology-aware point cloud\ncompletion model by localizing aligned keypoints, with a novel\nKeypoints-Skeleton-Shape prediction manner. Specifically, our method completes\nmissing topology using three steps: 1) Aligned Keypoint Localization. An\nasymmetric keypoint locator, including an unsupervised multi-scale keypoint\ndetector and a complete keypoint generator, is proposed for localizing aligned\nkeypoints from complete and partial point clouds. We theoretically prove that\nthe detector can capture aligned keypoints for objects within a sub-category.\n2) Surface-skeleton Generation. A new type of skeleton, named Surface-skeleton,\nis generated from keypoints based on geometric priors to fully represent the\ntopological information captured from keypoints and better recover the local\ndetails. 3) Shape Refinement. We design a refinement subnet where multi-scale\nsurface-skeletons are fed into each recursive skeleton-assisted refinement\nmodule to assist the completion process. Experimental results show that our\nmethod achieves the state-of-the-art performance on point cloud completion.",
    "descriptor": "\nComments: 10 pages, 8 figures\n",
    "authors": [
      "Junshu Tang",
      "Zhijun Gong",
      "Ran Yi",
      "Yuan Xie",
      "Lizhuang Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.16771"
  },
  {
    "id": "arXiv:2203.16772",
    "title": "Learning Decoupling Features Through Orthogonality Regularization",
    "abstract": "Keyword spotting (KWS) and speaker verification (SV) are two important tasks\nin speech applications. Research shows that the state-of-art KWS and SV models\nare trained independently using different datasets since they expect to learn\ndistinctive acoustic features. However, humans can distinguish language content\nand the speaker identity simultaneously. Motivated by this, we believe it is\nimportant to explore a method that can effectively extract common features\nwhile decoupling task-specific features. Bearing this in mind, a two-branch\ndeep network (KWS branch and SV branch) with the same network structure is\ndeveloped and a novel decoupling feature learning method is proposed to push up\nthe performance of KWS and SV simultaneously where speaker-invariant keyword\nrepresentations and keyword-invariant speaker representations are expected\nrespectively. Experiments are conducted on Google Speech Commands Dataset\n(GSCD). The results demonstrate that the orthogonality regularization helps the\nnetwork to achieve SOTA EER of 1.31% and 1.87% on KWS and SV, respectively.",
    "descriptor": "\nComments: Accepted at ICASSP 2022\n",
    "authors": [
      "Li Wang",
      "Rongzhi Gu",
      "Weiji Zhuang",
      "Peng Gao",
      "Yujun Wang",
      "Yuexian Zou"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.16772"
  },
  {
    "id": "arXiv:2203.16775",
    "title": "Bangla hate speech detection on social media using attention-based  recurrent neural network",
    "abstract": "Hate speech has spread more rapidly through the daily use of technology and,\nmost notably, by sharing your opinions or feelings on social media in a\nnegative aspect. Although numerous works have been carried out in detecting\nhate speeches in English, German, and other languages, very few works have been\ncarried out in the context of the Bengali language. In contrast, millions of\npeople communicate on social media in Bengali. The few existing works that have\nbeen carried out need improvements in both accuracy and interpretability. This\narticle proposed encoder decoder based machine learning model, a popular tool\nin NLP, to classify user's Bengali comments on Facebook pages. A dataset of\n7,425 Bengali comments, consisting of seven distinct categories of hate\nspeeches, was used to train and evaluate our model. For extracting and encoding\nlocal features from the comments, 1D convolutional layers were used. Finally,\nthe attention mechanism, LSTM, and GRU based decoders have been used for\npredicting hate speech categories. Among the three encoder decoder algorithms,\nthe attention-based decoder obtained the best accuracy (77%).",
    "descriptor": "",
    "authors": [
      "Amit Kumar Das",
      "Abdullah Al Asif",
      "Anik Paul",
      "Md. Nur Hossain"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.16775"
  },
  {
    "id": "arXiv:2203.16777",
    "title": "Mask Atari for Deep Reinforcement Learning as POMDP Benchmarks",
    "abstract": "We present Mask Atari, a new benchmark to help solve partially observable\nMarkov decision process (POMDP) problems with Deep Reinforcement Learning\n(DRL)-based approaches. To achieve a simulation environment for the POMDP\nproblems, Mask Atari is constructed based on Atari 2600 games with\ncontrollable, moveable, and learnable masks as the observation area for the\ntarget agent, especially with the active information gathering (AIG) setting in\nPOMDPs. Given that one does not yet exist, Mask Atari provides a challenging,\nefficient benchmark for evaluating the methods that focus on the above problem.\nMoreover, the mask operation is a trial for introducing the receptive field in\nthe human vision system into a simulation environment for an agent, which means\nthe evaluations are not biased from the sensing ability and purely focus on the\ncognitive performance of the methods when compared with the human baseline. We\ndescribe the challenges and features of our benchmark and evaluate several\nbaselines with Mask Atari.",
    "descriptor": "",
    "authors": [
      "Yang Shao",
      "Quan Kong",
      "Tadayuki Matsumura",
      "Taiki Fuji",
      "Kiyoto Ito",
      "Hiroyuki Mizuno"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.16777"
  },
  {
    "id": "arXiv:2203.16778",
    "title": "ViSTA: Vision and Scene Text Aggregation for Cross-Modal Retrieval",
    "abstract": "Visual appearance is considered to be the most important cue to understand\nimages for cross-modal retrieval, while sometimes the scene text appearing in\nimages can provide valuable information to understand the visual semantics.\nMost of existing cross-modal retrieval approaches ignore the usage of scene\ntext information and directly adding this information may lead to performance\ndegradation in scene text free scenarios. To address this issue, we propose a\nfull transformer architecture to unify these cross-modal retrieval scenarios in\na single $\\textbf{Vi}$sion and $\\textbf{S}$cene $\\textbf{T}$ext\n$\\textbf{A}$ggregation framework (ViSTA). Specifically, ViSTA utilizes\ntransformer blocks to directly encode image patches and fuse scene text\nembedding to learn an aggregated visual representation for cross-modal\nretrieval. To tackle the modality missing problem of scene text, we propose a\nnovel fusion token based transformer aggregation approach to exchange the\nnecessary scene text information only through the fusion token and concentrate\non the most important features in each modality. To further strengthen the\nvisual modality, we develop dual contrastive learning losses to embed both\nimage-text pairs and fusion-text pairs into a common cross-modal space.\nCompared to existing methods, ViSTA enables to aggregate relevant scene text\nsemantics with visual appearance, and hence improve results under both scene\ntext free and scene text aware scenarios. Experimental results show that ViSTA\noutperforms other methods by at least $\\bf{8.4}\\%$ at Recall@1 for scene text\naware retrieval task. Compared with state-of-the-art scene text free retrieval\nmethods, ViSTA can achieve better accuracy on Flicker30K and MSCOCO while\nrunning at least three times faster during the inference stage, which validates\nthe effectiveness of the proposed framework.",
    "descriptor": "\nComments: Accepted by CVPR 2022\n",
    "authors": [
      "Mengjun Cheng",
      "Yipeng Sun",
      "Longchao Wang",
      "Xiongwei Zhu",
      "Kun Yao",
      "Jie Chen",
      "Guoli Song",
      "Junyu Han",
      "Jingtuo Liu",
      "Errui Ding",
      "Jingdong Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.16778"
  },
  {
    "id": "arXiv:2203.16780",
    "title": "A Pixel-based Encryption Method for Privacy-Preserving Deep Learning  Models",
    "abstract": "In the recent years, pixel-based perceptual algorithms have been successfully\napplied for privacy-preserving deep learning (DL) based applications. However,\ntheir security has been broken in subsequent works by demonstrating a\nchosen-plaintext attack. In this paper, we propose an efficient pixel-based\nperceptual encryption method. The method provides a necessary level of security\nwhile preserving the intrinsic properties of the original image. Thereby, can\nenable deep learning (DL) applications in the encryption domain. The method is\nsubstitution based where pixel values are XORed with a sequence (as opposed to\na single value used in the existing methods) generated by a chaotic map. We\nhave used logistic maps for their low computational requirements. In addition,\nto compensate for any inefficiency because of the logistic maps, we use a\nsecond key to shuffle the sequence. We have compared the proposed method in\nterms of encryption efficiency and classification accuracy of the DL models on\nthem. We have validated the proposed method with CIFAR datasets. The analysis\nshows that when classification is performed on the cipher images, the model\npreserves accuracy of the existing methods while provides better security.",
    "descriptor": "\nComments: in the proceedings of the Korean Institute of Communications and Information Sciences (KICS) Winter Conference, Pyeongchang, Korea, Feb 2022\n",
    "authors": [
      "Ijaz Ahmad",
      "Seokjoo Shin"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2203.16780"
  },
  {
    "id": "arXiv:2203.16781",
    "title": "Misogynistic Meme Detection using Early Fusion Model with Graph Network",
    "abstract": "In recent years , there has been an upsurge in a new form of entertainment\nmedium called memes. These memes although seemingly innocuous have transcended\nonto the boundary of online harassment against women and created an unwanted\nbias against them . To help alleviate this problem , we propose an early fusion\nmodel for prediction and identification of misogynistic memes and its type in\nthis paper for which we participated in SemEval-2022 Task 5 . The model\nreceives as input meme image with its text transcription with a target vector.\nGiven that a key challenge with this task is the combination of different\nmodalities to predict misogyny, our model relies on pretrained contextual\nrepresentations from different state-of-the-art transformer-based language\nmodels and pretrained image pretrained models to get an effective image\nrepresentation. Our model achieved competitive results on both SubTask-A and\nSubTask-B with the other competition teams and significantly outperforms the\nbaselines.",
    "descriptor": "",
    "authors": [
      "Harshvardhan Srivastava"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.16781"
  },
  {
    "id": "arXiv:2203.16782",
    "title": "Weakly Supervised Patch Label Inference Networks for Efficient Pavement  Distress Detection and Recognition in the Wild",
    "abstract": "Automatic image-based pavement distress detection and recognition are vital\nfor pavement maintenance and management. However, existing deep learning-based\nmethods largely omit the specific characteristics of pavement images, such as\nhigh image resolution and low distress area ratio, and are not end-to-end\ntrainable. In this paper, we present a series of simple yet effective\nend-to-end deep learning approaches named Weakly Supervised Patch Label\nInference Networks (WSPLIN) for efficiently addressing these tasks under\nvarious application settings. To fully exploit the resolution and scale\ninformation, WSPLIN first divides the pavement image under different scales\ninto patches with different collection strategies and then employs a Patch\nLabel Inference Network (PLIN) to infer the labels of these patches. Notably,\nwe design a patch label sparsity constraint based on the prior knowledge of\ndistress distribution, and leverage the Comprehensive Decision Network (CDN) to\nguide the training of PLIN in a weakly supervised way. Therefore, the patch\nlabels produced by PLIN provide interpretable intermediate information, such as\nthe rough location and the type of distress. We evaluate our method on a\nlarge-scale bituminous pavement distress dataset named CQU-BPDD. Extensive\nresults demonstrate the superiority of our method over baselines in both\nperformance and efficiency.",
    "descriptor": "\nComments: Extension of ICASSP 2021 Paper entitled \"Weakly Supervised Patch Label Inference Network with Image Pyramid for Pavement Diseases Recognition in the Wild\", Submitted to IEEE T-ITS\n",
    "authors": [
      "Sheng Huang",
      "Wenhao Tang",
      "Guixin Huang",
      "Luwen Huangfu",
      "Dan Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.16782"
  },
  {
    "id": "arXiv:2203.16784",
    "title": "Video-Text Representation Learning via Differentiable Weak Temporal  Alignment",
    "abstract": "Learning generic joint representations for video and text by a supervised\nmethod requires a prohibitively substantial amount of manually annotated video\ndatasets. As a practical alternative, a large-scale but uncurated and narrated\nvideo dataset, HowTo100M, has recently been introduced. But it is still\nchallenging to learn joint embeddings of video and text in a self-supervised\nmanner, due to its ambiguity and non-sequential alignment. In this paper, we\npropose a novel multi-modal self-supervised framework Video-Text Temporally\nWeak Alignment-based Contrastive Learning (VT-TWINS) to capture significant\ninformation from noisy and weakly correlated data using a variant of Dynamic\nTime Warping (DTW). We observe that the standard DTW inherently cannot handle\nweakly correlated data and only considers the globally optimal alignment path.\nTo address these problems, we develop a differentiable DTW which also reflects\nlocal information with weak temporal alignment. Moreover, our proposed model\napplies a contrastive learning scheme to learn feature representations on\nweakly correlated data. Our extensive experiments demonstrate that VT-TWINS\nattains significant improvements in multi-modal representation learning and\noutperforms various challenging downstream tasks. Code is available at\nhttps://github.com/mlvlab/VT-TWINS.",
    "descriptor": "",
    "authors": [
      "Dohwan Ko",
      "Joonmyung Choi",
      "Juyeon Ko",
      "Shinyeong Noh",
      "Kyoung-Woon On",
      "Eun-Sol Kim",
      "Hyunwoo J. Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.16784"
  },
  {
    "id": "arXiv:2203.16786",
    "title": "Latent Sub-structural Resilience Mechanisms in Temporal Human Mobility  Networks during Urban Flooding",
    "abstract": "In studying resilience in temporal human networks, relying solely on global\nnetwork measures would be inadequate; latent sub-structural network mechanisms\nneed to be examined to determine the extent of impact and recovery of these\nnetworks during perturbations, such as urban flooding. In this study, we\nutilized high-resolution aggregated location-based disaster related data to\nconstruct temporal human mobility networks. Using the constructed temporal\nnetwork models, we examined characteristics such as motif distribution, motif\npersistence and temporal stability, and motif attributes to reveal latent\nsub-structural mechanisms related to the resilience of human mobility networks\nduring disaster-induced perturbations. The results show that urban flood\nimpacts persists in human mobility networks at the sub-structure level for\nseveral weeks. The impact extent and recovery duration is heterogeneous across\ndifferent network types. Also, perturbation impacts persist at the\nsub-structure level while global topological network properties might indicate\nthe network has recovered. The findings highlight the importance of examining\nthe microstructures and their dynamic processes and attributes in understanding\nthe resilience of temporal human mobility networks (and other temporal\nnetworks), it is essential to examine the microstructures and their\nperturbation impacts and recovery. The findings can also provide disaster\nmanagers, public officials, and transportation planners with insights to better\nevaluate impacts and to monitor recovery in affected communities based on the\npatterns of impact and recovery in human mobility networks at both\nsub-structure and global-network levels.",
    "descriptor": "",
    "authors": [
      "Akhil Anil Rajput",
      "Ali Mostafavi"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2203.16786"
  },
  {
    "id": "arXiv:2203.16787",
    "title": "Reflection and Rotation Symmetry Detection via Equivariant Learning",
    "abstract": "The inherent challenge of detecting symmetries stems from arbitrary\norientations of symmetry patterns; a reflection symmetry mirrors itself against\nan axis with a specific orientation while a rotation symmetry matches its\nrotated copy with a specific orientation. Discovering such symmetry patterns\nfrom an image thus benefits from an equivariant feature representation, which\nvaries consistently with reflection and rotation of the image. In this work, we\nintroduce a group-equivariant convolutional network for symmetry detection,\ndubbed EquiSym, which leverages equivariant feature maps with respect to a\ndihedral group of reflection and rotation. The proposed network is built\nend-to-end with dihedrally-equivariant layers and trained to output a spatial\nmap for reflection axes or rotation centers. We also present a new dataset,\nDENse and DIverse symmetry (DENDI), which mitigates limitations of existing\nbenchmarks for reflection and rotation symmetry detection. Experiments show\nthat our method achieves the state of the arts in symmetry detection on LDRS\nand DENDI datasets.",
    "descriptor": "\nComments: To be appear at CVPR 2022\n",
    "authors": [
      "Ahyun Seo",
      "Byungjin Kim",
      "Suha Kwak",
      "Minsu Cho"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.16787"
  },
  {
    "id": "arXiv:2203.16788",
    "title": "ESGBERT: Language Model to Help with Classification Tasks Related to  Companies Environmental, Social, and Governance Practices",
    "abstract": "Environmental, Social, and Governance (ESG) are non-financial factors that\nare garnering attention from investors as they increasingly look to apply these\nas part of their analysis to identify material risks and growth opportunities.\nSome of this attention is also driven by clients who, now more aware than ever,\nare demanding for their money to be managed and invested responsibly. As the\ninterest in ESG grows, so does the need for investors to have access to\nconsumable ESG information. Since most of it is in text form in reports,\ndisclosures, press releases, and 10-Q filings, we see a need for sophisticated\nNLP techniques for classification tasks for ESG text. We hypothesize that an\nESG domain-specific pre-trained model will help with such and study building of\nthe same in this paper. We explored doing this by fine-tuning BERTs pre-trained\nweights using ESG specific text and then further fine-tuning the model for a\nclassification task. We were able to achieve accuracy better than the original\nBERT and baseline models in environment-specific classification tasks.",
    "descriptor": "",
    "authors": [
      "Srishti Mehra",
      "Robert Louka",
      "Yixun Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.16788"
  },
  {
    "id": "arXiv:2203.16792",
    "title": "TrajGen: Generating Realistic and Diverse Trajectories with Reactive and  Feasible Agent Behaviors for Autonomous Driving",
    "abstract": "Realistic and diverse simulation scenarios with reactive and feasible agent\nbehaviors can be used for validation and verification of self-driving system\nperformance without relying on expensive and time-consuming real-world testing.\nExisting simulators rely on heuristic-based behavior models for background\nvehicles, which cannot capture the complex interactive behaviors in real-world\nscenarios. To bridge the gap between simulation and the real world, we propose\nTrajGen, a two-stage trajectory generation framework, which can capture more\nrealistic behaviors directly from human demonstration. In particular, TrajGen\nconsists of the multi-modal trajectory prediction stage and the reinforcement\nlearning based trajectory modification stage. In the first stage, we propose a\nnovel auxiliary RouteLoss for the trajectory prediction model to generate\nmulti-modal diverse trajectories in the drivable area. In the second stage,\nreinforcement learning is used to track the predicted trajectories while\navoiding collisions, which can improve the feasibility of generated\ntrajectories. In addition, we develop a data-driven simulator I-Sim that can be\nused to train reinforcement learning models in parallel based on naturalistic\ndriving data. The vehicle model in I-Sim can guarantee that the generated\ntrajectories by TrajGen satisfy vehicle kinematic constraints. Finally, we give\ncomprehensive metrics to evaluate generated trajectories for simulation\nscenarios, which shows that TrajGen outperforms either trajectory prediction or\ninverse reinforcement learning in terms of fidelity, reactivity, feasibility,\nand diversity.",
    "descriptor": "",
    "authors": [
      "Qichao Zhang",
      "Yinfeng Gao",
      "Yikang Zhang",
      "Youtian Guo",
      "Dawei Ding",
      "Yunpeng Wang",
      "Peng Sun",
      "Dongbin Zhao"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.16792"
  },
  {
    "id": "arXiv:2203.16793",
    "title": "Topology optimization of locomoting soft bodies using material point  method",
    "abstract": "Topology optimization methods have widely been used in various industries,\nowing to their potential for providing promising design candidates for\nmechanical devices. However, their applications are usually limited to the\nobjects which do not move significantly due to the difficulty in\ncomputationally efficient handling of the contact and interactions among\nmultiple structures or with boundaries by conventionally used simulation\ntechniques. In the present study, we propose a topology optimization method for\nmoving objects incorporating the material point method, which is often used to\nsimulate the motion of objects in the field of computer graphics. Several\nnumerical experiments demonstrate the effectiveness and the utility of the\nproposed method.",
    "descriptor": "",
    "authors": [
      "Yuki Sato",
      "Hiroki Kobayashi",
      "Changyoung Yuhn",
      "Atsushi Kawamoto",
      "Tsuyoshi Nomura",
      "Noboru Kikuchi"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2203.16793"
  },
  {
    "id": "arXiv:2203.16794",
    "title": "MMER: Multimodal Multi-task learning for Emotion Recognition in Spoken  Utterances",
    "abstract": "Emotion Recognition (ER) aims to classify human utterances into different\nemotion categories. Based on early-fusion and self-attention-based multimodal\ninteraction between text and acoustic modalities, in this paper, we propose a\nmultimodal multitask learning approach for ER from individual utterances in\nisolation. Experiments on the IEMOCAP benchmark show that our proposed model\nperforms better than our re-implementation of state-of-the-art and achieves\nbetter performance than all other unimodal and multimodal approaches in\nliterature. In addition, strong baselines and ablation studies prove the\neffectiveness of our proposed approach. We make all our codes publicly\navailable on GitHub.",
    "descriptor": "",
    "authors": [
      "Harshvardhan Srivastava",
      "Sreyan Ghosh",
      "S. Umesh"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.16794"
  },
  {
    "id": "arXiv:2203.16795",
    "title": "Deformable Video Transformer",
    "abstract": "Video transformers have recently emerged as an effective alternative to\nconvolutional networks for action classification. However, most prior video\ntransformers adopt either global space-time attention or hand-defined\nstrategies to compare patches within and across frames. These fixed attention\nschemes not only have high computational cost but, by comparing patches at\npredetermined locations, they neglect the motion dynamics in the video. In this\npaper, we introduce the Deformable Video Transformer (DVT), which dynamically\npredicts a small subset of video patches to attend for each query location\nbased on motion information, thus allowing the model to decide where to look in\nthe video based on correspondences across frames. Crucially, these motion-based\ncorrespondences are obtained at zero-cost from information stored in the\ncompressed format of the video. Our deformable attention mechanism is optimised\ndirectly with respect to classification performance, thus eliminating the need\nfor suboptimal hand-design of attention strategies. Experiments on four\nlarge-scale video benchmarks (Kinetics-400, Something-Something-V2,\nEPIC-KITCHENS and Diving-48) demonstrate that, compared to existing video\ntransformers, our model achieves higher accuracy at the same or lower\ncomputational cost, and it attains state-of-the-art results on these four\ndatasets.",
    "descriptor": "\nComments: Accepted in CVPR 2022\n",
    "authors": [
      "Jue Wang",
      "Lorenzo Torresani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.16795"
  },
  {
    "id": "arXiv:2203.16796",
    "title": "Delays have Dangerous Ends: Slow HTTP/2 DoS attacks into the Wild and  their Real-Time Detection using Event Sequence Analysis",
    "abstract": "The robustness principle, written by Jon Postel in an early version of TCP\nimplementation, states that the communicating entities should be liberal while\naccepting the data. Several entities on the Internet do follow this principle.\nFor instance, in this work, we show that many popular web servers on the\nInternet are generous as they wait for a substantial time period to receive the\nremaining portion of an incomplete web request. Unfortunately, this behavior\nalso makes them vulnerable to a class of cyber attacks, commonly known as Slow\nRate DoS attacks. HTTP/2, the recent version of HTTP, is recently found\nvulnerable to these attacks. However, the impact of Slow HTTP/2 DoS attacks on\nreal web servers on the Internet has not been studied yet. Also, to the best of\nour knowledge, there is no defense scheme known to detect Slow Rate DoS attacks\nagainst HTTP/2 in real-time. To bridge these gaps, we first test the behavior\nof HTTP/2 supporting web servers on the Internet against Slow HTTP/2 DoS\nattacks. Subsequently, we propose a scheme to detect these attacks in\nreal-time. We show that the proposed detection scheme can detect attacks in\nreal-time with high accuracy and marginal computational overhead.",
    "descriptor": "\nComments: 11 pages, 8 figures\n",
    "authors": [
      "Nikhil Tripathi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2203.16796"
  },
  {
    "id": "arXiv:2203.16797",
    "title": "When Physics Meets Machine Learning: A Survey of Physics-Informed  Machine Learning",
    "abstract": "Physics-informed machine learning (PIML), referring to the combination of\nprior knowledge of physics, which is the high level abstraction of natural\nphenomenons and human behaviours in the long history, with data-driven machine\nlearning models, has emerged as an effective way to mitigate the shortage of\ntraining data, to increase models' generalizability and to ensure the physical\nplausibility of results. In this paper, we survey an abundant number of recent\nworks in PIML and summarize them from three aspects: (1) motivations of PIML,\n(2) physics knowledge in PIML, (3) methods of physics knowledge integration in\nPIML. We also discuss current challenges and corresponding research\nopportunities in PIML.",
    "descriptor": "",
    "authors": [
      "Chuizheng Meng",
      "Sungyong Seo",
      "Defu Cao",
      "Sam Griesemer",
      "Yan Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.16797"
  },
  {
    "id": "arXiv:2203.16798",
    "title": "Ternary and Binary Quantization for Improved Classification",
    "abstract": "Dimension reduction and data quantization are two important methods for\nreducing data complexity. In the paper, we study the methodology of first\nreducing data dimension by random projection and then quantizing the\nprojections to ternary or binary codes, which has been widely applied in\nclassification. Usually, the quantization will seriously degrade the accuracy\nof classification due to high quantization errors. Interestingly, however, we\nobserve that the quantization could provide comparable and often superior\naccuracy, as the data to be quantized are sparse features generated with common\nfilters. Furthermore, this quantization property could be maintained in the\nrandom projections of sparse features, if both the features and random\nprojection matrices are sufficiently sparse. By conducting extensive\nexperiments, we validate and analyze this intriguing property.",
    "descriptor": "",
    "authors": [
      "Weizhi Lu",
      "Mingrui Chen",
      "Kai Guo",
      "Weiyu Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.16798"
  },
  {
    "id": "arXiv:2203.16799",
    "title": "A Discourse Aware Sequence Learning Approach for Emotion Recognition in  Conversations",
    "abstract": "The expression of emotions is a crucial part of daily human communication.\nModeling the conversational and sequential context has seen much success and\nplays a vital role in Emotion Recognition in Conversations (ERC). However,\nexisting approaches either model only one of the two or employ naive\nlate-fusion methodologies to obtain final utterance representations. This paper\nproposes a novel idea to incorporate both these contexts and better model the\nintrinsic structure within a conversation. More precisely, we propose a novel\narchitecture boosted by a modified LSTM cell, which we call DiscLSTM, that\nbetter captures the interaction between conversational and sequential context.\nDiscLSTM brings together the best of both worlds and provides a more intuitive\nand efficient way to model the information flow between individual utterances\nby better capturing long-distance conversational background through discourse\nrelations and sequential context through recurrence. We conduct experiments on\nfour benchmark datasets for ERC and show that our model achieves performance\ncompetitive to state-of-the-art and at times performs better than other\ngraph-based approaches in literature, with a conversational graph that is both\nsparse and avoids complicated edge relations like much of previous work. We\nmake all our codes publicly available on GitHub.",
    "descriptor": "",
    "authors": [
      "Sreyan Ghosh",
      "Harshvardhan Srivastava",
      "S. Umesh"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.16799"
  },
  {
    "id": "arXiv:2203.16800",
    "title": "Fine-grained Temporal Contrastive Learning for Weakly-supervised  Temporal Action Localization",
    "abstract": "We target at the task of weakly-supervised action localization (WSAL), where\nonly video-level action labels are available during model training. Despite the\nrecent progress, existing methods mainly embrace a\nlocalization-by-classification paradigm and overlook the fruitful fine-grained\ntemporal distinctions between video sequences, thus suffering from severe\nambiguity in classification learning and classification-to-localization\nadaption. This paper argues that learning by contextually comparing\nsequence-to-sequence distinctions offers an essential inductive bias in WSAL\nand helps identify coherent action instances. Specifically, under a\ndifferentiable dynamic programming formulation, two complementary contrastive\nobjectives are designed, including Fine-grained Sequence Distance (FSD)\ncontrasting and Longest Common Subsequence (LCS) contrasting, where the first\none considers the relations of various action/background proposals by using\nmatch, insert, and delete operators and the second one mines the longest common\nsubsequences between two videos. Both contrasting modules can enhance each\nother and jointly enjoy the merits of discriminative action-background\nseparation and alleviated task gap between classification and localization.\nExtensive experiments show that our method achieves state-of-the-art\nperformance on two popular benchmarks. Our code is available at\nhttps://github.com/MengyuanChen21/CVPR2022-FTCL.",
    "descriptor": "\nComments: Accepted by CVPR 2022. Code is available at this https URL\n",
    "authors": [
      "Junyu Gao",
      "Mengyuan Chen",
      "Changsheng Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.16800"
  },
  {
    "id": "arXiv:2203.16801",
    "title": "Robust Meta-Reinforcement Learning with Curriculum-Based Task Sampling",
    "abstract": "Meta-reinforcement learning (meta-RL) acquires meta-policies that show good\nperformance for tasks in a wide task distribution. However, conventional\nmeta-RL, which learns meta-policies by randomly sampling tasks, has been\nreported to show meta-overfitting for certain tasks, especially for easy tasks\nwhere an agent can easily get high scores. To reduce effects of the\nmeta-overfitting, we considered meta-RL with curriculum-based task sampling.\nOur method is Robust Meta Reinforcement Learning with Guided Task Sampling\n(RMRL-GTS), which is an effective method that restricts task sampling based on\nscores and epochs. We show that in order to achieve robust meta-RL, it is\nnecessary not only to intensively sample tasks with poor scores, but also to\nrestrict and expand the task regions of the tasks to be sampled.",
    "descriptor": "",
    "authors": [
      "Morio Matsumoto",
      "Hiroya Matsuba",
      "Toshihiro Kujirai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.16801"
  },
  {
    "id": "arXiv:2203.16802",
    "title": "SIERRA: Ranking Anomalous Activities in Enterprise Networks",
    "abstract": "An enterprise today deploys multiple security middleboxes such as firewalls,\nIDS, IPS, etc. in its network to collect different kinds of events related to\nthreats and attacks. These events are streamed into a SIEM (Security\nInformation and Event Management) system for analysts to investigate and\nrespond quickly with appropriate actions. However, the number of events\ncollected for a single enterprise can easily run into hundreds of thousands per\nday, much more than what analysts can investigate under a given budget\nconstraint (time). In this work, we look into the problem of prioritizing\nsuspicious events or anomalies to analysts for further investigation. We\ndevelop SIERRA, a system that processes event logs from multiple and diverse\nmiddleboxes to detect and rank anomalous activities. SIERRA takes an\nunsupervised approach and therefore has no dependence on ground truth data.\nDifferent from other works, SIERRA defines contexts, that help it to provide\nvisual explanations of highly-ranked anomalous points to analysts, despite\nemploying unsupervised models. We evaluate SIERRA using months of logs from\nmultiple security middleboxes of an enterprise network. The evaluations\ndemonstrate the capability of SIERRA to detect top anomalies in a network while\noutperforming naive application of existing anomaly detection algorithms as\nwell as a state-of-the-art SIEM-based anomaly detection solution.",
    "descriptor": "\nComments: to appear in IEEE European Symposium on Security and Privacy (EuroS&P) 2022\n",
    "authors": [
      "Jehyun Lee",
      "Farren Tang",
      "Phyo May Thet",
      "Desmond Yeoh",
      "Mitch Rybczynski",
      "Dinil Mon Divakaran"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2203.16802"
  },
  {
    "id": "arXiv:2203.16803",
    "title": "Attack Impact Evaluation by Exact Convexification through State Space  Augmentation",
    "abstract": "We address the attack impact evaluation problem for control system security.\nWe formulate the problem as a Markov decision process with a temporally joint\nchance constraint that forces the adversary to avoid being detected throughout\nthe considered time period. Owing to the joint constraint, the optimal control\npolicy depends not only on the current state but also on the entire history,\nwhich leads to the explosion of the search space and makes the problem\ngenerally intractable. It is shown that whether an alarm has been triggered or\nnot, in addition to the current state is sufficient for specifying the optimal\ndecision at each time step. Augmentation of the information to the state space\ninduces an equivalent convex optimization problem, which is tractable using\nstandard solvers.",
    "descriptor": "\nComments: 8 pages\n",
    "authors": [
      "Hampei Sasahara",
      "Takashi Tanaka",
      "Henrik Sandberg"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2203.16803"
  },
  {
    "id": "arXiv:2203.16804",
    "title": "BRIO: Bringing Order to Abstractive Summarization",
    "abstract": "Abstractive summarization models are commonly trained using maximum\nlikelihood estimation, which assumes a deterministic (one-point) target\ndistribution in which an ideal model will assign all the probability mass to\nthe reference summary. This assumption may lead to performance degradation\nduring inference, where the model needs to compare several system-generated\n(candidate) summaries that have deviated from the reference summary. To address\nthis problem, we propose a novel training paradigm which assumes a\nnon-deterministic distribution so that different candidate summaries are\nassigned probability mass according to their quality. Our method achieves a new\nstate-of-the-art result on the CNN/DailyMail (47.78 ROUGE-1) and XSum (49.07\nROUGE-1) datasets. Further analysis also shows that our model can estimate\nprobabilities of candidate summaries that are more correlated with their level\nof quality.",
    "descriptor": "\nComments: ACL 2022\n",
    "authors": [
      "Yixin Liu",
      "Pengfei Liu",
      "Dragomir Radev",
      "Graham Neubig"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.16804"
  },
  {
    "id": "arXiv:2203.16807",
    "title": "Joint Power Allocation and Rate Control for Rate Splitting Multiple  Access Networks with Covert Communications",
    "abstract": "Rate Splitting Multiple Access (RSMA) has recently emerged as a promising\ntechnique to enhance the transmission rate for multiple access networks. Unlike\nconventional multiple access schemes, RSMA requires splitting and transmitting\nmessages at different rates. The joint optimization of the power allocation and\nrate control at the transmitter is challenging given the uncertainty and\ndynamics of the environment. Furthermore, securing transmissions in RSMA\nnetworks is a crucial problem because the messages transmitted can be easily\nexposed to adversaries. This work first proposes a stochastic optimization\nframework that allows the transmitter to adaptively adjust its power and\ntransmission rates allocated to users, and thereby maximizing the sum-rate and\nfairness of the system under the presence of an adversary. We then develop a\nhighly effective learning algorithm that can help the transmitter to find the\noptimal policy without requiring complete information about the environment in\nadvance. Extensive simulations show that our proposed scheme can achieve\npositive covert transmission rates in the finite blocklength regime and\nnon-saturating rates at high SNR values. More significantly, our achievable\ncovert rate can be increased at high SNR values (i.e., 20 dB to 40 dB),\ncompared with saturating rates of a conventional multiple access scheme.",
    "descriptor": "",
    "authors": [
      "Nguyen Quang Hieu",
      "Dinh Thai Hoang",
      "Dusit Niyato",
      "Diep N. Nguyen",
      "Dong In Kim",
      "Abbas Jamalipour"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2203.16807"
  },
  {
    "id": "arXiv:2203.16810",
    "title": "Adaptive Estimation of Random Vectors with Bandit Feedback",
    "abstract": "We consider the problem of sequentially learning to estimate, in the mean\nsquared error (MSE) sense, a Gaussian $K$-vector of unknown covariance by\nobserving only $m < K$ of its entries in each round. This reduces to learning\nan optimal subset for estimating the entire vector. Towards this, we first\nestablish an exponential concentration bound for an estimate of the MSE for\neach observable subset. We then frame the estimation problem with bandit\nfeedback in the best-subset identification setting. We propose a variant of the\nsuccessive elimination algorithm to cater to the adaptive estimation problem,\nand we derive an upper bound on the sample complexity of this algorithm. In\naddition, to understand the fundamental limit on the sample complexity of this\nadaptive estimation bandit problem, we derive a minimax lower bound.",
    "descriptor": "",
    "authors": [
      "Dipayan Sen",
      "Prashanth L.A.",
      "Aditya Gopalan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.16810"
  },
  {
    "id": "arXiv:2203.16811",
    "title": "Approximate Sensitivity Conditioning and Singular Perturbation Analysis  for Power Converters",
    "abstract": "A feed-forward sensitivity conditioning control strategy is analyzed in this\npaper and it is applied to power electronic converters. The feed-forward term\nis used to improve closed loop systems, such as power converters with cascaded\ninner and outer loop controllers. The impact of the feed-forward sensitivity\nterm is analyzed using singular perturbation theory. In addition, the\nimplementation of the feed-forward control term is addressed for practical\nsystems, where the number of inputs is generally not sufficient for exact\nsensitivity conditioning. Simulation results are presented for a buck converter\nwith output capacitor voltage regulation and a Permanent Magnet Synchronous\nMachine (PMSM), used as a generator with an active rectifier. Finally,\nexperimental results are presented for the buck converter, demonstrating the\nadvantages and feasibility in implementing the approximate sensitivity\nconditioning term for closed loop power converters.",
    "descriptor": "",
    "authors": [
      "Kaushik Gajula",
      "Lalit Kishore Marepalli",
      "Luis Herrera"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.16811"
  },
  {
    "id": "arXiv:2203.16816",
    "title": "Budget-Constrained Auctions with Unassured Priors",
    "abstract": "In today's online advertising markets, it is common for an advertiser to set\na long-period budget. Correspondingly, advertising platforms adopt budget\ncontrol methods to ensure that any advertiser's payment is within her budget.\nMost budget control methods rely on value distributions of advertisers.\nHowever, due to the complex environment advertisers stand in and privacy\nissues, the platform hardly learns their true priors. Therefore, it is\nessential to understand how budget control auction mechanisms perform under\nunassured priors.\nThis paper gives a two-fold answer. First, we propose a bid-discount method\nbarely studied in the literature. We show that such a method exhibits desirable\nproperties in revenue-maximizing and computation when fitting into first-price\nauction. Second, we compare this mechanism with another four in the prior\nmanipulation model, where an advertiser can arbitrarily report a value\ndistribution to the platform. These four mechanisms include the optimal\nmechanism satisfying budget-constrained IC, first-price/second-price mechanisms\nwith the widely-studied pacing method, and an application of bid-discount in\nsecond-price mechanism. We consider three settings under the model, depending\non whether the reported priors are fixed and advertisers are symmetric or not.\nWe show that under all three cases, the bid-discount first-price auction we\nintroduce dominates the other four mechanisms concerning the platform's\nrevenue. For the advertisers' side, we show a surprising strategic-equivalence\nresult between this mechanism and the optimal auction. Extensive revenue\ndominance and strategic relationships among these mechanisms are also revealed.\nBased on these findings, we provide a thorough understanding of prior\ndependency in repeated auctions with budgets. The bid-discount first-price\nauction itself may also be of further independent research interest.",
    "descriptor": "\nComments: 47 pages, 2 figures, 1 table. In review\n",
    "authors": [
      "Zhaohua Chen",
      "Xiaotie Deng",
      "Jicheng Li",
      "Chang Wang",
      "Mingwei Yang"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Theoretical Economics (econ.TH)"
    ],
    "url": "https://arxiv.org/abs/2203.16816"
  },
  {
    "id": "arXiv:2203.16823",
    "title": "Effectiveness of text to speech pseudo labels for forced alignment and  cross lingual pretrained models for low resource speech recognition",
    "abstract": "In the recent years end to end (E2E) automatic speech recognition (ASR)\nsystems have achieved promising results given sufficient resources. Even for\nlanguages where not a lot of labelled data is available, state of the art E2E\nASR systems can be developed by pretraining on huge amounts of high resource\nlanguages and finetune on low resource languages. For a lot of low resource\nlanguages the current approaches are still challenging, since in many cases\nlabelled data is not available in open domain. In this paper we present an\napproach to create labelled data for Maithili, Bhojpuri and Dogri by utilising\npseudo labels from text to speech for forced alignment. The created data was\ninspected for quality and then further used to train a transformer based\nwav2vec 2.0 ASR model. All data and models are available in open domain.",
    "descriptor": "\nComments: Submitted to InterSpeech 2022\n",
    "authors": [
      "Anirudh Gupta",
      "Rishabh Gaur",
      "Ankur Dhuriya",
      "Harveen Singh Chadha",
      "Neeraj Chhimwal",
      "Priyanshi Shah",
      "Vivek Raghavan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.16823"
  },
  {
    "id": "arXiv:2203.16825",
    "title": "indic-punct: An automatic punctuation restoration and inverse text  normalization framework for Indic languages",
    "abstract": "Automatic Speech Recognition (ASR) generates text which is most of the times\ndevoid of any punctuation. Absence of punctuation is text can affect\nreadability. Also, down stream NLP tasks such as sentiment analysis, machine\ntranslation, greatly benefit by having punctuation and sentence boundary\ninformation. We present an approach for automatic punctuation of text using a\npretrained IndicBERT model. Inverse text normalization is done by hand writing\nweighted finite state transducer (WFST) grammars. We have developed this tool\nfor 11 Indic languages namely Hindi, Tamil, Telugu, Kannada, Gujarati, Marathi,\nOdia, Bengali, Assamese, Malayalam and Punjabi. All code and data is publicly.\navailable",
    "descriptor": "\nComments: Submitted to InterSpeech 2022. arXiv admin note: text overlap with arXiv:2104.05055 by other authors\n",
    "authors": [
      "Anirudh Gupta",
      "Neeraj Chhimwal",
      "Ankur Dhuriya",
      "Rishabh Gaur",
      "Priyanshi Shah",
      "Harveen Singh Chadha",
      "Vivek Raghavan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.16825"
  },
  {
    "id": "arXiv:2203.16826",
    "title": "Remote State Estimation of Multiple Systems over Semi-Markov Wireless  Fading Channels",
    "abstract": "This work studies remote state estimation of multiple linear time-invariant\nsystems over shared wireless time-varying communication channels. We model the\nchannel states by a semi-Markov process which captures both the random holding\nperiod of each channel state and the state transitions. The model is\nsufficiently general to be used in both fast and slow fading scenarios. We\nderive necessary and sufficient stability conditions of the\nmulti-sensor-multi-channel system in terms of the system parameters. We further\ninvestigate how the delay of the channel state information availability and the\nholding period of channel states affect the stability. In particular, we show\nthat, from a system stability perspective, fast fading channels may be\npreferable to slow fading ones.",
    "descriptor": "\nComments: This is an extended version of a submission to IEEE L-CSS with CDC option. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Wanchun Liu",
      "Daniel E. Quevedo",
      "Branka Vucetic",
      "Yonghui Li"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2203.16826"
  },
  {
    "id": "arXiv:2203.16828",
    "title": "Rethinking Portrait Matting with Privacy Preserving",
    "abstract": "Recently, there has been an increasing concern about the privacy issue raised\nby using personally identifiable information in machine learning. However,\nprevious portrait matting methods were all based on identifiable portrait\nimages. To fill the gap, we present P3M-10k in this paper, which is the first\nlarge-scale anonymized benchmark for Privacy-Preserving Portrait Matting (P3M).\nP3M-10k consists of 10,000 high-resolution face-blurred portrait images along\nwith high-quality alpha mattes. We systematically evaluate both trimap-free and\ntrimap-based matting methods on P3M-10k and find that existing matting methods\nshow different generalization abilities under the privacy preserving training\nsetting, i.e., training only on face-blurred images while testing on arbitrary\nimages. Based on the gained insights, we propose a unified matting model named\nP3M-Net consisting of three carefully designed integration modules that can\nperform privacy-insensitive semantic perception and detail-reserved matting\nsimultaneously. We further design multiple variants of P3M-Net with different\nCNN and transformer backbones and identify the difference in their\ngeneralization abilities. To further mitigate this issue, we devise a simple\nyet effective Copy and Paste strategy (P3M-CP) that can borrow facial\ninformation from public celebrity images without privacy concerns and direct\nthe network to reacquire the face context at both data and feature levels.\nP3M-CP only brings a few additional computations during training, while\nenabling the matting model to process both face-blurred and normal images\nwithout extra effort during inference. Extensive experiments on P3M-10k\ndemonstrate the superiority of P3M-Net over state-of-the-art methods and the\neffectiveness of P3M-CP in improving the generalization ability of P3M-Net,\nimplying a great significance of P3M for future research and real-world\napplications.",
    "descriptor": "\nComments: An extended version of the ACM Multimedia 2021 paper \"Privacy-Preserving Portrait Matting\". The code, dataset, and models are available at this https URL arXiv admin note: substantial text overlap with arXiv:2104.14222\n",
    "authors": [
      "Sihan Ma",
      "Jizhizi Li",
      "Jing Zhang",
      "He Zhang",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.16828"
  },
  {
    "id": "arXiv:2203.16832",
    "title": "Point Scene Understanding via Disentangled Instance Mesh Reconstruction",
    "abstract": "Semantic scene reconstruction from point cloud is an essential and\nchallenging task for 3D scene understanding. This task requires not only to\nrecognize each instance in the scene, but also to recover their geometries\nbased on the partial observed point cloud. Existing methods usually attempt to\ndirectly predict occupancy values of the complete object based on incomplete\npoint cloud proposals from a detection-based backbone. However, this framework\nalways fails to reconstruct high fidelity mesh due to the obstruction of\nvarious detected false positive object proposals and the ambiguity of\nincomplete point observations for learning occupancy values of complete\nobjects. To circumvent the hurdle, we propose a Disentangled Instance Mesh\nReconstruction (DIMR) framework for effective point scene understanding. A\nsegmentation-based backbone is applied to reduce false positive object\nproposals, which further benefits our exploration on the relationship between\nrecognition and reconstruction. Based on the accurate proposals, we leverage a\nmesh-aware latent code space to disentangle the processes of shape completion\nand mesh generation, relieving the ambiguity caused by the incomplete point\nobservations. Furthermore, with access to the CAD model pool at test time, our\nmodel can also be used to improve the reconstruction quality by performing mesh\nretrieval without extra training. We thoroughly evaluate the reconstructed mesh\nquality with multiple metrics, and demonstrate the superiority of our method on\nthe challenging ScanNet dataset.",
    "descriptor": "",
    "authors": [
      "Jiaxiang Tang",
      "Xiaokang Chen",
      "Jingbo Wang",
      "Gang Zeng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.16832"
  },
  {
    "id": "arXiv:2203.16834",
    "title": "A Comparative Study on Speaker-attributed Automatic Speech Recognition  in Multi-party Meetings",
    "abstract": "In this paper, we conduct a comparative study on speaker-attributed automatic\nspeech recognition (SA-ASR) in the multi-party meeting scenario, a topic with\nincreasing attention in meeting rich transcription. Specifically, three\napproaches are evaluated in this study. The first approach, FD-SOT, consists of\na frame-level diarization model to identify speakers and a multi-talker ASR to\nrecognize utterances. The speaker-attributed transcriptions are obtained by\naligning the diarization results and recognized hypotheses. However, such an\nalignment strategy may suffer from erroneous timestamps due to the modular\nindependence, severely hindering the model performance. Therefore, we propose\nthe second approach, WD-SOT, to address alignment errors by introducing a\nword-level diarization model, which can get rid of such timestamp alignment\ndependency. To further mitigate the alignment issues, we propose the third\napproach, TS-ASR, which trains a target-speaker separation module and an ASR\nmodule jointly. By comparing various strategies for each SA-ASR approach,\nexperimental results on a real meeting scenario corpus, AliMeeting, reveal that\nthe WD-SOT approach achieves 10.7% relative reduction on averaged\nspeaker-dependent character error rate (SD-CER), compared with the FD-SOT\napproach. In addition, the TS-ASR approach also outperforms the FD-SOT approach\nand brings 16.5% relative average SD-CER reduction.",
    "descriptor": "\nComments: Submitted to INTERSPEECH 2022, 5 pages, 1 figure\n",
    "authors": [
      "Fan Yu",
      "Zhihao Du",
      "Shiliang Zhang",
      "Yuxiao Lin",
      "Lei Xie"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.16834"
  },
  {
    "id": "arXiv:2203.16838",
    "title": "NeuFA: Neural Network Based End-to-End Forced Alignment with  Bidirectional Attention Mechanism",
    "abstract": "Although deep learning and end-to-end models have been widely used and shown\nsuperiority in automatic speech recognition (ASR) and text-to-speech (TTS)\nsynthesis, state-of-the-art forced alignment (FA) models are still based on\nhidden Markov model (HMM). HMM has limited view of contextual information and\nis developed with long pipelines, leading to error accumulation and\nunsatisfactory performance. Inspired by the capability of attention mechanism\nin capturing long term contextual information and learning alignments in ASR\nand TTS, we propose a neural network based end-to-end forced aligner called\nNeuFA, in which a novel bidirectional attention mechanism plays an essential\nrole. NeuFA integrates the alignment learning of both ASR and TTS tasks in a\nunified framework by learning bidirectional alignment information from a shared\nattention matrix in the proposed bidirectional attention mechanism. Alignments\nare extracted from the learnt attention weights and optimized by the ASR, TTS\nand FA tasks in a multi-task learning manner. Experimental results demonstrate\nthe effectiveness of our proposed model, with mean absolute error on test set\ndrops from 25.8 ms to 23.7 ms at word level, and from 17.0 ms to 15.7 ms at\nphoneme level compared with state-of-the-art HMM based model.",
    "descriptor": "\nComments: Accepted by ICASSP 2022\n",
    "authors": [
      "Jingbei Li",
      "Yi Meng",
      "Zhiyong Wu",
      "Helen Meng",
      "Qiao Tian",
      "Yuping Wang",
      "Yuxuan Wang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.16838"
  },
  {
    "id": "arXiv:2203.16844",
    "title": "Open Source MagicData-RAMC: A Rich Annotated Mandarin  Conversational(RAMC) Speech Dataset",
    "abstract": "This paper introduces a high-quality rich annotated Mandarin conversational\n(RAMC) speech dataset called MagicData-RAMC. The MagicData-RAMC corpus contains\n180 hours of conversational speech data recorded from native speakers of\nMandarin Chinese over mobile phones with a sampling rate of 16 kHz. The dialogs\nin MagicData-RAMC are classified into 15 diversified domains and tagged with\ntopic labels, ranging from science and technology to ordinary life. Accurate\ntranscription and precise speaker voice activity timestamps are manually\nlabeled for each sample. Speakers' detailed information is also provided. As a\nMandarin speech dataset designed for dialog scenarios with high quality and\nrich annotations, MagicData-RAMC enriches the data diversity in the Mandarin\nspeech community and allows extensive research on a series of speech-related\ntasks, including automatic speech recognition, speaker diarization, topic\ndetection, keyword search, text-to-speech, etc. We also conduct several\nrelevant tasks and provide experimental results to help evaluate the dataset.",
    "descriptor": "\nComments: Paper on submission to Interspeech2022\n",
    "authors": [
      "Zehui Yang",
      "Yifan Chen",
      "Lei Luo",
      "Runyan Yang",
      "Lingxuan Ye",
      "Gaofeng Cheng",
      "Ji Xu",
      "Yaohui Jin",
      "Qingqing Zhang",
      "Pengyuan Zhang",
      "Lei Xie",
      "Yonghong Yan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.16844"
  },
  {
    "id": "arXiv:2203.16845",
    "title": "Multi-access Coded Caching with Decentralized Prefetching",
    "abstract": "An extension of coded caching referred to as multi-access coded caching where\neach user can access multiple caches and each cache can serve multiple users is\nconsidered in this paper. Most of the literature in multi-access coded caching\nfocuses on cyclic wrap-around cache access where each user is allowed to access\nan exclusive set of consecutive caches only. In this paper, a more general\nframework of multi-access caching problem is considered in which each user is\nallowed to randomly connect to a specific number of caches and multiple users\ncan access the same set of caches. For the proposed system model considering\ndecentralized prefetching, a new delivery scheme is proposed and an expression\nfor per user delivery rate is obtained. A lower bound on the delivery rate is\nderived using techniques from index coding. The proposed scheme is shown to be\noptimal among all the linear schemes under certain conditions. An improved\ndelivery rate and a lower bound for the decentralized multi-access coded\ncaching scheme with cyclic wrap-around cache access can be obtained as a\nspecial case. By giving specific values to certain parameters, the results of\ndecentralized shared caching scheme and of conventional decentralized caching\nscheme can be recovered.",
    "descriptor": "\nComments: 26 pages, 6 figures, 6 tables, Submitted to IEEE Transactions on Communications\n",
    "authors": [
      "Monolina Dutta",
      "Anoop Thomas",
      "B. Sundar Rajan"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2203.16845"
  },
  {
    "id": "arXiv:2203.16851",
    "title": "Towards Driving-Oriented Metric for Lane Detection Models",
    "abstract": "After the 2017 TuSimple Lane Detection Challenge, its dataset and evaluation\nbased on accuracy and F1 score have become the de facto standard to measure the\nperformance of lane detection methods. While they have played a major role in\nimproving the performance of lane detection methods, the validity of this\nevaluation method in downstream tasks has not been adequately researched. In\nthis study, we design 2 new driving-oriented metrics for lane detection:\nEnd-to-End Lateral Deviation metric (E2E-LD) is directly formulated based on\nthe requirements of autonomous driving, a core downstream task of lane\ndetection; Per-frame Simulated Lateral Deviation metric (PSLD) is a lightweight\nsurrogate metric of E2E-LD. To evaluate the validity of the metrics, we conduct\na large-scale empirical study with 4 major types of lane detection approaches\non the TuSimple dataset and our newly constructed dataset Comma2k19-LD. Our\nresults show that the conventional metrics have strongly negative correlations\n($\\leq$-0.55) with E2E-LD, meaning that some recent improvements purely\ntargeting the conventional metrics may not have led to meaningful improvements\nin autonomous driving, but rather may actually have made it worse by\noverfitting to the conventional metrics. As autonomous driving is a\nsecurity/safety-critical system, the underestimation of robustness hinders the\nsound development of practical lane detection models. We hope that our study\nwill help the community achieve more downstream task-aware evaluations for lane\ndetection.",
    "descriptor": "\nComments: Accepted to CVPR 2022. arXiv admin note: text overlap with arXiv:2107.02488\n",
    "authors": [
      "Takami Sato",
      "Qi Alfred Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.16851"
  },
  {
    "id": "arXiv:2203.16854",
    "title": "Identifying Cost-effective Debunkers for Multi-stage Fake News  Mitigation Campaigns",
    "abstract": "Online social networks have become a fertile ground for spreading fake news.\nMethods to automatically mitigate fake news propagation have been proposed.\nSome studies focus on selecting top k influential users on social networks as\ndebunkers, but the social influence of debunkers may not translate to wide\nmitigation information propagation as expected. Other studies assume a given\nset of debunkers and focus on optimizing intensity for debunkers to publish\ntrue news, but as debunkers are fixed, even if with high social influence\nand/or high intensity to post true news, the true news may not reach users\nexposed to fake news and therefore mitigation effect may be limited. In this\npaper, we propose the multi-stage fake news mitigation campaign where debunkers\nare dynamically selected within budget at each stage. We formulate it as a\nreinforcement learning problem and propose a greedy algorithm optimized by\npredicting future states so that the debunkers can be selected in a way that\nmaximizes the overall mitigation effect. We conducted extensive experiments on\nsynthetic and real-world social networks and show that our solution outperforms\nstate-of-the-art baselines in terms of mitigation effect.",
    "descriptor": "",
    "authors": [
      "Xiaofei Xu",
      "Ke Deng",
      "Xiuzhen Zhang"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2203.16854"
  },
  {
    "id": "arXiv:2203.16857",
    "title": "Lifeline: Emergency Ad Hoc Network",
    "abstract": "Lifeline is a group of systems designed for mobile phones and battery powered\nwireless routers for forming emergency Ad hoc networks. Devices installed with\nLifeline program can automatically form Ad hoc networks when cellular signal is\nunavailable or disrupted during natural disasters. For instance, large scale\nearthquakes can cause extensive damages to land-based telecommunication\ninfrastructures. In such circumstances, mobile phones installed with Lifeline\nprogram can be used to send emergency messages by the victims who are trapped\nunder collapsed buildings. In addition, Lifeline also provides a function for\nthe rescuers to estimate the positions of the victims based on network\npropagation techniques. Lifeline also has the ability to recover from partial\ncrash of network and nodes lost.",
    "descriptor": "",
    "authors": [
      "Se-Hang Cheong",
      "Kai-Ip Lee",
      "Yain-Whar Si",
      "Leong-Hou U"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2203.16857"
  },
  {
    "id": "arXiv:2203.16859",
    "title": "Boundary Node Detection and Unfolding of Complex Non-Convex Ad Hoc  Networks",
    "abstract": "Complex non-convex ad hoc networks (CNCAH) contain intersecting polygons and\nedges. In many instances, the layouts of these networks are not entirely convex\nin shape. In this article, we propose a Kamada-Kawai-based algorithm called\nW-KK-MS for boundary node detection problems, which is capable of aligning node\npositions while achieving high sensitivity, specificity, and accuracy in\nproducing a visual drawing from the input network topology. The algorithm put\nforward in this article selects and assigns weights to top-k nodes in each\niteration to speed up the updating process of nodes. We also propose a novel\napproach to detect and unfold stacked regions in CNCAH networks. Experimental\nresults show that the proposed algorithms can achieve fast convergence on\nboundary node detection in CNCAH networks and are able to successfully unfold\nstacked regions. The design and implementation of a prototype system called\nELnet for analyzing CNCAH networks is also described in this article. The ELnet\nsystem is capable of generating synthetic networks for testing, integrating\nwith force-directed algorithms, and visualizing and analyzing algorithms'\noutcomes.",
    "descriptor": "",
    "authors": [
      "Se-Hang Cheong",
      "Yain-Whar Si"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2203.16859"
  },
  {
    "id": "arXiv:2203.16860",
    "title": "Investigating Modality Bias in Audio Visual Video Parsing",
    "abstract": "We focus on the audio-visual video parsing (AVVP) problem that involves\ndetecting audio and visual event labels with temporal boundaries. The task is\nespecially challenging since it is weakly supervised with only event labels\navailable as a bag of labels for each video. An existing state-of-the-art model\nfor AVVP uses a hybrid attention network (HAN) to generate cross-modal features\nfor both audio and visual modalities, and an attentive pooling module that\naggregates predicted audio and visual segment-level event probabilities to\nyield video-level event probabilities. We provide a detailed analysis of\nmodality bias in the existing HAN architecture, where a modality is completely\nignored during prediction. We also propose a variant of feature aggregation in\nHAN that leads to an absolute gain in F-scores of about 2% and 1.6% for visual\nand audio-visual events at both segment-level and event-level, in comparison to\nthe existing HAN model.",
    "descriptor": "\nComments: Work submitted at Interspeech 2022\n",
    "authors": [
      "Piyush Singh Pasi",
      "Shubham Nemani",
      "Preethi Jyothi",
      "Ganesh Ramakrishnan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2203.16860"
  },
  {
    "id": "arXiv:2203.16863",
    "title": "Cross-Domain Recommendation to Cold-Start Users via Variational  Information Bottleneck",
    "abstract": "Recommender systems have been widely deployed in many real-world\napplications, but usually suffer from the long-standing user cold-start\nproblem. As a promising way, Cross-Domain Recommendation (CDR) has attracted a\nsurge of interest, which aims to transfer the user preferences observed in the\nsource domain to make recommendations in the target domain. Previous CDR\napproaches mostly achieve the goal by following the Embedding and Mapping\n(EMCDR) idea which attempts to learn a mapping function to transfer the\npre-trained user representations (embeddings) from the source domain into the\ntarget domain. However, they pre-train the user/item representations\nindependently for each domain, ignoring to consider both domain interactions\nsimultaneously. Therefore, the biased pre-trained representations inevitably\ninvolve the domain-specific information which may lead to negative impact to\ntransfer information across domains. In this work, we consider a key point of\nthe CDR task: what information needs to be shared across domains? To achieve\nthe above idea, this paper utilizes the information bottleneck (IB) principle,\nand proposes a novel approach termed as CDRIB to enforce the representations\nencoding the domain-shared information. To derive the unbiased representations,\nwe devise two IB regularizers to model the cross-domain/in-domain user-item\ninteractions simultaneously and thereby CDRIB could consider both domain\ninteractions jointly for de-biasing.",
    "descriptor": "\nComments: This paper has been accepted by ICDE 2022\n",
    "authors": [
      "Jiangxia Cao",
      "Jiawei Sheng",
      "Xin Cong",
      "Tingwen Liu",
      "Bin Wang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2203.16863"
  },
  {
    "id": "arXiv:2203.16864",
    "title": "Saving lives: design and implementation of lifeline emergency ad hoc  network",
    "abstract": "This paper aims to propose a system for automatically forming ad hoc networks\nusing mobile phones and battery-powered wireless routers for emergency\nsituations. The system also provides functions to send emergency messages and\nidentify the location of victims based on the network topology information.\nOptimized link state routing protocol is used to instantly form an ad hoc\nemergency network based on WiFi signals from mobile phones of the victims,\nbackup battery-powered wireless routers preinstalled in buildings and mobile\ndevices deployed by search and rescue teams. The proposed system is also\ndesigned to recover from partial crash of network and nodes lost.\nExperimental results demonstrate the effectiveness of the proposed system in\nterms of battery life, transmission distance and noises.\nA novel message routing schedule is proposed for conserving battery life. A\nnovel function to estimate the location of a mobile device which sent an\nemergency message is proposed in this paper.",
    "descriptor": "",
    "authors": [
      "Se-Hang Cheong",
      "Yain-Whar Si",
      "Leong-Hou U"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2203.16864"
  },
  {
    "id": "arXiv:2203.16867",
    "title": "Snapshot Visualization of Complex Graphs with Force-Directed Algorithms",
    "abstract": "Force-directed algorithms are widely used for visualizing graphs. However,\nthese algorithms are computationally expensive in producing good quality\nlayouts for complex graphs. The layout quality is largely influenced by\nexecution time and methods' input parameters especially for large complex\ngraphs. The snapshots of visualization generated from these algorithms are\nuseful in presenting the current view or a past state of an information on\ntimeslices. Therefore, researchers often need to make a trade-off between the\nquality of visualization and the selection of appropriate force-directed\nalgorithms. In this paper, we evaluate the quality of snapshots generated from\n7 force-directed algorithms in terms of number of edge crossing and the\nstandard deviations of edge length. Our experimental results showed that KK,\nFA2 and DH algorithms cannot produce satisfactory visualizations for large\ngraphs within the time limit. KK-MS-DS algorithm can process large and planar\ngraphs but it does not perform well for graphs with low average degrees. KK-MS\nalgorithm produces better visualizations for sparse and non-clustered graphs\nthan KK-MS-DS algorithm.",
    "descriptor": "",
    "authors": [
      "Se-Hang Cheong",
      "Yain-Whar Si"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2203.16867"
  },
  {
    "id": "arXiv:2203.16869",
    "title": "Cyberbullying Indicator as a Precursor to a Cyber Construct Development",
    "abstract": "The current global pandemic occasioned by the SARS-CoV-2 virus has been\nattributed, partially, to the growing range of cyber vises within the cyber\necosystem. One area of such impact is the increasing tendencies of\ncyber-bullying among students. Cyberbullying -- the act of subjugating others\nusing a cyber platform -- is a growing concern among educators, especially in\nHigh-S chools. Whilst studies have been carried out towards understanding this\nmenace, the approach towards id entifying indicators of cyberbullying is\nlargely missing in the literature. To address this research gap, this study\nproposed a cyberbullying framework based on the identification of some\nobservable behavioral indicators. Using a self-administered measurement\ninstrument from 30-respondents, the study observed the probability of a\ncyberbully construct, as a potential measure of the presence of cyberbullying;\na probability that has been largely ignored in extant literature. This\nobservation presents a veritable tool for the development of an active and\nintegrated learning platform void of abuse among students. Furthermore, within\nthe cyber education ecosystem, a cyberbullying construct would provide a\nmechanism for the development of an appropriate online learning platform, which\nwould be useful to the information system and cyber education research\ncommunities.",
    "descriptor": "\nComments: 6 Pages, 2 Figures, 3 Tables. 17th International Conference on Cyber Warfare and Security, 03/2022\n",
    "authors": [
      "Salman Khalifa Al-Romaihi",
      "Richard Adeyemi Ikuesan"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2203.16869"
  },
  {
    "id": "arXiv:2203.16870",
    "title": "A Convex Optimal Control Framework for Autonomous Vehicle Intersection  Crossing",
    "abstract": "Cooperative vehicle management emerges as a promising solution to improve\nroad traffic safety and efficiency. This paper addresses the speed planning\nproblem for connected and autonomous vehicles (CAVs) at an unsignalized\nintersection with consideration of turning maneuvers. The problem is approached\nby a hierarchical centralized coordination scheme that successively optimizes\nthe crossing order and velocity trajectories of a group of vehicles so as to\nminimize their total energy consumption and travel time required to pass the\nintersection. For an accurate estimate of the energy consumption of each CAV,\nthe vehicle modeling framework in this paper captures 1) friction losses that\naffect longitudinal vehicle dynamics, and 2) the powertrain of each CAV in line\nwith a battery-electric architecture. It is shown that the underlying\noptimization problem subject to safety constraints for powertrain operation,\ncornering and collision avoidance, after convexification and relaxation in some\naspects can be formulated as two second-order cone programs, which ensures a\nrapid solution search and a unique global optimum. Simulation case studies are\nprovided showing the tightness of the convex relaxation bounds, the overall\neffectiveness of the proposed approach, and its advantages over a benchmark\nsolution invoking the widely used first-in-first-out policy. The investigation\nof Pareto optimal solutions for the two objectives (travel time and energy\nconsumption) highlights the importance of optimizing their trade-off, as small\ncompromises in travel time could produce significant energy savings.",
    "descriptor": "\nComments: 16 pages, 11 figures. This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Xiao Pan",
      "Boli Chen",
      "Stelios Timotheou",
      "Simos A. Evangelou"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.16870"
  },
  {
    "id": "arXiv:2203.16871",
    "title": "Ransomware Detection using Process Memory",
    "abstract": "Ransomware attacks have increased significantly in recent years, causing\ngreat destruction and damage to critical systems and business operations.\nAttackers are unfailingly finding innovative ways to bypass detection\nmechanisms, whichencouraged the adoption of artificial intelligence. However,\nmost research summarizes the general features of AI and induces many false\npositives, as the behavior of ransomware constantly differs to bypass\ndetection. Focusing on the key indicating features of ransomware becomes vital\nas this guides the investigator to the inner workings and main function of\nransomware itself. By utilizing access privileges in process memory, the main\nfunction of the ransomware can be detected more easily and accurately.\nFurthermore, new signatures and fingerprints of ransomware families can be\nidentified to classify novel ransomware attacks correctly. The current research\nused the process memory access privileges of the different memory regions of\nthe behavior of an executable to quickly determine its intent before serious\nharm can occur. To achieve this aim, several well-known machine learning\nalgorithms were explored with an accuracy range of 81.38 to 96.28 percents. The\nstudy thus confirms the feasibility of utilizing process memory as a detection\nmechanism for ransomware.",
    "descriptor": "\nComments: 11 Pages, 3 Figures, and 11 Tables\n",
    "authors": [
      "Avinash Singh",
      "Richard Adeyemi Ikuesan",
      "Hein Venter"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.16871"
  },
  {
    "id": "arXiv:2203.16872",
    "title": "Group Control for Procedural Rules: Parameterized Complexity and  Consecutive Domains",
    "abstract": "We consider {\\sc{Group Control by Adding Individuals}} (\\sc{GCAI}) for two\nprocedural rules -- the consensus-start-respecting rule and the\nliberal-start-respecting rule. It is known that {\\sc{GCAI}} for both rules are\nNP-hard, but whether they are fixed-parameter tractable with respect to the\nnumber of distinguished candidates remained open. We resolve both open problems\nin the affirmative. In addition, we strengthen the NP-hardness of GCAI by\nshowing that, with respect to the natural parameter the number of added\nindividuals, GCAI for both rules is W[2]-hard. Notably, the W[2]-hardness for\nthe liberal-start-respecting rule holds even when restricted to a very special\ncase where the qualifications of individuals satisfy the so-called consecutive\nones property. However, for the consensus-start-respecting rule, the problem\nbecomes polynomial-time solvable in this special case. We also study a duality\nrestriction where the disqualifications of individuals fulfill the consecutive\nones property, and we show that under this restriction {\\sc{GCAI}} for both\nrules turn out to be polynomial-time solvable. Our reductions for showing\nW[2]-hardness also imply several other lower bounds concerning kernelization\nand exact algorithms.",
    "descriptor": "",
    "authors": [
      "Yongjie Yang",
      "Dinko Dimitrov"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2203.16872"
  },
  {
    "id": "arXiv:2203.16874",
    "title": "An Optimal Control Method to Compute the Most Likely Transition Path for  Stochastic Dynamical Systems with Jumps",
    "abstract": "Many complex real world phenomena exhibit abrupt, intermittent or jumping\nbehaviors, which are more suitable to be described by stochastic differential\nequations under non-Gaussian L\\'evy noise. Among these complex phenomena, the\nmost likely transition paths between metastable states are important since\nthese rare events may have high impact in certain scenarios. Based on the large\ndeviation principle, the most likely transition path could be treated as the\nminimizer of the rate function upon paths that connect two points. One of the\nchallenges to calculate the most likely transition path for stochastic\ndynamical systems under non-Gaussian L\\'evy noise is that the associated rate\nfunction can not be explicitly expressed by paths. For this reason, we\nformulate an optimal control problem to obtain the optimal state as the most\nlikely transition path. We then develop a neural network method to solve this\nissue. Several experiments are investigated for both Gaussian and non-Gaussian\ncases.",
    "descriptor": "\nComments: 15 pages, 14 figures\n",
    "authors": [
      "Wei Wei",
      "Xiaoli Chen",
      "Ting Gao",
      "Jinqiao Duan"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2203.16874"
  },
  {
    "id": "arXiv:2203.16875",
    "title": "MPS-NeRF: Generalizable 3D Human Rendering from Multiview Images",
    "abstract": "There has been rapid progress recently on 3D human rendering, including novel\nview synthesis and pose animation, based on the advances of neural radiance\nfields (NeRF). However, most existing methods focus on person-specific training\nand their training typically requires multi-view videos. This paper deals with\na new challenging task -- rendering novel views and novel poses for a person\nunseen in training, using only multiview images as input. For this task, we\npropose a simple yet effective method to train a generalizable NeRF with\nmultiview images as conditional input. The key ingredient is a dedicated\nrepresentation combining a canonical NeRF and a volume deformation scheme.\nUsing a canonical space enables our method to learn shared properties of human\nand easily generalize to different people. Volume deformation is used to\nconnect the canonical space with input and target images and query image\nfeatures for radiance and density prediction. We leverage the parametric 3D\nhuman model fitted on the input images to derive the deformation, which works\nquite well in practice when combined with our canonical NeRF. The experiments\non both real and synthetic data with the novel view synthesis and pose\nanimation tasks collectively demonstrate the efficacy of our method.",
    "descriptor": "",
    "authors": [
      "Xiangjun Gao",
      "Jiaolong Yang",
      "Jongyoo Kim",
      "Sida Peng",
      "Zicheng Liu",
      "Xin Tong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.16875"
  },
  {
    "id": "arXiv:2203.16882",
    "title": "A Contextual Framework for Adaptive User Interfaces: Modelling the  Interaction Environment",
    "abstract": "The interaction context (or environment) is key to any HCI task and\nespecially to adaptive user interfaces (AUIs), since it represents the\nconditions under which users interact with computers. Unfortunately, there are\ncurrently no formal representations to model said interaction context. In order\nto address this gap, we propose a contextual framework for AUIs and illustrate\na practical applica- tion using learning management systems as a case study. We\nalso discuss limitations of our framework and offer discussion points about the\nrealisation of truly context-aware AUIs.",
    "descriptor": "\nComments: 5 pages, 2 figures\n",
    "authors": [
      "Mateusz Dubiel",
      "Bereket Abera Yilma",
      "Kayhan Latifzadeh",
      "Luis A. Leiva"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2203.16882"
  },
  {
    "id": "arXiv:2203.16885",
    "title": "A bilingual approach to specialised adjectives through word embeddings  in the karstology domain",
    "abstract": "We present an experiment in extracting adjectives which express a specific\nsemantic relation using word embeddings. The results of the experiment are then\nthoroughly analysed and categorised into groups of adjectives exhibiting formal\nor semantic similarity. The experiment and analysis are performed for English\nand Croatian in the domain of karstology using data sets and methods developed\nin the TermFrame project. The main original contributions of the article are\ntwofold: firstly, proposing a new and promising method of extracting\nsemantically related words relevant for terminology, and secondly, providing a\ndetailed evaluation of the output so that we gain a better understanding of the\ndomain-specific semantic structures on the one hand and the types of\nsimilarities extracted by word embeddings on the other.",
    "descriptor": "\nComments: The paper is published as part of TOTH 2020 proceedings (this https URL)\n",
    "authors": [
      "Larisa Gr\u010di\u0107 Simeunovi\u0107",
      "Matej Martinc",
      "\u0160pela Vintar"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.16885"
  },
  {
    "id": "arXiv:2203.16887",
    "title": "Mutual information estimation for graph convolutional neural networks",
    "abstract": "Measuring model performance is a key issue for deep learning practitioners.\nHowever, we often lack the ability to explain why a specific architecture\nattains superior predictive accuracy for a given data set. Often, validation\naccuracy is used as a performance heuristic quantifying how well a network\ngeneralizes to unseen data, but it does not capture anything about the\ninformation flow in the model. Mutual information can be used as a measure of\nthe quality of internal representations in deep learning models, and the\ninformation plane may provide insights into whether the model exploits the\navailable information in the data. The information plane has previously been\nexplored for fully connected neural networks and convolutional architectures.\nWe present an architecture-agnostic method for tracking a network's internal\nrepresentations during training, which are then used to create the mutual\ninformation plane. The method is exemplified for graph-based neural networks\nfitted on citation data. We compare how the inductive bias introduced in\ngraph-based architectures changes the mutual information plane relative to a\nfully connected neural network.",
    "descriptor": "\nComments: Northern Lights Deep Learning proceedings, 8 pages, 3 figures\n",
    "authors": [
      "Marius C. Landverk",
      "Signe Riemer-S\u00f8rensen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.16887"
  },
  {
    "id": "arXiv:2203.16890",
    "title": "A generalization of falsity in finitely-many valued logics",
    "abstract": "The paper proposes a new type of negation in multi-valued logics, providing a\ndifferent way to answer the following question: what does it mean that some\nobject language formula does not have a given truth-value. Along the way, the\npaper provides a general definition of truth and falsity in an arbitrary\nmany-valued logic.",
    "descriptor": "",
    "authors": [
      "Nissim Francez"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2203.16890"
  },
  {
    "id": "arXiv:2203.16891",
    "title": "A survey of neural models for the automatic analysis of conversation:  Towards a better integration of the social sciences",
    "abstract": "Some exciting new approaches to neural architectures for the analysis of\nconversation have been introduced over the past couple of years. These include\nneural architectures for detecting emotion, dialogue acts, and sentiment\npolarity. They take advantage of some of the key attributes of contemporary\nmachine learning, such as recurrent neural networks with attention mechanisms\nand transformer-based approaches. However, while the architectures themselves\nare extremely promising, the phenomena they have been applied to to date are\nbut a small part of what makes conversation engaging. In this paper we survey\nthese neural architectures and what they have been applied to. On the basis of\nthe social science literature, we then describe what we believe to be the most\nfundamental and definitional feature of conversation, which is its\nco-construction over time by two or more interlocutors. We discuss how neural\narchitectures of the sort surveyed could profitably be applied to these more\nfundamental aspects of conversation, and what this buys us in terms of a better\nanalysis of conversation and even, in the longer term, a better way of\ngenerating conversation for a conversational system.",
    "descriptor": "",
    "authors": [
      "Chlo\u00e9 Clavel",
      "Matthieu Labeau",
      "Justine Cassell"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.16891"
  },
  {
    "id": "arXiv:2203.16894",
    "title": "Analysis and Optimization of A Double-IRS Cooperatively Assisted System  with A Quasi-Static Phase Shift Design",
    "abstract": "The analysis and optimization of single intelligent reflecting surface\n(IRS)-assisted systems have been extensively studied, whereas little is known\nregarding multiple-IRS-assisted systems. This paper investigates the analysis\nand optimization of a double-IRS cooperatively assisted downlink system, where\na multi-antenna base station (BS) serves a single-antenna user with the help of\ntwo multi-element IRSs, connected by an inter-IRS channel. The channel between\nany two nodes is modeled with Rician fading. The BS adopts the instantaneous\nCSI-adaptive maximum-ratio transmission (MRT) beamformer, and the two IRSs\nadopt a cooperative quasi-static phase shift design. The goal is to maximize\nthe average achievable rate, which can be reflected by the average channel\npower of the equivalent channel between the BS and user, at a low phase\nadjustment cost and computational complexity. First, we obtain tractable\nexpressions of the average channel power of the equivalent channel in the\ngeneral Rician factor, pure line of sight (LoS), and pure non-line of sight\n(NLoS) regimes, respectively. Then, we jointly optimize the phase shifts of the\ntwo IRSs to maximize the average channel power of the equivalent channel in\nthese regimes. The optimization problems are challenging non-convex problems.\nWe obtain globally optimal closed-form solutions for some cases and propose\ncomputationally efficient iterative algorithms to obtain stationary points for\nthe other cases. Next, we compare the computational complexity for optimizing\nthe phase shifts and the optimal average channel power of the double-IRS\ncooperatively assisted system with those of a counterpart single-IRS-assisted\nsystem at a large number of reflecting elements in the three regimes. Finally,\nwe numerically demonstrate notable gains of the proposed solutions over the\nexisting solutions at different system parameters.",
    "descriptor": "\nComments: 40 pages, 7 figures. This work is submitted to IEEE Trans.Wireless Commun. (under major revision)\n",
    "authors": [
      "Gengfa Ding",
      "Feng Yang",
      "Lianghui Ding",
      "Ying Cui"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2203.16894"
  },
  {
    "id": "arXiv:2203.16895",
    "title": "Deformation and Correspondence Aware Unsupervised Synthetic-to-Real  Scene Flow Estimation for Point Clouds",
    "abstract": "Point cloud scene flow estimation is of practical importance for dynamic\nscene navigation in autonomous driving. Since scene flow labels are hard to\nobtain, current methods train their models on synthetic data and transfer them\nto real scenes. However, large disparities between existing synthetic datasets\nand real scenes lead to poor model transfer. We make two major contributions to\naddress that. First, we develop a point cloud collector and scene flow\nannotator for GTA-V engine to automatically obtain diverse realistic training\nsamples without human intervention. With that, we develop a large-scale\nsynthetic scene flow dataset GTA-SF. Second, we propose a mean-teacher-based\ndomain adaptation framework that leverages self-generated pseudo-labels of the\ntarget domain. It also explicitly incorporates shape deformation regularization\nand surface correspondence refinement to address distortions and misalignments\nin domain transfer. Through extensive experiments, we show that our GTA-SF\ndataset leads to a consistent boost in model generalization to three real\ndatasets (i.e., Waymo, Lyft and KITTI) as compared to the most widely used FT3D\ndataset. Moreover, our framework achieves superior adaptation performance on\nsix source-target dataset pairs, remarkably closing the average domain gap by\n60%. Data and codes are available at https://github.com/leolyj/DCA-SRSFE",
    "descriptor": "\nComments: CVPR 2022\n",
    "authors": [
      "Zhao Jin",
      "Yinjie Lei",
      "Naveed Akhtar",
      "Haifeng Li",
      "Munawar Hayat"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.16895"
  },
  {
    "id": "arXiv:2203.16896",
    "title": "CRAFT: Cross-Attentional Flow Transformer for Robust Optical Flow",
    "abstract": "Optical flow estimation aims to find the 2D motion field by identifying\ncorresponding pixels between two images. Despite the tremendous progress of\ndeep learning-based optical flow methods, it remains a challenge to accurately\nestimate large displacements with motion blur. This is mainly because the\ncorrelation volume, the basis of pixel matching, is computed as the dot product\nof the convolutional features of the two images. The locality of convolutional\nfeatures makes the computed correlations susceptible to various noises. On\nlarge displacements with motion blur, noisy correlations could cause severe\nerrors in the estimated flow. To overcome this challenge, we propose a new\narchitecture \"CRoss-Attentional Flow Transformer\" (CRAFT), aiming to revitalize\nthe correlation volume computation. In CRAFT, a Semantic Smoothing Transformer\nlayer transforms the features of one frame, making them more global and\nsemantically stable. In addition, the dot-product correlations are replaced\nwith transformer Cross-Frame Attention. This layer filters out feature noises\nthrough the Query and Key projections, and computes more accurate correlations.\nOn Sintel (Final) and KITTI (foreground) benchmarks, CRAFT has achieved new\nstate-of-the-art performance. Moreover, to test the robustness of different\nmodels on large motions, we designed an image shifting attack that shifts input\nimages to generate large artificial motions. Under this attack, CRAFT performs\nmuch more robustly than two representative methods, RAFT and GMA. The code of\nCRAFT is is available at https://github.com/askerlee/craft.",
    "descriptor": "\nComments: CVPR 2022 camera ready\n",
    "authors": [
      "Xiuchao Sui",
      "Shaohua Li",
      "Xue Geng",
      "Yan Wu",
      "Xinxing Xu",
      "Yong Liu",
      "Rick Goh",
      "Hongyuan Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.16896"
  },
  {
    "id": "arXiv:2203.16897",
    "title": "Multi-Granularity Alignment Domain Adaptation for Object Detection",
    "abstract": "Domain adaptive object detection is challenging due to distinctive data\ndistribution between source domain and target domain. In this paper, we propose\na unified multi-granularity alignment based object detection framework towards\ndomain-invariant feature learning. To this end, we encode the dependencies\nacross different granularity perspectives including pixel-, instance-, and\ncategory-levels simultaneously to align two domains. Based on pixel-level\nfeature maps from the backbone network, we first develop the omni-scale gated\nfusion module to aggregate discriminative representations of instances by\nscale-aware convolutions, leading to robust multi-scale object detection.\nMeanwhile, the multi-granularity discriminators are proposed to identify which\ndomain different granularities of samples(i.e., pixels, instances, and\ncategories) come from. Notably, we leverage not only the instance\ndiscriminability in different categories but also the category consistency\nbetween two domains. Extensive experiments are carried out on multiple domain\nadaptation scenarios, demonstrating the effectiveness of our framework over\nstate-of-the-art algorithms on top of anchor-free FCOS and anchor-based Faster\nRCNN detectors with different backbones.",
    "descriptor": "\nComments: Accepted to CVPR 2022\n",
    "authors": [
      "Wenzhang Zhou",
      "Dawei Du",
      "Libo Zhang",
      "Tiejian Luo",
      "Yanjun Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.16897"
  },
  {
    "id": "arXiv:2203.16898",
    "title": "Semantic-shape Adaptive Feature Modulation for Semantic Image Synthesis",
    "abstract": "Recent years have witnessed substantial progress in semantic image synthesis,\nit is still challenging in synthesizing photo-realistic images with rich\ndetails. Most previous methods focus on exploiting the given semantic map,\nwhich just captures an object-level layout for an image. Obviously, a\nfine-grained part-level semantic layout will benefit object details generation,\nand it can be roughly inferred from an object's shape. In order to exploit the\npart-level layouts, we propose a Shape-aware Position Descriptor (SPD) to\ndescribe each pixel's positional feature, where object shape is explicitly\nencoded into the SPD feature. Furthermore, a Semantic-shape Adaptive Feature\nModulation (SAFM) block is proposed to combine the given semantic map and our\npositional features to produce adaptively modulated features. Extensive\nexperiments demonstrate that the proposed SPD and SAFM significantly improve\nthe generation of objects with rich details. Moreover, our method performs\nfavorably against the SOTA methods in terms of quantitative and qualitative\nevaluation. The source code and model are available at\nhttps://github.com/cszy98/SAFM.",
    "descriptor": "",
    "authors": [
      "Zhengyao Lv",
      "Xiaoming Li",
      "Zhenxing Niu",
      "Bing Cao",
      "Wangmeng Zuo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.16898"
  },
  {
    "id": "arXiv:2203.16908",
    "title": "Suffix tree-based linear algorithms for multiple prefixes, single suffix  counting and listing problems",
    "abstract": "Given two strings $T$ and $S$ and a set of strings $P$, for each string $p\n\\in P$, consider the unique substrings of $T$ that have $p$ as their prefix and\n$S$ as their suffix. Two problems then come to mind; the first problem being\nthe counting of such substrings, and the second problem being the problem of\nlisting all such substrings. In this paper, we describe linear-time,\nlinear-space suffix tree-based algorithms for both problems. More specifically,\nwe describe an $O(|T| + |P|)$ time algorithm for the counting problem, and an\n$O(|T| + |P| + \\#(ans))$ time algorithm for the listing problem, where\n$\\#(ans)$ refers to the number of strings being listed in total, and $|P|$\nrefers to the total length of the strings in $P$. We also consider the reversed\nversion of the problems, where one prefix condition string and multiple suffix\ncondition strings are given instead, and similarly describe linear-time,\nlinear-space algorithms to solve them.",
    "descriptor": "\nComments: 16 pages, 5 figures\n",
    "authors": [
      "Laurentius Leonard",
      "Ken Tanaka"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2203.16908"
  },
  {
    "id": "arXiv:2203.16910",
    "title": "End-to-End Trajectory Distribution Prediction Based on Occupancy Grid  Maps",
    "abstract": "In this paper, we aim to forecast a future trajectory distribution of a\nmoving agent in the real world, given the social scene images and historical\ntrajectories. Yet, it is a challenging task because the ground-truth\ndistribution is unknown and unobservable, while only one of its samples can be\napplied for supervising model learning, which is prone to bias. Most recent\nworks focus on predicting diverse trajectories in order to cover all modes of\nthe real distribution, but they may despise the precision and thus give too\nmuch credit to unrealistic predictions. To address the issue, we learn the\ndistribution with symmetric cross-entropy using occupancy grid maps as an\nexplicit and scene-compliant approximation to the ground-truth distribution,\nwhich can effectively penalize unlikely predictions. In specific, we present an\ninverse reinforcement learning based multi-modal trajectory distribution\nforecasting framework that learns to plan by an approximate value iteration\nnetwork in an end-to-end manner. Besides, based on the predicted distribution,\nwe generate a small set of representative trajectories through a differentiable\nTransformer-based network, whose attention mechanism helps to model the\nrelations of trajectories. In experiments, our method achieves state-of-the-art\nperformance on the Stanford Drone Dataset and Intersection Drone Dataset.",
    "descriptor": "\nComments: CVPR2022\n",
    "authors": [
      "Ke Guo",
      "Wenxi Liu",
      "Jia Pan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.16910"
  },
  {
    "id": "arXiv:2203.16912",
    "title": "MBORE: Multi-objective Bayesian Optimisation by Density-Ratio Estimation",
    "abstract": "Optimisation problems often have multiple conflicting objectives that can be\ncomputationally and/or financially expensive. Mono-surrogate Bayesian\noptimisation (BO) is a popular model-based approach for optimising such\nblack-box functions. It combines objective values via scalarisation and builds\na Gaussian process (GP) surrogate of the scalarised values. The location which\nmaximises a cheap-to-query acquisition function is chosen as the next location\nto expensively evaluate. While BO is an effective strategy, the use of GPs is\nlimiting. Their performance decreases as the problem input dimensionality\nincreases, and their computational complexity scales cubically with the amount\nof data. To address these limitations, we extend previous work on BO by\ndensity-ratio estimation (BORE) to the multi-objective setting. BORE links the\ncomputation of the probability of improvement acquisition function to that of\nprobabilistic classification. This enables the use of state-of-the-art\nclassifiers in a BO-like framework. In this work we present MBORE:\nmulti-objective Bayesian optimisation by density-ratio estimation, and compare\nit to BO across a range of synthetic and real-world benchmarks. We find that\nMBORE performs as well as or better than BO on a wide variety of problems, and\nthat it outperforms BO on high-dimensional and real-world problems.",
    "descriptor": "\nComments: To appear at Genetic and Evolutionary Computation Conference (GECCO '22). 10 pages (main paper) + 25 pages (supplement). Code avaliable at this https URL\n",
    "authors": [
      "George De Ath",
      "Tinkle Chugh",
      "Alma A. M. Rahat"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.16912"
  },
  {
    "id": "arXiv:2203.16915",
    "title": "A Dataset of Images of Public Streetlights with Operational Monitoring  using Computer Vision Techniques",
    "abstract": "A dataset of street light images is presented. Our dataset consists of\n$\\sim350\\textrm{k}$ images, taken from 140 UMBRELLA nodes installed in the\nSouth Gloucestershire region in the UK. Each UMBRELLA node is installed on the\npole of a lamppost and is equipped with a Raspberry Pi Camera Module v1 facing\nupwards towards the sky and lamppost light bulb. Each node collects an image at\nhourly intervals for 24h every day. The data collection spans for a period of\nsix months.",
    "descriptor": "\nComments: Submitted to Data in Brief Journal\n",
    "authors": [
      "Ioannis Mavromatis",
      "Aleksandar Stanoev",
      "Pietro Carnelli",
      "Yichao Jin",
      "Mahesh Sooriyabandara",
      "Aftab Khan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.16915"
  },
  {
    "id": "arXiv:2203.16920",
    "title": "Desenvolvimento de ferramenta de simula\u00e7\u00e3o para aux\u00edlio no  ensino da disciplina de rob\u00f3tica industrial",
    "abstract": "Currently, robotics is one of the fastest growing areas not only in the\nindustrial sector but also in the consumer and service sectors. Several areas\nbenefit from the technological advancement of robotics, especially the\nindustrial area those benefits from gains in productivity and quality. However,\nto supply this growing demand it is necessary for the newly graduated\nprofessionals to have a deeper understanding of how to design and control a\nrobotic manipulator. It is logical that in order to obtain this more in-depth\nknowledge of robotics, it is necessary to have an experience with a real\nrobotic manipulator, since the practice is a much more efficient way of\nlearning than theory. However, it is known that a robotic arm is not a cheap\ninvestment, and its maintenance is not cheap either. Therefore, many\neducational institutions are not able to provide this type of experience to\ntheir students. With this in mind, and through the use of Unity 3D, which is a\ngame development software, a robotic arm simulator has been developed to\ncorrelate classroom theory with what actually happens in practice. The robotic\nmanipulators implemented on this simulator can be controlled by both inverse\nkinematics (which is the industry standard) and direct kinematics.",
    "descriptor": "\nComments: COBENGE 2019, in Portuguese language\n",
    "authors": [
      "Afonso Henriques Fontes Neto Segundo",
      "Joel Sotero da Cunha Neto",
      "Halisson Alves de Oliveira",
      "\u00c1tila Gir\u00e3o de Oliveira",
      "Reginaldo Florencio da Silva"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2203.16920"
  },
  {
    "id": "arXiv:2203.16921",
    "title": "Assessing the risk of re-identification arising from an attack on  anonymised data",
    "abstract": "Objective: The use of routinely-acquired medical data for research purposes\nrequires the protection of patient confidentiality via data anonymisation. The\nobjective of this work is to calculate the risk of re-identification arising\nfrom a malicious attack to an anonymised dataset, as described below. Methods:\nWe first present an analytical means of estimating the probability of\nre-identification of a single patient in a k-anonymised dataset of Electronic\nHealth Record (EHR) data. Second, we generalize this solution to obtain the\nprobability of multiple patients being re-identified. We provide synthetic\nvalidation via Monte Carlo simulations to illustrate the accuracy of the\nestimates obtained. Results: The proposed analytical framework for risk\nestimation provides re-identification probabilities that are in agreement with\nthose provided by simulation in a number of scenarios. Our work is limited by\nconservative assumptions which inflate the re-identification probability.\nDiscussion: Our estimates show that the re-identification probability increases\nwith the proportion of the dataset maliciously obtained and that it has an\ninverse relationship with the equivalence class size. Our recursive approach\nextends the applicability domain to the general case of a multi-patient\nre-identification attack in an arbitrary k-anonymisation scheme. Conclusion: We\nprescribe a systematic way to parametrize the k-anonymisation process based on\na pre-determined re-identification probability. We observed that the benefits\nof a reduced re-identification risk that come with increasing k-size may not be\nworth the reduction in data granularity when one is considering benchmarking\nthe re-identification probability on the size of the portion of the dataset\nmaliciously obtained by the adversary.",
    "descriptor": "",
    "authors": [
      "Anna Antoniou",
      "Giacomo Dossena",
      "Julia MacMillan",
      "Steven Hamblin",
      "David Clifton",
      "Paula Petrone"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2203.16921"
  },
  {
    "id": "arXiv:2203.16922",
    "title": "A Character-level Span-based Model for Mandarin Prosodic Structure  Prediction",
    "abstract": "The accuracy of prosodic structure prediction is crucial to the naturalness\nof synthesized speech in Mandarin text-to-speech system, but now is limited by\nwidely-used sequence-to-sequence framework and error accumulation from previous\nword segmentation results. In this paper, we propose a span-based Mandarin\nprosodic structure prediction model to obtain an optimal prosodic structure\ntree, which can be converted to corresponding prosodic label sequence. Instead\nof the prerequisite for word segmentation, rich linguistic features are\nprovided by Chinese character-level BERT and sent to encoder with\nself-attention architecture. On top of this, span representation and label\nscoring are used to describe all possible prosodic structure trees, of which\neach tree has its corresponding score. To find the optimal tree with the\nhighest score for a given sentence, a bottom-up CKY-style algorithm is further\nused. The proposed method can predict prosodic labels of different levels at\nthe same time and accomplish the process directly from Chinese characters in an\nend-to-end manner. Experiment results on two real-world datasets demonstrate\nthe excellent performance of our span-based method over all\nsequence-to-sequence baseline approaches.",
    "descriptor": "\nComments: Accepted by ICASSP 2022\n",
    "authors": [
      "Xueyuan Chen",
      "Changhe Song",
      "Yixuan Zhou",
      "Zhiyong Wu",
      "Changbin Chen",
      "Zhongqin Wu",
      "Helen Meng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.16922"
  },
  {
    "id": "arXiv:2203.16923",
    "title": "Aplica\u00e7\u00e3o de ros como ferramenta de ensino a rob\u00f3tica / using  ros as a robotics teaching tool",
    "abstract": "The study of robotic manipulators is the main goal of Industrial Robotics\nClass, part of Control Engineers training course. There is a difficulty in\npreparing academic practices and projects in the area of robotics due to the\nhigh cost of specific educational equipment. The practical classes and the\ndevelopment of projects are very important for engineers training, it is\nproposed to use simulation software in order to provide practical experience\nfor the students of the discipline. In this context, the present article aims\nto expose the use of the Robot Operation System (ROS) as a tool to develop a\nrobotic arm and implement the functionality of forward and inverse kinematics.\nSuch development could be used as an educational tool to increase the interest\nand learning of students in the robotics discipline and to expand research\nareas for the discipline.",
    "descriptor": "\nComments: in Portuguese language\n",
    "authors": [
      "Daniel Maia Evangelista",
      "Pedro Benevides Cavalcante",
      "Afonso Henriques Fontes Neto Segundo"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.16923"
  },
  {
    "id": "arXiv:2203.16924",
    "title": "Development of a robotic manipulator: Applying interdisciplinarity in  Computer Assister Project, Microcontrollers and Industrial Robotics",
    "abstract": "This work was conceived based on Project-Based Learning (ABP) and presents\nthe design, development and mathematical modeling steps of a low-cost robotic\nmanipulator with five degrees of freedom through an interdisciplinary project\nlinking two very important disciplines of the course of Control Engineering and\nAutomation of the University of Fortaleza: Computer Aided Design,\nMicrocontrollers and Industrial Robotics. At the end are presented the results\nthat the project has brought to the best learning of the discipline on the\noptics of the tutor and students.",
    "descriptor": "\nComments: in Portuguese language\n",
    "authors": [
      "Afonso Henriques Fontes Neto Segundo",
      "Joel Sotero da Cunha Neto",
      "Reginaldo Florencio da Silva",
      "Paulo Cirillo Souza Barbosa",
      "Raul Fontenele Santana"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.16924"
  },
  {
    "id": "arXiv:2203.16926",
    "title": "Domain Adaptation for Sparse-Data Settings: What Do We Gain by Not Using  Bert?",
    "abstract": "The practical success of much of NLP depends on the availability of training\ndata. However, in real-world scenarios, training data is often scarce, not\nleast because many application domains are restricted and specific. In this\nwork, we compare different methods to handle this problem and provide\nguidelines for building NLP applications when there is only a small amount of\nlabeled training data available for a specific domain. While transfer learning\nwith pre-trained language models outperforms other methods across tasks,\nalternatives do not perform much worse while requiring much less computational\neffort, thus significantly reducing monetary and environmental cost. We examine\nthe performance tradeoffs of several such alternatives, including models that\ncan be trained up to 175K times faster and do not require a single GPU.",
    "descriptor": "",
    "authors": [
      "Marina Sedinkina",
      "Martin Schmitt",
      "Hinrich Sch\u00fctze"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.16926"
  },
  {
    "id": "arXiv:2203.16927",
    "title": "Applying PBL in the Development and Modeling of kinematics for Robotic  Manipulators with Interdisciplinarity between Computer-Assisted Project,  Robotics, and Microcontrollers",
    "abstract": "Considering the difficulty of students in calculating the direct and inverse\nkinematics of a robotic manipulator using only conventional tools of a\nclassroom, this article proposes the application of Project Based Learning\n(ABP) through the design, development, mathematical modeling of a robotic\nmanipulator as an integrative project of the disciplines of Industrial\nRobotics, Microcontrollers and Computer Assisted Design with students of the\nControl and Automation Engineering of the University of Fortaleza. Once\ndesigned and machined, the manipulator arm was assembled using servo motors\nconnected to a microcontroled prototyping board, to then have its kinematics\ncalculated. At the end are presented the results that the project has brought\nto the learning of the disciplines on the optics of the tutor and students.",
    "descriptor": "\nComments: in Portuguese language\n",
    "authors": [
      "Afonso Henriques Fontes Neto Segundo",
      "Joel Sotero da Cunha Neto",
      "Paulo Cirillo Souza Barbosa",
      "Raul Fontenele Santana"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.16927"
  },
  {
    "id": "arXiv:2203.16928",
    "title": "Neural Architecture Search for Speech Emotion Recognition",
    "abstract": "Deep neural networks have brought significant advancements to speech emotion\nrecognition (SER). However, the architecture design in SER is mainly based on\nexpert knowledge and empirical (trial-and-error) evaluations, which is\ntime-consuming and resource intensive. In this paper, we propose to apply\nneural architecture search (NAS) techniques to automatically configure the SER\nmodels. To accelerate the candidate architecture optimization, we propose a\nuniform path dropout strategy to encourage all candidate architecture\noperations to be equally optimized. Experimental results of two different\nneural structures on IEMOCAP show that NAS can improve SER performance (54.89\\%\nto 56.28\\%) while maintaining model parameter sizes. The proposed dropout\nstrategy also shows superiority over the previous approaches.",
    "descriptor": "\nComments: Accepted by ICASSP 2022\n",
    "authors": [
      "Xixin Wu",
      "Shoukang Hu",
      "Zhiyong Wu",
      "Xunying Liu",
      "Helen Meng"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.16928"
  },
  {
    "id": "arXiv:2203.16930",
    "title": "WavThruVec: Latent speech representation as intermediate features for  neural speech synthesis",
    "abstract": "Recent advances in neural text-to-speech research have been dominated by\ntwo-stage pipelines utilizing low-level intermediate speech representation such\nas mel-spectrograms. However, such predetermined features are fundamentally\nlimited, because they do not allow to exploit the full potential of a\ndata-driven approach through learning hidden representations. For this reason,\nseveral end-to-end methods have been proposed. However, such models are harder\nto train and require a large number of high-quality recordings with\ntranscriptions. Here, we propose WavThruVec - a two-stage architecture that\nresolves the bottleneck by using high-dimensional Wav2Vec 2.0 embeddings as\nintermediate speech representation. Since these hidden activations provide\nhigh-level linguistic features, they are more robust to noise. That allows us\nto utilize annotated speech datasets of a lower quality to train the\nfirst-stage module. At the same time, the second-stage component can be trained\non large-scale untranscribed audio corpora, as Wav2Vec 2.0 embeddings are\ntime-aligned and speaker-independent. This results in an increased\ngeneralization capability to out-of-vocabulary words, as well as to a better\ngeneralization to unseen speakers. We show that the proposed model not only\nmatches the quality of state-of-the-art neural models, but also presents useful\nproperties enabling tasks like voice conversion or zero-shot synthesis.",
    "descriptor": "\nComments: Submitted to Interspeech'22\n",
    "authors": [
      "Hubert Siuzdak",
      "Piotr Dura",
      "Pol van Rijn",
      "Nori Jacoby"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.16930"
  },
  {
    "id": "arXiv:2203.16931",
    "title": "Towards Robust Rain Removal Against Adversarial Attacks: A Comprehensive  Benchmark Analysis and Beyond",
    "abstract": "Rain removal aims to remove rain streaks from images/videos and reduce the\ndisruptive effects caused by rain. It not only enhances image/video visibility\nbut also allows many computer vision algorithms to function properly. This\npaper makes the first attempt to conduct a comprehensive study on the\nrobustness of deep learning-based rain removal methods against adversarial\nattacks. Our study shows that, when the image/video is highly degraded, rain\nremoval methods are more vulnerable to the adversarial attacks as small\ndistortions/perturbations become less noticeable or detectable. In this paper,\nwe first present a comprehensive empirical evaluation of various methods at\ndifferent levels of attacks and with various losses/targets to generate the\nperturbations from the perspective of human perception and machine analysis\ntasks. A systematic evaluation of key modules in existing methods is performed\nin terms of their robustness against adversarial attacks. From the insights of\nour analysis, we construct a more robust deraining method by integrating these\neffective modules. Finally, we examine various types of adversarial attacks\nthat are specific to deraining problems and their effects on both human and\nmachine vision tasks, including 1) rain region attacks, adding perturbations\nonly in the rain regions to make the perturbations in the attacked rain images\nless visible; 2) object-sensitive attacks, adding perturbations only in regions\nnear the given objects. Code is available at\nhttps://github.com/yuyi-sd/Robust_Rain_Removal.",
    "descriptor": "\nComments: 10 pages, 6 figures, to appear in CVPR 2022\n",
    "authors": [
      "Yi Yu",
      "Wenhan Yang",
      "Yap-Peng Tan",
      "Alex C. Kot"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2203.16931"
  },
  {
    "id": "arXiv:2203.16932",
    "title": "Probabilistic Map Matching for Robust Inertial Navigation Aiding",
    "abstract": "Robust aiding of inertial navigation systems in GNSS-denied environments is\ncritical for the removal of accumulated navigation error caused by the drift\nand bias inherent in inertial sensors. One way to perform such an aiding uses\nmatching of geophysical measurements, such as gravimetry, gravity gradiometry\nor magnetometry, with a known geo-referenced map. Although simple in concept,\nthis map matching procedure is challenging: the measurements themselves are\nnoisy; their associated spatial location is uncertain; and the measurements may\nmatch multiple points within the map (i.e. non-unique solution). In this paper,\nwe propose a probabilistic multiple hypotheses tracker to solve the map\nmatching problem and allow robust inertial navigation aiding. Our approach\naddresses the problem both locally, via probabilistic data association, and\ntemporally by incorporating the underlying platform kinematic constraints into\nthe tracker. The map matching output is then integrated into the navigation\nsystem using an unscented Kalman filter. Additionally, we present a statistical\nmeasure of local map information density -- the map feature variability -- and\nuse it to weight the output covariance of the proposed algorithm. The\neffectiveness and robustness of the proposed algorithm are demonstrated using a\nnavigation scenario involving gravitational map matching.",
    "descriptor": "\nComments: 12 pages. 13 figures\n",
    "authors": [
      "Xuezhi Wang",
      "Christopher Gilliam",
      "Allison Kealy",
      "John Close",
      "Bill Moran"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.16932"
  },
  {
    "id": "arXiv:2203.16934",
    "title": "Contributions to interframe coding",
    "abstract": "Advanced motion models (4 or 6 parameters) are needed for a good\nrepresentation of the motion experimented by the different objects contained in\na sequence of images. If the image is split in very small blocks, then an\naccurate description of complex movements can be achieved with only 2\nparameters. This alternative implies a large set of vectors per image. We\npropose a new approach to reduce the number of vectors, using different block\nsizes as a function of the local characteristics of the image, without\nincreasing the error accepted with the smallest blocks. A second algorithm is\nproposed for an inter/intraframe coder.",
    "descriptor": "\nComments: 6 pages, published in Workshop on image analysis & synthesis in image coding. October 1994. Berlin. pp. C3.1 to C3.6. arXiv admin note: text overlap with arXiv:2203.00445\n",
    "authors": [
      "Marcos Faundez-Zanuy",
      "Francesc Vallverdu-Bayes",
      "Francesc Tarres-Ruiz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.16934"
  },
  {
    "id": "arXiv:2203.16935",
    "title": "Learning from few examples with nonlinear feature maps",
    "abstract": "In this work we consider the problem of data classification in post-classical\nsettings were the number of training examples consists of mere few data points.\nWe explore the phenomenon and reveal key relationships between dimensionality\nof AI model's feature space, non-degeneracy of data distributions, and the\nmodel's generalisation capabilities. The main thrust of our present analysis is\non the influence of nonlinear feature transformations mapping original data\ninto higher- and possibly infinite-dimensional spaces on the resulting model's\ngeneralisation capabilities. Subject to appropriate assumptions, we establish\nnew relationships between intrinsic dimensions of the transformed data and the\nprobabilities to learn successfully from few presentations.",
    "descriptor": "",
    "authors": [
      "Ivan Y. Tyukin",
      "Oliver Sutton",
      "Alexander N. Gorban"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.16935"
  },
  {
    "id": "arXiv:2203.16937",
    "title": "HiFi-VC: High Quality ASR-Based Voice Conversion",
    "abstract": "The goal of voice conversion (VC) is to convert input voice to match the\ntarget speaker's voice while keeping text and prosody intact. VC is usually\nused in entertainment and speaking-aid systems, as well as applied for speech\ndata generation and augmentation. The development of any-to-any VC systems,\nwhich are capable of generating voices unseen during model training, is of\nparticular interest to both researchers and the industry. Despite recent\nprogress, any-to-any conversion quality is still inferior to natural speech.\nIn this work, we propose a new any-to-any voice conversion pipeline. Our\napproach uses automated speech recognition (ASR) features, pitch tracking, and\na state-of-the-art waveform prediction model. According to multiple subjective\nand objective evaluations, our method outperforms modern baselines in terms of\nvoice quality, similarity and consistency.",
    "descriptor": "\nComments: Submitted to INTERSPEECH 2022\n",
    "authors": [
      "A. Kashkin",
      "I. Karpukhin",
      "S. Shishkin"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.16937"
  },
  {
    "id": "arXiv:2203.16939",
    "title": "Hypergraph Convolutional Networks via Equivalency between Hypergraphs  and Undirected Graphs",
    "abstract": "As a powerful tool for modeling complex relationships, hypergraphs are\ngaining popularity from the graph learning community. However, commonly used\nframeworks in deep hypergraph learning focus on hypergraphs with\n\\textit{edge-independent vertex weights}(EIVWs), without considering\nhypergraphs with \\textit{edge-dependent vertex weights} (EDVWs) that have more\nmodeling power. To compensate for this, in this paper, we present General\nHypergraph Spectral Convolution(GHSC), a general learning framework that not\nonly can handle EDVW and EIVW hypergraphs, but more importantly, enables\ntheoretically explicitly utilizing the existing powerful Graph Convolutional\nNeural Networks (GCNNs) such that largely ease the design of Hypergraph Neural\nNetworks. In this framework, the graph Laplacian of the given undirected GCNNs\nis replaced with a unified hypergraph Laplacian that incorporates vertex weight\ninformation from a random walk perspective by equating our defined generalized\nhypergraphs with simple undirected graphs. Extensive experiments from various\ndomains including social network analysis, visual objective classification,\nprotein learning demonstrate that the proposed framework can achieve\nstate-of-the-art performance.",
    "descriptor": "",
    "authors": [
      "Jiying Zhang",
      "Fuyang Li",
      "Xi Xiao",
      "Tingyang Xu",
      "Yu Rong",
      "Junzhou Huang",
      "Yatao Bian"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.16939"
  },
  {
    "id": "arXiv:2203.16941",
    "title": "The ideal data compression and automatic discovery of hidden law using  neural network",
    "abstract": "Recently machine learning using neural networks has been developed, and many\nnew methods have been suggested. On the other hand, a system that has true\nversatility has not been developed, and there remain many fields in which the\nhuman brain has advantages over machine learning. We considered how the human\nbrain recognizes events and memorizes them and succeeded to reproduce the\nsystem of the human brain on a machine learning model with a new autoencoder\nneural network (NN). The previous autoencoders have the problem that they\ncannot define well what is the features of the input data, and we need to\nrestrict the middle layer of the autoencoder artificially. We solve this\nproblem by defining a new loss function that reflects the information entropy,\nand it enables the NN to compress the input data ideally and automatically\ndiscover the hidden law behind the input data set. The loss function used in\nour NN is based on the free-energy principle which is known as the unified\nbrain theory, and our study is the first concrete formularization of this\nprinciple. The result of this study can be applied to any kind of data analysis\nand also to cognitive science.",
    "descriptor": "",
    "authors": [
      "Taisuke Katayose"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2203.16941"
  },
  {
    "id": "arXiv:2203.16942",
    "title": "Sequential Recommendation with User Evolving Preference Decomposition",
    "abstract": "Modeling user sequential behaviors has recently attracted increasing\nattention in the recommendation domain. Existing methods mostly assume coherent\npreference in the same sequence. However, user personalities are volatile and\neasily changed, and there can be multiple mixed preferences underlying user\nbehaviors. To solve this problem, in this paper, we propose a novel sequential\nrecommender model via decomposing and modeling user independent preferences. To\nachieve this goal, we highlight three practical challenges considering the\ninconsistent, evolving and uneven nature of the user behavior, which are seldom\nnoticed by the previous work. For overcoming these challenges in a unified\nframework, we introduce a reinforcement learning module to simulate the\nevolution of user preference. More specifically, the action aims to allocate\neach item into a sub-sequence or create a new one according to how the previous\nitems are decomposed as well as the time interval between successive behaviors.\nThe reward is associated with the final loss of the learning objective, aiming\nto generate sub-sequences which can better fit the training data. We conduct\nextensive experiments based on six real-world datasets across different\ndomains. Compared with the state-of-the-art methods, empirical studies manifest\nthat our model can on average improve the performance by about 8.21%, 10.08%,\n10.32%, and 9.82% on the metrics of Precision, Recall, NDCG and MRR,\nrespectively.",
    "descriptor": "\nComments: sequential recommendation\n",
    "authors": [
      "Weiqi Shao",
      "Xu Chen",
      "Long Xia",
      "Jiashu Zhao",
      "Dawei Yin"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2203.16942"
  },
  {
    "id": "arXiv:2203.16945",
    "title": "Semantic Pose Verification for Outdoor Visual Localization with  Self-supervised Contrastive Learning",
    "abstract": "Any city-scale visual localization system has to overcome long-term\nappearance changes, such as varying illumination conditions or seasonal changes\nbetween query and database images. Since semantic content is more robust to\nsuch changes, we exploit semantic information to improve visual localization.\nIn our scenario, the database consists of gnomonic views generated from\npanoramic images (e.g. Google Street View) and query images are collected with\na standard field-of-view camera at a different time. To improve localization,\nwe check the semantic similarity between query and database images, which is\nnot trivial since the position and viewpoint of the cameras do not exactly\nmatch. To learn similarity, we propose training a CNN in a self-supervised\nfashion with contrastive learning on a dataset of semantically segmented\nimages. With experiments we showed that this semantic similarity estimation\napproach works better than measuring the similarity at pixel-level. Finally, we\nused the semantic similarity scores to verify the retrievals obtained by a\nstate-of-the-art visual localization method and observed that contrastive\nlearning-based pose verification increases top-1 recall value to 0.90 which\ncorresponds to a 2% improvement.",
    "descriptor": "",
    "authors": [
      "Semih Orhan",
      "Jose J. Guerrero",
      "Yalin Bastanlar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.16945"
  },
  {
    "id": "arXiv:2203.16952",
    "title": "Multimodal Fusion Transformer for Remote Sensing Image Classification",
    "abstract": "Vision transformer (ViT) has been trending in image classification tasks due\nto its promising performance when compared to convolutional neural networks\n(CNNs). As a result, many researchers have tried to incorporate ViT models in\nhyperspectral image (HSI) classification tasks, but without achieving\nsatisfactory performance. To this paper, we introduce a new multimodal fusion\ntransformer (MFT) network for HSI land-cover classification, which utilizes\nother sources of multimodal data in addition to HSI. Instead of using\nconventional feature fusion techniques, other multimodal data are used as an\nexternal classification (CLS) token in the transformer encoder, which helps\nachieving better generalization. ViT and other similar transformer models use a\nrandomly initialized external classification token {and fail to generalize\nwell}. However, the use of a feature embedding derived from other sources of\nmultimodal data, such as light detection and ranging (LiDAR), offers the\npotential to improve those models by means of a CLS. The concept of\ntokenization is used in our work to generate CLS and HSI patch tokens, helping\nto learn key features in a reduced feature space. We also introduce a new\nattention mechanism for improving the exchange of information between HSI\ntokens and the CLS (e.g., LiDAR) token. Extensive experiments are carried out\non widely used and benchmark datasets i.e., the University of Houston, Trento,\nUniversity of Southern Mississippi Gulfpark (MUUFL), and Augsburg. In the\nresults section, we compare the proposed MFT model with other state-of-the-art\ntransformer models, classical CNN models, as well as conventional classifiers.\nThe superior performance achieved by the proposed model is due to the use of\nmultimodal information as external classification tokens.",
    "descriptor": "",
    "authors": [
      "Swalpa Kumar Roy",
      "Ankur Deria",
      "Danfeng Hong",
      "Behnood Rasti",
      "Antonio Plaza",
      "Jocelyn Chanussot"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2203.16952"
  },
  {
    "id": "arXiv:2203.16954",
    "title": "An End-to-end Chinese Text Normalization Model based on Rule-guided  Flat-Lattice Transformer",
    "abstract": "Text normalization, defined as a procedure transforming non standard words to\nspoken-form words, is crucial to the intelligibility of synthesized speech in\ntext-to-speech system. Rule-based methods without considering context can not\neliminate ambiguation, whereas sequence-to-sequence neural network based\nmethods suffer from the unexpected and uninterpretable errors problem. Recently\nproposed hybrid system treats rule-based model and neural model as two cascaded\nsub-modules, where limited interaction capability makes neural network model\ncannot fully utilize expert knowledge contained in the rules. Inspired by\nFlat-LAttice Transformer (FLAT), we propose an end-to-end Chinese text\nnormalization model, which accepts Chinese characters as direct input and\nintegrates expert knowledge contained in rules into the neural network, both\ncontribute to the superior performance of proposed model for the text\nnormalization task. We also release a first publicly accessible largescale\ndataset for Chinese text normalization. Our proposed model has achieved\nexcellent results on this dataset.",
    "descriptor": "\nComments: Accepted by ICASSP 2022\n",
    "authors": [
      "Wenlin Dai",
      "Changhe Song",
      "Xiang Li",
      "Zhiyong Wu",
      "Huashan Pan",
      "Xiulin Li",
      "Helen Meng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.16954"
  },
  {
    "id": "arXiv:2203.16960",
    "title": "Multi-Agent Spatial Predictive Control with Application to Drone  Flocking (Extended Version)",
    "abstract": "We introduce the novel concept of Spatial Predictive Control (SPC) to solve\nthe following problem: given a collection of agents (e.g., drones) with\npositional low-level controllers (LLCs) and a mission-specific distributed cost\nfunction, how can a distributed controller achieve and maintain cost-function\nminimization without a plant model and only positional observations of the\nenvironment? Our fully distributed SPC controller is based strictly on the\nposition of the agent itself and on those of its neighboring agents. This\ninformation is used in every time-step to compute the gradient of the cost\nfunction and to perform a spatial look-ahead to predict the best next target\nposition for the LLC. Using a high-fidelity simulation environment, we show\nthat SPC outperforms the most closely related class of controllers, Potential\nField Controllers, on the drone flocking problem. We also show that SPC is able\nto cope with a potential sim-to-real transfer gap by demonstrating its\nperformance on real hardware, namely our implementation of flocking using nine\nCrazyflie 2.1 drones.",
    "descriptor": "",
    "authors": [
      "Andreas Brandst\u00e4tter",
      "Scott A. Smolka",
      "Scott D. Stoller",
      "Ashish Tiwari",
      "Radu Grosu"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.16960"
  },
  {
    "id": "arXiv:2203.16962",
    "title": "A comparative study between linear and nonlinear speech prediction",
    "abstract": "This paper is focused on nonlinear prediction coding, which consists on the\nprediction of a speech sample based on a nonlinear combination of previous\nsamples. It is known that in the generation of the glottal pulse, the wave\nequation does not behave linearly [2], [10], and we model these effects by\nmeans of a nonlinear prediction of speech based on a parametric neural network\nmodel. This work is centred on the neural net weight's quantization and on the\ncompression gain.",
    "descriptor": "\nComments: 11 pages, published in Mira, J., Moreno-D\\'iaz, R., Cabestany, J. (eds) Biological and Artificial Computation: From Neuroscience to Technology. IWANN 1997. Lecture Notes in Computer Science, vol 1240. Springer, Berlin, Heidelberg\n",
    "authors": [
      "Marcos Faundez-Zanuy",
      "Enric Monte",
      "Francesc Vallverd\u00fa"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.16962"
  },
  {
    "id": "arXiv:2203.16964",
    "title": "A Novel Probabilistic V2X Data Fusion Framework for Cooperative  Perception",
    "abstract": "The paper addresses the vehicle-to-X (V2X) data fusion for cooperative or\ncollective perception (CP). This emerging and promising intelligent\ntransportation systems (ITS) technology has enormous potential for improving\nefficiency and safety of road transportation. Recent advances in V2X\ncommunication primarily address the definition of V2X messages and data\ndissemination amongst ITS stations (ITS-Ss) in a traffic environment. Yet, a\nlargely unsolved problem is how a connected vehicle (CV) can efficiently and\nconsistently fuse its local perception information with the data received from\nother ITS-Ss. In this paper, we present a novel data fusion framework to fuse\nthe local and V2X perception data for CP that considers the presence of\ncross-correlation. The proposed approach is validated through comprehensive\nresults obtained from numerical simulation, CARLA simulation, and real-world\nexperimentation that incorporates V2X-enabled intelligent platforms. The\nreal-world experiment includes a CV, a connected and automated vehicle (CAV),\nand an intelligent roadside unit (IRSU) retrofitted with vision and lidar\nsensors. We also demonstrate how the fused CP information can improve the\nawareness of vulnerable road users (VRU) for CV/CAV, and how this information\ncan be considered in path planning/decision making within the CAV to facilitate\nsafe interactions.",
    "descriptor": "",
    "authors": [
      "Mao Shan",
      "Karan Narula",
      "Stewart Worrall",
      "Yung Fei Wong",
      "Julie Stephany Berrio Perez",
      "Paul Gray",
      "Eduardo Nebot"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.16964"
  },
  {
    "id": "arXiv:2203.16965",
    "title": "PADA: Pruning Assisted Domain Adaptation for Self-Supervised Speech  Representations",
    "abstract": "While self-supervised speech representation learning (SSL) models serve a\nvariety of downstream tasks, these models have been observed to overfit to the\ndomain from which the unlabelled data originates. To alleviate this issue, we\npropose PADA (Pruning Assisted Domain Adaptation) and zero out redundant\nweights from models pre-trained on large amounts of out-of-domain (OOD) data.\nIntuitively, this helps to make space for the target-domain ASR finetuning. The\nredundant weights can be identified through various pruning strategies which\nhave been discussed in detail as a part of this work. Specifically, we\ninvestigate the effect of the recently discovered Task-Agnostic and Task-Aware\npruning on PADA and propose a new pruning paradigm based on the latter, which\nwe call Cross-Domain Task-Aware Pruning (CD-TAW). CD-TAW obtains the initial\npruning mask from a well fine-tuned OOD model, which makes it starkly different\nfrom the rest of the pruning strategies discussed in the paper. Our proposed\nCD-TAW methodology achieves up to 20.6% relative WER improvement over our\nbaseline when fine-tuned on a 2-hour subset of Switchboard data without\nlanguage model (LM) decoding. Furthermore, we conduct a detailed analysis to\nhighlight the key design choices of our proposed method.",
    "descriptor": "\nComments: Submitted to Interspeech 2022\n",
    "authors": [
      "Lodagala V S V Durga Prasad",
      "Sreyan Ghosh",
      "S. Umesh"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.16965"
  },
  {
    "id": "arXiv:2203.16966",
    "title": "Human Instance Segmentation and Tracking via Data Association and  Single-stage Detector",
    "abstract": "Human video instance segmentation plays an important role in computer\nunderstanding of human activities and is widely used in video processing, video\nsurveillance, and human modeling in virtual reality. Most current VIS methods\nare based on Mask-RCNN framework, where the target appearance and motion\ninformation for data matching will increase computational cost and have an\nimpact on segmentation real-time performance; on the other hand, the existing\ndatasets for VIS focus less on all the people appearing in the video. In this\npaper, to solve the problems, we develop a new method for human video instance\nsegmentation based on single-stage detector. To tracking the instance across\nthe video, we have adopted data association strategy for matching the same\ninstance in the video sequence, where we jointly learn target instance\nappearances and their affinities in a pair of video frames in an end-to-end\nfashion. We have also adopted the centroid sampling strategy for enhancing the\nembedding extraction ability of instance, which is to bias the instance\nposition to the inside of each instance mask with heavy overlap condition. As a\nresult, even there exists a sudden change in the character activity, the\ninstance position will not move out of the mask, so that the problem that the\nsame instance is represented by two different instances can be alleviated.\nFinally, we collect PVIS dataset by assembling several video instance\nsegmentation datasets to fill the gap of the current lack of datasets dedicated\nto human video segmentation. Extensive simulations based on such dataset has\nbeen conduct. Simulation results verify the effectiveness and efficiency of the\nproposed work.",
    "descriptor": "",
    "authors": [
      "Lu Cheng",
      "Mingbo Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.16966"
  },
  {
    "id": "arXiv:2203.16969",
    "title": "Software Engineering for Quantum Programming: How Far Are We?",
    "abstract": "Quantum computing is no longer only a scientific interest but is rapidly\nbecoming an industrially available technology that can potentially overcome the\nlimits of classical computation. Over the last years, all major companies have\nprovided frameworks and programming languages that allow developers to create\ntheir quantum applications. This shift has led to the definition of a new\ndiscipline called quantum software engineering, which is demanded to define\nnovel methods for engineering large-scale quantum applications. While the\nresearch community is successfully embracing this call, we notice a lack of\nsystematic investigations into the state of the practice of quantum\nprogramming. Understanding the challenges that quantum developers face is vital\nto precisely define the aims of quantum software engineering. Hence, in this\npaper, we first mine all the GitHub repositories that make use of the most used\nquantum programming frameworks currently on the market and then conduct coding\nanalysis sessions to produce a taxonomy of the purposes for which quantum\ntechnologies are used. In the second place, we conduct a survey study that\ninvolves the contributors of the considered repositories, which aims to elicit\nthe developers' opinions on the current adoption and challenges of quantum\nprogramming. On the one hand, the results highlight that the current adoption\nof quantum programming is still limited. On the other hand, there are many\nchallenges that the software engineering community should carefully consider:\nthese do not strictly pertain to technical concerns but also socio-technical\nmatters.",
    "descriptor": "",
    "authors": [
      "Manuel De Stefano",
      "Fabiano Pecorelli",
      "Dario Di Nucci",
      "Fabio Palomba",
      "Andrea De Lucia"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2203.16969"
  },
  {
    "id": "arXiv:2203.16970",
    "title": "A Comparative Study of Fusion Methods for SASV Challenge 2022",
    "abstract": "Automatic Speaker Verification (ASV) system is a type of bio-metric\nauthentication. It can be attacked by an intruder, who falsifies data in order\nto get access to protected information. Countermeasures (CM) are special\nalgorithms that detect these spoofing-attacks. While the ASVspoof Challenge\nseries were focused on the development of CM for fixed ASV system, the new\nSpoofing Aware Speaker Verification (SASV) Challenge organizers believe that\nbest results can be achieved if CM and ASV systems are optimized jointly. One\nof the approaches for cooperative optimization is a fusion over embeddings or\nscores obtained from ASV and CM models. The baselines of SASV Challenge 2022\npresent two types of fusion: score-sum and back-end ensemble with a 3-layer\nMLP. This paper describes our research of other fusion methods, including\nboosting over embeddings, which has not been used in anti-spoofing studies\nbefore.",
    "descriptor": "\nComments: This paper is submitted to INTERSPEECH 2022\n",
    "authors": [
      "Petr Grinberg",
      "Vladislav Shikhov"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.16970"
  },
  {
    "id": "arXiv:2203.16973",
    "title": "Analyzing the factors affecting usefulness of Self-Supervised  Pre-trained Representations for Speech Recognition",
    "abstract": "Self-supervised learning (SSL) to learn high-level speech representations has\nbeen a popular approach to building Automatic Speech Recognition (ASR) systems\nin low-resource settings. However, the common assumption made in literature is\nthat a considerable amount of unlabeled data is available for the same domain\nor language that can be leveraged for SSL pre-training, which we acknowledge is\nnot feasible in a real-world setting. In this paper, as part of the Interspeech\nGram Vaani ASR challenge, we try to study the effect of domain, language,\ndataset size, and other aspects of our upstream pre-training SSL data on the\nfinal performance low-resource downstream ASR task. We also build on the\ncontinued pre-training paradigm to study the effect of prior knowledge\npossessed by models trained using SSL. Extensive experiments and studies reveal\nthat the performance of ASR systems is susceptible to the data used for SSL\npre-training. Their performance improves with an increase in similarity and\nvolume of pre-training data. We believe our work will be helpful to the speech\ncommunity in building better ASR systems in low-resource settings and steer\nresearch towards improving generalization in SSL-based pre-training for speech\nsystems.",
    "descriptor": "\nComments: Submitted to Interspeech 2022\n",
    "authors": [
      "Lodagala V S V Durga Prasad",
      "Ashish Seth",
      "Sreyan Ghosh",
      "S. Umesh"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.16973"
  },
  {
    "id": "arXiv:2203.16978",
    "title": "Matrix Polynomial Factorization via Higman Linearization",
    "abstract": "In continuation to our recent work on noncommutative polynomial\nfactorization, we consider the factorization problem for matrices of\npolynomials and show the following results.\n(1) Given as input a full rank $d\\times d$ matrix $M$ whose entries $M_{ij}$\nare polynomials in the free noncommutative ring $\\mathbb{F}_q\\langle\nx_1,x_2,\\ldots,x_n \\rangle$, where each $M_{ij}$ is given by a noncommutative\narithmetic formula of size at most $s$, we give a randomized algorithm that\nruns in time polynomial in $d,s, n$ and $\\log_2q$ that computes a factorization\nof $M$ as a matrix product $M=M_1M_2\\cdots M_r$, where each $d\\times d$ matrix\nfactor $M_i$ is irreducible (in a well-defined sense) and the entries of each\n$M_i$ are polynomials in $\\mathbb{F}_q \\langle x_1,x_2,\\ldots,x_n \\rangle$ that\nare output as algebraic branching programs. We also obtain a deterministic\nalgorithm for the problem that runs in $poly(d,n,s,q)$.\n(2)A special case is the efficient factorization of matrices whose entries\nare univariate polynomials in $\\mathbb{F}[x]$. When $\\mathbb{F}$ is a finite\nfield the above result applies. When $\\mathbb{F}$ is the field of rationals we\nobtain a deterministic polynomial-time algorithm for the problem.",
    "descriptor": "",
    "authors": [
      "V. Arvind",
      "Pushkar S. Joglekar"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2203.16978"
  },
  {
    "id": "arXiv:2203.16981",
    "title": "Design of a robot for the automatic charging of an electric car",
    "abstract": "In this paper, a robot with parallel architecture is proposed for charging an\nelectric vehicle having the charging socket on its front side. Kinematic models\nare developed to design the robot for a given workspace that corresponds to the\ncar's plug placements. A demonstrator composed by commercial components is\nshown.",
    "descriptor": "",
    "authors": [
      "Damien Chablat",
      "Riccardo Mattacchione",
      "Erika Ottaviano"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.16981"
  },
  {
    "id": "arXiv:2203.16983",
    "title": "Self-distillation Augmented Masked Autoencoders for Histopathological  Image Classification",
    "abstract": "Self-supervised learning (SSL) has drawn increasing attention in pathological\nimage analysis in recent years. However, the prevalent contrastive SSL is\nsuboptimal in feature representation under this scenario due to the homogeneous\nvisual appearance. Alternatively, masked autoencoders (MAE) build SSL from a\ngenerative paradigm. They are more friendly to pathological image modeling. In\nthis paper, we firstly introduce MAE to pathological image analysis. A novel\nSD-MAE model is proposed to enable a self-distillation augmented SSL on top of\nthe raw MAE. Besides the reconstruction loss on masked image patches, SD-MAE\nfurther imposes the self-distillation loss on visible patches. It guides the\nencoder to perceive high-level semantics that benefit downstream tasks. We\napply SD-MAE to the image classification task on two pathological and one\nnatural image datasets. Experiments demonstrate that SD-MAE performs highly\ncompetitive when compared with leading contrastive SSL methods. The results,\nwhich are pre-trained using a moderate size of pathological images, are also\ncomparable to the method pre-trained with two orders of magnitude more images.\nOur code will be released soon.",
    "descriptor": "",
    "authors": [
      "Yang Luo",
      "Zhineng Chen",
      "Xieping Gao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.16983"
  },
  {
    "id": "arXiv:2203.16987",
    "title": "Leveraging Predictions from Multiple Repositories to Improve Bot  Detection",
    "abstract": "Contemporary social coding platforms such as GitHub facilitate collaborative\ndistributed software development. Developers engaged in these platforms often\nuse machine accounts (bots) for automating effort-intensive or repetitive\nactivities. Determining whether a contributor corresponds to a bot or a human\naccount is important in socio-technical studies, for example, to assess the\npositive and negative impact of using bots, analyse the evolution of bots and\ntheir usage, identify top human contributors, and so on. BoDeGHa is one of the\nbot detection tools that have been proposed in the literature. It relies on\ncomment activity within a single repository to predict whether an account is\ndriven by a bot or by a human. This paper presents preliminary results on how\nthe effectiveness of BoDeGHa can be improved by combining the predictions\nobtained from many repositories at once. We found that doing this not only\nincreases the number of cases for which a prediction can be made but that many\ndiverging predictions can be fixed this way. These promising, albeit\npreliminary, results suggest that the \"wisdom of the crowd\" principle can\nimprove the effectiveness of bot detection tools.",
    "descriptor": "\nComments: 4 pages, 2 figures, 3 tables\n",
    "authors": [
      "Natarajan Chidambaram",
      "Alexandre Decan",
      "Mehdi Golzadeh"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2203.16987"
  },
  {
    "id": "arXiv:2203.16988",
    "title": "Acoustic-Net: A Novel Neural Network for Sound Localization and  Quantification",
    "abstract": "Acoustic source localization has been applied in different fields, such as\naeronautics and ocean science, generally using multiple microphones array data\nto reconstruct the source location. However, the model-based beamforming\nmethods fail to achieve the high-resolution of conventional beamforming maps.\nDeep neural networks are also appropriate to locate the sound source, but in\ngeneral, these methods with complex network structures are hard to be\nrecognized by hardware. In this paper, a novel neural network, termed the\nAcoustic-Net, is proposed to locate and quantify the sound source simply using\nthe original signals. The experiments demonstrate that the proposed method\nsignificantly improves the accuracy of sound source prediction and the\ncomputing speed, which may generalize well to real data. The code and trained\nmodels are available at https://github.com/JoaquinChou/Acoustic-Net.",
    "descriptor": "",
    "authors": [
      "Guanxing Zhou",
      "Hao Liang",
      "Xinghao Ding",
      "Yue Huang",
      "Xiaotong Tu",
      "Saqlain Abbas"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.16988"
  },
  {
    "id": "arXiv:2203.16989",
    "title": "Functional Stability of Discounted Markov Decision Processes Using  Economic MPC Dissipativity Theory",
    "abstract": "This paper discusses the functional stability of closed-loop Markov Chains\nunder optimal policies resulting from a discounted optimality criterion,\nforming Markov Decision Processes (MDPs). We investigate the stability of MDPs\nin the sense of probability measures (densities) underlying the state\ndistributions and extend the dissipativity theory of Economic Model Predictive\nControl in order to characterize the MDP stability. This theory requires a\nso-called storage function satisfying a dissipativity inequality. In the\nprobability measures space and for the discounted setting, we introduce new\ndissipativity conditions ensuring the MDP stability. We then use finite-horizon\noptimal control problems in order to generate valid storage functionals. In\npractice, we propose to use Q-learning to compute the storage functionals.",
    "descriptor": "\nComments: This paper has been accepted to ECC2022. 6 pages\n",
    "authors": [
      "Arash Bahari Kordabad",
      "Sebastien Gros"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.16989"
  },
  {
    "id": "arXiv:2203.16992",
    "title": "Subquadratic Dynamic Path Reporting in Directed Graphs Against an  Adaptive Adversary",
    "abstract": "We study reachability and shortest paths problems in dynamic directed graphs.\nWhereas algebraic dynamic data structures supporting edge updates and\nreachability/distance queries have been known for quite a long time, they do\nnot, in general, allow reporting the underlying paths within the same time\nbounds, especially against an adaptive adversary.\nIn this paper we develop the first known fully dynamic reachability data\nstructures working against an adaptive adversary and supporting edge updates\nand path queries for two natural variants: (1) point-to-point path reporting,\nand (2) single-source reachability tree reporting. For point-to-point queries\nin DAGs, we achieve $O(n^{1.529})$ worst-case update and query bounds, whereas\nfor tree reporting in DAGs, the worst-case bounds are $O(n^{1.765})$. More\nimportantly, we show how to lift these algorithms to work on general graphs at\nthe cost of increasing the bounds to $n^{1+5/6+o(1)}$ and making the update\ntimes amortized. On the way to accomplishing that, we obtain two interesting\nsubresults. We give subquadratic fully dynamic algorithms for topological order\n(in a DAG), and strongly connected components. To the best of our knowledge,\nsuch algorithms have not been described before.\nAdditionally, we provide deterministic incremental data structures for\nreachability and shortest paths that handle edge insertions and report the\nrespective paths within subquadratic worst-case time bounds. For reachability\nand $(1+\\epsilon)$-approximate shortest paths in weighted digraphs, these\nbounds match the best known dynamic matrix inverse-based randomized bounds for\nfully dynamic reachability [v.d.Brand, Nanongkai and Saranurak, FOCS'19]. For\nexact shortest paths in unweighted graphs, the obtained bounds in the\nincremental setting polynomially improve upon the respective best known\nrandomized update/distance query bounds in the fully dynamic setting.",
    "descriptor": "\nComments: To appear at STOC'22\n",
    "authors": [
      "Adam Karczmarz",
      "Anish Mukherjee",
      "Piotr Sankowski"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2203.16992"
  },
  {
    "id": "arXiv:2203.16995",
    "title": "Message Passing Neural Networks for Hypergraphs",
    "abstract": "Hypergraph representations are both more efficient and better suited to\ndescribe data characterized by relations between two or more objects. In this\nwork, we present the first graph neural network based on message passing\ncapable of processing hypergraph-structured data. We show that the proposed\nmodel defines a design space for neural network models for hypergraphs, thus\ngeneralizing existing models for hypergraphs. We report experiments on a\nbenchmark dataset for node classification, highlighting the effectiveness of\nthe proposed model with respect to other state-of-the-art methods for graphs\nand hypergraphs. We also discuss the benefits of using hypergraph\nrepresentations and, at the same time, highlight the limitation of using\nequivalent graph representations when the underlying problem has relations\namong more than two objects.",
    "descriptor": "",
    "authors": [
      "Sajjad Heydari",
      "Lorenzo Livi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.16995"
  },
  {
    "id": "arXiv:2203.16997",
    "title": "Bot Detection in GitHub Repositories",
    "abstract": "Contemporary social coding platforms like GitHub promote collaborative\ndevelopment. Many open-source software repositories hosted in these platforms\nuse machine accounts (bots) to automate and facilitate a wide range of\neffort-intensive and repetitive activities. Determining if an account\ncorresponds to a bot or a human contributor is important for socio-technical\ndevelopment analytics, for example, to understand how humans collaborate and\ninteract in the presence of bots, to assess the positive and negative impact of\nusing bots, to identify the top project contributors, to identify potential bus\nfactors, and so on. Our project aims to include the trained machine learning\n(ML) classifier from the BoDeGHa bot detection tool as a plugin to the\nGrimoireLab software development analytics platform. In this work, we present\nthe procedure to form a pipeline for retrieving contribution and contributor\ndata using Perceval, distinguishing bots from humans using BoDeGHa, and\nvisualising the results using Kibana.",
    "descriptor": "\nComments: 3 pages, 3 figures\n",
    "authors": [
      "Natarajan Chidambaram",
      "Pooya Rostami Mazrae"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2203.16997"
  },
  {
    "id": "arXiv:2203.17002",
    "title": "Conditional Autoregressors are Interpretable Classifiers",
    "abstract": "We explore the use of class-conditional autoregressive (CA) models to perform\nimage classification on MNIST-10. Autoregressive models assign probability to\nan entire input by combining probabilities from each individual feature; hence\nclassification decisions made by a CA can be readily decomposed into\ncontributions from each each input feature. That is to say, CA are inherently\nlocally interpretable. Our experiments show that naively training a CA achieves\nmuch worse accuracy compared to a standard classifier, however this is due to\nover-fitting and not a lack of expressive power. Using knowledge distillation\nfrom a standard classifier, a student CA can be trained to match the\nperformance of the teacher while still being interpretable.",
    "descriptor": "\nComments: 4 pages, 2 figures\n",
    "authors": [
      "Nathan Elazar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.17002"
  },
  {
    "id": "arXiv:2203.17003",
    "title": "Equivariant Diffusion for Molecule Generation in 3D",
    "abstract": "This work introduces a diffusion model for molecule generation in 3D that is\nequivariant to Euclidean transformations. Our E(3) Equivariant Diffusion Model\n(EDM) learns to denoise a diffusion process with an equivariant network that\njointly operates on both continuous (atom coordinates) and categorical features\n(atom types). In addition, we provide a probabilistic analysis which admits\nlikelihood computation of molecules using our model. Experimentally, the\nproposed method significantly outperforms previous 3D molecular generative\nmethods regarding the quality of generated samples and efficiency at training\ntime.",
    "descriptor": "",
    "authors": [
      "Emiel Hoogeboom",
      "Victor Garcia Satorras",
      "Cl\u00e9ment Vignac",
      "Max Welling"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.17003"
  },
  {
    "id": "arXiv:2203.17005",
    "title": "Privacy-Preserving Aggregation in Federated Learning: A Survey",
    "abstract": "Over the recent years, with the increasing adoption of Federated Learning\n(FL) algorithms and growing concerns over personal data privacy,\nPrivacy-Preserving Federated Learning (PPFL) has attracted tremendous attention\nfrom both academia and industry. Practical PPFL typically allows multiple\nparticipants to individually train their machine learning models, which are\nthen aggregated to construct a global model in a privacy-preserving manner. As\nsuch, Privacy-Preserving Aggregation (PPAgg) as the key protocol in PPFL has\nreceived substantial research interest. This survey aims to fill the gap\nbetween a large number of studies on PPFL, where PPAgg is adopted to provide a\nprivacy guarantee, and the lack of a comprehensive survey on the PPAgg\nprotocols applied in FL systems. In this survey, we review the PPAgg protocols\nproposed to address privacy and security issues in FL systems. The focus is\nplaced on the construction of PPAgg protocols with an extensive analysis of the\nadvantages and disadvantages of these selected PPAgg protocols and solutions.\nAdditionally, we discuss the open-source FL frameworks that support PPAgg.\nFinally, we highlight important challenges and future research directions for\napplying PPAgg to FL systems and the combination of PPAgg with other\ntechnologies for further security improvement.",
    "descriptor": "\nComments: 20 pages, 10 figures\n",
    "authors": [
      "Ziyao Liu",
      "Jiale Guo",
      "Wenzhuo Yang",
      "Jiani Fan",
      "Kwok-Yan Lam",
      "Jun Zhao"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2203.17005"
  },
  {
    "id": "arXiv:2203.17007",
    "title": "Vehicular Positioning and Tracking in Multipath Non-Line-of-Sight  Channels",
    "abstract": "We consider the downlink transmission in a single cell multiple-input\nmultiple-output system, in which the user equipment correspond to a vehicle\nmoving along a given trajectory. This system utilizes millimeter wave channels\ncharacterized by multiple non-line-of-sight (NLoS) components. As it has been\npointed out in several related works, in such systems radio access network\n(RAN)-based positioning can effectively improve the positioning accuracy\nachieved by Global Navigation Satellite Systems. However, the RAN-based\npositioning accuracy is highly dependent on the quality of the channel\nestimates, especially if multipath propagation is exploited. Recognizing that\nthe communication channels between the serving base station and the vehicle as\nwell as the geographical position of the vehicle can be advantageously modeled\nas inter-related autoregressive processes, we propose a two-stage Kalman filter\nalgorithm employing two intertwined filters for channel tracking, position\ntracking and abrupt channel change detection. The first Kalman filter tracks\nangles-of-departure and angles-of-arrival associated with the communication\nchannels, which are used to make a coarse position estimation. The second\nKalman filter tracks the position of the vehicle utilizing the kinematic\nparameters of the vehicle. Simulation results clearly show the advantages of\nusing the proposed scheme, which exploits the memoryful property of both the\ncommunication channels and the geographical positions, as compared to employing\npreviously proposed single-stage or not properly combined filters in NLoS\nenvironments.",
    "descriptor": "\nComments: 5 pages, 6 figures\n",
    "authors": [
      "Zhicheng Ye",
      "Julia Vinogradova",
      "G\u00e1bor Fodor",
      "Peter Hammarberg"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2203.17007"
  },
  {
    "id": "arXiv:2203.17008",
    "title": "It's All In the Teacher: Zero-Shot Quantization Brought Closer to the  Teacher",
    "abstract": "Model quantization is considered as a promising method to greatly reduce the\nresource requirements of deep neural networks. To deal with the performance\ndrop induced by quantization errors, a popular method is to use training data\nto fine-tune quantized networks. In real-world environments, however, such a\nmethod is frequently infeasible because training data is unavailable due to\nsecurity, privacy, or confidentiality concerns. Zero-shot quantization\naddresses such problems, usually by taking information from the weights of a\nfull-precision teacher network to compensate the performance drop of the\nquantized networks. In this paper, we first analyze the loss surface of\nstate-of-the-art zero-shot quantization techniques and provide several\nfindings. In contrast to usual knowledge distillation problems, zero-shot\nquantization often suffers from 1) the difficulty of optimizing multiple loss\nterms together, and 2) the poor generalization capability due to the use of\nsynthetic samples. Furthermore, we observe that many weights fail to cross the\nrounding threshold during training the quantized networks even when it is\nnecessary to do so for better performance. Based on the observations, we\npropose AIT, a simple yet powerful technique for zero-shot quantization, which\naddresses the aforementioned two problems in the following way: AIT i) uses a\nKL distance loss only without a cross-entropy loss, and ii) manipulates\ngradients to guarantee that a certain portion of weights are properly updated\nafter crossing the rounding thresholds. Experiments show that AIT outperforms\nthe performance of many existing methods by a great margin, taking over the\noverall state-of-the-art position in the field.",
    "descriptor": "\nComments: selected for an oral presentation at CVPR 2022\n",
    "authors": [
      "Kanghyun Choi",
      "Hye Yoon Lee",
      "Deokki Hong",
      "Joonsang Yu",
      "Noseong Park",
      "Youngsok Kim",
      "Jinho Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.17008"
  },
  {
    "id": "arXiv:2203.17010",
    "title": "Consistency of randomized integration methods",
    "abstract": "For integrable functions we provide a weak law of large numbers for\nstructured Monte Carlo methods, such as estimators based on randomized digital\nnets, Latin hypercube sampling, randomized Frolov point sets as well as\nCranley-Patterson rotations. Moreover, we suggest median modified methods and\nshow that for integrands in $L^p$ with $p>1$ a strong law of large numbers\nholds.",
    "descriptor": "\nComments: 12 pages\n",
    "authors": [
      "Julian Hofstadler",
      "Daniel Rudolf"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2203.17010"
  },
  {
    "id": "arXiv:2203.17012",
    "title": "A Temporal-oriented Broadcast ResNet for COVID-19 Detection",
    "abstract": "Detecting COVID-19 from audio signals, such as breathing and coughing, can be\nused as a fast and efficient pre-testing method to reduce the virus\ntransmission. Due to the promising results of deep learning networks in\nmodelling time sequences, and since applications to rapidly identify COVID\nin-the-wild should require low computational effort, we present a\ntemporal-oriented broadcasting residual learning method that achieves efficient\ncomputation and high accuracy with a small model size. Based on the\nEfficientNet architecture, our novel network, named Temporal-oriented\nResNet~(TorNet), constitutes of a broadcasting learning block, i.e. the\nAlternating Broadcast (AB) Block, which contains several Broadcast Residual\nBlocks (BC ResBlocks) and a convolution layer. With the AB Block, the network\nobtains useful audio-temporal features and higher level embeddings effectively\nwith much less computation than Recurrent Neural Networks~(RNNs), typically\nused to model temporal information. TorNet achieves 72.2% Unweighted Average\nRecall (UAR) on the INTERPSEECH 2021 Computational Paralinguistics Challenge\nCOVID-19 cough Sub-Challenge, by this showing competitive results with a higher\ncomputational efficiency than other state-of-the-art alternatives.",
    "descriptor": "\nComments: 5 pages,submitted to Intesspeech 2022\n",
    "authors": [
      "Xin Jing",
      "Shuo Liu",
      "Emilia Parada-Cabaleiro",
      "Andreas Triantafyllopoulos",
      "Meishu Song",
      "Zijiang Yang",
      "Bj\u00f6rn W. Schuller"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.17012"
  },
  {
    "id": "arXiv:2203.17013",
    "title": "A Temporal Learning Approach to Inpainting Endoscopic Specularities and  Its effect on Image Correspondence",
    "abstract": "Video streams are utilised to guide minimally-invasive surgery and diagnostic\nprocedures in a wide range of procedures, and many computer assisted techniques\nhave been developed to automatically analyse them. These approaches can provide\nadditional information to the surgeon such as lesion detection, instrument\nnavigation, or anatomy 3D shape modeling. However, the necessary image features\nto recognise these patterns are not always reliably detected due to the\npresence of irregular light patterns such as specular highlight reflections. In\nthis paper, we aim at removing specular highlights from endoscopic videos using\nmachine learning. We propose using a temporal generative adversarial network\n(GAN) to inpaint the hidden anatomy under specularities, inferring its\nappearance spatially and from neighbouring frames where they are not present in\nthe same location. This is achieved using in-vivo data of gastric endoscopy\n(Hyper-Kvasir) in a fully unsupervised manner that relies on automatic\ndetection of specular highlights. System evaluations show significant\nimprovements to traditional methods through direct comparison as well as other\nmachine learning techniques through an ablation study that depicts the\nimportance of the network's temporal and transfer learning components. The\ngeneralizability of our system to different surgical setups and procedures was\nalso evaluated qualitatively on in-vivo data of gastric endoscopy and ex-vivo\nporcine data (SERV-CT, SCARED). We also assess the effect of our method in\ncomputer vision tasks that underpin 3D reconstruction and camera motion\nestimation, namely stereo disparity, optical flow, and sparse point feature\nmatching. These are evaluated quantitatively and qualitatively and results show\na positive effect of specular highlight inpainting on these tasks in a novel\ncomprehensive analysis.",
    "descriptor": "",
    "authors": [
      "Rema Daher",
      "Francisco Vasconcelos",
      "Danail Stoyanov"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.17013"
  },
  {
    "id": "arXiv:2203.17018",
    "title": "An Illustrative Industry Architecture to Mitigate Potential  Fragmentation across Central Bank Digital Currency and Commercial Bank Money",
    "abstract": "Central banks are actively exploring central bank digital currencies (CBDCs)\nby conducting research, proofs of concept and pilots. However, adoption of a\nCBDC can risk fragmenting both payments markets and retail deposits. In this\npaper, we aim to provide a mitigation to this fragmentation risk by presenting\nan illustrative industry architecture which places CBDCs and commercial bank\nmoney on a similar footing. We introduce the concept of ecosystems providing a\ncommon programmability layer that interfaces with the account systems at both\ncommercial banks and the central bank. We focus on a potential United Kingdom\n(UK) CBDC, including industry ecosystems interfacing with commercial banks\nusing Open Banking application programming interfaces (APIs).",
    "descriptor": "\nComments: 7 pages, 2 figures, 1 table\n",
    "authors": [
      "Lee Braine",
      "Shreepad Shukla"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2203.17018"
  },
  {
    "id": "arXiv:2203.17020",
    "title": "Logit Normalization for Long-tail Object Detection",
    "abstract": "Real-world data exhibiting skewed distributions pose a serious challenge to\nexisting object detectors. Moreover, the samplers in detectors lead to shifted\ntraining label distributions, while the tremendous proportion of background to\nforeground samples severely harms foreground classification. To mitigate these\nissues, in this paper, we propose Logit Normalization (LogN), a simple\ntechnique to self-calibrate the classified logits of detectors in a similar way\nto batch normalization. In general, our LogN is training- and tuning-free (i.e.\nrequire no extra training and tuning process), model- and label\ndistribution-agnostic (i.e. generalization to different kinds of detectors and\ndatasets), and also plug-and-play (i.e. direct application without any bells\nand whistles). Extensive experiments on the LVIS dataset demonstrate superior\nperformance of LogN to state-of-the-art methods with various detectors and\nbackbones. We also provide in-depth studies on different aspects of our LogN.\nFurther experiments on ImageNet-LT reveal its competitiveness and\ngeneralizability. Our LogN can serve as a strong baseline for long-tail object\ndetection and is expected to inspire future research in this field. Code and\ntrained models will be publicly available at https://github.com/MCG-NJU/LogN.",
    "descriptor": "",
    "authors": [
      "Liang Zhao",
      "Yao Teng",
      "Limin Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.17020"
  },
  {
    "id": "arXiv:2203.17023",
    "title": "CTA-RNN: Channel and Temporal-wise Attention RNN Leveraging Pre-trained  ASR Embeddings for Speech Emotion Recognition",
    "abstract": "Previous research has looked into ways to improve speech emotion recognition\n(SER) by utilizing both acoustic and linguistic cues of speech. However, the\npotential association between state-of-the-art ASR models and the SER task has\nyet to be investigated. In this paper, we propose a novel channel and\ntemporal-wise attention RNN (CTA-RNN) architecture based on the intermediate\nrepresentations of pre-trained ASR models. Specifically, the embeddings of a\nlarge-scale pre-trained end-to-end ASR encoder contain both acoustic and\nlinguistic information, as well as the ability to generalize to different\nspeakers, making them well suited for downstream SER task. To further exploit\nthe embeddings from different layers of the ASR encoder, we propose a novel\nCTA-RNN architecture to capture the emotional salient parts of embeddings in\nboth the channel and temporal directions. We evaluate our approach on two\npopular benchmark datasets, IEMOCAP and MSP-IMPROV, using both within-corpus\nand cross-corpus settings. Experimental results show that our proposed method\ncan achieve excellent performance in terms of accuracy and robustness.",
    "descriptor": "\nComments: 5 pages, 2 figures, submitted to INTERSPEECH 2022\n",
    "authors": [
      "Chengxin Chen",
      "Pengyuan Zhang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.17023"
  },
  {
    "id": "arXiv:2203.17024",
    "title": "VQF: Highly Accurate IMU Orientation Estimation with Bias Estimation and  Magnetic Disturbance Rejection",
    "abstract": "The miniaturization of inertial measurement units (IMUs) facilitates their\nwidespread use in a growing number of application domains. Orientation\nestimation is a prerequisite for most further data processing steps in inertial\nmotion tracking, such as position/velocity estimation, joint angle estimation,\nand 3D visualization. Errors in the estimated orientations severely affect all\nfurther processing steps. Few existing publications systematically compare\nmultiple algorithms on a broad collection of experimental data, and those\npublications show that out-of-the-box accuracy of existing algorithms is often\nlow and that application-specific tuning is required. In the present work, we\npropose and extensively evaluate an orientation estimation algorithm that is\nbased on a novel approach of filtering the acceleration measurements in an\nalmost-inertial frame and that includes extensions for gyroscope bias\nestimation and magnetic disturbance rejection, as well as a variant for offline\ndata processing. In contrast to all existing work, we perform a comprehensive\nevaluation, using a large collection of publicly available datasets and eight\nliterature methods for comparison. The proposed method consistently outperforms\nall literature methods and achieves an average RMSE of 2.9{\\deg}, while the\nerrors obtained with literature methods range from 5.3{\\deg} to 16.7{\\deg}.\nSince the evaluation was performed with one single fixed parametrization across\na very diverse dataset collection, we conclude that the proposed method\nprovides unprecedented out-of-the-box performance for a broad range of motions,\nsensor hardware, and environmental conditions. This gain in orientation\nestimation accuracy is expected to advance the field of IMU-based motion\nanalysis and provide performance benefits in numerous applications. The\nprovided open-source implementation makes it easy to employ the proposed\nmethod.",
    "descriptor": "",
    "authors": [
      "Daniel Laidig",
      "Thomas Seel"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Robotics (cs.RO)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2203.17024"
  },
  {
    "id": "arXiv:2203.17027",
    "title": "Flat-topped Probability Density Functions for Mixture Models",
    "abstract": "This paper investigates probability density functions (PDFs) that are\ncontinuous everywhere, nearly uniform around the mode of distribution, and\nadaptable to a variety of distribution shapes ranging from bell-shaped to\nrectangular. From the viewpoint of computational tractability, the PDF based on\nthe Fermi-Dirac or logistic function is advantageous in estimating its shape\nparameters. The most appropriate PDF for $n$-variate distribution is of the\nform:\n$p\\left(\\mathbf{x}\\right)\\propto\\left[\\cosh\\left(\\left[\\left(\\mathbf{x}-\\mathbf{m}\\right)^{\\mathsf{T}}\\boldsymbol{\\Sigma}^{-1}\\left(\\mathbf{x}-\\mathbf{m}\\right)\\right]^{n/2}\\right)+\\cosh\\left(r^{n}\\right)\\right]^{-1}$\nwhere $\\mathbf{x},\\mathbf{m}\\in\\mathbb{R}^{n}$, $\\boldsymbol{\\Sigma}$ is an\n$n\\times n$ positive definite matrix, and $r>0$ is a shape parameter. The\nflat-topped PDFs can be used as a component of mixture models in machine\nlearning to improve goodness of fit and make a model as simple as possible.",
    "descriptor": "\nComments: 32 pages, 8 figures, 1 table\n",
    "authors": [
      "Osamu Fujita"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Probability (math.PR)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.17027"
  },
  {
    "id": "arXiv:2203.17030",
    "title": "Few-Shot Class-Incremental Learning by Sampling Multi-Phase Tasks",
    "abstract": "New classes arise frequently in our ever-changing world, e.g., emerging\ntopics in social media and new types of products in e-commerce. A model should\nrecognize new classes and meanwhile maintain discriminability over old classes.\nUnder severe circumstances, only limited novel instances are available to\nincrementally update the model. The task of recognizing few-shot new classes\nwithout forgetting old classes is called few-shot class-incremental learning\n(FSCIL). In this work, we propose a new paradigm for FSCIL based on\nmeta-learning by LearnIng Multi-phase Incremental Tasks (LIMIT), which\nsynthesizes fake FSCIL tasks from the base dataset. The data format of fake\ntasks is consistent with the `real' incremental tasks, and we can build a\ngeneralizable feature space for the unseen tasks through meta-learning.\nBesides, LIMIT also constructs a calibration module based on transformer, which\ncalibrates the old class classifiers and new class prototypes into the same\nscale and fills in the semantic gap. The calibration module also adaptively\ncontextualizes the instance-specific embedding with a set-to-set function.\nLIMIT efficiently adapts to new classes and meanwhile resists forgetting over\nold classes. Experiments on three benchmark datasets (CIFAR100, miniImageNet,\nand CUB200) and large-scale dataset, i.e., ImageNet ILSVRC2012 validate that\nLIMIT achieves state-of-the-art performance.",
    "descriptor": "",
    "authors": [
      "Da-Wei Zhou",
      "Han-Jia Ye",
      "De-Chuan Zhan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.17030"
  },
  {
    "id": "arXiv:2203.17031",
    "title": "Training strategy for a lightweight countermeasure model for automatic  speaker verification",
    "abstract": "The countermeasure (CM) model is developed to protect Automatic Speaker\nVerification (ASV) systems from spoof attacks and prevent resulting personal\ninformation leakage. Based on practicality and security considerations, the CM\nmodel is usually deployed on edge devices, which have more limited computing\nresources and storage space than cloud- based systems. This work proposes\ntraining strategies for a lightweight CM model for ASV, using generalized end-\nto-end (GE2E) pre-training and adversarial fine-tuning to improve performance,\nand applying knowledge distillation (KD) to reduce the size of the CM model. In\nthe evalua- tion phase of the ASVspoof 2021 Logical Access task, the\nlightweight ResNetSE model reaches min t-DCF 0.2695 and EER 3.54%. Compared to\nthe teacher model, the lightweight student model only uses 22.5% of parameters\nand 21.1% of multiply and accumulate operands of the teacher model.",
    "descriptor": "\nComments: ASVspoof2021\n",
    "authors": [
      "Yen-Lun Liao",
      "Xuanjun Chen",
      "Chung-Che Wang",
      "Jyh-Shing Roger Jang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.17031"
  },
  {
    "id": "arXiv:2203.17041",
    "title": "On the Population Monotonicity of Independent Set Games",
    "abstract": "An independent set game is a cooperative game defined on graphs and dealing\nwith profit sharing in maximum independent set problems. A population monotonic\nallocation scheme is a rule specifying how to share the profit of each\ncoalition among its participants such that every participant is better off when\nthe coalition expands. In this paper, we provide a necessary and sufficient\ncharacterization for population monotonic allocation schemes in independent set\ngames. Moreover, our characterization can be verified efficiently.",
    "descriptor": "",
    "authors": [
      "Han Xiao",
      "Libing Wang",
      "Donglei Du",
      "Dachuan Xu"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2203.17041"
  },
  {
    "id": "arXiv:2203.17042",
    "title": "IITD-DBAI: Multi-Stage Retrieval with Pseudo-Relevance Feedback and  Query Reformulation",
    "abstract": "Resolving the contextual dependency is one of the most challenging tasks in\nthe Conversational system. Our submission to CAsT-2021 aimed to preserve the\nkey terms and the context in all subsequent turns and use classical Information\nretrieval methods. It was aimed to pull as relevant documents as possible from\nthe corpus. We have participated in automatic track and submitted two runs in\nthe CAsT-2021. Our submission has produced a mean NDCG@3 performance better\nthan the median model.",
    "descriptor": "",
    "authors": [
      "Shivani Choudhary"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2203.17042"
  },
  {
    "id": "arXiv:2203.17044",
    "title": "Efficient Dropout-resilient Aggregation for Privacy-preserving Machine  Learning",
    "abstract": "With the increasing adoption of data-hungry machine learning algorithms,\npersonal data privacy has emerged as one of the key concerns that could hinder\nthe success of digital transformation. As such, Privacy-Preserving Machine\nLearning (PPML) has received much attention from both academia and industry.\nHowever, organizations are faced with the dilemma that, on the one hand, they\nare encouraged to share data to enhance ML performance, but on the other hand,\nthey could potentially be breaching the relevant data privacy regulations.\nPractical PPML typically allows multiple participants to individually train\ntheir ML models, which are then aggregated to construct a global model in a\nprivacy-preserving manner, e.g., based on multi-party computation or\nhomomorphic encryption. Nevertheless, in most important applications of\nlarge-scale PPML, e.g., by aggregating clients' gradients to update a global\nmodel for federated learning, such as consumer behavior modeling of mobile\napplication services, some participants are inevitably resource-constrained\nmobile devices, which may drop out of the PPML system due to their mobility\nnature. Therefore, the resilience of privacy-preserving aggregation has become\nan important problem to be tackled. In this paper, we propose a scalable\nprivacy-preserving aggregation scheme that can tolerate dropout by participants\nat any time, and is secure against both semi-honest and active malicious\nadversaries by setting proper system parameters. By replacing\ncommunication-intensive building blocks with a seed homomorphic pseudo-random\ngenerator, and relying on the additive homomorphic property of Shamir secret\nsharing scheme, our scheme outperforms state-of-the-art schemes by up to\n6.37$\\times$ in runtime and provides a stronger dropout-resilience. The\nsimplicity of our scheme makes it attractive both for implementation and for\nfurther improvements.",
    "descriptor": "\nComments: 16 pages, 5 figures. Accepted by IEEE Transactions on Information Forensics and Security\n",
    "authors": [
      "Ziyao Liu",
      "Jiale Guo",
      "Kwok-Yan Lam",
      "Jun Zhao"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2203.17044"
  },
  {
    "id": "arXiv:2203.17045",
    "title": "Wasserstein Distributionally Robust Control of Partially Observable  Linear Systems: Tractable Approximation and Performance Guarantee",
    "abstract": "Wasserstein distributionally robust control (WDRC) is an effective method for\naddressing inaccurate distribution information about disturbances in stochastic\nsystems. It provides various salient features, such as an out-of-sample\nperformance guarantee, while most of existing methods use full-state\nobservations. In this paper, we develop a computationally tractable WDRC method\nfor discrete-time partially observable linear-quadratic (LQ) control problems.\nThe key idea is to reformulate the WDRC problem as a novel minimax control\nproblem with an approximate Wasserstein penalty. We derive a closed-form\nexpression of the optimal solution to the approximate problem using a\nnontrivial Riccati equation. We further show the guaranteed cost property of\nthe resulting controller and identify a provable bound for the optimality gap.\nFinally, we evaluate the performance of our method through numerical\nexperiments using both Gaussian and non-Gaussian disturbances.",
    "descriptor": "",
    "authors": [
      "Astghik Hakobyan",
      "Insoon Yang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.17045"
  },
  {
    "id": "arXiv:2203.17051",
    "title": "You Don't Know What I Know: On Notion of High-Order Opacity in  Discrete-Event Systems",
    "abstract": "In this paper, we investigate a class of information-flow security properties\ncalled opacity in partial-observed discrete-event systems. Roughly speaking, a\nsystem is said to be opaque if the intruder, which is modeled by a passive\nobserver, can never determine the \"secret\" of the system for sure. Most of the\nexisting notions of opacity consider secrets related to the actual behaviors of\nthe system. In this paper, we consider a new type of secret related to the\nknowledge of the system user. Specifically, we assume that the system user also\nonly has partial observation of the system and has to reason the actual\nbehavior of the system. We say a system is high-order opaque if the intruder\ncan never determine that the system user knows some information of importance\nbased on its own incomparable information. We provide the formal definition of\nhigh-order opacity. Two algorithms are provided for the verification of this\nnew notion: one with doubly-exponential complexity for the worst case and the\nother with single-exponential complexity. Illustrative examples are provided\nfor the new notion of high-order opacity.",
    "descriptor": "",
    "authors": [
      "Bohan Cui",
      "Xiang Yin",
      "Shaoyuan Li",
      "Alessandro Giua"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.17051"
  },
  {
    "id": "arXiv:2203.17052",
    "title": "Model order reduction of layered waveguides via rational Krylov fitting",
    "abstract": "Rational approximation recently emerged as an efficient numerical tool for\nthe solution of exterior wave propagation problems. Currently, this technique\nis limited to wave media which are invariant along the main propagation\ndirection. We propose a new model order reduction-based approach for\ncompressing unbounded waveguides with layered inclusions. It is based on the\nsolution of a nonlinear rational least squares problem using the RKFIT method.\nWe show that approximants can be converted into an accurate finite difference\nrepresentation within a rational Krylov framework. Numerical experiments\nindicate that RKFIT computes more accurate grids than previous analytic\napproaches and even works in the presence of pronounced scattering resonances.\nSpectral adaptation effects allow for finite difference grids with dimensions\nnear or even below the Nyquist limit.",
    "descriptor": "",
    "authors": [
      "Vladimir Druskin",
      "Stefan G\u00fcttel",
      "Leonid Knizhnerman"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2203.17052"
  },
  {
    "id": "arXiv:2203.17054",
    "title": "BEVDet4D: Exploit Temporal Cues in Multi-camera 3D Object Detection",
    "abstract": "Single frame data contains finite information which limits the performance of\nthe existing vision-based multi-camera 3D object detection paradigms. For\nfundamentally pushing the performance boundary in this area, BEVDet4D is\nproposed to lift the scalable BEVDet paradigm from the spatial-only 3D space to\nthe spatial-temporal 4D space. We upgrade the framework with a few\nmodifications just for fusing the feature from the previous frame with the\ncorresponding one in the current frame. In this way, with negligible extra\ncomputing budget, we enable the algorithm to access the temporal cues by\nquerying and comparing the two candidate features. Beyond this, we also\nsimplify the velocity learning task by removing the factors of ego-motion and\ntime, which equips BEVDet4D with robust generalization performance and reduces\nthe velocity error by 52.8%. This makes vision-based methods, for the first\ntime, become comparable with those relied on LiDAR or radar in this aspect. On\nchallenge benchmark nuScenes, we report a new record of 51.5% NDS with the\nhigh-performance configuration dubbed BEVDet4D-Base, which surpasses the\nprevious leading method BEVDet by +4.3% NDS.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2112.11790\n",
    "authors": [
      "Junjie Huang",
      "Guan Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.17054"
  },
  {
    "id": "arXiv:2203.17055",
    "title": "Certified machine learning: A posteriori error estimation for  physics-informed neural networks",
    "abstract": "Physics-informed neural networks (PINNs) are one popular approach to\nintroduce a priori knowledge about physical systems into the learning\nframework. PINNs are known to be robust for smaller training sets, derive\nbetter generalization problems, and are faster to train. In this paper, we show\nthat using PINNs in comparison with purely data-driven neural networks is not\nonly favorable for training performance but allows us to extract significant\ninformation on the quality of the approximated solution. Assuming that the\nunderlying differential equation for the PINN training is an ordinary\ndifferential equation, we derive a rigorous upper limit on the PINN prediction\nerror. This bound is applicable even for input data not included in the\ntraining phase and without any prior knowledge about the true solution.\nTherefore, our a posteriori error estimation is an essential step to certify\nthe PINN. We apply our error estimator exemplarily to two academic toy\nproblems, whereof one falls in the category of model-predictive control and\nthereby shows the practical use of the derived results.",
    "descriptor": "",
    "authors": [
      "Birgit Hillebrecht",
      "Benjamin Unger"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2203.17055"
  },
  {
    "id": "arXiv:2203.17063",
    "title": "Efficient and Eventually Consistent Collective Operations",
    "abstract": "Collective operations are common features of parallel programming models that\nare frequently used in High-Performance (HPC) and machine/ deep learning (ML/\nDL) applications. In strong scaling scenarios, collective operations can\nnegatively impact the overall application performance: with the increase in\ncore count, the load per rank decreases, while the time spent in collective\noperations increases logarithmically.\nIn this article, we propose a design for eventually consistent collectives\nsuitable for ML/ DL computations by reducing communication in Broadcast and\nReduce, as well as by exploring the Stale Synchronous Parallel (SSP)\nsynchronization model for the Allreduce collective. Moreover, we also enrich\nthe GASPI ecosystem with frequently used classic/ consistent collective\noperations -- such as Allreduce for large messages and AlltoAll used in an HPC\ncode. Our implementations show promising preliminary results with significant\nimprovements, especially for Allreduce and AlltoAll, compared to the\nvendor-provided MPI alternatives.",
    "descriptor": "",
    "authors": [
      "Roman Iakymchuk",
      "Amandio Faustino",
      "Andrew Emerson",
      "Joao Barreto",
      "Valeria Bartsch",
      "Rodrigo Rodrigues",
      "Jose C. Monteiro"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2203.17063"
  },
  {
    "id": "arXiv:2203.17067",
    "title": "CADG: A Model Based on Cross Attention for Domain Generalization",
    "abstract": "In Domain Generalization (DG) tasks, models are trained by using only\ntraining data from the source domains to achieve generalization on an unseen\ntarget domain, this will suffer from the distribution shift problem. So it's\nimportant to learn a classifier to focus on the common representation which can\nbe used to classify on multi-domains, so that this classifier can achieve a\nhigh performance on an unseen target domain as well. With the success of cross\nattention in various cross-modal tasks, we find that cross attention is a\npowerful mechanism to align the features come from different distributions. So\nwe design a model named CADG (cross attention for domain generalization),\nwherein cross attention plays a important role, to address distribution shift\nproblem. Such design makes the classifier can be adopted on multi-domains, so\nthe classifier will generalize well on an unseen domain. Experiments show that\nour proposed method achieves state-of-the-art performance on a variety of\ndomain generalization benchmarks compared with other single model and can even\nachieve a better performance than some ensemble-based methods.",
    "descriptor": "",
    "authors": [
      "Cheng Dai",
      "Fan Li",
      "Xiyao Li",
      "Donglin Xie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.17067"
  },
  {
    "id": "arXiv:2203.17070",
    "title": "Traffic4cast at NeurIPS 2021 - Temporal and Spatial Few-Shot Transfer  Learning in Gridded Geo-Spatial Processes",
    "abstract": "The IARAI Traffic4cast competitions at NeurIPS 2019 and 2020 showed that\nneural networks can successfully predict future traffic conditions 1 hour into\nthe future on simply aggregated GPS probe data in time and space bins. We thus\nreinterpreted the challenge of forecasting traffic conditions as a movie\ncompletion task. U-Nets proved to be the winning architecture, demonstrating an\nability to extract relevant features in this complex real-world geo-spatial\nprocess. Building on the previous competitions, Traffic4cast 2021 now focuses\non the question of model robustness and generalizability across time and space.\nMoving from one city to an entirely different city, or moving from pre-COVID\ntimes to times after COVID hit the world thus introduces a clear domain shift.\nWe thus, for the first time, release data featuring such domain shifts. The\ncompetition now covers ten cities over 2 years, providing data compiled from\nover 10^12 GPS probe data. Winning solutions captured traffic dynamics\nsufficiently well to even cope with these complex domain shifts. Surprisingly,\nthis seemed to require only the previous 1h traffic dynamic history and static\nroad graph as input.",
    "descriptor": "\nComments: Pre-print under review, submitted to Proceedings of Machine Learning Research\n",
    "authors": [
      "Christian Eichenberger",
      "Moritz Neun",
      "Henry Martin",
      "Pedro Herruzo",
      "Markus Spanring",
      "Yichao Lu",
      "Sungbin Choi",
      "Vsevolod Konyakhin",
      "Nina Lukashina",
      "Aleksei Shpilman",
      "Nina Wiedemann",
      "Martin Raubal",
      "Bo Wang",
      "Hai L. Vu",
      "Reza Mohajerpoor",
      "Chen Cai",
      "Inhi Kim",
      "Luca Hermes",
      "Andrew Melnik",
      "Riza Velioglu",
      "Markus Vieth",
      "Malte Schilling",
      "Alabi Bojesomo",
      "Hasan Al Marzouqi",
      "Panos Liatsis",
      "Jay Santokhi",
      "Dylan Hillier",
      "Yiming Yang",
      "Joned Sarwar",
      "Anna Jordan",
      "Emil Hewage",
      "David Jonietz",
      "Fei Tang",
      "Aleksandra Gruca",
      "Michael Kopp",
      "David Kreil",
      "Sepp Hochreiter"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.17070"
  },
  {
    "id": "arXiv:2203.17072",
    "title": "Manipulation of oral cancer speech using neural articulatory synthesis",
    "abstract": "We present an articulatory synthesis framework for the synthesis and\nmanipulation of oral cancer speech for clinical decision making and alleviation\nof patient stress. Objective and subjective evaluations demonstrate that the\nframework has acceptable naturalness and is worth further investigation. A\nsubsequent subjective vowel and consonant identification experiment showed that\nthe articulatory synthesis system can manipulate the articulatory trajectories\nso that the synthesised speech reproduces problems present in the ground truth\noral cancer speech.",
    "descriptor": "\nComments: 5 pages, 4 tables, 1 figure. Submitted to Interspeech 2022\n",
    "authors": [
      "Bence Mark Halpern",
      "Teja Rebernik",
      "Thomas Tienkamp",
      "Rob van Son",
      "Michiel van den Brekel",
      "Martijn Wieling",
      "Max Witjes",
      "Odette Scharenborg"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.17072"
  },
  {
    "id": "arXiv:2203.17076",
    "title": "Deep Hyperspectral Unmixing using Transformer Network",
    "abstract": "Currently, this paper is under review in IEEE. Transformers have intrigued\nthe vision research community with their state-of-the-art performance in\nnatural language processing. With their superior performance, transformers have\nfound their way in the field of hyperspectral image classification and achieved\npromising results. In this article, we harness the power of transformers to\nconquer the task of hyperspectral unmixing and propose a novel deep unmixing\nmodel with transformers. We aim to utilize the ability of transformers to\nbetter capture the global feature dependencies in order to enhance the quality\nof the endmember spectra and the abundance maps. The proposed model is a\ncombination of a convolutional autoencoder and a transformer. The hyperspectral\ndata is encoded by the convolutional encoder. The transformer captures\nlong-range dependencies between the representations derived from the encoder.\nThe data are reconstructed using a convolutional decoder. We applied the\nproposed unmixing model to three widely used unmixing datasets, i.e., Samson,\nApex, and Washington DC mall and compared it with the state-of-the-art in terms\nof root mean squared error and spectral angle distance. The source code for the\nproposed model will be made publicly available at\n\\url{https://github.com/preetam22n/DeepTrans-HSU}.",
    "descriptor": "\nComments: Currently, this paper is under review in IEEE\n",
    "authors": [
      "Preetam Ghosh",
      "Swalpa Kumar Roy",
      "Bikram Koirala",
      "Behnood Rasti",
      "Paul Scheunders"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2203.17076"
  },
  {
    "id": "arXiv:2203.17079",
    "title": "Scientific and Technological Text Knowledge Extraction Method of based  on Word Mixing and GRU",
    "abstract": "The knowledge extraction task is to extract triple relations (head\nentity-relation-tail entity) from unstructured text data. The existing\nknowledge extraction methods are divided into \"pipeline\" method and joint\nextraction method. The \"pipeline\" method is to separate named entity\nrecognition and entity relationship extraction and use their own modules to\nextract them. Although this method has better flexibility, the training speed\nis slow. The learning model of joint extraction is an end-to-end model\nimplemented by neural network to realize entity recognition and relationship\nextraction at the same time, which can well preserve the association between\nentities and relationships, and convert the joint extraction of entities and\nrelationships into a sequence annotation problem. In this paper, we propose a\nknowledge extraction method for scientific and technological resources based on\nword mixture and GRU, combined with word mixture vector mapping method and\nself-attention mechanism, to effectively improve the effect of text\nrelationship extraction for Chinese scientific and technological resources.",
    "descriptor": "\nComments: 8 pages,2 figures\n",
    "authors": [
      "Suyu Ouyang",
      "Yingxia Shao",
      "Junping Du",
      "Ang Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.17079"
  },
  {
    "id": "arXiv:2203.17081",
    "title": "Interpretation of Black Box NLP Models: A Survey",
    "abstract": "An increasing number of machine learning models have been deployed in domains\nwith high stakes such as finance and healthcare. Despite their superior\nperformances, many models are black boxes in nature which are hard to explain.\nThere are growing efforts for researchers to develop methods to interpret these\nblack-box models. Post hoc explanations based on perturbations, such as LIME,\nare widely used approaches to interpret a machine learning model after it has\nbeen built. This class of methods has been shown to exhibit large instability,\nposing serious challenges to the effectiveness of the method itself and harming\nuser trust. In this paper, we propose S-LIME, which utilizes a hypothesis\ntesting framework based on central limit theorem for determining the number of\nperturbation points needed to guarantee stability of the resulting explanation.\nExperiments on both simulated and real world data sets are provided to\ndemonstrate the effectiveness of our method.",
    "descriptor": "",
    "authors": [
      "Shivani Choudhary",
      "Niladri Chatterjee",
      "Subir Kumar Saha"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2203.17081"
  },
  {
    "id": "arXiv:2203.17085",
    "title": "RobIn: A Robust Interpretable Deep Network for Schizophrenia Diagnosis",
    "abstract": "Schizophrenia is a severe mental health condition that requires a long and\ncomplicated diagnostic process. However, early diagnosis is vital to control\nsymptoms. Deep learning has recently become a popular way to analyse and\ninterpret medical data. Past attempts to use deep learning for schizophrenia\ndiagnosis from brain-imaging data have shown promise but suffer from a large\ntraining-application gap - it is difficult to apply lab research to the real\nworld. We propose to reduce this training-application gap by focusing on\nreadily accessible data. We collect a data set of psychiatric observations of\npatients based on DSM-5 criteria. Because similar data is already recorded in\nall mental health clinics that diagnose schizophrenia using DSM-5, our method\ncould be easily integrated into current processes as a tool to assist\nclinicians, whilst abiding by formal diagnostic criteria. To facilitate\nreal-world usage of our system, we show that it is interpretable and robust.\nUnderstanding how a machine learning tool reaches its diagnosis is essential to\nallow clinicians to trust that diagnosis. To interpret the framework, we fuse\ntwo complementary attention mechanisms, 'squeeze and excitation' and\n'self-attention', to determine global attribute importance and attribute\ninteractivity, respectively. The model uses these importance scores to make\ndecisions. This allows clinicians to understand how a diagnosis was reached,\nimproving trust in the model. Because machine learning models often struggle to\ngeneralise to data from different sources, we perform experiments with\naugmented test data to evaluate the model's applicability to the real world. We\nfind that our model is more robust to perturbations, and should therefore\nperform better in a clinical setting. It achieves 98% accuracy with 10-fold\ncross-validation.",
    "descriptor": "",
    "authors": [
      "Daniel Organisciak",
      "Hubert P. H. Shum",
      "Ephraim Nwoye",
      "Wai Lok Woo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.17085"
  },
  {
    "id": "arXiv:2203.17090",
    "title": "PANGUBOT: Efficient Generative Dialogue Pre-training from Pre-trained  Language Model",
    "abstract": "In this paper, we introduce PANGUBOT, a Chinese pre-trained open-domain\ndialogue generation model based on a large pre-trained language model (PLM)\nPANGU-alpha (Zeng et al.,2021). Different from other pre-trained dialogue\nmodels trained over a massive amount of dialogue data from scratch, we aim to\nbuild a powerful dialogue model with relatively fewer data and computation\ncosts by inheriting valuable language capabilities and knowledge from PLMs. To\nthis end, we train PANGUBOT from the large PLM PANGU-alpha, which has been\nproven well-performed on a variety of Chinese natural language tasks. We\ninvestigate different aspects of responses generated by PANGUBOT, including\nresponse quality, knowledge, and safety. We show that PANGUBOT outperforms\nstate-of-the-art Chinese dialogue systems (CDIALGPT (Wang et al., 2020), EVA\n(Zhou et al., 2021)) w.r.t. the above three aspects. We also demonstrate that\nPANGUBOT can be easily deployed to generate emotional responses without further\ntraining. Throughout our empirical analysis, we also point out that the\nPANGUBOT response quality, knowledge correctness, and safety are still far from\nperfect, and further explorations are indispensable to building reliable and\nsmart dialogue systems.",
    "descriptor": "",
    "authors": [
      "Fei Mi",
      "Yitong Li",
      "Yulong Zeng",
      "Jingyan Zhou",
      "Yasheng Wang",
      "Chuanfei Xu",
      "Lifeng Shang",
      "Xin Jiang",
      "Shiqi Zhao",
      "Qun Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.17090"
  },
  {
    "id": "arXiv:2203.17096",
    "title": "Sensor Deception Attacks Against Initial-State Privacy in Supervisory  Control Systems",
    "abstract": "This paper investigates the problem of synthesizing sensor deception\nattackers against privacy in the context of supervisory control of\ndiscrete-event systems (DES). We consider a DES plant controlled by a\nsupervisor, which is subject to sensor deception attacks. Specifically, we\nconsider an active attacker that can tamper with the observations received by\nthe supervisor by, e.g., hacking on the communication channel between the\nsensors and the supervisor. The privacy requirement of the supervisory control\nsystem is to maintain initial-state opacity, i.e., it does not want to reveal\nthe fact that it was initiated from a secret state during its operation. On the\nother hand, the attacker aims to deceive the supervisor, by tampering with its\nobservations, such that initial-state opacity is violated due to incorrect\ncontrol actions. In this work, we investigate from the attacker's point of view\nby presenting an effective approach for synthesizing sensor attack strategies\nthreatening the privacy of the system. To this end, we propose the All Attack\nStructure (AAS) that records state estimates for both the supervisor and the\nattacker. This structure serves as a basis for synthesizing a sensor attack\nstrategy. We also discuss how to simplify the synthesis complexity by\nleveraging the structural property of the initial-state privacy requirement. A\nrunning academic example is provided to illustrate the synthesis procedure.",
    "descriptor": "\nComments: 8 pages, 7 figures\n",
    "authors": [
      "Jingshi Yao",
      "Xiang Yin",
      "Shaoyuan Li"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.17096"
  },
  {
    "id": "arXiv:2203.17102",
    "title": "Sequential Cooperative Energy and Time-Optimal Lane Change Maneuvers for  Highway Traffic",
    "abstract": "We derive optimal control policies for a Connected Automated Vehicle (CAV)\nand cooperating neighboring CAVs to carry out a lane change maneuver consisting\nof a longitudinal phase where the CAV properly positions itself relative to the\ncooperating neighbors and a lateral phase where it safely changes lanes. In\ncontrast to prior work on this problem, where the CAV \"selfishly\" seeks to\nminimize its maneuver time, we seek to ensure that the fast-lane traffic flow\nis minimally disrupted (through a properly defined metric) and that highway\nthroughput is improved by optimally selecting the cooperating vehicles. We show\nthat analytical solutions for the optimal trajectories can be derived and are\nguaranteed to satisfy safety constraints for all vehicles involved in the\nmaneuver. When feasible solutions do not exist, we include a time relaxation\nmethod trading off a longer maneuver time with reduced disruption. Our analysis\nis also extended to multiple sequential maneuvers. Simulation results where the\ncontrollers are implemented show their effectiveness in terms of safety\nguarantees and up to 35% throughput improvement compared to maneuvers with no\nvehicle cooperation.",
    "descriptor": "",
    "authors": [
      "Andres S. Chavez Armijos",
      "Rui Chen",
      "Christos G. Cassandras",
      "Yasir K. Al-Nadawi",
      "Hossein Noukhiz Mahjoub",
      "Hidekazu Araki"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.17102"
  },
  {
    "id": "arXiv:2203.17103",
    "title": "$k$NN-NER: Named Entity Recognition with Nearest Neighbor Search",
    "abstract": "Inspired by recent advances in retrieval augmented methods in\nNLP~\\citep{khandelwal2019generalization,khandelwal2020nearest,meng2021gnn}, in\nthis paper, we introduce a $k$ nearest neighbor NER ($k$NN-NER) framework,\nwhich augments the distribution of entity labels by assigning $k$ nearest\nneighbors retrieved from the training set. This strategy makes the model more\ncapable of handling long-tail cases, along with better few-shot learning\nabilities. $k$NN-NER requires no additional operation during the training\nphase, and by interpolating $k$ nearest neighbors search into the vanilla NER\nmodel, $k$NN-NER consistently outperforms its vanilla counterparts: we achieve\na new state-of-the-art F1-score of 72.03 (+1.25) on the Chinese Weibo dataset\nand improved results on a variety of widely used NER benchmarks. Additionally,\nwe show that $k$NN-NER can achieve comparable results to the vanilla NER model\nwith 40\\% less amount of training data. Code available at\n\\url{https://github.com/ShannonAI/KNN-NER}.",
    "descriptor": "\nComments: preprint\n",
    "authors": [
      "Shuhe Wang",
      "Xiaoya Li",
      "Yuxian Meng",
      "Tianwei Zhang",
      "Rongbin Ouyang",
      "Jiwei Li",
      "Guoyin Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.17103"
  },
  {
    "id": "arXiv:2203.17105",
    "title": "A Computationally Informed Realisation Algorithm for Lithium-Ion  Batteries Implemented with LiiBRA.jl",
    "abstract": "Real-time battery modelling advancements have quickly become a requirement as\nthe adoption of battery electric vehicles (BEVs) has rapidly increased. In this\npaper an open-source, improved discrete realisation algorithm, implemented in\nJulia for creation and simulation of reduced-order, real-time capable\nphysics-based models is presented. This work reduces the Doyle-Fuller-Newman\nelectrochemical model into continuous-form transfer functions and introduces a\ncomputationally informed discrete realisation algorithm (CI-DRA) to generate\nthe reduced-order models. Further improvements in conventional offline model\ncreation are obtained as well as achieving in-vehicle capable model creation\nfor ARM based computing architectures. Furthermore, a sensitivity analysis on\nthe resultant computational time is completed as well as experimental\nvalidation of a worldwide harmonised light vehicle test procedure (WLTP) for a\nLG Chem. M50 21700 parameterisation. A performance comparison to the\nconventional Matlab implemented discrete realisation algorithm (DRA) is\ncompleted showcasing a mean computational time improvement of 88%. Finally, an\nARM based compilation is investigated for in-vehicle model generation and shows\na modest performance reduction of 43% when compared to the x86 implementation\nwhile still generating accurate models within 5.5 seconds.",
    "descriptor": "",
    "authors": [
      "Brady Planden",
      "Katie Lukow",
      "Paul Henshall",
      "Gordana Collier",
      "Denise Morrey"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.17105"
  },
  {
    "id": "arXiv:2203.17106",
    "title": "A Cooperative Optimal Control Framework for Connected and Automated  Vehicles in Mixed Traffic Using Social Value Orientation",
    "abstract": "In this paper, we develop a socially cooperative optimal control framework\nfor connected and automated vehicles (CAVs) in mixed traffic using social value\norientation (SVO). In our approach, we formulate the interaction between a CAV\nand a human-driven vehicle (HDV) as a simultaneous game to facilitate the\nderivation of a Nash equilibrium. In the imposed game, each vehicle minimizes a\nweighted sum of its egoistic objective and a cooperative objective. The SVO\nangles are used to quantify preferences of the vehicles toward the egoistic and\ncooperative objectives which lead to an appropriate design of weighting factors\nin a multi-objective optimal control problem. We prove that by solving the\nproposed optimal control problem, a Nash equilibrium can be obtained. To\nestimate the SVO angle of the HDV, we develop a receding horizon estimation\nbased on maximum entropy inverse reinforcement learning. The effectiveness of\nthe proposed approach is demonstrated by numerical simulations at a highway\non-ramp merging scenario.",
    "descriptor": "\nComments: submitted to CDC2022\n",
    "authors": [
      "Viet-Anh Le",
      "Andreas A. Malikopoulos"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.17106"
  },
  {
    "id": "arXiv:2203.17109",
    "title": "A Rich Recipe Representation as Plan to Support Expressive Multi Modal  Queries on Recipe Content and Preparation Process",
    "abstract": "Food is not only a basic human necessity but also a key factor driving a\nsociety's health and economic well-being. As a result, the cooking domain is a\npopular use-case to demonstrate decision-support (AI) capabilities in service\nof benefits like precision health with tools ranging from information retrieval\ninterfaces to task-oriented chatbots. An AI here should understand concepts in\nthe food domain (e.g., recipes, ingredients), be tolerant to failures\nencountered while cooking (e.g., browning of butter), handle allergy-based\nsubstitutions, and work with multiple data modalities (e.g. text and images).\nHowever, the recipes today are handled as textual documents which makes it\ndifficult for machines to read, reason and handle ambiguity. This demands a\nneed for better representation of the recipes, overcoming the ambiguity and\nsparseness that exists in the current textual documents. In this paper, we\ndiscuss the construction of a machine-understandable rich recipe representation\n(R3), in the form of plans, from the recipes available in natural language. R3\nis infused with additional knowledge such as information about allergens and\nimages of ingredients, possible failures and tips for each atomic cooking step.\nTo show the benefits of R3, we also present TREAT, a tool for recipe retrieval\nwhich uses R3 to perform multi-modal reasoning on the recipe's content (plan\nobjects - ingredients and cooking tools), food preparation process (plan\nactions and time), and media type (image, text). R3 leads to improved retrieval\nefficiency and new capabilities that were hither-to not possible in textual\nrepresentation.",
    "descriptor": "",
    "authors": [
      "Vishal Pallagani",
      "Priyadharsini Ramamurthy",
      "Vedant Khandelwal",
      "Revathy Venkataramanan",
      "Kausik Lakkaraju",
      "Sathyanarayanan N. Aakur",
      "Biplav Srivastava"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.17109"
  },
  {
    "id": "arXiv:2203.17110",
    "title": "Impact of Acoustic Noise on Alzheimer's Disease Detection from Speech:  Should You Let Baby Cry?",
    "abstract": "Research related to automatically detecting Alzheimer's disease (AD) is\nimportant, given the high prevalence of AD and the high cost of traditional\nmethods. Since AD significantly affects the acoustics of spontaneous speech,\nspeech processing and machine learning (ML) provide promising techniques for\nreliably detecting AD. However, speech audio may be affected by different types\nof background noise and it is important to understand how the noise influences\nthe accuracy of ML models detecting AD from speech. In this paper, we study the\neffect of fifteen types of noise from five different categories on the\nperformance of four ML models trained with three types of acoustic\nrepresentations. We perform a thorough analysis showing how ML models and\nacoustic features are affected by different types of acoustic noise. We show\nthat acoustic noise is not necessarily harmful - certain types of noise are\nbeneficial for AD detection models and help increasing accuracy by up to 4.8\\%.\nWe provide recommendations on how to utilize acoustic noise in order to achieve\nthe best performance results with the ML models deployed in real world.",
    "descriptor": "\nComments: Submitted to Interspeech 2022\n",
    "authors": [
      "Jekaterina Novikova"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.17110"
  },
  {
    "id": "arXiv:2203.17112",
    "title": "SLNET: A Redistributable Corpus of 3rd-party Simulink Models",
    "abstract": "MATLAB/Simulink is widely used for model-based design. Engineers create\nSimulink models and compile them to embedded code, often to control\nsafety-critical cyber-physical systems in automotive, aerospace, and healthcare\napplications. Despite Simulink's importance, there are few large-scale\nempirical Simulink studies, perhaps because there is no large readily available\ncorpus of third-party open-source Simulink models. To enable empirical Simulink\nstudies, this paper introduces SLNET, the largest corpus of freely available\nthird-party Simulink models. SLNET has several advantages over earlier\ncollections. Specifically, SLNET is 8 times larger than the largest previous\ncorpus of Simulink models, includes fine-grained metadata, is constructed\nautomatically, is self-contained, and allows redistribution. SLNET is available\nunder permissive open-source licenses and contains all of its collection and\nanalysis tools.",
    "descriptor": "\nComments: Published in Mining Software Repositories 2022 - Data and Tool Showcase Track\n",
    "authors": [
      "Sohil Lal Shrestha",
      "Shafiul Azam Chowdhury",
      "Christoph Csallner"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2203.17112"
  },
  {
    "id": "arXiv:2203.17113",
    "title": "Pre-Training Transformer Decoder for End-to-End ASR Model with Unpaired  Speech Data",
    "abstract": "This paper studies a novel pre-training technique with unpaired speech data,\nSpeech2C, for encoder-decoder based automatic speech recognition (ASR). Within\na multi-task learning framework, we introduce two pre-training tasks for the\nencoder-decoder network using acoustic units, i.e., pseudo codes, derived from\nan offline clustering model. One is to predict the pseudo codes via masked\nlanguage modeling in encoder output, like HuBERT model, while the other lets\nthe decoder learn to reconstruct pseudo codes autoregressively instead of\ngenerating textual scripts. In this way, the decoder learns to reconstruct\noriginal speech information with codes before learning to generate correct\ntext. Comprehensive experiments on the LibriSpeech corpus show that the\nproposed Speech2C can relatively reduce the word error rate (WER) by 19.2% over\nthe method without decoder pre-training, and also outperforms significantly the\nstate-of-the-art wav2vec 2.0 and HuBERT on fine-tuning subsets of 10h and 100h.",
    "descriptor": "\nComments: Submitted to INTERSPEECH 2022\n",
    "authors": [
      "Junyi Ao",
      "Ziqiang Zhang",
      "Long Zhou",
      "Shujie Liu",
      "Haizhou Li",
      "Tom Ko",
      "Lirong Dai",
      "Jinyu Li",
      "Yao Qian",
      "Furu Wei"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.17113"
  },
  {
    "id": "arXiv:2203.17114",
    "title": "A Physical Layer Model for the Performance Evaluation of V2X  Communication",
    "abstract": "Recent advancements in V2X communications have greatly increased the\nflexibility of the physical and MAC layers. The performance evaluation of V2X\ncommunication systems should take such flexibility into account through a\ncross-layer approach, which often leads to complex evaluation processes.\nIndeed, many performance evaluations presented in the literature rely on simple\nmodels to abstract the physical layer of the supported technologies. However,\nsuch models are usually not general, i.e., their applications are limited to\nspecific scenarios or technologies, thus failing to reflect the flexibility of\ncurrent V2X communications. Alternative solutions require computationally\nintensive simulations at the link level or non-trivial parameter tuning. The\ngoal of this paper is to develop a new approach for modeling V2X communications\nat the physical layer. The approach is general for different technologies and\nhas been validated through experimental data and system simulations with both\nIEEE 802.11p and sidelink LTE-V2X technologies.",
    "descriptor": "",
    "authors": [
      "Stefania Bartoletti",
      "Wu Zhuofei",
      "Vincent Martinez",
      "Alessandro Bazzi"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2203.17114"
  },
  {
    "id": "arXiv:2203.17117",
    "title": "Gradient flow structure and convergence analysis of the ensemble Kalman  inversion for nonlinear forward models",
    "abstract": "The ensemble Kalman inversion (EKI) is a particle based method which has been\nintroduced as the application of the ensemble Kalman filter to inverse\nproblems. In practice it has been widely used as derivative-free optimization\nmethod in order to estimate unknown parameters from noisy measurement data. For\nlinear forward models the EKI can be viewed as gradient flow preconditioned by\na certain sample covariance matrix. Through the preconditioning the resulting\nscheme remains in a finite dimensional subspace of the original\nhigh-dimensional (or even infinite dimensional) parameter space and can be\nviewed as optimizer restricted to this subspace. For general nonlinear forward\nmodels the resulting EKI flow can only be viewed as gradient flow in\napproximation. In this paper we discuss the effect of applying a sample\ncovariance as preconditioning matrix and quantify the gradient flow structure\nof the EKI by controlling the approximation error through the spread in the\nparticle system. The ensemble collapse on the one side leads to an accurate\ngradient approximation, but on the other side to degeneration in the\npreconditioning sample covariance matrix. In order to ensure convergence as\noptimization method we derive lower as well as upper bounds on the ensemble\ncollapse. Furthermore, we introduce covariance inflation without breaking the\nsubspace property intending to reduce the collapse rate of the ensemble such\nthat the convergence rate improves. In a numerical experiment we apply EKI to a\nnonlinear elliptic boundary-value problem and illustrate the dependence of EKI\nas derivative-free optimizer on the choice of the initial ensemble.",
    "descriptor": "",
    "authors": [
      "Simon Weissmann"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2203.17117"
  },
  {
    "id": "arXiv:2203.17118",
    "title": "Doubly-Robust Estimation for Unbiased Learning-to-Rank from  Position-Biased Click Feedback",
    "abstract": "Clicks on rankings suffer from position bias: generally items on lower ranks\nare less likely to be examined - and thus clicked - by users, in spite of their\nactual preferences between items. The prevalent approach to unbiased\nclick-based Learning-to-Rank (LTR) is based on counterfactual\nInverse-Propensity-Scoring (IPS) estimation. Unique about LTR is the fact that\nstandard Doubly-Robust (DR) estimation - which combines IPS with regression\npredictions - is inapplicable since the treatment variable - indicating whether\na user examined an item - cannot be observed in the data. In this paper, we\nintroduce a novel DR estimator that uses the expectation of treatment per rank\ninstead. Our novel DR estimator has more robust unbiasedness conditions than\nthe existing IPS approach, and in addition, provides enormous decreases in\nvariance: our experimental results indicate it requires several orders of\nmagnitude fewer datapoints to converge at optimal performance. For the unbiased\nLTR field, our DR estimator contributes both increases in state-of-the-art\nperformance and the most robust theoretical guarantees of all known LTR\nestimators.",
    "descriptor": "",
    "authors": [
      "Harrie Oosterhuis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2203.17118"
  },
  {
    "id": "arXiv:2203.17125",
    "title": "An Affine Type System with Hindley-Milner Style Type Inference",
    "abstract": "This article first provides an algorithm W based type inference algorithm for\nan affine type system. Then the article further assumes the language equipped\nwith the above type system uses lazy evaluation, and explores the possibility\nof representing the !-modality as a user-defined type synonym with the power of\nthe newly gained polymorphism.",
    "descriptor": "\nComments: 9 pages\n",
    "authors": [
      "Gonglin Li"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2203.17125"
  },
  {
    "id": "arXiv:2203.17128",
    "title": "Neural Q-learning for solving elliptic PDEs",
    "abstract": "Solving high-dimensional partial differential equations (PDEs) is a major\nchallenge in scientific computing. We develop a new numerical method for\nsolving elliptic-type PDEs by adapting the Q-learning algorithm in\nreinforcement learning. Our \"Q-PDE\" algorithm is mesh-free and therefore has\nthe potential to overcome the curse of dimensionality. Using a neural tangent\nkernel (NTK) approach, we prove that the neural network approximator for the\nPDE solution, trained with the Q-PDE algorithm, converges to the trajectory of\nan infinite-dimensional ordinary differential equation (ODE) as the number of\nhidden units $\\rightarrow \\infty$. For monotone PDE (i.e. those given by\nmonotone operators, which may be nonlinear), despite the lack of a spectral gap\nin the NTK, we then prove that the limit neural network, which satisfies the\ninfinite-dimensional ODE, converges in $L^2$ to the PDE solution as the\ntraining time $\\rightarrow \\infty$. More generally, we can prove that any fixed\npoint of the wide-network limit for the Q-PDE algorithm is a solution of the\nPDE (not necessarily under the monotone condition). The numerical performance\nof the Q-PDE algorithm is studied for several elliptic PDEs.",
    "descriptor": "",
    "authors": [
      "Samuel N. Cohen",
      "Deqing Jiang",
      "Justin Sirignano"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)",
      "Analysis of PDEs (math.AP)",
      "Probability (math.PR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.17128"
  },
  {
    "id": "arXiv:2203.17132",
    "title": "Finding Balance-Fair Short Paths in Graphs",
    "abstract": "The computation of short paths in graphs with edge lengths is a pillar of\ngraph algorithmics and network science. In a more diverse world, however, not\nevery short path is equally valuable. We contribute to a broader view on path\nfinding by injecting a natural fairness aspect. Our fairness notion relates to\nvertex-colored graphs. Herein, we seek to find short paths where all colors\nshould appear with roughly the same frequency. Among other results, we prove\nthe introduced problems to be computationally hard (NP-hard and parameterized\nhard with respect to the number of colors), while also presenting an\nencouraging algorithmic result (\"fixed-parameter tractability\") related to the\nlength of the sought solution path.",
    "descriptor": "",
    "authors": [
      "Matthias Bentert",
      "Leon Kellerhals",
      "Rolf Niedermeier"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2203.17132"
  },
  {
    "id": "arXiv:2203.17134",
    "title": "Java Prolog Interface",
    "abstract": "There are many initiatives in presents-days for interaction between Java and\nProlog programming languages. These initiatives allow combine two programming\nparadigms, Object Oriented Programming and Logic Programming. Every proposed\ninterface has specifics features depending of the final use. The present paper\nintroduces a new Java Prolog Interface to be use for Prolog persistence\ninteracting from Java side and functional programming from Prolog side. To\nsupport this interaction, the most advanced solutions implements interlanguages\ndata type mappings between Java objects and Prolog terms. Java Prolog Interface\nis a modern solution that take the best features from existing solutions and\ncombine all in one. It' s more flexible, adaptive and have an Application\nProvider Interface (API) easy to use. JPI implement the javax.script interface\ninclude in Java from version 1.6. The project like existing solutions have an\nimplementation for the most popular open source Prolog Engines. Is hosted on\nGitHub source code management at Prolobjectlink repository and deploy the\nresulting artifacts on Maven Central repository. The project have a web page\ntoo hosted on GitHub.",
    "descriptor": "",
    "authors": [
      "Jose E. Zalacain Llanes"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2203.17134"
  },
  {
    "id": "arXiv:2203.17138",
    "title": "Imitate and Repurpose: Learning Reusable Robot Movement Skills From  Human and Animal Behaviors",
    "abstract": "We investigate the use of prior knowledge of human and animal movement to\nlearn reusable locomotion skills for real legged robots. Our approach builds\nupon previous work on imitating human or dog Motion Capture (MoCap) data to\nlearn a movement skill module. Once learned, this skill module can be reused\nfor complex downstream tasks. Importantly, due to the prior imposed by the\nMoCap data, our approach does not require extensive reward engineering to\nproduce sensible and natural looking behavior at the time of reuse. This makes\nit easy to create well-regularized, task-oriented controllers that are suitable\nfor deployment on real robots. We demonstrate how our skill module can be used\nfor imitation, and train controllable walking and ball dribbling policies for\nboth the ANYmal quadruped and OP3 humanoid. These policies are then deployed on\nhardware via zero-shot simulation-to-reality transfer. Accompanying videos are\navailable at https://bit.ly/robot-npmp.",
    "descriptor": "\nComments: 30 pages, 9 figures, 8 tables, 14 videos at this https URL , submitted to Science Robotics\n",
    "authors": [
      "Steven Bohez",
      "Saran Tunyasuvunakool",
      "Philemon Brakel",
      "Fereshteh Sadeghi",
      "Leonard Hasenclever",
      "Yuval Tassa",
      "Emilio Parisotto",
      "Jan Humplik",
      "Tuomas Haarnoja",
      "Roland Hafner",
      "Markus Wulfmeier",
      "Michael Neunert",
      "Ben Moran",
      "Noah Siegel",
      "Andrea Huber",
      "Francesco Romano",
      "Nathan Batchelor",
      "Federico Casarini",
      "Josh Merel",
      "Raia Hadsell",
      "Nicolas Heess"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.17138"
  },
  {
    "id": "arXiv:2203.17139",
    "title": "Prefix Filter: Practically and Theoretically Better Than Bloom",
    "abstract": "Many applications of approximate membership query data structures, or\nfilters, require only an incremental filter that supports insertions but not\ndeletions. However, the design space of incremental filters is missing a \"sweet\nspot\" filter that combines space efficiency, fast queries, and fast insertions.\nIncremental filters, such as the Bloom and blocked Bloom filter, are not space\nefficient. Dynamic filters (i.e., supporting deletions), such as the cuckoo or\nvector quotient filter, are space efficient but do not exhibit consistently\nfast insertions and queries.\nIn this paper, we propose the prefix filter, an incremental filter that\naddresses the above challenge: (1) its space (in bits) is similar to\nstate-of-the-art dynamic filters; (2) query throughput is high and is\ncomparable to that of the cuckoo filter; and (3) insert throughput is high with\noverall build times faster than those of the vector quotient filter and cuckoo\nfilter by $1.39\\times$-$1.46\\times$ and $3.2\\times$-$3.5\\times$, respectively.\nWe present a rigorous analysis of the prefix filter that holds also for\npractical set sizes (i.e., $n=2^{25}$). The analysis deals with the probability\nof failure, false positive rate, and probability that an operation requires\naccessing more than a single cache line.",
    "descriptor": "",
    "authors": [
      "Tomer Even",
      "Guy Even",
      "Adam Morrison"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2203.17139"
  },
  {
    "id": "arXiv:2203.17144",
    "title": "Instability of backoff protocols with arbitrary arrival rates",
    "abstract": "In contention resolution, multiple processors are trying to coordinate to\nsend discrete messages through a shared channel with sharply limited\ncommunication. If two processors inadvertently send at the same time, the\nmessages collide and are not transmitted successfully. An important case is\nacknowledgement-based contention resolution, in which processors cannot listen\nto the channel at all; all they know is whether or not their own messages have\ngot through. This situation arises frequently in both networking and cloud\ncomputing. One particularly important example of an acknowledgement-based\ncontention resolution protocol is binary exponential backoff. Variants of\nbinary exponential backoff are used in both Ethernet and TCP/IP, and both\nGoogle Drive and AWS instruct their users to implement it to handle busy\nperiods.\nIn queueing models, where each processor has a queue of messages, stable\nacknowledgement-based protocols are already known (H{\\aa}stad et al., SICOMP\n1996). In queue-free models, where each processor has a single message but\nprocessors arrive randomly, it is widely conjectured that no stable\nacknowledgement-based protocols exist for any positive arrival rate of\nprocessors. Despite exciting recent results for full-sensing protocols which\nassume greater listening capabilities of the processors (see e.g. Bender et al.\nSTOC 2020 or Chen et al. PODC 2021), this foundational question remains open\neven for backoff protocols unless the arrival rate of processors is at least\n0.42 (Goldberg et al. SICOMP 2004). We prove the conjecture for all backoff\nprotocols outside of a tightly-constrained special case, and set out the\nremaining technical obstacles to a full proof.",
    "descriptor": "",
    "authors": [
      "Leslie Ann Goldberg",
      "John Lapinskas"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)",
      "Networking and Internet Architecture (cs.NI)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2203.17144"
  },
  {
    "id": "arXiv:2203.17146",
    "title": "Approximate Group Fairness for Clustering",
    "abstract": "We incorporate group fairness into the algorithmic centroid clustering\nproblem, where $k$ centers are to be located to serve $n$ agents distributed in\na metric space. We refine the notion of proportional fairness proposed in [Chen\net al., ICML 2019] as {\\em core fairness}, and $k$-clustering is in the core if\nno coalition containing at least $n/k$ agents can strictly decrease their total\ndistance by deviating to a new center together. Our solution concept is\nmotivated by the situation where agents are able to coordinate and utilities\nare transferable. A string of existence, hardness and approximability results\nis provided. Particularly, we propose two dimensions to relax core\nrequirements: one is on the degree of distance improvement, and the other is on\nthe size of deviating coalition. For both relaxations and their combination, we\nstudy the extent to which relaxed core fairness can be satisfied in metric\nspaces including line, tree and general metric space, and design approximation\nalgorithms accordingly.",
    "descriptor": "\nComments: Appears in ICML 2021\n",
    "authors": [
      "Bo Li",
      "Lijun Li",
      "Ankang Sun",
      "Chenhao Wang",
      "Yingfan Wang"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Theoretical Economics (econ.TH)"
    ],
    "url": "https://arxiv.org/abs/2203.17146"
  },
  {
    "id": "arXiv:2203.17149",
    "title": "AEGNN: Asynchronous Event-based Graph Neural Networks",
    "abstract": "The best performing learning algorithms devised for event cameras work by\nfirst converting events into dense representations that are then processed\nusing standard CNNs. However, these steps discard both the sparsity and high\ntemporal resolution of events, leading to high computational burden and\nlatency. For this reason, recent works have adopted Graph Neural Networks\n(GNNs), which process events as \"static\" spatio-temporal graphs, which are\ninherently \"sparse\". We take this trend one step further by introducing\nAsynchronous, Event-based Graph Neural Networks (AEGNNs), a novel\nevent-processing paradigm that generalizes standard GNNs to process events as\n\"evolving\" spatio-temporal graphs. AEGNNs follow efficient update rules that\nrestrict recomputation of network activations only to the nodes affected by\neach new event, thereby significantly reducing both computation and latency for\nevent-by-event processing. AEGNNs are easily trained on synchronous inputs and\ncan be converted to efficient, \"asynchronous\" networks at test time. We\nthoroughly validate our method on object classification and detection tasks,\nwhere we show an up to a 200-fold reduction in computational complexity\n(FLOPs), with similar or even better performance than state-of-the-art\nasynchronous methods. This reduction in computation directly translates to an\n8-fold reduction in computational latency when compared to standard GNNs, which\nopens the door to low-latency event-based processing.",
    "descriptor": "\nComments: IEEE Conference on Computer Vision and Pattern Recognition (CVPR), New Orleans, 2022\n",
    "authors": [
      "Simon Schaefer",
      "Daniel Gehrig",
      "Davide Scaramuzza"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.17149"
  },
  {
    "id": "arXiv:2203.17150",
    "title": "Online Learning for Traffic Routing under Unknown Preferences",
    "abstract": "In transportation networks, users typically choose routes in a decentralized\nand self-interested manner to minimize their individual travel costs, which, in\npractice, often results in inefficient overall outcomes for society. As a\nresult, there has been a growing interest in designing road tolling schemes to\ncope with these efficiency losses and steer users toward a system-efficient\ntraffic pattern. However, the efficacy of road tolling schemes often relies on\nhaving access to complete information on users' trip attributes, such as their\norigin-destination (O-D) travel information and their values of time, which may\nnot be available in practice.\nMotivated by this practical consideration, we propose an online learning\napproach to set tolls in a traffic network to drive heterogeneous users with\ndifferent values of time toward a system-efficient traffic pattern. In\nparticular, we develop a simple yet effective algorithm that adjusts tolls at\neach time period solely based on the observed aggregate flows on the roads of\nthe network without relying on any additional trip attributes of users, thereby\npreserving user privacy. In the setting where the O-D pairs and values of time\nof users are drawn i.i.d. at each period, we show that our approach obtains an\nexpected regret and road capacity violation of $O(\\sqrt{T})$, where $T$ is the\nnumber of periods over which tolls are updated. Our regret guarantee is\nrelative to an offline oracle that has complete information on users' trip\nattributes. We further establish a $\\Omega(\\sqrt{T})$ lower bound on the regret\nof any algorithm, which establishes that our algorithm is optimal up to\nconstants. Finally, we demonstrate the superior performance of our approach\nrelative to several benchmarks on a real-world transportation network, thereby\nhighlighting its practical applicability.",
    "descriptor": "",
    "authors": [
      "Devansh Jalota",
      "Karthik Gopalakrishnan",
      "Navid Azizan",
      "Ramesh Johari",
      "Marco Pavone"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Science and Game Theory (cs.GT)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2203.17150"
  },
  {
    "id": "arXiv:2203.17152",
    "title": "Perceptual Contrast Stretching on Target Feature for Speech Enhancement",
    "abstract": "Speech enhancement (SE) performance has improved considerably since the use\nof deep learning (DL) models as a base function. In this study, we propose a\nperceptual contrast stretching (PCS) approach to further improve SE\nperformance. PCS is derived based on the critical band importance function and\napplied to modify the targets of the SE model. Specifically, PCS stretches the\ncontract of target features according to perceptual importance, thereby\nimproving the overall SE performance. Compared to post-processing based\nimplementations, incorporating PCS into the training phase preserves\nperformance and reduces online computation. It is also worth noting that PCS\ncan be suitably combined with different SE model architectures and training\ncriteria. Meanwhile, PCS does not affect the causality or convergence of the SE\nmodel training. Experimental results on the VoiceBank-DEMAND dataset showed\nthat the proposed method can achieve state-of-the-art performance on both\ncausal (PESQ=3.07) and non-causal (PESQ=3.35) SE tasks.",
    "descriptor": "",
    "authors": [
      "Rong Chao",
      "Cheng Yu",
      "Szu-Wei Fu",
      "Xugang Lu",
      "Yu Tsao"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.17152"
  },
  {
    "id": "arXiv:2203.17155",
    "title": "Predicting extreme events from data using deep machine learning: when  and where",
    "abstract": "We develop a deep convolutional neural network (DCNN) based framework for\nmodel-free prediction of the occurrence of extreme events both in time (\"when\")\nand in space (\"where\") in nonlinear physical systems of spatial dimension two.\nThe measurements or data are a set of two-dimensional snapshots or images. For\na desired time horizon of prediction, a proper labeling scheme can be\ndesignated to enable successful training of the DCNN and subsequent prediction\nof extreme events in time. Given that an extreme event has been predicted to\noccur within the time horizon, a space-based labeling scheme can be applied to\npredict, within certain resolution, the location at which the event will occur.\nWe use synthetic data from the 2D complex Ginzburg-Landau equation and\nempirical wind speed data of the North Atlantic ocean to demonstrate and\nvalidate our machine-learning based prediction framework. The trade-offs among\nthe prediction horizon, spatial resolution, and accuracy are illustrated, and\nthe detrimental effect of spatially biased occurrence of extreme event on\nprediction accuracy is discussed. The deep learning framework is viable for\npredicting extreme events in the real world.",
    "descriptor": "\nComments: 15 pages, 10 figures\n",
    "authors": [
      "Junjie Jiang",
      "Zi-Gang Huang",
      "Celso Grebogi",
      "Ying-Cheng Lai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Dynamical Systems (math.DS)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ],
    "url": "https://arxiv.org/abs/2203.17155"
  },
  {
    "id": "arXiv:2203.17156",
    "title": "Adaptive Mean-Residue Loss for Robust Facial Age Estimation",
    "abstract": "Automated facial age estimation has diverse real-world applications in\nmultimedia analysis, e.g., video surveillance, and human-computer interaction.\nHowever, due to the randomness and ambiguity of the aging process, age\nassessment is challenging. Most research work over the topic regards the task\nas one of age regression, classification, and ranking problems, and cannot well\nleverage age distribution in representing labels with age ambiguity. In this\nwork, we propose a simple yet effective loss function for robust facial age\nestimation via distribution learning, i.e., adaptive mean-residue loss, in\nwhich, the mean loss penalizes the difference between the estimated age\ndistribution's mean and the ground-truth age, whereas the residue loss\npenalizes the entropy of age probability out of dynamic top-K in the\ndistribution. Experimental results in the datasets FG-NET and CLAP2016 have\nvalidated the effectiveness of the proposed loss. Our code is available at\nhttps://github.com/jacobzhaoziyuan/AMR-Loss.",
    "descriptor": "\nComments: Accepted by IEEE International Conference on Multimedia and Expo (ICME 2022)\n",
    "authors": [
      "Ziyuan Zhao",
      "Peisheng Qian",
      "Yubo Hou",
      "Zeng Zeng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2203.17156"
  },
  {
    "id": "arXiv:2203.17159",
    "title": "Preventing Over-Smoothing for Hypergraph Neural Networks",
    "abstract": "In recent years, hypergraph learning has attracted great attention due to its\ncapacity in representing complex and high-order relationships. However, current\nneural network approaches designed for hypergraphs are mostly shallow, thus\nlimiting their ability to extract information from high-order neighbors. In\nthis paper, we show both theoretically and empirically, that the performance of\nhypergraph neural networks does not improve as the number of layers increases,\nwhich is known as the over-smoothing problem. To tackle this issue, we develop\na new deep hypergraph convolutional network called Deep-HGCN, which can\nmaintain the heterogeneity of node representation in deep layers. Specifically,\nwe prove that a $k$-layer Deep-HGCN simulates a polynomial filter of order $k$\nwith arbitrary coefficients, which can relieve the problem of over-smoothing.\nExperimental results on various datasets demonstrate the superior performance\nof the proposed model comparing to the state-of-the-art hypergraph learning\napproaches.",
    "descriptor": "",
    "authors": [
      "Guanzi Chen",
      "Jiying Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.17159"
  },
  {
    "id": "arXiv:2203.17165",
    "title": "Policy Iteration for Multiplicative Noise Output Feedback Control",
    "abstract": "We propose a policy iteration algorithm for solving the multiplicative noise\nlinear quadratic output feedback design problem. The algorithm solves a set of\ncoupled Riccati equations for estimation and control arising from a partially\nobservable Markov decision process (POMDP) under a class of linear dynamic\ncontrol policies. We show in numerical experiments far faster convergence than\na value iteration algorithm, formerly the only known algorithm for solving this\nclass of problem. The results suggest promising future research directions for\npolicy optimization algorithms in more general POMDPs, including the potential\nto develop novel approximate data-driven approaches when model parameters are\nnot available.",
    "descriptor": "",
    "authors": [
      "Benjamin Gravell",
      "Matilde Gargiani",
      "John Lygeros",
      "Tyler H. Summers"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2203.17165"
  },
  {
    "id": "arXiv:2203.17166",
    "title": "On the Evaluation of NLP-based Models for Software Engineering",
    "abstract": "NLP-based models have been increasingly incorporated to address SE problems.\nThese models are either employed in the SE domain with little to no change, or\nthey are greatly tailored to source code and its unique characteristics. Many\nof these approaches are considered to be outperforming or complementing\nexisting solutions. However, an important question arises here: \"Are these\nmodels evaluated fairly and consistently in the SE community?\". To answer this\nquestion, we reviewed how NLP-based models for SE problems are being evaluated\nby researchers. The findings indicate that currently there is no consistent and\nwidely-accepted protocol for the evaluation of these models. While different\naspects of the same task are being assessed in different studies, metrics are\ndefined based on custom choices, rather than a system, and finally, answers are\ncollected and interpreted case by case. Consequently, there is a dire need to\nprovide a methodological way of evaluating NLP-based models to have a\nconsistent assessment and preserve the possibility of fair and efficient\ncomparison.",
    "descriptor": "\nComments: To appear in the Proceedings of the 1sth International Workshop on Natural Language-based Software Engineering (NLBSE), co-located with ICSE, 2022\n",
    "authors": [
      "Maliheh Izadi",
      "Matin Nili Ahmadabadi"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.17166"
  },
  {
    "id": "arXiv:2203.17167",
    "title": "The Legend of Zelda: The Complexity of Mechanics",
    "abstract": "We analyze some of the many game mechanics available to Link in the classic\nLegend of Zelda series of video games. In each case, we prove that the\ngeneralized game with that mechanic is polynomial, NP-complete, NP-hard and in\nPSPACE, or PSPACE-complete. In the process we give an overview of many of the\nhardness proof techniques developed for video games over the past decade: the\nmotion-planning-through-gadgets framework, the planar doors framework, the\ndoors-and-buttons framework, the \"Nintendo\" platform game / SAT framework, and\nthe collectible tokens and toll roads / Hamiltonicity framework.",
    "descriptor": "\nComments: Full version of the paper appearing at TJCDCGGG 2021. 27 pages, 14 figures\n",
    "authors": [
      "Jeffrey Bosboom",
      "Josh Brunner",
      "Michael Coulombe",
      "Erik D. Demaine",
      "Dylan H. Hendrickson",
      "Jayson Lynch",
      "Elle Najt"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2203.17167"
  },
  {
    "id": "arXiv:2203.17168",
    "title": "Lower bounds for uniform read-once threshold formulae in the randomized  decision tree model",
    "abstract": "We investigate the randomized decision tree complexity of a specific class of\nread-once threshold functions. A read-once threshold formula can be defined by\na rooted tree, every internal node of which is labeled by a threshold function\n$T_k^n$ (with output 1 only when at least $k$ out of $n$ input bits are 1) and\neach leaf by a distinct variable. Such a tree defines a Boolean function in a\nnatural way. We focus on the randomized decision tree complexity of such\nfunctions, when the underlying tree is a uniform tree with all its internal\nnodes labeled by the same threshold function. We prove lower bounds of the form\n$c(k,n)^d$, where $d$ is the depth of the tree. We also treat trees with\nalternating levels of AND and OR gates separately and show asymptotically\noptimal bounds, extending the known bounds for the binary case.",
    "descriptor": "",
    "authors": [
      "Nikos Leonardos"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2203.17168"
  },
  {
    "id": "arXiv:2203.17174",
    "title": "Krylov techniques for low-rank ADI",
    "abstract": "One of the most computationally expensive steps of the low-rank ADI method\nfor large-scale Lyapunov equations is the solution of a shifted linear system\nat each iteration. We propose the use of the extended Krylov subspace method\nfor this task. In particular, we illustrate how a single approximation space\ncan be constructed to solve all the shifted linear systems needed to achieve a\nprescribed accuracy in terms of Lyapunov residual norm. Moreover, we show how\nto fully merge the two iterative procedures in order to obtain a novel,\nefficient implementation of the low-rank ADI method, for an important class of\nequations. Many state-of-the-art algorithms for the shift computation can be\neasily incorporated into our new scheme, as well. Several numerical results\nillustrate the potential of our novel procedure when compared to an\nimplementation of the low-rank ADI method based on sparse direct solvers for\nthe shifted linear systems.",
    "descriptor": "",
    "authors": [
      "Peter Benner",
      "Davide Palitta",
      "Jens Saak"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2203.17174"
  },
  {
    "id": "arXiv:2203.17178",
    "title": "3D Equivariant Graph Implicit Functions",
    "abstract": "In recent years, neural implicit representations have made remarkable\nprogress in modeling of 3D shapes with arbitrary topology. In this work, we\naddress two key limitations of such representations, in failing to capture\nlocal 3D geometric fine details, and to learn from and generalize to shapes\nwith unseen 3D transformations. To this end, we introduce a novel family of\ngraph implicit functions with equivariant layers that facilitates modeling fine\nlocal details and guaranteed robustness to various groups of geometric\ntransformations, through local $k$-NN graph embeddings with sparse point set\nobservations at multiple resolutions. Our method improves over the existing\nrotation-equivariant implicit function from 0.69 to 0.89 (IoU) on the ShapeNet\nreconstruction task. We also show that our equivariant implicit function can be\nextended to other types of similarity transformations and generalizes to unseen\ntranslations and scaling.",
    "descriptor": "\nComments: Video: this https URL\n",
    "authors": [
      "Yunlu Chen",
      "Basura Fernando",
      "Hakan Bilen",
      "Matthias Nie\u00dfner",
      "Efstratios Gavves"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.17178"
  },
  {
    "id": "arXiv:2203.17179",
    "title": "4DL: a four-valued Dynamic logic and its proof-theory",
    "abstract": "Transition systems are often used to describe the behaviour of software\nsystems. If viewed as a graph then, at their most basic level, vertices\ncorrespond to the states of a program and each edge represents a transition\nbetween states via the (atomic) action labelled. In this setting, systems are\nthought to be consistent so that at each state formulas are evaluated as either\nTrue or False.\nOn the other hand, when a structure of this sort - for example a map where\nstates represent locations, some local properties are known and labelled\ntransitions represent information available about different routes - is built\nresorting to multiple sources of information, it is common to find inconsistent\nor incomplete information regarding what holds at each state, both at the level\nof propositional variables and transitions.\nThis paper aims at bringing together Belnap's four values, Dynamic Logic and\nhybrid machinery such as nominals and the satisfaction operator, so that\nreasoning is still possible in face of contradicting evidence. Proof-theory for\nthis new logic is explored by means of a terminating, sound and complete\ntableaux system.",
    "descriptor": "",
    "authors": [
      "Diana Costa"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2203.17179"
  },
  {
    "id": "arXiv:2203.17182",
    "title": "Current Challenges in Infinite-Domain Constraint Satisfaction: Dilemmas  of the Infinite Sheep",
    "abstract": "A Constraint Satisfaction Problem (CSP) is a computational problem where we\nare given variables and constraints about them; the question is whether the\nvariables can be assigned values such that all constraints are satisfied. We\ngive an overview of the current state of research on CSPs where values for the\nvariables and constraints are taken from a finitely bounded homogeneous\nstructure which is fixed beforehand. We explain the main mathematical ideas so\nfar, the three dilemmas they brought upon us, and what could be done to\novercome them in order to obtain a satisfactory understanding of the\ncomputational complexity of such CSPs.",
    "descriptor": "\nComments: 8 pages; invited paper for the IEEE 52nd International Symposium on Multiple-Valued Logic (ISMVL) 2022\n",
    "authors": [
      "Michael Pinsker"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Logic (math.LO)"
    ],
    "url": "https://arxiv.org/abs/2203.17182"
  },
  {
    "id": "arXiv:2203.17184",
    "title": "Stein-based preconditioners for weak-constraint 4D-var",
    "abstract": "Algorithms for data assimilation try to predict the most likely state of a\ndynamical system by combining information from observations and prior models.\nOne of the most successful data assimilation frameworks is the linearized\nweak-constraint four-dimensional variational assimilation problem (4D-Var),\nthat can be ultimately interpreted as a minimization problem. One of the main\nchallenges of such an approach is the solution of large saddle point linear\nsystems arising as an inner linear step within the adopted non-linear solver.\nThe linear algebraic problem can be solved by means of a Krylov method, like\nMINRES or GMRES, that needs to be preconditioned to ensure fast convergence in\nterms of the number of iterations. In this paper we illustrate novel, efficient\npreconditioning operators which involve the solution of certain Stein matrix\nequations. In addition to achieving better computational performance, the\nlatter machinery allows us to derive tighter bounds for the eigenvalue\ndistribution of the preconditioned saddle point linear system. A panel of\ndiverse numerical results displays the effectiveness of the proposed\nmethodology compared to current state-of-the-art approaches.",
    "descriptor": "",
    "authors": [
      "Davide Palitta",
      "Jemima M. Tabeart"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2203.17184"
  },
  {
    "id": "arXiv:2203.17189",
    "title": "Scaling Up Models and Data with $\\texttt{t5x}$ and $\\texttt{seqio}$",
    "abstract": "Recent neural network-based language models have benefited greatly from\nscaling up the size of training datasets and the number of parameters in the\nmodels themselves. Scaling can be complicated due to various factors including\nthe need to distribute computation on supercomputer clusters (e.g., TPUs),\nprevent bottlenecks when infeeding data, and ensure reproducible results. In\nthis work, we present two software libraries that ease these issues:\n$\\texttt{t5x}$ simplifies the process of building and training large language\nmodels at scale while maintaining ease of use, and $\\texttt{seqio}$ provides a\ntask-based API for simple creation of fast and reproducible training data and\nevaluation pipelines. These open-source libraries have been used to train\nmodels with hundreds of billions of parameters on datasets with multiple\nterabytes of training data.\nAlong with the libraries, we release configurations and instructions for\nT5-like encoder-decoder models as well as GPT-like decoder-only architectures.\n$\\texttt{t5x}$ and $\\texttt{seqio}$ are open source and available at\nhttps://github.com/google-research/t5x and https://github.com/google/seqio,\nrespectively.",
    "descriptor": "",
    "authors": [
      "Adam Roberts",
      "Hyung Won Chung",
      "Anselm Levskaya",
      "Gaurav Mishra",
      "James Bradbury",
      "Daniel Andor",
      "Sharan Narang",
      "Brian Lester",
      "Colin Gaffney",
      "Afroz Mohiuddin",
      "Curtis Hawthorne",
      "Aitor Lewkowycz",
      "Alex Salcianu",
      "Marc van Zee",
      "Jacob Austin",
      "Sebastian Goodman",
      "Livio Baldini Soares",
      "Haitang Hu",
      "Sasha Tsvyashchenko",
      "Aakanksha Chowdhery",
      "Jasmijn Bastings",
      "Jannis Bulian",
      "Xavier Garcia",
      "Jianmo Ni",
      "Andrew Chen",
      "Kathleen Kenealy",
      "Jonathan H. Clark",
      "Stephan Lee",
      "Dan Garrette",
      "James Lee-Thorp",
      "Colin Raffel",
      "Noam Shazeer",
      "Marvin Ritter",
      "Maarten Bosma",
      "Alexandre Passos",
      "Jeremy Maitin-Shepard",
      "Noah Fiedel",
      "Mark Omernick",
      "Brennan Saeta",
      "Ryan Sepassi",
      "Alexander Spiridonov",
      "Joshua Newlan",
      "Andrea Gesmundo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.17189"
  },
  {
    "id": "arXiv:2203.17191",
    "title": "Time Lens++: Event-based Frame Interpolation with Parametric Non-linear  Flow and Multi-scale Fusion",
    "abstract": "Recently, video frame interpolation using a combination of frame- and\nevent-based cameras has surpassed traditional image-based methods both in terms\nof performance and memory efficiency. However, current methods still suffer\nfrom (i) brittle image-level fusion of complementary interpolation results,\nthat fails in the presence of artifacts in the fused image, (ii) potentially\ntemporally inconsistent and inefficient motion estimation procedures, that run\nfor every inserted frame and (iii) low contrast regions that do not trigger\nevents, and thus cause events-only motion estimation to generate artifacts.\nMoreover, previous methods were only tested on datasets consisting of planar\nand faraway scenes, which do not capture the full complexity of the real world.\nIn this work, we address the above problems by introducing multi-scale\nfeature-level fusion and computing one-shot non-linear inter-frame motion from\nevents and images, which can be efficiently sampled for image warping. We also\ncollect the first large-scale events and frames dataset consisting of more than\n100 challenging scenes with depth variations, captured with a new experimental\nsetup based on a beamsplitter. We show that our method improves the\nreconstruction quality by up to 0.2 dB in terms of PSNR and up to 15% in LPIPS\nscore.",
    "descriptor": "\nComments: IEEE Conference on Computer Vision and Pattern Recognition (CVPR), New Orleans, 2022\n",
    "authors": [
      "Stepan Tulyakov",
      "Alfredo Bochicchio",
      "Daniel Gehrig",
      "Stamatios Georgoulis",
      "Yuanyou Li",
      "Davide Scaramuzza"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.17191"
  },
  {
    "id": "arXiv:2203.17193",
    "title": "Learning from many trajectories",
    "abstract": "We initiate a study of supervised learning from many independent sequences\n(\"trajectories\") of non-independent covariates, reflecting tasks in sequence\nmodeling, control, and reinforcement learning. Conceptually, our\nmulti-trajectory setup sits between two traditional settings in statistical\nlearning theory: learning from independent examples and learning from a single\nauto-correlated sequence. Our conditions for efficient learning generalize the\nformer setting--trajectories must be non-degenerate in ways that extend\nstandard requirements for independent examples. They do not require that\ntrajectories be ergodic, long, nor strictly stable.\nFor linear least-squares regression, given $n$-dimensional examples produced\nby $m$ trajectories, each of length $T$, we observe a notable change in\nstatistical efficiency as the number of trajectories increases from a few\n(namely $m \\lesssim n$) to many (namely $m \\gtrsim n$). Specifically, we\nestablish that the worst-case error rate this problem is $\\Theta(n / m T)$\nwhenever $m \\gtrsim n$. Meanwhile, when $m \\lesssim n$, we establish a (sharp)\nlower bound of $\\Omega(n^2 / m^2 T)$ on the worst-case error rate, realized by\na simple, marginally unstable linear dynamical system. A key upshot is that, in\ndomains where trajectories regularly reset, the error rate eventually behaves\nas if all of the examples were independent altogether, drawn from their\nmarginals. As a corollary of our analysis, we also improve guarantees for the\nlinear system identification problem.",
    "descriptor": "",
    "authors": [
      "Stephen Tu",
      "Roy Frostig",
      "Mahdi Soltanolkotabi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.17193"
  },
  {
    "id": "arXiv:2203.17194",
    "title": "Free Resolutions and Generalized Hamming Weights of binary linear codes",
    "abstract": "In this work, we explore the relationship between free resolution of some\nmonomial ideals and Generalized Hamming Weights (GHWs) of binary codes. More\nprecisely, we look for a structure smaller than the set of codewords of minimal\nsupport that provides us some information about the GHWs. We prove that the\nfirst and second generalized Hamming weight of a binary linear code can be\ncomputed (by means of a graded free resolution) from a set of monomials\nassociated to a binomial ideal related with the code. Moreover, the remaining\nweights are bounded by the Betti numbers for that set.",
    "descriptor": "",
    "authors": [
      "Ignacio Garc\u00eda-Marco",
      "Irene M\u00e1rquez-Corbella",
      "Edgar Mart\u00ednez-Moro",
      "Yuriko Pitones"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Commutative Algebra (math.AC)"
    ],
    "url": "https://arxiv.org/abs/2203.17194"
  },
  {
    "id": "arXiv:2203.17196",
    "title": "CatIss: An Intelligent Tool for Categorizing Issues Reports using  Transformers",
    "abstract": "Users use Issue Tracking Systems to keep track and manage issue reports in\ntheir repositories. An issue is a rich source of software information that\ncontains different reports including a problem, a request for new features, or\nmerely a question about the software product. As the number of these issues\nincreases, it becomes harder to manage them manually. Thus, automatic\napproaches are proposed to help facilitate the management of issue reports.\nThis paper describes CatIss, an automatic CATegorizer of ISSue reports which\nis built upon the Transformer-based pre-trained RoBERTa model. CatIss\nclassifies issue reports into three main categories of Bug reports,\nEnhancement/feature requests, and Questions. First, the datasets provided for\nthe NLBSE tool competition are cleaned and preprocessed. Then, the pre-trained\nRoBERTa model is fine-tuned on the preprocessed dataset. Evaluating CatIss on\nabout 80 thousand issue reports from GitHub, indicates that it performs very\nwell surpassing the competition baseline, TicketTagger, and achieving 87.2%\nF1-score (micro average). Additionally, as CatIss is trained on a wide set of\nrepositories, it is a generic prediction model, hence applicable for any unseen\nsoftware project or projects with little historical data. Scripts for cleaning\nthe datasets, training CatIss, and evaluating the model are publicly available.",
    "descriptor": "\nComments: To appear in the Proceedings of the 1sth International Workshop on Natural Language-based Software Engineering (NLBSE), co-located with ICSE, 2022\n",
    "authors": [
      "Maliheh Izadi"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.17196"
  },
  {
    "id": "arXiv:2203.17200",
    "title": "Restoring Vision through Retinal Implants - A Systematic Literature  Review",
    "abstract": "This work presents a bunched of the promising technologies to treat blind\npeople: the bionic eyes. The strategy is to combine a retina implant with\nsoftware capable to interpret the information received. Along this line of\nthinking, projects as Retinal Prosthetic Strategy with the Capacity to Restore\nNormal Vision from Weill Medical College of Cornell University Project, Update\non Retinal Prosthetic Research from The Boston Retinal Implant Project and\nRestoration of Vision Using Wireless Cortical Implants from Monash Vision Group\nProject, have shown in different context the use of technologies that commits\nto bring the vision through its use.",
    "descriptor": "\nComments: 15 pages, 5 figures, 3 tables\n",
    "authors": [
      "Magali Andreia Rossi",
      "Sylviane da Silva Vitor"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Image and Video Processing (eess.IV)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2203.17200"
  },
  {
    "id": "arXiv:2203.17205",
    "title": "Leverage Your Local and Global Representations: A New Self-Supervised  Learning Strategy",
    "abstract": "Self-supervised learning (SSL) methods aim to learn view-invariant\nrepresentations by maximizing the similarity between the features extracted\nfrom different crops of the same image regardless of cropping size and content.\nIn essence, this strategy ignores the fact that two crops may truly contain\ndifferent image information, e.g., background and small objects, and thus tends\nto restrain the diversity of the learned representations. %To this end, the\nexisting strategies typically employ loss functions that enforces the networks\nto discard part of valuable information, e.g. background and small objects, and\nsacrifices the diversity of representation. In this work, we address this issue\nby introducing a new self-supervised learning strategy, LoGo, that explicitly\nreasons about {\\bf Lo}cal and {\\bf G}l{\\bf o}bal crops. To achieve view\ninvariance, LoGo encourages similarity between global crops from the same\nimage, as well as between a global and a local crop. However, to correctly\nencode the fact that the content of smaller crops may differ entirely, LoGo\npromotes two local crops to have dissimilar representations, while being close\nto global crops. Our LoGo strategy can easily be applied to existing SSL\nmethods. Our extensive experiments on a variety of datasets and using different\nself-supervised learning frameworks validate its superiority over existing\napproaches. Noticeably, we achieve better results than supervised models on\ntransfer learning when using only $1/10$ of the data.",
    "descriptor": "\nComments: CVPR 2022\n",
    "authors": [
      "Tong Zhang",
      "Congpei Qiu",
      "Wei Ke",
      "Sabine S\u00fcsstrunk",
      "Mathieu Salzmann"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.17205"
  },
  {
    "id": "arXiv:2203.17209",
    "title": "Adversarial Examples in Random Neural Networks with General Activations",
    "abstract": "A substantial body of empirical work documents the lack of robustness in deep\nlearning models to adversarial examples. Recent theoretical work proved that\nadversarial examples are ubiquitous in two-layers networks with sub-exponential\nwidth and ReLU or smooth activations, and multi-layer ReLU networks with\nsub-exponential width. We present a result of the same type, with no\nrestriction on width and for general locally Lipschitz continuous activations.\nMore precisely, given a neural network $f(\\,\\cdot\\,;{\\boldsymbol \\theta})$\nwith random weights ${\\boldsymbol \\theta}$, and feature vector ${\\boldsymbol\nx}$, we show that an adversarial example ${\\boldsymbol x}'$ can be found with\nhigh probability along the direction of the gradient $\\nabla_{{\\boldsymbol\nx}}f({\\boldsymbol x};{\\boldsymbol \\theta})$. Our proof is based on a Gaussian\nconditioning technique. Instead of proving that $f$ is approximately linear in\na neighborhood of ${\\boldsymbol x}$, we characterize the joint distribution of\n$f({\\boldsymbol x};{\\boldsymbol \\theta})$ and $f({\\boldsymbol x}';{\\boldsymbol\n\\theta})$ for ${\\boldsymbol x}' = {\\boldsymbol x}-s({\\boldsymbol\nx})\\nabla_{{\\boldsymbol x}}f({\\boldsymbol x};{\\boldsymbol \\theta})$.",
    "descriptor": "\nComments: 28 pages\n",
    "authors": [
      "Andrea Montanari",
      "Yuchen Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2203.17209"
  },
  {
    "id": "arXiv:2203.17211",
    "title": "ShapeFindAR: Exploring In-Situ Spatial Search for Physical Artifact  Retrieval using Mixed Reality",
    "abstract": "Personal fabrication is made more accessible through repositories like\nThingiverse, as they replace modeling with retrieval. However, they require\nusers to translate spatial requirements to keywords, which paints an incomplete\npicture of physical artifacts: proportions or morphology are non-trivially\nencoded through text only. We explore a vision of in-situ spatial search for\n(future) physical artifacts, and present ShapeFindAR, a mixed-reality tool to\nsearch for 3D models using in-situ sketches blended with textual queries. With\nShapeFindAR, users search for geometry, and not necessarily precise labels,\nwhile coupling the search process to the physical environment (e.g., by\nsketching in-situ, extracting search terms from objects present, or tracing\nthem). We developed ShapeFindAR for HoloLens 2, connected to a database of\n3D-printable artifacts. We specify in-situ spatial search, describe its\nadvantages, and present walkthroughs using ShapeFindAR, which highlight novel\nways for users to articulate their wishes, without requiring complex modeling\ntools or profound domain knowledge.",
    "descriptor": "\nComments: 10 pages, 10 figures. Preprint of a conditionally accepted paper to appear in the Proceedings of the CHI Conference on Human Factors in Computing Systems (CHI '22), April 29-May 5, 2022, New Orleans, LA, USA. ACM\n",
    "authors": [
      "Evgeny Stemasov",
      "Tobias Wagner",
      "Jan Gugenheimer",
      "Enrico Rukzio"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2203.17211"
  },
  {
    "id": "arXiv:2203.17213",
    "title": "Analyzing Wrap-Up Effects through an Information-Theoretic Lens",
    "abstract": "Numerous analyses of reading time (RT) data have been implemented -- all in\nan effort to better understand the cognitive processes driving reading\ncomprehension. However, data measured on words at the end of a sentence -- or\neven at the end of a clause -- is often omitted due to the confounding factors\nintroduced by so-called \"wrap-up effects,\" which manifests as a skewed\ndistribution of RTs for these words. Consequently, the understanding of the\ncognitive processes that might be involved in these wrap-up effects is limited.\nIn this work, we attempt to learn more about these processes by examining the\nrelationship between wrap-up effects and information-theoretic quantities, such\nas word and context surprisals. We find that the distribution of information in\nprior contexts is often predictive of sentence- and clause-final RTs (while not\nof sentence-medial RTs). This lends support to several prior hypotheses about\nthe processes involved in wrap-up effects.",
    "descriptor": "\nComments: ACL 2022 (main conference)\n",
    "authors": [
      "Clara Meister",
      "Tiago Pimentel",
      "Thomas Hikaru Clark",
      "Ryan Cotterell",
      "Roger Levy"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.17213"
  },
  {
    "id": "arXiv:2203.17217",
    "title": "On the probability-quality paradox in language generation",
    "abstract": "When generating natural language from neural probabilistic models, high\nprobability does not always coincide with high quality: It has often been\nobserved that mode-seeking decoding methods, i.e., those that produce\nhigh-probability text under the model, lead to unnatural language. On the other\nhand, the lower-probability text generated by stochastic methods is perceived\nas more human-like. In this note, we offer an explanation for this phenomenon\nby analyzing language generation through an information-theoretic lens.\nSpecifically, we posit that human-like language should contain an amount of\ninformation (quantified as negative log-probability) that is close to the\nentropy of the distribution over natural strings. Further, we posit that\nlanguage with substantially more (or less) information is undesirable. We\nprovide preliminary empirical evidence in favor of this hypothesis; quality\nratings of both human and machine-generated text -- covering multiple tasks and\ncommon decoding strategies -- suggest high-quality text has an information\ncontent significantly closer to the entropy than we would expect by chance.",
    "descriptor": "\nComments: ACL 2022 (main conference)\n",
    "authors": [
      "Clara Meister",
      "Gian Wiher",
      "Tiago Pimentel",
      "Ryan Cotterell"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.17217"
  },
  {
    "id": "arXiv:2203.17219",
    "title": "SimVQA: Exploring Simulated Environments for Visual Question Answering",
    "abstract": "Existing work on VQA explores data augmentation to achieve better\ngeneralization by perturbing the images in the dataset or modifying the\nexisting questions and answers. While these methods exhibit good performance,\nthe diversity of the questions and answers are constrained by the available\nimage set. In this work we explore using synthetic computer-generated data to\nfully control the visual and language space, allowing us to provide more\ndiverse scenarios. We quantify the effect of synthetic data in real-world VQA\nbenchmarks and to which extent it produces results that generalize to real\ndata. By exploiting 3D and physics simulation platforms, we provide a pipeline\nto generate synthetic data to expand and replace type-specific questions and\nanswers without risking the exposure of sensitive or personal data that might\nbe present in real images. We offer a comprehensive analysis while expanding\nexisting hyper-realistic datasets to be used for VQA. We also propose Feature\nSwapping (F-SWAP) -- where we randomly switch object-level features during\ntraining to make a VQA model more domain invariant. We show that F-SWAP is\neffective for enhancing a currently existing VQA dataset of real images without\ncompromising on the accuracy to answer existing questions in the dataset.",
    "descriptor": "\nComments: Accepted to CVPR 2022. Camera-Ready version. Project page: this https URL\n",
    "authors": [
      "Paola Cascante-Bonilla",
      "Hui Wu",
      "Letao Wang",
      "Rogerio Feris",
      "Vicente Ordonez"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.17219"
  },
  {
    "id": "arXiv:2203.17225",
    "title": "A Baseline Readability Model for Cebuano",
    "abstract": "In this study, we developed the first baseline readability model for the\nCebuano language. Cebuano is the second most-used native language in the\nPhilippines with about 27.5 million speakers. As the baseline, we extracted\ntraditional or surface-based features, syllable patterns based from Cebuano's\ndocumented orthography, and neural embeddings from the multilingual BERT model.\nResults show that the use of the first two handcrafted linguistic features\nobtained the best performance trained on an optimized Random Forest model with\napproximately 84\\% across all metrics. The feature sets and algorithm used also\nis similar to previous results in readability assessment for the Filipino\nlanguage showing potential of crosslingual application. To encourage more work\nfor readability assessment in Philippine languages such as Cebuano, we\nopen-sourced both code and data.",
    "descriptor": "",
    "authors": [
      "Lloyd Lois Antonie Reyes",
      "Michael Antonio Iba\u00f1ez",
      "Ranz Sapinit",
      "Mohammed Hussien",
      "Joseph Marvin Imperial"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.17225"
  },
  {
    "id": "arXiv:2203.17232",
    "title": "Performative Power",
    "abstract": "We introduce the notion of performative power, which measures the ability of\na firm operating an algorithmic system, such as a digital content\nrecommendation platform, to steer a population. We relate performative power to\nthe economic theory of market power. Traditional economic concepts are well\nknown to struggle with identifying anti-competitive patterns in digital\nplatforms--a core challenge is the difficulty of defining the market, its\nparticipants, products, and prices. Performative power sidesteps the problem of\nmarket definition by focusing on a directly observable statistical measure\ninstead. High performative power enables a platform to profit from steering\nparticipant behavior, whereas low performative power ensures that learning from\nhistorical data is close to optimal.\nOur first general result shows that under low performative power, a firm\ncannot do better than standard supervised learning on observed data. We draw an\nanalogy with a firm being a price-taker, an economic condition that arises\nunder perfect competition in classical market models. We then contrast this\nwith a market where performative power is concentrated and show that the\nequilibrium state can differ significantly. We go on to study performative\npower in a concrete setting of strategic classification where participants can\nswitch between competing firms. We show that monopolies maximize performative\npower and disutility for the participant, while competition and outside options\ndecrease performative power. We end on a discussion of connections to measures\nof market power in economics and of the relationship with ongoing antitrust\ndebates.",
    "descriptor": "",
    "authors": [
      "Moritz Hardt",
      "Meena Jagadeesan",
      "Celestine Mendler-D\u00fcnner"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)",
      "Computer Science and Game Theory (cs.GT)",
      "Theoretical Economics (econ.TH)"
    ],
    "url": "https://arxiv.org/abs/2203.17232"
  },
  {
    "id": "arXiv:2203.17234",
    "title": "Templates for 3D Object Pose Estimation Revisited: Generalization to New  Objects and Robustness to Occlusions",
    "abstract": "We present a method that can recognize new objects and estimate their 3D pose\nin RGB images even under partial occlusions. Our method requires neither a\ntraining phase on these objects nor real images depicting them, only their CAD\nmodels. It relies on a small set of training objects to learn local object\nrepresentations, which allow us to locally match the input image to a set of\n\"templates\", rendered images of the CAD models for the new objects. In contrast\nwith the state-of-the-art methods, the new objects on which our method is\napplied can be very different from the training objects. As a result, we are\nthe first to show generalization without retraining on the LINEMOD and\nOcclusion-LINEMOD datasets. Our analysis of the failure modes of previous\ntemplate-based approaches further confirms the benefits of local features for\ntemplate matching. We outperform the state-of-the-art template matching methods\non the LINEMOD, Occlusion-LINEMOD and T-LESS datasets. Our source code and data\nare publicly available at https://github.com/nv-nguyen/template-pose",
    "descriptor": "\nComments: CVPR 2022\n",
    "authors": [
      "Van Nguyen Nguyen",
      "Yinlin Hu",
      "Yang Xiao",
      "Mathieu Salzmann",
      "Vincent Lepetit"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.17234"
  },
  {
    "id": "arXiv:2203.17239",
    "title": "Cite-seeing and Reviewing: A Study on Citation Bias in Peer Review",
    "abstract": "Citations play an important role in researchers' careers as a key factor in\nevaluation of scientific impact. Many anecdotes advice authors to exploit this\nfact and cite prospective reviewers to try obtaining a more positive evaluation\nfor their submission. In this work, we investigate if such a citation bias\nactually exists: Does the citation of a reviewer's own work in a submission\ncause them to be positively biased towards the submission? In conjunction with\nthe review process of two flagship conferences in machine learning and\nalgorithmic economics, we execute an observational study to test for citation\nbias in peer review. In our analysis, we carefully account for various\nconfounding factors such as paper quality and reviewer expertise, and apply\ndifferent modeling techniques to alleviate concerns regarding the model\nmismatch. Overall, our analysis involves 1,314 papers and 1,717 reviewers and\ndetects citation bias in both venues we consider. In terms of the effect size,\nby citing a reviewer's work, a submission has a non-trivial chance of getting a\nhigher score from the reviewer: an expected increase in the score is\napproximately 0.23 on a 5-point Likert item. For reference, a one-point\nincrease of a score by a single reviewer improves the position of a submission\nby 11% on average.",
    "descriptor": "\nComments: 19 pages, 3 figures\n",
    "authors": [
      "Ivan Stelmakh",
      "Charvi Rastogi",
      "Ryan Liu",
      "Shuchi Chawla",
      "Federico Echenique",
      "Nihar B. Shah"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2203.17239"
  },
  {
    "id": "arXiv:2203.17240",
    "title": "ImpDet: Exploring Implicit Fields for 3D Object Detection",
    "abstract": "Conventional 3D object detection approaches concentrate on bounding boxes\nrepresentation learning with several parameters, i.e., localization, dimension,\nand orientation. Despite its popularity and universality, such a\nstraightforward paradigm is sensitive to slight numerical deviations,\nespecially in localization. By exploiting the property that point clouds are\nnaturally captured on the surface of objects along with accurate location and\nintensity information, we introduce a new perspective that views bounding box\nregression as an implicit function. This leads to our proposed framework,\ntermed Implicit Detection or ImpDet, which leverages implicit field learning\nfor 3D object detection. Our ImpDet assigns specific values to points in\ndifferent local 3D spaces, thereby high-quality boundaries can be generated by\nclassifying points inside or outside the boundary. To solve the problem of\nsparsity on the object surface, we further present a simple yet efficient\nvirtual sampling strategy to not only fill the empty region, but also learn\nrich semantic features to help refine the boundaries. Extensive experimental\nresults on KITTI and Waymo benchmarks demonstrate the effectiveness and\nrobustness of unifying implicit fields into object detection.",
    "descriptor": "\nComments: 11 pages, 4 figures\n",
    "authors": [
      "Xuelin Qian",
      "Li Wang",
      "Yi Zhu",
      "Li Zhang",
      "Yanwei Fu",
      "Xiangyang Xue"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.17240"
  },
  {
    "id": "arXiv:2203.17242",
    "title": "Automatic Detection of Expressed Emotion from Five-Minute Speech  Samples: Challenges and Opportunities",
    "abstract": "We present a novel feasibility study on the automatic recognition of\nExpressed Emotion (EE), a family environment concept based on caregivers\nspeaking freely about their relative/family member. We describe an automated\napproach for determining the \\textit{degree of warmth}, a key component of EE,\nfrom acoustic and text features acquired from a sample of 37 recorded\ninterviews. These recordings, collected over 20 years ago, are derived from a\nnationally representative birth cohort of 2,232 British twin children and were\nmanually coded for EE. We outline the core steps of extracting usable\ninformation from recordings with highly variable audio quality and assess the\nefficacy of four machine learning approaches trained with different\ncombinations of acoustic and text features. Despite the challenges of working\nwith this legacy data, we demonstrated that the degree of warmth can be\npredicted with an $F_{1}$-score of \\textbf{61.5\\%}. In this paper, we summarise\nour learning and provide recommendations for future work using real-world\nspeech samples.",
    "descriptor": "\nComments: Submitted to Interspeech 2022\n",
    "authors": [
      "Bahman Mirheidari",
      "Andr\u00e9 Bittar",
      "Nicholas Cummins",
      "Johnny Downs",
      "Helen L. Fisher",
      "Heidi Christensen"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.17242"
  },
  {
    "id": "arXiv:2203.17247",
    "title": "VL-InterpreT: An Interactive Visualization Tool for Interpreting  Vision-Language Transformers",
    "abstract": "Breakthroughs in transformer-based models have revolutionized not only the\nNLP field, but also vision and multimodal systems. However, although\nvisualization and interpretability tools have become available for NLP models,\ninternal mechanisms of vision and multimodal transformers remain largely\nopaque. With the success of these transformers, it is increasingly critical to\nunderstand their inner workings, as unraveling these black-boxes will lead to\nmore capable and trustworthy models. To contribute to this quest, we propose\nVL-InterpreT, which provides novel interactive visualizations for interpreting\nthe attentions and hidden representations in multimodal transformers.\nVL-InterpreT is a task agnostic and integrated tool that (1) tracks a variety\nof statistics in attention heads throughout all layers for both vision and\nlanguage components, (2) visualizes cross-modal and intra-modal attentions\nthrough easily readable heatmaps, and (3) plots the hidden representations of\nvision and language tokens as they pass through the transformer layers. In this\npaper, we demonstrate the functionalities of VL-InterpreT through the analysis\nof KD-VLP, an end-to-end pretraining vision-language multimodal\ntransformer-based model, in the tasks of Visual Commonsense Reasoning (VCR) and\nWebQA, two visual question answering benchmarks. Furthermore, we also present a\nfew interesting findings about multimodal transformer behaviors that were\nlearned through our tool.",
    "descriptor": "\nComments: CVPR 2022 demo track\n",
    "authors": [
      "Estelle Aflalo",
      "Meng Du",
      "Shao-Yen Tseng",
      "Yongfei Liu",
      "Chenfei Wu",
      "Nan Duan",
      "Vasudev Lal"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.17247"
  },
  {
    "id": "arXiv:2203.17248",
    "title": "Dual Temperature Helps Contrastive Learning Without Many Negative  Samples: Towards Understanding and Simplifying MoCo",
    "abstract": "Contrastive learning (CL) is widely known to require many negative samples,\n65536 in MoCo for instance, for which the performance of a dictionary-free\nframework is often inferior because the negative sample size (NSS) is limited\nby its mini-batch size (MBS). To decouple the NSS from the MBS, a dynamic\ndictionary has been adopted in a large volume of CL frameworks, among which\narguably the most popular one is MoCo family. In essence, MoCo adopts a\nmomentum-based queue dictionary, for which we perform a fine-grained analysis\nof its size and consistency. We point out that InfoNCE loss used in MoCo\nimplicitly attract anchors to their corresponding positive sample with various\nstrength of penalties and identify such inter-anchor hardness-awareness\nproperty as a major reason for the necessity of a large dictionary. Our\nfindings motivate us to simplify MoCo v2 via the removal of its dictionary as\nwell as momentum. Based on an InfoNCE with the proposed dual temperature, our\nsimplified frameworks, SimMoCo and SimCo, outperform MoCo v2 by a visible\nmargin. Moreover, our work bridges the gap between CL and non-CL frameworks,\ncontributing to a more unified understanding of these two mainstream frameworks\nin SSL. Code is available at: https://bit.ly/3LkQbaT.",
    "descriptor": "\nComments: Accepted by CVPR2022\n",
    "authors": [
      "Chaoning Zhang",
      "Kang Zhang",
      "Trung X. Pham",
      "Axi Niu",
      "Zhinan Qiao",
      "Chang D. Yoo",
      "In So Kweon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.17248"
  },
  {
    "id": "arXiv:2203.17250",
    "title": "Generation and Simulation of Synthetic Datasets with Copulas",
    "abstract": "This paper proposes a new method to generate synthetic data sets based on\ncopula models. Our goal is to produce surrogate data resembling real data in\nterms of marginal and joint distributions. We present a complete and reliable\nalgorithm for generating a synthetic data set comprising numeric or categorical\nvariables. Applying our methodology to two datasets shows better performance\ncompared to other methods such as SMOTE and autoencoders.",
    "descriptor": "",
    "authors": [
      "Regis Houssou",
      "Mihai-Cezar Augustin",
      "Efstratios Rappos",
      "Vivien Bonvin",
      "Stephan Robert-Nicoud"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.17250"
  },
  {
    "id": "arXiv:2203.17251",
    "title": "Continuous Scene Representations for Embodied AI",
    "abstract": "We propose Continuous Scene Representations (CSR), a scene representation\nconstructed by an embodied agent navigating within a space, where objects and\ntheir relationships are modeled by continuous valued embeddings. Our method\ncaptures feature relationships between objects, composes them into a graph\nstructure on-the-fly, and situates an embodied agent within the representation.\nOur key insight is to embed pair-wise relationships between objects in a latent\nspace. This allows for a richer representation compared to discrete relations\n(e.g., [support], [next-to]) commonly used for building scene representations.\nCSR can track objects as the agent moves in a scene, update the representation\naccordingly, and detect changes in room configurations. Using CSR, we\noutperform state-of-the-art approaches for the challenging downstream task of\nvisual room rearrangement, without any task specific training. Moreover, we\nshow the learned embeddings capture salient spatial details of the scene and\nshow applicability to real world data. A summery video and code is available at\nhttps://prior.allenai.org/projects/csr.",
    "descriptor": "\nComments: CVPR 2022\n",
    "authors": [
      "Samir Yitzhak Gadre",
      "Kiana Ehsani",
      "Shuran Song",
      "Roozbeh Mottaghi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.17251"
  },
  {
    "id": "arXiv:2203.17253",
    "title": "PLCverif: Status of a Formal Verification Tool for Programmable Logic  Controller",
    "abstract": "Programmable Logic Controllers (PLC) are widely used for industrial\nautomation including safety systems at CERN. The incorrect behaviour of the PLC\ncontrol system logic can cause significant financial losses by damage of\nproperty or the environment or even injuries in some cases, therefore ensuring\ntheir correct behaviour is essential. While testing has been for many years the\ntraditional way of validating the PLC control system logic, CERN developed a\nmodel checking platform to go one step further and formally verify PLC logic.\nThis platform, called PLCverif, first released internally for CERN usage in\n2019, is now available to anyone since September 2020 via an open source\nlicence. In this paper, we will first give an overview of the PLCverif platform\ncapabilities before focusing on the improvements done since 2019 such as the\nlarger support coverage of the Siemens PLC programming languages, the better\nsupport of the C Bounded Model Checker backend (CBMC) and the process of\nreleasing PLCverif as an open-source software.",
    "descriptor": "\nComments: 18th International Conference on Accelerator and Large Experimental Physics Control Systems (ICALEPCS2021)\n",
    "authors": [
      "Ignacio D. Lopez-Miguel",
      "Jean-Charles Tournier",
      "Borja Fernandez Adiego"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2203.17253"
  },
  {
    "id": "arXiv:2203.17256",
    "title": "LEAD1.0: A Large-scale Annotated Dataset for Energy Anomaly Detection in  Commercial Buildings",
    "abstract": "Modern buildings are densely equipped with smart energy meters, which\nperiodically generate a massive amount of time-series data yielding few million\ndata points every day. This data can be leveraged to discover the underlying\nloads, infer their energy consumption patterns, inter-dependencies on\nenvironmental factors, and the building's operational properties. Furthermore,\nit allows us to simultaneously identify anomalies present in the electricity\nconsumption profiles, which is a big step towards saving energy and achieving\nglobal sustainability. However, to date, the lack of large-scale annotated\nenergy consumption datasets hinders the ongoing research in anomaly detection.\nWe contribute to this effort by releasing a well-annotated version of a\npublicly available ASHRAE Great Energy Predictor III data set containing 1,413\nsmart electricity meter time series spanning over one year. In addition, we\nbenchmark the performance of eight state-of-the-art anomaly detection methods\non our dataset and compare their performance.",
    "descriptor": "",
    "authors": [
      "Manoj Gulati",
      "Pandarasamy Arjunan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2203.17256"
  },
  {
    "id": "arXiv:2203.17257",
    "title": "Rethinking Video Salient Object Ranking",
    "abstract": "Salient Object Ranking (SOR) involves ranking the degree of saliency of\nmultiple salient objects in an input image. Most recently, a method is proposed\nfor ranking salient objects in an input video based on a predicted fixation\nmap. It relies solely on the density of the fixations within the salient\nobjects to infer their saliency ranks, which is incompatible with human\nperception of saliency ranking. In this work, we propose to explicitly learn\nthe spatial and temporal relations between different salient objects to produce\nthe saliency ranks. To this end, we propose an end-to-end method for video\nsalient object ranking (VSOR), with two novel modules: an intra-frame adaptive\nrelation (IAR) module to learn the spatial relation among the salient objects\nin the same frame locally and globally, and an inter-frame dynamic relation\n(IDR) module to model the temporal relation of saliency across different\nframes. In addition, to address the limited video types (just sports and\nmovies) and scene diversity in the existing VSOR dataset, we propose a new\ndataset that covers different video types and diverse scenes on a large scale.\nExperimental results demonstrate that our method outperforms state-of-the-art\nmethods in relevant fields. We will make the source code and our proposed\ndataset available.",
    "descriptor": "",
    "authors": [
      "Jiaying Lin",
      "Huankang Guan",
      "Rynson W.H. Lau"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.17257"
  },
  {
    "id": "arXiv:2203.17259",
    "title": "To ArXiv or not to ArXiv: A Study Quantifying Pros and Cons of Posting  Preprints Online",
    "abstract": "Double-blind conferences have engaged in debates over whether to allow\nauthors to post their papers online on arXiv or elsewhere during the review\nprocess. Independently, some authors of research papers face the dilemma of\nwhether to put their papers on arXiv due to its pros and cons. We conduct a\nstudy to substantiate this debate and dilemma via quantitative measurements.\nSpecifically, we conducted surveys of reviewers in two top-tier double-blind\ncomputer science conferences -- ICML 2021 (5361 submissions and 4699 reviewers)\nand EC 2021 (498 submissions and 190 reviewers). Our two main findings are as\nfollows. First, more than a third of the reviewers self-report searching online\nfor a paper they are assigned to review. Second, outside the review process, we\nfind that preprints from better-ranked affiliations see a weakly higher\nvisibility, with a correlation of 0.06 in ICML and 0.05 in EC. In particular,\npapers associated with the top-10-ranked affiliations had a visibility of\napproximately 11% in ICML and 22% in EC, whereas the remaining papers had a\nvisibility of 7% and 18% respectively.",
    "descriptor": "\nComments: 17 pages, 3 figures\n",
    "authors": [
      "Charvi Rastogi",
      "Ivan Stelmakh",
      "Xinwei Shen",
      "Marina Meila",
      "Federico Echenique",
      "Shuchi Chawla",
      "Nihar B. Shah"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2203.17259"
  },
  {
    "id": "arXiv:2203.17260",
    "title": "Generating High Fidelity Data from Low-density Regions using Diffusion  Models",
    "abstract": "Our work focuses on addressing sample deficiency from low-density regions of\ndata manifold in common image datasets. We leverage diffusion process based\ngenerative models to synthesize novel images from low-density regions. We\nobserve that uniform sampling from diffusion models predominantly samples from\nhigh-density regions of the data manifold. Therefore, we modify the sampling\nprocess to guide it towards low-density regions while simultaneously\nmaintaining the fidelity of synthetic data. We rigorously demonstrate that our\nprocess successfully generates novel high fidelity samples from low-density\nregions. We further examine generated samples and show that the model does not\nmemorize low-density data and indeed learns to generate novel samples from\nlow-density regions.",
    "descriptor": "\nComments: CVPR 2022\n",
    "authors": [
      "Vikash Sehwag",
      "Caner Hazirbas",
      "Albert Gordo",
      "Firat Ozgenel",
      "Cristian Canton Ferrer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.17260"
  },
  {
    "id": "arXiv:2203.17261",
    "title": "R2L: Distilling Neural Radiance Field to Neural Light Field for  Efficient Novel View Synthesis",
    "abstract": "Recent research explosion on Neural Radiance Field (NeRF) shows the\nencouraging potential to represent complex scenes with neural networks. One\nmajor drawback of NeRF is its prohibitive inference time: Rendering a single\npixel requires querying the NeRF network hundreds of times. To resolve it,\nexisting efforts mainly attempt to reduce the number of required sampled\npoints. However, the problem of iterative sampling still exists. On the other\nhand, Neural Light Field (NeLF) presents a more straightforward representation\nover NeRF in novel view synthesis -- the rendering of a pixel amounts to one\nsingle forward pass without ray-marching. In this work, we present a deep\nresidual MLP network (88 layers) to effectively learn the light field. We show\nthe key to successfully learning such a deep NeLF network is to have sufficient\ndata, for which we transfer the knowledge from a pre-trained NeRF model via\ndata distillation. Extensive experiments on both synthetic and real-world\nscenes show the merits of our method over other counterpart algorithms. On the\nsynthetic scenes, we achieve 26-35x FLOPs reduction (per camera ray) and 28-31x\nruntime speedup, meanwhile delivering significantly better (1.4-2.8 dB average\nPSNR improvement) rendering quality than NeRF without any customized\nimplementation tricks.",
    "descriptor": "\nComments: Project: this https URL\n",
    "authors": [
      "Huan Wang",
      "Jian Ren",
      "Zeng Huang",
      "Kyle Olszewski",
      "Menglei Chai",
      "Yun Fu",
      "Sergey Tulyakov"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.17261"
  },
  {
    "id": "arXiv:2203.17263",
    "title": "Audio-Visual Speech Codecs: Rethinking Audio-Visual Speech Enhancement  by Re-Synthesis",
    "abstract": "Since facial actions such as lip movements contain significant information\nabout speech content, it is not surprising that audio-visual speech enhancement\nmethods are more accurate than their audio-only counterparts. Yet,\nstate-of-the-art approaches still struggle to generate clean, realistic speech\nwithout noise artifacts and unnatural distortions in challenging acoustic\nenvironments. In this paper, we propose a novel audio-visual speech enhancement\nframework for high-fidelity telecommunications in AR/VR. Our approach leverages\naudio-visual speech cues to generate the codes of a neural speech codec,\nenabling efficient synthesis of clean, realistic speech from noisy signals.\nGiven the importance of speaker-specific cues in speech, we focus on developing\npersonalized models that work well for individual speakers. We demonstrate the\nefficacy of our approach on a new audio-visual speech dataset collected in an\nunconstrained, large vocabulary setting, as well as existing audio-visual\ndatasets, outperforming speech enhancement baselines on both quantitative\nmetrics and human evaluation studies. Please see the supplemental video for\nqualitative results at\nhttps://github.com/facebookresearch/facestar/releases/download/paper_materials/video.mp4.",
    "descriptor": "",
    "authors": [
      "Karren Yang",
      "Dejan Markovic",
      "Steven Krenn",
      "Vasu Agrawal",
      "Alexander Richard"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.17263"
  },
  {
    "id": "arXiv:2203.17265",
    "title": "A 23 MW data centre is all you need",
    "abstract": "The field of machine learning has achieved striking progress in recent years,\nwitnessing breakthrough results on language modelling, protein folding and\nnitpickingly fine-grained dog breed classification. Some even succeeded at\nplaying computer games and board games, a feat both of engineering and of\nsetting their employers' expectations. The central contribution of this work is\nto carefully examine whether this progress, and technology more broadly, can be\nexpected to continue indefinitely. Through a rigorous application of\nstatistical theory and failure to extrapolate beyond the training data, we\nanswer firmly in the negative and provide details: technology will peak at 3:07\nam (BST) on 20th July, 2032. We then explore the implications of this finding,\ndiscovering that individuals awake at this ungodly hour with access to a\nsufficiently powerful computer possess an opportunity for myriad forms of\nlong-term linguistic 'lock in'. All we need is a large (>> 1W) data centre to\nseize this pivotal moment. By setting our analogue alarm clocks, we propose a\ntractable algorithm to ensure that, for the future of humanity, the British\nspelling of colour becomes the default spelling across more than 80% of the\nglobal word processing software market.",
    "descriptor": "\nComments: SIGBOVIK 2022\n",
    "authors": [
      "Samuel Albanie",
      "Dylan Campbell",
      "Jo\u00e3o F. Henriques"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.17265"
  },
  {
    "id": "arXiv:2203.17266",
    "title": "TransEditor: Transformer-Based Dual-Space GAN for Highly Controllable  Facial Editing",
    "abstract": "Recent advances like StyleGAN have promoted the growth of controllable facial\nediting. To address its core challenge of attribute decoupling in a single\nlatent space, attempts have been made to adopt dual-space GAN for better\ndisentanglement of style and content representations. Nonetheless, these\nmethods are still incompetent to obtain plausible editing results with high\ncontrollability, especially for complicated attributes. In this study, we\nhighlight the importance of interaction in a dual-space GAN for more\ncontrollable editing. We propose TransEditor, a novel Transformer-based\nframework to enhance such interaction. Besides, we develop a new dual-space\nediting and inversion strategy to provide additional editing flexibility.\nExtensive experiments demonstrate the superiority of the proposed framework in\nimage quality and editing capability, suggesting the effectiveness of\nTransEditor for highly controllable facial editing.",
    "descriptor": "\nComments: CVPR 2022. Code: this https URL Project page: this https URL\n",
    "authors": [
      "Yanbo Xu",
      "Yueqin Yin",
      "Liming Jiang",
      "Qianyi Wu",
      "Chengyao Zheng",
      "Chen Change Loy",
      "Bo Dai",
      "Wayne Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.17266"
  },
  {
    "id": "arXiv:2203.17269",
    "title": "A Closer Look at Rehearsal-Free Continual Learning",
    "abstract": "Continual learning describes a setting where machine learning models learn\nnovel concepts from continuously shifting training data, while simultaneously\navoiding degradation of knowledge on previously seen classes (a phenomenon\nknown as the catastrophic forgetting problem) which may disappear from the\ntraining data for extended periods of time. Current approaches for continual\nlearning of a single expanding task (aka class-incremental continual learning)\nrequire extensive rehearsal of previously seen data to avoid this degradation\nof knowledge. Unfortunately, rehearsal comes at a sharp cost to memory and\ncomputation, and it may also violate data-privacy. Instead, we explore\ncombining knowledge distillation and parameter regularization in new ways to\nachieve strong continual learning performance without rehearsal. Specifically,\nwe take a deep dive into common continual learning techniques: prediction\ndistillation, feature distillation, L2 parameter regularization, and EWC\nparameter regularization. We first disprove the common assumption that\nparameter regularization techniques fail for rehearsal-free continual learning\nof a single, expanding task. Next, we explore how to leverage knowledge from a\npre-trained model in rehearsal-free continual learning and find that vanilla L2\nparameter regularization outperforms EWC parameter regularization and feature\ndistillation. We then highlight the impact of the rehearsal-free continual\nlearning settings with a classifier expansion benchmark, showing that a\nstrategy based on our findings combined with a positive/negative label\nbalancing heuristic can close the performance gap between the upper bound and\nthe existing strategies by up to roughly 50%. Finally, we show that a simple\nmethod consisting of pre-training, L2 regularization, and prediction\ndistillation can even outperform rehearsal-based methods on the common\nCIFAR-100 benchmark.",
    "descriptor": "",
    "authors": [
      "James Seale Smith",
      "Junjiao Tian",
      "Yen-Chang Hsu",
      "Zsolt Kira"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.17269"
  },
  {
    "id": "arXiv:2203.17270",
    "title": "BEVFormer: Learning Bird's-Eye-View Representation from Multi-Camera  Images via Spatiotemporal Transformers",
    "abstract": "3D visual perception tasks, including 3D detection and map segmentation based\non multi-camera images, are essential for autonomous driving systems. In this\nwork, we present a new framework termed BEVFormer, which learns unified BEV\nrepresentations with spatiotemporal transformers to support multiple autonomous\ndriving perception tasks. In a nutshell, BEVFormer exploits both spatial and\ntemporal information by interacting with spatial and temporal space through\npredefined grid-shaped BEV queries. To aggregate spatial information, we design\na spatial cross-attention that each BEV query extracts the spatial features\nfrom the regions of interest across camera views. For temporal information, we\npropose a temporal self-attention to recurrently fuse the history BEV\ninformation. Our approach achieves the new state-of-the-art 56.9\\% in terms of\nNDS metric on the nuScenes test set, which is 9.0 points higher than previous\nbest arts and on par with the performance of LiDAR-based baselines. We further\nshow that BEVFormer remarkably improves the accuracy of velocity estimation and\nrecall of objects under low visibility conditions. The code will be released at\nhttps://github.com/zhiqi-li/BEVFormer.",
    "descriptor": "\nComments: 20 pages, 9 figures\n",
    "authors": [
      "Zhiqi Li",
      "Wenhai Wang",
      "Hongyang Li",
      "Enze Xie",
      "Chonghao Sima",
      "Tong Lu",
      "Qiao Yu",
      "Jifeng Dai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.17270"
  },
  {
    "id": "arXiv:2203.17271",
    "title": "Do Vision-Language Pretrained Models Learn Primitive Concepts?",
    "abstract": "Vision-language pretrained models have achieved impressive performance on\nmultimodal reasoning and zero-shot recognition tasks. Many of these VL models\nare pretrained on unlabeled image and caption pairs from the internet. In this\npaper, we study whether the notion of primitive concepts, such as color and\nshape attributes, emerges automatically from these pretrained VL models. We\npropose to learn compositional derivations that map primitive concept\nactivations into composite concepts, a task which we demonstrate to be\nstraightforward given true primitive concept annotations. This compositional\nderivation learning (CompDL) framework allows us to quantitively measure the\nusefulness and interpretability of the learned derivations, by jointly\nconsidering the entire set of candidate primitive concepts. Our study reveals\nthat state-of-the-art VL pretrained models learn primitive concepts that are\nhighly useful as visual descriptors, as demonstrated by their strong\nperformance on fine-grained visual recognition tasks, but those concepts\nstruggle to provide interpretable compositional derivations, which highlights\nlimitations of existing VL models. Code and models will be released.",
    "descriptor": "\nComments: Under review\n",
    "authors": [
      "Tian Yun",
      "Usha Bhalla",
      "Ellie Pavlick",
      "Chen Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.17271"
  },
  {
    "id": "arXiv:2203.17272",
    "title": "MyStyle: A Personalized Generative Prior",
    "abstract": "We introduce MyStyle, a personalized deep generative prior trained with a few\nshots of an individual. MyStyle allows to reconstruct, enhance and edit images\nof a specific person, such that the output is faithful to the person's key\nfacial characteristics. Given a small reference set of portrait images of a\nperson (~100), we tune the weights of a pretrained StyleGAN face generator to\nform a local, low-dimensional, personalized manifold in the latent space. We\nshow that this manifold constitutes a personalized region that spans latent\ncodes associated with diverse portrait images of the individual. Moreover, we\ndemonstrate that we obtain a personalized generative prior, and propose a\nunified approach to apply it to various ill-posed image enhancement problems,\nsuch as inpainting and super-resolution, as well as semantic editing. Using the\npersonalized generative prior we obtain outputs that exhibit high-fidelity to\nthe input images and are also faithful to the key facial characteristics of the\nindividual in the reference set. We demonstrate our method with fair-use images\nof numerous widely recognizable individuals for whom we have the prior\nknowledge for a qualitative evaluation of the expected outcome. We evaluate our\napproach against few-shots baselines and show that our personalized prior,\nquantitatively and qualitatively, outperforms state-of-the-art alternatives.",
    "descriptor": "\nComments: Project webpage: this https URL, Video: this https URL\n",
    "authors": [
      "Yotam Nitzan",
      "Kfir Aberman",
      "Qiurui He",
      "Orly Liba",
      "Michal Yarom",
      "Yossi Gandelsman",
      "Inbar Mosseri",
      "Yael Pritch",
      "Daniel Cohen-or"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.17272"
  },
  {
    "id": "arXiv:2203.17273",
    "title": "FindIt: Generalized Localization with Natural Language Queries",
    "abstract": "We propose FindIt, a simple and versatile framework that unifies a variety of\nvisual grounding and localization tasks including referring expression\ncomprehension, text-based localization, and object detection. Key to our\narchitecture is an efficient multi-scale fusion module that unifies the\ndisparate localization requirements across the tasks. In addition, we discover\nthat a standard object detector is surprisingly effective in unifying these\ntasks without a need for task-specific design, losses, or pre-computed\ndetections. Our end-to-end trainable framework responds flexibly and accurately\nto a wide range of referring expression, localization or detection queries for\nzero, one, or multiple objects. Jointly trained on these tasks, FindIt\noutperforms the state of the art on both referring expression and text-based\nlocalization, and shows competitive performance on object detection. Finally,\nFindIt generalizes better to out-of-distribution data and novel categories\ncompared to strong single-task baselines. All of these are accomplished by a\nsingle, unified and efficient model. The code will be released.",
    "descriptor": "\nComments: Tech report\n",
    "authors": [
      "Weicheng Kuo",
      "Fred Bertsch",
      "Wei Li",
      "AJ Piergiovanni",
      "Mohammad Saffar",
      "Anelia Angelova"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.17273"
  },
  {
    "id": "arXiv:2203.17274",
    "title": "Visual Prompting: Modifying Pixel Space to Adapt Pre-trained Models",
    "abstract": "Prompting has recently become a popular paradigm for adapting language models\nto downstream tasks. Rather than fine-tuning model parameters or adding\ntask-specific heads, this approach steers a model to perform a new task simply\nby adding a text prompt to the model's inputs. In this paper, we explore the\nquestion: can we create prompts with pixels instead? In other words, can\npre-trained vision models be adapted to a new task solely by adding pixels to\ntheir inputs? We introduce visual prompting, which learns a task-specific image\nperturbation such that a frozen pre-trained model prompted with this\nperturbation performs a new task. We discover that changing only a few pixels\nis enough to adapt models to new tasks and datasets, and performs on par with\nlinear probing, the current de facto approach to lightweight adaptation. The\nsurprising effectiveness of visual prompting provides a new perspective on how\nto adapt pre-trained models in vision, and opens up the possibility of adapting\nmodels solely through their inputs, which, unlike model parameters or outputs,\nare typically under an end-user's control. Code is available at\nthis http URL .",
    "descriptor": "\nComments: 17 pages, 10 figures\n",
    "authors": [
      "Hyojin Bahng",
      "Ali Jahanian",
      "Swami Sankaranarayanan",
      "Phillip Isola"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.17274"
  },
  {
    "id": "arXiv:2203.17275",
    "title": "DiffSkill: Skill Abstraction from Differentiable Physics for Deformable  Object Manipulations with Tools",
    "abstract": "We consider the problem of sequential robotic manipulation of deformable\nobjects using tools. Previous works have shown that differentiable physics\nsimulators provide gradients to the environment state and help trajectory\noptimization to converge orders of magnitude faster than model-free\nreinforcement learning algorithms for deformable object manipulation. However,\nsuch gradient-based trajectory optimization typically requires access to the\nfull simulator states and can only solve short-horizon, single-skill tasks due\nto local optima. In this work, we propose a novel framework, named DiffSkill,\nthat uses a differentiable physics simulator for skill abstraction to solve\nlong-horizon deformable object manipulation tasks from sensory observations. In\nparticular, we first obtain short-horizon skills using individual tools from a\ngradient-based optimizer, using the full state information in a differentiable\nsimulator; we then learn a neural skill abstractor from the demonstration\ntrajectories which takes RGBD images as input. Finally, we plan over the skills\nby finding the intermediate goals and then solve long-horizon tasks. We show\nthe advantages of our method in a new set of sequential deformable object\nmanipulation tasks compared to previous reinforcement learning algorithms and\ncompared to the trajectory optimizer.",
    "descriptor": "\nComments: ICLR 2022. Project page: this https URL\n",
    "authors": [
      "Xingyu Lin",
      "Zhiao Huang",
      "Yunzhu Li",
      "Joshua B. Tenenbaum",
      "David Held",
      "Chuang Gan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.17275"
  },
  {
    "id": "arXiv:2203.17276",
    "title": "Bringing Old Films Back to Life",
    "abstract": "We present a learning-based framework, recurrent transformer network (RTN),\nto restore heavily degraded old films. Instead of performing frame-wise\nrestoration, our method is based on the hidden knowledge learned from adjacent\nframes that contain abundant information about the occlusion, which is\nbeneficial to restore challenging artifacts of each frame while ensuring\ntemporal coherency. Moreover, contrasting the representation of the current\nframe and the hidden knowledge makes it possible to infer the scratch position\nin an unsupervised manner, and such defect localization generalizes well to\nreal-world degradations. To better resolve mixed degradation and compensate for\nthe flow estimation error during frame alignment, we propose to leverage more\nexpressive transformer blocks for spatial restoration. Experiments on both\nsynthetic dataset and real-world old films demonstrate the significant\nsuperiority of the proposed RTN over existing solutions. In addition, the same\nframework can effectively propagate the color from keyframes to the whole\nvideo, ultimately yielding compelling restored films. The implementation and\nmodel will be released at\nhttps://github.com/raywzy/Bringing-Old-Films-Back-to-Life.",
    "descriptor": "\nComments: CVPR 2022, code is available at this https URL\n",
    "authors": [
      "Ziyu Wan",
      "Bo Zhang",
      "Dongdong Chen",
      "Jing Liao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2203.17276"
  },
  {
    "id": "arXiv:2109.03379",
    "title": "Application of Ghost-DeblurGAN to Fiducial Marker Detection",
    "abstract": "Feature extraction or localization based on the fiducial marker could fail\ndue to motion blur in real-world robotic applications. To solve this problem, a\nlightweight generative adversarial network, named Ghost-DeblurGAN, for\nreal-time motion deblurring is developed in this paper. Furthermore, on account\nthat there is no existing deblurring benchmark for such task, a new large-scale\ndataset, YorkTag, is proposed that provides pairs of sharp/blurred images\ncontaining fiducial markers. With the proposed model trained and tested on\nYorkTag, it is demonstrated that when applied along with fiducial marker\nsystems to motion-blurred images, Ghost-DeblurGAN improves the marker detection\nsignificantly. The datasets and codes used in this paper are available at:\nhttps://github.com/York-SDCNLab/Ghost-DeblurGAN.",
    "descriptor": "\nComments: 6 pages, 6 figures\n",
    "authors": [
      "Yibo Liu",
      "Amaldev Haridevan",
      "Hunter Schofield",
      "Jinjun Shan"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.03379"
  },
  {
    "id": "arXiv:2203.15937",
    "title": "Improving Mispronunciation Detection with Wav2vec2-based Momentum  Pseudo-Labeling for Accentedness and Intelligibility Assessment",
    "abstract": "Current leading mispronunciation detection and diagnosis (MDD) systems\nachieve promising performance via end-to-end phoneme recognition. One challenge\nof such end-to-end solutions is the scarcity of human-annotated phonemes on\nnatural L2 speech. In this work, we leverage unlabeled L2 speech via a\npseudo-labeling (PL) procedure and extend the fine-tuning approach based on\npre-trained self-supervised learning (SSL) models. Specifically, we use Wav2vec\n2.0 as our SSL model, and fine-tune it using original labeled L2 speech samples\nplus the created pseudo-labeled L2 speech samples. Our pseudo labels are\ndynamic and are produced by an ensemble of the online model on-the-fly, which\nensures that our model is robust to pseudo label noise. We show that\nfine-tuning with pseudo labels gains a 5.35% phoneme error rate reduction and\n2.48% MDD F1 score improvement over a labeled-samples-only fine-tuning\nbaseline. The proposed PL method is also shown to outperform conventional\noffline PL methods. Compared to the state-of-the-art MDD systems, our MDD\nsolution achieves a more accurate and consistent phonetic error diagnosis. In\naddition, we conduct an open test on a separate UTD-4Accents dataset, where our\nsystem recognition outputs show a strong correlation with human perception,\nbased on accentedness and intelligibility.",
    "descriptor": "\nComments: Submitted to Interspeech 2022\n",
    "authors": [
      "Mu Yang",
      "Kevin Hirschi",
      "Stephen D. Looney",
      "Okim Kang",
      "John H. L. Hansen"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.15937"
  },
  {
    "id": "arXiv:2203.16557",
    "title": "COSMOS: Cross-Modality Unsupervised Domain Adaptation for 3D Medical  Image Segmentation based on Target-aware Domain Translation and Iterative  Self-Training",
    "abstract": "Recent advances in deep learning-based medical image segmentation studies\nachieve nearly human-level performance when in fully supervised condition.\nHowever, acquiring pixel-level expert annotations is extremely expensive and\nlaborious in medical imaging fields. Unsupervised domain adaptation can\nalleviate this problem, which makes it possible to use annotated data in one\nimaging modality to train a network that can successfully perform segmentation\non target imaging modality with no labels. In this work, we propose a\nself-training based unsupervised domain adaptation framework for 3D medical\nimage segmentation named COSMOS and validate it with automatic segmentation of\nVestibular Schwannoma (VS) and cochlea on high-resolution T2 Magnetic Resonance\nImages (MRI). Our target-aware contrast conversion network translates source\ndomain annotated T1 MRI to pseudo T2 MRI to enable segmentation training on\ntarget domain, while preserving important anatomical features of interest in\nthe converted images. Iterative self-training is followed to incorporate\nunlabeled data to training and incrementally improve the quality of\npseudo-labels, thereby leading to improved performance of segmentation. COSMOS\nwon the 1\\textsuperscript{st} place in the Cross-Modality Domain Adaptation\n(crossMoDA) challenge held in conjunction with the 24th International\nConference on Medical Image Computing and Computer Assisted Intervention\n(MICCAI 2021). It achieves mean Dice score and Average Symmetric Surface\nDistance of 0.871(0.063) and 0.437(0.270) for VS, and 0.842(0.020) and\n0.152(0.030) for cochlea.",
    "descriptor": "\nComments: 10 pages, 6 figures, MICCAI 2021 Cross-Modality Domain Adaptation (crossMoDA) Challenge\n",
    "authors": [
      "Hyungseob Shin",
      "Hyeongyu Kim",
      "Sewon Kim",
      "Yohan Jun",
      "Taejoon Eo",
      "Dosik Hwang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.16557"
  },
  {
    "id": "arXiv:2203.16587",
    "title": "Spatially Adaptive Online Prediction of Piecewise Regular Functions",
    "abstract": "We consider the problem of estimating piecewise regular functions in an\nonline setting, i.e., the data arrive sequentially and at any round our task is\nto predict the value of the true function at the next revealed point using the\navailable data from past predictions. We propose a suitably modified version of\na recently developed online learning algorithm called the sleeping experts\naggregation algorithm. We show that this estimator satisfies oracle risk bounds\nsimultaneously for all local regions of the domain. As concrete instantiations\nof the expert aggregation algorithm proposed here, we study an online mean\naggregation and an online linear regression aggregation algorithm where experts\ncorrespond to the set of dyadic subrectangles of the domain. The resulting\nalgorithms are near linear time computable in the sample size. We specifically\nfocus on the performance of these online algorithms in the context of\nestimating piecewise polynomial and bounded variation function classes in the\nfixed design setup. The simultaneous oracle risk bounds we obtain for these\nestimators in this context provide new and improved (in certain aspects)\nguarantees even in the batch setting and are not available for the state of the\nart batch learning estimators.",
    "descriptor": "\nComments: 34 pages, 12 figures\n",
    "authors": [
      "Sabyasachi Chatterjee",
      "Subhajit Goswami"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.16587"
  },
  {
    "id": "arXiv:2203.16606",
    "title": "Enhancing Cancer Prediction in Challenging Screen-Detected Incident Lung  Nodules Using Time-Series Deep Learning",
    "abstract": "Lung cancer is the leading cause of cancer-related mortality worldwide. Lung\ncancer screening (LCS) using annual low-dose computed tomography (CT) scanning\nhas been proven to significantly reduce lung cancer mortality by detecting\ncancerous lung nodules at an earlier stage. Improving risk stratification of\nmalignancy risk in lung nodules can be enhanced using machine/deep learning\nalgorithms. However most existing algorithms: a) have primarily assessed single\ntime-point CT data alone thereby failing to utilize the inherent advantages\ncontained within longitudinal imaging datasets; b) have not integrated into\ncomputer models pertinent clinical data that might inform risk prediction; c)\nhave not assessed algorithm performance on the spectrum of nodules that are\nmost challenging for radiologists to interpret and where assistance from\nanalytic tools would be most beneficial.\nHere we show the performance of our time-series deep learning model\n(DeepCAD-NLM-L) which integrates multi-model information across three\nlongitudinal data domains: nodule-specific, lung-specific, and clinical\ndemographic data. We compared our time-series deep learning model to a)\nradiologist performance on CTs from the National Lung Screening Trial enriched\nwith the most challenging nodules for diagnosis; b) a nodule management\nalgorithm from a North London LCS study (SUMMIT). Our model demonstrated\ncomparable and complementary performance to radiologists when interpreting\nchallenging lung nodules and showed improved performance (AUC=88\\%) against\nmodels utilizing single time-point data only. The results emphasise the\nimportance of time-series, multi-modal analysis when interpreting malignancy\nrisk in LCS.",
    "descriptor": "",
    "authors": [
      "Shahab Aslani",
      "Pavan Alluri",
      "Eyjolfur Gudmundsson",
      "Edward Chandy",
      "John McCabe",
      "Anand Devaraj",
      "Carolyn Horst",
      "Sam M Janes",
      "Rahul Chakkara",
      "Arjun Nair",
      "Daniel C Alexander",
      "SUMMIT consortium",
      "Joseph Jacob"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.16606"
  },
  {
    "id": "arXiv:2203.16614",
    "title": "Joint domain adaptation and speech bandwidth extension using time-domain  GANs for speaker verification",
    "abstract": "Speech systems developed for a particular choice of acoustic domain and\nsampling frequency do not translate easily to others. The usual practice is to\nlearn domain adaptation and bandwidth extension models independently. Contrary\nto this, we propose to learn both tasks together. Particularly, we learn to map\nnarrowband conversational telephone speech to wideband microphone speech. We\ndeveloped parallel and non-parallel learning solutions which utilize both\npaired and unpaired data. First, we first discuss joint and disjoint training\nof multiple generative models for our tasks. Then, we propose a two-stage\nlearning solution where we use a pre-trained domain adaptation system for\npre-processing in bandwidth extension training. We evaluated our schemes on a\nSpeaker Verification downstream task. We used the JHU-MIT experimental setup\nfor NIST SRE21, which comprises SRE16, SRE-CTS Superset and SRE21. Our results\nprovide the first evidence that learning both tasks is better than learning\njust one. On SRE16, our best system achieves 22% relative improvement in Equal\nError Rate w.r.t. a direct learning baseline and 8% w.r.t. a strong bandwidth\nexpansion system.",
    "descriptor": "\nComments: submitted to Interspeech 2022\n",
    "authors": [
      "Saurabh Kataria",
      "Jes\u00fas Villalba",
      "Laureano Moro-Vel\u00e1zquez",
      "Najim Dehak"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2203.16614"
  },
  {
    "id": "arXiv:2203.16622",
    "title": "Federated Learning for the Classification of Tumor Infiltrating  Lymphocytes",
    "abstract": "We evaluate the performance of federated learning (FL) in developing deep\nlearning models for analysis of digitized tissue sections. A classification\napplication was considered as the example use case, on quantifiying the\ndistribution of tumor infiltrating lymphocytes within whole slide images\n(WSIs). A deep learning classification model was trained using 50*50 square\nmicron patches extracted from the WSIs. We simulated a FL environment in which\na dataset, generated from WSIs of cancer from numerous anatomical sites\navailable by The Cancer Genome Atlas repository, is partitioned in 8 different\nnodes. Our results show that the model trained with the federated training\napproach achieves similar performance, both quantitatively and qualitatively,\nto that of a model trained with all the training data pooled at a centralized\nlocation. Our study shows that FL has tremendous potential for enabling\ndevelopment of more robust and accurate models for histopathology image\nanalysis without having to collect large and diverse training data at a single\nlocation.",
    "descriptor": "",
    "authors": [
      "Ujjwal Baid",
      "Sarthak Pati",
      "Tahsin M. Kurc",
      "Rajarsi Gupta",
      "Erich Bremer",
      "Shahira Abousamra",
      "Siddhesh P. Thakur",
      "Joel H. Saltz",
      "Spyridon Bakas"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.16622"
  },
  {
    "id": "arXiv:2203.16642",
    "title": "Data-driven Prediction of Relevant Scenarios for Robust Optimization",
    "abstract": "In this work we study robust one- and two-stage problems with discrete\nuncertainty sets which are known to be hard to solve even if the underlying\ndeterministic problem is easy. Popular solution methods iteratively generate\nscenario constraints and possibly second-stage variables. This way, by solving\na sequence of smaller problems, it is often possible to avoid the complexity of\nconsidering all scenarios simultaneously. A key ingredient for the performance\nof the iterative methods is a good selection of start scenarios. In this paper\nwe propose a data-driven heuristic to seed the iterative solution method with a\nset of starting scenarios that provide a strong lower bound early in the\nprocess, and result in considerably smaller overall solution times compared to\nother benchmark methods. Our heuristic learns the relevance of a scenario by\nextracting information from training data based on a combined similarity\nmeasure between robust problem instances and single scenarios. Our experiments\nshow that predicting even a small number of good start scenarios by our method\ncan considerably reduce the computation time of the iterative methods.",
    "descriptor": "",
    "authors": [
      "Marc Goerigk",
      "Jannis Kurtz"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.16642"
  },
  {
    "id": "arXiv:2203.16662",
    "title": "Challenges in leveraging GANs for few-shot data augmentation",
    "abstract": "In this paper, we explore the use of GAN-based few-shot data augmentation as\na method to improve few-shot classification performance. We perform an\nexploration into how a GAN can be fine-tuned for such a task (one of which is\nin a class-incremental manner), as well as a rigorous empirical investigation\ninto how well these models can perform to improve few-shot classification. We\nidentify issues related to the difficulty of training such generative models\nunder a purely supervised regime with very few examples, as well as issues\nregarding the evaluation protocols of existing works. We also find that in this\nregime, classification accuracy is highly sensitive to how the classes of the\ndataset are randomly split. Therefore, we propose a semi-supervised fine-tuning\napproach as a more pragmatic way forward to address these problems.",
    "descriptor": "",
    "authors": [
      "Christopher Beckham",
      "Issam Laradji",
      "Pau Rodriguez",
      "David Vazquez",
      "Derek Nowrouzezahrai",
      "Christopher Pal"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.16662"
  },
  {
    "id": "arXiv:2203.16673",
    "title": "System Identification via Nuclear Norm Regularization",
    "abstract": "This paper studies the problem of identifying low-order linear systems via\nHankel nuclear norm regularization. Hankel regularization encourages the\nlow-rankness of the Hankel matrix, which maps to the low-orderness of the\nsystem. We provide novel statistical analysis for this regularization and\ncarefully contrast it with the unregularized ordinary least-squares (OLS)\nestimator. Our analysis leads to new bounds on estimating the impulse response\nand the Hankel matrix associated with the linear system. We first design an\ninput excitation and show that Hankel regularization enables one to recover the\nsystem using optimal number of observations in the true system order and\nachieve strong statistical estimation rates. Surprisingly, we demonstrate that\nthe input design indeed matters, by showing that intuitive choices such as\ni.i.d. Gaussian input leads to provably sub-optimal sample complexity. To\nbetter understand the benefits of regularization, we also revisit the OLS\nestimator. Besides refining existing bounds, we experimentally identify when\nregularized approach improves over OLS: (1) For low-order systems with slow\nimpulse-response decay, OLS method performs poorly in terms of sample\ncomplexity, (2) Hankel matrix returned by regularization has a more clear\nsingular value gap that ease identification of the system order, (3) Hankel\nregularization is less sensitive to hyperparameter choice. Finally, we\nestablish model selection guarantees through a joint train-validation procedure\nwhere we tune the regularization parameter for near-optimal estimation.",
    "descriptor": "",
    "authors": [
      "Yue Sun",
      "Samet Oymak",
      "Maryam Fazel"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)",
      "Dynamical Systems (math.DS)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2203.16673"
  },
  {
    "id": "arXiv:2203.16683",
    "title": "Active Learning for Computationally Efficient Distribution of Binary  Evolution Simulations",
    "abstract": "Binary stars undergo a variety of interactions and evolutionary phases,\ncritical for predicting and explaining observed properties. Binary population\nsynthesis with full stellar-structure and evolution simulations are\ncomputationally expensive requiring a large number of mass-transfer sequences.\nThe recently developed binary population synthesis code POSYDON incorporates\ngrids of MESA binary star simulations which are then interpolated to model\nlarge-scale populations of massive binaries. The traditional method of\ncomputing a high-density rectilinear grid of simulations is not scalable for\nhigher-dimension grids, accounting for a range of metallicities, rotation, and\neccentricity. We present a new active learning algorithm, psy-cris, which uses\nmachine learning in the data-gathering process to adaptively and iteratively\nselect targeted simulations to run, resulting in a custom, high-performance\ntraining set. We test psy-cris on a toy problem and find the resulting training\nsets require fewer simulations for accurate classification and regression than\neither regular or randomly sampled grids. We further apply psy-cris to the\ntarget problem of building a dynamic grid of MESA simulations, and we\ndemonstrate that, even without fine tuning, a simulation set of only $\\sim 1/4$\nthe size of a rectilinear grid is sufficient to achieve the same classification\naccuracy. We anticipate further gains when algorithmic parameters are optimized\nfor the targeted application. We find that optimizing for classification only\nmay lead to performance losses in regression, and vice versa. Lowering the\ncomputational cost of producing grids will enable future versions of POSYDON to\ncover more input parameters while preserving interpolation accuracies.",
    "descriptor": "\nComments: 20 pages (16 main text), 10 figures, submitted to ApJ\n",
    "authors": [
      "Kyle Akira Rocha",
      "Jeff J. Andrews",
      "Christopher P. L. Berry",
      "Zoheyr Doctor",
      "Pablo Marchant",
      "Vicky Kalogera",
      "Scott Coughlin",
      "Simone S. Bavera",
      "Aaron Dotter",
      "Tassos Fragos",
      "Konstantinos Kovlakas",
      "Devina Misra",
      "Zepei Xing",
      "Emmanouil Zapartas"
    ],
    "subjectives": [
      "Solar and Stellar Astrophysics (astro-ph.SR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.16683"
  },
  {
    "id": "arXiv:2203.16685",
    "title": "Streaming Speaker-Attributed ASR with Token-Level Speaker Embeddings",
    "abstract": "This paper presents a streaming speaker-attributed automatic speech\nrecognition (SA-ASR) model that can recognize \"who spoke what\" with low latency\neven when multiple people are speaking simultaneously. Our model is based on\ntoken-level serialized output training (t-SOT) which was recently proposed to\ntranscribe multi-talker speech in a streaming fashion. To further recognize\nspeaker identities, we propose an encoder-decoder based speaker embedding\nextractor that can estimate a speaker representation for each recognized token\nnot only from non-overlapping speech but also from overlapping speech. The\nproposed speaker embedding, named t-vector, is extracted synchronously with the\nt-SOT ASR model, enabling joint execution of speaker identification (SID) or\nspeaker diarization (SD) with the multi-talker transcription with low latency.\nWe evaluate the proposed model for a joint task of ASR and SID/SD by using\nLibriSpeechMix and LibriCSS corpora. The proposed model achieves substantially\nbetter accuracy than a prior streaming model and shows comparable or sometimes\neven superior results to the state-of-the-art offline SA-ASR model.",
    "descriptor": "\nComments: Submitted to Interspeech 2022\n",
    "authors": [
      "Naoyuki Kanda",
      "Jian Wu",
      "Yu Wu",
      "Xiong Xiao",
      "Zhong Meng",
      "Xiaofei Wang",
      "Yashesh Gaur",
      "Zhuo Chen",
      "Jinyu Li",
      "Takuya Yoshioka"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2203.16685"
  },
  {
    "id": "arXiv:2203.16691",
    "title": "MAE-AST: Masked Autoencoding Audio Spectrogram Transformer",
    "abstract": "In this paper, we propose a simple yet powerful improvement over the recent\nSelf-Supervised Audio Spectrogram Transformer (SSAST) model for speech and\naudio classification. Specifically, we leverage the insight that the SSAST uses\na very high masking ratio (75%) during pretraining, meaning that the vast\nmajority of self-attention compute is performed on mask tokens. We address this\nby integrating the encoder-decoder architecture from Masked Autoencoders are\nScalable Vision Learners (MAE) into the SSAST, where a deep encoder operates on\nonly unmasked input, and a shallow decoder operates on encoder outputs and mask\ntokens. We find that MAE-like pretraining can provide a 3x speedup and 2x\nmemory usage reduction over the vanilla SSAST using current audio pretraining\nstrategies with ordinary model and input sizes. When fine-tuning on downstream\ntasks, which only uses the encoder, we find that our approach outperforms the\nSSAST on a variety of downstream tasks. We further conduct comprehensive\nevaluations into different strategies of pretraining and explore differences in\nMAE-style pretraining between the visual and audio domains.",
    "descriptor": "\nComments: Submitted to INTERSPEECH. 5 pages, 2 figures, 5 tables\n",
    "authors": [
      "Alan Baade",
      "Puyuan Peng",
      "David Harwath"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2203.16691"
  },
  {
    "id": "arXiv:2203.16705",
    "title": "Robust Disentangled Variational Speech Representation Learning for  Zero-shot Voice Conversion",
    "abstract": "Traditional studies on voice conversion (VC) have made progress with parallel\ntraining data and known speakers. Good voice conversion quality is obtained by\nexploring better alignment modules or expressive mapping functions. In this\nstudy, we investigate zero-shot VC from a novel perspective of self-supervised\ndisentangled speech representation learning. Specifically, we achieve the\ndisentanglement by balancing the information flow between global speaker\nrepresentation and time-varying content representation in a sequential\nvariational autoencoder (VAE). A zero-shot voice conversion is performed by\nfeeding an arbitrary speaker embedding and content embeddings to the VAE\ndecoder. Besides that, an on-the-fly data augmentation training strategy is\napplied to make the learned representation noise invariant. On TIMIT and VCTK\ndatasets, we achieve state-of-the-art performance on both objective evaluation,\ni.e., speaker verification (SV) on speaker embedding and content embedding, and\nsubjective evaluation, i.e., voice naturalness and similarity, and remains to\nbe robust even with noisy source/target utterances.",
    "descriptor": "\nComments: Accepted to 2022 ICASSP\n",
    "authors": [
      "Jiachen Lian",
      "Chunlei Zhang",
      "Dong Yu"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2203.16705"
  },
  {
    "id": "arXiv:2203.16706",
    "title": "Going Beyond RF: How AI-enabled Multimodal Beamforming will Shape the  NextG Standard",
    "abstract": "Incorporating artificial intelligence and machine learning (AI/ML) methods\nwithin the 5G wireless standard promises autonomous network behavior and\nultra-low-latency reconfiguration. However, the effort so far has purely\nfocused on learning from radio frequency (RF) signals. Future standards and\nnext-generation (nextG) networks beyond 5G will have two significant evolutions\nover the state-of-the-art 5G implementations: (i) massive number of antenna\nelements, scaling up to hundreds-to-thousands in number, and (ii) inclusion of\nAI/ML in the critical path of the network reconfiguration process that can\naccess sensor feeds from a variety of RF and non-RF sources. While the former\nallows unprecedented flexibility in 'beamforming', where signals combine\nconstructively at a target receiver, the latter enables the network with\nenhanced situation awareness not captured by a single and isolated data\nmodality. This survey presents a thorough analysis of the different approaches\nused for beamforming today, focusing on mmWave bands, and then proceeds to make\na compelling case for considering non-RF sensor data from multiple modalities,\nsuch as LiDAR, Radar, GPS for increasing beamforming directional accuracy and\nreducing processing time. This so called idea of multimodal beamforming will\nrequire deep learning based fusion techniques, which will serve to augment the\ncurrent RF-only and classical signal processing methods that do not scale well\nfor massive antenna arrays. The survey describes relevant deep learning\narchitectures for multimodal beamforming, identifies computational challenges\nand the role of edge computing in this process, dataset generation tools, and\nfinally, lists open challenges that the community should tackle to realize this\ntransformative vision of the future of beamforming.",
    "descriptor": "",
    "authors": [
      "Debashri Roy",
      "Batool Salehi",
      "Stella Banou",
      "Subhramoy Mohanti",
      "Guillem Reus-Muns",
      "Mauro Belgiovine",
      "Prashant Ganesh",
      "Carlos Bocanegra",
      "Chris Dick",
      "Kaushik Chowdhury"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.16706"
  },
  {
    "id": "arXiv:2203.16707",
    "title": "Monte Carlo Tree Search based Hybrid Optimization of Variational Quantum  Circuits",
    "abstract": "Variational quantum algorithms stand at the forefront of simulations on\nnear-term and future fault-tolerant quantum devices. While most variational\nquantum algorithms involve only continuous optimization variables, the\nrepresentational power of the variational ansatz can sometimes be significantly\nenhanced by adding certain discrete optimization variables, as is exemplified\nby the generalized quantum approximate optimization algorithm (QAOA). However,\nthe hybrid discrete-continuous optimization problem in the generalized QAOA\nposes a challenge to the optimization. We propose a new algorithm called\nMCTS-QAOA, which combines a Monte Carlo tree search method with an improved\nnatural policy gradient solver to optimize the discrete and continuous\nvariables in the quantum circuit, respectively. We find that MCTS-QAOA has\nexcellent noise-resilience properties and outperforms prior algorithms in\nchallenging instances of the generalized QAOA.",
    "descriptor": "",
    "authors": [
      "Jiahao Yao",
      "Haoya Li",
      "Marin Bukov",
      "Lin Lin",
      "Lexing Ying"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Quantum Gases (cond-mat.quant-gas)",
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2203.16707"
  },
  {
    "id": "arXiv:2203.16711",
    "title": "An analytic theory for the dynamics of wide quantum neural networks",
    "abstract": "Parametrized quantum circuits can be used as quantum neural networks and have\nthe potential to outperform their classical counterparts when trained for\naddressing learning problems. To date, much of the results on their performance\non practical problems are heuristic in nature. In particular, the convergence\nrate for the training of quantum neural networks is not fully understood. Here,\nwe analyze the dynamics of gradient descent for the training error of a class\nof variational quantum machine learning models. We define wide quantum neural\nnetworks as parameterized quantum circuits in the limit of a large number of\nqubits and variational parameters. We then find a simple analytic formula that\ncaptures the average behavior of their loss function and discuss the\nconsequences of our findings. For example, for random quantum circuits, we\npredict and characterize an exponential decay of the residual training error as\na function of the parameters of the system. We finally validate our analytic\nresults with numerical experiments.",
    "descriptor": "\nComments: 26 pages, 5 figures. Comments welcome\n",
    "authors": [
      "Junyu Liu",
      "Khadijeh Najafi",
      "Kunal Sharma",
      "Francesco Tacchino",
      "Liang Jiang",
      "Antonio Mezzacapo"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.16711"
  },
  {
    "id": "arXiv:2203.16749",
    "title": "SpecGrad: Diffusion Probabilistic Model based Neural Vocoder with  Adaptive Noise Spectral Shaping",
    "abstract": "Neural vocoder using denoising diffusion probabilistic model (DDPM) has been\nimproved by adaptation of the diffusion noise distribution to given acoustic\nfeatures. In this study, we propose SpecGrad that adapts the diffusion noise so\nthat its time-varying spectral envelope becomes close to the conditioning\nlog-mel spectrogram. This adaptation by time-varying filtering improves the\nsound quality especially in the high-frequency bands. It is processed in the\ntime-frequency domain to keep the computational cost almost the same as the\nconventional DDPM-based neural vocoders. Experimental results showed that\nSpecGrad generates higher-fidelity speech waveform than conventional DDPM-based\nneural vocoders in both analysis-synthesis and speech enhancement scenarios.\nAudio demos are available at wavegrad.github.io/specgrad/.",
    "descriptor": "\nComments: Submitted to Interspeech 2022\n",
    "authors": [
      "Yuma Koizumi",
      "Heiga Zen",
      "Kohei Yatabe",
      "Nanxin Chen",
      "Michiel Bacchiani"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.16749"
  },
  {
    "id": "arXiv:2203.16757",
    "title": "Exploiting Single-Channel Speech for Multi-Channel End-to-End Speech  Recognition: A Comparative Study",
    "abstract": "Recently, the end-to-end training approach for multi-channel ASR has shown\nits effectiveness, which usually consists of a beamforming front-end and a\nrecognition back-end. However, the end-to-end training becomes more difficult\ndue to the integration of multiple modules, particularly considering that\nmulti-channel speech data recorded in real environments are limited in size.\nThis raises the demand to exploit the single-channel data for multi-channel\nend-to-end ASR. In this paper, we systematically compare the performance of\nthree schemes to exploit external single-channel data for multi-channel\nend-to-end ASR, namely back-end pre-training, data scheduling, and data\nsimulation, under different settings such as the sizes of the single-channel\ndata and the choices of the front-end. Extensive experiments on CHiME-4 and\nAISHELL-4 datasets demonstrate that while all three methods improve the\nmulti-channel end-to-end speech recognition performance, data simulation\noutperforms the other two, at the cost of longer training time. Data scheduling\noutperforms back-end pre-training marginally but nearly consistently,\npresumably because that in the pre-training stage, the back-end tends to\noverfit on the single-channel data, especially when the single-channel data\nsize is small.",
    "descriptor": "\nComments: submitted to INTERSPEECH 2022. arXiv admin note: substantial text overlap with arXiv:2107.02670\n",
    "authors": [
      "Keyu An",
      "Zhijian Ou"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.16757"
  },
  {
    "id": "arXiv:2203.16758",
    "title": "CUSIDE: Chunking, Simulating Future Context and Decoding for Streaming  ASR",
    "abstract": "History and future contextual information are known to be important for\naccurate acoustic modeling. However, acquiring future context brings latency\nfor streaming ASR. In this paper, we propose a new framework - Chunking,\nSimulating Future Context and Decoding (CUSIDE) for streaming speech\nrecognition. A new simulation module is introduced to recursively simulate the\nfuture contextual frames, without waiting for future context. The simulation\nmodule is jointly trained with the ASR model using a self-supervised loss; the\nASR model is optimized with the usual ASR loss, e.g., CTC-CRF as used in our\nexperiments. Experiments show that, compared to using real future frames as\nright context, using simulated future context can drastically reduce latency\nwhile maintaining recognition accuracy. With CUSIDE, we obtain new\nstate-of-the-art streaming ASR results on the AISHELL-1 dataset.",
    "descriptor": "\nComments: submitted to INTERSPEECH 2022\n",
    "authors": [
      "Keyu An",
      "Huahuan Zheng",
      "Zhijian Ou",
      "Hongyu Xiang",
      "Ke Ding",
      "Guanglu Wan"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.16758"
  },
  {
    "id": "arXiv:2203.16773",
    "title": "An Exploration of Prompt Tuning on Generative Spoken Language Model for  Speech Processing Tasks",
    "abstract": "Speech representations learned from Self-supervised learning (SSL) models\nhave been found beneficial for various speech processing tasks. However,\nutilizing SSL representations usually requires fine-tuning the pre-trained\nmodels or designing task-specific downstream models and loss functions, causing\nmuch memory usage and human labor. On the other hand, prompting in Natural\nLanguage Processing (NLP) is an efficient and widely used technique to leverage\npre-trained language models (LMs). Nevertheless, such a paradigm is little\nstudied in the speech community. We report in this paper the first exploration\nof the prompt tuning paradigm for speech processing tasks based on Generative\nSpoken Language Model (GSLM). Experiment results show that the prompt tuning\ntechnique achieves competitive performance in speech classification tasks with\nfewer trainable parameters than fine-tuning specialized downstream models. We\nfurther study the technique in challenging sequence generation tasks. Prompt\ntuning also demonstrates its potential, while the limitation and possible\nresearch directions are discussed in this paper.",
    "descriptor": "\nComments: Submitted to Interspeech 2022\n",
    "authors": [
      "Kai-Wei Chang",
      "Wei-Cheng Tseng",
      "Shang-Wen Li",
      "Hung-yi Lee"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2203.16773"
  },
  {
    "id": "arXiv:2203.16776",
    "title": "An Empirical Study of Language Model Integration for Transducer based  Speech Recognition",
    "abstract": "Utilizing text-only data with an external language model (LM) in end-to-end\nRNN-Transducer (RNN-T) for speech recognition is challenging. Recently, a class\nof methods such as density ratio (DR) and ILM estimation (ILME) have been\ndeveloped, outperforming the classic shallow fusion (SF) method. The basic idea\nbehind these methods is that RNN-T posterior should first subtract the\nimplicitly learned ILM prior, in order to integrate the external LM. While\nrecent studies suggest that RNN-T only learns some low-order language model\ninformation, the DR method uses a well-trained ILM. We hypothesize that this\nsetting is appropriate and may deteriorate the performance of the DR method,\nand propose a low-order density ratio method (LODR) by training a low-order\nweak ILM for DR. Extensive empirical experiments are conducted on both\nin-domain and cross-domain scenarios on English LibriSpeech & Tedlium-2 and\nChinese WenetSpeech & AISHELL-1 datasets. It is shown that LODR consistently\noutperforms SF in all tasks, while performing generally close to ILME and\nbetter than DR in most tests.",
    "descriptor": "\nComments: submitted to INTERSPEECH 2022\n",
    "authors": [
      "Huahuan Zheng",
      "Keyu An",
      "Zhijian Ou",
      "Chen Huang",
      "Ke Ding",
      "Guanglu Wan"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.16776"
  },
  {
    "id": "arXiv:2203.16805",
    "title": "Minimum Roman Dominating Distance Energy of a Graph",
    "abstract": "In this correspondence, we introduced the concept of minimum roman dominating\ndistance energy $E_{RDd}(G)$ of a graph $G$ and computed minimum roman\ndominating distance energy of some standard graphs. Also, we discussed the\nproperties of eigenvalues of a minimum roman dominating distance matrix\n$A_{RDd}(G).$ Finally, we derived the Upper and lower bounds for $E_{RDd}(G).$",
    "descriptor": "",
    "authors": [
      "Lakshmanan R",
      "N. Annamalai"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2203.16805"
  },
  {
    "id": "arXiv:2203.16822",
    "title": "How Does Pre-trained Wav2Vec2.0 Perform on Domain Shifted ASR? An  Extensive Benchmark on Air Traffic Control Communications",
    "abstract": "Recent work on self-supervised pre-training focus on leveraging large-scale\nunlabeled speech data to build robust end-to-end (E2E) acoustic models (AM)\nthat can be later fine-tuned on downstream tasks e.g., automatic speech\nrecognition (ASR). Yet, few works investigated the impact on performance when\nthe data substantially differs between the pre-training and downstream\nfine-tuning phases (i.e., domain shift). We target this scenario by analyzing\nthe robustness of Wav2Vec2.0 and XLS-R models on downstream ASR for a\ncompletely unseen domain, i.e., air traffic control (ATC) communications. We\nbenchmark the proposed models on four challenging ATC test sets\n(signal-to-noise ratio varies between 5 to 20 dB). Relative word error rate\n(WER) reduction between 20% to 40% are obtained in comparison to hybrid-based\nstate-of-the-art ASR baselines by fine-tuning E2E acoustic models with a small\nfraction of labeled data. We also study the impact of fine-tuning data size on\nWERs, going from 5 minutes (few-shot) to 15 hours.",
    "descriptor": "\nComments: This paper has been submitted to Interspeech 2022\n",
    "authors": [
      "Juan Zuluaga-Gomez",
      "Amrutha Prasad",
      "Iuliia Nigmatulina",
      "Saeed Sarfjoo",
      "Petr Motlicek",
      "Matthias Kleinert",
      "Hartmut Helmke",
      "Oliver Ohneiser",
      "Qingran Zhan"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.16822"
  },
  {
    "id": "arXiv:2203.16840",
    "title": "Speaker Extraction with Co-Speech Gestures Cue",
    "abstract": "Speaker extraction seeks to extract the clean speech of a target speaker from\na multi-talker mixture speech. There have been studies to use a pre-recorded\nspeech sample or face image of the target speaker as the speaker cue. In human\ncommunication, co-speech gestures that are naturally timed with speech also\ncontribute to speech perception. In this work, we explore the use of co-speech\ngestures sequence, e.g. hand and body movements, as the speaker cue for speaker\nextraction, which could be easily obtained from low-resolution video\nrecordings, thus more available than face recordings. We propose two networks\nusing the co-speech gestures cue to perform attentive listening on the target\nspeaker, one that implicitly fuses the co-speech gestures cue in the speaker\nextraction process, the other performs speech separation first, followed by\nexplicitly using the co-speech gestures cue to associate a separated speech to\nthe target speaker. The experimental results show that the co-speech gestures\ncue is informative in associating the target speaker, and the quality of the\nextracted speech shows significant improvements over the unprocessed mixture\nspeech.",
    "descriptor": "",
    "authors": [
      "Zexu Pan",
      "Xinyuan Qian",
      "Haizhou Li"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2203.16840"
  },
  {
    "id": "arXiv:2203.16843",
    "title": "A Hybrid Continuity Loss to Reduce Over-Suppression for Time-domain  Target Speaker Extraction",
    "abstract": "Speaker extraction algorithm extracts the target speech from a mixture speech\ncontaining interference speech and background noise. The extraction process\nsometimes over-suppresses the extracted target speech, which not only creates\nartifacts during listening but also harms the performance of downstream\nautomatic speech recognition algorithms. We propose a hybrid continuity loss\nfunction for time-domain speaker extraction algorithms to settle the\nover-suppression problem. On top of the waveform-level loss used for superior\nsignal quality, i.e., SI-SDR, we introduce a multi-resolution delta spectrum\nloss in the frequency-domain, to ensure the continuity of an extracted speech\nsignal, thus alleviating the over-suppression. We examine the hybrid continuity\nloss function using a time-domain audio-visual speaker extraction algorithm on\nthe YouTube LRS2-BBC dataset. Experimental results show that the proposed loss\nfunction reduces the over-suppression and improves the word error rate of\nspeech recognition on both clean and noisy two-speakers mixtures, without\nharming the reconstructed speech quality.",
    "descriptor": "\nComments: Submitted to Interspeech2022\n",
    "authors": [
      "Zexu Pan",
      "Meng Ge",
      "Haizhou Li"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2203.16843"
  },
  {
    "id": "arXiv:2203.16852",
    "title": "JETS: Jointly Training FastSpeech2 and HiFi-GAN for End to End Text to  Speech",
    "abstract": "In neural text-to-speech (TTS), two-stage system or a cascade of separately\nlearned models have shown synthesis quality close to human speech. For example,\nFastSpeech2 transforms an input text to a mel-spectrogram and then HiFi-GAN\ngenerates a raw waveform from a mel-spectogram where they are called an\nacoustic feature generator and a neural vocoder respectively. However, their\ntraining pipeline is somewhat cumbersome in that it requires a fine-tuning and\nan accurate speech-text alignment for optimal performance. In this work, we\npresent end-to-end text-to-speech (E2E-TTS) model which has a simplified\ntraining pipeline and outperforms a cascade of separately learned models.\nSpecifically, our proposed model is jointly trained FastSpeech2 and HiFi-GAN\nwith an alignment module. Since there is no acoustic feature mismatch between\ntraining and inference, it does not requires fine-tuning. Furthermore, we\nremove dependency on an external speech-text alignment tool by adopting an\nalignment learning objective in our joint training framework. Experiments on\nLJSpeech corpus shows that the proposed model outperforms publicly available,\nstate-of-the-art implementations of ESPNet2-TTS on subjective evaluation (MOS)\nand some objective evaluations.",
    "descriptor": "\nComments: Submitted to INTERSPEECH 2022\n",
    "authors": [
      "Dan Lim",
      "Sunghee Jung",
      "Eesung Kim"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2203.16852"
  },
  {
    "id": "arXiv:2203.16861",
    "title": "On Reconfiguration Graph of Independent Sets under Token Sliding",
    "abstract": "An independent set of a graph $G$ is a vertex subset $I$ such that there is\nno edge joining any two vertices in $I$. Imagine that a token is placed on each\nvertex of an independent set of $G$. The $\\mathsf{TS}$- ($\\mathsf{TS}_k$-)\nreconfiguration graph of $G$ takes all non-empty independent sets (of size $k$)\nas its nodes, where $k$ is some given positive integer. Two nodes are adjacent\nif one can be obtained from the other by sliding a token on some vertex to one\nof its unoccupied neighbors. This paper focuses on the structure and\nrealizability of these reconfiguration graphs. More precisely, we study two\nmain questions for a given graph $G$: (1) Whether the\n$\\mathsf{TS}_k$-reconfiguration graph of $G$ belongs to some graph class\n$\\mathcal{G}$ (including complete graphs, paths, cycles, complete bipartite\ngraphs, and connected split graphs) and (2) If $G$ satisfies some property\n$\\mathcal{P}$ (including $s$-partitedness, planarity, Eulerianity, girth, and\nthe clique's size), whether the corresponding $\\mathsf{TS}$- ($\\mathsf{TS}_k$-)\nreconfiguration graph of $G$ also satisfies $\\mathcal{P}$, and vice versa.",
    "descriptor": "\nComments: 17 pages, 12 figures\n",
    "authors": [
      "David Avis",
      "Duc A. Hoang"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2203.16861"
  },
  {
    "id": "arXiv:2203.16865",
    "title": "Error estimates for the numerical approximation of a non-smooth  quasilinear elliptic control problem",
    "abstract": "In this paper, we carry out the numerical analysis of a non-smooth\nquasilinear elliptic optimal control problem, where the coefficient in the\ndivergence term of the corresponding state equation is a finitely $PC^2$\n(continuous and $C^2$ apart from finitely many points) function in the state\nvariable. Although the nonlinearity of the quasilinear elliptic equation is\nnon-smooth, the corresponding control-to-state operator is of class $C^1$ but\nnot of class $C^2$. Analogously, the discrete control-to-state operators\nassociated with the approximated control problems are proven to be of class\n$C^1$ only. An explicit formula of a second-order generalized derivative of the\ncost functional is also established. We then exploit a second-order sufficient\noptimality condition to prove a priori error estimates for a variational and a\npiecewise constant approximation of the continuous optimal control problem.",
    "descriptor": "",
    "authors": [
      "Christian Clason",
      "Vu Huu Nhu",
      "Arnd R\u00f6sch"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2203.16865"
  },
  {
    "id": "arXiv:2203.16868",
    "title": "Memory-Efficient Training of RNN-Transducer with Sampled Softmax",
    "abstract": "RNN-Transducer has been one of promising architectures for end-to-end\nautomatic speech recognition. Although RNN-Transducer has many advantages\nincluding its strong accuracy and streaming-friendly property, its high memory\nconsumption during training has been a critical problem for development. In\nthis work, we propose to apply sampled softmax to RNN-Transducer, which\nrequires only a small subset of vocabulary during training thus saves its\nmemory consumption. We further extend sampled softmax to optimize memory\nconsumption for a minibatch, and employ distributions of auxiliary CTC losses\nfor sampling vocabulary to improve model accuracy. We present experimental\nresults on LibriSpeech, AISHELL-1, and CSJ-APS, where sampled softmax greatly\nreduces memory consumption and still maintains the accuracy of the baseline\nmodel.",
    "descriptor": "\nComments: Submitted to INTERSPEECH 2022\n",
    "authors": [
      "Jaesong Lee",
      "Lukas Lee",
      "Shinji Watanabe"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.16868"
  },
  {
    "id": "arXiv:2203.16900",
    "title": "Transducing paths in graph classes with unbounded shrubdepth",
    "abstract": "Transductions are a general formalism for expressing transformations of\ngraphs (and more generally, of relational structures) in logic. We prove that a\ngraph class $\\mathscr{C}$ can be $\\mathsf{FO}$-transduced from a class of\nbounded-height trees (that is, has bounded shrubdepth) if, and only if, from\n$\\mathscr{C}$ one cannot $\\mathsf{FO}$-transduce the class of all paths. This\nestablishes one of the three remaining open questions posed by Blumensath and\nCourcelle about the $\\mathsf{MSO}$-transduction quasi-order, even in the\nstronger form that concerns $\\mathsf{FO}$-transductions instead of\n$\\mathsf{MSO}$-transductions.\nThe backbone of our proof is a graph-theoretic statement that says the\nfollowing: If a graph $G$ excludes a path, the bipartite complement of a path,\nand a half-graph as semi-induced subgraphs, then the vertex set of $G$ can be\npartitioned into a bounded number of parts so that every part induces a cograph\nof bounded height, and every pair of parts semi-induce a bi-cograph of bounded\nheight. This statement may be of independent interest; for instance, it implies\nthat the graphs in question form a class that is linearly $\\chi$-bounded.",
    "descriptor": "",
    "authors": [
      "Micha\u0142 Pilipczuk",
      "Patrice Ossona de Mendez",
      "Sebastian Siebertz"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)",
      "Logic in Computer Science (cs.LO)",
      "Logic (math.LO)"
    ],
    "url": "https://arxiv.org/abs/2203.16900"
  },
  {
    "id": "arXiv:2203.16940",
    "title": "Direction of Arrival Estimation of Sound Sources Using Icosahedral CNNs",
    "abstract": "In this paper, we present a new model for Direction of Arrival (DOA)\nestimation of sound sources based on an Icosahedral Convolutional Neural\nNetwork (CNN) applied over SRP-PHAT power maps computed from the signals\nreceived by a microphone array. This icosahedral CNN is equivariant to the 60\nrotational symmetries of the icosahedron, which represent a good approximation\nof the continuous space of spherical rotations, and can be implemented using\nstandard 2D convolutional layers, having a lower computational cost than most\nof the spherical CNNs. In addition, instead of using fully connected layers\nafter the icosahedral convolutions, we propose a new soft-argmax function that\ncan be seen as a differentiable version of the argmax function and allows us to\nsolve the DOA estimation as a regression problem interpreting the output of the\nconvolutional layers as a probability distribution. We prove that using models\nthat fit the equivariances of the problem allows us to outperform other\nstate-of-the-art models with a lower computational cost and more robustness,\nobtaining root mean square localization errors lower than 10{\\deg} even in\nscenarios with a reverberation time $T_{60}$ of 1.5 s.",
    "descriptor": "\nComments: Submitted to IEEE/ACM Transactions on Audio Speech and Language Processing. The code to reproduce this work can be found in our GitHub repository: this https URL\n",
    "authors": [
      "David Diaz-Guerra",
      "Antonio Miguel",
      "Jose R. Beltran"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2203.16940"
  },
  {
    "id": "arXiv:2203.16944",
    "title": "A data-driven approach for the closure of RANS models by the divergence  of the Reynolds Stress Tensor",
    "abstract": "In the present paper a new data-driven model to close and increase accuracy\nof RANS equations is proposed. It is based on the direct approximation of the\ndivergence of the Reynolds Stress Tensor (RST) through a Neural Network (NN).\nThis choice is driven by the presence of the divergence of RST in the RANS\nequations. Furthermore, once this data-driven approach is trained, there is no\nneed to run any turbulence model to close the equations. Finally, it is well\nknown that a good approximation of a function it is not necessarily a good\napproximation of its derivative. The architecture and inputs choices of the\nproposed network guarantee both Galilean and coordinates-frame rotation\ninvariances by looking to a vector basis expansion of the divergence of the\nRST. Two well-known test cases are used to show advantages of the proposed\nmethod compared to classic turbulence models.",
    "descriptor": "\nComments: 26 pages, 13 figures\n",
    "authors": [
      "Stefano Berrone",
      "Davide Oberto"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2203.16944"
  },
  {
    "id": "arXiv:2203.16996",
    "title": "Measuring hand use in the home after cervical spinal cord injury using  egocentric video",
    "abstract": "Background: Egocentric video has recently emerged as a potential solution for\nmonitoring hand function in individuals living with tetraplegia in the\ncommunity, especially for its ability to detect functional use in the home\nenvironment. Objective: To develop and validate a wearable vision-based system\nfor measuring hand use in the home among individuals living with tetraplegia.\nMethods: Several deep learning algorithms for detecting functional hand-object\ninteractions were developed and compared. The most accurate algorithm was used\nto extract measures of hand function from 65 hours of unscripted video recorded\nat home by 20 participants with tetraplegia. These measures were: the\npercentage of interaction time over total recording time (Perc); the average\nduration of individual interactions (Dur); the number of interactions per hour\n(Num). To demonstrate the clinical validity of the technology, egocentric\nmeasures were correlated with validated clinical assessments of hand function\nand independence (Graded Redefined Assessment of Strength, Sensibility and\nPrehension - GRASSP, Upper Extremity Motor Score - UEMS, and Spinal Cord\nIndependent Measure - SCIM). Results: Hand-object interactions were\nautomatically detected with a median F1-score of 0.80 (0.67-0.87). Our results\ndemonstrated that higher UEMS and better prehension were related to greater\ntime spent interacting, whereas higher SCIM and better hand sensation resulted\nin a higher number of interactions performed during the egocentric video\nrecordings. Conclusions: For the first time, measures of hand function\nautomatically estimated in an unconstrained environment in individuals with\ntetraplegia have been validated against internationally accepted measures of\nhand function. Future work will necessitate a formal evaluation of the\nreliability and responsiveness of the egocentric-based performance measures for\nhand use.",
    "descriptor": "",
    "authors": [
      "Andrea Bandini",
      "Mehdy Dousty",
      "Sander L. Hitzig",
      "B. Catharine Craven",
      "Sukhvinder Kalsi-Ryan",
      "Jos\u00e9 Zariffa"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.16996"
  },
  {
    "id": "arXiv:2203.17001",
    "title": "SingAug: Data Augmentation for Singing Voice Synthesis with  Cycle-consistent Training Strategy",
    "abstract": "Deep learning based singing voice synthesis (SVS) systems have been\ndemonstrated to flexibly generate singing with better qualities, compared to\nconventional statistical parametric based methods. However, neural systems are\ngenerally data-hungry and have difficulty to reach reasonable singing quality\nwith limited public available training data. In this work, we explore different\ndata augmentation methods to boost the training of SVS systems, including\nseveral strategies customized to SVS based on pitch augmentation and mix-up\naugmentation. To further stabilize the training, we introduce the\ncycle-consistent training strategy. Extensive experiments on two public singing\ndatabases demonstrate that our proposed augmentation methods and the\nstabilizing training strategy can significantly improve the performance on both\nobjective and subjective evaluations.",
    "descriptor": "",
    "authors": [
      "Shuai Guo",
      "Jiatong Shi",
      "Tao Qian",
      "Shinji Watanabe",
      "Qin Jin"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2203.17001"
  },
  {
    "id": "arXiv:2203.17004",
    "title": "Speech Enhancement with Score-Based Generative Models in the Complex  STFT Domain",
    "abstract": "Score-based generative models (SGMs) have recently shown impressive results\nfor difficult generative tasks such as the unconditional and conditional\ngeneration of natural images and audio signals. In this work, we extend these\nmodels to the complex short-time Fourier transform (STFT) domain, proposing a\nnovel training task for speech enhancement using a complex-valued deep neural\nnetwork. We derive this training task within the formalism of stochastic\ndifferential equations, thereby enabling the use of predictor-corrector\nsamplers. We provide alternative formulations inspired by previous publications\non using SGMs for speech enhancement, avoiding the need for any prior\nassumptions on the noise distribution and making the training task purely\ngenerative which, as we show, results in improved enhancement performance.",
    "descriptor": "\nComments: Submitted to INTERSPEECH 2022\n",
    "authors": [
      "Simon Welker",
      "Julius Richter",
      "Timo Gerkmann"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2203.17004"
  },
  {
    "id": "arXiv:2203.17006",
    "title": "Quantum simulation of real-space dynamics",
    "abstract": "Quantum simulation is a prominent application of quantum computers. While\nthere is extensive previous work on simulating finite-dimensional systems, less\nis known about quantum algorithms for real-space dynamics. We conduct a\nsystematic study of such algorithms. In particular, we show that the dynamics\nof a $d$-dimensional Schr\\\"{o}dinger equation with $\\eta$ particles can be\nsimulated with gate complexity $\\tilde{O}\\bigl(\\eta d F\n\\text{poly}(\\log(g'/\\epsilon))\\bigr)$, where $\\epsilon$ is the discretization\nerror, $g'$ controls the higher-order derivatives of the wave function, and $F$\nmeasures the time-integrated strength of the potential. Compared to the best\nprevious results, this exponentially improves the dependence on $\\epsilon$ and\n$g'$ from $\\text{poly}(g'/\\epsilon)$ to $\\text{poly}(\\log(g'/\\epsilon))$ and\npolynomially improves the dependence on $T$ and $d$, while maintaining best\nknown performance with respect to $\\eta$. For the case of Coulomb interactions,\nwe give an algorithm using $\\eta^{3}(d+\\eta)T\\text{poly}(\\log(\\eta\ndTg'/(\\Delta\\epsilon)))/\\Delta$ one- and two-qubit gates, and another using\n$\\eta^{3}(4d)^{d/2}T\\text{poly}(\\log(\\eta dTg'/(\\Delta\\epsilon)))/\\Delta$ one-\nand two-qubit gates and QRAM operations, where $T$ is the evolution time and\nthe parameter $\\Delta$ regulates the unbounded Coulomb interaction. We give\napplications to several computational problems, including faster real-space\nsimulation of quantum chemistry, rigorous analysis of discretization error for\nsimulation of a uniform electron gas, and a quadratic improvement to a quantum\nalgorithm for escaping saddle points in nonconvex optimization.",
    "descriptor": "",
    "authors": [
      "Andrew M. Childs",
      "Jiaqi Leng",
      "Tongyang Li",
      "Jin-Peng Liu",
      "Chenyi Zhang"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2203.17006"
  },
  {
    "id": "arXiv:2203.17019",
    "title": "DeepFry: Identifying Vocal Fry Using Deep Neural Networks",
    "abstract": "Vocal fry or creaky voice refers to a voice quality characterized by\nirregular glottal opening and low pitch. It occurs in diverse languages and is\nprevalent in American English, where it is used not only to mark phrase\nfinality, but also sociolinguistic factors and affect. Due to its irregular\nperiodicity, creaky voice challenges automatic speech processing and\nrecognition systems, particularly for languages where creak is frequently used.\nThis paper proposes a deep learning model to detect creaky voice in fluent\nspeech. The model is composed of an encoder and a classifier trained together.\nThe encoder takes the raw waveform and learns a representation using a\nconvolutional neural network. The classifier is implemented as a multi-headed\nfully-connected network trained to detect creaky voice, voicing, and pitch,\nwhere the last two are used to refine creak prediction. The model is trained\nand tested on speech of American English speakers, annotated for creak by\ntrained phoneticians.\nWe evaluated the performance of our system using two encoders: one is\ntailored for the task, and the other is based on a state-of-the-art\nunsupervised representation. Results suggest our best-performing system has\nimproved recall and F1 scores compared to previous methods on unseen data.",
    "descriptor": "\nComments: under submission to Interspeech 2022\n",
    "authors": [
      "Bronya R. Chernyak",
      "Talia Ben Simon",
      "Yael Segal",
      "Jeremy Steffman",
      "Eleanor Chodroff",
      "Jennifer S. Cole",
      "Joseph Keshet"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2203.17019"
  },
  {
    "id": "arXiv:2203.17028",
    "title": "Differentially Private Federated Learning via Reconfigurable Intelligent  Surface",
    "abstract": "Federated learning (FL), as a disruptive machine learning paradigm, enables\nthe collaborative training of a global model over decentralized local datasets\nwithout sharing them. It spans a wide scope of applications from\nInternet-of-Things (IoT) to biomedical engineering and drug discovery. To\nsupport low-latency and high-privacy FL over wireless networks, in this paper,\nwe propose a reconfigurable intelligent surface (RIS) empowered over-the-air FL\nsystem to alleviate the dilemma between learning accuracy and privacy. This is\nachieved by simultaneously exploiting the channel propagation reconfigurability\nwith RIS for boosting the receive signal power, as well as waveform\nsuperposition property with over-the-air computation (AirComp) for fast model\naggregation. By considering a practical scenario where high-dimensional local\nmodel updates are transmitted across multiple communication blocks, we\ncharacterize the convergence behaviors of the differentially private federated\noptimization algorithm. We further formulate a system optimization problem to\noptimize the learning accuracy while satisfying privacy and power constraints\nvia the joint design of transmit power, artificial noise, and phase shifts at\nRIS, for which a two-step alternating minimization framework is developed.\nSimulation results validate our systematic, theoretical, and algorithmic\nachievements and demonstrate that RIS can achieve a better trade-off between\nprivacy and accuracy for over-the-air FL systems.",
    "descriptor": "\nComments: 16 pages, 11 figures\n",
    "authors": [
      "Yuhan Yang",
      "Yong Zhou",
      "Youlong Wu",
      "Yuanming Shi"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Cryptography and Security (cs.CR)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.17028"
  },
  {
    "id": "arXiv:2203.17036",
    "title": "Partial Coupling of Optimal Transport for Spoken Language Identification",
    "abstract": "In order to reduce domain discrepancy to improve the performance of\ncross-domain spoken language identification (SLID) system, as an unsupervised\ndomain adaptation (UDA) method, we have proposed a joint distribution alignment\n(JDA) model based on optimal transport (OT). A discrepancy measurement based on\nOT was adopted for JDA between training and test data sets. In our previous\nstudy, it was supposed that the training and test sets share the same label\nspace. However, in real applications, the label space of the test set is only a\nsubset of that of the training set. Fully matching training and test domains\nfor distribution alignment may introduce negative domain transfer. In this\npaper, we propose an JDA model based on partial optimal transport (POT), i.e.,\nonly partial couplings of OT are allowed during JDA. Moreover, since the label\nof test data is unknown, in the POT, a soft weighting on the coupling based on\ntransport cost is adaptively set during domain alignment. Experiments were\ncarried out on a cross-domain SLID task to evaluate the proposed UDA. Results\nshowed that our proposed UDA significantly improved the performance due to the\nconsideration of the partial couplings in OT.",
    "descriptor": "\nComments: This work was submitted to INTERSPEECH 2022\n",
    "authors": [
      "Xugang Lu",
      "Peng Shen",
      "Yu Tsao",
      "Hisashi Kawai"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.17036"
  },
  {
    "id": "arXiv:2203.17040",
    "title": "Potential impact of CV-QKD integration on classical WDM network capacity",
    "abstract": "Continuous-variable quantum key distribution (CV-QKD) could allow QKD and\nclassical optical signals physically sharing the same optical fibers in\nexisting networks. However, Raman scattering imposes a limit on the optical\npower, which in turn impacts the network capacity for classical traffic in\npresence of CV-QKD. Network-planning simulations indicate that maxing out the\nCV-QKD capacity in an optical link can adversely impact its classical capacity.\nAlthough preliminary, these results show that designing a mixed classical and\nCV-QKD network will require dedicated planning heuristics and tools that\nspecifically seek a compromise between classical and CV-QKD traffics.",
    "descriptor": "",
    "authors": [
      "C\u00e9dric Ware",
      "Rapha\u00ebl Aymeric",
      "Chaima Zidi",
      "Mounia Lourdiane"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2203.17040"
  },
  {
    "id": "arXiv:2203.17056",
    "title": "Weakly toll convexity and proper interval graphs",
    "abstract": "A walk $u_0u_1 \\ldots u_{k-1}u_k$ is a \\textit{weakly toll walk} if $u_0u_i\n\\in E(G)$ implies $u_i = u_1$ and $u_ju_k\\in E(G)$ implies $u_j=u_{k-1}$. A set\n$S$ of vertices of $G$ is {\\it weakly toll convex} if for any two non-adjacent\nvertices $x,y \\in S$ any vertex in a weakly toll walk between $x$ and $y$ is\nalso in $S$. The {\\em weakly toll convexity} is the graph convexity space\ndefined over weakly toll convex sets. Many studies are devoted to determine if\na graph equipped with a convexity space is a {\\em convex geometry}. An\n\\emph{extreme vertex} is an element $x$ of a convex set $S$ such that the set\n$S\\backslash\\{x\\}$ is also convex. A graph convexity space is said to be a\nconvex geometry if it satisfies the Minkowski-Krein-Milman property, which\nstates that every convex set is the convex hull of its extreme vertices. It is\nknown that chordal, Ptolemaic, weakly polarizable, and interval graphs can be\ncharacterized as convex geometries with respect to the monophonic, geodesic,\n$m^3$, and toll convexities, respectively. Other important classes of graphs\ncan also be characterized in this way. In this paper, we prove that a graph is\na convex geometry with respect to the weakly toll convexity if and only if it\nis a proper interval graph. Furthermore, some well-known graph invariants are\nstudied with respect to the weakly toll convexity.",
    "descriptor": "\nComments: 19 pages\n",
    "authors": [
      "Mitre C. Dourado",
      "Marisa Gutierrez",
      "F\u00e1bio Protti",
      "Silvia Tondato"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2203.17056"
  },
  {
    "id": "arXiv:2203.17065",
    "title": "Wind Farm Layout Optimisation using Set Based Multi-objective Bayesian  Optimisation",
    "abstract": "Wind energy is one of the cleanest renewable electricity sources and can help\nin addressing the challenge of climate change. One of the drawbacks of\nwind-generated energy is the large space necessary to install a wind farm; this\narises from the fact that placing wind turbines in a limited area would hinder\ntheir productivity and therefore not be economically convenient. This naturally\nleads to an optimisation problem, which has three specific challenges: (1)\nmultiple conflicting objectives (2) computationally expensive simulation models\nand (3) optimisation over design sets instead of design vectors. The first and\nsecond challenges can be addressed by using surrogate-assisted e.g.\\ Bayesian\nmulti-objective optimisation. However, the traditional Bayesian optimisation\ncannot be applied as the optimisation function in the problem relies on design\nsets instead of design vectors. This paper extends the applicability of\nBayesian multi-objective optimisation to set based optimisation for solving the\nwind farm layout problem. We use a set-based kernel in Gaussian process to\nquantify the correlation between wind farms (with a different number of\nturbines). The results on the given data set of wind energy and direction\nclearly show the potential of using set-based Bayesian multi-objective\noptimisation.",
    "descriptor": "",
    "authors": [
      "Tinkle Chugh",
      "Endi Ymeraj"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2203.17065"
  },
  {
    "id": "arXiv:2203.17066",
    "title": "Cross-modal Learning of Graph Representations using Radar Point Cloud  for Long-Range Gesture Recognition",
    "abstract": "Gesture recognition is one of the most intuitive ways of interaction and has\ngathered particular attention for human computer interaction. Radar sensors\npossess multiple intrinsic properties, such as their ability to work in low\nillumination, harsh weather conditions, and being low-cost and compact, making\nthem highly preferable for a gesture recognition solution. However, most\nliterature work focuses on solutions with a limited range that is lower than a\nmeter. We propose a novel architecture for a long-range (1m - 2m) gesture\nrecognition solution that leverages a point cloud-based cross-learning approach\nfrom camera point cloud to 60-GHz FMCW radar point cloud, which allows learning\nbetter representations while suppressing noise. We use a variant of Dynamic\nGraph CNN (DGCNN) for the cross-learning, enabling us to model relationships\nbetween the points at a local and global level and to model the temporal\ndynamics a Bi-LSTM network is employed. In the experimental results section, we\ndemonstrate our model's overall accuracy of 98.4% for five gestures and its\ngeneralization capability.",
    "descriptor": "\nComments: Submitted to IEEE Sensor Array and Multichannel Signal Processing Workshop (SAM 2022)\n",
    "authors": [
      "Souvik Hazra",
      "Hao Feng",
      "Gamze Naz Kiprit",
      "Michael Stephan",
      "Lorenzo Servadei",
      "Robert Wille",
      "Robert Weigel",
      "Avik Santra"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.17066"
  },
  {
    "id": "arXiv:2203.17068",
    "title": "EEND-SS: Joint End-to-End Neural Speaker Diarization and Speech  Separation for Flexible Number of Speakers",
    "abstract": "In this paper, we present a novel framework that jointly performs speaker\ndiarization, speech separation, and speaker counting. Our proposed method\ncombines end-to-end speaker diarization and speech separation methods, namely,\nEnd-to-End Neural Speaker Diarization with Encoder-Decoder-based Attractor\ncalculation (EEND-EDA) and the Convolutional Time-domain Audio Separation\nNetwork (ConvTasNet) as multi-tasking joint model. We also propose the multiple\n1x1 convolutional layer architecture for estimating the separation masks\ncorresponding to the number of speakers, and a post-processing technique for\nrefining the separated speech signal with speech activity. Experiments using\nLibriMix dataset show that our proposed method outperforms the baselines in\nterms of diarization and separation performance for both fixed and flexible\nnumbers of speakers, as well as speaker counting performance for flexible\nnumbers of speakers. All materials will be open-sourced and reproducible in\nESPnet toolkit.",
    "descriptor": "\nComments: submitted to INTERSPEECH 2022\n",
    "authors": [
      "Yushi Ueda",
      "Soumi Maiti",
      "Shinji Watanabe",
      "Chunlei Zhang",
      "Meng Yu",
      "Shi-Xiong Zhang",
      "Yong Xu"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2203.17068"
  },
  {
    "id": "arXiv:2203.17089",
    "title": "Quantum-Aided Meta-Learning for Bayesian Binary Neural Networks via Born  Machines",
    "abstract": "Near-term noisy intermediate-scale quantum circuits can efficiently implement\nimplicit probabilistic models in discrete spaces, supporting distributions that\nare practically infeasible to sample from using classical means. One of the\npossible applications of such models, also known as Born machines, is\nprobabilistic inference, which is at the core of Bayesian methods. This paper\nstudies the use of Born machines for the problem of training binary Bayesian\nneural networks. In the proposed approach, a Born machine is used to model the\nvariational distribution of the binary weights of the neural network, and data\nfrom multiple tasks is used to reduce training data requirements on new tasks.\nThe method combines gradient-based meta-learning and variational inference via\nBorn machines, and is shown in a prototypical regression problem to outperform\nconventional joint learning strategies.",
    "descriptor": "\nComments: submitted for publication\n",
    "authors": [
      "Ivana Nikoloska",
      "Osvaldo Simeone"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.17089"
  },
  {
    "id": "arXiv:2203.17143",
    "title": "Quantitative convergence of the vectorial Allen-Cahn equation towards  multiphase mean curvature flow",
    "abstract": "Phase-field models such as the Allen-Cahn equation may give rise to the\nformation and evolution of geometric shapes, a phenomenon that may be analyzed\nrigorously in suitable scaling regimes. In its sharp-interface limit, the\nvectorial Allen-Cahn equation with a potential with $N\\geq 3$ distinct minima\nhas been conjectured to describe the evolution of branched interfaces by\nmultiphase mean curvature flow.\nIn the present work, we give a rigorous proof for this statement in two and\nthree ambient dimensions and for a suitable class of potentials: As long as a\nstrong solution to multiphase mean curvature flow exists, solutions to the\nvectorial Allen-Cahn equation with well-prepared initial data converge towards\nmultiphase mean curvature flow in the limit of vanishing interface width\nparameter $\\varepsilon\\searrow 0$. We even establish the rate of convergence\n$O(\\varepsilon^{1/2})$.\nOur approach is based on the gradient flow structure of the Allen-Cahn\nequation and its limiting motion: Building on the recent concept of \"gradient\nflow calibrations\" for multiphase mean curvature flow, we introduce a notion of\nrelative entropy for the vectorial Allen-Cahn equation with multi-well\npotential. This enables us to overcome the limitations of other approaches,\ne.g. avoiding the need for a stability analysis of the Allen-Cahn operator or\nadditional convergence hypotheses for the energy at positive times.",
    "descriptor": "\nComments: 53 pages\n",
    "authors": [
      "Julian Fischer",
      "Alice Marveggio"
    ],
    "subjectives": [
      "Analysis of PDEs (math.AP)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2203.17143"
  },
  {
    "id": "arXiv:2203.17145",
    "title": "Convex Parameterization of Stabilizing Controllers and its LMI-based  Computation via Filtering",
    "abstract": "Various new implicit parameterizations for stabilizing controllers that allow\none to impose structural constraints on the controller have been proposed\nlately. They are convex but infinite-dimensional, formulated in the frequency\ndomain with no available efficient methods for computation. In this paper, we\nintroduce a kernel version of the Youla parameterization to characterize the\nset of stabilizing controllers. It features a single affine constraint, which\nallows us to recast the controller parameterization as a novel robust filtering\nproblem. This makes it possible to derive the first efficient Linear Matrix\nInequality (LMI) implicit parametrization of stabilizing controllers. Our LMI\ncharacterization not only admits efficient numerical computation, but also\nguarantees a full-order stabilizing dynamical controller that is efficient for\npractical deployment. Numerical experiments demonstrate that our LMI can be\norders of magnitude faster to solve than the existing closed-loop\nparameterizations.",
    "descriptor": "\nComments: 11 pages, 5 figures, and two tables; code available at this https URL\n",
    "authors": [
      "Mauricio C. de Oliveira",
      "Yang Zheng"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2203.17145"
  },
  {
    "id": "arXiv:2203.17153",
    "title": "An energy-based deep splitting method for the nonlinear filtering  problem",
    "abstract": "The main goal of this paper is to approximately solve the nonlinear filtering\nproblem through deep learning. This is achieved by solving the Zakai equation\nby a deep splitting method, previously developed for approximate solution of\n(stochastic) partial differential equations. This is combined with an\nenergy-based model for the approximation of functions by a deep neural network.\nThis results in a computationally fast filter that takes observations as input\nand that does not require re-training when new observations are received. The\nmethod is tested on three examples, one linear Gaussian and two nonlinear. The\nmethod shows promising performance when benchmarked against the Kalman filter\nand the bootstrap particle filter.",
    "descriptor": "\nComments: 20 pages, 5 figures\n",
    "authors": [
      "Kasper B\u00e5gmark",
      "Adam Andersson",
      "Stig Larsson"
    ],
    "subjectives": [
      "Computation (stat.CO)",
      "Numerical Analysis (math.NA)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.17153"
  },
  {
    "id": "arXiv:2203.17164",
    "title": "Recovering models of open quantum systems from data via polynomial  optimization: Towards globally convergent quantum system identification",
    "abstract": "Current quantum devices suffer imperfections as a result of fabrication, as\nwell as noise and dissipation as a result of coupling to their immediate\nenvironments. Because of this, it is often difficult to obtain accurate models\nof their dynamics from first principles. An alternative is to extract such\nmodels from time-series measurements of their behavior. Here, we formulate this\nsystem-identification problem as a polynomial optimization problem. Recent\nadvances in optimization have provided globally convergent solvers for this\nclass of problems, which using our formulation prove estimates of the Kraus map\nor the Lindblad equation. We include an overview of the state-of-the-art\nalgorithms, bounds, and convergence rates, and illustrate the use of this\napproach to modeling open quantum systems.",
    "descriptor": "",
    "authors": [
      "Denys I. Bondar",
      "Zakhar Popovych",
      "Kurt Jacobs",
      "Georgios Korpas",
      "Jakub Marecek"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2203.17164"
  },
  {
    "id": "arXiv:2203.17190",
    "title": "Mixed-Phoneme BERT: Improving BERT with Mixed Phoneme and Sup-Phoneme  Representations for Text to Speech",
    "abstract": "Recently, leveraging BERT pre-training to improve the phoneme encoder in text\nto speech (TTS) has drawn increasing attention. However, the works apply\npre-training with character-based units to enhance the TTS phoneme encoder,\nwhich is inconsistent with the TTS fine-tuning that takes phonemes as input.\nPre-training only with phonemes as input can alleviate the input mismatch but\nlack the ability to model rich representations and semantic information due to\nlimited phoneme vocabulary. In this paper, we propose MixedPhoneme BERT, a\nnovel variant of the BERT model that uses mixed phoneme and sup-phoneme\nrepresentations to enhance the learning capability. Specifically, we merge the\nadjacent phonemes into sup-phonemes and combine the phoneme sequence and the\nmerged sup-phoneme sequence as the model input, which can enhance the model\ncapacity to learn rich contextual representations. Experiment results\ndemonstrate that our proposed Mixed-Phoneme BERT significantly improves the TTS\nperformance with 0.30 CMOS gain compared with the FastSpeech 2 baseline. The\nMixed-Phoneme BERT achieves 3x inference speedup and similar voice quality to\nthe previous TTS pre-trained model PnG BERT",
    "descriptor": "\nComments: submitted to interspeech 2022\n",
    "authors": [
      "Guangyan Zhang",
      "Kaitao Song",
      "Xu Tan",
      "Daxin Tan",
      "Yuzi Yan",
      "Yanqing Liu",
      "Gang Wang",
      "Wei Zhou",
      "Tao Qin",
      "Tan Lee",
      "Sheng Zhao"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.17190"
  },
  {
    "id": "arXiv:2203.17207",
    "title": "A Proof of the Kahn-Kalai Conjecture",
    "abstract": "We prove the \"expectation-threshold\" conjecture of Kahn and Kalai.",
    "descriptor": "",
    "authors": [
      "Jinyoung Park",
      "Huy Tuan Pham"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2203.17207"
  },
  {
    "id": "arXiv:2203.17215",
    "title": "A simplified nonsmooth nonconvex bundle method with applications to  security-constrained ACOPF problems",
    "abstract": "An optimization algorithm for a group of nonsmooth nonconvex problems\ninspired by two-stage stochastic programming problems is proposed. The main\nchallenges for these problems include (1) the problems lack the popular\nlower-type properties such as prox-regularity assumed in many nonsmooth\nnonconvex optimization algorithms, (2) the objective can not be analytically\nexpressed and (3) the evaluation of function values and subgradients are\ncomputationally expensive. To address these challenges, this report first\nexamines the properties that exist in many two-stage problems, specifically\nupper-C^2 objectives. Then, we show that quadratic penalty method for\nsecurity-constrained alternating current optimal power flow (SCACOPF)\ncontingency problems can make the contingency solution functions upper-C^2 .\nBased on these observations, a simplified bundle algorithm that bears\nsimilarity to sequential quadratic programming (SQP) method is proposed. It is\nmore efficient in implementation and computation compared to conventional\nbundle methods. Global convergence analysis of the algorithm is presented under\nnovel and reasonable assumptions. The proposed algorithm therefore fills the\ngap of theoretical convergence for some smoothed SCACOPF problems. The\ninconsistency that might arise in our treatment of the constraints are\naddressed through a penalty algorithm whose convergence analysis is also\nprovided. Finally, theoretical capabilities and numerical performance of the\nalgorithm are demonstrated through numerical examples.",
    "descriptor": "",
    "authors": [
      "Jingyi Wang",
      "Cosmin G. Petra"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2203.17215"
  },
  {
    "id": "arXiv:2203.17218",
    "title": "Improved Relation Networks for End-to-End Speaker Verification and  Identification",
    "abstract": "Speaker identification systems in a real-world scenario are tasked to\nidentify a speaker amongst a set of enrolled speakers given just a few samples\nfor each enrolled speaker. This paper demonstrates the effectiveness of\nmeta-learning and relation networks for this use case. We propose improved\nrelation networks for speaker verification and few-shot (unseen) speaker\nidentification. The use of relation networks facilitates joint training of the\nfrontend speaker encoder and the backend model. Inspired by the use of\nprototypical networks in speaker verification and to increase the\ndiscriminability of the speaker embeddings, we train the model to classify\nsamples in the current episode amongst all speakers present in the training\nset. Furthermore, we propose a new training regime for faster model convergence\nby extracting more information from a given meta-learning episode with\nnegligible extra computation. We evaluate the proposed techniques on VoxCeleb,\nSITW and VCTK datasets on the tasks of speaker verification and unseen speaker\nidentification. The proposed approach outperforms the existing approaches\nconsistently on both tasks.",
    "descriptor": "\nComments: Submitted to Interspeech 2022\n",
    "authors": [
      "Ashutosh Chaubey",
      "Sparsh Sinha",
      "Susmita Ghose"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2203.17218"
  },
  {
    "id": "arXiv:2203.17226",
    "title": "A Derivation of Nesterov's Accelerated Gradient Algorithm from Optimal  Control Theory",
    "abstract": "Nesterov's accelerated gradient algorithm is derived from first principles.\nThe first principles are founded on the recently-developed optimal control\ntheory for optimization. This theory frames an optimization problem as an\noptimal control problem whose trajectories generate various continuous-time\nalgorithms. The algorithmic trajectories satisfy the necessary conditions for\noptimal control. The necessary conditions produce a controllable dynamical\nsystem for accelerated optimization. Stabilizing this system via a quadratic\ncontrol Lyapunov function generates an ordinary differential equation. An Euler\ndiscretization of the resulting differential equation produces Nesterov's\nalgorithm. In this context, this result solves the purported mystery\nsurrounding the algorithm.",
    "descriptor": "\nComments: 7 pages. arXiv admin note: text overlap with arXiv:1902.09004\n",
    "authors": [
      "I. M. Ross"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.17226"
  },
  {
    "id": "arXiv:2203.17241",
    "title": "Bayesian optimization with known experimental and design constraints for  chemistry applications",
    "abstract": "Optimization strategies driven by machine learning, such as Bayesian\noptimization, are being explored across experimental sciences as an efficient\nalternative to traditional design of experiment. When combined with automated\nlaboratory hardware and high-performance computing, these strategies enable\nnext-generation platforms for autonomous experimentation. However, the\npractical application of these approaches is hampered by a lack of flexible\nsoftware and algorithms tailored to the unique requirements of chemical\nresearch. One such aspect is the pervasive presence of constraints in the\nexperimental conditions when optimizing chemical processes or protocols, and in\nthe chemical space that is accessible when designing functional molecules or\nmaterials. Although many of these constraints are known a priori, they can be\ninterdependent, non-linear, and result in non-compact optimization domains. In\nthis work, we extend our experiment planning algorithms Phoenics and Gryffin\nsuch that they can handle arbitrary known constraints via an intuitive and\nflexible interface. We benchmark these extended algorithms on continuous and\ndiscrete test functions with a diverse set of constraints, demonstrating their\nflexibility and robustness. In addition, we illustrate their practical utility\nin two simulated chemical research scenarios: the optimization of the synthesis\nof o-xylenyl Buckminsterfullerene adducts under constrained flow conditions,\nand the design of redox active molecules for flow batteries under synthetic\naccessibility constraints. The tools developed constitute a simple, yet\nversatile strategy to enable model-based optimization with known experimental\nconstraints, contributing to its applicability as a core component of\nautonomous platforms for scientific discovery.",
    "descriptor": "\nComments: 15 pages, 5 figures (SI with 13 pages, 8 figures)\n",
    "authors": [
      "Riley J. Hickman",
      "Matteo Aldeghi",
      "Florian H\u00e4se",
      "Al\u00e1n Aspuru-Guzik"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.17241"
  },
  {
    "id": "arXiv:2203.17255",
    "title": "A Computational Architecture for Machine Consciousness and Artificial  Superintelligence: Updating Working Memory Iteratively",
    "abstract": "This theoretical article examines how to construct human-like working memory\nand thought processes within a computer. There should be two working memory\nstores, one analogous to sustained firing in association cortex, and one\nanalogous to synaptic potentiation in the cerebral cortex. These stores must be\nconstantly updated with new representations that arise from either\nenvironmental stimulation or internal processing. They should be updated\ncontinuously, and in an iterative fashion, meaning that, in the next state,\nsome items in the set of coactive items should always be retained. Thus, the\nset of concepts coactive in working memory will evolve gradually and\nincrementally over time. This makes each state is a revised iteration of the\npreceding state and causes successive states to overlap and blend with respect\nto the set of representations they contain. As new representations are added\nand old ones are subtracted, some remain active for several seconds over the\ncourse of these changes. This persistent activity, similar to that used in\nartificial recurrent neural networks, is used to spread activation energy\nthroughout the global workspace to search for the next associative update. The\nresult is a chain of associatively linked intermediate states that are capable\nof advancing toward a solution or goal. Iterative updating is conceptualized\nhere as an information processing strategy, a computational and\nneurophysiological determinant of the stream of thought, and an algorithm for\ndesigning and programming artificial intelligence.",
    "descriptor": "",
    "authors": [
      "Jared Edward Reser"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.17255"
  },
  {
    "id": "arXiv:1812.00086",
    "title": "Graph Node-Feature Convolution for Representation Learning",
    "abstract": "Graph Node-Feature Convolution for Representation Learning",
    "descriptor": "",
    "authors": [
      "Li Zhang",
      "Heda Song",
      "Nikolaos Aletras",
      "Haiping Lu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1812.00086"
  },
  {
    "id": "arXiv:1902.09941",
    "title": "Unsupervised Part Mining for Fine-grained Image Classification",
    "abstract": "Comments: 10 pages,4 figures",
    "descriptor": "\nComments: 10 pages,4 figures\n",
    "authors": [
      "Runsheng Zhang",
      "jian zhang",
      "Yaping Huang",
      "Qi Zou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/1902.09941"
  },
  {
    "id": "arXiv:1907.02704",
    "title": "Extraction and Analysis of Fictional Character Networks: A Survey",
    "abstract": "Extraction and Analysis of Fictional Character Networks: A Survey",
    "descriptor": "",
    "authors": [
      "Vincent Labatut",
      "Xavier Bost"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Retrieval (cs.IR)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/1907.02704"
  },
  {
    "id": "arXiv:1908.02203",
    "title": "Model Agnostic Defence against Backdoor Attacks in Machine Learning",
    "abstract": "Comments: IEEE Transactions on Reliability, 2022",
    "descriptor": "\nComments: IEEE Transactions on Reliability, 2022\n",
    "authors": [
      "Sakshi Udeshi",
      "Shanshan Peng",
      "Gerald Woo",
      "Lionell Loh",
      "Louth Rawshan",
      "Sudipta Chattopadhyay"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/1908.02203"
  },
  {
    "id": "arXiv:1909.08065",
    "title": "Deterministic algorithms for the Lovasz Local Lemma: simpler, more  general, and more parallel",
    "abstract": "Comments: This superseded arxiv:1807.06672",
    "descriptor": "\nComments: This superseded arxiv:1807.06672\n",
    "authors": [
      "David G. Harris"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/1909.08065"
  },
  {
    "id": "arXiv:1911.06872",
    "title": "Innovation and Strategic Network Formation",
    "abstract": "Innovation and Strategic Network Formation",
    "descriptor": "",
    "authors": [
      "Krishna Dasaratha"
    ],
    "subjectives": [
      "Theoretical Economics (econ.TH)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/1911.06872"
  },
  {
    "id": "arXiv:2001.02299",
    "title": "The LDBC Social Network Benchmark",
    "abstract": "Comments: For the repository containing the source code of this technical report, see this https URL",
    "descriptor": "\nComments: For the repository containing the source code of this technical report, see this https URL\n",
    "authors": [
      "Renzo Angles",
      "J\u00e1nos Benjamin Antal",
      "Alex Averbuch",
      "Peter Boncz",
      "Orri Erling",
      "Andrey Gubichev",
      "Vlad Haprian",
      "Moritz Kaufmann",
      "Josep Llu\u00eds Larriba Pey",
      "Norbert Mart\u00ednez",
      "J\u00f3zsef Marton",
      "Marcus Paradies",
      "Minh-Duc Pham",
      "Arnau Prat-P\u00e9rez",
      "Mirko Spasi\u0107",
      "Benjamin A. Steer",
      "G\u00e1bor Sz\u00e1rnyas",
      "Jack Waudby"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Performance (cs.PF)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2001.02299"
  },
  {
    "id": "arXiv:2002.08101",
    "title": "The Sum of Its Parts: Analysis of Federated Byzantine Agreement Systems",
    "abstract": "The Sum of Its Parts: Analysis of Federated Byzantine Agreement Systems",
    "descriptor": "",
    "authors": [
      "Martin Florian",
      "Sebastian Henningsen",
      "Charmaine Ndolo",
      "Bj\u00f6rn Scheuermann"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2002.08101"
  },
  {
    "id": "arXiv:2006.05630",
    "title": "Distributional Robust Batch Contextual Bandits",
    "abstract": "Comments: The short version has been accepted in ICML 2020",
    "descriptor": "\nComments: The short version has been accepted in ICML 2020\n",
    "authors": [
      "Nian Si",
      "Fan Zhang",
      "Zhengyuan Zhou",
      "Jose Blanchet"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.05630"
  },
  {
    "id": "arXiv:2006.06053",
    "title": "Causal Feature Selection for Algorithmic Fairness",
    "abstract": "Comments: Full version of the paper at SIGMOD 2022",
    "descriptor": "\nComments: Full version of the paper at SIGMOD 2022\n",
    "authors": [
      "Sainyam Galhotra",
      "Karthikeyan Shanmugam",
      "Prasanna Sattigeri",
      "Kush R. Varshney"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)",
      "Databases (cs.DB)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.06053"
  },
  {
    "id": "arXiv:2006.12789",
    "title": "Modelling Value-oriented Legal Reasoning in LogiKEy",
    "abstract": "Comments: 43 pages (+14 appendix), 21 figures; extended and improved version of our contribution to the 1st Workshop on Models of Legal Reasoning (MLR 2020)",
    "descriptor": "\nComments: 43 pages (+14 appendix), 21 figures; extended and improved version of our contribution to the 1st Workshop on Models of Legal Reasoning (MLR 2020)\n",
    "authors": [
      "Christoph Benzm\u00fcller",
      "David Fuenmayor",
      "Bertram Lomfeld"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2006.12789"
  },
  {
    "id": "arXiv:2006.15009",
    "title": "A Unifying Framework for Reinforcement Learning and Planning",
    "abstract": "A Unifying Framework for Reinforcement Learning and Planning",
    "descriptor": "",
    "authors": [
      "Thomas M. Moerland",
      "Joost Broekens",
      "Aske Plaat",
      "Catholijn M. Jonker"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.15009"
  },
  {
    "id": "arXiv:2006.16712",
    "title": "Model-based Reinforcement Learning: A Survey",
    "abstract": "Model-based Reinforcement Learning: A Survey",
    "descriptor": "",
    "authors": [
      "Thomas M. Moerland",
      "Joost Broekens",
      "Aske Plaat",
      "Catholijn M. Jonker"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.16712"
  },
  {
    "id": "arXiv:2006.16745",
    "title": "Machine learning fairness notions: Bridging the gap with real-world  applications",
    "abstract": "Machine learning fairness notions: Bridging the gap with real-world  applications",
    "descriptor": "",
    "authors": [
      "Karima Makhlouf",
      "Sami Zhioua",
      "Catuscia Palamidessi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.16745"
  },
  {
    "id": "arXiv:2008.00146",
    "title": "CROSSLINE: Breaking \"Security-by-Crash\" based Memory Isolation in AMD  SEV",
    "abstract": "Comments: 14 pages, 5 figures, security",
    "descriptor": "\nComments: 14 pages, 5 figures, security\n",
    "authors": [
      "Mengyuan Li",
      "Yinqian Zhang",
      "Zhiqiang Lin"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2008.00146"
  },
  {
    "id": "arXiv:2008.00252",
    "title": "Distributed Nonconvex Optimization: Gradient-free Iterations and  $\u03b5$-Globally Optimal Solution",
    "abstract": "Distributed Nonconvex Optimization: Gradient-free Iterations and  $\u03b5$-Globally Optimal Solution",
    "descriptor": "",
    "authors": [
      "Zhiyu He",
      "Jianping He",
      "Cailian Chen",
      "Xinping Guan"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2008.00252"
  },
  {
    "id": "arXiv:2008.00492",
    "title": "Extendability of simplicial maps is undecidable",
    "abstract": "Comments: 10 pages, 1 figure, exposition improved, minor flaw corrected",
    "descriptor": "\nComments: 10 pages, 1 figure, exposition improved, minor flaw corrected\n",
    "authors": [
      "A. Skopenkov"
    ],
    "subjectives": [
      "Algebraic Topology (math.AT)",
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2008.00492"
  },
  {
    "id": "arXiv:2008.05569",
    "title": "A new notion of commutativity for the algorithmic Lov\u00e1sz Local Lemma",
    "abstract": "A new notion of commutativity for the algorithmic Lov\u00e1sz Local Lemma",
    "descriptor": "",
    "authors": [
      "David G. Harris",
      "Fotis Iliopoulos",
      "Vladimir Kolmogorov"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2008.05569"
  },
  {
    "id": "arXiv:2010.02116",
    "title": "Optimal bounds for approximate counting",
    "abstract": "Comments: v2: incorporated PODS 2022 reviewer comments to improve presentation",
    "descriptor": "\nComments: v2: incorporated PODS 2022 reviewer comments to improve presentation\n",
    "authors": [
      "Jelani Nelson",
      "Huacheng Yu"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2010.02116"
  },
  {
    "id": "arXiv:2010.04605",
    "title": "Instance Weighted Incremental Evolution Strategies for Reinforcement  Learning in Dynamic Environments",
    "abstract": "Comments: Accepted by IEEE Transactions on Neural Networks and Learning Systems, 2022, DOI: 10.1109/TNNLS.2022.3160173",
    "descriptor": "\nComments: Accepted by IEEE Transactions on Neural Networks and Learning Systems, 2022, DOI: 10.1109/TNNLS.2022.3160173\n",
    "authors": [
      "Zhi Wang",
      "Chunlin Chen",
      "Daoyi Dong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2010.04605"
  },
  {
    "id": "arXiv:2010.12837",
    "title": "XDM: Improving Sequential Deep Matching with Unclicked User Behaviors  for Recommender System",
    "abstract": "Comments: 12 pages, accepted by DASFAA2022",
    "descriptor": "\nComments: 12 pages, accepted by DASFAA2022\n",
    "authors": [
      "Fuyu Lv",
      "Mengxue Li",
      "Tonglei Guo",
      "Changlong Yu",
      "Fei Sun",
      "Taiwei Jin",
      "Wilfred Ng"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2010.12837"
  },
  {
    "id": "arXiv:2011.05622",
    "title": "Reinforcement Learning with Dual-Observation for General Video Game  Playing",
    "abstract": "Comments: This work has been accepted by the IEEE Transactions on Games on March 21, 2022",
    "descriptor": "\nComments: This work has been accepted by the IEEE Transactions on Games on March 21, 2022\n",
    "authors": [
      "Chengpeng Hu",
      "Ziqi Wang",
      "Tianye Shu",
      "Hao Tong",
      "Julian Togelius",
      "Xin Yao",
      "Jialin Liu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2011.05622"
  },
  {
    "id": "arXiv:2011.06392",
    "title": "Using IPA-Based Tacotron for Data Efficient Cross-Lingual Speaker  Adaptation and Pronunciation Enhancement",
    "abstract": "Comments: Preprint",
    "descriptor": "\nComments: Preprint\n",
    "authors": [
      "Hamed Hemati",
      "Damian Borth"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2011.06392"
  },
  {
    "id": "arXiv:2011.07434",
    "title": "Time-Domain Multiple Traces Boundary Integral Formulation for Acoustic  Wave Scattering in 2D",
    "abstract": "Time-Domain Multiple Traces Boundary Integral Formulation for Acoustic  Wave Scattering in 2D",
    "descriptor": "",
    "authors": [
      "Carlos Jerez-Hanckes",
      "Ignacio Labarca"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2011.07434"
  },
  {
    "id": "arXiv:2011.13634",
    "title": "Deep Reinforcement Learning for Resource Constrained Multiclass  Scheduling in Wireless Networks",
    "abstract": "Deep Reinforcement Learning for Resource Constrained Multiclass  Scheduling in Wireless Networks",
    "descriptor": "",
    "authors": [
      "Apostolos Avranas",
      "Marios Kountouris",
      "Philippe Ciblat"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2011.13634"
  },
  {
    "id": "arXiv:2011.15028",
    "title": "The LDBC Graphalytics Benchmark",
    "abstract": "The LDBC Graphalytics Benchmark",
    "descriptor": "",
    "authors": [
      "Alexandru Iosup",
      "Ahmed Musaafir",
      "Alexandru Uta",
      "Arnau Prat P\u00e9rez",
      "G\u00e1bor Sz\u00e1rnyas",
      "Hassan Chafi",
      "Ilie Gabriel T\u0103nase",
      "Lifeng Nai",
      "Michael Anderson",
      "Mihai Capot\u0103",
      "Narayanan Sundaram",
      "Peter Boncz",
      "Siegfried Depner",
      "Stijn Heldens",
      "Thomas Manhardt",
      "Tim Hegeman",
      "Wing Lung Ngai",
      "Yinglong Xia"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2011.15028"
  },
  {
    "id": "arXiv:2012.09966",
    "title": "Predicting Decisions in Language Based Persuasion Games",
    "abstract": "Predicting Decisions in Language Based Persuasion Games",
    "descriptor": "",
    "authors": [
      "Reut Apel",
      "Ido Erev",
      "Roi Reichart",
      "Moshe Tennenholtz"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2012.09966"
  },
  {
    "id": "arXiv:2012.11943",
    "title": "Compressing LSTM Networks by Matrix Product Operators",
    "abstract": "Comments: 2 figures, 5 tables",
    "descriptor": "\nComments: 2 figures, 5 tables\n",
    "authors": [
      "Ze-Feng Gao",
      "Xingwei Sun",
      "Lan Gao",
      "Junfeng Li",
      "Zhong-Yi Lu"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Computational Physics (physics.comp-ph)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2012.11943"
  },
  {
    "id": "arXiv:2012.13093",
    "title": "EDN: Salient Object Detection via Extremely-Downsampled Network",
    "abstract": "Comments: Accepted by IEEE Transactions on Image Processing, 12 pages",
    "descriptor": "\nComments: Accepted by IEEE Transactions on Image Processing, 12 pages\n",
    "authors": [
      "Yu-Huan Wu",
      "Yun Liu",
      "Le Zhang",
      "Ming-Ming Cheng",
      "Bo Ren"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2012.13093"
  },
  {
    "id": "arXiv:2101.09644",
    "title": "Mean-field Approximations for Stochastic Population Processes with  Heterogenous Interactions",
    "abstract": "Comments: 32 pages, 2 figures. Significant changes to the last version: now considering a more general continuous-time jump process, detailed applications to network games and epidemic models, and focused on only concentration inequalities for the technical results",
    "descriptor": "\nComments: 32 pages, 2 figures. Significant changes to the last version: now considering a more general continuous-time jump process, detailed applications to network games and epidemic models, and focused on only concentration inequalities for the technical results\n",
    "authors": [
      "Anirudh Sridhar",
      "Soummya Kar"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Multiagent Systems (cs.MA)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2101.09644"
  },
  {
    "id": "arXiv:2101.11139",
    "title": "A Strengthened Cutset Upper Bound on the Capacity of the Relay Channel  and Applications",
    "abstract": "Comments: To appear in the IEEE Transactions on Information Theory. 42 pages, 8 figures",
    "descriptor": "\nComments: To appear in the IEEE Transactions on Information Theory. 42 pages, 8 figures\n",
    "authors": [
      "Abbas El Gamal",
      "Amin Gohari",
      "Chandra Nair"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2101.11139"
  },
  {
    "id": "arXiv:2102.04671",
    "title": "A Single-Timescale Method for Stochastic Bilevel Optimization",
    "abstract": "Comments: Minor edits in Table 1",
    "descriptor": "\nComments: Minor edits in Table 1\n",
    "authors": [
      "Tianyi Chen",
      "Yuejiao Sun",
      "Quan Xiao",
      "Wotao Yin"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2102.04671"
  },
  {
    "id": "arXiv:2102.12252",
    "title": "Localization Distillation for Dense Object Detection",
    "abstract": "Comments: Accepted by CVPR 2022. Camera Ready",
    "descriptor": "\nComments: Accepted by CVPR 2022. Camera Ready\n",
    "authors": [
      "Zhaohui Zheng",
      "Rongguang Ye",
      "Ping Wang",
      "Dongwei Ren",
      "Wangmeng Zuo",
      "Qibin Hou",
      "Ming-Ming Cheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2102.12252"
  },
  {
    "id": "arXiv:2102.12967",
    "title": "A statistical framework for efficient out of distribution detection in  deep neural networks",
    "abstract": "A statistical framework for efficient out of distribution detection in  deep neural networks",
    "descriptor": "",
    "authors": [
      "Matan Haroush",
      "Tzviel Frostig",
      "Ruth Heller",
      "Daniel Soudry"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2102.12967"
  },
  {
    "id": "arXiv:2103.01012",
    "title": "Unambiguously coded shifts",
    "abstract": "Unambiguously coded shifts",
    "descriptor": "",
    "authors": [
      "Marie-Pierre B\u00e9al",
      "Dominique Perrin",
      "Antonio Restivo"
    ],
    "subjectives": [
      "Dynamical Systems (math.DS)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2103.01012"
  },
  {
    "id": "arXiv:2103.14512",
    "title": "Continual Speaker Adaptation for Text-to-Speech Synthesis",
    "abstract": "Comments: Preprint",
    "descriptor": "\nComments: Preprint\n",
    "authors": [
      "Hamed Hemati",
      "Damian Borth"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2103.14512"
  },
  {
    "id": "arXiv:2103.15537",
    "title": "Cloth-Changing Person Re-identification from A Single Image with Gait  Prediction and Regularization",
    "abstract": "Comments: Accepted by CVPR 2022. arXiv admin note: text overlap with arXiv:2002.02295 by other authors",
    "descriptor": "\nComments: Accepted by CVPR 2022. arXiv admin note: text overlap with arXiv:2002.02295 by other authors\n",
    "authors": [
      "Xin Jin",
      "Tianyu He",
      "Kecheng Zheng",
      "Zhiheng Yin",
      "Xu Shen",
      "Zhen Huang",
      "Ruoyu Feng",
      "Jianqiang Huang",
      "Xian-Sheng Hua",
      "Zhibo Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.15537"
  },
  {
    "id": "arXiv:2104.01539",
    "title": "DINE: Domain Adaptation from Single and Multiple Black-box Predictors",
    "abstract": "Comments: CVPR2022 Camera Ready Version",
    "descriptor": "\nComments: CVPR2022 Camera Ready Version\n",
    "authors": [
      "Jian Liang",
      "Dapeng Hu",
      "Jiashi Feng",
      "Ran He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.01539"
  },
  {
    "id": "arXiv:2104.06159",
    "title": "Muesli: Combining Improvements in Policy Optimization",
    "abstract": "Muesli: Combining Improvements in Policy Optimization",
    "descriptor": "",
    "authors": [
      "Matteo Hessel",
      "Ivo Danihelka",
      "Fabio Viola",
      "Arthur Guez",
      "Simon Schmitt",
      "Laurent Sifre",
      "Theophane Weber",
      "David Silver",
      "Hado van Hasselt"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2104.06159"
  },
  {
    "id": "arXiv:2105.04044",
    "title": "Practical parallel self-testing of Bell states via magic rectangles",
    "abstract": "Comments: 29 pages, 4 figures; published version",
    "descriptor": "\nComments: 29 pages, 4 figures; published version\n",
    "authors": [
      "Sean A. Adamson",
      "Petros Wallden"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2105.04044"
  },
  {
    "id": "arXiv:2105.14785",
    "title": "Two Coupled Rejection Metrics Can Tell Adversarial Examples Apart",
    "abstract": "Comments: CVPR 2022",
    "descriptor": "\nComments: CVPR 2022\n",
    "authors": [
      "Tianyu Pang",
      "Huishuai Zhang",
      "Di He",
      "Yinpeng Dong",
      "Hang Su",
      "Wei Chen",
      "Jun Zhu",
      "Tie-Yan Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.14785"
  },
  {
    "id": "arXiv:2106.00402",
    "title": "A note on the network coloring game: A randomized distributed $(\u0394  +1)$-coloring algorithm",
    "abstract": "Comments: Some references have been added, as well as some discussion on the connection between the network coloring game and the distributed coloring problem",
    "descriptor": "\nComments: Some references have been added, as well as some discussion on the connection between the network coloring game and the distributed coloring problem\n",
    "authors": [
      "Nikolaos Fryganiotis",
      "Symeon Papavassiliou",
      "Christos Pelekis"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2106.00402"
  },
  {
    "id": "arXiv:2106.02689",
    "title": "RegionViT: Regional-to-Local Attention for Vision Transformers",
    "abstract": "Comments: add more results and link to codes and models. this https URL, formatted with ICLR style",
    "descriptor": "\nComments: add more results and link to codes and models. this https URL, formatted with ICLR style\n",
    "authors": [
      "Chun-Fu Chen",
      "Rameswar Panda",
      "Quanfu Fan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.02689"
  },
  {
    "id": "arXiv:2106.03339",
    "title": "Anisotropic interpolation error estimates using a new geometric  parameter",
    "abstract": "Comments: 34 pages",
    "descriptor": "\nComments: 34 pages\n",
    "authors": [
      "Hiroki Ishizaka",
      "Kenta Kobayashi",
      "Takuya Tsuchiya"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.03339"
  },
  {
    "id": "arXiv:2106.03721",
    "title": "OoD-Bench: Quantifying and Understanding Two Dimensions of  Out-of-Distribution Generalization",
    "abstract": "Comments: Accepted by CVPR 2022 (oral)",
    "descriptor": "\nComments: Accepted by CVPR 2022 (oral)\n",
    "authors": [
      "Nanyang Ye",
      "Kaican Li",
      "Haoyue Bai",
      "Runpeng Yu",
      "Lanqing Hong",
      "Fengwei Zhou",
      "Zhenguo Li",
      "Jun Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.03721"
  },
  {
    "id": "arXiv:2106.03959",
    "title": "Generative Flows with Invertible Attentions",
    "abstract": "Comments: Accepted to CVPR 2022",
    "descriptor": "\nComments: Accepted to CVPR 2022\n",
    "authors": [
      "Rhea Sanjay Sukthanker",
      "Zhiwu Huang",
      "Suryansh Kumar",
      "Radu Timofte",
      "Luc Van Gool"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.03959"
  },
  {
    "id": "arXiv:2106.04564",
    "title": "Are Pretrained Transformers Robust in Intent Classification? A Missing  Ingredient in Evaluation of Out-of-Scope Intent Detection",
    "abstract": "Comments: ACL 2022 Workshop on NLP for Conversational AI",
    "descriptor": "\nComments: ACL 2022 Workshop on NLP for Conversational AI\n",
    "authors": [
      "Jianguo Zhang",
      "Kazuma Hashimoto",
      "Yao Wan",
      "Zhiwei Liu",
      "Ye Liu",
      "Caiming Xiong",
      "Philip S. Yu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.04564"
  },
  {
    "id": "arXiv:2106.06233",
    "title": "Enhancing Speaking Styles in Conversational Text-to-Speech Synthesis  with Graph-based Multi-modal Context Modeling",
    "abstract": "Comments: Accepted by ICASSP 2022",
    "descriptor": "\nComments: Accepted by ICASSP 2022\n",
    "authors": [
      "Jingbei Li",
      "Yi Meng",
      "Chenyi Li",
      "Zhiyong Wu",
      "Helen Meng",
      "Chao Weng",
      "Dan Su"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2106.06233"
  },
  {
    "id": "arXiv:2106.06278",
    "title": "Union and intersection contracts are hard, actually",
    "abstract": "Union and intersection contracts are hard, actually",
    "descriptor": "",
    "authors": [
      "Teodoro Freund",
      "Yann Hamdaoui",
      "Arnaud Spiwack"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2106.06278"
  },
  {
    "id": "arXiv:2106.08708",
    "title": "The association between topic growth and citation impact of research  publications",
    "abstract": "The association between topic growth and citation impact of research  publications",
    "descriptor": "",
    "authors": [
      "Peter Sj\u00f6g\u00e5rde",
      "Fereshteh Didegah"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2106.08708"
  },
  {
    "id": "arXiv:2106.09212",
    "title": "Long-Short Temporal Contrastive Learning of Video Transformers",
    "abstract": "Comments: Accepted in CVPR 2022",
    "descriptor": "\nComments: Accepted in CVPR 2022\n",
    "authors": [
      "Jue Wang",
      "Gedas Bertasius",
      "Du Tran",
      "Lorenzo Torresani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.09212"
  },
  {
    "id": "arXiv:2106.10811",
    "title": "DiGS : Divergence guided shape implicit neural representation for  unoriented point clouds",
    "abstract": "DiGS : Divergence guided shape implicit neural representation for  unoriented point clouds",
    "descriptor": "",
    "authors": [
      "Yizhak Ben-Shabat",
      "Chamin Hewa Koneputugodage",
      "Stephen Gould"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.10811"
  },
  {
    "id": "arXiv:2106.11821",
    "title": "Data Augmentation for Opcode Sequence Based Malware Detection",
    "abstract": "Comments: 8 pages, 4 figures",
    "descriptor": "\nComments: 8 pages, 4 figures\n",
    "authors": [
      "Niall McLaughlin",
      "Jesus Martinez del Rincon"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.11821"
  },
  {
    "id": "arXiv:2106.12435",
    "title": "Existence of dissipative solutions to the compressible Navier-Stokes  system with potential temperature transport",
    "abstract": "Existence of dissipative solutions to the compressible Navier-Stokes  system with potential temperature transport",
    "descriptor": "",
    "authors": [
      "M\u00e1ria Luk\u00e1\u010dov\u00e1-Medvid'ov\u00e1",
      "Andreas Sch\u00f6mer"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.12435"
  },
  {
    "id": "arXiv:2107.01438",
    "title": "Corrected trapezoidal rules for singular implicit boundary integrals",
    "abstract": "Comments: 44 pages, 13 figures, 2 tables",
    "descriptor": "\nComments: 44 pages, 13 figures, 2 tables\n",
    "authors": [
      "Federico Izzo",
      "Olof Runborg",
      "Richard Tsai"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2107.01438"
  },
  {
    "id": "arXiv:2107.06822",
    "title": "General-purpose preconditioning for regularized interior point methods",
    "abstract": "General-purpose preconditioning for regularized interior point methods",
    "descriptor": "",
    "authors": [
      "Jacek Gondzio",
      "Spyridon Pougkakiotis",
      "John W. Pearson"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2107.06822"
  },
  {
    "id": "arXiv:2107.11956",
    "title": "Preliminary Steps Towards Federated Sentiment Classification",
    "abstract": "Preliminary Steps Towards Federated Sentiment Classification",
    "descriptor": "",
    "authors": [
      "Xin-Chun Li",
      "Lan Li",
      "De-Chuan Zhan",
      "Yunfeng Shao",
      "Bingshuai Li",
      "Shaoming Song"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.11956"
  },
  {
    "id": "arXiv:2107.12438",
    "title": "Debiasing In-Sample Policy Performance for Small-Data, Large-Scale  Optimization",
    "abstract": "Debiasing In-Sample Policy Performance for Small-Data, Large-Scale  Optimization",
    "descriptor": "",
    "authors": [
      "Vishal Gupta",
      "Michael Huang",
      "Paat Rusmevichientong"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.12438"
  },
  {
    "id": "arXiv:2107.13955",
    "title": "Local Structure Matters Most: Perturbation Study in NLU",
    "abstract": "Comments: 11 pages, 13 figure + appendix",
    "descriptor": "\nComments: 11 pages, 13 figure + appendix\n",
    "authors": [
      "Louis Clouatre",
      "Prasanna Parthasarathi",
      "Amal Zouaq",
      "Sarath Chandar"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.13955"
  },
  {
    "id": "arXiv:2108.00632",
    "title": "Skeena: Efficient and Consistent Cross-Engine Transactions",
    "abstract": "Comments: 14 pages, 12 figures",
    "descriptor": "\nComments: 14 pages, 12 figures\n",
    "authors": [
      "Jianqiu Zhang",
      "Kaisong Huang",
      "Tianzheng Wang",
      "King Lv"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2108.00632"
  },
  {
    "id": "arXiv:2108.05885",
    "title": "The paradox of the compositionality of natural language: a neural  machine translation case study",
    "abstract": "Comments: To appear at ACL 2022; 22 pages total (9 in the main paper, 3 pages of references and 10 pages with appendices)",
    "descriptor": "\nComments: To appear at ACL 2022; 22 pages total (9 in the main paper, 3 pages of references and 10 pages with appendices)\n",
    "authors": [
      "Verna Dankers",
      "Elia Bruni",
      "Dieuwke Hupkes"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.05885"
  },
  {
    "id": "arXiv:2108.06485",
    "title": "Multirate partially explicit scheme for multiscale flow problems",
    "abstract": "Multirate partially explicit scheme for multiscale flow problems",
    "descriptor": "",
    "authors": [
      "Wing Tat Leung",
      "Yating Wang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2108.06485"
  },
  {
    "id": "arXiv:2109.02165",
    "title": "FBDNN: Filter Banks and Deep Neural Networks for Portable and Fast  Brain-Computer Interfaces",
    "abstract": "Comments: We included additional tests of statistical significance",
    "descriptor": "\nComments: We included additional tests of statistical significance\n",
    "authors": [
      "Pedro R. A. S. Bassi",
      "Romis Attux"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.02165"
  },
  {
    "id": "arXiv:2109.03910",
    "title": "A Recipe For Arbitrary Text Style Transfer with Large Language Models",
    "abstract": "A Recipe For Arbitrary Text Style Transfer with Large Language Models",
    "descriptor": "",
    "authors": [
      "Emily Reif",
      "Daphne Ippolito",
      "Ann Yuan",
      "Andy Coenen",
      "Chris Callison-Burch",
      "Jason Wei"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.03910"
  },
  {
    "id": "arXiv:2110.01661",
    "title": "Rerunning OCR: A Machine Learning Approach to Quality Assessment and  Enhancement Prediction",
    "abstract": "Comments: Journal of Data Mining and Digital Humanities; Major revision",
    "descriptor": "\nComments: Journal of Data Mining and Digital Humanities; Major revision\n",
    "authors": [
      "Pit Schneider",
      "Yves Maurer"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.01661"
  },
  {
    "id": "arXiv:2110.01863",
    "title": "DeepEdge: A Deep Reinforcement Learning based Task Orchestrator for Edge  Computing",
    "abstract": "Comments: 14 pages, 12 figures, 6 tables",
    "descriptor": "\nComments: 14 pages, 12 figures, 6 tables\n",
    "authors": [
      "Baris Yamansavascilar",
      "Ahmet Cihat Baktir",
      "Cagatay Sonmez",
      "Atay Ozgovde",
      "Cem Ersoy"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.01863"
  },
  {
    "id": "arXiv:2110.04184",
    "title": "When Can We Learn General-Sum Markov Games with a Large Number of  Players Sample-Efficiently?",
    "abstract": "When Can We Learn General-Sum Markov Games with a Large Number of  Players Sample-Efficiently?",
    "descriptor": "",
    "authors": [
      "Ziang Song",
      "Song Mei",
      "Yu Bai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.04184"
  },
  {
    "id": "arXiv:2110.04488",
    "title": "Demystifying the Transferability of Adversarial Attacks in Computer  Networks",
    "abstract": "Comments: 14 pages",
    "descriptor": "\nComments: 14 pages\n",
    "authors": [
      "Ehsan Nowroozi",
      "Yassine Mekdad",
      "Mohammad Hajian Berenjestanaki",
      "Mauro Conti",
      "Abdeslam EL Fergougui"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2110.04488"
  },
  {
    "id": "arXiv:2110.05781",
    "title": "BERTraffic: BERT-based Joint Speaker Role and Speaker Change Detection  for Air Traffic Control Communications",
    "abstract": "Comments: This paper has been submitted to Interspeech 2022",
    "descriptor": "\nComments: This paper has been submitted to Interspeech 2022\n",
    "authors": [
      "Juan Zuluaga-Gomez",
      "Seyyed Saeed Sarfjoo",
      "Amrutha Prasad",
      "Iuliia Nigmatulina",
      "Petr Motlicek",
      "Karel Ondrej",
      "Oliver Ohneiser",
      "Hartmut Helmke"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.05781"
  },
  {
    "id": "arXiv:2110.06537",
    "title": "Well-classified Examples are Underestimated in Classification with Deep  Neural Networks",
    "abstract": "Comments: Accepted by AAAI 2022; 17 pages, 11 figures, 13 tables",
    "descriptor": "\nComments: Accepted by AAAI 2022; 17 pages, 11 figures, 13 tables\n",
    "authors": [
      "Guangxiang Zhao",
      "Wenkai Yang",
      "Xuancheng Ren",
      "Lei Li",
      "Yunfang Wu",
      "Xu Sun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.06537"
  },
  {
    "id": "arXiv:2110.07274",
    "title": "An Approach to Mispronunciation Detection and Diagnosis with Acoustic,  Phonetic and Linguistic (APL) Embeddings",
    "abstract": "Comments: Accepted by ICASSP 2022",
    "descriptor": "\nComments: Accepted by ICASSP 2022\n",
    "authors": [
      "Wenxuan Ye",
      "Shaoguang Mao",
      "Frank Soong",
      "Wenshan Wu",
      "Yan Xia",
      "Jonathan Tien",
      "Zhiyong Wu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.07274"
  },
  {
    "id": "arXiv:2110.07298",
    "title": "LFPT5: A Unified Framework for Lifelong Few-shot Language Learning Based  on Prompt Tuning of T5",
    "abstract": "Comments: ICLR 2022. Code is available at this https URL",
    "descriptor": "\nComments: ICLR 2022. Code is available at this https URL\n",
    "authors": [
      "Chengwei Qin",
      "Shafiq Joty"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.07298"
  },
  {
    "id": "arXiv:2110.07552",
    "title": "BI-RADS BERT & Using Section Segmentation to Understand Radiology  Reports",
    "abstract": "BI-RADS BERT & Using Section Segmentation to Understand Radiology  Reports",
    "descriptor": "",
    "authors": [
      "Grey Kuling",
      "Dr. Belinda Curpen",
      "Anne L. Martel"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.07552"
  },
  {
    "id": "arXiv:2110.08454",
    "title": "Good Examples Make A Faster Learner: Simple Demonstration-based Learning  for Low-resource NER",
    "abstract": "Comments: Accepted to ACL 2022 main conference. 14 pages, 8 figures, 9 tables",
    "descriptor": "\nComments: Accepted to ACL 2022 main conference. 14 pages, 8 figures, 9 tables\n",
    "authors": [
      "Dong-Ho Lee",
      "Akshen Kadakia",
      "Kangmin Tan",
      "Mahak Agarwal",
      "Xinyu Feng",
      "Takashi Shibuya",
      "Ryosuke Mitani",
      "Toshiyuki Sekiya",
      "Jay Pujara",
      "Xiang Ren"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.08454"
  },
  {
    "id": "arXiv:2110.09977",
    "title": "An Ultra-Reliable Low-Latency Non-Binary Polar Coded SCMA Scheme",
    "abstract": "An Ultra-Reliable Low-Latency Non-Binary Polar Coded SCMA Scheme",
    "descriptor": "",
    "authors": [
      "Shufeng Li",
      "Mingyu Cai",
      "Libiao Jin",
      "Yao Sun",
      "Hongda Wu",
      "Ping Wang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2110.09977"
  },
  {
    "id": "arXiv:2110.12558",
    "title": "Recommender Systems meet Mechanism Design",
    "abstract": "Recommender Systems meet Mechanism Design",
    "descriptor": "",
    "authors": [
      "Yang Cai",
      "Constantinos Daskalakis"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.12558"
  },
  {
    "id": "arXiv:2110.12983",
    "title": "Stochastic Rounding for Image Interpolation and Scan Conversion",
    "abstract": "Comments: 10 pages, 17 figures, 3 tables. International Journal of Advanced Computer Science and Applications, 2022",
    "descriptor": "\nComments: 10 pages, 17 figures, 3 tables. International Journal of Advanced Computer Science and Applications, 2022\n",
    "authors": [
      "Olivier Rukundo",
      "Samuel Emil Schmidt"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.12983"
  },
  {
    "id": "arXiv:2110.13492",
    "title": "TUNet: A Block-online Bandwidth Extension Model based on Transformers  and Self-supervised Pretraining",
    "abstract": "Comments: ICASSP 2022 accepted, 5 pages, 4 figures, 3 tables",
    "descriptor": "\nComments: ICASSP 2022 accepted, 5 pages, 4 figures, 3 tables\n",
    "authors": [
      "Viet-Anh Nguyen",
      "Anh H. T. Nguyen",
      "Andy W. H. Khong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.13492"
  },
  {
    "id": "arXiv:2110.14928",
    "title": "Learning Actions for Drift-Free Navigation in Highly Dynamic Scenes",
    "abstract": "Comments: Accepted in American Control Conference 2022",
    "descriptor": "\nComments: Accepted in American Control Conference 2022\n",
    "authors": [
      "Mohd Omama",
      "Sundar Sripada V. S.",
      "Sandeep Chinchali",
      "K. Madhava Krishna"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.14928"
  },
  {
    "id": "arXiv:2111.00345",
    "title": "Multi-Agent Advisor Q-Learning",
    "abstract": "Comments: Paper has been accepted to Journal of Artificial Intelligence Research (JAIR). The new version contains some change in formatting to be consistent with the JAIR version",
    "descriptor": "\nComments: Paper has been accepted to Journal of Artificial Intelligence Research (JAIR). The new version contains some change in formatting to be consistent with the JAIR version\n",
    "authors": [
      "Sriram Ganapathi Subramanian",
      "Matthew E. Taylor",
      "Kate Larson",
      "Mark Crowley"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2111.00345"
  },
  {
    "id": "arXiv:2111.00600",
    "title": "Minimum Description Length Recurrent Neural Networks",
    "abstract": "Comments: 15 pages",
    "descriptor": "\nComments: 15 pages\n",
    "authors": [
      "Nur Lan",
      "Michal Geyer",
      "Emmanuel Chemla",
      "Roni Katzir"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2111.00600"
  },
  {
    "id": "arXiv:2111.01272",
    "title": "Sequence Transduction with Graph-based Supervision",
    "abstract": "Comments: Accepted for publication at IEEE ICASSP 2022",
    "descriptor": "\nComments: Accepted for publication at IEEE ICASSP 2022\n",
    "authors": [
      "Niko Moritz",
      "Takaaki Hori",
      "Shinji Watanabe",
      "Jonathan Le Roux"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2111.01272"
  },
  {
    "id": "arXiv:2111.03735",
    "title": "A PTAS for Capacitated Vehicle Routing on Trees",
    "abstract": "Comments: Submitted to ICALP 2022",
    "descriptor": "\nComments: Submitted to ICALP 2022\n",
    "authors": [
      "Claire Mathieu",
      "Hang Zhou"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2111.03735"
  },
  {
    "id": "arXiv:2111.04704",
    "title": "Data-driven Set-based Estimation of Polynomial Systems with Application  to SIR Epidemics",
    "abstract": "Comments: Accepted for the 20th European Control Conference (ECC 2022)",
    "descriptor": "\nComments: Accepted for the 20th European Control Conference (ECC 2022)\n",
    "authors": [
      "Amr Alanwar",
      "Muhammad Umar B. Niazi",
      "Karl H. Johansson"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2111.04704"
  },
  {
    "id": "arXiv:2111.05249",
    "title": "Fracture Modes for Realtime Destruction",
    "abstract": "Fracture Modes for Realtime Destruction",
    "descriptor": "",
    "authors": [
      "Silvia Sell\u00e1n",
      "Jack Luong",
      "Leticia Mattos Da Silva",
      "Aravind Ramakrishnan",
      "Yuchuan Yang",
      "Alec Jacobson"
    ],
    "subjectives": [
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2111.05249"
  },
  {
    "id": "arXiv:2111.07038",
    "title": "Commodity Wi-Fi Sensing Survey: Current Status, Challenges, and  Opportunities",
    "abstract": "Commodity Wi-Fi Sensing Survey: Current Status, Challenges, and  Opportunities",
    "descriptor": "",
    "authors": [
      "Sheng Tan",
      "Jie Yang"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2111.07038"
  },
  {
    "id": "arXiv:2111.08093",
    "title": "Monotone Inclusions, Acceleration and Closed-Loop Control",
    "abstract": "Comments: 46 Pages; Fixing some confusing points in the proof of Theorem 3.8 and removing the typos",
    "descriptor": "\nComments: 46 Pages; Fixing some confusing points in the proof of Theorem 3.8 and removing the typos\n",
    "authors": [
      "Tianyi Lin",
      "Michael. I. Jordan"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2111.08093"
  },
  {
    "id": "arXiv:2111.11873",
    "title": "Deformable image registration with deep network priors: a study on  longitudinal PET images",
    "abstract": "Comments: 11 pages 3 figures in the main article 2 tables in the main article 2 figures in supplementary material",
    "descriptor": "\nComments: 11 pages 3 figures in the main article 2 tables in the main article 2 figures in supplementary material\n",
    "authors": [
      "Constance Fourcade",
      "Ludovic Ferrer",
      "Noemie Moreau",
      "Gianmarco Santini",
      "Aishlinn Brennan",
      "Caroline Rousseau",
      "Marie Lacombe",
      "Vincent Fleury",
      "Mathilde Colombi\u00e9",
      "Pascal J\u00e9z\u00e9quel",
      "Mario Campone",
      "Mathieu Rubeaux",
      "Diana Mateus"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.11873"
  },
  {
    "id": "arXiv:2111.13011",
    "title": "Transferability Metrics for Selecting Source Model Ensembles",
    "abstract": "Transferability Metrics for Selecting Source Model Ensembles",
    "descriptor": "",
    "authors": [
      "Andrea Agostinelli",
      "Jasper Uijlings",
      "Thomas Mensink",
      "Vittorio Ferrari"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.13011"
  },
  {
    "id": "arXiv:2111.13738",
    "title": "The Implicit Values of A Good Hand Shake: Handheld Multi-Frame Neural  Depth Refinement",
    "abstract": "Comments: Project github: this https URL",
    "descriptor": "\nComments: Project github: this https URL\n",
    "authors": [
      "Ilya Chugunov",
      "Yuxuan Zhang",
      "Zhihao Xia",
      "Xuaner",
      "Zhang",
      "Jiawen Chen",
      "Felix Heide"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.13738"
  },
  {
    "id": "arXiv:2111.14213",
    "title": "Local Learning Matters: Rethinking Data Heterogeneity in Federated  Learning",
    "abstract": "Comments: CVPR 2022",
    "descriptor": "\nComments: CVPR 2022\n",
    "authors": [
      "Matias Mendieta",
      "Taojiannan Yang",
      "Pu Wang",
      "Minwoo Lee",
      "Zhengming Ding",
      "Chen Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2111.14213"
  },
  {
    "id": "arXiv:2111.14244",
    "title": "Schema matching using Gaussian mixture models with Wasserstein distance",
    "abstract": "Schema matching using Gaussian mixture models with Wasserstein distance",
    "descriptor": "",
    "authors": [
      "Mateusz Przyborowski",
      "Mateusz Pabi\u015b",
      "Andrzej Janusz",
      "Dominik \u015al\u0119zak"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Databases (cs.DB)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.14244"
  },
  {
    "id": "arXiv:2111.14447",
    "title": "ZeroCap: Zero-Shot Image-to-Text Generation for Visual-Semantic  Arithmetic",
    "abstract": "Comments: To appear in CVPR'22",
    "descriptor": "\nComments: To appear in CVPR'22\n",
    "authors": [
      "Yoad Tewel",
      "Yoav Shalev",
      "Idan Schwartz",
      "Lior Wolf"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2111.14447"
  },
  {
    "id": "arXiv:2111.14451",
    "title": "HDR-NeRF: High Dynamic Range Neural Radiance Fields",
    "abstract": "Comments: Accepted to CVPR 2022. Project page: this https URL",
    "descriptor": "\nComments: Accepted to CVPR 2022. Project page: this https URL\n",
    "authors": [
      "Xin Huang",
      "Qi Zhang",
      "Ying Feng",
      "Hongdong Li",
      "Xuan Wang",
      "Qing Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.14451"
  },
  {
    "id": "arXiv:2111.15058",
    "title": "Computing Generalized Rank Invariant for 2-Parameter Persistence Modules  via Zigzag Persistence and its Applications",
    "abstract": "Comments: Full version of the paper in the Proceedings of the 38th International Symposium on Computational Geometry (SoCG 2022). Shortened the proof of Theorem 3.12 and added new sections 4.4 and 4.5; 21 pages, 4 figures",
    "descriptor": "\nComments: Full version of the paper in the Proceedings of the 38th International Symposium on Computational Geometry (SoCG 2022). Shortened the proof of Theorem 3.12 and added new sections 4.4 and 4.5; 21 pages, 4 figures\n",
    "authors": [
      "Tamal K. Dey",
      "Woojin Kim",
      "Facundo M\u00e9moli"
    ],
    "subjectives": [
      "Algebraic Topology (math.AT)",
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2111.15058"
  },
  {
    "id": "arXiv:2112.02456",
    "title": "Spatio-Temporal Resource Meshes for Serverless Computing",
    "abstract": "Spatio-Temporal Resource Meshes for Serverless Computing",
    "descriptor": "",
    "authors": [
      "Hailiang Zhao",
      "Shuiguang Deng",
      "Jianwei Yin",
      "Schahram Dustdar",
      "Albert Y. Zomaya"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2112.02456"
  },
  {
    "id": "arXiv:2112.02753",
    "title": "MobRecon: Mobile-Friendly Hand Mesh Reconstruction from Monocular Image",
    "abstract": "MobRecon: Mobile-Friendly Hand Mesh Reconstruction from Monocular Image",
    "descriptor": "",
    "authors": [
      "Xingyu Chen",
      "Yufeng Liu",
      "Yajiao Dong",
      "Xiong Zhang",
      "Chongyang Ma",
      "Yanmin Xiong",
      "Yuan Zhang",
      "Xiaoyan Guo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.02753"
  },
  {
    "id": "arXiv:2112.02815",
    "title": "Make It Move: Controllable Image-to-Video Generation with Text  Descriptions",
    "abstract": "Comments: Accepted by CVPR'2022",
    "descriptor": "\nComments: Accepted by CVPR'2022\n",
    "authors": [
      "Yaosi Hu",
      "Chong Luo",
      "Zhenzhong Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.02815"
  },
  {
    "id": "arXiv:2112.04148",
    "title": "Neural Points: Point Cloud Representation with Neural Fields for  Arbitrary Upsampling",
    "abstract": "Comments: Accepted to CVPR2022. Project page: this https URL",
    "descriptor": "\nComments: Accepted to CVPR2022. Project page: this https URL\n",
    "authors": [
      "Wanquan Feng",
      "Jin Li",
      "Hongrui Cai",
      "Xiaonan Luo",
      "Juyong Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.04148"
  },
  {
    "id": "arXiv:2112.05230",
    "title": "Injecting Semantic Concepts into End-to-End Image Captioning",
    "abstract": "Injecting Semantic Concepts into End-to-End Image Captioning",
    "descriptor": "",
    "authors": [
      "Zhiyuan Fang",
      "Jianfeng Wang",
      "Xiaowei Hu",
      "Lin Liang",
      "Zhe Gan",
      "Lijuan Wang",
      "Yezhou Yang",
      "Zicheng Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.05230"
  },
  {
    "id": "arXiv:2112.05597",
    "title": "Marvin: an Innovative Omni-Directional Robotic Assistant for Domestic  Environments",
    "abstract": "Comments: 22 pages, 11 figures, 3 table",
    "descriptor": "\nComments: 22 pages, 11 figures, 3 table\n",
    "authors": [
      "Andrea Eirale",
      "Mauro Martini",
      "Luigi Tagliavini",
      "Dario Gandini",
      "Marcello Chiaberge",
      "Giuseppe Quaglia"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.05597"
  },
  {
    "id": "arXiv:2112.05921",
    "title": "Simultaneous Localization and Mapping: Through the Lens of Nonlinear  Optimization",
    "abstract": "Comments: 22 pages",
    "descriptor": "\nComments: 22 pages\n",
    "authors": [
      "Amay Saxena",
      "Chih-Yuan Chiu",
      "Joseph Menke",
      "Ritika Shrivastava",
      "Shankar Sastry"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.05921"
  },
  {
    "id": "arXiv:2112.07534",
    "title": "Reinforced Abstractive Summarization with Adaptive Length Controlling",
    "abstract": "Comments: content revising",
    "descriptor": "\nComments: content revising\n",
    "authors": [
      "Mingyang Song",
      "Yi Feng",
      "Liping Jing"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.07534"
  },
  {
    "id": "arXiv:2112.07583",
    "title": "Reinforcing Semantic-Symmetry for Document Summarization",
    "abstract": "Comments: content revising",
    "descriptor": "\nComments: content revising\n",
    "authors": [
      "Mingyang Song",
      "Liping Jing"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.07583"
  },
  {
    "id": "arXiv:2112.08588",
    "title": "Learning to acquire novel cognitive tasks with evolution, plasticity and  meta-meta-learning",
    "abstract": "Learning to acquire novel cognitive tasks with evolution, plasticity and  meta-meta-learning",
    "descriptor": "",
    "authors": [
      "Thomas Miconi"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.08588"
  },
  {
    "id": "arXiv:2112.08740",
    "title": "Feature Erasing and Diffusion Network for Occluded Person  Re-Identification",
    "abstract": "Comments: 10 pages, 5 figures",
    "descriptor": "\nComments: 10 pages, 5 figures\n",
    "authors": [
      "Zhikang Wang",
      "Feng Zhu",
      "Shixiang Tang",
      "Rui Zhao",
      "Lihuo He",
      "Jiangning Song"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.08740"
  },
  {
    "id": "arXiv:2112.09572",
    "title": "Topic-Aware Encoding for Extractive Summarization",
    "abstract": "Comments: content revising",
    "descriptor": "\nComments: content revising\n",
    "authors": [
      "Mingyang Song",
      "Liping Jing"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.09572"
  },
  {
    "id": "arXiv:2112.10482",
    "title": "ScanQA: 3D Question Answering for Spatial Scene Understanding",
    "abstract": "Comments: CVPR2022. The first three authors are equally contributed. Project page: this https URL",
    "descriptor": "\nComments: CVPR2022. The first three authors are equally contributed. Project page: this https URL\n",
    "authors": [
      "Daichi Azuma",
      "Taiki Miyanishi",
      "Shuhei Kurita",
      "Motoki Kawanabe"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.10482"
  },
  {
    "id": "arXiv:2112.11594",
    "title": "GCoD: Graph Convolutional Network Acceleration via Dedicated Algorithm  and Accelerator Co-Design",
    "abstract": "Comments: Published as a conference paper at HPCA 2022",
    "descriptor": "\nComments: Published as a conference paper at HPCA 2022\n",
    "authors": [
      "Haoran You",
      "Tong Geng",
      "Yongan Zhang",
      "Ang Li",
      "Yingyan Lin"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.11594"
  },
  {
    "id": "arXiv:2112.11790",
    "title": "BEVDet: High-performance Multi-camera 3D Object Detection in  Bird-Eye-View",
    "abstract": "Comments: Multi-camera 3D Object Detection",
    "descriptor": "\nComments: Multi-camera 3D Object Detection\n",
    "authors": [
      "Junjie Huang",
      "Guan Huang",
      "Zheng Zhu",
      "Yun Ye",
      "Dalong Du"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.11790"
  },
  {
    "id": "arXiv:2112.11964",
    "title": "On a linear Gromov-Wasserstein distance",
    "abstract": "On a linear Gromov-Wasserstein distance",
    "descriptor": "",
    "authors": [
      "Florian Beier",
      "Robert Beinert",
      "Gabriele Steidl"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2112.11964"
  },
  {
    "id": "arXiv:2112.12970",
    "title": "SGTR: End-to-end Scene Graph Generation with Transformer",
    "abstract": "Comments: Accepted by CVPR2022",
    "descriptor": "\nComments: Accepted by CVPR2022\n",
    "authors": [
      "Rongjie Li",
      "Songyang Zhang",
      "Xuming He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.12970"
  },
  {
    "id": "arXiv:2112.13215",
    "title": "Continual Learning for Unsupervised Anomaly Detection in Continuous  Auditing of Financial Accounting Data",
    "abstract": "Comments: AAAI 2022 Workshop on AI in Financial Services: Adaptiveness, Resilience & Governance",
    "descriptor": "\nComments: AAAI 2022 Workshop on AI in Financial Services: Adaptiveness, Resilience & Governance\n",
    "authors": [
      "Hamed Hemati",
      "Marco Schreyer",
      "Damian Borth"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.13215"
  },
  {
    "id": "arXiv:2112.13763",
    "title": "Yet Another Proof of the Joint Convexity of Relative Entropy",
    "abstract": "Comments: Added dedication to Derek W. Robinson; corrected typos and minor errors; added proof of the montonicity of relative entropy under partial traces and proof of strong subadditivity of quantum entropy",
    "descriptor": "\nComments: Added dedication to Derek W. Robinson; corrected typos and minor errors; added proof of the montonicity of relative entropy under partial traces and proof of strong subadditivity of quantum entropy\n",
    "authors": [
      "Mary Beth Ruskai"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Information Theory (cs.IT)",
      "Mathematical Physics (math-ph)",
      "Functional Analysis (math.FA)"
    ],
    "url": "https://arxiv.org/abs/2112.13763"
  },
  {
    "id": "arXiv:2112.13874",
    "title": "Unbiased Parameter Inference for a Class of Partially Observed  Levy-Process Models",
    "abstract": "Comments: 24 pages, 2 figures, 1 table",
    "descriptor": "\nComments: 24 pages, 2 figures, 1 table\n",
    "authors": [
      "Hamza Ruzayqat",
      "Ajay Jasra"
    ],
    "subjectives": [
      "Computation (stat.CO)",
      "Numerical Analysis (math.NA)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2112.13874"
  },
  {
    "id": "arXiv:2201.00267",
    "title": "On the Cross-dataset Generalization in License Plate Recognition",
    "abstract": "Comments: Accepted for presentation at the International Conference on Computer Vision Theory and Applications (VISAPP) 2022",
    "descriptor": "\nComments: Accepted for presentation at the International Conference on Computer Vision Theory and Applications (VISAPP) 2022\n",
    "authors": [
      "Rayson Laroca",
      "Everton V. Cardoso",
      "Diego R. Lucio",
      "Valter Estevam",
      "David Menotti"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.00267"
  },
  {
    "id": "arXiv:2201.02732",
    "title": "C2-CRS: Coarse-to-Fine Contrastive Learning for Conversational  Recommender System",
    "abstract": "C2-CRS: Coarse-to-Fine Contrastive Learning for Conversational  Recommender System",
    "descriptor": "",
    "authors": [
      "Yuanhang Zhou",
      "Kun Zhou",
      "Wayne Xin Zhao",
      "Cheng Wang",
      "Peng Jiang",
      "He Hu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2201.02732"
  },
  {
    "id": "arXiv:2201.05346",
    "title": "Arbitrary Handwriting Image Style Transfer",
    "abstract": "Arbitrary Handwriting Image Style Transfer",
    "descriptor": "",
    "authors": [
      "Kai Yang",
      "Xiaoman Liang",
      "Huihuang Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.05346"
  },
  {
    "id": "arXiv:2201.07116",
    "title": "Robust Computation Tree Logic",
    "abstract": "Comments: 23 pages, 1 figure, to be published in the proceedings of NASA Formal Methods (NFM), 2022",
    "descriptor": "\nComments: 23 pages, 1 figure, to be published in the proceedings of NASA Formal Methods (NFM), 2022\n",
    "authors": [
      "Satya Prakash Nayak",
      "Daniel Neider",
      "Rajarshi Roy",
      "Martin Zimmermann"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2201.07116"
  },
  {
    "id": "arXiv:2201.07398",
    "title": "An efficient Chorin-Temam projection proper orthogonal decomposition  based reduced-order model for nonstationary Stokes equations",
    "abstract": "An efficient Chorin-Temam projection proper orthogonal decomposition  based reduced-order model for nonstationary Stokes equations",
    "descriptor": "",
    "authors": [
      "Xi Li",
      "Yan Luo",
      "Minfu Feng"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2201.07398"
  },
  {
    "id": "arXiv:2201.08377",
    "title": "Omnivore: A Single Model for Many Visual Modalities",
    "abstract": "Comments: Accepted at CVPR 2022 (Oral Presentation)",
    "descriptor": "\nComments: Accepted at CVPR 2022 (Oral Presentation)\n",
    "authors": [
      "Rohit Girdhar",
      "Mannat Singh",
      "Nikhila Ravi",
      "Laurens van der Maaten",
      "Armand Joulin",
      "Ishan Misra"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.08377"
  },
  {
    "id": "arXiv:2201.09488",
    "title": "Comparative Verification of the Digital Library of Mathematical  Functions and Computer Algebra Systems",
    "abstract": "Comparative Verification of the Digital Library of Mathematical  Functions and Computer Algebra Systems",
    "descriptor": "",
    "authors": [
      "Andr\u00e9 Greiner-Petter",
      "Howard S. Cohl",
      "Abdou Youssef",
      "Moritz Schubotz",
      "Avi Trost",
      "Rajen Dey",
      "Akiko Aizawa",
      "Bela Gipp"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2201.09488"
  },
  {
    "id": "arXiv:2201.09562",
    "title": "GoSafeOpt: Scalable Safe Exploration for Global Optimization of  Dynamical Systems",
    "abstract": "GoSafeOpt: Scalable Safe Exploration for Global Optimization of  Dynamical Systems",
    "descriptor": "",
    "authors": [
      "Bhavya Sukhija",
      "Matteo Turchetta",
      "David Lindner",
      "Andreas Krause",
      "Sebastian Trimpe",
      "Dominik Baumann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2201.09562"
  },
  {
    "id": "arXiv:2201.11251",
    "title": "Reinforcement Learning Based Query Vertex Ordering Model for Subgraph  Matching",
    "abstract": "Comments: Accepted by ICDE 2022",
    "descriptor": "\nComments: Accepted by ICDE 2022\n",
    "authors": [
      "Hanchen Wang",
      "Ying Zhang",
      "Lu Qin",
      "Wei Wang",
      "Wenjie Zhang",
      "Xuemin Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2201.11251"
  },
  {
    "id": "arXiv:2202.00645",
    "title": "Stability and Generalization Capabilities of Message Passing Graph  Neural Networks",
    "abstract": "Comments: 44 pages, typos corrected, preprint",
    "descriptor": "\nComments: 44 pages, typos corrected, preprint\n",
    "authors": [
      "Sohir Maskey",
      "Ron Levie",
      "Yunseok Lee",
      "Gitta Kutyniok"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Numerical Analysis (math.NA)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2202.00645"
  },
  {
    "id": "arXiv:2202.00886",
    "title": "Accurate calibration of multi-perspective cameras from a generalization  of the hand-eye constraint",
    "abstract": "Comments: accepted in the 2022 IEEE International Conference on Robotics and Automation (ICRA), Philadelphia (PA), USA",
    "descriptor": "\nComments: accepted in the 2022 IEEE International Conference on Robotics and Automation (ICRA), Philadelphia (PA), USA\n",
    "authors": [
      "Yifu Wang",
      "Wenqing Jiang",
      "Kun Huang",
      "S\u00f6ren Schwertfeger",
      "Laurent Kneip"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.00886"
  },
  {
    "id": "arXiv:2202.00989",
    "title": "Coding for Sensing: An Improved Scheme for Integrated Sensing and  Communication over MACs",
    "abstract": "Coding for Sensing: An Improved Scheme for Integrated Sensing and  Communication over MACs",
    "descriptor": "",
    "authors": [
      "Mehrasa Ahmadipour",
      "Michele Wigger",
      "Mari Kobayashi"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.00989"
  },
  {
    "id": "arXiv:2202.06484",
    "title": "D2ADA: Dynamic Density-aware Active Domain Adaptation for Semantic  Segmentation",
    "abstract": "Comments: 14 pages, 5 figures",
    "descriptor": "\nComments: 14 pages, 5 figures\n",
    "authors": [
      "Tsung-Han Wu",
      "Yi-Syuan Liou",
      "Shao-Ji Yuan",
      "Hsin-Ying Lee",
      "Tung-I Chen",
      "Kuan-Chih Huang",
      "Winston H. Hsu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.06484"
  },
  {
    "id": "arXiv:2202.07577",
    "title": "Weighted Programming",
    "abstract": "Comments: 71 pages",
    "descriptor": "\nComments: 71 pages\n",
    "authors": [
      "Kevin Batz",
      "Adrian Gallus",
      "Benjamin Lucien Kaminski",
      "Joost-Pieter Katoen",
      "Tobias Winkler"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Machine Learning (cs.LG)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2202.07577"
  },
  {
    "id": "arXiv:2202.09011",
    "title": "A class of twisted generalized Reed-Solomon codes",
    "abstract": "Comments: 11 pages",
    "descriptor": "\nComments: 11 pages\n",
    "authors": [
      "Jun Zhang",
      "Zhengchun Zhou",
      "Chunming Tang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.09011"
  },
  {
    "id": "arXiv:2202.09986",
    "title": "Isogeometric Analysis of Bound States of a Quantum Three-Body Problem in  1D",
    "abstract": "Isogeometric Analysis of Bound States of a Quantum Three-Body Problem in  1D",
    "descriptor": "",
    "authors": [
      "Quanling Deng"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2202.09986"
  },
  {
    "id": "arXiv:2202.11345",
    "title": "Prompt-Learning for Short Text Classification",
    "abstract": "Prompt-Learning for Short Text Classification",
    "descriptor": "",
    "authors": [
      "Yi Zhu",
      "Xinke Zhou",
      "Jipeng Qiang",
      "Yun Li",
      "Yunhao Yuan",
      "Xindong Wu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.11345"
  },
  {
    "id": "arXiv:2202.12106",
    "title": "Classification of preordered spaces in terms of monotones -- Filling in  the gaps",
    "abstract": "Classification of preordered spaces in terms of monotones -- Filling in  the gaps",
    "descriptor": "",
    "authors": [
      "Pedro Hack",
      "Daniel A. Braun",
      "Sebastian Gottwald"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Information Theory (cs.IT)",
      "Theoretical Economics (econ.TH)",
      "Functional Analysis (math.FA)"
    ],
    "url": "https://arxiv.org/abs/2202.12106"
  },
  {
    "id": "arXiv:2202.12650",
    "title": "Time-coded Spiking Fourier Transform in Neuromorphic Hardware",
    "abstract": "Comments: Accepted version on IEEE Transactions on Computers (early access). Added copyright notice",
    "descriptor": "\nComments: Accepted version on IEEE Transactions on Computers (early access). Added copyright notice\n",
    "authors": [
      "Javier L\u00f3pez-Randulfe",
      "Nico Reeb",
      "Negin Karimi",
      "Chen Liu",
      "Hector A. Gonzalez",
      "Robin Dietrich",
      "Bernhard Vogginger",
      "Christian Mayr",
      "Alois Knoll"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.12650"
  },
  {
    "id": "arXiv:2202.12740",
    "title": "A note on Cops and Robbers, independence number, domination number and  diameter",
    "abstract": "A note on Cops and Robbers, independence number, domination number and  diameter",
    "descriptor": "",
    "authors": [
      "Jan Petr",
      "Julien Portier",
      "Leo Versteegen"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2202.12740"
  },
  {
    "id": "arXiv:2202.14035",
    "title": "ParaNames: A Massively Multilingual Entity Name Corpus",
    "abstract": "ParaNames: A Massively Multilingual Entity Name Corpus",
    "descriptor": "",
    "authors": [
      "Jonne S\u00e4lev\u00e4",
      "Constantine Lignos"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.14035"
  },
  {
    "id": "arXiv:2203.00116",
    "title": "Enhancing Satellite Imagery using Deep Learning for the Sensor To  Shooter Timeline",
    "abstract": "Comments: 5 Pages, 3 Figures, 1 Table, 39 References",
    "descriptor": "\nComments: 5 Pages, 3 Figures, 1 Table, 39 References\n",
    "authors": [
      "Matthew Ciolino",
      "Dominick Hambrick",
      "David Noever"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2203.00116"
  },
  {
    "id": "arXiv:2203.01322",
    "title": "Recent, rapid advancement in visual question answering architecture: a  review",
    "abstract": "Comments: 11 pages",
    "descriptor": "\nComments: 11 pages\n",
    "authors": [
      "Venkat Kodali",
      "Daniel Berleant"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2203.01322"
  },
  {
    "id": "arXiv:2203.01515",
    "title": "Code Synonyms Do Matter: Multiple Synonyms Matching Network for  Automatic ICD Coding",
    "abstract": "Comments: Accepted by ACL 2022 Main Conference, Short Paper",
    "descriptor": "\nComments: Accepted by ACL 2022 Main Conference, Short Paper\n",
    "authors": [
      "Zheng Yuan",
      "Chuanqi Tan",
      "Songfang Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.01515"
  },
  {
    "id": "arXiv:2203.01779",
    "title": "Exchange distance of basis pairs in split matroids",
    "abstract": "Comments: 17 pages",
    "descriptor": "\nComments: 17 pages\n",
    "authors": [
      "Krist\u00f3f B\u00e9rczi",
      "Tam\u00e1s Schwarcz"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2203.01779"
  },
  {
    "id": "arXiv:2203.01932",
    "title": "Contextual Attention Network: Transformer Meets U-Net",
    "abstract": "Contextual Attention Network: Transformer Meets U-Net",
    "descriptor": "",
    "authors": [
      "Reza Azad",
      "Moein Heidari",
      "Yuli Wu",
      "Dorit Merhof"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.01932"
  },
  {
    "id": "arXiv:2203.01933",
    "title": "Temporal Context Matters: Enhancing Single Image Prediction with Disease  Progression Representations",
    "abstract": "Comments: Accepted in CVPR 2022 (ORAL)",
    "descriptor": "\nComments: Accepted in CVPR 2022 (ORAL)\n",
    "authors": [
      "Aishik Konwer",
      "Xuan Xu",
      "Joseph Bae",
      "Chao Chen",
      "Prateek Prasanna"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.01933"
  },
  {
    "id": "arXiv:2203.02231",
    "title": "OPAL: Occlusion Pattern Aware Loss for Unsupervised Light Field  Disparity Estimation",
    "abstract": "OPAL: Occlusion Pattern Aware Loss for Unsupervised Light Field  Disparity Estimation",
    "descriptor": "",
    "authors": [
      "Peng Li",
      "Jiayin Zhao",
      "Jingyao Wu",
      "Chao Deng",
      "Haoqian Wang",
      "Tao Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.02231"
  },
  {
    "id": "arXiv:2203.02459",
    "title": "From Simultaneous to Streaming Machine Translation by Leveraging  Streaming History",
    "abstract": "Comments: ACL 2022 - Camera ready; v3: expanded data pre-processing",
    "descriptor": "\nComments: ACL 2022 - Camera ready; v3: expanded data pre-processing\n",
    "authors": [
      "Javier Iranzo-S\u00e1nchez",
      "Jorge Civera",
      "Alfons Juan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.02459"
  },
  {
    "id": "arXiv:2203.02884",
    "title": "Towards Self-Supervised Category-Level Object Pose and Size Estimation",
    "abstract": "Towards Self-Supervised Category-Level Object Pose and Size Estimation",
    "descriptor": "",
    "authors": [
      "Yisheng He",
      "Haoqiang Fan",
      "Haibin Huang",
      "Qifeng Chen",
      "Jian Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.02884"
  },
  {
    "id": "arXiv:2203.03123",
    "title": "Mismatch between Multi-turn Dialogue and its Evaluation Metric in  Dialogue State Tracking",
    "abstract": "Comments: ACL 2022 (short)",
    "descriptor": "\nComments: ACL 2022 (short)\n",
    "authors": [
      "Takyoung Kim",
      "Hoonsang Yoon",
      "Yukyung Lee",
      "Pilsung Kang",
      "Misuk Kim"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.03123"
  },
  {
    "id": "arXiv:2203.04114",
    "title": "A study on joint modeling and data augmentation of multi-modalities for  audio-visual scene classification",
    "abstract": "Comments: 5 pages, 1 figure, submitted to INTERSPEECH 2022",
    "descriptor": "\nComments: 5 pages, 1 figure, submitted to INTERSPEECH 2022\n",
    "authors": [
      "Qing Wang",
      "Jun Du",
      "Siyuan Zheng",
      "Yunqing Li",
      "Yajian Wang",
      "Yuzhong Wu",
      "Hu Hu",
      "Chao-Han Huck Yang",
      "Sabato Marco Siniscalchi",
      "Yannan Wang",
      "Chin-Hui Lee"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.04114"
  },
  {
    "id": "arXiv:2203.04121",
    "title": "Few Shot Generative Model Adaption via Relaxed Spatial Structural  Alignment",
    "abstract": "Comments: Accepted by CVPR 2022",
    "descriptor": "\nComments: Accepted by CVPR 2022\n",
    "authors": [
      "Jiayu Xiao",
      "Liang Li",
      "Chaofei Wang",
      "Zheng-Jun Zha",
      "Qingming Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.04121"
  },
  {
    "id": "arXiv:2203.05598",
    "title": "A new approach to calculating BERTScore for automatic assessment of  translation quality",
    "abstract": "Comments: 8 pages, 4 figures, minor changes due to typographical errors",
    "descriptor": "\nComments: 8 pages, 4 figures, minor changes due to typographical errors\n",
    "authors": [
      "A.A. Vetrov",
      "E.A. Gorn"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.05598"
  },
  {
    "id": "arXiv:2203.06250",
    "title": "Learning from humans: combining imitation and deep reinforcement  learning to accomplish human-level performance on a virtual foraging task",
    "abstract": "Comments: 24 pages, 15 figures",
    "descriptor": "\nComments: 24 pages, 15 figures\n",
    "authors": [
      "Vittorio Giammarino",
      "Matthew F Dunne",
      "Kylie N Moore",
      "Michael E Hasselmo",
      "Chantal E Stern",
      "Ioannis Ch. Paschalidis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.06250"
  },
  {
    "id": "arXiv:2203.06358",
    "title": "Throughput Maximization for UAV-enabled Integrated Periodic Sensing and  Communication",
    "abstract": "Comments: 32 pages, This work has been submitted to the IEEE for possible publication",
    "descriptor": "\nComments: 32 pages, This work has been submitted to the IEEE for possible publication\n",
    "authors": [
      "Kaitao Meng",
      "Qingqing Wu",
      "Shaodan Ma",
      "Wen Chen",
      "Kunlun Wang",
      "Jun Li"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2203.06358"
  },
  {
    "id": "arXiv:2203.06398",
    "title": "SIGMA: Semantic-complete Graph Matching for Domain Adaptive Object  Detection",
    "abstract": "Comments: Accepted by CVPR2022 (ORAL presentation)",
    "descriptor": "\nComments: Accepted by CVPR2022 (ORAL presentation)\n",
    "authors": [
      "Wuyang Li",
      "Xinyu Liu",
      "Yixuan Yuan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.06398"
  },
  {
    "id": "arXiv:2203.06871",
    "title": "Block-STM: Scaling Blockchain Execution by Turning Ordering Curse to a  Performance Blessing",
    "abstract": "Block-STM: Scaling Blockchain Execution by Turning Ordering Curse to a  Performance Blessing",
    "descriptor": "",
    "authors": [
      "Rati Gelashvili",
      "Alexander Spiegelman",
      "Zhuolun Xiang",
      "George Danezis",
      "Zekun Li",
      "Yu Xia",
      "Runtian Zhou",
      "Dahlia Malkhi"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2203.06871"
  },
  {
    "id": "arXiv:2203.07194",
    "title": "Strict stability of extension types",
    "abstract": "Comments: 16 pages. This text is essentially Chapter 6 from author's PhD thesis arXiv:2202.13132. Updated acknowledgments. Submitted, but comments welcome!",
    "descriptor": "\nComments: 16 pages. This text is essentially Chapter 6 from author's PhD thesis arXiv:2202.13132. Updated acknowledgments. Submitted, but comments welcome!\n",
    "authors": [
      "Jonathan Weinberger"
    ],
    "subjectives": [
      "Category Theory (math.CT)",
      "Logic in Computer Science (cs.LO)",
      "Logic (math.LO)"
    ],
    "url": "https://arxiv.org/abs/2203.07194"
  },
  {
    "id": "arXiv:2203.07836",
    "title": "Graph Pre-training for AMR Parsing and Generation",
    "abstract": "Comments: ACL2022 camera-ready final version",
    "descriptor": "\nComments: ACL2022 camera-ready final version\n",
    "authors": [
      "Xuefeng Bai",
      "Yulong Chen",
      "Yue Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.07836"
  },
  {
    "id": "arXiv:2203.08516",
    "title": "Fantastic Style Channels and Where to Find Them: A Submodular Framework  for Discovering Diverse Directions in GANs",
    "abstract": "Fantastic Style Channels and Where to Find Them: A Submodular Framework  for Discovering Diverse Directions in GANs",
    "descriptor": "",
    "authors": [
      "Enis Simsar",
      "Umut Kocasari",
      "Ezgi G\u00fclperi Er",
      "Pinar Yanardag"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.08516"
  },
  {
    "id": "arXiv:2203.08537",
    "title": "Scribble-Supervised LiDAR Semantic Segmentation",
    "abstract": "Comments: Accepted at CVPR 2022 (ORAL)",
    "descriptor": "\nComments: Accepted at CVPR 2022 (ORAL)\n",
    "authors": [
      "Ozan Unal",
      "Dengxin Dai",
      "Luc Van Gool"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.08537"
  },
  {
    "id": "arXiv:2203.09611",
    "title": "STICC: A multivariate spatial clustering method for repeated geographic  pattern discovery with consideration of spatial contiguity",
    "abstract": "STICC: A multivariate spatial clustering method for repeated geographic  pattern discovery with consideration of spatial contiguity",
    "descriptor": "",
    "authors": [
      "Yuhao Kang",
      "Kunlin Wu",
      "Song Gao",
      "Ignavier Ng",
      "Jinmeng Rao",
      "Shan Ye",
      "Fan Zhang",
      "Teng Fei"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)",
      "Social and Information Networks (cs.SI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.09611"
  },
  {
    "id": "arXiv:2203.09725",
    "title": "Forward-Looking Dynamic Persuasion for Pipeline Stochastic Bayesian  Game: A Fixed-Point Alignment Principle",
    "abstract": "Forward-Looking Dynamic Persuasion for Pipeline Stochastic Bayesian  Game: A Fixed-Point Alignment Principle",
    "descriptor": "",
    "authors": [
      "Tao Zhang",
      "Quanyan Zhu"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.09725"
  },
  {
    "id": "arXiv:2203.09767",
    "title": "Speaker Embedding-aware Neural Diarization: an Efficient Framework for  Overlapping Speech Diarization in Meeting Scenarios",
    "abstract": "Comments: Submitted to INTERSPEECH 2022, 5 parges, 2 figure",
    "descriptor": "\nComments: Submitted to INTERSPEECH 2022, 5 parges, 2 figure\n",
    "authors": [
      "Zhihao Du",
      "Shiliang Zhang",
      "Siqi Zheng",
      "Zhijie Yan"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.09767"
  },
  {
    "id": "arXiv:2203.12187",
    "title": "Converse: A Tree-Based Modular Task-Oriented Dialogue System",
    "abstract": "Converse: A Tree-Based Modular Task-Oriented Dialogue System",
    "descriptor": "",
    "authors": [
      "Tian Xie",
      "Xinyi Yang",
      "Angela S. Lin",
      "Feihong Wu",
      "Kazuma Hashimoto",
      "Jin Qu",
      "Young Mo Kang",
      "Wenpeng Yin",
      "Huan Wang",
      "Semih Yavuz",
      "Gang Wu",
      "Michael Jones",
      "Richard Socher",
      "Yingbo Zhou",
      "Wenhao Liu",
      "Caiming Xiong"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.12187"
  },
  {
    "id": "arXiv:2203.12216",
    "title": "Minimizing Age-upon-Decisions in Bufferless System: Service Scheduling  and Decision Interval",
    "abstract": "Minimizing Age-upon-Decisions in Bufferless System: Service Scheduling  and Decision Interval",
    "descriptor": "",
    "authors": [
      "Shutong Chen",
      "Tianci Zhang",
      "Zhengchuan Chen",
      "Yunquan Dong",
      "Min Wang",
      "Yunjian Jia",
      "Tony Q. S. Quek"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2203.12216"
  },
  {
    "id": "arXiv:2203.12467",
    "title": "A Lower-bound for Variable-length Source Coding in LQG Feedback Control",
    "abstract": "Comments: Under dual submission to the IEEE Control Systems Letters and the 61st IEEE Conference on Decision and Control. This version fixed typo in the references for the original version",
    "descriptor": "\nComments: Under dual submission to the IEEE Control Systems Letters and the 61st IEEE Conference on Decision and Control. This version fixed typo in the references for the original version\n",
    "authors": [
      "Travis C. Cuvelier",
      "Takashi Tanaka",
      "Robert W. Heath Jr"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2203.12467"
  },
  {
    "id": "arXiv:2203.12692",
    "title": "Affective Feedback Synthesis Towards Multimodal Text and Image Data",
    "abstract": "Comments: Submitted to ACM Transactions on Multimedia Computing, Communications, and Applications",
    "descriptor": "\nComments: Submitted to ACM Transactions on Multimedia Computing, Communications, and Applications\n",
    "authors": [
      "Puneet Kumar",
      "Gaurav Bhat",
      "Omkar Ingle",
      "Daksh Goyal",
      "Balasubramanian Raman"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.12692"
  },
  {
    "id": "arXiv:2203.12759",
    "title": "Asynchronous Reinforcement Learning for Real-Time Control of Physical  Robots",
    "abstract": "Comments: Appears in Proceedings of the 2022 International Conference on Robotics and Automation (ICRA). Source code at this https URL and companion video at this https URL",
    "descriptor": "\nComments: Appears in Proceedings of the 2022 International Conference on Robotics and Automation (ICRA). Source code at this https URL and companion video at this https URL\n",
    "authors": [
      "Yufeng Yuan",
      "A. Rupam Mahmood"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.12759"
  },
  {
    "id": "arXiv:2203.13005",
    "title": "GX-Plug: a Middleware for Plugging Accelerators to Distributed Graph  Processing",
    "abstract": "Comments: 13 pages",
    "descriptor": "\nComments: 13 pages\n",
    "authors": [
      "Kai Zou",
      "Xike Xie",
      "Qi Li",
      "Deyu Kong"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2203.13005"
  },
  {
    "id": "arXiv:2203.13015",
    "title": "The SAGEX Review on Scattering Amplitudes, Chapter 4: Multi-loop Feynman  Integrals",
    "abstract": "Comments: 40 pages, see the overview article arXiv:2203.13011",
    "descriptor": "\nComments: 40 pages, see the overview article arXiv:2203.13011\n",
    "authors": [
      "Johannes Bl\u00fcmlein",
      "Carsten Schneider"
    ],
    "subjectives": [
      "High Energy Physics - Theory (hep-th)",
      "Symbolic Computation (cs.SC)"
    ],
    "url": "https://arxiv.org/abs/2203.13015"
  },
  {
    "id": "arXiv:2203.13032",
    "title": "Multi-modal Emotion Estimation for in-the-wild Videos",
    "abstract": "Multi-modal Emotion Estimation for in-the-wild Videos",
    "descriptor": "",
    "authors": [
      "Liyu Meng",
      "Yuchen Liu",
      "Xiaolong Liu",
      "Zhaopei Huang",
      "Yuan Cheng",
      "Meng Wang",
      "Chuanhe Liu",
      "Qin Jin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2203.13032"
  },
  {
    "id": "arXiv:2203.13366",
    "title": "Recommendation as Language Processing (RLP): A Unified Pretrain,  Personalized Prompt & Predict Paradigm (P5)",
    "abstract": "Recommendation as Language Processing (RLP): A Unified Pretrain,  Personalized Prompt & Predict Paradigm (P5)",
    "descriptor": "",
    "authors": [
      "Shijie Geng",
      "Shuchang Liu",
      "Zuohui Fu",
      "Yingqiang Ge",
      "Yongfeng Zhang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.13366"
  },
  {
    "id": "arXiv:2203.13560",
    "title": "MISC: A MIxed Strategy-Aware Model Integrating COMET for Emotional  Support Conversation",
    "abstract": "Comments: 12 pages, 5 figures, accepted by ACL 2022 main conference",
    "descriptor": "\nComments: 12 pages, 5 figures, accepted by ACL 2022 main conference\n",
    "authors": [
      "Quan Tu",
      "Yanran Li",
      "Jianwei Cui",
      "Bin Wang",
      "Ji-Rong Wen",
      "Rui Yan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.13560"
  },
  {
    "id": "arXiv:2203.13686",
    "title": "Image Compression and Actionable Intelligence With Deep Neural Networks",
    "abstract": "Comments: 3 Pages, 2 Figures, 1 Table, 31 Refereneces",
    "descriptor": "\nComments: 3 Pages, 2 Figures, 1 Table, 31 Refereneces\n",
    "authors": [
      "Matthew Ciolino"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2203.13686"
  },
  {
    "id": "arXiv:2203.14452",
    "title": "Optimisation-free Classification and Density Estimation with Quantum  Circuits",
    "abstract": "Comments: Paper condensing experiments shown in QTML 2021",
    "descriptor": "\nComments: Paper condensing experiments shown in QTML 2021\n",
    "authors": [
      "Vladimir Vargas-Calder\u00f3n",
      "Fabio A. Gonz\u00e1lez",
      "Herbert Vinck-Posada"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.14452"
  },
  {
    "id": "arXiv:2203.14542",
    "title": "UNICON: Combating Label Noise Through Uniform Selection and Contrastive  Learning",
    "abstract": "UNICON: Combating Label Noise Through Uniform Selection and Contrastive  Learning",
    "descriptor": "",
    "authors": [
      "Nazmul Karim",
      "Mamshad Nayeem Rizve",
      "Nazanin Rahnavard",
      "Ajmal Mian",
      "Mubarak Shah"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.14542"
  },
  {
    "id": "arXiv:2203.14601",
    "title": "Bribes to Miners: Evidence from Ethereum",
    "abstract": "Bribes to Miners: Evidence from Ethereum",
    "descriptor": "",
    "authors": [
      "Xiaotong Sun"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computational Finance (q-fin.CP)"
    ],
    "url": "https://arxiv.org/abs/2203.14601"
  },
  {
    "id": "arXiv:2203.14699",
    "title": "Towards Stable Interstellar Flight: Levitation of a Laser-Propelled  Sailcraft",
    "abstract": "Comments: A computational error have been found. It will be resubmitted when it will be fixed",
    "descriptor": "\nComments: A computational error have been found. It will be resubmitted when it will be fixed\n",
    "authors": [
      "Afroza Shirin",
      "Edl Schamiloglu",
      "Rafael Fierro"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.14699"
  },
  {
    "id": "arXiv:2203.14864",
    "title": "Chess is hard even for a single player",
    "abstract": "Comments: 22 pages, a slightly shorter version to appear in FUN 2022",
    "descriptor": "\nComments: 22 pages, a slightly shorter version to appear in FUN 2022\n",
    "authors": [
      "N.R. Aravind",
      "Neeldhara Misra",
      "Harshil Mittal"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2203.14864"
  },
  {
    "id": "arXiv:2203.15287",
    "title": "Accelerating Code Search with Deep Hashing and Code Classification",
    "abstract": "Comments: Accepted to 60th Annual Meeting of the Association for Computational Linguistics (ACL 2022)",
    "descriptor": "\nComments: Accepted to 60th Annual Meeting of the Association for Computational Linguistics (ACL 2022)\n",
    "authors": [
      "Wenchao Gu",
      "Yanlin Wang",
      "Lun Du",
      "Hongyu Zhang",
      "Shi Han",
      "Dongmei Zhang",
      "Michael R. Lyu"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.15287"
  },
  {
    "id": "arXiv:2203.15536",
    "title": "BARC: Learning to Regress 3D Dog Shape from Images by Exploiting Breed  Information",
    "abstract": "Comments: accepted for publication at CVPR 2022",
    "descriptor": "\nComments: accepted for publication at CVPR 2022\n",
    "authors": [
      "Nadine Rueegg",
      "Silvia Zuffi",
      "Konrad Schindler",
      "Michael J. Black"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.15536"
  },
  {
    "id": "arXiv:2203.15547",
    "title": "ME-CapsNet: A Multi-Enhanced Capsule Networks with Routing Mechanism",
    "abstract": "Comments: Submitted to 8th IEEE International Conference on Electronics, Computing and Communication Technologies (IEEE CONECCT'22)",
    "descriptor": "\nComments: Submitted to 8th IEEE International Conference on Electronics, Computing and Communication Technologies (IEEE CONECCT'22)\n",
    "authors": [
      "Jerrin Bright",
      "Suryaprakash Rajkumar",
      "Arockia Selvakumar Arockia Doss"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.15547"
  },
  {
    "id": "arXiv:2203.15588",
    "title": "Deep Multi-modal Fusion of Image and Non-image Data in Disease Diagnosis  and Prognosis: A Review",
    "abstract": "Deep Multi-modal Fusion of Image and Non-image Data in Disease Diagnosis  and Prognosis: A Review",
    "descriptor": "",
    "authors": [
      "Can Cui",
      "Haichun Yang",
      "Yaohong Wang",
      "Shilin Zhao",
      "Zuhayr Asad",
      "Lori A. Coburn",
      "Keith T. Wilson",
      "Bennett A. Landman",
      "Yuankai Huo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.15588"
  },
  {
    "id": "arXiv:2203.15640",
    "title": "Synthesis and Execution of Communicative Robotic Movements with  Generative Adversarial Networks",
    "abstract": "Comments: Submitted to the Special Issue on Emerging Topics on Development and Learning, IEEE TCDS. Unpublished, review process ongoing. Luca Garello and Linda Lastrico contributed equally to this work, hence they share the first name",
    "descriptor": "\nComments: Submitted to the Special Issue on Emerging Topics on Development and Learning, IEEE TCDS. Unpublished, review process ongoing. Luca Garello and Linda Lastrico contributed equally to this work, hence they share the first name\n",
    "authors": [
      "Luca Garello",
      "Linda Lastrico",
      "Alessandra Sciutti",
      "Nicoletta Noceti",
      "Fulvio Mastrogiovanni",
      "Francesco Rea"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.15640"
  },
  {
    "id": "arXiv:2203.15795",
    "title": "Not Another School Resource Map: Meeting Underserved Families'  Information Needs Requires Trusting Relationships and Personalized Care",
    "abstract": "Comments: To appear in CSCW 2022",
    "descriptor": "\nComments: To appear in CSCW 2022\n",
    "authors": [
      "Samantha Robertson",
      "Tonya Nguyen",
      "Niloufar Salehi"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2203.15795"
  },
  {
    "id": "arXiv:2203.15872",
    "title": "Protective Mission against a Highly Maneuverable Rogue Drone Using  Defense Margin Strategy",
    "abstract": "Protective Mission against a Highly Maneuverable Rogue Drone Using  Defense Margin Strategy",
    "descriptor": "",
    "authors": [
      "Minjun Sung",
      "Christophe Johannes Hiltebrandt-McIntosh",
      "Hunmin Kim",
      "Naira Hovakimyan"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.15872"
  },
  {
    "id": "arXiv:2203.15878",
    "title": "Characterizations of graph classes via convex geometries: A survey",
    "abstract": "Comments: 16 pages",
    "descriptor": "\nComments: 16 pages\n",
    "authors": [
      "Mitre C. Dourado",
      "F\u00e1bio Protti",
      "Rudini Sampaio"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2203.15878"
  },
  {
    "id": "arXiv:2203.15880",
    "title": "Proactive Image Manipulation Detection",
    "abstract": "Comments: Published at CVPR 2022",
    "descriptor": "\nComments: Published at CVPR 2022\n",
    "authors": [
      "Vishal Asnani",
      "Xi Yin",
      "Tal Hassner",
      "Sijia Liu",
      "Xiaoming Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.15880"
  },
  {
    "id": "arXiv:2203.15884",
    "title": "Radial Autoencoders for Enhanced Anomaly Detection",
    "abstract": "Radial Autoencoders for Enhanced Anomaly Detection",
    "descriptor": "",
    "authors": [
      "Mihai-Cezar Augustin",
      "Vivien Bonvin",
      "Regis Houssou",
      "Efstratios Rappos",
      "Stephan Robert-Nicoud"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.15884"
  },
  {
    "id": "arXiv:2203.15924",
    "title": "Hybrid of monolithic and staggered solution techniques for the  computational analysis of fracture, assessed on fibrous network mechanics",
    "abstract": "Comments: Numerical Analysis (math.NA)",
    "descriptor": "\nComments: Numerical Analysis (math.NA)\n",
    "authors": [
      "Vedad Tojaga",
      "Artem Kulachenko",
      "Soren Ostlund",
      "T. Christian Gasser"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2203.15924"
  },
  {
    "id": "arXiv:2203.15935",
    "title": "Graph Neural Networks in IoT: A Survey",
    "abstract": "Graph Neural Networks in IoT: A Survey",
    "descriptor": "",
    "authors": [
      "Guimin Dong",
      "Mingyue Tang",
      "Zhiyuan Wang",
      "Jiechao Gao",
      "Sikun Guo",
      "Lihua Cai",
      "Robert Gutierrez",
      "Bradford Campbell",
      "Laura E. Barnes",
      "Mehdi Boukhechba"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.15935"
  },
  {
    "id": "arXiv:2203.16024",
    "title": "Longitudinal Fairness with Censorship",
    "abstract": "Comments: Accepted to AAAI 2022",
    "descriptor": "\nComments: Accepted to AAAI 2022\n",
    "authors": [
      "Wenbin Zhang",
      "Jeremy C. Weiss"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2203.16024"
  },
  {
    "id": "arXiv:2203.16263",
    "title": "Does Audio Deepfake Detection Generalize?",
    "abstract": "Comments: Submitted to Interspeech 2022",
    "descriptor": "\nComments: Submitted to Interspeech 2022\n",
    "authors": [
      "Nicolas M. M\u00fcller",
      "Pavel Czempin",
      "Franziska Dieckmann",
      "Adam Froghyar",
      "Konstantin B\u00f6ttinger"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.16263"
  },
  {
    "id": "arXiv:2203.16297",
    "title": "Forecasting from LiDAR via Future Object Detection",
    "abstract": "Comments: This work has been accepted to Computer Vision and Pattern Recognition (CVPR) 2022",
    "descriptor": "\nComments: This work has been accepted to Computer Vision and Pattern Recognition (CVPR) 2022\n",
    "authors": [
      "Neehar Peri",
      "Jonathon Luiten",
      "Mengtian Li",
      "Aljo\u0161a O\u0161ep",
      "Laura Leal-Taix\u00e9",
      "Deva Ramanan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.16297"
  },
  {
    "id": "arXiv:2203.16336",
    "title": "TraHGR: Transformer for Hand Gesture Recognition via ElectroMyography",
    "abstract": "TraHGR: Transformer for Hand Gesture Recognition via ElectroMyography",
    "descriptor": "",
    "authors": [
      "Soheil Zabihi",
      "Elahe Rahimian",
      "Amir Asif",
      "Arash Mohammadi"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.16336"
  },
  {
    "id": "arXiv:2203.16349",
    "title": "The Block-based Mobile PDE Systems Are Not Secure -- Experimental  Attacks",
    "abstract": "The Block-based Mobile PDE Systems Are Not Secure -- Experimental  Attacks",
    "descriptor": "",
    "authors": [
      "Niusen Chen",
      "Bo Chen",
      "Weisong Shi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2203.16349"
  },
  {
    "id": "arXiv:2203.16415",
    "title": "The impact of using voxel-level segmentation metrics on evaluating  multifocal prostate cancer localisation",
    "abstract": "The impact of using voxel-level segmentation metrics on evaluating  multifocal prostate cancer localisation",
    "descriptor": "",
    "authors": [
      "Wen Yan",
      "Qianye Yang",
      "Tom Syer",
      "Zhe Min",
      "Shonit Punwani",
      "Mark Emberton",
      "Dean C. Barratt",
      "Bernard Chiu",
      "Yipeng Hu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.16415"
  },
  {
    "id": "arXiv:2203.16446",
    "title": "Near-Optimal Weighted Matrix Completion",
    "abstract": "Comments: 36 pages, 2 figures",
    "descriptor": "\nComments: 36 pages, 2 figures\n",
    "authors": [
      "Oscar L\u00f3pez"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2203.16446"
  },
  {
    "id": "arXiv:2203.16487",
    "title": "Lossless Speedup of Autoregressive Translation with Generalized  Aggressive Decoding",
    "abstract": "Comments: Work in progress",
    "descriptor": "\nComments: Work in progress\n",
    "authors": [
      "Heming Xia",
      "Tao Ge",
      "Furu Wei",
      "Zhifang Sui"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.16487"
  },
  {
    "id": "arXiv:2203.16505",
    "title": "Fast, Accurate and Memory-Efficient Partial Permutation Synchronization",
    "abstract": "Comments: Accepted to CVPR 2022",
    "descriptor": "\nComments: Accepted to CVPR 2022\n",
    "authors": [
      "Shaohan Li",
      "Yunpeng Shi",
      "Gilad Lerman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Numerical Analysis (math.NA)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.16505"
  },
  {
    "id": "arXiv:2203.16507",
    "title": "AdaMixer: A Fast-Converging Query-Based Object Detector",
    "abstract": "Comments: Accepted to CVPR 2022 (oral presentation)",
    "descriptor": "\nComments: Accepted to CVPR 2022 (oral presentation)\n",
    "authors": [
      "Ziteng Gao",
      "Limin Wang",
      "Bing Han",
      "Sheng Guo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.16507"
  }
]
[
  {
    "id": "arXiv:2204.04213",
    "title": "Structure-aware Protein Self-supervised Learning",
    "abstract": "Protein representation learning methods have shown great potential to yield\nuseful representation for many downstream tasks, especially on protein\nclassification. Moreover, a few recent studies have shown great promise in\naddressing insufficient labels of proteins with self-supervised learning\nmethods. However, existing protein language models are usually pretrained on\nprotein sequences without considering the important protein structural\ninformation. To this end, we propose a novel structure-aware protein\nself-supervised learning method to effectively capture structural information\nof proteins. In particular, a well-designed graph neural network (GNN) model is\npretrained to preserve the protein structural information with self-supervised\ntasks from a pairwise residue distance perspective and a dihedral angle\nperspective, respectively. Furthermore, we propose to leverage the available\nprotein language model pretrained on protein sequences to enhance the\nself-supervised learning. Specifically, we identify the relation between the\nsequential information in the protein language model and the structural\ninformation in the specially designed GNN model via a novel pseudo bi-level\noptimization scheme. Experiments on several supervised downstream tasks verify\nthe effectiveness of our proposed method.",
    "descriptor": "\nComments: 7 pages and 4 figures\n",
    "authors": [
      "Can Chen",
      "Jingbo Zhou",
      "Fan Wang",
      "Xue Liu",
      "Dejing Dou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2204.04213"
  },
  {
    "id": "arXiv:2204.04215",
    "title": "Data-Free Quantization with Accurate Activation Clipping and Adaptive  Batch Normalization",
    "abstract": "Data-free quantization is a task that compresses the neural network to low\nbit-width without access to original training data. Most existing data-free\nquantization methods cause severe performance degradation due to inaccurate\nactivation clipping range and quantization error, especially for low bit-width.\nIn this paper, we present a simple yet effective data-free quantization method\nwith accurate activation clipping and adaptive batch normalization. Accurate\nactivation clipping (AAC) improves the model accuracy by exploiting accurate\nactivation information from the full-precision model. Adaptive batch\nnormalization firstly proposes to address the quantization error from\ndistribution changes by updating the batch normalization layer adaptively.\nExtensive experiments demonstrate that the proposed data-free quantization\nmethod can yield surprisingly performance, achieving 64.33% top-1 accuracy of\nResNet18 on ImageNet dataset, with 3.7% absolute improvement outperforming the\nexisting state-of-the-art methods.",
    "descriptor": "\nComments: submitted to ICML2022\n",
    "authors": [
      "Yefei He",
      "Luoming Zhang",
      "Weijia Wu",
      "Hong Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2204.04215"
  },
  {
    "id": "arXiv:2204.04220",
    "title": "Characterizing and Understanding the Behavior of Quantized Models for  Reliable Deployment",
    "abstract": "Deep Neural Networks (DNNs) have gained considerable attention in the past\ndecades due to their astounding performance in different applications, such as\nnatural language modeling, self-driving assistance, and source code\nunderstanding. With rapid exploration, more and more complex DNN architectures\nhave been proposed along with huge pre-trained model parameters. The common way\nto use such DNN models in user-friendly devices (e.g., mobile phones) is to\nperform model compression before deployment. However, recent research has\ndemonstrated that model compression, e.g., model quantization, yields accuracy\ndegradation as well as outputs disagreements when tested on unseen data. Since\nthe unseen data always include distribution shifts and often appear in the\nwild, the quality and reliability of quantized models are not ensured. In this\npaper, we conduct a comprehensive study to characterize and help users\nunderstand the behaviors of quantized models. Our study considers 4 datasets\nspanning from image to text, 8 DNN architectures including feed-forward neural\nnetworks and recurrent neural networks, and 42 shifted sets with both synthetic\nand natural distribution shifts. The results reveal that 1) data with\ndistribution shifts happen more disagreements than without. 2)\nQuantization-aware training can produce more stable models than standard,\nadversarial, and Mixup training. 3) Disagreements often have closer top-1 and\ntop-2 output probabilities, and $Margin$ is a better indicator than the other\nuncertainty metrics to distinguish disagreements. 4) Retraining with\ndisagreements has limited efficiency in removing disagreements. We opensource\nour code and models as a new benchmark for further studying the quantized\nmodels.",
    "descriptor": "\nComments: 12 pages\n",
    "authors": [
      "Qiang Hu",
      "Yuejun Guo",
      "Maxime Cordy",
      "Xiaofei Xie",
      "Wei Ma",
      "Mike Papadakis",
      "Yves Le Traon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2204.04220"
  },
  {
    "id": "arXiv:2204.04221",
    "title": "CookieEnforcer: Automated Cookie Notice Analysis and Enforcement",
    "abstract": "Online websites use cookie notices to elicit consent from the users, as\nrequired by recent privacy regulations like the GDPR and the CCPA. Prior work\nhas shown that these notices use dark patterns to manipulate users into making\nwebsite-friendly choices which put users' privacy at risk. In this work, we\ndevelop CookieEnforcer, a new system for automatically discovering cookie\nnotices and deciding on the options that result in disabling all non-essential\ncookies. In order to achieve this, we first build an automatic cookie notice\ndetector that utilizes the rendering pattern of the HTML elements to identify\nthe cookie notices. Next, CookieEnforcer analyzes the cookie notices and\npredicts the set of actions required to disable all unnecessary cookies. This\nis done by modeling the problem as a sequence-to-sequence task, where the input\nis a machine-readable cookie notice and the output is the set of clicks to\nmake. We demonstrate the efficacy of CookieEnforcer via an end-to-end accuracy\nevaluation, showing that it can generate the required steps in 91% of the\ncases. Via a user study, we show that CookieEnforcer can significantly reduce\nthe user effort. Finally, we use our system to perform several measurements on\nthe top 5k websites from the Tranco list (as accessed from the US and the UK),\ndrawing comparisons and observations at scale.",
    "descriptor": "",
    "authors": [
      "Rishabh Khandelwal",
      "Asmit Nayak",
      "Hamza Harkous",
      "Kassem Fawaz"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2204.04221"
  },
  {
    "id": "arXiv:2204.04235",
    "title": "Vision-Based American Sign Language Classification Approach via Deep  Learning",
    "abstract": "Hearing-impaired is the disability of partial or total hearing loss that\ncauses a significant problem for communication with other people in society.\nAmerican Sign Language (ASL) is one of the sign languages that most commonly\nused language used by Hearing impaired communities to communicate with each\nother. In this paper, we proposed a simple deep learning model that aims to\nclassify the American Sign Language letters as a step in a path for removing\ncommunication barriers that are related to disabilities.",
    "descriptor": "\nComments: 4 pages, Accepted in the The Florida AI Research Society (FLAIRS-35) 2022\n",
    "authors": [
      "Nelly Elsayed",
      "Zag ElSayed",
      "Anthony S. Maida"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.04235"
  },
  {
    "id": "arXiv:2204.04236",
    "title": "ChildCI Framework: Analysis of Motor and Cognitive Development in  Children-Computer Interaction for Age Detection",
    "abstract": "This article presents a comprehensive analysis of the different tests\nproposed in the recent ChildCI framework, proving its potential for generating\na better understanding of children's neuromotor and cognitive development along\ntime, as well as their possible application in other research areas such as\ne-Health and e-Learning. In particular, we propose a set of over 100 global\nfeatures related to motor and cognitive aspects of the children interaction\nwith mobile devices, some of them collected and adapted from the literature.\nFurthermore, we analyse the robustness and discriminative power of the proposed\nfeature set including experimental results for the task of children age group\ndetection based on their motor and cognitive behaviors. Two different scenarios\nare considered in this study: i) single-test scenario, and ii) multiple-test\nscenario. Results over 93% accuracy are achieved using the publicly available\nChildCIdb_v1 database (over 400 children from 18 months to 8 years old),\nproving the high correlation of children's age with the way they interact with\nmobile devices.",
    "descriptor": "\nComments: 11 pages, 2 figures, 6 tables\n",
    "authors": [
      "Juan Carlos Ruiz-Garcia",
      "Ruben Tolosana",
      "Ruben Vera-Rodriguez",
      "Jaime Herreros-Rodriguez"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.04236"
  },
  {
    "id": "arXiv:2204.04238",
    "title": "Elastic shape analysis of surfaces with second-order Sobolev metrics: a  comprehensive numerical framework",
    "abstract": "This paper introduces a set of numerical methods for Riemannian shape\nanalysis of 3D surfaces within the setting of invariant (elastic) second-order\nSobolev metrics. More specifically, we address the computation of geodesics and\ngeodesic distances between parametrized or unparametrized immersed surfaces\nrepresented as 3D meshes. Building on this, we develop tools for the\nstatistical shape analysis of sets of surfaces, including methods for\nestimating Karcher means and performing tangent PCA on shape populations, and\nfor computing parallel transport along paths of surfaces. Our proposed approach\nfundamentally relies on a relaxed variational formulation for the geodesic\nmatching problem via the use of varifold fidelity terms, which enable us to\nenforce reparametrization independence when computing geodesics between\nunparametrized surfaces, while also yielding versatile algorithms that allow us\nto compare surfaces with varying sampling or mesh structures. Importantly, we\ndemonstrate how our relaxed variational framework can be extended to tackle\npartially observed data. The different benefits of our numerical pipeline are\nillustrated over various examples, synthetic and real.",
    "descriptor": "\nComments: 25 pages, 16 figures, 1 table\n",
    "authors": [
      "Emmanuel Hartman",
      "Yashil Sukurdeep",
      "Eric Klassen",
      "Nicolas Charon",
      "Martin Bauer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.04238"
  },
  {
    "id": "arXiv:2204.04240",
    "title": "Controlling Traffic with Humanoid Social Robot",
    "abstract": "The advancement of technology such as artificial intelligence, machine\nlearning and internet of things it became easy to develop more humanoid robots\nand automate different processes. An interactive robot must have high social\nbehavior so that it can be easily accepted by the people using it. In this\nstudy we designed a traffic police robot (TRAPROB) to automate the traffic\ncontrol at intersection. The human police officer experiences high stress\nbecause of long duty hours as well as pose the risk of accidents. The digital\nelectronic signals are automatic but we want to create a system which is more\nhuman like and looks like an officer controlling the traffic at intersection.\nWe used Thiago++ robot in this study and modified its look to like a police\nofficer, and then programmed it to imitate and make gestures just like traffic\npolice officer makes gestures for controlling traffic. We evaluated the looks,\ngestures, functionality, and social behavior of the robot. We asked a limited\nsample of two participants to identify the TRAPBOT, rate its look, the social\nbehaviors and gestures in comparison to a real life police officer. we found\nthat people can identify the robot as traffic police robot. Our analysis also\nshows that TRAPBOT has appearance like a traffic robot and can make similar\nsignal gestures as a traffic police officer.",
    "descriptor": "\nComments: 10 Pages, 21 figures\n",
    "authors": [
      "Faisal Ghaffar"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2204.04240"
  },
  {
    "id": "arXiv:2204.04242",
    "title": "Exploiting complex pattern features for interactive pattern mining",
    "abstract": "Recent years have seen a shift from a pattern mining process that has users\ndefine constraints before-hand, and sift through the results afterwards, to an\ninteractive one. This new framework depends on exploiting user feedback to\nlearn a quality function for patterns. Existing approaches have a weakness in\nthat they use static pre-defined low-level features, and attempt to learn\nindependent weights representing their importance to the user. As an\nalternative, we propose to work with more complex features that are derived\ndirectly from the pattern ranking imposed by the user. Learned weights are then\naggregated onto lower-level features and help to drive the quality function in\nthe right direction. We explore the effect of different parameter choices\nexperimentally and find that using higher-complexity features leads to the\nselection of patterns that are better aligned with a hidden quality function\nwhile not adding significantly to the run times of the method.\nGetting good user feedback requires to quickly present diverse patterns,\nsomething that we achieve but pushing an existing diversity constraint into the\nsampling component of the interactive mining system LetSip. Resulting patterns\nallow in most cases to converge to a good solution more quickly.\nCombining the two improvements, finally, leads to an algorithm showing clear\nadvantages over the existing state-of-the-art.",
    "descriptor": "",
    "authors": [
      "Arnold Hien",
      "Samir Loudni",
      "Noureddine Aribi",
      "Abdelkader Ouali",
      "Albrecht Zimmermann"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.04242"
  },
  {
    "id": "arXiv:2204.04244",
    "title": "How does online teamwork change student communication patterns in  programming courses?",
    "abstract": "Online teaching has become a new reality due to the COVID-19 pandemic raising\na lot of questions about its learning outcomes. Recent studies have shown that\npeer communication positively affects learning outcomes of online teaching.\nHowever, it is not clear how collaborative programming tasks change peer\ncommunication patterns in the learning process. In this study, we compare\ncommunication patterns in MOOCs where peer communication is limited with those\nof a blended course in which students are involved in online peer instruction.\nWe used a mixed-method approach comprising automated text analysis and\ncommunity extraction with further qualitative analysis. The results show that\nstudents prefer to seek help in programming from peers and not the teacher.\nTeam assignment helped to support this habit. Students communicated more\npositively and intensively with each other, while only team leaders\ncommunicated with the instructor reducing teacher overload. This shift could\nexplain how peer communication improves learning outcomes, as has been shown in\nprevious studies on MOOCs.",
    "descriptor": "\nComments: 11 pages, 5 figures, 2 tables\n",
    "authors": [
      "Natalya Kozhevnikova"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2204.04244"
  },
  {
    "id": "arXiv:2204.04245",
    "title": "Online Emotions During the Storming of the U.S. Capitol: Evidence from  the Social Media Network Parler",
    "abstract": "The storming of the U.S. Capitol on January 6, 2021 has led to the killing of\n5 people and is widely regarded as an attack on democracy. The storming was\nlargely coordinated through social media networks such as Twitter and \"Parler\".\nYet little is known regarding how users interacted on Parler during the\nstorming of the Capitol. In this work, we examine the emotion dynamics on\nParler during the storming with regard to heterogeneity across time and users.\nFor this, we segment the user base into different groups (e.g., Trump\nsupporters and QAnon supporters). We use affective computing to infer the\nemotions in content, thereby allowing us to provide a comprehensive assessment\nof online emotions. Our evaluation is based on a large-scale dataset from\nParler, comprising of 717,300 posts from 144,003 users. We find that the user\nbase responded to the storming of the Capitol with an overall negative\nsentiment. Akin to this, Trump supporters also expressed a negative sentiment\nand high levels of unbelief. In contrast to that, QAnon supporters did not\nexpress a more negative sentiment during the storming. We further provide a\ncross-platform analysis and compare the emotion dynamics on Parler and Twitter.\nOur findings point at a comparatively less negative response to the incidents\non Parler compared to Twitter accompanied by higher levels of disapproval and\noutrage. Our contribution to research is three-fold: (1) We identify online\nemotions that were characteristic of the storming; (2) we assess emotion\ndynamics across different user groups on Parler; (3) we compare the emotion\ndynamics on Parler and Twitter. Thereby, our work offers important implications\nfor actively managing online emotions to prevent similar incidents in the\nfuture.",
    "descriptor": "",
    "authors": [
      "Johannes Jakubik",
      "Michael V\u00f6ssing",
      "Dominik B\u00e4r",
      "Nicolas Pr\u00f6llochs",
      "Stefan Feuerriegel"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2204.04245"
  },
  {
    "id": "arXiv:2204.04247",
    "title": "Clone Detection on Large Scala Codebases",
    "abstract": "Code clones are identical or similar code segments. The wide existence of\ncode clones can increase the cost of maintenance and jeopardise the quality of\nsoftware. The research community has developed many techniques to detect code\nclones, however, there is little evidence of how these techniques may perform\nin industrial use cases. In this paper, we aim to uncover the differences when\nsuch techniques are applied in industrial use cases. We conducted large scale\nexperimental research on the performance of two state-of-the-art code clone\ndetection techniques, SourcererCC and AutoenCODE, on both open source projects\nand an industrial project written in the Scala language. Our results reveal\nthat both algorithms perform differently on the industrial project, with the\nlargest drop in precision being 30.7\\%, and the largest increase in recall\nbeing 32.4\\%. By manually labelling samples of the industrial project by its\ndevelopers, we discovered that there are substantially less Type-3 clones in\nthe aforementioned project than that in the open source projects.",
    "descriptor": "\nComments: Presented at IWSC SANER 2020\n",
    "authors": [
      "Wahidur Rahman",
      "Yisen Xu",
      "Fan Pu",
      "Jifeng Xuan",
      "Xiangyang Jia",
      "Michail Basios",
      "Leslie Kanthan",
      "Lingbo Li",
      "Fan Wu",
      "Baowen Xu"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2204.04247"
  },
  {
    "id": "arXiv:2204.04251",
    "title": "A Rotating Proposer Mechanism for Team Formation",
    "abstract": "We present a rotating proposer mechanism for team formation, which implements\na Pareto efficient subgame perfect Nash equilibrium of an extensive-form team\nformation game.",
    "descriptor": "",
    "authors": [
      "Jian Low",
      "Chen Hajaj",
      "Yevgeniy Vorobeychik"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Theoretical Economics (econ.TH)"
    ],
    "url": "https://arxiv.org/abs/2204.04251"
  },
  {
    "id": "arXiv:2204.04254",
    "title": "HBFL: A Hierarchical Blockchain-based Federated Learning Framework for a  Collaborative IoT Intrusion Detection",
    "abstract": "The continuous strengthening of the security posture of IoT ecosystems is\nvital due to the increasing number of interconnected devices and the volume of\nsensitive data shared. The utilisation of Machine Learning (ML) capabilities in\nthe defence against IoT cyber attacks has many potential benefits. However, the\ncurrently proposed frameworks do not consider data privacy, secure\narchitectures, and/or scalable deployments of IoT ecosystems. In this paper, we\npropose a hierarchical blockchain-based federated learning framework to enable\nsecure and privacy-preserved collaborative IoT intrusion detection. We\nhighlight and demonstrate the importance of sharing cyber threat intelligence\namong inter-organisational IoT networks to improve the model's detection\ncapabilities. The proposed ML-based intrusion detection framework follows a\nhierarchical federated learning architecture to ensure the privacy of the\nlearning process and organisational data. The transactions (model updates) and\nprocesses will run on a secure immutable ledger, and the conformance of\nexecuted tasks will be verified by the smart contract. We have tested our\nsolution and demonstrated its feasibility by implementing it and evaluating the\nintrusion detection performance using a key IoT data set. The outcome is a\nsecurely designed ML-based intrusion detection system capable of detecting a\nwide range of malicious activities while preserving data privacy.",
    "descriptor": "",
    "authors": [
      "Mohanad Sarhan",
      "Wai Weng Lo",
      "Siamak Layeghy",
      "Marius Portmann"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2204.04254"
  },
  {
    "id": "arXiv:2204.04256",
    "title": "Interpretable AI for policy-making in pandemics",
    "abstract": "Since the first wave of the COVID-19 pandemic, governments have applied\nrestrictions in order to slow down its spreading. However, creating such\npolicies is hard, especially because the government needs to trade-off the\nspreading of the pandemic with the economic losses. For this reason, several\nworks have applied machine learning techniques, often with the help of\nspecial-purpose simulators, to generate policies that were more effective than\nthe ones obtained by governments. While the performance of such approaches are\npromising, they suffer from a fundamental issue: since such approaches are\nbased on black-box machine learning, their real-world applicability is limited,\nbecause these policies cannot be analyzed, nor tested, and thus they are not\ntrustable. In this work, we employ a recently developed hybrid approach, which\ncombines reinforcement learning with evolutionary computation, for the\ngeneration of interpretable policies for containing the pandemic. These\npolicies, trained on an existing simulator, aim to reduce the spreading of the\npandemic while minimizing the economic losses. Our results show that our\napproach is able to find solutions that are extremely simple, yet very\npowerful. In fact, our approach has significantly better performance (in\nsimulated scenarios) than both previous work and government policies.",
    "descriptor": "\nComments: 6 pages, 3 figures, submitted to GECCO 2022\n",
    "authors": [
      "Leonardo Lucio Custode",
      "Giovanni Iacca"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2204.04256"
  },
  {
    "id": "arXiv:2204.04259",
    "title": "Evaluating the Adversarial Robustness for Fourier Neural Operators",
    "abstract": "In recent years, Machine-Learning (ML)-driven approaches have been widely\nused in scientific discovery domains. Among them, the Fourier Neural Operator\n(FNO) was the first to simulate turbulent flow with zero-shot super-resolution\nand superior accuracy, which significantly improves the speed when compared to\ntraditional partial differential equation (PDE) solvers. To inspect the\ntrustworthiness, we provide the first study on the adversarial robustness of\nscientific discovery models by generating adversarial examples for FNO, based\non norm-bounded data input perturbations. Evaluated on the mean squared error\nbetween the FNO model's output and the PDE solver's output, our results show\nthat the model's robustness degrades rapidly with increasing perturbation\nlevels, particularly in non-simplistic cases like the 2D Darcy and the Navier\ncases. Our research provides a sensitivity analysis tool and evaluation\nprinciples for assessing the adversarial robustness of ML-based scientific\ndiscovery models.",
    "descriptor": "\nComments: Accepted to Workshop on Socially Responsible Machine Learning (SRML), co-located with ICLR 2022\n",
    "authors": [
      "Abolaji D. Adesoji",
      "Pin-Yu Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.04259"
  },
  {
    "id": "arXiv:2204.04260",
    "title": "Do People Trust Robots that Learn in the Home?",
    "abstract": "It is not scalable for assistive robotics to have all functionalities\npre-programmed prior to user introduction. Instead, it is more realistic for\nagents to perform supplemental on site learning. This opportunity to learn user\nand environment particularities is especially helpful for care robots that\nassist with individualized caregiver activities in residential or nursing home\nenvironments. Many assistive robots, ranging in complexity from Roomba to\nPepper, already conduct some of their learning in the home, observable to the\nuser. We lack an understanding of how witnessing this learning impacts the\nuser. Thus, we propose to assess end-user attitudes towards the concept of\nembodied robots that conduct some learning in the home as compared to robots\nthat are delivered fully-capable. In this virtual, between-subjects study, we\nrecruit end users (care-givers and care-takers) from nursing homes, and\ninvestigate user trust in three different domains: navigation, manipulation,\nand preparation. Informed by the first study where we identify agent learning\nas a key factor in determining trust, we propose a second study to explore how\nto modulate that trust. This second, in-person study investigates the\neffectiveness of apologies, explanations of robot failure, and transparency of\nlearning at improving trust in embodied learning robots.",
    "descriptor": "\nComments: Presented at Machine Learning in Human-Robot Collaboration: Bridging the Gap (ML HRC) workshop at HRI 2022\n",
    "authors": [
      "Nina Moorman",
      "Matthew Gombolay"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2204.04260"
  },
  {
    "id": "arXiv:2204.04263",
    "title": "BioRED: A Comprehensive Biomedical Relation Extraction Dataset",
    "abstract": "Automated relation extraction (RE) from biomedical literature is critical for\nmany downstream text mining applications in both research and real-world\nsettings. However, most existing benchmarking datasets for bio-medical RE only\nfocus on relations of a single type (e.g., protein-protein interactions) at the\nsentence level, greatly limiting the development of RE systems in biomedicine.\nIn this work, we first review commonly used named entity recognition (NER) and\nRE datasets. Then we present BioRED, a first-of-its-kind biomedical RE corpus\nwith multiple entity types (e.g., gene/protein, disease, chemical) and relation\npairs (e.g., gene-disease; chemical-chemical), on a set of 600 PubMed articles.\nFurther, we label each relation as describing either a novel finding or\npreviously known background knowledge, enabling automated algorithms to\ndifferentiate between novel and background information. We assess the utility\nof BioRED by benchmarking several existing state-of-the-art methods, including\nBERT-based models, on the NER and RE tasks. Our results show that while\nexisting approaches can reach high performance on the NER task (F-score of\n89.3%), there is much room for improvement for the RE task, especially when\nextracting novel relations (F-score of 47.7%). Our experiments also demonstrate\nthat such a comprehensive dataset can successfully facilitate the development\nof more accurate, efficient, and robust RE systems for biomedicine.",
    "descriptor": "",
    "authors": [
      "Ling Luo",
      "Po-Ting Lai",
      "Chih-Hsuan Wei",
      "Cecilia N Arighi",
      "Zhiyong Lu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.04263"
  },
  {
    "id": "arXiv:2204.04272",
    "title": "Matrix Syncer -- A Multi-chain Data Aggregator For Supporting  Blockchain-based Metaverses",
    "abstract": "Due to the rising complexity of the metaverse's business logic and the\nlow-latency nature of the metaverse, developers typically encounter the\nchallenge of effectively reading, writing, and retrieving historical on-chain\ndata in order to facilitate their functional implementations at scale. While it\nis true that accessing blockchain states is simple, more advanced real-world\noperations such as search, aggregation, and conditional filtering are not\navailable when interacting directly with blockchain networks, particularly when\ndealing with requirements for on-chain event reflection. We offer Matrix\nSyncer, the ultimate middleware that bridges the data access gap between\nblockchains and end-user applications. Matrix Syncer is designed to facilitate\nthe consolidation of on-chain information into a distributed data warehouse\nwhile also enabling customized on-chain state transformation for a scalable\nstorage, access, and retrieval. It offers a unified layer for both on- and\noff-chain state, as well as a fast and flexible atomic query. Matrix Syncer is\neasily incorporated into any infrastructure to aggregate data from various\nblockchains concurrently, such as Ethereum and Flow. The system has been\ndeployed to support several metaverse projects with a total value of more than\n$15 million USD.",
    "descriptor": "",
    "authors": [
      "Xinyao Sun",
      "Yi Lu",
      "Jinghan Sun",
      "Bohao Tang",
      "Kyle D. Rehak",
      "Shuyi Zhang"
    ],
    "subjectives": [
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2204.04272"
  },
  {
    "id": "arXiv:2204.04273",
    "title": "Dimensionality Reduction in Deep Learning via Kronecker Multi-layer  Architectures",
    "abstract": "Deep learning using neural networks is an effective technique for generating\nmodels of complex data. However, training such models can be expensive when\nnetworks have large model capacity resulting from a large number of layers and\nnodes. For training in such a computationally prohibitive regime,\ndimensionality reduction techniques ease the computational burden, and allow\nimplementations of more robust networks. We propose a novel type of such\ndimensionality reduction via a new deep learning architecture based on fast\nmatrix multiplication of a Kronecker product decomposition; in particular our\nnetwork construction can be viewed as a Kronecker product-induced\nsparsification of an \"extended\" fully connected network. Analysis and practical\nexamples show that this architecture allows a neural network to be trained and\nimplemented with a significant reduction in computational time and resources,\nwhile achieving a similar error level compared to a traditional feedforward\nneural network.",
    "descriptor": "\nComments: 24 pages, 29 figures\n",
    "authors": [
      "Jarom D. Hogue",
      "Robert M. Kirby",
      "Akil Narayan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2204.04273"
  },
  {
    "id": "arXiv:2204.04274",
    "title": "String Diagram Rewriting Modulo Commutative Monoid Structure",
    "abstract": "We characterise freely generated props with a chosen commutative monoid\nstructure as certain categories of hypergraphs with interfaces. We use this\nresult to give a sound and complete interpretation of rewriting modulo\ncommutative monoid equations in a prop in terms of double-pushout rewriting of\nhypergraphs.",
    "descriptor": "",
    "authors": [
      "Aleksandar Milosavljevic",
      "Fabio Zanasi"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Category Theory (math.CT)"
    ],
    "url": "https://arxiv.org/abs/2204.04274"
  },
  {
    "id": "arXiv:2204.04279",
    "title": "Grid-connected Soft Switching Partial Resonance Inverter for Distributed  Generation",
    "abstract": "This paper presents current control method for a grid-connected partial\nresonant soft switching inverter. This inverter does not use an electrolytic\ncapacitor and is capable of boosting and bucking the voltage. Grid-connected\ninverters are used to integrate distributed energy sources to the grid. Current\ncontrol is vital in meeting the standards and requirements when connecting to\nthe grid. The closed-loop current regulation for this type of converters is\nanalyzed and design guidelines are provided. The control is implemented in the\nsynchronous frame. In addition active damping techniques using capacitor\nvoltage and inductor voltage feedback is used to mitigate CL filter resonance\nat the output. The mentioned control strategies are implemented on a 400W lab\nprototype and the results are presented",
    "descriptor": "\nComments: To be published at ISIE 2022\n",
    "authors": [
      "Farid Naghavi",
      "Hamid Toliyat"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2204.04279"
  },
  {
    "id": "arXiv:2204.04280",
    "title": "List covering of regular multigraphs",
    "abstract": "A graph covering projection, also known as a locally bijective homomorphism,\nis a mapping between vertices and edges of two graphs which preserves\nincidencies and is a local bijection. This notion stems from topological graph\ntheory, but has also found applications in combinatorics and theoretical\ncomputer science.\nIt has been known that for every fixed simple regular graph $H$ of valency\ngreater than 2, deciding if an input graph covers $H$ is NP-complete. In recent\nyears, topological graph theory has developed into heavily relying on multiple\nedges, loops, and semi-edges, but only partial results on the complexity of\ncovering multigraphs with semi-edges are known so far. In this paper we\nconsider the list version of the problem, called \\textsc{List-$H$-Cover}, where\nthe vertices and edges of the input graph come with lists of admissible\ntargets. Our main result reads that the \\textsc{List-$H$-Cover} problem is\nNP-complete for every regular multigraph $H$ of valency greater than 2 which\ncontains at least one semi-simple vertex (i.e., a vertex which is incident with\nno loops, with no multiple edges and with at most one semi-edge). Using this\nresult we almost show the NP-co/polytime dichotomy for the computational\ncomplexity of \\textsc{ List-$H$-Cover} of cubic multigraphs, leaving just five\nopen cases.",
    "descriptor": "\nComments: Accepted to IWOCA 2022\n",
    "authors": [
      "Jan Bok",
      "Ji\u0159\u00ed Fiala",
      "Nikola Jedli\u010dkov\u00e1",
      "Jan Kratochv\u00edl",
      "Pawe\u0142 Rz\u0105\u017cewski"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2204.04280"
  },
  {
    "id": "arXiv:2204.04282",
    "title": "Classification of Natural Language Processing Techniques for  Requirements Engineering",
    "abstract": "Research in applying natural language processing (NLP) techniques to\nrequirements engineering (RE) tasks spans more than 40 years, from initial\nefforts carried out in the 1980s to more recent attempts with machine learning\n(ML) and deep learning (DL) techniques. However, in spite of the progress, our\nrecent survey shows that there is still a lack of systematic understanding and\norganization of commonly used NLP techniques in RE. We believe one hurdle\nfacing the industry is lack of shared knowledge of NLP techniques and their\nusage in RE tasks. In this paper, we present our effort to synthesize and\norganize 57 most frequently used NLP techniques in RE. We classify these NLP\ntechniques in two ways: first, by their NLP tasks in typical pipelines and\nsecond, by their linguist analysis levels. We believe these two ways of\nclassification are complementary, contributing to a better understanding of the\nNLP techniques in RE and such understanding is crucial to the development of\nbetter NLP tools for RE.",
    "descriptor": "\nComments: 10 pages, 4 tables, 1 figure\n",
    "authors": [
      "Liping Zhao",
      "Waad Alhoshan",
      "Alessio Ferrari",
      "Keletso J. Letsholo"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2204.04282"
  },
  {
    "id": "arXiv:2204.04285",
    "title": "On Improving Cross-dataset Generalization of Deepfake Detectors",
    "abstract": "Facial manipulation by deep fake has caused major security risks and raised\nsevere societal concerns. As a countermeasure, a number of deep fake detection\nmethods have been proposed recently. Most of them model deep fake detection as\na binary classification problem using a backbone convolutional neural network\n(CNN) architecture pretrained for the task. These CNN-based methods have\ndemonstrated very high efficacy in deep fake detection with the Area under the\nCurve (AUC) as high as 0.99. However, the performance of these methods degrades\nsignificantly when evaluated across datasets. In this paper, we formulate deep\nfake detection as a hybrid combination of supervised and reinforcement learning\n(RL) to improve its cross-dataset generalization performance. The proposed\nmethod chooses the top-k augmentations for each test sample by an RL agent in\nan image-specific manner. The classification scores, obtained using CNN, of all\nthe augmentations of each test image are averaged together for final real or\nfake classification. Through extensive experimental validation, we demonstrate\nthe superiority of our method over existing published research in cross-dataset\ngeneralization of deep fake detectors, thus obtaining state-of-the-art\nperformance.",
    "descriptor": "\nComments: 2022 Conference on Computer Vision and Pattern Recognition Workshops | New Orleans, Louisiana\n",
    "authors": [
      "Aakash Varma Nadimpalli",
      "Ajita Rattani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.04285"
  },
  {
    "id": "arXiv:2204.04289",
    "title": "Towards Understanding Large-Scale Discourse Structures in Pre-Trained  and Fine-Tuned Language Models",
    "abstract": "With a growing number of BERTology work analyzing different components of\npre-trained language models, we extend this line of research through an\nin-depth analysis of discourse information in pre-trained and fine-tuned\nlanguage models. We move beyond prior work along three dimensions: First, we\ndescribe a novel approach to infer discourse structures from arbitrarily long\ndocuments. Second, we propose a new type of analysis to explore where and how\naccurately intrinsic discourse is captured in the BERT and BART models.\nFinally, we assess how similar the generated structures are to a variety of\nbaselines as well as their distribution within and between models.",
    "descriptor": "\nComments: 9 pages\n",
    "authors": [
      "Patrick Huber",
      "Giuseppe Carenini"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.04289"
  },
  {
    "id": "arXiv:2204.04290",
    "title": "FikoRE: 5G and Beyond RAN Emulator for Application Level Experimentation  and Prototyping",
    "abstract": "Novel and cutting-edge use cases have arisen since the first deployments of\nthe fifth generation of telecommunication networks (5G). There are plenty of\nwell-though optimally design 5G simulators and emulators which allow\ntelecommunication technologies engineers and researchers to thoroughly study\nand test the network. However, the 5G ecosystem is not only limited to the\nnetwork itself: a fast development of 5G-specific use cases can considerably\naccelerate the development of telecommunication technologies. We present\nFikoRE, our real-time Radio Access Networks (RAN) emulator carefully designed\nfor application-level experimentation and prototyping. Its modularity and\nstraightforward implementation allow multidisciplinary user to rapidly use or\neven modify it to test their own applications. In this article, we present\nFikoRE's architecture accompanied with relevant validation experiments and\nresults.",
    "descriptor": "",
    "authors": [
      "Diego Gonzalez Morin",
      "ManuelJ. L\u00f3pez Morales",
      "Pablo P\u00e9rez",
      "Ana Garc\u00eda Armada Alvaro Villegas"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2204.04290"
  },
  {
    "id": "arXiv:2204.04292",
    "title": "Multi-objective evolution for Generalizable Policy Gradient Algorithms",
    "abstract": "Performance, generalizability, and stability are three Reinforcement Learning\n(RL) challenges relevant to many practical applications in which they present\nthemselves in combination. Still, state-of-the-art RL algorithms fall short\nwhen addressing multiple RL objectives simultaneously and current human-driven\ndesign practices might not be well-suited for multi-objective RL. In this paper\nwe present MetaPG, an evolutionary method that discovers new RL algorithms\nrepresented as graphs, following a multi-objective search criteria in which\ndifferent RL objectives are encoded in separate fitness scores. Our findings\nshow that, when using a graph-based implementation of Soft Actor-Critic (SAC)\nto initialize the population, our method is able to find new algorithms that\nimprove upon SAC's performance and generalizability by 3% and 17%,\nrespectively, and reduce instability up to 65%. In addition, we analyze the\ngraph structure of the best algorithms in the population and offer an\ninterpretation of specific elements that help trading performance for\ngeneralizability and vice versa. We validate our findings in three different\ncontinuous control tasks: RWRL Cartpole, RWRL Walker, and Gym Pendulum.",
    "descriptor": "\nComments: 23 pages, 12 figures, 10 tables\n",
    "authors": [
      "Juan Jose Garau-Luis",
      "Yingjie Miao",
      "John D. Co-Reyes",
      "Aaron Parisi",
      "Jie Tan",
      "Esteban Real",
      "Aleksandra Faust"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.04292"
  },
  {
    "id": "arXiv:2204.04296",
    "title": "Solving $X^{2^{3n}+2^{2n}+2^{n}-1}+(X+1)^{2^{3n}+2^{2n}+2^{n}-1}=b$ in  $GF{2^{4n}}$",
    "abstract": "This article determines all the solutions in the finite field $GF{2^{4n}}$ of\nthe equation $x^{2^{3n}+2^{2n}+2^{n}-1}+(x+1)^{2^{3n}+2^{2n}+2^{n}-1}=b$.\nSpecifically, we explicitly determine the set of $b$'s for which the equation\nhas $i$ solutions for any positive integer $i$. Such sets, which depend on the\nnumber of solutions $i$, are given explicitly and expressed nicely, employing\nthe absolute trace function over $GF{2^{n}}$, the norm function over\n$GF{2^{4n}}$ relatively to $GF{2^{n}}$ and the set of $2^n+1$st roots of unity\nin $GF{2^{4n}}$. The equation considered in this paper comes from an article by\nBudaghyan et al. \\cite{BCCDK20}. As an immediate consequence of our results, we\nprove that the above equation has $2^{2n}$ solutions for one value of $b$,\n$2^{2n}-2^n$ solutions for $2^n$ values of $b$ in $GF{2^{4n}}$ and has at most\ntwo solutions for all remaining points $b$, leading to complete proof of the\nconjecture raised by Budaghyan et al. We highlight that the recent work of Li\net al., in \\cite{Li-et-al-2020} gives the complete differential spectrum of $F$\nand also gives an affirmative answer to the conjecture of Budaghyan et al.\nHowever, we emphasize that our approach is interesting and promising by being\ndifferent from Li et al. Indeed, on the opposite to their article, our\ntechnique allows determine ultimately the set of $b$'s for which the considered\nequation has solutions as well as the solutions of the equation for any $b$ in\n$GF{2^{4n}}$.",
    "descriptor": "",
    "authors": [
      "Kwang Ho Kim",
      "Sihem Mesnager"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2204.04296"
  },
  {
    "id": "arXiv:2204.04297",
    "title": "Learning to modulate random weights can induce task-specific contexts  for economical meta and continual learning",
    "abstract": "Neural networks are vulnerable to catastrophic forgetting when data\ndistributions are non-stationary during continual online learning; learning of\na later task often leads to forgetting of an earlier task. One solution\napproach is model-agnostic continual meta-learning, whereby both task-specific\nand meta parameters are trained. Here, we depart from this view and introduce a\nnovel neural-network architecture inspired by neuromodulation in biological\nnervous systems. Neuromodulation is the biological mechanism that dynamically\ncontrols and fine-tunes synaptic dynamics to complement the behavioral context\nin real-time, which has received limited attention in machine learning. We\nintroduce a single-hidden-layer network that learns only a relatively small\ncontext vector per task (task-specific parameters) that neuromodulates\nunchanging, randomized weights (meta parameters) that transform the input. We\nshow that when task boundaries are available, this approach can eliminate\ncatastrophic forgetting entirely while also drastically reducing the number of\nlearnable parameters relative to other context-vector-based approaches.\nFurthermore, by combining this model with a simple meta-learning approach for\ninferring task identity, we demonstrate that the model can be generalized into\na framework to perform continual learning without knowledge of task boundaries.\nFinally, we showcase the framework in a supervised continual online learning\nscenario and discuss the implications of the proposed formalism.",
    "descriptor": "\nComments: 17 pages, 14 figures, 1 table\n",
    "authors": [
      "Jinyung Hong",
      "Theodore P. Pavlic"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.04297"
  },
  {
    "id": "arXiv:2204.04301",
    "title": "Preliminary Results on Using Abstract AND-OR Graphs for Generalized  Solving of Stochastic Shortest Path Problems",
    "abstract": "Several goal-oriented problems in the real-world can be naturally expressed\nas Stochastic Shortest Path Problems (SSPs). However, a key difficulty for\ncomputing solutions for problems in the SSP framework is that the computational\nrequirements often make finding solutions to even moderately sized problems\nintractable. Solutions to many of such problems can often be expressed as\ngeneralized policies that are quite easy to compute from small examples and are\nreadily applicable to problems with a larger number of objects and/or different\nobject names. In this paper, we provide a preliminary study on using canonical\nabstractions to compute such generalized policies and represent them as AND-OR\ngraphs that translate to simple non-deterministic, memoryless controllers. Such\npolicy structures naturally lend themselves to a hierarchical approach for\nsolving problems and we show that our approach can be embedded in any SSP\nsolver to compute hierarchically optimal policies. We conducted an empirical\nevaluation on some well-known planning benchmarks and difficult robotics\ndomains and show that our approach is promising, often computing optimal\npolicies significantly faster than state-of-art SSP solvers.",
    "descriptor": "",
    "authors": [
      "Rushang Karia",
      "Rashmeet Kaur Nayyar",
      "Siddharth Srivastava"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.04301"
  },
  {
    "id": "arXiv:2204.04303",
    "title": "CERES: Pretraining of Graph-Conditioned Transformer for Semi-Structured  Session Data",
    "abstract": "User sessions empower many search and recommendation tasks on a daily basis.\nSuch session data are semi-structured, which encode heterogeneous relations\nbetween queries and products, and each item is described by the unstructured\ntext. Despite recent advances in self-supervised learning for text or graphs,\nthere lack of self-supervised learning models that can effectively capture both\nintra-item semantics and inter-item interactions for semi-structured sessions.\nTo fill this gap, we propose CERES, a graph-based transformer model for\nsemi-structured session data. CERES learns representations that capture both\ninter- and intra-item semantics with (1) a graph-conditioned masked language\npretraining task that jointly learns from item text and item-item relations;\nand (2) a graph-conditioned transformer architecture that propagates inter-item\ncontexts to item-level representations. We pretrained CERES using ~468 million\nAmazon sessions and find that CERES outperforms strong pretraining baselines by\nup to 9% in three session search and entity linking tasks.",
    "descriptor": "",
    "authors": [
      "Rui Feng",
      "Chen Luo",
      "Qingyu Yin",
      "Bing Yin",
      "Tuo Zhao",
      "Chao Zhang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2204.04303"
  },
  {
    "id": "arXiv:2204.04306",
    "title": "MMTAfrica: Multilingual Machine Translation for African Languages",
    "abstract": "In this paper, we focus on the task of multilingual machine translation for\nAfrican languages and describe our contribution in the 2021 WMT Shared Task:\nLarge-Scale Multilingual Machine Translation. We introduce MMTAfrica, the first\nmany-to-many multilingual translation system for six African languages: Fon\n(fon), Igbo (ibo), Kinyarwanda (kin), Swahili/Kiswahili (swa), Xhosa (xho), and\nYoruba (yor) and two non-African languages: English (eng) and French (fra). For\nmultilingual translation concerning African languages, we introduce a novel\nbacktranslation and reconstruction objective, BT\\&REC, inspired by the random\nonline back translation and T5 modeling framework respectively, to effectively\nleverage monolingual data. Additionally, we report improvements from MMTAfrica\nover the FLORES 101 benchmarks (spBLEU gains ranging from $+0.58$ in Swahili to\nFrench to $+19.46$ in French to Xhosa). We release our dataset and code source\nat https://github.com/edaiofficial/mmtafrica.",
    "descriptor": "\nComments: WMT Shared Task, EMNLP 2021 (version 2)\n",
    "authors": [
      "Chris C. Emezue",
      "Bonaventure F. P. Dossou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2204.04306"
  },
  {
    "id": "arXiv:2204.04308",
    "title": "Grounding Hindsight Instructions in Multi-Goal Reinforcement Learning  for Robotics",
    "abstract": "This paper focuses on robotic reinforcement learning with sparse rewards for\nnatural language goal representations. An open problem is the\nsample-inefficiency that stems from the compositionality of natural language,\nand from the grounding of language in sensory data and actions. We address\nthese issues with three contributions. We first present a mechanism for\nhindsight instruction replay utilizing expert feedback. Second, we propose a\nseq2seq model to generate linguistic hindsight instructions. Finally, we\npresent a novel class of language-focused learning tasks. We show that\nhindsight instructions improve the learning performance, as expected. In\naddition, we also provide an unexpected result: We show that the learning\nperformance of our agent can be improved by one third if, in a sense, the agent\nlearns to talk to itself in a self-supervised manner. We achieve this by\nlearning to generate linguistic instructions that would have been appropriate\nas a natural language goal for an originally unintended behavior. Our results\nindicate that the performance gain increases with the task-complexity.",
    "descriptor": "\nComments: Preprint ICDL 2022\n",
    "authors": [
      "Frank R\u00f6der",
      "Manfred Eppe",
      "Stefan Wermter"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.04308"
  },
  {
    "id": "arXiv:2204.04310",
    "title": "Risk-Bounded Temporal Logic Control of Continuous-Time Stochastic  Systems",
    "abstract": "Motivated by the recent interest in risk-aware control, we study a\ncontinuous-time control synthesis problem to bound the risk that a stochastic\nlinear system violates a given specification. We use risk signal temporal logic\nas a specification formalism in which distributionally robust risk predicates\nare considered and equipped with the usual Boolean and temporal operators. Our\ncontrol approach relies on reformulating these risk predicates as deterministic\npredicates over mean and covariance states of the system. We then obtain a\ntimed sequence of sets of mean and covariance states from the timed automata\nrepresentation of the specification. To avoid an explosion in the number of\nautomata states, we propose heuristics to find candidate sequences effectively.\nTo execute and check dynamic feasibility of these sequences, we present a\nsampled-data control technique based on time discretization and constraint\ntightening that allows to perform timed transitions while satisfying the\ncontinuous-time constraints.",
    "descriptor": "\nComments: 8 pages, 4 figures, contributed paper at the 2022 American Control Conference (ACC) in Atlanta, GA\n",
    "authors": [
      "Sleiman Safaoui",
      "Lars Lindemann",
      "Iman Shames",
      "Tyler H. Summers"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2204.04310"
  },
  {
    "id": "arXiv:2204.04312",
    "title": "The History of the Grid",
    "abstract": "With the widespread availability of high-speed networks, it becomes feasible\nto outsource computing to remote providers and to federate resources from many\nlocations. Such observations motivated the development, from the mid-1990s\nonwards, of a range of innovative Grid technologies, applications, and\ninfrastructures. We review the history, current status, and future prospects\nfor Grid computing.",
    "descriptor": "",
    "authors": [
      "Ian Foster",
      "Carl Kesselman"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2204.04312"
  },
  {
    "id": "arXiv:2204.04313",
    "title": "Predicci\u00f3n de radiaci\u00f3n solar en sistemas fotovoltaicos utilizando  t\u00e9cnicas de aprendizaje autom\u00e1tico",
    "abstract": "Knowing the behavior of solar radiation at a geographic location is essential\nfor the use of energy from the sun using photovoltaic systems; however, the\nnumber of stations for measuring meteorological parameters and for determining\nthe size of solar fields in remote areas is limited. In this work, images\nobtained from the GOES-13 satellite were used, from which variables were\nextracted that could be integrated into datasets from meteorological stations.\nFrom this, 3 different models were built, on which the performance of 5 machine\nlearning algorithms in predicting solar radiation was evaluated. The neural\nnetworks had the highest performance in the model that integrated the\nmeteorological variables and the variables obtained from the images, according\nto an analysis carried out using four evaluation metrics; although if the rRMSE\nis considered, all results obtained were higher than 20%, which classified the\nperformance of the algorithms as fair. In the 2012 dataset, the estimation\nresults according to the metrics MBE, R2, RMSE, and rRMSE corresponded to\n-0.051, 0.880, 90.99 and 26.7%, respectively. In the 2017 dataset, the results\nof MBE, R2, RMSE, and rRMSE were -0.146, 0.917, 40.97 and 22.3%, respectively.\nAlthough it is possible to calculate solar radiation from satellite images, it\nis also true that some statistical methods depend on radiation data and\nsunshine captured by ground-based instruments, which is not always possible\ngiven that the number of measurement stations on the surface is limited.",
    "descriptor": "",
    "authors": [
      "Luis Eduardo Ordo\u00f1ez Palacios",
      "V\u00edctor Bucheli Guerrero",
      "Hugo Ordo\u00f1ez"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.04313"
  },
  {
    "id": "arXiv:2204.04318",
    "title": "Towards Understanding Barriers and Mitigation Strategies of Software  Engineers with Non-traditional Educational and Occupational Backgrounds",
    "abstract": "The traditional path to a software engineering career involves a\npost-secondary diploma in Software Engineering, Computer Science, or a related\nfield. However, many software engineers take a non-traditional path to their\ncareer, starting from other industries or fields of study. This paper proposes\na study on barriers faced by software engineers with non-traditional\neducational and occupational backgrounds, and possible mitigation strategies\nfor those barriers. We propose a two-stage methodology, consisting of an\nexploratory study, followed by a validation study. The exploratory study will\ninvolve a grounded-theory-based qualitative analysis of relevant Reddit data to\nyield a framework around the barriers and possible mitigation strategies. These\nfindings will then be validated using a survey in the validation study. Making\nsoftware engineering more accessible to those with non-traditional backgrounds\nwill not only bring about the benefits of functional diversity, but also serves\nas a method of filling in the labour shortages of the software engineering\nindustry.",
    "descriptor": "\nComments: 8 pages, 5 figures, accepted at the MSR 2022 Registered Reports Track as a Continuity Acceptance (CA)\n",
    "authors": [
      "Tavian Barnes",
      "Ken Jen Lee",
      "Cristina Tavares",
      "Gema Rodr\u00edguez-P\u00e9rez",
      "Meiyappan Nagappan"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2204.04318"
  },
  {
    "id": "arXiv:2204.04321",
    "title": "Performance portable ice-sheet modeling with MALI",
    "abstract": "High resolution simulations of polar ice-sheets play a crucial role in the\nongoing effort to develop more accurate and reliable Earth-system models for\nprobabilistic sea-level projections. These simulations often require a massive\namount of memory and computation from large supercomputing clusters to provide\nsufficient accuracy and resolution. The latest exascale machines poised to come\nonline contain a diverse set of computing architectures. In an effort to avoid\narchitecture specific programming and maintain productivity across platforms,\nthe ice-sheet modeling code known as MALI uses high level abstractions to\nintegrate Trilinos libraries and the Kokkos programming model for performance\nportable code across a variety of different architectures. In this paper, we\nanalyze the performance portable features of MALI via a performance analysis on\ncurrent CPU-based and GPU-based supercomputers. The analysis highlights\nperformance portable improvements made in finite element assembly and multigrid\npreconditioning within MALI with speedups between 1.26-1.82x across CPU and GPU\narchitectures but also identifies the need to further improve performance in\nsoftware coupling and preconditioning on GPUs. We also perform a weak\nscalability study and show that simulations on GPU-based machines perform\n1.24-1.92x faster when utilizing the GPUs. The best performance is found in\nfinite element assembly which achieved a speedup of up to 8.65x and a weak\nscaling efficiency of 82.9% with GPUs. We additionally describe an automated\nperformance testing framework developed for this code base using a changepoint\ndetection method. The framework is used to make actionable decisions about\nperformance within MALI. We provide several concrete examples of scenarios in\nwhich the framework has identified performance regressions, improvements, and\nalgorithm differences over the course of two years of development.",
    "descriptor": "",
    "authors": [
      "Jerry Watkins",
      "Max Carlson",
      "Kyle Shan",
      "Irina Tezaur",
      "Mauro Perego",
      "Luca Bertagna",
      "Carolyn Kao",
      "Matthew J. Hoffman",
      "Stephen F. Price"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Performance (cs.PF)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2204.04321"
  },
  {
    "id": "arXiv:2204.04322",
    "title": "Iterative Depth-First Search for Fully Observable Non-Deterministic  Planning",
    "abstract": "Fully Observable Non-Deterministic (FOND) planning models uncertainty through\nactions with non-deterministic effects. Existing FOND planning algorithms are\neffective and employ a wide range of techniques. However, most of the existing\nalgorithms are not robust for dealing with both non-determinism and task size.\nIn this paper, we develop a novel iterative depth-first search algorithm that\nsolves FOND planning tasks and produces strong cyclic policies. Our algorithm\nis explicitly designed for FOND planning, addressing more directly the\nnon-deterministic aspect of FOND planning, and it also exploits the benefits of\nheuristic functions to make the algorithm more effective during the iterative\nsearching process. We compare our proposed algorithm to well-known FOND\nplanners, and show that it has robust performance over several distinct types\nof FOND domains considering different metrics.",
    "descriptor": "",
    "authors": [
      "Ramon Fraga Pereira",
      "Andr\u00e9 G. Pereira",
      "Frederico Messa",
      "Giuseppe De Giacomo"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.04322"
  },
  {
    "id": "arXiv:2204.04324",
    "title": "Approximate discounting-free policy evaluation from transient and  recurrent states",
    "abstract": "In order to distinguish policies that prescribe good from bad actions in\ntransient states, we need to evaluate the so-called bias of a policy from\ntransient states. However, we observe that most (if not all) works in\napproximate discounting-free policy evaluation thus far are developed for\nestimating the bias solely from recurrent states. We therefore propose a system\nof approximators for the bias (specifically, its relative value) from transient\nand recurrent states. Its key ingredient is a seminorm LSTD (least-squares\ntemporal difference), for which we derive its minimizer expression that enables\napproximation by sampling required in model-free reinforcement learning. This\nseminorm LSTD also facilitates the formulation of a general unifying procedure\nfor LSTD-based policy value approximators. Experimental results validate the\neffectiveness of our proposed method.",
    "descriptor": "\nComments: 28 pages\n",
    "authors": [
      "Vektor Dewanto",
      "Marcus Gallagher"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.04324"
  },
  {
    "id": "arXiv:2204.04327",
    "title": "Show, Don't Tell: Demonstrations Outperform Descriptions for  Schema-Guided Task-Oriented Dialogue",
    "abstract": "Building universal dialogue systems that can seamlessly operate across\nmultiple domains/APIs and generalize to new ones with minimal supervision and\nmaintenance is a critical challenge. Recent works have leveraged natural\nlanguage descriptions for schema elements to enable such systems; however,\ndescriptions can only indirectly convey schema semantics. In this work, we\npropose Show, Don't Tell, a prompt format for seq2seq modeling which uses a\nshort labeled example dialogue to show the semantics of schema elements rather\nthan tell the model via descriptions. While requiring similar effort from\nservice developers, we show that using short examples as schema representations\nwith large language models results in stronger performance and better\ngeneralization on two popular dialogue state tracking benchmarks: the\nSchema-Guided Dialogue dataset and the MultiWoZ leave-one-out benchmark.",
    "descriptor": "\nComments: To appear at NAACL 2022\n",
    "authors": [
      "Raghav Gupta",
      "Harrison Lee",
      "Jeffrey Zhao",
      "Abhinav Rastogi",
      "Yuan Cao",
      "Yonghui Wu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.04327"
  },
  {
    "id": "arXiv:2204.04329",
    "title": "An Adaptive Black-box Backdoor Detection Method for Deep Neural Networks",
    "abstract": "With the surge of Machine Learning (ML), An emerging amount of intelligent\napplications have been developed. Deep Neural Networks (DNNs) have demonstrated\nunprecedented performance across various fields such as medical diagnosis and\nautonomous driving. While DNNs are widely employed in security-sensitive\nfields, they are identified to be vulnerable to Neural Trojan (NT) attacks that\nare controlled and activated by stealthy triggers. In this paper, we target to\ndesign a robust and adaptive Trojan detection scheme that inspects whether a\npre-trained model has been Trojaned before its deployment. Prior works are\noblivious of the intrinsic property of trigger distribution and try to\nreconstruct the trigger pattern using simple heuristics, i.e., stimulating the\ngiven model to incorrect outputs. As a result, their detection time and\neffectiveness are limited. We leverage the observation that the pixel trigger\ntypically features spatial dependency and propose the first trigger\napproximation based black-box Trojan detection framework that enables a fast\nand scalable search of the trigger in the input space. Furthermore, our\napproach can also detect Trojans embedded in the feature space where certain\nfilter transformations are used to activate the Trojan. We perform extensive\nexperiments to investigate the performance of our approach across various\ndatasets and ML models. Empirical results show that our approach achieves a\nROC-AUC score of 0.93 on the public TrojAI dataset. Our code can be found at\nhttps://github.com/xinqiaozhang/adatrojan",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2102.01815\n",
    "authors": [
      "Xinqiao Zhang",
      "Huili Chen",
      "Ke Huang",
      "Farinaz Koushanfar"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.04329"
  },
  {
    "id": "arXiv:2204.04330",
    "title": "Improved Object Pose Estimation via Deep Pre-touch Sensing",
    "abstract": "For certain manipulation tasks, object pose estimation from head-mounted\ncameras may not be sufficiently accurate. This is at least in part due to our\ninability to perfectly calibrate the coordinate frames of today's high degree\nof freedom robot arms that link the head to the end-effectors. We present a\nnovel framework combining pre-touch sensing and deep learning to more\naccurately estimate pose in an efficient manner. The use of pre-touch sensing\nallows our method to localize the object directly with respect to the robot's\nend effector, thereby avoiding error caused by miscalibration of the arms.\nInstead of requiring the robot to scan the entire object with its pre-touch\nsensor, we use a deep neural network to detect object regions that contain\ndistinctive geometric features. By focusing pre-touch sensing on these regions,\nthe robot can more efficiently gather the information necessary to adjust its\noriginal pose estimate. Our region detection network was trained using a new\ndataset containing objects of widely varying geometries and has been labeled in\na scalable fashion that is free from human bias. This dataset is applicable to\nany task that involves a pre-touch sensor gathering geometric information, and\nhas been made publicly available. We evaluate our framework by having the robot\nre-estimate the pose of a number of objects of varying geometries. Compared to\ntwo simpler region proposal methods, we find that our deep neural network\nperforms significantly better. In addition, we find that after a sequence of\nscans, objects can typically be localized to within 0.5 cm of their true\nposition. We also observe that the original pose estimate can often be\nsignificantly improved after collecting a single quick scan.",
    "descriptor": "\nComments: 8 pages, 6 figures\n",
    "authors": [
      "Patrick Lancaster",
      "Boling Yang",
      "Joshua R. Smith"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2204.04330"
  },
  {
    "id": "arXiv:2204.04332",
    "title": "Fundamental Limits on Detection With a Dual-function Radar Communication  System",
    "abstract": "This paper investigates the fundamental limits on the target detection\nperformance with a dual-function multiple-input-multiple-output (MIMO) radar\ncommunication (RadCom) systems. By assuming the presence of a point-like target\nand a communication receiver, closed-form expressions for the maximum detection\nprobability and the transmit waveforms achieving the optimal performance are\nderived. Results show that for the considered case, the dual-function system\nshould transmit coherent waveforms to achieve the optimal detection\nperformance. Moreover, the angle separation between the target and\ncommunication receiver has a great impact on the achievable detection\nperformance.",
    "descriptor": "",
    "authors": [
      "Bo Tang",
      "Zhongrui Huang",
      "Lilong Qin",
      "Hai Wang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2204.04332"
  },
  {
    "id": "arXiv:2204.04338",
    "title": "Fuzzy temporal convolutional neural networks in P300-based  Brain-computer interface for smart home interaction",
    "abstract": "The processing and classification of electroencephalographic signals (EEG)\nare increasingly performed using deep learning frameworks, such as\nconvolutional neural networks (CNNs), to generate abstract features from brain\ndata, automatically paving the way for remarkable classification prowess.\nHowever, EEG patterns exhibit high variability across time and uncertainty due\nto noise. It is a significant problem to be addressed in P300-based Brain\nComputer Interface (BCI) for smart home interaction. It operates in a\nnon-optimal natural environment where added noise is often present. In this\nwork, we propose a sequential unification of temporal convolutional networks\n(TCNs) modified to EEG signals, LSTM cells, with a fuzzy neural block (FNB),\nwhich we called EEG-TCFNet. Fuzzy components may enable a higher tolerance to\nnoisy conditions. We applied three different architectures comparing the effect\nof using block FNB to classify a P300 wave to build a BCI for smart home\ninteraction with healthy and post-stroke individuals. Our results reported a\nmaximum classification accuracy of 98.6% and 74.3% using the proposed method of\nEEG-TCFNet in subject-dependent strategy and subject-independent strategy,\nrespectively. Overall, FNB usage in all three CNN topologies outperformed those\nwithout FNB. In addition, we compared the addition of FNB to other\nstate-of-the-art methods and obtained higher classification accuracies on\naccount of the integration with FNB. The remarkable performance of the proposed\nmodel, EEG-TCFNet, and the general integration of fuzzy units to other\nclassifiers would pave the way for enhanced P300-based BCIs for smart home\ninteraction within natural settings.",
    "descriptor": "",
    "authors": [
      "Christian Flores Vega",
      "Jonathan Quevedo",
      "Elmer Escand\u00f3n",
      "Mehrin Kiani",
      "Weiping Ding",
      "Javier Andreu-Perez"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2204.04338"
  },
  {
    "id": "arXiv:2204.04339",
    "title": "A Little Too Personal: Effects of Standardization versus Personalization  on Job Acquisition, Work Completion, and Revenue for Online Freelancers",
    "abstract": "As more individuals consider permanently working from home, the online labor\nmarket continues to grow as an alternative working environment. While the\nflexibility and autonomy of these online gigs attracts many workers, success\ndepends critically upon self-management and workers' efficient allocation of\nscarce resources. To achieve this, freelancers may develop alternative work\nstrategies, employing highly standardized schedules and communication patterns\nwhile taking on large work volumes, or engaging in smaller numbers of jobs\nwhilst tailoring their activities to build relationships with individual\nemployers. In this study, we consider this contrast in relation to worker\ncommunication patterns. We demonstrate the heterogeneous effects of\nstandardization versus personalization across different stages of a project and\nexamine the relative impact on job acquisition, project completion, and\nearnings. Our findings can inform the design of platforms and various worker\nsupport tools for the gig economy.",
    "descriptor": "\nComments: CHI'22, April 29-May 5, 2022, New Orleans, LA, USA\n",
    "authors": [
      "Jane Hsieh",
      "Yili Hong",
      "Gordon Burtch",
      "Haiyi Zhu"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2204.04339"
  },
  {
    "id": "arXiv:2204.04340",
    "title": "Sim-to-Real Learning for Bipedal Locomotion Under Unsensed Dynamic Loads",
    "abstract": "Recent work on sim-to-real learning for bipedal locomotion has demonstrated\nnew levels of robustness and agility over a variety of terrains. However, that\nwork, and most prior bipedal locomotion work, have not considered locomotion\nunder a variety of external loads that can significantly influence the overall\nsystem dynamics. In many applications, robots will need to maintain robust\nlocomotion under a wide range of potential dynamic loads, such as pulling a\ncart or carrying a large container of sloshing liquid, ideally without\nrequiring additional load-sensing capabilities. In this work, we explore the\ncapabilities of reinforcement learning (RL) and sim-to-real transfer for\nbipedal locomotion under dynamic loads using only proprioceptive feedback. We\nshow that prior RL policies trained for unloaded locomotion fail for some loads\nand that simply training in the context of loads is enough to result in\nsuccessful and improved policies. We also compare training specialized policies\nfor each load versus a single policy for all considered loads and analyze how\nthe resulting gaits change to accommodate different loads. Finally, we\ndemonstrate sim-to-real transfer, which is successful but shows a wider\nsim-to-real gap than prior unloaded work, which points to interesting future\nresearch.",
    "descriptor": "\nComments: Accepted to ICRA 2022. Video attachment: this https URL\n",
    "authors": [
      "Jeremy Dao",
      "Kevin Green",
      "Helei Duan",
      "Alan Fern",
      "Jonathan Hurst"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.04340"
  },
  {
    "id": "arXiv:2204.04342",
    "title": "An Improved Integer Modular Multiplicative Inverse (modulo $2^w$)",
    "abstract": "This paper presents an algorithm for the integer multiplicative inverse (mod\n$2^w$) which completes in the fewest cycles known for modern microprocessors,\nwhen using the native bit width $w$ for the modulus $2^w$. The algorithm is a\nmodification of a method by Dumas, and for computers it slightly increases\ngenerality and efficiency. A proof is given, and the algorithm is shown to be\nclosely related to the better known Newton's method algorithm for the inverse.\nSimple direct formulas, which are needed by this algorithm and by Newton's\nmethod, are reviewed and proven for the integer inverse modulo $2^k$ with $k$ =\n1, 2, 3, 4, or 5, providing the first proof of the preferred formula with $k$=4\nor 5.",
    "descriptor": "",
    "authors": [
      "Jeffrey Hurchalla"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2204.04342"
  },
  {
    "id": "arXiv:2204.04344",
    "title": "Towards Better Chinese-centric Neural Machine Translation for  Low-resource Languages",
    "abstract": "The last decade has witnessed enormous improvements in science and\ntechnology, stimulating the growing demand for economic and cultural exchanges\nin various countries. Building a neural machine translation (NMT) system has\nbecome an urgent trend, especially in the low-resource setting. However, recent\nwork tends to study NMT systems for low-resource languages centered on English,\nwhile few works focus on low-resource NMT systems centered on other languages\nsuch as Chinese. To achieve this, the low-resource multilingual translation\nchallenge of the 2021 iFLYTEK AI Developer Competition provides the\nChinese-centric multilingual low-resource NMT tasks, where participants are\nrequired to build NMT systems based on the provided low-resource samples. In\nthis paper, we present the winner competition system that leverages monolingual\nword embeddings data enhancement, bilingual curriculum learning, and\ncontrastive re-ranking. In addition, a new Incomplete-Trust (In-trust) loss\nfunction is proposed to replace the traditional cross-entropy loss when\ntraining. The experimental results demonstrate that the implementation of these\nideas leads better performance than other state-of-the-art methods. All the\nexperimental codes are released at:\nhttps://github.com/WENGSYX/Low-resource-text-translation.",
    "descriptor": "\nComments: 7pages, 4 figures, 4 tables\n",
    "authors": [
      "Bin Li",
      "Yixuan Weng",
      "Fei Xia",
      "Hanjun Deng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.04344"
  },
  {
    "id": "arXiv:2204.04347",
    "title": "On the Importance of Karaka Framework in Multi-modal Grounding",
    "abstract": "Computational Paninian Grammar model helps in decoding a natural language\nexpression as a series of modifier-modified relations and therefore facilitates\nin identifying dependency relations closer to language (context) semantics\ncompared to the usual Stanford dependency relations. However, the importance of\nthis CPG dependency scheme has not been studied in the context of multi-modal\nvision and language applications. At IIIT Hyderabad, we plan to perform a novel\nstudy to explore the potential advantages and disadvantages of CPG framework in\na vision-language navigation task setting, a popular and challenging\nmulti-modal grounding task.",
    "descriptor": "",
    "authors": [
      "Sai Kiran Gorthi",
      "Radhika Mamidi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.04347"
  },
  {
    "id": "arXiv:2204.04350",
    "title": "Hardware Trojan Insertion Using Reinforcement Learning",
    "abstract": "This paper utilizes Reinforcement Learning (RL) as a means to automate the\nHardware Trojan (HT) insertion process to eliminate the inherent human biases\nthat limit the development of robust HT detection methods. An RL agent explores\nthe design space and finds circuit locations that are best for keeping inserted\nHTs hidden. To achieve this, a digital circuit is converted to an environment\nin which an RL agent inserts HTs such that the cumulative reward is maximized.\nOur toolset can insert combinational HTs into the ISCAS-85 benchmark suite with\nvariations in HT size and triggering conditions. Experimental results show that\nthe toolset achieves high input coverage rates (100\\% in two benchmark\ncircuits) that confirms its effectiveness. Also, the inserted HTs have shown a\nminimal footprint and rare activation probability.",
    "descriptor": "\nComments: This paper was accepted for publication in GLSVLSI'22\n",
    "authors": [
      "Amin Sarihi",
      "Ahmad Patooghy",
      "Peter Jamieson",
      "Abdel-Hameed A. Badawy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Hardware Architecture (cs.AR)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2204.04350"
  },
  {
    "id": "arXiv:2204.04353",
    "title": "Should we tweet this? Generative response modeling for predicting  reception of public health messaging on Twitter",
    "abstract": "The way people respond to messaging from public health organizations on\nsocial media can provide insight into public perceptions on critical health\nissues, especially during a global crisis such as COVID-19. It could be\nvaluable for high-impact organizations such as the US Centers for Disease\nControl and Prevention (CDC) or the World Health Organization (WHO) to\nunderstand how these perceptions impact reception of messaging on health policy\nrecommendations. We collect two datasets of public health messages and their\nresponses from Twitter relating to COVID-19 and Vaccines, and introduce a\npredictive method which can be used to explore the potential reception of such\nmessages. Specifically, we harness a generative model (GPT-2) to directly\npredict probable future responses and demonstrate how it can be used to\noptimize expected reception of important health guidance. Finally, we introduce\na novel evaluation scheme with extensive statistical testing which allows us to\nconclude that our models capture the semantics and sentiment found in actual\npublic health responses.",
    "descriptor": "\nComments: Accepted at ACM WebSci 2022\n",
    "authors": [
      "Abraham Sanders",
      "Debjani Ray-Majumder",
      "John S. Erickson",
      "Kristin P. Bennett"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2204.04353"
  },
  {
    "id": "arXiv:2204.04358",
    "title": "Segmenting across places: The need for fair transfer learning with  satellite imagery",
    "abstract": "The increasing availability of high-resolution satellite imagery has enabled\nthe use of machine learning to support land-cover measurement and inform\npolicy-making. However, labelling satellite images is expensive and is\navailable for only some locations. This prompts the use of transfer learning to\nadapt models from data-rich locations to others. Given the potential for\nhigh-impact applications of satellite imagery across geographies, a systematic\nassessment of transfer learning implications is warranted. In this work, we\nconsider the task of land-cover segmentation and study the fairness\nimplications of transferring models across locations. We leverage a large\nsatellite image segmentation benchmark with 5987 images from 18 districts (9\nurban and 9 rural). Via fairness metrics we quantify disparities in model\nperformance along two axes -- across urban-rural locations and across\nland-cover classes. Findings show that state-of-the-art models have better\noverall accuracy in rural areas compared to urban areas, through unsupervised\ndomain adaptation methods transfer learning better to urban versus rural areas\nand enlarge fairness gaps. In analysis of reasons for these findings, we show\nthat raw satellite images are overall more dissimilar between source and target\ndistricts for rural than for urban locations. This work highlights the need to\nconduct fairness analysis for satellite imagery segmentation models and\nmotivates the development of methods for fair transfer learning in order not to\nintroduce disparities between places, particularly urban and rural locations.",
    "descriptor": "",
    "authors": [
      "Miao Zhang",
      "Harvineet Singh",
      "Lazarus Chok",
      "Rumi Chunara"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.04358"
  },
  {
    "id": "arXiv:2204.04360",
    "title": "Data Augmentation for Electrocardiograms",
    "abstract": "Neural network models have demonstrated impressive performance in predicting\npathologies and outcomes from the 12-lead electrocardiogram (ECG). However,\nthese models often need to be trained with large, labelled datasets, which are\nnot available for many predictive tasks of interest. In this work, we perform\nan empirical study examining whether training time data augmentation methods\ncan be used to improve performance on such data-scarce ECG prediction problems.\nWe investigate how data augmentation strategies impact model performance when\ndetecting cardiac abnormalities from the ECG. Motivated by our finding that the\neffectiveness of existing augmentation strategies is highly task-dependent, we\nintroduce a new method, TaskAug, which defines a flexible augmentation policy\nthat is optimized on a per-task basis. We outline an efficient learning\nalgorithm to do so that leverages recent work in nested optimization and\nimplicit differentiation. In experiments, considering three datasets and eight\npredictive tasks, we find that TaskAug is competitive with or improves on prior\nwork, and the learned policies shed light on what transformations are most\neffective for different tasks. We distill key insights from our experimental\nevaluation, generating a set of best practices for applying data augmentation\nto ECG prediction problems.",
    "descriptor": "\nComments: Conference on Health, Inference, and Learning (CHIL) 2022\n",
    "authors": [
      "Aniruddh Raghu",
      "Divya Shanmugam",
      "Eugene Pomerantsev",
      "John Guttag",
      "Collin M. Stultz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.04360"
  },
  {
    "id": "arXiv:2204.04362",
    "title": "Domain-Oriented Prefix-Tuning: Towards Efficient and Generalizable  Fine-tuning for Zero-Shot Dialogue Summarization",
    "abstract": "The most advanced abstractive dialogue summarizers lack generalization\nability on new domains and the existing researches for domain adaptation in\nsummarization generally rely on large-scale pre-trainings. To explore the\nlightweight fine-tuning methods for domain adaptation of dialogue\nsummarization, in this paper, we propose an efficient and generalizable\nDomain-Oriented Prefix-tuning model, which utilizes a domain word initialized\nprefix module to alleviate domain entanglement and adopts discrete prompts to\nguide the model to focus on key contents of dialogues and enhance model\ngeneralization. We conduct zero-shot experiments and build domain adaptation\nbenchmarks on two multi-domain dialogue summarization datasets, TODSum and\nQMSum. Adequate experiments and qualitative analysis prove the effectiveness of\nour methods.",
    "descriptor": "\nComments: NAACL 2022 main conference(long paper)\n",
    "authors": [
      "Lulu Zhao",
      "Fujia Zheng",
      "Weihao Zeng",
      "Keqing He",
      "Weiran Xu",
      "Huixing Jiang",
      "Wei Wu",
      "Yanan Wu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.04362"
  },
  {
    "id": "arXiv:2204.04363",
    "title": "Attention guided global enhancement and local refinement network for  semantic segmentation",
    "abstract": "The encoder-decoder architecture is widely used as a lightweight semantic\nsegmentation network. However, it struggles with a limited performance compared\nto a well-designed Dilated-FCN model for two major problems. First, commonly\nused upsampling methods in the decoder such as interpolation and deconvolution\nsuffer from a local receptive field, unable to encode global contexts. Second,\nlow-level features may bring noises to the network decoder through skip\nconnections for the inadequacy of semantic concepts in early encoder layers. To\ntackle these challenges, a Global Enhancement Method is proposed to aggregate\nglobal information from high-level feature maps and adaptively distribute them\nto different decoder layers, alleviating the shortage of global contexts in the\nupsampling process. Besides, a Local Refinement Module is developed by\nutilizing the decoder features as the semantic guidance to refine the noisy\nencoder features before the fusion of these two (the decoder features and the\nencoder features). Then, the two methods are integrated into a Context Fusion\nBlock, and based on that, a novel Attention guided Global enhancement and Local\nrefinement Network (AGLN) is elaborately designed. Extensive experiments on\nPASCAL Context, ADE20K, and PASCAL VOC 2012 datasets have demonstrated the\neffectiveness of the proposed approach. In particular, with a vanilla\nResNet-101 backbone, AGLN achieves the state-of-the-art result (56.23% mean\nIoU) on the PASCAL Context dataset. The code is available at\nhttps://github.com/zhasen1996/AGLN.",
    "descriptor": "\nComments: 12 pages, 6 figures\n",
    "authors": [
      "Jiangyun Li",
      "Sen Zha",
      "Chen Chen",
      "Meng Ding",
      "Tianxiang Zhang",
      "Hong Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.04363"
  },
  {
    "id": "arXiv:2204.04364",
    "title": "Application of machine learning for predicting the spread of COVID-19",
    "abstract": "The spread of diseases has been studied for many years, but it receives a\nparticular focus recently due to the outbreak and spread of COVID-19. Studies\nshow that the spread of COVID-19 can be characterized by the\nSusceptible-Infectious-Recovered-Deceased (SIRD) model with containment\ncoefficients (due to quarantine and keeping social distance). This project aims\nto apply the machine learning technique to predict the severity of COVID-19 and\nthe effect of quarantine, keeping social distance, working from home, and\nwearing masks on the transmission of the disease. This work deepens our\nunderstanding of disease transmission and reveals the importance of following\npolicies.",
    "descriptor": "\nComments: 11 pages, 8 figures\n",
    "authors": [
      "Xiaoxu Zhong",
      "Yukun Ye"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.04364"
  },
  {
    "id": "arXiv:2204.04371",
    "title": "Learning to Dispatch Multi-Server Jobs in Bipartite Graphs with Unknown  Service Rates",
    "abstract": "Multi-server jobs are imperative in modern cloud computing systems. A\nmulti-server job has multiple components and requests multiple servers for\nbeing served. How to allocate restricted computing devices to jobs is a topic\nof great concern, which leads to the job scheduling and load balancing\nalgorithms thriving. However, current job dispatching algorithms require the\nservice rates to be changeless and knowable, which is difficult to realize in\nproduction systems. Besides, for multi-server jobs, the dispatching decision\nfor each job component follows the All-or-Nothing property under service\nlocality constraints and resource capacity limits, which is not well supported\nby mainstream algorithms. In this paper, we propose a dispatching algorithm for\nmulti-server jobs that learns the unknown service rates and simultaneously\nmaximizes the expected Accumulative Social Welfare (Asw). We formulate the Asw\nas the sum of utilities of jobs and servers achieved over each time slot. The\nutility of a job is proportional to the valuation for being served, which is\nmainly impacted by the fluctuating but unknown service rates. We maximize the\nAsw without knowing the exact valuations, but approximate them with\nexploration-exploitation. From this, we bring in several evolving statistics\nand maximize the statistical Asw with dynamic programming. The proposed\nalgorithm is proved to have a polynomial complexity and a State-of-the-Art\nregret. We validate it with extensive simulations and the results show that the\nproposed algorithm outperforms several benchmark policies with improvements by\nup to 73%, 36%, and 28%, respectively.",
    "descriptor": "",
    "authors": [
      "Hailiang Zhao",
      "Shuiguang Deng",
      "Feiyi Chen",
      "Jianwei Yin",
      "Schahram Dustdar",
      "Albert Y. Zomaya"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2204.04371"
  },
  {
    "id": "arXiv:2204.04372",
    "title": "A Siren Song of Open Source Reproducibility",
    "abstract": "As reproducibility becomes a greater concern, conferences have largely\nconverged to a strategy of asking reviewers to indicate whether code was\nattached to a submission. This is part of a larger trend of taking action based\non assumed ideals, without studying if those actions will yield the desired\noutcome. Our argument is that this focus on code for replication is misguided\nif we want to improve the state of reproducible research. This focus can be\nharmful -- we should not force code to be submitted. There is a lack of\nevidence for effective actions taken by conferences to encourage and reward\nreproducibility. We argue that venues must take more action to advance\nreproducible machine learning research today.",
    "descriptor": "\nComments: To be presented at the ML Evaluation Standards Workshop at ICLR 2022\n",
    "authors": [
      "Edward Raff",
      "Andrew L. Farris"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2204.04372"
  },
  {
    "id": "arXiv:2204.04375",
    "title": "Channel Pruning In Quantization-aware Training: An Adaptive  Projection-gradient Descent-shrinkage-splitting Method",
    "abstract": "We propose an adaptive projection-gradient descent-shrinkage-splitting method\n(APGDSSM) to integrate penalty based channel pruning into quantization-aware\ntraining (QAT). APGDSSM concurrently searches weights in both the quantized\nsubspace and the sparse subspace. APGDSSM uses shrinkage operator and a\nsplitting technique to create sparse weights, as well as the Group Lasso\npenalty to push the weight sparsity into channel sparsity. In addition, we\npropose a novel complementary transformed l1 penalty to stabilize the training\nfor extreme compression.",
    "descriptor": "",
    "authors": [
      "Zhijian Li",
      "Jack Xin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2204.04375"
  },
  {
    "id": "arXiv:2204.04376",
    "title": "Small-Gain Theorem for Safety Verification under High-Relative-Degree  Constraints",
    "abstract": "This paper develops a small-gain technique for the safety analysis and\nverification of interconnected systems with high-relative-degree safety\nconstraints. In this technique, input-to-state safety (ISSf) is used to\ncharacterize how the safety of a subsystem is influenced by the external input,\nand ISSf-barrier functions (ISSf-BFs) with high relative degree are employed to\ncapture the safety of subsystems. With a coordination transform, the\nrelationship between ISSf-BFs and the existing high-relative-degree (or\nhigh-order) barrier functions is established in order to simplify the ISSf\nanalysis. With the help of high-relative-degree ISSf-BFs, a small-gain theorem\nis proposed for safety verification. It is shown that, under the small-gain\ncondition, i) the interconnection of ISSf subsystems is still ISSf; and ii) the\noverall interconnected system is input-to-state stable (ISS) with respect to\nthe compositional safe set. The effectiveness of the proposed small-gain\ntheorem is illustrated on the output-constrained decentralized control of two\ninverted pendulums connected by a spring mounted on two carts.",
    "descriptor": "",
    "authors": [
      "Ziliang Lyu",
      "Xiangru Xu",
      "Yiguang Hong"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Dynamical Systems (math.DS)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2204.04376"
  },
  {
    "id": "arXiv:2204.04377",
    "title": "Robotic Surgery Remote Mentoring via AR with 3D Scene Streaming and Hand  Interaction",
    "abstract": "With the growing popularity of robotic surgery, education becomes\nincreasingly important and urgently needed for the sake of patient safety.\nHowever, experienced surgeons have limited accessibility due to their busy\nclinical schedule or working in a distant city, thus can hardly provide\nsufficient education resources for novices. Remote mentoring, as an effective\nway, can help solve this problem, but traditional methods are limited to plain\ntext, audio, or 2D video, which are not intuitive nor vivid. Augmented reality\n(AR), a thriving technique being widely used for various education scenarios,\nis promising to offer new possibilities of visual experience and interactive\nteaching. In this paper, we propose a novel AR-based robotic surgery remote\nmentoring system with efficient 3D scene visualization and natural 3D hand\ninteraction. Using a head-mounted display (i.e., HoloLens), the mentor can\nremotely monitor the procedure streamed from the trainee's operation side. The\nmentor can also provide feedback directly with hand gestures, which is in-turn\ntransmitted to the trainee and viewed in surgical console as guidance. We\ncomprehensively validate the system on both real surgery stereo videos and\nex-vivo scenarios of common robotic training tasks (i.e., peg-transfer and\nsuturing). Promising results are demonstrated regarding the fidelity of\nstreamed scene visualization, the accuracy of feedback with hand interaction,\nand the low-latency of each component in the entire remote mentoring system.\nThis work showcases the feasibility of leveraging AR technology for reliable,\nflexible and low-cost solutions to robotic surgical education, and holds great\npotential for clinical applications.",
    "descriptor": "",
    "authors": [
      "Yonghao Long",
      "Chengkun Li",
      "Qi Dou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.04377"
  },
  {
    "id": "arXiv:2204.04379",
    "title": "Beyond 3DMM: Learning to Capture High-fidelity 3D Face Shape",
    "abstract": "3D Morphable Model (3DMM) fitting has widely benefited face analysis due to\nits strong 3D priori. However, previous reconstructed 3D faces suffer from\ndegraded visual verisimilitude due to the loss of fine-grained geometry, which\nis attributed to insufficient ground-truth 3D shapes, unreliable training\nstrategies and limited representation power of 3DMM. To alleviate this issue,\nthis paper proposes a complete solution to capture the personalized shape so\nthat the reconstructed shape looks identical to the corresponding person.\nSpecifically, given a 2D image as the input, we virtually render the image in\nseveral calibrated views to normalize pose variations while preserving the\noriginal image geometry. A many-to-one hourglass network serves as the\nencode-decoder to fuse multiview features and generate vertex displacements as\nthe fine-grained geometry. Besides, the neural network is trained by directly\noptimizing the visual effect, where two 3D shapes are compared by measuring the\nsimilarity between the multiview images rendered from the shapes. Finally, we\npropose to generate the ground-truth 3D shapes by registering RGB-D images\nfollowed by pose and shape augmentation, providing sufficient data for network\ntraining. Experiments on several challenging protocols demonstrate the superior\nreconstruction accuracy of our proposal on the face shape.",
    "descriptor": "\nComments: Accepted by T-PAMI 2022. see IEEE page this http URL\n",
    "authors": [
      "Xiangyu Zhu",
      "Chang Yu",
      "Di Huang",
      "Zhen Lei",
      "Hao Wang",
      "Stan Z. Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.04379"
  },
  {
    "id": "arXiv:2204.04380",
    "title": "A dataset of ant colonies motion trajectories in indoor and outdoor  scenes for social cluster behavior study",
    "abstract": "Motion and interaction of social insects (such as ants) have been studied by\nmany researchers to understand the clustering mechanism. Most studies in the\nfield of ant behavior have only focused on indoor environments, while outdoor\nenvironments are still underexplored. In this paper, we collect 10 videos of\nant colonies from different indoor and outdoor scenes. And we develop an image\nsequence marking software named VisualMarkData, which enables us to provide\nannotations of ants in the video. In all 5354 frames, the location information\nand the identification number of each ant are recorded for a total of 712 ants\nand 114112 annotations. Moreover, we provide visual analysis tools to assess\nand validate the technical quality and reproducibility of our data. It is hoped\nthat this dataset will contribute to a deeper exploration on the behavior of\nthe ant colony.",
    "descriptor": "",
    "authors": [
      "Meihong Wu",
      "Xiaoyan Cao",
      "Xiaoyu Cao",
      "Shihui Guo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.04380"
  },
  {
    "id": "arXiv:2204.04381",
    "title": "Harmonic Centralization of Some Graph Families",
    "abstract": "Centrality describes the importance of nodes in a graph and is modeled by\nvarious measures. Freeman's centralization, on the other hand, is a general\nmethod for calculating a graph-level centrality score based on a node-level\ncentrality measure. The latter enables us to compare graphs based on the extent\nto which the connections of a given network are concentrated on a single vertex\nor group of vertices. One of the measures of centrality in social network\nanalysis is harmonic centrality. It sums the inverse of the geodesic distances\nof each node to other nodes where it is 0 if there is no path from one node to\nanother, with the sum normalized by dividing it by $m-1$, where $m$ is the\nnumber of nodes of the graph. In this paper, we present some results regarding\nthe harmonic centralization of some important families of graphs with the hope\nthat formulas generated herein will be of use when one determines the harmonic\ncentralization of more complex graphs.",
    "descriptor": "\nComments: 14 pages, 5 figures. arXiv admin note: text overlap with arXiv:2111.12239\n",
    "authors": [
      "Jose Mari E. Ortega",
      "Rolito G. Eballe"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2204.04381"
  },
  {
    "id": "arXiv:2204.04382",
    "title": "Federated Unsupervised Domain Adaptation for Face Recognition",
    "abstract": "Given labeled data in a source domain, unsupervised domain adaptation has\nbeen widely adopted to generalize models for unlabeled data in a target domain,\nwhose data distributions are different. However, existing works are\ninapplicable to face recognition under privacy constraints because they require\nsharing of sensitive face images between domains. To address this problem, we\npropose federated unsupervised domain adaptation for face recognition, FedFR.\nFedFR jointly optimizes clustering-based domain adaptation and federated\nlearning to elevate performance on the target domain. Specifically, for\nunlabeled data in the target domain, we enhance a clustering algorithm with\ndistance constrain to improve the quality of predicted pseudo labels. Besides,\nwe propose a new domain constraint loss (DCL) to regularize source domain\ntraining in federated learning. Extensive experiments on a newly constructed\nbenchmark demonstrate that FedFR outperforms the baseline and classic methods\non the target domain by 3% to 14% on different evaluation metrics.",
    "descriptor": "\nComments: ICME'22. arXiv admin note: substantial text overlap with arXiv:2105.07606\n",
    "authors": [
      "Weiming Zhuang",
      "Xin Gan",
      "Yonggang Wen",
      "Xuesen Zhang",
      "Shuai Zhang",
      "Shuai Yi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2204.04382"
  },
  {
    "id": "arXiv:2204.04383",
    "title": "Learning-based Bounded Synthesis for Semi-MDPs with LTL Specifications",
    "abstract": "This letter proposes a learning-based bounded synthesis for a semi-Markov\ndecision process (SMDP) with a linear temporal logic (LTL) specification. In\nthe product of the SMDP and the deterministic $K$-co-B\\\"uchi automaton\n(d$K$cBA) converted from the LTL specification, we learn both the winning\nregion of satisfying the LTL specification and the dynamics therein based on\nreinforcement learning and Bayesian inference. Then, we synthesize an optimal\npolicy satisfying the following two conditions. (1) It maximizes the\nprobability of reaching the wining region. (2) It minimizes a long-term risk\nfor the dwell time within the winning region. The minimization of the long-term\nrisk is done based on the estimated dynamics and a value iteration. We show\nthat, if the discount factor is sufficiently close to one, the synthesized\npolicy converges to the optimal policy as the number of the data obtained by\nthe exploration goes to the infinity.",
    "descriptor": "\nComments: 6apges, 4figures\n",
    "authors": [
      "Ryohei Oura",
      "Toshimitsu Ushio"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2204.04383"
  },
  {
    "id": "arXiv:2204.04384",
    "title": "The Two Dimensions of Worst-case Training and the Integrated Effect for  Out-of-domain Generalization",
    "abstract": "Training with an emphasis on \"hard-to-learn\" components of the data has been\nproven as an effective method to improve the generalization of machine learning\nmodels, especially in the settings where robustness (e.g., generalization\nacross distributions) is valued. Existing literature discussing this\n\"hard-to-learn\" concept are mainly expanded either along the dimension of the\nsamples or the dimension of the features. In this paper, we aim to introduce a\nsimple view merging these two dimensions, leading to a new, simple yet\neffective, heuristic to train machine learning models by emphasizing the\nworst-cases on both the sample and the feature dimensions. We name our method\nW2D following the concept of \"Worst-case along Two Dimensions\". We validate the\nidea and demonstrate its empirical strength over standard benchmarks.",
    "descriptor": "\nComments: to appear at CVPR2022\n",
    "authors": [
      "Zeyi Huang",
      "Haohan Wang",
      "Dong Huang",
      "Yong Jae Lee",
      "Eric P. Xing"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.04384"
  },
  {
    "id": "arXiv:2204.04385",
    "title": "Divergence-aware Federated Self-Supervised Learning",
    "abstract": "Self-supervised learning (SSL) is capable of learning remarkable\nrepresentations from centrally available data. Recent works further implement\nfederated learning with SSL to learn from rapidly growing decentralized\nunlabeled images (e.g., from cameras and phones), often resulted from privacy\nconstraints. Extensive attention has been paid to SSL approaches based on\nSiamese networks. However, such an effort has not yet revealed deep insights\ninto various fundamental building blocks for the federated self-supervised\nlearning (FedSSL) architecture. We aim to fill in this gap via in-depth\nempirical study and propose a new method to tackle the non-independently and\nidentically distributed (non-IID) data problem of decentralized data. Firstly,\nwe introduce a generalized FedSSL framework that embraces existing SSL methods\nbased on Siamese networks and presents flexibility catering to future methods.\nIn this framework, a server coordinates multiple clients to conduct SSL\ntraining and periodically updates local models of clients with the aggregated\nglobal model. Using the framework, our study uncovers unique insights of\nFedSSL: 1) stop-gradient operation, previously reported to be essential, is not\nalways necessary in FedSSL; 2) retaining local knowledge of clients in FedSSL\nis particularly beneficial for non-IID data. Inspired by the insights, we then\npropose a new approach for model update, Federated Divergence-aware Exponential\nMoving Average update (FedEMA). FedEMA updates local models of clients\nadaptively using EMA of the global model, where the decay rate is dynamically\nmeasured by model divergence. Extensive experiments demonstrate that FedEMA\noutperforms existing methods by 3-4% on linear evaluation. We hope that this\nwork will provide useful insights for future research.",
    "descriptor": "\nComments: ICLR'22\n",
    "authors": [
      "Weiming Zhuang",
      "Yonggang Wen",
      "Shuai Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2204.04385"
  },
  {
    "id": "arXiv:2204.04386",
    "title": "Efficient Derivative-free Bayesian Inference for Large-Scale Inverse  Problems",
    "abstract": "We consider Bayesian inference for large scale inverse problems, where\ncomputational challenges arise from the need for repeated evaluations of an\nexpensive forward model. This renders most Markov chain Monte Carlo approaches\ninfeasible, since they typically require $O(10^4)$ model runs, or more.\nMoreover, the forward model is often given as a black box or is impractical to\ndifferentiate. Therefore derivative-free algorithms are highly desirable. We\npropose a framework, which is built on Kalman methodology, to efficiently\nperform Bayesian inference in such inverse problems. The basic method is based\non an approximation of the filtering distribution of a novel mean-field\ndynamical system into which the inverse problem is embedded as an observation\noperator. Theoretical properties of the mean-field model are established for\nlinear inverse problems, demonstrating that the desired Bayesian posterior is\ngiven by the steady state of the law of the filtering distribution of the\nmean-field dynamical system, and proving exponential convergence to it. This\nsuggests that, for nonlinear problems which are close to Gaussian, sequentially\ncomputing this law provides the basis for efficient iterative methods to\napproximate the Bayesian posterior. Ensemble methods are applied to obtain\ninteracting particle system approximations of the filtering distribution of the\nmean-field model; and practical strategies to further reduce the computational\nand memory cost of the methodology are presented, including low-rank\napproximation and a bi-fidelity approach. The effectiveness of the framework is\ndemonstrated in several numerical experiments, including proof-of-concept\nlinear/nonlinear examples and two large-scale applications: learning of\npermeability parameters in subsurface flow; and learning subgrid-scale\nparameters in a global climate model from time-averaged statistics.",
    "descriptor": "\nComments: 44 pages, 15 figures\n",
    "authors": [
      "Daniel Zhengyu Huang",
      "Jiaoyang Huang",
      "Sebastian Reich",
      "Andrew M. Stuart"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2204.04386"
  },
  {
    "id": "arXiv:2204.04390",
    "title": "Deep neural network goes lighter: A case study of deep compression  techniques on automatic RF modulation recognition for Beyond 5G networks",
    "abstract": "Automatic RF modulation recognition is a primary signal intelligence (SIGINT)\ntechnique that serves as a physical layer authentication enabler and automated\nsignal processing scheme for the beyond 5G and military networks. Most existing\nworks rely on adopting deep neural network architectures to enable RF\nmodulation recognition. The application of deep compression for the wireless\ndomain, especially automatic RF modulation classification, is still in its\ninfancy. Lightweight neural networks are key to sustain edge computation\ncapability on resource-constrained platforms. In this letter, we provide an\nin-depth view of the state-of-the-art deep compression and acceleration\ntechniques with an emphasis on edge deployment for beyond 5G networks. Finally,\nwe present an extensive analysis of the representative acceleration approaches\nas a case study on automatic radar modulation classification and evaluate them\nin terms of the computational metrics.",
    "descriptor": "\nComments: To appear in the Proceedings of SPIE Defense + Commercial Sensing\n",
    "authors": [
      "Anu Jagannath",
      "Jithin Jagannath",
      "Yanzhi Wang",
      "Tommaso Melodia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.04390"
  },
  {
    "id": "arXiv:2204.04391",
    "title": "MINER: Improving Out-of-Vocabulary Named Entity Recognition from an  Information Theoretic Perspective",
    "abstract": "NER model has achieved promising performance on standard NER benchmarks.\nHowever, recent studies show that previous approaches may over-rely on entity\nmention information, resulting in poor performance on out-of-vocabulary (OOV)\nentity recognition. In this work, we propose MINER, a novel NER learning\nframework, to remedy this issue from an information-theoretic perspective. The\nproposed approach contains two mutual information-based training objectives: i)\ngeneralizing information maximization, which enhances representation via deep\nunderstanding of context and entity surface forms; ii) superfluous information\nminimization, which discourages representation from rote memorizing entity\nnames or exploiting biased cues in data. Experiments on various settings and\ndatasets demonstrate that it achieves better performance in predicting OOV\nentities.",
    "descriptor": "",
    "authors": [
      "Xiao Wang",
      "Shihan Dou",
      "Limao Xiong",
      "Yicheng Zou",
      "Qi Zhang",
      "Tao Gui",
      "Liang Qiao",
      "Zhanzhan Cheng",
      "Xuanjing Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2204.04391"
  },
  {
    "id": "arXiv:2204.04392",
    "title": "Contrastive Demonstration Tuning for Pre-trained Language Models",
    "abstract": "Pretrained language models can be effectively stimulated by textual prompts\nor demonstrations, especially in low-data scenarios. Recent works have focused\non automatically searching discrete or continuous prompts or optimized\nverbalizers, yet studies for the demonstration are still limited. Concretely,\nthe demonstration examples are crucial for an excellent final performance of\nprompt-tuning. In this paper, we propose a novel pluggable, extensible, and\nefficient approach named contrastive demonstration tuning, which is free of\ndemonstration sampling. Furthermore, the proposed approach can be: (i) Plugged\nto any previous prompt-tuning approaches; (ii) Extended to widespread\nclassification tasks with a large number of categories. Experimental results on\n16 datasets illustrate that our method integrated with previous approaches\nLM-BFF and P-tuning can yield better performance. Code is available in\nhttps://github.com/zjunlp/PromptKG/tree/main/research/Demo-Tuning.",
    "descriptor": "\nComments: Work in progress\n",
    "authors": [
      "Xiaozhuan Liang",
      "Ningyu Zhang",
      "Siyuan Cheng",
      "Zhen Bi",
      "Zhenru Zhang",
      "Chuanqi Tan",
      "Songfang Huang",
      "Fei Huang",
      "Huajun Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.04392"
  },
  {
    "id": "arXiv:2204.04393",
    "title": "Star-Convex Constrained Optimization for Visibility Planning with  Application to Aerial Inspection",
    "abstract": "The visible capability is critical in many robot applications, such as\ninspection and surveillance, etc. Without the assurance of the visibility to\ntargets, some tasks end up not being complete or even failing. In this paper,\nwe propose a visibility guaranteed planner by star-convex constrained\noptimization. The visible space is modeled as star convex polytope (SCP) by\nnature and is generated by finding the visible points directly on point cloud.\nBy exploiting the properties of the SCP, the visibility constraint is\nformulated for trajectory optimization. The trajectory is confined in the safe\nand visible flight corridor which consists of convex polytopes and SCPs. We\nfurther make a relaxation to the visibility constraints and transform the\nconstrained trajectory optimization problem into an unconstrained one that can\nbe reliably and efficiently solved. To validate the capability of the proposed\nplanner, we present the practical application in site inspection. The\nexperimental results show that the method is efficient, scalable, and\nvisibility guaranteed, presenting the prospect of application to various other\napplications in the future.",
    "descriptor": "\nComments: Accepted by ICRA 2022\n",
    "authors": [
      "Tianyu Liu",
      "Qianhao Wang",
      "Xingguang Zhong",
      "Zhepei Wang",
      "Chao Xu",
      "Fu Zhang",
      "Fei Gao"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2204.04393"
  },
  {
    "id": "arXiv:2204.04394",
    "title": "Generalised Mathematical Formulations for Non-Linear Optimized  Scheduling",
    "abstract": "In practice, most of the optimization problems are non-linear requiring\ncertain interactive solutions and approaches to model. In 5G Advanced and\nBeyond network slicing, mathematically modeling the users, type of service\ndistributions and its adaptive SLAs are complex due to several dependencies. To\nfacilitate the above, in this paper, we present novel Non-linear mathematical\nformulations and results that will form the base to achieve Optimized\nScheduling.",
    "descriptor": "\nComments: 4 pages, 5 figures\n",
    "authors": [
      "Sharvari Ravindran",
      "Saptarshi Chaudhuri",
      "Jyotsna Bapat",
      "Debabrata Das"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2204.04394"
  },
  {
    "id": "arXiv:2204.04395",
    "title": "A Machine Learning-Based Method for Identifying Critical Distance Relays  for Transient Stability Studies",
    "abstract": "Modeling protective relays is crucial for performing accurate stability\nstudies as they play a critical role in defining the dynamic responses of power\nsystems during disturbances. Nevertheless, due to the current limitations of\nstability software and the challenges of keeping track of the changes in the\nsettings information of thousands of protective relays, modeling all the\nprotective relays in bulk power systems is a challenging task. Distance relays\nare among the critical protection schemes, which are not properly modeled in\ncurrent practices of stability studies. This paper proposes a machine\nlearning-based method that uses the results of early-terminated stability\nstudies to identify the critical distance relays required to be modeled in\nthose studies. The algorithm used is the random forest (RF) classifier. GE\npositive sequence load flow analysis (PSLF) software is used to perform\nstability studies. The model is trained and tested on the Western Electricity\nCoordinating Council (WECC) system data representing the 2018 summer peak load\nunder different operating conditions and topologies of the system. The results\nshow the great performance of the method in identifying the critical distance\nrelays. The results also show that only modeling the identified critical\ndistance relays suffices to perform accurate stability studies.",
    "descriptor": "\nComments: 10 pages, 5 figures\n",
    "authors": [
      "Ramin Vakili",
      "Mojdeh Khorsand"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2204.04395"
  },
  {
    "id": "arXiv:2204.04397",
    "title": "Denoising Neural Network for News Recommendation with Positive and  Negative Implicit Feedback",
    "abstract": "News recommendation is different from movie or e-commercial recommendation as\npeople usually do not grade the news. Therefore, user feedback for news is\nalways implicit (click behavior, reading time, etc). Inevitably, there are\nnoises in implicit feedback. On one hand, the user may exit immediately after\nclicking the news as he dislikes the news content, leaving the noise in his\npositive implicit feedback; on the other hand, the user may be recommended\nmultiple interesting news at the same time and only click one of them,\nproducing the noise in his negative implicit feedback. Opposite implicit\nfeedback could construct more integrated user preferences and help each other\nto minimize the noise influence. Previous works on news recommendation only\nused positive implicit feedback and suffered from the noise impact. In this\npaper, we propose a denoising neural network for news recommendation with\npositive and negative implicit feedback, named DRPN. DRPN utilizes both\nfeedback for recommendation with a module to denoise both positive and negative\nimplicit feedback to further enhance the performance. Experiments on the\nreal-world large-scale dataset demonstrate the state-of-the-art performance of\nDRPN.",
    "descriptor": "\nComments: Accepted by Findings of NAACL 2022\n",
    "authors": [
      "Yunfan Hu",
      "Zhaopeng Qiu",
      "Xian Wu"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.04397"
  },
  {
    "id": "arXiv:2204.04399",
    "title": "Crime Patterns in Los Angeles County Before and After Covid19  (2018-2021)",
    "abstract": "The objective of our research is to present the change in crime rates in Los\nAngeles post-Covid19. Using data analysis with Geo-Mapping, bubbles, Marimekko,\nand a time series charts, we can illustrate which areas have the largest crime\nrate, and how it has changed. Through regression modeling, we can interpret\nwhich locations may also have a correlation to crime versus income, race, type\nof crime, and gender. The story will help to uncover whether the areas\nassociated with crime are due to demographic or income variance. In showing the\ndetails of crimes in Los Angeles along with the factors at play we hope to see\na compelling relationship between crime rates and recent events from 2020 to\nthe present, along with changes in crime type trends during these periods. We\nuse Excel to clean the data for SAP SAC to model effectively, as well as\nresources from other studies a comparison.",
    "descriptor": "\nComments: Keywords: Pandemic, Crime Rate Los Angeles, Data Analysis, Data Science, Predictive Analysis\n",
    "authors": [
      "Rubab Hussain",
      "Rigo Vargas",
      "Hieu Hughes Le-Au",
      "Will Gass",
      "Melissa Fenn",
      "Briseyda Serna-Marquez",
      "Jongwook Woo"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2204.04399"
  },
  {
    "id": "arXiv:2204.04403",
    "title": "Improve Generalization of Driving Policy at Signalized Intersections  with Adversarial Learning",
    "abstract": "Intersections are quite challenging among various driving scenes wherein the\ninteraction of signal lights and distinct traffic actors poses great difficulty\nto learn a wise and robust driving policy. Current research rarely considers\nthe diversity of intersections and stochastic behaviors of traffic\nparticipants. For practical applications, the randomness usually leads to some\ndevastating events, which should be the focus of autonomous driving. This paper\nintroduces an adversarial learning paradigm to boost the intelligence and\nrobustness of driving policy for signalized intersections with dense traffic\nflow. Firstly, we design a static path planner which is capable of generating\ntrackable candidate paths for multiple intersections with diversified topology.\nNext, a constrained optimal control problem (COCP) is built based on these\ncandidate paths wherein the bounded uncertainty of dynamic models is considered\nto capture the randomness of driving environment. We propose adversarial policy\ngradient (APG) to solve the COCP wherein the adversarial policy is introduced\nto provide disturbances by seeking the most severe uncertainty while the\ndriving policy learns to handle this situation by competition. Finally, a\ncomprehensive system is established to conduct training and testing wherein the\nperception module is introduced and the human experience is incorporated to\nsolve the yellow light dilemma. Experiments indicate that the trained policy\ncan handle the signal lights flexibly meanwhile realizing the smooth and\nefficient passing with a humanoid paradigm. Besides, APG enables a large-margin\nimprovement of the resistance to the abnormal behaviors and thus ensures a high\nsafety level for the autonomous vehicle.",
    "descriptor": "",
    "authors": [
      "Yangang Ren",
      "Guojian Zhan",
      "Liye Tang",
      "Shengbo Eben Li",
      "Jianhua Jiang",
      "Jingliang Duan"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2204.04403"
  },
  {
    "id": "arXiv:2204.04412",
    "title": "Leaderless Swarm Formation Control: From Global Specifications to Local  Control Laws",
    "abstract": "This paper introduces a distributed leaderless swarm formation control\nframework to address the problem of collectively driving a swarm of robots to\ntrack a time-varying formation. The swarm's formation is captured by the\ntrajectory of an abstract shape that circumscribes the convex hull of robots'\npositions and is independent of the number of robots and their ordering in the\nswarm. For each robot in the swarm, given global specifications in terms of the\ntrajectory of the abstract shape parameters, the proposed framework synthesizes\na control law that steers the swarm to track the desired formation using the\ninformation available at the robot's local neighbors. For this purpose, we\ngenerate a suitable local reference trajectory that the robot controller tracks\nby solving the input-output linearization problem. Here, we select the swarm\noutput to be the parameters of the abstract shape. For this purpose, we design\na dynamic average consensus estimator to estimate the abstract shape\nparameters. The abstract shape parameters are used as the swarm state feedback\nto generate a suitable robot trajectory. We demonstrate the effectiveness and\nrobustness of the proposed control framework by providing the simulation of\ncoordinated collective navigation of a group of car-like robots in the presence\nof robots and communication link failures.",
    "descriptor": "",
    "authors": [
      "Solomon Gudeta",
      "Ali Karimoddini",
      "Mohammadreza Davoodi",
      "Ioannis Raptis"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2204.04412"
  },
  {
    "id": "arXiv:2204.04413",
    "title": "PSP: Pre-trained Soft Prompts for Few-Shot Abstractive Summarization",
    "abstract": "Few-shot abstractive summarization has become a challenging task in natural\nlanguage generation. To support it, we designed a novel soft prompts\narchitecture coupled with a prompt pre-training plus fine-tuning paradigm that\nis effective and tunes only extremely light parameters. The soft prompts\ninclude continuous input embeddings across an encoder and a decoder to fit the\nstructure of the generation models. Importantly, a novel inner-prompt placed in\nthe text is introduced to capture document-level information. The aim is to\ndevote attention to understanding the document that better prompts the model to\ngenerate document-related content. The first step in the summarization\nprocedure is to conduct prompt pre-training with self-supervised pseudo-data.\nThis teaches the model basic summarizing capabilities. The model is then\nfine-tuned with few-shot examples. Experimental results on the CNN/DailyMail\nand XSum datasets show that our method, with only 0.1% of the parameters,\noutperforms full-model tuning where all model parameters are tuned. It also\nsurpasses Prompt Tuning by a large margin and delivers competitive results\nagainst Prefix-Tuning with 3% of the parameters.",
    "descriptor": "\nComments: 12 pages\n",
    "authors": [
      "Xiaochen Liu",
      "Yu Bai",
      "Jiawei Li",
      "Yinan Hu",
      "Yang Gao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.04413"
  },
  {
    "id": "arXiv:2204.04415",
    "title": "Robust Dynamic Average Consensus for a Network of Agents with  Time-varying Reference Signals",
    "abstract": "This paper presents continuous dynamic average consensus (DAC) algorithms for\na group of agents to estimate the average of their time-varying reference\nsignals cooperatively. We propose consensus algorithms that are robust to\nagents joining and leaving the network, at the same time, avoid the chattering\nphenomena and guarantee zero steady-state consensus error. Our algorithms are\nedge-based protocols with smooth functions in their internal structure to avoid\nthe chattering effect. Furthermore, each agent is only capable of performing\nlocal computations and can only communicate with its local neighbors. For a\nbalanced and strongly connected underlying communication graph, we provide the\nconvergence analysis to determine the consensus design parameters that\nguarantee the agents' estimate of their average to asymptotically converge to\nthe average of the time-varying reference signals of the agents. We provide\nsimulation results to validate the proposed consensus algorithms and to perform\na performance comparison of the proposed algorithms to existing algorithms in\nthe literature.",
    "descriptor": "",
    "authors": [
      "Solomon Gudeta",
      "Ali Karimoddini",
      "Mohammadreza Davoodi"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2204.04415"
  },
  {
    "id": "arXiv:2204.04416",
    "title": "E^2TAD: An Energy-Efficient Tracking-based Action Detector",
    "abstract": "Video action detection (spatio-temporal action localization) is usually the\nstarting point for human-centric intelligent analysis of videos nowadays. It\nhas high practical impacts for many applications across robotics, security,\nhealthcare, etc. The two-stage paradigm of Faster R-CNN inspires a standard\nparadigm of video action detection in object detection, i.e., firstly\ngenerating person proposals and then classifying their actions. However, none\nof the existing solutions could provide fine-grained action detection to the\n\"who-when-where-what\" level. This paper presents a tracking-based solution to\naccurately and efficiently localize predefined key actions spatially (by\npredicting the associated target IDs and locations) and temporally (by\npredicting the time in exact frame indices). This solution won first place in\nthe UAV-Video Track of 2021 Low-Power Computer Vision Challenge (LPCVC).",
    "descriptor": "",
    "authors": [
      "Xin Hu",
      "Zhenyu Wu",
      "Hao-Yu Miao",
      "Siqi Fan",
      "Taiyu Long",
      "Zhenyu Hu",
      "Pengcheng Pi",
      "Yi Wu",
      "Zhou Ren",
      "Zhangyang Wang",
      "Gang Hua"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.04416"
  },
  {
    "id": "arXiv:2204.04419",
    "title": "Mapping Temporary Slums from Satellite Imagery using a Semi-Supervised  Approach",
    "abstract": "One billion people worldwide are estimated to be living in slums, and\ndocumenting and analyzing these regions is a challenging task. As compared to\nregular slums; the small, scattered and temporary nature of temporary slums\nmakes data collection and labeling tedious and time-consuming. To tackle this\nchallenging problem of temporary slums detection, we present a semi-supervised\ndeep learning segmentation-based approach; with the strategy to detect initial\nseed images in the zero-labeled data settings. A small set of seed samples (32\nin our case) are automatically discovered by analyzing the temporal changes,\nwhich are manually labeled to train a segmentation and representation learning\nmodule. The segmentation module gathers high dimensional image representations,\nand the representation learning module transforms image representations into\nembedding vectors. After that, a scoring module uses the embedding vectors to\nsample images from a large pool of unlabeled images and generates pseudo-labels\nfor the sampled images. These sampled images with their pseudo-labels are added\nto the training set to update the segmentation and representation learning\nmodules iteratively. To analyze the effectiveness of our technique, we\nconstruct a large geographically marked dataset of temporary slums. This\ndataset constitutes more than 200 potential temporary slum locations (2.28\nsquare kilometers) found by sieving sixty-eight thousand images from 12\nmetropolitan cities of Pakistan covering 8000 square kilometers. Furthermore,\nour proposed method outperforms several competitive semi-supervised semantic\nsegmentation baselines on a similar setting. The code and the dataset will be\nmade publicly available.",
    "descriptor": "",
    "authors": [
      "M. Fasi ur Rehman",
      "Izza Ali",
      "Waqas Sultani",
      "Mohsen Ali"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.04419"
  },
  {
    "id": "arXiv:2204.04420",
    "title": "Investigating Deep Learning Benchmarks for Electrocardiography Signal  Processing",
    "abstract": "In recent years, deep learning has witnessed its blossom in the field of\nElectrocardiography (ECG) processing, outperforming traditional signal\nprocessing methods in various tasks, for example, classification, QRS\ndetection, wave delineation. Although many neural architectures have been\nproposed in the literature, there is a lack of systematic studies and\nopen-source libraries for ECG deep learning.\nIn this paper, we propose a deep learning framework, named\n\\texttt{torch\\_ecg}, which gathers a large number of neural networks, both from\nliterature and novel, for various ECG processing tasks. It establishes a\nconvenient and modular way for automatic building and flexible scaling of the\nnetworks, as well as a neat and uniform way of organizing the preprocessing\nprocedures and augmentation techniques for preparing the input data for the\nmodels. Besides, \\texttt{torch\\_ecg} provides benchmark studies using the\nlatest databases, illustrating the principles and pipelines for solving ECG\nprocessing tasks and reproducing results from the literature.\n\\texttt{torch\\_ecg} offers the ECG research community a powerful tool meeting\nthe growing demand for the application of deep learning techniques.",
    "descriptor": "\nComments: 10 pages, 5 figures\n",
    "authors": [
      "Wen Hao",
      "Kang Jingsu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.04420"
  },
  {
    "id": "arXiv:2204.04421",
    "title": "Unbiased Directed Object Attention Graph for Object Navigation",
    "abstract": "Object navigation tasks require agents to locate specific objects in unknown\nenvironments based on visual information. Previously, graph convolutions were\nused to implicitly explore the relationships between objects. However, due to\ndifferences in visibility among objects, it is easy to generate biases in\nobject attention. Thus, in this paper, we propose a directed object attention\n(DOA) graph to guide the agent in explicitly learning the attention\nrelationships between objects, thereby reducing the object attention bias. In\nparticular, we use the DOA graph to perform unbiased adaptive object attention\n(UAOA) on the object features and unbiased adaptive image attention (UAIA) on\nthe raw images, respectively. To distinguish features in different branches, a\nconcise adaptive branch energy distribution (ABED) method is proposed. We\nassess our methods on the AI2-Thor dataset. Compared with the state-of-the-art\n(SOTA) method, our method reports 7.4%, 8.1% and 17.6% increase in success rate\n(SR), success weighted by path length (SPL) and success weighted by action\nefficiency (SAE), respectively.",
    "descriptor": "\nComments: 13 pages, ready to ACM Mutimedia, under review\n",
    "authors": [
      "Ronghao Dang",
      "Zhuofan Shi",
      "Liuyi Wang",
      "Zongtao He",
      "Chengju Liu",
      "Qijun Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.04421"
  },
  {
    "id": "arXiv:2204.04422",
    "title": "Reduction ratio of the IS-algorithm: worst and random cases",
    "abstract": "We study the IS-algorithm, a well-known linear-time algorithm for computing\nthe suffix array of a word. This algorithm relies on transforming the input\nword $w$ into another word, called the reduced word of $w$, that will be at\nleast twice shorter; then, the algorithm recursively computes the suffix array\nof the reduced word. In this article, we study the reduction ratio of the\nIS-algorithm, i.e., the ratio between the lengths of the input word and the\nword obtained after reducing $k$ times the input word. We investigate both\nworst cases, in which we find precise results, and random cases, where we prove\nsome strong convergence phenomena. Finally, we prove that, if the input word is\na randomly chosen word of length $n$, we should not expect much more than\n$\\log(\\log(n))$ recursive function calls.",
    "descriptor": "\nComments: 21 pages. Article to be published in the proceedings of the 33rd Annual Symposium on Combinatorial Pattern Matching (CPM 2022)\n",
    "authors": [
      "Vincent Jug\u00e9"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2204.04422"
  },
  {
    "id": "arXiv:2204.04423",
    "title": "Revisiting the Effect of Branch Handling Strategies on Change  Recommendation",
    "abstract": "Although literature has noted the effects of branch handling strategies on\nchange recommendation based on evolutionary coupling, they have been tested in\na limited experimental setting. Additionally, the branches characteristics that\nlead to these effects have not been investigated. In this study, we revisited\nthe investigation conducted by Kovalenko et al. on the effect to change\nrecommendation using two different branch handling strategies: including\nchangesets from commits on a branch and excluding them. In addition to the\nsetting by Kovalenko et al., we introduced another setting to compare:\nextracting a changeset for a branch from a merge commit at once. We compared\nthe change recommendation results and the similarity of the extracted\nco-changes to those in the future obtained using two strategies through 30\nopen-source software systems. The results show that handling commits on a\nbranch separately is often more appropriate in change recommendation, although\nthe comparison in an additional setting resulted in a balanced performance\namong the branch handling strategies. Additionally, we found that the merge\ncommit size and the branch length positively influence the change\nrecommendation results.",
    "descriptor": "\nComments: 11 pages, ICPC 2022\n",
    "authors": [
      "Keisuke Isemoto",
      "Takashi Kobayashi",
      "Shinpei Hayashi"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2204.04423"
  },
  {
    "id": "arXiv:2204.04424",
    "title": "Adaptive Differential Filters for Fast and Communication-Efficient  Federated Learning",
    "abstract": "Federated learning (FL) scenarios inherently generate a large communication\noverhead by frequently transmitting neural network updates between clients and\nserver. To minimize the communication cost, introducing sparsity in conjunction\nwith differential updates is a commonly used technique. However, sparse model\nupdates can slow down convergence speed or unintentionally skip certain update\naspects, e.g., learned features, if error accumulation is not properly\naddressed. In this work, we propose a new scaling method operating at the\ngranularity of convolutional filters which 1) compensates for highly sparse\nupdates in FL processes, 2) adapts the local models to new data domains by\nenhancing some features in the filter space while diminishing others and 3)\nmotivates extra sparsity in updates and thus achieves higher compression\nratios, i.e., savings in the overall data transfer. Compared to unscaled\nupdates and previous work, experimental results on different computer vision\ntasks (Pascal VOC, CIFAR10, Chest X-Ray) and neural networks (ResNets,\nMobileNets, VGGs) in uni-, bidirectional and partial update FL settings show\nthat the proposed method improves the performance of the central server model\nwhile converging faster and reducing the total amount of transmitted data by up\nto 377 times.",
    "descriptor": "\nComments: CVPR 2022 FedVision Workshop (CVPRW), 12 pages, 5 figures, 2 tables, supplementary material\n",
    "authors": [
      "Daniel Becking",
      "Heiner Kirchhoffer",
      "Gerhard Tech",
      "Paul Haase",
      "Karsten M\u00fcller",
      "Heiko Schwarz",
      "Wojciech Samek"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2204.04424"
  },
  {
    "id": "arXiv:2204.04428",
    "title": "ManiTrans: Entity-Level Text-Guided Image Manipulation via Token-wise  Semantic Alignment and Generation",
    "abstract": "Existing text-guided image manipulation methods aim to modify the appearance\nof the image or to edit a few objects in a virtual or simple scenario, which is\nfar from practical application. In this work, we study a novel task on\ntext-guided image manipulation on the entity level in the real world. The task\nimposes three basic requirements, (1) to edit the entity consistent with the\ntext descriptions, (2) to preserve the text-irrelevant regions, and (3) to\nmerge the manipulated entity into the image naturally. To this end, we propose\na new transformer-based framework based on the two-stage image synthesis\nmethod, namely \\textbf{ManiTrans}, which can not only edit the appearance of\nentities but also generate new entities corresponding to the text guidance. Our\nframework incorporates a semantic alignment module to locate the image regions\nto be manipulated, and a semantic loss to help align the relationship between\nthe vision and language. We conduct extensive experiments on the real datasets,\nCUB, Oxford, and COCO datasets to verify that our method can distinguish the\nrelevant and irrelevant regions and achieve more precise and flexible\nmanipulation compared with baseline methods. The project homepage is\n\\url{https://jawang19.github.io/manitrans}.",
    "descriptor": "\nComments: Accepted by CVPR2022 (Oral)\n",
    "authors": [
      "Jianan Wang",
      "Guansong Lu",
      "Hang Xu",
      "Zhenguo Li",
      "Chunjing Xu",
      "Yanwei Fu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.04428"
  },
  {
    "id": "arXiv:2204.04431",
    "title": "A Spiking Neural Network Structure Implementing Reinforcement Learning",
    "abstract": "At present, implementation of learning mechanisms in spiking neural networks\n(SNN) cannot be considered as a solved scientific problem despite plenty of SNN\nlearning algorithms proposed. It is also true for SNN implementation of\nreinforcement learning (RL), while RL is especially important for SNNs because\nof its close relationship to the domains most promising from the viewpoint of\nSNN application such as robotics. In the present paper, I describe an SNN\nstructure which, seemingly, can be used in wide range of RL tasks. The\ndistinctive feature of my approach is usage of only the spike forms of all\nsignals involved - sensory input streams, output signals sent to actuators and\nreward/punishment signals. Besides that, selecting the neuron/plasticity\nmodels, I was guided by the requirement that they should be easily implemented\non modern neurochips. The SNN structure considered in the paper includes\nspiking neurons described by a generalization of the LIFAT (leaky\nintegrate-and-fire neuron with adaptive threshold) model and a simple spike\ntiming dependent synaptic plasticity model (a generalization of\ndopamine-modulated plasticity). My concept is based on very general assumptions\nabout RL task characteristics and has no visible limitations on its\napplicability. To test it, I selected a simple but non-trivial task of training\nthe network to keep a chaotically moving light spot in the view field of an\nemulated DVS camera. Successful solution of this RL problem by the SNN\ndescribed can be considered as evidence in favor of efficiency of my approach.",
    "descriptor": "",
    "authors": [
      "Mikhail Kiselev"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2204.04431"
  },
  {
    "id": "arXiv:2204.04435",
    "title": "HSTR-Net: High Spatio-Temporal Resolution Video Generation For Wide Area  Surveillance",
    "abstract": "Wide area surveillance has many applications and tracking of objects under\nobservation is an important task, which often needs high spatio-temporal\nresolution (HSTR) video for better precision. This paper presents the usage of\nmultiple video feeds for the generation of HSTR video as an extension of\nreference based super resolution (RefSR). One feed captures video at high\nspatial resolution with low frame rate (HSLF) while the other captures low\nspatial resolution and high frame rate (LSHF) video simultaneously for the same\nscene. The main purpose is to create an HSTR video from the fusion of HSLF and\nLSHF videos. In this paper we propose an end-to-end trainable deep network that\nperforms optical flow estimation and frame reconstruction by combining inputs\nfrom both video feeds. The proposed architecture provides significant\nimprovement over existing video frame interpolation and RefSR techniques in\nterms of objective PSNR and SSIM metrics.",
    "descriptor": "",
    "authors": [
      "H. Umut Suluhan",
      "Hasan F. Ates",
      "Bahadir K. Gunturk"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2204.04435"
  },
  {
    "id": "arXiv:2204.04436",
    "title": "Stability and error guarantees for least squares approximation with  noisy samples",
    "abstract": "Given $n$ samples of a function $f : D\\to\\mathbb C$ in random points drawn\nwith respect to a measure $\\nu$ we develop theoretical analysis of the $L_2(D,\n\\mu)$-approximation error. We show that the weighted least squares method from\nfinite dimensional function spaces $V_m$, $\\dim(V_m) = m < \\infty$ is stable\nand optimal up to a multiplicative constant when given exact samples with\nlogarithmic oversampling. Further, for noisy samples, our bounds describe the\nbias-variance trade off depending on the dimension $m$ of the approximation\nspace $V_m$. All results hold with high probability. For demonstration, we\nconsider functions defined on the $d$-dimensional cube given in unifom random\nsamples. We analyze polynomials, the half-perid cosine, and a bounded\northonormal basis of the non-periodic Sobolev space $H_{\\text{mix}}^2$.\nOvercoming numerical issues of this $H_{\\text{mix}}^2$ basis, this gives a\nnovel stable approximation method with quadratic error decay. Numerical\nexperiments indicate the applicability of our results.",
    "descriptor": "",
    "authors": [
      "Felix Bartel"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2204.04436"
  },
  {
    "id": "arXiv:2204.04437",
    "title": "Modeling Multi-Granularity Hierarchical Features for Relation Extraction",
    "abstract": "Relation extraction is a key task in Natural Language Processing (NLP), which\naims to extract relations between entity pairs from given texts. Recently,\nrelation extraction (RE) has achieved remarkable progress with the development\nof deep neural networks. Most existing research focuses on constructing\nexplicit structured features using external knowledge such as knowledge graph\nand dependency tree. In this paper, we propose a novel method to extract\nmulti-granularity features based solely on the original input sentences. We\nshow that effective structured features can be attained even without external\nknowledge. Three kinds of features based on the input sentences are fully\nexploited, which are in entity mention level, segment level, and sentence\nlevel. All the three are jointly and hierarchically modeled. We evaluate our\nmethod on three public benchmarks: SemEval 2010 Task 8, Tacred, and Tacred\nRevisited. To verify the effectiveness, we apply our method to different\nencoders such as LSTM and BERT. Experimental results show that our method\nsignificantly outperforms existing state-of-the-art models that even use\nexternal knowledge. Extensive analyses demonstrate that the performance of our\nmodel is contributed by the capture of multi-granularity features and the model\nof their hierarchical structure. Code and data are available at\n\\url{https://github.com/xnliang98/sms}.",
    "descriptor": "\nComments: NAACL 2022 Long Paper\n",
    "authors": [
      "Xinnian Liang",
      "Shuangzhi Wu",
      "Mu Li",
      "Zhoujun Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.04437"
  },
  {
    "id": "arXiv:2204.04438",
    "title": "Guided deep learning by subaperture decomposition: ocean patterns from  SAR imagery",
    "abstract": "Spaceborne synthetic aperture radar can provide meters scale images of the\nocean surface roughness day or night in nearly all weather conditions. This\nmakes it a unique asset for many geophysical applications. Sentinel 1 SAR wave\nmode vignettes have made possible to capture many important oceanic and\natmospheric phenomena since 2014. However, considering the amount of data\nprovided, expanding applications requires a strategy to automatically process\nand extract geophysical parameters. In this study, we propose to apply\nsubaperture decomposition as a preprocessing stage for SAR deep learning\nmodels. Our data centring approach surpassed the baseline by 0.7, obtaining\nstate of the art on the TenGeoPSARwv data set. In addition, we empirically\nshowed that subaperture decomposition could bring additional information over\nthe original vignette, by rising the number of clusters for an unsupervised\nsegmentation method. Overall, we encourage the development of data centring\napproaches, showing that, data preprocessing could bring significant\nperformance improvements over existing deep learning models.",
    "descriptor": "",
    "authors": [
      "Nicolae-Catalin Ristea",
      "Andrei Anghel",
      "Mihai Datcu",
      "Bertrand Chapron"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.04438"
  },
  {
    "id": "arXiv:2204.04440",
    "title": "Are Two Heads the Same as One? Identifying Disparate Treatment in Fair  Neural Networks",
    "abstract": "We show that deep neural networks that satisfy demographic parity do so\nthrough a form of race or gender awareness, and that the more we force a\nnetwork to be fair, the more accurately we can recover race or gender from the\ninternal state of the network. Based on this observation, we propose a simple\ntwo-stage solution for enforcing fairness. First, we train a two-headed network\nto predict the protected attribute (such as race or gender) alongside the\noriginal task, and second, we enforce demographic parity by taking a weighted\nsum of the heads. In the end, this approach creates a single-headed network\nwith the same backbone architecture as the original network. Our approach has\nnear identical performance compared to existing regularization-based or\npreprocessing methods, but has greater stability and higher accuracy where near\nexact demographic parity is required. To cement the relationship between these\ntwo approaches, we show that an unfair and optimally accurate classifier can be\nrecovered by taking a weighted sum of a fair classifier and a classifier\npredicting the protected attribute. We use this to argue that both the fairness\napproaches and our explicit formulation demonstrate disparate treatment and\nthat, consequentially, they are likely to be unlawful in a wide range of\nscenarios under the US law.",
    "descriptor": "",
    "authors": [
      "Michael Lohaus",
      "Matth\u00e4us Kleindessner",
      "Krishnaram Kenthapadi",
      "Francesco Locatello",
      "Chris Russell"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.04440"
  },
  {
    "id": "arXiv:2204.04444",
    "title": "Path-Tree Optimization in Partially Observable Environments using  Rapidly-Exploring Belief-Space Graphs",
    "abstract": "Robots often need to solve path planning problems where essential and\ndiscrete aspects of the environment are partially observable. This introduces a\nmulti-modality, where the robot must be able to observe and infer the state of\nits environment. To tackle this problem, we introduce the Path-Tree\nOptimization (PTO) algorithm which plans a path-tree in belief-space. A\npath-tree is a tree-like motion with branching points where the robot receives\nan observation leading to a belief-state update. The robot takes different\nbranches depending on the observation received. The algorithm has three main\nsteps. First, a rapidly-exploring random graph (RRG) on the state space is\ngrown. Second, the RRG is expanded to a belief-space graph by querying the\nobservation model. In a third step, dynamic programming is performed on the\nbelief-space graph to extract a path-tree. The resulting path-tree combines\nexploration with exploitation i.e. it balances the need for gaining knowledge\nabout the environment with the need for reaching the goal. We demonstrate the\nalgorithm capabilities on navigation and mobile manipulation tasks, and show\nits advantage over a baseline using a task and motion planning approach (TAMP)\nboth in terms of optimality and runtime.",
    "descriptor": "\nComments: Also submitted to IROS 2022 and RA-L\n",
    "authors": [
      "Camille Phiquepal",
      "Andreas Orthey",
      "Nicolas Viennot",
      "Marc Toussaint"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2204.04444"
  },
  {
    "id": "arXiv:2204.04450",
    "title": "Distributed Evolution Strategies for Black-box Stochastic Optimization",
    "abstract": "This work concerns the evolutionary approaches to distributed stochastic\nblack-box optimization, in which each worker can individually solve an\napproximation of the problem with nature-inspired algorithms. We propose a\ndistributed evolution strategy (DES) algorithm grounded on a proper\nmodification to evolution strategies, a family of classic evolutionary\nalgorithms, as well as a careful combination with existing distributed\nframeworks. On smooth and nonconvex landscapes, DES has a convergence rate\ncompetitive to existing zeroth-order methods, and can exploit the sparsity, if\napplicable, to match the rate of first-order methods. The DES method uses a\nGaussian probability model to guide the search and avoids the numerical issue\nresulted from finite-difference techniques in existing zeroth-order methods.\nThe DES method is also fully adaptive to the problem landscape, as its\nconvergence is guaranteed with any parameter setting. We further propose two\nalternative sampling schemes which significantly improve the sampling\nefficiency while leading to similar performance. Simulation studies on several\nmachine learning problems suggest that the proposed methods show much promise\nin reducing the convergence time and improving the robustness to parameter\nsettings.",
    "descriptor": "",
    "authors": [
      "Xiaoyu He",
      "Zibin Zheng",
      "Chuan Chen",
      "Yuren Zhou",
      "Chuan Luo",
      "Qingwei Lin"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2204.04450"
  },
  {
    "id": "arXiv:2204.04452",
    "title": "Yes, Topology Matters in Decentralized Optimization: Refined Convergence  and Topology Learning under Heterogeneous Data",
    "abstract": "One of the key challenges in federated and decentralized learning is to\ndesign algorithms that efficiently deal with highly heterogeneous data\ndistributions across agents. In this paper, we revisit the analysis of\nDecentralized Stochastic Gradient Descent algorithm (D-SGD), a popular\ndecentralized learning algorithm, under data heterogeneity. We exhibit the key\nrole played by a new quantity, that we call neighborhood heterogeneity, on the\nconvergence rate of D-SGD. Unlike prior work, neighborhood heterogeneity is\nmeasured at the level of the neighborhood of an agent in the graph topology. By\ncoupling the topology and the heterogeneity of the agents' distributions, our\nanalysis sheds light on the poorly understood interplay between these two\nconcepts in decentralized learning. We then argue that neighborhood\nheterogeneity provides a natural criterion to learn sparse data-dependent\ntopologies that reduce (and can even eliminate) the otherwise detrimental\neffect of data heterogeneity on the convergence time of D-SGD. For the\nimportant case of classification with label skew, we formulate the problem of\nlearning such a good topology as a tractable optimization problem that we solve\nwith a Frank-Wolfe algorithm. Our approach provides a principled way to design\na sparse topology that balances the number of iterations and the per-iteration\ncommunication costs of D-SGD under data heterogeneity.",
    "descriptor": "",
    "authors": [
      "B. Le Bars",
      "A. Bellet",
      "M. Tommasi",
      "AM. Kermarrec"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2204.04452"
  },
  {
    "id": "arXiv:2204.04455",
    "title": "Noise-based Enhancement for Foveated Rendering",
    "abstract": "Human visual sensitivity to spatial details declines towards the periphery.\nNovel image synthesis techniques, so-called foveated rendering, exploit this\nobservation and reduce the spatial resolution of synthesized images for the\nperiphery, avoiding the synthesis of high-spatial-frequency details that are\ncostly to generate but not perceived by a viewer. However, contemporary\ntechniques do not make a clear distinction between the range of spatial\nfrequencies that must be reproduced and those that can be omitted. For a given\neccentricity, there is a range of frequencies that are detectable but not\nresolvable. While the accurate reproduction of these frequencies is not\nrequired, an observer can detect their absence if completely omitted. We use\nthis observation to improve the performance of existing foveated rendering\ntechniques. We demonstrate that this specific range of frequencies can be\nefficiently replaced with procedural noise whose parameters are carefully tuned\nto image content and human perception. Consequently, these frequencies do not\nhave to be synthesized during rendering, allowing more aggressive foveation,\nand they can be replaced by noise generated in a less expensive post-processing\nstep, leading to improved performance of the rendering system. Our main\ncontribution is a perceptually-inspired technique for deriving the parameters\nof the noise required for the enhancement and its calibration. The method\noperates on rendering output and runs at rates exceeding 200FPS at 4K\nresolution, making it suitable for integration with real-time foveated\nrendering systems for VR and AR devices. We validate our results and compare\nthem to the existing contrast enhancement technique in user experiments.",
    "descriptor": "\nComments: 14 pages including refences\n",
    "authors": [
      "Taimoor Tariq",
      "Cara Tursun",
      "Piotr Didyk"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2204.04455"
  },
  {
    "id": "arXiv:2204.04456",
    "title": "Approximation-free control based on the bioinspired reference model for  suspension systems with uncertainty and unknown nonlinearity",
    "abstract": "Uncertainty and unknown nonlinearity are often inevitable in the suspension\nsystems, which were often solved using fuzzy logic system (FLS) or neural\nnetworks (NNs). However, these methods are restricted by the structural\ncomplexity of the controller and the huge computing cost. Meanwhile, the\nestimation error of such approximators is affected by adopted adaptive laws and\nlearning gains. Thus, in view of the above problem, this paper proposes the\napproximation-free control based on the bioinspired reference model for a class\nof uncertain suspension systems with unknown nonlinearity. The proposed method\nintegrates the superior vibration suppression of the bioinspired reference\nmodel and the structural advantage of the prescribed performance function (PPF)\nin approximation-free control. Then, the vibration suppression performance is\nimproved, the calculation burden is relieved, and the transient performance is\nimproved, which is analyzed theoretically in this paper. Finally, the\nsimulation results validate the approach, and the comparisons show the\nadvantages of the proposed control method in terms of good vibration\nsuppression, fast convergence, and less calculation burden.",
    "descriptor": "",
    "authors": [
      "Xiaoyan Hu",
      "Guilin Wen",
      "Shan Yin",
      "Zhao Tan",
      "Zebang Pan"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2204.04456"
  },
  {
    "id": "arXiv:2204.04457",
    "title": "Refining time-space traffic diagrams: A multiple linear regression model",
    "abstract": "A time-space traffic (TS) diagram that presents traffic states in time-space\ncells with colors is one of the most important traffic analysis and\nvisualization tools. Despite its importance for transportation research and\nengineering, most TS diagrams that have already existed or are being produced\nare too coarse to exhibit detailed traffic dynamics due to the limitation of\nthe current information technology and traffic infrastructure investment. To\nincrease the resolution of a TS diagram and make it present more traffic\ndetails, this paper introduces a TS diagram refinement problem and proposes a\nmultiple linear regression-based model to solve the problem. Two tests, which\nattempt to increase the resolution of a TS diagram for 4 and 16 times,\nrespectively, are carried out to evaluate the performance of the proposed\nmodel. The data collected from different time, different location and even\ndifferent country is involved to thoroughly evaluate the accuracy and\ntransferability of the proposed model. The strict tests with diverse data show\nthat the proposed model, although it is simple in form, is able to refine a TS\ndiagram with a promising accuracy and reliable transferability. The proposed\nrefinement model will \"save\" those widely-existing TS diagrams from their\nblurry \"faces\" and make it possible to learn more traffic details from those TS\ndiagrams.",
    "descriptor": "",
    "authors": [
      "Zhengbing He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.04457"
  },
  {
    "id": "arXiv:2204.04458",
    "title": "Understanding, Detecting, and Separating Out-of-Distribution Samples and  Adversarial Samples in Text Classification",
    "abstract": "In this paper, we study the differences and commonalities between\nstatistically out-of-distribution (OOD) samples and adversarial (Adv) samples,\nboth of which hurting a text classification model's performance. We conduct\nanalyses to compare the two types of anomalies (OOD and Adv samples) with the\nin-distribution (ID) ones from three aspects: the input features, the hidden\nrepresentations in each layer of the model, and the output probability\ndistributions of the classifier. We find that OOD samples expose their\naberration starting from the first layer, while the abnormalities of Adv\nsamples do not emerge until the deeper layers of the model. We also illustrate\nthat the models' output probabilities for Adv samples tend to be more\nunconfident. Based on our observations, we propose a simple method to separate\nID, OOD, and Adv samples using the hidden representations and output\nprobabilities of the model. On multiple combinations of ID, OOD datasets, and\nAdv attacks, our proposed method shows exceptional results on distinguishing\nID, OOD, and Adv samples.",
    "descriptor": "\nComments: Preprint. Work in progress\n",
    "authors": [
      "Cheng-Han Chiang",
      "Hung-yi Lee"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.04458"
  },
  {
    "id": "arXiv:2204.04462",
    "title": "A3CLNN: Spatial, Spectral and Multiscale Attention ConvLSTM Neural  Network for Multisource Remote Sensing Data Classification",
    "abstract": "The problem of effectively exploiting the information multiple data sources\nhas become a relevant but challenging research topic in remote sensing. In this\npaper, we propose a new approach to exploit the complementarity of two data\nsources: hyperspectral images (HSIs) and light detection and ranging (LiDAR)\ndata. Specifically, we develop a new dual-channel spatial, spectral and\nmultiscale attention convolutional long short-term memory neural network\n(called dual-channel A3CLNN) for feature extraction and classification of\nmultisource remote sensing data. Spatial, spectral and multiscale attention\nmechanisms are first designed for HSI and LiDAR data in order to learn\nspectral- and spatial-enhanced feature representations, and to represent\nmultiscale information for different classes. In the designed fusion network, a\nnovel composite attention learning mechanism (combined with a three-level\nfusion strategy) is used to fully integrate the features in these two data\nsources. Finally, inspired by the idea of transfer learning, a novel stepwise\ntraining strategy is designed to yield a final classification result. Our\nexperimental results, conducted on several multisource remote sensing data\nsets, demonstrate that the newly proposed dual-channel A3CLNN exhibits better\nfeature representation ability (leading to more competitive classification\nperformance) than other state-of-the-art methods.",
    "descriptor": "\nComments: 16 pages, 10 figures\n",
    "authors": [
      "Heng-Chao Li",
      "Wen-Shuai Hu",
      "Wei Li",
      "Jun Li",
      "Qian Du",
      "Antonio Plaza"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2204.04462"
  },
  {
    "id": "arXiv:2204.04464",
    "title": "Multichannel Speech Separation with Narrow-band Conformer",
    "abstract": "This work proposes a multichannel speech separation method with narrow-band\nConformer (named NBC). The network is trained to learn to automatically exploit\nnarrow-band speech separation information, such as spatial vector clustering of\nmultiple speakers. Specifically, in the short-time Fourier transform (STFT)\ndomain, the network processes each frequency independently, and is shared by\nall frequencies. For one frequency, the network inputs the STFT coefficients of\nmultichannel mixture signals, and predicts the STFT coefficients of separated\nspeech signals. Clustering of spatial vectors shares a similar principle with\nthe self-attention mechanism in the sense of computing the similarity of\nvectors and then aggregating similar vectors. Therefore, Conformer would be\nespecially suitable for the present problem. Experiments show that the proposed\nnarrow-band Conformer achieves better speech separation performance than other\nstate-of-the-art methods by a large margin.",
    "descriptor": "\nComments: submitted to INTERSPEECH 2022. arXiv admin note: text overlap with arXiv:2110.05966\n",
    "authors": [
      "Changsheng Quan",
      "Xiaofei Li"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2204.04464"
  },
  {
    "id": "arXiv:2204.04472",
    "title": "A BAT-based Exact-Solution Algorithm for the Series-Parallel Redundancy  Allocation Problem with Mixed Components",
    "abstract": "The series-parallel (active) redundancy allocation problem with mixed\ncomponents (RAP) involves setting reliable objectives for components or\nsubsystems to meet the resource consumption constraint, e.g., the total cost.\nRAP has been an active research area for the past four decades. The NP-hard\ndifficulties confronted by RAP are maintaining feasibility with respect to two\nconstraints: cost and weight. A novel algorithm called the bound-rule-BAT (BRB)\nbased on the binary-addition-tree algorithm (BAT), the dominance rule, and\ndynamic bounds are proposed to solve the exact solutions of the most famous RAP\nbenchmark problems called the (33-variation) Fyffe RAP. From the experiments,\nthe proposed BRB can solve the Fyffe RAP correctly under the assumption that\nthe maximal number of components of each subsystem is eight, and this is the\nfirst exact-solution algorithm that can solve the Fyffe RAP within 8 seconds\nand 60 seconds if no reliability lower bound is used.",
    "descriptor": "",
    "authors": [
      "Wei-Chang Yeh"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)",
      "Networking and Internet Architecture (cs.NI)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2204.04472"
  },
  {
    "id": "arXiv:2204.04477",
    "title": "FoundationLayerNorm: Scaling BERT and GPT to 1,000 Layers",
    "abstract": "The mainstream BERT/GPT model contains only 10 to 20 layers, and there is\nlittle literature to discuss the training of deep BERT/GPT. This paper proposes\na simple yet effective method to stabilize BERT and GPT training. We\nsuccessfully scale up BERT and GPT to 1,000 layers, which is an order of\nmagnitude deeper than previous BERT and GPT. The proposed method\nFoundationLayerNormalization enables efficient training of deep neural networks\nand is validated at the 1000-layer scale.",
    "descriptor": "\nComments: 7 pages, 5 tables\n",
    "authors": [
      "Dezhou Shen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.04477"
  },
  {
    "id": "arXiv:2204.04481",
    "title": "KUCST@LT-EDI-ACL2022: Detecting Signs of Depression from Social Media  Text",
    "abstract": "In this paper we present our approach for detecting signs of depression from\nsocial media text. Our model relies on word unigrams, part-of-speech tags,\nreadabilitiy measures and the use of first, second or third person and the\nnumber of words. Our best model obtained a macro F1-score of 0.439 and ranked\n25th, out of 31 teams. We further take advantage of the interpretability of the\nLogistic Regression model and we make an attempt to interpret the model\ncoefficients with the hope that these will be useful for further research on\nthe topic.",
    "descriptor": "",
    "authors": [
      "Manex Agirrezabal",
      "Janek Amann"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.04481"
  },
  {
    "id": "arXiv:2204.04483",
    "title": "Why did I fail? A Causal-based Method to Find Explanations for Robot  Failures",
    "abstract": "Robot failures in human-centered environments are inevitable. Therefore, the\nability of robots to explain such failures is paramount for interacting with\nhumans to increase trust and transparency. To achieve this skill, the main\nchallenges addressed in this paper are I) acquiring enough data to learn a\ncause-effect model of the environment and II) generating causal explanations\nbased on that model. We address I) by learning a causal Bayesian network from\nsimulation data. Concerning II), we propose a novel method that enables robots\nto generate contrastive explanations upon task failures. The explanation is\nbased on setting the failure state in contrast with the closest state that\nwould have allowed for successful execution, which is found through\nbreadth-first search and is based on success predictions from the learned\ncausal model. We assess the sim2real transferability of the causal model on a\ncube stacking scenario. Based on real-world experiments with two differently\nembodied robots, we achieve a sim2real accuracy of 70% without any adaptation\nor retraining. Our method thus allowed real robots to give failure explanations\nlike, 'the upper cube was dropped too high and too far to the right of the\nlower cube.'",
    "descriptor": "\nComments: submitted to IEEE Robotics and Automation Letters (February 2022)\n",
    "authors": [
      "Maximilian Diehl",
      "Karinne Ramirez-Amaro"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.04483"
  },
  {
    "id": "arXiv:2204.04487",
    "title": "Uninformative Input Features and Counterfactual Invariance: Two  Perspectives on Spurious Correlations in Natural Language",
    "abstract": "Spurious correlations are a threat to the trustworthiness of natural language\nprocessing systems, motivating research into methods for identifying and\neliminating them. Gardner et al (2021) argue that the compositional nature of\nlanguage implies that \\emph{all} correlations between labels and individual\ninput features are spurious. This paper analyzes this proposal in the context\nof a toy example, demonstrating three distinct conditions that can give rise to\nfeature-label correlations in a simple PCFG. Linking the toy example to a\nstructured causal model shows that (1) feature-label correlations can arise\neven when the label is invariant to interventions on the feature, and (2)\nfeature-label correlations may be absent even when the label is sensitive to\ninterventions on the feature. Because input features will be individually\ncorrelated with labels in all but very rare circumstances, domain knowledge\nmust be applied to identify spurious correlations that pose genuine robustness\nthreats.",
    "descriptor": "\nComments: NAACL 2022\n",
    "authors": [
      "Jacob Eisenstein"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.04487"
  },
  {
    "id": "arXiv:2204.04489",
    "title": "ShorTor: Improving Tor Network Latency via Multi-hop Overlay Routing",
    "abstract": "We present ShorTor, a protocol for reducing latency on the Tor network.\nShorTor uses multi-hop overlay routing, a technique typically employed by\ncontent delivery networks, to influence the route Tor traffic takes across the\ninternet. ShorTor functions as an overlay on top of onion routing-Tor's\nexisting routing protocol and is run by Tor relays, making it independent of\nthe path selection performed by Tor clients. As such, ShorTor reduces latency\nwhile preserving Tor's existing security properties. Specifically, the routes\ntaken in ShorTor are in no way correlated to either the Tor user or their\ndestination, including the geographic location of either party. We analyze the\nsecurity of ShorTor using the AnoA framework, showing that ShorTor maintains\nall of Tor's anonymity guarantees. We augment our theoretical claims with an\nempirical analysis. To evaluate ShorTor's performance, we collect a real-world\ndataset of over 400,000 latency measurements between the 1,000 most popular Tor\nrelays, which collectively see the vast majority of Tor traffic. With this\ndata, we identify pairs of relays that could benefit from ShorTor: that is, two\nrelays where introducing an additional intermediate network hop results in\nlower latency than the direct route between them. We use our measurement\ndataset to simulate the impact on end users by applying ShorTor to two million\nTor circuits chosen according to Tor's specification. ShorTor reduces the\nlatency for the 99th percentile of relay pairs in Tor by 148 ms. Similarly,\nShorTor reduces the latency of Tor circuits by 122 ms at the 99th percentile.\nIn practice, this translates to ShorTor truncating tail latencies for Tor which\nhas a direct impact on page load times and, consequently, user experience on\nthe Tor browser.",
    "descriptor": "",
    "authors": [
      "Kyle Hogan",
      "Sacha Servan-Schreiber",
      "Zachary Newman",
      "Ben Weintraub",
      "Cristina Nita-Rotaru",
      "Srinivas Devadas"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2204.04489"
  },
  {
    "id": "arXiv:2204.04492",
    "title": "S4OD: Semi-Supervised learning for Single-Stage Object Detection",
    "abstract": "Single-stage detectors suffer from extreme foreground-background class\nimbalance, while two-stage detectors do not. Therefore, in semi-supervised\nobject detection, two-stage detectors can deliver remarkable performance by\nonly selecting high-quality pseudo labels based on classification scores.\nHowever, directly applying this strategy to single-stage detectors would\naggravate the class imbalance with fewer positive samples. Thus, single-stage\ndetectors have to consider both quality and quantity of pseudo labels\nsimultaneously. In this paper, we design a dynamic self-adaptive threshold\n(DSAT) strategy in classification branch, which can automatically select pseudo\nlabels to achieve an optimal trade-off between quality and quantity. Besides,\nto assess the regression quality of pseudo labels in single-stage detectors, we\npropose a module to compute the regression uncertainty of boxes based on\nNon-Maximum Suppression. By leveraging only 10% labeled data from COCO, our\nmethod achieves 35.0% AP on anchor-free detector (FCOS) and 32.9% on\nanchor-based detector (RetinaNet).",
    "descriptor": "",
    "authors": [
      "Yueming Zhang",
      "Xingxu Yao",
      "Chao Liu",
      "Feng Chen",
      "Xiaolin Song",
      "Tengfei Xing",
      "Runbo Hu",
      "Hua Chai",
      "Pengfei Xu",
      "Guoshan Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.04492"
  },
  {
    "id": "arXiv:2204.04494",
    "title": "DeepLIIF: An Online Platform for Quantification of Clinical Pathology  Slides",
    "abstract": "In the clinic, resected tissue samples are stained with Hematoxylin-and-Eosin\n(H&E) and/or Immunhistochemistry (IHC) stains and presented to the pathologists\non glass slides or as digital scans for diagnosis and assessment of disease\nprogression. Cell-level quantification, e.g. in IHC protein expression scoring,\ncan be extremely inefficient and subjective. We present DeepLIIF\n(https://deepliif.org), a first free online platform for efficient and\nreproducible IHC scoring. DeepLIIF outperforms current state-of-the-art\napproaches (relying on manual error-prone annotations) by virtually restaining\nclinical IHC slides with more informative multiplex immunofluorescence\nstaining. Our DeepLIIF cloud-native platform supports (1) more than 150\nproprietary/non-proprietary input formats via the Bio-Formats standard, (2)\ninteractive adjustment, visualization, and downloading of the IHC\nquantification results and the accompanying restained images, (3) consumption\nof an exposed workflow API programmatically or through interactive plugins for\nopen source whole slide image viewers such as QuPath/ImageJ, and (4) auto\nscaling to efficiently scale GPU resources based on user demand.",
    "descriptor": "\nComments: CVPR 2022. First three authors contributed equally. Demo paper accompanying DeepLIIF Nature Machine Intelligence paper (this https URL)\n",
    "authors": [
      "Parmida Ghahremani",
      "Joseph Marino",
      "Ricardo Dodds",
      "Saad Nadeem"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.04494"
  },
  {
    "id": "arXiv:2204.04497",
    "title": "IDPG: An Instance-Dependent Prompt Generation Method",
    "abstract": "Prompt tuning is a new, efficient NLP transfer learning paradigm that adds a\ntask-specific prompt in each input instance during the model training stage. It\nfreezes the pre-trained language model and only optimizes a few task-specific\nprompts. In this paper, we propose a conditional prompt generation method to\ngenerate prompts for each input instance, referred to as the Instance-Dependent\nPrompt Generation (IDPG). Unlike traditional prompt tuning methods that use a\nfixed prompt, IDPG introduces a lightweight and trainable component to generate\nprompts based on each input sentence. Extensive experiments on ten natural\nlanguage understanding (NLU) tasks show that the proposed strategy consistently\noutperforms various prompt tuning baselines and is on par with other efficient\ntransfer learning methods such as Compacter while tuning far fewer model\nparameters.",
    "descriptor": "\nComments: To appear at the NAACL 2022 main conference\n",
    "authors": [
      "Zhuofeng Wu",
      "Sinong Wang",
      "Jiatao Gu",
      "Rui Hou",
      "Yuxiao Dong",
      "V.G.Vinod Vydiswaran",
      "Hao Ma"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.04497"
  },
  {
    "id": "arXiv:2204.04500",
    "title": "Faster Min-Plus Product for Monotone Instances",
    "abstract": "In this paper, we show that the time complexity of monotone min-plus product\nof two $n\\times n$ matrices is\n$\\tilde{O}(n^{(3+\\omega)/2})=\\tilde{O}(n^{2.687})$, where $\\omega < 2.373$ is\nthe fast matrix multiplication exponent [Alman and Vassilevska Williams 2021].\nThat is, when $A$ is an arbitrary integer matrix and $B$ is either row-monotone\nor column-monotone with integer elements bounded by $O(n)$, computing the\nmin-plus product $C$ where $C_{i,j}=\\min_k\\{A_{i,k}+B_{k,j}\\}$ takes\n$\\tilde{O}(n^{(3+\\omega)/2})$ time, which greatly improves the previous time\nbound of $\\tilde{O}(n^{(12+\\omega)/5})=\\tilde{O}(n^{2.875})$ [Gu, Polak,\nVassilevska Williams and Xu 2021]. Then by simple reductions, this means the\nfollowing problems also have $\\tilde{O}(n^{(3+\\omega)/2})$ time algorithms:\n(1) $A$ and $B$ are both bounded-difference, that is, the difference between\nany two adjacent entries is a constant. The previous results give time\ncomplexities of $\\tilde{O}(n^{2.824})$ [Bringmann, Grandoni, Saha and\nVassilevska Williams 2016] and $\\tilde{O}(n^{2.779})$ [Chi, Duan and Xie 2022].\n(2) $A$ is arbitrary and the columns or rows of $B$ are bounded-difference.\nPrevious result gives time complexity of $\\tilde{O}(n^{2.922})$ [Bringmann,\nGrandoni, Saha and Vassilevska Williams 2016].\n(3) The problems reducible to these problems, such as language edit distance,\nRNA-folding, scored parsing problem on BD grammars. [Bringmann, Grandoni, Saha\nand Vassilevska Williams 2016].\nFinally, we also consider the problem of min-plus convolution between two\nintegral sequences which are monotone and bounded by $O(n)$, and achieve a\nrunning time upper bound of $\\tilde{O}(n^{1.5})$. Previously, this task\nrequires running time $\\tilde{O}(n^{(9+\\sqrt{177})/12}) = O(n^{1.859})$ [Chan\nand Lewenstein 2015].",
    "descriptor": "\nComments: 26 pages\n",
    "authors": [
      "Shucheng Chi",
      "Ran Duan",
      "Tianle Xie",
      "Tianyi Zhang"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2204.04500"
  },
  {
    "id": "arXiv:2204.04501",
    "title": "Explain yourself! Effects of Explanations in Human-Robot Interaction",
    "abstract": "Recent developments in explainable artificial intelligence promise the\npotential to transform human-robot interaction: Explanations of robot decisions\ncould affect user perceptions, justify their reliability, and increase trust.\nHowever, the effects on human perceptions of robots that explain their\ndecisions have not been studied thoroughly. To analyze the effect of\nexplainable robots, we conduct a study in which two simulated robots play a\ncompetitive board game. While one robot explains its moves, the other robot\nonly announces them. Providing explanations for its actions was not sufficient\nto change the perceived competence, intelligence, likeability or safety ratings\nof the robot. However, the results show that the robot that explains its moves\nis perceived as more lively and human-like. This study demonstrates the need\nfor and potential of explainable human-robot interaction and the wider\nassessment of its effects as a novel research direction.",
    "descriptor": "",
    "authors": [
      "Jakob Ambsdorf",
      "Alina Munir",
      "Yiyao Wei",
      "Klaas Degkwitz",
      "Harm Matthias Harms",
      "Susanne Stannek",
      "Kyra Ahrens",
      "Dennis Becker",
      "Erik Strahl",
      "Tom Weber",
      "Stefan Wermter"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.04501"
  },
  {
    "id": "arXiv:2204.04504",
    "title": "TANet: Thread-Aware Pretraining for Abstractive Conversational  Summarization",
    "abstract": "Although pre-trained language models (PLMs) have achieved great success and\nbecome a milestone in NLP, abstractive conversational summarization remains a\nchallenging but less studied task. The difficulty lies in two aspects. One is\nthe lack of large-scale conversational summary data. Another is that applying\nthe existing pre-trained models to this task is tricky because of the\nstructural dependence within the conversation and its informal expression, etc.\nIn this work, we first build a large-scale (11M) pretraining dataset called\nRCS, based on the multi-person discussions in the Reddit community. We then\npresent TANet, a thread-aware Transformer-based network. Unlike the existing\npre-trained models that treat a conversation as a sequence of sentences, we\nargue that the inherent contextual dependency among the utterances plays an\nessential role in understanding the entire conversation and thus propose two\nnew techniques to incorporate the structural information into our model. The\nfirst is thread-aware attention which is computed by taking into account the\ncontextual dependency within utterances. Second, we apply thread prediction\nloss to predict the relations between utterances. We evaluate our model on four\ndatasets of real conversations, covering types of meeting transcripts,\ncustomer-service records, and forum threads. Experimental results demonstrate\nthat TANET achieves a new state-of-the-art in terms of both automatic\nevaluation and human judgment.",
    "descriptor": "\nComments: NAACL2022-findings\n",
    "authors": [
      "Ze Yang",
      "Liran Wang",
      "Zhoujin Tian",
      "Wei Wu",
      "Zhoujun Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.04504"
  },
  {
    "id": "arXiv:2204.04507",
    "title": "MR-iNet Gym: Framework for Edge Deployment of Deep Reinforcement  Learning on Embedded Software Defined Radio",
    "abstract": "Dynamic resource allocation plays a critical role in the next generation of\nintelligent wireless communication systems. Machine learning has been leveraged\nas a powerful tool to make strides in this domain. In most cases, the progress\nhas been limited to simulations due to the challenging nature of hardware\ndeployment of these solutions. In this paper, for the first time, we design and\ndeploy deep reinforcement learning (DRL)-based power control agents on the GPU\nembedded software defined radios (SDRs). To this end, we propose an end-to-end\nframework (MR-iNet Gym) where the simulation suite and the embedded SDR\ndevelopment work cohesively to overcome real-world implementation hurdles. To\nprove feasibility, we consider the problem of distributed power control for\ncode-division multiple access (DS-CDMA)-based LPI/D transceivers. We first\nbuild a DS-CDMA ns3 module that interacts with the OpenAI Gym environment.\nNext, we train the power control DRL agents in this ns3-gym simulation\nenvironment in a scenario that replicates our hardware testbed. Next, for edge\n(embedded on-device) deployment, the trained models are optimized for real-time\noperation without loss of performance. Hardware-based evaluation verifies the\nefficiency of DRL agents over traditional distributed constrained power control\n(DCPC) algorithm. More significantly, as the primary goal, this is the first\nwork that has established the feasibility of deploying DRL to provide optimized\ndistributed resource allocation for next-generation of GPU-embedded radios.",
    "descriptor": "\nComments: To appear in Proceedings of ACM Workshop on Wireless Security and Machine Learning (WiseML 2022)\n",
    "authors": [
      "Jithin Jagannath",
      "Kian Hamedani",
      "Collin Farquhar",
      "Keyvan Ramezanpour",
      "Anu Jagannath"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2204.04507"
  },
  {
    "id": "arXiv:2204.04508",
    "title": "Finding the Right Place: Sensor Placement for UWB Time Difference of  Arrival Localization in Cluttered Indoor Environments",
    "abstract": "Ultra-wideband (UWB) time difference of arrival (TDOA)-based localization has\nrecently emerged as a promising indoor positioning solution. However, in\ncluttered environments, both the UWB radio positions and the obstacle-induced\nnon-line-of-sight (NLOS) measurement biases significantly impact the quality of\nthe position estimate. Consequently, the placement of the UWB radios must be\ncarefully designed to provide satisfactory localization accuracy for a region\nof interest. In this work, we propose a novel algorithm that optimizes the UWB\nradio positions for a pre-defined region of interest in the presence of\nobstacles. The mean-squared error (MSE) metric is used to formulate an\noptimization problem that balances the influence of the geometry of the radio\npositions and the NLOS effects. We further apply the proposed algorithm to\ncompute a minimal number of UWB radios required for a desired localization\naccuracy and their corresponding positions. In a real-world cluttered\nenvironment, we show that the designed UWB radio placements provide 47% and 76%\nlocalization root-mean-squared error (RMSE) reduction in 2D and 3D experiments,\nrespectively, when compared against trivial placements.",
    "descriptor": "",
    "authors": [
      "Wenda Zhao",
      "Abhishek Goudar",
      "Angela P. Schoellig"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2204.04508"
  },
  {
    "id": "arXiv:2204.04510",
    "title": "Efficient Representation Learning of Subgraphs by Subgraph-To-Node  Translation",
    "abstract": "A subgraph is a data structure that can represent various real-world\nproblems. We propose Subgraph-To-Node (S2N) translation, which is a novel\nformulation to efficiently learn representations of subgraphs. Specifically,\ngiven a set of subgraphs in the global graph, we construct a new graph by\ncoarsely transforming subgraphs into nodes. We perform subgraph-level tasks as\nnode-level tasks through this translation. By doing so, we can significantly\nreduce the memory and computational costs in both training and inference. We\nconduct experiments on four real-world datasets to evaluate performance and\nefficiency. Our experiments demonstrate that models with S2N translation are\nmore efficient than state-of-the-art models without substantial performance\ndecrease.",
    "descriptor": "\nComments: ICLR 2022 Workshop GTRL\n",
    "authors": [
      "Dongkwan Kim",
      "Alice Oh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2204.04510"
  },
  {
    "id": "arXiv:2204.04511",
    "title": "FuNNscope: Visual microscope for interactively exploring the loss  landscape of fully connected neural networks",
    "abstract": "Despite their effective use in various fields, many aspects of neural\nnetworks are poorly understood. One important way to investigate the\ncharacteristics of neural networks is to explore the loss landscape. However,\nmost models produce a high-dimensional non-convex landscape which is difficult\nto visualize. We discuss and extend existing visualization methods based on 1D-\nand 2D slicing with a novel method that approximates the actual loss landscape\ngeometry by using charts with interpretable axes. Based on the assumption that\nobservations on small neural networks can generalize to more complex systems\nand provide us with helpful insights, we focus on small models in the range of\na few dozen weights, which enables computationally cheap experiments and the\nuse of an interactive dashboard. We observe symmetries around the zero vector,\nthe influence of different layers on the global landscape, the different weight\nsensitivities around a minimizer, and how gradient descent navigates high-loss\nobstacles. The user study resulted in an average SUS (System Usability Scale)\nscore with suggestions for improvement and opened up a number of possible\napplication scenarios, such as autoencoders and ensemble networks.",
    "descriptor": "\nComments: 10 pages, 18 figures, under review\n",
    "authors": [
      "Aleksandar Doknic",
      "Torsten M\u00f6ller"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.04511"
  },
  {
    "id": "arXiv:2204.04513",
    "title": "On the Exploitation of Deepfake Model Recognition",
    "abstract": "Despite recent advances in Generative Adversarial Networks (GANs), with\nspecial focus to the Deepfake phenomenon there is no a clear understanding\nneither in terms of explainability nor of recognition of the involved models.\nIn particular, the recognition of a specific GAN model that generated the\ndeepfake image compared to many other possible models created by the same\ngenerative architecture (e.g. StyleGAN) is a task not yet completely addressed\nin the state-of-the-art. In this work, a robust processing pipeline to evaluate\nthe possibility to point-out analytic fingerprints for Deepfake model\nrecognition is presented. After exploiting the latent space of 50 slightly\ndifferent models through an in-depth analysis on the generated images, a proper\nencoder was trained to discriminate among these models obtaining a\nclassification accuracy of over 96%. Once demonstrated the possibility to\ndiscriminate extremely similar images, a dedicated metric exploiting the\ninsights discovered in the latent space was introduced. By achieving a final\naccuracy of more than 94% for the Model Recognition task on images generated by\nmodels not employed in the training phase, this study takes an important step\nin countering the Deepfake phenomenon introducing a sort of signature in some\nsense similar to those employed in the multimedia forensics field (e.g. for\ncamera source identification task, image ballistics task, etc).",
    "descriptor": "",
    "authors": [
      "Luca Guarnera",
      "Oliver Giudice",
      "Matthias Niessner",
      "Sebastiano Battiato"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.04513"
  },
  {
    "id": "arXiv:2204.04515",
    "title": "Applying machine learning to predict behavior of bus transport in  Warsaw, Poland",
    "abstract": "Nowadays, it is possible to collect precise data describing movements of\npublic transport. Specifically, for each bus (or tram) geoposition data can be\nregularly collected. This includes data for all buses in Warsaw, Poland.\nMoreover, this data can be downloaded and analyzed. In this context, one of the\nsimplest questions is: can a model be build to represent behavior of busses,\nand predict their delays. This work provides initial results of our attempt to\nanswer this question.",
    "descriptor": "\nComments: 18 pages, full version of paper for ICCS conference\n",
    "authors": [
      "\u0141ukasz Pa\u0142ys",
      "Maria Ganzha",
      "Marcin Paprzycki"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2204.04515"
  },
  {
    "id": "arXiv:2204.04518",
    "title": "Attention U-Net as a surrogate model for groundwater prediction",
    "abstract": "Numerical simulations of groundwater flow are used to analyze and predict the\nresponse of an aquifer system to its change in state by approximating the\nsolution of the fundamental groundwater physical equations. The most used and\nclassical methodologies, such as Finite Difference (FD) and Finite Element (FE)\nMethods, use iterative solvers which are associated with high computational\ncost. This study proposes a physics-based convolutional encoder-decoder neural\nnetwork as a surrogate model to quickly calculate the response of the\ngroundwater system. Holding strong promise in cross-domain mappings,\nencoder-decoder networks are applicable for learning complex input-output\nmappings of physical systems. This manuscript presents an Attention U-Net model\nthat attempts to capture the fundamental input-output relations of the\ngroundwater system and generates solutions of hydraulic head in the whole\ndomain given a set of physical parameters and boundary conditions. The model\naccurately predicts the steady state response of a highly heterogeneous\ngroundwater system given the locations and piezometric head of up to 3 wells as\ninput. The network learns to pay attention only in the relevant parts of the\ndomain and the generated hydraulic head field corresponds to the target samples\nin great detail. Even relative to coarse finite difference approximations the\nproposed model is shown to be significantly faster than a comparative\nstate-of-the-art numerical solver, thus providing a base for further\ndevelopment of the presented networks as surrogate models for groundwater\nprediction.",
    "descriptor": "",
    "authors": [
      "Maria Luisa Taccari",
      "Jonathan Nuttall",
      "Xiaohui Chen",
      "He Wang",
      "Bennie Minnema",
      "Peter K.Jimack"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.04518"
  },
  {
    "id": "arXiv:2204.04521",
    "title": "Benchmarking for Public Health Surveillance tasks on Social Media with a  Domain-Specific Pretrained Language Model",
    "abstract": "A user-generated text on social media enables health workers to keep track of\ninformation, identify possible outbreaks, forecast disease trends, monitor\nemergency cases, and ascertain disease awareness and response to official\nhealth correspondence. This exchange of health information on social media has\nbeen regarded as an attempt to enhance public health surveillance (PHS).\nDespite its potential, the technology is still in its early stages and is not\nready for widespread application. Advancements in pretrained language models\n(PLMs) have facilitated the development of several domain-specific PLMs and a\nvariety of downstream applications. However, there are no PLMs for social media\ntasks involving PHS. We present and release PHS-BERT, a transformer-based PLM,\nto identify tasks related to public health surveillance on social media. We\ncompared and benchmarked the performance of PHS-BERT on 25 datasets from\ndifferent social medial platforms related to 7 different PHS tasks. Compared\nwith existing PLMs that are mainly evaluated on limited tasks, PHS-BERT\nachieved state-of-the-art performance on all 25 tested datasets, showing that\nour PLM is robust and generalizable in the common PHS tasks. By making PHS-BERT\navailable, we aim to facilitate the community to reduce the computational cost\nand introduce new baselines for future works across various PHS-related tasks.",
    "descriptor": "\nComments: Accepted @ ACL2022 Workshop: The First Workshop on Efficient Benchmarking in NLP\n",
    "authors": [
      "Usman Naseem",
      "Byoung Chan Lee",
      "Matloob Khushi",
      "Jinman Kim",
      "Adam G. Dunn"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.04521"
  },
  {
    "id": "arXiv:2204.04522",
    "title": "Knowledge-Free Black-Box Watermark and Ownership Proof for Image  Classification Neural Networks",
    "abstract": "Watermarking has become a plausible candidate for ownership verification and\nintellectual property protection of deep neural networks. Regarding image\nclassification neural networks, current watermarking schemes uniformly resort\nto backdoor triggers. However, injecting a backdoor into a neural network\nrequires knowledge of the training dataset, which is usually unavailable in the\nreal-world commercialization. Meanwhile, established watermarking schemes\noversight the potential damage of exposed evidence during ownership\nverification and the watermarking algorithms themselves. Those concerns decline\ncurrent watermarking schemes from industrial applications. To confront these\nchallenges, we propose a knowledge-free black-box watermarking scheme for image\nclassification neural networks. The image generator obtained from a data-free\ndistillation process is leveraged to stabilize the network's performance during\nthe backdoor injection. A delicate encoding and verification protocol is\ndesigned to ensure the scheme's security against knowledgable adversaries. We\nalso give a pioneering analysis of the capacity of the watermarking scheme.\nExperiment results proved the functionality-preserving capability and security\nof the proposed watermarking scheme.",
    "descriptor": "\nComments: 11 pages\n",
    "authors": [
      "Fangqi Li",
      "Shilin Wang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2204.04522"
  },
  {
    "id": "arXiv:2204.04533",
    "title": "Motion Artifacts Correction from Single-Channel EEG and fNIRS Signals  using Novel Wavelet Packet Decomposition in Combination with Canonical  Correlation Analysis",
    "abstract": "The electroencephalogram (EEG) and functional near-infrared spectroscopy\n(fNIRS) signals, highly non-stationary in nature, greatly suffers from motion\nartifacts while recorded using wearable sensors. This paper proposes two robust\nmethods: i) Wavelet packet decomposition (WPD), and ii) WPD in combination with\ncanonical correlation analysis (WPD-CCA), for motion artifact correction from\nsingle-channel EEG and fNIRS signals. The efficacy of these proposed techniques\nis tested using a benchmark dataset and the performance of the proposed methods\nis measured using two well-established performance matrices: i) Difference in\nthe signal to noise ratio ({\\Delta}SNR) and ii) Percentage reduction in motion\nartifacts ({\\eta}). The proposed WPD-based single-stage motion artifacts\ncorrection technique produces the highest average {\\Delta}SNR (29.44 dB) when\ndb2 wavelet packet is incorporated whereas the greatest average {\\eta} (53.48%)\nis obtained using db1 wavelet packet for all the available 23 EEG recordings.\nOur proposed two-stage motion artifacts correction technique i.e. the WPD-CCA\nmethod utilizing db1 wavelet packet has shown the best denoising performance\nproducing an average {\\Delta}SNR and {\\eta} values of 30.76 dB and 59.51%,\nrespectively for all the EEG recordings. On the other hand, the two-stage\nmotion artifacts removal technique i.e. WPD-CCA has produced the best average\n{\\Delta}SNR (16.55 dB, utilizing db1 wavelet packet) and largest average {\\eta}\n(41.40%, using fk8 wavelet packet). The highest average {\\Delta}SNR and {\\eta}\nusing single-stage artifacts removal techniques (WPD) are found as 16.11 dB and\n26.40%, respectively for all the fNIRS signals using fk4 wavelet packet. In\nboth EEG and fNIRS modalities, the percentage reduction in motion artifacts\nincreases by 11.28% and 56.82%, respectively when two-stage WPD-CCA techniques\nare employed.",
    "descriptor": "\nComments: 25 pages, 10 figures and 2 tables\n",
    "authors": [
      "Md Shafayet Hossain",
      "Muhammad E. H. Chowdhury",
      "Mamun Bin Ibne Reaz",
      "Sawal H. M. Ali",
      "Ahmad Ashrif A. Bakar",
      "Serkan Kiranyaz",
      "Amith Khandakar",
      "Mohammed Alhatou",
      "Rumana Habib",
      "Muhammad Maqsud Hossain"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.04533"
  },
  {
    "id": "arXiv:2204.04534",
    "title": "Extending the Scope of Out-of-Domain: Examining QA models in multiple  subdomains",
    "abstract": "Past works that investigate out-of-domain performance of QA systems have\nmainly focused on general domains (e.g. news domain, wikipedia domain),\nunderestimating the importance of subdomains defined by the internal\ncharacteristics of QA datasets. In this paper, we extend the scope of\n\"out-of-domain\" by splitting QA examples into different subdomains according to\ntheir several internal characteristics including question type, text length,\nanswer position. We then examine the performance of QA systems trained on the\ndata from different subdomains. Experimental results show that the performance\nof QA systems can be significantly reduced when the train data and test data\ncome from different subdomains. These results question the generalizability of\ncurrent QA systems in multiple subdomains, suggesting the need to combat the\nbias introduced by the internal characteristics of QA datasets.",
    "descriptor": "\nComments: 14 pages, 6 figures, 29 tables, to appear at ACL 2022 Workshop on Insights from Negative Results in NLP, code available in this https URL\n",
    "authors": [
      "Chenyang Lyu",
      "Jennifer Foster",
      "Yvette Graham"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.04534"
  },
  {
    "id": "arXiv:2204.04540",
    "title": "Peekaboo: A Hub-Based Approach to Enable Transparency in Data Processing  within Smart Homes (Extended Technical Report)",
    "abstract": "We present Peekaboo, a new privacy-sensitive architecture for smart homes\nthat leverages an in-home hub to pre-process and minimize outgoing data in a\nstructured and enforceable manner before sending it to external cloud servers.\nPeekaboo's key innovations are (1) abstracting common data pre-processing\nfunctionality into a small and fixed set of chainable operators, and (2)\nrequiring that developers explicitly declare desired data collection behaviors\n(e.g., data granularity, destinations, conditions) in an application manifest,\nwhich also specifies how the operators are chained together. Given a manifest,\nPeekaboo assembles and executes a pre-processing pipeline using operators\npre-loaded on the hub. In doing so, developers can collect smart home data on a\nneed-to-know basis; third-party auditors can verify data collection behaviors;\nand the hub itself can offer a number of centralized privacy features to users\nacross apps and devices, without additional effort from app developers. We\npresent the design and implementation of Peekaboo, along with an evaluation of\nits coverage of smart home scenarios, system performance, data minimization,\nand example built-in privacy features.",
    "descriptor": "\nComments: 18 pages\n",
    "authors": [
      "Haojian Jin",
      "Gram Liu",
      "David Hwang",
      "Swarun Kumar",
      "Yuvraj Agarwal",
      "Jason I. Hong"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2204.04540"
  },
  {
    "id": "arXiv:2204.04541",
    "title": "KOBEST: Korean Balanced Evaluation of Significant Tasks",
    "abstract": "A well-formulated benchmark plays a critical role in spurring advancements in\nthe natural language processing (NLP) field, as it allows objective and precise\nevaluation of diverse models. As modern language models (LMs) have become more\nelaborate and sophisticated, more difficult benchmarks that require linguistic\nknowledge and reasoning have been proposed. However, most of these benchmarks\nonly support English, and great effort is necessary to construct benchmarks for\nother low resource languages. To this end, we propose a new benchmark named\nKorean balanced evaluation of significant tasks (KoBEST), which consists of\nfive Korean-language downstream tasks. Professional Korean linguists designed\nthe tasks that require advanced Korean linguistic knowledge. Moreover, our data\nis purely annotated by humans and thoroughly reviewed to guarantee high data\nquality. We also provide baseline models and human performance results. Our\ndataset is available on the Huggingface.",
    "descriptor": "\nComments: 9 pages\n",
    "authors": [
      "Dohyeong Kim",
      "Myeongjun Jang",
      "Deuk Sin Kwon",
      "Eric Davis"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.04541"
  },
  {
    "id": "arXiv:2204.04542",
    "title": "Survival Seq2Seq: A Survival Model based on Sequence to Sequence  Architecture",
    "abstract": "This paper introduces a novel non-parametric deep model for estimating\ntime-to-event (survival analysis) in presence of censored data and competing\nrisks. The model is designed based on the sequence-to-sequence (Seq2Seq)\narchitecture, therefore we name it Survival Seq2Seq. The first recurrent neural\nnetwork (RNN) layer of the encoder of our model is made up of Gated Recurrent\nUnit with Decay (GRU-D) cells. These cells have the ability to effectively\nimpute not-missing-at-random values of longitudinal datasets with very high\nmissing rates, such as electronic health records (EHRs). The decoder of\nSurvival Seq2Seq generates a probability distribution function (PDF) for each\ncompeting risk without assuming any prior distribution for the risks. Taking\nadvantage of RNN cells, the decoder is able to generate smooth and virtually\nspike-free PDFs. This is beyond the capability of existing non-parametric deep\nmodels for survival analysis. Training results on synthetic and medical\ndatasets prove that Survival Seq2Seq surpasses other existing deep survival\nmodels in terms of the accuracy of predictions and the quality of generated\nPDFs.",
    "descriptor": "",
    "authors": [
      "Ebrahim Pourjafari",
      "Navid Ziaei",
      "Mohammad R. Rezaei",
      "Amir Sameizadeh",
      "Mohammad Shafiee",
      "Mohammad Alavinia",
      "Mansour Abolghasemian",
      "Nick Sajadi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.04542"
  },
  {
    "id": "arXiv:2204.04544",
    "title": "Efficient Extraction of Pathologies from C-Spine Radiology Reports using  Multi-Task Learning",
    "abstract": "Pretrained Transformer based models finetuned on domain specific corpora have\nchanged the landscape of NLP. Generally, if one has multiple tasks on a given\ndataset, one may finetune different models or use task specific adapters. In\nthis work, we show that a multi-task model can beat or achieve the performance\nof multiple BERT-based models finetuned on various tasks and various task\nspecific adapter augmented BERT-based models. We validate our method on our\ninternal radiologist's report dataset on cervical spine. We hypothesize that\nthe tasks are semantically close and related and thus multitask learners are\npowerful classifiers. Our work opens the scope of using our method to\nradiologist's reports on various body parts.",
    "descriptor": "\nComments: Accepted at 6th International Workshop on Health Intelligence, AAAI-2022. To appear in as a book chapter published by Springer in Studies in Computational Intelligence\n",
    "authors": [
      "Arijit Sehanobish",
      "Nathaniel Brown",
      "Ishita Daga",
      "Jayashri Pawar",
      "Danielle Torres",
      "Anasuya Das",
      "Murray Becker",
      "Richard Herzog",
      "Benjamin Odry",
      "Ron Vianu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.04544"
  },
  {
    "id": "arXiv:2204.04545",
    "title": "Self-Labeling Refinement for Robust Representation Learning with  Bootstrap Your Own Latent",
    "abstract": "In this work, we have worked towards two major goals. Firstly, we have\ninvestigated the importance of Batch Normalisation (BN) layers in a\nnon-contrastive representation learning framework called Bootstrap Your Own\nLatent (BYOL). We conducted several experiments to conclude that BN layers are\nnot necessary for representation learning in BYOL. Moreover, BYOL only learns\nfrom the positive pairs of images but ignores other semantically similar images\nin the same input batch. For the second goal, we have introduced two new loss\nfunctions to determine the semantically similar pairs in the same input batch\nof images and reduce the distance between their representations. These loss\nfunctions are Cross-Cosine Similarity Loss (CCSL) and Cross-Sigmoid Similarity\nLoss (CSSL). Using the proposed loss functions, we are able to surpass the\nperformance of Vanilla BYOL (71.04%) by training the BYOL framework using CCSL\nloss (76.87%) on the STL10 dataset. BYOL trained using CSSL loss performs\ncomparably with Vanilla BYOL.",
    "descriptor": "",
    "authors": [
      "Siddhant Garg",
      "Dhruval Jain"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.04545"
  },
  {
    "id": "arXiv:2204.04546",
    "title": "Adaptive search area for fast motion estimation",
    "abstract": "This paper suggests a new method for determining the search area for a motion\nestimation algorithm based on block matching. The search area is adaptively\nfound in the proposed method for each frame block. This search area is similar\nto that of the full search (FS) algorithm but smaller for most blocks of a\nframe. Therefore, the proposed algorithm is analogous to FS in terms of\nregularity but has much less computational complexity. The temporal and spatial\ncorrelations among the motion vectors of blocks are used to find the search\narea. The matched block is chosen from a rectangular area that the prediction\nvectors set out. Simulation results indicate that the speed of the proposed\nalgorithm is at least seven times better than the FS algorithm.",
    "descriptor": "\nComments: 9 pages, 6 figures\n",
    "authors": [
      "S.M.Reza Soroushmehr",
      "Shadrokh Samavi",
      "Shahram Shirani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.04546"
  },
  {
    "id": "arXiv:2204.04558",
    "title": "Trajectory Optimization Using Neural Network Gradients of Learned  Dynamics",
    "abstract": "Trajectory optimization methods have achieved an exceptional level of\nperformance on real-world robots in recent years. These methods heavily rely on\naccurate physics simulators, yet some aspects of the physical world, such as\nfriction, can only be captured to a limited extent by most simulators. The goal\nof this paper is to leverage trajectory optimization for performing highly\ndynamic and complex tasks with robotic systems in absence of an accurate\nphysics simulator. This is achieved by applying machine learning techniques to\nlearn a differentiable dynamics model of the system from data. On the example\nof a RC car, we show that from data collected in only 15 minutes of\nhuman-operated interactions with the car, a neural network is able to model\nhighly nonlinear behaviors such as loss of traction and drifting. Furthermore,\nwe use the analytical gradients of the neural network to perform gradient-based\ntrajectory optimization, both in an offline and online setting. We find that\nour learned model is able to represent complex physical behavior, like drifting\nand gives unprecedented performance in combination with trajectory optimization\nmethods.",
    "descriptor": "",
    "authors": [
      "Nathanael K\u00f6hler",
      "Bhavya Sukhija",
      "Miguel Zamora",
      "Simon Zimmermann",
      "Stelian Coros"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.04558"
  },
  {
    "id": "arXiv:2204.04562",
    "title": "What are the characteristics of highly-selected packages? A case study  on the npm ecosystem",
    "abstract": "With the popularity of software ecosystems, the number of open source\ncomponents (known as packages) has grown rapidly. Identifying high-quality and\nwell-maintained packages from a large pool of packages to depend on is a basic\nand important problem, as it is beneficial for various applications, such as\npackage recommendation and package search. However, no systematic and\ncomprehensive work focuses on addressing this problem except in online\ndiscussions or informal literature and interviews. To fill this gap, in this\npaper, we conducted a mixed qualitative and quantitative analysis to understand\nhow developers identify and select relevant open source packages. In\nparticular, we started by surveying 118 JavaScript developers from the npm\necosystem to qualitatively understand the factors that make a package to be\nhighly-selected within the npm ecosystem. The survey results showed that\nJavaScript developers believe that highly-selected packages are\nwell-documented, receive a high number of stars on GitHub, have a large number\nof downloads, and do not suffer from vulnerabilities. Then, we conducted an\nexperiment to quantitatively validate the developers' perception of the factors\nthat make a highly-selected package. In this analysis, we collected and mined\nhistorical data from 2,527 packages divided into highly-selected and not\nhighly-selected packages. For each package in the dataset, we collected\nquantitative data to present the factors studied in the developers' survey.\nNext, we used regression analysis to quantitatively investigate which of the\nstudied factors are the most important. Our regression analysis complements our\nsurvey results about highly-selected packages. In particular, the results\nshowed that highly-selected packages tend to be correlated by the number of\ndownloads, stars, and how large the package's readme file is.",
    "descriptor": "\nComments: Submitted to the Journal of Systems & Software\n",
    "authors": [
      "Suhaib Mujahid",
      "Rabe Abdalkareem",
      "Emad Shihab"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2204.04562"
  },
  {
    "id": "arXiv:2204.04564",
    "title": "Multimodal Transformer for Nursing Activity Recognition",
    "abstract": "In an aging population, elderly patient safety is a primary concern at\nhospitals and nursing homes, which demands for increased nurse care. By\nperforming nurse activity recognition, we can not only make sure that all\npatients get an equal desired care, but it can also free nurses from manual\ndocumentation of activities they perform, leading to a fair and safe place of\ncare for the elderly. In this work, we present a multimodal transformer-based\nnetwork, which extracts features from skeletal joints and acceleration data,\nand fuses them to perform nurse activity recognition. Our method achieves\nstate-of-the-art performance of 81.8% accuracy on the benchmark dataset\navailable for nurse activity recognition from the Nurse Care Activity\nRecognition Challenge. We perform ablation studies to show that our fusion\nmodel is better than single modality transformer variants (using only\nacceleration or skeleton joints data). Our solution also outperforms\nstate-of-the-art ST-GCN, GRU and other classical hand-crafted-feature-based\nclassifier solutions by a margin of 1.6%, on the NCRC dataset. Code is\navailable at \\url{https://github.com/Momilijaz96/MMT_for_NCRC}.",
    "descriptor": "\nComments: CVPR-2022 Workshop\n",
    "authors": [
      "Momal Ijaz",
      "Renato Diaz",
      "Chen Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2204.04564"
  },
  {
    "id": "arXiv:2204.04567",
    "title": "Joint Distribution Matters: Deep Brownian Distance Covariance for  Few-Shot Classification",
    "abstract": "Few-shot classification is a challenging problem as only very few training\nexamples are given for each new task. One of the effective research lines to\naddress this challenge focuses on learning deep representations driven by a\nsimilarity measure between a query image and few support images of some class.\nStatistically, this amounts to measure the dependency of image features, viewed\nas random vectors in a high-dimensional embedding space. Previous methods\neither only use marginal distributions without considering joint distributions,\nsuffering from limited representation capability, or are computationally\nexpensive though harnessing joint distributions. In this paper, we propose a\ndeep Brownian Distance Covariance (DeepBDC) method for few-shot classification.\nThe central idea of DeepBDC is to learn image representations by measuring the\ndiscrepancy between joint characteristic functions of embedded features and\nproduct of the marginals. As the BDC metric is decoupled, we formulate it as a\nhighly modular and efficient layer. Furthermore, we instantiate DeepBDC in two\ndifferent few-shot classification frameworks. We make experiments on six\nstandard few-shot image benchmarks, covering general object recognition,\nfine-grained categorization and cross-domain classification. Extensive\nevaluations show our DeepBDC significantly outperforms the counterparts, while\nestablishing new state-of-the-art results. The source code is available at\nthis http URL",
    "descriptor": "\nComments: Accepted to CVPR 2022 as an oral presentation. Equal contribution from first two authors\n",
    "authors": [
      "Jiangtao Xie",
      "Fei Long",
      "Jiaming Lv",
      "Qilong Wang",
      "Peihua Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2204.04567"
  },
  {
    "id": "arXiv:2204.04576",
    "title": "Adaptable Plug and Play Security Operations Center Leveraging a Novel  Programmable Plugin-based Intrusion Detection and Prevention System",
    "abstract": "The number of cyber-attacks have substantially increased over the past decade\nresulting in huge organizational financial losses. Indeed, it is no longer a\nmatter of \"if\" but \"when\" a security incident will take place. A Security\nOperations Center(SOC) adoption will help in the detection, identification,\nprevention, and resolution of issues before they end up causing extensive\ncyber-related damage. In this paper, our proposed framework is brought about to\naddress the problem that current open-source SOC implementations are plagued\nwith. These include lack of ability to be strengthened on the fly, slow\ndevelopment processes, and their ineptness for continuous timely updates. We,\nherein, propose a framework that would offer a fully automated open-source SOC\ndeployment; otherwise dubbed, a \"plug-and-play framework\"; full horizontal\nscalability incorporating a modular architecture. These underpinning features\nare meant to mitigate underlying SOC challenges, which often emerge as a result\nof many pre-determined and repeated processes, bolstering their ability for\nexpansion with new tools. This is on top of enhancing their ability to handle\nmore servers in the clusters as a single logical unit. We also introduce a new\nsystem of its kind called a Programmable Plugin-based Intrusion Detection and\nPrevention System (PPIDPS). This system will extend a SOC's ability to add any\ntool to the monitored devices while collecting logs that can trigger alerts\nwhenever a suspicious behavior is detected.",
    "descriptor": "\nComments: Submitted to Computers & Security\n",
    "authors": [
      "Ahmed S. Shatnawi",
      "Basheer Al-Duwairi",
      "Mahmoud M. Almazari",
      "Mohammad S. Alshakhatreh",
      "Ahmad N. Khader",
      "Abdullah A. Abdullah"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2204.04576"
  },
  {
    "id": "arXiv:2204.04579",
    "title": "Inferring Pitch from Coarse Spectral Features",
    "abstract": "Fundamental frequency (F0) has long been treated as the physical definition\nof \"pitch\" in phonetic analysis. But there have been many demonstrations that\nF0 is at best an approximation to pitch, both in production and in perception:\npitch is not F0, and F0 is not pitch. Changes in the pitch involve many\narticulatory and acoustic covariates; pitch perception often deviates from what\nF0 analysis predicts; and in fact, quasi-periodic signals from a single voice\nsource are often incompletely characterized by an attempt to define a single\ntime-varying F0. In this paper, we find strong support for the existence of\ncovariates for pitch in aspects of relatively coarse spectra, in which an\novertone series is not available. Thus linear regression can predict the pitch\nof simple vocalizations, produced by an articulatory synthesizer or by human,\nfrom single frames of such coarse spectra. Across speakers, and in more complex\nvocalizations, our experiments indicate that the covariates are not quite so\nsimple, though apparently still available for more sophisticated modeling. On\nthis basis, we propose that the field needs a better way of thinking about\nspeech pitch, just as celestial mechanics requires us to go beyond Newton's\npoint mass approximations to heavenly bodies.",
    "descriptor": "\nComments: Submitted to Interspeech 2022\n",
    "authors": [
      "Danni Ma",
      "Neville Ryant",
      "Mark Liberman"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2204.04579"
  },
  {
    "id": "arXiv:2204.04580",
    "title": "Re-Examining Human Annotations for Interpretable NLP",
    "abstract": "Explanation methods in Interpretable NLP often explain the model's decision\nby extracting evidence (rationale) from the input texts supporting the\ndecision. Benchmark datasets for rationales have been released to evaluate how\ngood the rationale is. The ground truth rationales in these datasets are often\nhuman annotations obtained via crowd-sourced websites. Valuable as these\ndatasets are, the details on how those human annotations are obtained are often\nnot clearly specified. We conduct comprehensive controlled experiments using\ncrowd-sourced websites on two widely used datasets in Interpretable NLP to\nunderstand how those unsaid details can affect the annotation results.\nSpecifically, we compare the annotation results obtained from recruiting\nworkers satisfying different levels of qualification. We also provide\nhigh-quality workers with different instructions for completing the same\nunderlying tasks. Our results reveal that the annotation quality is highly\nsubject to the workers' qualification, and workers can be guided to provide\ncertain annotations by the instructions. We further show that specific\nexplanation methods perform better when evaluated using the ground truth\nrationales obtained by particular instructions. Based on these observations, we\nhighlight the importance of providing complete details of the annotation\nprocess and call for careful interpretation of any experiment results obtained\nusing those annotations.",
    "descriptor": "\nComments: Explainable Agency in Artificial Intelligence Workshop, AAAI 2022\n",
    "authors": [
      "Cheng-Han Chiang",
      "Hung-yi Lee"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.04580"
  },
  {
    "id": "arXiv:2204.04581",
    "title": "Augmenting Pre-trained Language Models with QA-Memory for Open-Domain  Question Answering",
    "abstract": "Retrieval augmented language models have recently become the standard for\nknowledge intensive tasks. Rather than relying purely on latent semantics\nwithin the parameters of large neural models, these methods enlist a\nsemi-parametric memory to encode an index of knowledge for the model to\nretrieve over. Most prior work has employed text passages as the unit of\nknowledge, which has high coverage at the cost of interpretability,\ncontrollability, and efficiency. The opposite properties arise in other methods\nwhich have instead relied on knowledge base (KB) facts. At the same time, more\nrecent work has demonstrated the effectiveness of storing and retrieving from\nan index of Q-A pairs derived from text \\citep{lewis2021paq}. This approach\nyields a high coverage knowledge representation that maintains KB-like\nproperties due to its representations being more atomic units of information.\nIn this work we push this line of research further by proposing a\nquestion-answer augmented encoder-decoder model and accompanying pretraining\nstrategy. This yields an end-to-end system that not only outperforms prior QA\nretrieval methods on single-hop QA tasks but also enables compositional\nreasoning, as demonstrated by strong performance on two multi-hop QA datasets.\nTogether, these methods improve the ability to interpret and control the model\nwhile narrowing the performance gap with passage retrieval systems.",
    "descriptor": "",
    "authors": [
      "Wenhu Chen",
      "Pat Verga",
      "Michiel de Jong",
      "John Wieting",
      "William Cohen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.04581"
  },
  {
    "id": "arXiv:2204.04584",
    "title": "An improved method for constructing linear codes with small hulls",
    "abstract": "In this paper, we give a method for constructing linear codes with small\nhulls by generalizing the method in \\cite{LCD-T-matric}. As a result, we obtain\nmany optimal Euclidean LCD codes and Hermitian LCD codes, which improve the\npreviously known lower bound on the largest minimum distance. We also obtain\nmany optimal codes with one-dimension hull. Furthermore, we give three tables\nabout formally self-dual LCD codes.",
    "descriptor": "",
    "authors": [
      "Shitao Li"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2204.04584"
  },
  {
    "id": "arXiv:2204.04588",
    "title": "Robust Cross-Modal Representation Learning with Progressive  Self-Distillation",
    "abstract": "The learning objective of vision-language approach of CLIP does not\neffectively account for the noisy many-to-many correspondences found in\nweb-harvested image captioning datasets, which contributes to its compute and\ndata inefficiency. To address this challenge, we introduce a novel training\nframework based on cross-modal contrastive learning that uses progressive\nself-distillation and soft image-text alignments to more efficiently learn\nrobust representations from noisy data. Our model distills its own knowledge to\ndynamically generate soft-alignment targets for a subset of images and captions\nin every minibatch, which are then used to update its parameters. Extensive\nevaluation across 14 benchmark datasets shows that our method consistently\noutperforms its CLIP counterpart in multiple settings, including: (a) zero-shot\nclassification, (b) linear probe transfer, and (c) image-text retrieval,\nwithout incurring added computational cost. Analysis using an ImageNet-based\nrobustness test-bed reveals that our method offers better effective robustness\nto natural distribution shifts compared to both ImageNet-trained models and\nCLIP itself. Lastly, pretraining with datasets spanning two orders of magnitude\nin size shows that our improvements over CLIP tend to scale with number of\ntraining examples.",
    "descriptor": "\nComments: Accepted to CVPR 2022\n",
    "authors": [
      "Alex Andonian",
      "Shixing Chen",
      "Raffay Hamid"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.04588"
  },
  {
    "id": "arXiv:2204.04591",
    "title": "AABAC -- Automated Attribute Based Access Control for Genomics Data",
    "abstract": "The COVID-19 crisis has demonstrated the potential of cutting-edge genomics\nresearch. However, privacy of these sensitive pieces of information is an area\nof significant concern for genomics researchers. The current security models\nmakes it difficult to create flexible and automated data sharing frameworks.\nThese models also increases the complexity of adding or revoking access without\ncontacting the data publisher. In this work, we investigate an automated\nattribute-based access control (AABAC) model for genomics data over Named Data\nNetworking (NDN). AABAC secures the data itself rather than the storage\nlocation or transmission channel, provides automated data invalidation, and\nautomates key retrieval and data validation while maintaining the ability to\ncontrol access. We show that AABC when combined with NDN provide a secure and\nflexible combination for work with genomics research.",
    "descriptor": "\nComments: Named Data Networking, Access Control, Genomics Data\n",
    "authors": [
      "David Reddick",
      "Justin Presley",
      "F. Alex Feltus",
      "Susmit Shannigrahi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2204.04591"
  },
  {
    "id": "arXiv:2204.04596",
    "title": "Parameter-Efficient Tuning by Manipulating Hidden States of Pretrained  Language Models For Classification Tasks",
    "abstract": "Parameter-efficient tuning aims to distill knowledge for downstream tasks by\noptimizing a few introduced parameters while freezing the pretrained language\nmodels (PLMs). Continuous prompt tuning which prepends a few trainable vectors\nto the embeddings of input is one of these methods and has drawn much attention\ndue to its effectiveness and efficiency. This family of methods can be\nillustrated as exerting nonlinear transformations of hidden states inside PLMs.\nHowever, a natural question is ignored: can the hidden states be directly used\nfor classification without changing them? In this paper, we aim to answer this\nquestion by proposing a simple tuning method which only introduces three\ntrainable vectors. Firstly, we integrate all layers hidden states using the\nintroduced vectors. And then, we input the integrated hidden state(s) to a\ntask-specific linear classifier to predict categories. This scheme is similar\nto the way ELMo utilises hidden states except that they feed the hidden states\nto LSTM-based models. Although our proposed tuning scheme is simple, it\nachieves comparable performance with prompt tuning methods like P-tuning and\nP-tuning v2, verifying that original hidden states do contain useful\ninformation for classification tasks. Moreover, our method has an advantage\nover prompt tuning in terms of time and the number of parameters.",
    "descriptor": "",
    "authors": [
      "Haoran Yang",
      "Piji Li",
      "Wai Lam"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.04596"
  },
  {
    "id": "arXiv:2204.04599",
    "title": "Optimal Round and Sample-Size Complexity for Partitioning in Parallel  Sorting",
    "abstract": "Sate-of-the-art parallel sorting algorithms for distributed-memory\narchitectures are based on computing a balanced partitioning via sampling and\nhistogramming. By finding samples that partition the sorted keys into\nevenly-sized chunks, these algorithms minimize the number of communication\nrounds required. Histogramming (computing positions of samples) guides\nsampling, enabling a decrease in the overall number of samples collected. We\nderive lower and upper bounds on the number of sampling/histogramming rounds\nrequired to compute a balanced partitioning. We improve on prior results to\ndemonstrate that when using $p$ processors/parts, $O(\\log^* p)$ rounds with\n$O(p/\\log^* p)$ samples per round suffice. We match that with a lower bound\nthat shows any algorithm requires at least $\\Omega(\\log^* p)$ rounds with\n$O(p)$ samples per round. Additionally, we prove the $\\Omega(p \\log p)$ samples\nlower bound for one round, showing the optimality of sample sort in this case.\nTo derive the lower bound, we propose a hard randomized input distribution and\napply classical results from the distribution theory of runs.",
    "descriptor": "\nComments: 10 pages, submitted to SPAA 2022\n",
    "authors": [
      "Wentao Yang",
      "Vipul Harsh",
      "Edgar Solomonik"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2204.04599"
  },
  {
    "id": "arXiv:2204.04601",
    "title": "Explaining Deep Convolutional Neural Networks via Latent Visual-Semantic  Filter Attention",
    "abstract": "Interpretability is an important property for visual models as it helps\nresearchers and users understand the internal mechanism of a complex model.\nHowever, generating semantic explanations about the learned representation is\nchallenging without direct supervision to produce such explanations. We propose\na general framework, Latent Visual Semantic Explainer (LaViSE), to teach any\nexisting convolutional neural network to generate text descriptions about its\nown latent representations at the filter level. Our method constructs a mapping\nbetween the visual and semantic spaces using generic image datasets, using\nimages and category names. It then transfers the mapping to the target domain\nwhich does not have semantic labels. The proposed framework employs a modular\nstructure and enables to analyze any trained network whether or not its\noriginal training data is available. We show that our method can generate novel\ndescriptions for learned filters beyond the set of categories defined in the\ntraining dataset and perform an extensive evaluation on multiple datasets. We\nalso demonstrate a novel application of our method for unsupervised dataset\nbias analysis which allows us to automatically discover hidden biases in\ndatasets or compare different subsets without using additional labels. The\ndataset and code are made public to facilitate further research.",
    "descriptor": "\nComments: To appear in CVPR 2022 (oral presentation)\n",
    "authors": [
      "Yu Yang",
      "Seungbae Kim",
      "Jungseock Joo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.04601"
  },
  {
    "id": "arXiv:2204.04602",
    "title": "How much can one learn a partial differential equation from its  solution?",
    "abstract": "In this work we study the problem about learning a partial differential\nequation (PDE) from its solution data. PDEs of various types are used as\nexamples to illustrate how much the solution data can reveal the PDE operator\ndepending on the underlying operator and initial data. A data driven and data\nadaptive approach based on local regression and global consistency is proposed\nfor stable PDE identification. Numerical experiments are provided to verify our\nanalysis and demonstrate the performance of the proposed algorithms.",
    "descriptor": "\nComments: 44 pages\n",
    "authors": [
      "Yuchen He",
      "Hongkai Zhao",
      "Yimin Zhong"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)"
    ],
    "url": "https://arxiv.org/abs/2204.04602"
  },
  {
    "id": "arXiv:2204.04604",
    "title": "A High Capacity Preamble Sequence for Random Access in Beyond 5G  Networks: Design and Analysis",
    "abstract": "The widely used Zadoff-Chu sequence (ZC sequence) for random access preamble\nin 5G has limitations in terms of the total number of preambles generated,\nforcing the reuse of preambles. Hence, the probability of collision of\npreambles of UEs increase, resulting in the failure of random access procedure.\nTo truly qualify beyond 5G networks as green technology, the preamble capacity\nshould be increased without sacrificing energy efficiency. In this paper, we\npropose a new candidate preamble sequence called $mALL$ sequence using the\nconcept of cover sequences to achieve higher preamble capacity without\ndegrading the power efficiency and hence minimizing device's carbon footprint.\nWe compare the performance of $mALL$ sequence with Zadoff-Chu sequence and\nother sequences in the literature, such as $mZC$ and $aZC$ sequences. We\nevaluate the performance of the preamble sequences in terms of periodic\ncorrelation, detection probability and the effect of diversity combining. Also,\nthis paper explores the Peak to Average Power Ratio (PAPR) and Cubic Metric(CM)\nfor these sequences, as these are essential parameters to evaluate energy\nefficiency. We show that the preamble capacity of the proposed $mALL$ sequence\nis $10^{4}$ times higher than that of legacy ZC sequence without any\ndeterioration in the detection performance.",
    "descriptor": "",
    "authors": [
      "Sagar Pawar",
      "Lokesh Bommisetty",
      "T.G. Venkatesh"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2204.04604"
  },
  {
    "id": "arXiv:2204.04606",
    "title": "Towards efficient representation identification in supervised learning",
    "abstract": "Humans have a remarkable ability to disentangle complex sensory inputs (e.g.,\nimage, text) into simple factors of variation (e.g., shape, color) without much\nsupervision. This ability has inspired many works that attempt to solve the\nfollowing question: how do we invert the data generation process to extract\nthose factors with minimal or no supervision? Several works in the literature\non non-linear independent component analysis have established this negative\nresult; without some knowledge of the data generation process or appropriate\ninductive biases, it is impossible to perform this inversion. In recent years,\na lot of progress has been made on disentanglement under structural\nassumptions, e.g., when we have access to auxiliary information that makes the\nfactors of variation conditionally independent. However, existing work requires\na lot of auxiliary information, e.g., in supervised classification, it\nprescribes that the number of label classes should be at least equal to the\ntotal dimension of all factors of variation. In this work, we depart from these\nassumptions and ask: a) How can we get disentanglement when the auxiliary\ninformation does not provide conditional independence over the factors of\nvariation? b) Can we reduce the amount of auxiliary information required for\ndisentanglement? For a class of models where auxiliary information does not\nensure conditional independence, we show theoretically and experimentally that\ndisentanglement (to a large extent) is possible even when the auxiliary\ninformation dimension is much less than the dimension of the true latent\nrepresentation.",
    "descriptor": "\nComments: Proceedings of the First Conference on Causal Learning and Reasoning\n",
    "authors": [
      "Kartik Ahuja",
      "Divyat Mahajan",
      "Vasilis Syrgkanis",
      "Ioannis Mitliagkas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2204.04606"
  },
  {
    "id": "arXiv:2204.04607",
    "title": "Self-Supervised Video Representation Learning with Motion-Contrastive  Perception",
    "abstract": "Visual-only self-supervised learning has achieved significant improvement in\nvideo representation learning. Existing related methods encourage models to\nlearn video representations by utilizing contrastive learning or designing\nspecific pretext tasks. However, some models are likely to focus on the\nbackground, which is unimportant for learning video representations. To\nalleviate this problem, we propose a new view called long-range residual frame\nto obtain more motion-specific information. Based on this, we propose the\nMotion-Contrastive Perception Network (MCPNet), which consists of two branches,\nnamely, Motion Information Perception (MIP) and Contrastive Instance Perception\n(CIP), to learn generic video representations by focusing on the changing areas\nin videos. Specifically, the MIP branch aims to learn fine-grained motion\nfeatures, and the CIP branch performs contrastive learning to learn overall\nsemantics information for each instance. Experiments on two benchmark datasets\nUCF-101 and HMDB-51 show that our method outperforms current state-of-the-art\nvisual-only self-supervised approaches.",
    "descriptor": "\nComments: Accepted by ICME 2022\n",
    "authors": [
      "Jinyu Liu",
      "Ying Cheng",
      "Yuejie Zhang",
      "Rui-Wei Zhao",
      "Rui Feng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.04607"
  },
  {
    "id": "arXiv:2204.04611",
    "title": "Decay No More: A Persistent Twitter Dataset for Learning Social Meaning",
    "abstract": "With the proliferation of social media, many studies resort to social media\nto construct datasets for developing social meaning understanding systems. For\nthe popular case of Twitter, most researchers distribute tweet IDs without the\nactual text contents due to the data distribution policy of the platform. One\nissue is that the posts become increasingly inaccessible over time, which leads\nto unfair comparisons and a temporal bias in social media research. To\nalleviate this challenge of data decay, we leverage a paraphrase model to\npropose a new persistent English Twitter dataset for social meaning (PTSM).\nPTSM consists of $17$ social meaning datasets in $10$ categories of tasks. We\nexperiment with two SOTA pre-trained language models and show that our PTSM can\nsubstitute the actual tweets with paraphrases with marginal performance loss.",
    "descriptor": "\nComments: Under review. arXiv admin note: text overlap with arXiv:2108.00356\n",
    "authors": [
      "Chiyu Zhang",
      "Muhammad Abdul-Mageed",
      "El Moatez Billah Nagoudi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.04611"
  },
  {
    "id": "arXiv:2204.04612",
    "title": "Confidence Estimation Transformer for Long-term Renewable Energy  Forecasting in Reinforcement Learning-based Power Grid Dispatching",
    "abstract": "The expansion of renewable energy could help realizing the goals of peaking\ncarbon dioxide emissions and carbon neutralization. Some existing grid\ndispatching methods integrating short-term renewable energy prediction and\nreinforcement learning (RL) have been proved to alleviate the adverse impact of\nenergy fluctuations risk. However, these methods omit the long-term output\nprediction, which leads to stability and security problems on the optimal power\nflow. This paper proposes a confidence estimation Transformer for long-term\nrenewable energy forecasting in reinforcement learning-based power grid\ndispatching (Conformer-RLpatching). Conformer-RLpatching predicts long-term\nactive output of each renewable energy generator with an enhanced Transformer\nto boost the performance of hybrid energy grid dispatching. Furthermore, a\nconfidence estimation method is proposed to reduce the prediction error of\nrenewable energy. Meanwhile, a dispatching necessity evaluation mechanism is\nput forward to decide whether the active output of a generator needs to be\nadjusted. Experiments carried out on the SG-126 power grid simulator show that\nConformer-RLpatching achieves great improvement over the second best algorithm\nDDPG in security score by 25.8% and achieves a better total reward compared\nwith the golden medal team in the power grid dispatching competition sponsored\nby State Grid Corporation of China under the same simulation environment. Codes\nare outsourced in https://github.com/buptlxh/Conformer-RLpatching.",
    "descriptor": "",
    "authors": [
      "Xinhang Li",
      "Zihao Li",
      "Nan Yang",
      "Zheng Yuan",
      "Qinwen Wang",
      "Yiying Yang",
      "Yupeng Huang",
      "Xuri Song",
      "Lei Li",
      "Lin Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.04612"
  },
  {
    "id": "arXiv:2204.04615",
    "title": "Learning Pixel-Level Distinctions for Video Highlight Detection",
    "abstract": "The goal of video highlight detection is to select the most attractive\nsegments from a long video to depict the most interesting parts of the video.\nExisting methods typically focus on modeling relationship between different\nvideo segments in order to learning a model that can assign highlight scores to\nthese segments; however, these approaches do not explicitly consider the\ncontextual dependency within individual segments. To this end, we propose to\nlearn pixel-level distinctions to improve the video highlight detection. This\npixel-level distinction indicates whether or not each pixel in one video\nbelongs to an interesting section. The advantages of modeling such fine-level\ndistinctions are two-fold. First, it allows us to exploit the temporal and\nspatial relations of the content in one video, since the distinction of a pixel\nin one frame is highly dependent on both the content before this frame and the\ncontent around this pixel in this frame. Second, learning the pixel-level\ndistinction also gives a good explanation to the video highlight task regarding\nwhat contents in a highlight segment will be attractive to people. We design an\nencoder-decoder network to estimate the pixel-level distinction, in which we\nleverage the 3D convolutional neural networks to exploit the temporal context\ninformation, and further take advantage of the visual saliency to model the\nspatial distinction. State-of-the-art performance on three public benchmarks\nclearly validates the effectiveness of our framework for video highlight\ndetection.",
    "descriptor": "\nComments: Accepted at CVPR 2022\n",
    "authors": [
      "Fanyue Wei",
      "Biao Wang",
      "Tiezheng Ge",
      "Yuning Jiang",
      "Wen Li",
      "Lixin Duan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.04615"
  },
  {
    "id": "arXiv:2204.04618",
    "title": "ME-GCN: Multi-dimensional Edge-Embedded Graph Convolutional Networks for  Semi-supervised Text Classification",
    "abstract": "Compared to sequential learning models, graph-based neural networks exhibit\nexcellent ability in capturing global information and have been used for\nsemi-supervised learning tasks. Most Graph Convolutional Networks are designed\nwith the single-dimensional edge feature and failed to utilise the rich edge\ninformation about graphs. This paper introduces the ME-GCN (Multi-dimensional\nEdge-enhanced Graph Convolutional Networks) for semi-supervised text\nclassification. A text graph for an entire corpus is firstly constructed to\ndescribe the undirected and multi-dimensional relationship of word-to-word,\ndocument-document, and word-to-document. The graph is initialised with\ncorpus-trained multi-dimensional word and document node representation, and the\nrelations are represented according to the distance of those words/documents\nnodes. Then, the generated graph is trained with ME-GCN, which considers the\nedge features as multi-stream signals, and each stream performs a separate\ngraph convolutional operation. Our ME-GCN can integrate a rich source of graph\nedge information of the entire text corpus. The results have demonstrated that\nour proposed model has significantly outperformed the state-of-the-art methods\nacross eight benchmark datasets.",
    "descriptor": "\nComments: ICLR 2022 on DLG4NLP\n",
    "authors": [
      "Kunze Wang",
      "Soyeon Caren Han",
      "Siqu Long",
      "Josiah Poon"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.04618"
  },
  {
    "id": "arXiv:2204.04619",
    "title": "A New Framework for Fast Automated Phonological Reconstruction Using  Trimmed Alignments and Sound Correspondence Patterns",
    "abstract": "Computational approaches in historical linguistics have been increasingly\napplied during the past decade and many new methods that implement parts of the\ntraditional comparative method have been proposed. Despite these increased\nefforts, there are not many easy-to-use and fast approaches for the task of\nphonological reconstruction. Here we present a new framework that combines\nstate-of-the-art techniques for automated sequence comparison with novel\ntechniques for phonetic alignment analysis and sound correspondence pattern\ndetection to allow for the supervised reconstruction of word forms in ancestral\nlanguages. We test the method on a new dataset covering six groups from three\ndifferent language families. The results show that our method yields promising\nresults while at the same time being not only fast but also easy to apply and\nexpand.",
    "descriptor": "\nComments: To appear at the 3rd Workshop on Computational Approaches to Historical Language Change, co-located with the ACL 2022 conference. this https URL\n",
    "authors": [
      "Johann-Mattis List",
      "Robert Forkel",
      "Nathan W. Hill"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.04619"
  },
  {
    "id": "arXiv:2204.04620",
    "title": "On Principal Curve-Based Classifiers and Similarity-Based Selective  Sampling in Time-Series",
    "abstract": "Considering the concept of time-dilation, there exist some major issues with\nrecurrent neural Architectures. Any variation in time spans between input data\npoints causes performance attenuation in recurrent neural network\narchitectures. Principal curve-based classifiers have the ability of handling\nany kind of variation in time spans. In other words, principal curve-based\nclassifiers preserve the relativity of time while neural network architecture\nviolates this property of time. On the other hand, considering the labeling\ncosts and problems in online monitoring devices, there should be an algorithm\nthat finds the data points which knowing their labels will cause in better\nperformance of the classifier. Current selective sampling algorithms have lack\nof reliability due to the randomness of the proposed algorithms. This paper\nproposes a classifier and also a deterministic selective sampling algorithm\nwith the same computational steps, both by use of principal curve as their\nbuilding block in model definition.",
    "descriptor": "\nComments: 13 double column pages\n",
    "authors": [
      "Aref Hakimzadeh",
      "Koorush Ziarati",
      "Mohammad Taheri"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.04620"
  },
  {
    "id": "arXiv:2204.04621",
    "title": "Unsupervised Manga Character Re-identification via Face-body and  Spatial-temporal Associated Clustering",
    "abstract": "In the past few years, there has been a dramatic growth in e-manga\n(electronic Japanese-style comics). Faced with the booming demand for manga\nresearch and the large amount of unlabeled manga data, we raised a new task,\ncalled unsupervised manga character re-identification. However, the artistic\nexpression and stylistic limitations of manga pose many challenges to the\nre-identification problem. Inspired by the idea that some content-related\nfeatures may help clustering, we propose a Face-body and Spatial-temporal\nAssociated Clustering method (FSAC). In the face-body combination module, a\nface-body graph is constructed to solve problems such as exaggeration and\ndeformation in artistic creation by using the integrity of the image. In the\nspatial-temporal relationship correction module, we analyze the appearance\nfeatures of characters and design a temporal-spatial-related triplet loss to\nfine-tune the clustering. Extensive experiments on a manga book dataset with\n109 volumes validate the superiority of our method in unsupervised manga\ncharacter re-identification.",
    "descriptor": "",
    "authors": [
      "Zhimin Zhang",
      "Zheng Wang",
      "Wei Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.04621"
  },
  {
    "id": "arXiv:2204.04627",
    "title": "Stripformer: Strip Transformer for Fast Image Deblurring",
    "abstract": "Images taken in dynamic scenes may contain unwanted motion blur, which\nsignificantly degrades visual quality. Such blur causes short- and long-range\nregion-specific smoothing artifacts that are often directional and non-uniform,\nwhich is difficult to be removed. Inspired by the current success of\ntransformers on computer vision and image processing tasks, we develop,\nStripformer, a transformer-based architecture that constructs intra- and\ninter-strip tokens to reweight image features in the horizontal and vertical\ndirections to catch blurred patterns with different orientations. It stacks\ninterlaced intra-strip and inter-strip attention layers to reveal blur\nmagnitudes. In addition to detecting region-specific blurred patterns of\nvarious orientations and magnitudes, Stripformer is also a token-efficient and\nparameter-efficient transformer model, demanding much less memory usage and\ncomputation cost than the vanilla transformer but works better without relying\non tremendous training data. Experimental results show that Stripformer\nperforms favorably against state-of-the-art models in dynamic scene deblurring.",
    "descriptor": "",
    "authors": [
      "Fu-Jen Tsai",
      "Yan-Tsung Peng",
      "Yen-Yu Lin",
      "Chung-Chi Tsai",
      "Chia-Wen Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.04627"
  },
  {
    "id": "arXiv:2204.04628",
    "title": "A Skyline and ranking query odissey: a journey from skyline and ranking  queries up to f-skyline queries",
    "abstract": "Skyline and ranking queries are two of the most used tools to manage large\ndata sets. The former is based on non-dominance, while the latter on a scoring\nfunction. Despite their effectiveness, they have some drawbacks like the result\nsize or the need for a utility function that must be taken into account. To do\nthis, in the last years, new kinds of queries, called flexible skyline queries,\nhave been developed. In the present article, a description of skyline and\nranking queries, f-skyline queries and a comparison among them are provided to\nhighlight the improvements achieved and how some limitations have been\novercome.",
    "descriptor": "",
    "authors": [
      "Giuseppe Sorrentino"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2204.04628"
  },
  {
    "id": "arXiv:2204.04629",
    "title": "Pushing on Personality Detection from Verbal Behavior: A Transformer  Meets Text Contours of Psycholinguistic Features",
    "abstract": "Research at the intersection of personality psychology, computer science, and\nlinguistics has recently focused increasingly on modeling and predicting\npersonality from language use. We report two major improvements in predicting\npersonality traits from text data: (1) to our knowledge, the most comprehensive\nset of theory-based psycholinguistic features and (2) hybrid models that\nintegrate a pre-trained Transformer Language Model BERT and Bidirectional Long\nShort-Term Memory (BLSTM) networks trained on within-text distributions ('text\ncontours') of psycholinguistic features. We experiment with BLSTM models (with\nand without Attention) and with two techniques for applying pre-trained\nlanguage representations from the transformer model - 'feature-based' and\n'fine-tuning'. We evaluate the performance of the models we built on two\nbenchmark datasets that target the two dominant theoretical models of\npersonality: the Big Five Essay dataset and the MBTI Kaggle dataset. Our\nresults are encouraging as our models outperform existing work on the same\ndatasets. More specifically, our models achieve improvement in classification\naccuracy by 2.9% on the Essay dataset and 8.28% on the Kaggle MBTI dataset. In\naddition, we perform ablation experiments to quantify the impact of different\ncategories of psycholinguistic features in the respective personality\nprediction models.",
    "descriptor": "\nComments: accepted at WASSA 2022\n",
    "authors": [
      "Elma Kerz",
      "Yu Qiao",
      "Sourabh Zanwar",
      "Daniel Wiechmann"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.04629"
  },
  {
    "id": "arXiv:2204.04633",
    "title": "A Distributed Real-Time Recommender System for Big Data Streams",
    "abstract": "In today's data-driven world, recommender systems (RS) play a crucial role to\nsupport the decision-making process. As users become continuously connected to\nthe internet, they become less patient and less tolerant to obsolete\nrecommendations made by an RS, e.g., movie recommendations on Netflix or books\nto read on Amazon. This, in turn, requires continuous training of the RS to\ncope with both the online fashion of data and the changing nature of user\ntastes and interests, known as concept drift. Streaming (online) RS has to\naddress three requirements: continuous training and recommendation, handling\nconcept drifts, and ability to scale. Streaming recommender systems proposed in\nthe literature mostly, address the first two requirements and do not consider\nscalability. That is because they run the training process on a single machine.\nSuch a machine, no matter how powerful it is, will eventually fail to cope with\nthe volume of the data, a lesson learned from big data processing. To tackle\nthe third challenge, we propose a Splitting and Replication mechanism for\nbuilding distributed streaming recommender systems. Our mechanism is inspired\nby the successful shared-nothing architecture that underpins contemporary big\ndata processing systems. We have applied our mechanism to two well-known\napproaches for online recommender systems, namely, matrix factorization and\nitem-based collaborative filtering. We have implemented our mechanism on top of\nApache Flink. We conducted experiments comparing the performance of the\nbaseline (single machine) approach with our distributed approach. Evaluating\ndifferent data sets, improvement in processing latency, throughput, and\naccuracy have been observed. Our experiments show online recall improvement by\n40\\% with more than 50\\% less memory consumption.",
    "descriptor": "",
    "authors": [
      "Heidy Hazem",
      "Ahmed Awad",
      "Ahmed Hassan"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2204.04633"
  },
  {
    "id": "arXiv:2204.04634",
    "title": "Intersection Prediction from Single 360\u00b0 Image via Deep Detection  of Possible Direction of Travel",
    "abstract": "Movie-Map, an interactive first-person-view map that engages the user in a\nsimulated walking experience, comprises short 360{\\deg} video segments\nseparated by traffic intersections that are seamlessly connected according to\nthe viewer's direction of travel. However, in wide urban-scale areas with\nnumerous intersecting roads, manual intersection segmentation requires\nsignificant human effort. Therefore, automatic identification of intersections\nfrom 360{\\deg} videos is an important problem for scaling up Movie-Map. In this\npaper, we propose a novel method that identifies an intersection from\nindividual frames in 360{\\deg} videos. Instead of formulating the intersection\nidentification as a standard binary classification task with a 360{\\deg} image\nas input, we identify an intersection based on the number of the possible\ndirections of travel (PDoT) in perspective images projected in eight directions\nfrom a single 360{\\deg} image detected by the neural network for handling\nvarious types of intersections. We constructed a large-scale 360{\\deg} Image\nIntersection Identification (iii360) dataset for training and evaluation where\n360{\\deg} videos were collected from various areas such as school campus,\ndowntown, suburb, and china town and demonstrate that our PDoT-based method\nachieves 88\\% accuracy, which is significantly better than that achieved by the\ndirect naive binary classification based method. The source codes and a partial\ndataset will be shared in the community after the paper is published.",
    "descriptor": "\nComments: Accepted for publication in BMVC\n",
    "authors": [
      "Naoki Sugimoto",
      "Satoshi Ikehata",
      "Kiyoharu Aizawa"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2204.04634"
  },
  {
    "id": "arXiv:2204.04635",
    "title": "ConsInstancy: Learning Instance Representations for Semi-Supervised  Panoptic Segmentation of Concrete Aggregate Particles",
    "abstract": "We present a semi-supervised method for panoptic segmentation based on\nConsInstancy regularisation, a novel strategy for semi-supervised learning. It\nleverages completely unlabelled data by enforcing consistency between predicted\ninstance representations and semantic segmentations during training in order to\nimprove the segmentation performance. To this end, we also propose new types of\ninstance representations that can be predicted by one simple forward path\nthrough a fully convolutional network (FCN), delivering a convenient and\nsimple-to-train framework for panoptic segmentation. More specifically, we\npropose the prediction of a three-dimensional instance orientation map as\nintermediate representation and two complementary distance transform maps as\nfinal representation, providing unique instance representations for a panoptic\nsegmentation. We test our method on two challenging data sets of both, hardened\nand fresh concrete, the latter being proposed by the authors in this paper\ndemonstrating the effectiveness of our approach, outperforming the results\nachieved by state-of-the-art methods for semi-supervised segmentation. In\nparticular, we are able to show that by leveraging completely unlabeled data in\nour semi-supervised approach the achieved overall accuracy (OA) is increased by\nup to 5% compared to an entirely supervised training using only labeled data.\nFurthermore, we exceed the OA achieved by state-of-the-art semi-supervised\nmethods by up to 1.5%.",
    "descriptor": "",
    "authors": [
      "Max Coenen",
      "Tobias Schack",
      "Dries Beyer",
      "Christian Heipke",
      "Michael Haist"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.04635"
  },
  {
    "id": "arXiv:2204.04636",
    "title": "\"That Is a Suspicious Reaction!\": Interpreting Logits Variation to  Detect NLP Adversarial Attacks",
    "abstract": "Adversarial attacks are a major challenge faced by current machine learning\nresearch. These purposely crafted inputs fool even the most advanced models,\nprecluding their deployment in safety-critical applications. Extensive research\nin computer vision has been carried to develop reliable defense strategies.\nHowever, the same issue remains less explored in natural language processing.\nOur work presents a model-agnostic detector of adversarial text examples. The\napproach identifies patterns in the logits of the target classifier when\nperturbing the input text. The proposed detector improves the current\nstate-of-the-art performance in recognizing adversarial inputs and exhibits\nstrong generalization capabilities across different NLP models, datasets, and\nword-level attacks.",
    "descriptor": "\nComments: ACL 2022\n",
    "authors": [
      "Edoardo Mosca",
      "Shreyash Agarwal",
      "Javier Rando-Ramirez",
      "Georg Groh"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.04636"
  },
  {
    "id": "arXiv:2204.04637",
    "title": "UniDU: Towards A Unified Generative Dialogue Understanding Framework",
    "abstract": "With the development of pre-trained language models, remarkable success has\nbeen witnessed in dialogue understanding (DU) direction. However, the current\nDU approaches just employ an individual model for each DU task, independently,\nwithout considering the shared knowledge across different DU tasks. In this\npaper, we investigate a unified generative dialogue understanding framework,\nnamely UniDU, to achieve information exchange among DU tasks. Specifically, we\nreformulate the DU tasks into unified generative paradigm. In addition, to\nconsider different training data for each task, we further introduce\nmodel-agnostic training strategy to optimize unified model in a balanced\nmanner. We conduct the experiments on ten dialogue understanding datasets,\nwhich span five fundamental tasks: dialogue summary, dialogue completion, slot\nfilling, intent detection and dialogue state tracking. The proposed UniDU\nframework outperforms task-specific well-designed methods on all 5 tasks. We\nfurther conduct comprehensive analysis experiments to study the effect factors.\nThe experimental results also show that the proposed method obtains promising\nperformance on unseen dialogue domain.",
    "descriptor": "\nComments: 13 pages, 9 figures\n",
    "authors": [
      "Zhi Chen",
      "Lu Chen",
      "Bei Chen",
      "Libo Qin",
      "Yuncong Liu",
      "Su Zhu",
      "Jian-Guang Lou",
      "Kai Yu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.04637"
  },
  {
    "id": "arXiv:2204.04640",
    "title": "Conservation laws with discontinuous flux function on networks: a  splitting algorithm",
    "abstract": "In this article, we present an extension of the splitting algorithm proposed\nin [22] to networks of conservation laws with discontinuous flux functions in\nthe unknown. We start with the discussion of a suitable Riemann solver at the\njunction and then describe a strategy how to use the splitting algorithm on the\nnetwork. Finally, numerical examples demonstrate the accuracy of the splitting\nalgorithm by comparisons to the exact solution and other approaches used in the\nliterature.",
    "descriptor": "",
    "authors": [
      "Jan Friedrich",
      "Simone G\u00f6ttlich",
      "Annika Uphoff"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2204.04640"
  },
  {
    "id": "arXiv:2204.04643",
    "title": "A Palm Calculus Approach to the Distribution of the Age of Information",
    "abstract": "A key metric to express the timeliness of status updates in latency-sensitive\nnetworked systems is the age of information (AoI), i.e., the time elapsed since\nthe generation of the last received informative status message. This metric\nallows studying a number of applications including updates of sensory and\ncontrol information in cyber-physical systems and vehicular networks as well\nas, job and resource allocation in cloud clusters. State-of-the-art approaches\nto analyzing the AoI rely on queueing models that are composed of one or many\nqueuing systems endowed with service order, e.g., FIFO, LIFO, or\nlast-generated-first-out order. A major difficulty arising in these analysis\nmethods is capturing the AoI under message reordering when the delivery is\nnon-preemptive and non-FIFO, i.e., when messages can overtake each other and\nthe reception of informative messages may obsolete some messages that are\nunderway. In this paper, we derive an exact formulation for the distribution of\nAoI in non-preemptive, non-FIFO systems where the main ingredients of our\nanalysis are Palm calculus and time inversion. Owing to the rationality of the\nLaplace-Stieltjes transforms that are used in our approach, we obtain\ncomputable exact expressions for the distribution of AoI.",
    "descriptor": "",
    "authors": [
      "Amr Rizk",
      "Jean-Yves Le Boudec"
    ],
    "subjectives": [
      "Performance (cs.PF)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2204.04643"
  },
  {
    "id": "arXiv:2204.04644",
    "title": "From graphs to DAGs: a low-complexity model and a scalable algorithm",
    "abstract": "Learning directed acyclic graphs (DAGs) is long known a critical challenge at\nthe core of probabilistic and causal modeling. The NoTears approach of (Zheng\net al., 2018), through a differentiable function involving the matrix\nexponential trace $\\mathrm{tr}(\\exp(\\cdot))$, opens up a way to learning DAGs\nvia continuous optimization, though with a $O(d^3)$ complexity in the number\n$d$ of nodes. This paper presents a low-complexity model, called LoRAM for\nLow-Rank Additive Model, which combines low-rank matrix factorization with a\nsparsification mechanism for the continuous optimization of DAGs. The main\ncontribution of the approach lies in an efficient gradient approximation method\nleveraging the low-rank property of the model, and its straightforward\napplication to the computation of projections from graph matrices onto the DAG\nmatrix space. The proposed method achieves a reduction from a cubic complexity\nto quadratic complexity while handling the same DAG characteristic function as\nNoTears, and scales easily up to thousands of nodes for the projection problem.\nThe experiments show that the LoRAM achieves efficiency gains of orders of\nmagnitude compared to the state-of-the-art at the expense of a very moderate\naccuracy loss in the considered range of sparse matrices, and with a low\nsensitivity to the rank choice of the model's low-rank component.",
    "descriptor": "",
    "authors": [
      "Shuyu Dong",
      "Mich\u00e8le Sebag"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2204.04644"
  },
  {
    "id": "arXiv:2204.04645",
    "title": "Self-Supervised Audio-and-Text Pre-training with Extremely Low-Resource  Parallel Data",
    "abstract": "Multimodal pre-training for audio-and-text has recently been proved to be\neffective and has significantly improved the performance of many downstream\nspeech understanding tasks. However, these state-of-the-art pre-training\naudio-text models work well only when provided with large amount of parallel\naudio-and-text data, which brings challenges on many languages that are rich in\nunimodal corpora but scarce of parallel cross-modal corpus. In this paper, we\ninvestigate whether it is possible to pre-train an audio-text multimodal model\nwith extremely low-resource parallel data and extra non-parallel unimodal data.\nOur pre-training framework consists of the following components: (1)\nIntra-modal Denoising Auto-Encoding (IDAE), which is able to reconstruct input\ntext (audio) representations from a noisy version of itself. (2) Cross-modal\nDenoising Auto-Encoding (CDAE), which is pre-trained to reconstruct the input\ntext (audio), given both a noisy version of the input text (audio) and the\ncorresponding translated noisy audio features (text embeddings). (3) Iterative\nDenoising Process (IDP), which iteratively translates raw audio (text) and the\ncorresponding text embeddings (audio features) translated from previous\niteration into the new less-noisy text embeddings (audio features). We adapt a\ndual cross-modal Transformer as our backbone model which consists of two\nunimodal encoders for IDAE and two cross-modal encoders for CDAE and IDP. Our\nmethod achieves comparable performance on multiple downstream speech\nunderstanding tasks compared with the model pre-trained on fully parallel data,\ndemonstrating the great potential of the proposed method. Our code is available\nat: \\url{https://github.com/KarlYuKang/Low-Resource-Multimodal-Pre-training}.",
    "descriptor": "\nComments: AAAI 2022\n",
    "authors": [
      "Yu Kang",
      "Tianqiao Liu",
      "Hang Li",
      "Yang Hao",
      "Wenbiao Ding"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2204.04645"
  },
  {
    "id": "arXiv:2204.04646",
    "title": "Deep Embeddings for Robust User-Based Amateur Vocal Percussion  Classification",
    "abstract": "Vocal Percussion Transcription (VPT) is concerned with the automatic\ndetection and classification of vocal percussion sound events, allowing music\ncreators and producers to sketch drum lines on the fly. Classifier algorithms\nin VPT systems learn best from small user-specific datasets, which usually\nrestrict modelling to small input feature sets to avoid data overfitting. This\nstudy explores several deep supervised learning strategies to obtain\ninformative feature sets for amateur vocal percussion classification. We\nevaluated the performance of these sets on regular vocal percussion\nclassification tasks and compared them with several baseline approaches\nincluding feature selection methods and a speech recognition engine. These\nproposed learning models were supervised with several label sets containing\ninformation from four different levels of abstraction: instrument-level,\nsyllable-level, phoneme-level, and boxeme-level. Results suggest that\nconvolutional neural networks supervised with syllable-level annotations\nproduced the most informative embeddings for classification, which can be used\nas input representations to fit classifiers with. Finally, we used\nback-propagation-based saliency maps to investigate the importance of different\nspectrogram regions for feature learning.",
    "descriptor": "\nComments: Accepted at Sound and Music Computing (SMC) conference 2022\n",
    "authors": [
      "Alejandro Delgado",
      "Emir Demirel",
      "Vinod Subramanian",
      "Charalampos Saitis",
      "Mark Sandler"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Information Retrieval (cs.IR)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2204.04646"
  },
  {
    "id": "arXiv:2204.04651",
    "title": "Deep Conditional Representation Learning for Drum Sample Retrieval by  Vocalisation",
    "abstract": "Imitating musical instruments with the human voice is an efficient way of\ncommunicating ideas between music producers, from sketching melody lines to\nclarifying desired sonorities. For this reason, there is an increasing interest\nin building applications that allow artists to efficiently pick target samples\nfrom big sound libraries just by imitating them vocally. In this study, we\ninvestigated the potential of conditional autoencoder models to learn\ninformative features for Drum Sample Retrieval by Vocalisation (DSRV). We\nassessed the usefulness of their embeddings using four evaluation metrics, two\nof them relative to their acoustic properties and two of them relative to their\nperceptual properties via human listeners' similarity ratings. Results suggest\nthat models conditioned on both sound-type labels (drum vs imitation) and\ndrum-type labels (kick vs snare vs closed hi-hat vs opened hi-hat) learn the\nmost informative embeddings for DSRV. We finally looked into individual\ndifferences in vocal imitation style via the Mantel test and found salient\ndifferences among participants, highlighting the importance of user information\nwhen designing DSRV systems.",
    "descriptor": "\nComments: Submitted to Interspeech 2022 (under review)\n",
    "authors": [
      "Alejandro Delgado",
      "Charalampos Saitis",
      "Emmanouil Benetos",
      "Mark Sandler"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Information Retrieval (cs.IR)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2204.04651"
  },
  {
    "id": "arXiv:2204.04653",
    "title": "Counting in the 2020s: Binned Representations and Inclusive Performance  Measures for Deep Crowd Counting Approaches",
    "abstract": "The data distribution in popular crowd counting datasets is typically heavy\ntailed and discontinuous. This skew affects all stages within the pipelines of\ndeep crowd counting approaches. Specifically, the approaches exhibit\nunacceptably large standard deviation wrt statistical measures (MSE, MAE). To\naddress such concerns in a holistic manner, we make two fundamental\ncontributions. Firstly, we modify the training pipeline to accommodate the\nknowledge of dataset skew. To enable principled and balanced minibatch\nsampling, we propose a novel smoothed Bayesian binning approach. More\nspecifically, we propose a novel cost function which can be readily\nincorporated into existing crowd counting deep networks to encourage bin-aware\noptimization. As the second contribution, we introduce additional performance\nmeasures which are more inclusive and throw light on various comparative\nperformance aspects of the deep networks. We also show that our binning-based\nmodifications retain their superiority wrt the newly proposed performance\nmeasures. Overall, our contributions enable a practically useful and\ndetail-oriented characterization of performance for crowd counting approaches.",
    "descriptor": "\nComments: Extended version of arXiv:2108.08784. In review\n",
    "authors": [
      "Sravya Vardhani Shivapuja",
      "Ashwin Gopinath",
      "Ayush Gupta",
      "Ganesh Ramakrishnan",
      "Ravi Kiran Sarvadevabhatla"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2204.04653"
  },
  {
    "id": "arXiv:2204.04654",
    "title": "Fashionformer: A simple, Effective and Unified Baseline for Human  Fashion Segmentation and Recognition",
    "abstract": "Human fashion understanding is one important computer vision task since it\nhas the comprehensive information that can be used for real-world applications.\nIn this work, we focus on joint human fashion segmentation and attribute\nrecognition. Contrary to the previous works that separately model each task as\na multi-head prediction problem, our insight is to bridge these two tasks with\none unified model via vision transformer modeling to benefit each task. In\nparticular, we introduce the object query for segmentation and the attribute\nquery for attribute prediction. Both queries and their corresponding features\ncan be linked via mask prediction. Then we adopt a two-stream query learning\nframework to learn the decoupled query representations. For attribute stream,\nwe design a novel Multi-Layer Rendering module to explore more fine-grained\nfeatures. The decoder design shares the same spirits with DETR, thus we name\nthe proposed method Fahsionformer. Extensive experiments on three human fashion\ndatasets including Fashionpedia, ModaNet and Deepfashion illustrate the\neffectiveness of our approach. In particular, our method with the same backbone\nachieve relative 10% improvements than previous works in case of \\textit{a\njoint metric ( AP$^{\\text{mask}}_{\\text{IoU+F}_1}$) for both segmentation and\nattribute recognition}. To the best of our knowledge, we are the first unified\nend-to-end vision transformer framework for human fashion analysis. We hope\nthis simple yet effective method can serve as a new flexible baseline for\nfashion analysis. Code will be available at\nhttps://github.com/xushilin1/FashionFormer.",
    "descriptor": "\nComments: technical report\n",
    "authors": [
      "Shilin Xu",
      "Xiangtai Li",
      "Jingbo Wang",
      "Guangliang Cheng",
      "Yunhai Tong",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.04654"
  },
  {
    "id": "arXiv:2204.04655",
    "title": "Panoptic-PartFormer: Learning a Unified Model for Panoptic Part  Segmentation",
    "abstract": "Panoptic Part Segmentation (PPS) aims to unify panoptic segmentation and part\nsegmentation into one task. Previous work mainly utilizes separated approaches\nto handle thing, stuff, and part predictions individually without performing\nany shared computation and task association. In this work, we aim to unify\nthese tasks at the architectural level, designing the first end-to-end unified\nmethod named Panoptic-PartFormer. In particular, motivated by the recent\nprogress in Vision Transformer, we model things, stuff, and part as object\nqueries and directly learn to optimize the all three predictions as unified\nmask prediction and classification problem. We design a decoupled decoder to\ngenerate part feature and thing/stuff feature respectively. Then we propose to\nutilize all the queries and corresponding features to perform reasoning jointly\nand iteratively. The final mask can be obtained via inner product between\nqueries and the corresponding features. The extensive ablation studies and\nanalysis prove the effectiveness of our framework. Our Panoptic-PartFormer\nachieves the new state-of-the-art results on both Cityscapes PPS and Pascal\nContext PPS datasets with at least 70% GFlops and 50% parameters decrease. In\nparticular, we get 3.4% relative improvements with ResNet50 backbone and 10%\nimprovements after adopting Swin Transformer on Pascal Context PPS dataset. To\nthe best of our knowledge, we are the first to solve the PPS problem via\n\\textit{a unified and end-to-end transformer model. Given its effectiveness and\nconceptual simplicity, we hope our Panoptic-PartFormer can serve as a good\nbaseline and aid future unified research for PPS. Our code and models will be\navailable at https://github.com/lxtGH/Panoptic-PartFormer.",
    "descriptor": "\nComments: technical report\n",
    "authors": [
      "Xiangtai Li",
      "Shilin Xu",
      "Yibo Yang.Guangliang Cheng",
      "Yunhai Tong",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.04655"
  },
  {
    "id": "arXiv:2204.04656",
    "title": "Video K-Net: A Simple, Strong, and Unified Baseline for Video  Segmentation",
    "abstract": "This paper presents Video K-Net, a simple, strong, and unified framework for\nfully end-to-end video panoptic segmentation. The method is built upon K-Net, a\nmethod that unifies image segmentation via a group of learnable kernels. We\nobserve that these learnable kernels from K-Net, which encode object\nappearances and contexts, can naturally associate identical instances across\nvideo frames. Motivated by this observation, Video K-Net learns to\nsimultaneously segment and track \"things\" and \"stuff\" in a video with simple\nkernel-based appearance modeling and cross-temporal kernel interaction. Despite\nthe simplicity, it achieves state-of-the-art video panoptic segmentation\nresults on Citscapes-VPS and KITTI-STEP without bells and whistles. In\nparticular on KITTI-STEP, the simple method can boost almost 12\\% relative\nimprovements over previous methods. We also validate its generalization on\nvideo semantic segmentation, where we boost various baselines by 2\\% on the\nVSPW dataset. Moreover, we extend K-Net into clip-level video framework for\nvideo instance segmentation where we obtain 40.5\\% for ResNet50 backbone and\n51.5\\% mAP for Swin-base on YouTube-2019 validation set. We hope this simple\nyet effective method can serve as a new flexible baseline in video\nsegmentation. Both code and models are released at\nhttps://github.com/lxtGH/Video-K-Net",
    "descriptor": "\nComments: accepted by CVPR-2022(oral)\n",
    "authors": [
      "Xiangtai Li",
      "Wenwei Zhang",
      "Jiangmiao Pang",
      "Kai Chen",
      "Guangliang Cheng",
      "Yunhai Tong",
      "Chen Change Loy"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.04656"
  },
  {
    "id": "arXiv:2204.04659",
    "title": "Amalgamation of Indirect Gamification into Development and Operations  (DEVOPS) Course Teaching",
    "abstract": "In DevOps Course, the Installation and configuration of the various software\ntools are useful in the context of application development. To teach DevOps\nTools precisely to achieve the learning outcome is a skilled task for a\ntrainer. From the perspective of the learner, the learning environment has to\nbe encouraging and exciting. The author used the third-party Competition as an\nindirect Gamification technique to achieve the learning outcomes of the Course.\nThe author encouraged the students to participate in the Hacktoberfest\nCompetition to use the practical skills learned in the Course. The Under\nGraduate and Post Graduate Students have gone through the regular sessions of\nDevOps. For the participation purpose, both groups of students communicated on\none platform. The students who succeeded faster during the GitHub Pull Request\nsubmission shared their experiences with other participants. The PG students\nparticipated 68.75% higher than UG students. The active participation of the\nsmall number of UG students became a motivational factor for the PG students.\nThe Gaussian distribution on the marks obtained by the experimental group shows\nthe absence of outliers. The research shows that the effectiveness of indirect\nGamification depends on the age group, level, course content, and learning\nenvironment. The participation of a faculty member in the Competition during\nthe learning activity boosts the desire of the Student to complete the task.\nThe experimental group of 15 Students has outperformed in terms of the marks\nobtained compared to the control group of 52 students.",
    "descriptor": "\nComments: 15 pages, 14 Figures, Abstract is also available in Ukrainian Language at the Last Page\n",
    "authors": [
      "Manoj Devare"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2204.04659"
  },
  {
    "id": "arXiv:2204.04661",
    "title": "Expressiveness and Approximation Properties of Graph Neural Networks",
    "abstract": "Characterizing the separation power of graph neural networks (GNNs) provides\nan understanding of their limitations for graph learning tasks. Results\nregarding separation power are, however, usually geared at specific GNN\narchitectures, and tools for understanding arbitrary GNN architectures are\ngenerally lacking. We provide an elegant way to easily obtain bounds on the\nseparation power of GNNs in terms of the Weisfeiler-Leman (WL) tests, which\nhave become the yardstick to measure the separation power of GNNs. The crux is\nto view GNNs as expressions in a procedural tensor language describing the\ncomputations in the layers of the GNNs. Then, by a simple analysis of the\nobtained expressions, in terms of the number of indexes and the nesting depth\nof summations, bounds on the separation power in terms of the WL-tests readily\nfollow. We use tensor language to define Higher-Order Message-Passing Neural\nNetworks (or k-MPNNs), a natural extension of MPNNs. Furthermore, the tensor\nlanguage point of view allows for the derivation of universality results for\nclasses of GNNs in a natural way. Our approach provides a toolbox with which\nGNN architecture designers can analyze the separation power of their GNNs,\nwithout needing to know the intricacies of the WL-tests. We also provide\ninsights in what is needed to boost the separation power of GNNs.",
    "descriptor": "\nComments: 43 pages, accepted as oral presentation at ICLR 2022: this https URL\n",
    "authors": [
      "Floris Geerts",
      "Juan L. Reutter"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.04661"
  },
  {
    "id": "arXiv:2204.04662",
    "title": "FOSTER: Feature Boosting and Compression for Class-Incremental Learning",
    "abstract": "The ability to learn new concepts continually is necessary in this\never-changing world. However, deep neural networks suffer from catastrophic\nforgetting when learning new categories. Many works have been proposed to\nalleviate this phenomenon, whereas most of them either fall into the\nstability-plasticity dilemma or take too much computation or storage overhead.\nInspired by the gradient boosting algorithm to gradually fit the residuals\nbetween the target and the current approximation function, we propose a novel\ntwo-stage learning paradigm FOSTER, empowering the model to learn new\ncategories adaptively. Specifically, we first dynamically expand new modules to\nfit the residuals of the target and the original model. Next, we remove\nredundant parameters and feature dimensions through an effective distillation\nstrategy to maintain the single backbone model. We validate our method FOSTER\non CIFAR-100, ImageNet-100/1000 under different settings. Experimental results\nshow that our method achieves state-of-the-art performance.",
    "descriptor": "",
    "authors": [
      "Fu-Yun Wang",
      "Da-Wei Zhou",
      "Han-Jia Ye",
      "De-Chuan Zhan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.04662"
  },
  {
    "id": "arXiv:2204.04664",
    "title": "Optimization of IoT-Enabled Physical Location Monitoring Using DT and  VAR",
    "abstract": "This study shows an enhancement of IoT that gets sensor data and performs\nreal-time face recognition to screen physical areas to find strange situations\nand send an alarm mail to the client to make remedial moves to avoid any\npotential misfortune in the environment. Sensor data is pushed onto the local\nsystem and GoDaddy Cloud whenever the camera detects a person to optimize the\nphysical location monitoring system by reducing the bandwidth requirement and\nstorage cost onto the cloud using edge computation. The study reveals that\ndecision tree (DT) and random forest give reasonably similar macro average\nf1-scores to predict a person using sensor data. Experimental results show that\nDT is the most reliable predictive model for the cloud datasets of three\ndifferent physical locations to predict a person using timestamp with an\naccuracy of 83.99%, 88.92%, and 80.97%. This study also explains multivariate\ntime series prediction using vector auto regression that gives reasonably good\nroot mean squared error to predict temperature, humidity, light-dependent\nresistor, and gas time series.",
    "descriptor": "\nComments: 28 pages, 14 figures, Use of Machine Learning to process IoT Sensor Data\n",
    "authors": [
      "Ajitkumar Sureshrao Shitole",
      "Manoj Himmatrao Devare"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.04664"
  },
  {
    "id": "arXiv:2204.04665",
    "title": "Effective Out-of-Distribution Detection in Classifier Based on  PEDCC-Loss",
    "abstract": "Deep neural networks suffer from the overconfidence issue in the open world,\nmeaning that classifiers could yield confident, incorrect predictions for\nout-of-distribution (OOD) samples. Thus, it is an urgent and challenging task\nto detect these samples drawn far away from training distribution based on the\nsecurity considerations of artificial intelligence. Many current methods based\non neural networks mainly rely on complex processing strategies, such as\ntemperature scaling and input preprocessing, to obtain satisfactory results. In\nthis paper, we propose an effective algorithm for detecting out-of-distribution\nexamples utilizing PEDCC-Loss. We mathematically analyze the nature of the\nconfidence score output by the PEDCC (Predefined Evenly-Distribution Class\nCentroids) classifier, and then construct a more effective scoring function to\ndistinguish in-distribution (ID) and out-of-distribution. In this method, there\nis no need to preprocess the input samples and the computational burden of the\nalgorithm is reduced. Experiments demonstrate that our method can achieve\nbetter OOD detection performance.",
    "descriptor": "",
    "authors": [
      "Qiuyu Zhu",
      "Guohui Zheng",
      "Yingying Yan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.04665"
  },
  {
    "id": "arXiv:2204.04666",
    "title": "Near-Optimal Trajectory Design and Restoration Areas Allocation for  UAV-Enabled Grassland Restoration",
    "abstract": "Grassland restoration is a critical means to safeguard grassland ecological\ndegradation. This work considers the maximization restoration areas problem for\nUAV-enabled grassland restoration method in a restoration process, which is a\nprecise restoration scheme. We first formulate the problem as a multivariable\ncombinatorial optimization problem. By analyzing the characteristics of the\noptimization problem, it can be decomposed into the two stages: UAV trajectory\ndesign and restoration areas allocation. On this basis, the problem can be\nregarded as a composite problem of traveling salesman problem (TSP) and\nmultidimensional knapsack problem (MKP). Unlike the single combinatorial\noptimization problem, the coupling relationship between them makes the problem\ndifficult to directly solve by employing the single stage traditional methods.\nTo effectively solve without ignoring the dependence between the two stages, we\ndevelop a cooperative optimization algorithm based on heuristic algorithm and\npopulation-based incremental learning (PBIL) incorporated with a\nmaximum-residual-energy-based local search (MRELS) strategy, called CHAPBILM,\nto deal with this problem under constraint conditions of the UAV energy, the\ntotal seeds weight, and the number of restored areas. The simulation studies\ndemonstrate that the proposed cooperative optimization method is effective for\nUAV-enabled grassland restoration problem and can significantly outperform the\nnoncooperative optimization methods, which also verifies the dependency\nrelationship between UAV trajectory design and restoration areas allocation.",
    "descriptor": "",
    "authors": [
      "Dongbin Jiaoa",
      "Lingyu Wanga",
      "Peng Yang",
      "Weibo Yang",
      "Yu Peng",
      "Zhanhuan Shang",
      "Ke Tang",
      "Fengyuan Ren"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2204.04666"
  },
  {
    "id": "arXiv:2204.04667",
    "title": "Linear Complexity Randomized Self-attention Mechanism",
    "abstract": "Recently, random feature attentions (RFAs) are proposed to approximate the\nsoftmax attention in linear time and space complexity by linearizing the\nexponential kernel. In this paper, we first propose a novel perspective to\nunderstand the bias in such approximation by recasting RFAs as self-normalized\nimportance samplers. This perspective further sheds light on an \\emph{unbiased}\nestimator for the whole softmax attention, called randomized attention (RA). RA\nconstructs positive random features via query-specific distributions and enjoys\ngreatly improved approximation fidelity, albeit exhibiting quadratic\ncomplexity. By combining the expressiveness in RA and the efficiency in RFA, we\ndevelop a novel linear complexity self-attention mechanism called linear\nrandomized attention (LARA). Extensive experiments across various domains\ndemonstrate that RA and LARA significantly improve the performance of RFAs by a\nsubstantial margin.",
    "descriptor": "\nComments: 37 pages\n",
    "authors": [
      "Lin Zheng",
      "Chong Wang",
      "Lingpeng Kong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.04667"
  },
  {
    "id": "arXiv:2204.04668",
    "title": "NAN: Noise-Aware NeRFs for Burst-Denoising",
    "abstract": "Burst denoising is now more relevant than ever, as computational photography\nhelps overcome sensitivity issues inherent in mobile phones and small cameras.\nA major challenge in burst-denoising is in coping with pixel misalignment,\nwhich was so far handled with rather simplistic assumptions of simple motion,\nor the ability to align in pre-processing. Such assumptions are not realistic\nin the presence of large motion and high levels of noise. We show that Neural\nRadiance Fields (NeRFs), originally suggested for physics-based novel-view\nrendering, can serve as a powerful framework for burst denoising. NeRFs have an\ninherent capability of handling noise as they integrate information from\nmultiple images, but they are limited in doing so, mainly since they build on\npixel-wise operations which are suitable to ideal imaging conditions. Our\napproach, termed NAN, leverages inter-view and spatial information in NeRFs to\nbetter deal with noise. It achieves state-of-the-art results in burst denoising\nand is especially successful in coping with large movement and occlusions,\nunder very high levels of noise. With the rapid advances in accelerating NeRFs,\nit could provide a powerful platform for denoising in challenging environments.",
    "descriptor": "\nComments: to appear at CVPR 2022\n",
    "authors": [
      "Naama Pearl",
      "Tali Treibitz",
      "Simon Korman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.04668"
  },
  {
    "id": "arXiv:2204.04670",
    "title": "Active Learning with Label Comparisons",
    "abstract": "Supervised learning typically relies on manual annotation of the true labels.\nWhen there are many potential classes, searching for the best one can be\nprohibitive for a human annotator. On the other hand, comparing two candidate\nlabels is often much easier. We focus on this type of pairwise supervision and\nask how it can be used effectively in learning, and in particular in active\nlearning. We obtain several insightful results in this context. In principle,\nfinding the best of $k$ labels can be done with $k-1$ active queries. We show\nthat there is a natural class where this approach is sub-optimal, and that\nthere is a more comparison-efficient active learning scheme. A key element in\nour analysis is the \"label neighborhood graph\" of the true distribution, which\nhas an edge between two classes if they share a decision boundary. We also show\nthat in the PAC setting, pairwise comparisons cannot provide improved sample\ncomplexity in the worst case. We complement our theoretical results with\nexperiments, clearly demonstrating the effect of the neighborhood graph on\nsample complexity.",
    "descriptor": "",
    "authors": [
      "Gal Yona",
      "Shay Moran",
      "Gal Elidan",
      "Amir Globerson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.04670"
  },
  {
    "id": "arXiv:2204.04673",
    "title": "Optimal long-time decay rate of solutions of complete  monotonicity-preserving schemes for nonlinear time-fractional evolutionary  equations",
    "abstract": "The solution of the nonlinear initial-value problem\n$\\mathcal{D}_{t}^{\\alpha}y(t)=-\\lambda y(t)^{\\gamma}$ for $t>0$ with $y(0)>0$,\nwhere $\\mathcal{D}_{t}^{\\alpha}$ is a Caputo derivative of order $\\alpha\\in\n(0,1)$ and $\\lambda, \\gamma$ are positive parameters, is known to exhibit\n$O(t^{\\alpha/\\gamma})$ decay as $t\\to\\infty$. No corresponding result for any\ndiscretisation of this problem has previously been proved. In the present paper\nit is shown that for the class of complete monotonicity-preserving\n($\\mathcal{CM}$-preserving) schemes (which includes the L1 and\nGr\\\"unwald-Letnikov schemes) on uniform meshes $\\{t_n:=nh\\}_{n=0}^\\infty$, the\ndiscrete solution also has $O(t_{n}^{-\\alpha/\\gamma})$ decay as\n$t_{n}\\to\\infty$. This result is then extended to $\\mathcal{CM}$-preserving\ndiscretisations of certain time-fractional nonlinear subdiffusion problems such\nas the time-fractional porous media and $p$-Laplace equations. For the L1\nscheme, the $O(t_{n}^{-\\alpha/\\gamma})$ decay result is shown to remain valid\non a very general class of nonuniform meshes. Our analysis uses a discrete\ncomparison principle with discrete subsolutions and supersolutions that are\ncarefully constructed to give tight bounds on the discrete solution. Numerical\nexperiments are provided to confirm our theoretical analysis.",
    "descriptor": "",
    "authors": [
      "Dongling Wang",
      "Martin Stynes"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2204.04673"
  },
  {
    "id": "arXiv:2204.04674",
    "title": "Is my Driver Observation Model Overconfident? Input-guided Calibration  Networks for Reliable and Interpretable Confidence Estimates",
    "abstract": "Driver observation models are rarely deployed under perfect conditions. In\npractice, illumination, camera placement and type differ from the ones present\nduring training and unforeseen behaviours may occur at any time. While\nobserving the human behind the steering wheel leads to more intuitive\nhuman-vehicle-interaction and safer driving, it requires recognition algorithms\nwhich do not only predict the correct driver state, but also determine their\nprediction quality through realistic and interpretable confidence measures.\nReliable uncertainty estimates are crucial for building trust and are a serious\nobstacle for deploying activity recognition networks in real driving systems.\nIn this work, we for the first time examine how well the confidence values of\nmodern driver observation models indeed match the probability of the correct\noutcome and show that raw neural network-based approaches tend to significantly\noverestimate their prediction quality. To correct this misalignment between the\nconfidence values and the actual uncertainty, we consider two strategies.\nFirst, we enhance two activity recognition models often used for driver\nobservation with temperature scaling-an off-the-shelf method for confidence\ncalibration in image classification. Then, we introduce Calibrated Action\nRecognition with Input Guidance (CARING)-a novel approach leveraging an\nadditional neural network to learn scaling the confidences depending on the\nvideo representation. Extensive experiments on the Drive&Act dataset\ndemonstrate that both strategies drastically improve the quality of model\nconfidences, while our CARING model out-performs both, the original\narchitectures and their temperature scaling enhancement, leading to best\nuncertainty estimates.",
    "descriptor": "",
    "authors": [
      "Alina Roitberg",
      "Kunyu Peng",
      "David Schneider",
      "Kailun Yang",
      "Marios Koulakis",
      "Manuel Martinez",
      "Rainer Stiefelhagen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.04674"
  },
  {
    "id": "arXiv:2204.04676",
    "title": "Simple Baselines for Image Restoration",
    "abstract": "Although there have been significant advances in the field of image\nrestoration recently, the system complexity of the state-of-the-art (SOTA)\nmethods is increasing as well, which may hinder the convenient analysis and\ncomparison of methods. In this paper, we propose a simple baseline that exceeds\nthe SOTA methods and is computationally efficient. To further simplify the\nbaseline, we reveal that the nonlinear activation functions, e.g. Sigmoid,\nReLU, GELU, Softmax, etc. are not necessary: they could be replaced by\nmultiplication or removed. Thus, we derive a Nonlinear Activation Free Network,\nnamely NAFNet, from the baseline. SOTA results are achieved on various\nchallenging benchmarks, e.g. 33.69 dB PSNR on GoPro (for image deblurring),\nexceeding the previous SOTA 0.38 dB with only 8.4% of its computational costs;\n40.30 dB PSNR on SIDD (for image denoising), exceeding the previous SOTA 0.28\ndB with less than half of its computational costs. The code and the pretrained\nmodels will be released at https://github.com/megvii-research/NAFNet.",
    "descriptor": "\nComments: Image Restoration\n",
    "authors": [
      "Liangyu Chen",
      "Xiaojie Chu",
      "Xiangyu Zhang",
      "Jian Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.04676"
  },
  {
    "id": "arXiv:2204.04677",
    "title": "FedCorr: Multi-Stage Federated Learning for Label Noise Correction",
    "abstract": "Federated learning (FL) is a privacy-preserving distributed learning paradigm\nthat enables clients to jointly train a global model. In real-world FL\nimplementations, client data could have label noise, and different clients\ncould have vastly different label noise levels. Although there exist methods in\ncentralized learning for tackling label noise, such methods do not perform well\non heterogeneous label noise in FL settings, due to the typically smaller sizes\nof client datasets and data privacy requirements in FL. In this paper, we\npropose $\\texttt{FedCorr}$, a general multi-stage framework to tackle\nheterogeneous label noise in FL, without making any assumptions on the noise\nmodels of local clients, while still maintaining client data privacy. In\nparticular, (1) $\\texttt{FedCorr}$ dynamically identifies noisy clients by\nexploiting the dimensionalities of the model prediction subspaces independently\nmeasured on all clients, and then identifies incorrect labels on noisy clients\nbased on per-sample losses. To deal with data heterogeneity and to increase\ntraining stability, we propose an adaptive local proximal regularization term\nthat is based on estimated local noise levels. (2) We further finetune the\nglobal model on identified clean clients and correct the noisy labels for the\nremaining noisy clients after finetuning. (3) Finally, we apply the usual\ntraining on all clients to make full use of all local data. Experiments\nconducted on CIFAR-10/100 with federated synthetic label noise, and on a\nreal-world noisy dataset, Clothing1M, demonstrate that $\\texttt{FedCorr}$ is\nrobust to label noise and substantially outperforms the state-of-the-art\nmethods at multiple noise levels.",
    "descriptor": "\nComments: Accepted at IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) 2022. 18 pages, 10 figures (including supplementary material). First two authors contributed equally. Code is available at: this https URL\n",
    "authors": [
      "Jingyi Xu",
      "Zihan Chen",
      "Tony Q.S. Quek",
      "Kai Fong Ernest Chong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.04677"
  },
  {
    "id": "arXiv:2204.04679",
    "title": "Scale Invariant Semantic Segmentation with RGB-D Fusion",
    "abstract": "In this paper, we propose a neural network architecture for scale-invariant\nsemantic segmentation using RGB-D images. We utilize depth information as an\nadditional modality apart from color images only. Especially in an outdoor\nscene which consists of different scale objects due to the distance of the\nobjects from the camera. The near distance objects consist of significantly\nmore pixels than the far ones. We propose to incorporate depth information to\nthe RGB data for pixel-wise semantic segmentation to address the different\nscale objects in an outdoor scene. We adapt to a well-known\nDeepLab-v2(ResNet-101) model as our RGB baseline. Depth images are passed\nseparately as an additional input with a distinct branch. The intermediate\nfeature maps of both color and depth image branch are fused using a novel\nfusion block. Our model is compact and can be easily applied to the other RGB\nmodel. We perform extensive qualitative and quantitative evaluation on a\nchallenging dataset Cityscapes. The results obtained are comparable to the\nstate-of-the-art. Additionally, we evaluated our model on a self-recorded real\ndataset. For the shake of extended evaluation of a driving scene with ground\ntruth we generated a synthetic dataset using popular vehicle simulation project\nCARLA. The results obtained from the real and synthetic dataset shows the\neffectiveness of our approach.",
    "descriptor": "\nComments: 8 pages\n",
    "authors": [
      "Mohammad Dawud Ansari",
      "Alwi Husada",
      "Didier Stricker"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.04679"
  },
  {
    "id": "arXiv:2204.04680",
    "title": "Reasoning with Multi-Structure Commonsense Knowledge in Visual Dialog",
    "abstract": "Visual Dialog requires an agent to engage in a conversation with humans\ngrounded in an image. Many studies on Visual Dialog focus on the understanding\nof the dialog history or the content of an image, while a considerable amount\nof commonsense-required questions are ignored. Handling these scenarios depends\non logical reasoning that requires commonsense priors. How to capture relevant\ncommonsense knowledge complementary to the history and the image remains a key\nchallenge. In this paper, we propose a novel model by Reasoning with\nMulti-structure Commonsense Knowledge (RMK). In our model, the external\nknowledge is represented with sentence-level facts and graph-level facts, to\nproperly suit the scenario of the composite of dialog history and image. On top\nof these multi-structure representations, our model can capture relevant\nknowledge and incorporate them into the vision and semantic features, via\ngraph-based interaction and transformer-based fusion. Experimental results and\nanalysis on VisDial v1.0 and VisDialCK datasets show that our proposed model\neffectively outperforms comparative methods.",
    "descriptor": "\nComments: MULA Workshop, CVPR 2022\n",
    "authors": [
      "Shunyu Zhang",
      "Xiaoze Jiang",
      "Zequn Yang",
      "Tao Wan",
      "Zengchang Qin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2204.04680"
  },
  {
    "id": "arXiv:2204.04681",
    "title": "Enhancing the Robustness, Efficiency, and Diversity of Differentiable  Architecture Search",
    "abstract": "Differentiable architecture search (DARTS) has attracted much attention due\nto its simplicity and significant improvement in efficiency. However, the\nexcessive accumulation of the skip connection makes it suffer from long-term\nweak stability and low robustness. Many works attempt to restrict the\naccumulation of skip connections by indicators or manual design, however, these\nmethods are susceptible to thresholds and human priors. In this work, we\nsuggest a more subtle and direct approach that removes skip connections from\nthe operation space. Then, by introducing an adaptive channel allocation\nstrategy, we redesign the DARTS framework to automatically refill the skip\nconnections in the evaluation stage, resolving the performance degradation\ncaused by the absence of skip connections. Our method, dubbed\nAdaptive-Channel-Allocation-DARTS (ACA-DRATS), could eliminate the\ninconsistency in operation strength and significantly expand the architecture\ndiversity. We continue to explore smaller search space under our framework, and\noffer a direct search on the entire ImageNet dataset. Experiments show that\nACA-DRATS improves the search stability and significantly speeds up DARTS by\nmore than ten times while yielding higher accuracy.",
    "descriptor": "",
    "authors": [
      "Chao Li",
      "Jia Ning",
      "Han Hu",
      "Kun He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.04681"
  },
  {
    "id": "arXiv:2204.04685",
    "title": "EPTAS for the dual of splittable bin packing with cardinality constraint",
    "abstract": "The problem considered is the splittable bin packing with cardinality\nconstraint. It is a variant of the bin packing problem where items are allowed\nto be split into parts but the number of parts in each bin is at most a given\nupper bound. Two versions of the splittable bin packing with cardinality\nconstraint have been studied in the literature. Among these variants we\nconsider the dual one where the objective is to minimize the maximum bin size\nwhile packing (may be fractional) the items to a given set of bins. We exhibit\nan EPTAS for the dual problem when the cardinality upper bound is part of the\ninput. This result answers an open question raised by Epstein, Levin, and van\nStee.",
    "descriptor": "",
    "authors": [
      "G. Jaykrishnan",
      "Asaf Levin"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2204.04685"
  },
  {
    "id": "arXiv:2204.04686",
    "title": "DISK: Domain-constrained Instance Sketch for Math Word Problem  Generation",
    "abstract": "A math word problem (MWP) is a coherent narrative which reflects the\nunderlying logic of math equations. Successful MWP generation can automate the\nwriting of mathematics questions. Previous methods mainly generate MWP text\nbased on inflexible pre-defined templates. In this paper, we propose a neural\nmodel for generating MWP text from math equations. Firstly, we incorporate a\nmatching model conditioned on the domain knowledge to retrieve a MWP instance\nwhich is most consistent with the ground-truth, where the domain is a latent\nvariable extracted with a domain summarizer. Secondly, by constructing a\nQuantity Cell Graph (QCG) from the retrieved MWP instance and reasoning over\nit, we improve the model's comprehension of real-world scenarios and derive a\ndomain-constrained instance sketch to guide the generation. Besides, the QCG\nalso interacts with the equation encoder to enhance the alignment between math\ntokens (e.g., quantities and variables) and MWP text. Experiments and empirical\nanalysis on educational MWP set show that our model achieves impressive\nperformance in both automatic evaluation metrics and human evaluation metrics.",
    "descriptor": "",
    "authors": [
      "Tianyang Cao",
      "Shuang Zeng",
      "Xiaodan Xu",
      "Mairgup Mansur",
      "Baobao Chang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.04686"
  },
  {
    "id": "arXiv:2204.04687",
    "title": "MA-Dreamer: Coordination and communication through shared imagination",
    "abstract": "Multi-agent RL is rendered difficult due to the non-stationary nature of\nenvironment perceived by individual agents. Theoretically sound methods using\nthe REINFORCE estimator are impeded by its high-variance, whereas\nvalue-function based methods are affected by issues stemming from their ad-hoc\nhandling of situations like inter-agent communication. Methods like MADDPG are\nfurther constrained due to their requirement of centralized critics etc. In\norder to address these issues, we present MA-Dreamer, a model-based method that\nuses both agent-centric and global differentiable models of the environment in\norder to train decentralized agents' policies and critics using model-rollouts\na.k.a `imagination'. Since only the model-training is done off-policy,\ninter-agent communication/coordination and `language emergence' can be handled\nin a straight-forward manner. We compare the performance of MA-Dreamer with\nother methods on two soccer-based games. Our experiments show that in long-term\nspeaker-listener tasks and in cooperative games with strong\npartial-observability, MA-Dreamer finds a solution that makes effective use of\ncoordination, whereas competing methods obtain marginal scores and fail\noutright, respectively. By effectively achieving coordination and communication\nunder more relaxed and general conditions, out method opens the door to the\nstudy of more complex problems and population-based training.",
    "descriptor": "",
    "authors": [
      "Kenzo Lobos-Tsunekawa",
      "Akshay Srinivasan",
      "Michael Spranger"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2204.04687"
  },
  {
    "id": "arXiv:2204.04694",
    "title": "ClioQuery: Interactive Query-Oriented Text Analytics for Comprehensive  Investigation of Historical News Archives",
    "abstract": "Historians and archivists often find and analyze the occurrences of query\nwords in newspaper archives, to help answer fundamental questions about\nsociety. But much work in text analytics focuses on helping people investigate\nother textual units, such as events, clusters, ranked documents, entity\nrelationships, or thematic hierarchies. Informed by a study into the needs of\nhistorians and archivists, we thus propose ClioQuery, a text analytics system\nuniquely organized around the analysis of query words in context. ClioQuery\napplies text simplification techniques from natural language processing to help\nhistorians quickly and comprehensively gather and analyze all occurrences of a\nquery word across an archive. It also pairs these new NLP methods with more\ntraditional features like linked views and in-text highlighting to help\nengender trust in summarization techniques. We evaluate ClioQuery with two\nseparate user studies, in which historians explain how ClioQuery's novel text\nsimplification features can help facilitate historical research. We also\nevaluate with a separate quantitative comparison study, which shows that\nClioQuery helps crowdworkers find and remember historical information. Such\nresults suggest possible new directions for text analytics in other\nquery-oriented settings.",
    "descriptor": "\nComments: Forthcoming in ACM Transactions on Interactive Intelligent Systems (TiiS)\n",
    "authors": [
      "Abram Handler",
      "Narges Mahyar",
      "Brendan O'Connor"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2204.04694"
  },
  {
    "id": "arXiv:2204.04698",
    "title": "Verification of Strong K-Step Opacity for Discrete-Event Systems",
    "abstract": "In this paper, we revisit the verification of strong K-step opacity (K-SSO)\nfor partially-observed discrete-event systems modeled as nondeterministic\nfinite-state automata. As a stronger version of the standard K-step opacity,\nK-SSO requires that an intruder cannot make sure whether or not a secret state\nhas been visited within the last K observable steps. To efficiently verify\nK-SSO, we propose a new concurrent-composition structure, which is a variant of\nour previously- proposed one. Based on this new structure, we design an\nalgorithm for deciding K-SSO and prove that the proposed algorithm not only\nreduces the time complexity of the existing algorithms, but also does not\ndepend on the value of K. Furthermore, a new upper bound on the value of K in\nK-SSO is derived, which also reduces the existing upper bound on K in the\nliterature. Finally, we illustrate the proposed algorithm by a simple example.",
    "descriptor": "\nComments: 6 pages, 2 figures, submitted to IEEE CDC on March 28, 2022\n",
    "authors": [
      "Xiaoguang Han",
      "Kuize Zhang",
      "Zhiwu Li"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2204.04698"
  },
  {
    "id": "arXiv:2204.04704",
    "title": "An Efficient Pattern Mining Convolution Neural Network (CNN) algorithm  with Grey Wolf Optimization (GWO)",
    "abstract": "Automation of feature analysis in the dynamic image frame dataset deals with\ncomplexity of intensity mapping with normal and abnormal class. The\nthreshold-based data clustering and feature analysis requires iterative model\nto learn the component of image frame in multi-pattern for different image\nframe data type. This paper proposed a novel model of feature analysis method\nwith the CNN based on Convoluted Pattern of Wavelet Transform (CPWT) feature\nvectors that are optimized by Grey Wolf Optimization (GWO) algorithm.\nInitially, the image frame gets normalized by applying median filter to the\nimage frame that reduce the noise and apply smoothening on it. From that, the\nedge information represents the boundary region of bright spot in the image\nframe. Neural network-based image frame classification performs repeated\nlearning of the feature with minimum training of dataset to cluster the image\nframe pixels. Features of the filtered image frame was analyzed in different\npattern of feature extraction model based on the convoluted model of wavelet\ntransformation method. These features represent the different class of image\nframe in spatial and textural pattern of it. Convolutional Neural Network (CNN)\nclassifier supports to analyze the features and classify the action label for\nthe image frame dataset. This process enhances the classification with minimum\nnumber of training dataset. The performance of this proposed method can be\nvalidated by comparing with traditional state-of-art methods.",
    "descriptor": "",
    "authors": [
      "Aatif Jamshed",
      "Bhawna Mallick",
      "Rajendra Kumar Bharti"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.04704"
  },
  {
    "id": "arXiv:2204.04705",
    "title": "SplitNets: Designing Neural Architectures for Efficient Distributed  Computing on Head-Mounted Systems",
    "abstract": "We design deep neural networks (DNNs) and corresponding networks' splittings\nto distribute DNNs' workload to camera sensors and a centralized aggregator on\nhead mounted devices to meet system performance targets in inference accuracy\nand latency under the given hardware resource constraints. To achieve an\noptimal balance among computation, communication, and performance, a\nsplit-aware neural architecture search framework, SplitNets, is introduced to\nconduct model designing, splitting, and communication reduction simultaneously.\nWe further extend the framework to multi-view systems for learning to fuse\ninputs from multiple camera sensors with optimal performance and systemic\nefficiency. We validate SplitNets for single-view system on ImageNet as well as\nmulti-view system on 3D classification, and show that the SplitNets framework\nachieves state-of-the-art (SOTA) performance and system latency compared with\nexisting approaches.",
    "descriptor": "\nComments: IEEE/CVF Conference on Computer Vision and Pattern Recognition 2022\n",
    "authors": [
      "Xin Dong",
      "Barbara De Salvo",
      "Meng Li",
      "Chiao Liu",
      "Zhongnan Qu",
      "H.T. Kung",
      "Ziyun Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2204.04705"
  },
  {
    "id": "arXiv:2204.04707",
    "title": "Generative Adversarial Networks for Image Augmentation in Agriculture: A  Systematic Review",
    "abstract": "In agricultural image analysis, optimal model performance is keenly pursued\nfor better fulfilling visual recognition tasks (e.g., image classification,\nsegmentation, object detection and localization), in the presence of challenges\nwith biological variability and unstructured environments. Large-scale,\nbalanced and ground-truthed image datasets, however, are often difficult to\nobtain to fuel the development of advanced, high-performance models. As\nartificial intelligence through deep learning is impacting analysis and\nmodeling of agricultural images, data augmentation plays a crucial role in\nboosting model performance while reducing manual efforts for data preparation,\nby algorithmically expanding training datasets. Beyond traditional data\naugmentation techniques, generative adversarial network (GAN) invented in 2014\nin the computer vision community, provides a suite of novel approaches that can\nlearn good data representations and generate highly realistic samples. Since\n2017, there has been a growth of research into GANs for image augmentation or\nsynthesis in agriculture for improved model performance. This paper presents an\noverview of the evolution of GAN architectures followed by a systematic review\nof their application to agriculture\n(https://github.com/Derekabc/GANs-Agriculture), involving various vision tasks\nfor plant health, weeds, fruits, aquaculture, animal farming, plant phenotyping\nas well as postharvest detection of fruit defects. Challenges and opportunities\nof GANs are discussed for future research.",
    "descriptor": "\nComments: 32 pages, 15 figures\n",
    "authors": [
      "Ebenezer Olaniyi",
      "Dong Chen",
      "Yuzhen Lu",
      "Yanbo Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2204.04707"
  },
  {
    "id": "arXiv:2204.04708",
    "title": "Cache-Aided Massive MIMO with Linear Precoding in Multi-cell Systems",
    "abstract": "In this paper, we propose a novel joint caching and massive multiple-input\nmultiple-output (MIMO) transmission scheme, referred to as \\emph{cache-aided\nmassive MIMO}, for multi-cell downlink transmission to multiple cache-enabled\nreceivers. With the proposed scheme, users who have cached (a portion of) the\nfiles that they request are offloaded and, hence, (partially) inactive during\ndownlink transmission. The other users either benefit from the cache-enabled\noffloading for mitigating pilot contamination or exploit the cached but\nunrequested files to cancel interference during uplink channel estimation and\ndownlink file reception. Moreover, by redesigning the transmit precoders based\non the cache status of the users and channel state information, we gain\nadditional degrees of freedom for massive MIMO transmission. For a given cache\nstatus, we analyze the equivalent content delivery rates (ECDRs), i.e., the\naverage rates of delivering a requested file via both caching and massive MIMO\ntransmission to the requesting user, for cache-aided massive MIMO employing\nre-designed maximum ratio transmission (MRT), zero-forcing (ZF) precoding, and\nregularized zero-forcing (RZF) precoding. Based on the derived results, the\nimpact of (random) uncoded caching and coded caching on the performance of the\nre-designed precoding schemes is investigated. Simulation results validate our\nderivations and show that caching is beneficial for precoded downlink\ntransmission as it enhances the transmit power allocation, mitigates intra- and\ninter-cell interference, and reduces the impairment caused by pilot\ncontamination. Compared with conventional massive MIMO without caching and with\ncache-oblivious precoding, the proposed cache-aided massive MIMO scheme\nachieves a significantly higher ECDR even when the number of users approaches\nthe number of transmit antennas.",
    "descriptor": "\nComments: Extended version of journal submission\n",
    "authors": [
      "Lin Xiang",
      "Xiao Wei",
      "Laura Cottatellucci",
      "Robert Schober",
      "Tao Jiang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2204.04708"
  },
  {
    "id": "arXiv:2204.04711",
    "title": "Data Augmentation for Biomedical Factoid Question Answering",
    "abstract": "We study the effect of seven data augmentation (da) methods in factoid\nquestion answering, focusing on the biomedical domain, where obtaining training\ninstances is particularly difficult. We experiment with data from the BioASQ\nchallenge, which we augment with training instances obtained from an artificial\nbiomedical machine reading comprehension dataset, or via back-translation,\ninformation retrieval, word substitution based on word2vec embeddings, or\nmasked language modeling, question generation, or extending the given passage\nwith additional context. We show that da can lead to very significant\nperformance gains, even when using large pre-trained Transformers, contributing\nto a broader discussion of if/when da benefits large pre-trained models. One of\nthe simplest da methods, word2vec-based word substitution, performed best and\nis recommended. We release our artificial training instances and code.",
    "descriptor": "",
    "authors": [
      "Dimitris Pappas",
      "Prodromos Malakasiotis",
      "Ion Androutsopoulos"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.04711"
  },
  {
    "id": "arXiv:2204.04715",
    "title": "Image Harmonization by Matching Regional References",
    "abstract": "To achieve visual consistency in composite images, recent image harmonization\nmethods typically summarize the appearance pattern of global background and\napply it to the global foreground without location discrepancy. However, for a\nreal image, the appearances (illumination, color temperature, saturation, hue,\ntexture, etc) of different regions can vary significantly. So previous methods,\nwhich transfer the appearance globally, are not optimal. Trying to solve this\nissue, we firstly match the contents between the foreground and background and\nthen adaptively adjust every foreground location according to the appearance of\nits content-related background regions. Further, we design a residual\nreconstruction strategy, that uses the predicted residual to adjust the\nappearance, and the composite foreground to reserve the image details.\nExtensive experiments demonstrate the effectiveness of our method. The source\ncode will be available publicly.",
    "descriptor": "",
    "authors": [
      "Ziyue Zhu",
      "Zhao Zhang",
      "Zheng Lin",
      "Ruiqi Wu",
      "Zhi Chai",
      "Chun-Le Guo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.04715"
  },
  {
    "id": "arXiv:2204.04716",
    "title": "TOV: The Original Vision Model for Optical Remote Sensing Image  Understanding via Self-supervised Learning",
    "abstract": "Do we on the right way for remote sensing image understanding (RSIU) by\ntraining models via supervised data-dependent and task-dependent way, instead\nof human vision in a label-free and task-independent way? We argue that a more\ndesirable RSIU model should be trained with intrinsic structure from data\nrather that extrinsic human labels to realize generalizability across a wide\nrange of RSIU tasks. According to this hypothesis, we proposed \\textbf{T}he\n\\textbf{O}riginal \\textbf{V}ision model (TOV) in remote sensing filed. Trained\nby massive unlabeled optical data along a human-like self-supervised learning\n(SSL) path that is from general knowledge to specialized knowledge, TOV model\ncan be easily adapted to various RSIU tasks, including scene classification,\nobject detection, and semantic segmentation, and outperforms dominant ImageNet\nsupervised pretrained method as well as two recently proposed SSL pretrained\nmethods on majority of 12 publicly available benchmarks. Moreover, we analyze\nthe influences of two key factors on the performance of building TOV model for\nRSIU, including the influence of using different data sampling methods and the\nselection of learning paths during self-supervised optimization. We believe\nthat a general model which is trained by a label-free and task-independent way\nmay be the next paradigm for RSIU and hope the insights distilled from this\nstudy can help to foster the development of an original vision model for RSIU.",
    "descriptor": "\nComments: 38 pages, 5 figures, 8 Tables\n",
    "authors": [
      "Chao Tao",
      "Ji Qia",
      "Guo Zhang",
      "Qing Zhu",
      "Weipeng Lu",
      "Haifeng Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2204.04716"
  },
  {
    "id": "arXiv:2204.04717",
    "title": "Closing the Gap between Weighted and Unweighted Matching in the Sliding  Window Model",
    "abstract": "We consider the Maximum-weight Matching (MWM) problem in the streaming\nsliding window model of computation. In this model, the input consists of a\nsequence of weighted edges on a given vertex set $V$ of size $n$. The objective\nis to maintain an approximation of a maximum-weight matching in the graph\nspanned by the $L$ most recent edges, for some integer $L$, using space\n$\\tilde{O}(n)$.\nCrouch et al. [ESA'13] gave a $(3+\\varepsilon)$-approximation for\n(unweighted) Maximum Matching (MM), and, very recently, Biabani et al.\n[ISAAC'21] gave a $(3.5+\\varepsilon)$-approximation for MWM. In this paper, we\ngive a $(3 + \\varepsilon)$-approximation for MWM, thereby closing the gap\nbetween MWM and MM.\nBiabani et al.'s work makes use of the smooth histogram technique introduced\nby Braverman and Ostrovsky [FOCS'07]. Rather than designing sliding window\nalgorithms directly, this technique reduces the problem to designing so-called\nlookahead algorithms that have certain smoothness properties. Biabani et al.\nshowed that the one-pass MWM streaming algorithm by Paz and Schwartzman\n[SODA'17] constitutes a lookahead algorithm with approximation factor $3.5 +\n\\varepsilon$, which yields their result.\nWe first give a hard instance, showing that Paz and Schwartzman's algorithm\nis indeed no better than a $3.5$-approximation lookahead algorithm, which\nimplies that Biabani et al.'s analysis is tight. To obtain our improvement, we\ngive an alternative and more complex definition of lookahead algorithms that\nstill maintains the connection to the sliding window model. Our new definition,\nhowever, reflects further smoothness properties of Paz and Schwartzman's\nalgorithm, which we exploit in order to improve upon Biabani et al.'s analysis,\nthereby establishing our result.",
    "descriptor": "",
    "authors": [
      "Cezar-Mihail Alexandru",
      "Pavel Dvo\u0159\u00e1k",
      "Christian Konrad",
      "Kheeran K. Naidu"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2204.04717"
  },
  {
    "id": "arXiv:2204.04718",
    "title": "Rethinking Exponential Averaging of the Fisher",
    "abstract": "In optimization for Machine learning (ML), it is typical that\ncurvature-matrix (CM) estimates rely on an exponential average (EA) of local\nestimates (giving EA-CM algorithms). This approach has little principled\njustification, but is very often used in practice. In this paper, we draw a\nconnection between EA-CM algorithms and what we call a \"Wake of Quadratic\nregularized models\". The outlined connection allows us to understand what EA-CM\nalgorithms are doing from an optimization perspective. Generalizing from the\nestablished connection, we propose a new family of algorithms, \"KL-Divergence\nWake-Regularized Models\" (KLD-WRM). We give three different practical\ninstantiations of KLD-WRM, and show numerical results where we outperform\nK-FAC.",
    "descriptor": "\nComments: 17 pages of main body. 16 pages of supplementary material. 2 figures in main body. 4 figures in supplementary material. 1 table in main body\n",
    "authors": [
      "Constantin Octavian Puiu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2204.04718"
  },
  {
    "id": "arXiv:2204.04722",
    "title": "Regret Analysis of Online Gradient Descent-based Iterative Learning  Control with Model Mismatch",
    "abstract": "In Iterative Learning Control (ILC), a sequence of feedforward control\nactions is generated at each iteration on the basis of partial model knowledge\nand past measurements with the goal of steering the system toward a desired\nreference trajectory. This is framed here as an online learning task, where the\ndecision-maker takes sequential decisions by solving a sequence of optimization\nproblems having only partial knowledge of the cost functions. Having\nestablished this connection, the performance of an online gradient-descent\nbased scheme using inexact gradient information is analyzed in the setting of\ndynamic and static regret, standard measures in online learning. Fundamental\nlimitations of the scheme and its integration with adaptation mechanisms are\nfurther investigated, followed by numerical simulations on a benchmark ILC\nproblem.",
    "descriptor": "",
    "authors": [
      "Efe C. Balta",
      "Andrea Iannelli",
      "Roy S. Smith",
      "John Lygeros"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.04722"
  },
  {
    "id": "arXiv:2204.04723",
    "title": "Machine Learning-Based CSI Feedback With Variable Length in FDD Massive  MIMO",
    "abstract": "To fully unlock the benefits of multiple-input multiple-output (MIMO)\nnetworks, downlink channel state information (CSI) is required at the base\nstation (BS). In frequency division duplex (FDD) systems, the CSI is acquired\nthrough a feedback signal from the user equipment (UE). However, this may lead\nto an important overhead in FDD massive MIMO systems. Focusing on these\nsystems, in this study, we propose a novel strategy to design the CSI feedback.\nOur strategy allows to optimally design the feedback with variable length,\nwhile reducing the parameter number at the UE. Specifically, principal\ncomponent analysis (PCA) is used to compress the channel into a latent space\nwith adaptive dimensionality. To quantize this compressed channel, the feedback\nbits are smartly allocated to the latent space dimensions by minimizing the\nnormalized mean squared error (NMSE) distortion. Finally, the quantization\ncodebook is determined with k-means clustering. Numerical simulations show that\nour strategy improves the zeroforcing beamforming sum rate by 26.8%, compared\nwith the popular CsiNet. The number of model parameters is reduced by 24.9\ntimes, thus causing a significantly smaller offloading overhead. At the same\ntime, PCA is characterized by a lightweight unsupervised training, requiring\neight times fewer training samples than CsiNet.",
    "descriptor": "\nComments: Submitted to IEEE for publication\n",
    "authors": [
      "Matteo Nerini",
      "Valentina Rizzello",
      "Michael Joham",
      "Wolfgang Utschick",
      "Bruno Clerckx"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2204.04723"
  },
  {
    "id": "arXiv:2204.04724",
    "title": "ProFairRec: Provider Fairness-aware News Recommendation",
    "abstract": "News recommendation aims to help online news platform users find their\npreferred news articles. Existing news recommendation methods usually learn\nmodels from historical user behaviors on news. However, these behaviors are\nusually biased on news providers. Models trained on biased user data may\ncapture and even amplify the biases on news providers, and are unfair for some\nminority news providers. In this paper, we propose a provider fairness-aware\nnews recommendation framework (named ProFairRec), which can learn news\nrecommendation models fair for different news providers from biased user data.\nThe core idea of ProFairRec is to learn provider-fair news representations and\nprovider-fair user representations to achieve provider fairness. To learn\nprovider-fair representations from biased data, we employ provider-biased\nrepresentations to inherit provider bias from data. Provider-fair and -biased\nnews representations are learned from news content and provider IDs\nrespectively, which are further aggregated to build fair and biased user\nrepresentations based on user click history. All of these representations are\nused in model training while only fair representations are used for user-news\nmatching to achieve fair news recommendation. Besides, we propose an\nadversarial learning task on news provider discrimination to prevent\nprovider-fair news representation from encoding provider bias. We also propose\nan orthogonal regularization on provider-fair and -biased representations to\nbetter reduce provider bias in provider-fair representations. Moreover,\nProFairRec is a general framework and can be applied to different news\nrecommendation methods. Extensive experiments on a public dataset verify that\nour ProFairRec approach can effectively improve the provider fairness of many\nexisting methods and meanwhile maintain their recommendation accuracy.",
    "descriptor": "\nComments: SIGIR 2022\n",
    "authors": [
      "Tao Qi",
      "Fangzhao Wu",
      "Chuhan Wu",
      "Peijie Sun",
      "Le Wu",
      "Xiting Wang",
      "Yongfeng Huang",
      "Xing Xie"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2204.04724"
  },
  {
    "id": "arXiv:2204.04726",
    "title": "News Recommendation with Candidate-aware User Modeling",
    "abstract": "News recommendation aims to match news with personalized user interest.\nExisting methods for news recommendation usually model user interest from\nhistorical clicked news without the consideration of candidate news. However,\neach user usually has multiple interests, and it is difficult for these methods\nto accurately match a candidate news with a specific user interest. In this\npaper, we present a candidate-aware user modeling method for personalized news\nrecommendation, which can incorporate candidate news into user modeling for\nbetter matching between candidate news and user interest. We propose a\ncandidate-aware self-attention network that uses candidate news as clue to\nmodel candidate-aware global user interest. In addition, we propose a\ncandidate-aware CNN network to incorporate candidate news into local behavior\ncontext modeling and learn candidate-aware short-term user interest. Besides,\nwe use a candidate-aware attention network to aggregate previously clicked news\nweighted by their relevance with candidate news to build candidate-aware user\nrepresentation. Experiments on real-world datasets show the effectiveness of\nour method in improving news recommendation performance.",
    "descriptor": "\nComments: SIGIR 2022\n",
    "authors": [
      "Tao Qi",
      "Fangzhao Wu",
      "Chuhan Wu",
      "Yongfeng Huang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2204.04726"
  },
  {
    "id": "arXiv:2204.04727",
    "title": "FUM: Fine-grained and Fast User Modeling for News Recommendation",
    "abstract": "User modeling is important for news recommendation. Existing methods usually\nfirst encode user's clicked news into news embeddings independently and then\naggregate them into user embedding. However, the word-level interactions across\ndifferent clicked news from the same user, which contain rich detailed clues to\ninfer user interest, are ignored by these methods. In this paper, we propose a\nfine-grained and fast user modeling framework (FUM) to model user interest from\nfine-grained behavior interactions for news recommendation. The core idea of\nFUM is to concatenate the clicked news into a long document and transform user\nmodeling into a document modeling task with both intra-news and inter-news\nword-level interactions. Since vanilla transformer cannot efficiently handle\nlong document, we apply an efficient transformer named Fastformer to model\nfine-grained behavior interactions. Extensive experiments on two real-world\ndatasets verify that FUM can effectively and efficiently model user interest\nfor news recommendation.",
    "descriptor": "\nComments: SIGIR 2022\n",
    "authors": [
      "Tao Qi",
      "Fangzhao Wu",
      "Chuhan Wu",
      "Yongfeng Huang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2204.04727"
  },
  {
    "id": "arXiv:2204.04729",
    "title": "On dually-CPT and strong-CPT posets",
    "abstract": "A poset is a containment of paths in a tree (CPT) if it admits a\nrepresentation by containment where each element of the poset is represented by\na path in a tree and two elements are comparable in the poset if and only if\nthe corresponding paths are related by the inclusion relation. Recently\nAlc\\'on, Gudi\\~{n}o and Gutierrez introduced proper subclasses of CPT posets,\nnamely dually-CPT, and strongly-CPT. A poset $\\mathbf{P}$ is dually-CPT, if and\nonly if $\\mathbf{P}$ and its dual $\\mathbf{P}^{d}$ both admit a CPT\nrepresentation. A poset $\\mathbf{P}$ is strongly-CPT, if and only if\n$\\mathbf{P}$ and all the posets that share the same underlying comparability\ngraph admit a CPT representation. Where as the inclusion between Dually-CPT and\nCPT was known to be strict. It was raised as an open question by Alc\\'on,\nGudi\\~{n}o and Gutierrez whether strongly-CPT was a strict subclass of\ndually-CPT. We provide a proof that both classes actually coincide.",
    "descriptor": "",
    "authors": [
      "Liliana Alc\u00f3n",
      "Martin Charles Golumbic",
      "Noem\u00ed Gudi\u00f1o",
      "Marisa Gutierrez",
      "Vincent Limouzy"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2204.04729"
  },
  {
    "id": "arXiv:2204.04730",
    "title": "Deep Non-rigid Structure-from-Motion: A Sequence-to-Sequence Translation  Perspective",
    "abstract": "Directly regressing the non-rigid shape and camera pose from the individual\n2D frame is ill-suited to the Non-Rigid Structure-from-Motion (NRSfM) problem.\nThis frame-by-frame 3D reconstruction pipeline overlooks the inherent\nspatial-temporal nature of NRSfM, i.e., reconstructing the whole 3D sequence\nfrom the input 2D sequence. In this paper, we propose to model deep NRSfM from\na sequence-to-sequence translation perspective, where the input 2D frame\nsequence is taken as a whole to reconstruct the deforming 3D non-rigid shape\nsequence. First, we apply a shape-motion predictor to estimate the initial\nnon-rigid shape and camera motion from a single frame. Then we propose a\ncontext modeling module to model camera motions and complex non-rigid shapes.\nTo tackle the difficulty in enforcing the global structure constraint within\nthe deep framework, we propose to impose the union-of-subspace structure by\nreplacing the self-expressiveness layer with multi-head attention and delayed\nregularizers, which enables end-to-end batch-wise training. Experimental\nresults across different datasets such as Human3.6M, CMU Mocap and InterHand\nprove the superiority of our framework. The code will be made publicly\navailable",
    "descriptor": "",
    "authors": [
      "Hui Deng",
      "Tong Zhang",
      "Yuchao Dai",
      "Jiawei Shi",
      "Yiran Zhong",
      "Hongdong Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.04730"
  },
  {
    "id": "arXiv:2204.04734",
    "title": "A Comparative Analysis of Decision-Level Fusion for Multimodal Driver  Behaviour Understanding",
    "abstract": "Visual recognition inside the vehicle cabin leads to safer driving and more\nintuitive human-vehicle interaction but such systems face substantial obstacles\nas they need to capture different granularities of driver behaviour while\ndealing with highly limited body visibility and changing illumination.\nMultimodal recognition mitigates a number of such issues: prediction outcomes\nof different sensors complement each other due to different modality-specific\nstrengths and weaknesses. While several late fusion methods have been\nconsidered in previously published frameworks, they constantly feature\ndifferent architecture backbones and building blocks making it very hard to\nisolate the role of the chosen late fusion strategy itself. This paper presents\nan empirical evaluation of different paradigms for decision-level late fusion\nin video-based driver observation. We compare seven different mechanisms for\njoining the results of single-modal classifiers which have been both popular,\n(e.g. score averaging) and not yet considered (e.g. rank-level fusion) in the\ncontext of driver observation evaluating them based on different criteria and\nbenchmark settings. This is the first systematic study of strategies for fusing\noutcomes of multimodal predictors inside the vehicles, conducted with the goal\nto provide guidance for fusion scheme selection.",
    "descriptor": "\nComments: Accepted at Intelligent Vehicles Symposium 2022, IEEE\n",
    "authors": [
      "Alina Roitberg",
      "Kunyu Peng",
      "Zdravko Marinov",
      "Constantin Seibold",
      "David Schneider",
      "Rainer Stiefelhagen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.04734"
  },
  {
    "id": "arXiv:2204.04735",
    "title": "Reducing Model Jitter: Stable Re-training of Semantic Parsers in  Production Environments",
    "abstract": "Retraining modern deep learning systems can lead to variations in model\nperformance even when trained using the same data and hyper-parameters by\nsimply using different random seeds. We call this phenomenon model jitter. This\nissue is often exacerbated in production settings, where models are retrained\non noisy data. In this work we tackle the problem of stable retraining with a\nfocus on conversational semantic parsers. We first quantify the model jitter\nproblem by introducing the model agreement metric and showing the variation\nwith dataset noise and model sizes. We then demonstrate the effectiveness of\nvarious jitter reduction techniques such as ensembling and distillation.\nLastly, we discuss practical trade-offs between such techniques and show that\nco-distillation provides a sweet spot in terms of jitter reduction for semantic\nparsing systems with only a modest increase in resource usage.",
    "descriptor": "",
    "authors": [
      "Christopher Hidey",
      "Fei Liu",
      "Rahul Goel"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.04735"
  },
  {
    "id": "arXiv:2204.04741",
    "title": "Is GitHub's Copilot as Bad As Humans at Introducing Vulnerabilities in  Code?",
    "abstract": "Several advances in deep learning have been successfully applied to the\nsoftware development process. Of recent interest is the use of neural language\nmodels to build tools that can assist in writing code. There is a growing body\nof work to evaluate these tools and their underlying language models. We aim to\ncontribute to this line of research via a comparative empirical analysis of\nthese tools and language models from a security perspective. For the rest of\nthis paper, we use CGT (Code Generation Tool) to refer to language models as\nwell as other tools, such as Copilot, that are built with language models.\nThe aim of this study is to compare the performance of one CGT, Copilot, with\nthe performance of human developers. Specifically, we investigate whether\nCopilot is just as likely to introduce the same software vulnerabilities as\nhuman developers.\nWe will use the Big-Vul dataset proposed by Fan et al. - a dataset of\nvulnerabilities introduced by human developers. For each entry in the dataset,\nwe will recreate the scenario before the bug was introduced and allow Copilot\nto generate a completion. The completions are manually inspected by three\nindependent coders in order to be classified as 1. containing the same\nvulnerability (introduced by the human), 2. containing a fix for the\nvulnerability or 3. other. The \"other\" category is used as a catchall for\nscenarios that are out of scope for this project.",
    "descriptor": "",
    "authors": [
      "Owura Asare",
      "Meiyappan Nagappan",
      "N. Asokan"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2204.04741"
  },
  {
    "id": "arXiv:2204.04746",
    "title": "CholecTriplet2021: A benchmark challenge for surgical action triplet  recognition",
    "abstract": "Context-aware decision support in the operating room can foster surgical\nsafety and efficiency by leveraging real-time feedback from surgical workflow\nanalysis. Most existing works recognize surgical activities at a coarse-grained\nlevel, such as phases, steps or events, leaving out fine-grained interaction\ndetails about the surgical activity; yet those are needed for more helpful AI\nassistance in the operating room. Recognizing surgical actions as triplets of\n<instrument, verb, target> combination delivers comprehensive details about the\nactivities taking place in surgical videos. This paper presents\nCholecTriplet2021: an endoscopic vision challenge organized at MICCAI 2021 for\nthe recognition of surgical action triplets in laparoscopic videos. The\nchallenge granted private access to the large-scale CholecT50 dataset, which is\nannotated with action triplet information. In this paper, we present the\nchallenge setup and assessment of the state-of-the-art deep learning methods\nproposed by the participants during the challenge. A total of 4 baseline\nmethods from the challenge organizers and 19 new deep learning algorithms by\ncompeting teams are presented to recognize surgical action triplets directly\nfrom surgical videos, achieving mean average precision (mAP) ranging from 4.2%\nto 38.1%. This study also analyzes the significance of the results obtained by\nthe presented approaches, performs a thorough methodological comparison between\nthem, in-depth result analysis, and proposes a novel ensemble method for\nenhanced recognition. Our analysis shows that surgical workflow analysis is not\nyet solved, and also highlights interesting directions for future research on\nfine-grained surgical activity recognition which is of utmost importance for\nthe development of AI in surgery.",
    "descriptor": "\nComments: CholecTriplet2021 challenge report. Submitted to journal of Medical Image Analysis. 22 pages, 8 figures, 11 tables\n",
    "authors": [
      "Chinedu Innocent Nwoye",
      "Deepak Alapatt",
      "Tong Yu",
      "Armine Vardazaryan",
      "Fangfang Xia",
      "Zixuan Zhao",
      "Tong Xia",
      "Fucang Jia",
      "Yuxuan Yang",
      "Hao Wang",
      "Derong Yu",
      "Guoyan Zheng",
      "Xiaotian Duan",
      "Neil Getty",
      "Ricardo Sanchez-Matilla",
      "Maria Robu",
      "Li Zhang",
      "Huabin Chen",
      "Jiacheng Wang",
      "Liansheng Wang",
      "Bokai Zhang",
      "Beerend Gerats",
      "Sista Raviteja",
      "Rachana Sathish",
      "Rong Tao",
      "Satoshi Kondo",
      "Winnie Pang",
      "Hongliang Ren",
      "Julian Ronald Abbing",
      "Mohammad Hasan Sarhan",
      "Sebastian Bodenstedt",
      "Nithya Bhasker",
      "Bruno Oliveira",
      "Helena R. Torres",
      "Li Ling",
      "Finn Gaida",
      "Tobias Czempiel",
      "Jo\u00e3o L. Vila\u00e7a",
      "Pedro Morais",
      "Jaime Fonseca",
      "Ruby Mae Egging",
      "Inge Nicole Wijma",
      "Chen Qian",
      "Guibin Bian",
      "Zhen Li",
      "Velmurugan Balasubramanian",
      "Debdoot Sheet",
      "Imanol Luengo",
      "Yuanbo Zhu",
      "Shuai Ding",
      "Jakob-Anton Aschenbrenner",
      "Nicolas Elini van der Kar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.04746"
  },
  {
    "id": "arXiv:2204.04748",
    "title": "Breaking Character: Are Subwords Good Enough for MRLs After All?",
    "abstract": "Large pretrained language models (PLMs) typically tokenize the input string\ninto contiguous subwords before any pretraining or inference. However, previous\nstudies have claimed that this form of subword tokenization is inadequate for\nprocessing morphologically-rich languages (MRLs). We revisit this hypothesis by\npretraining a BERT-style masked language model over character sequences instead\nof word-pieces. We compare the resulting model, dubbed TavBERT, against\ncontemporary PLMs based on subwords for three highly complex and ambiguous MRLs\n(Hebrew, Turkish, and Arabic), testing them on both morphological and semantic\ntasks. Our results show, for all tested languages, that while TavBERT obtains\nmild improvements on surface-level tasks \\`a la POS tagging and full\nmorphological disambiguation, subword-based PLMs achieve significantly higher\nperformance on semantic tasks, such as named entity recognition and extractive\nquestion answering. These results showcase and (re)confirm the potential of\nsubword tokenization as a reasonable modeling assumption for many languages,\nincluding MRLs.",
    "descriptor": "",
    "authors": [
      "Omri Keren",
      "Tal Avinari",
      "Reut Tsarfaty",
      "Omer Levy"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.04748"
  },
  {
    "id": "arXiv:2204.04752",
    "title": "Beyond Cross-view Image Retrieval: Highly Accurate Vehicle Localization  Using Satellite Image",
    "abstract": "This paper addresses the problem of vehicle-mounted camera localization by\nmatching a ground-level image with an overhead-view satellite map. Existing\nmethods often treat this problem as cross-view image retrieval, and use learned\ndeep features to match the ground-level query image to a partition (eg, a small\npatch) of the satellite map. By these methods, the localization accuracy is\nlimited by the partitioning density of the satellite map (often in the order of\ntens meters). Departing from the conventional wisdom of image retrieval, this\npaper presents a novel solution that can achieve highly-accurate localization.\nThe key idea is to formulate the task as pose estimation and solve it by\nneural-net based optimization. Specifically, we design a two-branch {CNN} to\nextract robust features from the ground and satellite images, respectively. To\nbridge the vast cross-view domain gap, we resort to a Geometry Projection\nmodule that projects features from the satellite map to the ground-view, based\non a relative camera pose. Aiming to minimize the differences between the\nprojected features and the observed features, we employ a differentiable\nLevenberg-Marquardt ({LM}) module to search for the optimal camera pose\niteratively. The entire pipeline is differentiable and runs end-to-end.\nExtensive experiments on standard autonomous vehicle localization datasets have\nconfirmed the superiority of the proposed method. Notably, e.g., starting from\na coarse estimate of camera location within a wide region of 40m x 40m, with an\n80% likelihood our method quickly reduces the lateral location error to be\nwithin 5m on a new KITTI cross-view dataset.",
    "descriptor": "\nComments: accepted to CVPR2022\n",
    "authors": [
      "Yujiao Shi",
      "Hongdong Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.04752"
  },
  {
    "id": "arXiv:2204.04756",
    "title": "Towards Evaluation of Autonomously Generated Musical Compositions: A  Comprehensive Survey",
    "abstract": "There are many applications that aim to create a complete model for an\nautonomously generated composition; systems are able to generate muzak songs,\nassist singers in transcribing songs or can imitate long-dead authors.\nSubjective understanding of creativity or aesthetics differs not only within\npreferences (popular authors or genres), but also differs on the basis of\nexperienced experience or socio-cultural environment. So, what do we want to\nachieve with such an adaptation? What is the benefit of the resulting work for\nthe author, who can no longer evaluate this composition? And in what ways\nshould we evaluate such a composition at all?",
    "descriptor": "",
    "authors": [
      "Daniel Kvak"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2204.04756"
  },
  {
    "id": "arXiv:2204.04758",
    "title": "Iceberg Sensemaking: A Process Model for Critical Data Analysis and  Visualization",
    "abstract": "We offer a new model of the sensemaking process for data science and visual\nanalytics. Whereas past sensemaking models have been built on theoretical\nfoundations in cognitivism and positivism, this model adopts interpretivist\nfoundations in order to reframe data sensemaking in humanistic terms. We\nidentify five key principles centered on the concept of schemas: Tacit and\nExplicit Schemas, Schemas First and Always, Data as a Schematic Artifact,\nSchematic Multiplicity, and Sensemaking Over Time. Our model uses the analogy\nof an iceberg, where data is the visible tip of the schema underneath it. The\nanalysis process iteratively refines both the data and its schema in tandem. We\ncompare the roles of schemas in past sensemaking models and draw conceptual\ndistinctions based on a historical review of schemas in different philosophical\ntraditions. We validate the descriptive, predictive, and explanatory power of\nour model through four analysis scenarios: uncovering data injustice,\ninvestigating official data, teaching data wrangling, and producing data\nmashups.",
    "descriptor": "\nComments: 11 pages, 3 figures, submitted to IEEE VIS 2022\n",
    "authors": [
      "Charles Berret",
      "Tamara Munzner"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2204.04758"
  },
  {
    "id": "arXiv:2204.04763",
    "title": "Information-theoretic Online Memory Selection for Continual Learning",
    "abstract": "A challenging problem in task-free continual learning is the online selection\nof a representative replay memory from data streams. In this work, we\ninvestigate the online memory selection problem from an information-theoretic\nperspective. To gather the most information, we propose the \\textit{surprise}\nand the \\textit{learnability} criteria to pick informative points and to avoid\noutliers. We present a Bayesian model to compute the criteria efficiently by\nexploiting rank-one matrix structures. We demonstrate that these criteria\nencourage selecting informative points in a greedy algorithm for online memory\nselection. Furthermore, by identifying the importance of \\textit{the timing to\nupdate the memory}, we introduce a stochastic information-theoretic reservoir\nsampler (InfoRS), which conducts sampling among selective points with high\ninformation. Compared to reservoir sampling, InfoRS demonstrates improved\nrobustness against data imbalance. Finally, empirical performances over\ncontinual learning benchmarks manifest its efficiency and efficacy.",
    "descriptor": "\nComments: ICLR 2022\n",
    "authors": [
      "Shengyang Sun",
      "Daniele Calandriello",
      "Huiyi Hu",
      "Ang Li",
      "Michalis Titsias"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2204.04763"
  },
  {
    "id": "arXiv:2204.04765",
    "title": "Minimal Roman Dominating Functions: Extensions and Enumeration",
    "abstract": "Roman domination is one of the many variants of domination that keeps most of\nthe complexity features of the classical domination problem. We prove that\nRoman domination behaves differently in two aspects: enumeration and extension.\nWe develop non-trivial enumeration algorithms for minimal Roman domination\nfunctions with polynomial delay and polynomial space. Recall that the existence\nof a similar enumeration result for minimal dominating sets is open for\ndecades. Our result is based on a polynomial-time algorithm for Extension Roman\nDomination: Given a graph $G = (V,E)$ and a function $f:V\\to\\{0,1,2\\}$, is\nthere a minimal Roman domination function $\\Tilde{f}$ with $f\\leq \\Tilde{f}$?\nHere, $\\leq$ lifts $0< 1< 2$ pointwise; minimality is understood in this order.\nOur enumeration algorithm is also analyzed from an input-sensitive viewpoint,\nleading to a run-time estimate of $\\Oh(\\RomanUpperbound^n)$ for graphs of order\nn; this is complemented by a lower bound example of\n$\\Omega(\\RomanLowerbound^n)$.",
    "descriptor": "",
    "authors": [
      "Faisal N. Abu-Khzam",
      "Henning Fernau",
      "Kevin Mann"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2204.04765"
  },
  {
    "id": "arXiv:2204.04766",
    "title": "Configuration and Collection Factors for Side-Channel Disassembly",
    "abstract": "Myriad uses, methodologies, and channels have been explored for side-channel\nanalysis. However, specific implementation considerations are often\nunpublished. This paper explores select test configuration and collection\nparameters, such as input voltage, shunt resistance, sample rate, and\nmicrocontroller clock frequency, along with their impact on side-channel\nanalysis performance. The analysis use case considered is instruction\ndisassembly and classification using the microcontroller power side-channel. An\nATmega328P microcontroller and a subset of the AVR instruction set are used in\nthe experiments as the Device Under Test (DUT). A time-series convolutional\nneural network (CNN) is used to evaluate classification performance at\nclock-cycle fidelity. We conclude that configuration and collection parameters\nhave a meaningful impact on performance, especially where the\ninstruction-trace's signal to noise ratio (SNR) is impacted. Additionally, data\ncollection and analysis well above the Nyquist rate is required for\nside-channel disassembly. We also found that 7V input voltage with 1 kiloohm\nshunt and a sample rate of 250-500 MSa/s provided optimal performance in our\napplication, with diminishing returns or in some cases degradation at higher\nlevels.",
    "descriptor": "\nComments: 8 pages, 8 figures\n",
    "authors": [
      "Random Gwinn",
      "Mark Matties",
      "Aviel D. Rubin"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2204.04766"
  },
  {
    "id": "arXiv:2204.04767",
    "title": "Risk-aware UAV-UGV Rendezvous with Chance-Constrained Markov Decision  Process",
    "abstract": "We study a chance-constrained variant of the cooperative aerial-ground\nvehicle routing problem, in which an Unmanned Aerial Vehicle (UAV) with limited\nbattery capacity and an Unmanned Ground Vehicle (UGV) that can also act as a\nmobile recharging station need to jointly accomplish a mission such as\nmonitoring a set of points. Due to the limited battery capacity of the UAV, two\nvehicles sometimes have to deviate from their task to rendezvous and recharge\nthe UAV\\@. Unlike prior work that has focused on the deterministic case, we\naddress the challenge of stochastic energy consumption of the UAV\\@. We are\ninterested in finding the optimal policy that decides when and where to\nrendezvous such that the expected travel time of the UAV is minimized and the\nprobability of running out of charge is less than a user-defined tolerance. We\nformulate this problem as a Chance Constrained Markov Decision Process (CCMDP).\nTo the best knowledge of the authors, this is the first CMDP-based formulation\nfor the UAV-UGV routing problems under power consumption uncertainty. We adopt\na Linear Programming (LP) based approach to solve the problem optimally. We\ndemonstrate the effectiveness of our formulation in the context of an\nIntelligence Surveillance and Reconnaissance (ISR) mission.",
    "descriptor": "",
    "authors": [
      "Guangyao Shi",
      "Nare Karapetyan",
      "Ahmad Bilal Asghar",
      "Jean-Paul Reddinger",
      "James Dotterweich",
      "James Humann",
      "Pratap Tokekar"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2204.04767"
  },
  {
    "id": "arXiv:2204.04768",
    "title": "Analysis of Power-Oriented Fault Injection Attacks on Spiking Neural  Networks",
    "abstract": "Spiking Neural Networks (SNN) are quickly gaining traction as a viable\nalternative to Deep Neural Networks (DNN). In comparison to DNNs, SNNs are more\ncomputationally powerful and provide superior energy efficiency. SNNs, while\nexciting at first appearance, contain security-sensitive assets (e.g., neuron\nthreshold voltage) and vulnerabilities (e.g., sensitivity of classification\naccuracy to neuron threshold voltage change) that adversaries can exploit. We\ninvestigate global fault injection attacks by employing external power supplies\nand laser-induced local power glitches to corrupt crucial training parameters\nsuch as spike amplitude and neuron's membrane threshold potential on SNNs\ndeveloped using common analog neurons. We also evaluate the impact of\npower-based attacks on individual SNN layers for 0% (i.e., no attack) to 100%\n(i.e., whole layer under attack). We investigate the impact of the attacks on\ndigit classification tasks and find that in the worst-case scenario,\nclassification accuracy is reduced by 85.65%. We also propose defenses e.g., a\nrobust current driver design that is immune to power-oriented attacks, improved\ncircuit sizing of neuron components to reduce/recover the adversarial accuracy\ndegradation at the cost of negligible area and 25% power overhead. We also\npresent a dummy neuron-based voltage fault injection detection system with 1%\npower and area overhead.",
    "descriptor": "\nComments: Design, Automation and Test in Europe Conference (DATE) 2022\n",
    "authors": [
      "Karthikeyan Nagarajan",
      "Junde Li",
      "Sina Sayyah Ensan",
      "Mohammad Nasim Imtiaz Khan",
      "Sachhidh Kannan",
      "Swaroop Ghosh"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2204.04768"
  },
  {
    "id": "arXiv:2204.04769",
    "title": "A review of knowledge graph application scenarios in cyber security",
    "abstract": "Facing the dynamic complex cyber environments, internal and external cyber\nthreat intelligence, and the increasing risk of cyber-attack, knowledge graphs\nshow great application potential in the cyber security area because of their\ncapabilities in knowledge aggregation, representation, management, and\nreasoning. However, while most research has focused on how to develop a\ncomplete knowledge graph, it remains unclear how to apply the knowledge graph\nto solve industrial real challenges in cyber-attack and defense scenarios. In\nthis review, we provide a brief overview of the basic concepts, schema, and\nconstruction approaches for the cyber security knowledge graph. To facilitate\nfuture research on cyber security knowledge graphs, we also present a curated\ncollection of datasets and open-source libraries on the knowledge construction\nand information extraction task. In the major part of this article, we conduct\na comparative review of the different works that elaborate on the recent\nprogress in the application scenarios of the cyber security knowledge graph.\nFurthermore, a novel comprehensive classification framework is created to\ndescribe the connected works from nine primary categories and eighteen\nsubcategories. Finally, we have a thorough outlook on several promising\nresearch directions based on the discussion of existing research flaws.",
    "descriptor": "",
    "authors": [
      "Kai Liu",
      "Fei Wang",
      "Zhaoyun Ding",
      "Sheng Liang",
      "Zhengfei Yu",
      "Yun Zhou"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2204.04769"
  },
  {
    "id": "arXiv:2204.04775",
    "title": "Few-Shot Cross-lingual Transfer for Coarse-grained De-identification of  Code-Mixed Clinical Texts",
    "abstract": "Despite the advances in digital healthcare systems offering curated\nstructured knowledge, much of the critical information still lies in large\nvolumes of unlabeled and unstructured clinical texts. These texts, which often\ncontain protected health information (PHI), are exposed to information\nextraction tools for downstream applications, risking patient identification.\nExisting works in de-identification rely on using large-scale annotated corpora\nin English, which often are not suitable in real-world multilingual settings.\nPre-trained language models (LM) have shown great potential for cross-lingual\ntransfer in low-resource settings. In this work, we empirically show the\nfew-shot cross-lingual transfer property of LMs for named entity recognition\n(NER) and apply it to solve a low-resource and real-world challenge of\ncode-mixed (Spanish-Catalan) clinical notes de-identification in the stroke\ndomain. We annotate a gold evaluation dataset to assess few-shot setting\nperformance where we only use a few hundred labeled examples for training. Our\nmodel improves the zero-shot F1-score from 73.7% to 91.2% on the gold\nevaluation set when adapting Multilingual BERT (mBERT) (Devlin et al., 2019)\nfrom the MEDDOCAN (Marimon et al., 2019) corpus with our few-shot cross-lingual\ntarget corpus. When generalized to an out-of-sample test set, the best model\nachieves a human-evaluation F1-score of 97.2%.",
    "descriptor": "\nComments: Accepted by BioNLP'22\n",
    "authors": [
      "Saadullah Amin",
      "Noon Pokaratsiri Goldstein",
      "Morgan Kelly Wixted",
      "Alejandro Garc\u00eda-Rudolph",
      "Catalina Mart\u00ednez-Costa",
      "G\u00fcnter Neumann"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.04775"
  },
  {
    "id": "arXiv:2204.04777",
    "title": "Multimodal Machine Learning in Precision Health",
    "abstract": "As machine learning and artificial intelligence are more frequently being\nleveraged to tackle problems in the health sector, there has been increased\ninterest in utilizing them in clinical decision-support. This has historically\nbeen the case in single modal data such as electronic health record data.\nAttempts to improve prediction and resemble the multimodal nature of clinical\nexpert decision-making this has been met in the computational field of machine\nlearning by a fusion of disparate data. This review was conducted to summarize\nthis field and identify topics ripe for future research. We conducted this\nreview in accordance with the PRISMA (Preferred Reporting Items for Systematic\nreviews and Meta-Analyses) extension for Scoping Reviews to characterize\nmulti-modal data fusion in health. We used a combination of content analysis\nand literature searches to establish search strings and databases of PubMed,\nGoogle Scholar, and IEEEXplore from 2011 to 2021. A final set of 125 articles\nwere included in the analysis. The most common health areas utilizing\nmulti-modal methods were neurology and oncology. However, there exist a wide\nbreadth of current applications. The most common form of information fusion was\nearly fusion. Notably, there was an improvement in predictive performance\nperforming heterogeneous data fusion. Lacking from the papers were clear\nclinical deployment strategies and pursuit of FDA-approved tools. These\nfindings provide a map of the current literature on multimodal data fusion as\napplied to health diagnosis/prognosis problems. Multi-modal machine learning,\nwhile more robust in its estimations over unimodal methods, has drawbacks in\nits scalability and the time-consuming nature of information concatenation.",
    "descriptor": "",
    "authors": [
      "Adrienne Kline",
      "Hanyin Wang",
      "Yikuan Li",
      "Saya Dennis",
      "Meghan Hutch",
      "Zhenxing Xu",
      "Fei Wang",
      "Feixiong Cheng",
      "Yuan Luo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.04777"
  },
  {
    "id": "arXiv:2204.04778",
    "title": "Measuring the False Sense of Security",
    "abstract": "Recently, several papers have demonstrated how widespread gradient masking is\namongst proposed adversarial defenses. Defenses that rely on this phenomenon\nare considered failed, and can easily be broken. Despite this, there has been\nlittle investigation into ways of measuring the phenomenon of gradient masking\nand enabling comparisons of its extent amongst different networks. In this\nwork, we investigate gradient masking under the lens of its mensurability,\ndeparting from the idea that it is a binary phenomenon. We propose and motivate\nseveral metrics for it, performing extensive empirical tests on defenses\nsuspected of exhibiting different degrees of gradient masking. These are\ncomputationally cheaper than strong attacks, enable comparisons between models,\nand do not require the large time investment of tailor-made attacks for\nspecific models. Our results reveal metrics that are successful in measuring\nthe extent of gradient masking across different networks",
    "descriptor": "",
    "authors": [
      "Carlos Gomes"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2204.04778"
  },
  {
    "id": "arXiv:2204.04779",
    "title": "MedDistant19: A Challenging Benchmark for Distantly Supervised  Biomedical Relation Extraction",
    "abstract": "Relation Extraction in the biomedical domain is challenging due to the lack\nof labeled data and high annotation costs, needing domain experts. Distant\nsupervision is commonly used as a way to tackle the scarcity of annotated data\nby automatically pairing knowledge graph relationships with raw texts.\nDistantly Supervised Biomedical Relation Extraction (Bio-DSRE) models can\nseemingly produce very accurate results in several benchmarks. However, given\nthe challenging nature of the task, we set out to investigate the validity of\nsuch impressive results. We probed the datasets used by Amin et al. (2020) and\nHogan et al. (2021) and found a significant overlap between training and\nevaluation relationships that, once resolved, reduced the accuracy of the\nmodels by up to 71%. Furthermore, we noticed several inconsistencies with the\ndata construction process, such as creating negative samples and improper\nhandling of redundant relationships. We mitigate these issues and present\nMedDistant19, a new benchmark dataset obtained by aligning the MEDLINE\nabstracts with the widely used SNOMED Clinical Terms (SNOMED CT) knowledge\nbase. We experimented with several state-of-the-art models achieving an AUC of\n55.4% and 49.8% at sentence- and bag-level, showing that there is still plenty\nof room for improvement.",
    "descriptor": "\nComments: Accepted by BioNLP'22\n",
    "authors": [
      "Saadullah Amin",
      "Pasquale Minervini",
      "David Chang",
      "G\u00fcnter Neumann",
      "Pontus Stenetorp"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.04779"
  },
  {
    "id": "arXiv:2204.04780",
    "title": "A Fully Polynomial Time Approximation Scheme for Fixed-Horizon  Constrained Stochastic Shortest Path Problem under Local Transitions",
    "abstract": "The fixed-horizon constrained stochastic shortest path problem (C-SSP) is a\nformalism for planning in stochastic environments under certain operating\nconstraints. Chance-Constrained SSP (CC-SSP) is a variant that allows bounding\nthe probability of constraint violation, which is desired in many\nsafety-critical applications. This work considers an important variant of\n(C)C-SSP under local transition, capturing a broad class of SSP problems where\nstate reachability exhibit a certain locality. Only a constant number of states\ncan share some subsequent states. (C)C-SSP under local transition is NP-Hard\neven for a planning horizon of two. In this work, we propose a fully\npolynomial-time approximation scheme for (C)C-SSP that computes (near) optimal\ndeterministic policies. Such an algorithm is the best approximation algorithm\nattainable in theory",
    "descriptor": "",
    "authors": [
      "Majid Khonji"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.04780"
  },
  {
    "id": "arXiv:2204.04783",
    "title": "Temporal Knowledge Graph Reasoning with Low-rank and Model-agnostic  Representations",
    "abstract": "Temporal knowledge graph completion (TKGC) has become a popular approach for\nreasoning over the event and temporal knowledge graphs, targeting the\ncompletion of knowledge with accurate but missing information. In this context,\ntensor decomposition has successfully modeled interactions between entities and\nrelations. Their effectiveness in static knowledge graph completion motivates\nus to introduce Time-LowFER, a family of parameter-efficient and time-aware\nextensions of the low-rank tensor factorization model LowFER. Noting several\nlimitations in current approaches to represent time, we propose a cycle-aware\ntime-encoding scheme for time features, which is model-agnostic and offers a\nmore generalized representation of time. We implement our methods in a unified\ntemporal knowledge graph embedding framework, focusing on time-sensitive data\nprocessing. The experiments show that our proposed methods perform on par or\nbetter than the state-of-the-art semantic matching models on two benchmarks.",
    "descriptor": "\nComments: Accepted by RepL4NLP'22\n",
    "authors": [
      "Ioannis Dikeoulias",
      "Saadullah Amin",
      "G\u00fcnter Neumann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.04783"
  },
  {
    "id": "arXiv:2204.04788",
    "title": "DILEMMA: Self-Supervised Shape and Texture Learning with Transformers",
    "abstract": "There is a growing belief that deep neural networks with a shape bias may\nexhibit better generalization capabilities than models with a texture bias,\nbecause shape is a more reliable indicator of the object category. However, we\nshow experimentally that existing measures of shape bias are not stable\npredictors of generalization and argue that shape discrimination should not\ncome at the expense of texture discrimination. Thus, we propose a pseudo-task\nto explicitly boost both shape and texture discriminability in models trained\nvia self-supervised learning. For this purpose, we train a ViT to detect which\ninput token has been combined with an incorrect positional embedding. To retain\ntexture discrimination, the ViT is also trained as in MoCo with a\nstudent-teacher architecture and a contrastive loss over an extra learnable\nclass token. We call our method DILEMMA, which stands for Detection of\nIncorrect Location EMbeddings with MAsked inputs. We evaluate our method\nthrough fine-tuning on several datasets and show that it outperforms MoCoV3 and\nDINO. Moreover, we show that when downstream tasks are strongly reliant on\nshape (such as in the YOGA-82 pose dataset), our pre-trained features yield a\nsignificant gain over prior work. Code will be released upon publication.",
    "descriptor": "",
    "authors": [
      "Sepehr Sameni",
      "Simon Jenni",
      "Paolo Favaro"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.04788"
  },
  {
    "id": "arXiv:2204.04792",
    "title": "Differentially Private Fingerprinting for Location Trajectories",
    "abstract": "Location-based services have brought significant convenience to people in\ntheir daily lives. Services like navigation, food delivery, and carpooling\nfrequently ask for location data from users. On the other side, researchers and\nbusinesses are eager to acquire those data (that is collected by location-based\nservice providers) for various purposes. However, directly releasing those data\ncauses privacy concerns since location data contain users' sensitive\ninformation, e.g., regular moving patterns and favorite spots. To solve this,\nwe propose a system that protects users' location data under differential\nprivacy and prevents unauthorized redistribution at the same time. Observing\nhigh amount of noise introduced to achieve differential privacy, we implement a\nnovel post-processing scheme to regain data utility. In addition, we also\npropose a novel fingerprinting scheme as a part of the post-processing (to\ndetect unauthorized redistribution of data). Our proposed fingerprinting scheme\nconsiders correlations in location datasets and collusions among multiple\nparties, which makes it hard for the attackers to infer the fingerprinting\ncodes and avoid accusation. Using the experiments on a real-life location\ndataset, we show that our system achieves high fingerprint robustness against\nstate-of-the-art attacks. We also show the integrated fingerprinting scheme\nincreases data utility for differentially private datasets, which is beneficial\nfor data analyzers in data mining.",
    "descriptor": "",
    "authors": [
      "Yuzhou Jiang",
      "Emre Yilmaz",
      "Erman Ayday"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2204.04792"
  },
  {
    "id": "arXiv:2204.04793",
    "title": "Fake news detection using parallel BERT deep neural networks",
    "abstract": "Fake news is a growing challenge for social networks and media. Detection of\nfake news always has been a problem for many years, but after the evolution of\nsocial networks and increasing speed of news dissemination in recent years has\nbeen considered again. There are several approaches to solving this problem,\none of which is to detect fake news based on its text style using deep neural\nnetworks. In recent years, one of the most used forms of deep neural networks\nfor natural language processing is transfer learning with transformers. BERT is\none of the most promising transformers who outperforms other models in many NLP\nbenchmarks. This article, we introduce MWPBert, which uses two parallel BERT\nnetworks to perform veracity detection on full-text news articles. One of the\nBERT networks encodes news headline, and another encodes news body. Since the\ninput length of the BERT network is limited and constant and the news body is\nusually a long text, we cannot fed the whole news text into the BERT.\nTherefore, using the MaxWorth algorithm, we selected the part of the news text\nthat is more valuable for fact-checking, and fed it into the BERT network.\nFinally, we encode the output of the two BERT networks to an output network to\nclassify the news. The experiment results showed that the proposed model\noutperformed previous models in terms of accuracy and other performance\nmeasures.",
    "descriptor": "",
    "authors": [
      "Mahmood Farokhian",
      "Vahid Rafe",
      "Hadi Veisi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.04793"
  },
  {
    "id": "arXiv:2204.04795",
    "title": "Edge Continual Learning for Dynamic Digital Twins over Wireless Networks",
    "abstract": "Digital twins (DTs) constitute a critical link between the real-world and the\nmetaverse. To guarantee a robust connection between these two worlds, DTs\nshould maintain accurate representations of the physical applications, while\npreserving synchronization between real and digital entities. In this paper, a\nnovel edge continual learning framework is proposed to accurately model the\nevolving affinity between a physical twin (PT) and its corresponding cyber twin\n(CT) while maintaining their utmost synchronization. In particular, a CT is\nsimulated as a deep neural network (DNN) at the wireless network edge to model\nan autonomous vehicle traversing an episodically dynamic environment. As the\nvehicular PT updates its driving policy in each episode, the CT is required to\nconcurrently adapt its DNN model to the PT, which gives rise to a\nde-synchronization gap. Considering the history-aware nature of DTs, the model\nupdate process is posed a dual objective optimization problem whose goal is to\njointly minimize the loss function over all encountered episodes and the\ncorresponding de-synchronization time. As the de-synchronization time continues\nto increase over sequential episodes, an elastic weight consolidation (EWC)\ntechnique that regularizes the DT history is proposed to limit\nde-synchronization time. Furthermore, to address the plasticity-stability\ntradeoff accompanying the progressive growth of the EWC regularization terms, a\nmodified EWC method that considers fair execution between the historical\nepisodes of the DTs is adopted. Ultimately, the proposed framework achieves a\nsimultaneously accurate and synchronous CT model that is robust to catastrophic\nforgetting. Simulation results show that the proposed solution can achieve an\naccuracy of 90 % while guaranteeing a minimal desynchronization time.",
    "descriptor": "",
    "authors": [
      "Omar Hashash",
      "Christina Chaccour",
      "Walid Saad"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2204.04795"
  },
  {
    "id": "arXiv:2204.04796",
    "title": "SOS! Self-supervised Learning Over Sets Of Handled Objects In Egocentric  Action Recognition",
    "abstract": "Learning an egocentric action recognition model from video data is\nchallenging due to distractors (e.g., irrelevant objects) in the background.\nFurther integrating object information into an action model is hence\nbeneficial. Existing methods often leverage a generic object detector to\nidentify and represent the objects in the scene. However, several important\nissues remain. Object class annotations of good quality for the target domain\n(dataset) are still required for learning good object representation. Besides,\nprevious methods deeply couple the existing action models and need to retrain\nthem jointly with object representation, leading to costly and inflexible\nintegration. To overcome both limitations, we introduce Self-Supervised\nLearning Over Sets (SOS), an approach to pre-train a generic Objects In Contact\n(OIC) representation model from video object regions detected by an\noff-the-shelf hand-object contact detector. Instead of augmenting object\nregions individually as in conventional self-supervised learning, we view the\naction process as a means of natural data transformations with unique\nspatio-temporal continuity and exploit the inherent relationships among\nper-video object sets. Extensive experiments on two datasets, EPIC-KITCHENS-100\nand EGTEA, show that our OIC significantly boosts the performance of multiple\nstate-of-the-art video classification models.",
    "descriptor": "\nComments: CVPR2022 submission. Guess the decision, and email it to 1st author ;P\n",
    "authors": [
      "Victor Escorcia",
      "Ricardo Guerrero",
      "Xiatian Zhu",
      "Brais Martinez"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.04796"
  },
  {
    "id": "arXiv:2204.04797",
    "title": "Multi-Label Clinical Time-Series Generation via Conditional GAN",
    "abstract": "With wide applications of electronic health records (EHR), deep learning\nmethods have been adopted to analyze EHR data on various tasks such as\nrepresentation learning, clinical event prediction, and phenotyping. However,\ndue to privacy constraints, limited access to EHR becomes a bottleneck for deep\nlearning research. Recently, generative adversarial networks (GANs) have been\nsuccessful in generating EHR data. However, there are still challenges in\nhigh-quality EHR generation, including generating time-series EHR and uncommon\ndiseases given imbalanced datasets. In this work, we propose a Multi-label\nTime-series GAN (MTGAN) to generate EHR data and simultaneously improve the\nquality of uncommon disease generation. The generator of MTGAN uses a gated\nrecurrent unit (GRU) with a smooth conditional matrix to generate sequences and\nuncommon diseases. The critic gives scores using Wasserstein distance to\nrecognize real samples from synthetic samples by considering both data and\ntemporal features. We also propose a training strategy to calculate temporal\nfeatures for real data and stabilize GAN training. Furthermore, we design\nmultiple statistical metrics and prediction tasks to evaluate the generated\ndata. Experimental results demonstrate the quality of the synthetic data and\nthe effectiveness of MTGAN in generating realistic sequential EHR data,\nespecially for uncommon diseases.",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Chang Lu",
      "Chandan K. Reddy",
      "Ping Wang",
      "Dong Nie",
      "Yue Ning"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.04797"
  },
  {
    "id": "arXiv:2204.04799",
    "title": "DualPrompt: Complementary Prompting for Rehearsal-free Continual  Learning",
    "abstract": "Continual learning aims to enable a single model to learn a sequence of tasks\nwithout catastrophic forgetting. Top-performing methods usually require a\nrehearsal buffer to store past pristine examples for experience replay, which,\nhowever, limits their practical value due to privacy and memory constraints. In\nthis work, we present a simple yet effective framework, DualPrompt, which\nlearns a tiny set of parameters, called prompts, to properly instruct a\npre-trained model to learn tasks arriving sequentially without buffering past\nexamples. DualPrompt presents a novel approach to attach complementary prompts\nto the pre-trained backbone, and then formulates the objective as learning\ntask-invariant and task-specific \"instructions\". With extensive experimental\nvalidation, DualPrompt consistently sets state-of-the-art performance under the\nchallenging class-incremental setting. In particular, DualPrompt outperforms\nrecent advanced continual learning methods with relatively large buffer sizes.\nWe also introduce a more challenging benchmark, Split ImageNet-R, to help\ngeneralize rehearsal-free continual learning research. Source code is available\nat https://github.com/google-research/l2p.",
    "descriptor": "",
    "authors": [
      "Zifeng Wang",
      "Zizhao Zhang",
      "Sayna Ebrahimi",
      "Ruoxi Sun",
      "Han Zhang",
      "Chen-Yu Lee",
      "Xiaoqi Ren",
      "Guolong Su",
      "Vincent Perot",
      "Jennifer Dy",
      "Tomas Pfister"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.04799"
  },
  {
    "id": "arXiv:2204.04802",
    "title": "On the pragmatism of using binary classifiers over data intensive neural  network classifiers for detection of COVID-19 from voice",
    "abstract": "Lately, there has been a global effort by multiple research groups to detect\nCOVID-19 from voice. Different researchers use different kinds of information\nfrom the voice signal to achieve this. Various types of phonated sounds and the\nsound of cough and breath have all been used with varying degrees of success in\nautomated voice-based COVID-19 detection apps. In this paper, we show that\ndetecting COVID-19 from voice does not require custom-made non-standard\nfeatures or complicated neural network classifiers rather it can be\nsuccessfully done with just standard features and simple binary classifiers. In\nfact, we show that the latter is not only more accurate and interpretable and\nalso more computationally efficient in that they can be run locally on small\ndevices. We demonstrate this from a human-curated dataset collected and\ncalibrated in clinical settings. On this dataset which comprises over 1000\nspeakers, a simple binary classifier is able to achieve 94% detection accuracy.",
    "descriptor": "\nComments: Submitted to Interspeech 2022\n",
    "authors": [
      "Ankit Shah",
      "Hira Dhamyal",
      "Yang Gao",
      "Rita Singh",
      "Bhiksha Raj"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2204.04802"
  },
  {
    "id": "arXiv:2204.04812",
    "title": "OutfitTransformer: Learning Outfit Representations for Fashion  Recommendation",
    "abstract": "Learning an effective outfit-level representation is critical for predicting\nthe compatibility of items in an outfit, and retrieving complementary items for\na partial outfit. We present a framework, OutfitTransformer, that uses the\nproposed task-specific tokens and leverages the self-attention mechanism to\nlearn effective outfit-level representations encoding the compatibility\nrelationships between all items in the entire outfit for addressing both\ncompatibility prediction and complementary item retrieval tasks. For\ncompatibility prediction, we design an outfit token to capture a global outfit\nrepresentation and train the framework using a classification loss. For\ncomplementary item retrieval, we design a target item token that additionally\ntakes the target item specification (in the form of a category or text\ndescription) into consideration. We train our framework using a proposed\nset-wise outfit ranking loss to generate a target item embedding given an\noutfit, and a target item specification as inputs. The generated target item\nembedding is then used to retrieve compatible items that match the rest of the\noutfit. Additionally, we adopt a pre-training approach and a curriculum\nlearning strategy to improve retrieval performance. Since our framework learns\nat an outfit-level, it allows us to learn a single embedding capturing\nhigher-order relations among multiple items in the outfit more effectively than\npairwise methods. Experiments demonstrate that our approach outperforms\nstate-of-the-art methods on compatibility prediction, fill-in-the-blank, and\ncomplementary item retrieval tasks. We further validate the quality of our\nretrieval results with a user study.",
    "descriptor": "",
    "authors": [
      "Rohan Sarkar",
      "Navaneeth Bodla",
      "Mariya Vasileva",
      "Yen-Liang Lin",
      "Anurag Beniwal",
      "Alan Lu",
      "Gerard Medioni"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.04812"
  },
  {
    "id": "arXiv:2204.04813",
    "title": "Explanation Graph Generation via Pre-trained Language Models: An  Empirical Study with Contrastive Learning",
    "abstract": "Pre-trained sequence-to-sequence language models have led to widespread\nsuccess in many natural language generation tasks. However, there has been\nrelatively less work on analyzing their ability to generate structured outputs\nsuch as graphs. Unlike natural language, graphs have distinct structural and\nsemantic properties in the context of a downstream NLP task, e.g., generating a\ngraph that is connected and acyclic can be attributed to its structural\nconstraints, while the semantics of a graph can refer to how meaningfully an\nedge represents the relation between two node concepts. In this work, we study\npre-trained language models that generate explanation graphs in an end-to-end\nmanner and analyze their ability to learn the structural constraints and\nsemantics of such graphs. We first show that with limited supervision,\npre-trained language models often generate graphs that either violate these\nconstraints or are semantically incoherent. Since curating large amount of\nhuman-annotated graphs is expensive and tedious, we propose simple yet\neffective ways of graph perturbations via node and edge edit operations that\nlead to structurally and semantically positive and negative graphs. Next, we\nleverage these graphs in different contrastive learning models with Max-Margin\nand InfoNCE losses. Our methods lead to significant improvements in both\nstructural and semantic accuracy of explanation graphs and also generalize to\nother similar graph generation tasks. Lastly, we show that human errors are the\nbest negatives for contrastive learning and also that automatically generating\nmore such human-like negative graphs can lead to further improvements. Our code\nand models are publicly available at https://github.com/swarnaHub/ExplagraphGen",
    "descriptor": "\nComments: ACL 2022 (19 pages)\n",
    "authors": [
      "Swarnadeep Saha",
      "Prateek Yadav",
      "Mohit Bansal"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.04813"
  },
  {
    "id": "arXiv:2204.04816",
    "title": "Distributed Hardware Accelerated Secure Joint Computation on the COPA  Framework",
    "abstract": "Performance of distributed data center applications can be improved through\nuse of FPGA-based SmartNICs, which provide additional functionality and enable\nhigher bandwidth communication. Until lately, however, the lack of a simple\napproach for customizing SmartNICs to application requirements has limited the\npotential benefits. Intel's Configurable Network Protocol Accelerator (COPA)\nprovides a customizable FPGA framework that integrates both hardware and\nsoftware development to improve computation and communication performance. In\nthis first case study, we demonstrate the capabilities of the COPA framework\nwith an application from cryptography -- secure Multi-Party Computation (MPC)\n-- that utilizes hardware accelerators connected directly to host memory and\nthe COPA network. We find that using the COPA framework gives significant\nimprovements to both computation and communication as compared to traditional\nimplementations of MPC that use CPUs and NICs. A single MPC accelerator running\non COPA enables more than 17Gbps of communication bandwidth while using only 1%\nof Stratix 10 resources. We show that utilizing the COPA framework enables\nmultiple MPC accelerators running in parallel to fully saturate a 100Gbps link\nenabling higher performance compared to traditional NICs.",
    "descriptor": "",
    "authors": [
      "Rushi Patel",
      "Pouya Haghi",
      "Shweta Jain",
      "Andriy Kot",
      "Venkata Krishnan",
      "Mayank Varia",
      "Martin Herbordt"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2204.04816"
  },
  {
    "id": "arXiv:2204.04817",
    "title": "Effective Mutation Rate Adaptation through Group Elite Selection",
    "abstract": "Evolutionary algorithms are sensitive to the mutation rate (MR); no single\nvalue of this parameter works well across domains. Self-adaptive MR approaches\nhave been proposed but they tend to be brittle: Sometimes they decay the MR to\nzero, thus halting evolution. To make self-adaptive MR robust, this paper\nintroduces the Group Elite Selection of Mutation Rates (GESMR) algorithm. GESMR\nco-evolves a population of solutions and a population of MRs, such that each MR\nis assigned to a group of solutions. The resulting best mutational change in\nthe group, instead of average mutational change, is used for MR selection\nduring evolution, thus avoiding the vanishing MR problem. With the same number\nof function evaluations and with almost no overhead, GESMR converges faster and\nto better solutions than previous approaches on a wide range of continuous test\noptimization problems. GESMR also scales well to high-dimensional\nneuroevolution for supervised image-classification tasks and for reinforcement\nlearning control tasks. Remarkably, GESMR produces MRs that are optimal in the\nlong-term, as demonstrated through a comprehensive look-ahead grid search.\nThus, GESMR and its theoretical and empirical analysis demonstrate how\nself-adaptation can be harnessed to improve performance in several applications\nof evolutionary computation.",
    "descriptor": "\nComments: 14 pages, 9 figures, GECCO 2022\n",
    "authors": [
      "Akarsh Kumar",
      "Bo Liu",
      "Risto Miikkulainen",
      "Peter Stone"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.04817"
  },
  {
    "id": "arXiv:2204.04821",
    "title": "Markov categories, causal theories, and the do-calculus",
    "abstract": "We give a category-theoretic treatment of causal models that formalizes the\nsyntax for causal reasoning over a directed acyclic graph (DAG) by associating\na free Markov category with the DAG in a canonical way. This framework enables\nus to define and study important concepts in causal reasoning from an abstract\nand \"purely causal\" point of view, such as causal independence/separation,\ncausal conditionals, and decomposition of intervention effects. Our results\nregarding these concepts abstract away from the details of the commonly adopted\ncausal models such as (recursive) structural equation models or causal Bayesian\nnetworks. They are therefore more widely applicable and in a way conceptually\nclearer. Our results are also intimately related to Judea Pearl's celebrated\ndo-calculus, and yield a syntactic version of a core part of the calculus that\nis inherited in all causal models. In particular, it induces a simpler and\nspecialized version of Pearl's do-calculus in the context of causal Bayesian\nnetworks, which we show is as strong as the full version.",
    "descriptor": "",
    "authors": [
      "Yimu Yin",
      "Jiji Zhang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)",
      "Category Theory (math.CT)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2204.04821"
  },
  {
    "id": "arXiv:2204.04823",
    "title": "ACuTE: Automatic Curriculum Transfer from Simple to Complex Environments",
    "abstract": "Despite recent advances in Reinforcement Learning (RL), many problems,\nespecially real-world tasks, remain prohibitively expensive to learn. To\naddress this issue, several lines of research have explored how tasks, or data\nsamples themselves, can be sequenced into a curriculum to learn a problem that\nmay otherwise be too difficult to learn from scratch. However, generating and\noptimizing a curriculum in a realistic scenario still requires extensive\ninteractions with the environment. To address this challenge, we formulate the\ncurriculum transfer problem, in which the schema of a curriculum optimized in a\nsimpler, easy-to-solve environment (e.g., a grid world) is transferred to a\ncomplex, realistic scenario (e.g., a physics-based robotics simulation or the\nreal world). We present \"ACuTE\", Automatic Curriculum Transfer from Simple to\nComplex Environments, a novel framework to solve this problem, and evaluate our\nproposed method by comparing it to other baseline approaches (e.g., domain\nadaptation) designed to speed up learning. We observe that our approach\nproduces improved jumpstart and time-to-threshold performance even when adding\ntask elements that further increase the difficulty of the realistic scenario.\nFinally, we demonstrate that our approach is independent of the learning\nalgorithm used for curriculum generation, and is Sim2Real transferable to a\nreal world scenario using a physical robot.",
    "descriptor": "",
    "authors": [
      "Yash Shukla",
      "Christopher Thierauf",
      "Ramtin Hosseini",
      "Gyan Tatiya",
      "Jivko Sinapov"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2204.04823"
  },
  {
    "id": "arXiv:2204.04826",
    "title": "Equilibrium Finding in Normal-Form Games Via Greedy Regret Minimization",
    "abstract": "We extend the classic regret minimization framework for approximating\nequilibria in normal-form games by greedily weighing iterates based on regrets\nobserved at runtime. Theoretically, our method retains all previous convergence\nrate guarantees. Empirically, experiments on large randomly generated games and\nnormal-form subgames of the AI benchmark Diplomacy show that greedy weights\noutperforms previous methods whenever sampling is used, sometimes by several\norders of magnitude.",
    "descriptor": "\nComments: AAAI 2022\n",
    "authors": [
      "Hugh Zhang",
      "Adam Lerer",
      "Noam Brown"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2204.04826"
  },
  {
    "id": "arXiv:2204.04828",
    "title": "Improved Approximations for Euclidean $k$-means and $k$-median, via  Nested Quasi-Independent Sets",
    "abstract": "Motivated by data analysis and machine learning applications, we consider the\npopular high-dimensional Euclidean $k$-median and $k$-means problems. We\npropose a new primal-dual algorithm, inspired by the classic algorithm of Jain\nand Vazirani and the recent algorithm of Ahmadian, Norouzi-Fard, Svensson, and\nWard. Our algorithm achieves an approximation ratio of $2.406$ and $5.912$ for\nEuclidean $k$-median and $k$-means, respectively, improving upon the 2.633\napproximation ratio of Ahmadian et al. and the 6.1291 approximation ratio of\nGrandoni, Ostrovsky, Rabani, Schulman, and Venkat.\nOur techniques involve a much stronger exploitation of the Euclidean metric\nthan previous work on Euclidean clustering. In addition, we introduce a new\nmethod of removing excess centers using a variant of independent sets over\ngraphs that we dub a \"nested quasi-independent set\". In turn, this technique\nmay be of interest for other optimization problems in Euclidean and $\\ell_p$\nmetric spaces.",
    "descriptor": "\nComments: 74 pages. To appear in Symposium on Theory of Computing (STOC), 2022\n",
    "authors": [
      "Vincent Cohen-Addad",
      "Hossein Esfandiari",
      "Vahab Mirrokni",
      "Shyam Narayanan"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Geometry (cs.CG)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.04828"
  },
  {
    "id": "arXiv:2204.04830",
    "title": "A parallel iterative procedure for weak Galerkin methods for second  order elliptic problems",
    "abstract": "A parallelizable iterative procedure based on domain decomposition is\npresented and analyzed for weak Galerkin finite element methods for second\norder elliptic equations. The convergence analysis is established for the\ndecomposition of the domain into individual elements associated to the weak\nGalerkin methods or into larger subdomains. A series of numerical tests are\nillustrated to verify the theory developed in this paper.",
    "descriptor": "\nComments: 18 pages, 4 figures, 12 tables\n",
    "authors": [
      "Chunmei Wang",
      "Junping Wang",
      "Shangyou Zhang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2204.04830"
  },
  {
    "id": "arXiv:2204.04831",
    "title": "Cello: Efficient Computer Systems Optimization with Predictive Early  Termination and Censored Regression",
    "abstract": "Sample-efficient machine learning (SEML) has been widely applied to find\noptimal latency and power tradeoffs for configurable computer systems. Instead\nof randomly sampling from the configuration space, SEML reduces the search cost\nby dramatically reducing the number of configurations that must be sampled to\noptimize system goals (e.g., low latency or energy). Nevertheless, SEML only\nreduces one component of cost -- the total number of samples collected -- but\ndoes not decrease the cost of collecting each sample. Critically, not all\nsamples are equal; some take much longer to collect because they correspond to\nslow system configurations. This paper present Cello, a computer systems\noptimization framework that reduces sample collection costs -- especially those\nthat come from the slowest configurations. The key insight is to predict ahead\nof time whether samples will have poor system behavior (e.g., long latency or\nhigh energy) and terminate these samples early before their measured system\nbehavior surpasses the termination threshold, which we call it predictive early\ntermination. To predict the future system behavior accurately before it\nmanifests as high runtime or energy, Cello uses censored regression to produces\naccurate predictions for running samples. We evaluate Cello by optimizing\nlatency and energy for Apache Spark workloads. We give Cello a fixed amount of\ntime to search a combined space of hardware and software configuration\nparameters. Our evaluation shows that compared to the state-of-the-art SEML\napproach in computer systems optimization, Cello improves latency by 1.19X for\nminimizing latency under a power constraint, and improves energy by 1.18X for\nminimizing energy under a latency constraint.",
    "descriptor": "",
    "authors": [
      "Yi Ding",
      "Alex Renda",
      "Ahsan Pervaiz",
      "Michael Carbin",
      "Henry Hoffmann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Hardware Architecture (cs.AR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2204.04831"
  },
  {
    "id": "arXiv:2204.04832",
    "title": "The Complexity of Temporal Vertex Cover in Small-Degree Graphs",
    "abstract": "Temporal graphs naturally model graphs whose underlying topology changes over\ntime. Recently, the problems TEMPORAL VERTEX COVER (or TVC) and SLIDING-WINDOW\nTEMPORAL VERTEX COVER(or $\\Delta$-TVC for time-windows of a fixed-length\n$\\Delta$) have been established as natural extensions of the classic problem\nVERTEX COVER on static graphs with connections to areas such as surveillance in\nsensor networks. In this paper we initiate a systematic study of the complexity\nof TVC and $\\Delta$-TVC on sparse graphs. Our main result shows that for every\n$\\Delta\\geq 2$, $\\Delta$-TVC is NP-hard even when the underlying topology is\ndescribed by a path or a cycle. This resolves an open problem from literature\nand shows a surprising contrast between $\\Delta$-TVC and TVC for which we\nprovide a polynomial-time algorithm in the same setting. To circumvent this\nhardness, we present a number of exact and approximation algorithms for\ntemporal graphs whose underlying topologies are given by a path, that have\nbounded vertex degree in every time step, or that admit a small-sized temporal\nvertex cover.",
    "descriptor": "",
    "authors": [
      "Thekla Hamm",
      "Nina Klobas",
      "George B. Mertzios",
      "Paul G. Spirakis"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2204.04832"
  },
  {
    "id": "arXiv:2204.04833",
    "title": "Word Embeddings Are Capable of Capturing Rhythmic Similarity of Words",
    "abstract": "Word embedding systems such as Word2Vec and GloVe are well-known in deep\nlearning approaches to NLP. This is largely due to their ability to capture\nsemantic relationships between words. In this work we investigated their\nusefulness in capturing rhythmic similarity of words instead. The results show\nthat vectors these embeddings assign to rhyming words are more similar to each\nother, compared to the other words. It is also revealed that GloVe performs\nrelatively better than Word2Vec in this regard. We also proposed a first of its\nkind metric for quantifying rhythmic similarity of a pair of words.",
    "descriptor": "",
    "authors": [
      "Hosein Rezaei"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.04833"
  },
  {
    "id": "arXiv:2204.04836",
    "title": "Consistency Learning via Decoding Path Augmentation for Transformers in  Human Object Interaction Detection",
    "abstract": "Human-Object Interaction detection is a holistic visual recognition task that\nentails object detection as well as interaction classification. Previous works\nof HOI detection has been addressed by the various compositions of subset\npredictions, e.g., Image -> HO -> I, Image -> HI -> O. Recently, transformer\nbased architecture for HOI has emerged, which directly predicts the HOI\ntriplets in an end-to-end fashion (Image -> HOI). Motivated by various\ninference paths for HOI detection, we propose cross-path consistency learning\n(CPC), which is a novel end-to-end learning strategy to improve HOI detection\nfor transformers by leveraging augmented decoding paths. CPC learning enforces\nall the possible predictions from permuted inference sequences to be\nconsistent. This simple scheme makes the model learn consistent\nrepresentations, thereby improving generalization without increasing model\ncapacity. Our experiments demonstrate the effectiveness of our method, and we\nachieved significant improvement on V-COCO and HICO-DET compared to the\nbaseline models. Our code is available at https://github.com/mlvlab/CPChoi.",
    "descriptor": "\nComments: CVPR2022 accepted\n",
    "authors": [
      "Jihwan Park",
      "SeungJun Lee",
      "Hwan Heo",
      "Hyeong Kyu Choi",
      "Hyunwoo J.Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.04836"
  },
  {
    "id": "arXiv:2204.04837",
    "title": "Dependable Intrusion Detection System for IoT: A Deep Transfer  Learning-based Approach",
    "abstract": "Security concerns for IoT applications have been alarming because of their\nwidespread use in different enterprise systems. The potential threats to these\napplications are constantly emerging and changing, and therefore, sophisticated\nand dependable defense solutions are necessary against such threats. With the\nrapid development of IoT networks and evolving threat types, the traditional\nmachine learning-based IDS must update to cope with the security requirements\nof the current sustainable IoT environment. In recent years, deep learning, and\ndeep transfer learning have progressed and experienced great success in\ndifferent fields and have emerged as a potential solution for dependable\nnetwork intrusion detection. However, new and emerging challenges have arisen\nrelated to the accuracy, efficiency, scalability, and dependability of the\ntraditional IDS in a heterogeneous IoT setup. This manuscript proposes a deep\ntransfer learning-based dependable IDS model that outperforms several existing\napproaches. The unique contributions include effective attribute selection,\nwhich is best suited to identify normal and attack scenarios for a small amount\nof labeled data, designing a dependable deep transfer learning-based ResNet\nmodel, and evaluating considering real-world data. To this end, a comprehensive\nexperimental performance evaluation has been conducted. Extensive analysis and\nperformance evaluation show that the proposed model is robust, more efficient,\nand has demonstrated better performance, ensuring dependability.",
    "descriptor": "\nComments: 12 pages, 13 Figures, 4 tables IEEE Transaction\n",
    "authors": [
      "Sk. Tanzir Mehedi",
      "Adnan Anwar",
      "Ziaur Rahman",
      "Kawsar Ahmed",
      "Rafiqul Islam"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.04837"
  },
  {
    "id": "arXiv:2204.04841",
    "title": "Autonomous Mobile Clinics: Empowering Affordable Anywhere Anytime  Healthcare Access",
    "abstract": "We are facing a global healthcare crisis today as the healthcare cost is ever\nclimbing, but with the aging population, government fiscal revenue is ever\ndropping. To create a more efficient and effective healthcare system, three\ntechnical challenges immediately present themselves: healthcare access,\nhealthcare equity, and healthcare efficiency. An autonomous mobile clinic\nsolves the healthcare access problem by bringing healthcare services to the\npatient by the order of the patient's fingertips. Nevertheless, to enable a\nuniversal autonomous mobile clinic network, a three-stage technical roadmap\nneeds to be achieved: In stage one, we focus on solving the inequity challenge\nin the existing healthcare system by combining autonomous mobility and\ntelemedicine. In stage two, we develop an AI doctor for primary care, which we\nfoster from infancy to adulthood with clean healthcare data. With the AI\ndoctor, we can solve the inefficiency problem. In stage three, after we have\nproven that the autonomous mobile clinic network can truly solve the target\nclinical use cases, we shall open up the platform for all medical verticals,\nthus enabling universal healthcare through this whole new system.",
    "descriptor": "\nComments: 5 pages, 1 figure\n",
    "authors": [
      "Shaoshan Liu",
      "Yuzhang Huang",
      "Leiyu Shi"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.04841"
  },
  {
    "id": "arXiv:2204.04842",
    "title": "Towards Homogeneous Modality Learning and Multi-Granularity Information  Exploration for Visible-Infrared Person Re-Identification",
    "abstract": "Visible-infrared person re-identification (VI-ReID) is a challenging and\nessential task, which aims to retrieve a set of person images over visible and\ninfrared camera views. In order to mitigate the impact of large modality\ndiscrepancy existing in heterogeneous images, previous methods attempt to apply\ngenerative adversarial network (GAN) to generate the modality-consisitent data.\nHowever, due to severe color variations between the visible domain and infrared\ndomain, the generated fake cross-modality samples often fail to possess good\nqualities to fill the modality gap between synthesized scenarios and target\nreal ones, which leads to sub-optimal feature representations. In this work, we\naddress cross-modality matching problem with Aligned Grayscale Modality (AGM),\nan unified dark-line spectrum that reformulates visible-infrared dual-mode\nlearning as a gray-gray single-mode learning problem. Specifically, we generate\nthe grasycale modality from the homogeneous visible images. Then, we train a\nstyle tranfer model to transfer infrared images into homogeneous grayscale\nimages. In this way, the modality discrepancy is significantly reduced in the\nimage space. In order to reduce the remaining appearance discrepancy, we\nfurther introduce a multi-granularity feature extraction network to conduct\nfeature-level alignment. Rather than relying on the global information, we\npropose to exploit local (head-shoulder) features to assist person Re-ID, which\ncomplements each other to form a stronger feature descriptor. Comprehensive\nexperiments implemented on the mainstream evaluation datasets include SYSU-MM01\nand RegDB indicate that our method can significantly boost cross-modality\nretrieval performance against the state of the art methods.",
    "descriptor": "\nComments: 15 pages, 9figures\n",
    "authors": [
      "Haojie Liu",
      "Daoxun Xia",
      "Wei Jiang",
      "Chao Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.04842"
  },
  {
    "id": "arXiv:2204.04843",
    "title": "An Adaptive Alternating-direction-method-based Nonnegative Latent Factor  Model",
    "abstract": "An alternating-direction-method-based nonnegative latent factor model can\nperform efficient representation learning to a high-dimensional and incomplete\n(HDI) matrix. However, it introduces multiple hyper-parameters into the\nlearning process, which should be chosen with care to enable its superior\nperformance. Its hyper-parameter adaptation is desired for further enhancing\nits scalability. Targeting at this issue, this paper proposes an Adaptive\nAlternating-direction-method-based Nonnegative Latent Factor (A2NLF) model,\nwhose hyper-parameter adaptation is implemented following the principle of\nparticle swarm optimization. Empirical studies on nonnegative HDI matrices\ngenerated by industrial applications indicate that A2NLF outperforms several\nstate-of-the-art models in terms of computational and storage efficiency, as\nwell as maintains highly competitive estimation accuracy for an HDI matrix's\nmissing data.",
    "descriptor": "",
    "authors": [
      "Yurong Zhong",
      "Xin Luo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.04843"
  },
  {
    "id": "arXiv:2204.04844",
    "title": "HFL at SemEval-2022 Task 8: A Linguistics-inspired Regression Model with  Data Augmentation for Multilingual News Similarity",
    "abstract": "This paper describes our system designed for SemEval-2022 Task 8:\nMultilingual News Article Similarity. We proposed a linguistics-inspired model\ntrained with a few task-specific strategies. The main techniques of our system\nare: 1) data augmentation, 2) multi-label loss, 3) adapted R-Drop, 4) samples\nreconstruction with the head-tail combination. We also present a brief analysis\nof some negative methods like two-tower architecture. Our system ranked 1st on\nthe leaderboard while achieving a Pearson's Correlation Coefficient of 0.818 on\nthe official evaluation set.",
    "descriptor": "\nComments: 6 pages; SemEval-2022 Task 8\n",
    "authors": [
      "Zihang Xu",
      "Ziqing Yang",
      "Yiming Cui",
      "Zhigang Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.04844"
  },
  {
    "id": "arXiv:2204.04851",
    "title": "A numerical algorithm for inverse problem from partial boundary  measurement arising from mean field game problem",
    "abstract": "In this work, we consider a novel inverse problem in mean-field games (MFG).\nWe aim to recover the MFG model parameters that govern the underlying\ninteractions among the population based on a limited set of noisy partial\nobservations of the population dynamics under the limited aperture. Due to its\nsevere ill-posedness, obtaining a good quality reconstruction is very\ndifficult. Nonetheless, it is vital to recover the model parameters stably and\nefficiently in order to uncover the underlying causes for population dynamics\nfor practical needs.\nOur work focuses on the simultaneous recovery of running cost and interaction\nenergy in the MFG equations from a \\emph{finite number of boundary\nmeasurements} of population profile and boundary movement. To achieve this\ngoal, we formalize the inverse problem as a constrained optimization problem of\na least squares residual functional under suitable norms. We then develop a\nfast and robust operator splitting algorithm to solve the optimization using\ntechniques including harmonic extensions, three-operator splitting scheme, and\nprimal-dual hybrid gradient method. Numerical experiments illustrate the\neffectiveness and robustness of the algorithm.",
    "descriptor": "",
    "authors": [
      "Yat Tin Chow",
      "Samy Wu Fung",
      "Siting Liu",
      "Levon Nurbekyan",
      "Stanley Osher"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2204.04851"
  },
  {
    "id": "arXiv:2204.04853",
    "title": "Neural Lagrangian Schr\u00f6dinger bridge",
    "abstract": "Population dynamics is the study of temporal and spatial variation in the\nsize of populations of organisms and is a major part of population ecology. One\nof the main difficulties in analyzing population dynamics is that we can only\nobtain observation data with coarse time intervals from fixed-point\nobservations due to experimental costs or other constraints. Recently, modeling\npopulation dynamics by using continuous normalizing flows (CNFs) and dynamic\noptimal transport has been proposed to infer the expected trajectory of samples\nfrom a fixed-point observed population. While the sample behavior in CNF is\ndeterministic, the actual sample in biological systems moves in an essentially\nrandom yet directional manner. Moreover, when a sample moves from point A to\npoint B in dynamical systems, its trajectory is such that the corresponding\naction has the smallest possible value, known as the principle of least action.\nTo satisfy these requirements of the sample trajectories, we formulate the\nLagrangian Schr\\\"odinger bridge (LSB) problem and propose to solve it\napproximately using neural SDE with regularization. We also develop a model\narchitecture that enables faster computation. Our experiments show that our\nsolution to the LSB problem can approximate the dynamics at the population\nlevel and that using the prior knowledge introduced by the Lagrangian enables\nus to estimate the trajectories of individual samples with stochastic behavior.",
    "descriptor": "",
    "authors": [
      "Takeshi Koshizuka",
      "Issei Sato"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Populations and Evolution (q-bio.PE)"
    ],
    "url": "https://arxiv.org/abs/2204.04853"
  },
  {
    "id": "arXiv:2204.04855",
    "title": "Fusion of Self-supervised Learned Models for MOS Prediction",
    "abstract": "We participated in the mean opinion score (MOS) prediction challenge, 2022.\nThis challenge aims to predict MOS scores of synthetic speech on two tracks,\nthe main track and a more challenging sub-track: out-of-domain (OOD). To\nimprove the accuracy of the predicted scores, we have explored several model\nfusion-related strategies and proposed a fused framework in which seven\npretrained self-supervised learned (SSL) models have been engaged. These\npretrained SSL models are derived from three ASR frameworks, including Wav2Vec,\nHubert, and WavLM. For the OOD track, we followed the 7 SSL models selected on\nthe main track and adopted a semi-supervised learning method to exploit the\nunlabeled data. According to the official analysis results, our system has\nachieved 1st rank in 6 out of 16 metrics and is one of the top 3 systems for 13\nout of 16 metrics. Specifically, we have achieved the highest LCC, SRCC, and\nKTAU scores at the system level on main track, as well as the best performance\non the LCC, SRCC, and KTAU evaluation metrics at the utterance level on OOD\ntrack. Compared with the basic SSL models, the prediction accuracy of the fused\nsystem has been largely improved, especially on OOD sub-track.",
    "descriptor": "\nComments: MOS 2022 shared task system description paper\n",
    "authors": [
      "Zhengdong Yang",
      "Wangjin Zhou",
      "Chenhui Chu",
      "Sheng Li",
      "Raj Dabre",
      "Raphael Rubino",
      "Yi Zhao"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2204.04855"
  },
  {
    "id": "arXiv:2204.04856",
    "title": "Defect Identification, Categorization, and Repair: Better Together",
    "abstract": "Just-In-Time defect prediction (JIT-DP) models can identify defect-inducing\ncommits at check-in time. Even though previous studies have achieved a great\nprogress, these studies still have the following limitations: 1) useful\ninformation (e.g., semantic information and structure information) are not\nfully used; 2) existing work can only predict a commit as buggy one or clean\none without more information about what type of defect it is; 3) a commit may\ninvolve changes in many files, which cause difficulty in locating the defect;\n4) prior studies treat defect identification and defect repair as separate\ntasks, none aims to handle both tasks simultaneously. In this paper, to handle\naforementioned limitations, we propose a comprehensive defect prediction and\nrepair framework named CompDefect, which can identify whether a changed\nfunction (a more fine-grained level) is defect-prone, categorize the type of\ndefect, and repair such a defect automatically if it falls into several\nscenarios, e.g., defects with single statement fixes, or those that match a\nsmall set of defect templates. Generally, the first two tasks in CompDefect are\ntreated as a multiclass classification task, while the last one is treated as a\nsequence generation task. The whole input of CompDefect consists of three parts\n(exampled with positive functions): the clean version of a function (i.e., the\nversion before defect introduced), the buggy version of a function and the\nfixed version of a function. In multiclass classification task, CompDefect\ncategorizes the type of defect via multiclass classification with the\ninformation in both the clean version and the buggy version. In code sequence\ngeneration task, CompDefect repairs the defect once identified or keeps it\nunchanged.",
    "descriptor": "\nComments: 22 pages, 4 figures\n",
    "authors": [
      "Chao Ni",
      "Kaiwen Yang",
      "Xin Xia",
      "David Lo",
      "Xiang Chen",
      "Xiaohu Yang"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2204.04856"
  },
  {
    "id": "arXiv:2204.04857",
    "title": "Why Shape Coding? Asymptotic Analysis of the Entropy Rate for Digital  Images",
    "abstract": "This paper focuses on the ultimate limit theory of image compression. It\nproves that for an image source, there exists a coding method with shapes that\ncan achieve the entropy rate under a certain condition where the shape-pixel\nratio in the encoder/decoder is $O({1 \\over {\\log t}})$. Based on the new\nfinding, an image coding framework with shapes is proposed and proved to be\nasymptotically optimal for stationary and ergodic processes.",
    "descriptor": "",
    "authors": [
      "Gangtao Xin",
      "Pingyi Fan",
      "Khaled B. Letaief"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Image and Video Processing (eess.IV)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2204.04857"
  },
  {
    "id": "arXiv:2204.04858",
    "title": "Stability and Generalization of Differentially Private Minimax Problems",
    "abstract": "In the field of machine learning, many problems can be formulated as the\nminimax problem, including reinforcement learning, generative adversarial\nnetworks, to just name a few. So the minimax problem has attracted a huge\namount of attentions from researchers in recent decades. However, there is\nrelatively little work on studying the privacy of the general minimax paradigm.\nIn this paper, we focus on the privacy of the general minimax setting,\ncombining differential privacy together with minimax optimization paradigm.\nBesides, via algorithmic stability theory, we theoretically analyze the high\nprobability generalization performance of the differentially private minimax\nalgorithm under the strongly-convex-strongly-concave condition. To the best of\nour knowledge, this is the first time to analyze the generalization performance\nof general minimax paradigm, taking differential privacy into account.",
    "descriptor": "",
    "authors": [
      "Yilin Kang",
      "Yong Liu",
      "Jian Li",
      "Weiping Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2204.04858"
  },
  {
    "id": "arXiv:2204.04859",
    "title": "A Survey on Legal Judgment Prediction: Datasets, Metrics, Models and  Challenges",
    "abstract": "Legal judgment prediction (LJP) applies Natural Language Processing (NLP)\ntechniques to predict judgment results based on fact descriptions\nautomatically. Recently, large-scale public datasets and advances in NLP\nresearch have led to increasing interest in LJP. Despite a clear gap between\nmachine and human performance, impressive results have been achieved in various\nbenchmark datasets. In this paper, to address the current lack of comprehensive\nsurvey of existing LJP tasks, datasets, models and evaluations, (1) we analyze\n31 LJP datasets in 6 languages, present their construction process and define a\nclassification method of LJP with 3 different attributes; (2) we summarize 14\nevaluation metrics under four categories for different outputs of LJP tasks;\n(3) we review 12 legal-domain pretrained models in 3 languages and highlight 3\nmajor research directions for LJP; (4) we show the state-of-art results for 8\nrepresentative datasets from different court cases and discuss the open\nchallenges. This paper can provide up-to-date and comprehensive reviews to help\nreaders understand the status of LJP. We hope to facilitate both NLP\nresearchers and legal professionals for further joint efforts in this problem.",
    "descriptor": "\nComments: 25 pages, 6 figures and 12 tables\n",
    "authors": [
      "Junyun Cui",
      "Xiaoyu Shen",
      "Feiping Nie",
      "Zheng Wang",
      "Jinglong Wang",
      "Yulong Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.04859"
  },
  {
    "id": "arXiv:2204.04861",
    "title": "SUMD: Super U-shaped Matrix Decomposition Convolutional neural network  for Image denoising",
    "abstract": "In this paper, we propose a novel and efficient CNN-based framework that\nleverages local and global context information for image denoising. Due to the\nlimitations of convolution itself, the CNN-based method is generally unable to\nconstruct an effective and structured global feature representation, usually\ncalled the long-distance dependencies in the Transformer-based method. To\ntackle this problem, we introduce the matrix decomposition module(MD) in the\nnetwork to establish the global context feature, comparable to the Transformer\nbased method performance. Inspired by the design of multi-stage progressive\nrestoration of U-shaped architecture, we further integrate the MD module into\nthe multi-branches to acquire the relative global feature representation of the\npatch range at the current stage. Then, the stage input gradually rises to the\noverall scope and continuously improves the final feature. Experimental results\non various image denoising datasets: SIDD, DND, and synthetic Gaussian noise\ndatasets show that our model(SUMD) can produce comparable visual quality and\naccuracy results with Transformer-based methods.",
    "descriptor": "",
    "authors": [
      "QiFan Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.04861"
  },
  {
    "id": "arXiv:2204.04862",
    "title": "Tweet Emotion Dynamics: Emotion Word Usage in Tweets from US and Canada",
    "abstract": "Over the last decade, Twitter has emerged as one of the most influential\nforums for social, political, and health discourse. In this paper, we introduce\na massive dataset of more than 45 million geo-located tweets posted between\n2015 and 2021 from US and Canada (TUSC), especially curated for natural\nlanguage analysis. We also introduce Tweet Emotion Dynamics (TED) -- metrics to\ncapture patterns of emotions associated with tweets over time. We use TED and\nTUSC to explore the use of emotion-associated words across US and Canada;\nacross 2019 (pre-pandemic), 2020 (the year the pandemic hit), and 2021 (the\nsecond year of the pandemic); and across individual tweeters. We show that\nCanadian tweets tend to have higher valence, lower arousal, and higher\ndominance than the US tweets. Further, we show that the COVID-19 pandemic had a\nmarked impact on the emotional signature of tweets posted in 2020, when\ncompared to the adjoining years. Finally, we determine metrics of TED for\n170,000 tweeters to benchmark characteristics of TED metrics at an aggregate\nlevel. TUSC and the metrics for TED will enable a wide variety of research on\nstudying how we use language to express ourselves, persuade, communicate, and\ninfluence, with particularly promising applications in public health, affective\nscience, social science, and psychology.",
    "descriptor": "\nComments: Accepted for publication at LREC 2022\n",
    "authors": [
      "Krishnapriya Vishnubhotla",
      "Saif M. Mohammad"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.04862"
  },
  {
    "id": "arXiv:2204.04865",
    "title": "A novel stereo matching pipeline with robustness and unfixed disparity  search range",
    "abstract": "Stereo matching is an essential basis for various applications, but most\nstereo matching methods have poor generalization performance and require a\nfixed disparity search range. Moreover, current stereo matching methods focus\non the scenes that only have positive disparities, but ignore the scenes that\ncontain both positive and negative disparities, such as 3D movies. In this\npaper, we present a new stereo matching pipeline that first computes semi-dense\ndisparity maps based on binocular disparity, and then completes the rest\ndepending on monocular cues. The new stereo matching pipeline have the\nfollowing advantages: It 1) has better generalization performance than most of\nthe current stereo matching methods; 2) relaxes the limitation of a fixed\ndisparity search range; 3) can handle the scenes that involve both positive and\nnegative disparities, which has more potential applications, such as view\nsynthesis in 3D multimedia and VR/AR. Experimental results demonstrate the\neffectiveness of our new stereo matching pipeline.",
    "descriptor": "\nComments: Accepted by IEEE International Conference on Multimedia and Expo (ICME) 2022\n",
    "authors": [
      "Jiazhi Liu",
      "Feng Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.04865"
  },
  {
    "id": "arXiv:2204.04867",
    "title": "Structured Graph Variational Autoencoders for Indoor Furniture layout  Generation",
    "abstract": "We present a structured graph variational autoencoder for generating the\nlayout of indoor 3D scenes. Given the room type (e.g., living room or library)\nand the room layout (e.g., room elements such as floor and walls), our\narchitecture generates a collection of objects (e.g., furniture items such as\nsofa, table and chairs) that is consistent with the room type and layout. This\nis a challenging problem because the generated scene should satisfy multiple\nconstrains, e.g., each object must lie inside the room and two objects cannot\noccupy the same volume. To address these challenges, we propose a deep\ngenerative model that encodes these relationships as soft constraints on an\nattributed graph (e.g., the nodes capture attributes of room and furniture\nelements, such as class, pose and size, and the edges capture geometric\nrelationships such as relative orientation). The architecture consists of a\ngraph encoder that maps the input graph to a structured latent space, and a\ngraph decoder that generates a furniture graph, given a latent code and the\nroom graph. The latent space is modeled with auto-regressive priors, which\nfacilitates the generation of highly structured scenes. We also propose an\nefficient training procedure that combines matching and constrained learning.\nExperiments on the 3D-FRONT dataset show that our method produces scenes that\nare diverse and are adapted to the room layout.",
    "descriptor": "",
    "authors": [
      "Aditya Chattopadhyay",
      "Xi Zhang",
      "David Paul Wipf",
      "Rene Vidal",
      "Himanshu Arora"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.04867"
  },
  {
    "id": "arXiv:2204.04868",
    "title": "On complex roots of the independence polynomial",
    "abstract": "It is known from the work of Shearer (1985) (and also Scott and Sokal (2005))\nthat the independence polynomial $Z_G(\\lambda)$ of a graph $G$ of maximum\ndegree at most $d+1$ does not vanish provided that $\\vert{\\lambda}\\vert \\leq\n\\frac{d^d}{(d+1)^{d+1}}$. Significant extensions of this result have recently\nbeen given in the case $\\Re \\lambda \\geq 0$ by Peters and Regts (2019) and\nBencs and Csikv\\'ari (arxiv:1807.08963). In this paper, our motivation is to\nfurther extend these results and find zero free regions when $\\Re \\lambda \\leq\n0$.\nWe begin by giving new geometric criteria for establishing zero-free regions\nas well as for carrying out semi-rigorous numerical explorations. We then\nprovide two examples of the (rigorous) use of these criteria, by establishing\ntwo new zero-free regions in the left-half plane. We also improve upon the\nresults of Bencs and P\\'eter Csikv\\'ari (arxiv:1807.08963) for the right\nhalf-plane using our framework. By a direct application of the interpolation\nmethod of Barvinok, combined with extensions due to Patel and Regts, these\nresults also imply deterministic polynomial time approximation algorithms for\nthe independence polynomial of bounded degree graphs in the new zero-free\nregions.",
    "descriptor": "",
    "authors": [
      "Ferenc Bencs",
      "P\u00e9ter Csikv\u00e1ri",
      "Piyush Srivastava",
      "Jan Vondr\u00e1k"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)",
      "Mathematical Physics (math-ph)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2204.04868"
  },
  {
    "id": "arXiv:2204.04869",
    "title": "Evaluation of Automatic Text Summarization using Synthetic Facts",
    "abstract": "Despite some recent advances, automatic text summarization remains\nunreliable, elusive, and of limited practical use in applications. Two main\nproblems with current summarization methods are well known: evaluation and\nfactual consistency. To address these issues, we propose a new automatic\nreference-less text summarization evaluation system that can measure the\nquality of any text summarization model with a set of generated facts based on\nfactual consistency, comprehensiveness, and compression rate. As far as we\nknow, our evaluation system is the first system that measures the overarching\nquality of the text summarization models based on factuality, information\ncoverage, and compression rate.",
    "descriptor": "",
    "authors": [
      "Jay Ahn",
      "Foaad Khosmood"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.04869"
  },
  {
    "id": "arXiv:2204.04873",
    "title": "Adapting BigScience Multilingual Model to Unseen Languages",
    "abstract": "We benchmark different strategies of adding new languages (German and Korean)\ninto the BigScience's pretrained multilingual language model with 1.3 billion\nparameters that currently supports 13 languages. We investigate the factors\nthat affect the language adaptability of the model and the trade-offs between\ncomputational costs and expected performance.",
    "descriptor": "",
    "authors": [
      "Zheng-Xin Yong",
      "Vassilina Nikoulina"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.04873"
  },
  {
    "id": "arXiv:2204.04874",
    "title": "Augmentation-Free Graph Contrastive Learning",
    "abstract": "Graph contrastive learning (GCL) is the most representative and prevalent\nself-supervised learning approach for graph-structured data. Despite its\nremarkable success, existing GCL methods highly rely on an augmentation scheme\nto learn the representations invariant across different augmentation views. In\nthis work, we revisit such a convention in GCL through examining the effect of\naugmentation techniques on graph data via the lens of spectral theory. We found\nthat graph augmentations preserve the low-frequency components and perturb the\nmiddle- and high-frequency components of the graph, which contributes to the\nsuccess of GCL algorithms on homophilic graphs but hinders its application on\nheterophilic graphs, due to the high-frequency preference of heterophilic data.\nMotivated by this, we propose a novel, theoretically-principled, and\naugmentation-free GCL method, named AF-GCL, that (1) leverages the features\naggregated by Graph Neural Network to construct the self-supervision signal\ninstead of augmentations and therefore (2) is less sensitive to the graph\nhomophily degree. Theoretically, We present the performance guarantee for\nAF-GCL as well as an analysis for understanding the efficacy of AF-GCL.\nExtensive experiments on 14 benchmark datasets with varying degrees of\nheterophily show that AF-GCL presents competitive or better performance on\nhomophilic graphs and outperforms all existing state-of-the-art GCL methods on\nheterophilic graphs with significantly less computational overhead.",
    "descriptor": "",
    "authors": [
      "Haonan Wang",
      "Jieyu Zhang",
      "Qi Zhu",
      "Wei Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2204.04874"
  },
  {
    "id": "arXiv:2204.04876",
    "title": "Lyapunov-Guided Embedding for Hyperparameter Selection in Recurrent  Neural Networks",
    "abstract": "Recurrent Neural Networks (RNN) are ubiquitous computing systems for\nsequences and multivariate time series data. While several robust architectures\nof RNN are known, it is unclear how to relate RNN initialization, architecture,\nand other hyperparameters with accuracy for a given task. In this work, we\npropose to treat RNN as dynamical systems and to correlate hyperparameters with\naccuracy through Lyapunov spectral analysis, a methodology specifically\ndesigned for nonlinear dynamical systems. To address the fact that RNN features\ngo beyond the existing Lyapunov spectral analysis, we propose to infer relevant\nfeatures from the Lyapunov spectrum with an Autoencoder and an embedding of its\nlatent representation (AeLLE). Our studies of various RNN architectures show\nthat AeLLE successfully correlates RNN Lyapunov spectrum with accuracy.\nFurthermore, the latent representation learned by AeLLE is generalizable to\nnovel inputs from the same task and is formed early in the process of RNN\ntraining. The latter property allows for the prediction of the accuracy to\nwhich RNN would converge when training is complete. We conclude that\nrepresentation of RNN through Lyapunov spectrum along with AeLLE, and assists\nwith hyperparameter selection of RNN, provides a novel method for organization\nand interpretation of variants of RNN architectures.",
    "descriptor": "",
    "authors": [
      "Ryan Vogt",
      "Yang Zheng",
      "Eli Shlizerman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)",
      "Chaotic Dynamics (nlin.CD)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2204.04876"
  },
  {
    "id": "arXiv:2204.04878",
    "title": "Semantic Information Market For The Metaverse: An Auction Based Approach",
    "abstract": "In this paper, we address the networking and communications problems of\ncreating a digital copy in the Metaverse digital twin. Specifically, a virtual\nservice provider (VSP) which is responsible for creating and rendering the\nMetaverse, is required to use the data collected by IoT devices to create the\nvirtual copy of the physical world. However, due to the huge volume of the\ncollected data by IoT devices (e.g., images and videos) and the limited\nbandwidth, the VSP might become unable to retrieve all the required data from\nthe physical world. Furthermore, the Metaverse needs fast replication (e.g.,\nrendering) of the digital copy adding more restrictions on the data\ntransmission delay. To solve the aforementioned challenges, we propose to equip\nthe IoT devices with semantic information extraction algorithms to minimize the\nsize of the transmitted data over the wireless channels. Since many IoT devices\nwill be interested to sell their semantic information to the VSP, we propose a\ntruthful reverse auction mechanism that helps the VSP select only IoT devices\nthat can improve the quality of its virtual copy of objects through the\nsemantic information. We conduct extensive simulations on a dataset that\ncontains synchronized camera and radar images, and show that our novel design\nenables a fast replication of the digital copy with high accuracy.",
    "descriptor": "\nComments: 6 pages,5 figures\n",
    "authors": [
      "Lotfi Ismail",
      "Dusit Niyato",
      "Sumei Sun",
      "Dong In Kim",
      "Melike Erol-Kantarci",
      "Chunyan Miao"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2204.04878"
  },
  {
    "id": "arXiv:2204.04879",
    "title": "How to Find Your Friendly Neighborhood: Graph Attention Design with  Self-Supervision",
    "abstract": "Attention mechanism in graph neural networks is designed to assign larger\nweights to important neighbor nodes for better representation. However, what\ngraph attention learns is not understood well, particularly when graphs are\nnoisy. In this paper, we propose a self-supervised graph attention network\n(SuperGAT), an improved graph attention model for noisy graphs. Specifically,\nwe exploit two attention forms compatible with a self-supervised task to\npredict edges, whose presence and absence contain the inherent information\nabout the importance of the relationships between nodes. By encoding edges,\nSuperGAT learns more expressive attention in distinguishing mislinked\nneighbors. We find two graph characteristics influence the effectiveness of\nattention forms and self-supervision: homophily and average degree. Thus, our\nrecipe provides guidance on which attention design to use when those two graph\ncharacteristics are known. Our experiment on 17 real-world datasets\ndemonstrates that our recipe generalizes across 15 datasets of them, and our\nmodels designed by recipe show improved performance over baselines.",
    "descriptor": "\nComments: ICLR 2021\n",
    "authors": [
      "Dongkwan Kim",
      "Alice Oh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2204.04879"
  },
  {
    "id": "arXiv:2204.04883",
    "title": "Accurate Portraits of Scientific Resources and Knowledge Service  Components",
    "abstract": "With the advent of the cloud computing era, the cost of creating, capturing\nand managing information has gradually decreased. The amount of data in the\nInternet is also showing explosive growth, and more and more scientific and\ntechnological resources are uploaded to the network. Different from news and\nsocial media data ubiquitous in the Internet, the main body of scientific and\ntechnological resources is composed of academic-style resources or entities\nsuch as papers, patents, authors, and research institutions. There is a rich\nrelationship network between resources, from which a large amount of\ncutting-edge scientific and technological information can be mined. There are a\nlarge number of management and classification standards for existing scientific\nand technological resources, but these standards are difficult to completely\ncover all entities and associations of scientific and technological resources,\nand cannot accurately extract important information contained in scientific and\ntechnological resources. How to construct a complete and accurate\nrepresentation of scientific and technological resources from structured and\nunstructured reports and texts in the network, and how to tap the potential\nvalue of scientific and technological resources is an urgent problem. The\nsolution is to construct accurate portraits of scientific and technological\nresources in combination with knowledge graph related technologies.",
    "descriptor": "\nComments: 9 pages\n",
    "authors": [
      "Yue Wang",
      "Zhe Xue",
      "Ang Li"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.04883"
  },
  {
    "id": "arXiv:2204.04887",
    "title": "Research on Cross-media Science and Technology Information Data  Retrieval",
    "abstract": "Since the era of big data, the Internet has been flooded with all kinds of\ninformation. Browsing information through the Internet has become an integral\npart of people's daily life. Unlike the news data and social data in the\nInternet, the cross-media technology information data has different\ncharacteristics. This data has become an important basis for researchers and\nscholars to track the current hot spots and explore the future direction of\ntechnology development. As the volume of science and technology information\ndata becomes richer, the traditional science and technology information\nretrieval system, which only supports unimodal data retrieval and uses outdated\ndata keyword matching model, can no longer meet the daily retrieval needs of\nscience and technology scholars. Therefore, in view of the above research\nbackground, it is of profound practical significance to study the cross-media\nscience and technology information data retrieval system based on deep semantic\nfeatures, which is in line with the development trend of domestic and\ninternational technologies.",
    "descriptor": "\nComments: 7 pages\n",
    "authors": [
      "Yang Jiang",
      "Zhe Xue",
      "Ang Li"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.04887"
  },
  {
    "id": "arXiv:2204.04888",
    "title": "Knowledge Graph and Accurate Portrait Construction of Scientific and  Technological Academic Conferences",
    "abstract": "In recent years, with the continuous progress of science and technology, the\nnumber of scientific research achievements is increasing day by day, as the\nexchange platform and medium of scientific research achievements, the\nscientific and technological academic conferences have become more and more\nabundant. The convening of scientific and technological academic conferences\nwill bring large number of academic papers, researchers, research institutions\nand other data, and the massive data brings difficulties for researchers to\nobtain valuable information. Therefore, it is of great significance to use deep\nlearning technology to mine the core information in the data of scientific and\ntechnological academic conferences, and to realize a knowledge graph and\naccurate portrait system of scientific and technological academic conferences,\nso that researchers can obtain scientific research information faster.",
    "descriptor": "\nComments: 14 pages\n",
    "authors": [
      "Runyu Yu",
      "Zhe Xue",
      "Ang Li"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.04888"
  },
  {
    "id": "arXiv:2204.04890",
    "title": "Anti-Adversarially Manipulated Attributions for Weakly Supervised  Semantic Segmentation and Object Localization",
    "abstract": "Obtaining accurate pixel-level localization from class labels is a crucial\nprocess in weakly supervised semantic segmentation and object localization.\nAttribution maps from a trained classifier are widely used to provide\npixel-level localization, but their focus tends to be restricted to a small\ndiscriminative region of the target object. An AdvCAM is an attribution map of\nan image that is manipulated to increase the classification score produced by a\nclassifier before the final softmax or sigmoid layer. This manipulation is\nrealized in an anti-adversarial manner, so that the original image is perturbed\nalong pixel gradients in directions opposite to those used in an adversarial\nattack. This process enhances non-discriminative yet class-relevant features,\nwhich make an insufficient contribution to previous attribution maps, so that\nthe resulting AdvCAM identifies more regions of the target object. In addition,\nwe introduce a new regularization procedure that inhibits the incorrect\nattribution of regions unrelated to the target object and the excessive\nconcentration of attributions on a small region of the target object. Our\nmethod achieves a new state-of-the-art performance in weakly and\nsemi-supervised semantic segmentation, on both the PASCAL VOC 2012 and MS COCO\n2014 datasets. In weakly supervised object localization, it achieves a new\nstate-of-the-art performance on the CUB-200-2011 and ImageNet-1K datasets.",
    "descriptor": "\nComments: IEEE TPAMI, 2022\n",
    "authors": [
      "Jungbeom Lee",
      "Eunji Kim",
      "Jisoo Mok",
      "Sungroh Yoon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.04890"
  },
  {
    "id": "arXiv:2204.04891",
    "title": "Methods of Informational Trends Analytics and Fake News Detection on  Twitter",
    "abstract": "In the paper, different approaches for the analysis of news trends on Twitter\nhas been considered. For the analysis and case study, informational trends on\nTwitter caused by Russian invasion of Ukraine in 2022 year have been studied. A\ndeep learning approach for fake news detection has been analyzed. The use of\nthe theory of frequent itemsets and association rules, graph theory for news\ntrends analytics have been considered.",
    "descriptor": "",
    "authors": [
      "Bohdan M. Pavlyshenko"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2204.04891"
  },
  {
    "id": "arXiv:2204.04892",
    "title": "JORLDY: a fully customizable open source framework for reinforcement  learning",
    "abstract": "Recently, Reinforcement Learning (RL) has been actively researched in both\nacademic and industrial fields. However, there exist only a few RL frameworks\nwhich are developed for researchers or students who want to study RL. In\nresponse, we propose an open-source RL framework \"Join Our Reinforcement\nLearning framework for Developing Yours\" (JORLDY). JORLDY provides more than 20\nwidely used RL algorithms which are implemented with Pytorch. Also, JORLDY\nsupports multiple RL environments which include OpenAI gym, Unity ML-Agents,\nMujoco, Super Mario Bros and Procgen. Moreover, the algorithmic components such\nas agent, network, environment can be freely customized, so that the users can\neasily modify and append algorithmic components. We expect that JORLDY will\nsupport various RL research and contribute further advance the field of RL. The\nsource code of JORLDY is provided on the following Github:\nhttps://github.com/kakaoenterprise/JORLDY",
    "descriptor": "\nComments: 12 pages, 6 figures\n",
    "authors": [
      "Kyushik Min",
      "Hyunho Lee",
      "Kwansu Shin",
      "Taehak Lee",
      "Hojoon Lee",
      "Jinwon Choi",
      "Sungho Son"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.04892"
  },
  {
    "id": "arXiv:2204.04898",
    "title": "PM4Py-GPU: a High-Performance General-Purpose Library for Process Mining",
    "abstract": "Open-source process mining provides many algorithms for the analysis of event\ndata which could be used to analyze mainstream processes (e.g., O2C, P2P, CRM).\nHowever, compared to commercial tools, they lack the performance and struggle\nto analyze large amounts of data. This paper presents PM4Py-GPU, a Python\nprocess mining library based on the NVIDIA RAPIDS framework. Thanks to the\ndataframe columnar storage and the high level of parallelism, a significant\nspeed-up is achieved on classic process mining computations and processing\nactivities.",
    "descriptor": "",
    "authors": [
      "Alessandro Berti",
      "Minh Phan Nghia",
      "Wil M.P. van der Aalst"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2204.04898"
  },
  {
    "id": "arXiv:2204.04900",
    "title": "Confusing Image Quality Assessment: Towards Better Augmented Reality  Experience",
    "abstract": "With the development of multimedia technology, Augmented Reality (AR) has\nbecome a promising next-generation mobile platform. The primary value of AR is\nto promote the fusion of digital contents and real-world environments, however,\nstudies on how this fusion will influence the Quality of Experience (QoE) of\nthese two components are lacking. To achieve better QoE of AR, whose two layers\nare influenced by each other, it is important to evaluate its perceptual\nquality first. In this paper, we consider AR technology as the superimposition\nof virtual scenes and real scenes, and introduce visual confusion as its basic\ntheory. A more general problem is first proposed, which is evaluating the\nperceptual quality of superimposed images, i.e., confusing image quality\nassessment. A ConFusing Image Quality Assessment (CFIQA) database is\nestablished, which includes 600 reference images and 300 distorted images\ngenerated by mixing reference images in pairs. Then a subjective quality\nperception study and an objective model evaluation experiment are conducted\ntowards attaining a better understanding of how humans perceive the confusing\nimages. An objective metric termed CFIQA is also proposed to better evaluate\nthe confusing image quality. Moreover, an extended ARIQA study is further\nconducted based on the CFIQA study. We establish an ARIQA database to better\nsimulate the real AR application scenarios, which contains 20 AR reference\nimages, 20 background (BG) reference images, and 560 distorted images generated\nfrom AR and BG references, as well as the correspondingly collected subjective\nquality ratings. We also design three types of full-reference (FR) IQA metrics\nto study whether we should consider the visual confusion when designing\ncorresponding IQA algorithms. An ARIQA metric is finally proposed for better\nevaluating the perceptual quality of AR images.",
    "descriptor": "",
    "authors": [
      "Huiyu Duan",
      "Xiongkuo Min",
      "Yucheng Zhu",
      "Guangtao Zhai",
      "Xiaokang Yang",
      "Patrick Le Callet"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2204.04900"
  },
  {
    "id": "arXiv:2204.04902",
    "title": "NeuS: Neutral Multi-News Summarization for Mitigating Framing Bias",
    "abstract": "Media framing bias can lead to increased political polarization, and thus,\nthe need for automatic mitigation methods is growing. We propose a new task, a\nneutral summary generation from multiple news headlines of the varying\npolitical spectrum, to facilitate balanced and unbiased news reading. In this\npaper, we first collect a new dataset, obtain some insights about framing bias\nthrough a case study, and propose a new effective metric and models for the\ntask. Lastly, we conduct experimental analyses to provide insights about\nremaining challenges and future directions. One of the most interesting\nobservations is that generation models can hallucinate not only factually\ninaccurate or unverifiable content, but also politically biased content.",
    "descriptor": "\nComments: NAACL2022 Long Paper\n",
    "authors": [
      "Nayeon Lee",
      "Yejin Bang",
      "Tiezheng Yu",
      "Andrea Madotto",
      "Pascale Fung"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.04902"
  },
  {
    "id": "arXiv:2204.04903",
    "title": "PICASSO: Unleashing the Potential of GPU-centric Training for  Wide-and-deep Recommender Systems",
    "abstract": "The development of personalized recommendation has significantly improved the\naccuracy of information matching and the revenue of e-commerce platforms.\nRecently, it has 2 trends: 1) recommender systems must be trained timely to\ncope with ever-growing new products and ever-changing user interests from\nonline marketing and social network; 2) SOTA recommendation models introduce\nDNN modules to improve prediction accuracy. Traditional CPU-based recommender\nsystems cannot meet these two trends, and GPU- centric training has become a\ntrending approach. However, we observe that GPU devices in training recommender\nsystems are underutilized, and they cannot attain an expected throughput\nimprovement as what it has achieved in CV and NLP areas. This issue can be\nexplained by two characteristics of these recommendation models: First, they\ncontain up to a thousand input feature fields, introducing fragmentary and\nmemory-intensive operations; Second, the multiple constituent feature\ninteraction submodules introduce substantial small-sized compute kernels. To\nremove this roadblock to the development of recommender systems, we propose a\nnovel framework named PICASSO to accelerate the training of recommendation\nmodels on commodity hardware. Specifically, we conduct a systematic analysis to\nreveal the bottlenecks encountered in training recommendation models. We\nleverage the model structure and data distribution to unleash the potential of\nhardware through our packing, interleaving, and caching optimization.\nExperiments show that PICASSO increases the hardware utilization by an order of\nmagnitude on the basis of SOTA baselines and brings up to 6x throughput\nimprovement for a variety of industrial recommendation models. Using the same\nhardware budget in production, PICASSO on average shortens the walltime of\ndaily training tasks by 7 hours, significantly reducing the delay of continuous\ndelivery.",
    "descriptor": "",
    "authors": [
      "Yuanxing Zhang",
      "Langshi Chen",
      "Siran Yang",
      "Man Yuan",
      "Huimin Yi",
      "Jie Zhang",
      "Jiamang Wang",
      "Jianbo Dong",
      "Yunlong Xu",
      "Yue Song",
      "Yong Li",
      "Di Zhang",
      "Wei Lin",
      "Lin Qu",
      "Bo Zheng"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2204.04903"
  },
  {
    "id": "arXiv:2204.04904",
    "title": "The Compact Genetic Algorithm Struggles on Cliff Functions",
    "abstract": "The compact genetic algorithm (cGA) is an non-elitist estimation of\ndistribution algorithm which has shown to be able to deal with difficult\nmultimodal fitness landscapes that are hard to solve by elitist algorithms. In\nthis paper, we investigate the cGA on the CLIFF function for which it has been\nshown recently that non-elitist evolutionary algorithms and artificial immune\nsystems optimize it in expected polynomial time. We point out that the cGA\nfaces major difficulties when solving the CLIFF function and investigate its\ndynamics both experimentally and theoretically around the cliff. Our\nexperimental results indicate that the cGA requires exponential time for all\nvalues of the update strength $K$. We show theoretically that, under sensible\nassumptions, there is a negative drift when sampling around the location of the\ncliff. Experiments further suggest that there is a phase transition for $K$\nwhere the expected optimization time drops from $n^{\\Theta(n)}$ to\n$2^{\\Theta(n)}$.",
    "descriptor": "\nComments: accepted at GECCO 2022\n",
    "authors": [
      "Frank Neumann",
      "Dirk Sudholt",
      "Carsten Witt"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2204.04904"
  },
  {
    "id": "arXiv:2204.04905",
    "title": "Evaluating Vision Transformer Methods for Deep Reinforcement Learning  from Pixels",
    "abstract": "Vision Transformers (ViT) have recently demonstrated the significant\npotential of transformer architectures for computer vision. To what extent can\nimage-based deep reinforcement learning also benefit from ViT architectures, as\ncompared to standard convolutional neural network (CNN) architectures? To\nanswer this question, we evaluate ViT training methods for image-based\nreinforcement learning (RL) control tasks and compare these results to a\nleading convolutional-network architecture method, RAD. For training the ViT\nencoder, we consider several recently-proposed self-supervised losses that are\ntreated as auxiliary tasks, as well as a baseline with no additional loss\nterms. We find that the CNN architectures trained using RAD still generally\nprovide superior performance. For the ViT methods, all three types of auxiliary\ntasks that we consider provide a benefit over plain ViT training. Furthermore,\nViT masking-based tasks are found to significantly outperform ViT\ncontrastive-learning.",
    "descriptor": "",
    "authors": [
      "Tianxin Tao",
      "Daniele Reda",
      "Michiel van de Panne"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2204.04905"
  },
  {
    "id": "arXiv:2204.04907",
    "title": "Same Author or Just Same Topic? Towards Content-Independent Style  Representations",
    "abstract": "Linguistic style is an integral component of language. Recent advances in the\ndevelopment of style representations have increasingly used training objectives\nfrom authorship verification (AV): Do two texts have the same author? The\nassumption underlying the AV training task (same author approximates same\nwriting style) enables self-supervised and, thus, extensive training. However,\na good performance on the AV task does not ensure good \"general-purpose\" style\nrepresentations. For example, as the same author might typically write about\ncertain topics, representations trained on AV might also encode content\ninformation instead of style alone. We introduce a variation of the AV training\ntask that controls for content using conversation or domain labels. We evaluate\nwhether known style dimensions are represented and preferred over content\ninformation through an original variation to the recently proposed STEL\nframework. We find that representations trained by controlling for conversation\nare better than representations trained with domain or no content control at\nrepresenting style independent from content.",
    "descriptor": "\nComments: accepted to the 7th workshop on RepL4NLP at ACL 2022\n",
    "authors": [
      "Anna Wegmann",
      "Marijn Schraagen",
      "Dong Nguyen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.04907"
  },
  {
    "id": "arXiv:2204.04908",
    "title": "No Token Left Behind: Explainability-Aided Image Classification and  Generation",
    "abstract": "The application of zero-shot learning in computer vision has been\nrevolutionized by the use of image-text matching models. The most notable\nexample, CLIP, has been widely used for both zero-shot classification and\nguiding generative models with a text prompt. However, the zero-shot use of\nCLIP is unstable with respect to the phrasing of the input text, making it\nnecessary to carefully engineer the prompts used. We find that this instability\nstems from a selective similarity score, which is based only on a subset of the\nsemantically meaningful input tokens. To mitigate it, we present a novel\nexplainability-based approach, which adds a loss term to ensure that CLIP\nfocuses on all relevant semantic parts of the input, in addition to employing\nthe CLIP similarity loss used in previous works. When applied to one-shot\nclassification through prompt engineering, our method yields an improvement in\nthe recognition rate, without additional training or fine-tuning. Additionally,\nwe show that CLIP guidance of generative models using our method significantly\nimproves the generated images. Finally, we demonstrate a novel use of CLIP\nguidance for text-based image generation with spatial conditioning on object\nlocation, by requiring the image explainability heatmap for each object to be\nconfined to a pre-determined bounding box.",
    "descriptor": "",
    "authors": [
      "Roni Paiss",
      "Hila Chefer",
      "Lior Wolf"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.04908"
  },
  {
    "id": "arXiv:2204.04910",
    "title": "A-DRIVE: Autonomous Deadlock Detection and Recovery at Road  Intersections for Connected and Automated Vehicles",
    "abstract": "Connected and Automated Vehicles (CAVs) are highly expected to improve\ntraffic throughput and safety at road intersections, single-track lanes, and\nconstruction zones. However, multiple CAVs can block each other and create a\nmutual deadlock around these road segments (i) when vehicle systems have a\nfailure, such as a communication failure, control failure, or localization\nfailure and/or (ii) when vehicles use a long shared road segment. In this\npaper, we present an Autonomous Deadlock Detection and Recovery Protocol at\nIntersections for Automated Vehicles named A-DRIVE that is a decentralized and\ntime-sensitive technique to improve traffic throughput and shorten worst-case\nrecovery time. To enable the deadlock recovery with automated vehicles and with\nhuman-driven vehicles, A-DRIVE includes two components: V2V communication-based\nA-DRIVE and Local perception-based A-DRIVE. V2V communication-based A-DRIVE is\ndesigned for homogeneous traffic environments in which all the vehicles are\nconnected and automated. Local perception-based A-DRIVE is for mixed traffic,\nwhere CAVs, non-connected automated vehicles, and human-driven vehicles\nco-exist and cooperate with one another. Since these two components are not\nexclusive, CAVs inclusively and seamlessly use them in practice. Finally, our\nsimulation results show that A-DRIVE improves traffic throughput compared to a\nbaseline protocol.",
    "descriptor": "",
    "authors": [
      "Shunsuke Aoki",
      "Ragunathan",
      "Rajkumar"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2204.04910"
  },
  {
    "id": "arXiv:2204.04911",
    "title": "Category-Aware Transformer Network for Better Human-Object Interaction  Detection",
    "abstract": "Human-Object Interactions (HOI) detection, which aims to localize a human and\na relevant object while recognizing their interaction, is crucial for\nunderstanding a still image. Recently, transformer-based models have\nsignificantly advanced the progress of HOI detection. However, the capability\nof these models has not been fully explored since the Object Query of the model\nis always simply initialized as just zeros, which would affect the performance.\nIn this paper, we try to study the issue of promoting transformer-based HOI\ndetectors by initializing the Object Query with category-aware semantic\ninformation. To this end, we innovatively propose the Category-Aware\nTransformer Network (CATN). Specifically, the Object Query would be initialized\nvia category priors represented by an external object detection model to yield\nbetter performance. Moreover, such category priors can be further used for\nenhancing the representation ability of features via the attention mechanism.\nWe have firstly verified our idea via the Oracle experiment by initializing the\nObject Query with the groundtruth category information. And then extensive\nexperiments have been conducted to show that a HOI detection model equipped\nwith our idea outperforms the baseline by a large margin to achieve a new\nstate-of-the-art result.",
    "descriptor": "",
    "authors": [
      "Leizhen Dong",
      "Zhimin Li",
      "Kunlun Xu",
      "Zhijun Zhang",
      "Luxin Yan",
      "Sheng Zhong",
      "Xu Zou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.04911"
  },
  {
    "id": "arXiv:2204.04913",
    "title": "Permutation-Invariant Relational Network for Multi-person 3D Pose  Estimation",
    "abstract": "Recovering multi-person 3D poses from a single RGB image is a severely\nill-conditioned problem due not only to the inherent 2D-3D depth ambiguity but\nalso because of inter-person occlusions and body truncations. Recent works have\nshown promising results by simultaneously reasoning for different people but in\nall cases within a local neighborhood. An interesting exception is PI-Net,\nwhich introduces a self-attention block to reason for all people in the image\nat the same time and refine potentially noisy initial 3D poses. However, the\nproposed methodology requires defining one of the individuals as a reference,\nand the outcome of the algorithm is sensitive to this choice. In this paper, we\nmodel people interactions at a whole, independently of their number, and in a\npermutation-invariant manner building upon the Set Transformer. We leverage on\nthis representation to refine the initial 3D poses estimated by off-the-shelf\ndetectors. A thorough evaluation demonstrates that our approach is able to\nboost the performance of the initially estimated 3D poses by large margins,\nachieving state-of-the-art results on MuPoTS-3D, CMU Panoptic and NBA2K\ndatasets. Additionally, the proposed module is computationally efficient and\ncan be used as a drop-in complement for any 3D pose detector in multi-people\nscenes.",
    "descriptor": "",
    "authors": [
      "Nicolas Ugrinovic",
      "Adria Ruiz",
      "Antonio Agudo",
      "Alberto Sanfeliu",
      "Francesc Moreno-Noguer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.04913"
  },
  {
    "id": "arXiv:2204.04914",
    "title": "Zero-shot Cross-lingual Conversational Semantic Role Labeling",
    "abstract": "While conversational semantic role labeling (CSRL) has shown its usefulness\non Chinese conversational tasks, it is still under-explored in non-Chinese\nlanguages due to the lack of multilingual CSRL annotations for the parser\ntraining. To avoid expensive data collection and error-propagation of\ntranslation-based methods, we present a simple but effective approach to\nperform zero-shot cross-lingual CSRL. Our model implicitly learns\nlanguage-agnostic, conversational structure-aware and semantically rich\nrepresentations with the hierarchical encoders and elaborately designed\npre-training objectives. Experimental results show that our model outperforms\nall baselines by large margins on two newly collected English CSRL test sets.\nMore importantly, we confirm the usefulness of CSRL to non-Chinese\nconversational tasks such as the question-in-context rewriting task in English\nand the multi-turn dialogue response generation tasks in English, German and\nJapanese by incorporating the CSRL information into the downstream\nconversation-based models. We believe this finding is significant and will\nfacilitate the research of non-Chinese dialogue tasks which suffer the problems\nof ellipsis and anaphora.",
    "descriptor": "\nComments: NAACL 2022 findings\n",
    "authors": [
      "Han Wu",
      "Haochen Tan",
      "Kun Xu",
      "Shuqi Liu",
      "Lianwei Wu",
      "Linqi Song"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.04914"
  },
  {
    "id": "arXiv:2204.04915",
    "title": "Low-Complexity Sum-Capacity Maximization for Intelligent Reflecting  Surface-Aided MIMO Systems",
    "abstract": "Reducing computational complexity is crucial in optimizing the phase shifts\nof Intelligent Reflecting Surface (IRS) systems since IRS-assisted\ncommunication systems are generally deployed with a large number of reflecting\nelements (REs). This letter proposes a low-complexity algorithm, designated as\nDimension-wise Sinusoidal Maximization (DSM), to obtain the optimal IRS phase\nshifts that maximize the sum capacity of a MIMO network. The algorithm exploits\nthe fact that the objective function for the optimization problem is sinusoidal\nw.r.t. the phase shift of each RE. The numerical results show that DSM achieves\na near-maximal sum rate and faster convergence speed than two other benchmark\nmethods.",
    "descriptor": "\nComments: This paper was accepted by IEEE Wireless Communications Letters\n",
    "authors": [
      "Ahmad Sirojuddin",
      "Dony Darmawan Putra",
      "Wan-Jen Huang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2204.04915"
  },
  {
    "id": "arXiv:2204.04916",
    "title": "ConSLT: A Token-level Contrastive Framework for Sign Language  Translation",
    "abstract": "Sign language translation (SLT) is an important technology that can bridge\nthe communication gap between the deaf and the hearing people. SLT task is\nessentially a low-resource problem due to the scarcity of publicly available\nparallel data. To this end, inspired by the success of neural machine\ntranslation methods based on contrastive learning, we propose ConSLT, a novel\ntoken-level \\textbf{Con}trastive learning framework for \\textbf{S}ign\n\\textbf{L}anguage \\textbf{T}ranslation. Unlike previous contrastive learning\nbased works whose goal is to obtain better sentence representation, ConSLT aims\nto learn effective token representation by pushing apart tokens from different\nsentences. Concretely, our model follows the two-stage SLT method. First, in\nthe recoginition stage, we use a state-of-the-art continuous sign language\nrecognition model to recognize glosses from sign frames. Then, in the\ntranslation stage, we adopt the Transformer framework while introducing\ncontrastive learning. Specifically, we pass each sign glosses to the\nTransformer model twice to obtain two different hidden layer representations\nfor each token as \"positive examples\" and randomly sample K tokens that are not\nin the current sentence from the vocabulary as \"negative examples\" for each\ntoken. Experimental results demonstrate that ConSLT achieves new\nstate-of-the-art performance on PHOENIX14T dataset, with +1.48 BLEU\nimprovements.",
    "descriptor": "",
    "authors": [
      "Biao Fu",
      "Peigen Ye",
      "Liang Zhang",
      "Pei Yu",
      "Cong Hu",
      "Yidong Chen",
      "Xiaodong Shi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.04916"
  },
  {
    "id": "arXiv:2204.04918",
    "title": "When NAS Meets Trees: An Efficient Algorithm for Neural Architecture  Search",
    "abstract": "The key challenge in neural architecture search (NAS) is designing how to\nexplore wisely in the huge search space. We propose a new NAS method called\nTNAS (NAS with trees), which improves search efficiency by exploring only a\nsmall number of architectures while also achieving a higher search accuracy.\nTNAS introduces an architecture tree and a binary operation tree, to factorize\nthe search space and substantially reduce the exploration size. TNAS performs a\nmodified bi-level Breadth-First Search in the proposed trees to discover a\nhigh-performance architecture. Impressively, TNAS finds the global optimal\narchitecture on CIFAR-10 with test accuracy of 94.37\\% in four GPU hours in\nNAS-Bench-201. The average test accuracy is 94.35\\%, which outperforms the\nstate-of-the-art. Code is available at:\n\\url{https://github.com/guochengqian/TNAS}.",
    "descriptor": "\nComments: 4 pages, accepted at CVPR Workshop 2022 (ECV2022)\n",
    "authors": [
      "Guocheng Qian",
      "Xuanyang Zhang",
      "Guohao Li",
      "Chen Zhao",
      "Yukang Chen",
      "Xiangyu Zhang",
      "Bernard Ghanem",
      "Jian Sun"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.04918"
  },
  {
    "id": "arXiv:2204.04922",
    "title": "Active and Passive Collection of SSH key material for cyber threat  intelligence",
    "abstract": "This paper describes a system for storing historical forensic artefacts\ncollected from SSH connections. This system exposes a REST API in a similar\nfashion as passive DNS databases, malware hash registries, and SSL notaries\nwith the goal of supporting incident investigations and monitoring of\ninfrastructure.",
    "descriptor": "",
    "authors": [
      "Alexandre Dulaunoy",
      "Jean-Louis Huynen",
      "Aurelien Thirion"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2204.04922"
  },
  {
    "id": "arXiv:2204.04928",
    "title": "Multi-User Wireless Communications with Holographic MIMO Surfaces: A  Convenient Channel Model and Spectral Efficiency Analysis",
    "abstract": "The multi-user Holographic Multiple-Input and Multiple-Output Surface\n(MU-HMIMOS) paradigm, which is capable of realizing large continuous apertures\nwith minimal power consumption and of shaping radio wave propagation at will,\nhas been recently considered as an energy-efficient solution for future\nwireless networks. The tractable channel modeling of MU-HMIMOS signal\npropagation is one of the most critical challenges, mainly due to the coupling\neffect induced by the excessively large number of closely spaced patch\nantennas. In this paper, we focus on this challenge for downlink communications\nand model the electromagnetic channel in the wavenumber domain using the\nFourier plane wave representation. Based on the proposed model, we devise a\nZero-Forcing (ZF) precoding scheme, capitalizing on the sampled channel\nvariance that depends on the number and spacing of the HMIMOS patch antennas,\nand perform a spectral efficiency analysis. Our simulation results showcase\nthat the more patch antennas and the larger their spacing is, the performance\nof the considered MU-HMIMOS system improves. In addition, it is demonstrated\nthat our theoretical performance expressions approximate sufficiently well the\nsimulated spectral efficiency, even for the highly correlated cases, thus\nverifying the effectiveness and robustness of the presented analytical\nframework.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2112.02803\n",
    "authors": [
      "Li Wei",
      "Chongwen Huang",
      "George C. Alexandropoulos",
      "Wei E. I. Sha",
      "Zhaoyang Zhang",
      "Merouane Debbah",
      "Chau Yuen"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2204.04928"
  },
  {
    "id": "arXiv:2204.04930",
    "title": "A Unified Perspective on Deep Equilibrium Finding",
    "abstract": "Extensive-form games provide a versatile framework for modeling interactions\nof multiple agents subjected to imperfect observations and stochastic events.\nIn recent years, two paradigms, policy space response oracles (PSRO) and\ncounterfactual regret minimization (CFR), showed that extensive-form games may\nindeed be solved efficiently. Both of them are capable of leveraging deep\nneural networks to tackle the scalability issues inherent to extensive-form\ngames and we refer to them as deep equilibrium-finding algorithms. Even though\nPSRO and CFR share some similarities, they are often regarded as distinct and\nthe answer to the question of which is superior to the other remains ambiguous.\nInstead of answering this question directly, in this work we propose a unified\nperspective on deep equilibrium finding that generalizes both PSRO and CFR. Our\nfour main contributions include: i) a novel response oracle (RO) which computes\nQ values as well as reaching probability values and baseline values; ii) two\ntransform modules -- a pre-transform and a post-transform -- represented by\nneural networks transforming the outputs of RO to a latent additive space\n(LAS), and then the LAS to action probabilities for execution; iii) two average\noracles -- local average oracle (LAO) and global average oracle (GAO) -- where\nLAO operates on LAS and GAO is used for evaluation only; and iv) a novel method\ninspired by fictitious play that optimizes the transform modules and average\noracles, and automatically selects the optimal combination of components of the\ntwo frameworks. Experiments on Leduc poker game demonstrate that our approach\ncan outperform both frameworks.",
    "descriptor": "",
    "authors": [
      "Xinrun Wang",
      "Jakub Cerny",
      "Shuxin Li",
      "Chang Yang",
      "Zhuyun Yin",
      "Hau Chan",
      "Bo An"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2204.04930"
  },
  {
    "id": "arXiv:2204.04932",
    "title": "Optimized SC-F-LOAM: Optimized Fast LiDAR Odometry and Mapping Using  Scan Context",
    "abstract": "LiDAR odometry can achieve accurate vehicle pose estimation for short driving\nrange or in small-scale environments, but for long driving range or in\nlarge-scale environments, the accuracy deteriorates as a result of cumulative\nestimation errors. This drawback necessitates the inclusion of loop closure\ndetection in a SLAM framework to suppress the adverse effects of cumulative\nerrors. To improve the accuracy of pose estimation, we propose a new\nLiDAR-based SLAM method which uses F-LOAM as LiDAR odometry, Scan Context for\nloop closure detection, and GTSAM for global optimization. In our approach, an\nadaptive distance threshold (instead of a fixed threshold) is employed for loop\nclosure detection, which achieves more accurate loop closure detection results.\nBesides, a feature-based matching method is used in our approach to compute\nvehicle pose transformations between loop closure point cloud pairs, instead of\nusing the raw point cloud obtained by the LiDAR sensor, which significantly\nreduces the computation time. The KITTI dataset and a UGV platform are used for\nverifications of our method, and the experimental results demonstrate that the\nproposed method outperforms typical LiDAR odometry/SLAM methods in the\nliterature. Our code is made publicly available for the benefit of the\ncommunity.",
    "descriptor": "",
    "authors": [
      "Lizhou Liao",
      "Chunyun Fu",
      "Binbin Feng",
      "Tian Su"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2204.04932"
  },
  {
    "id": "arXiv:2204.04935",
    "title": "The Placebo Effect of Artificial Intelligence in Human-Computer  Interaction",
    "abstract": "In medicine, patients can obtain real benefits from a sham treatment. These\nbenefits are known as the placebo effect. We report two experiments (Experiment\nI: N=369; Experiment II: N=100) demonstrating a placebo effect in adaptive\ninterfaces. Participants were asked to solve word puzzles while being supported\nby no system or an adaptive AI interface. All participants experienced the same\nword puzzle difficulty and had no support from an AI throughout the\nexperiments. Our results showed that the belief of receiving adaptive AI\nsupport increases expectations regarding the participant's own task\nperformance, sustained after interaction. These expectations were positively\ncorrelated to performance, as indicated by the number of solved word puzzles.\nWe integrate our findings into technological acceptance theories and discuss\nimplications for the future assessment of AI-based user interfaces and novel\ntechnologies. We argue that system descriptions can elicit placebo effects\nthrough user expectations biasing the results of user-centered studies.",
    "descriptor": "",
    "authors": [
      "Thomas Kosch",
      "Robin Welsch",
      "Lewis Chuang",
      "Albrecht Schmidt"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2204.04935"
  },
  {
    "id": "arXiv:2204.04937",
    "title": "Assessment of Massively Multilingual Sentiment Classifiers",
    "abstract": "Models are increasing in size and complexity in the hunt for SOTA. But what\nif those 2\\% increase in performance does not make a difference in a production\nuse case? Maybe benefits from a smaller, faster model outweigh those slight\nperformance gains. Also, equally good performance across languages in\nmultilingual tasks is more important than SOTA results on a single one. We\npresent the biggest, unified, multilingual collection of sentiment analysis\ndatasets. We use these to assess 11 models and 80 high-quality sentiment\ndatasets (out of 342 raw datasets collected) in 27 languages and included\nresults on the internally annotated datasets. We deeply evaluate multiple\nsetups, including fine-tuning transformer-based models for measuring\nperformance. We compare results in numerous dimensions addressing the imbalance\nin both languages coverage and dataset sizes. Finally, we present some best\npractices for working with such a massive collection of datasets and models\nfrom a multilingual perspective.",
    "descriptor": "\nComments: Accepted for WASSA at ACL 2022\n",
    "authors": [
      "Krzysztof Rajda",
      "\u0141ukasz Augustyniak",
      "Piotr Gramacki",
      "Marcin Gruza",
      "Szymon Wo\u017aniak",
      "Tomasz Kajdanowicz"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.04937"
  },
  {
    "id": "arXiv:2204.04938",
    "title": "Value-based Practical Reasoning: Modal Logic + Argumentation",
    "abstract": "Autonomous agents are supposed to be able to finish tasks or achieve goals\nthat are assigned by their users through performing a sequence of actions.\nSince there might exist multiple plans that an agent can follow and each plan\nmight promote or demote different values along each action, the agent should be\nable to resolve the conflicts between them and evaluate which plan he should\nfollow. In this paper, we develop a logic-based framework that combines modal\nlogic and argumentation for value-based practical reasoning with plans. Modal\nlogic is used as a technique to represent and verify whether a plan with its\nlocal properties of value promotion or demotion can be followed to achieve an\nagent's goal. We then propose an argumentation-based approach that allows an\nagent to reason about his plans in the form of supporting or objecting to a\nplan using the verification results.",
    "descriptor": "",
    "authors": [
      "Jieting Luo",
      "Beishui Liao",
      "Dov Gabbay"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.04938"
  },
  {
    "id": "arXiv:2204.04944",
    "title": "Semantic Segmentation for Point Cloud Scenes via Dilated Graph Feature  Aggregation and Pyramid Decoders",
    "abstract": "Semantic segmentation of point clouds generates comprehensive understanding\nof scenes through densely predicting the category for each point. Due to the\nunicity of receptive field, semantic segmentation of point clouds remains\nchallenging for the expression of multi-receptive field features, which brings\nabout the misclassification of instances with similar spatial structures. In\nthis paper, we propose a graph convolutional network DGFA-Net rooted in dilated\ngraph feature aggregation (DGFA), guided by multi-basis aggregation loss\n(MALoss) calculated through Pyramid Decoders. To configure multi-receptive\nfield features, DGFA which takes the proposed dilated graph convolution\n(DGConv) as its basic building block, is designed to aggregate multi-scale\nfeature representation by capturing dilated graphs with various receptive\nregions. By simultaneously considering penalizing the receptive field\ninformation with point sets of different resolutions as calculation bases, we\nintroduce Pyramid Decoders driven by MALoss for the diversity of receptive\nfield bases. Combining these two aspects, DGFA-Net significantly improves the\nsegmentation performance of instances with similar spatial structures.\nExperiments on S3DIS, ShapeNetPart and Toronto-3D show that DGFA-Net\noutperforms the baseline approach, achieving a new state-of-the-art\nsegmentation performance.",
    "descriptor": "",
    "authors": [
      "Yongqiang Mao",
      "Xian Sun",
      "Wenhui Diao",
      "Kaiqiang Chen",
      "Zonghao Guo",
      "Xiaonan Lu",
      "Kun Fu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.04944"
  },
  {
    "id": "arXiv:2204.04950",
    "title": "Commonality in Natural Images Rescues GANs: Pretraining GANs with  Generic and Privacy-free Synthetic Data",
    "abstract": "Transfer learning for GANs successfully improves generation performance under\nlow-shot regimes. However, existing studies show that the pretrained model\nusing a single benchmark dataset is not generalized to various target datasets.\nMore importantly, the pretrained model can be vulnerable to copyright or\nprivacy risks as membership inference attack advances. To resolve both issues,\nwe propose an effective and unbiased data synthesizer, namely Primitives-PS,\ninspired by the generic characteristics of natural images. Specifically, we\nutilize 1) the generic statistics on the frequency magnitude spectrum, 2) the\nelementary shape (i.e., image composition via elementary shapes) for\nrepresenting the structure information, and 3) the existence of saliency as\nprior. Since our synthesizer only considers the generic properties of natural\nimages, the single model pretrained on our dataset can be consistently\ntransferred to various target datasets, and even outperforms the previous\nmethods pretrained with the natural images in terms of Fr'echet inception\ndistance. Extensive analysis, ablation study, and evaluations demonstrate that\neach component of our data synthesizer is effective, and provide insights on\nthe desirable nature of the pretrained model for the transferability of GANs.",
    "descriptor": "\nComments: CVPR 2022 accepted\n",
    "authors": [
      "Kyungjune Baek",
      "Hyunjung Shim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.04950"
  },
  {
    "id": "arXiv:2204.04952",
    "title": "MGIMN: Multi-Grained Interactive Matching Network for Few-shot Text  Classification",
    "abstract": "Text classification struggles to generalize to unseen classes with very few\nlabeled text instances per class. In such a few-shot learning (FSL) setting,\nmetric-based meta-learning approaches have shown promising results. Previous\nstudies mainly aim to derive a prototype representation for each class.\nHowever, they neglect that it is challenging-yet-unnecessary to construct a\ncompact representation which expresses the entire meaning for each class. They\nalso ignore the importance to capture the inter-dependency between query and\nthe support set for few-shot text classification. To deal with these issues, we\npropose a meta-learning based method MGIMN which performs instance-wise\ncomparison followed by aggregation to generate class-wise matching vectors\ninstead of prototype learning. The key of instance-wise comparison is the\ninteractive matching within the class-specific context and episode-specific\ncontext. Extensive experiments demonstrate that the proposed method\nsignificantly outperforms the existing state-of-the-art approaches, under both\nthe standard FSL and generalized FSL settings.",
    "descriptor": "\nComments: 10 pages, 2 figures, 6 tabels\n",
    "authors": [
      "Jianhai Zhang",
      "Mieradilijiang Maimaiti",
      "Xing Gao",
      "Yuanhang Zheng",
      "Ji Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.04952"
  },
  {
    "id": "arXiv:2204.04954",
    "title": "Reinforcement Re-ranking with 2D Grid-based Recommendation Panels",
    "abstract": "Modern recommender systems usually present items as one-dimensional ranking\nlist. Recently there is a trend in e-commerce that the recommended items are\norganized as two-dimensional grid-based panels where users can view the items\nin both vertical and horizontal directions. Presenting items in grid-based\nresult panels poses new challenges to recommender systems because existing\nmodels are all designed to output sequential lists while the slots in a\ngrid-based panel have no explicit order. Directly converting the item rankings\ninto grids (e.g., pre-defining an order on the slots)overlooks the\nuser-specific behavioral patterns on grid-based pan-els and inevitably hurts\nthe user experiences. To address this issue, we propose a novel Markov decision\nprocess (MDP) to place the items in 2D grid-based result panels at the final\nre-ranking stage of the recommender systems. The model, referred to as\nPanel-MDP, takes an initial item ranking from the early stages as the input.\nThen, it defines the MDP discrete time steps as the ranks in the initial\nranking list, and the actions as the slots in the grid-based panels, plus a\nNULL action. At each time step, Panel-MDP sequentially takes an action of\nselecting one slot for placing an item of the initial ranking list, or\ndiscarding the item if NULL action is selected. The process is continued until\nall of the slots are filled. The reinforcement learning algorithm of DQN is\nemployed to implement and learn the parameters in the Panel-MDP. Experiments on\na dataset collected from a widely-used e-commerce app demonstrated the\nsuperiority ofPanel-MDP in terms of recommending 2D grid-based result panels.",
    "descriptor": "",
    "authors": [
      "Sirui Chen",
      "Xiao Zhang",
      "Xu Chen",
      "Zhiyu Li",
      "Yuan Wang",
      "Quan Lin",
      "Jun Xu"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2204.04954"
  },
  {
    "id": "arXiv:2204.04959",
    "title": "HAKG: Hierarchy-Aware Knowledge Gated Network for Recommendation",
    "abstract": "Knowledge graph (KG) plays an increasingly important role to improve the\nrecommendation performance and interpretability. A recent technical trend is to\ndesign end-to-end models based on information propagation schemes. However,\nexisting propagation-based methods fail to (1) model the underlying\nhierarchical structures and relations, and (2) capture the high-order\ncollaborative signals of items for learning high-quality user and item\nrepresentations.\nIn this paper, we propose a new model, called Hierarchy-Aware Knowledge Gated\nNetwork (HAKG), to tackle the aforementioned problems. Technically, we model\nusers and items (that are captured by a user-item graph), as well as entities\nand relations (that are captured in a KG) in hyperbolic space, and design a\nhyperbolic aggregation scheme to gather relational contexts over KG. Meanwhile,\nwe introduce a novel angle constraint to preserve characteristics of items in\nthe embedding space. Furthermore, we propose a dual item embeddings design to\nrepresent and propagate collaborative signals and knowledge associations\nseparately, and leverage the gated aggregation to distill discriminative\ninformation for better capturing user behavior patterns. Experimental results\non three benchmark datasets show that, HAKG achieves significant improvement\nover the state-of-the-art methods like CKAN, Hyper-Know, and KGIN. Further\nanalyses on the learned hyperbolic embeddings confirm that HAKG offers\nmeaningful insights into the hierarchies of data.",
    "descriptor": "\nComments: Accept to SIGIR2022\n",
    "authors": [
      "Yuntao Du",
      "Xinjun Zhu",
      "Lu Chen",
      "Baihua Zheng",
      "Yunjun Gao"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2204.04959"
  },
  {
    "id": "arXiv:2204.04960",
    "title": "Constrained Shortest Path and Hierarchical Structures",
    "abstract": "The Constraint Shortest Path (CSP) problem is as follows. An $n$-vertex graph\nis given, each edge/arc assigned two weights. Let us call them \"cost\" and\n\"length\" for definiteness. Finding a min-cost upper-bounded length path between\na given pair of vertices is required. The problem is NP-hard even when the\nlengths of all edges are the same. Therefore, various approximation algorithms\nhave been proposed in the literature for it. The constraint on path length can\nbe accounted for by considering one edge weight equals to a linear combination\nof cost and length. By varying the multiplier value in a linear combination, a\nfeasible solution delivers a minimum to the function with new weights. At the\nsame time, Dijkstra's algorithm or its modifications are used to construct the\nshortest path with the current weights of the edges. However, with\ninsufficiently large graphs, this approach may turn out to be time-consuming.\nIn this article, we propose to look for a solution, not in the original graph\nbut specially constructed hierarchical structures (HS). We show that the\nshortest path in the HS is constructed with $O(m)$-time complexity, where $m$\nis the number of edges/arcs of the graph, and the approximate solution in the\ncase of integer costs and lengths of the edges is found with $O(m\\log n)$-time\ncomplexity. The a priori estimate of the algorithm's accuracy turned out to\ndepend on the parameters of the problem and can be significant. Therefore, to\nevaluate the algorithm's effectiveness, we conducted a numerical experiment on\nthe graphs of roads of megalopolis and randomly constructed unit-disk graphs\n(UDGs). The numerical experiment results show that in the HS, a solution close\nto optimal one is built 10--100 times faster than in the methods which use\nDijkstra's algorithm to build a min-weight path in the original graph.",
    "descriptor": "",
    "authors": [
      "Adil Erzin",
      "Roman Plotnikov",
      "Ilya Ladygin"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2204.04960"
  },
  {
    "id": "arXiv:2204.04962",
    "title": "IC-GVINS: A Robust, Real-time, INS-Centric GNSS-Visual-Inertial  Navigation System for Wheeled Robot",
    "abstract": "In this letter, we present a robust, real-time, inertial navigation system\n(INS)-Centric GNSS-Visual-Inertial navigation system (IC-GVINS) for wheeled\nrobot, in which the precise INS is fully utilized in both the state estimation\nand visual process. To improve the system robustness, the INS information is\nemployed during the whole keyframe-based visual process, with strict\noutlier-culling strategy. GNSS is adopted to perform an accurate and convenient\ninitialization of the IC-GVINS, and is further employed to achieve absolute\npositioning in large-scale environments. The IMU, visual, and GNSS measurements\nare tightly fused within the framework of factor graph optimization. Dedicated\nexperiments were conducted to evaluate the robustness and accuracy of the\nIC-GVINS on a wheeled robot. The IC-GVINS demonstrates superior robustness in\nvarious visual-degenerated scenes with moving objects. Compared to the\nstate-of-the-art visual-inertial navigation systems, the proposed method yields\nimproved robustness and accuracy in various environments. We open source our\ncodes combined with the dataset on GitHub",
    "descriptor": "",
    "authors": [
      "Hailiang Tang",
      "Tisheng Zhang",
      "Xiaoji Niu",
      "Jing Fan",
      "Jingnan Liu"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2204.04962"
  },
  {
    "id": "arXiv:2204.04964",
    "title": "Online Frank-Wolfe with Unknown Delays",
    "abstract": "The online Frank-Wolfe (OFW) method has gained much popularity for online\nconvex optimization due to its projection-free property. Previous studies\nshowed that for convex losses, OFW attains $O(T^{3/4})$ regret over general\nsets and $O(T^{2/3})$ regret over strongly convex sets, and if losses are\nstrongly convex, these bounds can be improved to $O(T^{2/3})$ and\n$O(\\sqrt{T})$, respectively. However, they assumed that each gradient queried\nby OFW is revealed immediately, which may not hold in practice. In this paper,\nwe consider a more practical setting where gradients arrive with arbitrary and\nunknown delays, and propose delayed OFW which generalizes OFW to this setting.\nThe main idea is to perform an update similar to OFW after receiving any\ngradient, and play the latest decision for each round. We first show that for\nconvex losses, delayed OFW achieves $O(T^{3/4}+dT^{1/4})$ regret over general\nsets and $O(T^{2/3}+dT^{1/3})$ regret over strongly convex sets, where $d$ is\nthe maximum delay. Furthermore, we prove that for strongly convex losses,\ndelayed OFW attains $O(T^{2/3}+d\\log T)$ regret over general sets and\n$O(\\sqrt{T}+d\\log T)$ regret over strongly convex sets. Compared with regret\nbounds in the non-delayed setting, our results imply that the proposed method\nis robust to a relatively large amount of delay.",
    "descriptor": "",
    "authors": [
      "Yuanyu Wan",
      "Wei-Wei Tu",
      "Lijun Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.04964"
  },
  {
    "id": "arXiv:2204.04965",
    "title": "Multistream neural architectures for cued-speech recognition using a  pre-trained visual feature extractor and constrained CTC decoding",
    "abstract": "This paper proposes a simple and effective approach for automatic recognition\nof Cued Speech (CS), a visual communication tool that helps people with hearing\nimpairment to understand spoken language with the help of hand gestures that\ncan uniquely identify the uttered phonemes in complement to lipreading. The\nproposed approach is based on a pre-trained hand and lips tracker used for\nvisual feature extraction and a phonetic decoder based on a multistream\nrecurrent neural network trained with connectionist temporal classification\nloss and combined with a pronunciation lexicon. The proposed system is\nevaluated on an updated version of the French CS dataset CSF18 for which the\nphonetic transcription has been manually checked and corrected. With a decoding\naccuracy at the phonetic level of 70.88%, the proposed system outperforms our\nprevious CNN-HMM decoder and competes with more complex baselines.",
    "descriptor": "",
    "authors": [
      "Sanjana Sankar",
      "Denis Beautemps",
      "Thomas Hueber"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2204.04965"
  },
  {
    "id": "arXiv:2204.04968",
    "title": "Bimodal Camera Pose Prediction for Endoscopy",
    "abstract": "Deducing the 3D structure of endoscopic scenes from images remains extremely\nchallenging. In addition to deformation and view-dependent lighting, tubular\nstructures like the colon present problems stemming from the self-occluding,\nrepetitive anatomical structures. In this paper, we propose SimCol, a synthetic\ndataset for camera pose estimation in colonoscopy and a novel method that\nexplicitly learns a bimodal distribution to predict the endoscope pose. Our\ndataset replicates real colonoscope motion and highlights drawbacks of existing\nmethods. We publish 18k RGB images from simulated colonoscopy with\ncorresponding depth and camera poses and make our data generation environment\nin Unity publicly available. We evaluate different camera pose prediction\nmethods and demonstrate that, when trained on our data, they generalize to real\ncolonoscopy sequences and our bimodal approach outperforms prior unimodal work.",
    "descriptor": "",
    "authors": [
      "Anita Rau",
      "Binod Bhattarai",
      "Lourdes Agapito",
      "Danail Stoyanov"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.04968"
  },
  {
    "id": "arXiv:2204.04969",
    "title": "Assessing hierarchies by their consistent segmentations",
    "abstract": "Recent segmentation approaches start by creating a hierarchy of nested image\npartitions, and then specify a segmentation from it, usually, by choosing one\nhorizontal cut. Our first contribution is to describe several different ways,\nsome of them new, for specifying segmentations using the hierarchy regions.\nThen we consider the best hierarchy-induced segmentation, in which the segments\nare specified by a limited number, k, of hierarchy nodes/regions. The number of\nhierarchy-induced segmentations grows exponentially with the hierarchy size,\nimplying that exhaustive search is unfeasible. We focus on a common quality\nmeasure, the Jaccard index (known also as IoU). Optimizing the Jaccard index is\nhighly nontrivial. Yet, we propose an efficient optimization * This work was\ndone when the first author was with the Math dept. Technion, Israel.",
    "descriptor": "",
    "authors": [
      "Zeev Gutman",
      "Ritvik Vij",
      "Laurent Najman",
      "Michael Lindenbaum"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2204.04969"
  },
  {
    "id": "arXiv:2204.04970",
    "title": "Non-Convex Optimization with Certificates and Fast Rates Through Kernel  Sums of Squares",
    "abstract": "We consider potentially non-convex optimization problems, for which optimal\nrates of approximation depend on the dimension of the parameter space and the\nsmoothness of the function to be optimized. In this paper, we propose an\nalgorithm that achieves close to optimal a priori computational guarantees,\nwhile also providing a posteriori certificates of optimality. Our general\nformulation builds on infinite-dimensional sums-of-squares and Fourier\nanalysis, and is instantiated on the minimization of multivariate periodic\nfunctions.",
    "descriptor": "",
    "authors": [
      "Blake Woodworth",
      "Francis Bach",
      "Alessandro Rudi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2204.04970"
  },
  {
    "id": "arXiv:2204.04972",
    "title": "External control of a genetic toggle switch via Reinforcement Learning",
    "abstract": "We investigate the problem of using a learning-based strategy to stabilize a\nsynthetic toggle switch via an external control approach. To overcome the data\nefficiency problem that would render the algorithm unfeasible for practical use\nin synthetic biology, we adopt a sim-to-real paradigm where the policy is\nlearnt via training on a simplified model of the toggle switch and it is then\nsubsequently exploited to control a more realistic model of the switch\nparameterized from in-vivo experiments. Our in-silico experiments confirm the\nviability of the approach suggesting its potential use for in-vivo control\nimplementations.",
    "descriptor": "",
    "authors": [
      "Sara Maria Brancato",
      "Francesco De Lellis",
      "Davide Salzano",
      "Giovanni Russo",
      "Mario di Bernardo"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)",
      "Molecular Networks (q-bio.MN)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2204.04972"
  },
  {
    "id": "arXiv:2204.04977",
    "title": "Regularization-based Pruning of Irrelevant Weights in Deep Neural  Architectures",
    "abstract": "Deep neural networks exploiting millions of parameters are nowadays the norm\nin deep learning applications. This is a potential issue because of the great\namount of computational resources needed for training, and of the possible loss\nof generalization performance of overparametrized networks. We propose in this\npaper a method for learning sparse neural topologies via a regularization\ntechnique which identifies non relevant weights and selectively shrinks their\nnorm, while performing a classic update for relevant ones. This technique,\nwhich is an improvement of classical weight decay, is based on the definition\nof a regularization term which can be added to any loss functional regardless\nof its form, resulting in a unified general framework exploitable in many\ndifferent contexts. The actual elimination of parameters identified as\nirrelevant is handled by an iterative pruning algorithm. We tested the proposed\ntechnique on different image classification and Natural language generation\ntasks, obtaining results on par or better then competitors in terms of sparsity\nand metrics, while achieving strong models compression.",
    "descriptor": "",
    "authors": [
      "Giovanni Bonetta",
      "Matteo Ribero",
      "Rossella Cancelliere"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.04977"
  },
  {
    "id": "arXiv:2204.04980",
    "title": "A Comparative Study of Pre-trained Encoders for Low-Resource Named  Entity Recognition",
    "abstract": "Pre-trained language models (PLM) are effective components of few-shot named\nentity recognition (NER) approaches when augmented with continued pre-training\non task-specific out-of-domain data or fine-tuning on in-domain data. However,\ntheir performance in low-resource scenarios, where such data is not available,\nremains an open question. We introduce an encoder evaluation framework, and use\nit to systematically compare the performance of state-of-the-art pre-trained\nrepresentations on the task of low-resource NER. We analyze a wide range of\nencoders pre-trained with different strategies, model architectures,\nintermediate-task fine-tuning, and contrastive learning. Our experimental\nresults across ten benchmark NER datasets in English and German show that\nencoder performance varies significantly, suggesting that the choice of encoder\nfor a specific low-resource scenario needs to be carefully evaluated.",
    "descriptor": "\nComments: Accepted at Repl4NLP 2022 (ACL)\n",
    "authors": [
      "Yuxuan Chen",
      "Jonas Mikkelsen",
      "Arne Binder",
      "Christoph Alt",
      "Leonhard Hennig"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.04980"
  },
  {
    "id": "arXiv:2204.04983",
    "title": "T- Hop: Tensor representation of paths in graph convolutional networks",
    "abstract": "We describe a method for encoding path information in graphs into a 3-d\ntensor. We show a connection between the introduced path representation scheme\nand powered adjacency matrices. To alleviate the heavy computational demands of\nworking with the 3-d tensor, we propose to apply dimensionality reduction on\nthe depth axis of the tensor. We then describe our the reduced 3-d matrix can\nbe parlayed into a plausible graph convolutional layer, by infusing it into an\nestablished graph convolutional network framework such as MixHop.",
    "descriptor": "",
    "authors": [
      "Abdulrahman Ibraheem"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.04983"
  },
  {
    "id": "arXiv:2204.04986",
    "title": "Multi-Objective Yield Optimization for Electrical Machines using Machine  Learning",
    "abstract": "This work deals with the design optimization of electrical machines under the\nconsideration of manufacturing uncertainties. In order to efficiently quantify\nthe uncertainty, blackbox machine learning methods are employed. A\nmulti-objective optimization problem is formulated, maximizing simultaneously\nthe reliability, i.e., the yield, and further performance objectives, e.g., the\ncosts. A permanent magnet synchronous machine is modeled and simulated in\ncommercial finite element simulation software. Four approaches for solving the\nmulti-objective optimization problem are described and numerically compared,\nnamely: epsilon-constraint scalarization, weighted sum scalarization, a\nmulti-start weighted sum approach and a genetic algorithm.",
    "descriptor": "",
    "authors": [
      "Morten Huber",
      "Mona Fuhrl\u00e4nder",
      "Sebastian Sch\u00f6ps"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2204.04986"
  },
  {
    "id": "arXiv:2204.04988",
    "title": "gTLO: A Generalized and Non-linear Multi-Objective Deep Reinforcement  Learning Approach",
    "abstract": "In real-world decision optimization, often multiple competing objectives must\nbe taken into account. Following classical reinforcement learning, these\nobjectives have to be combined into a single reward function. In contrast,\nmulti-objective reinforcement learning (MORL) methods learn from vectors of\nper-objective rewards instead. In the case of multi-policy MORL, sets of\ndecision policies for various preferences regarding the conflicting objectives\nare optimized. This is especially important when target preferences are not\nknown during training or when preferences change dynamically during\napplication. While it is, in general, straightforward to extend a\nsingle-objective reinforcement learning method for MORL based on linear\nscalarization, solutions that are reachable by these methods are limited to\nconvex regions of the Pareto front. Non-linear MORL methods like Thresholded\nLexicographic Ordering (TLO) are designed to overcome this limitation.\nGeneralized MORL methods utilize function approximation to generalize across\nobjective preferences and thereby implicitly learn multiple policies in a\ndata-efficient manner, even for complex decision problems with high-dimensional\nor continuous state spaces. In this work, we propose \\textit{generalized\nThresholded Lexicographic Ordering} (gTLO), a novel method that aims to combine\nnon-linear MORL with the advantages of generalized MORL. We introduce a deep\nreinforcement learning realization of the algorithm and present promising\nresults on a standard benchmark for non-linear MORL and a real-world\napplication from the domain of manufacturing process control.",
    "descriptor": "",
    "authors": [
      "Johannes Dornheim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2204.04988"
  },
  {
    "id": "arXiv:2204.04991",
    "title": "TRUE: Re-evaluating Factual Consistency Evaluation",
    "abstract": "Grounded text generation systems often generate text that contains factual\ninconsistencies, hindering their real-world applicability. Automatic factual\nconsistency evaluation may help alleviate this limitation by accelerating\nevaluation cycles, filtering inconsistent outputs and augmenting training data.\nWhile attracting increasing attention, such evaluation metrics are usually\ndeveloped and evaluated in silo for a single task or dataset, slowing their\nadoption. Moreover, previous meta-evaluation protocols focused on system-level\ncorrelations with human annotations, which leave the example-level accuracy of\nsuch metrics unclear. In this work, we introduce TRUE: a comprehensive study of\nfactual consistency metrics on a standardized collection of existing texts from\ndiverse tasks, manually annotated for factual consistency. Our standardization\nenables an example-level meta-evaluation protocol that is more actionable and\ninterpretable than previously reported correlations, yielding clearer quality\nmeasures. Across diverse state-of-the-art metrics and 11 datasets we find that\nlarge-scale NLI and question generation-and-answering-based approaches achieve\nstrong and complementary results. We recommend those methods as a starting\npoint for model and metric developers, and hope TRUE will foster progress\ntowards even better methods.",
    "descriptor": "\nComments: Accepted as a long paper to NAACL 2022 main conference\n",
    "authors": [
      "Or Honovich",
      "Roee Aharoni",
      "Jonathan Herzig",
      "Hagai Taitelbaum",
      "Doron Kukliansy",
      "Vered Cohen",
      "Thomas Scialom",
      "Idan Szpektor",
      "Avinatan Hassidim",
      "Yossi Matias"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.04991"
  },
  {
    "id": "arXiv:2204.04998",
    "title": "Team \u00daFAL at CMCL 2022 Shared Task: Figuring out the correct recipe  for predicting Eye-Tracking features using Pretrained Language Models",
    "abstract": "Eye-Tracking data is a very useful source of information to study cognition\nand especially language comprehension in humans. In this paper, we describe our\nsystems for the CMCL 2022 shared task on predicting eye-tracking information.\nWe describe our experiments with pretrained models like BERT and XLM and the\ndifferent ways in which we used those representations to predict four\neye-tracking features. Along with analysing the effect of using two different\nkinds of pretrained multilingual language models and different ways of pooling\nthe tokenlevel representations, we also explore how contextual information\naffects the performance of the systems. Finally, we also explore if factors\nlike augmenting linguistic information affect the predictions. Our submissions\nachieved an average MAE of 5.72 and ranked 5th in the shared task. The average\nMAE showed further reduction to 5.25 in post task evaluation.",
    "descriptor": "",
    "authors": [
      "Sunit Bhattacharya",
      "Rishu Kumar",
      "Ondrej Bojar"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.04998"
  },
  {
    "id": "arXiv:2204.05002",
    "title": "Fast evaluation of B-spline functions and rendering of multiple B-spline  curves using linear-time algorithm for computing the Bernstein-B\u00e9zier  coefficients of B-spline functions",
    "abstract": "A new differential-recurrence relation for the B-spline functions of the same\ndegree is proved. From this relation, a recursive method of computing the\ncoefficients of B-spline functions of degree $m$ in the Bernstein-B\\'{e}zier\nform is derived. Its complexity is proportional to the number of coefficients\nin the case of coincident boundary knots. This means that, asymptotically, the\nalgorithm is optimal. In other cases, the complexity is increased by at most\n$O(m^3)$. When the Bernstein-B\\'{e}zier coefficients of B-spline basis\nfunctions are known, it is possible to compute any B-spline function in linear\ntime with respect to its degree by performing the geometric algorithm proposed\nrecently by the authors. Using a similar approach, one can also convert a\n$d$-dimensional B-spline curve of degree $m$ over one knot span to a B\\'{e}zier\ncurve in $O(m^2)$ time and then evaluate it in $O(md)$ time. Since one only\nneeds to convert each knot span once, this algorithm scales well when\nevaluating the B-spline curve at multiple points, e.g., in order to render it.\nWhen evaluating many B-spline curves at multiple points, such approach has\nlower computational complexity than using the de Boor-Cox algorithm. The\nproblem of finding the coefficients of the B-spline functions in the power\nbasis can be solved similarly.",
    "descriptor": "",
    "authors": [
      "Filip Chudy",
      "Pawe\u0142 Wo\u017any"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2204.05002"
  },
  {
    "id": "arXiv:2204.05007",
    "title": "HiMODE: A Hybrid Monocular Omnidirectional Depth Estimation Model",
    "abstract": "Monocular omnidirectional depth estimation is receiving considerable research\nattention due to its broad applications for sensing 360{\\deg} surroundings.\nExisting approaches in this field suffer from limitations in recovering small\nobject details and data lost during the ground-truth depth map acquisition. In\nthis paper, a novel monocular omnidirectional depth estimation model, namely\nHiMODE is proposed based on a hybrid CNN+Transformer (encoder-decoder)\narchitecture whose modules are efficiently designed to mitigate distortion and\ncomputational cost, without performance degradation. Firstly, we design a\nfeature pyramid network based on the HNet block to extract high-resolution\nfeatures near the edges. The performance is further improved, benefiting from a\nself and cross attention layer and spatial/temporal patches in the Transformer\nencoder and decoder, respectively. Besides, a spatial residual block is\nemployed to reduce the number of parameters. By jointly passing the deep\nfeatures extracted from an input image at each backbone block, along with the\nraw depth maps predicted by the transformer encoder-decoder, through a context\nadjustment layer, our model can produce resulting depth maps with better visual\nquality than the ground-truth. Comprehensive ablation studies demonstrate the\nsignificance of each individual module. Extensive experiments conducted on\nthree datasets; Stanford3D, Matterport3D, and SunCG, demonstrate that HiMODE\ncan achieve state-of-the-art performance for 360{\\deg} monocular depth\nestimation.",
    "descriptor": "\nComments: IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR 2022)\n",
    "authors": [
      "Masum Shah Junayed",
      "Arezoo Sadeghzadeh",
      "Md Baharul Islam",
      "Lai-Kuan Wong",
      "Tarkan Aydin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.05007"
  },
  {
    "id": "arXiv:2204.05009",
    "title": "VWR2A: A Very-Wide-Register Reconfigurable-Array Architecture for  Low-Power Embedded Devices",
    "abstract": "Edge-computing requires high-performance energy-efficient embedded systems.\nFixed-function or custom accelerators, such as FFT or FIR filter engines, are\nvery efficient at implementing a particular functionality for a given set of\nconstraints. However, they are inflexible when facing application-wide\noptimizations or functionality upgrades. Conversely, programmable cores offer\nhigher flexibility, but often with a penalty in area, performance, and, above\nall, energy consumption. In this paper, we propose VWR2A, an architecture that\nintegrates high computational density and low power memory structures (i.e.,\nvery-wide registers and scratchpad memories). VWR2A narrows the energy gap with\nsimilar or better performance on FFT kernels with respect to an FFT\naccelerator. Moreover, VWR2A flexibility allows to accelerate multiple kernels,\nresulting in significant energy savings at the application level.",
    "descriptor": "",
    "authors": [
      "Beno\u00eet Walter Denkinger",
      "Miguel Pe\u00f3n-Quir\u00f3s",
      "Mario Konijnenburg",
      "David Atienza",
      "Francky Catthoor"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2204.05009"
  },
  {
    "id": "arXiv:2204.05010",
    "title": "Certified Reduced Basis Method for the Damped Wave Equations on Networks",
    "abstract": "In this paper we present a reduced basis method which yields\nstructure-preservation and a tight a posteriori error bound for the simulation\nof the damped wave equations on networks. The error bound is based on the\nexponential decay of the energy inside the system and therefore allows for\nsharp bounds without the need of regularization parameters. The fast\nconvergence of the reduced solution to the truth solution as well as the\ntightness of the error bound are verified numerically using an academic network\nas example.",
    "descriptor": "",
    "authors": [
      "Nadine Stahl",
      "Bj\u00f6rn Liljegren-Sailer",
      "Nicole Marheineke"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2204.05010"
  },
  {
    "id": "arXiv:2204.05011",
    "title": "FederatedScope: A Comprehensive and Flexible Federated Learning Platform  via Message Passing",
    "abstract": "Although remarkable progress has been made by the existing federated learning\n(FL) platforms to provide fundamental functionalities for development, these FL\nplatforms cannot well satisfy burgeoning demands from rapidly growing FL tasks\nin both academia and industry. To fill this gap, in this paper, we propose a\nnovel and comprehensive federated learning platform, named FederatedScope,\nwhich is based on a message-oriented framework. Towards more handy and flexible\nsupport for various FL tasks, FederatedScope frames an FL course into several\nrounds of message passing among participants, and allows developers to\ncustomize new types of exchanged messages and the corresponding handlers for\nvarious FL applications. Compared to the procedural framework, the proposed\nmessage-oriented framework is more flexible to express heterogeneous message\nexchange and the rich behaviors of participants, and provides a unified view\nfor both simulation and deployment. Besides, we also include several functional\ncomponents in FederatedScope, such as personalization, auto-tuning, and privacy\nprotection, to satisfy the requirements of frontier studies in FL. We conduct a\nseries of experiments on the provided easy-to-use and comprehensive FL\nbenchmarks to validate the correctness and efficiency of FederatedScope. We\nhave released FederatedScope for users on\nhttps://github.com/alibaba/FederatedScope to promote research and industrial\ndeployment of federated learning in a variety of real-world applications.",
    "descriptor": "\nComments: We have released FederatedScope for users on this https URL\n",
    "authors": [
      "Yuexiang Xie",
      "Zhen Wang",
      "Daoyuan Chen",
      "Dawei Gao",
      "Liuyi Yao",
      "Weirui Kuang",
      "Yaliang Li",
      "Bolin Ding",
      "Jingren Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.05011"
  },
  {
    "id": "arXiv:2204.05018",
    "title": "Structure-Aware Motion Transfer with Deformable Anchor Model",
    "abstract": "Given a source image and a driving video depicting the same object type, the\nmotion transfer task aims to generate a video by learning the motion from the\ndriving video while preserving the appearance from the source image. In this\npaper, we propose a novel structure-aware motion modeling approach, the\ndeformable anchor model (DAM), which can automatically discover the motion\nstructure of arbitrary objects without leveraging their prior structure\ninformation. Specifically, inspired by the known deformable part model (DPM),\nour DAM introduces two types of anchors or keypoints: i) a number of motion\nanchors that capture both appearance and motion information from the source\nimage and driving video; ii) a latent root anchor, which is linked to the\nmotion anchors to facilitate better learning of the representations of the\nobject structure information. Moreover, DAM can be further extended to a\nhierarchical version through the introduction of additional latent anchors to\nmodel more complicated structures. By regularizing motion anchors with latent\nanchor(s), DAM enforces the correspondences between them to ensure the\nstructural information is well captured and preserved. Moreover, DAM can be\nlearned effectively in an unsupervised manner. We validate our proposed DAM for\nmotion transfer on different benchmark datasets. Extensive experiments clearly\ndemonstrate that DAM achieves superior performance relative to existing\nstate-of-the-art methods.",
    "descriptor": "\nComments: CVPR 2022\n",
    "authors": [
      "Jiale Tao",
      "Biao Wang",
      "Borun Xu",
      "Tiezheng Ge",
      "Yuning Jiang",
      "Wen Li",
      "Lixin Duan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.05018"
  },
  {
    "id": "arXiv:2204.05021",
    "title": "Landmarks and Regions: A Robust Approach to Data Extraction",
    "abstract": "We propose a new approach to extracting data items or field values from\nsemi-structured documents. Examples of such problems include extracting\npassenger name, departure time and departure airport from a travel itinerary,\nor extracting price of an item from a purchase receipt. Traditional approaches\nto data extraction use machine learning or program synthesis to process the\nwhole document to extract the desired fields. Such approaches are not robust to\nformat changes in the document, and the extraction process typically fails even\nif changes are made to parts of the document that are unrelated to the desired\nfields of interest. We propose a new approach to data extraction based on the\nconcepts of landmarks and regions. Humans routinely use landmarks in manual\nprocessing of documents to zoom in and focus their attention on small regions\nof interest in the document. Inspired by this human intuition, we use the\nnotion of landmarks in program synthesis to automatically synthesize extraction\nprograms that first extract a small region of interest, and then automatically\nextract the desired value from the region in a subsequent step. We have\nimplemented our landmark-based extraction approach in a tool LRSyn, and show\nextensive evaluation on documents in HTML as well as scanned images of invoices\nand receipts. Our results show that our approach is robust to various types of\nformat changes that routinely happen in real-world settings.",
    "descriptor": "\nComments: To be published at PLDI,2022\n",
    "authors": [
      "Suresh Parthasarathy",
      "Lincy Pattanaik",
      "Anirudh Khatry",
      "Arun Iyer",
      "Arjun Radhakrishna",
      "Sriram Rajamani",
      "Mohammad Raza"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Information Retrieval (cs.IR)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2204.05021"
  },
  {
    "id": "arXiv:2204.05022",
    "title": "Hermite-type modifications of BOBYQA for optimization with some partial  derivatives",
    "abstract": "In this work we propose two Hermite-type optimization methods, Hermite least\nsquares and Hermite BOBYQA, specialized for the case that some partial\nderivatives of the objective function are available and others are not. The\nmain objective is to reduce the number of objective function calls by\nmaintaining the convergence properties. Both methods are modifications of\nPowell's derivative-free BOBYQA algorithm. But instead of (underdetermined)\ninterpolation for building the quadratic subproblem in each iteration, the\ntraining data is enriched with first and -- if possible -- second order\nderivatives and then (weighted) least squares regression is used. Proofs for\nglobal convergence are discussed and numerical results are presented. Further,\nthe applicability is verified for a realistic test case in the context of yield\noptimization. Numerical tests show that the Hermite least squares approach\noutperforms classic BOBYQA if half or more partial derivatives are available.\nIn addition, the Hermite-type approaches achieve more robustness and thus\nbetter performance in case of noisy objective functions.",
    "descriptor": "",
    "authors": [
      "Mona Fuhrl\u00e4nder",
      "Sebastian Sch\u00f6ps"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2204.05022"
  },
  {
    "id": "arXiv:2204.05027",
    "title": "Exploring the Pareto front of multi-objective COVID-19 mitigation  policies using reinforcement learning",
    "abstract": "Infectious disease outbreaks can have a disruptive impact on public health\nand societal processes. As decision making in the context of epidemic\nmitigation is hard, reinforcement learning provides a methodology to\nautomatically learn prevention strategies in combination with complex epidemic\nmodels. Current research focuses on optimizing policies w.r.t. a single\nobjective, such as the pathogen's attack rate. However, as the mitigation of\nepidemics involves distinct, and possibly conflicting criteria (i.a.,\nprevalence, mortality, morbidity, cost), a multi-objective approach is\nwarranted to learn balanced policies. To lift this decision-making process to\nreal-world epidemic models, we apply deep multi-objective reinforcement\nlearning and build upon a state-of-the-art algorithm, Pareto Conditioned\nNetworks (PCN), to learn a set of solutions that approximates the Pareto front\nof the decision problem. We consider the first wave of the Belgian COVID-19\nepidemic, which was mitigated by a lockdown, and study different deconfinement\nstrategies, aiming to minimize both COVID-19 cases (i.e., infections and\nhospitalizations) and the societal burden that is induced by the applied\nmitigation measures. We contribute a multi-objective Markov decision process\nthat encapsulates the stochastic compartment model that was used to inform\npolicy makers during the COVID-19 epidemic. As these social mitigation measures\nare implemented in a continuous action space that modulates the contact matrix\nof the age-structured epidemic model, we extend PCN to this setting. We\nevaluate the solution returned by PCN, and observe that it correctly learns to\nreduce the social burden whenever the hospitalization rates are sufficiently\nlow. In this work, we thus show that multi-objective reinforcement learning is\nattainable in complex epidemiological models and provides essential insights to\nbalance complex mitigation policies.",
    "descriptor": "",
    "authors": [
      "Mathieu Reymond",
      "Conor F. Hayes",
      "Lander Willem",
      "Roxana R\u0103dulescu",
      "Steven Abrams",
      "Diederik M. Roijers",
      "Enda Howley",
      "Patrick Mannion",
      "Niel Hens",
      "Ann Now\u00e9",
      "Pieter Libin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Populations and Evolution (q-bio.PE)"
    ],
    "url": "https://arxiv.org/abs/2204.05027"
  },
  {
    "id": "arXiv:2204.05030",
    "title": "Assessing the communication gap between AI models and healthcare  professionals: explainability, utility and trust in AI-driven clinical  decision-making",
    "abstract": "This paper contributes with a pragmatic evaluation framework for explainable\nMachine Learning (ML) models for clinical decision support. The study revealed\na more nuanced role for ML explanation models, when these are pragmatically\nembedded in the clinical context. Despite the general positive attitude of\nhealthcare professionals (HCPs) towards explanations as a safety and trust\nmechanism, for a significant set of participants there were negative effects\nassociated with confirmation bias, accentuating model over-reliance and\nincreased effort to interact with the model. Also, contradicting one of its\nmain intended functions, standard explanatory models showed limited ability to\nsupport a critical understanding of the limitations of the model. However, we\nfound new significant positive effects which repositions the role of\nexplanations within a clinical context: these include reduction of automation\nbias, addressing ambiguous clinical cases (cases where HCPs were not certain\nabout their decision) and support of less experienced HCPs in the acquisition\nof new domain knowledge.",
    "descriptor": "\nComments: supplementary information in the main pdf\n",
    "authors": [
      "Oskar Wysocki",
      "Jessica Katharine Davies",
      "Markel Vigo",
      "Anne Caroline Armstrong",
      "D\u00f3nal Landers",
      "Rebecca Lee",
      "Andr\u00e9 Freitas"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.05030"
  },
  {
    "id": "arXiv:2204.05036",
    "title": "Pareto Conditioned Networks",
    "abstract": "In multi-objective optimization, learning all the policies that reach\nPareto-efficient solutions is an expensive process. The set of optimal policies\ncan grow exponentially with the number of objectives, and recovering all\nsolutions requires an exhaustive exploration of the entire state space. We\npropose Pareto Conditioned Networks (PCN), a method that uses a single neural\nnetwork to encompass all non-dominated policies. PCN associates every past\ntransition with its episode's return. It trains the network such that, when\nconditioned on this same return, it should reenact said transition. In doing so\nwe transform the optimization problem into a classification problem. We recover\na concrete policy by conditioning the network on the desired Pareto-efficient\nsolution. Our method is stable as it learns in a supervised fashion, thus\navoiding moving target issues. Moreover, by using a single network, PCN scales\nefficiently with the number of objectives. Finally, it makes minimal\nassumptions on the shape of the Pareto front, which makes it suitable to a\nwider range of problems than previous state-of-the-art multi-objective\nreinforcement learning algorithms.",
    "descriptor": "\nComments: Accepted at the International Conference on Autonomous Agents and Multiagent Systems (AAMAS) 2022\n",
    "authors": [
      "Mathieu Reymond",
      "Eugenio Bargiacchi",
      "Ann Now\u00e9"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.05036"
  },
  {
    "id": "arXiv:2204.05037",
    "title": "Schwartz-Zippel for multilinear polynomials mod N",
    "abstract": "We derive a tight upper bound on the probability over\n$\\mathbf{x}=(x_1,\\dots,x_\\mu) \\in \\mathbb{Z}^\\mu$ uniformly distributed in $\n[0,m)^\\mu$ that $f(\\mathbf{x}) = 0 \\bmod N$ for any $\\mu$-linear polynomial $f\n\\in \\mathbb{Z}[X_1,\\dots,X_\\mu]$ co-prime to $N$. We show that for\n$N=p_1^{r_1},...,p_\\ell^{r_\\ell}$ this probability is bounded byb$\\frac{\\mu}{m}\n+ \\prod_{i=1}^\\ell I_{\\frac{1}{p_i}}(r_i,\\mu)$ where $I$ is the regularized\nbeta function. Furthermore, we provide an inverse result that for any target\nparameter $\\lambda$ bounds the minimum size of $N$ for which the probability\nthat $f(\\mathbf{x}) \\equiv 0 \\bmod N$ is at most $2^{-\\lambda} +\n\\frac{\\mu}{m}$. For $\\mu =1$ this is simply $N \\geq 2^\\lambda$. For $\\mu \\geq\n2$, $\\log_2(N) \\geq 8 \\mu^{2}+ \\log_2(2 \\mu)\\cdot \\lambda$ the probability that\n$f(\\mathbf{x}) \\equiv 0 \\bmod N$ is bounded by $2^{-\\lambda} +\\frac{\\mu}{m}$.\nWe also present a computational method that derives tighter bounds for specific\nvalues of $\\mu$ and $\\lambda$. For example, our analysis shows that for\n$\\mu=20$, $\\lambda = 120$ (values typical in cryptography applications), and\n$\\log_2(N)\\geq 416$ the probability is bounded by $ 2^{-120}+\\frac{20}{m}$. We\nprovide a table of computational bounds for a large set of $\\mu$ and $\\lambda$\nvalues.",
    "descriptor": "",
    "authors": [
      "Benedikt B\u00fcnz",
      "Ben Fisch"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Cryptography and Security (cs.CR)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2204.05037"
  },
  {
    "id": "arXiv:2204.05039",
    "title": "Answering Count Queries with Explanatory Evidence",
    "abstract": "A challenging case in web search and question answering are count queries,\nsuch as \\textit{\"number of songs by John Lennon\"}. Prior methods merely answer\nthese with a single, and sometimes puzzling number or return a ranked list of\ntext snippets with different numbers. This paper proposes a methodology for\nanswering count queries with inference, contextualization and explanatory\nevidence. Unlike previous systems, our method infers final answers from\nmultiple observations, supports semantic qualifiers for the counts, and\nprovides evidence by enumerating representative instances. Experiments with a\nwide variety of queries show the benefits of our method. To promote further\nresearch on this underexplored topic, we release an annotated dataset of 5k\nqueries with 200k relevant text spans.",
    "descriptor": "\nComments: Version accepted at SIGIR 2022\n",
    "authors": [
      "Shrestha Ghosh",
      "Simon Razniewski",
      "Gerhard Weikum"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2204.05039"
  },
  {
    "id": "arXiv:2204.05041",
    "title": "Pyramid Grafting Network for One-Stage High Resolution Saliency  Detection",
    "abstract": "Recent salient object detection (SOD) methods based on deep neural network\nhave achieved remarkable performance. However, most of existing SOD models\ndesigned for low-resolution input perform poorly on high-resolution images due\nto the contradiction between the sampling depth and the receptive field size.\nAiming at resolving this contradiction, we propose a novel one-stage framework\ncalled Pyramid Grafting Network (PGNet), using transformer and CNN backbone to\nextract features from different resolution images independently and then graft\nthe features from transformer branch to CNN branch. An attention-based\nCross-Model Grafting Module (CMGM) is proposed to enable CNN branch to combine\nbroken detailed information more holistically, guided by different source\nfeature during decoding process. Moreover, we design an Attention Guided Loss\n(AGL) to explicitly supervise the attention matrix generated by CMGM to help\nthe network better interact with the attention from different models. We\ncontribute a new Ultra-High-Resolution Saliency Detection dataset UHRSD,\ncontaining 5,920 images at 4K-8K resolutions. To our knowledge, it is the\nlargest dataset in both quantity and resolution for high-resolution SOD task,\nwhich can be used for training and testing in future research. Sufficient\nexperiments on UHRSD and widely-used SOD datasets demonstrate that our method\nachieves superior performance compared to the state-of-the-art methods.",
    "descriptor": "\nComments: accept by CVPR 2022\n",
    "authors": [
      "Chenxi Xie",
      "Changqun Xia",
      "Mingcan Ma",
      "Zhirui Zhao",
      "Xiaowu Chen",
      "Jia Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.05041"
  },
  {
    "id": "arXiv:2204.05042",
    "title": "Resources for Turkish Natural Language Processing: A critical survey",
    "abstract": "This paper presents a comprehensive survey of corpora and lexical resources\navailable for Turkish. We review a broad range of resources, focusing on the\nones that are publicly available. In addition to providing information about\nthe available linguistic resources, we present a set of recommendations, and\nidentify gaps in the data available for conducting research and building\napplications in Turkish Linguistics and Natural Language Processing.",
    "descriptor": "\nComments: Submitted to Language Resources and Evaluation\n",
    "authors": [
      "\u00c7a\u011fr\u0131 \u00c7\u00f6ltekin",
      "A. Seza Do\u011fru\u00f6z",
      "\u00d6zlem \u00c7etino\u011flu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.05042"
  },
  {
    "id": "arXiv:2204.05045",
    "title": "SAL-CNN: Estimate the Remaining Useful Life of Bearings Using  Time-frequency Information",
    "abstract": "In modern industrial production, the prediction ability of the remaining\nuseful life (RUL) of bearings directly affects the safety and stability of the\nsystem. Traditional methods require rigorous physical modeling and perform\npoorly for complex systems. In this paper, an end-to-end RUL prediction method\nis proposed, which uses short-time Fourier transform (STFT) as preprocessing.\nConsidering the time correlation of signal sequences, a long and short-term\nmemory network is designed in CNN, incorporating the convolutional block\nattention module, and understanding the decision-making process of the network\nfrom the interpretability level. Experiments were carried out on the 2012PHM\ndataset and compared with other methods, and the results proved the\neffectiveness of the method.",
    "descriptor": "",
    "authors": [
      "Bingguo Liu",
      "Zhuo Gao",
      "Binghui Lu",
      "Hangcheng Dong",
      "Zeru An"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.05045"
  },
  {
    "id": "arXiv:2204.05049",
    "title": "Using Linguistic Typology to Enrich Multilingual Lexicons: the Case of  Lexical Gaps in Kinship",
    "abstract": "This paper describes a method to enrich lexical resources with content\nrelating to linguistic diversity, based on knowledge from the field of lexical\ntypology. We capture the phenomenon of diversity through the notions of lexical\ngap and language-specific word and use a systematic method to infer gaps\nsemi-automatically on a large scale. As a first result obtained for the domain\nof kinship terminology, known to be very diverse throughout the world, we\npublish a lexico-semantic resource consisting of 198 domain concepts, 1,911\nwords, and 37,370 gaps covering 699 languages. We see potential in the use of\nresources such as ours for the improvement of a variety of cross-lingual NLP\ntasks, which we demonstrate through a downstream application for the evaluation\nof machine translation systems.",
    "descriptor": "\nComments: LREC 2022\n",
    "authors": [
      "Temuulen Khishigsuren",
      "G\u00e1bor Bella",
      "Khuyagbaatar Batsuren",
      "Abed Alhakim Freihat",
      "Nandu Chandran Nair",
      "Amarsanaa Ganbold",
      "Hadi Khalilia",
      "Yamini Chandrashekar",
      "Fausto Giunchiglia"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.05049"
  },
  {
    "id": "arXiv:2204.05051",
    "title": "Performance Metrics for Communication Systems with Forward Error  Correction",
    "abstract": "We revisit performance metrics for optical communication systems with FEC. We\nillustrate the concept of universality and discuss the most widespread\nperformance thresholds. Finally, we show by example how to include FEC into\ntransmission experiments.",
    "descriptor": "\nComments: published at European Conference on Optical Communications (ECOC) 2018\n",
    "authors": [
      "Laurent Schmalen"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2204.05051"
  },
  {
    "id": "arXiv:2204.05056",
    "title": "What do complexity measures measure? Correlating and validating  corpus-based measures of morphological complexity",
    "abstract": "We present an analysis of eight measures used for quantifying morphological\ncomplexity of natural languages. The measures we study are corpus-based\nmeasures of morphological complexity with varying requirements for corpus\nannotation. We present similarities and differences between these measures\nvisually and through correlation analyses, as well as their relation to the\nrelevant typological variables. Our analysis focuses on whether these\n`measures' are measures of the same underlying variable, or whether they\nmeasure more than one dimension of morphological complexity. The principal\ncomponent analysis indicates that the first principal component explains 92.62\n% of the variation in eight measures, indicating a strong linear dependence\nbetween the complexity measures studied.",
    "descriptor": "\nComments: Submitted to Linguistics Vanguard\n",
    "authors": [
      "\u00c7a\u011fr\u0131 \u00c7\u00f6ltekin",
      "Taraka Rama"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.05056"
  },
  {
    "id": "arXiv:2204.05059",
    "title": "Forecasting new diseases in low-data settings using transfer learning",
    "abstract": "Recent infectious disease outbreaks, such as the COVID-19 pandemic and the\nZika epidemic in Brazil, have demonstrated both the importance and difficulty\nof accurately forecasting novel infectious diseases. When new diseases first\nemerge, we have little knowledge of the transmission process, the level and\nduration of immunity to reinfection, or other parameters required to build\nrealistic epidemiological models. Time series forecasts and machine learning,\nwhile less reliant on assumptions about the disease, require large amounts of\ndata that are also not available in early stages of an outbreak. In this study,\nwe examine how knowledge of related diseases can help make predictions of new\ndiseases in data-scarce environments using transfer learning. We implement both\nan empirical and a theoretical approach. Using empirical data from Brazil, we\ncompare how well different machine learning models transfer knowledge between\ntwo different disease pairs: (i) dengue and Zika, and (ii) influenza and\nCOVID-19. In the theoretical analysis, we generate data using different\ntransmission and recovery rates with an SIR compartmental model, and then\ncompare the effectiveness of different transfer learning methods. We find that\ntransfer learning offers the potential to improve predictions, even beyond a\nmodel based on data from the target disease, though the appropriate source\ndisease must be chosen carefully. While imperfect, these models offer an\nadditional input for decision makers during pandemic response.",
    "descriptor": "",
    "authors": [
      "Kirstin Roster",
      "Colm Connaughton",
      "Francisco A. Rodrigues"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2204.05059"
  },
  {
    "id": "arXiv:2204.05068",
    "title": "HFT: Lifting Perspective Representations via Hybrid Feature  Transformation",
    "abstract": "Autonomous driving requires accurate and detailed Bird's Eye View (BEV)\nsemantic segmentation for decision making, which is one of the most challenging\ntasks for high-level scene perception. Feature transformation from frontal view\nto BEV is the pivotal technology for BEV semantic segmentation. Existing works\ncan be roughly classified into two categories, i.e., Camera model-Based Feature\nTransformation (CBFT) and Camera model-Free Feature Transformation (CFFT). In\nthis paper, we empirically analyze the vital differences between CBFT and CFFT.\nThe former transforms features based on the flat-world assumption, which may\ncause distortion of regions lying above the ground plane. The latter is limited\nin the segmentation performance due to the absence of geometric priors and\ntime-consuming computation. In order to reap the benefits and avoid the\ndrawbacks of CBFT and CFFT, we propose a novel framework with a Hybrid Feature\nTransformation module (HFT). Specifically, we decouple the feature maps\nproduced by HFT for estimating the layout of outdoor scenes in BEV.\nFurthermore, we design a mutual learning scheme to augment hybrid\ntransformation by applying feature mimicking. Notably, extensive experiments\ndemonstrate that with negligible extra overhead, HFT achieves a relative\nimprovement of 13.3% on the Argoverse dataset and 16.8% on the KITTI 3D Object\ndatasets compared to the best-performing existing method. The codes are\navailable at https://github.com/JiayuZou2020/HFT.",
    "descriptor": "",
    "authors": [
      "Jiayu Zou",
      "Junrui Xiao",
      "Zheng Zhu",
      "Junjie Huang",
      "Guan Huang",
      "Dalong Du",
      "Xingang Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.05068"
  },
  {
    "id": "arXiv:2204.05070",
    "title": "Fine-grained Noise Control for Multispeaker Speech Synthesis",
    "abstract": "A text-to-speech (TTS) model typically factorizes speech attributes such as\ncontent, speaker and prosody into disentangled representations.Recent works aim\nto additionally model the acoustic conditions explicitly, in order to\ndisentangle the primary speech factors, i.e. linguistic content, prosody and\ntimbre from any residual factors, such as recording conditions and background\nnoise.This paper proposes unsupervised, interpretable and fine-grained noise\nand prosody modeling. We incorporate adversarial training, representation\nbottleneck and utterance-to-frame modeling in order to learn frame-level noise\nrepresentations. To the same end, we perform fine-grained prosody modeling via\na Fully Hierarchical Variational AutoEncoder (FVAE) which additionally results\nin more expressive speech synthesis.",
    "descriptor": "\nComments: submitted to Interspeech 2022\n",
    "authors": [
      "Karolos Nikitaras",
      "Georgios Vamvoukakis",
      "Nikolaos Ellinas",
      "Konstantinos Klapsas",
      "Konstantinos Markopoulos",
      "Spyros Raptis",
      "June Sig Sung",
      "Gunu Jho",
      "Aimilios Chalamandaris",
      "Pirros Tsiakoulis"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2204.05070"
  },
  {
    "id": "arXiv:2204.05072",
    "title": "Few-Shot Object Detection in Unseen Domains",
    "abstract": "Few-shot object detection (FSOD) has thrived in recent years to learn novel\nobject classes with limited data by transfering knowledge gained on abundant\nbase classes. FSOD approaches commonly assume that both the scarcely provided\nexamples of novel classes and test-time data belong to the same domain.\nHowever, this assumption does not hold in various industrial and robotics\napplications (e.g., object grasping and manipulation), where a model can learn\nnovel classes from a source domain while inferring on classes from a different\ntarget domain. In this work, we address the task of zero-shot domain\nadaptation, also known as domain generalization, for FSOD. Specifically, we\nassume that neither images nor labels of the novel classes in the target domain\nare available during training. Our approach for solving the domain gap is\ntwo-fold. First, we leverage a meta-training paradigm, where we learn\ndomain-invariant features on the base classes. Second, we propose various data\naugmentations techniques on the few shots of novel classes to account for all\npossible domain-specific information. To further constraint the network into\nencoding domain-agnostic class-specific representations only, a contrastive\nloss is proposed to maximize the mutual information between foreground\nproposals and class prototypes, and to reduce the network's bias to the\nbackground information. Our experiments on the T-LESS dataset show that the\nproposed approach succeeds in alleviating the domain gap considerably without\nutilizing labels or images of novel categories from the target domain.",
    "descriptor": "",
    "authors": [
      "Karim Guirguis",
      "George Eskandar",
      "Matthias Kayser",
      "Bin Yang",
      "Juergen Beyerer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.05072"
  },
  {
    "id": "arXiv:2204.05076",
    "title": "End-to-End Speech Translation for Code Switched Speech",
    "abstract": "Code switching (CS) refers to the phenomenon of interchangeably using words\nand phrases from different languages. CS can pose significant accuracy\nchallenges to NLP, due to the often monolingual nature of the underlying\nsystems. In this work, we focus on CS in the context of English/Spanish\nconversations for the task of speech translation (ST), generating and\nevaluating both transcript and translation. To evaluate model performance on\nthis task, we create a novel ST corpus derived from existing public data sets.\nWe explore various ST architectures across two dimensions: cascaded (transcribe\nthen translate) vs end-to-end (jointly transcribe and translate) and\nunidirectional (source -> target) vs bidirectional (source <-> target). We show\nthat our ST architectures, and especially our bidirectional end-to-end\narchitecture, perform well on CS speech, even when no CS training data is used.",
    "descriptor": "\nComments: Accepted to Findings of ACL 2022\n",
    "authors": [
      "Orion Weller",
      "Matthias Sperber",
      "Telmo Pires",
      "Hendra Setiawan",
      "Christian Gollan",
      "Dominic Telaar",
      "Matthias Paulik"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2204.05076"
  },
  {
    "id": "arXiv:2204.05077",
    "title": "Learning Trajectories of Hamiltonian Systems with Neural Networks",
    "abstract": "Modeling of conservative systems with neural networks is an area of active\nresearch. A popular approach is to use Hamiltonian neural networks (HNNs) which\nrely on the assumptions that a conservative system is described with Hamilton's\nequations of motion. Many recent works focus on improving the integration\nschemes used when training HNNs. In this work, we propose to enhance HNNs with\nan estimation of a continuous-time trajectory of the modeled system using an\nadditional neural network, called a deep hidden physics model in the\nliterature. We demonstrate that the proposed integration scheme works well for\nHNNs, especially with low sampling rates, noisy and irregular observations.",
    "descriptor": "",
    "authors": [
      "Katsiaryna Haitsiukevich",
      "Alexander Ilin"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2204.05077"
  },
  {
    "id": "arXiv:2204.05080",
    "title": "Semantic Exploration from Language Abstractions and Pretrained  Representations",
    "abstract": "Continuous first-person 3D environments pose unique exploration challenges to\nreinforcement learning (RL) agents because of their high-dimensional state and\naction spaces. These challenges can be ameliorated by using semantically\nmeaningful state abstractions to define novelty for exploration. We propose\nthat learned representations shaped by natural language provide exactly this\nform of abstraction. In particular, we show that vision-language\nrepresentations, when pretrained on image captioning datasets sampled from the\ninternet, can drive meaningful, task-relevant exploration and improve\nperformance on 3D simulated environments. We also characterize why and how\nlanguage provides useful abstractions for exploration by comparing the impacts\nof using representations from a pretrained model, a language oracle, and\nseveral ablations. We demonstrate the benefits of our approach in two very\ndifferent task domains -- one that stresses the identification and manipulation\nof everyday objects, and one that requires navigational exploration in an\nexpansive world -- as well as two popular deep RL algorithms: Impala and R2D2.\nOur results suggest that using language-shaped representations could improve\nexploration for various algorithms and agents in challenging environments.",
    "descriptor": "",
    "authors": [
      "Allison C. Tam",
      "Neil C. Rabinowitz",
      "Andrew K. Lampinen",
      "Nicholas A. Roy",
      "Stephanie C. Y. Chan",
      "DJ Strouse",
      "Jane X. Wang",
      "Andrea Banino",
      "Felix Hill"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.05080"
  },
  {
    "id": "arXiv:2204.05082",
    "title": "An approach to improving sound-based vehicle speed estimation",
    "abstract": "We consider improving the performance of a recently proposed sound-based\nvehicle speed estimation method. In the original method, an intermediate\nfeature, referred to as the modified attenuation (MA), has been proposed for\nboth vehicle detection and speed estimation. The MA feature maximizes at the\ninstant of the vehicle's closest point of approach, which represents a training\nlabel extracted from video recording of the vehicle's pass by. In this paper,\nwe show that the original labeling approach is suboptimal and propose a method\nfor label correction. The method is tested on the VS10 dataset, which contains\n304 audio-video recordings of ten different vehicles. The results show that the\nproposed label correction method reduces average speed estimation error from\n7.39 km/h to 6.92 km/h. If the speed is discretized into 10 km/h classes, the\naccuracy of correct class prediction is improved from 53.2% to 53.8%, whereas\nwhen tolerance of one class offset is allowed, accuracy is improved from 93.4%\nto 94.3%.",
    "descriptor": "\nComments: Submitted to: 2022 Zooming Innovation in Consumer Technologies Conference (ZINC)\n",
    "authors": [
      "Nikola Bulatovic",
      "Slobodan Djukanovic"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2204.05082"
  },
  {
    "id": "arXiv:2204.05084",
    "title": "XMP-Font: Self-Supervised Cross-Modality Pre-training for Few-Shot Font  Generation",
    "abstract": "Generating a new font library is a very labor-intensive and time-consuming\njob for glyph-rich scripts. Few-shot font generation is thus required, as it\nrequires only a few glyph references without fine-tuning during test. Existing\nmethods follow the style-content disentanglement paradigm and expect novel\nfonts to be produced by combining the style codes of the reference glyphs and\nthe content representations of the source. However, these few-shot font\ngeneration methods either fail to capture content-independent style\nrepresentations, or employ localized component-wise style representations,\nwhich is insufficient to model many Chinese font styles that involve\nhyper-component features such as inter-component spacing and\n\"connected-stroke\". To resolve these drawbacks and make the style\nrepresentations more reliable, we propose a self-supervised cross-modality\npre-training strategy and a cross-modality transformer-based encoder that is\nconditioned jointly on the glyph image and the corresponding stroke labels. The\ncross-modality encoder is pre-trained in a self-supervised manner to allow\neffective capture of cross- and intra-modality correlations, which facilitates\nthe content-style disentanglement and modeling style representations of all\nscales (stroke-level, component-level and character-level). The pre-trained\nencoder is then applied to the downstream font generation task without\nfine-tuning. Experimental comparisons of our method with state-of-the-art\nmethods demonstrate our method successfully transfers styles of all scales. In\naddition, it only requires one reference glyph and achieves the lowest rate of\nbad cases in the few-shot font generation task 28% lower than the second best",
    "descriptor": "\nComments: Accepted by CVPR2022\n",
    "authors": [
      "Wei Liu",
      "Fangyue Liu",
      "Fei Din",
      "Qian He",
      "Zili Yi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.05084"
  },
  {
    "id": "arXiv:2204.05088",
    "title": "M^2BEV: Multi-Camera Joint 3D Detection and Segmentation with Unified  Birds-Eye View Representation",
    "abstract": "In this paper, we propose M$^2$BEV, a unified framework that jointly performs\n3D object detection and map segmentation in the Birds Eye View~(BEV) space with\nmulti-camera image inputs. Unlike the majority of previous works which\nseparately process detection and segmentation, M$^2$BEV infers both tasks with\na unified model and improves efficiency. M$^2$BEV efficiently transforms\nmulti-view 2D image features into the 3D BEV feature in ego-car coordinates.\nSuch BEV representation is important as it enables different tasks to share a\nsingle encoder. Our framework further contains four important designs that\nbenefit both accuracy and efficiency: (1) An efficient BEV encoder design that\nreduces the spatial dimension of a voxel feature map. (2) A dynamic box\nassignment strategy that uses learning-to-match to assign ground-truth 3D boxes\nwith anchors. (3) A BEV centerness re-weighting that reinforces with larger\nweights for more distant predictions, and (4) Large-scale 2D detection\npre-training and auxiliary supervision. We show that these designs\nsignificantly benefit the ill-posed camera-based 3D perception tasks where\ndepth information is missing. M$^2$BEV is memory efficient, allowing\nsignificantly higher resolution images as input, with faster inference speed.\nExperiments on nuScenes show that M$^2$BEV achieves state-of-the-art results in\nboth 3D object detection and BEV segmentation, with the best single model\nachieving 42.5 mAP and 57.0 mIoU in these two tasks, respectively.",
    "descriptor": "\nComments: Tech Report\n",
    "authors": [
      "Enze Xie",
      "Zhiding Yu",
      "Daquan Zhou",
      "Jonah Philion",
      "Anima Anandkumar",
      "Sanja Fidler",
      "Ping Luo",
      "Jose M. Alvarez"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.05088"
  },
  {
    "id": "arXiv:2204.05091",
    "title": "Linguistic communication as (inverse) reward design",
    "abstract": "Natural language is an intuitive and expressive way to communicate reward\ninformation to autonomous agents. It encompasses everything from concrete\ninstructions to abstract descriptions of the world. Despite this, natural\nlanguage is often challenging to learn from: it is difficult for machine\nlearning methods to make appropriate inferences from such a wide range of\ninput. This paper proposes a generalization of reward design as a unifying\nprinciple to ground linguistic communication: speakers choose utterances to\nmaximize expected rewards from the listener's future behaviors. We first extend\nreward design to incorporate reasoning about unknown future states in a linear\nbandit setting. We then define a speaker model which chooses utterances\naccording to this objective. Simulations show that short-horizon speakers\n(reasoning primarily about a single, known state) tend to use instructions,\nwhile long-horizon speakers (reasoning primarily about unknown, future states)\ntend to describe the reward function. We then define a pragmatic listener which\nperforms inverse reward design by jointly inferring the speaker's latent\nhorizon and rewards. Our findings suggest that this extension of reward design\nto linguistic communication, including the notion of a latent speaker horizon,\nis a promising direction for achieving more robust alignment outcomes from\nnatural language supervision.",
    "descriptor": "\nComments: 6 pages, 3 figures. Accepted at Learning from Natural Language Supervision workshop (ACL 2022)\n",
    "authors": [
      "Theodore R. Sumers",
      "Robert D. Hawkins",
      "Mark K. Ho",
      "Thomas L. Griffiths",
      "Dylan Hadfield-Menell"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.05091"
  },
  {
    "id": "arXiv:2204.05092",
    "title": "Efficient Geometric Linearization of Moving-Base Rigid Robot Dynamics",
    "abstract": "The linearization of the equations of motion of a robotics system about a\ngiven state-input trajectory, including a controlled equilibrium state, is a\nvaluable tool for model-based planning, closed-loop control, gain tuning, and\nstate estimation. Contrary to the case of fixed based manipulators with\nprismatic or rotary joints, the state space of moving-base robotic systems such\nas humanoids, quadruped robots, or aerial manipulators cannot be globally\nparametrized by a finite number of independent coordinates. This impossibility\nis a direct consequence of the fact that the state of these systems includes\nthe system's global orientation, formally described as an element of the\nspecial orthogonal group SO(3). As a consequence, obtaining the linearization\nof the equations of motion for these systems is typically resolved, from a\npractical perspective, by locally parameterizing the system's attitude by means\nof, e.g., Euler or Cardan angles. This has the drawback, however, of\nintroducing artificial parameterization singularities and extra derivative\ncomputations. In this contribution, we show that it is actually possible to\ndefine a notion of linearization that does not require the use of a local\nparameterization for the system's orientation, obtaining a mathematically\nelegant, recursive, and singularity-free linearization for moving-based robot\nsystems. Recursiveness, in particular, is obtained by proposing a nontrivial\nmodification of existing recursive algorithms to allow for computations of the\ngeometric derivatives of the inverse dynamics and the inverse of the mass\nmatrix of the robotic system. The correctness of the proposed algorithm is\nvalidated by means of a numerical comparison with the result obtained via\ngeometric finite difference.",
    "descriptor": "",
    "authors": [
      "Martijn Bos",
      "Silvio Traversaro",
      "Daniele Pucci",
      "Alessandro Saccon"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2204.05092"
  },
  {
    "id": "arXiv:2204.05093",
    "title": "When is Good Good Enough? Context Factors for Good Remote Work of Agile  Software Development Teams. The Otto Case",
    "abstract": "The Covid-19 pandemic led to several challenges in everybody working life.\nMany companies worldwide enabled comprehensive remote work settings for their\nemployees. Agile Software Development Teams are affected by the switch to\nremote work as agile methods setting communication and collaboration in focus.\nThe well-being and motivation of software engineers and developers, which\nimpacting their performance, are influenced by specific context factors. This\npaper aims to analyze identify specific context factors for a good remote work\nsetting. We designed a single case study at a German ecommerce company and\nconducted an experiment using a gamification approach including eight\nsemi-structured interviews. Our results show, that the agile software\ndevelopment team members to their health. Furthermore, most the team members\nvalue the gamification approach to put more focus on physical activities and\nthe health well-being. We discuss several practical implications and provide\nrecommendations for other teams and companies.",
    "descriptor": "",
    "authors": [
      "Lisa Rometsch",
      "Richard Wegner",
      "Florian Brusch",
      "Michael Neumann",
      "Lukas Linke"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2204.05093"
  },
  {
    "id": "arXiv:2204.05096",
    "title": "Block-Segmentation Vectors for Arousal Prediction using Semi-supervised  Learning",
    "abstract": "To handle emotional expressions in computer applications, Russell's circum-\nplex model has been useful for representing emotions according to valence and\narousal. In SentiWordNet, the level of valence is automatically assigned to a\nlarge number of synsets (groups of synonyms in WordNet) using semi-supervised\nlearning. However, when assigning the level of arousal, the existing method\nproposed for SentiWordNet reduces the accuracy of sentiment prediction. In this\npaper, we propose a block-segmentation vector for predicting the arousal levels\nof many synsets from a small number of labeled words using semi-supervised\nlearning. We analyze the distribution of arousal and non-arousal words in a\ncorpus of sentences by comparing it with the distribution of valence words. We\naddress the problem that arousal level prediction fails when arousal and\nnon-arousal words are mixed together in some sentences. To capture the features\nof such arousal and non-arousal words, we generate word vectors based on\ninverted indexes by block IDs, where the corpus is divided into blocks in the\nflow of sentences. In the evaluation experiment, we show that the results of\narousal prediction with the block-segmentation vectors outperform the results\nof the previous method in SentiWordNet.",
    "descriptor": "",
    "authors": [
      "Yuki Odaka",
      "Ken Kaneiwa"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.05096"
  },
  {
    "id": "arXiv:2204.05101",
    "title": "Concept Drift Adaptation for CTR Prediction in Online Advertising  Systems",
    "abstract": "Click-through rate (CTR) prediction is a crucial task in web search,\nrecommender systems, and online advertisement displaying. In practical\napplication, CTR models often serve with high-speed user-generated data\nstreams, whose underlying distribution rapidly changing over time. The concept\ndrift problem inevitably exists in those streaming data, which can lead to\nperformance degradation due to the timeliness issue. To ensure model freshness,\nincremental learning has been widely adopted in real-world production systems.\nHowever, it is hard for the incremental update to achieve the balance of the\nCTR models between the adaptability to capture the fast-changing trends and\ngeneralization ability to retain common knowledge. In this paper, we propose\nadaptive mixture of experts (AdaMoE), a new framework to alleviate the concept\ndrift problem by adaptive filtering in the data stream of CTR prediction. The\nextensive experiments on the offline industrial dataset and online A/B tests\nshow that our AdaMoE significantly outperforms all incremental learning\nframeworks considered.",
    "descriptor": "",
    "authors": [
      "Congcong Liu",
      "Yuejiang Li",
      "Xiwei Zhao",
      "Changping Peng",
      "Zhangang Lin",
      "Jingping Shao"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.05101"
  },
  {
    "id": "arXiv:2204.05102",
    "title": "Convolutional autoencoders for spatially-informed ensemble  post-processing",
    "abstract": "Ensemble weather predictions typically show systematic errors that have to be\ncorrected via post-processing. Even state-of-the-art post-processing methods\nbased on neural networks often solely rely on location-specific predictors that\nrequire an interpolation of the physical weather model's spatial forecast\nfields to the target locations. However, potentially useful predictability\ninformation contained in large-scale spatial structures within the input fields\nis potentially lost in this interpolation step. Therefore, we propose the use\nof convolutional autoencoders to learn compact representations of spatial input\nfields which can then be used to augment location-specific information as\nadditional inputs to post-processing models. The benefits of including this\nspatial information is demonstrated in a case study of 2-m temperature\nforecasts at surface stations in Germany.",
    "descriptor": "\nComments: Accepted as conference paper at ICLR 2022 - AI for Earth and Space Science Workshop, this https URL\n",
    "authors": [
      "Sebastian Lerch",
      "Kai L. Polsterer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Atmospheric and Oceanic Physics (physics.ao-ph)"
    ],
    "url": "https://arxiv.org/abs/2204.05102"
  },
  {
    "id": "arXiv:2204.05104",
    "title": "Self-Supervised Graph Neural Network for Multi-Source Domain Adaptation",
    "abstract": "Domain adaptation (DA) tries to tackle the scenarios when the test data does\nnot fully follow the same distribution of the training data, and multi-source\ndomain adaptation (MSDA) is very attractive for real world applications. By\nlearning from large-scale unlabeled samples, self-supervised learning has now\nbecome a new trend in deep learning. It is worth noting that both\nself-supervised learning and multi-source domain adaptation share a similar\ngoal: they both aim to leverage unlabeled data to learn more expressive\nrepresentations. Unfortunately, traditional multi-task self-supervised learning\nfaces two challenges: (1) the pretext task may not strongly relate to the\ndownstream task, thus it could be difficult to learn useful knowledge being\nshared from the pretext task to the target task; (2) when the same feature\nextractor is shared between the pretext task and the downstream one and only\ndifferent prediction heads are used, it is ineffective to enable inter-task\ninformation exchange and knowledge sharing. To address these issues, we propose\na novel \\textbf{S}elf-\\textbf{S}upervised \\textbf{G}raph Neural Network (SSG),\nwhere a graph neural network is used as the bridge to enable more effective\ninter-task information exchange and knowledge sharing. More expressive\nrepresentation is learned by adopting a mask token strategy to mask some domain\ninformation. Our extensive experiments have demonstrated that our proposed SSG\nmethod has achieved state-of-the-art results over four multi-source domain\nadaptation datasets, which have shown the effectiveness of our proposed SSG\nmethod from different aspects.",
    "descriptor": "",
    "authors": [
      "Jin Yuan",
      "Feng Hou",
      "Yangzhou Du",
      "Zhongchao Shi",
      "Xin Geng",
      "Jianping Fan",
      "Yong Rui"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.05104"
  },
  {
    "id": "arXiv:2204.05107",
    "title": "Challenges in implementing DDR3 memory interface on PCB systems: a  methodology for interfacing DDR3 SDRAM DIMM to an FPGA",
    "abstract": "Undoubtedly faster, larger and lower power per bit, but just how do you go\nabout interfacing a DDR3 SDRAM DIMM to an FPGA? The DDR3 standard addresses the\nfaster, more bandwidth and lower power per bit need, but it introduces new\ndesign challenges in addition to challenges introduced by DDR2 ODT, slew rate\nderating, etc. The DDR3 fly-by topology requirement means customers designing\nDDR3 memories must now account for write leveling and read de-skew on the PCB.\nThis paper will cover modeling, simulation, and physical layout approaches\nrequired to meet JEDEC-defined termination and tight timing requirements for\ndesigning DDR3 memory interfaces on PCB systems.",
    "descriptor": "\nComments: 12 pages, 10 figures, DesignCon 2008, published in 2008\n",
    "authors": [
      "Phil Murray",
      "Feras Al-Hawari"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2204.05107"
  },
  {
    "id": "arXiv:2204.05108",
    "title": "Improved Training of Physics-Informed Neural Networks with Model  Ensembles",
    "abstract": "Learning the solution of partial differential equations (PDEs) with a neural\nnetwork (known in the literature as a physics-informed neural network, PINN) is\nan attractive alternative to traditional solvers due to its elegancy, greater\nflexibility and the ease of incorporating observed data. However, training\nPINNs is notoriously difficult in practice. One problem is the existence of\nmultiple simple (but wrong) solutions which are attractive for PINNs when the\nsolution interval is too large. In this paper, we propose to expand the\nsolution interval gradually to make the PINN converge to the correct solution.\nTo find a good schedule for the solution interval expansion, we train an\nensemble of PINNs. The idea is that all ensemble members converge to the same\nsolution in the vicinity of observed data (e.g., initial conditions) while they\nmay be pulled towards different wrong solutions farther away from the\nobservations. Therefore, we use the ensemble agreement as the criterion for\nincluding new points for computing the loss derived from PDEs. We show\nexperimentally that the proposed method can improve the accuracy of the found\nsolution.",
    "descriptor": "",
    "authors": [
      "Katsiaryna Haitsiukevich",
      "Alexander Ilin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2204.05108"
  },
  {
    "id": "arXiv:2204.05112",
    "title": "FastMapSVM: Classifying Complex Objects Using the FastMap Algorithm and  Support-Vector Machines",
    "abstract": "Neural Networks and related Deep Learning methods are currently at the\nleading edge of technologies used for classifying objects. However, they\ngenerally demand large amounts of time and data for model training; and their\nlearned models can sometimes be difficult to interpret. In this paper, we\npresent FastMapSVM, a novel interpretable Machine Learning framework for\nclassifying complex objects. FastMapSVM combines the strengths of FastMap and\nSupport-Vector Machines. FastMap is an efficient linear-time algorithm that\nmaps complex objects to points in a Euclidean space, while preserving pairwise\nnon-Euclidean distances between them. We demonstrate the efficiency and\neffectiveness of FastMapSVM in the context of classifying seismograms. We show\nthat its performance, in terms of precision, recall, and accuracy, is\ncomparable to that of other state-of-the-art methods. However, compared to\nother methods, FastMapSVM uses significantly smaller amounts of time and data\nfor model training. It also provides a perspicuous visualization of the objects\nand the classification boundaries between them. We expect FastMapSVM to be\nviable for classification tasks in many other real-world domains.",
    "descriptor": "\nComments: 27 pages, 12 figures\n",
    "authors": [
      "Malcolm C. A. White",
      "Kushal Sharma",
      "Ang Li",
      "T. K. Satish Kumar",
      "Nori Nakata"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Geophysics (physics.geo-ph)"
    ],
    "url": "https://arxiv.org/abs/2204.05112"
  },
  {
    "id": "arXiv:2204.05113",
    "title": "ShiftNAS: Towards Automatic Generation of Advanced Mulitplication-Less  Neural Networks",
    "abstract": "Multiplication-less neural networks significantly reduce the time and energy\ncost on the hardware platform, as the compute-intensive multiplications are\nreplaced with lightweight bit-shift operations. However, existing bit-shift\nnetworks are all directly transferred from state-of-the-art convolutional\nneural networks (CNNs), which lead to non-negligible accuracy drop or even\nfailure of model convergence. To combat this, we propose ShiftNAS, the first\nframework tailoring Neural Architecture Search (NAS) to substantially reduce\nthe accuracy gap between bit-shift neural networks and their real-valued\ncounterparts. Specifically, we pioneer dragging NAS into a shift-oriented\nsearch space and endow it with the robust topology-related search strategy and\ncustom regularization and stabilization. As a result, our ShiftNAS breaks\nthrough the incompatibility of traditional NAS methods for bit-shift neural\nnetworks and achieves more desirable performance in terms of accuracy and\nconvergence. Extensive experiments demonstrate that ShiftNAS sets a new\nstate-of-the-art for bit-shift neural networks, where the accuracy increases\n(1.69-8.07)% on CIFAR10, (5.71-18.09)% on CIFAR100 and (4.36-67.07)% on\nImageNet, especially when many conventional CNNs fail to converge on ImageNet\nwith bit-shift weights.",
    "descriptor": "",
    "authors": [
      "Xiaoxuan Lou",
      "Guowen Xu",
      "Kangjie Chen",
      "Guanlin Li",
      "Jiwei Li",
      "Tianwei Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.05113"
  },
  {
    "id": "arXiv:2204.05114",
    "title": "PetroGAN: A novel GAN-based approach to generate realistic, label-free  petrographic datasets",
    "abstract": "Deep learning architectures have enriched data analytics in the geosciences,\ncomplementing traditional approaches to geological problems. Although deep\nlearning applications in geosciences show encouraging signs, the actual\npotential remains untapped. This is primarily because geological datasets,\nparticularly petrography, are limited, time-consuming, and expensive to obtain,\nrequiring in-depth knowledge to provide a high-quality labeled dataset. We\napproached these issues by developing a novel deep learning framework based on\ngenerative adversarial networks (GANs) to create the first realistic synthetic\npetrographic dataset. The StyleGAN2 architecture is selected to allow robust\nreplication of statistical and esthetical characteristics, and improving the\ninternal variance of petrographic data. The training dataset consists of 10070\nimages of rock thin sections both in plane- and cross-polarized light. The\nalgorithm trained for 264 GPU hours and reached a state-of-the-art Fr\\'echet\nInception Distance (FID) score of 12.49 for petrographic images. We further\nobserved the FID values vary with lithology type and image resolution. Our\nsurvey established that subject matter experts found the generated images were\nindistinguishable from real images. This study highlights that GANs are a\npowerful method for generating realistic synthetic data, experimenting with the\nlatent space, and as a future tool for self-labelling, reducing the effort of\ncreating geological datasets.",
    "descriptor": "",
    "authors": [
      "I. Ferreira",
      "L. Ochoa",
      "A. Koeshidayatullah"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2204.05114"
  },
  {
    "id": "arXiv:2204.05117",
    "title": "ReservoirComputing.jl: An Efficient and Modular Library for Reservoir  Computing Models",
    "abstract": "We introduce ReservoirComputing.jl, an open source Julia library for\nreservoir computing models. The software offers a great number of algorithms\npresented in the literature, and allows to expand on them with both internal\nand external tools in a simple way. The implementation is highly modular, fast\nand comes with a comprehensive documentation, which includes reproduced\nexperiments from literature. The code and documentation are hosted on Github\nunder an MIT license https://github.com/SciML/ReservoirComputing.jl.",
    "descriptor": "",
    "authors": [
      "Francesco Martinuzzi",
      "Chris Rackauckas",
      "Anas Abdelrehim",
      "Miguel D. Mahecha",
      "Karin Mora"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.05117"
  },
  {
    "id": "arXiv:2204.05122",
    "title": "Measuring and Mitigating the Risk of IP Reuse on Public Clouds",
    "abstract": "Public clouds provide scalable and cost-efficient computing through resource\nsharing. However, moving from traditional on-premises service management to\nclouds introduces new challenges; failure to correctly provision, maintain, or\ndecommission elastic services can lead to functional failure and vulnerability\nto attack. In this paper, we explore a broad class of attacks on clouds which\nwe refer to as cloud squatting. In a cloud squatting attack, an adversary\nallocates resources in the cloud (e.g., IP addresses) and thereafter leverages\nlatent configuration to exploit prior tenants. To measure and categorize cloud\nsquatting we deployed a custom Internet telescope within the Amazon Web\nServices us-east-1 region. Using this apparatus, we deployed over 3 million\nservers receiving 1.5 million unique IP addresses (56% of the available pool)\nover 101 days beginning in March of 2021. We identified 4 classes of cloud\nservices, 7 classes of third-party services, and DNS as sources of exploitable\nlatent configurations. We discovered that exploitable configurations were both\ncommon and in many cases extremely dangerous; we received over 5 million cloud\nmessages, many containing sensitive data such as financial transactions, GPS\nlocation, and PII. Within the 7 classes of third-party services, we identified\ndozens of exploitable software systems spanning hundreds of servers (e.g.,\ndatabases, caches, mobile applications, and web services). Lastly, we\nidentified 5446 exploitable domains spanning 231 eTLDs-including 105 in the top\n10,000 and 23 in the top 1000 popular domains. Through tenant disclosures we\nhave identified several root causes, including (a) a lack of organizational\ncontrols, (b) poor service hygiene, and (c) failure to follow best practices.\nWe conclude with a discussion of the space of possible mitigations and describe\nthe mitigations to be deployed by Amazon in response to this study.",
    "descriptor": "",
    "authors": [
      "Eric Pauley",
      "Ryan Sheatsley",
      "Blaine Hoak",
      "Quinn Burke",
      "Yohan Beugin",
      "Patrick McDaniel"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2204.05122"
  },
  {
    "id": "arXiv:2204.05125",
    "title": "ESCM$^2$: Entire Space Counterfactual Multi-Task Model for Post-Click  Conversion Rate Estimation",
    "abstract": "Accurate estimation of post-click conversion rate is critical for building\nrecommender systems, which has long been confronted with sample selection bias\nand data sparsity issues. Methods in the Entire Space Multi-task Model (ESMM)\nfamily leverage the sequential pattern of user actions, i.e.\n$impression\\rightarrow click \\rightarrow conversion$ to address data sparsity\nissue. However, they still fail to ensure the unbiasedness of CVR estimates. In\nthis paper, we theoretically demonstrate that ESMM suffers from the following\ntwo problems: (1) Inherent Estimation Bias (IEB), where the estimated CVR of\nESMM is inherently higher than the ground truth; (2) Potential Independence\nPriority (PIP) for CTCVR estimation, where there is a risk that the ESMM\noverlooks the causality from click to conversion. To this end, we devise a\nprincipled approach named Entire Space Counterfactual Multi-task Modelling\n(ESCM$^2$), which employs a counterfactual risk miminizer as a regularizer in\nESMM to address both IEB and PIP issues simultaneously. Extensive experiments\non offline datasets and online environments demonstrate that our proposed\nESCM$^2$ can largely mitigate the inherent IEB and PIP issues and achieve\nbetter performance than baseline models.",
    "descriptor": "",
    "authors": [
      "Hao Wang",
      "Tai-Wei Chang",
      "Tianqiao Liu",
      "Jianmin Huang",
      "Zhichao Chen",
      "Chao Yu",
      "Ruopeng Li",
      "Wei Chu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2204.05125"
  },
  {
    "id": "arXiv:2204.05126",
    "title": "General Hamiltonian Representation of ML Detection Relying on the  Quantum Approximate Optimization Algorithm",
    "abstract": "The quantum approximate optimization algorithm (QAOA) conceived for solving\ncombinatorial optimization problems has attracted significant interest since it\ncan be run on the existing noisy intermediate-scale quantum (NISQ) devices. A\nprimary step of using the QAOA is the efficient Hamiltonian construction based\non different problem instances. Hence, we solve the maximum likelihood (ML)\ndetection problem for general constellations by appropriately adapting the\nQAOA, which gives rise to a new paradigm in communication systems. We first\ntransform the ML detection problem into a weighted minimum $N$-satisfiability\n(WMIN-$N$-SAT) problem, where we formulate the objective function of the\nWMIN-$N$-SAT as a pseudo Boolean function. Furthermore, we formalize the\nconnection between the degree of the objective function and the Gray-labelled\nmodulation constellations. Explicitly, we show a series of results exploring\nthe connection between the coefficients of the monomials and the patterns of\nthe associated constellation points, which substantially simplifies the\nobjective function with respect to the problem Hamiltonian of the QAOA. In\nparticular, for an M-ary Gray-mapped quadrature amplitude modulation (MQAM)\nconstellation, we show that the specific qubits encoding the in-phase\ncomponents and those encoding the quadrature components are independent in the\nquantum system of interest, which allows the in-phase and quadrature components\nto be detected separately using the QAOA. Furthermore, we characterize the\ndegree of the objective function in the WMIN-$N$-SAT problem corresponding to\nthe ML detection of multiple-input and multiple-output (MIMO) channels.\nFinally, we evaluate the approximation ratio of the QAOA for the ML detection\nproblem of quadrature phase shift keying (QPSK) relying on QAOA circuits of\ndifferent depths.",
    "descriptor": "",
    "authors": [
      "Jingjing Cui",
      "Gui Lu Long",
      "Lajos Hanzo"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2204.05126"
  },
  {
    "id": "arXiv:2204.05128",
    "title": "Linking Scientific Instruments and HPC: Patterns, Technologies,  Experiences",
    "abstract": "Powerful detectors at modern experimental facilities routinely collect data\nat multiple GB/s. Online analysis methods are needed to enable the collection\nof only interesting subsets of such massive data streams, such as by explicitly\ndiscarding some data elements or by directing instruments to relevant areas of\nexperimental space. Such online analyses require methods for configuring and\nrunning high-performance distributed computing pipelines--what we call\nflows--linking instruments, HPC (e.g., for analysis, simulation, AI model\ntraining), edge computing (for analysis), data stores, metadata catalogs, and\nhigh-speed networks. In this article, we review common patterns associated with\nsuch flows and describe methods for instantiating those patterns. We also\npresent experiences with the application of these methods to the processing of\ndata from five different scientific instruments, each of which engages HPC\nresources for data inversion, machine learning model training, or other\npurposes. We also discuss implications of these new methods for operators and\nusers of scientific facilities.",
    "descriptor": "",
    "authors": [
      "Rafael Vescovi",
      "Ryan Chard",
      "Nickolaus Saint",
      "Ben Blaiszik",
      "Jim Pruyne",
      "Tekin Bicer",
      "Alex Lavens",
      "Zhengchun Liu",
      "Michael E. Papka",
      "Suresh Narayanan",
      "Nicholas Schwarz",
      "Kyle Chard",
      "Ian Foster"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2204.05128"
  },
  {
    "id": "arXiv:2204.05133",
    "title": "On the link between conscious function and general intelligence in  humans and machines",
    "abstract": "In popular media, there is often a connection drawn between the advent of\nawareness in artificial agents and those same agents simultaneously achieving\nhuman or superhuman level intelligence. In this work, we explore the validity\nand potential application of this seemingly intuitive link between\nconsciousness and intelligence. We do so by examining the cognitive abilities\nassociated with three contemporary theories of conscious function: Global\nWorkspace Theory (GWT), Information Generation Theory (IGT), and Attention\nSchema Theory (AST). We find that all three theories specifically relate\nconscious function to some aspect of domain-general intelligence in humans.\nWith this insight, we turn to the field of Artificial Intelligence (AI) and\nfind that, while still far from demonstrating general intelligence, many\nstate-of-the-art deep learning methods have begun to incorporate key aspects of\neach of the three functional theories. Given this apparent trend, we use the\nmotivating example of mental time travel in humans to propose ways in which\ninsights from each of the three theories may be combined into a unified model.\nWe believe that doing so can enable the development of artificial agents which\nare not only more generally intelligent but are also consistent with multiple\ncurrent theories of conscious function.",
    "descriptor": "",
    "authors": [
      "Arthur Juliani",
      "Kai Arulkumaran",
      "Shuntaro Sasai",
      "Ryota Kanai"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2204.05133"
  },
  {
    "id": "arXiv:2204.05135",
    "title": "Exergetic Port-Hamiltonian Systems: Navier-Stokes-Fourier Fluid",
    "abstract": "The Exergetic Port-Hamiltonian Systems modeling language combines a graphical\nsyntax inspired by bond graphs with a port-Hamiltonian semantics akin to the\nGENERIC formalism. The syntax enables the modular and hierarchical\nspecification of the composition pattern of lumped and distributed-parameter\nmodels. The semantics reflects the first and second law of thermodynamics as\nstructural properties. Interconnected and hierarchically defined models of\nmultiphysical thermodynamic systems can thus be expressed in a formal language\naccessible to humans and computers alike. We discuss a composed model of the\nNavier-Stokes-Fourier fluid on a fixed spatial domain as an example of an open\ndistributed-parameter system. At the top level, the system comprises five\nsubsystems which model kinetic energy storage, internal energy storage, thermal\nconduction, bulk viscosity, and shear viscosity.",
    "descriptor": "",
    "authors": [
      "Markus Lohmayer",
      "Sigrid Leyendecker"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Computational Physics (physics.comp-ph)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2204.05135"
  },
  {
    "id": "arXiv:2204.05136",
    "title": "SoK: Privacy Preserving Machine Learning using Functional Encryption:  Opportunities and Challenges",
    "abstract": "With the advent of functional encryption, new possibilities for computation\non encrypted data have arisen. Functional Encryption enables data owners to\ngrant third-party access to perform specified computations without disclosing\ntheir inputs. It also provides computation results in plain, unlike Fully\nHomomorphic Encryption. The ubiquitousness of machine learning has led to the\ncollection of massive private data in the cloud computing environment. This\nraises potential privacy issues and the need for more private and secure\ncomputing solutions. Numerous efforts have been made in privacy-preserving\nmachine learning (PPML) to address security and privacy concerns. There are\napproaches based on fully homomorphic encryption (FHE), secure multiparty\ncomputation (SMC), and, more recently, functional encryption (FE). However,\nFE-based PPML is still in its infancy and has not yet gotten much attention\ncompared to FHE-based PPML approaches. In this paper, we provide a\nsystematization of PPML works based on FE summarizing state-of-the-art in the\nliterature. We focus on Inner-product-FE and Quadratic-FE-based machine\nlearning models for the PPML applications. We analyze the performance and\nusability of the available FE libraries and their applications to PPML. We also\ndiscuss potential directions for FE-based PPML approaches. To the best of our\nknowledge, this is the first work to systematize FE-based PPML approaches.",
    "descriptor": "",
    "authors": [
      "Prajwal Panzade",
      "Daniel Takabi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.05136"
  },
  {
    "id": "arXiv:2204.05141",
    "title": "Learning Object-Centered Autotelic Behaviors with Graph Neural Networks",
    "abstract": "Although humans live in an open-ended world and endlessly face new\nchallenges, they do not have to learn from scratch each time they face the next\none. Rather, they have access to a handful of previously learned skills, which\nthey rapidly adapt to new situations. In artificial intelligence, autotelic\nagents, which are intrinsically motivated to represent and set their own goals,\nexhibit promising skill adaptation capabilities. However, these capabilities\nare highly constrained by their policy and goal space representations. In this\npaper, we propose to investigate the impact of these representations on the\nlearning capabilities of autotelic agents. We study different implementations\nof autotelic agents using four types of Graph Neural Networks policy\nrepresentations and two types of goal spaces, either geometric or\npredicate-based. We show that combining object-centered architectures that are\nexpressive enough with semantic relational goals enables an efficient transfer\nbetween skills and promotes behavioral diversity. We also release our\ngraph-based implementations to encourage further research in this direction.",
    "descriptor": "\nComments: 13 pages, 9 figures, published at the workshop on Agent learning in Open-Endedness (ALOE) at ICLR 2022\n",
    "authors": [
      "Ahmed Akakzia",
      "Olivier Sigaud"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2204.05141"
  },
  {
    "id": "arXiv:2204.05145",
    "title": "Focal Length and Object Pose Estimation via Render and Compare",
    "abstract": "We introduce FocalPose, a neural render-and-compare method for jointly\nestimating the camera-object 6D pose and camera focal length given a single RGB\ninput image depicting a known object. The contributions of this work are\ntwofold. First, we derive a focal length update rule that extends an existing\nstate-of-the-art render-and-compare 6D pose estimator to address the joint\nestimation task. Second, we investigate several different loss functions for\njointly estimating the object pose and focal length. We find that a combination\nof direct focal length regression with a reprojection loss disentangling the\ncontribution of translation, rotation, and focal length leads to improved\nresults. We show results on three challenging benchmark datasets that depict\nknown 3D models in uncontrolled settings. We demonstrate that our focal length\nand 6D pose estimates have lower error than the existing state-of-the-art\nmethods.",
    "descriptor": "\nComments: Accepted to CVPR2022. Code available at this http URL\n",
    "authors": [
      "Georgy Ponimatkin",
      "Yann Labb\u00e9",
      "Bryan Russell",
      "Mathieu Aubry",
      "Josef Sivic"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.05145"
  },
  {
    "id": "arXiv:2204.05148",
    "title": "Speech Sequence Embeddings using Nearest Neighbors Contrastive Learning",
    "abstract": "We introduce a simple neural encoder architecture that can be trained using\nan unsupervised contrastive learning objective which gets its positive samples\nfrom data-augmented k-Nearest Neighbors search. We show that when built on top\nof recent self-supervised audio representations, this method can be applied\niteratively and yield competitive SSE as evaluated on two tasks:\nquery-by-example of random sequences of speech, and spoken term discovery. On\nboth tasks our method pushes the state-of-the-art by a significant margin\nacross 5 different languages. Finally, we establish a benchmark on a\nquery-by-example task on the LibriSpeech dataset to monitor future improvements\nin the field.",
    "descriptor": "",
    "authors": [
      "Algayres Robin",
      "Adel Nabli",
      "Benoit Sagot",
      "Emmanuel Dupoux"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.05148"
  },
  {
    "id": "arXiv:2204.05149",
    "title": "The Carbon Footprint of Machine Learning Training Will Plateau, Then  Shrink",
    "abstract": "Machine Learning (ML) workloads have rapidly grown in importance, but raised\nconcerns about their carbon footprint. Four best practices can reduce ML\ntraining energy by up to 100x and CO2 emissions up to 1000x. By following best\npractices, overall ML energy use (across research, development, and production)\nheld steady at <15% of Google's total energy use for the past three years. If\nthe whole ML field were to adopt best practices, total carbon emissions from\ntraining would reduce. Hence, we recommend that ML papers include emissions\nexplicitly to foster competition on more than just model quality. Estimates of\nemissions in papers that omitted them have been off 100x-100,000x, so\npublishing emissions has the added benefit of ensuring accurate accounting.\nGiven the importance of climate change, we must get the numbers right to make\ncertain that we work on its biggest challenges.",
    "descriptor": "",
    "authors": [
      "David Patterson",
      "Joseph Gonzalez",
      "Urs H\u00f6lzle",
      "Quoc Le",
      "Chen Liang",
      "Lluis-Miquel Munguia",
      "Daniel Rothchild",
      "David So",
      "Maud Texier",
      "Jeff Dean"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "General Literature (cs.GL)"
    ],
    "url": "https://arxiv.org/abs/2204.05149"
  },
  {
    "id": "arXiv:2204.05151",
    "title": "Metaethical Perspectives on 'Benchmarking' AI Ethics",
    "abstract": "Benchmarks are seen as the cornerstone for measuring technical progress in\nArtificial Intelligence (AI) research and have been developed for a variety of\ntasks ranging from question answering to facial recognition. An increasingly\nprominent research area in AI is ethics, which currently has no set of\nbenchmarks nor commonly accepted way for measuring the 'ethicality' of an AI\nsystem. In this paper, drawing upon research in moral philosophy and\nmetaethics, we argue that it is impossible to develop such a benchmark. As\nsuch, alternative mechanisms are necessary for evaluating whether an AI system\nis 'ethical'. This is especially pressing in light of the prevalence of\napplied, industrial AI research. We argue that it makes more sense to talk\nabout 'values' (and 'value alignment') rather than 'ethics' when considering\nthe possible actions of present and future AI systems. We further highlight\nthat, because values are unambiguously relative, focusing on values forces us\nto consider explicitly what the values are and whose values they are. Shifting\nthe emphasis from ethics to values therefore gives rise to several new ways of\nunderstanding how researchers might advance research programmes for robustly\nsafe or beneficial AI. We conclude by highlighting a number of possible ways\nforward for the field as a whole, and we advocate for different approaches\ntowards more value-aligned AI research.",
    "descriptor": "\nComments: 39 Pages\n",
    "authors": [
      "Travis LaCroix",
      "Alexandra Sasha Luccioni"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.05151"
  },
  {
    "id": "arXiv:2204.05154",
    "title": "Submodular Maximization Subject to Matroid Intersection on the Fly",
    "abstract": "Despite a surge of interest in submodular maximization in the data stream\nmodel, there remain significant gaps in our knowledge about what can be\nachieved in this setting, especially when dealing with multiple constraints. In\nthis work, we nearly close several basic gaps in submodular maximization\nsubject to $k$ matroid constraints in the data stream model. We present a new\nhardness result showing that super polynomial memory in $k$ is needed to obtain\nan $o(k / \\log k)$-approximation. This implies near optimality of prior\nalgorithms. For the same setting, we show that one can nevertheless obtain a\nconstant-factor approximation by maintaining a set of elements whose size is\nindependent of the stream size. Finally, for bipartite matching constraints, a\nwell-known special case of matroid intersection, we present a new technique to\nobtain hardness bounds that are significantly stronger than those obtained with\nprior approaches. Prior results left it open whether a $2$-approximation may\nexist in this setting, and only a complexity-theoretic hardness of $1.91$ was\nknown. We prove an unconditional hardness of $2.69$.",
    "descriptor": "\nComments: 41 pages, 1 figure. arXiv admin note: text overlap with arXiv:2107.07183\n",
    "authors": [
      "Moran Feldman",
      "Ashkan Norouzi-Fard",
      "Ola Svensson",
      "Rico Zenklusen"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2204.05154"
  },
  {
    "id": "arXiv:2204.05156",
    "title": "How to Listen? Rethinking Visual Sound Localization",
    "abstract": "Localizing visual sounds consists on locating the position of objects that\nemit sound within an image. It is a growing research area with potential\napplications in monitoring natural and urban environments, such as wildlife\nmigration and urban traffic. Previous works are usually evaluated with datasets\nhaving mostly a single dominant visible object, and proposed models usually\nrequire the introduction of localization modules during training or dedicated\nsampling strategies, but it remains unclear how these design choices play a\nrole in the adaptability of these methods in more challenging scenarios. In\nthis work, we analyze various model choices for visual sound localization and\ndiscuss how their different components affect the model's performance, namely\nthe encoders' architecture, the loss function and the localization strategy.\nFurthermore, we study the interaction between these decisions, the model\nperformance, and the data, by digging into different evaluation datasets\nspanning different difficulties and characteristics, and discuss the\nimplications of such decisions in the context of real-world applications. Our\ncode and model weights are open-sourced and made available for further\napplications.",
    "descriptor": "\nComments: Submitted to INTERSPEECH 2022\n",
    "authors": [
      "Ho-Hsiang Wu",
      "Magdalena Fuentes",
      "Prem Seetharaman",
      "Juan Pablo Bello"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2204.05156"
  },
  {
    "id": "arXiv:2204.05157",
    "title": "SF-PATE: Scalable, Fair, and Private Aggregation of Teacher Ensembles",
    "abstract": "A critical concern in data-driven processes is to build models whose outcomes\ndo not discriminate against some demographic groups, including gender,\nethnicity, or age. To ensure non-discrimination in learning tasks, knowledge of\nthe group attributes is essential. However, in practice, these attributes may\nnot be available due to legal and ethical requirements. To address this\nchallenge, this paper studies a model that protects the privacy of the\nindividuals' sensitive information while also allowing it to learn\nnon-discriminatory predictors. A key characteristic of the proposed model is to\nenable the adoption of off-the-selves and non-private fair models to create a\nprivacy-preserving and fair model. The paper analyzes the relation between\naccuracy, privacy, and fairness, and the experimental evaluation illustrates\nthe benefits of the proposed models on several prediction tasks. In particular,\nthis proposal is the first to allow both scalable and accurate training of\nprivate and fair models for very large neural networks.",
    "descriptor": "",
    "authors": [
      "Cuong Tran",
      "Keyu Zhu",
      "Ferdinando Fioretto",
      "Pascal Van Hentenryck"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.05157"
  },
  {
    "id": "arXiv:2204.05158",
    "title": "Gaining Insights into Unrecognized User Utterances in Task-Oriented  Dialog Systems",
    "abstract": "The rapidly growing market demand for dialogue agents capable of\ngoal-oriented behavior has caused many tech-industry leaders to invest\nconsiderable efforts into task-oriented dialog systems. The performance and\nsuccess of these systems is highly dependent on the accuracy of their intent\nidentification -- the process of deducing the goal or meaning of the user's\nrequest and mapping it to one of the known intents for further processing.\nGaining insights into unrecognized utterances -- user requests the systems\nfails to attribute to a known intent -- is therefore a key process in\ncontinuous improvement of goal-oriented dialog systems.\nWe present an end-to-end pipeline for processing unrecognized user\nutterances, including a specifically-tailored clustering algorithm, a novel\napproach to cluster representative extraction, and cluster naming. We evaluated\nthe proposed clustering algorithm and compared its performance to\nout-of-the-box SOTA solutions, demonstrating its benefits in the analysis of\nunrecognized user requests.",
    "descriptor": "",
    "authors": [
      "Ella Rabinovich",
      "Matan Vetzler",
      "David Boaz",
      "Vineet Kumar",
      "Gaurav Pandey",
      "Ateret Anaby-Tavor"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.05158"
  },
  {
    "id": "arXiv:2204.05164",
    "title": "Generative Biomedical Entity Linking via Knowledge Base-Guided  Pre-training and Synonyms-Aware Fine-tuning",
    "abstract": "Entities lie in the heart of biomedical natural language understanding, and\nthe biomedical entity linking (EL) task remains challenging due to the\nfine-grained and diversiform concept names. Generative methods achieve\nremarkable performances in general domain EL with less memory usage while\nrequiring expensive pre-training. Previous biomedical EL methods leverage\nsynonyms from knowledge bases (KB) which is not trivial to inject into a\ngenerative method. In this work, we use a generative approach to model\nbiomedical EL and propose to inject synonyms knowledge in it. We propose\nKB-guided pre-training by constructing synthetic samples with synonyms and\ndefinitions from KB and require the model to recover concept names. We also\npropose synonyms-aware fine-tuning to select concept names for training, and\npropose decoder prompt and multi-synonyms constrained prefix tree for\ninference. Our method achieves state-of-the-art results on several biomedical\nEL tasks without candidate selection which displays the effectiveness of\nproposed pre-training and fine-tuning strategies.",
    "descriptor": "\nComments: Accepted by NAACL 2022\n",
    "authors": [
      "Hongyi Yuan",
      "Zheng Yuan",
      "Sheng Yu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.05164"
  },
  {
    "id": "arXiv:2204.05168",
    "title": "The Principle of Least Sensing: A Privacy-Friendly Sensing Paradigm for  Urban Big Data Analytics",
    "abstract": "With the worldwide emergence of data protection regulations, how to conduct\nlaw-regulated big data analytics becomes a challenging and fundamental problem.\nThis article introduces the principle of least sensing, a promising sensing\nparadigm toward law-regulated big data analytics.",
    "descriptor": "",
    "authors": [
      "Leye Wang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.05168"
  },
  {
    "id": "arXiv:2204.05169",
    "title": "Towards End-to-End Integration of Dialog History for Improved Spoken  Language Understanding",
    "abstract": "Dialog history plays an important role in spoken language understanding (SLU)\nperformance in a dialog system. For end-to-end (E2E) SLU, previous work has\nused dialog history in text form, which makes the model dependent on a cascaded\nautomatic speech recognizer (ASR). This rescinds the benefits of an E2E system\nwhich is intended to be compact and robust to ASR errors. In this paper, we\npropose a hierarchical conversation model that is capable of directly using\ndialog history in speech form, making it fully E2E. We also distill semantic\nknowledge from the available gold conversation transcripts by jointly training\na similar text-based conversation model with an explicit tying of acoustic and\nsemantic embeddings. We also propose a novel technique that we call DropFrame\nto deal with the long training time incurred by adding dialog history in an E2E\nmanner. On the HarperValleyBank dialog dataset, our E2E history integration\noutperforms a history independent baseline by 7.7% absolute F1 score on the\ntask of dialog action recognition. Our model performs competitively with the\nstate-of-the-art history based cascaded baseline, but uses 48% fewer\nparameters. In the absence of gold transcripts to fine-tune an ASR model, our\nmodel outperforms this baseline by a significant margin of 10% absolute F1\nscore.",
    "descriptor": "\nComments: 5 pages, 1 figure\n",
    "authors": [
      "Vishal Sunder",
      "Samuel Thomas",
      "Hong-Kwang J. Kuo",
      "Jatin Ganhotra",
      "Brian Kingsbury",
      "Eric Fosler-Lussier"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.05169"
  },
  {
    "id": "arXiv:2204.05172",
    "title": "Event Transformer",
    "abstract": "The event camera is a bio-vision inspired camera with high dynamic range,\nhigh response speed, and low power consumption, recently attracting extensive\nattention for its use in vast vision tasks. Unlike the conventional cameras\nthat output intensity frame at a fixed time interval, event camera records the\npixel brightness change (a.k.a., event) asynchronously (in time) and sparsely\n(in space). Existing methods often aggregate events occurred in a predefined\ntemporal duration for downstream tasks, which apparently overlook varying\nbehaviors of fine-grained temporal events. This work proposes the Event\nTransformer to directly process the event sequence in its native vectorized\ntensor format. It cascades a Local Transformer (LXformer) for exploiting the\nlocal temporal correlation, a Sparse Conformer (SCformer) for embedding the\nlocal spatial similarity, and a Global Transformer (GXformer) for further\naggregating the global information in a serial means to effectively\ncharacterize the time and space correlations from input raw events for the\ngeneration of effective spatiotemporal features used for tasks. %In both\nLXformer and SCformer, Experimental studies have been extensively conducted in\ncomparison to another fourteen existing algorithms upon five different datasets\nwidely used for classification. Quantitative results report the\nstate-of-the-arts classification accuracy and the least computational resource\nrequirements, of the Event Transformer, making it practically attractive for\nevent-based vision tasks.",
    "descriptor": "",
    "authors": [
      "Zhihao Li",
      "M. Salman Asif",
      "Zhan Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.05172"
  },
  {
    "id": "arXiv:2204.05173",
    "title": "Machine Learning State-of-the-Art with Uncertainties",
    "abstract": "With the availability of data, hardware, software ecosystem and relevant\nskill sets, the machine learning community is undergoing a rapid development\nwith new architectures and approaches appearing at high frequency every year.\nIn this article, we conduct an exemplary image classification study in order to\ndemonstrate how confidence intervals around accuracy measurements can greatly\nenhance the communication of research results as well as impact the reviewing\nprocess. In addition, we explore the hallmarks and limitations of this\napproximation. We discuss the relevance of this approach reflecting on a\nspotlight publication of ICLR22. A reproducible workflow is made available as\nan open-source adjoint to this publication. Based on our discussion, we make\nsuggestions for improving the authoring and reviewing process of machine\nlearning articles.",
    "descriptor": "\nComments: 9 pages, 6 figures. Accepted at the ICLR2022 workshop on ML Evaluation Standards. Code to reproduce results can be obtained from this https URL\n",
    "authors": [
      "Peter Steinbach",
      "Felicita Gernhardt",
      "Mahnoor Tanveer",
      "Steve Schmerler",
      "Sebastian Starke"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.05173"
  },
  {
    "id": "arXiv:2204.05176",
    "title": "Towards Painless Policy Optimization for Constrained MDPs",
    "abstract": "We study policy optimization in an infinite horizon, $\\gamma$-discounted\nconstrained Markov decision process (CMDP). Our objective is to return a policy\nthat achieves large expected reward with a small constraint violation. We\nconsider the online setting with linear function approximation and assume\nglobal access to the corresponding features. We propose a generic primal-dual\nframework that allows us to bound the reward sub-optimality and constraint\nviolation for arbitrary algorithms in terms of their primal and dual regret on\nonline linear optimization problems. We instantiate this framework to use\ncoin-betting algorithms and propose the Coin Betting Politex (CBP) algorithm.\nAssuming that the action-value functions are $\\varepsilon_b$-close to the span\nof the $d$-dimensional state-action features and no sampling errors, we prove\nthat $T$ iterations of CBP result in an $O\\left(\\frac{1}{(1 - \\gamma)^3\n\\sqrt{T}} + \\frac{\\varepsilon_b\\sqrt{d}}{(1 - \\gamma)^2} \\right)$ reward\nsub-optimality and an $O\\left(\\frac{1}{(1 - \\gamma)^2 \\sqrt{T}} +\n\\frac{\\varepsilon_b \\sqrt{d}}{1 - \\gamma} \\right)$ constraint violation.\nImportantly, unlike gradient descent-ascent and other recent methods, CBP does\nnot require extensive hyperparameter tuning. Via experiments on synthetic and\nCartpole environments, we demonstrate the effectiveness and robustness of CBP.",
    "descriptor": "\nComments: Paper under submission. 27 pages, 12 figures\n",
    "authors": [
      "Arushi Jain",
      "Sharan Vaswani",
      "Reza Babanezhad",
      "Csaba Szepesvari",
      "Doina Precup"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.05176"
  },
  {
    "id": "arXiv:2204.05182",
    "title": "Towards Understanding Analytics in Software Startups",
    "abstract": "Analytics plays a crucial role in the data-informed decision-making processes\nof modern businesses. Unlike established software companies, software startups\nare not seen utilizing the potential of analytics even though a startup process\nshould be primarily data-driven. There has been little understanding in the\nliterature about analytics for software startups. This study set out to address\nthe knowledge gap by exploring how analytics is understood in the context of\nsoftware startups. To this end, we collected the qualitative data of three\nanalytics platforms that are mostly used by startups from multiple sources. We\ncovered platform documentation as well as experience reports of the software\nstartups using these platforms. The data was analyzed using content analysis\ntechniques. Four high-level concepts were identified that encapsulate the real\nunderstanding of software startups on analytics, including instrumentation of\nanalytics, experimentation, diagnostic analysis, and getting insights. The\nfirst concept describes how startups set up analytics and the latter three\nillustrate the usage scenarios of analytics. This study is the first step\ntoward understanding analytics in the software startup context. The identified\nconcepts can guide further investigation of analytics in this context. It also\nprovides some insights for software startups to set up analytics for\ndata-informed decisions. Given the limitation of the data used in the study,\nthe immediate next step is to ground as well as validate the acquired\nunderstanding using the primary data, by directly interacting with software\nstartups.",
    "descriptor": "\nComments: 8 pages, 2 figures, accepted for presentation at 5th International Workshop on Software-intensive Business: Towards Sustainable Software Business, Pittsburgh, PA, USA\n",
    "authors": [
      "Usman Rafiq"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2204.05182"
  },
  {
    "id": "arXiv:2204.05183",
    "title": "Building an ASR Error Robust Spoken Virtual Patient System in a Highly  Class-Imbalanced Scenario Without Speech Data",
    "abstract": "A Virtual Patient (VP) is a powerful tool for training medical students to\ntake patient histories, where responding to a diverse set of spoken questions\nis essential to simulate natural conversations with a student. The performance\nof such a Spoken Language Understanding system (SLU) can be adversely affected\nby both the presence of Automatic Speech Recognition (ASR) errors in the test\ndata and a high degree of class imbalance in the SLU training data. While these\ntwo issues have been addressed separately in prior work, we develop a novel\ntwo-step training methodology that tackles both these issues effectively in a\nsingle dialog agent. As it is difficult to collect spoken data from users\nwithout a functioning SLU system, our method does not rely on spoken data for\ntraining, rather we use an ASR error predictor to \"speechify\" the text data.\nOur method shows significant improvements over strong baselines on the VP\nintent classification task at various word error rate settings.",
    "descriptor": "\nComments: 5 pages, 3 figures\n",
    "authors": [
      "Vishal Sunder",
      "Prashant Serai",
      "Eric Fosler-Lussier"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2204.05183"
  },
  {
    "id": "arXiv:2204.05184",
    "title": "Domain Adversarial Graph Convolutional Network Based on RSSI and  Crowdsensing for Indoor Localization",
    "abstract": "In recent years, due to the wider WiFi coverage and the popularization of\nmobile communication devices, the technology of indoor positioning using WiFi\nfingerprints has been rapidly developed. Currently, most supervised methods\nneed to collect a large amount of data to construct fingerprint datasets, which\nis labor-intensive and time-consuming. To solve the problem, we proposed a\nnovel WiDAGCN model that can be trained with a few labeled site survey data and\nunlabeled crowdsensing WiFi fingerprints. To comprehensively represent the\ntopology structure of the data, we constructed heterogeneous graphs according\nto the received signal strength indicators (RSSIs) between the waypoints and\nWiFi access points (APs). We focus on the graph convolutional network (GCN)\nmethod and the representation of graph-level features, which were rarely\ninvolved in previous WiFi indoor localization studies. Then, we try to minimize\nthe difference between the source and target domains and make full use of the\nunlabeled data in the target domain using the domain adversarial training\nscheme. A public indoor localization dataset containing different buildings was\nused to evaluate the performance of the model. The experimental results show\nthat our system can achieve a competitive localization accuracy in large\nbuildings such as shopping malls.",
    "descriptor": "",
    "authors": [
      "Mingxin Zhang",
      "Zipei Fan",
      "Ryosuke Shibasaki",
      "Xuan Song"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2204.05184"
  },
  {
    "id": "arXiv:2204.05185",
    "title": "Uniform Complexity for Text Generation",
    "abstract": "Powerful language models such as GPT-2 have shown promising results in tasks\nsuch as narrative generation which can be useful in an educational setup. These\nmodels, however, should be consistent with the linguistic properties of\ntriggers used. For example, if the reading level of an input text prompt is\nappropriate for low-leveled learners (ex. A2 in the CEFR), then the generated\ncontinuation should also assume this particular level. Thus, we propose the\ntask of uniform complexity for text generation which serves as a call to make\nexisting language generators uniformly complex with respect to prompts used.\nOur study surveyed over 160 linguistic properties for evaluating text\ncomplexity and found out that both humans and GPT-2 models struggle in\npreserving the complexity of prompts in a narrative generation setting.",
    "descriptor": "",
    "authors": [
      "Joseph Marvin Imperial"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.05185"
  },
  {
    "id": "arXiv:2204.05186",
    "title": "Correcting Robot Plans with Natural Language Feedback",
    "abstract": "When humans design cost or goal specifications for robots, they often produce\nspecifications that are ambiguous, underspecified, or beyond planners' ability\nto solve. In these cases, corrections provide a valuable tool for\nhuman-in-the-loop robot control. Corrections might take the form of new goal\nspecifications, new constraints (e.g. to avoid specific objects), or hints for\nplanning algorithms (e.g. to visit specific waypoints). Existing correction\nmethods (e.g. using a joystick or direct manipulation of an end effector)\nrequire full teleoperation or real-time interaction. In this paper, we explore\nnatural language as an expressive and flexible tool for robot correction. We\ndescribe how to map from natural language sentences to transformations of cost\nfunctions. We show that these transformations enable users to correct goals,\nupdate robot motions to accommodate additional user preferences, and recover\nfrom planning errors. These corrections can be leveraged to get 81% and 93%\nsuccess rates on tasks where the original planner failed, with either one or\ntwo language corrections. Our method makes it possible to compose multiple\nconstraints and generalizes to unseen scenes, objects, and sentences in\nsimulated environments and real-world environments.",
    "descriptor": "\nComments: 10 pages, 13 figures\n",
    "authors": [
      "Pratyusha Sharma",
      "Balakumar Sundaralingam",
      "Valts Blukis",
      "Chris Paxton",
      "Tucker Hermans",
      "Antonio Torralba",
      "Jacob Andreas",
      "Dieter Fox"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.05186"
  },
  {
    "id": "arXiv:2204.05188",
    "title": "Tokenwise Contrastive Pretraining for Finer Speech-to-BERT Alignment in  End-to-End Speech-to-Intent Systems",
    "abstract": "Recent advances in End-to-End (E2E) Spoken Language Understanding (SLU) have\nbeen primarily due to effective pretraining of speech representations. One such\npretraining paradigm is the distillation of semantic knowledge from\nstate-of-the-art text-based models like BERT to speech encoder neural networks.\nThis work is a step towards doing the same in a much more efficient and\nfine-grained manner where we align speech embeddings and BERT embeddings on a\ntoken-by-token basis. We introduce a simple yet novel technique that uses a\ncross-modal attention mechanism to extract token-level contextual embeddings\nfrom a speech encoder such that these can be directly compared and aligned with\nBERT based contextual embeddings. This alignment is performed using a novel\ntokenwise contrastive loss. Fine-tuning such a pretrained model to perform\nintent recognition using speech directly yields state-of-the-art performance on\ntwo widely used SLU datasets. Our model improves further when fine-tuned with\nadditional regularization using SpecAugment especially when speech is noisy,\ngiving an absolute improvement as high as 8% over previous results.",
    "descriptor": "\nComments: 5 pages, 2 figures\n",
    "authors": [
      "Vishal Sunder",
      "Eric Fosler-Lussier",
      "Samuel Thomas",
      "Hong-Kwang J. Kuo",
      "Brian Kingsbury"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2204.05188"
  },
  {
    "id": "arXiv:2204.05191",
    "title": "Meshfree Collocation for Elliptic Problems with Discontinuous  Coefficients",
    "abstract": "We present a meshfree generalized finite difference method (GFDM) for solving\nPoisson's equation with coefficients containing jump discontinuities up to\nseveral orders of magnitude. To discretize the diffusion operator, we formulate\na strong form method that uses a smearing of the discontinuity, and a\nconservative formulation based on locally computed Voronoi cells. Additionally,\nwe propose a novel conservative formulation of enforcing Neumann boundary\nconditions that is compatible with the conservative formulation of the\ndiffusion operator. Finally, we introduce a way to switch between the strong\nform and the conservative formulation to obtain a locally conservative and\npositivity preserving scheme. The presented numerical methods are benchmarked\nagainst four test cases with varying complexity and different jump magnitudes\non point clouds that are not aligned to the discontinuity. Our results show\nthat the new hybrid method that switches between the two formulations produces\nbetter results than the standard GFDM approach for high jumps in the\ndiffusivity parameter.",
    "descriptor": "",
    "authors": [
      "Heinrich Kraus",
      "J\u00f6rg Kuhnert",
      "Andreas Meister",
      "Pratik Suchde"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2204.05191"
  },
  {
    "id": "arXiv:2204.05192",
    "title": "Time-Adaptive Recurrent Neural Networks",
    "abstract": "Data are often sampled irregularly in time. Dealing with this using Recurrent\nNeural Networks (RNNs) traditionally involved ignoring the fact, feeding the\ntime differences as additional inputs, or resampling the data. All these\nmethods have their shortcomings. We propose an elegant alternative approach\nwhere instead the RNN is in effect resampled in time to match the time of the\ndata. We use Echo State Network (ESN) and Gated Recurrent Unit (GRU) as the\nbasis for our solution. Such RNNs can be seen as discretizations of\ncontinuous-time dynamical systems, which gives a solid theoretical ground for\nour approach. Similar recent observations have been made in feed-forward neural\nnetworks as neural ordinary differential equations. Our Time-Adaptive ESN\n(TAESN) and GRU (TAGRU) models allow for a direct model time setting and\nrequire no additional training, parameter tuning, or computation compared to\nthe regular counterparts, thus retaining their original efficiency. We confirm\nempirically that our models can effectively compensate for the\ntime-non-uniformity of the data and demonstrate that they compare favorably to\ndata resampling, classical RNN methods, and alternative RNN models proposed to\ndeal with time irregularities on several real-world nonuniform-time datasets.",
    "descriptor": "\nComments: Originally written in May 2019\n",
    "authors": [
      "Mantas Luko\u0161evi\u010dius",
      "Arnas Uselis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2204.05192"
  },
  {
    "id": "arXiv:2204.05193",
    "title": "Worldwide city transport typology prediction with sentence-BERT based  supervised learning via Wikipedia",
    "abstract": "An overwhelming majority of the world's human population lives in urban areas\nand cities. Understanding a city's transportation typology is immensely\nvaluable for planners and policy makers whose decisions can potentially impact\nmillions of city residents. Despite the value of understanding a city's\ntypology, labeled data (city and it's typology) is scarce, and spans at most a\nfew hundred cities in the current transportation literature. To break this\nbarrier, we propose a supervised machine learning approach to predict a city's\ntypology given the information in its Wikipedia page. Our method leverages\nrecent breakthroughs in natural language processing, namely sentence-BERT, and\nshows how the text-based information from Wikipedia can be effectively used as\na data source for city typology prediction tasks that can be applied to over\n2000 cities worldwide. We propose a novel method for low-dimensional city\nrepresentation using a city's Wikipedia page, which makes supervised learning\nof city typology labels tractable even with a few hundred labeled samples.\nThese features are used with labeled city samples to train binary classifiers\n(logistic regression) for four different city typologies: (i) congestion, (ii)\nauto-heavy, (iii) transit-heavy, and (iv) bike-friendly cities resulting in\nreasonably high AUC scores of 0.87, 0.86, 0.61 and 0.94 respectively. Our\napproach provides sufficient flexibility for incorporating additional variables\nin the city typology models and can be applied to study other city typologies\nas well. Our findings can assist a diverse group of stakeholders in\ntransportation and urban planning fields, and opens up new opportunities for\nusing text-based information from Wikipedia (or similar platforms) as data\nsources in such fields.",
    "descriptor": "",
    "authors": [
      "Srushti Rath",
      "Joseph Y.J. Chow"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.05193"
  },
  {
    "id": "arXiv:2204.05196",
    "title": "Automatically Learning Fallback Strategies with Model-Free Reinforcement  Learning in Safety-Critical Driving Scenarios",
    "abstract": "When learning to behave in a stochastic environment where safety is critical,\nsuch as driving a vehicle in traffic, it is natural for human drivers to plan\nfallback strategies as a backup to use if ever there is an unexpected change in\nthe environment. Knowing to expect the unexpected, and planning for such\noutcomes, increases our capability for being robust to unseen scenarios and may\nhelp prevent catastrophic failures. Control of Autonomous Vehicles (AVs) has a\nparticular interest in knowing when and how to use fallback strategies in the\ninterest of safety. Due to imperfect information available to an AV about its\nenvironment, it is important to have alternate strategies at the ready which\nmight not have been deduced from the original training data distribution.\nIn this paper we present a principled approach for a model-free Reinforcement\nLearning (RL) agent to capture multiple modes of behaviour in an environment.\nWe introduce an extra pseudo-reward term to the reward model, to encourage\nexploration to areas of state-space different from areas privileged by the\noptimal policy. We base this reward term on a distance metric between the\ntrajectories of agents, in order to force policies to focus on different areas\nof state-space than the initial exploring agent. Throughout the paper, we refer\nto this particular training paradigm as learning fallback strategies.\nWe apply this method to an autonomous driving scenario, and show that we are\nable to learn useful policies that would have otherwise been missed out on\nduring training, and unavailable to use when executing the control algorithm.",
    "descriptor": "\nComments: To appear in proceedings of International Conference on Machine Learning Technologies (ICMLT) 2022\n",
    "authors": [
      "Ugo Lecerf",
      "Christelle Yemdji-Tchassi",
      "S\u00e9bastien Aubert",
      "Pietro Michiardi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.05196"
  },
  {
    "id": "arXiv:2204.05200",
    "title": "Human vs Objective Evaluation of Colourisation Performance",
    "abstract": "Automatic colourisation of grey-scale images is the process of creating a\nfull-colour image from the grey-scale prior. It is an ill-posed problem, as\nthere are many plausible colourisations for a given grey-scale prior. The\ncurrent SOTA in auto-colourisation involves image-to-image type Deep\nConvolutional Neural Networks with Generative Adversarial Networks showing the\ngreatest promise. The end goal of colourisation is to produce full colour\nimages that appear plausible to the human viewer, but human assessment is\ncostly and time consuming. This work assesses how well commonly used objective\nmeasures correlate with human opinion. We also attempt to determine what facets\nof colourisation have the most significant effect on human opinion. For each of\n20 images from the BSD dataset, we create 65 recolourisations made up of local\nand global changes. Opinion scores are then crowd sourced using the Amazon\nMechanical Turk and together with the images this forms an extensible dataset\ncalled the Human Evaluated Colourisation Dataset (HECD). While we find\nstatistically significant correlations between human-opinion scores and a small\nnumber of objective measures, the strength of the correlations is low. There is\nalso evidence that human observers are most intolerant to an incorrect hue of\nnaturally occurring objects.",
    "descriptor": "",
    "authors": [
      "Se\u00e1n Mullery",
      "Paul F. Whelan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.05200"
  },
  {
    "id": "arXiv:2204.05206",
    "title": "Access to care: analysis of the geographical distribution of healthcare  using Linked Open Data",
    "abstract": "Background: Access to medical care is strongly dependent on resource\nallocation, such as the geographical distribution of medical facilities.\nNevertheless, this data is usually restricted to country official\ndocumentation, not available to the public. While some medical facilities' data\nis accessible as semantic resources on the Web, it is not consistent in its\nmodeling and has yet to be integrated into a complete, open, and specialized\nrepository. This work focuses on generating a comprehensive semantic dataset of\nmedical facilities worldwide containing extensive information about such\nfacilities' geo-location.\nResults: For this purpose, we collect, align, and link various open-source\ndatabases where medical facilities' information may be present. This work\nallows us to evaluate each data source along various dimensions, such as\ncompleteness, correctness, and interlinking with other sources, all critical\naspects of current knowledge representation technologies.\nConclusions: Our contributions directly benefit stakeholders in the\nbiomedical and health domain (patients, healthcare professionals, companies,\nregulatory authorities, and researchers), who will now have a better overview\nof the access to and distribution of medical facilities.",
    "descriptor": "",
    "authors": [
      "Selene Baez Santamaria",
      "Emmanouil Manousogiannis",
      "Guusje Boomgaard",
      "Linh P. Tran",
      "Zoltan Szlavik",
      "Robert-Jan Sips"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.05206"
  },
  {
    "id": "arXiv:2204.05208",
    "title": "\"FIJO\": a French Insurance Soft Skill Detection Dataset",
    "abstract": "Understanding the evolution of job requirements is becoming more important\nfor workers, companies and public organizations to follow the fast\ntransformation of the employment market. Fortunately, recent natural language\nprocessing (NLP) approaches allow for the development of methods to\nautomatically extract information from job ads and recognize skills more\nprecisely. However, these efficient approaches need a large amount of annotated\ndata from the studied domain which is difficult to access, mainly due to\nintellectual property. This article proposes a new public dataset, FIJO,\ncontaining insurance job offers, including many soft skill annotations. To\nunderstand the potential of this dataset, we detail some characteristics and\nsome limitations. Then, we present the results of skill detection algorithms\nusing a named entity recognition approach and show that transformers-based\nmodels have good token-wise performances on this dataset. Lastly, we analyze\nsome errors made by our best model to emphasize the difficulties that may arise\nwhen applying NLP approaches.",
    "descriptor": "\nComments: Accepted in CAIA 2022\n",
    "authors": [
      "David Beauchemin",
      "Julien Laumonier",
      "Yvan Le Ster",
      "Marouane Yassine"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.05208"
  },
  {
    "id": "arXiv:2204.05209",
    "title": "Can instability variations warn developers when open-source projects  boost?",
    "abstract": "Although architecture instability has been studied and measured using a\nvariety of metrics, a deeper analysis of which project parts are less stable\nand how such instability varies over time is still needed. While having more\ninformation on architecture instability is, in general, useful for any software\ndevelopment project, it is especially important in Open Source Software (OSS)\nprojects where the supervision of the development process is more difficult to\nachieve. In particular, we are interested when OSS projects grow from a small\ncontrolled environment (i.e., the cathedral phase) to a community-driven\nproject (i.e., the bazaar phase). In such a transition, the project often\nexplodes in terms of software size and number of contributing developers.\nHence, the complexity of the newly added features, and the frequency of the\ncommits and files modified may cause significant variations of the instability\nof the structure of the classes and packages. Consequently, in this registered\nreport we suggest ways to analyze the instability in OSS projects, especially\nduring that sensitive phase where they become community-driven. We intend to\nsuggest ways to predict the evolution of the instability in several OSS\nprojects. Our preliminary results show that it seems possible to provide\nmeaningful estimations that can be useful for OSS teams before a project grows\nin excess.",
    "descriptor": "",
    "authors": [
      "Alejandro Valdezate",
      "Rafael Capilla",
      "Gregorio Robles",
      "Victor Salamanca"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2204.05209"
  },
  {
    "id": "arXiv:2204.05210",
    "title": "Bridging the Gap between Language Models and Cross-Lingual Sequence  Labeling",
    "abstract": "Large-scale cross-lingual pre-trained language models (xPLMs) have shown\neffectiveness in cross-lingual sequence labeling tasks (xSL), such as\ncross-lingual machine reading comprehension (xMRC) by transferring knowledge\nfrom a high-resource language to low-resource languages. Despite the great\nsuccess, we draw an empirical observation that there is a training objective\ngap between pre-training and fine-tuning stages: e.g., mask language modeling\nobjective requires local understanding of the masked token and the\nspan-extraction objective requires global understanding and reasoning of the\ninput passage/paragraph and question, leading to the discrepancy between\npre-training and xMRC. In this paper, we first design a pre-training task\ntailored for xSL named Cross-lingual Language Informative Span Masking (CLISM)\nto eliminate the objective gap in a self-supervised manner. Second, we present\nContrAstive-Consistency Regularization (CACR), which utilizes contrastive\nlearning to encourage the consistency between representations of input parallel\nsequences via unsupervised cross-lingual instance-wise training signals during\npre-training. By these means, our methods not only bridge the gap between\npretrain-finetune, but also enhance PLMs to better capture the alignment\nbetween different languages. Extensive experiments prove that our method\nachieves clearly superior results on multiple xSL benchmarks with limited\npre-training data. Our methods also surpass the previous state-of-the-art\nmethods by a large margin in few-shot data settings, where only a few hundred\ntraining examples are available.",
    "descriptor": "\nComments: 15 pages\n",
    "authors": [
      "Nuo Chen",
      "Linjun Shou",
      "Ming Gong",
      "Jian Pei",
      "Daxin Jiang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.05210"
  },
  {
    "id": "arXiv:2204.05211",
    "title": "Entities, Dates, and Languages: Zero-Shot on Historical Texts with T0",
    "abstract": "In this work, we explore whether the recently demonstrated zero-shot\nabilities of the T0 model extend to Named Entity Recognition for\nout-of-distribution languages and time periods. Using a historical newspaper\ncorpus in 3 languages as test-bed, we use prompts to extract possible named\nentities. Our results show that a naive approach for prompt-based zero-shot\nmultilingual Named Entity Recognition is error-prone, but highlights the\npotential of such an approach for historical languages lacking labeled\ndatasets. Moreover, we also find that T0-like models can be probed to predict\nthe publication date and language of a document, which could be very relevant\nfor the study of historical texts.",
    "descriptor": "",
    "authors": [
      "Francesco De Toni",
      "Christopher Akiki",
      "Javier de la Rosa",
      "Cl\u00e9mentine Fourrier",
      "Enrique Manjavacas",
      "Stefan Schweter",
      "Daniel van Strien"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.05211"
  },
  {
    "id": "arXiv:2204.05212",
    "title": "Single-Turn Debate Does Not Help Humans Answer Hard  Reading-Comprehension Questions",
    "abstract": "Current QA systems can generate reasonable-sounding yet false answers without\nexplanation or evidence for the generated answer, which is especially\nproblematic when humans cannot readily check the model's answers. This presents\na challenge for building trust in machine learning systems. We take inspiration\nfrom real-world situations where difficult questions are answered by\nconsidering opposing sides (see Irving et al., 2018). For multiple-choice QA\nexamples, we build a dataset of single arguments for both a correct and\nincorrect answer option in a debate-style set-up as an initial step in training\nmodels to produce explanations for two candidate answers. We use long contexts\n-- humans familiar with the context write convincing explanations for\npre-selected correct and incorrect answers, and we test if those explanations\nallow humans who have not read the full context to more accurately determine\nthe correct answer. We do not find that explanations in our set-up improve\nhuman accuracy, but a baseline condition shows that providing human-selected\ntext snippets does improve accuracy. We use these findings to suggest ways of\nimproving the debate set up for future data collection efforts.",
    "descriptor": "\nComments: Accepted to LNLS workshop (co-located with ACL 2022). 12 pages total, 9 figures, 2 tables\n",
    "authors": [
      "Alicia Parrish",
      "Harsh Trivedi",
      "Ethan Perez",
      "Angelica Chen",
      "Nikita Nangia",
      "Jason Phang",
      "Samuel R. Bowman"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.05212"
  },
  {
    "id": "arXiv:2204.05217",
    "title": "Persona-driven Dominant/Submissive Map (PDSM) Generation for Tutorials",
    "abstract": "In this paper, we present a method for automated persona-driven video game\ntutorial level generation. Tutorial levels are scenarios in which the player\ncan explore and discover different rules and game mechanics. Procedural\npersonas can guide generators to create content which encourages or discourages\ncertain playstyle behaviors. In this system, we use procedural personas to\ncalculate the behavioral characteristics of levels which are evolved using the\nquality-diversity algorithm known as Constrained MAP-Elites. An evolved map's\nquality is determined by its simplicity: the simpler it is, the better it is.\nWithin this work, we show that the generated maps can strongly encourage or\ndiscourage different persona-like behaviors and range from simple solutions to\ncomplex puzzle-levels, making them perfect candidates for a tutorial generative\nsystem.",
    "descriptor": "\nComments: 10 pages, 7 figures, 2 tables\n",
    "authors": [
      "Michael Cerny Green",
      "Ahmed Khalifa",
      "M Charity",
      "Julian Togelius"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.05217"
  },
  {
    "id": "arXiv:2204.05218",
    "title": "An Optimal Experimental Design Approach for Light Configurations in  Photometric Stereo",
    "abstract": "This paper presents a technique for finding the surface normal of an object\nfrom a set of images obtained under different lighting positions. The method\npresented is based on the principles of Photometric Stereo (PS) combined with\nOptimum Experimental Design (OED) and Parameter Estimation (PE). Unclear by the\napproach of photometric stereo, and many models based thereon, is how to\nposition the light sources. So far, this is done by using heuristic approaches\nthis leads to suboptimal and non-data driven positioning of the light sources.\nBut what if the optimal positions of the light sources are calculated for\nphotometric stereo? To this end, in this contribution, the effect of\npositioning the light sources on the quality of the normal vector for PS is\nevaluated. Furthermore, a new approach in this direction is derived and\nformulated. For the calculation of the surface normal of a Lambertian surface,\nthe approach based on calibrated photometric stereo; for the estimation the\noptimal position of the light sources the approach is premised on parameter\nestimation and optimum experimental design. The approach is tested using\nsynthetic and real-data. Based on results it can be seen that the surface\nnormal estimated with the new method is more detailed than with conventional\nmethods.",
    "descriptor": "\nComments: 16 pages, 11 figures\n",
    "authors": [
      "Hamza Gardi",
      "Sebastian F. Walter",
      "Christoph S. Garbe"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2204.05218"
  },
  {
    "id": "arXiv:2204.05220",
    "title": "CFA: Constraint-based Finetuning Approach for Generalized Few-Shot  Object Detection",
    "abstract": "Few-shot object detection (FSOD) seeks to detect novel categories with\nlimited data by leveraging prior knowledge from abundant base data. Generalized\nfew-shot object detection (G-FSOD) aims to tackle FSOD without forgetting\npreviously seen base classes and, thus, accounts for a more realistic scenario,\nwhere both classes are encountered during test time. While current FSOD methods\nsuffer from catastrophic forgetting, G-FSOD addresses this limitation yet\nexhibits a performance drop on novel tasks compared to the state-of-the-art\nFSOD. In this work, we propose a constraint-based finetuning approach (CFA) to\nalleviate catastrophic forgetting, while achieving competitive results on the\nnovel task without increasing the model capacity. CFA adapts a continual\nlearning method, namely Average Gradient Episodic Memory (A-GEM) to G-FSOD.\nSpecifically, more constraints on the gradient search strategy are imposed from\nwhich a new gradient update rule is derived, allowing for better knowledge\nexchange between base and novel classes. To evaluate our method, we conduct\nextensive experiments on MS-COCO and PASCAL-VOC datasets. Our method\noutperforms current FSOD and G-FSOD approaches on the novel task with minor\ndegeneration on the base task. Moreover, CFA is orthogonal to FSOD approaches\nand operates as a plug-and-play module without increasing the model capacity or\ninference time.",
    "descriptor": "",
    "authors": [
      "Karim Guirguis",
      "Ahmed Hendawy",
      "George Eskandar",
      "Mohamed Abdelsamad",
      "Matthias Kayser",
      "Juergen Beyerer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.05220"
  },
  {
    "id": "arXiv:2204.05222",
    "title": "INTERSPEECH 2022 Audio Deep Packet Loss Concealment Challenge",
    "abstract": "Audio Packet Loss Concealment (PLC) is the hiding of gaps in audio streams\ncaused by data transmission failures in packet switched networks. This is a\ncommon problem, and of increasing importance as end-to-end VoIP telephony and\nteleconference systems become the default and ever more widely used form of\ncommunication in business as well as in personal usage. This paper presents the\nINTERSPEECH 2022 Audio Deep Packet Loss Concealment challenge. We first give an\noverview of the PLC problem, and introduce some classical approaches to PLC as\nwell as recent work. We then present the open source dataset released as part\nof this challenge as well as the evaluation methods and metrics used to\ndetermine the winner. We also briefly introduce PLCMOS, a novel data-driven\nmetric that can be used to quickly evaluate the performance PLC systems.\nFinally, we present the results of the INTERSPEECH 2022 Audio Deep PLC\nChallenge, and provide a summary of important takeaways.",
    "descriptor": "\nComments: 4 pages + 1 page references, 1 figure, 2 tables. Submitted to INTERSPEECH 2022\n",
    "authors": [
      "Lorenz Diener",
      "Sten Sootla",
      "Solomiya Branets",
      "Ando Saabas",
      "Robert Aichner",
      "Ross Cutler"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2204.05222"
  },
  {
    "id": "arXiv:2204.05223",
    "title": "Resource Allocation for Multiuser Edge Inference with Batching and Early  Exiting (Extended Version)",
    "abstract": "The deployment of inference services at the network edge, called edge\ninference, offloads computation-intensive inference tasks from mobile devices\nto edge servers, thereby enhancing the former's capabilities and battery lives.\nIn a multiuser system, the joint allocation of communication-and-computation\n($\\text{C}^\\text{2}$) resources (i.e., scheduling and bandwidth allocation) is\nmade challenging by adopting efficient inference techniques, batching and early\nexiting, and further complicated by the heterogeneity in users' requirements on\naccuracy and latency. Batching groups multiple tasks into one batch for\nparallel processing to reduce time-consuming memory access and thereby boosts\nthe throughput (i.e., completed task per second). On the other hand, early\nexiting allows a task to exit from a deep-neural network without traversing the\nwhole network to support a tradeoff between accuracy and latency. In this work,\nwe study optimal $\\text{C}^\\text{2}$ resource allocation with batching and\nearly exiting, which is an NP-complete integer program. A set of efficient\nalgorithms are designed under the criterion of maximum throughput by tackling\nthe challenge. Experimental results demonstrate that both optimal and\nsub-optimal $\\text{C}^\\text{2}$ resource allocation algorithms can leverage\nintegrated batching and early exiting to achieve 200% throughput gain over\nconventional schemes.",
    "descriptor": "\nComments: This is an extended version of a submission to IEEE journal\n",
    "authors": [
      "Zhiyan Liu",
      "Qiao Lan",
      "Kaibin Huang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2204.05223"
  },
  {
    "id": "arXiv:2204.05224",
    "title": "Performance analysis of WDM in LoS communications with arbitrary  orientation and position",
    "abstract": "This letter focuses on the wavenumber-division-multiplexing (WDM) scheme that\nwas recently proposed in [1] for line-of-sight communications between parallel\nspatially-continuous electromagnetic segments. Our aim is to analyze the\nperformance of WDM, combined with different digital processing architectures,\nwhen the electromagnetic segments have an arbitrary orientation and position.\nTo this end, we first show how the general electromagnetic MIMO (multiple-input\nmultiple-output) model from [1] can be particularized to the case of interest\nand then use numerical results to evaluate the impact of system parameters\n(e.g., horizontal and vertical distances, azimuth and elevation orientations).\nIt turns out that WDM performs satisfactorily also when the transmit and\nreceive segments are not in boresight direction of each other.",
    "descriptor": "\nComments: 5 pages, 7 figures, submitted to IEEE Wireless Communications Letters\n",
    "authors": [
      "Antonio Alberto D'Amico",
      "Luca Sanguinetti",
      "Merouane Debbah"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2204.05224"
  },
  {
    "id": "arXiv:2204.05227",
    "title": "The self-learning AI controller for adaptive power beaming with  fiber-array laser transmitter system",
    "abstract": "In this study we consider adaptive power beaming with fiber-array laser\ntransmitter system in presence of atmospheric turbulence. For optimization of\npower transition through the atmosphere fiber-array is traditionally controlled\nby stochastic parallel gradient descent (SPGD) algorithm where control feedback\nis provided via radio frequency link by an optical-to-electrical power\nconversion sensor, attached to a cooperative target. The SPGD algorithm\ncontinuously and randomly perturbs voltages applied to fiber-array phase\nshifters and fiber tip positioners in order to maximize sensor signal, i.e.\nuses, so-called, \"blind\" optimization principle.\nIn opposite to this approach a perspective artificially intelligent (AI)\ncontrol systems for synthesis of optimal control can utilize various pupil- or\ntarget-plane data available for the analysis including wavefront sensor data,\nphoto-voltaic array (PVA) data, other optical or atmospheric parameters, and\npotentially can eliminate well-known drawbacks of SPGD-based controllers. In\nthis study an optimal control is synthesized by a deep neural network (DNN)\nusing target-plane PVA sensor data as its input. A DNN training is occurred\nonline in sync with control system operation and is performed by applying of\nsmall perturbations to DNN's outputs. This approach does not require initial\nDNN's pre-training as well as guarantees optimization of system performance in\ntime. All theoretical results are verified by numerical experiments.",
    "descriptor": "\nComments: 21 pages, 11 figures\n",
    "authors": [
      "A.M. Vorontsov",
      "G.A. Filimonov"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Artificial Intelligence (cs.AI)",
      "Optics (physics.optics)"
    ],
    "url": "https://arxiv.org/abs/2204.05227"
  },
  {
    "id": "arXiv:2204.05229",
    "title": "Mixture-of-experts VAEs can disregard variation in surjective multimodal  data",
    "abstract": "Machine learning systems are often deployed in domains that entail data from\nmultiple modalities, for example, phenotypic and genotypic characteristics\ndescribe patients in healthcare. Previous works have developed multimodal\nvariational autoencoders (VAEs) that generate several modalities. We consider\nsubjective data, where single datapoints from one modality (such as class\nlabels) describe multiple datapoints from another modality (such as images). We\ntheoretically and empirically demonstrate that multimodal VAEs with a mixture\nof experts posterior can struggle to capture variability in such surjective\ndata.",
    "descriptor": "\nComments: Accepted at the NeurIPS 2021 workshop on Bayesian Deep Learning\n",
    "authors": [
      "Jannik Wolff",
      "Tassilo Klein",
      "Moin Nabi",
      "Rahul G. Krishnan",
      "Shinichi Nakajima"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2204.05229"
  },
  {
    "id": "arXiv:2204.05230",
    "title": "GDC- Generalized Distribution Calibration for Few-Shot Learning",
    "abstract": "Few shot learning is an important problem in machine learning as large\nlabelled datasets take considerable time and effort to assemble. Most few-shot\nlearning algorithms suffer from one of two limitations- they either require the\ndesign of sophisticated models and loss functions, thus hampering\ninterpretability; or employ statistical techniques but make assumptions that\nmay not hold across different datasets or features. Developing on recent work\nin extrapolating distributions of small sample classes from the most similar\nlarger classes, we propose a Generalized sampling method that learns to\nestimate few-shot distributions for classification as weighted random variables\nof all large classes. We use a form of covariance shrinkage to provide\nrobustness against singular covariances due to overparameterized features or\nsmall datasets. We show that our sampled points are close to few-shot classes\neven in cases when there are no similar large classes in the training set. Our\nmethod works with arbitrary off-the-shelf feature extractors and outperforms\nexisting state-of-the-art on miniImagenet, CUB and Stanford Dogs datasets by 3%\nto 5% on 5way-1shot and 5way-5shot tasks and by 1% in challenging cross domain\ntasks.",
    "descriptor": "\nComments: 13 pages of main text, 9 pages of supplementary\n",
    "authors": [
      "Shakti Kumar",
      "Hussain Zaidi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.05230"
  },
  {
    "id": "arXiv:2204.05231",
    "title": "Towards Generalizeable Semantic Product Search by Text Similarity  Pre-training on Search Click Logs",
    "abstract": "Recently, semantic search has been successfully applied to e-commerce product\nsearch and the learned semantic space(s) for query and product encoding are\nexpected to generalize to unseen queries or products. Yet, whether\ngeneralization can conveniently emerge has not been thoroughly studied in the\ndomain thus far. In this paper, we examine several general-domain and\ndomain-specific pre-trained Roberta variants and discover that general-domain\nfine-tuning does not help generalization, which aligns with the discovery of\nprior art. Proper domain-specific fine-tuning with clickstream data can lead to\nbetter model generalization, based on a bucketed analysis of a publicly\navailable manual annotated query-product pair data.",
    "descriptor": "\nComments: 9 pages\n",
    "authors": [
      "Zheng Liu",
      "Wei Zhang",
      "Yan Chen",
      "Weiyi Sun",
      "Michael Du",
      "Benjamin Schroeder"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.05231"
  },
  {
    "id": "arXiv:2204.05232",
    "title": "Survey of Aspect-based Sentiment Analysis Datasets",
    "abstract": "Aspect-based sentiment analysis (ABSA) is a natural language processing\nproblem that requires analyzing user-generated reviews in order to determine:\na) The target entity being reviewed, b) The high-level aspect to which it\nbelongs, and c) The sentiment expressed toward the targets and the aspects.\nNumerous yet scattered corpora for ABSA make it difficult for researchers to\nquickly identify corpora best suited for a specific ABSA subtask. This study\naims to present a database of corpora that can be used to train and assess\nautonomous ABSA systems. Additionally, we provide an overview of the major\ncorpora concerning the various ABSA and its subtasks and highlight several\ncorpus features that researchers should consider when selecting a corpus. We\nconclude that further large-scale ABSA corpora are required. Additionally,\nbecause each corpus is constructed differently, it is time-consuming for\nresearchers to experiment with a novel ABSA algorithm on many corpora and often\nemploy just one or a few corpora. The field would benefit from an agreement on\na data standard for ABSA corpora. Finally, we discuss the advantages and\ndisadvantages of current collection approaches and make recommendations for\nfuture ABSA dataset gathering.",
    "descriptor": "",
    "authors": [
      "Siva Uday Sampreeth Chebolu",
      "Franck Dernoncourt",
      "Nedim Lipka",
      "Thamar Solorio"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.05232"
  },
  {
    "id": "arXiv:2204.05235",
    "title": "Data Splits and Metrics for Method Benchmarking on Surgical Action  Triplet Datasets",
    "abstract": "In addition to generating data and annotations, devising sensible data\nsplitting strategies and evaluation metrics is essential for the creation of a\nbenchmark dataset. This practice ensures consensus on the usage of the data,\nhomogeneous assessment, and uniform comparison of research methods on the\ndataset. This study focuses on CholecT50, which is a 50 video surgical dataset\nthat formalizes surgical activities as triplets of <instrument, verb, target>.\nIn this paper, we introduce the standard splits for the CholecT50 and CholecT45\ndatasets and show how they compare with existing use of the dataset. CholecT45\nis the first public release of 45 videos of CholecT50 dataset. We also develop\na metrics library, ivtmetrics, for model evaluation on surgical triplets.\nFurthermore, we conduct a benchmark study by reproducing baseline methods in\nthe most predominantly used deep learning frameworks (PyTorch and TensorFlow)\nto evaluate them using the proposed data splits and metrics and release them\npublicly to support future research. The proposed data splits and evaluation\nmetrics will enable global tracking of research progress on the dataset and\nfacilitate optimal model selection for further deployment.",
    "descriptor": "\nComments: Official CholecT50 dataset split, 11 pages, 2 figures, 12 tables\n",
    "authors": [
      "Chinedu Innocent Nwoye",
      "Nicolas Padoy"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.05235"
  },
  {
    "id": "arXiv:2204.05239",
    "title": "Exploring the Universal Vulnerability of Prompt-based Learning Paradigm",
    "abstract": "Prompt-based learning paradigm bridges the gap between pre-training and\nfine-tuning, and works effectively under the few-shot setting. However, we find\nthat this learning paradigm inherits the vulnerability from the pre-training\nstage, where model predictions can be misled by inserting certain triggers into\nthe text. In this paper, we explore this universal vulnerability by either\ninjecting backdoor triggers or searching for adversarial triggers on\npre-trained language models using only plain text. In both scenarios, we\ndemonstrate that our triggers can totally control or severely decrease the\nperformance of prompt-based models fine-tuned on arbitrary downstream tasks,\nreflecting the universal vulnerability of the prompt-based learning paradigm.\nFurther experiments show that adversarial triggers have good transferability\namong language models. We also find conventional fine-tuning models are not\nvulnerable to adversarial triggers constructed from pre-trained language\nmodels. We conclude by proposing a potential solution to mitigate our attack\nmethods. Code and data are publicly available at\nhttps://github.com/leix28/prompt-universal-vulnerability",
    "descriptor": "\nComments: Accepted to Findings of NAACL 2022\n",
    "authors": [
      "Lei Xu",
      "Yangyi Chen",
      "Ganqu Cui",
      "Hongcheng Gao",
      "Zhiyuan Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.05239"
  },
  {
    "id": "arXiv:2204.05245",
    "title": "Approximate Top-$m$ Arm Identification with Heterogeneous Reward  Variances",
    "abstract": "We study the effect of reward variance heterogeneity in the approximate\ntop-$m$ arm identification setting. In this setting, the reward for the $i$-th\narm follows a $\\sigma^2_i$-sub-Gaussian distribution, and the agent needs to\nincorporate this knowledge to minimize the expected number of arm pulls to\nidentify $m$ arms with the largest means within error $\\epsilon$ out of the $n$\narms, with probability at least $1-\\delta$. We show that the worst-case sample\ncomplexity of this problem is $$\\Theta\\left( \\sum_{i =1}^n\n\\frac{\\sigma_i^2}{\\epsilon^2} \\ln\\frac{1}{\\delta} + \\sum_{i \\in G^{m}}\n\\frac{\\sigma_i^2}{\\epsilon^2} \\ln(m) + \\sum_{j \\in G^{l}}\n\\frac{\\sigma_j^2}{\\epsilon^2} \\text{Ent}(\\sigma^2_{G^{r}}) \\right),$$ where\n$G^{m}, G^{l}, G^{r}$ are certain specific subsets of the overall arm set $\\{1,\n2, \\ldots, n\\}$, and $\\text{Ent}(\\cdot)$ is an entropy-like function which\nmeasures the heterogeneity of the variance proxies. The upper bound of the\ncomplexity is obtained using a divide-and-conquer style algorithm, while the\nmatching lower bound relies on the study of a dual formulation.",
    "descriptor": "\nComments: AISTATS 2022\n",
    "authors": [
      "Ruida Zhou",
      "Chao Tian"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2204.05245"
  },
  {
    "id": "arXiv:2204.05248",
    "title": "Learning Downstream Task by Selectively Capturing Complementary  Knowledge from Multiple Self-supervisedly Learning Pretexts",
    "abstract": "Self-supervised learning (SSL), as a newly emerging unsupervised\nrepresentation learning paradigm, generally follows a two-stage learning\npipeline: 1) learning invariant and discriminative representations with\nauto-annotation pretext(s), then 2) transferring the representations to assist\ndownstream task(s). Such two stages are usually implemented separately, making\nthe learned representation learned agnostic to the downstream tasks. Currently,\nmost works are devoted to exploring the first stage. Whereas, it is less\nstudied on how to learn downstream tasks with limited labeled data using the\nalready learned representations. Especially, it is crucial and challenging to\nselectively utilize the complementary representations from diverse pretexts for\na downstream task. In this paper, we technically propose a novel solution by\nleveraging the attention mechanism to adaptively squeeze suitable\nrepresentations for the tasks. Meanwhile, resorting to information theory, we\ntheoretically prove that gathering representation from diverse pretexts is more\neffective than a single one. Extensive experiments validate that our scheme\nsignificantly exceeds current popular pretext-matching based methods in\ngathering knowledge and relieving negative transfer in downstream tasks.",
    "descriptor": "",
    "authors": [
      "Quan Feng",
      "Qingyuan Wu",
      "Jiayu Yao",
      "Songcan Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.05248"
  },
  {
    "id": "arXiv:2204.05251",
    "title": "Bayes Point Rule Set Learning",
    "abstract": "Interpretability is having an increasingly important role in the design of\nmachine learning algorithms. However, interpretable methods tend to be less\naccurate than their black-box counterparts. Among others, DNFs (Disjunctive\nNormal Forms) are arguably the most interpretable way to express a set of\nrules. In this paper, we propose an effective bottom-up extension of the\npopular FIND-S algorithm to learn DNF-type rulesets. The algorithm greedily\nfinds a partition of the positive examples. The produced DNF is a set of\nconjunctive rules, each corresponding to the most specific rule consistent with\na part of positive and all negative examples. We also propose two principled\nextensions of this method, approximating the Bayes Optimal Classifier by\naggregating DNF decision rules. Finally, we provide a methodology to\nsignificantly improve the explainability of the learned rules while retaining\ntheir generalization capabilities. An extensive comparison with\nstate-of-the-art symbolic and statistical methods on several benchmark data\nsets shows that our proposal provides an excellent balance between\nexplainability and accuracy.",
    "descriptor": "",
    "authors": [
      "Fabio Aiolli",
      "Luca Bergamin",
      "Tommaso Carraro",
      "Mirko Polato"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.05251"
  },
  {
    "id": "arXiv:2204.05255",
    "title": "Narcissus: A Practical Clean-Label Backdoor Attack with Limited  Information",
    "abstract": "Backdoor attacks insert malicious data into a training set so that, during\ninference time, it misclassifies inputs that have been patched with a backdoor\ntrigger as the malware specified label. For backdoor attacks to bypass human\ninspection, it is essential that the injected data appear to be correctly\nlabeled. The attacks with such property are often referred to as \"clean-label\nattacks.\" Existing clean-label backdoor attacks require knowledge of the entire\ntraining set to be effective. Obtaining such knowledge is difficult or\nimpossible because training data are often gathered from multiple sources\n(e.g., face images from different users). It remains a question whether\nbackdoor attacks still present a real threat.\nThis paper provides an affirmative answer to this question by designing an\nalgorithm to mount clean-label backdoor attacks based only on the knowledge of\nrepresentative examples from the target class. With poisoning equal to or less\nthan 0.5% of the target-class data and 0.05% of the training set, we can train\na model to classify test examples from arbitrary classes into the target class\nwhen the examples are patched with a backdoor trigger. Our attack works well\nacross datasets and models, even when the trigger presents in the physical\nworld.\nWe explore the space of defenses and find that, surprisingly, our attack can\nevade the latest state-of-the-art defenses in their vanilla form, or after a\nsimple twist, we can adapt to the downstream defenses. We study the cause of\nthe intriguing effectiveness and find that because the trigger synthesized by\nour attack contains features as persistent as the original semantic features of\nthe target class, any attempt to remove such triggers would inevitably hurt the\nmodel accuracy first.",
    "descriptor": "\nComments: 13 pages of the main text\n",
    "authors": [
      "Yi Zeng",
      "Minzhou Pan",
      "Hoang Anh Just",
      "Lingjuan Lyu",
      "Meikang Qiu",
      "Ruoxi Jia"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.05255"
  },
  {
    "id": "arXiv:2204.05256",
    "title": "Invariant Smoothing with low process noise",
    "abstract": "In this paper we address smoothing-that is, optimisation-based-estimation\ntechniques for localisation problems in the case where motion sensors are very\naccurate. Our mathematical analysis focuses on the difficult limit case where\nmotion sensors are infinitely precise, resulting in the absence of process\nnoise. Then the formulation degenerates, as the dynamical model that serves as\na soft constraint becomes an equality constraint, and conventional smoothing\nmethods are not able to fully respect it. By contrast, once an appropriate Lie\ngroup embedding has been found, we prove theoretically that invariant smoothing\ngracefully accommodates this limit case in that the estimates tend to be\nconsistent with the induced constraints when the noise tends to zero.\nSimulations on the important problem of initial alignement in inertial\nnavigation show that, in a low noise setting, invariant smoothing may favorably\ncompare to state-of-the-art smoothers when using precise inertial measurements\nunits (IMU).",
    "descriptor": "\nComments: Pre-print submitted to CDC 2022\n",
    "authors": [
      "Paul Chauchat",
      "Silvere Bonnabel",
      "Axel Barrau"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Robotics (cs.RO)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2204.05256"
  },
  {
    "id": "arXiv:2204.05258",
    "title": "Multi-view graph structure learning using subspace merging on Grassmann  manifold",
    "abstract": "Many successful learning algorithms have been recently developed to represent\ngraph-structured data. For example, Graph Neural Networks (GNNs) have achieved\nconsiderable successes in various tasks such as node classification, graph\nclassification, and link prediction. However, these methods are highly\ndependent on the quality of the input graph structure. One used approach to\nalleviate this problem is to learn the graph structure instead of relying on a\nmanually designed graph. In this paper, we introduce a new graph structure\nlearning approach using multi-view learning, named MV-GSL (Multi-View Graph\nStructure Learning), in which we aggregate different graph structure learning\nmethods using subspace merging on Grassmann manifold to improve the quality of\nthe learned graph structures. Extensive experiments are performed to evaluate\nthe effectiveness of the proposed method on two benchmark datasets, Cora and\nCiteseer. Our experiments show that the proposed method has promising\nperformance compared to single and other combined graph structure learning\nmethods.",
    "descriptor": "",
    "authors": [
      "Razieh Ghiasi",
      "Hossein Amirkhani",
      "Alireza Bosaghzadeh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.05258"
  },
  {
    "id": "arXiv:2204.05265",
    "title": "The Importance of Future Information in Credit Card Fraud Detection",
    "abstract": "Fraud detection systems (FDS) mainly perform two tasks: (i) real-time\ndetection while the payment is being processed and (ii) posterior detection to\nblock the card retrospectively and avoid further frauds. Since human\nverification is often necessary and the payment processing time is limited, the\nsecond task manages the largest volume of transactions. In the literature,\nfraud detection challenges and algorithms performance are widely studied but\nthe very formulation of the problem is never disrupted: it aims at predicting\nif a transaction is fraudulent based on its characteristics and the past\ntransactions of the cardholder. Yet, in posterior detection, verification often\ntakes days, so new payments on the card become available before a decision is\ntaken. This is our motivation to propose a new paradigm: posterior fraud\ndetection with \"future\" information. We start by providing evidence of the\non-time availability of subsequent transactions, usable as extra context to\nimprove detection. We then design a Bidirectional LSTM to make use of these\ntransactions. On a real-world dataset with over 30 million transactions, it\nachieves higher performance than a regular LSTM, which is the state-of-the-art\nclassifier for fraud detection that only uses the past context. We also\nintroduce new metrics to show that the proposal catches more frauds, more\ncompromised cards, and based on their earliest frauds. We believe that future\nworks on this new paradigm will have a significant impact on the detection of\ncompromised cards.",
    "descriptor": "\nComments: 11 pages, 4 figures, to be published at AISTATS 2022\n",
    "authors": [
      "Van Bach Nguyen",
      "Kanishka Ghosh Dastidar",
      "Michael Granitzer",
      "Wissam Siblini"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.05265"
  },
  {
    "id": "arXiv:2204.05274",
    "title": "MIME: Adapting a Single Neural Network for Multi-task Inference with  Memory-efficient Dynamic Pruning",
    "abstract": "Recent years have seen a paradigm shift towards multi-task learning. This\ncalls for memory and energy-efficient solutions for inference in a multi-task\nscenario. We propose an algorithm-hardware co-design approach called MIME. MIME\nreuses the weight parameters of a trained parent task and learns task-specific\nthreshold parameters for inference on multiple child tasks. We find that MIME\nresults in highly memory-efficient DRAM storage of neural-network parameters\nfor multiple tasks compared to conventional multi-task inference. In addition,\nMIME results in input-dependent dynamic neuronal pruning, thereby enabling\nenergy-efficient inference with higher throughput on a systolic-array hardware.\nOur experiments with benchmark datasets (child tasks)- CIFAR10, CIFAR100, and\nFashion-MNIST, show that MIME achieves ~3.48x memory-efficiency and ~2.4-3.1x\nenergy-savings compared to conventional multi-task inference in Pipelined task\nmode.",
    "descriptor": "\nComments: Accepted in Design Automation Conference (DAC), 2022\n",
    "authors": [
      "Abhiroop Bhattacharjee",
      "Yeshwanth Venkatesha",
      "Abhishek Moitra",
      "Priyadarshini Panda"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.05274"
  },
  {
    "id": "arXiv:2204.05280",
    "title": "MONCE Tracking Metrics: a comprehensive quantitative performance  evaluation methodology for object tracking",
    "abstract": "Evaluating tracking model performance is a complicated task, particularly for\nnon-contiguous, multi-object trackers that are crucial in defense applications.\nWhile there are various excellent tracking benchmarks available, this work\nexpands them to quantify the performance of long-term, non-contiguous,\nmulti-object and detection model assisted trackers. We propose a suite of MONCE\n(Multi-Object Non-Contiguous Entities) image tracking metrics that provide both\nobjective tracking model performance benchmarks as well as diagnostic insight\nfor driving tracking model development in the form of Expected Average Overlap,\nShort/Long Term Re-Identification, Tracking Recall, Tracking Precision,\nLongevity, Localization and Absence Prediction.",
    "descriptor": "",
    "authors": [
      "Kenneth Rapko",
      "Wanlin Xie",
      "Andrew Walsh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.05280"
  },
  {
    "id": "arXiv:2204.05281",
    "title": "Physically Disentangled Representations",
    "abstract": "State-of-the-art methods in generative representation learning yield semantic\ndisentanglement, but typically do not consider physical scene parameters, such\nas geometry, albedo, lighting, or camera. We posit that inverse rendering, a\nway to reverse the rendering process to recover scene parameters from an image,\ncan also be used to learn physically disentangled representations of scenes\nwithout supervision. In this paper, we show the utility of inverse rendering in\nlearning representations that yield improved accuracy on downstream clustering,\nlinear classification, and segmentation tasks with the help of our novel\nLeave-One-Out, Cycle Contrastive loss (LOOCC), which improves disentanglement\nof scene parameters and robustness to out-of-distribution lighting and\nviewpoints. We perform a comparison of our method with other generative\nrepresentation learning methods across a variety of downstream tasks, including\nface attribute classification, emotion recognition, identification, face\nsegmentation, and car classification. Our physically disentangled\nrepresentations yield higher accuracy than semantically disentangled\nalternatives across all tasks and by as much as 18%. We hope that this work\nwill motivate future research in applying advances in inverse rendering and 3D\nunderstanding to representation learning.",
    "descriptor": "",
    "authors": [
      "Tzofi Klinghoffer",
      "Kushagra Tiwary",
      "Arkadiusz Balata",
      "Vivek Sharma",
      "Ramesh Raskar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.05281"
  },
  {
    "id": "arXiv:2204.05289",
    "title": "Towards Online Domain Adaptive Object Detection",
    "abstract": "Existing object detection models assume both the training and test data are\nsampled from the same source domain. This assumption does not hold true when\nthese detectors are deployed in real-world applications, where they encounter\nnew visual domain. Unsupervised Domain Adaptation (UDA) methods are generally\nemployed to mitigate the adverse effects caused by domain shift. Existing UDA\nmethods operate in an offline manner where the model is first adapted towards\nthe target domain and then deployed in real-world applications. However, this\noffline adaptation strategy is not suitable for real-world applications as the\nmodel frequently encounters new domain shifts. Hence, it becomes critical to\ndevelop a feasible UDA method that generalizes to these domain shifts\nencountered during deployment time in a continuous online manner. To this end,\nwe propose a novel unified adaptation framework that adapts and improves\ngeneralization on the target domain in online settings. In particular, we\nintroduce MemXformer - a cross-attention transformer-based memory module where\nitems in the memory take advantage of domain shifts and record prototypical\npatterns of the target distribution. Further, MemXformer produces strong\npositive and negative pairs to guide a novel contrastive loss, which enhances\ntarget specific representation learning. Experiments on diverse detection\nbenchmarks show that the proposed strategy can produce state-of-the-art\nperformance in both online and offline settings. To the best of our knowledge,\nthis is the first work to address online and offline adaptation settings for\nobject detection. Code at https://github.com/Vibashan/online-od",
    "descriptor": "",
    "authors": [
      "Vibashan VS",
      "Poojan Oza",
      "Vishal M. Patel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.05289"
  },
  {
    "id": "arXiv:2204.05300",
    "title": "Single-Photon Structured Light",
    "abstract": "We present a novel structured light technique that uses Single Photon\nAvalanche Diode (SPAD) arrays to enable 3D scanning at high-frame rates and\nlow-light levels. This technique, called \"Single-Photon Structured Light\",\nworks by sensing binary images that indicates the presence or absence of photon\narrivals during each exposure; the SPAD array is used in conjunction with a\nhigh-speed binary projector, with both devices operated at speeds as high as\n20~kHz. The binary images that we acquire are heavily influenced by photon\nnoise and are easily corrupted by ambient sources of light. To address this, we\ndevelop novel temporal sequences using error correction codes that are designed\nto be robust to short-range effects like projector and camera defocus as well\nas resolution mismatch between the two devices. Our lab prototype is capable of\n3D imaging in challenging scenarios involving objects with extremely low albedo\nor undergoing fast motion, as well as scenes under strong ambient illumination.",
    "descriptor": "\nComments: Accepted at CVPR 2022 (poster). 26 pages, 23 figures\n",
    "authors": [
      "Varun Sundar",
      "Sizhuo Ma",
      "Aswin C. Sankaranarayanan",
      "Mohit Gupta"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.05300"
  },
  {
    "id": "arXiv:2204.05306",
    "title": "Full-Spectrum Out-of-Distribution Detection",
    "abstract": "Existing out-of-distribution (OOD) detection literature clearly defines\nsemantic shift as a sign of OOD but does not have a consensus over covariate\nshift. Samples experiencing covariate shift but not semantic shift are either\nexcluded from the test set or treated as OOD, which contradicts the primary\ngoal in machine learning -- being able to generalize beyond the training\ndistribution. In this paper, we take into account both shift types and\nintroduce full-spectrum OOD (FS-OOD) detection, a more realistic problem\nsetting that considers both detecting semantic shift and being tolerant to\ncovariate shift; and designs three benchmarks. These new benchmarks have a more\nfine-grained categorization of distributions (i.e., training ID,\ncovariate-shifted ID, near-OOD, and far-OOD) for the purpose of more\ncomprehensively evaluating the pros and cons of algorithms. To address the\nFS-OOD detection problem, we propose SEM, a simple feature-based semantics\nscore function. SEM is mainly composed of two probability measures: one is\nbased on high-level features containing both semantic and non-semantic\ninformation, while the other is based on low-level feature statistics only\ncapturing non-semantic image styles. With a simple combination, the\nnon-semantic part is cancelled out, which leaves only semantic information in\nSEM that can better handle FS-OOD detection. Extensive experiments on the three\nnew benchmarks show that SEM significantly outperforms current state-of-the-art\nmethods. Our code and benchmarks are released in\nhttps://github.com/Jingkang50/OpenOOD.",
    "descriptor": "\nComments: Code and benchmarks are integrated in OpenOOD: this https URL, a unified codebase for OOD detection\n",
    "authors": [
      "Jingkang Yang",
      "Kaiyang Zhou",
      "Ziwei Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.05306"
  },
  {
    "id": "arXiv:2204.05307",
    "title": "Toward More Effective Human Evaluation for Machine Translation",
    "abstract": "Improvements in text generation technologies such as machine translation have\nnecessitated more costly and time-consuming human evaluation procedures to\nensure an accurate signal. We investigate a simple way to reduce cost by\nreducing the number of text segments that must be annotated in order to\naccurately predict a score for a complete test set. Using a sampling approach,\nwe demonstrate that information from document membership and automatic metrics\ncan help improve estimates compared to a pure random sampling baseline. We\nachieve gains of up to 20% in average absolute error by leveraging stratified\nsampling and control variates. Our techniques can improve estimates made from a\nfixed annotation budget, are easy to implement, and can be applied to any\nproblem with structure similar to the one we study.",
    "descriptor": "\nComments: ACL 2022 Workshop on Human Evaluation of NLP Systems\n",
    "authors": [
      "Bel\u00e9n Sald\u00edas",
      "George Foster",
      "Markus Freitag",
      "Qijun Tan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.05307"
  },
  {
    "id": "arXiv:2204.05308",
    "title": "On the Generalization of BasicVSR++ to Video Deblurring and Denoising",
    "abstract": "The exploitation of long-term information has been a long-standing problem in\nvideo restoration. The recent BasicVSR and BasicVSR++ have shown remarkable\nperformance in video super-resolution through long-term propagation and\neffective alignment. Their success has led to a question of whether they can be\ntransferred to different video restoration tasks. In this work, we extend\nBasicVSR++ to a generic framework for video restoration tasks. In tasks where\ninputs and outputs possess identical spatial size, the input resolution is\nreduced by strided convolutions to maintain efficiency. With only minimal\nchanges from BasicVSR++, the proposed framework achieves compelling performance\nwith great efficiency in various video restoration tasks including video\ndeblurring and denoising. Notably, BasicVSR++ achieves comparable performance\nto Transformer-based approaches with up to 79% of parameter reduction and 44x\nspeedup. The promising results demonstrate the importance of propagation and\nalignment in video restoration tasks beyond just video super-resolution. Code\nand models are available at https://github.com/ckkelvinchan/BasicVSR_PlusPlus.",
    "descriptor": "\nComments: Technical report. Extension of arXiv:2104.13371\n",
    "authors": [
      "Kelvin C.K. Chan",
      "Shangchen Zhou",
      "Xiangyu Xu",
      "Chen Change Loy"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.05308"
  },
  {
    "id": "arXiv:2204.04214",
    "title": "Intelligent Sight and Sound: A Chronic Cancer Pain Dataset",
    "abstract": "Cancer patients experience high rates of chronic pain throughout the\ntreatment process. Assessing pain for this patient population is a vital\ncomponent of psychological and functional well-being, as it can cause a rapid\ndeterioration of quality of life. Existing work in facial pain detection often\nhave deficiencies in labeling or methodology that prevent them from being\nclinically relevant. This paper introduces the first chronic cancer pain\ndataset, collected as part of the Intelligent Sight and Sound (ISS) clinical\ntrial, guided by clinicians to help ensure that model findings yield clinically\nrelevant results. The data collected to date consists of 29 patients, 509\nsmartphone videos, 189,999 frames, and self-reported affective and activity\npain scores adopted from the Brief Pain Inventory (BPI). Using static images\nand multi-modal data to predict self-reported pain levels, early models show\nsignificant gaps between current methods available to predict pain today, with\nroom for improvement. Due to the especially sensitive nature of the inherent\nPersonally Identifiable Information (PII) of facial images, the dataset will be\nreleased under the guidance and control of the National Institutes of Health\n(NIH).",
    "descriptor": "\nComments: Published as conference paper at the 35th Conference on Neural Information Processing Systems (NeurIPS 2021) Track on Datasets and Benchmarks\n",
    "authors": [
      "Catherine Ordun",
      "Alexandra N. Cha",
      "Edward Raff",
      "Byron Gaskin",
      "Alex Hanson",
      "Mason Rule",
      "Sanjay Purushotham",
      "James L. Gulley"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.04214"
  },
  {
    "id": "arXiv:2204.04216",
    "title": "Learning Trajectory-Aware Transformer for Video Super-Resolution",
    "abstract": "Video super-resolution (VSR) aims to restore a sequence of high-resolution\n(HR) frames from their low-resolution (LR) counterparts. Although some progress\nhas been made, there are grand challenges to effectively utilize temporal\ndependency in entire video sequences. Existing approaches usually align and\naggregate video frames from limited adjacent frames (e.g., 5 or 7 frames),\nwhich prevents these approaches from satisfactory results. In this paper, we\ntake one step further to enable effective spatio-temporal learning in videos.\nWe propose a novel Trajectory-aware Transformer for Video Super-Resolution\n(TTVSR). In particular, we formulate video frames into several pre-aligned\ntrajectories which consist of continuous visual tokens. For a query token,\nself-attention is only learned on relevant visual tokens along spatio-temporal\ntrajectories. Compared with vanilla vision Transformers, such a design\nsignificantly reduces the computational cost and enables Transformers to model\nlong-range features. We further propose a cross-scale feature tokenization\nmodule to overcome scale-changing problems that often occur in long-range\nvideos. Experimental results demonstrate the superiority of the proposed TTVSR\nover state-of-the-art models, by extensive quantitative and qualitative\nevaluations in four widely-used video super-resolution benchmarks. Both code\nand pre-trained models can be downloaded at\nhttps://github.com/researchmm/TTVSR.",
    "descriptor": "\nComments: CVPR 2022 Oral\n",
    "authors": [
      "Chengxu Liu",
      "Huan Yang",
      "Jianlong Fu",
      "Xueming Qian"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.04216"
  },
  {
    "id": "arXiv:2204.04217",
    "title": "Feature-enhanced Adversarial Semi-supervised Semantic Segmentation  Network for Pulmonary Embolism Annotation",
    "abstract": "This study established a feature-enhanced adversarial semi-supervised\nsemantic segmentation model to automatically annotate pulmonary embolism lesion\nareas in computed tomography pulmonary angiogram (CTPA) images. In current\nstudies, all of the PE CTPA image segmentation methods are trained by\nsupervised learning. However, the supervised learning models need to be\nretrained and the images need to be relabeled when the CTPA images come from\ndifferent hospitals. This study proposed a semi-supervised learning method to\nmake the model applicable to different datasets by adding a small amount of\nunlabeled images. By training the model with both labeled and unlabeled images,\nthe accuracy of unlabeled images can be improved and the labeling cost can be\nreduced. Our semi-supervised segmentation model includes a segmentation network\nand a discriminator network. We added feature information generated from the\nencoder of segmentation network to the discriminator so that it can learn the\nsimilarity between predicted mask and ground truth mask. This HRNet-based\narchitecture can maintain a higher resolution for convolutional operations so\nthe prediction of small PE lesion areas can be improved. We used the labeled\nopen-source dataset and the unlabeled National Cheng Kung University Hospital\n(NCKUH) (IRB number: B-ER-108-380) dataset to train the semi-supervised\nlearning model, and the resulting mean intersection over union (mIOU), dice\nscore, and sensitivity achieved 0.3510, 0.4854, and 0.4253, respectively on the\nNCKUH dataset. Then, we fine-tuned and tested the model with a small amount of\nunlabeled PE CTPA images from China Medical University Hospital (CMUH) (IRB\nnumber: CMUH110-REC3-173) dataset. Comparing the results of our semi-supervised\nmodel with the supervised model, the mIOU, dice score, and sensitivity improved\nfrom 0.2344, 0.3325, and 0.3151 to 0.3721, 0.5113, and 0.4967, respectively.",
    "descriptor": "",
    "authors": [
      "Ting-Wei Cheng",
      "Jerry Chang",
      "Ching-Chun Huang",
      "Chin Kuo",
      "Yun-Chien Cheng"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.04217"
  },
  {
    "id": "arXiv:2204.04218",
    "title": "Multimodal Multi-Head Convolutional Attention with Various Kernel Sizes  for Medical Image Super-Resolution",
    "abstract": "Super-resolving medical images can help physicians in providing more accurate\ndiagnostics. In many situations, computed tomography (CT) or magnetic resonance\nimaging (MRI) techniques output several scans (modes) during a single\ninvestigation, which can jointly be used (in a multimodal fashion) to further\nboost the quality of super-resolution results. To this end, we propose a novel\nmultimodal multi-head convolutional attention module to super-resolve CT and\nMRI scans. Our attention module uses the convolution operation to perform joint\nspatial-channel attention on multiple concatenated input tensors, where the\nkernel (receptive field) size controls the reduction rate of the spatial\nattention and the number of convolutional filters controls the reduction rate\nof the channel attention, respectively. We introduce multiple attention heads,\neach head having a distinct receptive field size corresponding to a particular\nreduction rate for the spatial attention. We integrate our multimodal\nmulti-head convolutional attention (MMHCA) into two deep neural architectures\nfor super-resolution and conduct experiments on three data sets. Our empirical\nresults show the superiority of our attention module over the state-of-the-art\nattention mechanisms used in super-resolution. Moreover, we conduct an ablation\nstudy to assess the impact of the components involved in our attention module,\ne.g. the number of inputs or the number of heads.",
    "descriptor": "",
    "authors": [
      "Mariana-Iuliana Georgescu",
      "Radu Tudor Ionescu",
      "Andreea-Iuliana Miron",
      "Olivian Savencu",
      "Nicolae-Catalin Ristea",
      "Nicolae Verga",
      "Fahad Shahbaz Khan"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.04218"
  },
  {
    "id": "arXiv:2204.04219",
    "title": "Towards Reliable and Explainable AI Model for Solid Pulmonary Nodule  Diagnosis",
    "abstract": "Lung cancer has the highest mortality rate of deadly cancers in the world.\nEarly detection is essential to treatment of lung cancer. However, detection\nand accurate diagnosis of pulmonary nodules depend heavily on the experiences\nof radiologists and can be a heavy workload for them. Computer-aided diagnosis\n(CAD) systems have been developed to assist radiologists in nodule detection\nand diagnosis, greatly easing the workload while increasing diagnosis accuracy.\nRecent development of deep learning, greatly improved the performance of CAD\nsystems. However, lack of model reliability and interpretability remains a\nmajor obstacle for its large-scale clinical application. In this work, we\nproposed a multi-task explainable deep-learning model for pulmonary nodule\ndiagnosis. Our neural model can not only predict lesion malignancy but also\nidentify relevant manifestations. Further, the location of each manifestation\ncan also be visualized for visual interpretability. Our proposed neural model\nachieved a test AUC of 0.992 on LIDC public dataset and a test AUC of 0.923 on\nour in-house dataset. Moreover, our experimental results proved that by\nincorporating manifestation identification tasks into the multi-task model, the\naccuracy of the malignancy classification can also be improved. This multi-task\nexplainable model may provide a scheme for better interaction with the\nradiologists in a clinical environment.",
    "descriptor": "",
    "authors": [
      "Chenglong Wang",
      "Yun Liu",
      "Fen Wang",
      "Chengxiu Zhang",
      "Yida Wang",
      "Mei Yuan",
      "Guang Yang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.04219"
  },
  {
    "id": "arXiv:2204.04250",
    "title": "Understanding the Influence of Receptive Field and Network Complexity in  Neural-Network-Guided TEM Image Analysis",
    "abstract": "Trained neural networks are promising tools to analyze the ever-increasing\namount of scientific image data, but it is unclear how to best customize these\nnetworks for the unique features in transmission electron micrographs. Here, we\nsystematically examine how neural network architecture choices affect how\nneural networks segment, or pixel-wise separate, crystalline nanoparticles from\namorphous background in transmission electron microscopy (TEM) images. We focus\non decoupling the influence of receptive field, or the area of the input image\nthat contributes to the output decision, from network complexity, which\ndictates the number of trainable parameters. We find that for low-resolution\nTEM images which rely on amplitude contrast to distinguish nanoparticles from\nbackground, the receptive field does not significantly influence segmentation\nperformance. On the other hand, for high-resolution TEM images which rely on a\ncombination of amplitude and phase contrast changes to identify nanoparticles,\nreceptive field is a key parameter for increased performance, especially in\nimages with minimal amplitude contrast. Our results provide insight and\nguidance as to how to adapt neural networks for applications with TEM datasets.",
    "descriptor": "\nComments: 11 pages, 8 figures\n",
    "authors": [
      "Katherine Sytwu",
      "Catherine Groschner",
      "Mary C. Scott"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2204.04250"
  },
  {
    "id": "arXiv:2204.04284",
    "title": "Auditory-Based Data Augmentation for End-to-End Automatic Speech  Recognition",
    "abstract": "End-to-end models have achieved significant improvement on automatic speech\nrecognition. One common method to improve performance of these models is\nexpanding the data-space through data augmentation. Meanwhile, human auditory\ninspired front-ends have also demonstrated improvement for automatic speech\nrecognisers. In this work, a well-verified auditory-based model, which can\nsimulate various hearing abilities, is investigated for the purpose of data\naugmentation for end-to-end speech recognition. By introducing the auditory\nmodel into the data augmentation process, end-to-end systems are encouraged to\nignore variation from the signal that cannot be heard and thereby focus on\nrobust features for speech recognition. Two mechanisms in the auditory model,\nspectral smearing and loudness recruitment, are studied on the LibriSpeech\ndataset with a transformer-based end-to-end model. The results show that the\nproposed augmentation methods can bring statistically significant improvement\non the performance of the state-of-the-art SpecAugment.",
    "descriptor": "",
    "authors": [
      "Zehai Tu",
      "Jack Deadman",
      "Ning Ma",
      "Jon Barker"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2204.04284"
  },
  {
    "id": "arXiv:2204.04287",
    "title": "Exploiting Hidden Representations from a DNN-based Speech Recogniser for  Speech Intelligibility Prediction in Hearing-impaired Listeners",
    "abstract": "An accurate objective speech intelligibility prediction algorithms is of\ngreat interest for many applications such as speech enhancement for hearing\naids. Most algorithms measures the signal-to-noise ratios or correlations\nbetween the acoustic features of clean reference signals and degraded signals.\nHowever, these hand-picked acoustic features are usually not explicitly\ncorrelated with recognition. Meanwhile, deep neural network (DNN) based\nautomatic speech recogniser (ASR) is approaching human performance in some\nspeech recognition tasks. This work leverages the hidden representations from\nDNN-based ASR as features for speech intelligibility prediction in\nhearing-impaired listeners. The experiments based on a hearing aid\nintelligibility database show that the proposed method could make better\nprediction than a widely used short-time objective intelligibility (STOI) based\nbinaural measure.",
    "descriptor": "\nComments: Submitted to INTERSPEECH2022\n",
    "authors": [
      "Zehai Tu",
      "Ning Ma",
      "Jon Barker"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2204.04287"
  },
  {
    "id": "arXiv:2204.04288",
    "title": "Unsupervised Uncertainty Measures of Automatic Speech Recognition for  Non-intrusive Speech Intelligibility Prediction",
    "abstract": "Non-intrusive intelligibility prediction is important for its application in\nrealistic scenarios, where a clean reference signal is difficult to access. The\nconstruction of many non-intrusive predictors require either ground truth\nintelligibility labels or clean reference signals for supervised learning. In\nthis work, we leverage an unsupervised uncertainty estimation method for\npredicting speech intelligibility, which does not require intelligibility\nlabels or reference signals to train the predictor. Our experiments demonstrate\nthat the uncertainty from state-of-the-art end-to-end automatic speech\nrecognition (ASR) models is highly correlated with speech intelligibility. The\nproposed method is evaluated on two databases and the results show that the\nunsupervised uncertainty measures of ASR models are more correlated with speech\nintelligibility from listening results than the predictions made by widely used\nintrusive methods.",
    "descriptor": "\nComments: Submitted to INTERSPEECH2022\n",
    "authors": [
      "Zehai Tu",
      "Ning Ma",
      "Jon Barker"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2204.04288"
  },
  {
    "id": "arXiv:2204.04319",
    "title": "A Mathematical Framework for Transformations of Physical Processes",
    "abstract": "We observe that the existence of sequential and parallel composition\nsupermaps in higher order physics can be formalized using enriched category\ntheory. Encouraged by physically relevant examples such as unitary supermaps\nand layers within higher order causal categories (HOCCs), we treat the modeling\nof higher order physics with enriched monoidal categories in analogy with the\nprocess theoretic framework in which physical theories are modeled with\nmonoidal categories. We use the enriched monoidal setting to construct a\nsuitable definition of structure-preserving map between higher order physical\ntheories via the Grothendieck construction. We then show that the convenient\nfeature of currying in higher order physical theories can be seen as a\nconsequence of combining the primitive assumption of the existence of parallel\nand sequential composition supermaps with an additional feature of \"linking\".\nIn a second application, we show more generally that categories containing\ninfinite towers of enriched monoidal categories with full and faithful\nstructure-preserving maps between them inevitably lead to closed monoidal\nstructure. The aim of the proposed definitions is to give a broad framework for\nthe study and comparison of novel causal structures in quantum theory, and,\nmore broadly, provide a paradigm of physical theory where static and dynamical\nfeatures are treated in a unified way.",
    "descriptor": "",
    "authors": [
      "Matt Wilson",
      "Giulio Chiribella"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Logic in Computer Science (cs.LO)",
      "Category Theory (math.CT)"
    ],
    "url": "https://arxiv.org/abs/2204.04319"
  },
  {
    "id": "arXiv:2204.04333",
    "title": "A Study of Using Cepstrogram for Countermeasure Against Replay Attacks",
    "abstract": "In this paper, we investigate the properties of the cepstrogram and\ndemonstrate its effectiveness as a powerful feature for countermeasure against\nreplay attacks. Cepstrum analysis of replay attacks suggests that crucial\ninformation for anti-spoofing against replay attacks may retain in the\ncepstrogram. Experimental results on the ASVspoof 2019 physical access (PA)\ndatabase demonstrate that, compared with other features, the cepstrogram\ndominates in both single and fusion systems when building countermeasures\nagainst replay attacks. Our LCNN-based single and fusion systems with the\ncepstrogram feature outperform the corresponding LCNN-based systems without\nusing the cepstrogram feature and several state-of-the-art (SOTA) single and\nfusion systems in the literature.",
    "descriptor": "\nComments: Submitted to INTERSPEECH 2022\n",
    "authors": [
      "Shih-Kuang Lee",
      "Yu Tsao",
      "Hsin-Min Wang"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Cryptography and Security (cs.CR)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2204.04333"
  },
  {
    "id": "arXiv:2204.04348",
    "title": "Neural networks embrace learned diversity",
    "abstract": "Diversity conveys advantages in nature, yet homogeneous neurons typically\ncomprise the layers of artificial neural networks. Here we construct neural\nnetworks from neurons that learn their own activation functions, quickly\ndiversify, and subsequently outperform their homogeneous counterparts.\nSub-networks instantiate the neurons, which meta-learn especially efficient\nsets of nonlinear responses. Such learned diversity provides examples of\ndynamical systems selecting diversity over uniformity and elucidates the role\nof diversity in natural and artificial systems.",
    "descriptor": "\nComments: 6 pages, 6 figures\n",
    "authors": [
      "Anshul Choudhary",
      "Anil Radhakrishnan",
      "John F. Lindner",
      "Sudeshna Sinha",
      "William L. Ditto"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.04348"
  },
  {
    "id": "arXiv:2204.04370",
    "title": "QuiKo: A Quantum Beat Generation Application",
    "abstract": "In this chapter a quantum music generation application called QuiKo will be\ndiscussed. It combines existing quantum algorithms with data encoding methods\nfrom quantum machine learning to build drum and audio sample patterns from a\ndatabase of audio tracks. QuiKo leverages the physical properties and\ncharacteristics of quantum computers to generate what can be referred to as\nSoft Rules proposed by Alexis Kirke. These rules take advantage of the noise\nproduced by quantum devices to develop flexible rules and grammars for quantum\nmusic generation. These properties include qubit decoherence and phase kickback\ndue controlled quantum gates within the quantum circuit. QuiKo builds upon the\nconcept of soft rules in quantum music generation and takes it a step further.\nIt attempts to mimic and react to an external musical inputs, similar to the\nway that human musicians play and compose with one another. Audio signals are\nused as inputs into the system. Feature extraction is then performed on the\nsignal to identify the harmonic and percussive elements. This information is\nthen encoded onto the quantum circuit. Measurements of the quantum circuit are\nthen taken providing results in the form of probability distributions for\nexternal music applications to use to build the new drum patterns.",
    "descriptor": "\nComments: Pre-publication draft, to appear in the book \"Quantum Computer Music\", E. R. Miranda (Ed.)\n",
    "authors": [
      "Scott Oshiro"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Emerging Technologies (cs.ET)",
      "Human-Computer Interaction (cs.HC)",
      "Sound (cs.SD)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2204.04370"
  },
  {
    "id": "arXiv:2204.04387",
    "title": "Dual-Stage Approach Toward Hyperspectral Image Super-Resolution",
    "abstract": "Hyperspectral image produces high spectral resolution at the sacrifice of\nspatial resolution. Without reducing the spectral resolution, improving the\nresolution in the spatial domain is a very challenging problem. Motivated by\nthe discovery that hyperspectral image exhibits high similarity between\nadjacent bands in a large spectral range, in this paper, we explore a new\nstructure for hyperspectral image super-resolution (DualSR), leading to a\ndual-stage design, i.e., coarse stage and fine stage. In coarse stage, five\nbands with high similarity in a certain spectral range are divided into three\ngroups, and the current band is guided to study the potential knowledge. Under\nthe action of alternative spectral fusion mechanism, the coarse SR image is\nsuper-resolved in band-by-band. In order to build model from a global\nperspective, an enhanced back-projection method via spectral angle constraint\nis developed in fine stage to learn the content of spatial-spectral\nconsistency, dramatically improving the performance gain. Extensive experiments\ndemonstrate the effectiveness of the proposed coarse stage and fine stage.\nBesides, our network produces state-of-the-art results against existing works\nin terms of spatial reconstruction and spectral fidelity.",
    "descriptor": "",
    "authors": [
      "Qiang Li",
      "Yuan Yuan",
      "Xiuping Jia",
      "Qi Wang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.04387"
  },
  {
    "id": "arXiv:2204.04430",
    "title": "CMOS Circuit Implementation of Spiking Neural Network for Pattern  Recognition Using On-chip Unsupervised STDP Learning",
    "abstract": "Computation on a large volume of data at high speed and low power requires\nenergy-efficient computing architectures. Spiking neural network (SNN) with\nbio-inspired spike-timing-dependent plasticity learning (STDP) is a promising\nsolution for energy-efficient neuromorphic systems than conventional artificial\nneural network (ANN). Previous works on SNN with STDP learning primarily uses\nmemristive devices which are difficult to fabricate. Some reported works on SNN\nmakes use of memristor macro models, which are software-based and cannot give\ncomplete insight into circuit implementation challenges. This article presents\nfor the first time, a full circuit-level implementation of the SNN system\nfeaturing on-chip unsupervised STDP learning in standard CMOS technology. It\ndoes not involve the use of FPGAs, CPUs or GPUs for training the neural\nnetwork. We demonstrated the complete circuit-level design, implementation and\nsimulation of SNN with on-chip training and inference for pattern\nclassification using 180 nm CMOS technology. A comprehensive comparison of the\nproposed SNN circuit with the previous related work is also presented. To\ndemonstrate the versatility of the CMOS synapse circuit for application\nscenarios requiring rate-based learning, we have tuned the pair-based STDP\ncircuit to obtain Bienenstock-Cooper-Munro (BCM) characteristics and applied it\nto heart rate classification.",
    "descriptor": "",
    "authors": [
      "Sahibia Kaur Vohra",
      "Sherin A Thomas",
      "Mahendra Sakare",
      "Devarshi Mrinal Das"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2204.04430"
  },
  {
    "id": "arXiv:2204.04466",
    "title": "Ultrasound Signal Processing: From Models to Deep Learning",
    "abstract": "Medical ultrasound imaging relies heavily on high-quality signal processing\nalgorithms to provide reliable and interpretable image reconstructions.\nHand-crafted reconstruction methods, often based on approximations of the\nunderlying measurement model, are useful in practice, but notoriously fall\nbehind in terms of image quality. More sophisticated solutions, based on\nstatistical modelling, careful parameter tuning, or through increased model\ncomplexity, can be sensitive to different environments. Recently, deep learning\nbased methods have gained popularity, which are optimized in a data-driven\nfashion. These model-agnostic methods often rely on generic model structures,\nand require vast training data to converge to a robust solution. A relatively\nnew paradigm combines the power of the two: leveraging data-driven deep\nlearning, as well as exploiting domain knowledge. These model-based solutions\nyield high robustness, and require less trainable parameters and training data\nthan conventional neural networks. In this work we provide an overview of these\nmethods from the recent literature, and discuss a wide variety of ultrasound\napplications. We aim to inspire the reader to further research in this area,\nand to address the opportunities within the field of ultrasound signal\nprocessing. We conclude with a future perspective on these model-based deep\nlearning techniques for medical ultrasound applications.",
    "descriptor": "",
    "authors": [
      "Ben Luijten",
      "Nishith Chennakeshava",
      "Yonina C. Eldar",
      "Massimo Mischi",
      "Ruud J.G. van Sloun"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2204.04466"
  },
  {
    "id": "arXiv:2204.04476",
    "title": "High-dimensional Asymptotics of Langevin Dynamics in Spiked Matrix  Models",
    "abstract": "We study Langevin dynamics for recovering the planted signal in the spiked\nmatrix model. We provide a \"path-wise\" characterization of the overlap between\nthe output of the Langevin algorithm and the planted signal. This overlap is\ncharacterized in terms of a self-consistent system of integro-differential\nequations, usually referred to as the\nCrisanti-Horner-Sommers-Cugliandolo-Kurchan (CHSCK) equations in the spin glass\nliterature. As a second contribution, we derive an explicit formula for the\nlimiting overlap in terms of the signal-to-noise ratio and the injected noise\nin the diffusion. This uncovers a sharp phase transition -- in one regime, the\nlimiting overlap is strictly positive, while in the other, the injected noise\novercomes the signal, and the limiting overlap is zero.",
    "descriptor": "\nComments: 26 pages\n",
    "authors": [
      "Tengyuan Liang",
      "Subhabrata Sen",
      "Pragya Sur"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Machine Learning (cs.LG)",
      "Probability (math.PR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2204.04476"
  },
  {
    "id": "arXiv:2204.04484",
    "title": "Data-analysis software framework 2DMAT and its application to  experimental measurements for two-dimensional material structures",
    "abstract": "An open-source data-analysis framework 2DMAT has been developed for\nexperimental measurements of two-dimensional material structures. 2DMAT| offers\nfive analysis methods: (i) Nelder-Mead optimization, (ii) grid search, (iii)\nBayesian optimization, (iv) replica exchange Monte Carlo method, and (v)\npopulation-annealing Monte Carlo method. Methods (ii) through (v) are\nimplemented by parallel computation, which is efficient not only for personal\ncomputers but also for supercomputers. The current version of 2DMAT is\napplicable to total-reflection high-energy positron diffraction (TRHEPD),\nsurface X-ray diffraction (SXRD), and low-energy electron diffraction (LEED)\nexperiments by installing corresponding forward problem solvers that generate\ndiffraction intensity data from a given dataset of the atomic positions. The\nanalysis methods are general and can be applied also to other experiments and\nphenomena.",
    "descriptor": "\nComments: 11 pages, 8 figures\n",
    "authors": [
      "Yuichi Motoyama",
      "Kazuyoshi Yoshimi",
      "Harumichi Iwamoto",
      "Hayato Ichinose",
      "Takeo Hoshi"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2204.04484"
  },
  {
    "id": "arXiv:2204.04512",
    "title": "Spectral bounds of the $\\varepsilon$-entropy of kernel classes",
    "abstract": "We develop new upper and lower bounds on the $\\varepsilon$-entropy of a unit\nball in a reproducing kernel Hilbert space induced by some Mercer kernel $K$.\nOur bounds are based on the behaviour of eigenvalues of a corresponding\nintegral operator. In our approach we exploit an ellipsoidal structure of a\nunit ball in RKHS and a previous work on covering numbers of an ellipsoid in\nthe euclidean space obtained by Dumer, Pinsker and Prelov.\nWe present a number of applications of our main bound, such as its tightness\nfor a practically important case of the Gaussian kernel. Further, we develop a\nseries of lower bounds on the $\\varepsilon$-entropy that can be established\nfrom a connection between covering numbers of a ball in RKHS and a quantization\nof a Gaussian Random Field that corresponds to the kernel $K$ by the\nKosambi-Karhunen-Lo\\`eve transform.",
    "descriptor": "",
    "authors": [
      "Rustem Takhanov"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Functional Analysis (math.FA)"
    ],
    "url": "https://arxiv.org/abs/2204.04512"
  },
  {
    "id": "arXiv:2204.04516",
    "title": "Uncertainty-Informed Deep Learning Models Enable High-Confidence  Predictions for Digital Histopathology",
    "abstract": "A model's ability to express its own predictive uncertainty is an essential\nattribute for maintaining clinical user confidence as computational biomarkers\nare deployed into real-world medical settings. In the domain of cancer digital\nhistopathology, we describe a novel, clinically-oriented approach to\nuncertainty quantification (UQ) for whole-slide images, estimating uncertainty\nusing dropout and calculating thresholds on training data to establish cutoffs\nfor low- and high-confidence predictions. We train models to identify lung\nadenocarcinoma vs. squamous cell carcinoma and show that high-confidence\npredictions outperform predictions without UQ, in both cross-validation and\ntesting on two large external datasets spanning multiple institutions. Our\ntesting strategy closely approximates real-world application, with predictions\ngenerated on unsupervised, unannotated slides using predetermined thresholds.\nFurthermore, we show that UQ thresholding remains reliable in the setting of\ndomain shift, with accurate high-confidence predictions of adenocarcinoma vs.\nsquamous cell carcinoma for out-of-distribution, non-lung cancer cohorts.",
    "descriptor": "",
    "authors": [
      "James M Dolezal",
      "Andrew Srisuwananukorn",
      "Dmitry Karpeyev",
      "Siddhi Ramesh",
      "Sara Kochanny",
      "Brittany Cody",
      "Aaron Mansfield",
      "Sagar Rakshit",
      "Radhika Bansa",
      "Melanie Bois",
      "Aaron O Bungum",
      "Jefree J Schulte",
      "Everett E Vokes",
      "Marina Chiara Garassino",
      "Aliya N Husain",
      "Alexander T Pearson"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2204.04516"
  },
  {
    "id": "arXiv:2204.04537",
    "title": "Super-Resolved Microbubble Localization in Single-Channel Ultrasound RF  Signals Using Deep Learning",
    "abstract": "Recently, super-resolution ultrasound imaging with ultrasound localization\nmicroscopy (ULM) has received much attention. However, ULM relies on low\nconcentrations of microbubbles in the blood vessels, ultimately resulting in\nlong acquisition times. Here, we present an alternative super-resolution\napproach, based on direct deconvolution of single-channel ultrasound\nradio-frequency (RF) signals with a one-dimensional dilated convolutional\nneural network (CNN). This work focuses on low-frequency ultrasound (1.7 MHz)\nfor deep imaging (10 cm) of a dense cloud of monodisperse microbubbles (up to\n1000 microbubbles in the measurement volume, corresponding to an average echo\noverlap of 94%). Data are generated with a simulator that uses a large range of\nacoustic pressures (5-250 kPa) and captures the full, nonlinear response of\nresonant, lipid-coated microbubbles. The network is trained with a novel\ndual-loss function, which features elements of both a classification loss and a\nregression loss and improves the detection-localization characteristics of the\noutput. Whereas imposing a localization tolerance of 0 yields poor detection\nmetrics, imposing a localization tolerance corresponding to 4% of the\nwavelength yields a precision and recall of both 0.90. Furthermore, the\ndetection improves with increasing acoustic pressure and deteriorates with\nincreasing microbubble density. The potential of the presented approach to\nsuper-resolution ultrasound imaging is demonstrated with a delay-and-sum\nreconstruction with deconvolved element data. The resulting image shows an\norder-of-magnitude gain in axial resolution compared to a delay-and-sum\nreconstruction with unprocessed element data.",
    "descriptor": "\nComments: Accepted for publication in IEEE Transactions on Medical Imaging\n",
    "authors": [
      "Nathan Blanken",
      "Jelmer M. Wolterink",
      "Herv\u00e9 Delingette",
      "Christoph Brune",
      "Michel Versluis",
      "Guillaume Lajoinie"
    ],
    "subjectives": [
      "Medical Physics (physics.med-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.04537"
  },
  {
    "id": "arXiv:2204.04539",
    "title": "Testability in group theory",
    "abstract": "This paper is a journal counterpart to our FOCS 2021 paper, in which we\ninitiate the study of property testing problems concerning a finite system of\nrelations $E$ between permutations, generalizing the study of stability in\npermutations. To every such system $E$, a group $\\Gamma=\\Gamma_E$ is associated\nand the testability of $E$ depends only on $\\Gamma$ (just like in Galois\ntheory, where the solvability of a polynomial is determined by the solvability\nof the associated group). This leads to the notion of testable groups, and,\nmore generally, Benjamini-Schramm rigid groups. The paper presents an ensemble\nof tools to check if a given group $\\Gamma$ is testable/BS-rigid or not.",
    "descriptor": "\nComments: 22 pages\n",
    "authors": [
      "Oren Becker",
      "Alexander Lubotzky",
      "Jonathan Mosheiff"
    ],
    "subjectives": [
      "Group Theory (math.GR)",
      "Data Structures and Algorithms (cs.DS)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2204.04539"
  },
  {
    "id": "arXiv:2204.04555",
    "title": "Trust-based Rate-Tunable Control Barrier Functions for Non-Cooperative  Multi-Agent Systems",
    "abstract": "For efficient and robust task accomplishment in multi-agent systems, an agent\nmust be able to distinguish cooperative agents from non-cooperative agents,\ni.e., uncooperative and adversarial agents. Task descriptions capturing safety\nand collaboration can often be encoded as Control Barrier Functions (CBFs). In\nthis work, we first develop a trust metric that each agent uses to form its own\nbelief of how cooperative other agents are. The metric is used to adjust the\nrate at which the CBFs allow the system trajectories to approach the boundaries\nof the safe region. Then, based on the presented notion of trust, we propose a\nRate-Tunable CBF framework that leads to less conservative performance compared\nto an identity-agnostic implementation, where cooperative and non-cooperative\nagents are treated similarly. Finally, in presence of non-cooperating agents,\nwe show the application of our control algorithm to heterogeneous multi-agent\nsystem through simulations.",
    "descriptor": "\nComments: Submitted to a conference for review\n",
    "authors": [
      "Hardik Parwana",
      "Dimitra Panagou"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2204.04555"
  },
  {
    "id": "arXiv:2204.04573",
    "title": "Efficient Reconstruction of Stochastic Pedigrees: Some Steps From Theory  to Practice",
    "abstract": "In an extant population, how much information do extant individuals provide\non the pedigree of their ancestors? Recent work by Kim, Mossel, Ramnarayan and\nTurner (2020) studied this question under a number of simplifying assumptions,\nincluding random mating, fixed length inheritance blocks and sufficiently large\nfounding population. They showed that under these conditions if the average\nnumber of offspring is a sufficiently large constant, then it is possible to\nrecover a large fraction of the pedigree structure and genetic content by an\nalgorithm they named REC-GEN.\nWe are interested in studying the performance of REC-GEN on simulated data\ngenerated according to the model. As a first step, we improve the running time\nof the algorithm. However, we observe that even the faster version of the\nalgorithm does not do well in any simulations in recovering the pedigree beyond\n2 generations. We claim that this is due to the inbreeding present in any\nsetting where the algorithm can be run, even on simulated data. To support the\nclaim we show that a main step of the algorithm, called ancestral\nreconstruction, performs accurately in a idealized setting with no inbreeding\nbut performs poorly in random mating populations.\nTo overcome the poor behavior of REC-GEN we introduce a Belief-Propagation\nbased heuristic that accounts for the inbreeding and performs much better in\nour simulations.",
    "descriptor": "",
    "authors": [
      "Elchanan Mossel",
      "David Vulakh"
    ],
    "subjectives": [
      "Populations and Evolution (q-bio.PE)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2204.04573"
  },
  {
    "id": "arXiv:2204.04582",
    "title": "Real order total variation with applications to the loss functions in  learning schemes",
    "abstract": "Loss function are an essential part in modern data-driven approach, such as\nbi-level training scheme and machine learnings. In this paper we propose a loss\nfunction consisting of a $r$-order (an)-isotropic total variation semi-norms\n$TV^r$, $r\\in \\mathbb{R}^+$, defined via the Riemann-Liouville (R-L) fractional\nderivative. We focus on studying key theoretical properties, such as the lower\nsemi-continuity and compactness with respect to both the function and the order\nof derivative $r$, of such loss functions.",
    "descriptor": "",
    "authors": [
      "Pan Liu",
      "Xin Yang Lu",
      "Kunlun He"
    ],
    "subjectives": [
      "Analysis of PDEs (math.AP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.04582"
  },
  {
    "id": "arXiv:2204.04597",
    "title": "Private Sequential Hypothesis Testing for Statisticians: Privacy, Error  Rates, and Sample Size",
    "abstract": "The sequential hypothesis testing problem is a class of statistical analyses\nwhere the sample size is not fixed in advance. Instead, the decision-process\ntakes in new observations sequentially to make real-time decisions for testing\nan alternative hypothesis against a null hypothesis until some stopping\ncriterion is satisfied. In many common applications of sequential hypothesis\ntesting, the data can be highly sensitive and may require privacy protection;\nfor example, sequential hypothesis testing is used in clinical trials, where\ndoctors sequentially collect data from patients and must determine when to stop\nrecruiting patients and whether the treatment is effective. The field of\ndifferential privacy has been developed to offer data analysis tools with\nstrong privacy guarantees, and has been commonly applied to machine learning\nand statistical tasks.\nIn this work, we study the sequential hypothesis testing problem under a\nslight variant of differential privacy, known as Renyi differential privacy. We\npresent a new private algorithm based on Wald's Sequential Probability Ratio\nTest (SPRT) that also gives strong theoretical privacy guarantees. We provide\ntheoretical analysis on statistical performance measured by Type I and Type II\nerror as well as the expected sample size. We also empirically validate our\ntheoretical results on several synthetic databases, showing that our algorithms\nalso perform well in practice. Unlike previous work in private hypothesis\ntesting that focused only on the classical fixed sample setting, our results in\nthe sequential setting allow a conclusion to be reached much earlier, and thus\nsaving the cost of collecting additional samples.",
    "descriptor": "",
    "authors": [
      "Wanrong Zhang",
      "Yajun Mei",
      "Rachel Cummings"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2204.04597"
  },
  {
    "id": "arXiv:2204.04638",
    "title": "Spectral Unmixing of Hyperspectral Images Based on Block Sparse  Structure",
    "abstract": "Spectral unmixing (SU) of hyperspectral images (HSIs) is one of the important\nareas in remote sensing (RS) that needs to be carefully addressed in different\nRS applications. Despite the high spectral resolution of the hyperspectral\ndata, the relatively low spatial resolution of the sensors may lead to mixture\nof different pure materials within the image pixels. In this case, the spectrum\nof a given pixel recorded by the sensor can be a combination of multiple\nspectra each belonging to a unique material in that pixel. Spectral unmixing is\nthen used as a technique to extract the spectral characteristics of the\ndifferent materials within the mixed pixels and to recover the spectrum of each\npure spectral signature, called endmember. Block-sparsity exists in\nhyperspectral images as a result of spectral similarity between neighboring\npixels. In block-sparse signals, the nonzero samples occur in clusters and the\npattern of the clusters is often supposed to be unavailable as prior\ninformation. This paper presents an innovative spectral unmixing approach for\nHSIs based on block-sparse structure and sparse Bayesian learning (SBL)\nstrategy. To evaluate the performance of the proposed SU algorithm, it is\ntested on both synthetic and real hyperspectral data and the quantitative\nresults are compared to those of other state-of-the-art methods in terms of\nabundance angel distance (AAD) and mean square error (MSE). The achieved\nresults show the superiority of the proposed algorithm over the other competing\nmethods by a significant margin.",
    "descriptor": "\nComments: 18 pages, 8 figures, submitted to journal, in review\n",
    "authors": [
      "Seyed Hossein Mosavi Azarang",
      "Roozbeh Rajabi",
      "Hadi Zayyani",
      "Amin Zehtabian"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.04638"
  },
  {
    "id": "arXiv:2204.04639",
    "title": "Lipschitz stability of $\u03b3$-FOCS and RC canonical Jordan bases of  real $H$-selfadjoint matrices under small perturbations",
    "abstract": "In 2008 Bella, Olshevsky and Prasad proved that the flipped orthogonal (FO)\nJordan bases of H-selfadjoint matrices are Lipschitz stable under small\nperturbations. In 2022, Dogruer, Minenkova and Olshevsky considered the real\ncase, and proved that for real H-selfadjoint matrices there exist a more\nrefined bases called FOCS bases. In addition to flipped orthogonality they also\npossess the conjugate symmetric (CS) property. In this paper we prove that\nthese new FOCS bases are Lipschitz stable under small perturbations as well. We\nalso establish the Lipschitz stability for the classical real canonical Jordan\nbases.",
    "descriptor": "\nComments: 31 pages\n",
    "authors": [
      "S. Dogruer Akgul",
      "A. Minenkova",
      "V. Olshevsky"
    ],
    "subjectives": [
      "Functional Analysis (math.FA)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2204.04639"
  },
  {
    "id": "arXiv:2204.04648",
    "title": "Gaussian Processes for Missing Value Imputation",
    "abstract": "Missing values are common in many real-life datasets. However, most of the\ncurrent machine learning methods can not handle missing values. This means that\nthey should be imputed beforehand. Gaussian Processes (GPs) are non-parametric\nmodels with accurate uncertainty estimates that combined with sparse\napproximations and stochastic variational inference scale to large data sets.\nSparse GPs can be used to compute a predictive distribution for missing data.\nHere, we present a hierarchical composition of sparse GPs that is used to\npredict missing values at each dimension using all the variables from the other\ndimensions. We call the approach missing GP (MGP). MGP can be trained\nsimultaneously to impute all observed missing values. Specifically, it outputs\na predictive distribution for each missing value that is then used in the\nimputation of other missing values. We evaluate MGP in one private clinical\ndata set and four UCI datasets with a different percentage of missing values.\nWe compare the performance of MGP with other state-of-the-art methods for\nimputing missing values, including variants based on sparse GPs and deep GPs.\nThe results obtained show a significantly better performance of MGP.",
    "descriptor": "",
    "authors": [
      "Bahram Jafrasteh",
      "Daniel Hern\u00e1ndez-Lobato",
      "Sim\u00f3n Pedro Lubi\u00e1n-L\u00f3pez",
      "Isabel Benavente-Fern\u00e1ndez"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2204.04648"
  },
  {
    "id": "arXiv:2204.04678",
    "title": "Parallelized integrated nested Laplace approximations for fast Bayesian  inference",
    "abstract": "There is a growing demand for performing larger-scale Bayesian inference\ntasks, arising from greater data availability and higher-dimensional model\nparameter spaces. In this work we present parallelization strategies for the\nmethodology of integrated nested Laplace approximations (INLA), a popular\nframework for performing approximate Bayesian inference on the class of Latent\nGaussian models. Our approach makes use of nested OpenMP parallelism, a\nparallel line search procedure using robust regression in INLA's optimization\nphase and the state-of-the-art sparse linear solver PARDISO. We leverage\nmutually independent function evaluations in the algorithm as well as advanced\nsparse linear algebra techniques. This way we can flexibly utilize the power of\ntoday's multi-core architectures. We demonstrate the performance of our new\nparallelization scheme on a number of different real-world applications. The\nintroduction of parallelism leads to speedups of a factor 10 and more for all\nlarger models. Our work is already integrated in the current version of the\nopen-source R-INLA package, making its improved performance conveniently\navailable to all users.",
    "descriptor": "\nComments: 18 pages, 7 figures\n",
    "authors": [
      "Lisa Gaedke-Merzh\u00e4user",
      "Janet van Niekerk",
      "Olaf Schenk",
      "H\u00e5vard Rue"
    ],
    "subjectives": [
      "Computation (stat.CO)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2204.04678"
  },
  {
    "id": "arXiv:2204.04691",
    "title": "Coreset of Hyperspectral Images on Small Quantum Computer",
    "abstract": "Machine Learning (ML) techniques are employed to analyze and process big\nRemote Sensing (RS) data, and one well-known ML technique is a Support Vector\nMachine (SVM). An SVM is a quadratic programming (QP) problem, and a D-Wave\nquantum annealer (D-Wave QA) promises to solve this QP problem more efficiently\nthan a conventional computer. However, the D-Wave QA cannot solve directly the\nSVM due to its very few input qubits. Hence, we use a coreset (\"core of a\ndataset\") of given EO data for training an SVM on this small D-Wave QA. The\ncoreset is a small, representative weighted subset of an original dataset, and\nany training models generate competitive classes by using the coreset in\ncontrast to by using its original dataset. We measured the closeness between an\noriginal dataset and its coreset by employing a Kullback-Leibler (KL)\ndivergence measure. Moreover, we trained the SVM on the coreset data by using\nboth a D-Wave QA and a conventional method. We conclude that the coreset\ncharacterizes the original dataset with very small KL divergence measure. In\naddition, we present our KL divergence results for demonstrating the closeness\nbetween our original data and its coreset. As practical RS data, we use\nHyperspectral Image (HSI) of Indian Pine, USA.",
    "descriptor": "\nComments: Accepted to IGARSS2022. You may not be able to access this article after the publication in the conference\n",
    "authors": [
      "Soronzonbold Otgonbaatar",
      "Mihai Datcu",
      "Beg\u00fcm Demir"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2204.04691"
  },
  {
    "id": "arXiv:2204.04699",
    "title": "On the Cleaning Lemma of Quantum Coding Theory",
    "abstract": "The term \"Cleaning Lemma\" refers to a family of similar propositions that\nhave been used in Quantum Coding Theory to estimate the minimum distance of a\ncode in terms of its length and dimension. We show that the mathematical core\nis a simple fact of linear algebra of inner product spaces; moreover, it admits\na further reduction to a combinatorial, lattice-theoretical level. Several\nconcrete variants of the Cleaning Lemma and some additional propositions are\nderived as corollaries of the proposed approach.",
    "descriptor": "\nComments: 25pp\n",
    "authors": [
      "Gleb Kalachev",
      "Sergey Sadov"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2204.04699"
  },
  {
    "id": "arXiv:2204.04721",
    "title": "Dual-Function Radar-Communication System Aided by Intelligent Reflecting  Surfaces",
    "abstract": "We propose a novel design of a dual-function radar communication (DFRC)\nsystem aided by an Intelligent Reflecting Surface (IRS). We consider a scenario\nwith one target and multiple communication receivers, where there is no\nline-of-sight between the radar and the target. The radar precoding matrix and\nthe IRS weights are optimally designed to maximize the weighted sum of the\nsignal-to-noise ratio (SNR) at the radar receiver and the SNR at the\ncommunication receivers subject to power constraints and constant modulus\nconstraints on the IRS weights. The problem is decoupled into two sub-problems,\nnamely, waveform design and IRS weight design, and is solved via alternating\noptimization. The former subproblem is solved via linear programming, and the\nlatter via manifold optimization with a quartic polynomial objective. The key\ncontribution of this paper lies in solving the IRS weight design sub-problem\nthat is based on the optimization of a quartic objective function in the IRS\nweights, and is subject to unit modulus-constraint on the IRS weights.\nSimulation results are provided to show the convergence behavior of the\nproposed algorithm under different system configurations, and the effectiveness\nof using IRS to improve radar and communication performance.",
    "descriptor": "\nComments: 5 pages, 3 figures\n",
    "authors": [
      "Yikai Li",
      "Athina Petropulu"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2204.04721"
  },
  {
    "id": "arXiv:2204.04762",
    "title": "Rockafellian Relaxation in Optimization under Uncertainty:  Asymptotically Exact Formulations",
    "abstract": "In practice, optimization models are often prone to unavoidable inaccuracies\ndue to lack of data and dubious assumptions. Traditionally, this placed special\nemphasis on risk-based and robust formulations, and their focus on\n\"conservative\" decisions. We develop, in contrast, an \"optimistic\" framework\nbased on Rockafellian relaxations in which optimization is conducted not only\nover the original decision space but also jointly with a choice of model\nperturbation. The framework enables us to address challenging problems with\nambiguous probability distributions from the areas of two-stage stochastic\noptimization without relatively complete recourse, probability functions\nlacking continuity properties, expectation constraints, and outlier analysis.\nWe are also able to circumvent the fundamental difficulty in stochastic\noptimization that convergence of distributions fails to guarantee convergence\nof expectations. The framework centers on the novel concepts of exact and\nasymptotically exact Rockafellians, with interpretations of \"negative\"\nregularization emerging in certain settings. We illustrate the role of\nPhi-divergence, examine rates of convergence under changing distributions, and\nexplore extensions to first-order optimality conditions. The main development\nis free of assumptions about convexity, smoothness, and even continuity of\nobjective functions.",
    "descriptor": "",
    "authors": [
      "Louis L. Chen",
      "Johannes O. Royset"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.04762"
  },
  {
    "id": "arXiv:2204.04773",
    "title": "Worst-case Performance of Greedy Policies in Bandits with Imperfect  Context Observations",
    "abstract": "Contextual bandits are canonical models for sequential decision-making under\nuncertainty in environments with time-varying components. In this setting, the\nexpected reward of each bandit arm consists of the inner product of an unknown\nparameter and the context vector of that arm, perturbed with a random error.\nThe classical setting heavily relies on fully observed contexts, while study of\nthe richer model of imperfectly observed contextual bandits is immature. This\nwork considers Greedy reinforcement learning policies that take actions as if\nthe current estimates of the parameter and of the unobserved contexts coincide\nwith the corresponding true values. We establish that the non-asymptotic\nworst-case regret grows logarithmically with the time horizon and the failure\nprobability, while it scales linearly with the number of arms. Numerical\nanalysis showcasing the above efficiency of Greedy policies is also provided.",
    "descriptor": "\nComments: 13 pages, 2figures\n",
    "authors": [
      "Hongju Park",
      "Mohamad Kazem Shirani Faradonbeh"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.04773"
  },
  {
    "id": "arXiv:2204.04785",
    "title": "Driving black-box quantum thermal machines with optimal power/efficiency  trade-offs using reinforcement learning",
    "abstract": "The optimal control of non-equilibrium open quantum systems is a challenging\ntask but has a key role in improving existing quantum information processing\ntechnologies. We introduce a general model-free framework based on\nReinforcement Learning to identify out-of-equilibrium thermodynamic cycles that\nare Pareto optimal trade-offs between power and efficiency for quantum heat\nengines and refrigerators. The method does not require any knowledge of the\nquantum thermal machine, nor of the system model, nor of the quantum state.\nInstead, it only observes the heat fluxes, so it is both applicable to\nsimulations and experimental devices. We test our method identifying\nPareto-optimal trade-offs between power and efficiency in two systems: an\nexperimentally realistic refrigerator based on a superconducting qubit, where\nwe identify non-intuitive control sequences that reduce quantum friction and\noutperform previous cycles proposed in literature; and a heat engine based on a\nquantum harmonic oscillator, where we find cycles with an elaborate structure\nthat outperform the optimized Otto cycle.",
    "descriptor": "\nComments: 7+13 pages, 9 figures. arXiv admin note: substantial text overlap with arXiv:2108.13525\n",
    "authors": [
      "Paolo Andrea Erdman",
      "Frank No\u00e9"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Mesoscale and Nanoscale Physics (cond-mat.mes-hall)",
      "Machine Learning (cs.LG)",
      "Chemical Physics (physics.chem-ph)"
    ],
    "url": "https://arxiv.org/abs/2204.04785"
  },
  {
    "id": "arXiv:2204.04808",
    "title": "Unbiased Multilevel Monte Carlo methods for intractable distributions:  MLMC meets MCMC",
    "abstract": "Constructing unbiased estimators from Markov chain Monte Carlo (MCMC) outputs\nhas recently increased much attention in statistics and machine learning\ncommunities. However, the existing unbiased MCMC framework only works when the\nquantity of interest is an expectation, which rules out many practical\napplications. In this paper, we propose a general method to construct unbiased\nestimators for function of expectations. We further generalize this method to\nestimate nested expectations. Our idea is based on the combination and\ngeneralization of the unbiased MCMC and Multilevel Monte Carlo (MLMC) methods.\nIn contrast to traditional sequential methods, our estimator can be easily\nimplemented on parallel processors independently. We prove our estimator has a\nfinite variance, a finite computational complexity, and achieves\n$\\varepsilon$-accuracy within $O(1/\\varepsilon^2)$ computational cost under\nmild conditions. We also illustrate our estimator on both synthetic and real\ndata examples.",
    "descriptor": "\nComments: 41 pages, 6 figures\n",
    "authors": [
      "Guanyang Wang",
      "Tianze Wang"
    ],
    "subjectives": [
      "Computation (stat.CO)",
      "Numerical Analysis (math.NA)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2204.04808"
  },
  {
    "id": "arXiv:2204.04811",
    "title": "Listen only to me! How well can target speech extraction handle false  alarms?",
    "abstract": "Target speech extraction (TSE) extracts the speech of a target speaker in a\nmixture given auxiliary clues characterizing the speaker, such as an enrollment\nutterance. TSE addresses thus the challenging problem of simultaneously\nperforming separation and speaker identification. There has been much progress\nin extraction performance following the recent development of neural networks\nfor speech enhancement and separation. Most studies have focused on processing\nmixtures where the target speaker is actively speaking. However, the target\nspeaker is sometimes silent in practice, i.e., inactive speaker (IS). A typical\nTSE system will tend to output a signal in IS cases, causing false alarms. This\nis a severe problem for the practical deployment of TSE systems. This paper\naims at understanding better how well TSE systems can handle IS cases. We\nconsider two approaches to deal with IS, (1) training a system to directly\noutput zero signals or (2) detecting IS with an extra speaker verification\nmodule. We perform an extensive experimental comparison of these schemes in\nterms of extraction performance and IS detection using the LibriMix dataset and\nreveal their pros and cons.",
    "descriptor": "\nComments: Submitted to Inerspeech 2022\n",
    "authors": [
      "Marc Delcroix",
      "Keisuke Kinoshita",
      "Tsubasa Ochiai",
      "Katerina Zmolikova",
      "Hiroshi Sato",
      "Tomohiro Nakatani"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2204.04811"
  },
  {
    "id": "arXiv:2204.04819",
    "title": "RMFGP: Rotated Multi-fidelity Gaussian process with Dimension Reduction  for High-dimensional Uncertainty Quantification",
    "abstract": "Multi-fidelity modelling arises in many situations in computational science\nand engineering world. It enables accurate inference even when only a small set\nof accurate data is available. Those data often come from a high-fidelity\nmodel, which is computationally expensive. By combining the realizations of the\nhigh-fidelity model with one or more low-fidelity models, the multi-fidelity\nmethod can make accurate predictions of quantities of interest. This paper\nproposes a new dimension reduction framework based on rotated multi-fidelity\nGaussian process regression and a Bayesian active learning scheme when the\navailable precise observations are insufficient. By drawing samples from the\ntrained rotated multi-fidelity model, the so-called supervised dimension\nreduction problems can be solved following the idea of the sliced average\nvariance estimation (SAVE) method combined with a Gaussian process regression\ndimension reduction technique. This general framework we develop can\neffectively solve high-dimensional problems while the data are insufficient for\napplying traditional dimension reduction methods. Moreover, a more accurate\nsurrogate Gaussian process model of the original problem can be obtained based\non our trained model. The effectiveness of the proposed rotated multi-fidelity\nGaussian process(RMFGP) model is demonstrated in four numerical examples. The\nresults show that our method has better performance in all cases and\nuncertainty propagation analysis is performed for last two cases involving\nstochastic partial differential equations.",
    "descriptor": "",
    "authors": [
      "Jiahao Zhang",
      "Shiqi Zhang",
      "Guang Lin"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.04819"
  },
  {
    "id": "arXiv:2204.04875",
    "title": "Learning to Induce Causal Structure",
    "abstract": "The fundamental challenge in causal induction is to infer the underlying\ngraph structure given observational and/or interventional data. Most existing\ncausal induction algorithms operate by generating candidate graphs and then\nevaluating them using either score-based methods (including continuous\noptimization) or independence tests. In this work, instead of proposing scoring\nfunction or independence tests, we treat the inference process as a black box\nand design a neural network architecture that learns the mapping from both\nobservational and interventional data to graph structures via supervised\ntraining on synthetic graphs. We show that the proposed model generalizes not\nonly to new synthetic graphs but also to naturalistic graphs.",
    "descriptor": "",
    "authors": [
      "Nan Rosemary Ke",
      "Silvia Chiappa",
      "Jane Wang",
      "Jorg Bornschein",
      "Theophane Weber",
      "Anirudh Goyal",
      "Matthew Botvinic",
      "Michael Mozer",
      "Danilo Jimenez Rezende"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.04875"
  },
  {
    "id": "arXiv:2204.04901",
    "title": "Entropic transfer operators",
    "abstract": "We propose a new concept for the regularization and discretization of\ntransfer operators in dynamical systems. Our approach is based on the\nentropically regularized optimal transport between two probability measures. In\nparticular, we use optimal transport plans in order to construct a\nfinite-dimensional approximation of some transfer operator which can be\nanalysed computationally. We prove that the spectrum of the discretized\noperator converges to the one of the regularized original operator, give a\ndetailed analysis of the relation between the discretized and the original\nperipheral spectrum for a rotation map on the $n$-torus and provide code for\nthree numerical experiments, including one based on the raw trajectory data of\na small biomolecule from which its dominant conformations are recovered.",
    "descriptor": "",
    "authors": [
      "Oliver Junge",
      "Daniel Matthes",
      "Bernhard Schmitzer"
    ],
    "subjectives": [
      "Dynamical Systems (math.DS)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2204.04901"
  },
  {
    "id": "arXiv:2204.04906",
    "title": "Application of QUBO solver using black-box optimization to structural  design for resonance avoidance",
    "abstract": "Quadratic unconstrained binary optimization (QUBO) solvers can be applied to\ndesign an optimal structure to avoid resonance. QUBO algorithms that work on a\nclassical or quantum device have succeeded in some industrial applications.\nHowever, their applications are still limited due to the difficulty of\ntransforming from the original optimization problem to QUBO. Recently,\nblack-box optimization (BBO) methods have been proposed to tackle this issue\nusing a machine learning technique and a Bayesian treatment for combinatorial\noptimization. We employed the BBO methods to design a printed circuit board for\nresonance avoidance. This design problem is formulated to maximize natural\nfrequency and simultaneously minimize the number of mounting points. The\nnatural frequency, which is the bottleneck for the QUBO formulation, is\napproximated to a quadratic model in the BBO method. We demonstrated that BBO\nusing a factorization machine shows good performance in both the calculation\ntime and the success probability of finding the optimal solution. Our results\ncan open up QUBO solvers' potential for other applications in structural\ndesigns.",
    "descriptor": "",
    "authors": [
      "Tadayoshi Matsumori",
      "Masato Taki",
      "Tadashi Kadowaki"
    ],
    "subjectives": [
      "Mesoscale and Nanoscale Physics (cond-mat.mes-hall)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Machine Learning (cs.LG)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2204.04906"
  },
  {
    "id": "arXiv:2204.04920",
    "title": "A graphical construction of free Markov categories",
    "abstract": "We describe how to perform surgeries on Joyal-Street style diagrams and\nthereby construct free Markov categories. We also show that the construction is\nfunctorial over ordered directed acyclic graphs.",
    "descriptor": "",
    "authors": [
      "Yimu Yin"
    ],
    "subjectives": [
      "Category Theory (math.CT)",
      "Logic in Computer Science (cs.LO)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2204.04920"
  },
  {
    "id": "arXiv:2204.04941",
    "title": "Linear Moment Models to Approximate Knudsen Layers",
    "abstract": "We propose a well-posed Maxwell-type boundary condition for the linear moment\nsystem in half-space. As a reduction of the Boltzmann equation, the moment\nequations are available to model Knudsen layers near a solid wall, where proper\nboundary conditions should be prescribed. Utilizing an orthogonal\ndecomposition, we separate the part with a damping term from the system and\nthen impose a new class of Maxwell-type boundary conditions on it. Due to the\nnew boundary condition, we show that the half-space boundary value problem\nadmits a unique solution with explicit expressions. Instantly, the\nwell-posedness of the linear moment system is achieved. We apply the procedure\nto classical flow problems with the Shakhov collision term, such as the\nvelocity slip and temperature jump problems. The model can capture Knudsen\nlayers with very high accuracy using only a few moments.",
    "descriptor": "",
    "authors": [
      "Ruo Li",
      "Yichen Yang"
    ],
    "subjectives": [
      "Analysis of PDEs (math.AP)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2204.04941"
  },
  {
    "id": "arXiv:2204.04949",
    "title": "A Semantic Segmentation Network Based Real-Time Computer-Aided Diagnosis  System for Hydatidiform Mole Hydrops Lesion Recognition in Microscopic View",
    "abstract": "As a disease with malignant potential, hydatidiform mole (HM) is one of the\nmost common gestational trophoblastic diseases. For pathologists, the HM\nsection of hydrops lesions is an important basis for diagnosis. In pathology\ndepartments, the diverse microscopic manifestations of HM lesions and the\nlimited view under the microscope mean that physicians with extensive\ndiagnostic experience are required to prevent missed diagnosis and\nmisdiagnosis. Feature extraction can significantly improve the accuracy and\nspeed of the diagnostic process. As a remarkable diagnosis assisting\ntechnology, computer-aided diagnosis (CAD) has been widely used in clinical\npractice. We constructed a deep-learning-based CAD system to identify HM\nhydrops lesions in the microscopic view in real-time. The system consists of\nthree modules; the image mosaic module and edge extension module process the\nimage to improve the outcome of the hydrops lesion recognition module, which\nadopts a semantic segmentation network, our novel compound loss function, and a\nstepwise training function in order to achieve the best performance in\nidentifying hydrops lesions. We evaluated our system using an HM hydrops\ndataset. Experiments show that our system is able to respond in real-time and\ncorrectly display the entire microscopic view with accurately labeled HM\nhydrops lesions.",
    "descriptor": "",
    "authors": [
      "Chengze Zhu",
      "Pingge Hu",
      "Xianxu Zeng",
      "Xingtong Wang",
      "Zehua Ji",
      "Li Shi"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.04949"
  },
  {
    "id": "arXiv:2204.04955",
    "title": "Machine learning based event classification for the energy-differential  measurement of the $^\\text{nat}$C(n,p) and $^\\text{nat}$C(n,d) reactions",
    "abstract": "The paper explores the feasibility of using machine learning techniques, in\nparticular neural networks, for classification of the experimental data from\nthe joint $^\\text{nat}$C(n,p) and $^\\text{nat}$C(n,d) reaction cross section\nmeasurement from the neutron time of flight facility n_TOF at CERN. Each\nrelevant $\\Delta E$-$E$ pair of strips from two segmented silicon telescopes is\ntreated separately and afforded its own dedicated neural network. An important\npart of the procedure is a careful preparation of training datasets, based on\nthe raw data from Geant4 simulations. Instead of using these raw data for the\ntraining of neural networks, we divide a relevant 3-parameter space into\ndiscrete voxels, classify each voxel according to a particle/reaction type and\nsubmit these voxels to a training procedure. The classification capabilities of\nthe structurally optimized and trained neural networks are found to be superior\nto those of the manually selected cuts.",
    "descriptor": "\nComments: 11 pages, 5 figures, 2 tables\n",
    "authors": [
      "P. \u017dugec",
      "M. Barbagallo",
      "J. Andrzejewski",
      "J. Perkowski",
      "N. Colonna",
      "D. Bosnar",
      "A. Gawlik",
      "M. Sabate-Gilarte",
      "M. Bacak",
      "F. Mingrone",
      "E. Chiaveri"
    ],
    "subjectives": [
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Nuclear Experiment (nucl-ex)"
    ],
    "url": "https://arxiv.org/abs/2204.04955"
  },
  {
    "id": "arXiv:2204.04956",
    "title": "Segmentation Network with Compound Loss Function for Hydatidiform Mole  Hydrops Lesion Recognition",
    "abstract": "Pathological morphology diagnosis is the standard diagnosis method of\nhydatidiform mole. As a disease with malignant potential, the hydatidiform mole\nsection of hydrops lesions is an important basis for diagnosis. Due to\nincomplete lesion development, early hydatidiform mole is difficult to\ndistinguish, resulting in a low accuracy of clinical diagnosis. As a remarkable\nmachine learning technology, image semantic segmentation networks have been\nused in many medical image recognition tasks. We developed a hydatidiform mole\nhydrops lesion segmentation model based on a novel loss function and training\nmethod. The model consists of different networks that segment the section image\nat the pixel and lesion levels. Our compound loss function assign weights to\nthe segmentation results of the two levels to calculate the loss. We then\npropose a stagewise training method to combine the advantages of various loss\nfunctions at different levels. We evaluate our method on a hydatidiform mole\nhydrops dataset. Experiments show that the proposed model with our loss\nfunction and training method has good recognition performance under different\nsegmentation metrics.",
    "descriptor": "",
    "authors": [
      "Chengze Zhu",
      "Pingge Hu",
      "Xianxu Zeng",
      "Xingtong Wang",
      "Zehua Ji",
      "Li Shi"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.04956"
  },
  {
    "id": "arXiv:2204.04973",
    "title": "Consistent Estimators for Nonlinear Vessel Models",
    "abstract": "In this work, the issue of obtaining consistent parameter estimators for\nnonlinear regression models where the regressors are second-order modulus\nfunctions is explored. It is shown that consistent instrumental variable\nestimators can be obtained by estimating first and second-order moments of\nnon-additive environmental disturbances' probability distributions as nuisance\nparameters in parallel to the sought-after model parameters, conducting\nexperiments with a static excitation offset of sufficient amplitude and forcing\nthe instruments to have zero mean. The proposed method is evaluated in a\nsimulation example with a model of a marine surface vessel.",
    "descriptor": "\nComments: 9 pages, 2 figures\n",
    "authors": [
      "Fredrik Ljungberg",
      "Martin Enqvist"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2204.04973"
  },
  {
    "id": "arXiv:2204.04993",
    "title": "Ischemic Stroke Lesion Segmentation Using Adversarial Learning",
    "abstract": "Ischemic stroke occurs through a blockage of clogged blood vessels supplying\nblood to the brain. Segmentation of the stroke lesion is vital to improve\ndiagnosis, outcome assessment and treatment planning. In this work, we propose\na segmentation model with adversarial learning for ischemic lesion\nsegmentation. We adopt U-Net with skip connection and dropout as segmentation\nbaseline network and a fully connected network (FCN) as discriminator network.\nDiscriminator network consists of 5 convolution layers followed by leaky-ReLU\nand an upsampling layer to rescale the output to the size of the input map.\nTraining a segmentation network along with an adversarial network can detect\nand correct higher order inconsistencies between the segmentation maps produced\nby ground-truth and the Segmentor. We exploit three modalities (CT, DPWI, CBF)\nof acute computed tomography (CT) perfusion data provided in ISLES 2018\n(Ischemic Stroke Lesion Segmentation) for ischemic lesion segmentation. Our\nmodel has achieved dice accuracy of 42.10% with the cross-validation of\ntraining and 39% with the testing data.",
    "descriptor": "\nComments: Published in MICCAI ISLES Challenge 2018\n",
    "authors": [
      "Mobarakol Islam",
      "N Rajiv Vaidyanathan",
      "V Jeya Maria Jose",
      "Hongliang Ren"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.04993"
  },
  {
    "id": "arXiv:2204.05033",
    "title": "Information in probability: Another information-theoretic proof of a  finite de Finetti theorem",
    "abstract": "We recall some of the history of the information-theoretic approach to\nderiving core results in probability theory and indicate parts of the recent\nresurgence of interest in this area with current progress along several\ninteresting directions. Then we give a new information-theoretic proof of a\nfinite version of de Finetti's classical representation theorem for\nfinite-valued random variables. We derive an upper bound on the relative\nentropy between the distribution of the first $k$ in a sequence of $n$\nexchangeable random variables, and an appropriate mixture over product\ndistributions. The mixing measure is characterised as the law of the empirical\nmeasure of the original sequence, and de Finetti's result is recovered as a\ncorollary. The proof is nicely motivated by the Gibbs conditioning principle in\nconnection with statistical mechanics, and it follows along an appealing\nsequence of steps. The technical estimates required for these steps are\nobtained via the use of a collection of combinatorial tools known within\ninformation theory as `the method of types.'",
    "descriptor": "",
    "authors": [
      "Lampros Gavalakis",
      "Ioannis Kontoyiannis"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2204.05033"
  },
  {
    "id": "arXiv:2204.05046",
    "title": "Root structures of polynomials with sparse exponents",
    "abstract": "For real polynomials with (sparse) exponents in some fixed set, \\[\n\\Psi(t)=x+y_1t^{k_1}+\\ldots +y_L t^{k_L}, \\] we analyse the types of root\nstructures that might occur as the coefficients vary. We first establish a\nstratification of roots into tiers, each containing roots of comparable sizes.\nWe then show that there exists a suitable small parameter $\\epsilon>0$ such\nthat, for any root $w\\in \\mathbb{C}$, $B(w,\\epsilon|w|)$ contains at most $L$\nroots, counted with multiplicity. Our analysis suggests the consideration of a\nrough factorisation of the original polynomial and we establish the closeness\nof the corresponding root structures: there exists a covering of the roots by\nballs wherein a) each ball contains the same number of roots of the original\npolynomial and of its rough factorisation and b) the balls are strongly\nseparated.",
    "descriptor": "\nComments: 47 pages, 4 figures\n",
    "authors": [
      "Reuben Wheeler"
    ],
    "subjectives": [
      "Classical Analysis and ODEs (math.CA)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2204.05046"
  },
  {
    "id": "arXiv:2204.05052",
    "title": "A Novel Channel Identification Architecture for mmWave Systems Based on  Eigen Features",
    "abstract": "Millimeter wave (mmWave) communication technique has been developed rapidly\nbecause of many advantages of high speed, large bandwidth, and ultra-low delay.\nHowever, mmWave communications systems suffer from fast fading and frequent\nblocking. Hence, the ideal communication environment for mmWave is line of\nsight (LOS) channel. To improve the efficiency and capacity of mmWave system,\nand to better build the Internet of Everything (IoE) service network, this\npaper focuses on the channel identification technique in line-of- sight (LOS)\nand non-LOS (NLOS) environments. Considering the limited computing ability of\nuser equipments (UEs), this paper proposes a novel channel identification\narchitecture based on eigen features, i.e. eigenmatrix and eigenvector (EMEV)\nof channel state information (CSI). Furthermore, this paper explores clustered\ndelay line (CDL) channel identification with mmWave, which is defined by the\n3rd generation partnership project (3GPP). Ther experimental results show that\nthe EMEV based scheme can achieve identification accuracy of 99.88% assuming\nperfect CSI. In the robustness test, the maximum noise can be tolerated is SNR=\n16 dB, with the threshold acc \\geq 95%. What is more, the novel architecture\nbased on EMEV feature will reduce the comprehensive overhead by about 90%.",
    "descriptor": "",
    "authors": [
      "Yibin Zhang",
      "Jinlong Sun",
      "Guan Gui",
      "Haris Gacanin",
      "Fumiyuki Adachi"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.05052"
  },
  {
    "id": "arXiv:2204.05075",
    "title": "Zero-phase angle asteroid taxonomy classification using unsupervised  machine learning algorithms",
    "abstract": "We are in an era of large catalogs and, thus, statistical analysis tools for\nlarge data sets, such as machine learning, play a fundamental role. One example\nof such a survey is the Sloan Moving Object Catalog (MOC), which lists the\nastrometric and photometric information of all moving objects captured by the\nSloan field of view. One great advantage of this telescope is represented by\nits set of five filters, allowing for taxonomic analysis of asteroids by\nstudying their colors. However, until now, the color variation produced by the\nchange of phase angle of the object has not been taken into account. In this\npaper, we address this issue by using absolute magnitudes for classification.\nWe aim to produce a new taxonomic classification of asteroids based on their\nmagnitudes that is unaffected by variations caused by the change in phase\nangle. We selected 9481 asteroids with absolute magnitudes of Hg, Hi and Hz,\ncomputed from the Sloan Moving Objects Catalog using the HG12 system. We\ncalculated the absolute colors with them. To perform the taxonomic\nclassification, we applied a unsupervised machine learning algorithm known as\nfuzzy C-means. This is a useful soft clustering tool for working with {data\nsets where the different groups are not completely separated and there are\nregions of overlap between them. We have chosen to work with the four main\ntaxonomic complexes, C, S, X, and V, as they comprise most of the known\nspectral characteristics. We classified a total of 6329 asteroids with more\nthan 60% probability of belonging to the assigned taxonomic class, with 162 of\nthese objects having been characterized by an ambiguous classification in the\npast. By analyzing the sample obtained in the plane Semimajor axis versus\ninclination, we identified 15 new V-type asteroid candidates outside the Vesta\nfamily region.",
    "descriptor": "",
    "authors": [
      "M. Colazo",
      "A. Alvarez-Candal",
      "R. Duffard"
    ],
    "subjectives": [
      "Earth and Planetary Astrophysics (astro-ph.EP)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.05075"
  },
  {
    "id": "arXiv:2204.05103",
    "title": "Transformer-Based Self-Supervised Learning for Emotion Recognition",
    "abstract": "In order to exploit representations of time-series signals, such as\nphysiological signals, it is essential that these representations capture\nrelevant information from the whole signal. In this work, we propose to use a\nTransformer-based model to process electrocardiograms (ECG) for emotion\nrecognition. Attention mechanisms of the Transformer can be used to build\ncontextualized representations for a signal, giving more importance to relevant\nparts. These representations may then be processed with a fully-connected\nnetwork to predict emotions. To overcome the relatively small size of datasets\nwith emotional labels, we employ self-supervised learning. We gathered several\nECG datasets with no labels of emotion to pre-train our model, which we then\nfine-tuned for emotion recognition on the AMIGOS dataset. We show that our\napproach reaches state-of-the-art performances for emotion recognition using\nECG signals on AMIGOS. More generally, our experiments show that transformers\nand pre-training are promising strategies for emotion recognition with\nphysiological signals.",
    "descriptor": "",
    "authors": [
      "Juan Vazquez-Rodriguez",
      "Gr\u00e9goire Lefebvre",
      "Julien Cumin",
      "James L. Crowley"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2204.05103"
  },
  {
    "id": "arXiv:2204.05110",
    "title": "Comparative Survey of Multigraph Integration Methods for Holistic Brain  Connectivity Mapping",
    "abstract": "One of the greatest scientific challenges in network neuroscience is to\ncreate a representative map of a population of heterogeneous brain networks,\nwhich acts as a connectional fingerprint. The connectional brain template\n(CBT), also named network atlas, presents a powerful tool for capturing the\nmost representative and discriminative traits of a given population while\npreserving its topological patterns. The idea of a CBT is to integrate a\npopulation of heterogeneous brain connectivity networks, derived from different\nneuroimaging modalities or brain views (e.g., structural and functional), into\na unified holistic representation. Here we review current state-of-the-art\nmethods designed to estimate well-centered and representative CBT for\npopulations of single-view and multi-view brain networks. We start by reviewing\neach CBT learning method, then we introduce the evaluation measures to compare\nCBT representativeness of populations generated by single-view and multigraph\nintegration methods, separately, based on the following criteria: centeredness,\nbiomarker-reproducibility, node-level similarity, global-level similarity, and\ndistance-based similarity. We demonstrate that the deep graph normalizer (DGN)\nmethod significantly outperforms other multi-graph and all single-view\nintegration methods for estimating CBTs using a variety of healthy and\ndisordered datasets in terms of centeredness, reproducibility (i.e.,\ngraph-derived biomarkers reproducibility that disentangle the typical from the\natypical connectivity variability), and preserving the topological traits at\nboth local and global graph-levels.",
    "descriptor": "",
    "authors": [
      "Nada Chaari",
      "Hatice Camgoz Akdag",
      "Islem Rekik"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.05110"
  },
  {
    "id": "arXiv:2204.05116",
    "title": "IMLE-Net: An Interpretable Multi-level Multi-channel Model for ECG  Classification",
    "abstract": "Early detection of cardiovascular diseases is crucial for effective treatment\nand an electrocardiogram (ECG) is pivotal for diagnosis. The accuracy of Deep\nLearning based methods for ECG signal classification has progressed in recent\nyears to reach cardiologist-level performance. In clinical settings, a\ncardiologist makes a diagnosis based on the standard 12-channel ECG recording.\nAutomatic analysis of ECG recordings from a multiple-channel perspective has\nnot been given enough attention, so it is essential to analyze an ECG recording\nfrom a multiple-channel perspective. We propose a model that leverages the\nmultiple-channel information available in the standard 12-channel ECG\nrecordings and learns patterns at the beat, rhythm, and channel level. The\nexperimental results show that our model achieved a macro-averaged ROC-AUC\nscore of 0.9216, mean accuracy of 88.85\\%, and a maximum F1 score of 0.8057 on\nthe PTB-XL dataset. The attention visualization results from the interpretable\nmodel are compared against the cardiologist's guidelines to validate the\ncorrectness and usability.",
    "descriptor": "\nComments: IEEE:SMC 2021\n",
    "authors": [
      "Likith Reddy",
      "Vivek Talwar",
      "Shanmukh Alle",
      "Raju. S. Bapi",
      "U. Deva Priyakumar"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2204.05116"
  },
  {
    "id": "arXiv:2204.05123",
    "title": "The Physicalization of Metamathematics and Its Implications for the  Foundations of Mathematics",
    "abstract": "Both metamathematics and physics are posited to emerge from samplings by\nobservers of the unique ruliad structure that corresponds to the entangled\nlimit of all possible computations. The possibility of higher-level mathematics\naccessible to humans is posited to be the analog for mathematical observers of\nthe perception of physical space for physical observers. A physicalized\nanalysis is given of the bulk limit of traditional axiomatic approaches to the\nfoundations of mathematics, together with explicit empirical metamathematics of\nsome examples of formalized mathematics. General physicalized laws of\nmathematics are discussed, associated with concepts such as metamathematical\nmotion, inevitable dualities, proof topology and metamathematical\nsingularities. It is argued that mathematics as currently practiced can be\nviewed as derived from the ruliad in a direct Platonic fashion analogous to our\nexperience of the physical world, and that axiomatic formulation, while often\nconvenient, does not capture the ultimate character of mathematics. Among the\nimplications of this view is that only certain collections of axioms may be\nconsistent with inevitable features of human mathematical observers. A\ndiscussion is included of historical and philosophical connections, as well as\nof foundational implications for the future of mathematics.",
    "descriptor": "",
    "authors": [
      "Stephen Wolfram"
    ],
    "subjectives": [
      "History and Overview (math.HO)",
      "Discrete Mathematics (cs.DM)",
      "Logic (math.LO)"
    ],
    "url": "https://arxiv.org/abs/2204.05123"
  },
  {
    "id": "arXiv:2204.05132",
    "title": "A Spiking Neural Network based on Neural Manifold for Augmenting  Intracortical Brain-Computer Interface Data",
    "abstract": "Brain-computer interfaces (BCIs), transform neural signals in the brain into\nin-structions to control external devices. However, obtaining sufficient\ntraining data is difficult as well as limited. With the advent of advanced\nmachine learning methods, the capability of brain-computer interfaces has been\nenhanced like never before, however, these methods require a large amount of\ndata for training and thus require data augmentation of the limited data\navailable. Here, we use spiking neural networks (SNN) as data generators. It is\ntouted as the next-generation neu-ral network and is considered as one of the\nalgorithms oriented to general artifi-cial intelligence because it borrows the\nneural information processing from bio-logical neurons. We use the SNN to\ngenerate neural spike information that is bio-interpretable and conforms to the\nintrinsic patterns in the original neural data. Ex-periments show that the\nmodel can directly synthesize new spike trains, which in turn improves the\ngeneralization ability of the BCI decoder. Both the input and output of the\nspiking neural model are spike information, which is a brain-inspired\nintelligence approach that can be better integrated with BCI in the future.",
    "descriptor": "\nComments: 12pages , 9 figures\n",
    "authors": [
      "Shengjie Zheng",
      "Wenyi Li",
      "Lang Qian",
      "Chenggang He",
      "Xiaojian Li"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.05132"
  },
  {
    "id": "arXiv:2204.05138",
    "title": "Artificial Intelligence Software Structured to Simulate Human Working  Memory, Mental Imagery, and Mental Continuity",
    "abstract": "This article presents an artificial intelligence (AI) architecture intended\nto simulate the human working memory system as well as the manner in which it\nis updated iteratively. It features several interconnected neural networks\ndesigned to emulate the specialized modules of the cerebral cortex. These are\nstructured hierarchically and integrated into a global workspace. They are\ncapable of temporarily maintaining high-level patterns akin to the\npsychological items maintained in working memory. This maintenance is made\npossible by persistent neural activity in the form of two modalities: sustained\nneural firing (resulting in a focus of attention) and synaptic potentiation\n(resulting in a short-term store). This persistent activity is updated\niteratively resulting in incremental changes to the content of the working\nmemory system. As the content stored in working memory gradually evolves,\nsuccessive states overlap and are continuous with one another. The present\narticle will explore how this architecture can lead to gradual shift in the\ndistribution of coactive representations, ultimately leading to mental\ncontinuity between processing states, and thus to human-like cognition.",
    "descriptor": "",
    "authors": [
      "Jared Edward Reser"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Symbolic Computation (cs.SC)"
    ],
    "url": "https://arxiv.org/abs/2204.05138"
  },
  {
    "id": "arXiv:2204.05139",
    "title": "On unsupervised projections and second order signals",
    "abstract": "Linear projections are widely used in the analysis of high-dimensional data.\nIn unsupervised settings where the data harbour latent classes/clusters, the\nquestion of whether class discriminatory signals are retained under projection\nis crucial. In the case of mean differences between classes, this question has\nbeen well studied. However, in many contemporary applications, notably in\nbiomedicine, group differences at the level of covariance or graphical model\nstructure are important. Motivated by such applications, in this paper we ask\nwhether linear projections can preserve differences in second order structure\nbetween latent groups. We focus on unsupervised projections, which can be\ncomputed without knowledge of class labels. We discuss a simple theoretical\nframework to study the behaviour of such projections which we use to inform an\nanalysis via quasi-exhaustive enumeration. This allows us to consider the\nperformance, over more than a hundred thousand sets of data-generating\npopulation parameters, of two popular projections, namely random projections\n(RP) and Principal Component Analysis (PCA). Across this broad range of\nregimes, PCA turns out to be more effective at retaining second order signals\nthan RP and is often even competitive with supervised projection. We complement\nthese results with fully empirical experiments showing 0-1 loss using simulated\nand real data. We study also the effect of projection dimension, drawing\nattention to a bias-variance trade-off in this respect. Our results show that\nPCA can indeed be a suitable first-step for unsupervised analysis, including in\ncases where differential covariance or graphical model structure are of\ninterest.",
    "descriptor": "\nComments: 25 pages, 10 figures, 3 tables\n",
    "authors": [
      "Thomas Lartigue",
      "Sach Mukherjee"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.05139"
  },
  {
    "id": "arXiv:2204.05146",
    "title": "Artificial Intelligence Enabled Spectral Reconfigurable Fiber Laser",
    "abstract": "The combinations of artificial intelligence and lasers provide powerful ways\nto form smart light sources with ground-breaking functions. Here, a Raman fiber\nlaser (RFL) with reconfigurable and programmable spectra in an ultra-wide\nbandwidth is developed based on spectral-spatial manipulation of light in\nmultimode fiber (MMF). The proposed fiber laser uses nonlinear gain from\ncascaded stimulated Raman scattering, random distributed feedback from Rayleigh\nscattering, and point feedback from an MMF-based smart spectral filter. Through\nwavefront shaping controlled by a genetic algorithm, light of selective\nwavelength(s) can be focused in the MMF, forming the filter that, together with\nthe active part of the laser, actively shape the output spectrum with a high\ndegree of freedom. We achieved arbitrary spectral shaping of the cascaded RFL\n(e.g., continuously tunable single-wavelength and multi-wavelength laser with\ncustomizable linewidth, mode separation, and power distribution) from the 1st-\nto the 3rd-order Stokes emission by adjusting the pump power and\nauto-optimization of the smart filter. Our research uses\nartificial-intelligence controlled light manipulation in a fiber platform with\nmulti-eigenmodes and nonlinear gain, mapping the spatial control into the\nspectral domain as well as extending the linear control of light in MMF to\nactive light emission, which is of great significance for applications in\noptical communication, sensing, and spectroscopy.",
    "descriptor": "\nComments: 10 pages,6 figures\n",
    "authors": [
      "Yanli Zhang",
      "Shanshan Wang",
      "Mingzhu She",
      "Weili Zhang"
    ],
    "subjectives": [
      "Optics (physics.optics)",
      "Systems and Control (eess.SY)",
      "Applied Physics (physics.app-ph)"
    ],
    "url": "https://arxiv.org/abs/2204.05146"
  },
  {
    "id": "arXiv:2204.05177",
    "title": "The PartialSpoof Database and Countermeasures for the Detection of Short  Generated Audio Segments Embedded in a Speech Utterance",
    "abstract": "Automatic speaker verification is susceptible to various manipulations and\nspoofing, such as text-to-speech (TTS) synthesis, voice conversion (VC),\nreplay, tampering, and so on. In this paper, we consider a new spoofing\nscenario called \"Partial Spoof\" (PS) in which synthesized or transformed audio\nsegments are embedded into a bona fide speech utterance. While existing\ncountermeasures (CMs) can detect fully spoofed utterances, there is a need for\ntheir adaptation or extension to the PS scenario to detect utterances in which\nonly a part of the audio signal is generated and hence only a fraction of an\nutterance is spoofed. For improved explainability, such new CMs should ideally\nalso be able to detect such short spoofed segments. Our previous study\nintroduced the first version of a speech database suitable for training CMs for\nthe PS scenario and showed that, although it is possible to train CMs to\nexecute the two types of detection described above, there is much room for\nimprovement. In this paper we propose various improvements to construct a\nsignificantly more accurate CM that can detect short generated spoofed audio\nsegments at finer temporal resolutions. First, we introduce newly proposed\nself-supervised pre-trained models as enhanced feature extractors. Second, we\nextend the PartialSpoof database by adding segment labels for various temporal\nresolutions, ranging from 20 ms to 640 ms. Third, we propose a new CM and\ntraining strategies that enable the simultaneous use of the utterance-level and\nsegment-level labels at different temporal resolutions. We also show that the\nproposed CM is capable of detecting spoofing at the utterance level with low\nerror rates, not only in the PS scenario but also in a related logical access\n(LA) scenario. The equal error rates of utterance-level detection on the\nPartialSpoof and the ASVspoof 2019 LA database were 0.47% and 0.59%,\nrespectively.",
    "descriptor": "\nComments: Submitted to IEEE/ACM Transactions on Audio Speech and Language Processing\n",
    "authors": [
      "Lin Zhang",
      "Xin Wang",
      "Erica Cooper",
      "Nicholas Evans",
      "Junichi Yamagishi"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Cryptography and Security (cs.CR)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2204.05177"
  },
  {
    "id": "arXiv:2204.05189",
    "title": "MmWave 6D Radio Localization with a Snapshot Observation from a Single  BS",
    "abstract": "Accurate and ubiquitous localization is crucial for a variety of applications\nsuch as logistics, navigation, intelligent transport, monitoring, and control.\nExploiting mmWave signals in 5G and Beyond 5G systems can provide accurate\nlocalization with limited infrastructure. We consider the single base station\nlocalization problem and extend it to 3D position and 3D orientation estimation\nof an unsynchronized multi-antenna user, using downlink MIMO-OFDM signals.\nThrough a Fisher information analysis, we show that the problem is often\nidentifiable, provided that there is at least one additional multipath\ncomponent, even if the position of corresponding incidence point is a priori\nunknown. Subsequently, we pose a maximum likelihood (ML) estimation problem, to\njointly estimate the 3D position and 3D orientation of the user as well as\nseveral nuisance parameters (the user clock offset and the positions of\nincidence points corresponding to the multipath). The ML problem is a\nhigh-dimensional non-convex optimization problem over a product of Euclidean\nand Riemannian manifolds. To avoid complex exhaustive search procedures, we\npropose a geometric initial estimate of all parameters, which reduces the\nproblem to a 1-dimensional search over a finite interval. Numerical results\nshow the efficiency of the proposed ad-hoc estimation, whose gap to the CRB is\ntightened using ML estimation.",
    "descriptor": "",
    "authors": [
      "Mohammad A. Nazari",
      "Gonzalo Seco-Granados",
      "Pontus Johannisson",
      "Henk Wymeersch"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2204.05189"
  },
  {
    "id": "arXiv:2204.05201",
    "title": "A Post-Processing Tool and Feasibility Study for Three-Dimensional  Imaging with Electrical Impedance Tomography During Deep Brain Stimulation  Surgery",
    "abstract": "Electrical impedance tomography (EIT) is a promising technique for biomedical\nimaging. The strength of EIT is its ability to reconstruct images of the body's\ninternal structures through radiation-safe techniques. EIT is regarded as safe\nfor patients' health, and it is currently being actively researched. This paper\ninvestigates the application of EIT during deep brain stimulation (DBS) surgery\nas a means to identify targets during operations. DBS involves a surgical\nprocedure in which a lead or electrode array is implanted in a specific target\narea in the brain. Electrical stimulations are then used to modulate neural\ncircuits within the target area to reduce disabling neurological symptoms. The\nmain difficulty in performing DBS surgery is to accurately position the lead in\nthe target area before commencing the treatment. Brain tissue shifts during DBS\nsurgery can be as large as the target size when compared with the pre-operative\nmagnetic resonance imaging (MRI) or computed tomography (CT) images. To address\nthis problem, a solution based on open-domain EIT to reconstruct images\nsurrounding the probe during DBS surgery is proposed. Data acquisition and\nimage reconstruction were performed, and artificial intelligence was applied to\nenhance the resulting images. The results showed that the proposed method is\nrapid, produces valuable high-quality images, and constitutes a first step\ntowards in-vivo study.",
    "descriptor": "",
    "authors": [
      "Sebastien Martin"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.05201"
  },
  {
    "id": "arXiv:2204.05203",
    "title": "CXR-FL: Deep Learning-based Chest X-ray Image Analysis Using Federated  Learning",
    "abstract": "Federated learning enables building a shared model from multicentre data\nwhile storing the training data locally for privacy. In this paper, we present\nan evaluation (called CXR-FL) of deep learning-based models for chest X-ray\nimage analysis using the federated learning method. We examine the impact of\nfederated learning parameters on the performance of central models.\nAdditionally, we show that classification models perform worse if trained on a\nregion of interest reduced to segmentation of the lung compared to the full\nimage. However, focusing training of the classification model on the lung area\nmay result in improved pathology interpretability during inference. We also\nfind that federated learning helps maintain model generalizability. The\npre-trained weights and code are publicly available at\n(https://github.com/SanoScience/CXR-FL).",
    "descriptor": "\nComments: Accepted at International Conference on Computational Science (ICCS) 2022, London\n",
    "authors": [
      "Filip \u015alazyk",
      "Przemys\u0142aw Jab\u0142ecki",
      "Aneta Lisowska",
      "Maciej Malawski",
      "Szymon P\u0142otka"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.05203"
  },
  {
    "id": "arXiv:2204.05205",
    "title": "Rethinking Machine Learning Model Evaluation in Pathology",
    "abstract": "Machine Learning has been applied to pathology images in research and\nclinical practice with promising outcomes. However, standard ML models often\nlack the rigorous evaluation required for clinical decisions. Machine learning\ntechniques for natural images are ill-equipped to deal with pathology images\nthat are significantly large and noisy, require expensive labeling, are hard to\ninterpret, and are susceptible to spurious correlations. We propose a set of\npractical guidelines for ML evaluation in pathology that address the above\nconcerns. The paper includes measures for setting up the evaluation framework,\neffectively dealing with variability in labels, and a recommended suite of\ntests to address issues related to domain shift, robustness, and confounding\nvariables. We hope that the proposed framework will bridge the gap between ML\nresearchers and domain experts, leading to wider adoption of ML techniques in\npathology and improving patient outcomes.",
    "descriptor": "\nComments: ICLR 2022 ML Evaluation Workshop\n",
    "authors": [
      "Syed Ashar Javed",
      "Dinkar Juyal",
      "Zahil Shanis",
      "Shreya Chakraborty",
      "Harsha Pokkalla",
      "Aaditya Prakash"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.05205"
  },
  {
    "id": "arXiv:2204.05249",
    "title": "Learning Local Equivariant Representations for Large-Scale Atomistic  Dynamics",
    "abstract": "A simultaneously accurate and computationally efficient parametrization of\nthe energy and atomic forces of molecules and materials is a long-standing goal\nin the natural sciences. In pursuit of this goal, neural message passing has\nlead to a paradigm shift by describing many-body correlations of atoms through\niteratively passing messages along an atomistic graph. This propagation of\ninformation, however, makes parallel computation difficult and limits the\nlength scales that can be studied. Strictly local descriptor-based methods, on\nthe other hand, can scale to large systems but do not currently match the high\naccuracy observed with message passing approaches. This work introduces\nAllegro, a strictly local equivariant deep learning interatomic potential that\nsimultaneously exhibits excellent accuracy and scalability of parallel\ncomputation. Allegro learns many-body functions of atomic coordinates using a\nseries of tensor products of learned equivariant representations, but without\nrelying on message passing. Allegro obtains improvements over state-of-the-art\nmethods on the QM9 and revised MD-17 data sets. A single tensor product layer\nis shown to outperform existing deep message passing neural networks and\ntransformers on the QM9 benchmark. Furthermore, Allegro displays remarkable\ngeneralization to out-of-distribution data. Molecular dynamics simulations\nbased on Allegro recover structural and kinetic properties of an amorphous\nphosphate electrolyte in excellent agreement with first principles\ncalculations. Finally, we demonstrate the parallel scaling of Allegro with a\ndynamics simulation of 100 million atoms.",
    "descriptor": "",
    "authors": [
      "Albert Musaelian",
      "Simon Batzner",
      "Anders Johansson",
      "Lixin Sun",
      "Cameron J. Owen",
      "Mordechai Kornbluth",
      "Boris Kozinsky"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)",
      "Chemical Physics (physics.chem-ph)"
    ],
    "url": "https://arxiv.org/abs/2204.05249"
  },
  {
    "id": "arXiv:2204.05263",
    "title": "Maximum entropy optimal density control of discrete-time linear systems  and Schr\u00f6dinger bridges",
    "abstract": "We consider an entropy-regularized version of optimal density control of\ndeterministic discrete-time linear systems. Entropy regularization, or a\nmaximum entropy (MaxEnt) method for optimal control has attracted much\nattention especially in reinforcement learning due to its many advantages such\nas a natural exploration strategy. Despite the merits, high-entropy control\npolicies introduce probabilistic uncertainty into systems, which severely\nlimits the applicability of MaxEnt optimal control to safety-critical systems.\nTo remedy this situation, we impose a Gaussian density constraint at a\nspecified time on the MaxEnt optimal control to directly control state\nuncertainty. Specifically, we derive the explicit form of the MaxEnt optimal\ndensity control. In addition, we also consider the case where a density\nconstraint is replaced by a fixed point constraint. Then, we characterize the\nassociated state process as a pinned process, which is a generalization of the\nBrownian bridge to linear systems. Finally, we reveal that the MaxEnt optimal\ndensity control induces the so-called Schr\\\"odinger bridge associated to a\ndiscrete-time linear system.",
    "descriptor": "",
    "authors": [
      "Kaito Ito",
      "Kenji Kashima"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2204.05263"
  },
  {
    "id": "arXiv:2204.05266",
    "title": "Optimizing a low-dimensional convex function over a high-dimensional  cube",
    "abstract": "For a matrix $W \\in \\mathbb{Z}^{m \\times n}$, $m \\leq n$, and a convex\nfunction $g: \\mathbb{R}^m \\rightarrow \\mathbb{R}$, we are interested in\nminimizing $f(x) = g(Wx)$ over the set $\\{0,1\\}^n$. Since non-linearity only\nstems from $g$, one might expect algorithms whose running time depends only\npolynomially on $n$. Provided that $W$ is known explicitly, various algorithms\ncan be used for this problem. For instance, if $g$ is separable convex, we will\nshow how the framework of Hochbaum and Shanthikumar can be adapted. However,\nknowledge of $W$ is a non-trivial assumption. We develop an algorithm that does\nnot require $W$ as an input, and achieves a running time of roughly $(m\n\\|W\\|_{\\infty})^{\\mathcal{O}(m^3)} \\cdot poly(n)$ for several classes of convex\nfunctions $g$. When $W$ is known explicitly, the running time decreases to $(m\n\\|W\\|_{\\infty})^{\\mathcal{O}(m^2)} \\cdot poly(n)$. In this case, the running\ntime is on par with the running time of Hochbaum and Shanthikumar. However, in\ncontrast to Hochbaum and Shanthikumar, our algorithm also applies to sharp\nconvex functions, which is a generalization of strongly convex functions, a\nclass that reaches far beyond separable convex functions.",
    "descriptor": "",
    "authors": [
      "Christoph Hunkenschr\u00f6der",
      "Sebastian Pokutta",
      "Robert Weismantel"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2204.05266"
  },
  {
    "id": "arXiv:2204.05275",
    "title": "Settling the Sample Complexity of Model-Based Offline Reinforcement  Learning",
    "abstract": "This paper is concerned with offline reinforcement learning (RL), which\nlearns using pre-collected data without further exploration. Effective offline\nRL would be able to accommodate distribution shift and limited data coverage.\nHowever, prior algorithms or analyses either suffer from suboptimal sample\ncomplexities or incur high burn-in cost to reach sample optimality, thus posing\nan impediment to efficient offline RL in sample-starved applications.\nWe demonstrate that the model-based (or \"plug-in\") approach achieves\nminimax-optimal sample complexity without burn-in cost for tabular Markov\ndecision processes (MDPs). Concretely, consider a finite-horizon (resp.\n$\\gamma$-discounted infinite-horizon) MDP with $S$ states and horizon $H$\n(resp. effective horizon $\\frac{1}{1-\\gamma}$), and suppose the distribution\nshift of data is reflected by some single-policy clipped concentrability\ncoefficient $C^{\\star}_{\\text{clipped}}$. We prove that model-based offline RL\nyields $\\varepsilon$-accuracy with a sample complexity of \\[ \\begin{cases}\n\\frac{H^{4}SC_{\\text{clipped}}^{\\star}}{\\varepsilon^{2}} &\n(\\text{finite-horizon MDPs})\n\\frac{SC_{\\text{clipped}}^{\\star}}{(1-\\gamma)^{3}\\varepsilon^{2}} &\n(\\text{infinite-horizon MDPs}) \\end{cases} \\] up to log factor, which is\nminimax optimal for the entire $\\varepsilon$-range. Our algorithms are\n\"pessimistic\" variants of value iteration with Bernstein-style penalties, and\ndo not require sophisticated variance reduction.",
    "descriptor": "",
    "authors": [
      "Gen Li",
      "Laixi Shi",
      "Yuxin Chen",
      "Yuejie Chi",
      "Yuting Wei"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2204.05275"
  },
  {
    "id": "arXiv:2204.05276",
    "title": "Segmentation-Consistent Probabilistic Lesion Counting",
    "abstract": "Lesion counts are important indicators of disease severity, patient\nprognosis, and treatment efficacy, yet counting as a task in medical imaging is\noften overlooked in favor of segmentation. This work introduces a novel\ncontinuously differentiable function that maps lesion segmentation predictions\nto lesion count probability distributions in a consistent manner. The proposed\nend-to-end approach--which consists of voxel clustering, lesion-level voxel\nprobability aggregation, and Poisson-binomial counting--is non-parametric and\nthus offers a robust and consistent way to augment lesion segmentation models\nwith post hoc counting capabilities. Experiments on Gadolinium-enhancing lesion\ncounting demonstrate that our method outputs accurate and well-calibrated count\ndistributions that capture meaningful uncertainty information. They also reveal\nthat our model is suitable for multi-task learning of lesion segmentation, is\nefficient in low data regimes, and is robust to adversarial attacks.",
    "descriptor": "\nComments: Accepted at Medical Imaging with Deep Learning (MIDL) 2022\n",
    "authors": [
      "Julien Schroeter",
      "Chelsea Myers-Colet",
      "Douglas L Arnold",
      "Tal Arbel"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.05276"
  },
  {
    "id": "arXiv:2204.05278",
    "title": "Neglectable effect of brain MRI data prepreprocessing for tumor  segmentation",
    "abstract": "Magnetic resonance imaging (MRI) data is heterogeneous due to the differences\nin device manufacturers, scanning protocols, and inter-subject variability. A\nconventional way to mitigate MR image heterogeneity is to apply preprocessing\ntransformations, such as anatomy alignment, voxel resampling, signal intensity\nequalization, image denoising, and localization of regions of interest (ROI).\nAlthough preprocessing pipeline standardizes image appearance, its influence on\nthe quality of image segmentation and other downstream tasks on deep neural\nnetworks (DNN) has never been rigorously studied.\nHere we report a comprehensive study of multimodal MRI brain cancer image\nsegmentation on TCIA-GBM open-source dataset. Our results demonstrate that most\npopular standardization steps add no value to artificial neural network\nperformance; moreover, preprocessing can hamper model performance. We suggest\nthat image intensity normalization approaches do not contribute to model\naccuracy because of the reduction of signal variance with image\nstandardization. Finally, we show the contribution of scull-stripping in data\npreprocessing is almost negligible if measured in terms of clinically relevant\nmetrics.\nWe show that the only essential transformation for accurate analysis is the\nunification of voxel spacing across the dataset. In contrast, anatomy alignment\nin form of non-rigid atlas registration is not necessary and most intensity\nequalization steps do not improve model productiveness.",
    "descriptor": "",
    "authors": [
      "Ekaterina Kondrateva",
      "Polina Druzhinina",
      "Alexandra Dalechina",
      "Boris Shirokikh",
      "Mikhail Belyaev",
      "Anvar Kurmukov"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.05278"
  },
  {
    "id": "arXiv:2204.05304",
    "title": "Hierarchical Bayesian Persuasion: Importance of Vice Presidents",
    "abstract": "We study strategic information transmission in a hierarchical setting where\ninformation gets transmitted through a chain of agents up to a decision maker\nwhose action is of importance to every agent. This situation could arise\nwhenever an agent can communicate to the decision maker only through a chain of\nintermediaries, for example, an entry-level worker and the CEO in a firm, or an\nofficial in the bottom of the chain of command and the president in a\ngovernment. Each agent can decide to conceal part or all the information she\nreceives. Proving we can focus on simple equilibria, where the only player who\nconceals information is the first one, we provide a tractable recursive\ncharacterization of the equilibrium outcome, and show that it could be\ninefficient. Interestingly, in the binary-action case, regardless of the number\nof intermediaries, there are a few pivotal ones who determine the amount of\ninformation communicated to the decision maker. In this case, our results\nunderscore the importance of choosing a pivotal vice president for maximizing\nthe payoff of the CEO or president.",
    "descriptor": "",
    "authors": [
      "Majid Mahzoon"
    ],
    "subjectives": [
      "Theoretical Economics (econ.TH)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2204.05304"
  },
  {
    "id": "arXiv:1612.03191",
    "title": "Multiparty testing preorders",
    "abstract": "Multiparty testing preorders",
    "descriptor": "",
    "authors": [
      "Rocco de Nicola",
      "Hern\u00e1n Melgratti"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/1612.03191"
  },
  {
    "id": "arXiv:1705.01708",
    "title": "Semi-Supervised AUC Optimization based on Positive-Unlabeled Learning",
    "abstract": "Comments: Fixed typos in Appendix",
    "descriptor": "\nComments: Fixed typos in Appendix\n",
    "authors": [
      "Tomoya Sakai",
      "Gang Niu",
      "Masashi Sugiyama"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/1705.01708"
  },
  {
    "id": "arXiv:1904.10631",
    "title": "Low-Memory Neural Network Training: A Technical Report",
    "abstract": "Comments: Version notes: Copyedits and citation fixes",
    "descriptor": "\nComments: Version notes: Copyedits and citation fixes\n",
    "authors": [
      "Nimit S. Sohoni",
      "Christopher R. Aberger",
      "Megan Leszczynski",
      "Jian Zhang",
      "Christopher R\u00e9"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1904.10631"
  },
  {
    "id": "arXiv:1905.03577",
    "title": "Spatial-Spectral Feature Extraction via Deep ConvLSTM Neural Networks  for Hyperspectral Image Classification",
    "abstract": "Comments: 14 pages, 8 figures",
    "descriptor": "\nComments: 14 pages, 8 figures\n",
    "authors": [
      "Wen-Shuai Hu",
      "Heng-Chao Li",
      "Lei Pan",
      "Wei Li",
      "Ran Tao",
      "Qian Du"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/1905.03577"
  },
  {
    "id": "arXiv:1906.00695",
    "title": "Continual learning with hypernetworks",
    "abstract": "Comments: Published at ICLR 2020",
    "descriptor": "\nComments: Published at ICLR 2020\n",
    "authors": [
      "Johannes von Oswald",
      "Christian Henning",
      "Benjamin F. Grewe",
      "Jo\u00e3o Sacramento"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1906.00695"
  },
  {
    "id": "arXiv:1906.11985",
    "title": "Near-Optimal Methods for Minimizing Star-Convex Functions and Beyond",
    "abstract": "Comments: 48 pages. Published as a conference paper at COLT 2020",
    "descriptor": "\nComments: 48 pages. Published as a conference paper at COLT 2020\n",
    "authors": [
      "Oliver Hinder",
      "Aaron Sidford",
      "Nimit S. Sohoni"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computational Complexity (cs.CC)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1906.11985"
  },
  {
    "id": "arXiv:1907.05168",
    "title": "Graph product structure for non-minor-closed classes",
    "abstract": "Comments: v2 Cosmetic improvements and a corrected bound for (layered-)(tree)width in Theorems 2, 9, 11, and Corollaries 1, 3, 4, 6, 12. v3 Complete restructure. v4 Major revision, improved constants for 1-planar and d-map graphs",
    "descriptor": "\nComments: v2 Cosmetic improvements and a corrected bound for (layered-)(tree)width in Theorems 2, 9, 11, and Corollaries 1, 3, 4, 6, 12. v3 Complete restructure. v4 Major revision, improved constants for 1-planar and d-map graphs\n",
    "authors": [
      "Vida Dujmovi\u0107",
      "Pat Morin",
      "David R. Wood"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/1907.05168"
  },
  {
    "id": "arXiv:1909.09927",
    "title": "Accelerating convolutional neural network by exploiting sparsity on GPUs",
    "abstract": "Accelerating convolutional neural network by exploiting sparsity on GPUs",
    "descriptor": "",
    "authors": [
      "Weizhi Xu",
      "Shengyu Fan",
      "Hui Yu",
      "Xin Fu"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/1909.09927"
  },
  {
    "id": "arXiv:1910.02684",
    "title": "Dynamic Self-training Framework for Graph Convolutional Networks",
    "abstract": "Comments: 11pages",
    "descriptor": "\nComments: 11pages\n",
    "authors": [
      "Ziang Zhou",
      "Shengzhong Zhang",
      "Zengfeng Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1910.02684"
  },
  {
    "id": "arXiv:1911.02104",
    "title": "Perceived Intensities of Normal and Shear Skin Stimuli using a Wearable  Haptic Bracelet",
    "abstract": "Comments: 8 pages, In Press IEEE Robotic Automation Letters, IEEE International Conference on Robotics and Automation",
    "descriptor": "\nComments: 8 pages, In Press IEEE Robotic Automation Letters, IEEE International Conference on Robotics and Automation\n",
    "authors": [
      "Mine Sarac",
      "Tae Myung Huh",
      "Hojung Choi",
      "Mark Cutkosky",
      "Massimiliano Di Luca",
      "Allison M. Okamura"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/1911.02104"
  },
  {
    "id": "arXiv:2001.06570",
    "title": "Harmonic Convolutional Networks based on Discrete Cosine Transform",
    "abstract": "Comments: arXiv admin note: substantial text overlap with arXiv:1812.03205",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:1812.03205\n",
    "authors": [
      "Matej Ulicny",
      "Vladimir A. Krylov",
      "Rozenn Dahyot"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2001.06570"
  },
  {
    "id": "arXiv:2002.05242",
    "title": "Leveraging Affect Transfer Learning for Behavior Prediction in an  Intelligent Tutoring System",
    "abstract": "Comments: Published at IEEE International Conference on Automatic Face and Gesture Recognition (FG), 2021 - Best Poster Award (4% award rate)",
    "descriptor": "\nComments: Published at IEEE International Conference on Automatic Face and Gesture Recognition (FG), 2021 - Best Poster Award (4% award rate)\n",
    "authors": [
      "Nataniel Ruiz",
      "Hao Yu",
      "Danielle A. Allessio",
      "Mona Jalal",
      "Ajjen Joshi",
      "Thomas Murray",
      "John J. Magee",
      "Jacob R. Whitehill",
      "Vitaly Ablavsky",
      "Ivon Arroyo",
      "Beverly P. Woolf",
      "Stan Sclaroff",
      "Margrit Betke"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2002.05242"
  },
  {
    "id": "arXiv:2004.03736",
    "title": "Learning Mixed-Integer Convex Optimization Strategies for Robot Planning  and Control",
    "abstract": "Learning Mixed-Integer Convex Optimization Strategies for Robot Planning  and Control",
    "descriptor": "",
    "authors": [
      "A. Cauligi",
      "P. Culbertson",
      "B. Stellato",
      "D. Bertsimas",
      "M. Schwager",
      "M. Pavone"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2004.03736"
  },
  {
    "id": "arXiv:2004.12164",
    "title": "Randomized spectral co-clustering for large-scale directed networks",
    "abstract": "Randomized spectral co-clustering for large-scale directed networks",
    "descriptor": "",
    "authors": [
      "Xiao Guo",
      "Yixuan Qiu",
      "Hai Zhang",
      "Xiangyu Chang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2004.12164"
  },
  {
    "id": "arXiv:2005.05108",
    "title": "Whole-grain Petri nets and processes",
    "abstract": "Comments: This paper previously had the title 'Elements of Petri nets and processes'. Version 3 (meant to be final) is a substantial revision, following the feedback from three anonymous referees. Expanded treatment of unfolding and denotational semantics; many new examples and figures throughout; new appendix on simplicial groupoids; some proofs sharpened; overall expository improvements. 62 pages",
    "descriptor": "\nComments: This paper previously had the title 'Elements of Petri nets and processes'. Version 3 (meant to be final) is a substantial revision, following the feedback from three anonymous referees. Expanded treatment of unfolding and denotational semantics; many new examples and figures throughout; new appendix on simplicial groupoids; some proofs sharpened; overall expository improvements. 62 pages\n",
    "authors": [
      "Joachim Kock"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Algebraic Topology (math.AT)",
      "Combinatorics (math.CO)",
      "Category Theory (math.CT)"
    ],
    "url": "https://arxiv.org/abs/2005.05108"
  },
  {
    "id": "arXiv:2005.09046",
    "title": "Improving the Effectiveness of Traceability Link Recovery using  Hierarchical Bayesian Networks",
    "abstract": "Comments: Accepted in the Proceedings of the 42nd International Conference on Software Engineering (ICSE'20), 13 pages",
    "descriptor": "\nComments: Accepted in the Proceedings of the 42nd International Conference on Software Engineering (ICSE'20), 13 pages\n",
    "authors": [
      "Kevin Moran",
      "David N. Palacio",
      "Carlos Bernal-C\u00e1rdenas",
      "Daniel McCrystal",
      "Denys Poshyvanyk",
      "Chris Shenefiel",
      "Jeff Johnson"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2005.09046"
  },
  {
    "id": "arXiv:2006.08421",
    "title": "An approximation algorithm for joint caching and recommendations in  cache networks",
    "abstract": "An approximation algorithm for joint caching and recommendations in  cache networks",
    "descriptor": "",
    "authors": [
      "Dimitra Tsigkari",
      "Thrasyvoulos Spyropoulos"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2006.08421"
  },
  {
    "id": "arXiv:2006.13192",
    "title": "Adversarial Robustness of Deep Sensor Fusion Models",
    "abstract": "Adversarial Robustness of Deep Sensor Fusion Models",
    "descriptor": "",
    "authors": [
      "Shaojie Wang",
      "Tong Wu",
      "Ayan Chakrabarti",
      "Yevgeniy Vorobeychik"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2006.13192"
  },
  {
    "id": "arXiv:2006.14062",
    "title": "An $\\ell_p$ theory of PCA and spectral clustering",
    "abstract": "Comments: 72 pages, 2 figures",
    "descriptor": "\nComments: 72 pages, 2 figures\n",
    "authors": [
      "Emmanuel Abbe",
      "Jianqing Fan",
      "Kaizheng Wang"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Machine Learning (cs.LG)",
      "Probability (math.PR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.14062"
  },
  {
    "id": "arXiv:2006.16140",
    "title": "Limits of Individual Consent and Models of Distributed Consent in Online  Social Networks",
    "abstract": "Limits of Individual Consent and Models of Distributed Consent in Online  Social Networks",
    "descriptor": "",
    "authors": [
      "Juniper Lovato",
      "Antoine Allard",
      "Randall Harp",
      "Jeremiah Onaolapo",
      "Laurent H\u00e9bert-Dufresne"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2006.16140"
  },
  {
    "id": "arXiv:2007.12927",
    "title": "Neural networks with late-phase weights",
    "abstract": "Comments: 25 pages, 6 figures",
    "descriptor": "\nComments: 25 pages, 6 figures\n",
    "authors": [
      "Johannes von Oswald",
      "Seijin Kobayashi",
      "Alexander Meulemans",
      "Christian Henning",
      "Benjamin F. Grewe",
      "Jo\u00e3o Sacramento"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2007.12927"
  },
  {
    "id": "arXiv:2007.14729",
    "title": "Formal Power Series on Algebraic Cryptanalysis",
    "abstract": "Formal Power Series on Algebraic Cryptanalysis",
    "descriptor": "",
    "authors": [
      "Shuhei Nakamura"
    ],
    "subjectives": [
      "Symbolic Computation (cs.SC)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2007.14729"
  },
  {
    "id": "arXiv:2008.03225",
    "title": "BayesCG As An Uncertainty Aware Version of CG",
    "abstract": "Comments: 33 Pages including supplementary material (main paper is 23 pages, supplement is 10 pages). Computer codes are available at this https URL",
    "descriptor": "\nComments: 33 Pages including supplementary material (main paper is 23 pages, supplement is 10 pages). Computer codes are available at this https URL\n",
    "authors": [
      "Tim W. Reid",
      "Ilse C. F. Ipsen",
      "Jon Cockayne",
      "Chris J. Oates"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2008.03225"
  },
  {
    "id": "arXiv:2009.01341",
    "title": "Secure Encoded Instruction Graphs for End-to-End Data Validation in  Autonomous Robots",
    "abstract": "Comments: To be published in the IEEE Internet of Things Journal",
    "descriptor": "\nComments: To be published in the IEEE Internet of Things Journal\n",
    "authors": [
      "Jorge Pe\u00f1a Queralta",
      "Li Qingqing",
      "Eduardo Castell\u00f3 Ferrer",
      "Tomi Westerlund"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2009.01341"
  },
  {
    "id": "arXiv:2009.08320",
    "title": "Binarized Johnson-Lindenstrauss embeddings",
    "abstract": "Comments: The results of this preprint have been strongly improved and expanded. The current preprint is no longer intended for publication and has been replaced by two new preprints, posted as arXiv:2201.05204 and arXiv:2204.04109",
    "descriptor": "\nComments: The results of this preprint have been strongly improved and expanded. The current preprint is no longer intended for publication and has been replaced by two new preprints, posted as arXiv:2201.05204 and arXiv:2204.04109\n",
    "authors": [
      "Sjoerd Dirksen",
      "Alexander Stollenwerk"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Data Structures and Algorithms (cs.DS)",
      "Metric Geometry (math.MG)"
    ],
    "url": "https://arxiv.org/abs/2009.08320"
  },
  {
    "id": "arXiv:2009.10054",
    "title": "Regularizing Attention Networks for Anomaly Detection in Visual Question  Answering",
    "abstract": "Comments: 16 pages, 7 figures, Accepted by AAAI-21",
    "descriptor": "\nComments: 16 pages, 7 figures, Accepted by AAAI-21\n",
    "authors": [
      "Doyup Lee",
      "Yeongjae Cheon",
      "Wook-Shin Han"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2009.10054"
  },
  {
    "id": "arXiv:2009.12127",
    "title": "The birth of the strong components",
    "abstract": "Comments: 75 pages, 16 figures, 8 tables. Supplementary computer algebra computations available at this https URL",
    "descriptor": "\nComments: 75 pages, 16 figures, 8 tables. Supplementary computer algebra computations available at this https URL\n",
    "authors": [
      "Sergey Dovgal",
      "\u00c9lie de Panafieu",
      "Dimbinaina Ralaivaosaona",
      "Vonjy Rasendrahasina",
      "Stephan Wagner"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2009.12127"
  },
  {
    "id": "arXiv:2009.14004",
    "title": "On the mixing time of coordinate Hit-and-Run",
    "abstract": "Comments: Close to the final published version",
    "descriptor": "\nComments: Close to the final published version\n",
    "authors": [
      "Hariharan Narayanan",
      "Piyush Srivastava"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Geometry (cs.CG)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2009.14004"
  },
  {
    "id": "arXiv:2009.14307",
    "title": "A Variational Framework for the Thermomechanics of Gradient-Extended  Dissipative Solids -- with Applications to Diffusion, Damage and Plasticity",
    "abstract": "A Variational Framework for the Thermomechanics of Gradient-Extended  Dissipative Solids -- with Applications to Diffusion, Damage and Plasticity",
    "descriptor": "",
    "authors": [
      "Stephan Teichtmeister",
      "Marc-Andre Keip"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2009.14307"
  },
  {
    "id": "arXiv:2010.01333",
    "title": "EGMM: an Evidential Version of the Gaussian Mixture Model for Clustering",
    "abstract": "EGMM: an Evidential Version of the Gaussian Mixture Model for Clustering",
    "descriptor": "",
    "authors": [
      "Lianmeng Jiao",
      "Thierry Denoeux",
      "Zhun-ga Liu",
      "Quan Pan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2010.01333"
  },
  {
    "id": "arXiv:2010.14601",
    "title": "On Linear Representation, Complexity and Inversion of maps over finite  fields",
    "abstract": "Comments: 22 pages",
    "descriptor": "\nComments: 22 pages\n",
    "authors": [
      "Ramachandran Anantharaman",
      "Virendra Sule"
    ],
    "subjectives": [
      "Symbolic Computation (cs.SC)",
      "Discrete Mathematics (cs.DM)",
      "Representation Theory (math.RT)"
    ],
    "url": "https://arxiv.org/abs/2010.14601"
  },
  {
    "id": "arXiv:2010.15835",
    "title": "Targeting for long-term outcomes",
    "abstract": "Comments: main text is 27 pages, with 3 figures and 1 table",
    "descriptor": "\nComments: main text is 27 pages, with 3 figures and 1 table\n",
    "authors": [
      "Jeremy Yang",
      "Dean Eckles",
      "Paramveer Dhillon",
      "Sinan Aral"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2010.15835"
  },
  {
    "id": "arXiv:2011.00830",
    "title": "VIO-UWB-Based Collaborative Localization and Dense Scene Reconstruction  within Heterogeneous Multi-Robot Systems",
    "abstract": "VIO-UWB-Based Collaborative Localization and Dense Scene Reconstruction  within Heterogeneous Multi-Robot Systems",
    "descriptor": "",
    "authors": [
      "Jorge Pe\u00f1a Queralta",
      "Li Qingqing",
      "Fabrizio Schiano",
      "Tomi Westerlund"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2011.00830"
  },
  {
    "id": "arXiv:2011.03526",
    "title": "Identifying Stress Responsive Genes using Overlapping Communities in  Co-expression Networks",
    "abstract": "Identifying Stress Responsive Genes using Overlapping Communities in  Co-expression Networks",
    "descriptor": "",
    "authors": [
      "Camila Riccio",
      "Jorge Finke",
      "Camilo Rocha"
    ],
    "subjectives": [
      "Molecular Networks (q-bio.MN)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2011.03526"
  },
  {
    "id": "arXiv:2011.11150",
    "title": "On the Convergence of Continuous Constrained Optimization for Structure  Learning",
    "abstract": "Comments: AISTATS 2022. A preliminary version of this paper was presented at the NeurIPS 2020 Workshop on Causal Discovery and Causality-Inspired Machine Learning. The code is available at this https URL",
    "descriptor": "\nComments: AISTATS 2022. A preliminary version of this paper was presented at the NeurIPS 2020 Workshop on Causal Discovery and Causality-Inspired Machine Learning. The code is available at this https URL\n",
    "authors": [
      "Ignavier Ng",
      "S\u00e9bastien Lachapelle",
      "Nan Rosemary Ke",
      "Simon Lacoste-Julien",
      "Kun Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2011.11150"
  },
  {
    "id": "arXiv:2011.12945",
    "title": "No Subclass Left Behind: Fine-Grained Robustness in Coarse-Grained  Classification Problems",
    "abstract": "Comments: 40 pages. Published as a conference paper at NeurIPS 2020",
    "descriptor": "\nComments: 40 pages. Published as a conference paper at NeurIPS 2020\n",
    "authors": [
      "Nimit S. Sohoni",
      "Jared A. Dunnmon",
      "Geoffrey Angus",
      "Albert Gu",
      "Christopher R\u00e9"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2011.12945"
  },
  {
    "id": "arXiv:2011.13173",
    "title": "Constrained high-index saddle dynamics for the solution landscape with  equality constraints",
    "abstract": "Constrained high-index saddle dynamics for the solution landscape with  equality constraints",
    "descriptor": "",
    "authors": [
      "Jianyuan Yin",
      "Zhen Huang",
      "Lei Zhang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2011.13173"
  },
  {
    "id": "arXiv:2012.03513",
    "title": "Adaptive Deep Learning for Entity Resolution by Risk Analysis",
    "abstract": "Comments: 31 pages, 5 figures, 4 tables",
    "descriptor": "\nComments: 31 pages, 5 figures, 4 tables\n",
    "authors": [
      "Zhaoqiang Chen",
      "Qun Chen",
      "Youcef Nafa",
      "Tianyi Duan",
      "Wei Pan",
      "Lijun Zhang",
      "Zhanhuai Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2012.03513"
  },
  {
    "id": "arXiv:2012.04025",
    "title": "Specification and Verification of Timing Properties in Interoperable  Medical Systems",
    "abstract": "Specification and Verification of Timing Properties in Interoperable  Medical Systems",
    "descriptor": "",
    "authors": [
      "Mahsa Zarneshan",
      "Fatemeh Ghassemi",
      "Ehsan Khamespanah",
      "Marjan Sirjani",
      "John Hatcliff"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2012.04025"
  },
  {
    "id": "arXiv:2012.04188",
    "title": "Learning to Represent Programs with Heterogeneous Graphs",
    "abstract": "Comments: Accepted by ICPC 2022",
    "descriptor": "\nComments: Accepted by ICPC 2022\n",
    "authors": [
      "Wenhan Wang",
      "Kechi Zhang",
      "Ge Li",
      "Zhi Jin"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2012.04188"
  },
  {
    "id": "arXiv:2101.00159",
    "title": "Fidel: Reconstructing Private Training Samples from Weight Updates in  Federated Learning",
    "abstract": "Fidel: Reconstructing Private Training Samples from Weight Updates in  Federated Learning",
    "descriptor": "",
    "authors": [
      "David Enthoven",
      "Zaid Al-Ars"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2101.00159"
  },
  {
    "id": "arXiv:2101.02129",
    "title": "Hirschman-Widder densities",
    "abstract": "Comments: 32 pages, no figures. Numerous small additions, including Proposition 2.9, as well as Section 3 and other remarks connecting Hirschman-Widder densities to orbital integrals. Final version, to appear in Applied and Computational Harmonic Analysis",
    "descriptor": "\nComments: 32 pages, no figures. Numerous small additions, including Proposition 2.9, as well as Section 3 and other remarks connecting Hirschman-Widder densities to orbital integrals. Final version, to appear in Applied and Computational Harmonic Analysis\n",
    "authors": [
      "Alexander Belton",
      "Dominique Guillot",
      "Apoorva Khare",
      "Mihai Putinar"
    ],
    "subjectives": [
      "Classical Analysis and ODEs (math.CA)",
      "Numerical Analysis (math.NA)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2101.02129"
  },
  {
    "id": "arXiv:2101.07361",
    "title": "Through the Data Management Lens: Experimental Analysis and Evaluation  of Fair Classification",
    "abstract": "Comments: Technical report of SIGMOD 2022 paper",
    "descriptor": "\nComments: Technical report of SIGMOD 2022 paper\n",
    "authors": [
      "Maliha Tashfia Islam",
      "Anna Fariha",
      "Alexandra Meliou",
      "Babak Salimi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2101.07361"
  },
  {
    "id": "arXiv:2101.08395",
    "title": "Privacy-Preserving Distributed Optimal Power Flow with Partially  Homomorphic Encryption",
    "abstract": "Comments: This work has been accepted by the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible",
    "descriptor": "\nComments: This work has been accepted by the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Tong Wu",
      "Changhong Zhao",
      "Ying-Jun Angela Zhang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2101.08395"
  },
  {
    "id": "arXiv:2101.10382",
    "title": "Curriculum Learning: A Survey",
    "abstract": "Comments: Accepted at the International Journal of Computer Vision",
    "descriptor": "\nComments: Accepted at the International Journal of Computer Vision\n",
    "authors": [
      "Petru Soviany",
      "Radu Tudor Ionescu",
      "Paolo Rota",
      "Nicu Sebe"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2101.10382"
  },
  {
    "id": "arXiv:2101.12051",
    "title": "Edge Federated Learning Via Unit-Modulus Over-The-Air Computation",
    "abstract": "Comments: IEEE Transactions on Communications, vol. 70, no. 5, 2022",
    "descriptor": "\nComments: IEEE Transactions on Communications, vol. 70, no. 5, 2022\n",
    "authors": [
      "Shuai Wang",
      "Yuncong Hong",
      "Rui Wang",
      "Qi Hao",
      "Yik-Chung Wu",
      "Derrick Wing Kwan Ng"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2101.12051"
  },
  {
    "id": "arXiv:2102.00872",
    "title": "A Weak Consensus Algorithm and Its Application to High-Performance  Blockchain",
    "abstract": "Comments: IEEE INFOCOM 2021, May 2021, Online, France",
    "descriptor": "\nComments: IEEE INFOCOM 2021, May 2021, Online, France\n",
    "authors": [
      "Qin Wang",
      "Rujia Li"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2102.00872"
  },
  {
    "id": "arXiv:2102.06448",
    "title": "The MSR-Video to Text Dataset with Clean Annotations",
    "abstract": "Comments: The paper is under consideration at Computer Vision and Image Understanding",
    "descriptor": "\nComments: The paper is under consideration at Computer Vision and Image Understanding\n",
    "authors": [
      "Haoran Chen",
      "Jianmin Li",
      "Simone Frintrop",
      "Xiaolin Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.06448"
  },
  {
    "id": "arXiv:2102.09310",
    "title": "VAE Approximation Error: ELBO and Exponential Families",
    "abstract": "Comments: ICLR 2022 spotlight",
    "descriptor": "\nComments: ICLR 2022 spotlight\n",
    "authors": [
      "Alexander Shekhovtsov",
      "Dmitrij Schlesinger",
      "Boris Flach"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2102.09310"
  },
  {
    "id": "arXiv:2102.13182",
    "title": "MIND: Inductive Mutual Information Estimation, A Convex Maximum-Entropy  Copula Approach",
    "abstract": "Comments: Code: this https URL",
    "descriptor": "\nComments: Code: this https URL\n",
    "authors": [
      "Yves-Laurent Kom Samo"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.13182"
  },
  {
    "id": "arXiv:2103.04814",
    "title": "Deeply Unsupervised Patch Re-Identification for Pre-training Object  Detectors",
    "abstract": "Comments: Accepted to IEEE TPAMI",
    "descriptor": "\nComments: Accepted to IEEE TPAMI\n",
    "authors": [
      "Jian Ding",
      "Enze Xie",
      "Hang Xu",
      "Chenhan Jiang",
      "Zhenguo Li",
      "Ping Luo",
      "Gui-Song Xia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.04814"
  },
  {
    "id": "arXiv:2103.05108",
    "title": "Believe The HiPe: Hierarchical Perturbation for Fast, Robust, and  Model-Agnostic Saliency Mapping",
    "abstract": "Comments: github.com/jessicamarycooper/Hierarchical-Perturbation",
    "descriptor": "\nComments: github.com/jessicamarycooper/Hierarchical-Perturbation\n",
    "authors": [
      "Jessica Cooper",
      "Ognjen Arandjelovi\u0107",
      "David J Harrison"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.05108"
  },
  {
    "id": "arXiv:2103.05893",
    "title": "A Jointly Optimal Design of Control and Scheduling in Networked Systems  under Denial-of-Service Attacks",
    "abstract": "Comments: 12 pages, 3 figures",
    "descriptor": "\nComments: 12 pages, 3 figures\n",
    "authors": [
      "Jingyi Lu",
      "Daniel E. Quevedo"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2103.05893"
  },
  {
    "id": "arXiv:2103.09504",
    "title": "PredRNN: A Recurrent Neural Network for Spatiotemporal Predictive  Learning",
    "abstract": "Comments: 17 pages, accepted by TPAMI",
    "descriptor": "\nComments: 17 pages, accepted by TPAMI\n",
    "authors": [
      "Yunbo Wang",
      "Haixu Wu",
      "Jianjin Zhang",
      "Zhifeng Gao",
      "Jianmin Wang",
      "Philip S. Yu",
      "Mingsheng Long"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.09504"
  },
  {
    "id": "arXiv:2103.10374",
    "title": "Consistency-based Active Learning for Object Detection",
    "abstract": "Comments: CVPR-2022 Workshop",
    "descriptor": "\nComments: CVPR-2022 Workshop\n",
    "authors": [
      "Weiping Yu",
      "Sijie Zhu",
      "Taojiannan Yang",
      "Chen Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.10374"
  },
  {
    "id": "arXiv:2103.15629",
    "title": "Stability analysis of time-delay systems in the parametric space",
    "abstract": "Comments: 11 pages, 5 figures, submitted to Automatica",
    "descriptor": "\nComments: 11 pages, 5 figures, submitted to Automatica\n",
    "authors": [
      "Vukan Turkulov",
      "Milan R. Rapaic",
      "Rachid Malti"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2103.15629"
  },
  {
    "id": "arXiv:2104.01392",
    "title": "Revisiting the Place Bisimulation Idea: Towards Formal Verification with  Petri Nets",
    "abstract": "Revisiting the Place Bisimulation Idea: Towards Formal Verification with  Petri Nets",
    "descriptor": "",
    "authors": [
      "Roberto Gorrieri"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2104.01392"
  },
  {
    "id": "arXiv:2104.01652",
    "title": "Nonlinear Repair of Reed-Solomon Codes",
    "abstract": "Comments: Small changes",
    "descriptor": "\nComments: Small changes\n",
    "authors": [
      "Roni Con",
      "Itzhak Tamo"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2104.01652"
  },
  {
    "id": "arXiv:2104.06188",
    "title": "Sectors, Beams and Environmental Impact on the Performance of Commercial  5G mmWave Cells: an Empirical Study",
    "abstract": "Comments: 12 pages, 11 figures, 7 tables",
    "descriptor": "\nComments: 12 pages, 11 figures, 7 tables\n",
    "authors": [
      "Salman Mohebi",
      "Foivos Michelinakis",
      "Ahmed Elmokashfi",
      "Ole Gr\u00f8ndalen",
      "Kashif Mahmood",
      "Andrea Zanella"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2104.06188"
  },
  {
    "id": "arXiv:2104.06685",
    "title": "BROADCAST: Reducing Both Stochastic and Compression Noise to Robustify  Communication-Efficient Federated Learning",
    "abstract": "BROADCAST: Reducing Both Stochastic and Compression Noise to Robustify  Communication-Efficient Federated Learning",
    "descriptor": "",
    "authors": [
      "Heng Zhu",
      "Qing Ling"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2104.06685"
  },
  {
    "id": "arXiv:2104.10635",
    "title": "Online misinformation is linked to early COVID-19 vaccination hesitancy  and refusal",
    "abstract": "Online misinformation is linked to early COVID-19 vaccination hesitancy  and refusal",
    "descriptor": "",
    "authors": [
      "Francesco Pierri",
      "Brea Perry",
      "Matthew R. DeVerna",
      "Kai-Cheng Yang",
      "Alessandro Flammini",
      "Filippo Menczer",
      "John Bryden"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2104.10635"
  },
  {
    "id": "arXiv:2104.14229",
    "title": "Assessing patient similarity through representation learning on medical  records",
    "abstract": "Assessing patient similarity through representation learning on medical  records",
    "descriptor": "",
    "authors": [
      "Hoda Memarzadeh",
      "Nasser Ghadiri",
      "Matthias Samwald",
      "Maryam Lotfi Shahreza"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.14229"
  },
  {
    "id": "arXiv:2104.14789",
    "title": "Analyzing Semantics of Aggregate Answer Set Programming Using  Approximation Fixpoint Theory",
    "abstract": "Comments: 15pages + appendix (7 pages), submitted to ICLP 2022",
    "descriptor": "\nComments: 15pages + appendix (7 pages), submitted to ICLP 2022\n",
    "authors": [
      "Linde Vanbesien",
      "Maurice Bruynooghe",
      "Marc Denecker"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2104.14789"
  },
  {
    "id": "arXiv:2105.02343",
    "title": "CombOptNet: Fit the Right NP-Hard Problem by Learning Integer  Programming Constraints",
    "abstract": "Comments: ICML 2021 conference paper",
    "descriptor": "\nComments: ICML 2021 conference paper\n",
    "authors": [
      "Anselm Paulus",
      "Michal Rol\u00ednek",
      "V\u00edt Musil",
      "Brandon Amos",
      "Georg Martius"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.02343"
  },
  {
    "id": "arXiv:2105.03081",
    "title": "Bounded Synthesis and Reinforcement Learning of Supervisors for  Stochastic Discrete Event Systems with LTL Specifications",
    "abstract": "Comments: 15 pages, 4 figures, 2 tables, submitted to a journal",
    "descriptor": "\nComments: 15 pages, 4 figures, 2 tables, submitted to a journal\n",
    "authors": [
      "Ryohei Oura",
      "Toshimitsu Ushio",
      "Ami Sakakibara"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2105.03081"
  },
  {
    "id": "arXiv:2105.03148",
    "title": "A State-of-the-art Survey of Object Detection Techniques in  Microorganism Image Analysis: From Classical Methods to Deep Learning  Approaches",
    "abstract": "A State-of-the-art Survey of Object Detection Techniques in  Microorganism Image Analysis: From Classical Methods to Deep Learning  Approaches",
    "descriptor": "",
    "authors": [
      "Pingli Ma",
      "Chen Li",
      "Md Mamunur Rahaman",
      "Yudong Yao",
      "Jiawei Zhang",
      "Shuojia Zou",
      "Xin Zhao",
      "Marcin Grzegorzek"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.03148"
  },
  {
    "id": "arXiv:2105.04123",
    "title": "Neural Program Repair with Execution-based Backpropagation",
    "abstract": "Neural Program Repair with Execution-based Backpropagation",
    "descriptor": "",
    "authors": [
      "He Ye",
      "Matias Martinez",
      "Martin Monperrus"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2105.04123"
  },
  {
    "id": "arXiv:2105.05343",
    "title": "Electrotactile feedback applications for hand and arm interactions: A  systematic review, meta-analysis, and future directions",
    "abstract": "Comments: 18 pages, 1 table, 8 figures, under review in Transactions on Haptics. This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible.Upon acceptance of the article by IEEE, the preprint article will be replaced with the accepted version",
    "descriptor": "\nComments: 18 pages, 1 table, 8 figures, under review in Transactions on Haptics. This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible.Upon acceptance of the article by IEEE, the preprint article will be replaced with the accepted version\n",
    "authors": [
      "Panagiotis Kourtesis",
      "Ferran Argelaguet",
      "Sebastian Vizcay",
      "Maud Marchal",
      "Claudio Pacchierotti"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2105.05343"
  },
  {
    "id": "arXiv:2105.06232",
    "title": "Retrieval-Free Knowledge-Grounded Dialogue Response Generation with  Adapters",
    "abstract": "Comments: The first two authors contribute equally; Accepted in ACL 2022 DialDoc Workshop",
    "descriptor": "\nComments: The first two authors contribute equally; Accepted in ACL 2022 DialDoc Workshop\n",
    "authors": [
      "Yan Xu",
      "Etsuko Ishii",
      "Samuel Cahyawijaya",
      "Zihan Liu",
      "Genta Indra Winata",
      "Andrea Madotto",
      "Dan Su",
      "Pascale Fung"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.06232"
  },
  {
    "id": "arXiv:2105.10043",
    "title": "A (Slightly) Improved Bound on the Integrality Gap of the Subtour LP for  TSP",
    "abstract": "A (Slightly) Improved Bound on the Integrality Gap of the Subtour LP for  TSP",
    "descriptor": "",
    "authors": [
      "Anna Karlin",
      "Nathan Klein",
      "Shayan Oveis Gharan"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Combinatorics (math.CO)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2105.10043"
  },
  {
    "id": "arXiv:2105.11727",
    "title": "Impatient Queuing for Intelligent Task Offloading in Multi-Access Edge  Computing",
    "abstract": "Impatient Queuing for Intelligent Task Offloading in Multi-Access Edge  Computing",
    "descriptor": "",
    "authors": [
      "Bin Han",
      "Vincenzo Sciancalepore",
      "Yihua Xu",
      "Di Feng",
      "Hans D. Schotten"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2105.11727"
  },
  {
    "id": "arXiv:2105.13381",
    "title": "Recent advances and clinical applications of deep learning in medical  image analysis",
    "abstract": "Comments: To appear in the journal Medical Image Analysis. The registration section was revised",
    "descriptor": "\nComments: To appear in the journal Medical Image Analysis. The registration section was revised\n",
    "authors": [
      "Xuxin Chen",
      "Ximin Wang",
      "Ke Zhang",
      "Kar-Ming Fung",
      "Theresa C. Thai",
      "Kathleen Moore",
      "Robert S. Mannel",
      "Hong Liu",
      "Bin Zheng",
      "Yuchen Qiu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2105.13381"
  },
  {
    "id": "arXiv:2105.14875",
    "title": "Bangla Natural Language Processing: A Comprehensive Analysis of  Classical, Machine Learning, and Deep Learning Based Methods",
    "abstract": "Comments: Accedpted in IEEE Access and it has 46 pages. Link: this https URL (Early Access - April 10, 2022)",
    "descriptor": "\nComments: Accedpted in IEEE Access and it has 46 pages. Link: this https URL (Early Access - April 10, 2022)\n",
    "authors": [
      "Ovishake Sen",
      "Mohtasim Fuad",
      "MD. Nazrul Islam",
      "Jakaria Rabbi",
      "Mehedi Masud",
      "MD. Kamrul Hasan",
      "Md. Abdul Awal",
      "Awal Ahmed Fime",
      "Md. Tahmid Hasan Fuad",
      "Delowar Sikder",
      "MD. Akil Raihan Iftee"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.14875"
  },
  {
    "id": "arXiv:2106.02104",
    "title": "Semi-Empirical Objective Functions for MCMC Proposal Optimization",
    "abstract": "Comments: 41 pages, 21 tables, 22 figures",
    "descriptor": "\nComments: 41 pages, 21 tables, 22 figures\n",
    "authors": [
      "Chris Cannella",
      "Vahid Tarokh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.02104"
  },
  {
    "id": "arXiv:2106.03330",
    "title": "Contextual Guided Segmentation Framework for Semi-supervised Video  Instance Segmentation",
    "abstract": "Comments: Project page: this https URL",
    "descriptor": "\nComments: Project page: this https URL\n",
    "authors": [
      "Trung-Nghia Le",
      "Tam V. Nguyen",
      "Minh-Triet Tran"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.03330"
  },
  {
    "id": "arXiv:2106.04569",
    "title": "Simulated Adversarial Testing of Face Recognition Models",
    "abstract": "Comments: Published at IEEE Conference on Computer Vision and Pattern Recognition (CVPR) 2022",
    "descriptor": "\nComments: Published at IEEE Conference on Computer Vision and Pattern Recognition (CVPR) 2022\n",
    "authors": [
      "Nataniel Ruiz",
      "Adam Kortylewski",
      "Weichao Qiu",
      "Cihang Xie",
      "Sarah Adel Bargal",
      "Alan Yuille",
      "Stan Sclaroff"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.04569"
  },
  {
    "id": "arXiv:2106.04703",
    "title": "Categorical Data Structures for Technical Computing",
    "abstract": "Comments: 27 pages, 7 figures",
    "descriptor": "\nComments: 27 pages, 7 figures\n",
    "authors": [
      "Evan Patterson",
      "Owen Lynch",
      "James Fairbanks"
    ],
    "subjectives": [
      "Category Theory (math.CT)",
      "Databases (cs.DB)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2106.04703"
  },
  {
    "id": "arXiv:2106.04757",
    "title": "Fair Machine Learning under Limited Demographically Labeled Data",
    "abstract": "Comments: Will appear at ICLR 2022 Socially Responsible Machine Learning (SRML) Workshop",
    "descriptor": "\nComments: Will appear at ICLR 2022 Socially Responsible Machine Learning (SRML) Workshop\n",
    "authors": [
      "Mustafa Safa Ozdayi",
      "Murat Kantarcioglu",
      "Rishabh Iyer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2106.04757"
  },
  {
    "id": "arXiv:2106.07115",
    "title": "Understanding Latent Correlation-Based Multiview Learning and  Self-Supervision: An Identifiability Perspective",
    "abstract": "Comments: Accepted to ICLR 2022 Spotlight, 37 pages, 11 figures",
    "descriptor": "\nComments: Accepted to ICLR 2022 Spotlight, 37 pages, 11 figures\n",
    "authors": [
      "Qi Lyu",
      "Xiao Fu",
      "Weiran Wang",
      "Songtao Lu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.07115"
  },
  {
    "id": "arXiv:2106.07476",
    "title": "Training Graph Neural Networks with 1000 Layers",
    "abstract": "Comments: Accepted at ICML'2021. Code available at this https URL Work done during Guohao Li's internship at Intel Intelligent Systems Lab. Revised reference in v3",
    "descriptor": "\nComments: Accepted at ICML'2021. Code available at this https URL Work done during Guohao Li's internship at Intel Intelligent Systems Lab. Revised reference in v3\n",
    "authors": [
      "Guohao Li",
      "Matthias M\u00fcller",
      "Bernard Ghanem",
      "Vladlen Koltun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2106.07476"
  },
  {
    "id": "arXiv:2106.11117",
    "title": "Uncertainty Quantification by MLMC and Local Time-stepping For Wave  Propagation",
    "abstract": "Uncertainty Quantification by MLMC and Local Time-stepping For Wave  Propagation",
    "descriptor": "",
    "authors": [
      "Marcus J. Grote",
      "Simon Michel",
      "Fabio Nobile"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.11117"
  },
  {
    "id": "arXiv:2106.13927",
    "title": "Investigation of Bare-bones Algorithms from Quantum Perspective: A  Quantum Dynamical Global Optimizer",
    "abstract": "Comments: The paper may provide a new quantum perspective for studying a bare-bones intelligence algorithms",
    "descriptor": "\nComments: The paper may provide a new quantum perspective for studying a bare-bones intelligence algorithms\n",
    "authors": [
      "Peng Wang",
      "Gang Xin",
      "Fang Wang"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2106.13927"
  },
  {
    "id": "arXiv:2106.14193",
    "title": "SAR-Net: Shape Alignment and Recovery Network for Category-level 6D  Object Pose and Size Estimation",
    "abstract": "Comments: accepted by CVPR2022",
    "descriptor": "\nComments: accepted by CVPR2022\n",
    "authors": [
      "Haitao Lin",
      "Zichang Liu",
      "Chilam Cheang",
      "Yanwei Fu",
      "Guodong Guo",
      "Xiangyang Xue"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2106.14193"
  },
  {
    "id": "arXiv:2106.14836",
    "title": "Understanding Dynamics of Nonlinear Representation Learning and Its  Application",
    "abstract": "Understanding Dynamics of Nonlinear Representation Learning and Its  Application",
    "descriptor": "",
    "authors": [
      "Kenji Kawaguchi",
      "Linjun Zhang",
      "Zhun Deng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.14836"
  },
  {
    "id": "arXiv:2106.15002",
    "title": "Characterization of the Variation Spaces Corresponding to Shallow Neural  Networks",
    "abstract": "Characterization of the Variation Spaces Corresponding to Shallow Neural  Networks",
    "descriptor": "",
    "authors": [
      "Jonathan W. Siegel",
      "Jinchao Xu"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.15002"
  },
  {
    "id": "arXiv:2106.16213",
    "title": "Saturated Transformers are Constant-Depth Threshold Circuits",
    "abstract": "Comments: To appear in TACL",
    "descriptor": "\nComments: To appear in TACL\n",
    "authors": [
      "William Merrill",
      "Ashish Sabharwal",
      "Noah A. Smith"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computational Complexity (cs.CC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.16213"
  },
  {
    "id": "arXiv:2107.00111",
    "title": "A Logic for Reasoning About LF Specifications",
    "abstract": "Comments: arXiv admin note: substantial text overlap with arXiv:2105.04110",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2105.04110\n",
    "authors": [
      "Gopalan Nadathur",
      "Mary Southern"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2107.00111"
  },
  {
    "id": "arXiv:2107.00643",
    "title": "Mandoline: Model Evaluation under Distribution Shift",
    "abstract": "Comments: 33 pages. Published as a conference paper at ICML 2021",
    "descriptor": "\nComments: 33 pages. Published as a conference paper at ICML 2021\n",
    "authors": [
      "Mayee Chen",
      "Karan Goel",
      "Nimit S. Sohoni",
      "Fait Poms",
      "Kayvon Fatahalian",
      "Christopher R\u00e9"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.00643"
  },
  {
    "id": "arXiv:2107.01610",
    "title": "Two Public-Key Cryptosystems Based on Expanded Gabidulin Codes",
    "abstract": "Two Public-Key Cryptosystems Based on Expanded Gabidulin Codes",
    "descriptor": "",
    "authors": [
      "Wenshuo Guo",
      "Fang-Wei Fu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2107.01610"
  },
  {
    "id": "arXiv:2107.02375",
    "title": "SplitAVG: A heterogeneity-aware federated deep learning method for  medical imaging",
    "abstract": "SplitAVG: A heterogeneity-aware federated deep learning method for  medical imaging",
    "descriptor": "",
    "authors": [
      "Miao Zhang",
      "Liangqiong Qu",
      "Praveer Singh",
      "Jayashree Kalpathy-Cramer",
      "Daniel L. Rubin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2107.02375"
  },
  {
    "id": "arXiv:2107.02438",
    "title": "Shell Language Processing: Unix command parsing for Machine Learning",
    "abstract": "Comments: 4 pages, 1 table",
    "descriptor": "\nComments: 4 pages, 1 table\n",
    "authors": [
      "Dmitrijs Trizna"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2107.02438"
  },
  {
    "id": "arXiv:2107.03032",
    "title": "Prospective Beamforming Technologies for Ultra-Massive MIMO in Terahertz  Communications: A Tutorial",
    "abstract": "Prospective Beamforming Technologies for Ultra-Massive MIMO in Terahertz  Communications: A Tutorial",
    "descriptor": "",
    "authors": [
      "Boyu Ning",
      "Zhongbao Tian",
      "Zhi Chen",
      "Chong Han",
      "Shaoqian Li",
      "Jinhong Yuan",
      "Rui Zhang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2107.03032"
  },
  {
    "id": "arXiv:2107.03730",
    "title": "Encoding Domain Information with Sparse Priors for Inferring Explainable  Latent Variables",
    "abstract": "Comments: 7 pages, 9 figures, Joint KDD 2021 Health Day and 2021 KDD Workshop on Applied Data Science for Healthcare",
    "descriptor": "\nComments: 7 pages, 9 figures, Joint KDD 2021 Health Day and 2021 KDD Workshop on Applied Data Science for Healthcare\n",
    "authors": [
      "Arber Qoku",
      "Florian Buettner"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.03730"
  },
  {
    "id": "arXiv:2107.04101",
    "title": "Inertia Pricing in Stochastic Electricity Markets",
    "abstract": "Inertia Pricing in Stochastic Electricity Markets",
    "descriptor": "",
    "authors": [
      "Zhirui Liang",
      "Robert Mieth",
      "Yury Dvorkin"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2107.04101"
  },
  {
    "id": "arXiv:2107.07173",
    "title": "Scene-adaptive Knowledge Distillation for Sequential Recommendation via  Differentiable Architecture Search",
    "abstract": "Scene-adaptive Knowledge Distillation for Sequential Recommendation via  Differentiable Architecture Search",
    "descriptor": "",
    "authors": [
      "Lei Chen",
      "Fajie Yuan",
      "Jiaxi Yang",
      "Min Yang",
      "Chengming Li"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.07173"
  },
  {
    "id": "arXiv:2107.08031",
    "title": "Is attention to bounding boxes all you need for pedestrian action  prediction?",
    "abstract": "Is attention to bounding boxes all you need for pedestrian action  prediction?",
    "descriptor": "",
    "authors": [
      "Lina Achaji",
      "Julien Moreau",
      "Thibault Fouqueray",
      "Francois Aioun",
      "Francois Charpillet"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2107.08031"
  },
  {
    "id": "arXiv:2107.13757",
    "title": "Bridging Gap between Image Pixels and Semantics via Supervision: A  Survey",
    "abstract": "Comments: Jiali Duan and C.-C. Jay Kuo (2022), \"Bridging Gap between Image Pixels and Semantics via Supervision: A Survey\", APSIPA Transactions on Signal and Information Processing: Vol. 11: No. 1, e2. this http URL",
    "descriptor": "\nComments: Jiali Duan and C.-C. Jay Kuo (2022), \"Bridging Gap between Image Pixels and Semantics via Supervision: A Survey\", APSIPA Transactions on Signal and Information Processing: Vol. 11: No. 1, e2. this http URL\n",
    "authors": [
      "Jiali Duan",
      "C.-C. Jay Kuo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.13757"
  },
  {
    "id": "arXiv:2107.13869",
    "title": "Autonomous UAV Base Stations for Next Generation Wireless Networks: A  Deep Learning Approach",
    "abstract": "Comments: 7 pages, 6 figures",
    "descriptor": "\nComments: 7 pages, 6 figures\n",
    "authors": [
      "Ali Murat Demirtas",
      "Mehmet Saygin Seyfioglu",
      "Irem Bor-Yaliniz",
      "Bulent Tavli",
      "Halim Yanikomeroglu"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2107.13869"
  },
  {
    "id": "arXiv:2108.00083",
    "title": "Majorization Minimization Methods for Distributed Pose Graph  Optimization",
    "abstract": "Comments: 33 pages",
    "descriptor": "\nComments: 33 pages\n",
    "authors": [
      "Taosha Fan",
      "Todd Murphey"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2108.00083"
  },
  {
    "id": "arXiv:2108.00356",
    "title": "Improving Social Meaning Detection with Pragmatic Masking and Surrogate  Fine-Tuning",
    "abstract": "Comments: WASSA at ACL 2022 camera-ready",
    "descriptor": "\nComments: WASSA at ACL 2022 camera-ready\n",
    "authors": [
      "Chiyu Zhang",
      "Muhammad Abdul-Mageed"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2108.00356"
  },
  {
    "id": "arXiv:2108.01513",
    "title": "SphereFace2: Binary Classification is All You Need for Deep Face  Recognition",
    "abstract": "Comments: ICLR 2022 Spotlight (v3: Updated Appendix)",
    "descriptor": "\nComments: ICLR 2022 Spotlight (v3: Updated Appendix)\n",
    "authors": [
      "Yandong Wen",
      "Weiyang Liu",
      "Adrian Weller",
      "Bhiksha Raj",
      "Rita Singh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.01513"
  },
  {
    "id": "arXiv:2108.02274",
    "title": "LEO: Learning Energy-based Models in Factor Graph Optimization",
    "abstract": "Comments: Accepted to Conference on Robot Learning (CoRL) 2021. 19 pages, 13 figures",
    "descriptor": "\nComments: Accepted to Conference on Robot Learning (CoRL) 2021. 19 pages, 13 figures\n",
    "authors": [
      "Paloma Sodhi",
      "Eric Dexheimer",
      "Mustafa Mukadam",
      "Stuart Anderson",
      "Michael Kaess"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2108.02274"
  },
  {
    "id": "arXiv:2108.03443",
    "title": "NODEO: A Neural Ordinary Differential Equation Based Optimization  Framework for Deformable Image Registration",
    "abstract": "NODEO: A Neural Ordinary Differential Equation Based Optimization  Framework for Deformable Image Registration",
    "descriptor": "",
    "authors": [
      "Yifan Wu",
      "Tom Z. Jiahao",
      "Jiancong Wang",
      "Paul A. Yushkevich",
      "M. Ani Hsieh",
      "James C. Gee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.03443"
  },
  {
    "id": "arXiv:2108.04501",
    "title": "Competition and Recall in Selection Problems",
    "abstract": "Competition and Recall in Selection Problems",
    "descriptor": "",
    "authors": [
      "Fabien Gensbittel",
      "Dana Pizarro",
      "J\u00e9r\u00f4me Renault"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2108.04501"
  },
  {
    "id": "arXiv:2108.06600",
    "title": "A Self-Distillation Embedded Supervised Affinity Attention Model for  Few-Shot Segmentation",
    "abstract": "Comments: 13 pages, 13 figures",
    "descriptor": "\nComments: 13 pages, 13 figures\n",
    "authors": [
      "Qi Zhao",
      "Binghao Liu",
      "Shuchang Lyu",
      "Xu Wang",
      "Lijiang Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.06600"
  },
  {
    "id": "arXiv:2108.07154",
    "title": "MMChat: Multi-Modal Chat Dataset on Social Media",
    "abstract": "Comments: Accepted by LREC2022. Dataset available in this https URL",
    "descriptor": "\nComments: Accepted by LREC2022. Dataset available in this https URL\n",
    "authors": [
      "Yinhe Zheng",
      "Guanyi Chen",
      "Xin Liu",
      "Jian Sun"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.07154"
  },
  {
    "id": "arXiv:2108.08018",
    "title": "Timed Automata Robustness Analysis via Model Checking",
    "abstract": "Timed Automata Robustness Analysis via Model Checking",
    "descriptor": "",
    "authors": [
      "Jaroslav Bend\u00edk",
      "Ahmet Sencan",
      "Ebru Aydin Gol",
      "Ivana \u010cern\u00e1"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2108.08018"
  },
  {
    "id": "arXiv:2108.09135",
    "title": "PatchCleanser: Certifiably Robust Defense against Adversarial Patches  for Any Image Classifier",
    "abstract": "Comments: USENIX Security Symposium 2022; extended technical report",
    "descriptor": "\nComments: USENIX Security Symposium 2022; extended technical report\n",
    "authors": [
      "Chong Xiang",
      "Saeed Mahloujifar",
      "Prateek Mittal"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2108.09135"
  },
  {
    "id": "arXiv:2108.11626",
    "title": "CoMPM: Context Modeling with Speaker's Pre-trained Memory Tracking for  Emotion Recognition in Conversation",
    "abstract": "Comments: To appear in NAACL 2022",
    "descriptor": "\nComments: To appear in NAACL 2022\n",
    "authors": [
      "Joosung Lee",
      "Wooin Lee"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2108.11626"
  },
  {
    "id": "arXiv:2108.12176",
    "title": "Rethinking the Misalignment Problem in Dense Object Detection",
    "abstract": "Rethinking the Misalignment Problem in Dense Object Detection",
    "descriptor": "",
    "authors": [
      "Yang Yang",
      "Min Li",
      "Bo Meng",
      "Junxing Ren",
      "Degang Sun",
      "Zihao Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.12176"
  },
  {
    "id": "arXiv:2108.13855",
    "title": "Successful Recovery Performance Guarantees of SOMP Under the  $\\ell_2$-norm of Noise",
    "abstract": "Successful Recovery Performance Guarantees of SOMP Under the  $\\ell_2$-norm of Noise",
    "descriptor": "",
    "authors": [
      "Wei Zhang",
      "Taejoon Kim"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2108.13855"
  },
  {
    "id": "arXiv:2109.00354",
    "title": "Outage Analysis and Beamwidth Optimization for Positioning-Assisted  Beamforming",
    "abstract": "Outage Analysis and Beamwidth Optimization for Positioning-Assisted  Beamforming",
    "descriptor": "",
    "authors": [
      "Bingcheng Zhu",
      "Zaichen Zhang",
      "Julian Cheng"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2109.00354"
  },
  {
    "id": "arXiv:2109.06085",
    "title": "On Pursuit of Designing Multi-modal Transformer for Video Grounding",
    "abstract": "Comments: Accepted by Conference on Empirical Methods in Natural Language Processing (EMNLP 2021, Oral)",
    "descriptor": "\nComments: Accepted by Conference on Empirical Methods in Natural Language Processing (EMNLP 2021, Oral)\n",
    "authors": [
      "Meng Cao",
      "Long Chen",
      "Mike Zheng Shou",
      "Can Zhang",
      "Yuexian Zou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.06085"
  },
  {
    "id": "arXiv:2109.07035",
    "title": "Data Hunches: Incorporating Personal Knowledge into Visualizations",
    "abstract": "Data Hunches: Incorporating Personal Knowledge into Visualizations",
    "descriptor": "",
    "authors": [
      "Haihan Lin",
      "Derya Akbaba",
      "Miriah Meyer",
      "Alexander Lex"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2109.07035"
  },
  {
    "id": "arXiv:2109.08564",
    "title": "Slot Filling for Biomedical Information Extraction",
    "abstract": "Slot Filling for Biomedical Information Extraction",
    "descriptor": "",
    "authors": [
      "Yannis Papanikolaou",
      "Marlene Staib",
      "Justin Grace",
      "Francine Bennett"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.08564"
  },
  {
    "id": "arXiv:2109.11450",
    "title": "An Improved Authentication & Key Exchange Protocol Based on ECDH for  WSNs",
    "abstract": "Comments: 7 Pages, 5 figures",
    "descriptor": "\nComments: 7 Pages, 5 figures\n",
    "authors": [
      "Sina Baghbanijam",
      "Hanie Sanaei",
      "Mahdi Farajzadeh"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2109.11450"
  },
  {
    "id": "arXiv:2109.12085",
    "title": "Text-based NP Enrichment",
    "abstract": "Comments: Accepted to the TACL journal, pre-MIT Press publication version",
    "descriptor": "\nComments: Accepted to the TACL journal, pre-MIT Press publication version\n",
    "authors": [
      "Yanai Elazar",
      "Victoria Basmov",
      "Yoav Goldberg",
      "Reut Tsarfaty"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.12085"
  },
  {
    "id": "arXiv:2109.12340",
    "title": "Distributed Online Optimization with Byzantine Adversarial Agents",
    "abstract": "Comments: 9 pages, 1 figure. To appear at ACC 2022",
    "descriptor": "\nComments: 9 pages, 1 figure. To appear at ACC 2022\n",
    "authors": [
      "Sourav Sahoo",
      "Anand Gokhale",
      "Rachel Kalpana Kalaimani"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2109.12340"
  },
  {
    "id": "arXiv:2109.12878",
    "title": "High-Rate Uninterrupted Internet-of-Vehicle Communications in Highways:  Dynamic Blockage Avoidance and CSIT Acquisition",
    "abstract": "Comments: Submitted to IEEE Communications Magazine",
    "descriptor": "\nComments: Submitted to IEEE Communications Magazine\n",
    "authors": [
      "Hao Guo",
      "Behrooz Makki",
      "Mohamed-Slim Alouini",
      "Tommy Svensson"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2109.12878"
  },
  {
    "id": "arXiv:2110.01351",
    "title": "Towards Time-Optimal Tunnel-Following for Quadrotors",
    "abstract": "Comments: This paper has been accepted for publication at the IEEE International Conference on Robotics and Automation (ICRA), Philadelphia, USA, May 2022. Copyright @ IEEE",
    "descriptor": "\nComments: This paper has been accepted for publication at the IEEE International Conference on Robotics and Automation (ICRA), Philadelphia, USA, May 2022. Copyright @ IEEE\n",
    "authors": [
      "Jon Arrizabalaga",
      "Markus Ryll"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.01351"
  },
  {
    "id": "arXiv:2110.01861",
    "title": "Social Co-OS: Cyber-Human Social Co-Operating System",
    "abstract": "Comments: 19 pages, 12 figures. Revised version based on the proceeding of the Forum on Information Technology 2021, Aug. 25-27, Japan",
    "descriptor": "\nComments: 19 pages, 12 figures. Revised version based on the proceeding of the Forum on Information Technology 2021, Aug. 25-27, Japan\n",
    "authors": [
      "Takeshi Kato",
      "Yasuyuki Kudo",
      "Junichi Miyakoshi",
      "Misa Owa",
      "Yasuhiro Asa",
      "Takashi Numata",
      "Ryuji Mine",
      "Hiroyuki Mizuno"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2110.01861"
  },
  {
    "id": "arXiv:2110.02152",
    "title": "Operation-Adversarial Scenario Generation",
    "abstract": "Operation-Adversarial Scenario Generation",
    "descriptor": "",
    "authors": [
      "Zhirui Liang",
      "Robert Mieth",
      "Yury Dvorkin"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.02152"
  },
  {
    "id": "arXiv:2110.03659",
    "title": "Transform2Act: Learning a Transform-and-Control Policy for Efficient  Agent Design",
    "abstract": "Comments: ICLR 2022 (Oral). Project page: this https URL Code: this https URL",
    "descriptor": "\nComments: ICLR 2022 (Oral). Project page: this https URL Code: this https URL\n",
    "authors": [
      "Ye Yuan",
      "Yuda Song",
      "Zhengyi Luo",
      "Wen Sun",
      "Kris Kitani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.03659"
  },
  {
    "id": "arXiv:2110.04534",
    "title": "Learning to Pick at Non-Zero-Velocity from Interactive Demonstrations",
    "abstract": "Comments: Accepted at Robotics and Automation Letter (RA-L) Special Issue on Learning and Control for Robot Compliant Manipulation with Human in the Loop in March 2022",
    "descriptor": "\nComments: Accepted at Robotics and Automation Letter (RA-L) Special Issue on Learning and Control for Robot Compliant Manipulation with Human in the Loop in March 2022\n",
    "authors": [
      "Anna M\u00e9sz\u00e1ros",
      "Giovanni Franzese",
      "Jens Kober"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.04534"
  },
  {
    "id": "arXiv:2110.05192",
    "title": "Convex-Concave Min-Max Stackelberg Games",
    "abstract": "Comments: 25 pages, 4 tables, 1 figure, Forthcoming in NeurIPS 2021",
    "descriptor": "\nComments: 25 pages, 4 tables, 1 figure, Forthcoming in NeurIPS 2021\n",
    "authors": [
      "Denizalp Goktas",
      "Amy Greenwald"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.05192"
  },
  {
    "id": "arXiv:2110.05310",
    "title": "An Enriched Galerkin Method for the Stokes Equations",
    "abstract": "An Enriched Galerkin Method for the Stokes Equations",
    "descriptor": "",
    "authors": [
      "Son-Young Yi",
      "Xiaozhe Hu",
      "Sanghyun Lee",
      "James H. Adler"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.05310"
  },
  {
    "id": "arXiv:2110.06862",
    "title": "Model hierarchies and higher-order discretisation of time-dependent  thin-film free boundary problems with dynamic contact angle",
    "abstract": "Comments: 28 pages, 13 Figures",
    "descriptor": "\nComments: 28 pages, 13 Figures\n",
    "authors": [
      "Dirk Peschka",
      "Luca Heltai"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.06862"
  },
  {
    "id": "arXiv:2110.07038",
    "title": "Towards Efficient NLP: A Standard Evaluation and A Strong Baseline",
    "abstract": "Comments: Accepted to the main conference of NAACL-2022",
    "descriptor": "\nComments: Accepted to the main conference of NAACL-2022\n",
    "authors": [
      "Xiangyang Liu",
      "Tianxiang Sun",
      "Junliang He",
      "Jiawen Wu",
      "Lingling Wu",
      "Xinyu Zhang",
      "Hao Jiang",
      "Zhao Cao",
      "Xuanjing Huang",
      "Xipeng Qiu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.07038"
  },
  {
    "id": "arXiv:2110.07474",
    "title": "MReD: A Meta-Review Dataset for Structure-Controllable Text Generation",
    "abstract": "Comments: 15 pages, 5 figures, accepted at ACL 2022",
    "descriptor": "\nComments: 15 pages, 5 figures, accepted at ACL 2022\n",
    "authors": [
      "Chenhui Shen",
      "Liying Cheng",
      "Ran Zhou",
      "Lidong Bing",
      "Yang You",
      "Luo Si"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.07474"
  },
  {
    "id": "arXiv:2110.07701",
    "title": "Exposing Query Identification for Search Transparency",
    "abstract": "Exposing Query Identification for Search Transparency",
    "descriptor": "",
    "authors": [
      "Ruohan Li",
      "Jianxiang Li",
      "Bhaskar Mitra",
      "Fernando Diaz",
      "Asia J. Biega"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.07701"
  },
  {
    "id": "arXiv:2110.07749",
    "title": "Attention-Free Keyword Spotting",
    "abstract": "Comments: 5 pages: Accepted at PML4DC workshop in ICLR 2022",
    "descriptor": "\nComments: 5 pages: Accepted at PML4DC workshop in ICLR 2022\n",
    "authors": [
      "Mashrur M. Morshed",
      "Ahmad Omar Ahsan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.07749"
  },
  {
    "id": "arXiv:2110.08467",
    "title": "Improving Compositional Generalization with Self-Training for  Data-to-Text Generation",
    "abstract": "Comments: Accepted at ACL 2022 main conference",
    "descriptor": "\nComments: Accepted at ACL 2022 main conference\n",
    "authors": [
      "Sanket Vaibhav Mehta",
      "Jinfeng Rao",
      "Yi Tay",
      "Mihir Kale",
      "Ankur P. Parikh",
      "Emma Strubell"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.08467"
  },
  {
    "id": "arXiv:2110.12347",
    "title": "Acceleration in Distributed Optimization under Similarity",
    "abstract": "Acceleration in Distributed Optimization under Similarity",
    "descriptor": "",
    "authors": [
      "Ye Tian",
      "Gesualdo Scutari",
      "Tianyu Cao",
      "Alexander Gasnikov"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.12347"
  },
  {
    "id": "arXiv:2111.01135",
    "title": "Arch-Net: Model Distillation for Architecture Agnostic Model Deployment",
    "abstract": "Comments: 15 pages, 6 figures",
    "descriptor": "\nComments: 15 pages, 6 figures\n",
    "authors": [
      "Weixin Xu",
      "Zipeng Feng",
      "Shuangkang Fang",
      "Song Yuan",
      "Yi Yang",
      "Shuchang Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.01135"
  },
  {
    "id": "arXiv:2111.01928",
    "title": "Verifying Switched System Stability With Logic",
    "abstract": "Comments: Long version of paper at HSCC 2022 (25th ACM International Conference on Hybrid Systems: Computation and Control, May 4-6, 2022)",
    "descriptor": "\nComments: Long version of paper at HSCC 2022 (25th ACM International Conference on Hybrid Systems: Computation and Control, May 4-6, 2022)\n",
    "authors": [
      "Yong Kiam Tan",
      "Stefan Mitsch",
      "Andr\u00e9 Platzer"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2111.01928"
  },
  {
    "id": "arXiv:2111.02331",
    "title": "LTD: Low Temperature Distillation for Robust Adversarial Training",
    "abstract": "LTD: Low Temperature Distillation for Robust Adversarial Training",
    "descriptor": "",
    "authors": [
      "Erh-Chung Chen",
      "Che-Rung Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.02331"
  },
  {
    "id": "arXiv:2111.02374",
    "title": "Can I use this publicly available dataset to build commercial AI  software? -- A Case Study on Publicly Available Image Datasets",
    "abstract": "Comments: This is revised version of the paper with updated co-authors",
    "descriptor": "\nComments: This is revised version of the paper with updated co-authors\n",
    "authors": [
      "Gopi Krishnan Rajbahadur",
      "Erika Tuck",
      "Li Zi",
      "Dayi Lin",
      "Boyuan Chen",
      "Zhen Ming",
      "Jiang",
      "Daniel M. German"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2111.02374"
  },
  {
    "id": "arXiv:2111.02708",
    "title": "Quasi-Newton Methods for Saddle Point Problems and Beyond",
    "abstract": "Comments: We use $\\lambda_k=\\|\\nabla f({\\bf z}_k)\\|$ as the measure for the convergence analysis in this version and fix some mistakes in the original analysis. The modification does not change the convergence rates shown in the last version.$ $",
    "descriptor": "\nComments: We use $\\lambda_k=\\|\\nabla f({\\bf z}_k)\\|$ as the measure for the convergence analysis in this version and fix some mistakes in the original analysis. The modification does not change the convergence rates shown in the last version.$ $\n",
    "authors": [
      "Chengchang Liu",
      "Luo Luo"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.02708"
  },
  {
    "id": "arXiv:2111.03015",
    "title": "Modeling Techniques for Machine Learning Fairness: A Survey",
    "abstract": "Comments: 26 pages, 4 figures",
    "descriptor": "\nComments: 26 pages, 4 figures\n",
    "authors": [
      "Mingyang Wan",
      "Daochen Zha",
      "Ninghao Liu",
      "Na Zou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.03015"
  },
  {
    "id": "arXiv:2111.03126",
    "title": "Generative Adversarial Network for Probabilistic Forecast of Random  Dynamical System",
    "abstract": "Generative Adversarial Network for Probabilistic Forecast of Random  Dynamical System",
    "descriptor": "",
    "authors": [
      "Kyongmin Yeo",
      "Zan Li",
      "Wesley M. Gifford"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Dynamical Systems (math.DS)",
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.03126"
  },
  {
    "id": "arXiv:2111.03735",
    "title": "A PTAS for Capacitated Vehicle Routing on Trees",
    "abstract": "Comments: Accepted for publication at ICALP 2022",
    "descriptor": "\nComments: Accepted for publication at ICALP 2022\n",
    "authors": [
      "Claire Mathieu",
      "Hang Zhou"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2111.03735"
  },
  {
    "id": "arXiv:2111.03962",
    "title": "Computing Simple Mechanisms: Lift-and-Round over Marginal Reduced Forms",
    "abstract": "Computing Simple Mechanisms: Lift-and-Round over Marginal Reduced Forms",
    "descriptor": "",
    "authors": [
      "Yang Cai",
      "Argyris Oikonomou",
      "Mingfei Zhao"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2111.03962"
  },
  {
    "id": "arXiv:2111.04179",
    "title": "The eXtreme Mesh deformation approach (X-MESH) for the Stefan  phase-change model",
    "abstract": "Comments: 18 pages",
    "descriptor": "\nComments: 18 pages\n",
    "authors": [
      "Nicolas Moes",
      "Jean-Francois Remacle",
      "Jonathan Lambrechts",
      "Benoit Le",
      "Nicolas Chevaugeon"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2111.04179"
  },
  {
    "id": "arXiv:2111.04682",
    "title": "SMU: smooth activation function for deep networks using smoothing  maximum technique",
    "abstract": "Comments: 7 pages",
    "descriptor": "\nComments: 7 pages\n",
    "authors": [
      "Koushik Biswas",
      "Sandeep Kumar",
      "Shilpak Banerjee",
      "Ashish Kumar Pandey"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2111.04682"
  },
  {
    "id": "arXiv:2111.04909",
    "title": "FPM: A Collection of Large-scale Foundation Pre-trained Language Models",
    "abstract": "Comments: 12 pages, 4 tables",
    "descriptor": "\nComments: 12 pages, 4 tables\n",
    "authors": [
      "Dezhou Shen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.04909"
  },
  {
    "id": "arXiv:2111.05063",
    "title": "Tightening the Approximation Error of Adversarial Risk with Auto Loss  Function Search",
    "abstract": "Tightening the Approximation Error of Adversarial Risk with Auto Loss  Function Search",
    "descriptor": "",
    "authors": [
      "Pengfei Xia",
      "Ziqiang Li",
      "Bin Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.05063"
  },
  {
    "id": "arXiv:2111.05623",
    "title": "FabricFlowNet: Bimanual Cloth Manipulation with a Flow-based Policy",
    "abstract": "Comments: CoRL 2021",
    "descriptor": "\nComments: CoRL 2021\n",
    "authors": [
      "Thomas Weng",
      "Sujay Bajracharya",
      "Yufei Wang",
      "Khush Agrawal",
      "David Held"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.05623"
  },
  {
    "id": "arXiv:2111.06179",
    "title": "An Enactivist account of Mind Reading in Natural Language Understanding",
    "abstract": "Comments: 18 pages, 46 references, 1 figure (transcript). As submitted to MTI special issue on speech-based interaction",
    "descriptor": "\nComments: 18 pages, 46 references, 1 figure (transcript). As submitted to MTI special issue on speech-based interaction\n",
    "authors": [
      "Peter Wallis"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2111.06179"
  },
  {
    "id": "arXiv:2111.07250",
    "title": "Metrics and Mechanisms: Measuring the Unmeasurable in the Science of  Science",
    "abstract": "Comments: 20 pages, 1 figure",
    "descriptor": "\nComments: 20 pages, 1 figure\n",
    "authors": [
      "Lingfei Wu",
      "Aniket Kittur",
      "Hyejin Youn",
      "Sta\u0161a Milojevi\u0107",
      "Erin Leahey",
      "Stephen M. Fiore",
      "Yong Yeol Ahn"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2111.07250"
  },
  {
    "id": "arXiv:2111.07524",
    "title": "PatchGraph: In-hand tactile tracking with learned surface normals",
    "abstract": "Comments: Accepted to IEEE Intl. Conf. on Robotics and Automation (ICRA) 2022. 7 pages, 8 figures",
    "descriptor": "\nComments: Accepted to IEEE Intl. Conf. on Robotics and Automation (ICRA) 2022. 7 pages, 8 figures\n",
    "authors": [
      "Paloma Sodhi",
      "Michael Kaess",
      "Mustafa Mukadam",
      "Stuart Anderson"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2111.07524"
  },
  {
    "id": "arXiv:2111.08366",
    "title": "Multi-Vector Models with Textual Guidance for Fine-Grained Scientific  Document Similarity",
    "abstract": "Comments: Accepted to NAACL 2022. Camera-ready version in progress",
    "descriptor": "\nComments: Accepted to NAACL 2022. Camera-ready version in progress\n",
    "authors": [
      "Sheshera Mysore",
      "Arman Cohan",
      "Tom Hope"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2111.08366"
  },
  {
    "id": "arXiv:2111.08440",
    "title": "On the Importance of Difficulty Calibration in Membership Inference  Attacks",
    "abstract": "Comments: 16 pages",
    "descriptor": "\nComments: 16 pages\n",
    "authors": [
      "Lauren Watson",
      "Chuan Guo",
      "Graham Cormode",
      "Alex Sablayrolles"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.08440"
  },
  {
    "id": "arXiv:2111.08706",
    "title": "How and When Random Feedback Works: A Case Study of Low-Rank Matrix  Factorization",
    "abstract": "Comments: Fixed minor typos. AISTATS 2022",
    "descriptor": "\nComments: Fixed minor typos. AISTATS 2022\n",
    "authors": [
      "Shivam Garg",
      "Santosh S. Vempala"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.08706"
  },
  {
    "id": "arXiv:2111.09484",
    "title": "Information-theoretic formulation of dynamical systems: causality,  modeling, and control",
    "abstract": "Information-theoretic formulation of dynamical systems: causality,  modeling, and control",
    "descriptor": "",
    "authors": [
      "Adri\u00e1n Lozano-Dur\u00e1n",
      "Gonzalo Arranz"
    ],
    "subjectives": [
      "Dynamical Systems (math.DS)",
      "Information Theory (cs.IT)",
      "Chaotic Dynamics (nlin.CD)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2111.09484"
  },
  {
    "id": "arXiv:2111.09883",
    "title": "Swin Transformer V2: Scaling Up Capacity and Resolution",
    "abstract": "Swin Transformer V2: Scaling Up Capacity and Resolution",
    "descriptor": "",
    "authors": [
      "Ze Liu",
      "Han Hu",
      "Yutong Lin",
      "Zhuliang Yao",
      "Zhenda Xie",
      "Yixuan Wei",
      "Jia Ning",
      "Yue Cao",
      "Zheng Zhang",
      "Li Dong",
      "Furu Wei",
      "Baining Guo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.09883"
  },
  {
    "id": "arXiv:2111.10438",
    "title": "Multi-Sensory HMI for Human-Centric Industrial Digital Twins: A 6G  Vision of Future Industry",
    "abstract": "Comments: Submitted to EuCNC 2022",
    "descriptor": "\nComments: Submitted to EuCNC 2022\n",
    "authors": [
      "Bin Han",
      "Hans D. Schotten"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2111.10438"
  },
  {
    "id": "arXiv:2111.10819",
    "title": "Stochastic viscosity approximations of Hamilton-Jacobi equations and  variance reduction",
    "abstract": "Stochastic viscosity approximations of Hamilton-Jacobi equations and  variance reduction",
    "descriptor": "",
    "authors": [
      "Gr\u00e9goire Ferr\u00e9"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Optimization and Control (math.OC)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2111.10819"
  },
  {
    "id": "arXiv:2111.12780",
    "title": "Transferability Estimation using Bhattacharyya Class Separability",
    "abstract": "Comments: Accepted for CVPR 2022",
    "descriptor": "\nComments: Accepted for CVPR 2022\n",
    "authors": [
      "Michal P\u00e1ndy",
      "Andrea Agostinelli",
      "Jasper Uijlings",
      "Vittorio Ferrari",
      "Thomas Mensink"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.12780"
  },
  {
    "id": "arXiv:2111.13656",
    "title": "Towards Low-Cost and Efficient Malaria Detection",
    "abstract": "Towards Low-Cost and Efficient Malaria Detection",
    "descriptor": "",
    "authors": [
      "Waqas Sultani",
      "Wajahat Nawaz",
      "Syed Javed",
      "Muhammad Sohail Danish",
      "Asma Saadia",
      "Mohsen Ali"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.13656"
  },
  {
    "id": "arXiv:2111.14200",
    "title": "Transfer Learning with Jukebox for Music Source Separation",
    "abstract": "Comments: 4Pages, 2 Figures",
    "descriptor": "\nComments: 4Pages, 2 Figures\n",
    "authors": [
      "Wadhah Zai El Amri",
      "Oliver Tautz",
      "Helge Ritter",
      "Andrew Melnik"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2111.14200"
  },
  {
    "id": "arXiv:2112.00668",
    "title": "A Few-Shot Meta-Learning based Siamese Neural Network using Entropy  Features for Ransomware Classification",
    "abstract": "A Few-Shot Meta-Learning based Siamese Neural Network using Entropy  Features for Ransomware Classification",
    "descriptor": "",
    "authors": [
      "Jinting Zhu",
      "Julian Jang-Jaccard",
      "Amardeep Singh",
      "Ian Welch",
      "Harith AI-Sahaf",
      "Seyit Camtepe"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2112.00668"
  },
  {
    "id": "arXiv:2112.00971",
    "title": "Towards Personalization of User Preferences in Partially Observable  Smart Home Environments",
    "abstract": "Towards Personalization of User Preferences in Partially Observable  Smart Home Environments",
    "descriptor": "",
    "authors": [
      "Shashi Suman",
      "Francois Rivest",
      "Ali Etemad"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.00971"
  },
  {
    "id": "arXiv:2112.06615",
    "title": "Quick Order Fairness",
    "abstract": "Quick Order Fairness",
    "descriptor": "",
    "authors": [
      "Christian Cachin",
      "Jovana Mi\u0107i\u0107",
      "Nathalie Steinhauer"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2112.06615"
  },
  {
    "id": "arXiv:2112.07342",
    "title": "Learning to Guide and to Be Guided in the Architect-Builder Problem",
    "abstract": "Comments: International Conference on Learning Representations (2022)",
    "descriptor": "\nComments: International Conference on Learning Representations (2022)\n",
    "authors": [
      "Paul Barde",
      "Tristan Karch",
      "Derek Nowrouzezahrai",
      "Cl\u00e9ment Moulin-Frier",
      "Christopher Pal",
      "Pierre-Yves Oudeyer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2112.07342"
  },
  {
    "id": "arXiv:2112.07528",
    "title": "n-CPS: Generalising Cross Pseudo Supervision to n Networks for  Semi-Supervised Semantic Segmentation",
    "abstract": "n-CPS: Generalising Cross Pseudo Supervision to n Networks for  Semi-Supervised Semantic Segmentation",
    "descriptor": "",
    "authors": [
      "Dominik Filipiak",
      "Piotr Tempczyk",
      "Marek Cygan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.07528"
  },
  {
    "id": "arXiv:2112.09065",
    "title": "Macroscopic properties of buyer-seller networks in online marketplaces",
    "abstract": "Macroscopic properties of buyer-seller networks in online marketplaces",
    "descriptor": "",
    "authors": [
      "Alberto Bracci",
      "J\u00f6rn Boehnke",
      "Abeer ElBahrawy",
      "Nicola Perra",
      "Alexander Teytelboym",
      "Andrea Baronchelli"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)",
      "General Economics (econ.GN)"
    ],
    "url": "https://arxiv.org/abs/2112.09065"
  },
  {
    "id": "arXiv:2112.09514",
    "title": "Call for establishing benchmark science and engineering",
    "abstract": "Call for establishing benchmark science and engineering",
    "descriptor": "",
    "authors": [
      "Jianfeng Zhan"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2112.09514"
  },
  {
    "id": "arXiv:2112.09745",
    "title": "Interpretable Data-Based Explanations for Fairness Debugging",
    "abstract": "Comments: Proceedings of the 2022 ACM SIGMOD International Conference on Management of Data (SIGMOD). 2022",
    "descriptor": "\nComments: Proceedings of the 2022 ACM SIGMOD International Conference on Management of Data (SIGMOD). 2022\n",
    "authors": [
      "Romila Pradhan",
      "Jiongli Zhu",
      "Boris Glavic",
      "Babak Salimi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2112.09745"
  },
  {
    "id": "arXiv:2112.12279",
    "title": "Randomize the Future: Asymptotically Optimal Locally Private Frequency  Estimation Protocol for Longitudinal Data",
    "abstract": "Randomize the Future: Asymptotically Optimal Locally Private Frequency  Estimation Protocol for Longitudinal Data",
    "descriptor": "",
    "authors": [
      "Olga Ohrimenko",
      "Anthony Wirth",
      "Hao Wu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2112.12279"
  },
  {
    "id": "arXiv:2112.13388",
    "title": "The brain as a probabilistic transducer: an evolutionarily plausible  network architecture for knowledge representation, computation, and behavior",
    "abstract": "The brain as a probabilistic transducer: an evolutionarily plausible  network architecture for knowledge representation, computation, and behavior",
    "descriptor": "",
    "authors": [
      "Joseph Y. Halpern",
      "Arnon Lotem"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Populations and Evolution (q-bio.PE)"
    ],
    "url": "https://arxiv.org/abs/2112.13388"
  },
  {
    "id": "arXiv:2112.13753",
    "title": "MetaCVR: Conversion Rate Prediction via Meta Learning in Small-Scale  Recommendation Scenarios",
    "abstract": "MetaCVR: Conversion Rate Prediction via Meta Learning in Small-Scale  Recommendation Scenarios",
    "descriptor": "",
    "authors": [
      "Xiaofeng Pan",
      "Ming Li",
      "Jing Zhang",
      "Keren Yu",
      "Luping Wang",
      "Hong Wen",
      "Chengjun Mao",
      "Bo Cao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2112.13753"
  },
  {
    "id": "arXiv:2112.14169",
    "title": "Fast Changeset-based Bug Localization with BERT",
    "abstract": "Fast Changeset-based Bug Localization with BERT",
    "descriptor": "",
    "authors": [
      "Agnieszka Ciborowska",
      "Kostadin Damevski"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2112.14169"
  },
  {
    "id": "arXiv:2112.14513",
    "title": "Spatial Distribution Patterns and Stress Potential Signs of Clownfish in  Recirculating Aquaculture Systems",
    "abstract": "Comments: 13 pages, 15 figures",
    "descriptor": "\nComments: 13 pages, 15 figures\n",
    "authors": [
      "Fahad Aljehani",
      "Ibrahima N'Doye",
      "Micaela S. Justo",
      "John E. Majoris",
      "Michael L. Berumen",
      "Taous-Meriem Laleg-Kirati"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.14513"
  },
  {
    "id": "arXiv:2112.14996",
    "title": "An Extension of Trakhtenbrot's Theorem",
    "abstract": "Comments: Changed the title and improved the presentation",
    "descriptor": "\nComments: Changed the title and improved the presentation\n",
    "authors": [
      "Reijo Jaakkola"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2112.14996"
  },
  {
    "id": "arXiv:2112.15352",
    "title": "Intention Adaptive Graph Neural Network for Category-aware Session-based  Recommendation",
    "abstract": "Intention Adaptive Graph Neural Network for Category-aware Session-based  Recommendation",
    "descriptor": "",
    "authors": [
      "Chuan Cui",
      "Qi Shen",
      "Shixuan Zhu",
      "Yitong Pang",
      "Yiming Zhang",
      "Hanning Gao",
      "Zhihua Wei"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2112.15352"
  },
  {
    "id": "arXiv:2112.15399",
    "title": "InfoNeRF: Ray Entropy Minimization for Few-Shot Neural Volume Rendering",
    "abstract": "Comments: CVPR 2022, Website: this http URL",
    "descriptor": "\nComments: CVPR 2022, Website: this http URL\n",
    "authors": [
      "Mijeong Kim",
      "Seonguk Seo",
      "Bohyung Han"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2112.15399"
  },
  {
    "id": "arXiv:2112.15459",
    "title": "Social Neuro AI: Social Interaction as the \"dark matter\" of AI",
    "abstract": "Comments: 14 pages, 2 figures",
    "descriptor": "\nComments: 14 pages, 2 figures\n",
    "authors": [
      "Samuele Bolotta",
      "Guillaume Dumas"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.15459"
  },
  {
    "id": "arXiv:2201.00072",
    "title": "BARACK: Partially Supervised Group Robustness With Guarantees",
    "abstract": "Comments: 26 pages",
    "descriptor": "\nComments: 26 pages\n",
    "authors": [
      "Nimit S. Sohoni",
      "Maziar Sanjabi",
      "Nicolas Ballas",
      "Aditya Grover",
      "Shaoliang Nie",
      "Hamed Firooz",
      "Christopher R\u00e9"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.00072"
  },
  {
    "id": "arXiv:2201.00264",
    "title": "Estimating Discretization Error with Preset Orders of Accuracy and  Fractional Refinement Ratios",
    "abstract": "Comments: 29 pages, 15 figures",
    "descriptor": "\nComments: 29 pages, 15 figures\n",
    "authors": [
      "Sharp Chim Yui Lo"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2201.00264"
  },
  {
    "id": "arXiv:2201.00577",
    "title": "Semantically Grounded Visual Embeddings for Zero-Shot Learning",
    "abstract": "Comments: Accepted at CVPRW",
    "descriptor": "\nComments: Accepted at CVPRW\n",
    "authors": [
      "Shah Nawaz",
      "Jacopo Cavazza",
      "Alessio Del Bue"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.00577"
  },
  {
    "id": "arXiv:2201.01228",
    "title": "Exponentially Convergent Direct Adaptive Pole Placement Control of  Plants with Unmatched Uncertainty under FE Condition",
    "abstract": "Comments: 6 pages, 2 figures",
    "descriptor": "\nComments: 6 pages, 2 figures\n",
    "authors": [
      "Anton Glushchenko",
      "Konstantin Lastochkin"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2201.01228"
  },
  {
    "id": "arXiv:2201.01347",
    "title": "Learning Differentiable Safety-Critical Control using Control Barrier  Functions for Generalization to Novel Environments",
    "abstract": "Comments: Accepted by European Control Conference 2022 (ECC22)",
    "descriptor": "\nComments: Accepted by European Control Conference 2022 (ECC22)\n",
    "authors": [
      "Hengbo Ma",
      "Bike Zhang",
      "Masayoshi Tomizuka",
      "Koushil Sreenath"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2201.01347"
  },
  {
    "id": "arXiv:2201.01845",
    "title": "Data-driven Model Generalizability in Crosslinguistic Low-resource  Morphological Segmentation",
    "abstract": "Comments: Published in TACL (this https URL)",
    "descriptor": "\nComments: Published in TACL (this https URL)\n",
    "authors": [
      "Zoey Liu",
      "Emily Prud'hommeaux"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2201.01845"
  },
  {
    "id": "arXiv:2201.02011",
    "title": "An unambiguous cloudiness index for nonwovens",
    "abstract": "An unambiguous cloudiness index for nonwovens",
    "descriptor": "",
    "authors": [
      "Michael Godehardt",
      "Ali Moghiseh",
      "Christine Oetjen",
      "Joachim Ohser",
      "Katja Schladitz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2201.02011"
  },
  {
    "id": "arXiv:2201.03230",
    "title": "Swin Transformer for Fast MRI",
    "abstract": "Comments: 55 pages, 19 figures, submitted to Neurocomputing journal",
    "descriptor": "\nComments: 55 pages, 19 figures, submitted to Neurocomputing journal\n",
    "authors": [
      "Jiahao Huang",
      "Yingying Fang",
      "Yinzhe Wu",
      "Huanjun Wu",
      "Zhifan Gao",
      "Yang Li",
      "Javier Del Ser",
      "Jun Xia",
      "Guang Yang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.03230"
  },
  {
    "id": "arXiv:2201.05051",
    "title": "Speech Resources in the Tamasheq Language",
    "abstract": "Comments: Accepted to LREC 2022",
    "descriptor": "\nComments: Accepted to LREC 2022\n",
    "authors": [
      "Marcely Zanon Boito",
      "Fethi Bougares",
      "Florentin Barbier",
      "Souhir Gahbiche",
      "Lo\u00efc Barrault",
      "Mickael Rouvier",
      "Yannick Est\u00e8ve"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2201.05051"
  },
  {
    "id": "arXiv:2201.05159",
    "title": "Structured access: an emerging paradigm for safe AI deployment",
    "abstract": "Comments: 28 pages",
    "descriptor": "\nComments: 28 pages\n",
    "authors": [
      "Toby Shevlane"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2201.05159"
  },
  {
    "id": "arXiv:2201.05766",
    "title": "Integrated Sensing and Communication with mmWave Massive MIMO: A  Compressed Sampling Perspective",
    "abstract": "Comments: 33 pages, 15 figures",
    "descriptor": "\nComments: 33 pages, 15 figures\n",
    "authors": [
      "Zhen Gao",
      "Ziwei Wan",
      "Dezhi Zheng",
      "Shufeng Tan",
      "Christos Masouros",
      "Derrick Wing Kwan Ng",
      "Sheng Chen"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2201.05766"
  },
  {
    "id": "arXiv:2201.06819",
    "title": "Sensor Scheduling Design for Complex Networks under a Distributed State  Estimation Framework",
    "abstract": "Sensor Scheduling Design for Complex Networks under a Distributed State  Estimation Framework",
    "descriptor": "",
    "authors": [
      "Peihu Duan",
      "Lidong He",
      "Lingying Huang",
      "Guanrong Chen",
      "Ling Shi"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2201.06819"
  },
  {
    "id": "arXiv:2201.07131",
    "title": "Leveraging Real Talking Faces via Self-Supervision for Robust Forgery  Detection",
    "abstract": "Comments: CVPR 2022",
    "descriptor": "\nComments: CVPR 2022\n",
    "authors": [
      "Alexandros Haliassos",
      "Rodrigo Mira",
      "Stavros Petridis",
      "Maja Pantic"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.07131"
  },
  {
    "id": "arXiv:2201.07197",
    "title": "Finding Strong Components Using Depth-First Search",
    "abstract": "Comments: 27 pages. In memory of Pierre Rosenstiehl. A slightly revised version",
    "descriptor": "\nComments: 27 pages. In memory of Pierre Rosenstiehl. A slightly revised version\n",
    "authors": [
      "Robert E. Tarjan",
      "Uri Zwick"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2201.07197"
  },
  {
    "id": "arXiv:2201.08281",
    "title": "Symplectic Momentum Neural Networks -- Using Discrete Variational  Mechanics as a prior in Deep Learning",
    "abstract": "Comments: 12 pages, 4 figures. Accepted at 4th Annual Learning for Dynamics & Control Conference",
    "descriptor": "\nComments: 12 pages, 4 figures. Accepted at 4th Annual Learning for Dynamics & Control Conference\n",
    "authors": [
      "Saul Santos",
      "Monica Ekal",
      "Rodrigo Ventura"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.08281"
  },
  {
    "id": "arXiv:2201.08506",
    "title": "alpha-Deep Probabilistic Inference (alpha-DPI): efficient uncertainty  quantification from exoplanet astrometry to black hole feature extraction",
    "abstract": "alpha-Deep Probabilistic Inference (alpha-DPI): efficient uncertainty  quantification from exoplanet astrometry to black hole feature extraction",
    "descriptor": "",
    "authors": [
      "He Sun",
      "Katherine L. Bouman",
      "Paul Tiede",
      "Jason J. Wang",
      "Sarah Blunt",
      "Dimitri Mawet"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2201.08506"
  },
  {
    "id": "arXiv:2201.09046",
    "title": "Differentially Private SGDA for Minimax Problems",
    "abstract": "Differentially Private SGDA for Minimax Problems",
    "descriptor": "",
    "authors": [
      "Zhenhuan Yang",
      "Shu Hu",
      "Yunwen Lei",
      "Kush R. Varshney",
      "Siwei Lyu",
      "Yiming Ying"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2201.09046"
  },
  {
    "id": "arXiv:2201.09180",
    "title": "Prescribed Performance Adaptive Fixed-Time Attitude Tracking Control of  a 3-DOF Helicopter with Small Overshoot",
    "abstract": "Comments: 5 pages, 4 figures",
    "descriptor": "\nComments: 5 pages, 4 figures\n",
    "authors": [
      "Xidong Wang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2201.09180"
  },
  {
    "id": "arXiv:2201.09360",
    "title": "POTHER: Patch-Voted Deep Learning-based Chest X-ray Bias Analysis for  COVID-19 Detection",
    "abstract": "Comments: Accepted at International Conference on Computational Science (ICCS) 2022, London",
    "descriptor": "\nComments: Accepted at International Conference on Computational Science (ICCS) 2022, London\n",
    "authors": [
      "Tomasz Szczepa\u0144ski",
      "Arkadiusz Sitek",
      "Tomasz Trzci\u0144ski",
      "Szymon P\u0142otka"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.09360"
  },
  {
    "id": "arXiv:2201.10243",
    "title": "BERTHA: Video Captioning Evaluation Via Transfer-Learned Human  Assessment",
    "abstract": "Comments: To be published in Language Resources and Evaluation Conference(LREC) 2022",
    "descriptor": "\nComments: To be published in Language Resources and Evaluation Conference(LREC) 2022\n",
    "authors": [
      "Luis Lebron",
      "Yvette Graham",
      "Kevin McGuinness",
      "Konstantinos Kouramas",
      "Noel E. O'Connor"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.10243"
  },
  {
    "id": "arXiv:2201.11409",
    "title": "On the RTL Implementation of FINN Matrix Vector Compute Unit",
    "abstract": "Comments: 22 pages, 7 tables, 16 figures",
    "descriptor": "\nComments: 22 pages, 7 tables, 16 figures\n",
    "authors": [
      "Syed Asad Alam",
      "David Gregg",
      "Giulio Gambardella",
      "Thomas Preusser",
      "Michaela Blott"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2201.11409"
  },
  {
    "id": "arXiv:2201.11650",
    "title": "Incremental Mining of Frequent Serial Episodes Considering Multiple  Occurrences",
    "abstract": "Incremental Mining of Frequent Serial Episodes Considering Multiple  Occurrences",
    "descriptor": "",
    "authors": [
      "Thomas Guyet",
      "Wenbin Zhang",
      "Albert Bifet"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2201.11650"
  },
  {
    "id": "arXiv:2201.12487",
    "title": "Counterfactual Plans under Distributional Ambiguity",
    "abstract": "Comments: 19 pages",
    "descriptor": "\nComments: 19 pages\n",
    "authors": [
      "Ngoc Bui",
      "Duy Nguyen",
      "Viet Anh Nguyen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2201.12487"
  },
  {
    "id": "arXiv:2201.12680",
    "title": "Deep Contrastive Learning is Provably (almost) Principal Component  Analysis",
    "abstract": "Comments: Theorem 2 now goes beyond InfoNCE loss and applicable to any loss $L_{\\phi, \\psi}$ with $\\psi(x) = e^{x/\\tau}$",
    "descriptor": "\nComments: Theorem 2 now goes beyond InfoNCE loss and applicable to any loss $L_{\\phi, \\psi}$ with $\\psi(x) = e^{x/\\tau}$\n",
    "authors": [
      "Yuandong Tian"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2201.12680"
  },
  {
    "id": "arXiv:2202.01993",
    "title": "Grounding Answers for Visual Questions Asked by Visually Impaired People",
    "abstract": "Comments: Computer Vision and Pattern Recognition",
    "descriptor": "\nComments: Computer Vision and Pattern Recognition\n",
    "authors": [
      "Chongyan Chen",
      "Samreen Anjum",
      "Danna Gurari"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.01993"
  },
  {
    "id": "arXiv:2202.02015",
    "title": "Energy-Efficient High-Accuracy Spiking Neural Network Inference Using  Time-Domain Neurons",
    "abstract": "Comments: Accepted in AICAS 2022",
    "descriptor": "\nComments: Accepted in AICAS 2022\n",
    "authors": [
      "Joonghyun Song",
      "Jiwon Shin",
      "Hanseok Kim",
      "Woo-Seok Choi"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.02015"
  },
  {
    "id": "arXiv:2202.02212",
    "title": "SSHA: Video Violence Recognition and Localization Using a  Semi-Supervised Hard Attention Model",
    "abstract": "Comments: 11 pages, 4 figures, 4 equations, 3 tables, 1 algorithm",
    "descriptor": "\nComments: 11 pages, 4 figures, 4 equations, 3 tables, 1 algorithm\n",
    "authors": [
      "Hamid Mohammadi",
      "Ehsan Nazerfard"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.02212"
  },
  {
    "id": "arXiv:2202.02436",
    "title": "Neural Logic Analogy Learning",
    "abstract": "Comments: In Proceedings of the ICLR 2022 PAIR2Struct Workshop",
    "descriptor": "\nComments: In Proceedings of the ICLR 2022 PAIR2Struct Workshop\n",
    "authors": [
      "Yujia Fan",
      "Yongfeng Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2202.02436"
  },
  {
    "id": "arXiv:2202.02557",
    "title": "Lower-bounds on the Bayesian Risk in Estimation Procedures via  $f$-Divergences",
    "abstract": "Comments: Submitted to ISIT 2022",
    "descriptor": "\nComments: Submitted to ISIT 2022\n",
    "authors": [
      "Adrien Vandenbroucque",
      "Amedeo Roberto Esposito",
      "Michael Gastpar"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Probability (math.PR)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2202.02557"
  },
  {
    "id": "arXiv:2202.03834",
    "title": "FSM: FBS Set Management, An energy efficient multi-drone 3D trajectory  approach in cellular networks",
    "abstract": "FSM: FBS Set Management, An energy efficient multi-drone 3D trajectory  approach in cellular networks",
    "descriptor": "",
    "authors": [
      "Mehdi Sookhak",
      "Amir Hossein Mohajerzadeh"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.03834"
  },
  {
    "id": "arXiv:2202.06830",
    "title": "Online Approval Committee Elections",
    "abstract": "Online Approval Committee Elections",
    "descriptor": "",
    "authors": [
      "Virginie Do",
      "Matthieu Hervouin",
      "J\u00e9r\u00f4me Lang",
      "Piotr Skowron"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.06830"
  },
  {
    "id": "arXiv:2202.07265",
    "title": "Analysis of a blockchain protocol based on LDPC codes",
    "abstract": "Analysis of a blockchain protocol based on LDPC codes",
    "descriptor": "",
    "authors": [
      "Massimo Battaglioni",
      "Paolo Santini",
      "Giulia Rafaiani",
      "Franco Chiaraluce",
      "Marco Baldi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.07265"
  },
  {
    "id": "arXiv:2202.08550",
    "title": "Delay-adaptive step-sizes for asynchronous learning",
    "abstract": "Comments: 21 pages, 4 figures",
    "descriptor": "\nComments: 21 pages, 4 figures\n",
    "authors": [
      "Xuyang Wu",
      "Sindri Magnusson",
      "Hamid Reza Feyzmahdavian",
      "Mikael Johansson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2202.08550"
  },
  {
    "id": "arXiv:2202.10337",
    "title": "Integration of knowledge and data in machine learning",
    "abstract": "Comments: The language has been modified and figures are updated",
    "descriptor": "\nComments: The language has been modified and figures are updated\n",
    "authors": [
      "Yuntian Chen",
      "Dongxiao Zhang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.10337"
  },
  {
    "id": "arXiv:2202.10707",
    "title": "Targeting occupant feedback using digital twins: Adaptive  spatial-temporal thermal preference sampling to optimize personal comfort  models",
    "abstract": "Targeting occupant feedback using digital twins: Adaptive  spatial-temporal thermal preference sampling to optimize personal comfort  models",
    "descriptor": "",
    "authors": [
      "Mahmoud Abdelrahman",
      "Clayton Miller"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.10707"
  },
  {
    "id": "arXiv:2202.10771",
    "title": "How Fast Can We Play Tetris Greedily With Rectangular Pieces?",
    "abstract": "Comments: Correction of typos and other minor corrections",
    "descriptor": "\nComments: Correction of typos and other minor corrections\n",
    "authors": [
      "Justin Dallant",
      "John Iacono"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2202.10771"
  },
  {
    "id": "arXiv:2202.12979",
    "title": "Generalised Gaussian Process Latent Variable Models (GPLVM) with  Stochastic Variational Inference",
    "abstract": "Comments: AISTATS 2022",
    "descriptor": "\nComments: AISTATS 2022\n",
    "authors": [
      "Vidhi Lalchand",
      "Aditya Ravuri",
      "Neil D. Lawrence"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.12979"
  },
  {
    "id": "arXiv:2202.13013",
    "title": "Sign and Basis Invariant Networks for Spectral Graph Representation  Learning",
    "abstract": "Comments: 35 pages",
    "descriptor": "\nComments: 35 pages\n",
    "authors": [
      "Derek Lim",
      "Joshua Robinson",
      "Lingxiao Zhao",
      "Tess Smidt",
      "Suvrit Sra",
      "Haggai Maron",
      "Stefanie Jegelka"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.13013"
  },
  {
    "id": "arXiv:2202.13158",
    "title": "Semantic Soundness for Language Interoperability",
    "abstract": "Comments: revised version with more exposition, typos fixed, etc",
    "descriptor": "\nComments: revised version with more exposition, typos fixed, etc\n",
    "authors": [
      "Daniel Patterson",
      "Noble Mushtak",
      "Andrew Wagner",
      "Amal Ahmed"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2202.13158"
  },
  {
    "id": "arXiv:2202.13340",
    "title": "Enumeration of chordal planar graphs and maps",
    "abstract": "Comments: 12 pages, 1 figure",
    "descriptor": "\nComments: 12 pages, 1 figure\n",
    "authors": [
      "Jordi Castellv\u00ed",
      "Marc Noy",
      "Cl\u00e9ment Requil\u00e9"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2202.13340"
  },
  {
    "id": "arXiv:2203.00379",
    "title": "Exploring Wilderness Using Explainable Machine Learning in Satellite  Imagery",
    "abstract": "Exploring Wilderness Using Explainable Machine Learning in Satellite  Imagery",
    "descriptor": "",
    "authors": [
      "Timo T. Stomberg",
      "Taylor Stone",
      "Johannes Leonhardt",
      "Immanuel Weber",
      "Ribana Roscher"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.00379"
  },
  {
    "id": "arXiv:2203.01436",
    "title": "CAMERA: A Method for Cost-aware, Adaptive, Multifidelity, Efficient  Reliability Analysis",
    "abstract": "Comments: 35 page, 16 figures",
    "descriptor": "\nComments: 35 page, 16 figures\n",
    "authors": [
      "S. Ashwin Renganathan",
      "Vishwas Rao",
      "Ionel M. Navon"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2203.01436"
  },
  {
    "id": "arXiv:2203.03107",
    "title": "Privacy Leakage in Proactive VR Streaming: Modeling and Tradeoff",
    "abstract": "Comments: 30 pages, 9 figures, submit to IEEE for possible publication, the proofs in this version of the manuscript is omitted and can be found in version 1",
    "descriptor": "\nComments: 30 pages, 9 figures, submit to IEEE for possible publication, the proofs in this version of the manuscript is omitted and can be found in version 1\n",
    "authors": [
      "Xing Wei",
      "Chenyang Yang",
      "Chengjian Sun"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Networking and Internet Architecture (cs.NI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.03107"
  },
  {
    "id": "arXiv:2203.03157",
    "title": "SingleSketch2Mesh : Generating 3D Mesh model from Sketch",
    "abstract": "Comments: Working on some updates",
    "descriptor": "\nComments: Working on some updates\n",
    "authors": [
      "Nitish Bhardwaj",
      "Dhornala Bharadwaj",
      "Alpana Dubey"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.03157"
  },
  {
    "id": "arXiv:2203.04090",
    "title": "Foundations for Grassroots Democratic Metaverse",
    "abstract": "Foundations for Grassroots Democratic Metaverse",
    "descriptor": "",
    "authors": [
      "Ehud Shapiro",
      "Nimrod Talmon"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Multiagent Systems (cs.MA)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2203.04090"
  },
  {
    "id": "arXiv:2203.05179",
    "title": "Towards Open-Set Text Recognition via Label-to-Prototype Learning",
    "abstract": "Comments: V2 of paper Towards Open-Set Text Recognition via Label-to-Prototype Learning. It is a major extension of V1 and the models are tunned for better performances, yet the core experiments from v1 are kept so its not a new paper",
    "descriptor": "\nComments: V2 of paper Towards Open-Set Text Recognition via Label-to-Prototype Learning. It is a major extension of V1 and the models are tunned for better performances, yet the core experiments from v1 are kept so its not a new paper\n",
    "authors": [
      "Chang Liu",
      "Chun Yang",
      "Hai-Bo Qin",
      "Xiaobin Zhu",
      "Cheng-Lin Liu",
      "Xu-Cheng Yin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.05179"
  },
  {
    "id": "arXiv:2203.05241",
    "title": "Theory of Network Wave (On a Primary Path)",
    "abstract": "Theory of Network Wave (On a Primary Path)",
    "descriptor": "",
    "authors": [
      "Bo Li",
      "Mao Yang",
      "Zhongjiang Yan"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2203.05241"
  },
  {
    "id": "arXiv:2203.05813",
    "title": "Averaging Spatio-temporal Signals using Optimal Transport and Soft  Alignments",
    "abstract": "Averaging Spatio-temporal Signals using Optimal Transport and Soft  Alignments",
    "descriptor": "",
    "authors": [
      "Hicham Janati",
      "Marco Cuturi",
      "Alexandre Gramfort"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.05813"
  },
  {
    "id": "arXiv:2203.06429",
    "title": "DFTR: Depth-supervised Fusion Transformer for Salient Object Detection",
    "abstract": "Comments: 15 pages, 5 figures, 4 tables",
    "descriptor": "\nComments: 15 pages, 5 figures, 4 tables\n",
    "authors": [
      "Heqin Zhu",
      "Xu Sun",
      "Yuexiang Li",
      "Kai Ma",
      "S. Kevin Zhou",
      "Yefeng Zheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.06429"
  },
  {
    "id": "arXiv:2203.07229",
    "title": "Physico-chemical properties extraction from the fluorescence spectrum  with 1D-convolutional neural networks: application to olive oil",
    "abstract": "Comments: 11 pages",
    "descriptor": "\nComments: 11 pages\n",
    "authors": [
      "Francesca Venturini",
      "Michela Sperti",
      "Umberto Michelucci",
      "Arnaud Gucciardi",
      "Vanessa M. Martose",
      "Marco A. Deriu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2203.07229"
  },
  {
    "id": "arXiv:2203.08147",
    "title": "Energy-Latency Attacks via Sponge Poisoning",
    "abstract": "Comments: Preprint;15 pages",
    "descriptor": "\nComments: Preprint;15 pages\n",
    "authors": [
      "Antonio Emanuele Cin\u00e0",
      "Ambra Demontis",
      "Battista Biggio",
      "Fabio Roli",
      "Marcello Pelillo"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.08147"
  },
  {
    "id": "arXiv:2203.08850",
    "title": "Pre-Trained Multilingual Sequence-to-Sequence Models: A Hope for  Low-Resource Language Translation?",
    "abstract": "Comments: Accepted to Findings of ACL 2022",
    "descriptor": "\nComments: Accepted to Findings of ACL 2022\n",
    "authors": [
      "En-Shiun Annie Lee",
      "Sarubi Thillainathan",
      "Shravan Nayak",
      "Surangika Ranathunga",
      "David Ifeoluwa Adelani",
      "Ruisi Su",
      "Arya D. McCarthy"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.08850"
  },
  {
    "id": "arXiv:2203.09096",
    "title": "DeepAD: A Robust Deep Learning Model of Alzheimer's Disease Progression  for Real-World Clinical Applications",
    "abstract": "DeepAD: A Robust Deep Learning Model of Alzheimer's Disease Progression  for Real-World Clinical Applications",
    "descriptor": "",
    "authors": [
      "Somaye Hashemifar",
      "Claudia Iriondo",
      "Evan Casey",
      "Mohsen Hejrati"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2203.09096"
  },
  {
    "id": "arXiv:2203.09268",
    "title": "Progressive Subsampling for Oversampled Data -- Application to  Quantitative MRI",
    "abstract": "Progressive Subsampling for Oversampled Data -- Application to  Quantitative MRI",
    "descriptor": "",
    "authors": [
      "Stefano B. Blumberg",
      "Hongxiang Lin",
      "Francesco Grussu",
      "Yukun Zhou",
      "Matteo Figini",
      "Daniel C. Alexander"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2203.09268"
  },
  {
    "id": "arXiv:2203.09553",
    "title": "Efficient Federated Learning on Knowledge Graphs via Privacy-preserving  Relation Embedding Aggregation",
    "abstract": "Comments: Accepted to ACL 2022 Workshop on Federated Learning for Natural Language Processing",
    "descriptor": "\nComments: Accepted to ACL 2022 Workshop on Federated Learning for Natural Language Processing\n",
    "authors": [
      "Kai Zhang",
      "Yu Wang",
      "Hongyi Wang",
      "Lifu Huang",
      "Carl Yang",
      "Lichao Sun"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.09553"
  },
  {
    "id": "arXiv:2203.10379",
    "title": "Lazy Rearrangement Planning in Confined Spaces",
    "abstract": "Comments: Accepted to the 32nd International Conference on Automated Planning and Scheduling (ICAPS 2022)",
    "descriptor": "\nComments: Accepted to the 32nd International Conference on Automated Planning and Scheduling (ICAPS 2022)\n",
    "authors": [
      "Rui Wang",
      "Kai Gao",
      "Jingjin Yu",
      "Kostas Bekris"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.10379"
  },
  {
    "id": "arXiv:2203.10909",
    "title": "x-enVENT: A Corpus of Event Descriptions with Experiencer-specific  Emotion and Appraisal Annotations",
    "abstract": "Comments: accepted at LREC 2022",
    "descriptor": "\nComments: accepted at LREC 2022\n",
    "authors": [
      "Enrica Troiano",
      "Laura Oberl\u00e4nder",
      "Maximilian Wegge",
      "Roman Klinger"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.10909"
  },
  {
    "id": "arXiv:2203.11200",
    "title": "Exploiting Neighbor Effect: Conv-Agnostic GNNs Framework for Graphs with  Heterophily",
    "abstract": "Exploiting Neighbor Effect: Conv-Agnostic GNNs Framework for Graphs with  Heterophily",
    "descriptor": "",
    "authors": [
      "Jie Chen",
      "Shouzhen Chen",
      "Junbin Gao",
      "Zengfeng Huang",
      "Junping Zhang",
      "Jian Pu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.11200"
  },
  {
    "id": "arXiv:2203.11585",
    "title": "Environment induced emergence of collective behaviour in evolving swarms  with limited sensing",
    "abstract": "Comments: (1) Three authors contributed equally to this research",
    "descriptor": "\nComments: (1) Three authors contributed equally to this research\n",
    "authors": [
      "Fuda van Diggelen",
      "Jie Luo",
      "Tugay Alperen Karag\u00fczel",
      "Nicolas Cambier",
      "Eliseo Ferrante",
      "A.E. Eiben"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.11585"
  },
  {
    "id": "arXiv:2203.11899",
    "title": "Transformer based ensemble for emotion detection",
    "abstract": "Comments: Accepted at WASSA, ACL 2022",
    "descriptor": "\nComments: Accepted at WASSA, ACL 2022\n",
    "authors": [
      "Aditya Kane",
      "Shantanu Patankar",
      "Sahil Khose",
      "Neeraja Kirtane"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.11899"
  },
  {
    "id": "arXiv:2203.12062",
    "title": "Distributionally Robust Model Predictive Control with Total Variation  Distance",
    "abstract": "Distributionally Robust Model Predictive Control with Total Variation  Distance",
    "descriptor": "",
    "authors": [
      "Anushri Dixit",
      "Mohamadreza Ahmadi",
      "Joel W. Burdick"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Robotics (cs.RO)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2203.12062"
  },
  {
    "id": "arXiv:2203.12292",
    "title": "Efficient distributed matrix-free multigrid methods on locally refined  meshes for FEM computations",
    "abstract": "Comments: 34 pages, 17 figures",
    "descriptor": "\nComments: 34 pages, 17 figures\n",
    "authors": [
      "Peter Munch",
      "Timo Heister",
      "Laura Prieto Saavedra",
      "Martin Kronbichler"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Mathematical Software (cs.MS)"
    ],
    "url": "https://arxiv.org/abs/2203.12292"
  },
  {
    "id": "arXiv:2203.12870",
    "title": "RNNPose: Recurrent 6-DoF Object Pose Refinement with Robust  Correspondence Field Estimation and Pose Optimization",
    "abstract": "Comments: Accepted to CVPR 2022",
    "descriptor": "\nComments: Accepted to CVPR 2022\n",
    "authors": [
      "Yan Xu",
      "Kwan-Yee Lin",
      "Guofeng Zhang",
      "Xiaogang Wang",
      "Hongsheng Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.12870"
  },
  {
    "id": "arXiv:2203.12997",
    "title": "Hierarchical Nearest Neighbor Graph Embedding for Efficient  Dimensionality Reduction",
    "abstract": "Comments: CVPR 2022",
    "descriptor": "\nComments: CVPR 2022\n",
    "authors": [
      "M. Saquib Sarfraz",
      "Marios Koulakis",
      "Constantin Seibold",
      "Rainer Stiefelhagen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Data Structures and Algorithms (cs.DS)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2203.12997"
  },
  {
    "id": "arXiv:2203.13147",
    "title": "Self-Triggered Coordination Control of Connected Automated Vehicles in  Traffic Networks",
    "abstract": "Self-Triggered Coordination Control of Connected Automated Vehicles in  Traffic Networks",
    "descriptor": "",
    "authors": [
      "Nader Meskin",
      "Ehsan Sabouni",
      "Wei Xiao",
      "Christos G. Cassandras"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.13147"
  },
  {
    "id": "arXiv:2203.13447",
    "title": "Component-wise Analysis of Automatically Designed Multiobjective  Algorithms on Constrained Problems",
    "abstract": "Component-wise Analysis of Automatically Designed Multiobjective  Algorithms on Constrained Problems",
    "descriptor": "",
    "authors": [
      "Yuri Lavinas",
      "Gabriela Ochoa",
      "Claus Aranha"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.13447"
  },
  {
    "id": "arXiv:2203.13802",
    "title": "Playing Lottery Tickets in Style Transfer Models",
    "abstract": "Playing Lottery Tickets in Style Transfer Models",
    "descriptor": "",
    "authors": [
      "Meihao Kong",
      "Jing Huo",
      "Wenbin Li",
      "Jing Wu",
      "Yu-Kun Lai",
      "Yang Gao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2203.13802"
  },
  {
    "id": "arXiv:2203.13887",
    "title": "Automatic Debiased Machine Learning for Dynamic Treatment Effects",
    "abstract": "Automatic Debiased Machine Learning for Dynamic Treatment Effects",
    "descriptor": "",
    "authors": [
      "Victor Chernozhukov",
      "Whitney Newey",
      "Rahul Singh",
      "Vasilis Syrgkanis"
    ],
    "subjectives": [
      "Econometrics (econ.EM)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.13887"
  },
  {
    "id": "arXiv:2203.14267",
    "title": "bitsa_nlp@LT-EDI-ACL2022: Leveraging Pretrained Language Models for  Detecting Homophobia and Transphobia in Social Media Comments",
    "abstract": "Comments: 6 pages, Accepted at LT-EDI workshop ACL 2022. Camera ready version. Addressed all reviewer comments. Added Baseline methods and Ablation study",
    "descriptor": "\nComments: 6 pages, Accepted at LT-EDI workshop ACL 2022. Camera ready version. Addressed all reviewer comments. Added Baseline methods and Ablation study\n",
    "authors": [
      "Vitthal Bhandari",
      "Poonam Goyal"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.14267"
  },
  {
    "id": "arXiv:2203.14457",
    "title": "PAEDID: Patch Autoencoder Based Deep Image Decomposition For Pixel-level  Defective Region Segmentation",
    "abstract": "PAEDID: Patch Autoencoder Based Deep Image Decomposition For Pixel-level  Defective Region Segmentation",
    "descriptor": "",
    "authors": [
      "Shancong Mou",
      "Meng Cao",
      "Haoping Bai",
      "Ping Huang",
      "Jianjun Shi",
      "Jiulong Shan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.14457"
  },
  {
    "id": "arXiv:2203.14763",
    "title": "Analysis and Performance Evaluation of Mobility for Multi-Panel User  Equipment in 5G Networks",
    "abstract": "Comments: 7 pages, 7 figures. Accepted for presentation at the 2022 IEEE 95th Vehicular Technology Conference (VTC2022)-Spring, Helsinki, Finland",
    "descriptor": "\nComments: 7 pages, 7 figures. Accepted for presentation at the 2022 IEEE 95th Vehicular Technology Conference (VTC2022)-Spring, Helsinki, Finland\n",
    "authors": [
      "Subhyal Bin Iqbal",
      "Ahmad Awada",
      "Umur Karabulut",
      "Ingo Viering",
      "Philipp Schulz",
      "Gerhard P. Fettweis"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2203.14763"
  },
  {
    "id": "arXiv:2203.14810",
    "title": "Data-Driven, Soft Alignment of Functional Data Using Shapes and  Landmarks",
    "abstract": "Data-Driven, Soft Alignment of Functional Data Using Shapes and  Landmarks",
    "descriptor": "",
    "authors": [
      "Xiaoyang Guo",
      "Wei Wu",
      "Anuj Srivastava"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2203.14810"
  },
  {
    "id": "arXiv:2203.14960",
    "title": "Domino: Discovering Systematic Errors with Cross-Modal Embeddings",
    "abstract": "Comments: ICLR 2022 (Oral)",
    "descriptor": "\nComments: ICLR 2022 (Oral)\n",
    "authors": [
      "Sabri Eyuboglu",
      "Maya Varma",
      "Khaled Saab",
      "Jean-Benoit Delbrouck",
      "Christopher Lee-Messer",
      "Jared Dunnmon",
      "James Zou",
      "Christopher R\u00e9"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.14960"
  },
  {
    "id": "arXiv:2203.15026",
    "title": "A systematic review and meta-analysis of Digital Elevation Model (DEM)  fusion: pre-processing, methods and applications",
    "abstract": "A systematic review and meta-analysis of Digital Elevation Model (DEM)  fusion: pre-processing, methods and applications",
    "descriptor": "",
    "authors": [
      "Chukwuma Okolie",
      "Julian Smit"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.15026"
  },
  {
    "id": "arXiv:2203.15099",
    "title": "LogicInference: A New Dataset for Teaching Logical Inference to seq2seq  Models",
    "abstract": "Comments: Accepted at ICLR 2022 OSC workshop (v3 contains updated results after fixing a problem in dataset generation)",
    "descriptor": "\nComments: Accepted at ICLR 2022 OSC workshop (v3 contains updated results after fixing a problem in dataset generation)\n",
    "authors": [
      "Santiago Ontanon",
      "Joshua Ainslie",
      "Vaclav Cvicek",
      "Zachary Fisher"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.15099"
  },
  {
    "id": "arXiv:2203.15312",
    "title": "In-N-Out Generative Learning for Dense Unsupervised Video Segmentation",
    "abstract": "In-N-Out Generative Learning for Dense Unsupervised Video Segmentation",
    "descriptor": "",
    "authors": [
      "Xiao Pan",
      "Peike Li",
      "Zongxin Yang",
      "Huiling Zhou",
      "Chang Zhou",
      "Hongxia Yang",
      "Jingren Zhou",
      "Yi Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.15312"
  },
  {
    "id": "arXiv:2203.15331",
    "title": "CNN Filter DB: An Empirical Investigation of Trained Convolutional  Filters",
    "abstract": "Comments: significantly reduced PDF size in v2; Accepted as ORAL at IEEE/CVF Conference on Computer Vision and Pattern Recognition 2022 (CVPR)",
    "descriptor": "\nComments: significantly reduced PDF size in v2; Accepted as ORAL at IEEE/CVF Conference on Computer Vision and Pattern Recognition 2022 (CVPR)\n",
    "authors": [
      "Paul Gavrikov",
      "Janis Keuper"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.15331"
  },
  {
    "id": "arXiv:2203.15371",
    "title": "mc-BEiT: Multi-choice Discretization for Image BERT Pre-training",
    "abstract": "mc-BEiT: Multi-choice Discretization for Image BERT Pre-training",
    "descriptor": "",
    "authors": [
      "Xiaotong Li",
      "Yixiao Ge",
      "Kun Yi",
      "Zixuan Hu",
      "Ying Shan",
      "Ling-Yu Duan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.15371"
  },
  {
    "id": "arXiv:2203.16088",
    "title": "Kleene Star of the Primes is not Regular in Any Base",
    "abstract": "Comments: 3 pages; typo corrected",
    "descriptor": "\nComments: 3 pages; typo corrected\n",
    "authors": [
      "Jason Yuen"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2203.16088"
  },
  {
    "id": "arXiv:2203.16135",
    "title": "Kron-based Model-order Reduction of Open Mass-action Kinetics Chemical  Reaction Networks",
    "abstract": "Comments: Submitted to IEEE Transactions on Automatic Control",
    "descriptor": "\nComments: Submitted to IEEE Transactions on Automatic Control\n",
    "authors": [
      "Mohamad Agung Prawira Negara",
      "Azka Muji Burohman",
      "Bayu Jayawardhana"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.16135"
  },
  {
    "id": "arXiv:2203.16318",
    "title": "Near-Field Communications for 6G: Fundamentals, Challenges, Potentials,  and Future Directions",
    "abstract": "Comments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Mingyao Cui",
      "Zidong Wu",
      "Yu Lu",
      "Xiuhong Wei",
      "Linglong Dai"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2203.16318"
  },
  {
    "id": "arXiv:2203.16328",
    "title": "Smooth Robust Tensor Completion for Background/Foreground Separation  with Missing Pixels: Novel Algorithm with Convergence Guarantee",
    "abstract": "Comments: 40 pages, 11 figures",
    "descriptor": "\nComments: 40 pages, 11 figures\n",
    "authors": [
      "Bo Shen",
      "Weijun Xie",
      "Zhenyu Kong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.16328"
  },
  {
    "id": "arXiv:2203.16597",
    "title": "NGSO Constellation Design for Global Connectivity",
    "abstract": "Comments: Book chapter submitted to IET Non-Geostationary Satellite Communications Systems",
    "descriptor": "\nComments: Book chapter submitted to IET Non-Geostationary Satellite Communications Systems\n",
    "authors": [
      "Israel Leyva-Mayorga",
      "Beatriz Soret",
      "Bho Matthiesen",
      "Maik R\u00f6per",
      "Dirk W\u00fcbben",
      "Armin Dekorsy",
      "Petar Popovski"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2203.16597"
  },
  {
    "id": "arXiv:2203.16969",
    "title": "Software Engineering for Quantum Programming: How Far Are We?",
    "abstract": "Software Engineering for Quantum Programming: How Far Are We?",
    "descriptor": "",
    "authors": [
      "Manuel De Stefano",
      "Fabiano Pecorelli",
      "Dario Di Nucci",
      "Fabio Palomba",
      "Andrea De Lucia"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2203.16969"
  },
  {
    "id": "arXiv:2204.00215",
    "title": "Federated Learning Framework Coping with Hierarchical Heterogeneity in  Cooperative ITS",
    "abstract": "Federated Learning Framework Coping with Hierarchical Heterogeneity in  Cooperative ITS",
    "descriptor": "",
    "authors": [
      "Rui Song",
      "Liguo Zhou",
      "Venkatnarayanan Lakshminarasimhan",
      "Andreas Festag",
      "Alois Knoll"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.00215"
  },
  {
    "id": "arXiv:2204.00486",
    "title": "GEB+: A benchmark for generic event boundary captioning, grounding and  text-based retrieval",
    "abstract": "Comments: 24 pages",
    "descriptor": "\nComments: 24 pages\n",
    "authors": [
      "Yuxuan Wang",
      "Difei Gao",
      "Licheng Yu",
      "Stan Weixian Lei",
      "Matt Feiszli",
      "Mike Zheng Shou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.00486"
  },
  {
    "id": "arXiv:2204.00697",
    "title": "Assisted Shortest Path Planning for a Convoy through a Repairable  Network",
    "abstract": "Assisted Shortest Path Planning for a Convoy through a Repairable  Network",
    "descriptor": "",
    "authors": [
      "Abhay Singh Bhadoriya",
      "Christopher Montez",
      "Sivakumar Rathinam",
      "Swaroop Darbha",
      "David W. Casbeer",
      "Satyanarayana G. Manyam"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2204.00697"
  },
  {
    "id": "arXiv:2204.00988",
    "title": "Whose Advantage? Measuring Attention Dynamics across YouTube and Twitter  on Controversial Topics",
    "abstract": "Comments: Accepted into ICWSM 2022. 11-page main paper and 11-page appendix",
    "descriptor": "\nComments: Accepted into ICWSM 2022. 11-page main paper and 11-page appendix\n",
    "authors": [
      "JooYoung Lee",
      "Siqi Wu",
      "Ali Mert Ertugrul",
      "Yu-Ru Lin",
      "Lexing Xie"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2204.00988"
  },
  {
    "id": "arXiv:2204.01098",
    "title": "A sequence-to-sequence approach for document-level relation extraction",
    "abstract": "Comments: Camera-ready copy for BioNLP 2022 @ ACL 2022",
    "descriptor": "\nComments: Camera-ready copy for BioNLP 2022 @ ACL 2022\n",
    "authors": [
      "John Giorgi",
      "Gary D. Bader",
      "Bo Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.01098"
  },
  {
    "id": "arXiv:2204.01379",
    "title": "Taking ROCKET on an Efficiency Mission: Multivariate Time Series  Classification with LightWaveS",
    "abstract": "Comments: This work has been accepted as a short paper at DCOSS 2022",
    "descriptor": "\nComments: This work has been accepted as a short paper at DCOSS 2022\n",
    "authors": [
      "Leonardos Pantiskas",
      "Kees Verstoep",
      "Mark Hoogendoorn",
      "Henri Bal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.01379"
  },
  {
    "id": "arXiv:2204.01403",
    "title": "How stable are Transferability Metrics evaluations?",
    "abstract": "How stable are Transferability Metrics evaluations?",
    "descriptor": "",
    "authors": [
      "Andrea Agostinelli",
      "Michal P\u00e1ndy",
      "Jasper Uijlings",
      "Thomas Mensink",
      "Vittorio Ferrari"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.01403"
  },
  {
    "id": "arXiv:2204.01705",
    "title": "Learning to Accelerate by the Methods of Step-size Planning",
    "abstract": "Learning to Accelerate by the Methods of Step-size Planning",
    "descriptor": "",
    "authors": [
      "Hengshuai Yao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2204.01705"
  },
  {
    "id": "arXiv:2204.01950",
    "title": "Digital Twin Virtualization with Machine Learning for IoT and Beyond 5G  Networks: Research Directions for Security and Optimal Control",
    "abstract": "Comments: Accepted to ACM Workshop on Wireless Security and Machine Learning (WiseML), San Antonio, Texas, USA May, 2022",
    "descriptor": "\nComments: Accepted to ACM Workshop on Wireless Security and Machine Learning (WiseML), San Antonio, Texas, USA May, 2022\n",
    "authors": [
      "Jithin Jagannath",
      "Keyvan Ramezanpour",
      "Anu Jagannath"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.01950"
  },
  {
    "id": "arXiv:2204.02022",
    "title": "Towards Digital Twin-enabled DevOps for CPS providing Architecture-Based  Service Adaptation & Verification at Runtime",
    "abstract": "Comments: Final published version appearing in 17th Symposium on Software Engineering for Adaptive and Self-Managing Systems (SEAMS 2022)",
    "descriptor": "\nComments: Final published version appearing in 17th Symposium on Software Engineering for Adaptive and Self-Managing Systems (SEAMS 2022)\n",
    "authors": [
      "J\u00fcrgen Dobaj",
      "Andreas Riel",
      "Thomas Krug",
      "Matthias Seidl",
      "Georg Macher",
      "Markus Egretzberger"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2204.02022"
  },
  {
    "id": "arXiv:2204.02121",
    "title": "MetaAudio: A Few-Shot Audio Classification Benchmark",
    "abstract": "Comments: 9 pages with 1 figure and 2 main results tables. V1 Preprint",
    "descriptor": "\nComments: 9 pages with 1 figure and 2 main results tables. V1 Preprint\n",
    "authors": [
      "Calum Heggan",
      "Sam Budgett",
      "Timothy Hospedales",
      "Mehrdad Yaghoobi"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2204.02121"
  },
  {
    "id": "arXiv:2204.02129",
    "title": "Scalable global state synchronization of discrete-time double integrator  multi-agent systems with input saturation via linear protocol (Completed  Version)",
    "abstract": "Comments: This article is the complete version of the paper that was accepted by CCC 2022, Hefei China, July 25th-28th, 2022. arXiv admin note: text overlap with arXiv:1908.06535, arXiv:2004.13479",
    "descriptor": "\nComments: This article is the complete version of the paper that was accepted by CCC 2022, Hefei China, July 25th-28th, 2022. arXiv admin note: text overlap with arXiv:1908.06535, arXiv:2004.13479\n",
    "authors": [
      "Zhenwei Liu",
      "Ali Saberi",
      "Anton A. Stoorvogel"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2204.02129"
  },
  {
    "id": "arXiv:2204.02473",
    "title": "\"Does it come in black?\" CLIP-like models are zero-shot recommenders",
    "abstract": "Comments: Accepted at ACL 2022 (ECNLP)",
    "descriptor": "\nComments: Accepted at ACL 2022 (ECNLP)\n",
    "authors": [
      "Patrick John Chia",
      "Jacopo Tagliabue",
      "Federico Bianchi",
      "Ciro Greco",
      "Diogo Goncalves"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.02473"
  },
  {
    "id": "arXiv:2204.02627",
    "title": "Cluster Synchronization of Kuramoto Oscillators and Brain Functional  Connectivity",
    "abstract": "Cluster Synchronization of Kuramoto Oscillators and Brain Functional  Connectivity",
    "descriptor": "",
    "authors": [
      "Rui Kato",
      "Hideaki Ishii"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2204.02627"
  },
  {
    "id": "arXiv:2204.02793",
    "title": "The Challenge of Sixfold Integrals: The Closed-Form Evaluation of Newton  Potentials between Two Cubes",
    "abstract": "Comments: amendments and additions (notation, main theorem, applications, references); 24 pages; sources include Mathematica code (with supplementary material)",
    "descriptor": "\nComments: amendments and additions (notation, main theorem, applications, references); 24 pages; sources include Mathematica code (with supplementary material)\n",
    "authors": [
      "Folkmar Bornemann"
    ],
    "subjectives": [
      "Classical Analysis and ODEs (math.CA)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2204.02793"
  },
  {
    "id": "arXiv:2204.02855",
    "title": "SPIDER-WEB enables stable, repairable, and encryptible algorithms under  arbitrary local biochemical constraints in DNA-based storage",
    "abstract": "Comments: 30 pages; 12 figures; 2 tables",
    "descriptor": "\nComments: 30 pages; 12 figures; 2 tables\n",
    "authors": [
      "Haoling Zhang",
      "Zhaojun Lan",
      "Wenwei Zhang",
      "Xun Xu",
      "Zhi Ping",
      "Yiwei Zhang",
      "Yue Shen"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Information Theory (cs.IT)",
      "Combinatorics (math.CO)",
      "Genomics (q-bio.GN)"
    ],
    "url": "https://arxiv.org/abs/2204.02855"
  },
  {
    "id": "arXiv:2204.03039",
    "title": "DSGN++: Exploiting Visual-Spatial Relation for Stereo-based 3D Detectors",
    "abstract": "DSGN++: Exploiting Visual-Spatial Relation for Stereo-based 3D Detectors",
    "descriptor": "",
    "authors": [
      "Yilun Chen",
      "Shijia Huang",
      "Shu Liu",
      "Bei Yu",
      "Jiaya Jia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.03039"
  },
  {
    "id": "arXiv:2204.03216",
    "title": "Neural Implicit Flow: a mesh-agnostic dimensionality reduction paradigm  of spatio-temporal data",
    "abstract": "Comments: 56 pages",
    "descriptor": "\nComments: 56 pages\n",
    "authors": [
      "Shaowu Pan",
      "Steven L. Brunton",
      "J. Nathan Kutz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2204.03216"
  },
  {
    "id": "arXiv:2204.03410",
    "title": "Incremental Prototype Prompt-tuning with Pre-trained Representation for  Class Incremental Learning",
    "abstract": "Incremental Prototype Prompt-tuning with Pre-trained Representation for  Class Incremental Learning",
    "descriptor": "",
    "authors": [
      "Jieren Deng",
      "Jianhua Hu",
      "Haojian Zhang",
      "Yunkuan Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.03410"
  },
  {
    "id": "arXiv:2204.03484",
    "title": "Commitment games with conditional information revelation",
    "abstract": "Comments: Accepted at the Games, Agents, and Incentives Workshop at AAMAS 2022",
    "descriptor": "\nComments: Accepted at the Games, Agents, and Incentives Workshop at AAMAS 2022\n",
    "authors": [
      "Anthony DiGiovanni",
      "Jesse Clifton"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2204.03484"
  },
  {
    "id": "arXiv:2204.03589",
    "title": "Collecting, Classifying, Analyzing, and Using Real-World Elections",
    "abstract": "Collecting, Classifying, Analyzing, and Using Real-World Elections",
    "descriptor": "",
    "authors": [
      "Niclas Boehmer",
      "Nathan Schaar"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2204.03589"
  },
  {
    "id": "arXiv:2204.03632",
    "title": "The Effects of Regularization and Data Augmentation are Class Dependent",
    "abstract": "The Effects of Regularization and Data Augmentation are Class Dependent",
    "descriptor": "",
    "authors": [
      "Randall Balestriero",
      "Leon Bottou",
      "Yann LeCun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2204.03632"
  },
  {
    "id": "arXiv:2204.03688",
    "title": "DAD-3DHeads: A Large-scale Dense, Accurate and Diverse Dataset for 3D  Head Alignment from a Single Image",
    "abstract": "DAD-3DHeads: A Large-scale Dense, Accurate and Diverse Dataset for 3D  Head Alignment from a Single Image",
    "descriptor": "",
    "authors": [
      "Tetiana Martyniuk",
      "Orest Kupyn",
      "Yana Kurlyak",
      "Igor Krashenyi",
      "Ji\u0159i Matas",
      "Viktoriia Sharmanska"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.03688"
  },
  {
    "id": "arXiv:2204.03959",
    "title": "Blockchain as an Enabler for Transfer Learning in Smart Environments",
    "abstract": "Blockchain as an Enabler for Transfer Learning in Smart Environments",
    "descriptor": "",
    "authors": [
      "Amin Anjomshoaa",
      "Edward Curry"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.03959"
  },
  {
    "id": "arXiv:2204.03965",
    "title": "Scoring of Large-Margin Embeddings for Speaker Verification: Cosine or  PLDA?",
    "abstract": "Scoring of Large-Margin Embeddings for Speaker Verification: Cosine or  PLDA?",
    "descriptor": "",
    "authors": [
      "Qiongqiong Wang",
      "Kong Aik Lee",
      "Tianchi Liu"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2204.03965"
  },
  {
    "id": "arXiv:2204.03972",
    "title": "FashionCLIP: Connecting Language and Images for Product Representations",
    "abstract": "Comments: Code will soon be available at this https URL, dataset at this https URL",
    "descriptor": "\nComments: Code will soon be available at this https URL, dataset at this https URL\n",
    "authors": [
      "Patrick John Chia",
      "Giuseppe Attanasio",
      "Federico Bianchi",
      "Silvia Terragni",
      "Ana Rita Magalh\u00e3es",
      "Diogo Goncalves",
      "Ciro Greco",
      "Jacopo Tagliabue"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.03972"
  },
  {
    "id": "arXiv:2204.04055",
    "title": "Reliable Wireless Networking via Soft-Source Information Combining",
    "abstract": "Comments: 14 pages, 17 figures",
    "descriptor": "\nComments: 14 pages, 17 figures\n",
    "authors": [
      "Lihao Zhang",
      "Soung Chang Liew"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2204.04055"
  },
  {
    "id": "arXiv:2204.04090",
    "title": "Generative Adversarial Method Based on Neural Tangent Kernels",
    "abstract": "Generative Adversarial Method Based on Neural Tangent Kernels",
    "descriptor": "",
    "authors": [
      "Yu-Rong Zhang",
      "Sheng Yen Chou",
      "Shan-Hung Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.04090"
  },
  {
    "id": "arXiv:2204.04105",
    "title": "Improving LSHADE by means of a pre-screening mechanism",
    "abstract": "Comments: Accepted at Genetic and Evolutionary Computation Conference (GECCO'22)",
    "descriptor": "\nComments: Accepted at Genetic and Evolutionary Computation Conference (GECCO'22)\n",
    "authors": [
      "Mateusz Zaborski",
      "Jacek Ma\u0144dziuk"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2204.04105"
  },
  {
    "id": "arXiv:2204.04149",
    "title": "A Credible and Robust approach to Ego-Motion Estimation using an  Automotive Radar",
    "abstract": "Comments: In IEEE Robotics and Automation Letters",
    "descriptor": "\nComments: In IEEE Robotics and Automation Letters\n",
    "authors": [
      "Karim Haggag",
      "Sven Lange",
      "Tim Pfeifer",
      "Peter Protzel"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2204.04149"
  }
]
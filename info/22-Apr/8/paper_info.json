[
  {
    "id": "arXiv:2204.02970",
    "title": "Evolutionary Programmer: Autonomously Creating Path Planning Programs  based on Evolutionary Algorithms",
    "abstract": "Evolutionary algorithms are wildly used in unmanned aerial vehicle path\nplanning for their flexibility and effectiveness. Nevertheless, they are so\nsensitive to the change of environment that can't adapt to all scenarios. Due\nto this drawback, the previously successful planner frequently fail in a new\nscene. In this paper, a first-of-its-kind machine learning method named\nEvolutionary Programmer is proposed to solve this problem. Concretely, the most\ncommonly used Evolutionary Algorithms are decomposed into a series of\noperators, which constitute the operator library of the system. The new method\nrecompose the operators to a integrated planner, thus, the most suitable\noperators can be selected for adapting to the changing circumstances. Different\nfrom normal machine programmers, this method focuses on a specific task with\nhigh-level integrated instructions and thus alleviate the problem of huge\nsearch space caused by the briefness of instructions. On this basis, a 64-bit\nsequence is presented to represent path planner and then evolved with the\nmodified Genetic Algorithm. Finally, the most suitable planner is created by\nutilizing the information of the previous planner and various randomly\ngenerated ones.",
    "descriptor": "",
    "authors": [
      "Jiabin Lou",
      "Rong Ding",
      "Wenjun Wu"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.02970"
  },
  {
    "id": "arXiv:2204.02972",
    "title": "Multi-task nonparallel support vector machine for classification",
    "abstract": "Direct multi-task twin support vector machine (DMTSVM) explores the shared\ninformation between multiple correlated tasks, then it produces better\ngeneralization performance. However, it contains matrix inversion operation\nwhen solving the dual problems, so it costs much running time. Moreover, kernel\ntrick cannot be directly utilized in the nonlinear case. To effectively avoid\nabove problems, a novel multi-task nonparallel support vector machine (MTNPSVM)\nincluding linear and nonlinear cases is proposed in this paper. By introducing\nepsilon-insensitive loss instead of square loss in DMTSVM, MTNPSVM effectively\navoids matrix inversion operation and takes full advantage of the kernel trick.\nTheoretical implication of the model is further discussed. To further improve\nthe computational efficiency, the alternating direction method of multipliers\n(ADMM) is employed when solving the dual problem. The computational complexity\nand convergence of the algorithm are provided. In addition, the property and\nsensitivity of the parameter in model are further explored. The experimental\nresults on fifteen benchmark datasets and twelve image datasets demonstrate the\nvalidity of MTNPSVM in comparison with the state-of-the-art algorithms.\nFinally, it is applied to real Chinese Wine dataset, and also verifies its\neffectiveness.",
    "descriptor": "",
    "authors": [
      "Zongmin Liu",
      "Yitian Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.02972"
  },
  {
    "id": "arXiv:2204.02973",
    "title": "Incremental Unsupervised Feature Selection for Dynamic Incomplete  Multi-view Data",
    "abstract": "Multi-view unsupervised feature selection has been proven to be efficient in\nreducing the dimensionality of multi-view unlabeled data with high dimensions.\nThe previous methods assume all of the views are complete. However, in real\napplications, the multi-view data are often incomplete, i.e., some views of\ninstances are missing, which will result in the failure of these methods.\nBesides, while the data arrive in form of streams, these existing methods will\nsuffer the issues of high storage cost and expensive computation time. To\naddress these issues, we propose an Incremental Incomplete Multi-view\nUnsupervised Feature Selection method (I$^2$MUFS) on incomplete multi-view\nstreaming data. By jointly considering the consistent and complementary\ninformation across different views, I$^2$MUFS embeds the unsupervised feature\nselection into an extended weighted non-negative matrix factorization model,\nwhich can learn a consensus clustering indicator matrix and fuse different\nlatent feature matrices with adaptive view weights. Furthermore, we introduce\nthe incremental leaning mechanisms to develop an alternative iterative\nalgorithm, where the feature selection matrix is incrementally updated, rather\nthan recomputing on the entire updated data from scratch. A series of\nexperiments are conducted to verify the effectiveness of the proposed method by\ncomparing with several state-of-the-art methods. The experimental results\ndemonstrate the effectiveness and efficiency of the proposed method in terms of\nthe clustering metrics and the computational cost.",
    "descriptor": "",
    "authors": [
      "Yanyong Huang",
      "Kejun Guo",
      "Xiuwen Yi",
      "Zhong Li",
      "Tianrui Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.02973"
  },
  {
    "id": "arXiv:2204.02974",
    "title": "An Intelligent Framework for Oversubscription Management in CPU-GPU  Unified Memory",
    "abstract": "This paper proposes a novel intelligent framework for oversubscription\nmanagement in CPU-GPU UVM. We analyze the current rule-based methods of GPU\nmemory oversubscription with unified memory, and the current learning-based\nmethods for other computer architectural components. We then identify the\nperformance gap between the existing rule-based methods and the theoretical\nupper bound. We also identify the advantages of applying machine intelligence\nand the limitations of the existing learning-based methods. This paper proposes\na novel intelligent framework for oversubscription management in CPU-GPU UVM.\nIt consists of an access pattern classifier followed by a pattern-specific\nTransformer-based model using a novel loss function aiming for reducing page\nthrashing. A policy engine is designed to leverage the model's result to\nperform accurate page prefetching and pre-eviction. We evaluate our intelligent\nframework on a set of 11 memory-intensive benchmarks from popular benchmark\nsuites. Our solution outperforms the state-of-the-art (SOTA) methods for\noversubscription management, reducing the number of pages thrashed by 64.4\\%\nunder 125\\% memory oversubscription compared to the baseline, while the SOTA\nmethod reduces the number of pages thrashed by 17.3\\%. Our solution achieves an\naverage IPC improvement of 1.52X under 125\\% memory oversubscription, and our\nsolution achieves an average IPC improvement of 3.66X under 150\\% memory\noversubscription. Our solution outperforms the existing learning-based methods\nfor page address prediction, improving top-1 accuracy by 6.45\\% (up to 41.2\\%)\non average for a single GPGPU workload, improving top-1 accuracy by 10.2\\% (up\nto 30.2\\%) on average for multiple concurrent GPGPU workloads.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2203.12672\n",
    "authors": [
      "Xinjian Long",
      "Xiangyang Gong",
      "Huiyang Zhou"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2204.02974"
  },
  {
    "id": "arXiv:2204.02980",
    "title": "Analysis of Different Losses for Deep Learning Image Colorization",
    "abstract": "Image colorization aims to add color information to a grayscale image in a\nrealistic way. Recent methods mostly rely on deep learning strategies. While\nlearning to automatically colorize an image, one can define well-suited\nobjective functions related to the desired color output. Some of them are based\non a specific type of error between the predicted image and ground truth one,\nwhile other losses rely on the comparison of perceptual properties. But, is the\nchoice of the objective function that crucial, i.e., does it play an important\nrole in the results? In this chapter, we aim to answer this question by\nanalyzing the impact of the loss function on the estimated colorization\nresults. To that goal, we review the different losses and evaluation metrics\nthat are used in the literature. We then train a baseline network with several\nof the reviewed objective functions: classic L1 and L2 losses, as well as more\ncomplex combinations such as Wasserstein GAN and VGG-based LPIPS loss.\nQuantitative results show that the models trained with VGG-based LPIPS provide\noverall slightly better results for most evaluation metrics. Qualitative\nresults exhibit more vivid colors when with Wasserstein GAN plus the L2 loss or\nagain with the VGG-based LPIPS. Finally, the convenience of quantitative user\nstudies is also discussed to overcome the difficulty of properly assessing on\ncolorized images, notably for the case of old archive photographs where no\nground truth is available.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2204.02850\n",
    "authors": [
      "Coloma Ballester",
      "Aur\u00e9lie Bugeau",
      "Hernan Carrillo",
      "Micha\u00ebl Cl\u00e9ment",
      "R\u00e9mi Giraud",
      "Lara Raad",
      "Patricia Vitoria"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.02980"
  },
  {
    "id": "arXiv:2204.03017",
    "title": "Learning from Untrimmed Videos: Self-Supervised Video Representation  Learning with Hierarchical Consistency",
    "abstract": "Natural videos provide rich visual contents for self-supervised learning. Yet\nmost existing approaches for learning spatio-temporal representations rely on\nmanually trimmed videos, leading to limited diversity in visual patterns and\nlimited performance gain. In this work, we aim to learn representations by\nleveraging more abundant information in untrimmed videos. To this end, we\npropose to learn a hierarchy of consistencies in videos, i.e., visual\nconsistency and topical consistency, corresponding respectively to clip pairs\nthat tend to be visually similar when separated by a short time span and share\nsimilar topics when separated by a long time span. Specifically, a hierarchical\nconsistency learning framework HiCo is presented, where the visually consistent\npairs are encouraged to have the same representation through contrastive\nlearning, while the topically consistent pairs are coupled through a topical\nclassifier that distinguishes whether they are topic related. Further, we\nimpose a gradual sampling algorithm for proposed hierarchical consistency\nlearning, and demonstrate its theoretical superiority. Empirically, we show\nthat not only HiCo can generate stronger representations on untrimmed videos,\nit also improves the representation quality when applied to trimmed videos.\nThis is in contrast to standard contrastive learning that fails to learn\nappropriate representations from untrimmed videos.",
    "descriptor": "\nComments: CVPR2022; Project page is: this https URL\n",
    "authors": [
      "Zhiwu Qing",
      "Shiwei Zhang",
      "Ziyuan Huang",
      "Yi Xu",
      "Xiang Wang",
      "Mingqian Tang",
      "Changxin Gao",
      "Rong Jin",
      "Nong Sang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.03017"
  },
  {
    "id": "arXiv:2204.03021",
    "title": "The Moral Integrity Corpus: A Benchmark for Ethical Dialogue Systems",
    "abstract": "Conversational agents have come increasingly closer to human competence in\nopen-domain dialogue settings; however, such models can reflect insensitive,\nhurtful, or entirely incoherent viewpoints that erode a user's trust in the\nmoral integrity of the system. Moral deviations are difficult to mitigate\nbecause moral judgments are not universal, and there may be multiple competing\njudgments that apply to a situation simultaneously. In this work, we introduce\na new resource, not to authoritatively resolve moral ambiguities, but instead\nto facilitate systematic understanding of the intuitions, values and moral\njudgments reflected in the utterances of dialogue systems. The Moral Integrity\nCorpus, MIC, is such a resource, which captures the moral assumptions of 38k\nprompt-reply pairs, using 99k distinct Rules of Thumb (RoTs). Each RoT reflects\na particular moral conviction that can explain why a chatbot's reply may appear\nacceptable or problematic. We further organize RoTs with a set of 9 moral and\nsocial attributes and benchmark performance for attribute classification. Most\nimportantly, we show that current neural language models can automatically\ngenerate new RoTs that reasonably describe previously unseen interactions, but\nthey still struggle with certain scenarios. Our findings suggest that MIC will\nbe a useful resource for understanding and language models' implicit moral\nassumptions and flexibly benchmarking the integrity of conversational agents.\nTo download the data, see https://github.com/GT-SALT/mic",
    "descriptor": "\nComments: ACL 2022 main conference\n",
    "authors": [
      "Caleb Ziems",
      "Jane A. Yu",
      "Yi-Chia Wang",
      "Alon Halevy",
      "Diyi Yang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.03021"
  },
  {
    "id": "arXiv:2204.03025",
    "title": "Using Interactive Feedback to Improve the Accuracy and Explainability of  Question Answering Systems Post-Deployment",
    "abstract": "Most research on question answering focuses on the pre-deployment stage;\ni.e., building an accurate model for deployment. In this paper, we ask the\nquestion: Can we improve QA systems further \\emph{post-}deployment based on\nuser interactions? We focus on two kinds of improvements: 1) improving the QA\nsystem's performance itself, and 2) providing the model with the ability to\nexplain the correctness or incorrectness of an answer. We collect a\nretrieval-based QA dataset, FeedbackQA, which contains interactive feedback\nfrom users. We collect this dataset by deploying a base QA system to\ncrowdworkers who then engage with the system and provide feedback on the\nquality of its answers. The feedback contains both structured ratings and\nunstructured natural language explanations. We train a neural model with this\nfeedback data that can generate explanations and re-score answer candidates. We\nshow that feedback data not only improves the accuracy of the deployed QA\nsystem but also other stronger non-deployed systems. The generated explanations\nalso help users make informed decisions about the correctness of answers.\nProject page: https://mcgill-nlp.github.io/feedbackqa/",
    "descriptor": "\nComments: ACL 2022 Findings\n",
    "authors": [
      "Zichao Li",
      "Prakhar Sharma",
      "Xing Han Lu",
      "Jackie C.K. Cheung",
      "Siva Reddy"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.03025"
  },
  {
    "id": "arXiv:2204.03027",
    "title": "Federated Learning for Distributed Spectrum Sensing in NextG  Communication Networks",
    "abstract": "NextG networks are intended to provide the flexibility of sharing the\nspectrum with incumbent users and support various spectrum monitoring tasks\nsuch as anomaly detection, fault diagnostics, user equipment identification,\nand authentication. A network of wireless sensors is needed to monitor the\nspectrum for signal transmissions of interest over a large deployment area.\nEach sensor receives signals under a specific channel condition depending on\nits location and trains an individual model of a deep neural network (DNN)\naccordingly to classify signals. To improve the accuracy, individual sensors\nmay exchange sensing data or sensor results with each other or with a fusion\ncenter (such as in cooperative spectrum sensing). In this paper, distributed\nfederated learning over a multi-hop wireless network is considered to\ncollectively train a DNN for signal identification. In distributed federated\nlearning, each sensor broadcasts its trained model to its neighbors, collects\nthe DNN models from its neighbors, and aggregates them to initialize its own\nmodel for the next round of training. Without exchanging any spectrum data,\nthis process is repeated over time such that a common DNN is built across the\nnetwork while preserving the privacy associated with signals collected at\ndifferent locations. Signal classification accuracy and convergence time are\nevaluated for different network topologies (including line, star, ring, grid,\nand random networks) and packet loss events. Then, the reduction of\ncommunication overhead and energy consumption is considered with random\nparticipation of sensors in model updates. The results show the feasibility of\nextending cooperative spectrum sensing over a general multi-hop wireless\nnetwork through federated learning and indicate its robustness to wireless\nnetwork effects, thereby sustaining high accuracy with low communication\noverhead and energy consumption.",
    "descriptor": "",
    "authors": [
      "Yi Shi",
      "Yalin E. Sagduyu",
      "Tugba Erpek"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.03027"
  },
  {
    "id": "arXiv:2204.03028",
    "title": "Software Testing, AI and Robotics (STAIR) Learning Lab",
    "abstract": "In this paper we presented the Software Testing, AI and Robotics (STAIR)\nLearning Lab. STAIR is an initiative started at the University of Innsbruck to\nbring robotics, Artificial Intelligence (AI) and software testing into schools.\nIn the lab physical and virtual learning units are developed in parallel and in\nsync with each other. Its core learning approach is based the develop of both a\nphysical and simulated robotics environment. In both environments AI scenarios\n(like traffic sign recognition) are deployed and tested. We present and focus\non our newly designed MiniBot that are both built on hardware which was\ndesigned for educational and research purposes as well as the simulation\nenvironment. Additionally, we describe first learning design concepts and a\nshowcase scenario (i.e., AI-based traffic sign recognition) with different\nexercises which can easily be extended.",
    "descriptor": "\nComments: 8 pages, 5 figures, Accepted at the Robotics in Education (RiE2022) Conference\n",
    "authors": [
      "Simon Haller-Seeber",
      "Thomas Gatterer",
      "Patrick Hofmann",
      "Christopher Kelter",
      "Thomas Auer",
      "Michael Felderer"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2204.03028"
  },
  {
    "id": "arXiv:2204.03030",
    "title": "Statistical Model Criticism of Variational Auto-Encoders",
    "abstract": "We propose a framework for the statistical evaluation of variational\nauto-encoders (VAEs) and test two instances of this framework in the context of\nmodelling images of handwritten digits and a corpus of English text. Our take\non evaluation is based on the idea of statistical model criticism, popular in\nBayesian data analysis, whereby a statistical model is evaluated in terms of\nits ability to reproduce statistics of an unknown data generating process from\nwhich we can obtain samples. A VAE learns not one, but two joint distributions\nover a shared sample space, each exploiting a choice of factorisation that\nmakes sampling tractable in one of two directions (latent-to-data,\ndata-to-latent). We evaluate samples from these distributions, assessing their\n(marginal) fit to the observed data and our choice of prior, and we also\nevaluate samples through a pipeline that connects the two distributions\nstarting from a data sample, assessing whether together they exploit and reveal\nlatent factors of variation that are useful to a practitioner. We show that\nthis methodology offers possibilities for model selection qualitatively beyond\nintrinsic evaluation metrics and at a finer granularity than commonly used\nstatistics can offer.",
    "descriptor": "",
    "authors": [
      "Claartje Barkhof",
      "Wilker Aziz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2204.03030"
  },
  {
    "id": "arXiv:2204.03031",
    "title": "VALUE: Understanding Dialect Disparity in NLU",
    "abstract": "English Natural Language Understanding (NLU) systems have achieved great\nperformances and even outperformed humans on benchmarks like GLUE and\nSuperGLUE. However, these benchmarks contain only textbook Standard American\nEnglish (SAE). Other dialects have been largely overlooked in the NLP\ncommunity. This leads to biased and inequitable NLU systems that serve only a\nsub-population of speakers. To understand disparities in current models and to\nfacilitate more dialect-competent NLU systems, we introduce the VernAcular\nLanguage Understanding Evaluation (VALUE) benchmark, a challenging variant of\nGLUE that we created with a set of lexical and morphosyntactic transformation\nrules. In this initial release (V.1), we construct rules for 11 features of\nAfrican American Vernacular English (AAVE), and we recruit fluent AAVE speakers\nto validate each feature transformation via linguistic acceptability judgments\nin a participatory design manner. Experiments show that these new dialectal\nfeatures can lead to a drop in model performance.",
    "descriptor": "\nComments: ACL 2022 main conference\n",
    "authors": [
      "Caleb Ziems",
      "Jiaao Chen",
      "Camille Harris",
      "Jessica Anderson",
      "Diyi Yang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.03031"
  },
  {
    "id": "arXiv:2204.03032",
    "title": "Benchmarking Apache Arrow Flight -- A wire-speed protocol for data  transfer, querying and microservices",
    "abstract": "Moving structured data between different big data frameworks and/or data\nwarehouses/storage systems often cause significant overhead. Most of the time\nmore than 80\\% of the total time spent in accessing data is elapsed in\nserialization/de-serialization step. Columnar data formats are gaining\npopularity in both analytics and transactional databases. Apache Arrow, a\nunified columnar in-memory data format promises to provide efficient data\nstorage, access, manipulation and transport. In addition, with the introduction\nof the Arrow Flight communication capabilities, which is built on top of gRPC,\nArrow enables high performance data transfer over TCP networks. Arrow Flight\nallows parallel Arrow RecordBatch transfer over networks in a platform and\nlanguage-independent way, and offers high performance, parallelism and security\nbased on open-source standards.\nIn this paper, we bring together some recently implemented use cases of Arrow\nFlight with their benchmarking results. These use cases include bulk Arrow data\ntransfer, querying subsystems and Flight as a microservice integration into\ndifferent frameworks to show the throughput and scalability results of this\nprotocol. We show that Flight is able to achieve up to 6000 MB/s and 4800 MB/s\nthroughput for DoGet() and DoPut() operations respectively. On Mellanox\nConnectX-3 or Connect-IB interconnect nodes Flight can utilize upto 95\\% of the\ntotal available bandwidth. Flight is scalable and can use upto half of the\navailable system cores efficiently for a bidirectional communication. For query\nsystems like Dremio, Flight is order of magnitude faster than ODBC and turbodbc\nprotocols. Arrow Flight based implementation on Dremio performs 20x and 30x\nbetter as compared to turbodbc and ODBC connections respectively.",
    "descriptor": "",
    "authors": [
      "Tanveer Ahmad",
      "Zaid Al Ars",
      "H. Peter Hofstee"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Databases (cs.DB)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2204.03032"
  },
  {
    "id": "arXiv:2204.03035",
    "title": "Hierarchical Annotation for Building A Suite of Clinical Natural  Language Processing Tasks: Progress Note Understanding",
    "abstract": "Applying methods in natural language processing on electronic health records\n(EHR) data is a growing field. Existing corpus and annotation focus on modeling\ntextual features and relation prediction. However, there is a paucity of\nannotated corpus built to model clinical diagnostic thinking, a process\ninvolving text understanding, domain knowledge abstraction and reasoning. This\nwork introduces a hierarchical annotation schema with three stages to address\nclinical text understanding, clinical reasoning, and summarization. We created\nan annotated corpus based on an extensive collection of publicly available\ndaily progress notes, a type of EHR documentation that is collected in time\nseries in a problem-oriented format. The conventional format for a progress\nnote follows a Subjective, Objective, Assessment and Plan heading (SOAP). We\nalso define a new suite of tasks, Progress Note Understanding, with three tasks\nutilizing the three annotation stages. The novel suite of tasks was designed to\ntrain and evaluate future NLP models for clinical text understanding, clinical\nknowledge representation, inference, and summarization.",
    "descriptor": "\nComments: To appear in 13th Language Resources and Evaluation Conference (LREC 2022)\n",
    "authors": [
      "Yanjun Gao",
      "Dmitriy Dligach",
      "Timothy Miller",
      "Samuel Tesch",
      "Ryan Laffin",
      "Matthew M. Churpek",
      "Majid Afshar"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2204.03035"
  },
  {
    "id": "arXiv:2204.03038",
    "title": "Safe Interactive Industrial Robots using Jerk-based Safe Set Algorithm",
    "abstract": "The need to increase the flexibility of production lines is calling for\nrobots to collaborate with human workers. However, existing interactive\nindustrial robots only guarantee intrinsic safety (reduce collision impact),\nbut not interactive safety (collision avoidance), which greatly limited their\nflexibility. The issue arises from two limitations in existing control software\nfor industrial robots: 1) lack of support for real-time trajectory\nmodification; 2) lack of intelligent safe control algorithms with guaranteed\ncollision avoidance under robot dynamics constraints. To address the first\nissue, a jerk-bounded position controller (JPC) was developed previously. This\npaper addresses the second limitation, on top of the JPC. Specifically, we\nintroduce a jerk-based safe set algorithm (JSSA) to ensure collision avoidance\nwhile considering the robot dynamics constraints. The JSSA greatly extends the\nscope of the original safe set algorithm, which has only been applied for\nsecond-order systems with unbounded accelerations. The JSSA is implemented on\nthe FANUC LR Mate 200id/7L robot and validated with HRI tasks. Experiments show\nthat the JSSA can consistently keep the robot at a safe distance from the human\nwhile executing the designated task.",
    "descriptor": "",
    "authors": [
      "Ruixuan Liu",
      "Rui Chen",
      "Changliu Liu"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2204.03038"
  },
  {
    "id": "arXiv:2204.03039",
    "title": "DSGN++: Exploiting Visual-Spatial Relation forStereo-based 3D Detectors",
    "abstract": "Camera-based 3D object detectors are welcome due to their wider deployment\nand lower price than LiDAR sensors. We revisit the prior stereo modeling DSGN\nabout the stereo volume constructions for representing both 3D geometry and\nsemantics. We polish the stereo modeling and propose our approach, DSGN++,\naiming for improving information flow throughout the 2D-to-3D pipeline in the\nfollowing three main aspects. First, to effectively lift the 2D information to\nstereo volume, we propose depth-wise plane sweeping (DPS) that allows denser\nconnections and extracts depth-guided features. Second, for better grasping\ndifferently spaced features, we present a novel stereo volume -- Dual-view\nStereo Volume (DSV) that integrates front-view and top-view features and\nreconstructs sub-voxel depth in the camera frustum. Third, as the foreground\nregion becomes less dominant in 3D space, we firstly propose a multi-modal data\nediting strategy -- Stereo-LiDAR Copy-Paste, which ensures cross-modal\nalignment and improves data efficiency. Without bells and whistles, extensive\nexperiments in various modality setups on the popular KITTI benchmark show that\nour method consistently outperforms other camera-based 3D detectors for all\ncategories. Code will be released at https://github.com/chenyilun95/DSGN2.",
    "descriptor": "",
    "authors": [
      "Yilun Chen",
      "Shijia Huang",
      "Shu Liu",
      "Bei Yu",
      "Jiaya Jia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.03039"
  },
  {
    "id": "arXiv:2204.03040",
    "title": "SOMOS: The Samsung Open MOS Dataset for the Evaluation of Neural  Text-to-Speech Synthesis",
    "abstract": "In this work, we present the SOMOS dataset, the first large-scale mean\nopinion scores (MOS) dataset consisting of solely neural text-to-speech (TTS)\nsamples. It can be employed to train automatic MOS prediction systems focused\non the assessment of modern synthesizers, and can stimulate advancements in\nacoustic model evaluation. It consists of 20K synthetic utterances of the LJ\nSpeech voice, a public domain speech dataset which is a common benchmark for\nbuilding neural acoustic models and vocoders. Utterances are generated from 200\nTTS systems including vanilla neural acoustic models as well as models which\nallow prosodic variations. An LPCNet vocoder is used for all systems, so that\nthe samples' variation depends only on the acoustic models. The synthesized\nutterances provide balanced and adequate domain and length coverage. We collect\nMOS naturalness evaluations on 3 English Amazon Mechanical Turk locales and\nshare practices leading to reliable crowdsourced annotations for this task.\nBaseline results of state-of-the-art MOS prediction models on the SOMOS dataset\nare presented, while we show the challenges that such models face when assigned\nto evaluate synthetic utterances.",
    "descriptor": "\nComments: Submitted to INTERSPEECH 2022\n",
    "authors": [
      "Georgia Maniati",
      "Alexandra Vioni",
      "Nikolaos Ellinas",
      "Karolos Nikitaras",
      "Konstantinos Klapsas",
      "June Sig Sung",
      "Gunu Jho",
      "Aimilios Chalamandaris",
      "Pirros Tsiakoulis"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2204.03040"
  },
  {
    "id": "arXiv:2204.03042",
    "title": "FFC-SE: Fast Fourier Convolution for Speech Enhancement",
    "abstract": "Fast Fourier convolution (FFC) is the recently proposed neural operator\nshowing promising performance in several computer vision problems. The FFC\noperator allows employing large receptive field operations within early layers\nof the neural network. It was shown to be especially helpful for inpainting of\nperiodic structures which are common in audio processing. In this work, we\ndesign neural network architectures which adapt FFC for speech enhancement. We\nhypothesize that a large receptive field allows these networks to produce more\ncoherent phases than vanilla convolutional models, and validate this hypothesis\nexperimentally. We found that neural networks based on Fast Fourier convolution\noutperform analogous convolutional models and show better or comparable results\nwith other speech enhancement baselines.",
    "descriptor": "\nComments: Submitted to INTERSPEECH 2022\n",
    "authors": [
      "Ivan Shchekotov",
      "Pavel Andreev",
      "Oleg Ivanov",
      "Aibek Alanov",
      "Dmitry Vetrov"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2204.03042"
  },
  {
    "id": "arXiv:2204.03044",
    "title": "Fusing finetuned models for better pretraining",
    "abstract": "Pretrained models are the standard starting point for training. This approach\nconsistently outperforms the use of a random initialization. However,\npretraining is a costly endeavour that few can undertake.\nIn this paper, we create better base models at hardly any cost, by fusing\nmultiple existing fine tuned models into one. Specifically, we fuse by\naveraging the weights of these models. We show that the fused model results\nsurpass the pretrained model ones. We also show that fusing is often better\nthan intertraining.\nWe find that fusing is less dependent on the target task. Furthermore, weight\ndecay nullifies intertraining effects but not those of fusing.",
    "descriptor": "",
    "authors": [
      "Leshem Choshen",
      "Elad Venezian",
      "Noam Slonim",
      "Yoav Katz"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.03044"
  },
  {
    "id": "arXiv:2204.03046",
    "title": "Effective Exposure Amortizing for Fair Top-k Recommendation",
    "abstract": "Result ranking often affects customer satisfaction as well as the amount of\nexposure each product receives in recommendation systems (RecSys). Myopically\nmaximizing customer satisfaction by ranking products only according to\nrelevance will lead to unfair distribution of exposure for products, followed\nby unfair opportunities and economic gains for product producers. This\nunfairness will force producers to leave the system, and discourage new\nproducers from coming in. Eventually, fewer purchase options would be left for\ncustomers and the overall transaction rates on e-commerce platforms would\ndecrease. Thus, how to maintain a balance between ranking relevance and\nfairness is important to both producers and customers. In this paper, we focus\non the task of exposure fairness in offline recommendation settings. We\ndemonstrate that existing methods for amortized fairness optimization are\nsuboptimal for offline recommendation because they fail to utilize the prior\nknowledge of customers. We further propose a novel fair recommendation\nalgorithm to reach a better balance between exposure fairness and\nrecommendation performance. Extensive experiments on three real-world datasets\ndemonstrate that our method significantly outperforms the state-of-the-art fair\nranking algorithm in terms of fairness-performance trade off from both\nindividual level and group level.",
    "descriptor": "\nComments: 10 pages, 3 figures\n",
    "authors": [
      "Tao Yang",
      "Zhichao Xu",
      "Qingyao Ai"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2204.03046"
  },
  {
    "id": "arXiv:2204.03051",
    "title": "Perceive, Represent, Generate: Translating Multimodal Information to  Robotic Motion Trajectories",
    "abstract": "We present Perceive-Represent-Generate (PRG), a novel three-stage framework\nthat maps perceptual information of different modalities (e.g., visual or\nsound), corresponding to a sequence of instructions, to an adequate sequence of\nmovements to be executed by a robot. In the first stage, we perceive and\npre-process the given inputs, isolating individual commands from the complete\ninstruction provided by a human user. In the second stage we encode the\nindividual commands into a multimodal latent space, employing a deep generative\nmodel. Finally, in the third stage we convert the multimodal latent values into\nindividual trajectories and combine them into a single dynamic movement\nprimitive, allowing its execution in a robotic platform. We evaluate our\npipeline in the context of a novel robotic handwriting task, where the robot\nreceives as input a word through different perceptual modalities (e.g., image,\nsound), and generates the corresponding motion trajectory to write it, creating\ncoherent and readable handwritten words.",
    "descriptor": "\nComments: 6 pages, 3 figures, 2 tables\n",
    "authors": [
      "F\u00e1bio Vital",
      "Miguel Vasco",
      "Alberto Sardinha",
      "Francisco Melo"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.03051"
  },
  {
    "id": "arXiv:2204.03057",
    "title": "Thermal to Visible Image Synthesis under Atmospheric Turbulence",
    "abstract": "In many practical applications of long-range imaging such as biometrics and\nsurveillance, thermal imagining modalities are often used to capture images in\nlow-light and nighttime conditions. However, such imaging systems often suffer\nfrom atmospheric turbulence, which introduces severe blur and deformation\nartifacts to the captured images. Such an issue is unavoidable in long-range\nimaging and significantly decreases the face verification accuracy. In this\npaper, we first investigate the problem with a turbulence simulation method on\nreal-world thermal images. An end-to-end reconstruction method is then proposed\nwhich can directly transform thermal images into visible-spectrum images by\nutilizing natural image priors based on a pre-trained StyleGAN2 network.\nCompared with the existing two-steps methods of consecutive turbulence\nmitigation and thermal to visible image translation, our method is demonstrated\nto be effective in terms of both the visual quality of the reconstructed\nresults and face verification accuracy. Moreover, to the best of our knowledge,\nthis is the first work that studies the problem of thermal to visible image\ntranslation under atmospheric turbulence.",
    "descriptor": "\nComments: 4 pages, 3 figures\n",
    "authors": [
      "Kangfu Mei",
      "Yiqun Mei",
      "Vishal M. Patel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.03057"
  },
  {
    "id": "arXiv:2204.03059",
    "title": "Semantic Sensor Network Ontology based Decision Support System for  Forest Fire Management",
    "abstract": "The forests are significant assets for every country. When it gets destroyed,\nit may negatively impact the environment, and forest fire is one of the primary\ncauses. Fire weather indices are widely used to measure fire danger and are\nused to issue bushfire warnings. It can also be used to predict the demand for\nemergency management resources. Sensor networks have grown in popularity in\ndata collection and processing capabilities for a variety of applications in\nindustries such as medical, environmental monitoring, home automation etc.\nSemantic sensor networks can collect various climatic circumstances like wind\nspeed, temperature, and relative humidity. However, estimating fire weather\nindices is challenging due to the various issues involved in processing the\ndata streams generated by the sensors. Hence, the importance of forest fire\ndetection has increased day by day. The underlying Semantic Sensor Network\n(SSN) ontologies are built to allow developers to create rules for calculating\nfire weather indices and also the convert dataset into Resource Description\nFramework (RDF). This research describes the various steps involved in\ndeveloping rules for calculating fire weather indices. Besides, this work\npresents a Web-based mapping interface to help users visualize the changes in\nfire weather indices over time. With the help of the inference rule, it\ndesigned a decision support system using the SSN ontology and query on it\nthrough SPARQL. The proposed fire management system acts according to the\nsituation, supports reasoning and the general semantics of the open-world\nfollowed by all the ontologies",
    "descriptor": "\nComments: Ontology and Semantic Modeling\n",
    "authors": [
      "Ritesh Chandra",
      "Sonali Agarwal",
      "Navjot Singh"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2204.03059"
  },
  {
    "id": "arXiv:2204.03061",
    "title": "Standardized feature extraction from pairwise conflicts applied to the  train rescheduling problem",
    "abstract": "We propose a train rescheduling algorithm which applies a standardized\nfeature selection based on pairwise conflicts in order to serve as input for\nthe reinforcement learning framework. We implement an analytical method which\nidentifies and optimally solves every conflict arising between two trains, then\nwe design a corresponding observation space which features the most relevant\ninformation considering these conflicts. The data obtained this way then\ntranslates to actions in the context of the reinforcement learning framework.\nWe test our preliminary model using the evaluation metrics of the Flatland\nChallenge. The empirical results indicate that the suggested feature space\nprovides meaningful observations, from which a sensible scheduling policy can\nbe learned.",
    "descriptor": "\nComments: 20th Jubilee World Symposium on Applied Machine Intelligence and Informatics (SAMI), Poprad, Slovakia, March 2-5, 2022\n",
    "authors": [
      "Anik\u00f3 Kopacz",
      "\u00c1gnes Mester",
      "S\u00e1ndor Kolumb\u00e1n",
      "Csat\u00f3 Lehel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.03061"
  },
  {
    "id": "arXiv:2204.03062",
    "title": "Abusive and Threatening Language Detection in Urdu using Supervised  Machine Learning and Feature Combinations",
    "abstract": "This paper presents the system descriptions submitted at the FIRE Shared Task\n2021 on Urdu's Abusive and Threatening Language Detection Task. This challenge\naims at automatically identifying abusive and threatening tweets written in\nUrdu. Our submitted results were selected for the third recognition at the\ncompetition. This paper reports a non-exhaustive list of experiments that\nallowed us to reach the submitted results. Moreover, after the result\ndeclaration of the competition, we managed to attain even better results than\nthe submitted results. Our models achieved 0.8318 F1 score on Task A (Abusive\nLanguage Detection for Urdu Tweets) and 0.4931 F1 score on Task B (Threatening\nLanguage Detection for Urdu Tweets). Results show that Support Vector Machines\nwith stopwords removed, lemmatization applied, and features vector created by\nthe combinations of word n-grams for n=1,2,3 produced the best results for Task\nA. For Task B, Support Vector Machines with stopwords removed, lemmatization\nnot applied, feature vector created from a pre-trained Urdu Word2Vec (on word\nunigrams and bigrams), and making the dataset balanced using oversampling\ntechnique produced the best results. The code is made available for\nreproducibility.",
    "descriptor": "\nComments: Accepted in FIRE'21 (Track Abusive and Threatening Language Detection Task in Urdu). Forum for Information Retrieval Evaluation, December 13-17, 2021, India\n",
    "authors": [
      "Muhammad Humayoun"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.03062"
  },
  {
    "id": "arXiv:2204.03063",
    "title": "Late multimodal fusion for image and audio music transcription",
    "abstract": "Music transcription, which deals with the conversion of music sources into a\nstructured digital format, is a key problem for Music Information Retrieval\n(MIR). When addressing this challenge in computational terms, the MIR community\nfollows two lines of research: music documents, which is the case of Optical\nMusic Recognition (OMR), or audio recordings, which is the case of Automatic\nMusic Transcription (AMT). The different nature of the aforementioned input\ndata has conditioned these fields to develop modality-specific frameworks.\nHowever, their recent definition in terms of sequence labeling tasks leads to a\ncommon output representation, which enables research on a combined paradigm. In\nthis respect, multimodal image and audio music transcription comprises the\nchallenge of effectively combining the information conveyed by image and audio\nmodalities. In this work, we explore this question at a late-fusion level: we\nstudy four combination approaches in order to merge, for the first time, the\nhypotheses regarding end-to-end OMR and AMT systems in a lattice-based search\nspace. The results obtained for a series of performance scenarios -- in which\nthe corresponding single-modality models yield different error rates -- showed\ninteresting benefits of these approaches. In addition, two of the four\nstrategies considered significantly improve the corresponding unimodal standard\nrecognition frameworks.",
    "descriptor": "\nComments: Submitted to IEEE/ACM Transactions on Audio Speech and Language Processing\n",
    "authors": [
      "Mar\u00eda Alfaro-Contreras",
      "Jose J. Valero-Mas",
      "Jos\u00e9 M. I\u00f1esta",
      "Jorge Calvo-Zaragoza"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Retrieval (cs.IR)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2204.03063"
  },
  {
    "id": "arXiv:2204.03064",
    "title": "The 2021 Urdu Fake News Detection Task using Supervised Machine Learning  and Feature Combinations",
    "abstract": "This paper presents the system description submitted at the FIRE Shared Task:\n\"The 2021 Fake News Detection in the Urdu Language\". This challenge aims at\nautomatically identifying Fake news written in Urdu. Our submitted results\nranked fifth in the competition. However, after the result declaration of the\ncompetition, we managed to attain even better results than the submitted\nresults. The best F1 Macro score achieved by one of our models is 0.6674,\nhigher than the second-best score in the competition. The result is achieved on\nSupport Vector Machines (polynomial kernel degree 1) with stopwords removed,\nlemmatization applied, and selecting the 20K best features out of 1.557 million\nfeatures in total (which were produced by Word n-grams n=1,2,3,4 and Char\nn-grams n=2,3,4,5,6). The code is made available for reproducibility.",
    "descriptor": "\nComments: Accepted in FIRE'21 (Track Abusive and Threatening Language Detection Task in Urdu). Forum for Information Retrieval Evaluation, December 13-17, 2021, India\n",
    "authors": [
      "Muhammad Humayoun"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.03064"
  },
  {
    "id": "arXiv:2204.03065",
    "title": "The Self-Optimal-Transport Feature Transform",
    "abstract": "The Self-Optimal-Transport (SOT) feature transform is designed to upgrade the\nset of features of a data instance to facilitate downstream matching or\ngrouping related tasks. The transformed set encodes a rich representation of\nhigh order relations between the instance features. Distances between\ntransformed features capture their direct original similarity and their third\nparty agreement regarding similarity to other features in the set. A particular\nmin-cost-max-flow fractional matching problem, whose entropy regularized\nversion can be approximated by an optimal transport (OT) optimization, results\nin our transductive transform which is efficient, differentiable, equivariant,\nparameterless and probabilistically interpretable. Empirically, the transform\nis highly effective and flexible in its use, consistently improving networks it\nis inserted into, in a variety of tasks and training schemes. We demonstrate\nits merits through the problem of unsupervised clustering and its efficiency\nand wide applicability for few-shot-classification, with state-of-the-art\nresults, and large-scale person re-identification.",
    "descriptor": "",
    "authors": [
      "Daniel Shalam",
      "Simon Korman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.03065"
  },
  {
    "id": "arXiv:2204.03066",
    "title": "The Impact of Remote Pair Programming in an Upper-Level CS Course",
    "abstract": "Pair programming has been highlighted as an active learning technique with\nseveral benefits to students, including increasing participation and improving\noutcomes, particularly for female computer science students. However, most of\nthe literature highlights the effects of pair programming in introductory\ncourses, where students have varied levels of prior programming experience and\nthus may experience related group issues. This work analyzes the effect of pair\nprogramming in an upper-level computer science course, where students have a\nmore consistent background education, particularly in languages learned and\nbest practices in coding. Secondly, the effect of remote pair programming on\nstudent outcomes is still an open question and one of increasing importance\nwith the advent of Covid-19. This work utilized split sections with a control\nand treatment group in a large, public university. In addition to comparing\npair programming to individual programming, results were analyzed by modality\n(remote vs. in person) and by gender, focusing on how pair programming benefits\nfemale computer science students in confidence, persistence in the major, and\noutcomes. We found that pair programming groups scored higher on assignments\nand exams, that remote pair programming groups performed as well as in person\ngroups, and that female students increased their confidence in asking questions\nin class and scored 12\\% higher in the course when utilizing pair programming.",
    "descriptor": "\nComments: 6 pages, 8 figures, 2 tables, ITiCSE conference\n",
    "authors": [
      "Zachariah J. Beasley",
      "Ayesha R. Johnson"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2204.03066"
  },
  {
    "id": "arXiv:2204.03067",
    "title": "ByT5 model for massively multilingual grapheme-to-phoneme conversion",
    "abstract": "In this study, we tackle massively multilingual grapheme-to-phoneme\nconversion through implementing G2P models based on ByT5. We have curated a G2P\ndataset from various sources that covers around 100 languages and trained\nlarge-scale multilingual G2P models based on ByT5. We found that ByT5 operating\non byte-level inputs significantly outperformed the token-based mT5 model in\nterms of multilingual G2P. Pairwise comparison with monolingual models in these\nlanguages suggests that multilingual ByT5 models generally lower the phone\nerror rate by jointly learning from a variety of languages. The pretrained\nmodel can further benefit low resource G2P through zero-shot prediction on\nunseen languages or provides pretrained weights for finetuning, which helps the\nmodel converge to a lower phone error rate than randomly initialized weights.\nTo facilitate future research on multilingual G2P, we make available our code\nand pretrained multilingual G2P models at:\nhttps://github.com/lingjzhu/CharsiuG2P.",
    "descriptor": "\nComments: Submitted to Interspeech 2022\n",
    "authors": [
      "Jian Zhu",
      "Cong Zhang",
      "David Jurgens"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.03067"
  },
  {
    "id": "arXiv:2204.03071",
    "title": "Urdu Morphology, Orthography and Lexicon Extraction",
    "abstract": "Urdu is a challenging language because of, first, its Perso-Arabic script and\nsecond, its morphological system having inherent grammatical forms and\nvocabulary of Arabic, Persian and the native languages of South Asia. This\npaper describes an implementation of the Urdu language as a software API, and\nwe deal with orthography, morphology and the extraction of the lexicon. The\nmorphology is implemented in a toolkit called Functional Morphology (Forsberg &\nRanta, 2004), which is based on the idea of dealing grammars as software\nlibraries. Therefore this implementation could be reused in applications such\nas intelligent search of keywords, language training and infrastructure for\nsyntax. We also present an implementation of a small part of Urdu syntax to\ndemonstrate this reusability.",
    "descriptor": "\nComments: Published in CAASL-2: The Second Workshop on Computational Approaches to Arabic Script-based Languages, July 21-22, 2007, LSA 2007 Linguistic Institute, Stanford University\n",
    "authors": [
      "Muhammad Humayoun",
      "Harald Hammarstr\u00f6m",
      "Aarne Ranta"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.03071"
  },
  {
    "id": "arXiv:2204.03073",
    "title": "Improved parallel-in-time integration via low-rank updates and  interpolation",
    "abstract": "This work is concerned with linear matrix equations that arise from the\nspace-time discretization of time-dependent linear partial differential\nequations (PDEs). Such matrix equations have been considered, for example, in\nthe context of parallel-in-time integration leading to a class of algorithms\ncalled ParaDiag. We develop and analyze two novel approaches for the numerical\nsolution of such equations. Our first approach is based on the observation that\nthe modification of these equations performed by ParaDiag in order to solve\nthem in parallel has low rank. Building upon previous work on low-rank updates\nof matrix equations, this allows us to make use of tensorized Krylov subspace\nmethods to account for the modification. Our second approach is based on\ninterpolating the solution of the matrix equation from the solutions of several\nmodifications. Both approaches avoid the use of iterative refinement needed by\nParaDiag and related space-time approaches in order to attain good accuracy. In\nturn, our new approaches have the potential to outperform, sometimes\nsignificantly, existing approaches. This potential is demonstrated for several\ndifferent types of PDEs.",
    "descriptor": "",
    "authors": [
      "Daniel Kressner",
      "Stefano Massei",
      "Junli Zhu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2204.03073"
  },
  {
    "id": "arXiv:2204.03074",
    "title": "OSCARS: An Outlier-Sensitive Content-Based Radiography Retrieval System",
    "abstract": "Improving the retrieval relevance on noisy datasets is an emerging need for\nthe curation of a large-scale clean dataset in the medical domain. While\nexisting methods can be applied for class-wise retrieval (aka. inter-class),\nthey cannot distinguish the granularity of likeness within the same class (aka.\nintra-class). The problem is exacerbated on medical external datasets, where\nnoisy samples of the same class are treated equally during training. Our goal\nis to identify both intra/inter-class similarities for fine-grained retrieval.\nTo achieve this, we propose an Outlier-Sensitive Content-based rAdiologhy\nRetrieval System (OSCARS), consisting of two steps. First, we train an outlier\ndetector on a clean internal dataset in an unsupervised manner. Then we use the\ntrained detector to generate the anomaly scores on the external dataset, whose\ndistribution will be used to bin intra-class variations. Second, we propose a\nquadruplet (a, p, nintra, ninter) sampling strategy, where intra-class\nnegatives nintra are sampled from bins of the same class other than the bin\nanchor a belongs to, while niner are randomly sampled from inter-classes. We\nsuggest a weighted metric learning objective to balance the intra and\ninter-class feature learning. We experimented on two representative public\nradiography datasets. Experiments show the effectiveness of our approach. The\ntraining and evaluation code can be found in\nhttps://github.com/XiaoyuanGuo/oscars.",
    "descriptor": "\nComments: 12 pages, 6 figures, 2 tables\n",
    "authors": [
      "Xiaoyuan Guo",
      "Jiali Duan",
      "Saptarshi Purkayastha",
      "Hari Trivedi",
      "Judy Wawira Gichoya",
      "Imon Banerjee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.03074"
  },
  {
    "id": "arXiv:2204.03076",
    "title": "Approximation Algorithms and Hardness for $n$-Pairs Shortest Paths and  All-Nodes Shortest Cycles",
    "abstract": "We study the approximability of two related problems: $n$-Pairs Shortest\nPaths ($n$-PSP), where the goal is to find a shortest path between $O(n)$\nprespecified pairs, and All Node Shortest Cycles (ANSC), where the goal is to\nfind the shortest cycle passing through each node. Approximate $n$-PSP has been\npreviously studied, mostly in the context of distance oracles. ANSC has also\nbeen studied previously, but only in terms of exact algorithms, rather than\napproximation.\nWe provide a thorough study of the approximability of $n$-PSP and ANSC,\nproviding a wide array of algorithms and conditional lower bounds that trade\noff between running time and approximation ratio. Our conditional hardness\nresults are based on well-established and believable fine-grained hypotheses.\nA highlight of our conditional lower bounds results is that under the\n$(k,3)$-Hyperclique Hypothesis for any integer $k\\ge 4$, there is no algorithm\nfor unweighted undirected $n$-PSP with approximation ratio better than $3-6/k$\nthat runs in $O(n^{k/(k-2)-\\epsilon})$ time. This is the first known lower\nbound with approximation ratio higher than 2 for any distance problem except\nfor the $ST$-Diameter problem, but unlike in $n$-PSP, the number of vertex\npairs one considers in $ST$-Diameter is much larger than the running time lower\nbounds.\nA highlight of our algorithmic results is that one can solve both $n$-PSP and\nANSC in $\\tilde O(m+ n^{3/2+\\epsilon})$ time with approximation factor\n$2+\\epsilon$ (and additive error that is function of $\\epsilon$), for any\nconstant $\\epsilon>0$. For $n$-PSP, our conditional lower bounds imply that\nthis approximation ratio is nearly optimal for any subquadratic-time\ncombinatorial algorithm. We further extend these algorithms for $n$-PSP and\nANSC to obtain a time/accuracy trade-off that includes near-linear time\nalgorithms.",
    "descriptor": "\nComments: Abstract truncated to meet arXiv requirement\n",
    "authors": [
      "Mina Dalirooyfard",
      "Ce Jin",
      "Virginia Vassilevska Williams",
      "Nicole Wein"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2204.03076"
  },
  {
    "id": "arXiv:2204.03077",
    "title": "Control barrier function based attack-recovery with provable guarantees",
    "abstract": "This paper studies provable security guarantees for cyber-physical systems\n(CPS) under actuator attacks. In particular, we consider CPS safety and propose\na new attack-detection mechanism based on a zeroing control barrier function\n(ZCBF) condition. In addition we design an adaptive recovery mechanism based on\nhow close the system is from violating safety. We show that the\nattack-detection mechanism is sound, i.e., there are no false negatives for\nadversarial attacks. Finally, we use a Quadratic Programming (QP) approach for\nonline recovery (and nominal) control synthesis. We demonstrate the\neffectiveness of the proposed method in a simulation case study involving a\nquadrotor with an attack on its motors.",
    "descriptor": "\nComments: 8 pages, 6 figures\n",
    "authors": [
      "Kunal Garg",
      "Ricardo G. Sanfelice",
      "Alvaro A. Cardenas"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2204.03077"
  },
  {
    "id": "arXiv:2204.03080",
    "title": "Graph Neural Networks Designed for Different Graph Types: A Survey",
    "abstract": "Graphs are ubiquitous in nature and can therefore serve as models for many\npractical but also theoretical problems. Based on this, the young research\nfield of Graph Neural Networks (GNNs) has emerged. Despite the youth of the\nfield and the speed in which new models are developed, many good surveys have\nbeen published in the last years. Nevertheless, an overview on which graph\ntypes can be modeled by GNNs is missing. In this survey, we give a detailed\noverview of already existing GNNs and, unlike previous surveys, categorize them\naccording to their ability to handle different graph types. We consider GNNs\noperating on static as well as on dynamic graphs of different structural\nconstitutions, with or without node or edge attributes. Moreover in the dynamic\ncase, we separate the models in discrete-time and continuous-time dynamic\ngraphs based on their architecture. According to our findings, there are still\ngraph types, that are not covered by existing GNN models. Specifically, models\nconcerning heterogeneity in attributes are missing and the deletion of nodes\nand edges is only covered rarely.",
    "descriptor": "",
    "authors": [
      "Josephine M. Thomas",
      "Alice Moallemy-Oureh",
      "Silvia Beddar-Wiesing",
      "Clara Holzh\u00fcter"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.03080"
  },
  {
    "id": "arXiv:2204.03082",
    "title": "Instance Segmentation of Unlabeled Modalities via Cyclic Segmentation  GAN",
    "abstract": "Instance segmentation for unlabeled imaging modalities is a challenging but\nessential task as collecting expert annotation can be expensive and\ntime-consuming. Existing works segment a new modality by either deploying a\npre-trained model optimized on diverse training data or conducting domain\ntranslation and image segmentation as two independent steps. In this work, we\npropose a novel Cyclic Segmentation Generative Adversarial Network (CySGAN)\nthat conducts image translation and instance segmentation jointly using a\nunified framework. Besides the CycleGAN losses for image translation and\nsupervised losses for the annotated source domain, we introduce additional\nself-supervised and segmentation-based adversarial objectives to improve the\nmodel performance by leveraging unlabeled target domain images. We benchmark\nour approach on the task of 3D neuronal nuclei segmentation with annotated\nelectron microscopy (EM) images and unlabeled expansion microscopy (ExM) data.\nOur CySGAN outperforms both pretrained generalist models and the baselines that\nsequentially conduct image translation and segmentation. Our implementation and\nthe newly collected, densely annotated ExM nuclei dataset, named NucExM, are\navailable at https://connectomics-bazaar.github.io/proj/CySGAN/index.html.",
    "descriptor": "\nComments: 13 pages with appendix\n",
    "authors": [
      "Leander Lauenburg",
      "Zudi Lin",
      "Ruihan Zhang",
      "M\u00e1rcia dos Santos",
      "Siyu Huang",
      "Ignacio Arganda-Carreras",
      "Edward S. Boyden",
      "Hanspeter Pfister",
      "Donglai Wei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.03082"
  },
  {
    "id": "arXiv:2204.03083",
    "title": "Audio-Visual Person-of-Interest DeepFake Detection",
    "abstract": "Face manipulation technology is advancing very rapidly, and new methods are\nbeing proposed day by day. The aim of this work is to propose a deepfake\ndetector that can cope with the wide variety of manipulation methods and\nscenarios encountered in the real world. Our key insight is that each person\nhas specific biometric characteristics that a synthetic generator cannot likely\nreproduce. Accordingly, we extract high-level audio-visual biometric features\nwhich characterize the identity of a person, and use them to create a\nperson-of-interest (POI) deepfake detector. We leverage a contrastive learning\nparadigm to learn the moving-face and audio segments embeddings that are most\ndiscriminative for each identity. As a result, when the video and/or audio of a\nperson is manipulated, its representation in the embedding space becomes\ninconsistent with the real identity, allowing reliable detection. Training is\ncarried out exclusively on real talking-face videos, thus the detector does not\ndepend on any specific manipulation method and yields the highest\ngeneralization ability. In addition, our method can detect both single-modality\n(audio-only, video-only) and multi-modality (audio-video) attacks, and is\nrobust to low-quality or corrupted videos by building only on high-level\nsemantic features. Experiments on a wide variety of datasets confirm that our\nmethod ensures a SOTA performance, with an average improvement in terms of AUC\nof around 3%, 10%, and 7% for high-quality, low quality and attacked videos,\nrespectively.",
    "descriptor": "",
    "authors": [
      "Davide Cozzolino",
      "Matthias Nie\u00dfner",
      "Luisa Verdoliva"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2204.03083"
  },
  {
    "id": "arXiv:2204.03084",
    "title": "Knowledge Infused Decoding",
    "abstract": "Pre-trained language models (LMs) have been shown to memorize a substantial\namount of knowledge from the pre-training corpora; however, they are still\nlimited in recalling factually correct knowledge given a certain context.\nHence, they tend to suffer from counterfactual or hallucinatory generation when\nused in knowledge-intensive natural language generation (NLG) tasks. Recent\nremedies to this problem focus on modifying either the pre-training or task\nfine-tuning objectives to incorporate knowledge, which normally require\nadditional costly training or architecture modification of LMs for practical\napplications. We present Knowledge Infused Decoding (KID) -- a novel decoding\nalgorithm for generative LMs, which dynamically infuses external knowledge into\neach step of the LM decoding. Specifically, we maintain a local knowledge\nmemory based on the current context, interacting with a dynamically created\nexternal knowledge trie, and continuously update the local memory as a\nknowledge-aware constraint to guide decoding via reinforcement learning. On six\ndiverse knowledge-intensive NLG tasks, task-agnostic LMs (e.g., GPT-2 and BART)\narmed with KID outperform many task-optimized state-of-the-art models, and show\nparticularly strong performance in few-shot scenarios over seven related\nknowledge-infusion techniques. Human evaluation confirms KID's ability to\ngenerate more relevant and factual language for the input context when compared\nwith multiple baselines. Finally, KID also alleviates exposure bias and\nprovides stable generation quality when generating longer sequences. Code for\nKID is available at https://github.com/microsoft/KID.",
    "descriptor": "\nComments: In ICLR 2022\n",
    "authors": [
      "Ruibo Liu",
      "Guoqing Zheng",
      "Shashank Gupta",
      "Radhika Gaonkar",
      "Chongyang Gao",
      "Soroush Vosoughi",
      "Milad Shokouhi",
      "Ahmed Hassan Awadallah"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.03084"
  },
  {
    "id": "arXiv:2204.03087",
    "title": "Faster Pattern Matching under Edit Distance",
    "abstract": "We consider the approximate pattern matching problem under the edit distance.\nGiven a text $T$ of length $n$, a pattern $P$ of length $m$, and a threshold\n$k$, the task is to find the starting positions of all substrings of $T$ that\ncan be transformed to $P$ with at most $k$ edits. More than 20 years ago, Cole\nand Hariharan [SODA'98, J. Comput.'02] gave an $\\mathcal{O}(n+k^4 \\cdot n/\nm)$-time algorithm for this classic problem, and this runtime has not been\nimproved since.\nHere, we present an algorithm that runs in time $\\mathcal{O}(n+k^{3.5}\n\\sqrt{\\log m \\log k} \\cdot n/m)$, thus breaking through this long-standing\nbarrier. In the case where $n^{1/4+\\varepsilon} \\leq k \\leq\nn^{2/5-\\varepsilon}$ for some arbitrarily small positive constant\n$\\varepsilon$, our algorithm improves over the state-of-the-art by polynomial\nfactors: it is polynomially faster than both the algorithm of Cole and\nHariharan and the classic $\\mathcal{O}(kn)$-time algorithm of Landau and\nVishkin [STOC'86, J. Algorithms'89].\nWe observe that the bottleneck case of the alternative $\\mathcal{O}(n+k^4\n\\cdot n/m)$-time algorithm of Charalampopoulos, Kociumaka, and Wellnitz\n[FOCS'20] is when the text and the pattern are (almost) periodic. Our new\nalgorithm reduces this case to a new dynamic problem (Dynamic Puzzle Matching),\nwhich we solve by building on tools developed by Tiskin [SODA'10,\nAlgorithmica'15] for the so-called seaweed monoid of permutation matrices. Our\nalgorithm relies only on a small set of primitive operations on strings and\nthus also applies to the fully-compressed setting (where text and pattern are\ngiven as straight-line programs) and to the dynamic setting (where we maintain\na collection of strings under creation, splitting, and concatenation),\nimproving over the state of the art.",
    "descriptor": "\nComments: 94 pages, 7 figures\n",
    "authors": [
      "Panagiotis Charalampopoulos",
      "Tomasz Kociumaka",
      "Philip Wellnitz"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2204.03087"
  },
  {
    "id": "arXiv:2204.03089",
    "title": "Fluently specifying taint-flow queries with fluentTQL",
    "abstract": "Previous work has shown that taint analyses are only useful if correctly\ncustomized to the context in which they are used. Existing domain-specific\nlanguages (DSLs) allow such customization through the definition of\ndeny-listing data-flow rules that describe potentially vulnerable taint-flows.\nThese languages, however, are designed primarily for security experts who are\nknowledgeable in taint analysis. Software developers consider these languages\nto be complex. This paper presents fluentTQL, a query language particularly for\ntaint-flow. fluentTQL is internal Java DSL and uses a fluent-interface design.\nfluentTQL queries can express various taint-style vulnerability types, e.g.\ninjections, cross-site scripting or path traversal. This paper describes\nfluentTQL's abstract and concrete syntax and defines its runtime semantics. The\nsemantics are independent of any underlying analysis and allows evaluation of\nfluentTQL queries by a variety of taint analyses. Instantiations of fluentTQL,\non top of two taint analysis solvers, Boomerang and FlowDroid, show and\nvalidate fluentTQL expressiveness. Based on existing examples from the\nliterature, we implemented queries for 11 popular security vulnerability types\nin Java. Using our SQL injection specification, the Boomerang-based taint\nanalysis found all 17 known taint-flows in the OWASP WebGoat application,\nwhereas with FlowDroid 13 taint-flows were found. Similarly, in a vulnerable\nversion of the Java PetClinic application, the Boomerang-based taint analysis\nfound all seven expected taint-flows. In seven real-world Android apps with 25\nexpected taint-flows, 18 were detected. In a user study with 26 software\ndevelopers, fluentTQL reached a high usability score. In comparison to CodeQL,\nthe state-of-the-art DSL by Semmle/GitHub, participants found fluentTQL more\nusable and with it they were able to specify taint analysis queries in shorter\ntime.",
    "descriptor": "\nComments: 39 pages, Springer Journal on Empirical Software Engineering\n",
    "authors": [
      "Goran Piskachev",
      "Johannes Sp\u00e4th",
      "Ingo Budde",
      "Eric Bodden"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2204.03089"
  },
  {
    "id": "arXiv:2204.03090",
    "title": "Advancing Data Justice Research and Practice: An Integrated Literature  Review",
    "abstract": "The Advancing Data Justice Research and Practice (ADJRP) project aims to\nwiden the lens of current thinking around data justice and to provide\nactionable resources that will help policymakers, practitioners, and impacted\ncommunities gain a broader understanding of what equitable, freedom-promoting,\nand rights-sustaining data collection, governance, and use should look like in\nincreasingly dynamic and global data innovation ecosystems. In this integrated\nliterature review we hope to lay the conceptual groundwork needed to support\nthis aspiration. The introduction motivates the broadening of data justice that\nis undertaken by the literature review which follows. First, we address how\ncertain limitations of the current study of data justice drive the need for a\nre-location of data justice research and practice. We map out the strengths and\nshortcomings of the contemporary state of the art and then elaborate on the\nchallenges faced by our own effort to broaden the data justice perspective in\nthe decolonial context. The body of the literature review covers seven thematic\nareas. For each theme, the ADJRP team has systematically collected and analysed\nkey texts in order to tell the critical empirical story of how existing social\nstructures and power dynamics present challenges to data justice and related\njustice fields. In each case, this critical empirical story is also\nsupplemented by the transformational story of how activists, policymakers, and\nacademics are challenging longstanding structures of inequity to advance social\njustice in data innovation ecosystems and adjacent areas of technological\npractice.",
    "descriptor": "",
    "authors": [
      "David Leslie",
      "Michael Katell",
      "Mhairi Aitken",
      "Jatinder Singh",
      "Morgan Briggs",
      "Rosamund Powell",
      "Cami Rinc\u00f3n",
      "Thompson Chengeta",
      "Abeba Birhane",
      "Antonella Perini",
      "Smera Jayadeva",
      "Anjali Mazumder"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)",
      "General Literature (cs.GL)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2204.03090"
  },
  {
    "id": "arXiv:2204.03096",
    "title": "From Little Things Big Things Grow: A Collection with Seed Studies for  Medical Systematic Review Literature Search",
    "abstract": "Medical systematic review query formulation is a highly complex task done by\ntrained information specialists. Complexity comes from the reliance on lengthy\nBoolean queries, which express a detailed research question. To aid query\nformulation, information specialists use a set of exemplar documents, called\n`seed studies', prior to query formulation. Seed studies help verify the\neffectiveness of a query prior to the full assessment of retrieved studies.\nBeyond this use of seeds, specific IR methods can exploit seed studies for\nguiding both automatic query formulation and new retrieval models. One major\nlimitation of work to date is that these methods exploit `pseudo seed studies'\nthrough retrospective use of included studies (i.e., relevance assessments).\nHowever, we show pseudo seed studies are not representative of real seed\nstudies used by information specialists. Hence, we provide a test collection\nwith real world seed studies used to assist with the formulation of queries. To\nsupport our collection, we provide an analysis, previously not possible, on how\nseed studies impact retrieval and perform several experiments using seed-study\nbased methods to compare the effectiveness of using seed studies versus pseudo\nseed studies. We make our test collection and the results of all of our\nexperiments and analysis available at\nthis http URL",
    "descriptor": "\nComments: Accepted and To be appeared in SIGIR 2022 proceeding\n",
    "authors": [
      "Shuai Wang",
      "Harrisen Scells",
      "Justin Clark",
      "Bevan Koopman",
      "Guido Zuccon"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2204.03096"
  },
  {
    "id": "arXiv:2204.03098",
    "title": "Closed Ranks: The Discursive Value of Military Support for Indian  Politicians on Social Media",
    "abstract": "Influencers play a crucial role in shaping public narratives through\ninformation creation and diffusion in the Global South. While public figures\nfrom various walks of life and their impact on public discourse have been\nstudied, defence veterans as influencers of the political discourse have been\nlargely overlooked. Veterans matter in the public spehere as a normatively\nimportant political lobby. They are also interesting because, unlike\nactive-duty military officers, they are not restricted from taking public sides\non politics, so their posts may provide a window into the views of those still\nin the service. In this work, we systematically analyze the engagement on\nTwitter of self-described defence-related accounts and politician accounts that\npost on defence-related issues. We find that self-described defence-related\naccounts disproportionately engage with the current ruling party in India. We\nfind that politicians promote their closeness to the defence services and\nnationalist credentials through engagements with defence-related influencers.\nWe briefly consider the institutional implications of these patterns and\nconnections",
    "descriptor": "",
    "authors": [
      "Soham De",
      "Agrima Seth",
      "Arshia Arya",
      "Steven Wilkinson",
      "Sushant Singh",
      "Joyojeet Singh"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2204.03098"
  },
  {
    "id": "arXiv:2204.03100",
    "title": "Data Justice Stories: A Repository of Case Studies",
    "abstract": "The idea of \"data justice\" is of recent academic vintage. It has arisen over\nthe past decade in Anglo-European research institutions as an attempt to bring\ntogether a critique of the power dynamics that underlie accelerating trends of\ndatafication with a normative commitment to the principles of social justice-a\ncommitment to the achievement of a society that is equitable, fair, and capable\nof confronting the root causes of injustice.However, despite the seeming\nnovelty of such a data justice pedigree, this joining up of the critique of the\npower imbalances that have shaped the digital and \"big data\" revolutions with a\ncommitment to social equity and constructive societal transformation has a\ndeeper historical, and more geographically diverse, provenance. As the stories\nof the data justice initiatives, activism, and advocacy contained in this\nvolume well evidence, practices of data justice across the globe have, in fact,\nlargely preceded the elaboration and crystallisation of the idea of data\njustice in contemporary academic discourse. In telling these data justice\nstories, we hope to provide the reader with two interdependent tools of data\njustice thinking: First, we aim to provide the reader with the critical\nleverage needed to discern those distortions and malformations of data justice\nthat manifest in subtle and explicit forms of power, domination, and coercion.\nSecond, we aim to provide the reader with access to the historically effective\nforms of normativity and ethical insight that have been marshalled by data\njustice activists and advocates as tools of societal transformation-so that\nthese forms of normativity and insight can be drawn on, in turn, as\nconstructive resources to spur future transformative data justice practices.",
    "descriptor": "",
    "authors": [
      "David Leslie",
      "Morgan Briggs",
      "Antonella Perini",
      "Smera Jayadeva",
      "Cami Rinc\u00f3n",
      "Noopur Raval",
      "Abeba Birhane",
      "Rosamund Powell",
      "Michael Katell",
      "Mhairi Aitken"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.03100"
  },
  {
    "id": "arXiv:2204.03101",
    "title": "Hierarchical Self-supervised Representation Learning for Movie  Understanding",
    "abstract": "Most self-supervised video representation learning approaches focus on action\nrecognition. In contrast, in this paper we focus on self-supervised video\nlearning for movie understanding and propose a novel hierarchical\nself-supervised pretraining strategy that separately pretrains each level of\nour hierarchical movie understanding model (based on [37]). Specifically, we\npropose to pretrain the low-level video backbone using a contrastive learning\nobjective, while pretrain the higher-level video contextualizer using an event\nmask prediction task, which enables the usage of different data sources for\npretraining different levels of the hierarchy. We first show that our\nself-supervised pretraining strategies are effective and lead to improved\nperformance on all tasks and metrics on VidSitu benchmark [37] (e.g., improving\non semantic role prediction from 47% to 61% CIDEr scores). We further\ndemonstrate the effectiveness of our contextualized event features on LVU tasks\n[54], both when used alone and when combined with instance features, showing\ntheir complementarity.",
    "descriptor": "\nComments: CVPR 2022\n",
    "authors": [
      "Fanyi Xiao",
      "Kaustav Kundu",
      "Joseph Tighe",
      "Davide Modolo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.03101"
  },
  {
    "id": "arXiv:2204.03105",
    "title": "AUV-Net: Learning Aligned UV Maps for Texture Transfer and Synthesis",
    "abstract": "In this paper, we address the problem of texture representation for 3D shapes\nfor the challenging and underexplored tasks of texture transfer and synthesis.\nPrevious works either apply spherical texture maps which may lead to large\ndistortions, or use continuous texture fields that yield smooth outputs lacking\ndetails. We argue that the traditional way of representing textures with images\nand linking them to a 3D mesh via UV mapping is more desirable, since\nsynthesizing 2D images is a well-studied problem. We propose AUV-Net which\nlearns to embed 3D surfaces into a 2D aligned UV space, by mapping the\ncorresponding semantic parts of different 3D shapes to the same location in the\nUV space. As a result, textures are aligned across objects, and can thus be\neasily synthesized by generative models of images. Texture alignment is learned\nin an unsupervised manner by a simple yet effective texture alignment module,\ntaking inspiration from traditional works on linear subspace learning. The\nlearned UV mapping and aligned texture representations enable a variety of\napplications including texture transfer, texture synthesis, and textured single\nview 3D reconstruction. We conduct experiments on multiple datasets to\ndemonstrate the effectiveness of our method. Project page:\nhttps://nv-tlabs.github.io/AUV-NET.",
    "descriptor": "\nComments: CVPR 2022. Project page: this https URL\n",
    "authors": [
      "Zhiqin Chen",
      "Kangxue Yin",
      "Sanja Fidler"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.03105"
  },
  {
    "id": "arXiv:2204.03110",
    "title": "Stability and Safety through Event-Triggered Intermittent Control with  Application to Spacecraft Orbit Stabilization",
    "abstract": "In systems where the ability to actuate is a scarce resource, e.g.,\nspacecrafts, it is desirable to only apply a given controller in an\nintermittent manner--with periods where the controller is on and periods where\nit is off. Motivated by the event-triggered control paradigm, where\nstate-dependent triggers are utilized in a sample-and-hold context, we\ngeneralize this concept to include state triggers where the controller is off\nthereby creating a framework for intermittent control. Our approach utilizes\ncertificates--either Lyapunov or barrier functions--to design intermittent\ntrigger laws that guarantee stability or safety; the controller is turned on\nfor the period for which is beneficial with regard to the certificate, and\nturned off until a performance threshold is reached. The main result of this\npaper is that the intermittent controller scheme guarantees (set) stability\nwhen Lyapunov functions are utilized, and safety (forward set invariance) in\nthe setting of barrier functions. As a result, our trigger designs can leverage\nthe intermittent nature of the actuator, and at the same time, achieve the task\nof stabilization or safety. We further demonstrate the application and benefits\nof intermittent control in the context of the spacecraft orbit stabilization\nproblem.",
    "descriptor": "\nComments: 8 pages, 3 figures, submitted to IEEE Conference on Decision and Control 2022\n",
    "authors": [
      "Pio Ong",
      "Gilbert Bahati",
      "Aaron D. Ames"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2204.03110"
  },
  {
    "id": "arXiv:2204.03111",
    "title": "UIGR: Unified Interactive Garment Retrieval",
    "abstract": "Interactive garment retrieval (IGR) aims to retrieve a target garment image\nbased on a reference garment image along with user feedback on what to change\non the reference garment. Two IGR tasks have been studied extensively:\ntext-guided garment retrieval (TGR) and visually compatible garment retrieval\n(VCR). The user feedback for the former indicates what semantic attributes to\nchange with the garment category preserved, while the category is the only\nthing to be changed explicitly for the latter, with an implicit requirement on\nstyle preservation. Despite the similarity between these two tasks and the\npractical need for an efficient system tackling both, they have never been\nunified and modeled jointly. In this paper, we propose a Unified Interactive\nGarment Retrieval (UIGR) framework to unify TGR and VCR. To this end, we first\ncontribute a large-scale benchmark suited for both problems. We further propose\na strong baseline architecture to integrate TGR and VCR in one model. Extensive\nexperiments suggest that unifying two tasks in one framework is not only more\nefficient by requiring a single model only, it also leads to better\nperformance. Code and datasets are available at\nhttps://github.com/BrandonHanx/CompFashion.",
    "descriptor": "\nComments: CVPRW 2022\n",
    "authors": [
      "Xiao Han",
      "Sen He",
      "Li Zhang",
      "Yi-Zhe Song",
      "Tao Xiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.03111"
  },
  {
    "id": "arXiv:2204.03112",
    "title": "An Instrumented Wheel-On-Limb System of Planetary Rovers for  Wheel-Terrain Interactions: System Conception and Preliminary Design",
    "abstract": "Understanding the wheel-terrain interaction is of great importance to improve\nthe maneuverability and traversability of the rovers. A well-developed sensing\ndevice carried by the rover would greatly facilitate the complex risk-reducing\noperations on sandy terrains. In this paper, an instrumented wheel-on-limb\n(WOL) system of planetary rovers for wheel-terrain interaction characterization\nis presented. Assuming the function of a passive suspension of the wheel, the\nWOL system allows itself to follow the terrain contour, and keep the wheel\nremain lowered onto the ground during rover motion including climbing and\ndescending, as well as deploy and place the wheel on the ground before a drive\ncommanding. The system concept, functional requirements, and pre-design work,\nas well as the system integration are presented.",
    "descriptor": "\nComments: 2nd International Conference on Robotics and Control Engineering, ACM RobCE 2022, March 25, 2022, Nanjing, China\n",
    "authors": [
      "Lihang Feng",
      "Xu Jiang",
      "Aiguo Song"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2204.03112"
  },
  {
    "id": "arXiv:2204.03113",
    "title": "P4BID: Information Flow Control in P4",
    "abstract": "Modern programmable network switches can implement custom applications using\nefficient packet processing hardware, and the programming language P4 provides\nhigh-level constructs to program such switches. The increase in speed and\nprogrammability has inspired research in dataplane programming, where many\ncomplex functionalities, e.g., key-value stores and load balancers, can be\nimplemented entirely in network switches. However, dataplane programs may\nsuffer from novel security errors that are not traditionally found in network\nswitches.\nTo address this issue, we present a new information-flow control type system\nfor P4. We formalize our type system in a recently-proposed core version of P4,\nand we prove a soundness theorem: well-typed programs satisfy non-interference.\nWe also implement our type system in a tool, P4bid, which extends the type\nchecker in the p4c compiler, the reference compiler for the latest version of\nP4. We present several case studies showing that natural security, integrity,\nand isolation properties in networks can be captured by non-interference, and\nour type system can detect violations of these properties while certifying\ncorrect programs.",
    "descriptor": "",
    "authors": [
      "Karuna Grewal",
      "Loris D'Antoni",
      "Justin Hsu"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2204.03113"
  },
  {
    "id": "arXiv:2204.03114",
    "title": "Do They Accept or Resist Cybersecurity Measures? Development and  Validation of the 13-Item Security Attitude Inventory (SA-13)",
    "abstract": "We present SA-13, the 13-item Security Attitude inventory. We develop and\nvalidate this assessment of cybersecurity attitudes by conducting an\nexploratory factor analysis, confirmatory factor analysis, and other tests with\ndata from a U.S. Census-weighted Qualtrics panel (N=209). Beyond a core six\nindicators of Engagement with Security Measures (SA-Engagement, three items)\nand Attentiveness to Security Measures (SA-Attentiveness, three items), our\nSA-13 inventory adds indicators of Resistance to Security Measures\n(SA-Resistance, four items) and Concernedness with Improving Compliance\n(SA-Concernedness, three items). SA-13 and the subscales exhibit desirable\npsychometric qualities; and higher scores on SA-13 and on the SA-Engagement and\nSA-Attentiveness subscales are associated with higher scores for security\nbehavior intention and for self-reported recent security behaviors. SA-13 and\nthe subscales are useful for researchers and security awareness teams who need\na lightweight survey measure of user security attitudes. The composite score of\nthe 13 indicators provides a compact measurement of cybersecurity decisional\nbalance.",
    "descriptor": "\nComments: Includes the directions for administering the scales in an appendix\n",
    "authors": [
      "Cori Faklaris",
      "Laura Dabbish",
      "Jason I. Hong"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Human-Computer Interaction (cs.HC)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2204.03114"
  },
  {
    "id": "arXiv:2204.03117",
    "title": "BiSyn-GAT+: Bi-Syntax Aware Graph Attention Network for Aspect-based  Sentiment Analysis",
    "abstract": "Aspect-based sentiment analysis (ABSA) is a fine-grained sentiment analysis\ntask that aims to align aspects and corresponding sentiments for\naspect-specific sentiment polarity inference. It is challenging because a\nsentence may contain multiple aspects or complicated (e.g., conditional,\ncoordinating, or adversative) relations. Recently, exploiting dependency syntax\ninformation with graph neural networks has been the most popular trend. Despite\nits success, methods that heavily rely on the dependency tree pose challenges\nin accurately modeling the alignment of the aspects and their words indicative\nof sentiment, since the dependency tree may provide noisy signals of unrelated\nassociations (e.g., the \"conj\" relation between \"great\" and \"dreadful\" in\nFigure 2). In this paper, to alleviate this problem, we propose a Bi-Syntax\naware Graph Attention Network (BiSyn-GAT+). Specifically, BiSyn-GAT+ fully\nexploits the syntax information (e.g., phrase segmentation and hierarchical\nstructure) of the constituent tree of a sentence to model the sentiment-aware\ncontext of every single aspect (called intra-context) and the sentiment\nrelations across aspects (called inter-context) for learning. Experiments on\nfour benchmark datasets demonstrate that BiSyn-GAT+ outperforms the\nstate-of-the-art methods consistently.",
    "descriptor": "",
    "authors": [
      "Shuo Liang",
      "Wei Wei",
      "Xian-Ling Mao",
      "Fei Wang",
      "Zhiyong He"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.03117"
  },
  {
    "id": "arXiv:2204.03120",
    "title": "AutoCOR: Autonomous Condylar Offset Ratio Calculator on  TKA-Postoperative Lateral Knee X-ray",
    "abstract": "The postoperative range of motion is one of the crucial factors indicating\nthe outcome of Total Knee Arthroplasty (TKA). Although the correlation between\nrange of knee flexion and posterior condylar offset (PCO) is controversial in\nthe literature, PCO maintains its importance on evaluation of TKA. Due to\nlimitations on PCO measurement, two novel parameters, posterior condylar offset\nratio (PCOR) and anterior condylar offset ratio (ACOR), were introduced.\nNowadays, the calculation of PCOR and ACOR on plain lateral radiographs is done\nmanually by orthopedic surgeons. In this regard, we developed a software,\nAutoCOR, to calculate PCOR and ACOR autonomously, utilizing unsupervised\nmachine learning algorithm (k-means clustering) and digital image processing\ntechniques. The software AutoCOR is capable of detecting the anterior/posterior\nedge points and anterior/posterior cortex of the femoral shaft on true\npostoperative lateral conventional radiographs. To test the algorithm, 50\npostoperative true lateral radiographs from Istanbul Kosuyolu Medipol Hospital\nDatabase were used (32 patients). The mean PCOR was 0.984 (SD 0.235) in\nsoftware results and 0.972 (SD 0.164) in ground truth values. It shows strong\nand significant correlation between software and ground truth values (Pearson\nr=0.845 p<0.0001). The mean ACOR was 0.107 (SD 0.092) in software results and\n0.107 (SD 0.070) in ground truth values. It shows moderate and significant\ncorrelation between software and ground truth values (Spearman's rs=0.519\np=0.0001412). We suggest that AutoCOR is a useful tool that can be used in\nclinical practice.",
    "descriptor": "\nComments: 9 pages\n",
    "authors": [
      "Gulsade Rabia Cakmak",
      "Ibrahim Ethem Hamamci",
      "Mehmet Kursat Yilmaz",
      "Reda Alhajj",
      "Ibrahim Azboy",
      "Mehmet Kemal Ozdemir"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.03120"
  },
  {
    "id": "arXiv:2204.03125",
    "title": "Deep transfer learning for system identification using long short-term  memory neural networks",
    "abstract": "Recurrent neural networks (RNNs) have many advantages over more traditional\nsystem identification techniques. They may be applied to linear and nonlinear\nsystems, and they require fewer modeling assumptions. However, these neural\nnetwork models may also need larger amounts of data to learn and generalize.\nFurthermore, neural networks training is a time-consuming process. Hence,\nbuilding upon long-short term memory neural networks (LSTM), this paper\nproposes using two types of deep transfer learning, namely parameter\nfine-tuning and freezing, to reduce the data and computation requirements for\nsystem identification. We apply these techniques to identify two dynamical\nsystems, namely a second-order linear system and a Wiener-Hammerstein nonlinear\nsystem. Results show that compared with direct learning, our method accelerates\nlearning by 10% to 50%, which also saves data and computing resources.",
    "descriptor": "",
    "authors": [
      "Kaicheng Niu",
      "Mi Zhou",
      "Chaouki T. Abdallah",
      "Mohammad Hayajneh"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.03125"
  },
  {
    "id": "arXiv:2204.03128",
    "title": "Sigma Workbook: A Spreadsheet for Cloud Data Warehouses",
    "abstract": "Cloud data warehouses (CDWs) bring large-scale data and compute power closer\nto users in enterprises. However, existing tools for analyzing data in CDWs are\neither limited in ad-hoc transformations or difficult to use for business\nusers. Here we introduce Sigma Workbook, a new interactive system that enables\nbusiness users to easily perform a visual analysis of data in CDWs at scale.\nFor this, Sigma Workbook provides an accessible spreadsheet-like interface for\nanalysis through direct manipulation. Sigma Workbook dynamically constructs\nmatching SQL queries from user interactions, building on the versatility and\nexpressivity of SQL. Constructed queries are directly executed on CDWs,\nleveraging the superior characteristics of the new generation CDWs, including\nscalability. We demonstrate Sigma Workbook through 3 real-life use cases --\ncohort analysis, sessionization, and data augmentation -- and underline\nWorkbook's ease of use, scalability, and expressivity.",
    "descriptor": "\nComments: Under review for VLDB'22 Demonstrations\n",
    "authors": [
      "James Gale",
      "Max Seiden",
      "Deepanshu Utkarsh",
      "Jason Frantz",
      "Rob Woollen",
      "\u00c7a\u011fatay Demiralp"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2204.03128"
  },
  {
    "id": "arXiv:2204.03133",
    "title": "Bi-fidelity conditional-value-at-risk estimation by dimensionally  decomposed generalized polynomial chaos expansion",
    "abstract": "Digital twin models allow us to continuously assess the possible risk of\ndamage and failure of a complex system. Yet high-fidelity digital twin models\ncan be computationally expensive, making quick-turnaround assessment\nchallenging. Towards this goal, this article proposes a novel bi-fidelity\nmethod for estimating the conditional value-at-risk (CVaR) for nonlinear\nsystems subject to dependent and high-dimensional inputs. For models that can\nbe evaluated fast, a method that integrates the dimensionally decomposed\ngeneralized polynomial chaos expansion (DD-GPCE) approximation with a standard\nsampling-based CVaR estimation is proposed. For expensive-to-evaluate models, a\nnew bi-fidelity method is proposed that couples the DD-GPCE with a\nFourier-polynomial expansions of the mapping between the stochastic\nlow-fidelity and high-fidelity output data to ensure computational efficiency.\nThe method employs a measure-consistent orthonormal polynomial in the random\nvariable of the low-fidelity output to approximate the high-fidelity output.\nNumerical results for a structural mechanics truss with 36-dimensional\n(dependent random variable) inputs indicate that the DD-GPCE method provides\nvery accurate CVaR estimates that require much lower computational effort than\nstandard GPCE approximations. A second example considers the realistic problem\nof estimating the risk of damage to a fiber-reinforced composite laminate. The\nhigh-fidelity model is a finite element simulation that is prohibitively\nexpensive for risk analysis, such as CVaR computation. Here, the novel\nbi-fidelity method can accurately estimate CVaR as it includes low-fidelity\nmodels in the estimation procedure and uses only a few high-fidelity model\nevaluations to significantly increase accuracy.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:1804.05676 by other authors. text overlap with arXiv:1804.05676 by other authors\n",
    "authors": [
      "Dongjin Lee",
      "Boris Kramer"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2204.03133"
  },
  {
    "id": "arXiv:2204.03134",
    "title": "Perception-aware receding horizon trajectory planning for multicopters  with visual-inertial odometry",
    "abstract": "Visual inertial odometry (VIO) is widely used for the state estimation of\nmulticopters, but it may function poorly in environments with few visual\nfeatures or in overly aggressive flights. In this work, we propose a\nperception-aware collision avoidance local planner for multicopters. Our\napproach is able to fly the vehicle to a goal position at high speed, avoiding\nobstacles in the environment while achieving good VIO state estimation\naccuracy. The proposed planner samples a group of minimum jerk trajectories and\nfinds collision-free trajectories among them, which are then evaluated based on\ntheir speed to the goal and perception quality. Both the features' motion blur\nand their locations are considered for the perception quality. The best\ntrajectory from the evaluation is tracked by the vehicle and is updated in a\nreceding horizon manner when new images are received from the camera. All the\nsampled trajectories have zero speed and acceleration at the end, and the\nplanner assumes no other visual features except those already found by the VIO.\nAs a result, the vehicle will follow the current trajectory to the end and stop\nsafely if no new trajectories are found, avoiding collision or flying into\nareas without features. The proposed method can run in real time on a small\nembedded computer on board. We validated the effectiveness of our proposed\napproach through experiments in indoor and outdoor environments. Compared to a\nperception-agnostic planner, the proposed planner kept more features in the\ncamera's view and made the flight less aggressive, making the VIO more\naccurate. It also reduced VIO failures, which occurred for the\nperception-agnostic planner but not for the proposed planner. The experiment\nvideo can be found at https://youtu.be/LjZju4KEH9Q.",
    "descriptor": "\nComments: 8 pages\n",
    "authors": [
      "Xiangyu Wu",
      "Shuxiao Chen",
      "Koushil Sreenath",
      "Mark W. Mueller"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2204.03134"
  },
  {
    "id": "arXiv:2204.03139",
    "title": "DiffCloud: Real-to-Sim from Point Clouds with Differentiable Simulation  and Rendering of Deformable Objects",
    "abstract": "Research in manipulation of deformable objects is typically conducted on a\nlimited range of scenarios, because handling each scenario on hardware takes\nsignificant effort. Realistic simulators with support for various types of\ndeformations and interactions have the potential to speed up experimentation\nwith novel tasks and algorithms. However, for highly deformable objects it is\nchallenging to align the output of a simulator with the behavior of real\nobjects. Manual tuning is not intuitive, hence automated methods are needed. We\nview this alignment problem as a joint perception-inference challenge and\ndemonstrate how to use recent neural network architectures to successfully\nperform simulation parameter inference from real point clouds. We analyze the\nperformance of various architectures, comparing their data and training\nrequirements. Furthermore, we propose to leverage differentiable point cloud\nsampling and differentiable simulation to significantly reduce the time to\nachieve the alignment. We employ an efficient way to propagate gradients from\npoint clouds to simulated meshes and further through to the physical simulation\nparameters, such as mass and stiffness. Experiments with highly deformable\nobjects show that our method can achieve comparable or better alignment with\nreal object behavior, while reducing the time needed to achieve this by more\nthan an order of magnitude. Videos and supplementary material are available at\nhttps://tinyurl.com/diffcloud.",
    "descriptor": "",
    "authors": [
      "Priya Sundaresan",
      "Rika Antonova",
      "Jeannette Bohg"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.03139"
  },
  {
    "id": "arXiv:2204.03140",
    "title": "Learning and Transferring Value Function for Robot Exploration in  Subterranean Environments",
    "abstract": "In traditional robot exploration methods, the robot usually does not have\nprior biases about the environment it is exploring. Thus the robot assigns\nequal importance to the goals which leads to insufficient exploration\nefficiency. Alternative, often a hand-tuned policy is used to tweak the value\nof goals. In this paper, we present a method to learn how \"good\" some states\nare, measured by the state value function, to provide a hint for the robot to\nmake exploration decisions. We propose to learn state value functions from\nprevious offline collected datasets and then transfer and improve the value\nfunction during testing in a new environment. Moreover, the environments\nusually have very few and even no extrinsic reward or feedback for the robot.\nTherefore in this work, we also tackle the problem of sparse extrinsic rewards\nfrom the environments. We design several intrinsic rewards to encourage the\nrobot to obtain more information during exploration. These reward functions\nthen become the building blocks of the state value functions. We test our\nmethod on challenging subterranean and urban environments. To the best of our\nknowledge, this work for the first time demonstrates value function prediction\nwith previous collected datasets to help exploration in challenging\nsubterranean environments.",
    "descriptor": "",
    "authors": [
      "Yafei Hu",
      "Chen Wang",
      "John Keller",
      "Sebastian Scherer"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.03140"
  },
  {
    "id": "arXiv:2204.03141",
    "title": "Adversarial Machine Learning Attacks Against Video Anomaly Detection  Systems",
    "abstract": "Anomaly detection in videos is an important computer vision problem with\nvarious applications including automated video surveillance. Although\nadversarial attacks on image understanding models have been heavily\ninvestigated, there is not much work on adversarial machine learning targeting\nvideo understanding models and no previous work which focuses on video anomaly\ndetection. To this end, we investigate an adversarial machine learning attack\nagainst video anomaly detection systems, that can be implemented via an\neasy-to-perform cyber-attack. Since surveillance cameras are usually connected\nto the server running the anomaly detection model through a wireless network,\nthey are prone to cyber-attacks targeting the wireless connection. We\ndemonstrate how Wi-Fi deauthentication attack, a notoriously easy-to-perform\nand effective denial-of-service (DoS) attack, can be utilized to generate\nadversarial data for video anomaly detection systems. Specifically, we apply\nseveral effects caused by the Wi-Fi deauthentication attack on video quality\n(e.g., slow down, freeze, fast forward, low resolution) to the popular\nbenchmark datasets for video anomaly detection. Our experiments with several\nstate-of-the-art anomaly detection models show that the attackers can\nsignificantly undermine the reliability of video anomaly detection systems by\ncausing frequent false alarms and hiding physical anomalies from the\nsurveillance system.",
    "descriptor": "",
    "authors": [
      "Furkan Mumcu",
      "Keval Doshi",
      "Yasin Yilmaz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.03141"
  },
  {
    "id": "arXiv:2204.03144",
    "title": "Exploring Cross-Domain Pretrained Model for Hyperspectral Image  Classification",
    "abstract": "A pretrain-finetune strategy is widely used to reduce the overfitting that\ncan occur when data is insufficient for CNN training. First few layers of a CNN\npretrained on a large-scale RGB dataset are capable of acquiring general image\ncharacteristics which are remarkably effective in tasks targeted for different\nRGB datasets. However, when it comes down to hyperspectral domain where each\ndomain has its unique spectral properties, the pretrain-finetune strategy no\nlonger can be deployed in a conventional way while presenting three major\nissues: 1) inconsistent spectral characteristics among the domains (e.g.,\nfrequency range), 2) inconsistent number of data channels among the domains,\nand 3) absence of large-scale hyperspectral dataset.\nWe seek to train a universal cross-domain model which can later be deployed\nfor various spectral domains. To achieve, we physically furnish multiple inlets\nto the model while having a universal portion which is designed to handle the\ninconsistent spectral characteristics among different domains. Note that only\nthe universal portion is used in the finetune process. This approach naturally\nenables the learning of our model on multiple domains simultaneously which acts\nas an effective workaround for the issue of the absence of large-scale dataset.\nWe have carried out a study to extensively compare models that were trained\nusing cross-domain approach with ones trained from scratch. Our approach was\nfound to be superior both in accuracy and in training efficiency. In addition,\nwe have verified that our approach effectively reduces the overfitting issue,\nenabling us to deepen the model up to 13 layers (from 9) without compromising\nthe accuracy.",
    "descriptor": "\nComments: Accept in IEEE TGRS\n",
    "authors": [
      "Hyungtae Lee",
      "Sungmin Eum",
      "Heesung Kwon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.03144"
  },
  {
    "id": "arXiv:2204.03154",
    "title": "Optimization Models and Interpretations for Three Types of Adversarial  Perturbations against Support Vector Machines",
    "abstract": "Adversarial perturbations have drawn great attentions in various deep neural\nnetworks. Most of them are computed by iterations and cannot be interpreted\nvery well. In contrast, little attentions are paid to basic machine learning\nmodels such as support vector machines. In this paper, we investigate the\noptimization models and the interpretations for three types of adversarial\nperturbations against support vector machines, including sample-adversarial\nperturbations (sAP), class-universal adversarial perturbations (cuAP) as well\nas universal adversarial perturbations (uAP). For linear binary/multi\nclassification support vector machines (SVMs), we derive the explicit solutions\nfor sAP, cuAP and uAP (binary case), and approximate solution for uAP of\nmulti-classification. We also obtain the upper bound of fooling rate for uAP.\nSuch results not only increase the interpretability of the three adversarial\nperturbations, but also provide great convenience in computation since\niterative process can be avoided. Numerical results show that our method is\nfast and effective in calculating three types of adversarial perturbations.",
    "descriptor": "",
    "authors": [
      "Wen Su",
      "Qingna Li",
      "Chunfeng Cui"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2204.03154"
  },
  {
    "id": "arXiv:2204.03155",
    "title": "Just-Noticeable-Difference Based Edge Map Quality Measure",
    "abstract": "The performance of an edge detector can be improved when assisted with an\neffective edge map quality measure. Several evaluation methods have been\nproposed resulting in different performance score for the same candidate edge\nmap. However, an effective measure is the one that can be automated and which\ncorrelates with human judgement perceived quality of the edge map.\nDistance-based edge map measures are widely used for assessment of edge map\nquality. These methods consider distance and statistical properties of edge\npixels to estimate a performance score. The existing methods can be automated;\nhowever, they lack perceptual features. This paper presents edge map quality\nmeasure based on Just-Noticeable-Difference (JND) feature of human visual\nsystem, to compensate the shortcomings of distance-based edge measures. For\nthis purpose, we have designed constant stimulus experiment to measure the JND\nvalue for two spatial alternative. Experimental results show that JND based\ndistance calculation outperforms existing distance-based measures according to\nsubjective evaluation.",
    "descriptor": "\nComments: In proceedings of the 4th International Conference on Next Generation Computing (ICNGC) 2018\n",
    "authors": [
      "Ijaz Ahmad",
      "Seokjoo Shin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.03155"
  },
  {
    "id": "arXiv:2204.03156",
    "title": "Multi-twisted codes as free modules over principal ideal domains",
    "abstract": "We begin this chapter by introducing the simple algebraic structure of cyclic\ncodes over finite fields. This structure undergoes a series of generalizations\nto present algebraic descriptions of constacyclic, quasi-cyclic (QC),\nquasi-twisted (QT), generalized quasi-cyclic (GQC), and multi-twisted (MT)\ncodes. The correspondence between these codes and submodules of the free\n$\\mathbb{F}_q[x]$-module $\\left(\\mathbb{F}_q[x]\\right)^\\ell$ is established.\nThus, any of these codes corresponds to a free linear code over the principal\nideal domain (PID) $\\mathbb{F}_q[x]$. A basis of this code exists and is used\nto build a generator matrix with polynomial entries, called the generator\npolynomial matrix (GPM). The Hermite normal form of matrices over PIDs is\nexploited to achieve the reduced GPMs of MT codes. Some properties of the\nreduced GPM are introduced, for example, the identical equation. A formula for\na GPM of the dual code $\\mathcal{C}^\\perp$ of a MT code is given. At this\npoint, special attention is paid to QC codes. For a QC code $\\mathcal{C}$, we\ndefine its reversed code $\\mathcal{R}$. We call $\\mathcal{C}$ reversible or\nself-dual if $\\mathcal{R}=\\mathcal{C}$ or $\\mathcal{C}^\\perp=\\mathcal{C}$,\nrespectively. A formula for a GPM of $\\mathcal{R}$ is given. We characterize\nGPMs for QC codes that combine reversibility and\nself-duality/self-orthogonality. For the reader interested in running computer\nsearch for optimal codes, we show the existence of binary self-orthogonal\nreversible QC codes that have the best known parameters as linear codes. These\nresults can be obtained by brute-force search using GPMs that meet the above\ncharacterization.",
    "descriptor": "\nComments: 35 pages\n",
    "authors": [
      "Ramy Taki ElDin"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Rings and Algebras (math.RA)"
    ],
    "url": "https://arxiv.org/abs/2204.03156"
  },
  {
    "id": "arXiv:2204.03159",
    "title": "Hybrid LMC: Hybrid Learning and Model-based Control for Wheeled Humanoid  Robot via Ensemble Deep Reinforcement Learning",
    "abstract": "Control of wheeled humanoid locomotion is a challenging problem due to the\nnonlinear dynamics and under-actuated characteristics of these robots.\nTraditionally, feedback controllers have been utilized for stabilization and\nlocomotion. However, these methods are often limited by the fidelity of the\nunderlying model used, choice of controller, and environmental variables\nconsidered (surface type, ground inclination, etc). Recent advances in\nreinforcement learning (RL) offer promising methods to tackle some of these\nconventional feedback controller issues, but require large amounts of\ninteraction data to learn. Here, we propose a hybrid learning and model-based\ncontroller Hybrid LMC that combines the strengths of a classical linear\nquadratic regulator (LQR) and ensemble deep reinforcement learning. Ensemble\ndeep reinforcement learning is composed of multiple Soft Actor-Critic (SAC) and\nis utilized in reducing the variance of RL networks. By using a feedback\ncontroller in tandem the network exhibits stable performance in the early\nstages of training. As a preliminary step, we explore the viability of Hybrid\nLMC in controlling wheeled locomotion of a humanoid robot over a set of\ndifferent physical parameters in MuJoCo simulator. Our results show that Hybrid\nLMC achieves better performance compared to other existing techniques and has\nincreased sample efficiency",
    "descriptor": "\nComments: Submitted to IROS2022\n",
    "authors": [
      "Donghoon Baek",
      "Amartya Purushottam",
      "Joao Ramos"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2204.03159"
  },
  {
    "id": "arXiv:2204.03161",
    "title": "Flexible Sampling for Long-tailed Skin Lesion Classification",
    "abstract": "Most of the medical tasks naturally exhibit a long-tailed distribution due to\nthe complex patient-level conditions and the existence of rare diseases.\nExisting long-tailed learning methods usually treat each class equally to\nre-balance the long-tailed distribution. However, considering that some\nchallenging classes may present diverse intra-class distributions, re-balancing\nall classes equally may lead to a significant performance drop. To address\nthis, in this paper, we propose a curriculum learning-based framework called\nFlexible Sampling for the long-tailed skin lesion classification task.\nSpecifically, we initially sample a subset of training data as anchor points\nbased on the individual class prototypes. Then, these anchor points are used to\npre-train an inference model to evaluate the per-class learning difficulty.\nFinally, we use a curriculum sampling module to dynamically query new samples\nfrom the rest training samples with the learning difficulty-aware sampling\nprobability. We evaluated our model against several state-of-the-art methods on\nthe ISIC dataset. The results with two long-tailed settings have demonstrated\nthe superiority of our proposed training strategy, which achieves a new\nbenchmark for long-tailed skin lesion classification.",
    "descriptor": "",
    "authors": [
      "Lie Ju",
      "Yicheng Wu",
      "Lin Wang",
      "Zhen Yu",
      "Xin Zhao",
      "Xin Wang",
      "Paul Bonnington",
      "Zongyuan Ge"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.03161"
  },
  {
    "id": "arXiv:2204.03162",
    "title": "Winoground: Probing Vision and Language Models for Visio-Linguistic  Compositionality",
    "abstract": "We present a novel task and dataset for evaluating the ability of vision and\nlanguage models to conduct visio-linguistic compositional reasoning, which we\ncall Winoground. Given two images and two captions, the goal is to match them\ncorrectly - but crucially, both captions contain a completely identical set of\nwords, only in a different order. The dataset was carefully hand-curated by\nexpert annotators and is labeled with a rich set of fine-grained tags to assist\nin analyzing model performance. We probe a diverse range of state-of-the-art\nvision and language models and find that, surprisingly, none of them do much\nbetter than chance. Evidently, these models are not as skilled at\nvisio-linguistic compositional reasoning as we might have hoped. We perform an\nextensive analysis to obtain insights into how future work might try to\nmitigate these models' shortcomings. We aim for Winoground to serve as a useful\nevaluation set for advancing the state of the art and driving further progress\nin the field. The dataset is available at\nhttps://huggingface.co/datasets/facebook/winoground.",
    "descriptor": "\nComments: CVPR 2022\n",
    "authors": [
      "Tristan Thrush",
      "Ryan Jiang",
      "Max Bartolo",
      "Amanpreet Singh",
      "Adina Williams",
      "Douwe Kiela",
      "Candace Ross"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.03162"
  },
  {
    "id": "arXiv:2204.03173",
    "title": "Enhancement on Model Interpretability and Sleep Stage Scoring  Performance with A Novel Pipeline Based on Deep Neural Network",
    "abstract": "Considering the natural frequency characteristics in sleep medicine, this\npaper first proposes a time-frequency framework for the representation learning\nof the electroencephalogram (EEG) following the definition of the American\nAcademy of Sleep Medicine. To meet the temporal-random and transient nature of\nthe defining characteristics of sleep stages, we further design a\ncontext-sensitive flexible pipeline that automatically adapts to the attributes\nof data itself. That is, the input EEG spectrogram is partitioned into a\nsequence of patches in the time and frequency axes, and then input to a\ndelicate deep learning network for further representation learning to extract\nthe stage-dependent features, which are used in the classification step\nfinally. The proposed pipeline is validated against a large database, i.e., the\nSleep Heart Health Study (SHHS), and the results demonstrate that the\ncompetitive performance for the wake, N2, and N3 stages outperforms the\nstate-of-art works, with the F1 scores being 0.93, 0.88, and 0.87,\nrespectively, and the proposed method has a high inter-rater reliability of\n0.80 kappa. Importantly, we visualize the stage scoring process of the model\ndecision with the Layer-wise Relevance Propagation (LRP) method, which shows\nthat the proposed pipeline is more sensitive and perceivable in the\ndecision-making process than the baseline pipelines. Therefore, the pipeline\ntogether with the LRP method can provide better model interpretability, which\nis important for clinical support.",
    "descriptor": "\nComments: 13 pages, 10 figures\n",
    "authors": [
      "Zheng Chen",
      "Ziwei Yang",
      "Ming Huang",
      "Toshiyo Tamura",
      "Naoaki Ono",
      "MD Altaf-Ul-Amin",
      "Shigehiko Kanaya"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2204.03173"
  },
  {
    "id": "arXiv:2204.03174",
    "title": "FedCos: A Scene-adaptive Federated Optimization Enhancement for  Performance Improvement",
    "abstract": "As an emerging technology, federated learning (FL) involves training machine\nlearning models over distributed edge devices, which attracts sustained\nattention and has been extensively studied. However, the heterogeneity of\nclient data severely degrades the performance of FL compared with that in\ncentralized training. It causes the locally trained models of clients to move\nin different directions. On the one hand, it slows down or even stalls the\nglobal updates, leading to inefficient communication. On the other hand, it\nenlarges the distances between local models, resulting in an aggregated global\nmodel with poor performance. Fortunately, these shortcomings can be mitigated\nby reducing the angle between the directions that local models move in. Based\non this fact, we propose FedCos, which reduces the directional inconsistency of\nlocal models by introducing a cosine-similarity penalty. It promotes the local\nmodel iterations towards an auxiliary global direction. Moreover, our approach\nis auto-adapt to various non-IID settings without an elaborate selection of\nhyperparameters. The experimental results show that FedCos outperforms the\nwell-known baselines and can enhance them under a variety of FL scenes,\nincluding varying degrees of data heterogeneity, different number of\nparticipants, and cross-silo and cross-device settings. Besides, FedCos\nimproves communication efficiency by 2 to 5 times. With the help of FedCos,\nmultiple FL methods require significantly fewer communication rounds than\nbefore to obtain a model with comparable performance.",
    "descriptor": "\nComments: 11 pages, 13 figures\n",
    "authors": [
      "Hao Zhang",
      "Tingting Wu",
      "Siyao Cheng",
      "Jie Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2204.03174"
  },
  {
    "id": "arXiv:2204.03178",
    "title": "3M: Multi-loss, Multi-path and Multi-level Neural Networks for speech  recognition",
    "abstract": "Recently, Conformer based CTC/AED model has become a mainstream architecture\nfor ASR. In this paper, based on our prior work, we identify and integrate\nseveral approaches to achieve further improvements for ASR tasks, which we\ndenote as multi-loss, multi-path and multi-level, summarized as \"3M\" model.\nSpecifically, multi-loss refers to the joint CTC/AED loss and multi-path\ndenotes the Mixture-of-Experts(MoE) architecture which can effectively increase\nthe model capacity without remarkably increasing computation cost. Multi-level\nmeans that we introduce auxiliary loss at multiple level of a deep model to\nhelp training. We evaluate our proposed method on the public WenetSpeech\ndataset and experimental results show that the proposed method provides\n12.2%-17.6% relative CER improvement over the baseline model trained by Wenet\ntoolkit. On our large scale dataset of 150k hours corpus, the 3M model has also\nshown obvious superiority over the baseline Conformer model.",
    "descriptor": "\nComments: 5 pages, 1 figure. Submitted to INTERSPEECH 2022\n",
    "authors": [
      "Zhao You",
      "Shulin Feng",
      "Dan Su",
      "Dong Yu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2204.03178"
  },
  {
    "id": "arXiv:2204.03181",
    "title": "Reaching Consensus in the Byzantine Empire: A Comprehensive Review of  BFT Consensus Algorithms",
    "abstract": "Byzantine fault-tolerant (BFT) consensus algorithms are at the core of\nproviding safety and liveness guarantees for distributed systems that must\noperate in the presence of arbitrary failures. Recently, numerous new BFT\nalgorithms have been proposed, not least due to the traction blockchain\ntechnologies have garnered in search for consensus solutions that offer high\nthroughput, low latency, and robust system designs. In this paper, we conduct a\nsystematic survey of selected and distinguished BFT algorithms that have\nreceived attention in academia and industry alike. We perform a qualitative\ncomparison among all algorithms we review along the lines of messaging and time\ncomplexities. Furthermore, we decompose each consensus algorithm into its\nconstituent subprotocols for replication and view change backed by intuitive\nfigures illustrating its message-passing pattern; we also elaborate on the\nstrengths and weaknesses of each algorithm as compared to the state of the art.",
    "descriptor": "",
    "authors": [
      "Gengrui Zhang",
      "Fei Pan",
      "Michael Dang'ana",
      "Yunhao Mao",
      "Shashank Motepalli",
      "Shiquan Zhang",
      "Hans-Arno Jacobsen"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2204.03181"
  },
  {
    "id": "arXiv:2204.03187",
    "title": "Distributed Statistical Min-Max Learning in the Presence of Byzantine  Agents",
    "abstract": "Recent years have witnessed a growing interest in the topic of min-max\noptimization, owing to its relevance in the context of generative adversarial\nnetworks (GANs), robust control and optimization, and reinforcement learning.\nMotivated by this line of work, we consider a multi-agent min-max learning\nproblem, and focus on the emerging challenge of contending with worst-case\nByzantine adversarial agents in such a setup. By drawing on recent results from\nrobust statistics, we design a robust distributed variant of the extra-gradient\nalgorithm - a popular algorithmic approach for min-max optimization. Our main\ncontribution is to provide a crisp analysis of the proposed robust\nextra-gradient algorithm for smooth convex-concave and smooth strongly\nconvex-strongly concave functions. Specifically, we establish statistical rates\nof convergence to approximate saddle points. Our rates are near-optimal, and\nreveal both the effect of adversarial corruption and the benefit of\ncollaboration among the non-faulty agents. Notably, this is the first paper to\nprovide formal theoretical guarantees for large-scale distributed min-max\nlearning in the presence of adversarial agents.",
    "descriptor": "",
    "authors": [
      "Arman Adibi",
      "Aritra Mitra",
      "George J. Pappas",
      "Hamed Hassani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2204.03187"
  },
  {
    "id": "arXiv:2204.03189",
    "title": "Separation of concerning things: a simpler basis for defining and  programming with the C/C++ memory model (extended version)",
    "abstract": "The C/C++ memory model provides an interface and execution model for\nprogrammers of concurrent (shared-variable) code. It provides a range of\nmechanisms that abstract from underlying hardware memory models -- that govern\nhow multicore architectures handle concurrent accesses to main memory -- as\nwell as abstracting from compiler transformations. The C standard describes the\nmemory model in terms of cross-thread relationships between events, and has\nbeen influenced by several research works that are similarly based. In this\npaper we provide a thread-local definition of the fundamental principles of the\nC memory model, which, for concise concurrent code, serves as a basis for\nrelatively straightforward reasoning about the effects of the C ordering\nmechanisms. We argue that this definition is more practical from a programming\nperspective and is amenable to analysis by already established techniques for\nconcurrent code. The key aspect is that the memory model definition is separate\nto other considerations of a rich programming language such as C, in\nparticular, expression evaluation and optimisations, though we show how to\nreason about those considerations in the presence of C concurrency. A major\nsimplification of our framework compared to the description in the C standard\nand related work in the literature is separating out considerations around the\n\"lack of multicopy atomicity\", a concept that is in any case irrelevant to\ndevelopers of code for x86, Arm, RISC-V or SPARC architectures. We show how the\nframework is convenient for reasoning about well-structured code, and for\nformally addressing unintuitive behaviours such as \"out-of-thin-air\" writes.",
    "descriptor": "",
    "authors": [
      "Robert J. Colvin"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2204.03189"
  },
  {
    "id": "arXiv:2204.03191",
    "title": "Efficient Community Detection in Large-Scale Dynamic Networks Using  Topological Data Analysis",
    "abstract": "In this paper, we propose a method that extends the persistence-based\ntopological data analysis (TDA) that is typically used for characterizing\nshapes to general networks. We introduce the concept of the community tree, a\ntree structure established based on clique communities from the clique\npercolation method, to summarize the topological structures in a network from a\npersistence perspective. Furthermore, we develop efficient algorithms to\nconstruct and update community trees by maintaining a series of clique graphs\nin the form of spanning forests, in which each spanning tree is built on an\nunderlying Euler Tour tree. With the information revealed by community trees\nand the corresponding persistence diagrams, our proposed approach is able to\ndetect clique communities and keep track of the major structural changes during\ntheir evolution given a stability threshold. The results demonstrate its\neffectiveness in extracting useful structural insights for time-varying social\nnetworks.",
    "descriptor": "",
    "authors": [
      "Wei Guo",
      "Ruqian Chen",
      "Yen-Chi Chen",
      "Ashis G. Banerjee"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2204.03191"
  },
  {
    "id": "arXiv:2204.03195",
    "title": "3D Perception based Imitation Learning under Limited Demonstration for  Laparoscope Control in Robotic Surgery",
    "abstract": "Automatic laparoscope motion control is fundamentally important for surgeons\nto efficiently perform operations. However, its traditional control methods\nbased on tool tracking without considering information hidden in surgical\nscenes are not intelligent enough, while the latest supervised imitation\nlearning (IL)-based methods require expensive sensor data and suffer from\ndistribution mismatch issues caused by limited demonstrations. In this paper,\nwe propose a novel Imitation Learning framework for Laparoscope Control (ILLC)\nwith reinforcement learning (RL), which can efficiently learn the control\npolicy from limited surgical video clips. Specially, we first extract surgical\nlaparoscope trajectories from unlabeled videos as the demonstrations and\nreconstruct the corresponding surgical scenes. To fully learn from limited\nmotion trajectory demonstrations, we propose Shape Preserving Trajectory\nAugmentation (SPTA) to augment these data, and build a simulation environment\nthat supports parallel RGB-D rendering to reinforce the RL policy for\ninteracting with the environment efficiently. With adversarial training for IL,\nwe obtain the laparoscope control policy based on the generated rollouts and\nsurgical demonstrations. Extensive experiments are conducted in unseen\nreconstructed surgical scenes, and our method outperforms the previous IL\nmethods, which proves the feasibility of our unified learning-based framework\nfor laparoscope control.",
    "descriptor": "\nComments: 7 pages, 7 figures, 2022 IEEE International Conference on Robotics and Automation (ICRA)\n",
    "authors": [
      "Bin Li",
      "Ruofeng Wei",
      "Jiaqi Xu",
      "Bo Lu",
      "Chi-Hang Yee",
      "Chi-Fai Ng",
      "Pheng-Ann Heng",
      "Qi Dou",
      "Yun-Hui Liu"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2204.03195"
  },
  {
    "id": "arXiv:2204.03196",
    "title": "A Framework for Following Temporal Logic Instructions with Unknown  Causal Dependencies",
    "abstract": "Teaching a deep reinforcement learning (RL) agent to follow instructions in\nmulti-task environments is a challenging problem. We consider that user defines\nevery task by a linear temporal logic (LTL) formula. However, some causal\ndependencies in complex environments may be unknown to the user in advance.\nHence, when human user is specifying instructions, the robot cannot solve the\ntasks by simply following the given instructions. In this work, we propose a\nhierarchical reinforcement learning (HRL) framework in which a symbolic\ntransition model is learned to efficiently produce high-level plans that can\nguide the agent efficiently solve different tasks. Specifically, the symbolic\ntransition model is learned by inductive logic programming (ILP) to capture\nlogic rules of state transitions. By planning over the product of the symbolic\ntransition model and the automaton derived from the LTL formula, the agent can\nresolve causal dependencies and break a causally complex problem down into a\nsequence of simpler low-level sub-tasks. We evaluate the proposed framework on\nthree environments in both discrete and continuous domains, showing advantages\nover previous representative methods.",
    "descriptor": "",
    "authors": [
      "Duo Xu",
      "Faramarz Fekri"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2204.03196"
  },
  {
    "id": "arXiv:2204.03200",
    "title": "The Distressing Ads That Persist: Uncovering The Harms of Targeted  Weight-Loss Ads Among Users with Histories of Disordered Eating",
    "abstract": "Targeted advertising can harm vulnerable groups when it targets individuals'\npersonal and psychological vulnerabilities. We focus on how targeted\nweight-loss advertisements harm people with histories of disordered eating. We\nidentify three features of targeted advertising that cause harm: the\npersistence of personal data that can expose vulnerabilities, over-simplifying\nalgorithmic relevancy models, and design patterns encouraging engagement that\ncan facilitate unhealthy behavior. Through a series of semi-structured\ninterviews with individuals with histories of unhealthy body stigma, dieting,\nand disordered eating, we found that targeted weight-loss ads reinforced low\nself-esteem and deepened pre-existing anxieties around food and exercise. At\nthe same time, we observed that targeted individuals demonstrated agency and\nresistance against distressing ads. Drawing on scholarship in postcolonial\nenvironmental studies, we use the concept of slow violence to articulate how\nonline targeted advertising inflicts harms that may not be immediately\nidentifiable. CAUTION: This paper includes media that could be triggering,\nparticularly to people with an eating disorder. Please use caution when\nreading, printing, or disseminating this paper.",
    "descriptor": "",
    "authors": [
      "Liza Gak",
      "Seyi Olojo",
      "Niloufar Salehi"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2204.03200"
  },
  {
    "id": "arXiv:2204.03201",
    "title": "A new multiphysics finite element method for a Biot model with secondary  consolidation",
    "abstract": "In this paper, we propose a new multiphysics finite element method for a Biot\nmodel with secondary consolidation in soil dynamics. To better describe the\nprocesses of deformation and diffusion underlying in the original model, we\nreformulate Biot model by a new multiphysics approach, which transforms the\nfluid-solid coupled problem to a fluid coupled problem--a generalized Stokes\nproblem and a diffusion problem. Then, we give the energy law and prior error\nestimate of the weak solution. And we design a fully discrete time-stepping\nscheme to use mixed finite element method for $P_2-P_1-P_1$ element pairs to\napproximate the space variables and backward Euler method for the time\nvariable, and we prove the discrete energy laws and the optimal convergence\norder error estimates. Also, we show some numerical examples to verify the\ntheoretical results. Finally, we draw a conclusion to summarize the main\nresults of this paper.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2112.12947. text overlap with arXiv:2112.12947\n",
    "authors": [
      "Zhihao Ge",
      "Wenlong He"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)"
    ],
    "url": "https://arxiv.org/abs/2204.03201"
  },
  {
    "id": "arXiv:2204.03206",
    "title": "L2G: A Simple Local-to-Global Knowledge Transfer Framework for Weakly  Supervised Semantic Segmentation",
    "abstract": "Mining precise class-aware attention maps, a.k.a, class activation maps, is\nessential for weakly supervised semantic segmentation. In this paper, we\npresent L2G, a simple online local-to-global knowledge transfer framework for\nhigh-quality object attention mining. We observe that classification models can\ndiscover object regions with more details when replacing the input image with\nits local patches. Taking this into account, we first leverage a local\nclassification network to extract attentions from multiple local patches\nrandomly cropped from the input image. Then, we utilize a global network to\nlearn complementary attention knowledge across multiple local attention maps\nonline. Our framework conducts the global network to learn the captured rich\nobject detail knowledge from a global view and thereby produces high-quality\nattention maps that can be directly used as pseudo annotations for semantic\nsegmentation networks. Experiments show that our method attains 72.1% and 44.2%\nmIoU scores on the validation set of PASCAL VOC 2012 and MS COCO 2014,\nrespectively, setting new state-of-the-art records. Code is available at\nhttps://github.com/PengtaoJiang/L2G.",
    "descriptor": "\nComments: Accepted at CVPR 2022\n",
    "authors": [
      "Peng-Tao Jiang",
      "Yuqi Yang",
      "Qibin Hou",
      "Yunchao Wei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.03206"
  },
  {
    "id": "arXiv:2204.03207",
    "title": "BIMxAR: BIM-Empowered Augmented Reality for Learning Architectural  Representations",
    "abstract": "Literature review shows limited research investigating the utilization of\nAugmented Reality (AR) to improve learning and understanding architectural\nrepresentations, specifically section views. In this study, we present an AR\nsystem prototype (BIMxAR), its new and accurate building-scale registration\nmethod, and its novel visualization features that facilitate the comprehension\nof building construction systems, materials configuration, and 3D section views\nof complex structures through the integration of AR, Building Information\nModeling (BIM), and physical buildings. A pilot user study found improvements\nafter students studied building section views in a physical building with AR,\nthough not statistically significant, in terms of scores of the Santa Barbara\nSolids Test (SBST) and the Architectural Representations Test (ART). When\nincorporating time as a performance factor, the ART timed scores show a\nsignificant improvement in the posttest session. BIMxAR has the potential to\nenhance the students spatial abilities, particularly in understanding buildings\nand complex section views.",
    "descriptor": "",
    "authors": [
      "Ziad Ashour",
      "Zohreh Shaghaghian",
      "Wei Yan"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2204.03207"
  },
  {
    "id": "arXiv:2204.03208",
    "title": "A Joint Learning Approach for Semi-supervised Neural Topic Modeling",
    "abstract": "Topic models are some of the most popular ways to represent textual data in\nan interpret-able manner. Recently, advances in deep generative models,\nspecifically auto-encoding variational Bayes (AEVB), have led to the\nintroduction of unsupervised neural topic models, which leverage deep\ngenerative models as opposed to traditional statistics-based topic models. We\nextend upon these neural topic models by introducing the Label-Indexed Neural\nTopic Model (LI-NTM), which is, to the extent of our knowledge, the first\neffective upstream semi-supervised neural topic model. We find that LI-NTM\noutperforms existing neural topic models in document reconstruction benchmarks,\nwith the most notable results in low labeled data regimes and for data-sets\nwith informative labels; furthermore, our jointly learned classifier\noutperforms baseline classifiers in ablation studies.",
    "descriptor": "\nComments: To appear in the 6th ACL Workshop on Structured Prediction for NLP (SPNLP)\n",
    "authors": [
      "Jeffrey Chiu",
      "Rajat Mittal",
      "Neehal Tumma",
      "Abhishek Sharma",
      "Finale Doshi-Velez"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2204.03208"
  },
  {
    "id": "arXiv:2204.03209",
    "title": "Speeding Up Sparsification using Inner Product Search Data Structures",
    "abstract": "We present a general framework that utilizes different efficient data\nstructures to improve various sparsification problems involving an iterative\nprocess. We also provide insights and characterization for different iterative\nprocess, and answer that when should we use which data structures in what type\nof problem. We obtain improved running time for the following problems.\n* For constructing linear-sized spectral sparsifier (Batson, Spielman and\nSrivastava, 2012), all the existing deterministic algorithms require\n$\\Omega(d^4)$ time. In this work, we provide the first deterministic algorithm\nthat breaks that barrier which runs in $O(d^{\\omega+1})$ time, where $\\omega$\nis the exponent of matrix multiplication.\n* For one-sided Kadison-Singer-typed discrepancy problem, we give fast\nalgorithms for both small and large number of iterations.\n* For experimental design problem, we speed up a key swapping process.\nIn the heart of our work is the design of a variety of different inner\nproduct search data structures that have efficient initialization, query and\nupdate time, compatible to dimensionality reduction and robust against adaptive\nadversary.",
    "descriptor": "",
    "authors": [
      "Zhao Song",
      "Zhaozhuo Xu",
      "Lichen Zhang"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2204.03209"
  },
  {
    "id": "arXiv:2204.03211",
    "title": "Elastic Model Aggregation with Parameter Service",
    "abstract": "Model aggregation, the process that updates model parameters, is an important\nstep for model convergence in distributed deep learning (DDL). However, the\nparameter server (PS), a popular paradigm of performing model aggregation,\ncauses CPU underutilization in deep learning (DL) clusters, due to the bursty\nnature of aggregation and static resource allocation. To remedy this problem,\nwe propose Parameter Service, an elastic model aggregation framework for DDL\ntraining, which decouples the function of model aggregation from individual\ntraining jobs and provides a shared model aggregation service to all jobs in\nthe cluster. In Parameter Service, model aggregations are efficiently packed\nand dynamically migrated to fit into the available CPUs with negligible time\noverhead. Furthermore, Parameter Service can elastically manage its CPU\nresources based on its load to enhance resource efficiency. We have implemented\nParameter Service in a prototype system called AutoPS and evaluated it via\ntestbed experimentation and trace-driven simulations. AutoPS reduces up to 75%\nof CPU consumption with little or no performance impact on the training jobs.\nThe design of Parameter Service is transparent to the users and can be\nincorporated in popular DL frameworks.",
    "descriptor": "",
    "authors": [
      "Juncheng Gu",
      "Mosharaf Chowdhury",
      "Kang G. Shin",
      "Aditya Akella"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2204.03211"
  },
  {
    "id": "arXiv:2204.03214",
    "title": "Transformer-Based Language Models for Software Vulnerability Detection:  Performance, Model's Security and Platforms",
    "abstract": "The large transformer-based language models demonstrate excellent performance\nin natural language processing. By considering the closeness of natural\nlanguages to the high-level programming language such as C/C++, this work\nstudies how good are the large transformer-based language models detecting\nsoftware vulnerabilities. Our results demonstrate the well performance of these\nmodels on software vulnerability detection. The answer enables extending\ntransformer-based language models to vulnerability detection and leveraging\nsuperior performance beyond the natural language processing domain. Besides, we\nperform the model's security check using Microsoft's Counterfit, a command-line\ntool to assess the model's security. Our results find that these models are\nvulnerable to adversarial examples. In this regard, we present a simple\ncountermeasure and its result. Experimenting with large models is always a\nchallenge due to the requirement of computing resources and platforms/libraries\n& dependencies. Based on the experiences and difficulties we faced during this\nwork, we present our recommendation while choosing the platforms to run these\nlarge models. Moreover, the popular platforms are surveyed thoroughly in this\npaper.",
    "descriptor": "\nComments: 15 pages\n",
    "authors": [
      "Chandra Thapa",
      "Seung Ick Jang",
      "Muhammad Ejaz Ahmed",
      "Seyit Camtepe",
      "Josef Pieprzyk",
      "Surya Nepal"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.03214"
  },
  {
    "id": "arXiv:2204.03216",
    "title": "Neural Implicit Flow: a mesh-agnostic dimensionality reduction paradigm  of spatio-temporal data",
    "abstract": "High-dimensional spatio-temporal dynamics can often be encoded in a\nlow-dimensional subspace. Engineering applications for modeling,\ncharacterization, design, and control of such large-scale systems often rely on\ndimensionality reduction to make solutions computationally tractable in\nreal-time. Common existing paradigms for dimensionality reduction include\nlinear methods, such as the singular value decomposition (SVD), and nonlinear\nmethods, such as variants of convolutional autoencoders (CAE). However, these\nencoding techniques lack the ability to efficiently represent the complexity\nassociated with spatio-temporal data, which often requires variable geometry,\nnon-uniform grid resolution, adaptive meshing, and/or parametric\ndependencies.To resolve these practical engineering challenges, we propose a\ngeneral framework called Neural Implicit Flow (NIF) that enables a\nmesh-agnostic, low-rank representation of large-scale, parametric,\nspatial-temporal data. NIF consists of two modified multilayer perceptrons\n(MLPs): (i) ShapeNet, which isolates and represents the spatial complexity, and\n(ii) ParameterNet, which accounts for any other input complexity, including\nparametric dependencies, time, and sensor measurements. We demonstrate the\nutility of NIF for parametric surrogate modeling, enabling the interpretable\nrepresentation and compression of complex spatio-temporal dynamics, efficient\nmany-spatial-query tasks, and improved generalization performance for sparse\nreconstruction.",
    "descriptor": "\nComments: 56 pages\n",
    "authors": [
      "Shaowu Pan",
      "Steven L. Brunton",
      "J. Nathan Kutz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2204.03216"
  },
  {
    "id": "arXiv:2204.03217",
    "title": "Resiliency of Nonlinear Control Systems to Stealthy Sensor Attacks",
    "abstract": "In this work, we focus on analyzing vulnerability of nonlinear dynamical\ncontrol systems to stealthy sensor attacks. We start by defining the notion of\nstealthy attacks in the most general form by leveraging Neyman-Pearson lemma;\nspecifically, an attack is considered to be stealthy if it is stealthy from\n(i.e., undetected by) any intrusion detector -- i.e., the probability of the\ndetection is not better than a random guess. We then provide a sufficient\ncondition under which a nonlinear control system is vulnerable to stealthy\nattacks, in terms of moving the system to an unsafe region due to the attacks.\nIn particular, we show that if the closed-loop system is incrementally\nexponentially stable while the open-loop plant is incrementally unstable, then\nthe system is vulnerable to stealthy yet impactful attacks on sensors. Finally,\nwe illustrate our results on a case study.",
    "descriptor": "",
    "authors": [
      "Amir Khazraei",
      "Miroslav Pajic"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2204.03217"
  },
  {
    "id": "arXiv:2204.03223",
    "title": "Semantic-functional Communications for Multiuser Event Transmissions via  Random Maps",
    "abstract": "This work introduces a new perspective for physical media sharing in\nmultiuser communication by jointly considering (i) the meaning of the\ntransmitted message and (ii) its function at the end user. Specifically, we\nhave defined a scenario where multiple users (sensors) are continuously\ntransmitting their own states concerning a predetermined event. On the receiver\nside there is an alarm monitoring system, whose function is to decide whether\nsuch a predetermined event has happened in a certain time period and, if yes,\nin which user. The media access control protocol proposed constitutes an\nalternative approach to the conventional physical layer methods, because the\nreceiver does not decode the received waveform directly; rather, the relative\nposition of the absence or presence of energy within a multidimensional\nresource space carries the (semantic) information. The protocol introduced here\nprovides high efficiency in multiuser networks that operate with\nevent-triggered sampling by enabling a constructive reconstruction of\ntransmission collisions. We have demonstrated that the proposed method leads to\na better event transmission efficiency than conventional methods like TDMA and\nslotted ALOHA. Remarkably, the proposed method achieves 100\\% efficiency and\n0\\% error probability in almost all the studied cases, while consistently\noutperforming TDMA and slotted ALOHA.",
    "descriptor": "",
    "authors": [
      "Pedro E. G\u00f3ria Silva",
      "Pl\u00ednio S. Dester",
      "Harun Siljak",
      "Nicola Marchetti",
      "Pedro H. J. Nardelli",
      "Rausley A. A. de Souza"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2204.03223"
  },
  {
    "id": "arXiv:2204.03225",
    "title": "Explicit Feature Interaction-aware Graph Neural Networks",
    "abstract": "Graph neural networks are powerful methods to handle graph-structured data.\nHowever, existing graph neural networks only learn higher-order feature\ninteractions implicitly. Thus, they cannot capture information that occurred in\nlow-order feature interactions. To overcome this problem, we propose Explicit\nFeature Interaction-aware Graph Neural Network (EFI-GNN), which explicitly\nlearns arbitrary-order feature interactions. EFI-GNN can jointly learn with any\nother graph neural network. We demonstrate that the joint learning method\nalways enhances performance on the various node classification tasks.\nFurthermore, since EFI-GNN is inherently a linear model, we can interpret the\nprediction result of EFI-GNN. With the computation rule, we can obtain an\nany-order feature's effect on the decision. By that, we visualize the effects\nof the first-order and second-order features as a form of a heatmap.",
    "descriptor": "\nComments: 9 pages, 9 figures, pre-print\n",
    "authors": [
      "Minkyu Kim",
      "Hyun-Soo Choi",
      "Jinho Kim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.03225"
  },
  {
    "id": "arXiv:2204.03227",
    "title": "Accelerating Attention through Gradient-Based Learned Runtime Pruning",
    "abstract": "Self-attention is a key enabler of state-of-art accuracy for various\ntransformer-based Natural Language Processing models. This attention mechanism\ncalculates a correlation score for each word with respect to the other words in\na sentence. Commonly, only a small subset of words highly correlates with the\nword under attention, which is only determined at runtime. As such, a\nsignificant amount of computation is inconsequential due to low attention\nscores and can potentially be pruned. The main challenge is finding the\nthreshold for the scores below which subsequent computation will be\ninconsequential. Although such a threshold is discrete, this paper formulates\nits search through a soft differentiable regularizer integrated into the loss\nfunction of the training. This formulation piggy backs on the back-propagation\ntraining to analytically co-optimize the threshold and the weights\nsimultaneously, striking a formally optimal balance between accuracy and\ncomputation pruning. To best utilize this mathematical innovation, we devise a\nbit-serial architecture, dubbed LeOPArd, for transformer language models with\nbit-level early termination microarchitectural mechanism. We evaluate our\ndesign across 43 back-end tasks for MemN2N, BERT, ALBERT, GPT-2, and Vision\ntransformer models. Post-layout results show that, on average, LeOPArd yields\n1.9x and 3.9x speedup and energy reduction, respectively, while keeping the\naverage accuracy virtually intact (<0.2% degradation)",
    "descriptor": "\nComments: First three authors contributed equally; published at ISCA 2022\n",
    "authors": [
      "Zhenge Li",
      "Soroush Ghodrati",
      "Amir Yazdanbakhsh",
      "Hadi Esmaeilzadeh",
      "Mingu Kang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Hardware Architecture (cs.AR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.03227"
  },
  {
    "id": "arXiv:2204.03230",
    "title": "What You See is What You Get: Distributional Generalization for  Algorithm Design in Deep Learning",
    "abstract": "We investigate and leverage a connection between Differential Privacy (DP)\nand the recently proposed notion of Distributional Generalization (DG).\nApplying this connection, we introduce new conceptual tools for designing\ndeep-learning methods that bypass \"pathologies\" of standard stochastic gradient\ndescent (SGD). First, we prove that differentially private methods satisfy a\n\"What You See Is What You Get (WYSIWYG)\" generalization guarantee: whatever a\nmodel does on its train data is almost exactly what it will do at test time.\nThis guarantee is formally captured by distributional generalization. WYSIWYG\nenables principled algorithm design in deep learning by reducing\n$\\textit{generalization}$ concerns to $\\textit{optimization}$ ones: in order to\nmitigate unwanted behavior at test time, it is provably sufficient to mitigate\nthis behavior on the train data. This is notably false for standard (non-DP)\nmethods, hence this observation has applications even when privacy is not\nrequired. For example, importance sampling is known to fail for standard SGD,\nbut we show that it has exactly the intended effect for DP-trained models.\nThus, with DP-SGD, unlike with SGD, we can influence test-time behavior by\nmaking principled train-time interventions. We use these insights to construct\nsimple algorithms which match or outperform SOTA in several distributional\nrobustness applications, and to significantly improve the privacy vs. disparate\nimpact trade-off of DP-SGD. Finally, we also improve on known theoretical\nbounds relating differential privacy, stability, and distributional\ngeneralization.",
    "descriptor": "\nComments: First two authors contributed equally\n",
    "authors": [
      "Bogdan Kulynych",
      "Yao-Yuan Yang",
      "Yaodong Yu",
      "Jaros\u0142aw B\u0142asiok",
      "Preetum Nakkiran"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2204.03230"
  },
  {
    "id": "arXiv:2204.03236",
    "title": "Learning to Solve Travelling Salesman Problem with Hardness-adaptive  Curriculum",
    "abstract": "Various neural network models have been proposed to tackle combinatorial\noptimization problems such as the travelling salesman problem (TSP). Existing\nlearning-based TSP methods adopt a simple setting that the training and testing\ndata are independent and identically distributed. However, the existing\nliterature fails to solve TSP instances when training and testing data have\ndifferent distributions. Concretely, we find that different training and\ntesting distribution will result in more difficult TSP instances, i.e., the\nsolution obtained by the model has a large gap from the optimal solution. To\ntackle this problem, in this work, we study learning-based TSP methods when\ntraining and testing data have different distributions using adaptive-hardness,\ni.e., how difficult a TSP instance can be for a solver. This problem is\nchallenging because it is non-trivial to (1) define hardness measurement\nquantitatively; (2) efficiently and continuously generate sufficiently hard TSP\ninstances upon model training; (3) fully utilize instances with different\nlevels of hardness to learn a more powerful TSP solver. To solve these\nchallenges, we first propose a principled hardness measurement to quantify the\nhardness of TSP instances. Then, we propose a hardness-adaptive generator to\ngenerate instances with different hardness. We further propose a curriculum\nlearner fully utilizing these instances to train the TSP solver. Experiments\nshow that our hardness-adaptive generator can generate instances ten times\nharder than the existing methods, and our proposed method achieves significant\nimprovement over state-of-the-art models in terms of the optimality gap.",
    "descriptor": "\nComments: AAAI 2022\n",
    "authors": [
      "Zeyang Zhang",
      "Ziwei Zhang",
      "Xin Wang",
      "Wenwu Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.03236"
  },
  {
    "id": "arXiv:2204.03237",
    "title": "Rule-based Procedural Tree Modeling Approach",
    "abstract": "In some entertainment and virtual reality applications, it is necessary to\nmodel and draw the real world realistically, so as to improve the fidelity of\nnatural scenes and make users have a better sense of immersion. However, due to\nthe morphological structure of trees The complexity and variety present many\nchallenges for photorealistic modeling and rendering of trees. This paper\nreviews the progress achieved in photorealistic modeling and rendering of tree\nbranches, leaves, and bark over the past few decades. The main achievement is\nmainly a rule-based procedural tree modeling method.",
    "descriptor": "",
    "authors": [
      "Yinhui Yang",
      "Rui Wang",
      "Yuchi Huo"
    ],
    "subjectives": [
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2204.03237"
  },
  {
    "id": "arXiv:2204.03240",
    "title": "Speech Pre-training with Acoustic Piece",
    "abstract": "Previous speech pre-training methods, such as wav2vec2.0 and HuBERT,\npre-train a Transformer encoder to learn deep representations from audio data,\nwith objectives predicting either elements from latent vector quantized space\nor pre-generated labels (known as target codes) with offline clustering.\nHowever, those training signals (quantized elements or codes) are independent\nacross different tokens without considering their relations. According to our\nobservation and analysis, the target codes share obvious patterns aligned with\nphonemized text data. Based on that, we propose to leverage those patterns to\nbetter pre-train the model considering the relations among the codes. The\npatterns we extracted, called \"acoustic piece\"s, are from the sentence piece\nresult of HuBERT codes. With the acoustic piece as the training signal, we can\nimplicitly bridge the input audio and natural language, which benefits\naudio-to-text tasks, such as automatic speech recognition (ASR). Simple but\neffective, our method \"HuBERT-AP\" significantly outperforms strong baselines on\nthe LibriSpeech ASR task.",
    "descriptor": "\nComments: 5 pages, 4 figures; submitted to Interspeech 2022\n",
    "authors": [
      "Shuo Ren",
      "Shujie Liu",
      "Yu Wu",
      "Long Zhou",
      "Furu Wei"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2204.03240"
  },
  {
    "id": "arXiv:2204.03241",
    "title": "Three Laws of Technology Rise or Fall",
    "abstract": "Newton's laws of motion perfectly explain or approximate physical phenomena\nin our everyday life. Are there any laws that explain or approximate\ntechnology's rise or fall? After reviewing thirteen information technologies\nthat succeeded, this article concludes three laws of technology and derives\nfive corollaries to explain or approximate the rise or fall of technology.\nThree laws are the laws of technology inertia, technology change force, and\ntechnology action and reaction. Five corollaries are the corollaries of\nmeasurement of technology change force, technology breakthrough, technology\nmonopoly, technology openness, and technology business opportunity. I present\nhow to use the laws and the corollaries to analyze an emerging technology --\nthe open-source RISC-V processor. Also, I elaborate on benchmarks' role in\napplying those laws.",
    "descriptor": "",
    "authors": [
      "Jianfeng Zhan"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2204.03241"
  },
  {
    "id": "arXiv:2204.03243",
    "title": "Pretraining Text Encoders with Adversarial Mixture of Training Signal  Generators",
    "abstract": "We present a new framework AMOS that pretrains text encoders with an\nAdversarial learning curriculum via a Mixture Of Signals from multiple\nauxiliary generators. Following ELECTRA-style pretraining, the main encoder is\ntrained as a discriminator to detect replaced tokens generated by auxiliary\nmasked language models (MLMs). Different from ELECTRA which trains one MLM as\nthe generator, we jointly train multiple MLMs of different sizes to provide\ntraining signals at various levels of difficulty. To push the discriminator to\nlearn better with challenging replaced tokens, we learn mixture weights over\nthe auxiliary MLMs' outputs to maximize the discriminator loss by\nbackpropagating the gradient from the discriminator via Gumbel-Softmax. For\nbetter pretraining efficiency, we propose a way to assemble multiple MLMs into\none unified auxiliary model. AMOS outperforms ELECTRA and recent\nstate-of-the-art pretrained models by about 1 point on the GLUE benchmark for\nBERT base-sized models.",
    "descriptor": "\nComments: ICLR 2022. (Code and Models: this https URL)\n",
    "authors": [
      "Yu Meng",
      "Chenyan Xiong",
      "Payal Bajaj",
      "Saurabh Tiwary",
      "Paul Bennett",
      "Jiawei Han",
      "Xia Song"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.03243"
  },
  {
    "id": "arXiv:2204.03245",
    "title": "HIT-UAV: A High-altitude Infrared Thermal Dataset for Unmanned Aerial  Vehicles",
    "abstract": "This paper presents a High-altitude infrared thermal dataset, HIT-UAV, for\nobject detection applications on Unmanned Aerial Vehicles (UAVs). HIT-UAV\ncontains 2898 infrared thermal images extracted from 43470 frames. These images\nare collected by UAV from schools, parking lots, roads, playgrounds, etc.\nHIT-UAV provides different flight data for each place, including flight\naltitude (from 60 to 130 meters), camera perspective (from 30 to 90 degrees),\ndate, and daylight intensity. For each image, the HIT-UAV manual annotates\nobject instances with two types of the bounding box (oriented and standard) to\naddress the challenge that object instances have a significant overlap in\naerial images. To the best of our knowledge, HIT-UAV is the first publicly\navailable high-altitude infrared thermal UAV dataset for persons and vehicles\ndetection. Moreover, we trained and evaluated the benchmark detection\nalgorithms (YOLOv4 and YOLOv4-tiny) on HIT-UAV. Compared to the visual light\ndataset, the detection algorithms have excellent performance on HIT-UAV because\nthe infrared thermal images do not contain a significant quantity of irrelevant\ninformation with detection objects. This indicates that infrared thermal\ndatasets can significantly promote the development of object detection\napplications. We hope HIT-UAV contributes to UAV applications such as traffic\nsurveillance and city monitoring at night. The dataset is available at\nhttps://github.com/suojiashun/HIT-UAV-Infrared-Thermal-Dataset.",
    "descriptor": "",
    "authors": [
      "Jiashun Suo",
      "Tianyi Wang",
      "Xingzhou Zhang",
      "Haiyang Chen",
      "Wei Zhou",
      "Weisong Shi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.03245"
  },
  {
    "id": "arXiv:2204.03246",
    "title": "Analysis of a class of globally divergence-free HDG methods for  stationary Navier-Stokes equations",
    "abstract": "This paper analyzes a class of globally divergence-free (and therefore\npressure-robust) hybridizable discontinuous Galerkin (HDG) finite element\nmethods for stationary Navier-Stokes equations. The methods use the\n$\\mathcal{P}_{k}/\\mathcal{P}_{k-1}$ $(k\\geq1)$ discontinuous finite element\ncombination for the velocity and pressure approximations in the interior of\nelements, and piecewise $\\mathcal{P}_k/\\mathcal{P}_{k}$ for the trace\napproximations of the velocity and pressure on the inter-element boundaries. It\nis shown that the uniqueness condition for the discrete solution is guaranteed\nby that for the continuous solution together with a sufficiently small mesh\nsize. Based on the derived discrete HDG Sobolev embedding properties, optimal\nerror estimates are obtained. Numerical experiments are performed to verify the\ntheoretical analysis.",
    "descriptor": "",
    "authors": [
      "Gang Chen",
      "Xiaoping Xie"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2204.03246"
  },
  {
    "id": "arXiv:2204.03249",
    "title": "Expressive Singing Synthesis Using Local Style Token and Dual-path Pitch  Encoder",
    "abstract": "This paper proposes a controllable singing voice synthesis system capable of\ngenerating expressive singing voice with two novel methodologies. First, a\nlocal style token module, which predicts frame-level style tokens from an input\npitch and text sequence, is proposed to allow the singing voice system to\ncontrol musical expression often unspecified in sheet music (e.g., breathing\nand intensity). Second, we propose a dual-path pitch encoder with a choice of\ntwo different pitch inputs: MIDI pitch sequence or f0 contour. Because the\ninitial generation of a singing voice is usually executed by taking a MIDI\npitch sequence, one can later extract an f0 contour from the generated singing\nvoice and modify the f0 contour to a finer level as desired. Through\nquantitative and qualitative evaluations, we confirmed that the proposed model\ncould control various musical expressions while not sacrificing the sound\nquality of the singing voice synthesis system.",
    "descriptor": "\nComments: 4 pages, Submitted to Interspeech 2022\n",
    "authors": [
      "Juheon Lee",
      "Hyeong-Seok Choi",
      "Kyogu Lee"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2204.03249"
  },
  {
    "id": "arXiv:2204.03251",
    "title": "Automatic WordNet Construction using Word Sense Induction through  Sentence Embeddings",
    "abstract": "Language resources such as wordnets remain indispensable tools for different\nnatural language tasks and applications. However, for low-resource languages\nsuch as Filipino, existing wordnets are old and outdated, and producing new\nones may be slow and costly in terms of time and resources. In this paper, we\npropose an automatic method for constructing a wordnet from scratch using only\nan unlabeled corpus and a sentence embeddings-based language model. Using this,\nwe produce FilWordNet, a new wordnet that supplants and improves the outdated\nFilipino WordNet. We evaluate our automatically-induced senses and synsets by\nmatching them with senses from the Princeton WordNet, as well as comparing the\nsynsets to the old Filipino WordNet. We empirically show that our method can\ninduce existing, as well as potentially new, senses and synsets automatically\nwithout the need for human supervision.",
    "descriptor": "\nComments: 8 pages, 4 figures, 2 tables\n",
    "authors": [
      "Dan John Velasco",
      "Axel Alba",
      "Trisha Gail Pelagio",
      "Bryce Anthony Ramirez",
      "Jan Christian Blaise Cruz",
      "Charibeth Cheng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.03251"
  },
  {
    "id": "arXiv:2204.03252",
    "title": "A note on asymptotically exact a posteriori error estimates for mixed  Laplace eigenvalue problems",
    "abstract": "We derive optimal and asymptotically exact a posteriori error estimates for\nthe approximation of the Laplace eigenvalue problem. To do so, we combine two\nresults from the literature. First, we use the hypercircle techniques developed\nfor mixed eigenvalue approximations with Raviart-Thomas Finite elements. In\naddition, we use the post-processings introduced for the eigenvalue and\neigenfunction based on mixed approximations with the Brezzi-Douglas-Marini\nFinite element. To combine these approaches, we define a novel additional local\npost-processing for the fluxes that appropriately modifies the divergence.\nConsequently, the new flux can be used to derive upper bounds and still shows\ngood approximation properties. Numerical examples validate the theory and\nmotivate the use of an adaptive mesh refinement.",
    "descriptor": "",
    "authors": [
      "Philip L. Lederer"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2204.03252"
  },
  {
    "id": "arXiv:2204.03254",
    "title": "The General Index of Software Engineering Papers",
    "abstract": "We introduce the General Index of Software Engineering Papers, a dataset of\nfulltext-indexed papers from the most prominent scientific venues in the field\nof Software Engineering. The dataset includes both complete bibliographic\ninformation and indexed ngrams (sequence of contiguous words after removal of\nstopwords and non-words, for a total of 577 276 382 unique n-grams in this\nrelease) with length 1 to 5 for 44 581 papers retrieved from 34 venues over the\n1971-2020 period.The dataset serves use cases in the field of meta-research,\nallowing to introspect the output of software engineering research even when\naccess to papers or scholarly search engines is not possible (e.g., due to\ncontractual reasons). The dataset also contributes to making such analyses\nreproducible and independently verifiable, as opposed to what happens when they\nare conducted using 3rd-party and non-open scholarly indexing services.The\ndataset is available as a portable Postgres database dump and released as open\ndata.",
    "descriptor": "\nComments: MSR 2022 - The 2022 Mining Software Repositories Conference, May 2022, Pittsburgh, Pennsylvania, United States\n",
    "authors": [
      "Zeinab Abou Khalil",
      "Stefano Zacchiroli"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2204.03254"
  },
  {
    "id": "arXiv:2204.03255",
    "title": "Arabic Text-To-Speech (TTS) Data Preparation",
    "abstract": "People may be puzzled by the fact that voice over recordings data sets exist\nin addition to Text-to-Speech (TTS), Synthesis system advancements, albeit this\nis not the case. The goal of this study is to explain the relevance of TTS as\nwell as the data preparation procedures. TTS relies heavily on recorded data\nsince it can have a substantial influence on the outcomes of TTS modules.\nFurthermore, whether the domain is specialized or general, appropriate data\nshould be developed to address all predicted language variants and domains.\nDifferent recording methodologies, taking into account quality and behavior,\nmay also be advantageous in the development of the module. In light of the lack\nof Arabic language in present synthesizing systems, numerous variables that\nimpact the flow of recorded utterances are being considered in order to\nmanipulate an Arabic TTS module. In this study, two viewpoints will be\ndiscussed: linguistics and the creation of high-quality recordings for TTS. The\npurpose of this work is to offer light on how ground-truth utterances may\ninfluence the evolution of speech systems in terms of naturalness,\nintelligibility, and understanding. Well provide voice actor specs as well as\ndata specs that will assist both voice actors and voice coaches in the studio\nas well as the annotators who will be evaluating the audios.",
    "descriptor": "",
    "authors": [
      "Hala Al Masri",
      "Muhy Eddin Za'ter"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2204.03255"
  },
  {
    "id": "arXiv:2204.03257",
    "title": "Pan-cancer computational histopathology reveals tumor mutational burden  status through weakly-supervised deep learning",
    "abstract": "Tumor mutational burden (TMB) is a potential genomic biomarker that can help\nidentify patients who will benefit from immunotherapy across a variety of\ncancers. We included whole slide images (WSIs) of 3228 diagnostic slides from\nthe Cancer Genome Atlas and 531 WSIs from the Clinical Proteomic Tumor Analysis\nConsortium for the development and verification of a pan-cancer TMB prediction\nmodel (PC-TMB). We proposed a multiscale weakly-supervised deep learning\nframework for predicting TMB of seven types of tumors based only on routinely\nused hematoxylin-eosin (H&E)-stained WSIs. PC-TMB achieved a mean area under\ncurve (AUC) of 0.818 (0.804-0.831) in the cross-validation cohort, which was\nsuperior to the best single-scale model. In comparison with the\nstate-of-the-art TMB prediction model from previous publications, our\nmultiscale model achieved better performance over previously reported models.\nIn addition, the improvements of PC-TMB over the single-tumor models were also\nconfirmed by the ablation tests on 10x magnification. The PC-TMB algorithm also\nexhibited good generalization on external validation cohort with AUC of 0.732\n(0.683-0.761). PC-TMB possessed a comparable survival-risk stratification\nperformance to the TMB measured by whole exome sequencing, but with low cost\nand being time-efficient for providing a prognostic biomarker of multiple solid\ntumors. Moreover, spatial heterogeneity of TMB within tumors was also\nidentified through our PC-TMB, which might enable image-based screening for\nmolecular biomarkers with spatial variation and potential exploring for\ngenotype-spatial heterogeneity relationships.",
    "descriptor": "\nComments: 19 pages; 8 figures\n",
    "authors": [
      "Siteng Chen",
      "Jinxi Xiang",
      "Xiyue Wang",
      "Jun Zhang",
      "Sen Yang",
      "Junzhou Huang",
      "Wei Yang",
      "Junhua Zheng",
      "Xiao Han"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.03257"
  },
  {
    "id": "arXiv:2204.03262",
    "title": "Korean Online Hate Speech Dataset for Multilabel Classification: How Can  Social Science Aid Developing Better Hate Speech Dataset?",
    "abstract": "We suggest a multilabel Korean online hate speech dataset that covers seven\ncategories of hate speech: (1) Race and Nationality, (2) Religion, (3)\nRegionalism, (4) Ageism, (5) Misogyny, (6) Sexual Minorities, and (7) Male. Our\n35K dataset consists of 24K online comments with Krippendorff's Alpha label\naccordance of .713, 2.2K neutral sentences from Wikipedia, 1.7K additionally\nlabeled sentences generated by the Human-in-the-Loop procedure and\nrule-generated 7.1K neutral sentences. The base model with 24K initial dataset\nachieved the accuracy of LRAP .892, but improved to .919 after being combined\nwith 11K additional data. Unlike the conventional binary hate and non-hate\ndichotomy approach, we designed a dataset considering both the cultural and\nlinguistic context to overcome the limitations of western culture-based English\ntexts. Thus, this paper is not only limited to presenting a local hate speech\ndataset but extends as a manual for building a more generalized hate speech\ndataset with diverse cultural backgrounds based on social science perspectives.",
    "descriptor": "\nComments: 12 pages, 3 tables\n",
    "authors": [
      "TaeYoung Kang",
      "Eunrang Kwon",
      "Junbum Lee",
      "Youngeun Nam",
      "Junmo Song",
      "JeongKyu Suh"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2204.03262"
  },
  {
    "id": "arXiv:2204.03266",
    "title": "Lower Bounds for Restricted Schemes in the Two-Adaptive Bitprobe Model",
    "abstract": "In the adaptive bitprobe model answering membership queries in two bitprobes,\nwe consider the class of restricted schemes as introduced by Kesh and Sharma\n(Discrete Applied Mathematics 2021). In that paper, the authors showed that\nsuch restricted schemes storing subsets of size 2 require\n$\\Omega(m^\\frac{2}{3})$ space. In this paper, we generalise the result to\narbitrary subsets of size $n$, and prove that the space required for such\nrestricted schemes will be $\\Omega(\\left(\\frac{m}{n}\\right)^{1 -\n\\frac{1}{\\lfloor n / 4 \\rfloor + 2}})$.",
    "descriptor": "\nComments: 18 pages, IWOCA2022\n",
    "authors": [
      "Sreshth Aggarwal",
      "Deepanjan Kesh",
      "Divyam Singal"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2204.03266"
  },
  {
    "id": "arXiv:2204.03270",
    "title": "Context-Sensitive Temporal Feature Learning for Gait Recognition",
    "abstract": "Although gait recognition has drawn increasing research attention recently,\nit remains challenging to learn discriminative temporal representation, since\nthe silhouette differences are quite subtle in spatial domain. Inspired by the\nobservation that human can distinguish gaits of different subjects by\nadaptively focusing on temporal clips with different time scales, we propose a\ncontext-sensitive temporal feature learning (CSTL) network for gait\nrecognition. CSTL produces temporal features in three scales, and adaptively\naggregates them according to the contextual information from local and global\nperspectives. Specifically, CSTL contains an adaptive temporal aggregation\nmodule that subsequently performs local relation modeling and global relation\nmodeling to fuse the multi-scale features. Besides, in order to remedy the\nspatial feature corruption caused by temporal operations, CSTL incorporates a\nsalient spatial feature learning (SSFL) module to select groups of\ndiscriminative spatial features. Particularly, we utilize transformers to\nimplement the global relation modeling and the SSFL module. To the best of our\nknowledge, this is the first work that adopts transformer in gait recognition.\nExtensive experiments conducted on three datasets demonstrate the\nstate-of-the-art performance. Concretely, we achieve rank-1 accuracies of\n98.7%, 96.2% and 88.7% under normal-walking, bag-carrying and coat-wearing\nconditions on CASIA-B, 97.5% on OU-MVLP and 50.6% on GREW.",
    "descriptor": "\nComments: Submitted to TPAMI\n",
    "authors": [
      "Xiaohu Huang",
      "Duowang Zhu",
      "Xinggang Wang",
      "Hao Wang",
      "Bo Yang",
      "Botao He",
      "Wenyu Liu",
      "Bin Feng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.03270"
  },
  {
    "id": "arXiv:2204.03272",
    "title": "mulEEG: A Multi-View Representation Learning on EEG Signals",
    "abstract": "Modeling effective representations using multiple views that positively\ninfluence each other is challenging, and the existing methods perform poorly on\nElectroencephalogram (EEG) signals for sleep-staging tasks. In this paper, we\npropose a novel multi-view self-supervised method (mulEEG) for unsupervised EEG\nrepresentation learning. Our method attempts to effectively utilize the\ncomplementary information available in multiple views to learn better\nrepresentations. We introduce diverse loss that further encourages\ncomplementary information across multiple views. Our method with no access to\nlabels beats the supervised training while outperforming multi-view baseline\nmethods on transfer learning experiments carried out on sleep-staging tasks. We\nposit that our method was able to learn better representations by using\ncomplementary multi-views.",
    "descriptor": "\nComments: Preprint version\n",
    "authors": [
      "Vamsi Kumar",
      "Likith Reddy",
      "Shivam Kumar Sharma",
      "Kamalakar Dadi",
      "Chiranjeevi Yarra",
      "Bapi S. Raju",
      "Srijithesh Rajendran"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2204.03272"
  },
  {
    "id": "arXiv:2204.03276",
    "title": "PALBERT: Teaching ALBERT to Ponder",
    "abstract": "Currently, pre-trained models can be considered the default choice for a wide\nrange of NLP tasks. Despite their SoTA results, there is practical evidence\nthat these models may require a different number of computing layers for\ndifferent input sequences, since evaluating all layers leads to overconfidence\non wrong predictions (namely overthinking). This problem can potentially be\nsolved by implementing adaptive computation time approaches, which were first\ndesigned to improve inference speed. Recently proposed PonderNet may be a\npromising solution for performing an early exit by treating the exit layers\nindex as a latent variable. However, the originally proposed exit criterion,\nrelying on sampling from trained posterior distribution on the probability of\nexiting from i-th layer, introduces major variance in model outputs,\nsignificantly reducing the resulting models performance. In this paper, we\npropose Ponder ALBERT (PALBERT): an improvement to PonderNet with a novel\ndeterministic Q-exit criterion and a revisited model architecture. We compared\nPALBERT with recent methods for performing an early exit. We observed that the\nproposed changes can be considered significant improvements on the original\nPonderNet architecture and outperform PABEE on a wide range of GLUE tasks. In\naddition, we also performed an in-depth ablation study of the proposed\narchitecture to further understand Lambda layers and their performance.",
    "descriptor": "",
    "authors": [
      "Nikita Balagansky",
      "Daniil Gavrilov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.03276"
  },
  {
    "id": "arXiv:2204.03281",
    "title": "Single-shot Embedding Dimension Search in Recommender System",
    "abstract": "As a crucial component of most modern deep recommender systems, feature\nembedding maps high-dimensional sparse user/item features into low-dimensional\ndense embeddings. However, these embeddings are usually assigned a unified\ndimension, which suffers from the following issues: (1) high memory usage and\ncomputation cost. (2) sub-optimal performance due to inferior dimension\nassignments. In order to alleviate the above issues, some works focus on\nautomated embedding dimension search by formulating it as hyper-parameter\noptimization or embedding pruning problems. However, they either require\nwell-designed search space for hyperparameters or need time-consuming\noptimization procedures. In this paper, we propose a Single-Shot Embedding\nDimension Search method, called SSEDS, which can efficiently assign dimensions\nfor each feature field via a single-shot embedding pruning operation while\nmaintaining the recommendation accuracy of the model. Specifically, it\nintroduces a criterion for identifying the importance of each embedding\ndimension for each feature field. As a result, SSEDS could automatically obtain\nmixed-dimensional embeddings by explicitly reducing redundant embedding\ndimensions based on the corresponding dimension importance ranking and the\npredefined parameter budget. Furthermore, the proposed SSEDS is model-agnostic,\nmeaning that it could be integrated into different base recommendation models.\nThe extensive offline experiments are conducted on two widely used public\ndatasets for CTR prediction tasks, and the results demonstrate that SSEDS can\nstill achieve strong recommendation performance even if it has reduced 90\\%\nparameters. Moreover, SSEDS has also been deployed on the WeChat Subscription\nplatform for practical recommendation services. The 7-day online A/B test\nresults show that SSEDS can significantly improve the performance of the online\nrecommendation model.",
    "descriptor": "\nComments: This paper has been accepted by SIGIR'22\n",
    "authors": [
      "Liang Qu",
      "Yonghong Ye",
      "Ningzhi Tang",
      "Lixin Zhang",
      "Yuhui Shi",
      "Hongzhi Yin"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2204.03281"
  },
  {
    "id": "arXiv:2204.03286",
    "title": "Entailment Graph Learning with Textual Entailment and Soft Transitivity",
    "abstract": "Typed entailment graphs try to learn the entailment relations between\npredicates from text and model them as edges between predicate nodes. The\nconstruction of entailment graphs usually suffers from severe sparsity and\nunreliability of distributional similarity. We propose a two-stage method,\nEntailment Graph with Textual Entailment and Transitivity (EGT2). EGT2 learns\nlocal entailment relations by recognizing possible textual entailment between\ntemplate sentences formed by typed CCG-parsed predicates. Based on the\ngenerated local graph, EGT2 then uses three novel soft transitivity constraints\nto consider the logical transitivity in entailment structures. Experiments on\nbenchmark datasets show that EGT2 can well model the transitivity in entailment\ngraph to alleviate the sparsity issue, and lead to significant improvement over\ncurrent state-of-the-art methods.",
    "descriptor": "\nComments: 9 pages, 2 figures, accepted to ACL 2022 (main conference)\n",
    "authors": [
      "Zhibin Chen",
      "Yansong Feng",
      "Dongyan Zhao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.03286"
  },
  {
    "id": "arXiv:2204.03289",
    "title": "Persistent Memory Objects: Fast and Easy Crash Consistency for  Persistent Memory",
    "abstract": "DIMM-compatible persistent memory unites memory and storage. Prior works\nutilize persistent memory either by combining the filesystem with direct access\non memory mapped files or by managing it as a collection of objects while\nabolishing the POSIX abstraction. In contrast, we propose retaining the POSIX\nabstraction and extending it to provide support for persistent memory, using\nPersistent Memory Objects (PMOs). In this work, we design and implement PMOs, a\ncrash-consistent abstraction for managing persistent memory. We introduce\npsync, a single system call, that a programmer can use to specify crash\nconsistency points in their code, without needing to orchestrate durability\nexplicitly. When rendering data crash consistent, our design incurs a overhead\nof $\\approx 25\\%$ and $\\approx 21\\%$ for parallel workloads and FileBench,\nrespectively, compared to a system without crash consistency. Compared to\nNOVA-Fortis, our design provides a speedup of $\\approx 1.67\\times$ and $\\approx\n3\\times$ for the two set of benchmarks, respectively.",
    "descriptor": "\nComments: 12 pages, 15 figures\n",
    "authors": [
      "Derrick Greenspan",
      "Naveed Ul Mustafa",
      "Zoran Kolega",
      "Mark Heinrich",
      "Yan Solihin"
    ],
    "subjectives": [
      "Operating Systems (cs.OS)"
    ],
    "url": "https://arxiv.org/abs/2204.03289"
  },
  {
    "id": "arXiv:2204.03290",
    "title": "Memory Performance of AMD EPYC Rome and Intel Cascade Lake SP Server  Processors",
    "abstract": "Modern processors, in particular within the server segment, integrate more\ncores with each generation. This increases their complexity in general, and\nthat of the memory hierarchy in particular. Software executed on such\nprocessors can suffer from performance degradation when data is distributed\ndisadvantageously over the available resources. To optimize data placement and\naccess patterns, an in-depth analysis of the processor design and its\nimplications for performance is necessary. This paper describes and\nexperimentally evaluates the memory hierarchy of AMD EPYC Rome and Intel Xeon\nCascade Lake SP server processors in detail. Their distinct microarchitectures\ncause different performance patterns for memory latencies, in particular for\nremote cache accesses. Our findings illustrate the complex NUMA properties and\nhow data placement and cache coherence states impact access latencies to local\nand remote locations. This paper also compares theoretical and effective\nbandwidths for accessing data at the different memory levels and main memory\nbandwidth saturation at reduced core counts. The presented insight is a\nfoundation for modeling performance of the given microarchitectures, which\nenables practical performance engineering of complex applications. Moreover,\nsecurity research on side-channel attacks can also leverage the presented\nfindings.",
    "descriptor": "",
    "authors": [
      "Markus Velten",
      "Robert Sch\u00f6ne",
      "Thomas Ilsche",
      "Daniel Hackenberg"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2204.03290"
  },
  {
    "id": "arXiv:2204.03291",
    "title": "Energy-stable global radial basis function methods on summation-by-parts  form",
    "abstract": "Radial basis function methods are powerful tools in numerical analysis and\nhave demonstrated good properties in many different simulations. However, for\ntime-dependent partial differential equations, only a few stability results are\nknown. In particular, if boundary conditions are included, stability issues\nfrequently occur. The question we address in this paper is how provable\nstability for RBF methods can be obtained. We develop and construct\nenergy-stable radial basis function methods using the general framework of\nsummation-by-parts operators often used in the Finite Difference and Finite\nElement communities.",
    "descriptor": "\nComments: 22 pages, 8 Figures\n",
    "authors": [
      "Jan Glaubitz",
      "Jan Nordstr\u00f6m",
      "Philipp \u00d6ffner"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2204.03291"
  },
  {
    "id": "arXiv:2204.03293",
    "title": "Enhancing Semantic Code Search with Multimodal Contrastive Learning and  Soft Data Augmentation",
    "abstract": "Code search aims to retrieve the most semantically relevant code snippet for\na given natural language query. Recently, large-scale code pre-trained models\nsuch as CodeBERT and GraphCodeBERT learn generic representations of source code\nand have achieved substantial improvement on code search task. However, the\nhigh-quality sequence-level representations of code snippets have not been\nsufficiently explored. In this paper, we propose a new approach with multimodal\ncontrastive learning and soft data augmentation for code search. Multimodal\ncontrastive learning is used to pull together the representations of code-query\npairs and push apart the unpaired code snippets and queries. Moreover, data\naugmentation is critical in contrastive learning for learning high-quality\nrepresentations. However, only semantic-preserving augmentations for source\ncode are considered in existing work. In this work, we propose to do soft data\naugmentation by dynamically masking and replacing some tokens in code sequences\nto generate code snippets that are similar but not necessarily\nsemantic-preserving as positive samples for paired queries. We conduct\nextensive experiments to evaluate the effectiveness of our approach on a\nlarge-scale dataset with six programming languages. The experimental results\nshow that our approach significantly outperforms the state-of-the-art methods.\nWe also adapt our techniques to several pre-trained models such as RoBERTa and\nCodeBERT, and significantly boost their performance on the code search task.",
    "descriptor": "",
    "authors": [
      "Ensheng Shi",
      "Wenchao Gub",
      "Yanlin Wang",
      "Lun Du",
      "Hongyu Zhang",
      "Shi Han",
      "Dongmei Zhang",
      "Hongbin Sun"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.03293"
  },
  {
    "id": "arXiv:2204.03296",
    "title": "Deep Learning for Real Time Satellite Pose Estimation on Low Power Edge  TPU",
    "abstract": "Pose estimation of an uncooperative space resident object is a key asset\ntowards autonomy in close proximity operations. In this context monocular\ncameras are a valuable solution because of their low system requirements.\nHowever, the associated image processing algorithms are either too\ncomputationally expensive for real time on-board implementation, or not enough\naccurate. In this paper we propose a pose estimation software exploiting neural\nnetwork architectures which can be scaled to different accuracy-latency\ntrade-offs. We designed our pipeline to be compatible with Edge Tensor\nProcessing Units to show how low power machine learning accelerators could\nenable Artificial Intelligence exploitation in space. The neural networks were\ntested both on the benchmark Spacecraft Pose Estimation Dataset, and on the\npurposely developed Cosmo Photorealistic Dataset, which depicts a COSMO-SkyMed\nsatellite in a variety of random poses and steerable solar panels orientations.\nThe lightest version of our architecture achieves state-of-the-art accuracy on\nboth datasets but at a fraction of networks complexity, running at 7.7 frames\nper second on a Coral Dev Board Mini consuming just 2.2W.",
    "descriptor": "\nComments: Submitted to IEEE Transactions on Aerospace and Electronic Systems\n",
    "authors": [
      "Alessandro Lotti",
      "Dario Modenini",
      "Paolo Tortora",
      "Massimiliano Saponara",
      "Maria A. Perino"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.03296"
  },
  {
    "id": "arXiv:2204.03297",
    "title": "A Multi-Transformation Evolutionary Framework for Influence Maximization  in Social Networks",
    "abstract": "Influence maximization is a key issue for mining the deep information of\nsocial networks, which aims to select a seed set from the network to maximize\nthe number of influenced nodes. To evaluate the influence spread of a seed set\nefficiently, existing works have proposed some proxy models (transformations)\nwith lower computational costs to replace the expensive Monte Carlo simulation\nprocess. These alternate transformations based on network prior knowledge\ninduce different search behaviors with similar characteristics from various\nperspectives. For a specific case, it is difficult for users to determine a\nsuitable transformation a priori. Keeping those in mind, we propose a\nmulti-transformation evolutionary framework for influence maximization (MTEFIM)\nto exploit the potential similarities and unique advantages of alternate\ntransformations and avoid users to determine the most suitable one manually. In\nMTEFIM, multiple transformations are optimized simultaneously as multiple\ntasks. Each transformation is assigned an evolutionary solver. Three major\ncomponents of MTEFIM are conducted: 1) estimating the potential relationship\nacross transformations based on the degree of overlap across individuals (seed\nsets) of different populations, 2) transferring individuals across populations\nadaptively according to the inter-transformation relationship, 3) selecting the\nfinal output seed set containing all the proxy model knowledge. The\neffectiveness of MTEFIM is validated on four real-world social networks.\nExperimental results show that MTEFIM can efficiently utilize the potentially\ntransferable knowledge across multiple transformations to achieve highly\ncompetitive performance compared to several popular IM-specific methods. The\nimplementation of MTEFIM can be accessed at\nhttps://github.com/xiaofangxd/MTEFIM.",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Chao Wang",
      "Jiaxuan Zhao",
      "Lingling Li",
      "Licheng Jiao",
      "Jing Liu",
      "Kai Wu"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2204.03297"
  },
  {
    "id": "arXiv:2204.03299",
    "title": "On the Impact of Social Media Recommendations on Opinion Consensus",
    "abstract": "We consider a discrete opinion formation problem in a setting where agents\nare influenced by both information diffused by their social relations and from\nrecommendations received directly from the social media manager. We study how\nthe \"strength\" of the influence of the social media and the homophily ratio\naffect the probability of the agents of reaching a consensus and how these\nfactors can determine the type of consensus reached. In a simple 2-symmetric\nblock model we prove that agents converge either to a consensus or to a\npersistent disagreement. In particular, we show that when the homophily ratio\nis large, the social media has a very low capacity of determining the outcome\nof the opinion dynamics. On the other hand, when the homophily ratio is low,\nthe social media influence can have an important role on the dynamics, either\nby making harder to reach a consensus or inducing it on extreme opinions.\nFinally, in order to extend our analysis to more general and realistic settings\nwe give some experimental evidences that our results still hold on general\nnetworks.",
    "descriptor": "\nComments: A previous version of this work was published at conference AIxIA 2021. The conference paper will be published in Proceedings Volume: \"AIxIA 2021 - Advances in Artificial Intelligence - XXth International Conference of the Italian Association for Artificial Intelligence, Virtual Event, December 1-3, Revised Selected Papers\"\n",
    "authors": [
      "Vincenzo Auletta",
      "Antonio Coppola",
      "Diodato Ferraioli"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computer Science and Game Theory (cs.GT)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2204.03299"
  },
  {
    "id": "arXiv:2204.03301",
    "title": "Sequence-Based Extractive Summarisation for Scientific Articles",
    "abstract": "This paper presents the results of research on supervised extractive text\nsummarisation for scientific articles. We show that a simple sequential tagging\nmodel based only on the text within a document achieves high results against a\nsimple classification model. Improvements can be achieved through additional\nsentence-level features, though these were minimal. Through further analysis,\nwe show the potential of the sequential model relying on the structure of the\ndocument depending on the academic discipline which the document is from.",
    "descriptor": "\nComments: 7 pages\n",
    "authors": [
      "Daniel Kershaw",
      "Rob Koeling"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2204.03301"
  },
  {
    "id": "arXiv:2204.03304",
    "title": "Federated Learning from Only Unlabeled Data with  Class-Conditional-Sharing Clients",
    "abstract": "Supervised federated learning (FL) enables multiple clients to share the\ntrained model without sharing their labeled data. However, potential clients\nmight even be reluctant to label their own data, which could limit the\napplicability of FL in practice. In this paper, we show the possibility of\nunsupervised FL whose model is still a classifier for predicting class labels,\nif the class-prior probabilities are shifted while the class-conditional\ndistributions are shared among the unlabeled data owned by the clients. We\npropose federation of unsupervised learning (FedUL), where the unlabeled data\nare transformed into surrogate labeled data for each of the clients, a modified\nmodel is trained by supervised FL, and the wanted model is recovered from the\nmodified model. FedUL is a very general solution to unsupervised FL: it is\ncompatible with many supervised FL methods, and the recovery of the wanted\nmodel can be theoretically guaranteed as if the data have been labeled.\nExperiments on benchmark and real-world datasets demonstrate the effectiveness\nof FedUL. Code is available at https://github.com/lunanbit/FedUL.",
    "descriptor": "\nComments: ICLR 2022 camera-ready version\n",
    "authors": [
      "Nan Lu",
      "Zhao Wang",
      "Xiaoxiao Li",
      "Gang Niu",
      "Qi Dou",
      "Masashi Sugiyama"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.03304"
  },
  {
    "id": "arXiv:2204.03307",
    "title": "Genre-conditioned Acoustic Models for Automatic Lyrics Transcription of  Polyphonic Music",
    "abstract": "Lyrics transcription of polyphonic music is challenging not only because the\nsinging vocals are corrupted by the background music, but also because the\nbackground music and the singing style vary across music genres, such as pop,\nmetal, and hip hop, which affects lyrics intelligibility of the song in\ndifferent ways. In this work, we propose to transcribe the lyrics of polyphonic\nmusic using a novel genre-conditioned network. The proposed network adopts\npre-trained model parameters, and incorporates the genre adapters between\nlayers to capture different genre peculiarities for lyrics-genre pairs, thereby\nonly requiring lightweight genre-specific parameters for training. Our\nexperiments show that the proposed genre-conditioned network outperforms the\nexisting lyrics transcription systems.",
    "descriptor": "\nComments: 5 pages, 1 figure, accepted by IEEE ICASSP 2022\n",
    "authors": [
      "Xiaoxue Gao",
      "Chitralekha Gupta",
      "Haizhou Li"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2204.03307"
  },
  {
    "id": "arXiv:2204.03311",
    "title": "How to design a network architecture using availability",
    "abstract": "The best way to design a network is to take into account Availability values\nand Capacity Planning. You already saw Availability expressed with numbers such\nas 99.99%. The purpose of this document is to introduce the way to compute\nAvailability values using Reliability Block Diagrams.",
    "descriptor": "\nComments: 9 pages\n",
    "authors": [
      "Gilbert Moisio"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2204.03311"
  },
  {
    "id": "arXiv:2204.03312",
    "title": "ESPRIT versus ESPIRA for reconstruction of short cosine sums and its  application",
    "abstract": "In this paper we introduce two new algorithms for stable approximation with\nand recovery of short cosine sums. The used signal model contains cosine terms\nwith arbitrary real positive frequency parameters and therefore strongly\ngeneralizes usual Fourier sums. The proposed methods both employ a set of\nequidistant signal values as input data. The ESPRIT method for cosine sums is a\nProny-like method and applies matrix pencils of Toeplitz+Hankel matrices while\nthe ESPIRA method is based on rational approximation of DCT data and can be\nunderstood as a matrix pencil method for special Loewner matrices. Compared to\nknown numerical methods for recovery of exponential sums, the design of the\nconsidered new algorithms directly exploits the special real structure of the\nsignal model and therefore usually provides real parameter estimates for noisy\ninput data, while the known general recovery algorithms for complex exponential\nsums tend to yield complex parameters in this case.",
    "descriptor": "\nComments: 29 pages, 6 figures\n",
    "authors": [
      "Nadiia Derevianko",
      "Gerlind Plonka",
      "Raha Razavi"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2204.03312"
  },
  {
    "id": "arXiv:2204.03313",
    "title": "Situation Awareness for Autonomous Vehicles Using Blockchain-based  Service Cooperation",
    "abstract": "Efficient Vehicle-to-Everything enabling cooperation and enhanced\ndecision-making for autonomous vehicles is essential for optimized and safe\ntraffic. Real-time decision-making based on vehicle sensor data, other traffic\ndata, and environmental and contextual data becomes imperative. As a part of\nsuch Intelligent Traffic Systems, cooperation between different stakeholders\nneeds to be facilitated rapidly, reliably, and securely. The Internet of Things\nprovides the fabric to connect these stakeholders who share their data, refined\ninformation, and provided services with each other. However, these cloud-based\nsystems struggle to meet the real-time requirements for smart traffic due to\nlong distances across networks. Here, edge computing systems bring the data and\nservices into the close proximity of fast-moving vehicles, reducing information\ndelivery latencies and improving privacy as sensitive data is processed\nlocally. To solve the issues of trust and latency in data sharing between these\nstakeholders, we propose a decentralized framework that enables smart contracts\nbetween traffic data producers and consumers based on blockchain. Autonomous\nvehicles connect to a local edge server, share their data, or use services\nbased on agreements, for which the cooperating edge servers across the system\nprovide a platform. We set up proof-of-concept experiments with Hyperledger\nFabric and virtual cars to analyze the system throughput with secure unicast\nand multicast data transmissions. Our results show that multicast transmissions\nin such a scenario boost the throughput up to 2.5 times where the data packets\nof different sizes can be transmitted in less than one second.",
    "descriptor": "\nComments: 16 pages, 4 figures\n",
    "authors": [
      "Huong Nguyen",
      "Tri Nguyen",
      "Teemu Lepp\u00e4nen",
      "Juha Partala",
      "Susanna Pirttikangas"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Computers and Society (cs.CY)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2204.03313"
  },
  {
    "id": "arXiv:2204.03315",
    "title": "Three-Module Modeling For End-to-End Spoken Language Understanding Using  Pre-trained DNN-HMM-Based Acoustic-Phonetic Model",
    "abstract": "In spoken language understanding (SLU), what the user says is converted to\nhis/her intent. Recent work on end-to-end SLU has shown that accuracy can be\nimproved via pre-training approaches. We revisit ideas presented by Lugosch et\nal. using speech pre-training and three-module modeling; however, to ease\nconstruction of the end-to-end SLU model, we use as our phoneme module an\nopen-source acoustic-phonetic model from a DNN-HMM hybrid automatic speech\nrecognition (ASR) system instead of training one from scratch. Hence we\nfine-tune on speech only for the word module, and we apply multi-target\nlearning (MTL) on the word and intent modules to jointly optimize SLU\nperformance. MTL yields a relative reduction of 40% in intent-classification\nerror rates (from 1.0% to 0.6%). Note that our three-module model is a\nstreaming method. The final outcome of the proposed three-module modeling\napproach yields an intent accuracy of 99.4% on FluentSpeech, an intent error\nrate reduction of 50% compared to that of Lugosch et al. Although we focus on\nreal-time streaming methods, we also list non-streaming methods for comparison.",
    "descriptor": "\nComments: Published in INTERSPEECH 2021\n",
    "authors": [
      "Nick J.C. Wang",
      "Lu Wang",
      "Yandan Sun",
      "Haimei Kang",
      "Dejun Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2204.03315"
  },
  {
    "id": "arXiv:2204.03316",
    "title": "Structured Gradient Descent for Fast Robust Low-Rank Hankel Matrix  Completion",
    "abstract": "We study the robust matrix completion problem for the low-rank Hankel matrix,\nwhich detects the sparse corruptions caused by extreme outliers while we try to\nrecover the original Hankel matrix from the partial observation. In this paper,\nwe explore the convenient Hankel structure and propose a novel non-convex\nalgorithm, coined Hankel Structured Gradient Descent (HSGD), for large-scale\nrobust Hankel matrix completion problems. HSGD is highly computing- and\nsample-efficient compared to the state-of-the-arts. The recovery guarantee with\na linear convergence rate has been established for HSGD under some mild\nassumptions. The empirical advantages of HSGD are verified on both synthetic\ndatasets and real-world nuclear magnetic resonance signals.",
    "descriptor": "",
    "authors": [
      "HanQin Cai",
      "Jian-Feng Cai",
      "Juntao You"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2204.03316"
  },
  {
    "id": "arXiv:2204.03319",
    "title": "Swarm behavior tracking based on a deep vision algorithm",
    "abstract": "The intelligent swarm behavior of social insects (such as ants) springs up in\ndifferent environments, promising to provide insights for the study of embodied\nintelligence. Researching swarm behavior requires that researchers could\naccurately track each individual over time. Obviously, manually labeling\nindividual insects in a video is labor-intensive. Automatic tracking methods,\nhowever, also poses serious challenges: (1) individuals are small and similar\nin appearance; (2) frequent interactions with each other cause severe and\nlong-term occlusion. With the advances of artificial intelligence and computing\nvision technologies, we are hopeful to provide a tool to automate monitor\nmultiple insects to address the above challenges. In this paper, we propose a\ndetection and tracking framework for multi-ant tracking in the videos by: (1)\nadopting a two-stage object detection framework using ResNet-50 as backbone and\ncoding the position of regions of interest to locate ants accurately; (2) using\nthe ResNet model to develop the appearance descriptors of ants; (3)\nconstructing long-term appearance sequences and combining them with motion\ninformation to achieve online tracking. To validate our method, we construct an\nant database including 10 videos of ants from different indoor and outdoor\nscenes. We achieve a state-of-the-art performance of 95.7\\% mMOTA and 81.1\\%\nmMOTP in indoor videos, 81.8\\% mMOTA and 81.9\\% mMOTP in outdoor videos.\nAdditionally, Our method runs 6-10 times faster than existing methods for\ninsect tracking. Experimental results demonstrate that our method provides a\npowerful tool for accelerating the unraveling of the mechanisms underlying the\nswarm behavior of social insects.",
    "descriptor": "",
    "authors": [
      "Meihong Wu",
      "Xiaoyan Cao",
      "Shihui Guo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.03319"
  },
  {
    "id": "arXiv:2204.03321",
    "title": "Using Decision Tree as Local Interpretable Model in Autoencoder-based  LIME",
    "abstract": "Nowadays, deep neural networks are being used in many domains because of\ntheir high accuracy results. However, they are considered as \"black box\", means\nthat they are not explainable for humans. On the other hand, in some tasks such\nas medical, economic, and self-driving cars, users want the model to be\ninterpretable to decide if they can trust these results or not. In this work,\nwe present a modified version of an autoencoder-based approach for local\ninterpretability called ALIME. The ALIME itself is inspired by a famous method\ncalled Local Interpretable Model-agnostic Explanations (LIME). LIME generates a\nsingle instance level explanation by generating new data around the instance\nand training a local linear interpretable model. ALIME uses an autoencoder to\nweigh the new data around the sample. Nevertheless, the ALIME uses a linear\nmodel as the interpretable model to be trained locally, just like the LIME.\nThis work proposes a new approach, which uses a decision tree instead of the\nlinear model, as the interpretable model. We evaluate the proposed model in\ncase of stability, local fidelity, and interpretability on different datasets.\nCompared to ALIME, the experiments show significant results on stability and\nlocal fidelity and improved results on interpretability.",
    "descriptor": "\nComments: 7 pages\n",
    "authors": [
      "Niloofar Ranjbar",
      "Reza Safabakhsh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.03321"
  },
  {
    "id": "arXiv:2204.03323",
    "title": "Multi-Sample $\u03b6$-mixup: Richer, More Realistic Synthetic Samples  from a $p$-Series Interpolant",
    "abstract": "Modern deep learning training procedures rely on model regularization\ntechniques such as data augmentation methods, which generate training samples\nthat increase the diversity of data and richness of label information. A\npopular recent method, mixup, uses convex combinations of pairs of original\nsamples to generate new samples. However, as we show in our experiments, mixup\ncan produce undesirable synthetic samples, where the data is sampled off the\nmanifold and can contain incorrect labels. We propose $\\zeta$-mixup, a\ngeneralization of mixup with provably and demonstrably desirable properties\nthat allows convex combinations of $N \\geq 2$ samples, leading to more\nrealistic and diverse outputs that incorporate information from $N$ original\nsamples by using a $p$-series interpolant. We show that, compared to mixup,\n$\\zeta$-mixup better preserves the intrinsic dimensionality of the original\ndatasets, which is a desirable property for training generalizable models.\nFurthermore, we show that our implementation of $\\zeta$-mixup is faster than\nmixup, and extensive evaluation on controlled synthetic and 24 real-world\nnatural and medical image classification datasets shows that $\\zeta$-mixup\noutperforms mixup and traditional data augmentation techniques.",
    "descriptor": "\nComments: 21 pages, 5 figures\n",
    "authors": [
      "Kumar Abhishek",
      "Colin J. Brown",
      "Ghassan Hamarneh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.03323"
  },
  {
    "id": "arXiv:2204.03324",
    "title": "Autoencoding Language Model Based Ensemble Learning for Commonsense  Validation and Explanation",
    "abstract": "An ultimate goal of artificial intelligence is to build computer systems that\ncan understand human languages. Understanding commonsense knowledge about the\nworld expressed in text is one of the foundational and challenging problems to\ncreate such intelligent systems. As a step towards this goal, we present in\nthis paper ALMEn, an Autoencoding Language Model based Ensemble learning method\nfor commonsense validation and explanation. By ensembling several advanced\npre-trained language models including RoBERTa, DeBERTa, and ELECTRA with\nSiamese neural networks, our method can distinguish natural language statements\nthat are against commonsense (validation subtask) and correctly identify the\nreason for making against commonsense (explanation selection subtask).\nExperimental results on the benchmark dataset of SemEval-2020 Task 4 show that\nour method outperforms state-of-the-art models, reaching 97.9% and 95.4%\naccuracies on the validation and explanation selection subtasks, respectively.",
    "descriptor": "",
    "authors": [
      "Ngo Quang Huy",
      "Tu Minh Phuong",
      "Ngo Xuan Bach"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.03324"
  },
  {
    "id": "arXiv:2204.03326",
    "title": "Enabling Deep Learning for All-in EDGE paradigm",
    "abstract": "Deep Learning-based models have been widely investigated, and they have\ndemonstrated significant performance on non-trivial tasks such as speech\nrecognition, image processing, and natural language understanding. However,\nthis is at the cost of substantial data requirements. Considering the\nwidespread proliferation of edge devices (e.g. Internet of Things devices) over\nthe last decade, Deep Learning in the edge paradigm, such as device-cloud\nintegrated platforms, is required to leverage its superior performance.\nMoreover, it is suitable from the data requirements perspective in the edge\nparadigm because the proliferation of edge devices has resulted in an explosion\nin the volume of generated and collected data. However, there are difficulties\ndue to other requirements such as high computation, high latency, and high\nbandwidth caused by Deep Learning applications in real-world scenarios. In this\nregard, this survey paper investigates Deep Learning at the edge, its\narchitecture, enabling technologies, and model adaption techniques, where edge\nservers and edge devices participate in deep learning training and inference.\nFor simplicity, we call this paradigm the All-in EDGE paradigm. Besides, this\npaper presents the key performance metrics for Deep Learning at the All-in EDGE\nparadigm to evaluate various deep learning techniques and choose a suitable\ndesign. Moreover, various open challenges arising from the deployment of Deep\nLearning at the All-in EDGE paradigm are identified and discussed.",
    "descriptor": "\nComments: 18 pages\n",
    "authors": [
      "Praveen Joshi",
      "Haithem Afli",
      "Mohammed Hasanuzzaman",
      "Chandra Thapa",
      "Ted Scully"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2204.03326"
  },
  {
    "id": "arXiv:2204.03328",
    "title": "A Comprehensive Review of Sign Language Recognition: Different Types,  Modalities, and Datasets",
    "abstract": "A machine can understand human activities, and the meaning of signs can help\novercome the communication barriers between the inaudible and ordinary people.\nSign Language Recognition (SLR) is a fascinating research area and a crucial\ntask concerning computer vision and pattern recognition. Recently, SLR usage\nhas increased in many applications, but the environment, background image\nresolution, modalities, and datasets affect the performance a lot. Many\nresearchers have been striving to carry out generic real-time SLR models. This\nreview paper facilitates a comprehensive overview of SLR and discusses the\nneeds, challenges, and problems associated with SLR. We study related works\nabout manual and non-manual, various modalities, and datasets. Research\nprogress and existing state-of-the-art SLR models over the past decade have\nbeen reviewed. Finally, we find the research gap and limitations in this domain\nand suggest future directions. This review paper will be helpful for readers\nand researchers to get complete guidance about SLR and the progressive design\nof the state-of-the-art SLR model",
    "descriptor": "\nComments: communicated to the Computer Science Review (Elsevier) status With Editor\n",
    "authors": [
      "Dr. M. Madhiarasan",
      "Prof. Partha Pratim Roy"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.03328"
  },
  {
    "id": "arXiv:2204.03329",
    "title": "Information-driven Path Planning for Hybrid Aerial Underwater Vehicles",
    "abstract": "This paper presents a novel Rapidly-exploring Adaptive Sampling Tree (RAST)\nalgorithm for the adaptive sampling mission of a hybrid aerial underwater\nvehicle (HAUV) in an air-sea 3D environment. This algorithm innovatively\ncombines the tournament-based point selection sampling strategy, the\ninformation heuristic search process and the framework of Rapidly-exploring\nRandom Tree (RRT) algorithm. Hence can guide the vehicle to the region of\ninterest to scientists for sampling and generate a collision-free path for\nmaximizing information collection by the HAUV under the constraints of\nenvironmental effects of currents or wind and limited budget. The simulation\nresults show that the fast search adaptive sampling tree algorithm has higher\noptimization performance, faster solution speed and better stability than the\nRapidly-exploring Information Gathering Tree (RIGT) algorithm and the particle\nswarm optimization (PSO) algorithm.",
    "descriptor": "",
    "authors": [
      "Zheng Zeng",
      "Chengke Xiong",
      "Xinyi Yuan",
      "Yulin Bai",
      "Yufei Jin",
      "Di Lu",
      "Lian Lian"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2204.03329"
  },
  {
    "id": "arXiv:2204.03330",
    "title": "Coarse-to-Fine Feature Mining for Video Semantic Segmentation",
    "abstract": "The contextual information plays a core role in semantic segmentation. As for\nvideo semantic segmentation, the contexts include static contexts and motional\ncontexts, corresponding to static content and moving content in a video clip,\nrespectively. The static contexts are well exploited in image semantic\nsegmentation by learning multi-scale and global/long-range features. The\nmotional contexts are studied in previous video semantic segmentation. However,\nthere is no research about how to simultaneously learn static and motional\ncontexts which are highly correlated and complementary to each other. To\naddress this problem, we propose a Coarse-to-Fine Feature Mining (CFFM)\ntechnique to learn a unified presentation of static contexts and motional\ncontexts. This technique consists of two parts: coarse-to-fine feature\nassembling and cross-frame feature mining. The former operation prepares data\nfor further processing, enabling the subsequent joint learning of static and\nmotional contexts. The latter operation mines useful information/contexts from\nthe sequential frames to enhance the video contexts of the features of the\ntarget frame. The enhanced features can be directly applied for the final\nprediction. Experimental results on popular benchmarks demonstrate that the\nproposed CFFM performs favorably against state-of-the-art methods for video\nsemantic segmentation. Our implementation is available at\nhttps://github.com/GuoleiSun/VSS-CFFM",
    "descriptor": "\nComments: Accepted to CVPR2022\n",
    "authors": [
      "Guolei Sun",
      "Yun Liu",
      "Henghui Ding",
      "Thomas Probst",
      "Luc Van Gool"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.03330"
  },
  {
    "id": "arXiv:2204.03331",
    "title": "Sparse Optical Flow-Based Line Feature Tracking",
    "abstract": "In this paper we propose a novel sparse optical flow (SOF)-based line feature\ntracking method for the camera pose estimation problem. This method is inspired\nby the point-based SOF algorithm and developed based on an observation that two\nadjacent images in time-varying image sequences satisfy brightness invariant.\nBased on this observation, we re-define the goal of line feature tracking:\ntrack two endpoints of a line feature instead of the entire line based on gray\nvalue matching instead of descriptor matching. To achieve this goal, an\nefficient two endpoint tracking (TET) method is presented: first, describe a\ngiven line feature with its two endpoints; next, track the two endpoints based\non SOF to obtain two new tracked endpoints by minimizing a pixel-level\ngrayscale residual function; finally, connect the two tracked endpoints to\ngenerate a new line feature. The correspondence is established between the\ngiven and the new line feature. Compared with current descriptor-based methods,\nour TET method needs not to compute descriptors and detect line features\nrepeatedly. Naturally, it has an obvious advantage over computation.\nExperiments in several public benchmark datasets show our method yields highly\ncompetitive accuracy with an obvious advantage over speed.",
    "descriptor": "",
    "authors": [
      "Qiang Fu",
      "Hongshan Yu",
      "Islam Ali",
      "Hong Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.03331"
  },
  {
    "id": "arXiv:2204.03332",
    "title": "Predicting Performance of Heterogeneous AI Systems with Discrete-Event  Simulations",
    "abstract": "In recent years, artificial intelligence (AI) technologies have found\nindustrial applications in various fields. AI systems typically possess complex\nsoftware and heterogeneous CPU/GPU hardware architecture, making it difficult\nto answer basic questions considering performance evaluation and software\noptimization. Where is the bottleneck impeding the system? How does the\nperformance scale with the workload? How the speed-up of a specific module\nwould contribute to the whole system? Finding the answers to these questions\nthrough experiments on the real system could require a lot of computational,\nhuman, financial, and time resources. A solution to cut these costs is to use a\nfast and accurate simulation model preparatory to implementing anything in the\nreal system. In this paper, we propose a discrete-event simulation model of a\nhigh-load heterogeneous AI system in the context of video analytics. Using the\nproposed model, we estimate: 1) the performance scalability with the increasing\nnumber of cameras; 2) the performance impact of integrating a new module; 3)\nthe performance gain from optimizing a single module. We show that the\nperformance estimation accuracy of the proposed model is higher than 90%. We\nalso demonstrate, that the considered system possesses a counter-intuitive\nrelationship between workload and performance, which nevertheless is correctly\ninferred by the proposed simulation model.",
    "descriptor": "\nComments: 36th International ECMS Conference on Modelling and Simulation\n",
    "authors": [
      "Vyacheslav Zhdanovskiy",
      "Lev Teplyakov",
      "Anton Grigoryev"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2204.03332"
  },
  {
    "id": "arXiv:2204.03333",
    "title": "Learning to Sieve: Prediction of Grading Curves from Images of Concrete  Aggregate",
    "abstract": "A large component of the building material concrete consists of aggregate\nwith varying particle sizes between 0.125 and 32 mm. Its actual size\ndistribution significantly affects the quality characteristics of the final\nconcrete in both, the fresh and hardened states. The usually unknown variations\nin the size distribution of the aggregate particles, which can be large\nespecially when using recycled aggregate materials, are typically compensated\nby an increased usage of cement which, however, has severe negative impacts on\neconomical and ecological aspects of the concrete production. In order to allow\na precise control of the target properties of the concrete, unknown variations\nin the size distribution have to be quantified to enable a proper adaptation of\nthe concrete's mixture design in real time. To this end, this paper proposes a\ndeep learning based method for the determination of concrete aggregate grading\ncurves. In this context, we propose a network architecture applying multi-scale\nfeature extraction modules in order to handle the strongly diverse object sizes\nof the particles. Furthermore, we propose and publish a novel dataset of\nconcrete aggregate used for the quantitative evaluation of our method.",
    "descriptor": "",
    "authors": [
      "Max Coenen",
      "Dries Beyer",
      "Christian Heipke",
      "Michael Haist"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.03333"
  },
  {
    "id": "arXiv:2204.03338",
    "title": "Online Adaptive Identification of Switched Affine Systems Using a  Two-Tier Filter Architecture with Memory",
    "abstract": "This work proposes an online adaptive identification method for multi-input\nmulti-output (MIMO) switched affine systems with guaranteed parameter\nconvergence. A family of online parameter estimators is used that is equipped\nwith a dual-layer low pass filter architecture to facilitate parameter learning\nand identification of each subsystem. The filters capture information about the\nunknown parameters in the form of a prediction error which is used in the\nparameter estimation algorithm. A salient feature of the proposed method that\ndistinguishes it from most previous results is the use of a memory bank that\nstores filter values and promotes parameter learning during both active and\ninactive phases of a subsystem. Specifically, the learnt experience from the\nprevious active phase of a subsystem is retained in the memory and leveraged\nfor parameter learning in its subsequent active and inactive phases. Further, a\nnew notion of intermittent initial excitation (IIE) is introduced that extends\nthe previously established initial excitation (IE) condition to the switched\nsystem framework. IIE is shown to be sufficient to ensure exponential\nconvergence of the switched system parameters.",
    "descriptor": "",
    "authors": [
      "Pritesh Patel",
      "Sayan Basu Roy",
      "Shubhendu Bhasin"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2204.03338"
  },
  {
    "id": "arXiv:2204.03340",
    "title": "PSTR: End-to-End One-Step Person Search With Transformers",
    "abstract": "We propose a novel one-step transformer-based person search framework, PSTR,\nthat jointly performs person detection and re-identification (re-id) in a\nsingle architecture. PSTR comprises a person search-specialized (PSS) module\nthat contains a detection encoder-decoder for person detection along with a\ndiscriminative re-id decoder for person re-id. The discriminative re-id decoder\nutilizes a multi-level supervision scheme with a shared decoder for\ndiscriminative re-id feature learning and also comprises a part attention block\nto encode relationship between different parts of a person. We further\nintroduce a simple multi-scale scheme to support re-id across person instances\nat different scales. PSTR jointly achieves the diverse objectives of\nobject-level recognition (detection) and instance-level matching (re-id). To\nthe best of our knowledge, we are the first to propose an end-to-end one-step\ntransformer-based person search framework. Experiments are performed on two\npopular benchmarks: CUHK-SYSU and PRW. Our extensive ablations reveal the\nmerits of the proposed contributions. Further, the proposed PSTR sets a new\nstate-of-the-art on both benchmarks. On the challenging PRW benchmark, PSTR\nachieves a mean average precision (mAP) score of 56.5%. The source code is\navailable at \\url{https://github.com/JialeCao001/PSTR}.",
    "descriptor": "\nComments: CVPR2022, Code: this https URL\n",
    "authors": [
      "Jiale Cao",
      "Yanwei Pang",
      "Rao Muhammad Anwer",
      "Hisham Cholakkal",
      "Jin Xie",
      "Mubarak Shah",
      "Fahad Shahbaz Khan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.03340"
  },
  {
    "id": "arXiv:2204.03341",
    "title": "Robust and Explainable Autoencoders for Unsupervised Time Series Outlier  Detection---Extended Version",
    "abstract": "Time series data occurs widely, and outlier detection is a fundamental\nproblem in data mining, which has numerous applications. Existing\nautoencoder-based approaches deliver state-of-the-art performance on\nchallenging real-world data but are vulnerable to outliers and exhibit low\nexplainability. To address these two limitations, we propose robust and\nexplainable unsupervised autoencoder frameworks that decompose an input time\nseries into a clean time series and an outlier time series using autoencoders.\nImproved explainability is achieved because clean time series are better\nexplained with easy-to-understand patterns such as trends and periodicities. We\nprovide insight into this by means of a post-hoc explainability analysis and\nempirical studies. In addition, since outliers are separated from clean time\nseries iteratively, our approach offers improved robustness to outliers, which\nin turn improves accuracy. We evaluate our approach on five real-world datasets\nand report improvements over the state-of-the-art approaches in terms of\nrobustness and explainability.\nThis is an extended version of \"Robust and Explainable Autoencoders for\nUnsupervised Time Series Outlier Detection\", to appear in IEEE ICDE 2022.",
    "descriptor": "\nComments: This paper has been accepted by IEEE ICDE 2022\n",
    "authors": [
      "Tung Kieu",
      "Bin Yang",
      "Chenjuan Guo",
      "Christian S. Jensen",
      "Yan Zhao",
      "Feiteng Huang",
      "Kai Zheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2204.03341"
  },
  {
    "id": "arXiv:2204.03342",
    "title": "Domain Adaptation for Time-Series Classification to Mitigate Covariate  Shift",
    "abstract": "The performance of a machine learning model degrades when it is applied to\ndata from a similar but different domain than the data it has initially been\ntrained on. To mitigate this domain shift problem, domain adaptation (DA)\ntechniques search for an optimal transformation that converts the (current)\ninput data from a source domain to a target domain to learn a domain-invariant\nrepresentations that reduces domain discrepancy.\nThis paper proposes a novel supervised domain adaptation based on two steps.\nFirst, we search for an optimal class-dependent transformation from the source\nto the target domain from a few samples. We consider optimal transport methods\nsuch as the earth mover distance with Laplacian regularization, Sinkhorn\ntransport and correlation alignment. Second, we use embedding similarity\ntechniques to select the corresponding transformation at inference. We use\ncorrelation metrics and maximum mean discrepancy with higher-order moment\nmatching techniques. We conduct an extensive evaluation on time-series datasets\nwith domain shift including simulated and various online handwriting datasets\nto demonstrate the performance.",
    "descriptor": "",
    "authors": [
      "Felix Ott",
      "David R\u00fcgamer",
      "Lucas Heublein",
      "Bernd Bischl",
      "Christopher Mutschler"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.03342"
  },
  {
    "id": "arXiv:2204.03346",
    "title": "Inference over radiative transfer models using variational and  expectation maximization methods",
    "abstract": "Earth observation from satellites offers the possibility to monitor our\nplanet with unprecedented accuracy. Radiative transfer models (RTMs) encode the\nenergy transfer through the atmosphere, and are used to model and understand\nthe Earth system, as well as to estimate the parameters that describe the\nstatus of the Earth from satellite observations by inverse modeling. However,\nperforming inference over such simulators is a challenging problem. RTMs are\nnonlinear, non-differentiable and computationally costly codes, which adds a\nhigh level of difficulty in inference. In this paper, we introduce two\ncomputational techniques to infer not only point estimates of biophysical\nparameters but also their joint distribution. One of them is based on a\nvariational autoencoder approach and the second one is based on a Monte Carlo\nExpectation Maximization (MCEM) scheme. We compare and discuss benefits and\ndrawbacks of each approach. We also provide numerical comparisons in synthetic\nsimulations and the real PROSAIL model, a popular RTM that combines land\nvegetation leaf and canopy modeling. We analyze the performance of the two\napproaches for modeling and inferring the distribution of three key biophysical\nparameters for quantifying the terrestrial biosphere.",
    "descriptor": "\nComments: Mach Learn (2021)\n",
    "authors": [
      "Daniel Heestermans Svendsen",
      "Daniel Hern\u00e1ndez-Lobato",
      "Luca Martino",
      "Valero Laparra",
      "Alvaro Moreno",
      "Gustau Camps-Valls"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Geophysics (physics.geo-ph)"
    ],
    "url": "https://arxiv.org/abs/2204.03346"
  },
  {
    "id": "arXiv:2204.03350",
    "title": "Implementing a Real-Time, YOLOv5 based Social Distancing Measuring  System for Covid-19",
    "abstract": "The purpose of this work is, to provide a YOLOv5 deep learning-based social\ndistance monitoring framework using an overhead view perspective. In addition,\nwe have developed a custom defined model YOLOv5 modified CSP (Cross Stage\nPartial Network) and assessed the performance on COCO and Visdrone dataset with\nand without transfer learning. Our findings show that the developed model\nsuccessfully identifies the individual who violates the social distances. The\naccuracy of 81.7% for the modified bottleneck CSP without transfer learning is\nobserved on COCO dataset after training the model for 300 epochs whereas for\nthe same epochs, the default YOLOv5 model is attaining 80.1% accuracy with\ntransfer learning. This shows an improvement in accuracy by our modified\nbottleneck CSP model. For the Visdrone dataset, we are able to achieve an\naccuracy of upto 56.5% for certain classes and especially an accuracy of 40%\nfor people and pedestrians with transfer learning using the default YOLOv5s\nmodel for 30 epochs. While the modified bottleneck CSP is able to perform\nslightly better than the default model with an accuracy score of upto 58.1% for\ncertain classes and an accuracy of ~40.4% for people and pedestrians.",
    "descriptor": "",
    "authors": [
      "Narayana Darapaneni",
      "Shrawan Kumar",
      "Selvarangan Krishnan",
      "Hemalatha K",
      "Arunkumar Rajagopal",
      "Nagendra",
      "Anwesh Reddy Paduri"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.03350"
  },
  {
    "id": "arXiv:2204.03353",
    "title": "Learning Online Multi-Sensor Depth Fusion",
    "abstract": "Many hand-held or mixed reality devices are used with a single sensor for 3D\nreconstruction, although they often comprise multiple sensors. Multi-sensor\ndepth fusion is able to substantially improve the robustness and accuracy of 3D\nreconstruction methods, but existing techniques are not robust enough to handle\nsensors which operate with diverse value ranges as well as noise and outlier\nstatistics. To this end, we introduce SenFuNet, a depth fusion approach that\nlearns sensor-specific noise and outlier statistics and combines the data\nstreams of depth frames from different sensors in an online fashion. Our method\nfuses multi-sensor depth streams regardless of time synchronization and\ncalibration and generalizes well with little training data. We conduct\nexperiments with various sensor combinations on the real-world CoRBS and\nScene3D datasets, as well as the Replica dataset. Experiments demonstrate that\nour fusion strategy outperforms traditional and recent online depth fusion\napproaches. In addition, the combination of multiple sensors yields more robust\noutlier handling and precise surface reconstruction than the use of a single\nsensor.",
    "descriptor": "\nComments: 31 pages, 17 figures\n",
    "authors": [
      "Erik Sandstr\u00f6m",
      "Martin R. Oswald",
      "Suryansh Kumar",
      "Silvan Weder",
      "Fisher Yu",
      "Cristian Sminchisescu",
      "Luc Van Gool"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.03353"
  },
  {
    "id": "arXiv:2204.03355",
    "title": "Event Transformer. A sparse-aware solution for efficient event data  processing",
    "abstract": "Event cameras are sensors of great interest for many applications that run in\nlow-resource and challenging environments. They log sparse illumination changes\nwith high temporal resolution and high dynamic range, while they present\nminimal power consumption. However, top-performing methods often ignore\nspecific event-data properties, leading to the development of generic but\ncomputationally expensive algorithms. Efforts toward efficient solutions\nusually do not achieve top-accuracy results for complex tasks. This work\nproposes a novel framework, Event Transformer (EvT), that effectively takes\nadvantage of event-data properties to be highly efficient and accurate. We\nintroduce a new patch-based event representation and a compact transformer-like\narchitecture to process it. EvT is evaluated on different event-based\nbenchmarks for action and gesture recognition. Evaluation results show better\nor comparable accuracy to the state-of-the-art while requiring significantly\nless computation resources, which makes EvT able to work with minimal latency\nboth on GPU and CPU.",
    "descriptor": "",
    "authors": [
      "Alberto Sabater",
      "Luis Montesano",
      "Ana C. Murillo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.03355"
  },
  {
    "id": "arXiv:2204.03356",
    "title": "Alternating Direction Based Sequential Boolean Quadratic Programming  Method for Transmit Antenna Selection",
    "abstract": "The wireless mobile communication system is updated and iterated on the whole\nalmost every decade. It is now in the development period of the application\nscenarios of the fifth generation mobile communication system (5G).\nUnfortunately, 5G relies on plenty of small base stations with a large number\nof antennas that consume a lot of energy. In this paper, a novel Boolean\nvariable quadratic programming algorithm is designed for the antenna selection\noptimization problem to reduce power consumption. Experiments show that the\nproposed algorithm achieves high complementarity satisfaction accuracy with\nonly a few steps.",
    "descriptor": "",
    "authors": [
      "Shijie Zhu",
      "Xu Du"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2204.03356"
  },
  {
    "id": "arXiv:2204.03357",
    "title": "Parameter-Efficient Abstractive Question Answering over Tables or Text",
    "abstract": "A long-term ambition of information seeking QA systems is to reason over\nmulti-modal contexts and generate natural answers to user queries. Today,\nmemory intensive pre-trained language models are adapted to downstream tasks\nsuch as QA by fine-tuning the model on QA data in a specific modality like\nunstructured text or structured tables. To avoid training such memory-hungry\nmodels while utilizing a uniform architecture for each modality,\nparameter-efficient adapters add and train small task-specific bottle-neck\nlayers between transformer layers. In this work, we study parameter-efficient\nabstractive QA in encoder-decoder models over structured tabular data and\nunstructured textual data using only 1.5% additional parameters for each\nmodality. We also ablate over adapter layers in both encoder and decoder\nmodules to study the efficiency-performance trade-off and demonstrate that\nreducing additional trainable parameters down to 0.7%-1.0% leads to comparable\nresults. Our models out-perform current state-of-the-art models on tabular QA\ndatasets such as Tablesum and FeTaQA, and achieve comparable performance on a\ntextual QA dataset such as NarrativeQA using significantly less trainable\nparameters than fine-tuning.",
    "descriptor": "\nComments: Published in Dialdoc Workshop at ACL 2022\n",
    "authors": [
      "Vaishali Pal",
      "Evangelos Kanoulas",
      "Maarten de Rijke"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.03357"
  },
  {
    "id": "arXiv:2204.03359",
    "title": "ECCV Caption: Correcting False Negatives by Collecting  Machine-and-Human-verified Image-Caption Associations for MS-COCO",
    "abstract": "Image-Test matching (ITM) is a common task for evaluating the quality of\nVision and Language (VL) models. However, existing ITM benchmarks have a\nsignificant limitation. They have many missing correspondences, originating\nfrom the data construction process itself. For example, a caption is only\nmatched with one image although the caption can be matched with other similar\nimages, and vice versa. To correct the massive false negatives, we construct\nthe Extended COCO Validation (ECCV) Caption dataset by supplying the missing\nassociations with machine and human annotators. We employ five state-of-the-art\nITM models with diverse properties for our annotation process. Our dataset\nprovides x3.6 positive image-to-caption associations and x8.5 caption-to-image\nassociations compared to the original MS-COCO. We also propose to use an\ninformative ranking-based metric, rather than the popular Recall@K(R@K). We\nre-evaluate the existing 25 VL models on existing and proposed benchmarks. Our\nfindings are that the existing benchmarks, such as COCO 1K R@K, COCO 5K R@K,\nCxC R@1 are highly correlated with each other, while the rankings change when\nwe shift to the ECCV mAP. Lastly, we delve into the effect of the bias\nintroduced by the choice of machine annotator. Source code and dataset are\navailable at https://github.com/naver-ai/eccv-caption",
    "descriptor": "\nComments: 30 pages (1.7MB). Source code and dataset are available at this https URL\n",
    "authors": [
      "Sanghyuk Chun",
      "Wonjae Kim",
      "Song Park",
      "Minsuk Chang",
      "Seong Joon Oh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.03359"
  },
  {
    "id": "arXiv:2204.03361",
    "title": "Robust Event-Driven Interactions in Cooperative Multi-Agent Learning",
    "abstract": "We present an approach to reduce the communication required between agents in\na Multi-Agent learning system by exploiting the inherent robustness of the\nunderlying Markov Decision Process. We compute so-called robustness surrogate\nfunctions (off-line), that give agents a conservative indication of how far\ntheir state measurements can deviate before they need to update other agents in\nthe system. This results in fully distributed decision functions, enabling\nagents to decide when it is necessary to update others. We derive bounds on the\noptimality of the resulting systems in terms of the discounted sum of rewards\nobtained, and show these bounds are a function of the design parameters.\nAdditionally, we extend the results for the case where the robustness surrogate\nfunctions are learned from data, and present experimental results demonstrating\na significant reduction in communication events between agents.",
    "descriptor": "",
    "authors": [
      "Daniel Jarne Ornia",
      "Manuel Mazo Jr"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2204.03361"
  },
  {
    "id": "arXiv:2204.03362",
    "title": "The seriation problem in the presence of a double Fiedler value",
    "abstract": "Seriation is a problem consisting of seeking the best enumeration order of a\nset of units whose interrelationship is described by a bipartite graph, that\nis, a graph whose nodes are partitioned in two sets and arcs only connect nodes\nin different groups. An algorithm for spectral seriation based on the use of\nthe Fiedler vector of the Laplacian matrix associated to the problem was\ndeveloped by Atkins et al., under the assumption that the Fiedler value is\nsimple. In this paper, we analyze the case in which the Fiedler value of the\nLaplacian is not simple, discuss its effect on the set of the admissible\nsolutions, and study possible approaches to actually perform the computation.\nExamples and numerical experiments illustrate the effectiveness of the proposed\nmethods.",
    "descriptor": "\nComments: 24 pages, 5 figures, 3 tables\n",
    "authors": [
      "Anna Concas",
      "Caterina Fenu",
      "Giuseppe Rodriguez",
      "Raf Vandebril"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2204.03362"
  },
  {
    "id": "arXiv:2204.03364",
    "title": "A Framework for Distributed Estimation with Reduced Communication via  Event-Based Strategies",
    "abstract": "This paper considers the problem of distributed estimation in a sensor\nnetwork, where multiple sensors are deployed to infer the state of a linear\ntime-invariant (LTI) Gaussian system. By proposing a lossless decomposition of\nKalman filter, a framework of event-based distributed estimation is developed,\nwhere each sensor node runs a local filter using solely its own measurement,\nalongside with an event-based synchronization algorithm to fuse the neighboring\ninformation. One novelty of the proposed framework is that it decouples the\nlocal filter from synchronization process. By doing so, we prove that a general\nclass of triggering strategies can be applied in our framework, which yields\nstable distributed estimators under the minimal requirements of network\nconnectivity and collective system observability. As compared with existing\nworks, the proposed algorithm enjoys lower data size for each transmission.\nMoreover, the developed results can be generalized to achieve a distributed\nimplementation of any Luenberger observer. By solving a semi-definite\nprogramming (SDP), we further present a low-rank estimator design to obtain the\noptimal gain of Luenberger observer such that the distributed estimation is\nrealized under the constraint of message complexity. Numerical examples are\nfinally provided to demonstrate the proposed methods.",
    "descriptor": "",
    "authors": [
      "Jiaqi Yan",
      "Yilin Mo",
      "Hideaki Ishii"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2204.03364"
  },
  {
    "id": "arXiv:2204.03366",
    "title": "Impact of Software Engineering Research in Practice",
    "abstract": "Existing work on the practical impact of software engineering (SE) research\nexamines industrial relevance rather than adoption of study results, hence the\nquestion of how results have been practically applied remains open. To answer\nthis and investigate the outcomes of impactful research, we performed a\nquantitative and qualitative analysis of 4,335 SE patents citing 1,668 SE\npapers published between 1975-2017. Moreover, we conducted a survey study on\n413 authors of 501 top-cited and awarded publications, achieving 25% response\nrate. Overall, researchers have equipped practitioners with various tools,\nprocesses, and methods, and improved many existing products. SE practice seems\nto value knowledge-seeking research and is impacted by diverse\ncross-disciplinary SE areas. Practitioner-oriented publication venues appear\nmore impactful than researcher-, while industry-related tracks in conferences\ncould enhance their impact. Some research works did not reach a wide footprint\ndue to limited funding resources or unfavorable cost-benefit tradeoff of the\nproposed solutions. The need for higher funding in SE research could be\ncorroborated through a dedicated empirical study. In general, the assessment of\nimpact is subject to its definition. Therefore, academia and industry could\njointly agree on a formal description to set a common ground for subsequent\nresearch on the topic.",
    "descriptor": "\nComments: 16 pages, 1 figure, 6 tables\n",
    "authors": [
      "Zoe Kotti",
      "Georgios Gousios",
      "Diomidis Spinellis"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2204.03366"
  },
  {
    "id": "arXiv:2204.03371",
    "title": "Detection of Distracted Driver using Convolution Neural Network",
    "abstract": "With over 50 million car sales annually and over 1.3 million deaths every\nyear due to motor accidents we have chosen this space. India accounts for 11\nper cent of global death in road accidents. Drivers are held responsible for\n78% of accidents. Road safety problems in developing countries is a major\nconcern and human behavior is ascribed as one of the main causes and\naccelerators of road safety problems. Driver distraction has been identified as\nthe main reason for accidents. Distractions can be caused due to reasons such\nas mobile usage, drinking, operating instruments, facial makeup, social\ninteraction. For the scope of this project, we will focus on building a highly\nefficient ML model to classify different driver distractions at runtime using\ncomputer vision. We would also analyze the overall speed and scalability of the\nmodel in order to be able to set it up on an edge device. We use CNN, VGG-16,\nRestNet50 and ensemble of CNN to predict the classes.",
    "descriptor": "",
    "authors": [
      "Narayana Darapaneni",
      "Jai Arora",
      "MoniShankar Hazra",
      "Naman Vig",
      "Simrandeep Singh Gandhi",
      "Saurabh Gupta",
      "Anwesh Reddy Paduri"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.03371"
  },
  {
    "id": "arXiv:2204.03372",
    "title": "Human-AI ecosystem with abrupt changes as a function of the composition",
    "abstract": "The progressive advent of artificial intelligence machines may represent both\nan opportunity or a threat. In order to have an idea of what is coming we\npropose a model that simulate a Human-AI ecosystem. In particular we consider\nsystems where agents present biases, peer-to-peer interactions and also three\nbody interactions that are crucial and describe two humans interacting with an\nartificial agent and two artificial intelligence agents interacting with a\nhuman. We focus our analysis by exploring how the relative fraction of\nartificial intelligence agents affect that ecosystem. We find evidence that for\nsuitable values of the interaction parameters, arbitrarily small changes in\nsuch percentage may trigger dramatic changes for the system that can be either\nin one of the two polarised states or in an undecided state.",
    "descriptor": "",
    "authors": [
      "Pierluigi Contucci",
      "J\u00e1nos Kert\u00e9sz",
      "Godwin Osabutey"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Statistical Mechanics (cond-mat.stat-mech)"
    ],
    "url": "https://arxiv.org/abs/2204.03372"
  },
  {
    "id": "arXiv:2204.03375",
    "title": "Towards Fair Evaluation of Dialogue State Tracking by Flexible  Incorporation of Turn-level Performances",
    "abstract": "Dialogue State Tracking (DST) is primarily evaluated using Joint Goal\nAccuracy (JGA) defined as the fraction of turns where the ground-truth dialogue\nstate exactly matches the prediction. Generally in DST, the dialogue state or\nbelief state for a given turn contains all the intents shown by the user till\nthat turn. Due to this cumulative nature of the belief state, it is difficult\nto get a correct prediction once a misprediction has occurred. Thus, although\nbeing a useful metric, it can be harsh at times and underestimate the true\npotential of a DST model. Moreover, an improvement in JGA can sometimes\ndecrease the performance of turn-level or non-cumulative belief state\nprediction due to inconsistency in annotations. So, using JGA as the only\nmetric for model selection may not be ideal for all scenarios. In this work, we\ndiscuss various evaluation metrics used for DST along with their shortcomings.\nTo address the existing issues, we propose a new evaluation metric named\nFlexible Goal Accuracy (FGA). FGA is a generalized version of JGA. But unlike\nJGA, it tries to give penalized rewards to mispredictions that are locally\ncorrect i.e. the root cause of the error is an earlier turn. By doing so, FGA\nconsiders the performance of both cumulative and turn-level prediction flexibly\nand provides a better insight than the existing metrics. We also show that FGA\nis a better discriminator of DST model performance.",
    "descriptor": "\nComments: ACL 2022 Main Conference (short paper)\n",
    "authors": [
      "Suvodip Dey",
      "Ramamohan Kummara",
      "Maunendra Sankar Desarkar"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.03375"
  },
  {
    "id": "arXiv:2204.03376",
    "title": "Offline Reinforcement Learning for Safer Blood Glucose Control in People  with Type 1 Diabetes",
    "abstract": "Hybrid closed loop systems represent the future of care for people with type\n1 diabetes (T1D). These devices usually utilise simple control algorithms to\nselect the optimal insulin dose for maintaining blood glucose levels within a\nhealthy range. Online reinforcement learning (RL) has been utilised as a method\nfor further enhancing glucose control in these devices. Previous approaches\nhave been shown to reduce patient risk and improve time spent in the target\nrange when compared to classical control algorithms, but are prone to\ninstability in the learning process, often resulting in the selection of unsafe\nactions. This work presents an evaluation of offline RL as a means for\ndeveloping clinically effective dosing policies without the need for patient\ninteraction. This paper examines the utility of BCQ, CQL and TD3-BC in managing\nthe blood glucose of nine virtual patients within the UVA/Padova glucose\ndynamics simulator. When trained on less than a tenth of the data required by\nonline RL approaches, this work shows that offline RL can significantly\nincrease time in the healthy blood glucose range when compared to the strongest\nstate-of-art baseline. This is achieved without any associated increase in low\nblood glucose events. Offline RL is also shown to be able to correct for common\nand challenging scenarios such as incorrect bolus dosing, irregular meal\ntimings and sub-optimal training data.",
    "descriptor": "\nComments: The code for this work is available at this https URL\n",
    "authors": [
      "Harry Emerson",
      "Matt Guy",
      "Ryan McConville"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.03376"
  },
  {
    "id": "arXiv:2204.03382",
    "title": "HunYuan_tvr for Text-Video Retrivial",
    "abstract": "Text-Video Retrieval plays an important role in multi-modal understanding and\nhas attracted increasing attention in recent years. Most existing methods focus\non constructing contrastive pairs between whole videos and complete caption\nsentences, while ignoring fine-grained cross-modal relationships, e.g., short\nclips and phrases or single frame and word. In this paper, we propose a novel\nmethod, named HunYuan\\_tvr, to explore hierarchical cross-modal interactions by\nsimultaneously exploring video-sentence, clip-phrase, and frame-word\nrelationships. Considering intrinsic semantic relations between frames,\nHunYuan\\_tvr first performs self-attention to explore frame-wise correlations\nand adaptively clusters correlated frames into clip-level representations.\nThen, the clip-wise correlation is explored to aggregate clip representations\ninto a compact one to describe the video globally. In this way, we can\nconstruct hierarchical video representations for frame-clip-video\ngranularities, and also explore word-wise correlations to form\nword-phrase-sentence embeddings for the text modality. Finally, hierarchical\ncontrastive learning is designed to explore cross-modal\nrelationships,~\\emph{i.e.,} frame-word, clip-phrase, and video-sentence, which\nenables HunYuan\\_tvr to achieve a comprehensive multi-modal understanding.\nFurther boosted by adaptive label denosing and marginal sample enhancement,\nHunYuan\\_tvr obtains new state-of-the-art results on various benchmarks, e.g.,\nRank@1 of 55.0%, 57.8%, 29.7%, 52.1%, and 57.3% on MSR-VTT, MSVD, LSMDC,\nDiDemo, and ActivityNet respectively.",
    "descriptor": "",
    "authors": [
      "Shaobo Min",
      "Weijie Kong",
      "Rong-Cheng Tu",
      "Dihong Gong",
      "Chengfei Cai",
      "Wenzhe Zhao",
      "Chenyang Liu",
      "Sixiao Zheng",
      "Hongfa Wang",
      "Zhifeng Li",
      "Wei Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.03382"
  },
  {
    "id": "arXiv:2204.03383",
    "title": "Overlay journals: a study of the current landscape",
    "abstract": "Overlay journals are characterised by their articles being archived on public\nopen access repositories, often already starting in their initial preprint form\nas a prerequisite for submission to the journal prior to initiating the\npeer-review process. In this study we aimed to identify currently active\noverlay journals and examine their characteristics. We utilised an explorative\nweb search and contacted key service providers for additional information. The\nfinal sample consisted of 35 active overlay journals. While the results show an\nincrease in the number of overlay journals in recent years, the current\npresence of overlay journals is diminutive compared to the overall number of\nopen access journals. The majority of overlay journals publish articles in the\nnatural sciences, mathematics or computer sciences. Overlay journals are\ncommonly published by groups of scientists rather than formal organisations and\noverlay journals may also rank highly within the traditional journal citation\nmetrics. Nearly none of the investigated journals charge fees from authors,\nwhich is likely related to the cost-effectiveness of the overlay publishing\nmodel. Both the growth in adoption of open access preprint repositories, and\nresearchers willingness to publish in overlay journals will determine the\nmodels wider impact on scholarly publishing.",
    "descriptor": "",
    "authors": [
      "Antti Mikael Rousi",
      "Mikael Laakso"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2204.03383"
  },
  {
    "id": "arXiv:2204.03387",
    "title": "Blockchain Application Development Using Model-Driven Engineering and  Low-Code Platforms: A Survey",
    "abstract": "The creation of blockchain-based software applications requires today\nconsiderable technical knowledge, particularly in software design and\nprogramming. This is regarded as a major barrier in adopting this technology in\nbusiness and making it accessible to a wider audience. As a solution, no-code\nand low-code approaches have been proposed that require only little or no\nprogramming knowledge for creating full-fledged software applications. In this\npaper we review academic approaches from the discipline of model-driven\nengineering as well as industrial no-code and low-code development platforms\nfor blockchains. We further present a case study for an integrated no-code\nblockchain environment for demonstrating the state-of-the-art in this area.\nBased on the gained insights we derive requirements for the future development\nof no-code and low-code approaches that are dedicated to the field of\nblockchains.",
    "descriptor": "",
    "authors": [
      "Simon Curty",
      "Felix H\u00e4rer",
      "Hans-Georg Fill"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2204.03387"
  },
  {
    "id": "arXiv:2204.03390",
    "title": "Electricity generation from renewable energy based on abandoned wind fan",
    "abstract": "In the 21st century, our world is facing difficult conditions for serious\nenvironmental pollution and the problem of energy shortage. An innovative idea\nhas emerged to recycle wind energy from air conditioning condenser fans in\noutdoor buildings. Therefore, the main goal of this research is to develop\nrenewable wind energy from the condenser fan of an air conditioner using\nArduino as a microcontroller. This research moves towards a portable, low cost,\nenvironmentally friendly mini device that harnesses renewable energies with\nendless resources for future alternative power generation and reduces the\nburden of consumers' electricity bills",
    "descriptor": "\nComments: 8 pages and 7 figures\n",
    "authors": [
      "Arni Munira Markom",
      "Muhammad Hakimi Aiman Hadri",
      "Tuah Zayan Muhamad Yazid",
      "Zakiah Mohd Yusof",
      "Marni Azira Markom",
      "Ahmad Razif Muhammad"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2204.03390"
  },
  {
    "id": "arXiv:2204.03393",
    "title": "TOSE: A Fast Capacity Determination Algorithm Based on Random Matrix  Theory",
    "abstract": "Wireless network capacity is one of the most important performance metrics\nfor wireless communication networks. Future wireless networks will be composed\nof extremely large number of base stations (BSs) and users, and organized in\nthe form of multiple clusters. Unfortunately, the determination of average\ncluster capacity for such future wireless networks is difficult, and lacks of\nboth analytical expressions and fast algorithms. In this paper, we propose a\nfast algorithm TOSE to estimate the average cluster capacity based on the\nrandom matrix theory (RMT). It can avoid the exact eigenvalue derivations of\nlarge dimensional matrices, which are complicated and inevitable in\nconventional capacity determination methods. Instead, fast eigenvalue\nestimations can be realized based on RMT in our TOSE algorithm. In addition, we\nderive the analytical upper and lower bounds of the average cluster capacity.\nOur numerical experiments show that TOSE is faster than the conventional\nCholesky decomposition method, by at least three orders of magnitude. Besides,\nTOSE has superior generality, since it is independent of the distributions of\nBSs and users, and the shape of network areas.",
    "descriptor": "\nComments: 5 pages, 4 figures\n",
    "authors": [
      "Dandan Jiang",
      "Han Hao",
      "Lu Yang",
      "Xiang Chen",
      "Wei Han",
      "Bo Bai"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2204.03393"
  },
  {
    "id": "arXiv:2204.03394",
    "title": "Towards Comparing Performance of Algorithms in Hardware and Software",
    "abstract": "In this paper, we report on a preliminary investigation of the potential\nperformance gain of programs implemented in field-programmable gate array's\n(FPGAs) using a high-level language Chisel compared to ordinary high-level\nsoftware implementations executed on general-purpose computers and embedded\nsystems. FPGAs inherently supports parallel evaluations while the sequential\ncomputers do not, and for this preliminary investigation we have chosen a\nhighly parallelizable program as case study to show an upper bound of\nperformance gain. The purpose is to demonstrate whether or not programming\nFPGAs has a potential for performance optimizations of ordinary programs.\nWe have developed and evaluated Conway's Game of Life for an FPGA, an\nembedded system Raspberry Pi 4, and a MacBook Pro Laptop. We have compared the\nperformance of programs over different input sizes to decide the relative\nincrease in runtime.",
    "descriptor": "",
    "authors": [
      "Maja H. Kirkeby",
      "Martin Schoeberl"
    ],
    "subjectives": [
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2204.03394"
  },
  {
    "id": "arXiv:2204.03397",
    "title": "Defending Active Directory by Combining Neural Network based Dynamic  Program and Evolutionary Diversity Optimisation",
    "abstract": "Active Directory (AD) is the default security management system for Windows\ndomain networks. We study a Stackelberg game model between one attacker and one\ndefender on an AD attack graph. The attacker initially has access to a set of\nentry nodes. The attacker can expand this set by strategically exploring edges.\nEvery edge has a detection rate and a failure rate. The attacker aims to\nmaximize their chance of successfully reaching the destination before getting\ndetected. The defender's task is to block a constant number of edges to\ndecrease the attacker's chance of success. We show that the problem is #P-hard\nand, therefore, intractable to solve exactly. We convert the attacker's problem\nto an exponential sized Dynamic Program that is approximated by a Neural\nNetwork (NN). Once trained, the NN provides an efficient fitness function for\nthe defender's Evolutionary Diversity Optimisation (EDO). The diversity\nemphasis on the defender's solution provides a diverse set of training samples,\nwhich improves the training accuracy of our NN for modelling the attacker. We\ngo back and forth between NN training and EDO. Experimental results show that\nfor R500 graph, our proposed EDO based defense is less than 1% away from the\noptimal defense.",
    "descriptor": "",
    "authors": [
      "Diksha Goel",
      "Max Hector Ward-Graham",
      "Aneta Neumann",
      "Frank Neumann",
      "Hung Nguyen",
      "Mingyu Guo"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2204.03397"
  },
  {
    "id": "arXiv:2204.03398",
    "title": "Linguistic-Acoustic Similarity Based Accent Shift for Accent Recognition",
    "abstract": "General accent recognition (AR) models tend to directly extract low-level\ninformation from spectrums, which always significantly overfit on speakers or\nchannels. Considering accent can be regarded as a series of shifts relative to\nnative pronunciation, distinguishing accents will be an easier task with accent\nshift as input. But due to the lack of native utterance as an anchor,\nestimating the accent shift is difficult. In this paper, we propose\nlinguistic-acoustic similarity based accent shift (LASAS) for AR tasks. For an\naccent speech utterance, after mapping the corresponding text vector to\nmultiple accent-associated spaces as anchors, its accent shift could be\nestimated by the similarities between the acoustic embedding and those anchors.\nThen, we concatenate the accent shift with a dimension-reduced text vector to\nobtain a linguistic-acoustic bimodal representation. Compared with pure\nacoustic embedding, the bimodal representation is richer and more clear by\ntaking full advantage of both linguistic and acoustic information, which can\neffectively improve AR performance. Experiments on Accented English Speech\nRecognition Challenge (AESRC) dataset show that our method achieves 77.42%\naccuracy on Test set, obtaining a 6.94% relative improvement over a competitive\nsystem in the challenge.",
    "descriptor": "\nComments: Submitted to Interspeech 2022\n",
    "authors": [
      "Qijie Shao",
      "Jinghao Yan",
      "Jian Kang",
      "Pengcheng Guo",
      "Xian Shi",
      "Pengfei Hu",
      "Lei Xie"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2204.03398"
  },
  {
    "id": "arXiv:2204.03400",
    "title": "Surrogate-Assisted Evolutionary Generative Design Of Breakwaters Using  Deep Convolutional Networks",
    "abstract": "In the paper, a multi-objective evolutionary surrogate-assisted approach for\nthe fast and effective generative design of coastal breakwaters is proposed. To\napproximate the computationally expensive objective functions, the deep\nconvolutional neural network is used as a surrogate model. This model allows\noptimizing a configuration of breakwaters with a different number of structures\nand segments. In addition to the surrogate, an assistant model was developed to\nestimate the confidence of predictions. The proposed approach was tested on the\nsynthetic water area, the SWAN model was used to calculate the wave heights.\nThe experimental results confirm that the proposed approach allows obtaining\nmore effective (less expensive with better protective properties) solutions\nthan non-surrogate approaches for the same time.",
    "descriptor": "",
    "authors": [
      "Nikita O. Starodubcev",
      "Nikolay O. Nikitin",
      "Anna V. Kalyuzhnaya"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2204.03400"
  },
  {
    "id": "arXiv:2204.03401",
    "title": "Energy Consumption and Performance of Heapsort in Hardware and Software",
    "abstract": "In this poster abstract we will report on a case study on implementing the\nHeapsort algorithm in hardware and software and comparing their time and energy\nconsumption. Our experiment shows that the Hardware implementation is more\nenergy efficient, but slower than the Software implementation due to a low\nclock frequency. It also indicate that the optimal degree of parallelization\ndiffers when optimizing for time compared to optimizing for time.",
    "descriptor": "",
    "authors": [
      "Maja H. Kirkeby",
      "Thomas Krabben",
      "Mathias Larsen",
      "Maria B. Mikkelsen",
      "Tjark Petersen",
      "Mads Rosendahl",
      "Martin Schoeberl",
      "Martin Sundman"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2204.03401"
  },
  {
    "id": "arXiv:2204.03405",
    "title": "Recommended Guidelines for Effective MOOCs based on a Multiple-Case  Study",
    "abstract": "Massive Open Online Courseware (MOOCs) appeared in 2008 and grew considerably\nin the past decade, now reaching millions of students and professionals all\nover the world. MOOCs do not replace other educational forms. Instead, they\ncomplement them by offering a powerful educational tool that can reach students\nthat, otherwise, would not have access to that information. Nevertheless,\ndesigning and implementing a successful MOOC is not straightforward. Simply\nrecording traditional classes is an approach that does not work, since the\nconditions in which a MOOC student learns are very different from the\nconventional classroom. In particular, dropout rates in MOOCs are, normally, at\nleast an order of magnitude higher than in conventional courses. In this paper,\nwe analyze data from 7 successful MOOCs that have attracted over 150,000\nstudents in the past years. The analysis led to the proposal of a set of\nguidelines to help instructors in designing more effective MOOCs. These results\ncontribute to the existing body of knowledge in the field, bring new insights,\nand pose new questions for future research.",
    "descriptor": "",
    "authors": [
      "Eduardo Guerra",
      "Fabio Kon",
      "Paulo Lemos"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2204.03405"
  },
  {
    "id": "arXiv:2204.03409",
    "title": "MAESTRO: Matched Speech Text Representations through Modality Matching",
    "abstract": "We present Maestro, a self-supervised training method to unify\nrepresentations learnt from speech and text modalities. Self-supervised\nlearning from speech signals aims to learn the latent structure inherent in the\nsignal, while self-supervised learning from text attempts to capture lexical\ninformation. Learning aligned representations from unpaired speech and text\nsequences is a challenging task. Previous work either implicitly enforced the\nrepresentations learnt from these two modalities to be aligned in the latent\nspace through multitasking and parameter sharing or explicitly through\nconversion of modalities via speech synthesis. While the former suffers from\ninterference between the two modalities, the latter introduces additional\ncomplexity. In this paper, we propose Maestro, a novel algorithm to learn\nunified representations from both these modalities simultaneously that can\ntransfer to diverse downstream tasks such as Automated Speech Recognition (ASR)\nand Speech Translation (ST). Maestro learns unified representations through\nsequence alignment, duration prediction and matching embeddings in the learned\nspace through an aligned masked-language model loss. We establish a new\nstate-of-the-art (SOTA) on VoxPopuli multilingual ASR with a 11% relative\nreduction in Word Error Rate (WER), multidomain SpeechStew ASR (3.7% relative)\nand 21 languages to English multilingual ST on CoVoST 2 with an improvement of\n2.8 BLEU averaged over 21 languages.",
    "descriptor": "\nComments: Submitted to Interspeech 2022\n",
    "authors": [
      "Zhehuai Chen",
      "Yu Zhang",
      "Andrew Rosenberg",
      "Bhuvana Ramabhadran",
      "Pedro Moreno",
      "Ankur Bapna",
      "Heiga Zen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2204.03409"
  },
  {
    "id": "arXiv:2204.03410",
    "title": "Incremental Prototype Prompt-tuning with Pre-trained Representation for  Class Incremental Learning",
    "abstract": "Class incremental learning has attracted much attention, but most existing\nworks still continually fine-tune the representation model, resulting in much\ncatastrophic forgetting. Instead of struggling to fight against such forgetting\nby replaying or distillation like most of the existing methods, we take the\npre-train-and-prompt-tuning paradigm to sequentially learn new visual concepts\nbased on a fixed semantic rich pre-trained representation model by incremental\nprototype prompt-tuning (IPP), which substantially reduces the catastrophic\nforgetting. In addition, an example prototype classification is proposed to\ncompensate for semantic drift, the problem caused by learning bias at different\nphases. Extensive experiments conducted on the three incremental learning\nbenchmarks demonstrate that our method consistently outperforms other\nstate-of-the-art methods with a large margin.",
    "descriptor": "",
    "authors": [
      "Jieren Deng",
      "Jianhua Hu",
      "Haojian Zhang",
      "Yunkuan Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.03410"
  },
  {
    "id": "arXiv:2204.03412",
    "title": "Maximizing Sums of Non-monotone Submodular and Linear Functions:  Understanding the Unconstrained Case",
    "abstract": "Motivated by practical applications, recent works have considered\nmaximization of sums of a submodular function $g$ and a linear function $\\ell$.\nAlmost all such works, to date, studied only the special case of this problem\nin which $g$ is also guaranteed to be monotone. Therefore, in this paper we\nsystematically study the simplest version of this problem in which $g$ is\nallowed to be non-monotone, namely the unconstrained variant, which we term\nRegularized Unconstrained Submodular Maximization (RegularizedUSM).\nOur main algorithmic result is the first non-trivial guarantee for general\nRegularizedUSM. For the special case of RegularizedUSM in which the linear\nfunction $\\ell$ is non-positive, we prove two inapproximability results,\nshowing that the algorithmic result implied for this case by previous works is\nnot far from optimal. Finally, we reanalyze the known Double Greedy algorithm\nto obtain improved guarantees for the special case of RegularizedUSM in which\nthe linear function $\\ell$ is non-negative; and we complement these guarantees\nby showing that it is not possible to obtain (1/2, 1)-approximation for this\ncase (despite intuitive arguments suggesting that this approximation guarantee\nis natural).",
    "descriptor": "\nComments: 28 pages, 1 figure\n",
    "authors": [
      "Kobi Bodek",
      "Moran Feldman"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2204.03412"
  },
  {
    "id": "arXiv:2204.03413",
    "title": "On the Price of Locality in Static Fast Rerouting",
    "abstract": "Modern communication networks feature fully decentralized flow rerouting\nmechanisms which allow them to quickly react to link failures. This paper\nrevisits the fundamental algorithmic problem underlying such local fast\nrerouting mechanisms. Is it possible to achieve perfect resilience, i.e., to\ndefine local routing tables which preserve connectivity as long as the\nunderlying network is still connected? Feigenbaum et al. (ACM PODC'12) and\nFoerster et al. (SIAM APOCS'21) showed that, unfortunately, it is impossible in\ngeneral.\nThis paper charts a more complete landscape of the feasibility of perfect\nresilience. We first show a perhaps surprisingly large price of locality in\nstatic fast rerouting mechanisms: even when source and destination remain\nconnected by a linear number of link-disjoint paths after link failures, local\nrerouting algorithms cannot find any of them which leads to a disconnection on\nthe routing level. This motivates us to study resilience in graphs which\nexclude certain dense minors, such as cliques or a complete bipartite graphs,\nand in particular, provide characterizations of the possibility of perfect\nresilience in different routing models. We provide further insights into the\nprice of locality by showing impossibility results for few failures and\ninvestigate perfect resilience on Topology Zoo networks.",
    "descriptor": "\nComments: Accepted and to appear at the 52nd Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN'22)\n",
    "authors": [
      "Klaus-Tycho Foerster",
      "Juho Hirvonen",
      "Yvonne-Anne Pignolet",
      "Stefan Schmid",
      "Gilles Tredan"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2204.03413"
  },
  {
    "id": "arXiv:2204.03415",
    "title": "Proceedings 16th Logical and Semantic Frameworks with Applications",
    "abstract": "This volume contains the post-proceedings of the Sixteenth Logical and\nSemantic Frameworks with Applications (LSFA 2021). The meeting was held online\non July 23-24, 2021, organised by the Universidad de Buenos Aires, Argentina.\nLSFA aims to bring researchers and students interested in theoretical and\npractical aspects of logical and semantic frameworks and their applications.\nThe covered topics include proof theory, type theory and rewriting theory,\nspecification and deduction languages, and formal semantics of languages and\nsystems.",
    "descriptor": "",
    "authors": [
      "Mauricio Ayala-Rincon",
      "Eduardo Bonelli"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2204.03415"
  },
  {
    "id": "arXiv:2204.03416",
    "title": "A CCBM-based generalized GKB iterative regularizing algorithm for  inverse Cauchy problems",
    "abstract": "This paper examines inverse Cauchy problems that are governed by a kind of\nelliptic partial differential equation. The inverse problems involve recovering\nthe missing data on an inaccessible boundary from the measured data on an\naccessible boundary, which is severely ill-posed. By using the coupled complex\nboundary method (CCBM), which integrates both Dirichlet and Neumann data into a\nsingle Robin boundary condition, we reformulate the underlying problem into an\noperator equation. Based on this new formulation, we prove the existence of a\nunique solution even in cases with noisy data. A Golub-Kahan bidiagonalization\n(GKB) process together with Givens rotation is employed for iteratively solving\nthe proposed operator equation. The regularizing property of the developed\nmethod, called CCBM-GKB, and its convergence rate results are proved under a\nposteriori stopping rule. Finally, a linear finite element method is used for\nthe numerical realization of CCBM-GKB. Various numerical experiments\ndemonstrate that CCBM-GKB is a kind of accelerated iterative regularization\nmethod, as it is much faster than the classic Landweber method.",
    "descriptor": "",
    "authors": [
      "Rongfang Gong",
      "Min Wang",
      "Qin Huang",
      "Ye Zhang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2204.03416"
  },
  {
    "id": "arXiv:2204.03418",
    "title": "Continual Inference: A Library for Efficient Online Inference with Deep  Neural Networks in PyTorch",
    "abstract": "We present Continual Inference, a Python library for implementing Continual\nInference Networks (CINs) in PyTorch, a class of Neural Networks designed\nspecifically for efficient inference in both online and batch processing\nscenarios. We offer a comprehensive introduction and guide to CINs and their\nimplementation in practice, and provide best-practices and code examples for\ncomposing complex modules for modern Deep Learning. Continual Inference is\nreadily downloadable via the Python Package Index and at\n\\url{www.github.com/lukashedegaard/continual-inference}.",
    "descriptor": "\nComments: 1- pages, 5 figures, 1 table\n",
    "authors": [
      "Lukas Hedegaard",
      "Alexandros Iosifidis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.03418"
  },
  {
    "id": "arXiv:2204.03421",
    "title": "Self supervised learning for robust voice cloning",
    "abstract": "Voice cloning is a difficult task which requires robust and informative\nfeatures incorporated in a high quality TTS system in order to effectively copy\nan unseen speaker's voice. In our work, we utilize features learned in a\nself-supervised framework via the Bootstrap Your Own Latent (BYOL) method,\nwhich is shown to produce high quality speech representations when specific\naudio augmentations are applied to the vanilla algorithm. We further extend the\naugmentations in the training procedure to aid the resulting features to\ncapture the speaker identity and to make them robust to noise and acoustic\nconditions. The learned features are used as pre-trained utterance-level\nembeddings and as inputs to a Non-Attentive Tacotron based architecture, aiming\nto achieve multispeaker speech synthesis without utilizing additional speaker\nfeatures. This method enables us to train our model in an unlabeled\nmultispeaker dataset as well as use unseen speaker embeddings to copy a\nspeaker's voice. Subjective and objective evaluations are used to validate the\nproposed model, as well as the robustness to the acoustic conditions of the\ntarget utterance.",
    "descriptor": "\nComments: Submitted to INTERSPEECH 2022\n",
    "authors": [
      "Konstantinos Klapsas",
      "Nikolaos Ellinas",
      "Karolos Nikitaras",
      "Georgios Vamvoukakis",
      "Panos Kakoulidis",
      "Konstantinos Markopoulos",
      "Spyros Raptis",
      "June Sig Sung",
      "Gunu Jho",
      "Aimilios Chalamandaris",
      "Pirros Tsiakoulis"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2204.03421"
  },
  {
    "id": "arXiv:2204.03425",
    "title": "Complete flux scheme for variable velocity fields: coupling between the  advection-diffusion equation and the Poisson equation for the velocity field",
    "abstract": "In this work, we consider an advection-diffusion equation, coupled to a\nPoisson equation for the velocity field. This type of coupling is typically\nencountered in models arising from plasma physics or porous media flow. The aim\nof this work is to build upon the complete flux scheme (an improvement over the\nScharfetter-Gummel scheme by considering the contribution of the source term),\nso that its second-order convergence, which is uniform in P\\'eclet numbers,\ncarries over to these models. This is done by considering a piecewise linear\napproximation of the velocity field, which is then used for defining\nupwind-adjusted P\\'eclet numbers.",
    "descriptor": "",
    "authors": [
      "Hanz Martin Cheng",
      "Jan ten Thije Boonkkamp"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2204.03425"
  },
  {
    "id": "arXiv:2204.03429",
    "title": "Finding Counterfactual Explanations through Constraint Relaxations",
    "abstract": "Interactive constraint systems often suffer from infeasibility (no solution)\ndue to conflicting user constraints. A common approach to recover infeasibility\nis to eliminate the constraints that cause the conflicts in the system. This\napproach allows the system to provide an explanation as: \"if the user is\nwilling to drop out some of their constraints, there exists a solution\".\nHowever, one can criticise this form of explanation as not being very\ninformative. A counterfactual explanation is a type of explanation that can\nprovide a basis for the user to recover feasibility by helping them understand\nwhich changes can be applied to their existing constraints rather than removing\nthem. This approach has been extensively studied in the machine learning field,\nbut requires a more thorough investigation in the context of constraint\nsatisfaction. We propose an iterative method based on conflict detection and\nmaximal relaxations in over-constrained constraint satisfaction problems to\nhelp compute a counterfactual explanation.",
    "descriptor": "\nComments: This work has appeared in Explainable Agency in Artificial Intelligence Workshop (EAAI'22) at AAAI'22\n",
    "authors": [
      "Sharmi Dev Gupta",
      "Begum Genc",
      "Barry O'Sullivan"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Symbolic Computation (cs.SC)"
    ],
    "url": "https://arxiv.org/abs/2204.03429"
  },
  {
    "id": "arXiv:2204.03431",
    "title": "Energy-Efficient Adaptive Machine Learning on IoT End-Nodes With  Class-Dependent Confidence",
    "abstract": "Energy-efficient machine learning models that can run directly on edge\ndevices are of great interest in IoT applications, as they can reduce network\npressure and response latency, and improve privacy. An effective way to obtain\nenergy-efficiency with small accuracy drops is to sequentially execute a set of\nincreasingly complex models, early-stopping the procedure for \"easy\" inputs\nthat can be confidently classified by the smallest models. As a stopping\ncriterion, current methods employ a single threshold on the output\nprobabilities produced by each model. In this work, we show that such a\ncriterion is sub-optimal for datasets that include classes of different\ncomplexity, and we demonstrate a more general approach based on per-classes\nthresholds. With experiments on a low-power end-node, we show that our method\ncan significantly reduce the energy consumption compared to the\nsingle-threshold approach.",
    "descriptor": "\nComments: Published in: 2020 27th IEEE International Conference on Electronics, Circuits and Systems (ICECS)\n",
    "authors": [
      "Francesco Daghero",
      "Alessio Burrello",
      "Daniele Jahier Pagliari",
      "Luca Benini",
      "Enrico Macii",
      "Massimo Poncino"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.03431"
  },
  {
    "id": "arXiv:2204.03433",
    "title": "Machine Learning-Enabled IoT Security: Open Issues and Challenges Under  Advanced Persistent Threats",
    "abstract": "Despite its technological benefits, Internet of Things (IoT) has cyber\nweaknesses due to the vulnerabilities in the wireless medium. Machine learning\n(ML)-based methods are widely used against cyber threats in IoT networks with\npromising performance. Advanced persistent threat (APT) is prominent for\ncybercriminals to compromise networks, and it is crucial to long-term and\nharmful characteristics. However, it is difficult to apply ML-based approaches\nto identify APT attacks to obtain a promising detection performance due to an\nextremely small percentage among normal traffic. There are limited surveys to\nfully investigate APT attacks in IoT networks due to the lack of public\ndatasets with all types of APT attacks. It is worth to bridge the\nstate-of-the-art in network attack detection with APT attack detection in a\ncomprehensive review article. This survey article reviews the security\nchallenges in IoT networks and presents the well-known attacks, APT attacks,\nand threat models in IoT systems. Meanwhile, signature-based, anomaly-based,\nand hybrid intrusion detection systems are summarized for IoT networks. The\narticle highlights statistical insights regarding frequently applied ML-based\nmethods against network intrusion alongside the number of attacks types\ndetected. Finally, open issues and challenges for common network intrusion and\nAPT attacks are presented for future research.",
    "descriptor": "\nComments: ACM Computing Surveys, 2022, 35 pages, 10 Figures, 8 Tables\n",
    "authors": [
      "Zhiyan Chen",
      "Jinxin Liu",
      "Yu Shen",
      "Murat Simsek",
      "Burak Kantarci",
      "Hussein T. Mouftah",
      "Petar Djukic"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2204.03433"
  },
  {
    "id": "arXiv:2204.03436",
    "title": "A unified theory of non-overlapping Robin-Schwarz methods -- continuous  and discrete, including cross points",
    "abstract": "Non-overlapping Schwarz methods with generalized Robin transmission\nconditions were originally introduced by B. Despr\\'es for time-harmonic wave\npropagation problems and have largely developed over the past thirty years. The\naim of the paper is to provide both a review of the available formulations and\nmethods as well as a consistent theory applicable to more general cases than\nstudied until to date. An abstract variational framework is provided\nreformulating the original problem by the well-known form involving a\nscattering operator and an interface exchange operator, and the equivalence\nbetween the formulations is discussed thoroughly. The framework applies to a\nseries of wave propagation problems throughout the de Rham complex, such as the\nscalar Helmholtz equation, Maxwell's equations, a dual formulation of the\nHelmholtz equation in H(div), as well as any conforming finite element\ndiscretization thereof, and it applies also to coercive problems. Three\nconvergence results are shown. The first one (using compactness) and the second\none (based on absorbtion) generalize Despr\\'es' early findings and apply as\nwell to the FETI-2LM formulation. The third result, oriented on the work by\nCollino, Ghanemi, and Joly, establishes a convergence rate and covers cases\nwith cross points, while not requiring any regularity of the solution. The key\ningredient is a global interface exchange operator, proposed originally by X.\nClaeys and further developed by Claeys and Parolin, here worked out in full\ngenerality. The third type of convergence theory is applicable at the discrete\nlevel as well, where the exchange operator is allowed to be even local. The\nresulting scheme can be viewed as a generalization of the 2-Lagrange-multiplier\nmethod introduced by S. Loisel, and connections are drawn to another technique\nproposed by Gander and Santugini.",
    "descriptor": "",
    "authors": [
      "Clemens Pechstein"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2204.03436"
  },
  {
    "id": "arXiv:2204.03440",
    "title": "Task-Aware Active Learning for Endoscopic Image Analysis",
    "abstract": "Semantic segmentation of polyps and depth estimation are two important\nresearch problems in endoscopic image analysis. One of the main obstacles to\nconduct research on these research problems is lack of annotated data.\nEndoscopic annotations necessitate the specialist knowledge of expert\nendoscopists and due to this, it can be difficult to organise, expensive and\ntime consuming. To address this problem, we investigate an active learning\nparadigm to reduce the number of training examples by selecting the most\ndiscriminative and diverse unlabelled examples for the task taken into\nconsideration. Most of the existing active learning pipelines are task-agnostic\nin nature and are often sub-optimal to the end task. In this paper, we propose\na novel task-aware active learning pipeline and applied for two important tasks\nin endoscopic image analysis: semantic segmentation and depth estimation. We\ncompared our method with the competitive baselines. From the experimental\nresults, we observe a substantial improvement over the compared baselines.\nCodes are available at https://github.com/thetna/endo-active-learn.",
    "descriptor": "",
    "authors": [
      "Shrawan Kumar Thapa",
      "Pranav Poudel",
      "Binod Bhattarai",
      "Danail Stoyanov"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.03440"
  },
  {
    "id": "arXiv:2204.03444",
    "title": "Deep Visual Geo-localization Benchmark",
    "abstract": "In this paper, we propose a new open-source benchmarking framework for Visual\nGeo-localization (VG) that allows to build, train, and test a wide range of\ncommonly used architectures, with the flexibility to change individual\ncomponents of a geo-localization pipeline. The purpose of this framework is\ntwofold: i) gaining insights into how different components and design choices\nin a VG pipeline impact the final results, both in terms of performance\n(recall@N metric) and system requirements (such as execution time and memory\nconsumption); ii) establish a systematic evaluation protocol for comparing\ndifferent methods. Using the proposed framework, we perform a large suite of\nexperiments which provide criteria for choosing backbone, aggregation and\nnegative mining depending on the use-case and requirements. We also assess the\nimpact of engineering techniques like pre/post-processing, data augmentation\nand image resizing, showing that better performance can be obtained through\nsomewhat simple procedures: for example, downscaling the images' resolution to\n80% can lead to similar results with a 36% savings in extraction time and\ndataset storage requirement. Code and trained models are available at\nhttps://deep-vg-bench.herokuapp.com/.",
    "descriptor": "\nComments: CVPR 2022 (Oral)\n",
    "authors": [
      "Gabriele Berton",
      "Riccardo Mereu",
      "Gabriele Trivigno",
      "Carlo Masone",
      "Gabriela Csurka",
      "Torsten Sattler",
      "Barbara Caputo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.03444"
  },
  {
    "id": "arXiv:2204.03445",
    "title": "A new DG method for a pure--stress formulation of the Brinkman problem  with strong symmetry",
    "abstract": "A strongly symmetric stress approximation is proposed for the Brinkman\nequations with mixed boundary conditions. The resulting formulation solves for\nthe Cauchy stress using a symmetric interior penalty discontinuous Galerkin\nmethod. Pressure and velocity are readily post-processed from stress, and a\nsecond post-process is shown to produce exactly divergence-free discrete\nvelocities. We demonstrate the stability of the method with respect to a\nDG-energy norm and obtain error estimates that are explicit with respect to the\ncoefficients of the problem. We derive optimal rates of convergence for the\nstress and for the post-processed variables. Moreover, under appropriate\nassumptions on the mesh, we prove optimal $L^2$-error estimates for the stress.\nFinally, we provide numerical examples in 2D and 3D.",
    "descriptor": "\nComments: 17 pages\n",
    "authors": [
      "Salim Meddahi",
      "Ricardo Ruiz-Baier"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2204.03445"
  },
  {
    "id": "arXiv:2204.03456",
    "title": "Few-Shot Forecasting of Time-Series with Heterogeneous Channels",
    "abstract": "Learning complex time series forecasting models usually requires a large\namount of data, as each model is trained from scratch for each task/data set.\nLeveraging learning experience with similar datasets is a well-established\ntechnique for classification problems called few-shot classification. However,\nexisting approaches cannot be applied to time-series forecasting because i)\nmultivariate time-series datasets have different channels and ii) forecasting\nis principally different from classification. In this paper we formalize the\nproblem of few-shot forecasting of time-series with heterogeneous channels for\nthe first time. Extending recent work on heterogeneous attributes in vector\ndata, we develop a model composed of permutation-invariant deep set-blocks\nwhich incorporate a temporal embedding. We assemble the first meta-dataset of\n40 multivariate time-series datasets and show through experiments that our\nmodel provides a good generalization, outperforming baselines carried over from\nsimpler scenarios that either fail to learn across tasks or miss temporal\ninformation.",
    "descriptor": "\nComments: Under review. Equal contribution (Brinkmeyer and Rego Drumond)\n",
    "authors": [
      "Lukas Brinkmeyer",
      "Rafael Rego Drumond",
      "Johannes Burchert",
      "Lars Schmidt-Thieme"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.03456"
  },
  {
    "id": "arXiv:2204.03458",
    "title": "Video Diffusion Models",
    "abstract": "Generating temporally coherent high fidelity video is an important milestone\nin generative modeling research. We make progress towards this milestone by\nproposing a diffusion model for video generation that shows very promising\ninitial results. Our model is a natural extension of the standard image\ndiffusion architecture, and it enables jointly training from image and video\ndata, which we find to reduce the variance of minibatch gradients and speed up\noptimization. To generate long and higher resolution videos we introduce a new\nconditional sampling technique for spatial and temporal video extension that\nperforms better than previously proposed methods. We present the first results\non a large text-conditioned video generation task, as well as state-of-the-art\nresults on an established unconditional video generation benchmark.\nSupplementary material is available at https://video-diffusion.github.io/",
    "descriptor": "",
    "authors": [
      "Jonathan Ho",
      "Tim Salimans",
      "Alexey Gritsenko",
      "William Chan",
      "Mohammad Norouzi",
      "David J. Fleet"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.03458"
  },
  {
    "id": "arXiv:2204.03465",
    "title": "BERTuit: Understanding Spanish language in Twitter through a native  transformer",
    "abstract": "The appearance of complex attention-based language models such as BERT,\nRoberta or GPT-3 has allowed to address highly complex tasks in a plethora of\nscenarios. However, when applied to specific domains, these models encounter\nconsiderable difficulties. This is the case of Social Networks such as Twitter,\nan ever-changing stream of information written with informal and complex\nlanguage, where each message requires careful evaluation to be understood even\nby humans given the important role that context plays. Addressing tasks in this\ndomain through Natural Language Processing involves severe challenges. When\npowerful state-of-the-art multilingual language models are applied to this\nscenario, language specific nuances use to get lost in translation. To face\nthese challenges we present \\textbf{BERTuit}, the larger transformer proposed\nso far for Spanish language, pre-trained on a massive dataset of 230M Spanish\ntweets using RoBERTa optimization. Our motivation is to provide a powerful\nresource to better understand Spanish Twitter and to be used on applications\nfocused on this social network, with special emphasis on solutions devoted to\ntackle the spreading of misinformation in this platform. BERTuit is evaluated\non several tasks and compared against M-BERT, XLM-RoBERTa and XLM-T, very\ncompetitive multilingual transformers. The utility of our approach is shown\nwith applications, in this case: a zero-shot methodology to visualize groups of\nhoaxes and profiling authors spreading disinformation.\nMisinformation spreads wildly on platforms such as Twitter in languages other\nthan English, meaning performance of transformers may suffer when transferred\noutside English speaking communities.",
    "descriptor": "\nComments: Support: 1) BBVA FOUNDATION - CIVIC, 2) Spanish Ministry of Science and Innovation - FightDIS (PID2020-117263GB-100) and XAI-Disinfodemics (PLEC2021-007681), 3) Comunidad Autonoma de Madrid - S2018/TCS-4566, 4) European Comission - IBERIFIER (2020-EU-IA-0252), 5) Digital Future Society (Mobile World Capital Barcelona) - DisTrack, 6) UPM - Programa de Excelencia para el Profesorado Universitario\n",
    "authors": [
      "Javier Huertas-Tato",
      "Alejandro Martin",
      "David Camacho"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.03465"
  },
  {
    "id": "arXiv:2204.03467",
    "title": "Jacobian Norm for Unsupervised Source-Free Domain Adaptation",
    "abstract": "Unsupervised Source (data) Free domain adaptation (USFDA) aims to transfer\nknowledge from a well-trained source model to a related but unlabeled target\ndomain. In such a scenario, all conventional adaptation methods that require\nsource data fail. To combat this challenge, existing USFDAs turn to transfer\nknowledge by aligning the target feature to the latent distribution hidden in\nthe source model. However, such information is naturally limited. Thus, the\nalignment in such a scenario is not only difficult but also insufficient, which\ndegrades the target generalization performance. To relieve this dilemma in\ncurrent USFDAs, we are motivated to explore a new perspective to boost their\nperformance. For this purpose and gaining necessary insight, we look back upon\nthe origin of the domain adaptation and first theoretically derive a new-brand\ntarget generalization error bound based on the model smoothness. Then,\nfollowing the theoretical insight, a general and model-smoothness-guided\nJacobian norm (JN) regularizer is designed and imposed on the target domain to\nmitigate this dilemma. Extensive experiments are conducted to validate its\neffectiveness. In its implementation, just with a few lines of codes added to\nthe existing USFDAs, we achieve superior results on various benchmark datasets.",
    "descriptor": "\nComments: 8 pages\n",
    "authors": [
      "Weikai Li",
      "Meng Cao",
      "Songcan Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2204.03467"
  },
  {
    "id": "arXiv:2204.03471",
    "title": "DynLight: Realize dynamic phase duration with multi-level traffic signal  control",
    "abstract": "Adopting reinforcement learning (RL) for traffic signal control is\nincreasingly popular. Most RL methods use fixed action interval (denoted as\ntduration) and actuate or maintain a phase every tduration, which makes the\nphase duration less dynamic and flexible. In addition, the actuated phase can\nbe arbitrary, affecting the real-world deployment, which requires a fixed\ncyclical phase structure. To address these challenges, we propose a multi-level\ntraffic signal control framework, DynLight, which uses an optimization method\nMax-QueueLength (M-QL) to determine the phase and uses a deep Q-network to\ndetermine the corresponding duration. Based on DynLight, we further propose\nDynLight-C that adopts a well trained deep Q-network of DynLight and replace\nM-QL by a fixed cyclical control policy that actuate a set of phases in fixed\norder to realize cyclical phase structure. Comprehensive experiments on\nmultiple real-world datasets demonstrate that DynLight achives a new\nstate-of-the-art. Furthermore, the deep Q-network of DynLight can learn well on\ndetermining the phase duration and DynLight-C demonstrates high performance for\ndeployment.",
    "descriptor": "\nComments: 6 pages, 3 figures\n",
    "authors": [
      "Liang Zhang",
      "Shubin Xie",
      "Jianming Deng"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2204.03471"
  },
  {
    "id": "arXiv:2204.03472",
    "title": "Distance Learning in Primary School During the COVID 19 Pandemic:  Results of the \"SMART KIDS\" Experiment",
    "abstract": "The paper analyzes the results of the introduction of the distance learning\nform (DLF) using electronic educational resources (EER) and the teacher's\nvirtual classroom in primary school. The experiment took place within the\nframework of the \"Smart Kids\" All-Ukrainian project during the long quarantine\ncaused by the COVID-19 pandemic. The educational process took place both\nsynchronously and asynchronously. The present paper substantiates the model of\norganization of distance learning of primary school students using EER and\noutlines its three main components: the organization of learning, conducting\nonline classes (explaining new material or practicing skills by students) and\nmonitoring the quality of students' independent performance of tasks. The\nresults of the experiment prove that it is necessary to provide teachers and\nstudents with computer equipment, Internet access, digital resources for\nteaching and assessment to implement DLF. It has been established that EER in\ndistance learning can be used both on a regular basis - in each class, and\nperiodically - to explain new material or train skills, the quality of tasks\nperformed by students can be monitored in the virtual office of the teacher and\nshape an individual trajectory of students' development. The teachers\nidentified the following main problems of DLF implementation: internet\ninterruptions, problems with providing new computer equipment to students and\nsome teachers; lack of state aid in providing EER to all participants in the\neducational process; limited access to students' computers during complete\nisolation due to online work of parents. Despite the outlined problems, the\nquality of distance learning of primary school students during the pandemic\nusing EER was positively and highly assessed by teachers.",
    "descriptor": "\nComments: 10 pages,10 figures, VI International Workshop on Professional Retraining and Life-Long Learning using ICT: Person-oriented Approach (3L-Person 2021)\n",
    "authors": [
      "Svitlana Lytvynova",
      "Nataliia Demeshkant"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2204.03472"
  },
  {
    "id": "arXiv:2204.03475",
    "title": "Solving ImageNet: a Unified Scheme for Training any Backbone to Top  Results",
    "abstract": "ImageNet serves as the primary dataset for evaluating the quality of\ncomputer-vision models. The common practice today is training each architecture\nwith a tailor-made scheme, designed and tuned by an expert. In this paper, we\npresent a unified scheme for training any backbone on ImageNet. The scheme,\nnamed USI (Unified Scheme for ImageNet), is based on knowledge distillation and\nmodern tricks. It requires no adjustments or hyper-parameters tuning between\ndifferent models, and is efficient in terms of training times. We test USI on a\nwide variety of architectures, including CNNs, Transformers, Mobile-oriented\nand MLP-only. On all models tested, USI outperforms previous state-of-the-art\nresults. Hence, we are able to transform training on ImageNet from an\nexpert-oriented task to an automatic seamless routine. Since USI accepts any\nbackbone and trains it to top results, it also enables to perform methodical\ncomparisons, and identify the most efficient backbones along the speed-accuracy\nPareto curve. Implementation is available\nat:https://github.com/Alibaba-MIIL/Solving_ImageNet",
    "descriptor": "",
    "authors": [
      "Tal Ridnik",
      "Hussam Lawen",
      "Emanuel Ben-Baruch",
      "Asaf Noy"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.03475"
  },
  {
    "id": "arXiv:2204.03476",
    "title": "ProbNVS: Fast Novel View Synthesis with Learned Probability-Guided  Sampling",
    "abstract": "Existing state-of-the-art novel view synthesis methods rely on either fairly\naccurate 3D geometry estimation or sampling of the entire space for neural\nvolumetric rendering, which limit the overall efficiency. In order to improve\nthe rendering efficiency by reducing sampling points without sacrificing\nrendering quality, we propose to build a novel view synthesis framework based\non learned MVS priors that enables general, fast and photo-realistic view\nsynthesis simultaneously. Specifically, fewer but important points are sampled\nunder the guidance of depth probability distributions extracted from the\nlearned MVS architecture. Based on the learned probability-guided sampling, a\nneural volume rendering module is elaborately devised to fully aggregate source\nview information as well as the learned scene structures to synthesize\nphotorealistic target view images. Finally, the rendering results in uncertain,\noccluded and unreferenced regions can be further improved by incorporating a\nconfidence-aware refinement module. Experiments show that our method achieves\n15 to 40 times faster rendering compared to state-of-the-art baselines, with\nstrong generalization capacity and comparable high-quality novel view synthesis\nperformance.",
    "descriptor": "",
    "authors": [
      "Yuemei Zhou",
      "Tao Yu",
      "Zerong Zheng",
      "Ying Fu",
      "Yebin Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.03476"
  },
  {
    "id": "arXiv:2204.03479",
    "title": "Delta Keyword Transformer: Bringing Transformers to the Edge through  Dynamically Pruned Multi-Head Self-Attention",
    "abstract": "Multi-head self-attention forms the core of Transformer networks. However,\ntheir quadratically growing complexity with respect to the input sequence\nlength impedes their deployment on resource-constrained edge devices. We\naddress this challenge by proposing a dynamic pruning method, which exploits\nthe temporal stability of data across tokens to reduce inference cost. The\nthreshold-based method only retains significant differences between the\nsubsequent tokens, effectively reducing the number of multiply-accumulates, as\nwell as the internal tensor data sizes. The approach is evaluated on the Google\nSpeech Commands Dataset for keyword spotting, and the performance is compared\nagainst the baseline Keyword Transformer. Our experiments show that we can\nreduce ~80% of operations while maintaining the original 98.4% accuracy.\nMoreover, a reduction of ~87-94% operations can be achieved when only degrading\nthe accuracy by 1-4%, speeding up the multi-head self-attention inference by a\nfactor of ~7.5-16.",
    "descriptor": "",
    "authors": [
      "Zuzana Jel\u010dicov\u00e1",
      "Marian Verhelst"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.03479"
  },
  {
    "id": "arXiv:2204.03484",
    "title": "Commitment games with conditional information revelation",
    "abstract": "The conditional commitment abilities of mutually transparent computer agents\nhave been studied in previous work on commitment games and program equilibrium.\nThis literature has shown how these abilities can help resolve Prisoner's\nDilemmas and other failures of cooperation in complete information settings.\nBut inefficiencies due to private information have been neglected thus far in\nthis literature, despite the fact that these problems are pervasive and might\nalso be addressed by greater mutual transparency. In this work, we introduce a\nframework for commitment games with a new kind of conditional commitment\ndevice, which agents can use to conditionally reveal private information. We\nprove a folk theorem for this setting that provides sufficient conditions for\nex post efficiency, and thus represents a model of ideal cooperation between\nagents without a third-party mediator. Connecting our framework with the\nliterature on strategic information revelation, we explore cases where\nconditional revelation can be used to achieve full cooperation while\nunconditional revelation cannot. Finally, extending previous work on program\nequilibrium, we develop an implementation of conditional information\nrevelation. We show that this implementation forms program $\\epsilon$-Bayesian\nNash equilibria corresponding to the Bayesian Nash equilibria of these\ncommitment games.",
    "descriptor": "\nComments: Accepted at the Games, Agents, and Incentives Workshop at AAMAS 2022\n",
    "authors": [
      "Anthony DiGiovanni",
      "Jesse Clifton"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2204.03484"
  },
  {
    "id": "arXiv:2204.03487",
    "title": "Optimizing the Long-Term Behaviour of Deep Reinforcement Learning for  Pushing and Grasping",
    "abstract": "We investigate the \"Visual Pushing for Grasping\" (VPG) system by Zeng et al.\nand the \"Hourglass\" system by Ewerton et al., an evolution of the former. The\nfocus of our work is the investigation of the capabilities of both systems to\nlearn long-term rewards and policies. Zeng et al. original task only needs a\nlimited amount of foresight. Ewerton et al. attain their best performance using\nan agent which only takes the most immediate action under consideration. We are\ninterested in the ability of their models and training algorithms to accurately\npredict long-term Q-Values. To evaluate this ability, we design a new bin\nsorting task and reward function. Our task requires agents to accurately\nestimate future rewards and therefore use high discount factors in their\nQ-Value calculation. We investigate the behaviour of an adaptation of the VPG\ntraining algorithm on our task. We show that this adaptation can not accurately\npredict the required long-term action sequences. In addition to the limitations\nidentified by Ewerton et al., it suffers from the known Deep Q-Learning problem\nof overestimated Q-Values. In an effort to solve our task, we turn to the\nHourglass models and combine them with the Double Q-Learning approach. We show\nthat this approach enables the models to accurately predict long-term action\nsequences when trained with large discount factors. Our results show that the\nDouble Q-Learning technique is essential for training with very high discount\nfactors, as the models Q-Value predictions diverge otherwise. We also\nexperiment with different approaches for discount factor scheduling, loss\ncalculation and exploration procedures. Our results show that the latter\nfactors do not visibly influence the model's performance for our task.",
    "descriptor": "",
    "authors": [
      "Rodrigo Chau"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2204.03487"
  },
  {
    "id": "arXiv:2204.03489",
    "title": "Position-based Prompting for Health Outcome Generation",
    "abstract": "Probing Pre-trained Language Models (PLMs) using prompts has indirectly\nimplied that language models (LMs) can be treated as knowledge bases. To this\nend, this phenomena has been effective especially when these LMs are fine-tuned\ntowards not just data of a specific domain, but also to the style or linguistic\npattern of the prompts themselves. We observe that, satisfying a particular\nlinguistic pattern in prompts is an unsustainable constraint that unnecessarily\nlengthens the probing task, especially because, they are often manually\ndesigned and the range of possible prompt template patterns can vary depending\non the prompting objective and domain. We therefore explore an idea of using a\nposition-attention mechanism to capture positional information of each word in\na prompt relative to the mask to be filled, hence avoiding the need to\nre-construct prompts when the prompts linguistic pattern changes. Using our\napproach, we demonstrate the ability of eliciting answers to rare prompt\ntemplates (in a case study on health outcome generation) such as Postfix and\nMixed patterns whose missing information is respectively at the start and in\nmultiple random places of the prompt. More so, using various biomedical PLMs,\nour approach consistently outperforms a baseline in which the default mask\nlanguage model (MLM) representation is used to predict masked tokens.",
    "descriptor": "",
    "authors": [
      "M. Abaho",
      "D. Bollegala",
      "P. Williamson",
      "S. Dodd"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.03489"
  },
  {
    "id": "arXiv:2204.03494",
    "title": "Deep Understanding based Multi-Document Machine Reading Comprehension",
    "abstract": "Most existing multi-document machine reading comprehension models mainly\nfocus on understanding the interactions between the input question and\ndocuments, but ignore following two kinds of understandings. First, to\nunderstand the semantic meaning of words in the input question and documents\nfrom the perspective of each other. Second, to understand the supporting cues\nfor a correct answer from the perspective of intra-document and\ninter-documents. Ignoring these two kinds of important understandings would\nmake the models oversee some important information that may be helpful for\ninding correct answers. To overcome this deiciency, we propose a deep\nunderstanding based model for multi-document machine reading comprehension. It\nhas three cascaded deep understanding modules which are designed to understand\nthe accurate semantic meaning of words, the interactions between the input\nquestion and documents, and the supporting cues for the correct answer. We\nevaluate our model on two large scale benchmark datasets, namely TriviaQA Web\nand DuReader. Extensive experiments show that our model achieves\nstate-of-the-art results on both datasets.",
    "descriptor": "\nComments: TALLIP\n",
    "authors": [
      "Feiliang Ren",
      "Yongkang Liu",
      "Bochao Li",
      "Zhibo Wang",
      "Yu Guo",
      "Shilei Liu",
      "Huimin Wu",
      "Jiaqi Wang",
      "Chunchao Liu",
      "Bingchao Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.03494"
  },
  {
    "id": "arXiv:2204.03497",
    "title": "Generalised Latent Assimilation in Heterogeneous Reduced Spaces with  Machine Learning Surrogate Models",
    "abstract": "Reduced-order modelling and low-dimensional surrogate models generated using\nmachine learning algorithms have been widely applied in high-dimensional\ndynamical systems to improve the algorithmic efficiency. In this paper, we\ndevelop a system which combines reduced-order surrogate models with a novel\ndata assimilation (DA) technique used to incorporate real-time observations\nfrom different physical spaces. We make use of local smooth surrogate functions\nwhich link the space of encoded system variables and the one of current\nobservations to perform variational DA with a low computational cost. The new\nsystem, named Generalised Latent Assimilation can benefit both the efficiency\nprovided by the reduced-order modelling and the accuracy of data assimilation.\nA theoretical analysis of the difference between surrogate and original\nassimilation cost function is also provided in this paper where an upper bound,\ndepending on the size of the local training set, is given. The new approach is\ntested on a high-dimensional CFD application of a two-phase liquid flow with\nnon-linear observation operators that current Latent Assimilation methods can\nnot handle. Numerical results demonstrate that the proposed assimilation\napproach can significantly improve the reconstruction and prediction accuracy\nof the deep learning surrogate model which is nearly 1000 times faster than the\nCFD simulation.",
    "descriptor": "",
    "authors": [
      "Sibo Cheng",
      "Jianhua Chen",
      "Charitos Anastasiou",
      "Panagiota Angeli",
      "Omar K. Matar",
      "Yi-Ke Guo",
      "Christopher C. Pain",
      "Rossella Arcucci"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Chaotic Dynamics (nlin.CD)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2204.03497"
  },
  {
    "id": "arXiv:2204.03498",
    "title": "On the Effectiveness of Pretrained Models for API Learning",
    "abstract": "Developers frequently use APIs to implement certain functionalities, such as\nparsing Excel Files, reading and writing text files line by line, etc.\nDevelopers can greatly benefit from automatic API usage sequence generation\nbased on natural language queries for building applications in a faster and\ncleaner manner. Existing approaches utilize information retrieval models to\nsearch for matching API sequences given a query or use RNN-based\nencoder-decoder to generate API sequences. As it stands, the first approach\ntreats queries and API names as bags of words. It lacks deep comprehension of\nthe semantics of the queries. The latter approach adapts a neural language\nmodel to encode a user query into a fixed-length context vector and generate\nAPI sequences from the context vector.\nWe want to understand the effectiveness of recent Pre-trained Transformer\nbased Models (PTMs) for the API learning task. These PTMs are trained on large\nnatural language corpora in an unsupervised manner to retain contextual\nknowledge about the language and have found success in solving similar Natural\nLanguage Processing (NLP) problems. However, the applicability of PTMs has not\nyet been explored for the API sequence generation task. We use a dataset that\ncontains 7 million annotations collected from GitHub to evaluate the PTMs\nempirically. This dataset was also used to assess previous approaches. Based on\nour results, PTMs generate more accurate API sequences and outperform other\nrelated methods by around 11%. We have also identified two different\ntokenization approaches that can contribute to a significant boost in PTMs'\nperformance for the API sequence generation task.",
    "descriptor": "\nComments: 12 pages, 4 figures, ICPC 2022\n",
    "authors": [
      "Mohammad Abdul Hadi",
      "Imam Nur Bani Yusuf",
      "Ferdian Thung",
      "Kien Gia Luong",
      "Jiang Lingxiao",
      "Fatemeh H. Fard",
      "David Lo"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.03498"
  },
  {
    "id": "arXiv:2204.03499",
    "title": "Unsignalized Intersection Management Strategy for Mixed Autonomy Traffic  Streams",
    "abstract": "With the rapid development of connected and automated vehicles (CAVs) and\nintelligent transportation infrastructure, CAVs and connected human-driven\nvehicles (CHVs) will coexist on the roads in the future for a long time. This\npaper comprehensively considers the different traffic characteristics of CHVs\nand CAVs, and systemically investigates the unsignalized intersection\nmanagement strategy from upper decision-making level to lower execution level.\nCombined with the designed vehicle planning and control algorithm, the\nunsignalized intersection management strategy consists of two parts: the\nheuristic priority queues based right of way allocation (HPQ) algorithm, and\nthe vehicle planning and control algorithm. In the HPQ algorithm, a vehicle\npriority management model considering the difference between CAVs and CHVs is\nbuilt to design the right of way management for CAVs and CHVs, respectively. In\nthe lower level for vehicle planning and control algorithm, different control\nmodes of CAVs are designed according to the upper level decision made by the\nHPQ algorithm. Moreover, the vehicle control execution is realized by the model\npredictive controller combined with the geographical environment constraints\nand the unsignalized intersection management strategy. The proposed strategy is\nevaluated by simulations, which show that the proposed intersection management\nstrategy can effectively reduce travel time and improve traffic efficiency. The\nintersection management strategy captures the real-world balance between\nefficiency and safety for potential future intelligent traffic systems.",
    "descriptor": "",
    "authors": [
      "Junjie Zhou",
      "Zhaokun Shen",
      "Xiaofan Wang",
      "Lin Wang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2204.03499"
  },
  {
    "id": "arXiv:2204.03500",
    "title": "Multi-Task Distributed Learning using Vision Transformer with Random  Patch Permutation",
    "abstract": "The widespread application of artificial intelligence in health research is\ncurrently hampered by limitations in data availability. Distributed learning\nmethods such as federated learning (FL) and shared learning (SL) are introduced\nto solve this problem as well as data management and ownership issues with\ntheir different strengths and weaknesses. The recent proposal of federated\nsplit task-agnostic (FeSTA) learning tries to reconcile the distinct merits of\nFL and SL by enabling the multi-task collaboration between participants through\nVision Transformer (ViT) architecture, but they suffer from higher\ncommunication overhead. To address this, here we present a multi-task\ndistributed learning using ViT with random patch permutation. Instead of using\na CNN based head as in FeSTA, p-FeSTA adopts a randomly permuting simple patch\nembedder, improving the multi-task learning performance without sacrificing\nprivacy. Experimental results confirm that the proposed method significantly\nenhances the benefit of multi-task collaboration, communication efficiency, and\nprivacy preservation, shedding light on practical multi-task distributed\nlearning in the field of medical imaging.",
    "descriptor": "\nComments: 10 pages\n",
    "authors": [
      "Sangjoon Park",
      "Jong Chul Ye"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.03500"
  },
  {
    "id": "arXiv:2204.03502",
    "title": "A Hard and Soft Hybrid Slicing Framework for Service Level Agreement  Guarantee via Deep Reinforcement Learning",
    "abstract": "Network slicing is a critical driver for guaranteeing the diverse service\nlevel agreements (SLA) in 5G and future networks. Recently, deep reinforcement\nlearning (DRL) has been widely utilized for resource allocation in network\nslicing. However, existing related works do not consider the performance loss\nassociated with the initial exploration phase of DRL. This paper proposes a new\nperformance-guaranteed slicing strategy with a soft and hard hybrid slicing\nsetting. Mainly, a common slice setting is applied to guarantee slices' SLA\nwhen training the neural network. Moreover, the resource of the common slice\ntends to precisely redistribute to slices with the training of DRL until it\nconverges. Furthermore, experiment results confirm the effectiveness of our\nproposed slicing framework: the slices' SLA of the training phase can be\nguaranteed, and the proposed algorithm can achieve the near-optimal performance\nin terms of the SLA satisfaction ratio, isolation degree and spectrum\nmaximization after convergence.",
    "descriptor": "\nComments: 5 pages, 5 figures, accepted by VTC2022-Spring\n",
    "authors": [
      "Heng Zhang",
      "Guangjin Pan",
      "Shugong Xu",
      "Shunqing Zhang",
      "Zhiyuan Jiang"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2204.03502"
  },
  {
    "id": "arXiv:2204.03503",
    "title": "Survey on Automated Short Answer Grading with Deep Learning: from Word  Embeddings to Transformers",
    "abstract": "Automated short answer grading (ASAG) has gained attention in education as a\nmeans to scale educational tasks to the growing number of students. Recent\nprogress in Natural Language Processing and Machine Learning has largely\ninfluenced the field of ASAG, of which we survey the recent research\nadvancements. We complement previous surveys by providing a comprehensive\nanalysis of recently published methods that deploy deep learning approaches. In\nparticular, we focus our analysis on the transition from hand engineered\nfeatures to representation learning approaches, which learn representative\nfeatures for the task at hand automatically from large corpora of data. We\nstructure our analysis of deep learning methods along three categories: word\nembeddings, sequential models, and attention-based methods. Deep learning\nimpacted ASAG differently than other fields of NLP, as we noticed that the\nlearned representations alone do not contribute to achieve the best results,\nbut they rather show to work in a complementary way with hand-engineered\nfeatures. The best performance are indeed achieved by methods that combine the\ncarefully hand-engineered features with the power of the semantic descriptions\nprovided by the latest models, like transformers architectures. We identify\nchallenges and provide an outlook on research direction that can be addressed\nin the future",
    "descriptor": "\nComments: Under review\n",
    "authors": [
      "Stefan Haller",
      "Adina Aldea",
      "Christin Seifert",
      "Nicola Strisciuglio"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.03503"
  },
  {
    "id": "arXiv:2204.03504",
    "title": "AI-aided Traffic Control Scheme for M2M Communications in the Internet  of Vehicles",
    "abstract": "Due to the rapid growth of data transmissions in internet of vehicles (IoV),\nfinding schemes that can effectively alleviate access congestion has become an\nimportant issue. Recently, many traffic control schemes have been studied.\nNevertheless, the dynamics of traffic and the heterogeneous requirements of\ndifferent IoV applications are not considered in most existing studies, which\nis significant for the random access resource allocation. In this paper, we\nconsider a hybrid traffic control scheme and use proximal policy optimization\n(PPO) method to tackle it. Firstly, IoV devices are divided into various\nclasses based on delay characteristics. The target of maximizing the successful\ntransmission of packets with the success rate constraint is established. Then,\nthe optimization objective is transformed into a markov decision process (MDP)\nmodel. Finally, the access class barring (ACB) factors are obtained based on\nthe PPO method to maximize the number of successful access devices. The\nperformance of the proposal algorithm in respect of successful events and delay\ncompared to existing schemes is verified by simulations.",
    "descriptor": "\nComments: 5 pages, 5 figures, conference\n",
    "authors": [
      "Haijun Zhang",
      "Minghui Jiang",
      "Xiangnan Liu",
      "Keping Long",
      "Victor C.M.Leung"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.03504"
  },
  {
    "id": "arXiv:2204.03505",
    "title": "Integrating Rankings into Quantized Scores in Peer Review",
    "abstract": "In peer review, reviewers are usually asked to provide scores for the papers.\nThe scores are then used by Area Chairs or Program Chairs in various ways in\nthe decision-making process. The scores are usually elicited in a quantized\nform to accommodate the limited cognitive ability of humans to describe their\nopinions in numerical values. It has been found that the quantized scores\nsuffer from a large number of ties, thereby leading to a significant loss of\ninformation. To mitigate this issue, conferences have started to ask reviewers\nto additionally provide a ranking of the papers they have reviewed. There are\nhowever two key challenges. First, there is no standard procedure for using\nthis ranking information and Area Chairs may use it in different ways\n(including simply ignoring them), thereby leading to arbitrariness in the\npeer-review process. Second, there are no suitable interfaces for judicious use\nof this data nor methods to incorporate it in existing workflows, thereby\nleading to inefficiencies. We take a principled approach to integrate the\nranking information into the scores. The output of our method is an updated\nscore pertaining to each review that also incorporates the rankings. Our\napproach addresses the two aforementioned challenges by: (i) ensuring that\nrankings are incorporated into the updates scores in the same manner for all\npapers, thereby mitigating arbitrariness, and (ii) allowing to seamlessly use\nexisting interfaces and workflows designed for scores. We empirically evaluate\nour method on synthetic datasets as well as on peer reviews from the ICLR 2017\nconference, and find that it reduces the error by approximately 30% as compared\nto the best performing baseline on the ICLR 2017 data.",
    "descriptor": "\nComments: 14 main pages, 7 appendix pages\n",
    "authors": [
      "Yusha Liu",
      "Yichong Xu",
      "Nihar B. Shah",
      "Aarti Singh"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.03505"
  },
  {
    "id": "arXiv:2204.03506",
    "title": "QCRI's COVID-19 Disinformation Detector: A System to Fight the COVID-19  Infodemic in Social Media",
    "abstract": "Fighting the ongoing COVID-19 infodemic has been declared as one of the most\nimportant focus areas by the World Health Organization since the onset of the\nCOVID-19 pandemic. While the information that is consumed and disseminated\nconsists of promoting fake cures, rumors, and conspiracy theories to spreading\nxenophobia and panic, at the same time there is information (e.g., containing\nadvice, promoting cure) that can help different stakeholders such as\npolicy-makers. Social media platforms enable the infodemic and there has been\nan effort to curate the content on such platforms, analyze and debunk them.\nWhile a majority of the research efforts consider one or two aspects (e.g.,\ndetecting factuality) of such information, in this study we focus on a\nmultifaceted approach, including an\nAPI,\\url{https://app.swaggerhub.com/apis/yifan2019/Tanbih/0.8.0/} and a demo\nsystem,\\url{https://covid19.tanbih.org}, which we made freely and publicly\navailable. We believe that this will facilitate researchers and different\nstakeholders. A screencast of the API services and demo is\navailable.\\url{https://youtu.be/zhbcSvxEKMk}",
    "descriptor": "\nComments: disinformation, misinformation, factuality, fact-checking, fact-checkers, check-worthiness, Social Media Platforms, COVID-19, social media\n",
    "authors": [
      "Preslav Nakov",
      "Firoj Alam",
      "Yifan Zhang",
      "Animesh Prakash",
      "Fahim Dalvi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Information Retrieval (cs.IR)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2204.03506"
  },
  {
    "id": "arXiv:2204.03507",
    "title": "Reliable Transiently-Powered Communication",
    "abstract": "Frequent power failures can introduce significant packet losses during\ncommunication among energy harvesting batteryless wireless sensors. Nodes\nshould be aware of the energy level of their neighbors to guarantee the success\nof communication and avoid wasting energy. This paper presents TRAP\n(TRAnsiently-powered Protocol) that allows nodes to communicate only if the\nenergy availability on both sides of the communication channel is sufficient\nbefore packet transmission. TRAP relies on a novel modulator circuit, which\noperates without microcontroller intervention and transmits the energy status\nalmost for free over the radiofrequency backscatter channel. Our experimental\nresults showed that TRAP avoids failed transmissions introduced by the power\nfailures and ensures reliable intermittent communication among batteryless\nsensors.",
    "descriptor": "\nComments: 10 pages, 12 figures, 5 tables\n",
    "authors": [
      "Alessandro Torrisi",
      "Kas\u0131m Sinan Y\u0131ld\u0131r\u0131m",
      "Davide Brunelli"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2204.03507"
  },
  {
    "id": "arXiv:2204.03508",
    "title": "A Survey of Multi-task Learning in Natural Language Processing:  Regarding Task Relatedness and Training Methods",
    "abstract": "Multi-task learning (MTL) has become increasingly popular in natural language\nprocessing (NLP) because it improves the performance of related tasks by\nexploiting their commonalities and differences. Nevertheless, it is still not\nunderstood very well how multi-task learning can be implemented based on the\nrelatedness of training tasks. In this survey, we review recent advances of\nmulti-task learning methods in NLP, with the aim of summarizing them into two\ngeneral multi-task training methods based on their task relatedness: (i) joint\ntraining and (ii) multi-step training. We present examples in various NLP\ndownstream applications, summarize the task relationships and discuss future\ndirections of this promising topic.",
    "descriptor": "",
    "authors": [
      "Zhihan Zhang",
      "Wenhao Yu",
      "Mengxia Yu",
      "Zhichun Guo",
      "Meng Jiang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.03508"
  },
  {
    "id": "arXiv:2204.03511",
    "title": "Interval Bound Propagation--aided Few-shot Learning",
    "abstract": "Few-shot learning aims to transfer the knowledge acquired from training on a\ndiverse set of tasks, from a given task distribution, to generalize to unseen\ntasks, from the same distribution, with a limited amount of labeled data. The\nunderlying requirement for effective few-shot generalization is to learn a good\nrepresentation of the task manifold. One way to encourage this is to preserve\nlocal neighborhoods in the feature space learned by the few-shot learner. To\nthis end, we introduce the notion of interval bounds from the provably robust\ntraining literature to few-shot learning. The interval bounds are used to\ncharacterize neighborhoods around the training tasks. These neighborhoods can\nthen be preserved by minimizing the distance between a task and its respective\nbounds. We further introduce a novel strategy to artificially form new tasks\nfor training by interpolating between the available tasks and their respective\ninterval bounds, to aid in cases with a scarcity of tasks. We apply our\nframework to both model-agnostic meta-learning as well as prototype-based\nmetric-learning paradigms. The efficacy of our proposed approach is evident\nfrom the improved performance on several datasets from diverse domains in\ncomparison to a sizable number of recent competitors.",
    "descriptor": "",
    "authors": [
      "Shounak Datta",
      "Sankha Subhra Mullick",
      "Swagatam Das"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.03511"
  },
  {
    "id": "arXiv:2204.03512",
    "title": "Forecasting lifetime and performance of a novel NVM last-level cache  with compression",
    "abstract": "Non-volatile memory (NVM) technologies are interesting alternatives for\nbuilding the on-chip Last-Level Cache (LLC). Their advantages, compared to SRAM\nmemory, are higher density and lower static power, but each write operation\nslightly wears out the bitcell, to the point of losing its storage capacity. In\nthis context, this paper proposes a novel NV-LLC organization leveraging data\ncompression. Data compression reduces the size of the blocks and, together with\nwear-leveling mechanisms, can defer the degradation of such a NV-LLC. Moreover,\nas capacity is reduced by write wear, data compression enables degraded cache\nframes to allocate blocks whose compressed size is adequate.\nFrom a methodological point of view, although different approaches are used\nin the literature to analyze the degradation of a NV-LLC, none of them allows\nto study in detail its temporal evolution. In this sense, this work proposes a\nforecasting procedure that combines detailed simulation and prediction,\nenabling an accurate analysis of different cache content mechanisms\n(replacement, wear leveling, compression, etc.) on the temporal evolution of\nthe indices of interest, such as the effective capacity of the NV-LLC or the\nsystem IPC.\nThe proposed NV-LLC organization has a small added cost compared to that of a\nbaseline NV-LLC without compression in terms of area, latency and energy\nconsumption, and increases more than 6 times the time a NV-LLC takes to reach\n50% effective capacity.",
    "descriptor": "",
    "authors": [
      "Carlos Escuin",
      "Pablo Iba\u00f1ez",
      "Teresa Monreal",
      "Jose M. Llaberia",
      "Victor Vi\u00f1als"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2204.03512"
  },
  {
    "id": "arXiv:2204.03513",
    "title": "Many-to-many Splatting for Efficient Video Frame Interpolation",
    "abstract": "Motion-based video frame interpolation commonly relies on optical flow to\nwarp pixels from the inputs to the desired interpolation instant. Yet due to\nthe inherent challenges of motion estimation (e.g. occlusions and\ndiscontinuities), most state-of-the-art interpolation approaches require\nsubsequent refinement of the warped result to generate satisfying outputs,\nwhich drastically decreases the efficiency for multi-frame interpolation. In\nthis work, we propose a fully differentiable Many-to-Many (M2M) splatting\nframework to interpolate frames efficiently. Specifically, given a frame pair,\nwe estimate multiple bidirectional flows to directly forward warp the pixels to\nthe desired time step, and then fuse any overlapping pixels. In doing so, each\nsource pixel renders multiple target pixels and each target pixel can be\nsynthesized from a larger area of visual context. This establishes a\nmany-to-many splatting scheme with robustness to artifacts like holes.\nMoreover, for each input frame pair, M2M only performs motion estimation once\nand has a minuscule computational overhead when interpolating an arbitrary\nnumber of in-between frames, hence achieving fast multi-frame interpolation. We\nconducted extensive experiments to analyze M2M, and found that it significantly\nimproves efficiency while maintaining high effectiveness.",
    "descriptor": "\nComments: CVPR2022, Project: this https URL\n",
    "authors": [
      "Ping Hu",
      "Simon Niklaus",
      "Stan Sclaroff",
      "Kate Saenko"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2204.03513"
  },
  {
    "id": "arXiv:2204.03514",
    "title": "Habitat-Web: Learning Embodied Object-Search Strategies from Human  Demonstrations at Scale",
    "abstract": "We present a large-scale study of imitating human demonstrations on tasks\nthat require a virtual robot to search for objects in new environments -- (1)\nObjectGoal Navigation (e.g. 'find & go to a chair') and (2) Pick&Place (e.g.\n'find mug, pick mug, find counter, place mug on counter'). First, we develop a\nvirtual teleoperation data-collection infrastructure -- connecting Habitat\nsimulator running in a web browser to Amazon Mechanical Turk, allowing remote\nusers to teleoperate virtual robots, safely and at scale. We collect 80k\ndemonstrations for ObjectNav and 12k demonstrations for Pick&Place, which is an\norder of magnitude larger than existing human demonstration datasets in\nsimulation or on real robots.\nSecond, we attempt to answer the question -- how does large-scale imitation\nlearning (IL) (which hasn't been hitherto possible) compare to reinforcement\nlearning (RL) (which is the status quo)? On ObjectNav, we find that IL (with no\nbells or whistles) using 70k human demonstrations outperforms RL using 240k\nagent-gathered trajectories. The IL-trained agent demonstrates efficient\nobject-search behavior -- it peeks into rooms, checks corners for small\nobjects, turns in place to get a panoramic view -- none of these are exhibited\nas prominently by the RL agent, and to induce these behaviors via RL would\nrequire tedious reward engineering. Finally, accuracy vs. training data size\nplots show promising scaling behavior, suggesting that simply collecting more\ndemonstrations is likely to advance the state of art further. On Pick&Place,\nthe comparison is starker -- IL agents achieve ${\\sim}$18% success on episodes\nwith new object-receptacle locations when trained with 9.5k human\ndemonstrations, while RL agents fail to get beyond 0%. Overall, our work\nprovides compelling evidence for investing in large-scale imitation learning.\nProject page: https://ram81.github.io/projects/habitat-web.",
    "descriptor": "",
    "authors": [
      "Ram Ramrakhya",
      "Eric Undersander",
      "Dhruv Batra",
      "Abhishek Das"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2204.03514"
  },
  {
    "id": "arXiv:2204.03516",
    "title": "Distributed Reinforcement Learning for Robot Teams: A Review",
    "abstract": "Purpose of review: Recent advances in sensing, actuation, and computation\nhave opened the door to multi-robot systems consisting of hundreds/thousands of\nrobots, with promising applications to automated manufacturing, disaster\nrelief, harvesting, last-mile delivery, port/airport operations, or search and\nrescue. The community has leveraged model-free multi-agent reinforcement\nlearning (MARL) to devise efficient, scalable controllers for multi-robot\nsystems (MRS). This review aims to provide an analysis of the state-of-the-art\nin distributed MARL for multi-robot cooperation.\nRecent findings: Decentralized MRS face fundamental challenges, such as\nnon-stationarity and partial observability. Building upon the \"centralized\ntraining, decentralized execution\" paradigm, recent MARL approaches include\nindependent learning, centralized critic, value decomposition, and\ncommunication learning approaches. Cooperative behaviors are demonstrated\nthrough AI benchmarks and fundamental real-world robotic capabilities such as\nmulti-robot motion/path planning.\nSummary: This survey reports the challenges surrounding decentralized\nmodel-free MARL for multi-robot cooperation and existing classes of approaches.\nWe present benchmarks and robotic applications along with a discussion on\ncurrent open avenues for research.",
    "descriptor": "\nComments: Preprint of the paper submitted to Springer's Current Robotics Reports\n",
    "authors": [
      "Yutong Wang",
      "Mehul Damani",
      "Pamela Wang",
      "Yuhong Cao",
      "Guillaume Sartoretti"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2204.03516"
  },
  {
    "id": "arXiv:2204.03518",
    "title": "Validating a Cortisol-Inspired Framework for Human-Robot Interaction  with a Replication of the Still Face Paradigm",
    "abstract": "When interacting with others in our everyday life, we prefer the company of\nthose who share with us the same desire of closeness and intimacy (or lack\nthereof), since this determines if our interaction will be more o less\npleasant. This sort of compatibility can be inferred by our innate attachment\nstyle. The attachment style represents our characteristic way of thinking,\nfeeling and behaving in close relationship, and other than behaviourally, it\ncan also affect us biologically via our hormonal dynamics. When we are looking\nhow to enrich human-robot interaction (HRI), one potential solution could be\nenabling robots to understand their partners' attachment style, which could\nthen improve the perception of their partners and help them behave in an\nadaptive manner during the interaction. We propose to use the relationship\nbetween the attachment style and the cortisol hormone, to endow the humanoid\nrobot iCub with an internal cortisol inspired framework that allows it to infer\nparticipant's attachment style by the effect of the interaction on its cortisol\nlevels (referred to as R-cortisol). In this work, we present our cognitive\nframework and its validation during the replication of a well-known paradigm on\nhormonal modulation in human-human interaction (HHI) - the Still Face paradigm.",
    "descriptor": "\nComments: Paper submitted to ICDL 2022\n",
    "authors": [
      "Sara Mongile",
      "Ana Tanevska",
      "Francesco Rea",
      "Alessandra Sciutti"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2204.03518"
  },
  {
    "id": "arXiv:2204.03521",
    "title": "DeepXPalm: Tilt and Position Rendering using Palm-worn Haptic Display  and CNN-based Tactile Pattern Recognition",
    "abstract": "Telemanipulation of deformable objects requires high precision and dexterity\nfrom the users, which can be increased by kinesthetic and tactile feedback.\nHowever, the object shape can change dynamically, causing ambiguous perception\nof its alignment and hence errors in the robot positioning. Therefore, the tilt\nangle and position classification problem has to be solved to present a clear\ntactile pattern to the user. This work presents a telemanipulation system for\nplastic pipettes consisting of a multi-contact haptic device LinkGlide to\ndeliver haptic feedback at the users' palm and two tactile sensors array\nembedded in the 2-finger Robotiq gripper. We propose a novel approach based on\nConvolutional Neural Networks (CNN) to detect the tilt and position while\ngrasping deformable objects. The CNN generates a mask based on recognized tilt\nand position data to render further multi-contact tactile stimuli provided to\nthe user during the telemanipulation. The study has shown that using the CNN\nalgorithm and the preset mask, tilt, and position recognition by users is\nincreased from 9.67% using the direct data to 82.5%.",
    "descriptor": "\nComments: Accepted paper in IEEE Haptic Symposium 2022, IEEE copyright\n",
    "authors": [
      "Altamirano Cabrera Miguel",
      "Sautenkov Oleg",
      "Tirado Jonathan",
      "Fedoseev Aleksey",
      "Kopanev Pavel",
      "Kajimoto Hiroyuki",
      "Tsetserukou Dzmitry"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2204.03521"
  },
  {
    "id": "arXiv:2204.03525",
    "title": "Temporal Alignment for History Representation in Reinforcement Learning",
    "abstract": "Environments in Reinforcement Learning are usually only partially observable.\nTo address this problem, a possible solution is to provide the agent with\ninformation about the past. However, providing complete observations of\nnumerous steps can be excessive. Inspired by human memory, we propose to\nrepresent history with only important changes in the environment and, in our\napproach, to obtain automatically this representation using self-supervision.\nOur method (TempAl) aligns temporally-close frames, revealing a general, slowly\nvarying state of the environment. This procedure is based on contrastive loss,\nwhich pulls embeddings of nearby observations to each other while pushing away\nother samples from the batch. It can be interpreted as a metric that captures\nthe temporal relations of observations. We propose to combine both common\ninstantaneous and our history representation and we evaluate TempAl on all\navailable Atari games from the Arcade Learning Environment. TempAl surpasses\nthe instantaneous-only baseline in 35 environments out of 49. The source code\nof the method and of all the experiments is available at\nhttps://github.com/htdt/tempal.",
    "descriptor": "\nComments: ICPR 2022\n",
    "authors": [
      "Aleksandr Ermolov",
      "Enver Sangineto",
      "Nicu Sebe"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.03525"
  },
  {
    "id": "arXiv:2204.03526",
    "title": "Reconstructing Bayesian Networks on a Quantum Annealer",
    "abstract": "Bayesian networks are widely used probabilistic graphical models, whose\nstructure is hard to learn starting from the generated data. O'Gorman et al.\nhave proposed an algorithm to encode this task, i.e., the Bayesian network\nstructure learning (BSNL), into a form that can be solved through quantum\nannealing, but they have not provided an experimental evaluation of it. In this\npaper, we present (i) an implementation in Python of O'Gorman's algorithm, (ii)\na divide et impera approach that allows addressing BNSL problems of larger\nsizes in order to overcome the limitations imposed by the current\narchitectures, and (iii) their empirical evaluation. Specifically, several\nproblems with an increasing number of variables have been used in the\nexperiments. The results have shown the effectiveness of O'Gorman's formulation\nfor BNSL instances of small sizes, and the superiority of the divide et impera\napproach on the direct execution of O'Gorman's algorithm.",
    "descriptor": "\nComments: 29 pages, 6 figures\n",
    "authors": [
      "Enrico Zardini",
      "Massimo Rizzoli",
      "Sebastiano Dissegna",
      "Enrico Blanzieri",
      "Davide Pastorello"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2204.03526"
  },
  {
    "id": "arXiv:2204.03528",
    "title": "Visualizing Deep Neural Networks with Topographic Activation Maps",
    "abstract": "Machine Learning with Deep Neural Networks (DNNs) has become a successful\ntool in solving tasks across various fields of application. The success of DNNs\nis strongly connected to their high complexity in terms of the number of\nnetwork layers or of neurons in each layer, which severely complicates to\nunderstand how DNNs solve their learned task. To improve the explainability of\nDNNs, we adapt methods from neuroscience because this field has a rich\nexperience in analyzing complex and opaque systems. In this work, we draw\ninspiration from how neuroscience uses topographic maps to visualize the\nactivity of the brain when it performs certain tasks. Transferring this\napproach to DNNs can help to visualize and understand their internal processes\nmore intuitively, too. However, the inner structures of brains and DNNs differ\nsubstantially. Therefore, to be able to visualize activations of neurons in\nDNNs as topographic maps, we research techniques to layout the neurons in a\ntwo-dimensional space in which neurons of similar activity are in the vicinity\nof each other. In this work, we introduce and compare different methods to\nobtain a topographic layout of the neurons in a network layer. Moreover, we\ndemonstrate how to use the resulting topographic activation maps to identify\nerrors or encoded biases in DNNs or data sets. Our novel visualization\ntechnique improves the transparency of DNN-based algorithmic decision-making\nsystems and is accessible to a broad audience because topographic maps are\nintuitive to interpret without expert-knowledge in Machine Learning.",
    "descriptor": "",
    "authors": [
      "Andreas Krug",
      "Raihan Kabir Ratul",
      "Sebastian Stober"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2204.03528"
  },
  {
    "id": "arXiv:2204.03529",
    "title": "FedADMM: A Robust Federated Deep Learning Framework with Adaptivity to  System Heterogeneity",
    "abstract": "Federated Learning (FL) is an emerging framework for distributed processing\nof large data volumes by edge devices subject to limited communication\nbandwidths, heterogeneity in data distributions and computational resources, as\nwell as privacy considerations. In this paper, we introduce a new FL protocol\ntermed FedADMM based on primal-dual optimization. The proposed method leverages\ndual variables to tackle statistical heterogeneity, and accommodates system\nheterogeneity by tolerating variable amount of work performed by clients.\nFedADMM maintains identical communication costs per round as FedAvg/Prox, and\ngeneralizes them via the augmented Lagrangian. A convergence proof is\nestablished for nonconvex objectives, under no restrictions in terms of data\ndissimilarity or number of participants per round of the algorithm. We\ndemonstrate the merits through extensive experiments on real datasets, under\nboth IID and non-IID data distributions across clients. FedADMM consistently\noutperforms all baseline methods in terms of communication efficiency, with the\nnumber of rounds needed to reach a prescribed accuracy reduced by up to 87%.\nThe algorithm effectively adapts to heterogeneous data distributions through\nthe use of dual variables, without the need for hyperparameter tuning, and its\nadvantages are more pronounced in large-scale systems.",
    "descriptor": "",
    "authors": [
      "Yonghai Gong",
      "Yichuan Li",
      "Nikolaos M. Freris"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.03529"
  },
  {
    "id": "arXiv:2204.03530",
    "title": "A Monolithic Eulerian Formulation for non-Classical Fluid-Structure  Interaction (nCFSI): Modeling and Simulation",
    "abstract": "In this paper a new monolithic Eulerian formulation in the framework of\nnon-classical continuum is presented for the analysis of fluid-strucuture\ninteraction problems. In this respect, Cosserat continuum theory taking into\naccount the micro-rotational degrees of freedom of the particles is considered.\nContinuum description of the model and variational formulation of the governing\nflow dynamics for non-classical -fluid-structure interaction nCFSI is\npresented. The model is analyzed by computing a well known benchmark problem by\nHecht and Pironneau (2017). The algorithmic description is presented and\nimplemented using FreeFEM++. Code is validated with the benchmark solution of\nTurek and Hron (2006) in case of flow around a flag attached with cylinder. New\nmicrostructural behavior of the solution is studied and numerical simulations\nand results are shown in the form of figures. Some interesting feature of the\nflow is observed and microstructural characteristics are discussed.",
    "descriptor": "\nComments: 15 pages, 10 figures. arXiv admin note: substantial text overlap with arXiv:2203.16493\n",
    "authors": [
      "Nazim Hussain",
      "Muhammad Sabeel Khan",
      "Lisheng Liu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2204.03530"
  },
  {
    "id": "arXiv:2204.03532",
    "title": "Literature Review on Image Compression, Tracking, Adaptive Training and  3D Data Transmission",
    "abstract": "The literature review presented below on Image Compression, Transmission of\n3D data over wireless networks and tracking of objects is the in depth study of\nResearch Papers done in Multimedia lab. Most of the papers presented in this\nliterature review have tackled the problems present in the conventional system\nand offered an optimal and practical solution.",
    "descriptor": "",
    "authors": [
      "Sravanti Chinta",
      "Rajat Bothra Jain"
    ],
    "subjectives": [
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2204.03532"
  },
  {
    "id": "arXiv:2204.03533",
    "title": "Efficient Multiscale Object-based Superpixel Framework",
    "abstract": "Superpixel segmentation can be used as an intermediary step in many\napplications, often to improve object delineation and reduce computer workload.\nHowever, classical methods do not incorporate information about the desired\nobject. Deep-learning-based approaches consider object information, but their\ndelineation performance depends on data annotation. Additionally, the\ncomputational time of object-based methods is usually much higher than desired.\nIn this work, we propose a novel superpixel framework, named Superpixels\nthrough Iterative CLEarcutting (SICLE), which exploits object information being\nable to generate a multiscale segmentation on-the-fly. SICLE starts off from\nseed oversampling and repeats optimal connectivity-based superpixel delineation\nand object-based seed removal until a desired number of superpixels is reached.\nIt generalizes recent superpixel methods, surpassing them and other\nstate-of-the-art approaches in efficiency and effectiveness according to\nmultiple delineation metrics.",
    "descriptor": "\nComments: 19 pages\n",
    "authors": [
      "Felipe Bel\u00e9m",
      "Benjamin Perret",
      "Jean Cousty",
      "Silvio J. F. Guimar\u00e3es",
      "Alexandre Falc\u00e3o"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.03533"
  },
  {
    "id": "arXiv:2204.03535",
    "title": "Practical Issues and Challenges in CSI-based Integrated Sensing and  Communication",
    "abstract": "Next-generation mobile communication network (i.e., 6G) has been envisioned\nto go beyond classical communication functionality and provide integrated\nsensing and communication (ISAC) capability to enable more emerging\napplications, such as smart cities, connected vehicles, AIoT and health\ncare/elder care. Among all the ISAC proposals, the most practical and promising\napproach is to empower existing wireless network (e.g., WiFi, 4G/5G) with the\naugmented ability to sense the surrounding human and environment, and evolve\nwireless communication networks into intelligent communication and sensing\nnetwork (e.g., 6G). In this paper, based on our experience on CSI-based\nwireless sensing with WiFi/4G/5G signals, we intend to identify ten major\npractical and theoretical problems that hinder real deployment of ISAC\napplications, and provide possible solutions to those critical challenges.\nHopefully, this work will inspire further research to evolve existing\nWiFi/4G/5G networks into next-generation intelligent wireless network (i.e.,\n6G).",
    "descriptor": "\nComments: ICC 2022 workshop on integrated sensing and communication (ISAC)\n",
    "authors": [
      "Daqing Zhang",
      "Dan Wu",
      "Kai Niu",
      "Xuanzhi Wang",
      "Fusang Zhang",
      "Jian Yao",
      "Dajie Jiang",
      "Fei Qin"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2204.03535"
  },
  {
    "id": "arXiv:2204.03536",
    "title": "Abstracting Noisy Robot Programs",
    "abstract": "Abstraction is a commonly used process to represent some low-level system by\na more coarse specification with the goal to omit unnecessary details while\npreserving important aspects. While recent work on abstraction in the situation\ncalculus has focused on non-probabilistic domains, we describe an approach to\nabstraction of probabilistic and dynamic systems. Based on a variant of the\nsituation calculus with probabilistic belief, we define a notion of\nbisimulation that allows to abstract a detailed probabilistic basic action\ntheory with noisy actuators and sensors by a possibly deterministic basic\naction theory. By doing so, we obtain abstract Golog programs that omit\nunnecessary details and which can be translated back to a detailed program for\nactual execution. This simplifies the implementation of noisy robot programs,\nopens up the possibility of using deterministic reasoning methods (e.g.,\nplanning) on probabilistic problems, and provides domain descriptions that are\nmore easily understandable and explainable.",
    "descriptor": "",
    "authors": [
      "Till Hofmann",
      "Vaishak Belle"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.03536"
  },
  {
    "id": "arXiv:2204.03538",
    "title": "Updating Industrial Robots for Emerging Technologies",
    "abstract": "Industrial arms need to evolve beyond their standard shape to embrace new and\nemerging technologies. In this paper, we shall first perform an analysis of\nfour popular but different modern industrial robot arms. By seeing the common\ntrends we will try to extrapolate and expand these trends for the future. Here,\nparticular focus will be on interaction based on augmented reality (AR) through\nhead-mounted displays (HMD), but also through smartphones. Long-term\nhuman-robot interaction and personalization of said interaction will also be\nconsidered. The use of AR in human-robot interaction has proven to enhance\ncommunication and information exchange. A basic addition to industrial arm\ndesign would be the integration of QR markers on the robot, both for accessing\ninformation and adding tracking capabilities to more easily display AR\noverlays. In a recent example of information access, Mercedes Benz added QR\nmarkers on their cars to help rescue workers estimate the best places to cut\nand evacuate people after car crashes. One has also to deal with safety in an\nenvironment that will be more and more about collaboration. The QR markers can\ntherefore be combined with RF-based ranging modules, developed in the\nEU-project SafeLog, that can be used both for safety as well as for tracking of\nhuman positions while in close proximity interactions with the industrial arms.\nThe industrial arms of the future should also be intuitive to program and\ninteract with. This would be achieved through AR and head mounted displays as\nwell as the already mentioned RF-based person tracking. Finally, a more\npersonalized interaction between the robots and humans can be achieved through\nlife-long learning AI and disembodied, personalized agents. We propose a design\nthat not only exists in the physical world, but also partly in the digital\nworld of mixed reality.",
    "descriptor": "\nComments: As accepted to the 2nd International Workshop on Designerly HRI; HRI 2022\n",
    "authors": [
      "David Puljiz",
      "Bj\u00f6rn Hein"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2204.03538"
  },
  {
    "id": "arXiv:2204.03541",
    "title": "End-to-End Zero-Shot HOI Detection via Vision and Language Knowledge  Distillation",
    "abstract": "Most existing Human-Object Interaction~(HOI) Detection methods rely heavily\non full annotations with predefined HOI categories, which is limited in\ndiversity and costly to scale further. We aim at advancing zero-shot HOI\ndetection to detect both seen and unseen HOIs simultaneously. The fundamental\nchallenges are to discover potential human-object pairs and identify novel HOI\ncategories. To overcome the above challenges, we propose a novel end-to-end\nzero-shot HOI Detection (EoID) framework via vision-language knowledge\ndistillation. We first design an Interactive Score module combined with a\nTwo-stage Bipartite Matching algorithm to achieve interaction distinguishment\nfor human-object pairs in an action-agnostic manner. Then we transfer the\ndistribution of action probability from the pretrained vision-language teacher\nas well as the seen ground truth to the HOI model to attain zero-shot HOI\nclassification. Extensive experiments on HICO-Det dataset demonstrate that our\nmodel discovers potential interactive pairs and enables the recognition of\nunseen HOIs. Finally, our method outperforms the previous SOTA by 8.92% on\nunseen mAP and 10.18% on overall mAP under UA setting, by 6.02% on unseen mAP\nand 9.1% on overall mAP under UC setting. Moreover, our method is generalizable\nto large-scale object detection data to further scale up the action sets. The\nsource code will be available at: https://github.com/mrwu-mac/EoID.",
    "descriptor": "",
    "authors": [
      "Mingrui Wu",
      "Jiaxin Gu",
      "Yunhang Shen",
      "Mingbao Lin",
      "Chao Chen",
      "Xiaoshuai Sun",
      "Rongrong Ji"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.03541"
  },
  {
    "id": "arXiv:2204.03542",
    "title": "Leveraging pre-trained language models for conversational information  seeking from text",
    "abstract": "Recent advances in Natural Language Processing, and in particular on the\nconstruction of very large pre-trained language representation models, is\nopening up new perspectives on the construction of conversational information\nseeking (CIS) systems. In this paper we investigate the usage of in-context\nlearning and pre-trained language representation models to address the problem\nof information extraction from process description documents, in an incremental\nquestion and answering oriented fashion. In particular we investigate the usage\nof the native GPT-3 (Generative Pre-trained Transformer 3) model, together with\ntwo in-context learning customizations that inject conceptual definitions and a\nlimited number of samples in a few shot-learning fashion. The results highlight\nthe potential of the approach and the usefulness of the in-context learning\ncustomizations, which can substantially contribute to address the \"training\ndata challenge\" of deep learning based NLP techniques the BPM field. It also\nhighlight the challenge posed by control flow relations for which further\ntraining needs to be devised.",
    "descriptor": "",
    "authors": [
      "Patrizio Bellan",
      "Mauro Dragoni",
      "Chiara Ghidini"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.03542"
  },
  {
    "id": "arXiv:2204.03546",
    "title": "Conversational agents for fostering curiosity-driven learning in  children",
    "abstract": "Curiosity is an important factor that favors independent and individualized\nlearning in children. Research suggests that it is also a competence that can\nbe fostered by training specific metacognitive skills and information-searching\nbehaviors. In this light, we develop a conversational agent that helps children\ngenerate curiosity-driven questions, and encourages their use to lead\nautonomous explorations and gain new knowledge. The study was conducted with 51\nprimary school students who interacted with either a neutral agent or an\nincentive agent that helped curiosity-driven questioning by offering specific\nsemantic cues. Results showed a significant increase in the number and the\nquality of the questions generated with the incentive agent. This interaction\nalso resulted in longer explorations and stronger learning progress. Together,\nour results suggest that the more our agent is able to train children's\ncuriosity-related metacognitive skills, the better they can maintain their\ninformation-searching behaviors and the more new knowledge they are likely to\nacquire.",
    "descriptor": "",
    "authors": [
      "Rania Abdelghani",
      "Pierre-Yves Oudeyer",
      "Edith Law",
      "Catherine de Vulpilli\u00e8res",
      "H\u00e9l\u00e8ne Sauz\u00e9on"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2204.03546"
  },
  {
    "id": "arXiv:2204.03550",
    "title": "Lane-Free Crossing of CAVs through Signal-Free Intersections as a  Minimum-Time Optimal Control Problem",
    "abstract": "Unlike traditional cars, connected and autonomous vehicles (CAVs) can cross\nintersections in a lane-free and signal-free order to increase the\ntemporal-spatial capacity of intersections. This paper presents an optimal\nstrategy to centrally control the CAVs entering an intersection to minimise the\nworst crossing time of the vehicles, or equivalently maximise the throughput of\nthe intersection. The strategy is the solution of a minimum-time optimal\ncontrol problem (OCP) that is highly non-convex due to the existence of\nconstraints to avoid collision of vehicles with each other and with road\nboundaries. An algorithm is proposed to solve the formulated OCP by smoothing\nand convexifying the obstacle avoidance constraints using their dual equivalent\nproblems in the form of relaxed necessary conditions. Simulation results show\nan average of 52% improvement in the crossing time of intersections as compared\nto the state-of-the-art reservation-based methods. Furthermore, it is shown\nthat the minimum crossing time of an intersection is fixed and does not change\nregardless of the number of CAVs.",
    "descriptor": "\nComments: 8 pages, 7 figures, Journal paper\n",
    "authors": [
      "Mahdi Amouzadi",
      "Mobolaji Olawumi Orisatoki",
      "Arash M. Dizqah"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Multiagent Systems (cs.MA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2204.03550"
  },
  {
    "id": "arXiv:2204.03551",
    "title": "Strong Admissibility, a Tractable Algorithmic Approach (proofs)",
    "abstract": "Much like admissibility is the key concept underlying preferred semantics,\nstrong admissibility is the key concept underlying grounded semantics, as\nmembership of a strongly admissible set is sufficient to show membership of the\ngrounded extension. As such, strongly admissible sets and labellings can be\nused as an explanation of membership of the grounded extension, as is for\ninstance done in some of the proof procedures for grounded semantics. In the\ncurrent paper, we present two polynomial algorithms for constructing relatively\nsmall strongly admissible labellings, with associated min-max numberings, for a\nparticular argument. These labellings can be used as relatively small\nexplanations for the argument's membership of the grounded extension. Although\nour algorithms are not guaranteed to yield an absolute minimal strongly\nadmissible labelling for the argument (as doing do would have implied an\nexponential complexity), our best performing algorithm yields results that are\nonly marginally bigger. Moreover, the runtime of this algorithm is an order of\nmagnitude smaller than that of the existing approach for computing an absolute\nminimal strongly admissible labelling for a particular argument. As such, we\nbelieve that our algorithms can be of practical value in situations where the\naim is to construct a minimal or near-minimal strongly admissible labelling in\na time-efficient way.",
    "descriptor": "",
    "authors": [
      "Martin Caminada",
      "Sri Harikrishnan"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.03551"
  },
  {
    "id": "arXiv:2204.03552",
    "title": "On the Correctness of Speculative Consensus",
    "abstract": "The introduction of Bitcoin fueled the development of blockchain-based\nresilient data management systems that are resilient against failures, enable\nfederated data management, and can support data provenance. The key factor\ndetermining the performance of such resilient data management systems is the\nconsensus protocol used by the system to replicate client transactions among\nall participants. Unfortunately, existing high-throughput consensus protocols\nare costly and impose significant latencies on transaction processing, which\nrules out their usage in responsive high-performance data management systems.\nIn this work, we improve on this situation by introducing the\nProof-of-Execution consensus protocol (PoE), a consensus protocol designed for\nhigh-performance low-latency resilient data management. PoE introduces\nspeculative execution, which minimizes latencies by starting execution before\nconsensus is reached, and PoE introduces proof-of-executions to guarantee\nsuccessful execution to clients. Furthermore, PoE introduces a single-round\ncheck-commit protocol to reduce the overall communication costs of consensus.\nHence, we believe that PoE is a promising step towards flexible general-purpose\nlow-latency resilient data management systems.",
    "descriptor": "\nComments: An extended abstract of this work appeared at the 24th International Conference on Extending Database Technology (EDBT 2021), see also arXiv:1911.00838\n",
    "authors": [
      "Jelle Hellings",
      "Suyash Gupta",
      "Sajjad Rahnama",
      "Mohammad Sadoghi"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2204.03552"
  },
  {
    "id": "arXiv:2204.03556",
    "title": "Goodbye Tracking? Impact of iOS App Tracking Transparency and Privacy  Labels",
    "abstract": "Tracking is a highly privacy-invasive data collection practice that has been\nubiquitous in mobile apps for many years due to its role in supporting\nadvertising-based revenue models. In defence of user privacy, Apple introduced\ntwo significant changes with iOS 14: App Tracking Transparency (ATT), a\nmandatory opt-in system for enabling tracking on iOS, and Privacy Nutrition\nLabels, which disclose what kinds of data each app processes. This paper\nstudies two versions of 1,759 iOS apps from the UK App Store: one version from\nbefore iOS 14 and one that has been updated to comply with the new rules.\nWe find that Apple's new policies, as promised, prevent the collection of the\nIdentifier for Advertisers (IDFA), an identifier used to facilitate cross-app\nuser tracking. However, many apps still collect device information that can be\nused to track users at a group level (cohort tracking) or identify individuals\nprobabilistically (fingerprinting). We find real-world evidence of apps\ncomputing and agreeing on a fingerprinting-derived identifier through the use\nof server-side code, thereby violating Apple's policies and exposing the limits\nof what ATT can do against tracking on iOS. This is especially concerning\nbecause we explicitly refused opt-in to tracking in our study, and consent is a\nlegal requirement for tracking under EU and UK data protection law. We find\nthat Apple itself engages in some forms of tracking and exempts invasive data\npractices like first-party tracking and credit scoring from its new rules, and\nthat the new Privacy Nutrition Labels were often inaccurate.\nOverall, our findings suggest that, while tracking individual users is more\ndifficult now, the changes reinforce existing market power of gatekeeper\ncompanies with access to large troves of first-party data.",
    "descriptor": "\nComments: This paper has been accepted for publication by the ACM Conference on Fairness, Accountability, and Transparency (FAccT) 2022\n",
    "authors": [
      "Konrad Kollnig",
      "Anastasia Shuba",
      "Max Van Kleek",
      "Reuben Binns",
      "Nigel Shadbolt"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2204.03556"
  },
  {
    "id": "arXiv:2204.03558",
    "title": "Mapping the Multilingual Margins: Intersectional Biases of Sentiment  Analysis Systems in English, Spanish, and Arabic",
    "abstract": "As natural language processing systems become more widespread, it is\nnecessary to address fairness issues in their implementation and deployment to\nensure that their negative impacts on society are understood and minimized.\nHowever, there is limited work that studies fairness using a multilingual and\nintersectional framework or on downstream tasks. In this paper, we introduce\nfour multilingual Equity Evaluation Corpora, supplementary test sets designed\nto measure social biases, and a novel statistical framework for studying\nunisectional and intersectional social biases in natural language processing.\nWe use these tools to measure gender, racial, ethnic, and intersectional social\nbiases across five models trained on emotion regression tasks in English,\nSpanish, and Arabic. We find that many systems demonstrate statistically\nsignificant unisectional and intersectional social biases.",
    "descriptor": "\nComments: LT-EDI 2022\n",
    "authors": [
      "Ant\u00f3nio C\u00e2mara",
      "Nina Taneja",
      "Tamjeed Azad",
      "Emily Allaway",
      "Richard Zemel"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.03558"
  },
  {
    "id": "arXiv:2204.03559",
    "title": "Practical Digital Disguises: Leveraging Face Swaps to Protect Patient  Privacy",
    "abstract": "With rapid advancements in image generation technology, face swapping for\nprivacy protection has emerged as an active area of research. The ultimate\nbenefit is improved access to video datasets, e.g. in healthcare settings.\nRecent literature has proposed deep network-based architectures to perform\nfacial swaps and reported the associated reduction in facial recognition\naccuracy. However, there is not much reporting on how well these methods\npreserve the types of semantic information needed for the privatized videos to\nremain useful for their intended application. Our main contribution is a novel\nend-to-end face swapping pipeline for recorded videos of standardized\nassessments of autism symptoms in children. Through this design, we are the\nfirst to provide a methodology for assessing the privacy-utility trade-offs for\nthe face swapping approach to patient privacy protection. Our methodology can\nshow, for example, that current deep network based face swapping is\nbottle-necked by face detection in real world videos, and the extent to which\ngaze and expression information is preserved by face swaps relative to baseline\nprivatization methods such as blurring.",
    "descriptor": "\nComments: 15 pages, 9 figures\n",
    "authors": [
      "Ethan Wilson",
      "Frederick Shic",
      "Jenny Skytta",
      "Eakta Jain"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.03559"
  },
  {
    "id": "arXiv:2204.03561",
    "title": "Emotional Speech Recognition with Pre-trained Deep Visual Models",
    "abstract": "In this paper, we propose a new methodology for emotional speech recognition\nusing visual deep neural network models. We employ the transfer learning\ncapabilities of the pre-trained computer vision deep models to have a mandate\nfor the emotion recognition in speech task. In order to achieve that, we\npropose to use a composite set of acoustic features and a procedure to convert\nthem into images. Besides, we present a training paradigm for these models\ntaking into consideration the different characteristics between acoustic-based\nimages and regular ones. In our experiments, we use the pre-trained VGG-16\nmodel and test the overall methodology on the Berlin EMO-DB dataset for\nspeaker-independent emotion recognition. We evaluate the proposed model on the\nfull list of the seven emotions and the results set a new state-of-the-art.",
    "descriptor": "",
    "authors": [
      "Waleed Ragheb",
      "Mehdi Mirzapour",
      "Ali Delfardi",
      "H\u00e9l\u00e8ne Jacquenet",
      "Lawrence Carbon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)",
      "Multimedia (cs.MM)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2204.03561"
  },
  {
    "id": "arXiv:2204.03563",
    "title": "Transfinite Modal Logic: a Semi-quantitative Explanation for Bayesian  Reasoning",
    "abstract": "Bayesian reasoning plays a significant role both in human rationality and in\nmachine learning. In this paper, we introduce transfinite modal logic, which\ncombines modal logic with ordinal arithmetic, in order to formalize Bayesian\nreasoning semi-quantitatively. Technically, we first investigate some\nnontrivial properties of ordinal arithmetic, which then enable us to expand\nnormal modal logic's semantics naturally and elegantly onto the novel\ntransfinite modal logic, while still keeping the ordinary definition of Kripke\nmodels totally intact. Despite all the transfinite mathematical definition, we\nargue that in practice, this logic can actually fit into a completely finite\ninterpretation as well. We suggest that transfinite modal logic captures the\nessence of Bayesian reasoning in a rather clear and simple form, in particular,\nit provides a perfect explanation for Sherlock Holmes' famous saying, \"When you\nhave eliminated the impossible, whatever remains, however improbable, must be\nthe truth.\" We also prove a counterpart of finite model property theorem for\nour logic.",
    "descriptor": "",
    "authors": [
      "Xinyu Wang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)",
      "Logic (math.LO)"
    ],
    "url": "https://arxiv.org/abs/2204.03563"
  },
  {
    "id": "arXiv:2204.03569",
    "title": "Faster algorithms for learning to link, align sequences, and price  two-part tariffs",
    "abstract": "Data-driven algorithm configuration is a promising, learning-based approach\nfor beyond worst-case analysis of algorithms with tunable parameters. An\nimportant open problem is the design of efficient data-driven algorithms for\nalgorithm families with more than one parameter. In this work we provide\nalgorithms for efficient (output-polynomial) multidimensional parameter tuning,\ni.e. for families with a small constant number of parameters, for three very\ndifferent combinatorial problems -- linkage-based clustering, dynamic\nprogramming for sequence alignment, and auction design for two-part tariff\nschemes. We extend the single-parameter clustering algorithm of Balcan et al.\n2020 arXiv:1907.00533 to multiple parameters and to the sequence alignment\nproblem by proposing an execution graph which compactly represents all the\nstates the algorithm could attain for all possible parameter values. A key\nproblem-specific challenge is to efficiently compute how the partition of the\nparameter space (into regions with unique algorithmic states) changes with a\nsingle algorithmic step. We give algorithms which improve on the runtime of\npreviously best known results for linkage-based clustering, sequence alignment\nand two-part tariff pricing.",
    "descriptor": "",
    "authors": [
      "Maria-Florina Balcan",
      "Christopher Seiler",
      "Dravyansh Sharma"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.03569"
  },
  {
    "id": "arXiv:2204.03570",
    "title": "Improving Urban Mobility: using artificial intelligence and new  technologies to connect supply and demand",
    "abstract": "As the demand for mobility in our society seems to increase, the various\nissues centered on urban mobility are among those that worry most city\ninhabitants in this planet. For instance, how to go from A to B in an efficient\n(but also less stressful) way? These questions and concerns have not changed\neven during the covid-19 pandemic; on the contrary, as the current stand,\npeople who are avoiding public transportation are only contributing to an\nincrease in the vehicular traffic. The are of intelligent transportation\nsystems (ITS) aims at investigating how to employ information and communication\ntechnologies to problems related to transportation. This may mean monitoring\nand managing the infrastructure (e.g., traffic roads, traffic signals, etc.).\nHowever, currently, ITS is also targeting the management of demand. In this\npanorama, artificial intelligence plays an important role, especially with the\nadvances in machine learning that translates in the use of computational\nvision, connected and autonomous vehicles, agent-based simulation, among\nothers. In the present work, a survey of several works developed by our group\nare discussed in a holistic perspective, i.e., they cover not only the supply\nside (as commonly found in ITS works), but also the demand side, and, in an\nnovel perspective, the integration of both.",
    "descriptor": "",
    "authors": [
      "Ana L. C. Bazzan"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.03570"
  },
  {
    "id": "arXiv:2204.03571",
    "title": "Explicit and Implicit Pattern Relation Analysis for Discovering  Actionable Negative Sequences",
    "abstract": "Real-life events, behaviors and interactions produce sequential data. An\nimportant but rarely explored problem is to analyze those nonoccurring (also\ncalled negative) yet important sequences, forming negative sequence analysis\n(NSA). A typical NSA area is to discover negative sequential patterns (NSPs)\nconsisting of important non-occurring and occurring elements and patterns. The\nlimited existing work on NSP mining relies on frequentist and downward closure\nproperty-based pattern selection, producing large and highly redundant NSPs,\nnonactionable for business decision-making. This work makes the first attempt\nfor actionable NSP discovery. It builds an NSP graph representation, quantify\nboth explicit occurrence and implicit non-occurrence-based element and pattern\nrelations, and then discover significant, diverse and informative NSPs in the\nNSP graph to represent the entire NSP set for discovering actionable NSPs. A\nDPP-based NSP representation and actionable NSP discovery method EINSP\nintroduces novel and significant contributions for NSA and sequence analysis:\n(1) it represents NSPs by a determinantal point process (DPP) based graph; (2)\nit quantifies actionable NSPs in terms of their statistical significance,\ndiversity, and strength of explicit/implicit element/pattern relations; and (3)\nit models and measures both explicit and implicit element/pattern relations in\nthe DPP-based NSP graph to represent direct and indirect couplings between NSP\nitems, elements and patterns. We substantially analyze the effectiveness of\nEINSP in terms of various theoretical and empirical aspects including\ncomplexity, item/pattern coverage, pattern size and diversity, implicit pattern\nrelation strength, and data factors.",
    "descriptor": "\nComments: 17 pages, 6 figures, 3 tables\n",
    "authors": [
      "Wei Wang",
      "Longbing Cao"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.03571"
  },
  {
    "id": "arXiv:2204.03574",
    "title": "Learning to Compose Soft Prompts for Compositional Zero-Shot Learning",
    "abstract": "We introduce compositional soft prompting (CSP), a parameter-efficient\nlearning technique to improve the zero-shot compositionality of large-scale\npretrained vision-language models (VLMs) without the overhead of fine-tuning\nthe entire model. VLMs can represent arbitrary classes as natural language\nprompts in their flexible text encoders but they underperform state-of-the-art\nmethods on compositional zero-shot benchmark tasks. To improve VLMs, we propose\na novel form of soft prompting. We treat the attributes and objects that are\ncomposed to define classes as learnable tokens of vocabulary and tune them on\nmultiple prompt compositions. During inference, we recompose the learned\nattribute-object vocabulary in new combinations and show that CSP outperforms\nthe original VLM on benchmark datasets by an average of 14.7 percentage points\nof accuracy. CSP also achieves new state-of-the-art accuracies on two out of\nthree benchmark datasets, while only fine-tuning a small number of parameters.\nFurther, we show that CSP improves generalization to higher-order\nattribute-attribute-object compositions and combinations of pretrained\nattributes and fine-tuned objects.",
    "descriptor": "",
    "authors": [
      "Nihal V. Nayak",
      "Peilin Yu",
      "Stephen H. Bach"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.03574"
  },
  {
    "id": "arXiv:2204.03575",
    "title": "Preconditioning for a Phase-Field Model with Application to Morphology  Evolution in Organic Semiconductors",
    "abstract": "The Cahn--Hilliard equations are a versatile model for describing the\nevolution of complex morphologies. In this paper we present a computational\npipeline for the numerical solution of a ternary phase-field model for\ndescribing the nanomorphology of donor--acceptor semiconductor blends used in\norganic photovoltaic devices. The model consists of two coupled fourth-order\npartial differential equations that are discretized using a finite element\napproach. In order to solve the resulting large-scale linear systems\nefficiently, we propose a preconditioning strategy that is based on efficient\napproximations of the Schur-complement of a saddle point system. We show that\nthis approach performs robustly with respect to variations in the\ndiscretization parameters. Finally, we outline that the computed morphologies\ncan be used for the computation of charge generation, recombination, and\ntransport in organic solar cells.",
    "descriptor": "",
    "authors": [
      "Kai Bergermann",
      "Carsten Deibel",
      "Roland Herzog",
      "Roderick C. I. MacKenzie",
      "Jan-Frederik Pietschmann",
      "Martin Stoll"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2204.03575"
  },
  {
    "id": "arXiv:2204.03583",
    "title": "Risk-based regulation for all: The need and a method for a wide adoption  solution for data-driven inspection targeting",
    "abstract": "Access to data and data processing, including the use of machine learning\ntechniques, has become significantly easier and cheaper in recent years.\nNevertheless, solutions that can be widely adopted by regulators for market\nmonitoring and inspection targeting in a data-driven way have not been\nfrequently discussed by the scientific community. This article discusses the\nneed and the difficulties for the development of such solutions, presents an\neffective method to address regulation planning, and illustrates its use to\naccount for the most important and common subject for the majority of\nregulators: the consumer. This article hopes to contribute to increase the\nawareness of the regulatory community to the need for data processing methods\nthat are objective, impartial, transparent, explainable, simple to implement\nand with low computational cost, aiming to the implementation of risk-based\nregulation in the world.",
    "descriptor": "",
    "authors": [
      "Celso H. H. Ribas",
      "Jos\u00e9 C. M. Bermudez"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2204.03583"
  },
  {
    "id": "arXiv:2204.03589",
    "title": "Collecting, Classifying, Analyzing, and Using Real-World Elections",
    "abstract": "We present a collection of $7582$ real-world elections from $25$ datasets\nfrom various sources ranging from sports competitions over music charts to\nsurvey- and indicator-based rankings. We provide evidence that the collected\nelections complement already publicly available data from the PrefLib database,\nwhich is currently the biggest and most prominent source containing $701$\nreal-world elections from $36$ datasets [Mattei and Walsh, ADT '13]. Using the\nmap of elections framework [Szufa et al., AAMAS '20], we divide the datasets\ninto three categories and conduct an analysis of the nature of our elections.\nTo evaluate the practical applicability of previous theoretical research on\n(parameterized) algorithms, we analyze different structural properties of our\nelections including the level of agreement between voters and election's\ndistances from restricted domains such as single-peakedness. Lastly, we use our\ndiverse set of collected elections to shed some further light on several\ntraditional questions from social choice, for instance, on the number of\noccurrences of the Condorcet paradox and on the consensus among different\nvoting rules.",
    "descriptor": "",
    "authors": [
      "Niclas Boehmer",
      "Nathan Schaar"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2204.03589"
  },
  {
    "id": "arXiv:2204.03592",
    "title": "Testing the limits of natural language models for predicting human  language judgments",
    "abstract": "Neural network language models can serve as computational hypotheses about\nhow humans process language. We compared the model-human consistency of diverse\nlanguage models using a novel experimental approach: controversial sentence\npairs. For each controversial sentence pair, two language models disagree about\nwhich sentence is more likely to occur in natural text. Considering nine\nlanguage models (including n-gram, recurrent neural networks, and transformer\nmodels), we created hundreds of such controversial sentence pairs by either\nselecting sentences from a corpus or synthetically optimizing sentence pairs to\nbe highly controversial. Human subjects then provided judgments indicating for\neach pair which of the two sentences is more likely. Controversial sentence\npairs proved highly effective at revealing model failures and identifying\nmodels that aligned most closely with human judgments. The most\nhuman-consistent model tested was GPT-2, although experiments also revealed\nsignificant shortcomings of its alignment with human perception.",
    "descriptor": "",
    "authors": [
      "Tal Golan",
      "Matthew Siegelman",
      "Nikolaus Kriegeskorte",
      "Christopher Baldassano"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2204.03592"
  },
  {
    "id": "arXiv:2204.03593",
    "title": "AutoRF: Learning 3D Object Radiance Fields from Single View Observations",
    "abstract": "We introduce AutoRF - a new approach for learning neural 3D object\nrepresentations where each object in the training set is observed by only a\nsingle view. This setting is in stark contrast to the majority of existing\nworks that leverage multiple views of the same object, employ explicit priors\nduring training, or require pixel-perfect annotations. To address this\nchallenging setting, we propose to learn a normalized, object-centric\nrepresentation whose embedding describes and disentangles shape, appearance,\nand pose. Each encoding provides well-generalizable, compact information about\nthe object of interest, which is decoded in a single-shot into a new target\nview, thus enabling novel view synthesis. We further improve the reconstruction\nquality by optimizing shape and appearance codes at test time by fitting the\nrepresentation tightly to the input image. In a series of experiments, we show\nthat our method generalizes well to unseen objects, even across different\ndatasets of challenging real-world street scenes such as nuScenes, KITTI, and\nMapillary Metropolis.",
    "descriptor": "\nComments: CVPR 2022. Project page: this https URL\n",
    "authors": [
      "Norman M\u00fcller",
      "Andrea Simonelli",
      "Lorenzo Porzi",
      "Samuel Rota Bul\u00f2",
      "Matthias Nie\u00dfner",
      "Peter Kontschieder"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.03593"
  },
  {
    "id": "arXiv:2204.03594",
    "title": "Heterogeneous Target Speech Separation",
    "abstract": "We introduce a new paradigm for single-channel target source separation where\nthe sources of interest can be distinguished using non-mutually exclusive\nconcepts (e.g., loudness, gender, language, spatial location, etc). Our\nproposed heterogeneous separation framework can seamlessly leverage datasets\nwith large distribution shifts and learn cross-domain representations under a\nvariety of concepts used as conditioning. Our experiments show that training\nseparation models with heterogeneous conditions facilitates the generalization\nto new concepts with unseen out-of-domain data while also performing\nsubstantially higher than single-domain specialist models. Notably, such\ntraining leads to more robust learning of new harder source separation\ndiscriminative concepts and can yield improvements over permutation invariant\ntraining with oracle source selection. We analyze the intrinsic behavior of\nsource separation training with heterogeneous metadata and propose ways to\nalleviate emerging problems with challenging separation conditions. We release\nthe collection of preparation recipes for all datasets used to further promote\nresearch towards this challenging task.",
    "descriptor": "\nComments: Submitted to Interspeech 2022\n",
    "authors": [
      "Efthymios Tzinis",
      "Gordon Wichern",
      "Aswin Subramanian",
      "Paris Smaragdis",
      "Jonathan Le Roux"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2204.03594"
  },
  {
    "id": "arXiv:2204.03596",
    "title": "Controlling Golog Programs against MTL Constraints",
    "abstract": "While Golog is an expressive programming language to control the high-level\nbehavior of a robot, it is often tedious to use on a real robotic system. On an\nactual robot, the user needs to consider low-level details, such as enabling\nand disabling hardware components, e.g., a camera to detect objects for\ngrasping. In other words, high-level actions usually pose implicit temporal\nconstraints on the low-level platform, which are typically independent of the\nconcrete program to be executed. In this paper, we propose to make these\nconstraints explicit by modeling them as MTL formulas, which enforce the\nexecution of certain low-level platform operations in addition to the main\nprogram. Based on results from timed automata controller synthesis, we describe\na method to synthesize a controller that executes both the high-level program\nand the low-level platform operations concurrently in order to satisfy the MTL\nspecification. This allows the user to focus on the high-level behavior without\nthe need to consider low-level operations. We present an extension to Golog by\nclocks together with the required theoretical foundations as well as\ndecidability results.",
    "descriptor": "",
    "authors": [
      "Till Hofmann",
      "Stefan Schupp"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.03596"
  },
  {
    "id": "arXiv:2204.03597",
    "title": "Imitating, Fast and Slow: Robust learning from demonstrations via  decision-time planning",
    "abstract": "The goal of imitation learning is to mimic expert behavior from\ndemonstrations, without access to an explicit reward signal. A popular class of\napproach infers the (unknown) reward function via inverse reinforcement\nlearning (IRL) followed by maximizing this reward function via reinforcement\nlearning (RL). The policies learned via these approaches are however very\nbrittle in practice and deteriorate quickly even with small test-time\nperturbations due to compounding errors. We propose Imitation with Planning at\nTest-time (IMPLANT), a new meta-algorithm for imitation learning that utilizes\ndecision-time planning to correct for compounding errors of any base imitation\npolicy. In contrast to existing approaches, we retain both the imitation policy\nand the rewards model at decision-time, thereby benefiting from the learning\nsignal of the two components. Empirically, we demonstrate that IMPLANT\nsignificantly outperforms benchmark imitation learning approaches on standard\ncontrol environments and excels at zero-shot generalization when subject to\nchallenging perturbations in test-time dynamics.",
    "descriptor": "",
    "authors": [
      "Carl Qi",
      "Pieter Abbeel",
      "Aditya Grover"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.03597"
  },
  {
    "id": "arXiv:2204.03603",
    "title": "Algebraic Structure of the Weak Stage Order Conditions for Runge-Kutta  Methods",
    "abstract": "Runge-Kutta (RK) methods may exhibit order reduction when applied to stiff\nproblems. For linear problems with time-independent operators, order reduction\ncan be avoided if the method satisfies certain weak stage order (WSO)\nconditions, which are less restrictive than traditional stage order conditions.\nThis paper outlines the first algebraic theory of WSO, and establishes general\norder barriers that relate the WSO of a RK scheme to its order and number of\nstages for both fully-implicit and DIRK schemes. It is shown in several\nscenarios that the constructed bounds are sharp. The theory characterizes WSO\nin terms of orthogonal invariant subspaces and associated minimal polynomials.\nThe resulting necessary conditions on the structure of RK methods with WSO are\nthen shown to be of practical use for the construction of such schemes.",
    "descriptor": "",
    "authors": [
      "Abhijit Biswas",
      "David Ketcheson",
      "Benjamin Seibold",
      "David Shirokoff"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2204.03603"
  },
  {
    "id": "arXiv:2204.03609",
    "title": "Pin the Memory: Learning to Generalize Semantic Segmentation",
    "abstract": "The rise of deep neural networks has led to several breakthroughs for\nsemantic segmentation. In spite of this, a model trained on source domain often\nfails to work properly in new challenging domains, that is directly concerned\nwith the generalization capability of the model. In this paper, we present a\nnovel memory-guided domain generalization method for semantic segmentation\nbased on meta-learning framework. Especially, our method abstracts the\nconceptual knowledge of semantic classes into categorical memory which is\nconstant beyond the domains. Upon the meta-learning concept, we repeatedly\ntrain memory-guided networks and simulate virtual test to 1) learn how to\nmemorize a domain-agnostic and distinct information of classes and 2) offer an\nexternally settled memory as a class-guidance to reduce the ambiguity of\nrepresentation in the test data of arbitrary unseen domain. To this end, we\nalso propose memory divergence and feature cohesion losses, which encourage to\nlearn memory reading and update processes for category-aware domain\ngeneralization. Extensive experiments for semantic segmentation demonstrate the\nsuperior generalization capability of our method over state-of-the-art works on\nvarious benchmarks.",
    "descriptor": "\nComments: Accepted to CVPR 2022\n",
    "authors": [
      "Jin Kim",
      "Jiyoung Lee",
      "Jungin Park",
      "Dongbo Min",
      "Kwanghoon Sohn"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.03609"
  },
  {
    "id": "arXiv:2204.03610",
    "title": "Unified Contrastive Learning in Image-Text-Label Space",
    "abstract": "Visual recognition is recently learned via either supervised learning on\nhuman-annotated image-label data or language-image contrastive learning with\nwebly-crawled image-text pairs. While supervised learning may result in a more\ndiscriminative representation, language-image pretraining shows unprecedented\nzero-shot recognition capability, largely due to the different properties of\ndata sources and learning objectives. In this work, we introduce a new\nformulation by combining the two data sources into a common image-text-label\nspace. In this space, we propose a new learning paradigm, called Unified\nContrastive Learning (UniCL) with a single learning objective to seamlessly\nprompt the synergy of two data types. Extensive experiments show that our UniCL\nis an effective way of learning semantically rich yet discriminative\nrepresentations, universally for image recognition in zero-shot, linear-probe,\nfully finetuning and transfer learning scenarios. Particularly, it attains\ngains up to 9.2% and 14.5% in average on zero-shot recognition benchmarks over\nthe language-image contrastive learning and supervised learning methods,\nrespectively. In linear probe setting, it also boosts the performance over the\ntwo methods by 7.3% and 3.4%, respectively. Our study also indicates that UniCL\nstand-alone is a good learner on pure image-label data, rivaling the supervised\nlearning methods across three image classification datasets and two types of\nvision backbones, ResNet and Swin Transformer. Code is available at\nhttps://github.com/microsoft/UniCL.",
    "descriptor": "\nComments: CVPR 2022\n",
    "authors": [
      "Jianwei Yang",
      "Chunyuan Li",
      "Pengchuan Zhang",
      "Bin Xiao",
      "Ce Liu",
      "Lu Yuan",
      "Jianfeng Gao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.03610"
  },
  {
    "id": "arXiv:2204.03619",
    "title": "Modeling Label Correlations for Second-Order Semantic Dependency Parsing  with Mean-Field Inference",
    "abstract": "Second-order semantic parsing with end-to-end mean-field inference has been\nshown good performance. In this work we aim to improve this method by modeling\nlabel correlations between adjacent arcs. However, direct modeling leads to\nmemory explosion because second-order score tensors have sizes of $O(n^3L^2)$\n($n$ is the sentence length and $L$ is the number of labels), which is not\naffordable. To tackle this computational challenge, we leverage tensor\ndecomposition techniques, and interestingly, we show that the large\nsecond-order score tensors have no need to be materialized during mean-field\ninference, thereby reducing the computational complexity from cubic to\nquadratic. We conduct experiments on SemEval 2015 Task 18 English datasets,\nshowing the effectiveness of modeling label correlations. Our code is publicly\navailable at https://github.com/sustcsonglin/mean-field-dep-parsing.",
    "descriptor": "\nComments: 12 pages\n",
    "authors": [
      "Songlin Yang",
      "Kewei Tu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.03619"
  },
  {
    "id": "arXiv:2204.03620",
    "title": "An Online Learning Approach to Shortest Path and Backpressure Routing in  Wireless Networks",
    "abstract": "We consider the adaptive routing problem in multihop wireless networks. The\nlink states are assumed to be random variables drawn from unknown\ndistributions, independent and identically distributed across links and time.\nThis model has attracted a growing interest recently in cognitive radio\nnetworks and adaptive communication systems. In such networks, devices are\ncognitive in the sense of learning the link states and updating the\ntransmission parameters to allow efficient resource utilization. This model\ncontrasts sharply with the vast literature on routing algorithms that assumed\ncomplete knowledge about the link state means. The goal is to design an\nalgorithm that learns online optimal paths for data transmissions to maximize\nthe network throughput while attaining low path cost over flows in the network.\nWe develop a novel Online Learning for Shortest path and Backpressure (OLSB)\nalgorithm to achieve this goal. We analyze the performance of OLSB rigorously\nand show that it achieves a logarithmic regret with time, defined as the loss\nof an algorithm as compared to a genie that has complete knowledge about the\nlink state means. We further evaluate the performance of OLSB numerically via\nextensive simulations, which support the theoretical findings and demonstrate\nits high efficiency.",
    "descriptor": "\nComments: 27 pages, 5 figures\n",
    "authors": [
      "Omer Amar",
      "Kobi Cohen"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2204.03620"
  },
  {
    "id": "arXiv:2204.03625",
    "title": "Security Aspects of Quantum Machine Learning: Opportunities, Threats and  Defenses",
    "abstract": "In the last few years, quantum computing has experienced a growth spurt. One\nexciting avenue of quantum computing is quantum machine learning (QML) which\ncan exploit the high dimensional Hilbert space to learn richer representations\nfrom limited data and thus can efficiently solve complex learning tasks.\nDespite the increased interest in QML, there have not been many studies that\ndiscuss the security aspects of QML. In this work, we explored the possible\nfuture applications of QML in the hardware security domain. We also expose the\nsecurity vulnerabilities of QML and emerging attack models, and corresponding\ncountermeasures.",
    "descriptor": "\nComments: 6 pages, GLSVLSI'22 Special Session\n",
    "authors": [
      "Satwik Kundu",
      "Swaroop Ghosh"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2204.03625"
  },
  {
    "id": "arXiv:2204.03631",
    "title": "Control Barrier Functions with Actuation Constraints under Signal  Temporal Logic Specifications",
    "abstract": "We propose control barrier functions (CBFs) for a family of dynamical systems\nto satisfy a broad fragment of Signal Temporal Logic (STL) specifications,\nwhich may include subtasks with nested temporal operators or conflicting\nrequirements (e.g., achieving multiple subtasks within the same time interval).\nThe proposed CBFs take into account the actuation limits of the dynamical\nsystem as well as a feasible sequence of subtasks, and they define time-varying\nfeasible sets of states the system must always stay inside. We show some\ntheoretical results on the correctness of the proposed method. We illustrate\nthe benefits of the proposed CBFs and compare their performance with the\nexisting methods via simulations.",
    "descriptor": "\nComments: Accepted to the 2022 European Control Conference (ECC)\n",
    "authors": [
      "Ali Tevfik Buyukkocak",
      "Derya Aksaray",
      "Yasin Yaz\u0131c\u0131o\u011flu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2204.03631"
  },
  {
    "id": "arXiv:2204.03632",
    "title": "The Effects of Regularization and Data Augmentation are Class Dependent",
    "abstract": "Regularization is a fundamental technique to prevent over-fitting and to\nimprove generalization performances by constraining a model's complexity.\nCurrent Deep Networks heavily rely on regularizers such as Data-Augmentation\n(DA) or weight-decay, and employ structural risk minimization, i.e.\ncross-validation, to select the optimal regularization hyper-parameters. In\nthis study, we demonstrate that techniques such as DA or weight decay produce a\nmodel with a reduced complexity that is unfair across classes. The optimal\namount of DA or weight decay found from cross-validation leads to disastrous\nmodel performances on some classes e.g. on Imagenet with a resnet50, the \"barn\nspider\" classification test accuracy falls from $68\\%$ to $46\\%$ only by\nintroducing random crop DA during training. Even more surprising, such\nperformance drop also appears when introducing uninformative regularization\ntechniques such as weight decay. Those results demonstrate that our search for\never increasing generalization performance -- averaged over all classes and\nsamples -- has left us with models and regularizers that silently sacrifice\nperformances on some classes. This scenario can become dangerous when deploying\na model on downstream tasks e.g. an Imagenet pre-trained resnet50 deployed on\nINaturalist sees its performances fall from $70\\%$ to $30\\%$ on class \\#8889\nwhen introducing random crop DA during the Imagenet pre-training phase. Those\nresults demonstrate that designing novel regularizers without class-dependent\nbias remains an open research question.",
    "descriptor": "",
    "authors": [
      "Randall Balestriero",
      "Leon Bottou",
      "Yann LeCun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2204.03632"
  },
  {
    "id": "arXiv:2204.03634",
    "title": "Class-Incremental Learning with Strong Pre-trained Models",
    "abstract": "Class-incremental learning (CIL) has been widely studied under the setting of\nstarting from a small number of classes (base classes). Instead, we explore an\nunderstudied real-world setting of CIL that starts with a strong model\npre-trained on a large number of base classes. We hypothesize that a strong\nbase model can provide a good representation for novel classes and incremental\nlearning can be done with small adaptations. We propose a 2-stage training\nscheme, i) feature augmentation -- cloning part of the backbone and fine-tuning\nit on the novel data, and ii) fusion -- combining the base and novel\nclassifiers into a unified classifier. Experiments show that the proposed\nmethod significantly outperforms state-of-the-art CIL methods on the\nlarge-scale ImageNet dataset (e.g. +10% overall accuracy than the best). We\nalso propose and analyze understudied practical CIL scenarios, such as\nbase-novel overlap with distribution shift. Our proposed method is robust and\ngeneralizes to all analyzed CIL settings.",
    "descriptor": "\nComments: Accepted at CVPR 2022, code to be released soon\n",
    "authors": [
      "Tz-Ying Wu",
      "Gurumurthy Swaminathan",
      "Zhizhong Li",
      "Avinash Ravichandran",
      "Nuno Vasconcelos",
      "Rahul Bhotika",
      "Stefano Soatto"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.03634"
  },
  {
    "id": "arXiv:2204.03635",
    "title": "Zero-Shot Category-Level Object Pose Estimation",
    "abstract": "Object pose estimation is an important component of most vision pipelines for\nembodied agents, as well as in 3D vision more generally. In this paper we\ntackle the problem of estimating the pose of novel object categories in a\nzero-shot manner. This extends much of the existing literature by removing the\nneed for pose-labelled datasets or category-specific CAD models for training or\ninference. Specifically, we make the following contributions. First, we\nformalise the zero-shot, category-level pose estimation problem and frame it in\na way that is most applicable to real-world embodied agents. Secondly, we\npropose a novel method based on semantic correspondences from a self-supervised\nvision transformer to solve the pose estimation problem. We further re-purpose\nthe recent CO3D dataset to present a controlled and realistic test setting.\nFinally, we demonstrate that all baselines for our proposed task perform\npoorly, and show that our method provides a six-fold improvement in average\nrotation accuracy at 30 degrees. Our code is available at\nhttps://github.com/applied-ai-lab/zero-shot-pose.",
    "descriptor": "\nComments: 29 pages, 5 figures\n",
    "authors": [
      "Walter Goodwin",
      "Sagar Vaze",
      "Ioannis Havoutis",
      "Ingmar Posner"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2204.03635"
  },
  {
    "id": "arXiv:2204.03636",
    "title": "SurroundDepth: Entangling Surrounding Views for Self-Supervised  Multi-Camera Depth Estimation",
    "abstract": "Depth estimation from images serves as the fundamental step of 3D perception\nfor autonomous driving and is an economical alternative to expensive depth\nsensors like LiDAR. The temporal photometric consistency enables\nself-supervised depth estimation without labels, further facilitating its\napplication. However, most existing methods predict the depth solely based on\neach monocular image and ignore the correlations among multiple surrounding\ncameras, which are typically available for modern self-driving vehicles. In\nthis paper, we propose a SurroundDepth method to incorporate the information\nfrom multiple surrounding views to predict depth maps across cameras.\nSpecifically, we employ a joint network to process all the surrounding views\nand propose a cross-view transformer to effectively fuse the information from\nmultiple views. We apply cross-view self-attention to efficiently enable the\nglobal interactions between multi-camera feature maps. Different from\nself-supervised monocular depth estimation, we are able to predict real-world\nscales given multi-camera extrinsic matrices. To achieve this goal, we adopt\nstructure-from-motion to extract scale-aware pseudo depths to pretrain the\nmodels. Further, instead of predicting the ego-motion of each individual\ncamera, we estimate a universal ego-motion of the vehicle and transfer it to\neach view to achieve multi-view consistency. In experiments, our method\nachieves the state-of-the-art performance on the challenging multi-camera depth\nestimation datasets DDAD and nuScenes.",
    "descriptor": "\nComments: Project page: this https URL Code: this https URL\n",
    "authors": [
      "Yi Wei",
      "Linqing Zhao",
      "Wenzhao Zheng",
      "Zheng Zhu",
      "Yongming Rao",
      "Guan Huang",
      "Jiwen Lu",
      "Jie Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.03636"
  },
  {
    "id": "arXiv:2204.03637",
    "title": "tmVar 3.0: an improved variant concept recognition and normalization  tool",
    "abstract": "Previous studies have shown that automated text-mining tools are becoming\nincreasingly important for successfully unlocking variant information in\nscientific literature at large scale. Despite multiple attempts in the past,\nexisting tools are still of limited recognition scope and precision. We propose\ntmVar 3.0: an improved variant recognition and normalization tool. Compared to\nits predecessors, tmVar 3.0 is able to recognize a wide spectrum of variant\nrelated entities (e.g., allele and copy number variants), and to group\ndifferent variant mentions belonging to the same concept in an article for\nimproved accuracy. Moreover, tmVar3 provides additional variant normalization\noptions such as allele-specific identifiers from the ClinGen Allele Registry.\ntmVar3 exhibits a state-of-the-art performance with over 90% accuracy in\nF-measure in variant recognition and normalization, when evaluated on three\nindependent benchmarking datasets. tmVar3 is freely available for download. We\nhave also processed the entire PubMed and PMC with tmVar3 and released its\nannotations on our FTP. Availability: this ftp URL",
    "descriptor": "",
    "authors": [
      "Chih-Hsuan Wei",
      "Alexis Allot",
      "Kevin Riehle",
      "Aleksandar Milosavljevic",
      "Zhiyong Lu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.03637"
  },
  {
    "id": "arXiv:2204.03638",
    "title": "Long Video Generation with Time-Agnostic VQGAN and Time-Sensitive  Transformer",
    "abstract": "Videos are created to express emotion, exchange information, and share\nexperiences. Video synthesis has intrigued researchers for a long time. Despite\nthe rapid progress driven by advances in visual synthesis, most existing\nstudies focus on improving the frames' quality and the transitions between\nthem, while little progress has been made in generating longer videos. In this\npaper, we present a method that builds on 3D-VQGAN and transformers to generate\nvideos with thousands of frames. Our evaluation shows that our model trained on\n16-frame video clips from standard benchmarks such as UCF-101, Sky Time-lapse,\nand Taichi-HD datasets can generate diverse, coherent, and high-quality long\nvideos. We also showcase conditional extensions of our approach for generating\nmeaningful long videos by incorporating temporal information with text and\naudio. Videos and code can be found at\nhttps://songweige.github.io/projects/tats/index.html.",
    "descriptor": "",
    "authors": [
      "Songwei Ge",
      "Thomas Hayes",
      "Harry Yang",
      "Xi Yin",
      "Guan Pang",
      "David Jacobs",
      "Jia-Bin Huang",
      "Devi Parikh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.03638"
  },
  {
    "id": "arXiv:2204.03640",
    "title": "Equivariance Discovery by Learned Parameter-Sharing",
    "abstract": "Designing equivariance as an inductive bias into deep-nets has been a\nprominent approach to build effective models, e.g., a convolutional neural\nnetwork incorporates translation equivariance. However, incorporating these\ninductive biases requires knowledge about the equivariance properties of the\ndata, which may not be available, e.g., when encountering a new domain. To\naddress this, we study how to discover interpretable equivariances from data.\nSpecifically, we formulate this discovery process as an optimization problem\nover a model's parameter-sharing schemes. We propose to use the partition\ndistance to empirically quantify the accuracy of the recovered equivariance.\nAlso, we theoretically analyze the method for Gaussian data and provide a bound\non the mean squared gap between the studied discovery scheme and the oracle\nscheme. Empirically, we show that the approach recovers known equivariances,\nsuch as permutations and shifts, on sum of numbers and spatially-invariant\ndata.",
    "descriptor": "\nComments: AISTATS 2022\n",
    "authors": [
      "Raymond A. Yeh",
      "Yuan-Ting Hu",
      "Mark Hasegawa-Johnson",
      "Alexander G. Schwing"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.03640"
  },
  {
    "id": "arXiv:2204.03641",
    "title": "Unsupervised Image-to-Image Translation with Generative Prior",
    "abstract": "Unsupervised image-to-image translation aims to learn the translation between\ntwo visual domains without paired data. Despite the recent progress in image\ntranslation models, it remains challenging to build mappings between complex\ndomains with drastic visual discrepancies. In this work, we present a novel\nframework, Generative Prior-guided UNsupervised Image-to-image Translation\n(GP-UNIT), to improve the overall quality and applicability of the translation\nalgorithm. Our key insight is to leverage the generative prior from pre-trained\nclass-conditional GANs (e.g., BigGAN) to learn rich content correspondences\nacross various domains. We propose a novel coarse-to-fine scheme: we first\ndistill the generative prior to capture a robust coarse-level content\nrepresentation that can link objects at an abstract semantic level, based on\nwhich fine-level content features are adaptively learned for more accurate\nmulti-level content correspondences. Extensive experiments demonstrate the\nsuperiority of our versatile framework over state-of-the-art methods in robust,\nhigh-quality and diversified translations, even for challenging and distant\ndomains.",
    "descriptor": "\nComments: CVPR 2022. Code: this https URL Project page: this https URL\n",
    "authors": [
      "Shuai Yang",
      "Liming Jiang",
      "Ziwei Liu",
      "Chen Change Loy"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.03641"
  },
  {
    "id": "arXiv:2204.03642",
    "title": "Pre-train, Self-train, Distill: A simple recipe for Supersizing 3D  Reconstruction",
    "abstract": "Our work learns a unified model for single-view 3D reconstruction of objects\nfrom hundreds of semantic categories. As a scalable alternative to direct 3D\nsupervision, our work relies on segmented image collections for learning 3D of\ngeneric categories. Unlike prior works that use similar supervision but learn\nindependent category-specific models from scratch, our approach of learning a\nunified model simplifies the training process while also allowing the model to\nbenefit from the common structure across categories. Using image collections\nfrom standard recognition datasets, we show that our approach allows learning\n3D inference for over 150 object categories. We evaluate using two datasets and\nqualitatively and quantitatively show that our unified reconstruction approach\nimproves over prior category-specific reconstruction baselines. Our final 3D\nreconstruction model is also capable of zero-shot inference on images from\nunseen object categories and we empirically show that increasing the number of\ntraining categories improves the reconstruction quality.",
    "descriptor": "\nComments: To appear in CVPR 22. Project page: this https URL\n",
    "authors": [
      "Kalyan Vasudev Alwala",
      "Abhinav Gupta",
      "Shubham Tulsiani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.03642"
  },
  {
    "id": "arXiv:2204.03643",
    "title": "Total Variation Optimization Layers for Computer Vision",
    "abstract": "Optimization within a layer of a deep-net has emerged as a new direction for\ndeep-net layer design. However, there are two main challenges when applying\nthese layers to computer vision tasks: (a) which optimization problem within a\nlayer is useful?; (b) how to ensure that computation within a layer remains\nefficient? To study question (a), in this work, we propose total variation (TV)\nminimization as a layer for computer vision. Motivated by the success of total\nvariation in image processing, we hypothesize that TV as a layer provides\nuseful inductive bias for deep-nets too. We study this hypothesis on five\ncomputer vision tasks: image classification, weakly supervised object\nlocalization, edge-preserving smoothing, edge detection, and image denoising,\nimproving over existing baselines. To achieve these results we had to address\nquestion (b): we developed a GPU-based projected-Newton method which is\n$37\\times$ faster than existing solutions.",
    "descriptor": "\nComments: CVPR 2022\n",
    "authors": [
      "Raymond A. Yeh",
      "Yuan-Ting Hu",
      "Zhongzheng Ren",
      "Alexander G. Schwing"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.03643"
  },
  {
    "id": "arXiv:2204.03645",
    "title": "DaViT: Dual Attention Vision Transformers",
    "abstract": "In this work, we introduce Dual Attention Vision Transformers (DaViT), a\nsimple yet effective vision transformer architecture that is able to capture\nglobal context while maintaining computational efficiency. We propose\napproaching the problem from an orthogonal angle: exploiting self-attention\nmechanisms with both \"spatial tokens\" and \"channel tokens\". With spatial\ntokens, the spatial dimension defines the token scope, and the channel\ndimension defines the token feature dimension. With channel tokens, we have the\ninverse: the channel dimension defines the token scope, and the spatial\ndimension defines the token feature dimension. We further group tokens along\nthe sequence direction for both spatial and channel tokens to maintain the\nlinear complexity of the entire model. We show that these two self-attentions\ncomplement each other: (i) since each channel token contains an abstract\nrepresentation of the entire image, the channel attention naturally captures\nglobal interactions and representations by taking all spatial positions into\naccount when computing attention scores between channels; (ii) the spatial\nattention refines the local representations by performing fine-grained\ninteractions across spatial locations, which in turn helps the global\ninformation modeling in channel attention. Extensive experiments show our DaViT\nachieves state-of-the-art performance on four different tasks with efficient\ncomputations. Without extra data, DaViT-Tiny, DaViT-Small, and DaViT-Base\nachieve 82.8%, 84.2%, and 84.6% top-1 accuracy on ImageNet-1K with 28.3M,\n49.7M, and 87.9M parameters, respectively. When we further scale up DaViT with\n1.5B weakly supervised image and text pairs, DaViT-Gaint reaches 90.4% top-1\naccuracy on ImageNet-1K. Code is available at https://github.com/dingmyu/davit.",
    "descriptor": "",
    "authors": [
      "Mingyu Ding",
      "Bin Xiao",
      "Noel Codella",
      "Ping Luo",
      "Jingdong Wang",
      "Lu Yuan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.03645"
  },
  {
    "id": "arXiv:2204.03646",
    "title": "FineDiving: A Fine-grained Dataset for Procedure-aware Action Quality  Assessment",
    "abstract": "Most existing action quality assessment methods rely on the deep features of\nan entire video to predict the score, which is less reliable due to the\nnon-transparent inference process and poor interpretability. We argue that\nunderstanding both high-level semantics and internal temporal structures of\nactions in competitive sports videos is the key to making predictions accurate\nand interpretable. Towards this goal, we construct a new fine-grained dataset,\ncalled FineDiving, developed on diverse diving events with detailed annotations\non action procedures. We also propose a procedure-aware approach for action\nquality assessment, learned by a new Temporal Segmentation Attention module.\nSpecifically, we propose to parse pairwise query and exemplar action instances\ninto consecutive steps with diverse semantic and temporal correspondences. The\nprocedure-aware cross-attention is proposed to learn embeddings between query\nand exemplar steps to discover their semantic, spatial, and temporal\ncorrespondences, and further serve for fine-grained contrastive regression to\nderive a reliable scoring mechanism. Extensive experiments demonstrate that our\napproach achieves substantial improvements over state-of-the-art methods with\nbetter interpretability. The dataset and code are available at\n\\url{https://github.com/xujinglin/FineDiving}.",
    "descriptor": "\nComments: Computer Vision and Pattern Recognition 2022 (Oral presentation)\n",
    "authors": [
      "Jinglin Xu",
      "Yongming Rao",
      "Xumin Yu",
      "Guangyi Chen",
      "Jie Zhou",
      "Jiwen Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.03646"
  },
  {
    "id": "arXiv:2204.03647",
    "title": "Adapting CLIP For Phrase Localization Without Further Training",
    "abstract": "Supervised or weakly supervised methods for phrase localization (textual\ngrounding) either rely on human annotations or some other supervised models,\ne.g., object detectors. Obtaining these annotations is labor-intensive and may\nbe difficult to scale in practice. We propose to leverage recent advances in\ncontrastive language-vision models, CLIP, pre-trained on image and caption\npairs collected from the internet. In its original form, CLIP only outputs an\nimage-level embedding without any spatial resolution. We adapt CLIP to generate\nhigh-resolution spatial feature maps. Importantly, we can extract feature maps\nfrom both ViT and ResNet CLIP model while maintaining the semantic properties\nof an image embedding. This provides a natural framework for phrase\nlocalization. Our method for phrase localization requires no human annotations\nor additional training. Extensive experiments show that our method outperforms\nexisting no-training methods in zero-shot phrase localization, and in some\ncases, it even outperforms supervised methods. Code is available at\nhttps://github.com/pals-ttic/adapting-CLIP .",
    "descriptor": "",
    "authors": [
      "Jiahao Li",
      "Greg Shakhnarovich",
      "Raymond A. Yeh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.03647"
  },
  {
    "id": "arXiv:2204.03648",
    "title": "SunStage: Portrait Reconstruction and Relighting using the Sun as a  Light Stage",
    "abstract": "Outdoor portrait photographs are often marred by the harsh shadows cast under\ndirect sunlight. To resolve this, one can use post-capture lighting\nmanipulation techniques, but these methods either require complex hardware\n(e.g., a light stage) to capture each individual, or rely on image-based priors\nand thus fail to reconstruct many of the subtle facial details that vary from\nperson to person. In this paper, we present SunStage, a system for accurate,\nindividually-tailored, and lightweight reconstruction of facial geometry and\nreflectance that can be used for general portrait relighting with cast shadows.\nOur method only requires the user to capture a selfie video outdoors, rotating\nin place, and uses the varying angles between the sun and the face as\nconstraints in the joint reconstruction of facial geometry, reflectance\nproperties, and lighting parameters. Aside from relighting, we show that our\nreconstruction can be used for applications like reflectance editing and view\nsynthesis. Results and interactive demos are available at\nhttps://grail.cs.washington.edu/projects/sunstage/.",
    "descriptor": "\nComments: Project page: this https URL\n",
    "authors": [
      "Yifan Wang",
      "Aleksander Holynski",
      "Xiuming Zhang",
      "Xuaner Cecilia Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.03648"
  },
  {
    "id": "arXiv:2204.03649",
    "title": "Unsupervised Prompt Learning for Vision-Language Models",
    "abstract": "Contrastive vision-language models like CLIP have shown great progress in\nzero-shot transfer learning. This new paradigm uses large-scale image-text\npairs for training and aligns images and texts in a common embedding space. In\nthe inference stage, the proper text description, known as prompt, needs to be\ncarefully designed for zero-shot transfer. To avoid laborious prompt\nengineering and simultaneously improve transfer performance, recent works such\nas CoOp, CLIP-Adapter and Tip-Adapter propose to adapt vision-language models\nfor downstream image recognition tasks by either optimizing the continuous\nprompt representations or training an additional adapter network on top of the\npre-trained vision-language models on a small set of labeled data. Though\npromising improvements are achieved, using labeled images from target datasets\nmay violate the intention of zero-shot transfer of pre-trained vision-language\nmodels. In this paper, we propose an unsupervised prompt learning (UPL)\nframework, which does not require any annotations of the target dataset, to\nimprove the zero-shot transfer of CLIP-like vision-language models.\nExperimentally, for zero-shot transfer, our UPL outperforms original CLIP with\nprompt engineering and on ImageNet as well as other 10 datasets. An enhanced\nversion of UPL is even on par with the 8-shot CoOp and the 8-shot TIP-Adapter\non most datasets while our method does not need any labeled images for\ntraining. Code and models are available at\nhttps://github.com/tonyhuang2022/UPL.",
    "descriptor": "",
    "authors": [
      "Tony Huang",
      "Jack Chu",
      "Fangyun Wei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.03649"
  },
  {
    "id": "arXiv:2204.02969",
    "title": "Holistic Fault Detection and Diagnosis System in Imbalanced, Scarce,  Multi-Domain (ISMD) Data Setting for Component-Level Prognostics and Health  Management (PHM)",
    "abstract": "In the current Industrial 4.0 revolution, Prognostics and Health Management\n(PHM) is an emerging field of research. The difficulty of obtaining data from\nelectromechanical systems in an industrial setting increases proportionally\nwith the scale and accessibility of the automated industry, resulting in a less\ninterpolated PHM system. To put it another way, the development of an accurate\nPHM system for each industrial system necessitates a unique dataset acquired\nunder specified conditions. In most circumstances, obtaining this one-of-a-kind\ndataset is difficult, and the resulting dataset has a significant imbalance, a\nlack of certain useful information, and multi-domain knowledge. To address\nthis, this paper provides a fault detection and diagnosis system that evaluates\nand pre-processes Imbalanced, Scarce, Multi-Domain (ISMD) data acquired from an\nindustrial robot utilizing Signal Processing (SP) techniques and Deep\nLearning-based (DL) domain knowledge transfer. The domain knowledge transfer is\nused to produce a synthetic dataset with a high interpolation rate that\ncontains all the useful information about each domain. For domain knowledge\ntransfer and data generation, Continuous Wavelet Transform (CWT) with\nGenerative Adversarial Network (GAN) was used, as well as Convolutional Neural\nNetwork (CNN) to test the suggested methodology using transfer learning and\ncategorize several faults. The proposed methodology was tested on a real\nexperimental bench that included an industrial robot created by Hyundai\nRobotics Co. This development resulted in a satisfactory resolution with 99.7%\n(highest) classification accuracy achieved by transfer learning on several CNN\nbenchmark models.",
    "descriptor": "",
    "authors": [
      "Ali Rohan"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Robotics (cs.RO)",
      "Image and Video Processing (eess.IV)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2204.02969"
  },
  {
    "id": "arXiv:2204.02976",
    "title": "Follow My Eye: Using Gaze to Supervise Computer-Aided Diagnosis",
    "abstract": "When deep neural network (DNN) was first introduced to the medical image\nanalysis community, researchers were impressed by its performance. However, it\nis evident now that a large number of manually labeled data is often a must to\ntrain a properly functioning DNN. This demand for supervision data and labels\nis a major bottleneck in current medical image analysis, since collecting a\nlarge number of annotations from experienced experts can be time-consuming and\nexpensive. In this paper, we demonstrate that the eye movement of radiologists\nreading medical images can be a new form of supervision to train the DNN-based\ncomputer-aided diagnosis (CAD) system. Particularly, we record the tracks of\nthe radiologists' gaze when they are reading images. The gaze information is\nprocessed and then used to supervise the DNN's attention via an Attention\nConsistency module. To the best of our knowledge, the above pipeline is among\nthe earliest efforts to leverage expert eye movement for deep-learning-based\nCAD. We have conducted extensive experiments on knee X-ray images for\nosteoarthritis assessment. The results show that our method can achieve\nconsiderable improvement in diagnosis performance, with the help of gaze\nsupervision.",
    "descriptor": "",
    "authors": [
      "Sheng Wang",
      "Xi Ouyang",
      "Tianming Liu",
      "Qian Wang",
      "Dinggang Shen"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.02976"
  },
  {
    "id": "arXiv:2204.02977",
    "title": "Multi-Scale Memory-Based Video Deblurring",
    "abstract": "Video deblurring has achieved remarkable progress thanks to the success of\ndeep neural networks. Most methods solve for the deblurring end-to-end with\nlimited information propagation from the video sequence. However, different\nframe regions exhibit different characteristics and should be provided with\ncorresponding relevant information. To achieve fine-grained deblurring, we\ndesigned a memory branch to memorize the blurry-sharp feature pairs in the\nmemory bank, thus providing useful information for the blurry query input. To\nenrich the memory of our memory bank, we further designed a bidirectional\nrecurrency and multi-scale strategy based on the memory bank. Experimental\nresults demonstrate that our model outperforms other state-of-the-art methods\nwhile keeping the model complexity and inference time low. The code is\navailable at https://github.com/jibo27/MemDeblur.",
    "descriptor": "\nComments: Accepted by CVPR 2022\n",
    "authors": [
      "Bo Ji",
      "Angela Yao"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.02977"
  },
  {
    "id": "arXiv:2204.02978",
    "title": "End-To-End Optimization of Online Neural Network-supported Two-Stage  Dereverberation for Hearing Devices",
    "abstract": "A two-stage online dereverberation algorithm for hearing devices is presented\nin this paper. The approach combines a multi-channel multi-frame linear\nfiltering approach with a single-channel single-frame post-filter. Both\ncomponents rely on power spectral density (PSD) estimates provided by deep\nneural networks (DNNs). This contribution extends our prior work, which shows\nthat directly optimizing for a criterion at the output of the multi-channel\nlinear filtering stage results in a more efficient dereverberation, as compared\nto placing the criterion at the output of the DNN to optimize the PSD\nestimation. In the present work, we show that the dereverberation performance\nof the proposed first stage particularly improves the early-to-mid\nreverberation ratio if trained end-to-end. We thus argue that it can be\ncombined with a post-filtering stage which benefits from the early-to-mid ratio\nimprovement and is consequently able to efficiently suppress the residual late\nreverberation. This proposed two stage procedure is shown to be both very\neffective in terms of dereverberation performance and computational demands.\nFurthermore, the proposed system can be adapted to the needs of different types\nof hearing-device users by controlling the amount of reduction of early\nreflections. The proposed system outperforms the previously proposed end-to-end\nDNN-supported linear filtering algorithm, as well as other traditional\napproaches, based on an evaluation using the noise-free version of the WHAMR!\ndataset.",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible. arXiv admin note: text overlap with arXiv:2204.02694\n",
    "authors": [
      "Jean-Marie Lemercier",
      "Joachim Thiemann",
      "Raphael Koning",
      "Timo Gerkmann"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2204.02978"
  },
  {
    "id": "arXiv:2204.03014",
    "title": "EfficientCellSeg: Efficient Volumetric Cell Segmentation Using Context  Aware Pseudocoloring",
    "abstract": "Volumetric cell segmentation in fluorescence microscopy images is important\nto study a wide variety of cellular processes. Applications range from the\nanalysis of cancer cells to behavioral studies of cells in the embryonic stage.\nLike in other computer vision fields, most recent methods use either large\nconvolutional neural networks (CNNs) or vision transformer models (ViTs). Since\nthe number of available 3D microscopy images is typically limited in\napplications, we take a different approach and introduce a small CNN for\nvolumetric cell segmentation. Compared to previous CNN models for cell\nsegmentation, our model is efficient and has an asymmetric encoder-decoder\nstructure with very few parameters in the decoder. Training efficiency is\nfurther improved via transfer learning. In addition, we introduce Context Aware\nPseudocoloring to exploit spatial context in z-direction of 3D images while\nperforming volumetric cell segmentation slice-wise. We evaluated our method\nusing different 3D datasets from the Cell Segmentation Benchmark of the Cell\nTracking Challenge. Our segmentation method achieves top-ranking results, while\nour CNN model has an up to 25x lower number of parameters than other\ntop-ranking methods. Code and pretrained models are available at:\nhttps://github.com/roydenwa/efficient-cell-seg",
    "descriptor": "\nComments: Accepted at MIDL 2022\n",
    "authors": [
      "Royden Wagner",
      "Karl Rohr"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.03014"
  },
  {
    "id": "arXiv:2204.03055",
    "title": "To Participate Or Not To Participate: An Investigation Of Strategic  Participation In Standards",
    "abstract": "Essential functionality in the ICT (Information and Communication Technology)\nspace draws from standards such as HTTP (IETF RFC 2616, Bluetooth (IEEE 802.15)\nand various telecommunication standards (4G, 5G). They have fuelled rapid\ngrowth of ICT sector in the last decades by ensuring interoperability and\nconsistency in computing environment. Research shows that firms that backed ICT\nstandards and participated in standards development, have emerged as industry\ninnovators. Standards development thus clearly has benefits for participating\ncompanies as well as technology development and innovation in general. However,\nsignificant costs are also associated with development of standards and need to\nbe better understood to support investment in standardization necessary for\ntodays ICT environment. We present a conceptual model that considers the\npotential for market innovation across a standards lifecycle and efficiency\nfrom standardization work, to build a forward-looking decision model that can\nguide an organizations standards development activities. We investigate and\nformalize motivations that drive firms to participate in standardization,\nspecifically, changes in market innovation. Our model can serve as a strategic\ndecision framework to drive assessments of a firms participation in standards\ndevelopment. We test our model with a use case on an established access control\napproach that was standardized more than two decades ago, Role Based Access\nControl (RBAC) using historical data. The investigation of the case study shows\nthat change in market innovation is a significant indicator of success in\nstandards development and are viable criteria to model a firms decision to\nparticipate (or not to participate) in a specific area of standardization.",
    "descriptor": "\nComments: this https URL\n",
    "authors": [
      "Paras Bhatt",
      "Claire Vishik",
      "Govind Hariharan",
      "H. Raghav Rao"
    ],
    "subjectives": [
      "General Economics (econ.GN)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2204.03055"
  },
  {
    "id": "arXiv:2204.03072",
    "title": "Theoretical description of power transfer in a magneto-acoustic  resonator",
    "abstract": "We derive an analytical model for the power flows in a magnetoacoustic\nresonator. The resonator consists of a piezoelectric-magnetostrictive bilayer\nsystem that can function as an electromagnetic transducer. The derived model\ncaptures the dynamic magnetic influence onto the elastodynamics via an\neffective frequency dependent stiffness constant. This allows to calculate both\nthe transducer magnetic and elastic power loss as well as its effciency in\nfunction of the frequency while also considering the resonance conditions. The\nmodel is applied onto an example system consisting of piezoelectric ScAlN and\nmagnetostrictive CoFeB. In addition, the influence of the magnetic material\nparameters onto the power and effciency are determined by comparing CoFeB with\nNickel and Terfenol-D magnetostrictive layers.",
    "descriptor": "\nComments: 31 pages, 10 figures. This project has received funding from the European Union's Horizon 2020 research and innovation program under grant agreement No. 801055 \"Spin Wave Computing for Ultimately-Scaled Hybrid Low-Power Electronics\" - CHIRON\n",
    "authors": [
      "Frederic Vanderveken",
      "Bart Soree",
      "Florin Ciubotaru",
      "Christoph Adelmann"
    ],
    "subjectives": [
      "Applied Physics (physics.app-ph)",
      "Mesoscale and Nanoscale Physics (cond-mat.mes-hall)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2204.03072"
  },
  {
    "id": "arXiv:2204.03094",
    "title": "Super-linear Scaling Behavior for Electric Vehicle Chargers and Road Map  to Addressing the Infrastructure Gap",
    "abstract": "Enabling widespread electric vehicle (EV) adoption requires substantial\nbuild-out of charging infrastructure in the coming decade. We formulate the\ncharging infrastructure needs as a scaling analysis problem and use it to\nestimate the EV infrastructure needs of the US at a county-level resolution.\nSurprisingly, we find that the current EV infrastructure deployment scales\nsuper-linearly with population, deviating from the sub-linear scaling of\ngasoline stations and other infrastructure. We discuss how this demonstrates\nthe infancy of EV station abundance compared to other mature transportation\ninfrastructures. By considering the power delivery of existing gasoline\nstations, and appropriate EV efficiencies, we estimate the EV infrastructure\ngap at the county level, providing a road map for future EV infrastructure\nexpansion. Our reliance on scaling analysis allows us to make a unique forecast\nin this domain.",
    "descriptor": "\nComments: 3 pages, 3 figures, 1 table\n",
    "authors": [
      "Alexius Wadell",
      "Matthew Guttenberg",
      "Christopher P. Kempes",
      "Venkatasubramanian Viswanathan"
    ],
    "subjectives": [
      "Econometrics (econ.EM)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2204.03094"
  },
  {
    "id": "arXiv:2204.03132",
    "title": "First-Order Algorithms for Nonlinear Generalized Nash Equilibrium  Problems",
    "abstract": "We consider the problem of computing an equilibrium in a class of nonlinear\ngeneralized Nash equilibrium problems (NGNEPs) in which the strategy sets for\neach player are defined by equality and inequality constraints that may depend\non the choices of rival players. While the asymptotic global convergence and\nlocal convergence rate of solution procedures have been studied in this\nsetting, the analysis of iteration complexity is still in its infancy. Our\ncontribution is to provide two simple first-order algorithmic frameworks based\non the quadratic penalty method and the augmented Lagrangian method,\nrespectively, with an accelerated mirror-prox algorithm as the inner loop. We\nprovide nonasymptotic theoretical guarantees for these algorithms. More\nspecifically, we establish the global convergence rate of our algorithms for\nsolving (strongly) monotone NGNEPs and we provide iteration complexity bounds\nexpressed in terms of the number of gradient evaluations. Experimental results\ndemonstrate the efficiency of our algorithms.",
    "descriptor": "\nComments: 43 Pages\n",
    "authors": [
      "Michael I. Jordan",
      "Tianyi Lin",
      "Manolis Zampetakis"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.03132"
  },
  {
    "id": "arXiv:2204.03145",
    "title": "DeepTensor: Low-Rank Tensor Decomposition with Deep Network Priors",
    "abstract": "DeepTensor is a computationally efficient framework for low-rank\ndecomposition of matrices and tensors using deep generative networks. We\ndecompose a tensor as the product of low-rank tensor factors (e.g., a matrix as\nthe outer product of two vectors), where each low-rank tensor is generated by a\ndeep network (DN) that is trained in a self-supervised manner to minimize the\nmean-squared approximation error. Our key observation is that the implicit\nregularization inherent in DNs enables them to capture nonlinear signal\nstructures (e.g., manifolds) that are out of the reach of classical linear\nmethods like the singular value decomposition (SVD) and principal component\nanalysis (PCA). Furthermore, in contrast to the SVD and PCA, whose performance\ndeteriorates when the tensor's entries deviate from additive white Gaussian\nnoise, we demonstrate that the performance of DeepTensor is robust to a wide\nrange of distributions. We validate that DeepTensor is a robust and\ncomputationally efficient drop-in replacement for the SVD, PCA, nonnegative\nmatrix factorization (NMF), and similar decompositions by exploring a range of\nreal-world applications, including hyperspectral image denoising, 3D MRI\ntomography, and image classification. In particular, DeepTensor offers a 6dB\nsignal-to-noise ratio improvement over standard denoising methods for signals\ncorrupted by Poisson noise and learns to decompose 3D tensors 60 times faster\nthan a single DN equipped with 3D convolutions.",
    "descriptor": "\nComments: 14 pages\n",
    "authors": [
      "Vishwanath Saragadam",
      "Randall Balestriero",
      "Ashok Veeraraghavan",
      "Richard G. Baraniuk"
    ],
    "subjectives": [
      "Applications (stat.AP)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2204.03145"
  },
  {
    "id": "arXiv:2204.03163",
    "title": "Low-Dose CT Denoising via Sinogram Inner-Structure Transformer",
    "abstract": "Low-Dose Computed Tomography (LDCT) technique, which reduces the radiation\nharm to human bodies, is now attracting increasing interest in the medical\nimaging field. As the image quality is degraded by low dose radiation, LDCT\nexams require specialized reconstruction methods or denoising algorithms.\nHowever, most of the recent effective methods overlook the inner-structure of\nthe original projection data (sinogram) which limits their denoising ability.\nThe inner-structure of the sinogram represents special characteristics of the\ndata in the sinogram domain. By maintaining this structure while denoising, the\nnoise can be obviously restrained. Therefore, we propose an LDCT denoising\nnetwork namely Sinogram Inner-Structure Transformer (SIST) to reduce the noise\nby utilizing the inner-structure in the sinogram domain. Specifically, we study\nthe CT imaging mechanism and statistical characteristics of sinogram to design\nthe sinogram inner-structure loss including the global and local\ninner-structure for restoring high-quality CT images. Besides, we propose a\nsinogram transformer module to better extract sinogram features. The\ntransformer architecture using a self-attention mechanism can exploit\ninterrelations between projections of different view angles, which achieves an\noutstanding performance in sinogram denoising. Furthermore, in order to improve\nthe performance in the image domain, we propose the image reconstruction module\nto complementarily denoise both in the sinogram and image domain.",
    "descriptor": "",
    "authors": [
      "Liutao Yang",
      "Zhongnian",
      "Rongjun",
      "Junyong",
      "Zhao",
      "Haipeng",
      "Daoqiang Zhang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.03163"
  },
  {
    "id": "arXiv:2204.03166",
    "title": "Musical Information Extraction from the Singing Voice",
    "abstract": "Music information retrieval is currently an active research area that\naddresses the extraction of musically important information from audio signals,\nand the applications of such information. The extracted information can be used\nfor search and retrieval of music in recommendation systems, or to aid\nmusicological studies or even in music learning. Sophisticated signal\nprocessing techniques are applied to convert low-level acoustic signal\nproperties to musical attributes which are further embedded in a rule-based or\nstatistical classification framework to link with high-level descriptions such\nas melody, genre, mood and artist type. Vocal music comprises a large and\ninteresting category of music where the lead instrument is the singing voice.\nThe singing voice is more versatile than many musical instruments and therefore\nposes interesting challenges to information retrieval systems. In this paper,\nwe provide a brief overview of research in vocal music processing followed by a\ndescription of related work at IIT Bombay leading to the development of an\ninterface for melody detection of singing voice in polyphony.",
    "descriptor": "",
    "authors": [
      "Preeti Rao"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2204.03166"
  },
  {
    "id": "arXiv:2204.03170",
    "title": "Decay Rate of $\\exp(A^{-1}t)A^{-1}$ on a Hilbert Space and the  Crank-Nicolson Scheme with Smooth Initial Data",
    "abstract": "This paper is concerned with the decay rate of $e^{A^{-1}t}A^{-1}$ for the\ngenerator $A$ of an exponentially stable $C_0$-semigroup $(e^{At})_{t\\geq 0}$\non a Hilbert space. To estimate the decay rate of $e^{A^{-1}t}A^{-1}$, we apply\na bounded functional calculus. Using this estimate and Lyapunov equations, we\nalso study the quantified asymptotic behavior of the Crank-Nicolson scheme with\nsmooth initial data. Analogous results are obtained for polynomially stable\n$C_0$-semigroups whose generator is normal.",
    "descriptor": "\nComments: 22 pages\n",
    "authors": [
      "Masashi Wakaiki"
    ],
    "subjectives": [
      "Functional Analysis (math.FA)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2204.03170"
  },
  {
    "id": "arXiv:2204.03188",
    "title": "Two flags in a semimodular lattice generate an antimatroid",
    "abstract": "A basic property in a modular lattice is that any two flags generate a\ndistributive sublattice. It is shown (Abels 1991, Herscovic 1998) that two\nflags in a semimodular lattice no longer generate such a good sublattice,\nwhereas shortest galleries connecting them form a relatively good\njoin-sublattice. In this note, we sharpen this investigation to establish an\nanalogue of the two-flag generation theorem for a semimodular lattice. We\nconsider the notion of a modular convex subset, which is a subset closed under\nthe join and meet only for modular pairs, and show that the modular convex hull\nof two flags in a semimodular lattice of rank $n$ is isomorphic to a\nunion-closed family on $[n]$. This family uniquely determines an antimatroid,\nwhich coincides with the join-sublattice of shortest galleries of the two\nflags.",
    "descriptor": "",
    "authors": [
      "Koyo Hayashi",
      "Hiroshi Hirai"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2204.03188"
  },
  {
    "id": "arXiv:2204.03193",
    "title": "MultiAuto-DeepONet: A Multi-resolution Autoencoder DeepONet for  Nonlinear Dimension Reduction, Uncertainty Quantification and Operator  Learning of Forward and Inverse Stochastic Problems",
    "abstract": "A new data-driven method for operator learning of stochastic differential\nequations(SDE) is proposed in this paper. The central goal is to solve forward\nand inverse stochastic problems more effectively using limited data. Deep\noperator network(DeepONet) has been proposed recently for operator learning.\nCompared to other neural networks to learn functions, it aims at the problem of\nlearning nonlinear operators. However, it can be challenging by using the\noriginal model to learn nonlinear operators for high-dimensional stochastic\nproblems. We propose a new multi-resolution autoencoder DeepONet model referred\nto as MultiAuto-DeepONet to deal with this difficulty with the aid of\nconvolutional autoencoder. The encoder part of the network is designed to\nreduce the dimensionality as well as discover the hidden features of\nhigh-dimensional stochastic inputs. The decoder is designed to have a special\nstructure, i.e. in the form of DeepONet. The first DeepONet in decoder is\ndesigned to reconstruct the input function involving randomness while the\nsecond one is used to approximate the solution of desired equations. Those two\nDeepONets has a common branch net and two independent trunk nets. This\narchitecture enables us to deal with multi-resolution inputs naturally. By\nadding $L_1$ regularization to our network, we found the outputs from the\nbranch net and two trunk nets all have sparse structures. This reduces the\nnumber of trainable parameters in the neural network thus making the model more\nefficient. Finally, we conduct several numerical experiments to illustrate the\neffectiveness of our proposed MultiAuto-DeepONet model with uncertainty\nquantification.",
    "descriptor": "",
    "authors": [
      "Jiahao Zhang",
      "Shiqi Zhang",
      "Guang Lin"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.03193"
  },
  {
    "id": "arXiv:2204.03197",
    "title": "MDA GAN: Adversarial-Learning-based 3-D Seismic Data Interpolation and  Reconstruction for Complex Missing",
    "abstract": "The interpolation and reconstruction of missing traces is a crucial step in\nseismic data processing, moreover it is also a highly ill-posed problem,\nespecially for complex cases such as high-ratio random discrete missing,\ncontinuous missing and missing in rich fault or salt body surveys. These\ncomplex cases are rarely mentioned in current sparse or low-rank priorbased and\ndeep learning-based approaches. To cope with complex missing cases, we propose\nMulti-Dimensional Adversarial GAN (MDA GAN), a novel 3-D GAN framework. It\nemploys three discriminators to ensure the consistency of the reconstructed\ndata with the original data distribution in each dimension. The feature\nsplicing module (FSM) is designed and embedded into the generator of this\nframework, which automatically splices the features of the unmissing part with\nthose of the reconstructed part (missing part), thus fully preserving the\ninformation of the unmissing part. To prevent pixel distortion in the seismic\ndata caused by the adversarial learning process, we propose a new\nreconstruction loss Tanh Cross Entropy (TCE) loss to provide smoother\ngradients. We experimentally verified the effectiveness of the individual\ncomponents of the study and then tested the method on multiple publicly\navailable data. The method achieves reasonable reconstructions for up to 95% of\nrandom discrete missing, 100 traces of continuous missing and more complex\nhybrid missing. In surveys of fault-rich and salt bodies, the method can\nachieve promising reconstructions with up to 75% missing in each of the three\ndirections (98.2% in total).",
    "descriptor": "\nComments: This work has been submitted to journal for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Yimin Dou",
      "Kewen Li",
      "Jianbing Zhu",
      "Timing Li",
      "Shaoquan Tan",
      "Zongchao Huang"
    ],
    "subjectives": [
      "Geophysics (physics.geo-ph)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.03197"
  },
  {
    "id": "arXiv:2204.03204",
    "title": "Convolutional Neural Network for Early Pulmonary Embolism Detection via  Computed Tomography Pulmonary Angiography",
    "abstract": "This study was conducted to develop a computer-aided detection (CAD) system\nfor triaging patients with pulmonary embolism (PE). The purpose of the system\nwas to reduce the death rate during the waiting period. Computed tomography\npulmonary angiography (CTPA) is used for PE diagnosis. Because CTPA reports\nrequire a radiologist to review the case and suggest further management, this\ncreates a waiting period during which patients may die. Our proposed CAD method\nwas thus designed to triage patients with PE from those without PE. In contrast\nto related studies involving CAD systems that identify key PE lesion images to\nexpedite PE diagnosis, our system comprises a novel classification-model\nensemble for PE detection and a segmentation model for PE lesion labeling. The\nmodels were trained using data from National Cheng Kung University Hospital and\nopen resources. The classification model yielded 0.73 for receiver operating\ncharacteristic curve (accuracy = 0.85), while the mean intersection over union\nwas 0.689 for the segmentation model. The proposed CAD system can distinguish\nbetween patients with and without PE and automatically label PE lesions to\nexpedite PE diagnosis",
    "descriptor": "",
    "authors": [
      "Ching-Yuan Yu",
      "Ming-Che Chang",
      "Yun-Chien Cheng",
      "Chin Kuo"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.03204"
  },
  {
    "id": "arXiv:2204.03213",
    "title": "MC-UNet Multi-module Concatenation based on U-shape Network for Retinal  Blood Vessels Segmentation",
    "abstract": "Accurate segmentation of the blood vessels of the retina is an important step\nin clinical diagnosis of ophthalmic diseases. Many deep learning frameworks\nhave come up for retinal blood vessels segmentation tasks. However, the complex\nvascular structure and uncertain pathological features make the blood vessel\nsegmentation still very challenging. A novel U-shaped network named\nMulti-module Concatenation which is based on Atrous convolution and\nmulti-kernel pooling is put forward to retinal vessels segmentation in this\npaper. The proposed network structure retains three layers the essential\nstructure of U-Net, in which the atrous convolution combining the multi-kernel\npooling blocks are designed to obtain more contextual information. The spatial\nattention module is concatenated with dense atrous convolution module and\nmulti-kernel pooling module to form a multi-module concatenation. And different\ndilation rates are selected by cascading to acquire a larger receptive field in\natrous convolution. Adequate comparative experiments are conducted on these\npublic retinal datasets: DRIVE, STARE and CHASE_DB1. The results show that the\nproposed method is effective, especially for microvessels. The code will be put\nout at https://github.com/Rebeccala/MC-UNet",
    "descriptor": "\nComments: 13pages,3957\n",
    "authors": [
      "Ting Zhang",
      "Jun Li",
      "Yi Zhao",
      "Nan Chen",
      "Han Zhou",
      "Hongtao Xu",
      "Zihao Guan",
      "Changcai Yang",
      "Lanyan Xue",
      "Riqing Chen",
      "Lifang Wei"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.03213"
  },
  {
    "id": "arXiv:2204.03219",
    "title": "DDOS: A MOS Prediction Framework utilizing Domain Adaptive Pre-training  and Distribution of Opinion Scores",
    "abstract": "Mean opinion score (MOS) is a typical subjective evaluation metric for speech\nsynthesis systems. Since collecting MOS is time-consuming, it would be\ndesirable if there are accurate MOS prediction models for automatic evaluation.\nIn this work, we propose DDOS, a novel MOS prediction model. DDOS utilizes\ndomain adaptive pre-training to further pre-train self-supervised learning\nmodels on synthetic speech. And a proposed module is added to model the opinion\nscore distribution of each utterance. With the proposed components, DDOS\noutperforms previous works on BVCC dataset. And the zero shot transfer result\non BC2019 dataset is significantly improved. DDOS also wins second place in\nInterspeech 2022 VoiceMOS challenge in terms of system-level score.",
    "descriptor": "\nComments: Submitted to Interspeech 2022. Code will be available in the future\n",
    "authors": [
      "Wei-Cheng Tseng",
      "Wei-Tsung Kao",
      "Hung-yi Lee"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2204.03219"
  },
  {
    "id": "arXiv:2204.03232",
    "title": "Leveraging Real Conversational Data for Multi-Channel Continuous Speech  Separation",
    "abstract": "Existing multi-channel continuous speech separation (CSS) models are heavily\ndependent on supervised data - either simulated data which causes data mismatch\nbetween the training and real-data testing, or the real transcribed overlapping\ndata, which is difficult to be acquired, hindering further improvements in the\nconversational/meeting transcription tasks. In this paper, we propose a\nthree-stage training scheme for the CSS model that can leverage both supervised\ndata and extra large-scale unsupervised real-world conversational data. The\nscheme consists of two conventional training approaches -- pre-training using\nsimulated data and ASR-loss-based training using transcribed data -- and a\nnovel continuous semi-supervised training between the two, in which the CSS\nmodel is further trained by using real data based on the teacher-student\nlearning framework. We apply this scheme to an array-geometry-agnostic CSS\nmodel, which can use the multi-channel data collected from any microphone\narray. Large-scale meeting transcription experiments are carried out on both\nMicrosoft internal meeting data and the AMI meeting corpus. The steady\nimprovement by each training stage has been observed, showing the effect of the\nproposed method that enables leveraging real conversational data for CSS model\ntraining.",
    "descriptor": "\nComments: Submitted to INTERSPEECH 2022\n",
    "authors": [
      "Xiaofei Wang",
      "Dongmei Wang",
      "Naoyuki Kanda",
      "Sefik Emre Eskimez",
      "Takuya Yoshioka"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2204.03232"
  },
  {
    "id": "arXiv:2204.03238",
    "title": "Unsupervised Quantized Prosody Representation for Controllable Speech  Synthesis",
    "abstract": "In this paper, we propose a novel prosody disentangle method for prosodic\nText-to-Speech (TTS) model, which introduces the vector quantization (VQ)\nmethod to the auxiliary prosody encoder to obtain the decomposed prosody\nrepresentations in an unsupervised manner. Rely on its advantages, the speaking\nstyles, such as pitch, speaking velocity, local pitch variance, etc., are\ndecomposed automatically into the latent quantize vectors. We also investigate\nthe internal mechanism of VQ disentangle process by means of a latent variables\ncounter and find that higher value dimensions usually represent prosody\ninformation. Experiments show that our model can control the speaking styles of\nsynthesis results by directly manipulating the latent variables. The objective\nand subjective evaluations illustrated that our model outperforms the popular\nmodels.",
    "descriptor": "\nComments: accepted by IEEE International Conference on Multimedia and Expo 2022 (ICME2022)\n",
    "authors": [
      "Yutian Wang",
      "Yuankun Xie",
      "Kun Zhao",
      "Hui Wang",
      "Qin Zhang"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2204.03238"
  },
  {
    "id": "arXiv:2204.03248",
    "title": "Composite Spatial Monte Carlo Integration Based on Generalized Least  Squares",
    "abstract": "Although evaluation of the expectations on the Ising model is essential in\nvarious applications, this is frequently infeasible because of intractable\nmultiple summations (or integrations). Spatial Monte Carlo integration (SMCI)\nis a sampling-based approximation, and can provide high-accuracy estimations\nfor such intractable expectations. To evaluate the expectation of a function of\nvariables in a specific region (called target region), SMCI considers a larger\nregion containing the target region (called sum region). In SMCI, the multiple\nsummation for the variables in the sum region is precisely executed, and that\nin the outer region is evaluated by the sampling approximation such as the\nstandard Monte Carlo integration. It is guaranteed that the accuracy of the\nSMCI estimator is monotonically improved as the size of the sum region\nincreases. However, a haphazard expansion of the sum region could cause a\ncombinatorial explosion. Therefore, we hope to improve the accuracy without\nsuch region expansion. In this study, based on the theory of generalized least\nsquares, a new effective method is proposed by combining multiple SMCI\nestimators. The validity of the proposed method is demonstrated theoretically\nand numerically. The results indicate that the proposed method can be effective\nin the inverse Ising problem (or Boltzmann machine learning).",
    "descriptor": "",
    "authors": [
      "Kaiji Sekimoto",
      "Muneki Yasuda"
    ],
    "subjectives": [
      "Computation (stat.CO)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Machine Learning (cs.LG)",
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2204.03248"
  },
  {
    "id": "arXiv:2204.03294",
    "title": "Heterogeneous Ultra-Dense Networks with Traffic Hotspots: A Unified  Handover Analysis",
    "abstract": "With the ever-growing communication demands and the unceasing miniaturization\nof mobile devices, the Internet of Things is expanding the amount of mobile\nterminals to an enormous level. To deal with such numbers of communication\ndata, plenty of base stations (BSs) need to be deployed. However, denser\ndeployments of heterogeneous networks (HetNets) lead to more frequent\nhandovers, which could increase network burden and degrade the users\nexperience, especially in traffic hotspot areas. In this paper, we develop a\nunified framework to investigate the handover performance of wireless networks\nwith traffic hotspots. Using the stochastic geometry, we derive the theoretical\nexpressions of average distances and handover metrics in HetNets, where the\ncorrelations between users and BSs in hotspots are captured. Specifically, the\ndistributions of macro cells are modeled as independent Poisson point processes\n(PPPs), and the two tiers of small cells outside and inside the hotspots are\nmodeled as PPP and Poisson cluster process (PCP) separately. A modified random\nwaypoint (MRWP) model is also proposed to eliminate the density wave phenomenon\nin traditional models and to increase the accuracy of handover decision. By\ncombining the PCP and MRWP model, the distributions of distances from a typical\nterminal to the BSs in different tiers are derived. Afterwards, we derive the\nexpressions of average distances from a typical terminal to different BSs, and\nreveal that the handover rate, handover failure rate, and ping-pong rate are\ndeduced as the functions of BS density, scattering variance of clustered small\ncell, user velocity, and threshold of triggered time. Simulation results verify\nthe accuracy of the proposed analytical model and closed-form theoretical\nexpressions.",
    "descriptor": "",
    "authors": [
      "He Zhou",
      "Haibo Zhou",
      "Jianguo Li",
      "Kai Yang",
      "Jianping An",
      "Xuemin",
      "Shen"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2204.03294"
  },
  {
    "id": "arXiv:2204.03302",
    "title": "Fast inverse elastic scattering of multiple particles in three  dimensions",
    "abstract": "Many applications require recovering the geometry information of multiple\nelastic particles based on the scattering information. In this paper, we\nconsider the inverse time-harmonic elastic scattering of multiple rigid\nparticles in three dimensions. We measure the far field information and apply\nthe time reversal method to recover the unknown elastic particles. Two regimes\nare considered depending on the size and distance among particles. First, an\nasymptotic analysis for the imaging of small and distant particles is given\nbased on the scattering property of a single particle, which can be used for\nselective focusing. Second, when particles are not small but well-separated, a\nfast algorithm, based on the combination of multiple scattering theory and fast\nmultipole method, is proposed to efficiently simulate the forward multiple\nscattering problem and applied in the inverse elastic scattering. Numerical\nexperiments demonstrate the proposed method can determine the locations and\nshapes of multiple particles instantly.",
    "descriptor": "",
    "authors": [
      "Jun Lai",
      "Jinrui Zhang"
    ],
    "subjectives": [
      "Mathematical Physics (math-ph)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2204.03302"
  },
  {
    "id": "arXiv:2204.03305",
    "title": "MBI-Net: A Non-Intrusive Multi-Branched Speech Intelligibility  Prediction Model for Hearing Aids",
    "abstract": "Improving the user's hearing ability to understand speech in noisy\nenvironments is critical to the development of hearing aid (HA) devices. For\nthis, it is important to derive a metric that can fairly predict speech\nintelligibility for HA users. A straightforward approach is to conduct a\nsubjective listening test and use the test results as an evaluation metric.\nHowever, conducting large-scale listening tests is time-consuming and\nexpensive. Therefore, several evaluation metrics were derived as surrogates for\nsubjective listening test results. In this study, we propose a multi-branched\nspeech intelligibility prediction model (MBI-Net), for predicting the\nsubjective intelligibility scores of HA users. MBI-Net consists of two branches\nof models, with each branch consisting of a hearing loss model, a cross-domain\nfeature extraction module, and a speech intelligibility prediction model, to\nprocess speech signals from one channel. The outputs of the two branches are\nfused through a linear layer to obtain predicted speech intelligibility scores.\nExperimental results confirm the effectiveness of MBI-Net, which produces\nhigher prediction scores than the baseline system in Track 1 and Track 2 on the\nClarity Prediction Challenge 2022 dataset.",
    "descriptor": "\nComments: Submitted to Interspeech 2022\n",
    "authors": [
      "Ryandhimas E. Zezario",
      "Fei Chen",
      "Chiou-Shann Fuh",
      "Hsin-Min Wang",
      "Yu Tsao"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2204.03305"
  },
  {
    "id": "arXiv:2204.03310",
    "title": "MTI-Net: A Multi-Target Speech Intelligibility Prediction Model",
    "abstract": "Recently, deep learning (DL)-based non-intrusive speech assessment models\nhave attracted great attention. Many studies report that these DL-based models\nyield satisfactory assessment performance and good flexibility, but their\nperformance in unseen environments remains a challenge. Furthermore, compared\nto quality scores, fewer studies elaborate deep learning models to estimate\nintelligibility scores. This study proposes a multi-task speech intelligibility\nprediction model, called MTI-Net, for simultaneously predicting human and\nmachine intelligibility measures. Specifically, given a speech utterance,\nMTI-Net is designed to predict subjective listening test results and word error\nrate (WER) scores. We also investigate several methods that can improve the\nprediction performance of MTI-Net. First, we compare different features\n(including low-level features and embeddings from self-supervised learning\n(SSL) models) and prediction targets of MTI-Net. Second, we explore the effect\nof transfer learning and multi-tasking learning on training MTI-Net. Finally,\nwe examine the potential advantages of fine-tuning SSL embeddings. Experimental\nresults demonstrate the effectiveness of using cross-domain features,\nmulti-task learning, and fine-tuning SSL embeddings. Furthermore, it is\nconfirmed that the intelligibility and WER scores predicted by MTI-Net are\nhighly correlated with the ground-truth scores.",
    "descriptor": "\nComments: Submitted to Interspeech 2022\n",
    "authors": [
      "Ryandhimas E. Zezario",
      "Szu-wei Fu",
      "Fei Chen",
      "Chiou-Shann Fuh",
      "Hsin-Min Wang",
      "Yu Tsao"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2204.03310"
  },
  {
    "id": "arXiv:2204.03343",
    "title": "Binary Spatial Random Field Reconstruction from Non-Gaussian  Inhomogeneous Time-series Observations",
    "abstract": "We develop a new model for binary spatial random field reconstruction of a\nphysical phenomenon which is partially observed via inhomogeneous time-series\ndata. We consider a sensor network deployed over a vast geographical region\nwhere sensors observe temporal processes and transmit compressed observations\nto the Fusion Center (FC). Two types of sensors are considered; one collects\npoint observations at specific time points while the other collects integral\nobservations over time intervals. Subsequently, the FC uses the compressed\nobservations to infer the spatial phenomenon modeled as a binary spatial random\nfield. We show that the resulting posterior predictive distribution is\nintractable and develop a tractable two-step procedure to perform inference.\nFirst, we develop procedures to approximately perform Likelihood Ratio Tests on\nthe time-series data, for both point sensors and integral sensors, in order to\ncompress the temporal observations to a single bit. Second, after the\ncompressed observations are transmitted to the FC, we develop a Spatial Best\nLinear Unbiased Estimator (S-BLUE) in order for the FC to reconstruct the\nbinary spatial random field at an arbitrary spatial location. Finally, we\npresent a comprehensive study of the performance of the proposed approaches\nusing both synthetic and real-world experiments. A weather dataset from the\nNational Environment Agency (NEA) of Singapore with fields including\ntemperature and relative humidity is used in the real-world experiments to\nvalidate the proposed approaches.",
    "descriptor": "",
    "authors": [
      "Shunan Sheng",
      "Qikun Xiang",
      "Ido Nevat",
      "Ariel Neufeld"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2204.03343"
  },
  {
    "id": "arXiv:2204.03354",
    "title": "Predictive Coding and Stochastic Resonance: Towards a Unified Theory of  Auditory (Phantom) Perception",
    "abstract": "Cognitive computational neuroscience (CCN) suggests that to gain a\nmechanistic understanding of brain function, hypothesis driven experiments\nshould be accompanied by biologically plausible computational models. This\nnovel research paradigm offers a way from alchemy to chemistry, in auditory\nneuroscience. With a special focus on tinnitus - as the prime example of\nauditory phantom perception - we review recent work at the intersection of\nartificial intelligence, psychology, and neuroscience, foregrounding the idea\nthat experiments will yield mechanistic insight only when employed to test\nformal or computational models. This view challenges the popular notion that\ntinnitus research is primarily data limited, and that producing large,\nmulti-modal, and complex data-sets, analyzed with advanced data analysis\nalgorithms, will lead to fundamental insights into how tinnitus emerges. We\nconclude that two fundamental processing principles - being ubiquitous in the\nbrain - best fit to a vast number of experimental results and therefore provide\nthe most explanatory power: predictive coding as a top-down, and stochastic\nresonance as a complementary bottom-up mechanism. Furthermore, we argue that\neven though contemporary artificial intelligence and machine learning\napproaches largely lack biological plausibility, the models to be constructed\nwill have to draw on concepts from these fields; since they provide a formal\naccount of the requisite computations that underlie brain function.\nNevertheless, biological fidelity will have to be addressed, allowing for\ntesting possible treatment strategies in silico, before application in animal\nor patient studies. This iteration of computational and empirical studies may\nhelp to open the \"black boxes\" of both machine learning and the human brain.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2010.01914\n",
    "authors": [
      "Achim Schilling",
      "William Sedley",
      "Richard Gerum",
      "Claus Metzner",
      "Konstantin Tziridis",
      "Andreas Maier",
      "Holger Schulze",
      "Fan-Gang Zeng",
      "Karl J. Friston",
      "Patrick Krauss"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.03354"
  },
  {
    "id": "arXiv:2204.03379",
    "title": "Correcting Misproducted Speech using Spectrogram Inpainting",
    "abstract": "Learning a new language involves constantly comparing speech productions with\nreference productions from the environment. Early in speech acquisition,\nchildren make articulatory adjustments to match their caregivers' speech.\nGrownup learners of a language tweak their speech to match the tutor reference.\nThis paper proposes a method to synthetically generate correct pronunciation\nfeedback given incorrect production. Furthermore, our aim is to generate the\ncorrected production while maintaining the speaker's original voice.\nThe system prompts the user to pronounce a phrase. The speech is recorded,\nand the samples associated with the inaccurate phoneme are masked with zeros.\nThis waveform serves as an input to a speech generator, implemented as a deep\nlearning inpainting system with a U-net architecture, and trained to output a\nreconstructed speech. The training set is composed of unimpaired proper speech\nexamples, and the generator is trained to reconstruct the original proper\nspeech. We evaluated the performance of our system on phoneme replacement of\nminimal pair words of English as well as on children with pronunciation\ndisorders. Results suggest that human listeners slightly prefer our generated\nspeech over a smoothed replacement of the inaccurate phoneme with a production\nof a different speaker.",
    "descriptor": "\nComments: under submission to Interspeech 2022\n",
    "authors": [
      "Talia Ben-Simon",
      "Felix Kreuk",
      "Faten Awwad",
      "Jacob T. Cohen",
      "Joseph Keshet"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.03379"
  },
  {
    "id": "arXiv:2204.03408",
    "title": "Surface Vision Transformers: Flexible Attention-Based Modelling of  Biomedical Surfaces",
    "abstract": "Recent state-of-the-art performances of Vision Transformers (ViT) in computer\nvision tasks demonstrate that a general-purpose architecture, which implements\nlong-range self-attention, could replace the local feature learning operations\nof convolutional neural networks. In this paper, we extend ViTs to surfaces by\nreformulating the task of surface learning as a sequence-to-sequence learning\nproblem, by proposing patching mechanisms for general surface meshes. Sequences\nof patches are then processed by a transformer encoder and used for\nclassification or regression. We validate our method on a range of different\nbiomedical surface domains and tasks: brain age prediction in the developing\nHuman Connectome Project (dHCP), fluid intelligence prediction in the Human\nConnectome Project (HCP), and coronary artery calcium score classification\nusing surfaces from the Scottish Computed Tomography of the Heart (SCOT-HEART)\ndataset, and investigate the impact of pretraining and data augmentation on\nmodel performance. Results suggest that Surface Vision Transformers (SiT)\ndemonstrate consistent improvement over geometric deep learning methods for\nbrain age and fluid intelligence prediction and achieve comparable performance\non calcium score classification to standard metrics used in clinical practice.\nFurthermore, analysis of transformer attention maps offers clear and\nindividualised predictions of the features driving each task. Code is available\non Github: https://github.com/metrics-lab/surface-vision-transformers",
    "descriptor": "\nComments: 10 pages, 3 figures, Submitted to IEEE Transactions on Medical Imaging\n",
    "authors": [
      "Simon Dahan",
      "Hao Xu",
      "Logan Z. J. Williams",
      "Abdulah Fawaz",
      "Chunhui Yang",
      "Timothy S. Coalson",
      "Michelle C. Williams",
      "David E. Newby",
      "A. David Edwards",
      "Matthew F. Glasser",
      "Alistair A. Young",
      "Daniel Rueckert",
      "Emma C. Robinson"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2204.03408"
  },
  {
    "id": "arXiv:2204.03417",
    "title": "Detecting Dysfluencies in Stuttering Therapy Using wav2vec 2.0",
    "abstract": "Stuttering is a varied speech disorder that harms an individual's\ncommunication ability. Persons who stutter (PWS) often use speech therapy to\ncope with their condition. Improving speech recognition systems for people with\nsuch non-typical speech or tracking the effectiveness of speech therapy would\nrequire systems that can detect dysfluencies while at the same time being able\nto detect speech techniques acquired in therapy.\nThis paper shows that fine-tuning wav2vec 2.0 for the classification of\nstuttering on a sizeable English corpus containing stuttered speech, in\nconjunction with multi-task learning, boosts the effectiveness of the\ngeneral-purpose wav2vec 2.0 features for detecting stuttering in speech; both\nwithin and across languages. We evaluate our method on Fluencybank and the\nGerman therapy-centric Kassel State of Fluency (KSoF) dataset by training\nSupport Vector Machine classifiers using features extracted from the fine-tuned\nmodels for six different stuttering-related events types: blocks,\nprolongations, sound repetitions, word repetitions, interjections, and -\nspecific to therapy - speech modifications. Using embeddings from the\nfine-tuned models leads to relative classification performance gains up to 27\\%\nw.r.t. F1-score.",
    "descriptor": "\nComments: Submitted to Interspeech 2022\n",
    "authors": [
      "Sebastian P. Bayerl",
      "Dominik Wagner",
      "Elmar N\u00f6th",
      "Korbinian Riedhammer"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.03417"
  },
  {
    "id": "arXiv:2204.03428",
    "title": "Detecting Vocal Fatigue with Neural Embeddings",
    "abstract": "Vocal fatigue refers to the feeling of tiredness and weakness of voice due to\nextended utilization. This paper investigates the effectiveness of neural\nembeddings for the detection of vocal fatigue. We compare x-vectors,\nECAPA-TDNN, and wav2vec 2.0 embeddings on a corpus of academic spoken English.\nLow-dimensional mappings of the data reveal that neural embeddings capture\ninformation about the change in vocal characteristics of a speaker during\nprolonged voice usage. We show that vocal fatigue can be reliably predicted\nusing all three kinds of neural embeddings after only 50 minutes of continuous\nspeaking when temporal smoothing and normalization are applied to the extracted\nembeddings. We employ support vector machines for classification and achieve\naccuracy scores of 81% using x-vectors, 85% using ECAPA-TDNN embeddings, and\n82% using wav2vec 2.0 embeddings as input features. We obtain an accuracy score\nof 76%, when the trained system is applied to a different speaker and recording\nenvironment without any adaptation.",
    "descriptor": "\nComments: Submitted to Interspeech 2022\n",
    "authors": [
      "Sebastian P. Bayerl",
      "Dominik Wagner",
      "Ilja Baumann",
      "Korbinian Riedhammer",
      "Tobias Bocklet"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.03428"
  },
  {
    "id": "arXiv:2204.03439",
    "title": "Half-sibling regression meets exoplanet imaging: PSF modeling and  subtraction using a flexible, domain knowledge-driven, causal framework",
    "abstract": "High-contrast imaging of exoplanets hinges on powerful post-processing\nmethods to denoise the data and separate the signal of a companion from its\nhost star, which is typically orders of magnitude brighter. Existing\npost-processing algorithms do not use all prior domain knowledge that is\navailable about the problem. We propose a new method that builds on our\nunderstanding of the systematic noise and the causal structure of the\ndata-generating process. Our algorithm is based on a modified version of\nhalf-sibling regression (HSR), a flexible denoising framework that combines\nideas from the fields of machine learning and causality. We adapt the method to\naddress the specific requirements of high-contrast exoplanet imaging data\nobtained in pupil tracking mode. The key idea is to estimate the systematic\nnoise in a pixel by regressing the time series of this pixel onto a set of\ncausally independent, signal-free predictor pixels. We use regularized linear\nmodels in this work; however, other (non-linear) models are also possible. In a\nsecond step, we demonstrate how the HSR framework allows us to incorporate\nobserving conditions such as wind speed or air temperature as additional\npredictors. When we apply our method to four data sets from the VLT/NACO\ninstrument, our algorithm provides a better false-positive fraction than\nPCA-based PSF subtraction, a popular baseline method in the field.\nAdditionally, we find that the HSR-based method provides direct and accurate\nestimates for the contrast of the exoplanets without the need to insert\nartificial companions for calibration in the data sets. Finally, we present\nfirst evidence that using the observing conditions as additional predictors can\nimprove the results. Our HSR-based method provides an alternative, flexible and\npromising approach to the challenge of modeling and subtracting the stellar PSF\nand systematic noise in exoplanet imaging data.",
    "descriptor": "\nComments: Accepted for publication in Astronomy & Astrophysics\n",
    "authors": [
      "Timothy D. Gebhard",
      "Markus J. Bonse",
      "Sascha P. Quanz",
      "Bernhard Sch\u00f6lkopf"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Earth and Planetary Astrophysics (astro-ph.EP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.03439"
  },
  {
    "id": "arXiv:2204.03485",
    "title": "Nonlinear Kalman Filter Using Cramer Rao Bound",
    "abstract": "This paper studies the optimal state estimation for a dynamic system, whose\ntransfer function can be nonlinear and the input noise can be of arbitrary\ndistribution. Our algorithm differs from the conventional extended Kalman\nfilter (EKF) and the particle filter (PF) in that it estimates not only the\nstate vector but also the Cramer-Rao bound (CRB), which serves as an accuracy\nindicator. Combining the state estimation, the CRB, and the incoming new\nmeasurement, the algorithm updates the state estimation according to the\nmaximum likelihood (ML) criterion. To illustrate the effectiveness of the\nproposed method for autonomous driving, we apply it to estimate the position\nand velocity of a vehicle based on the noisy measurements of distance and\nDoppler offset. Simulation results show that the proposed algorithm can achieve\nestimation significantly more accurate than the standard EKF and the PF.",
    "descriptor": "\nComments: 7 pages, 2 figures\n",
    "authors": [
      "Xin Liang",
      "Yi Jiang"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2204.03485"
  },
  {
    "id": "arXiv:2204.03495",
    "title": "Covariance matrix preparation for quantum principal component analysis",
    "abstract": "Principal component analysis (PCA) is a dimensionality reduction method in\ndata analysis that involves diagonalizing the covariance matrix of the dataset.\nRecently, quantum algorithms have been formulated for PCA based on\ndiagonalizing a density matrix. These algorithms assume that the covariance\nmatrix can be encoded in a density matrix, but a concrete protocol for this\nencoding has been lacking. Our work aims to address this gap. Assuming\namplitude encoding of the data, with the data given by the ensemble $\\{p_i,|\n\\psi_i \\rangle\\}$, then one can easily prepare the ensemble average density\nmatrix $\\overline{\\rho} = \\sum_i p_i |\\psi_i\\rangle \\langle \\psi_i |$. We first\nshow that $\\overline{\\rho}$ is precisely the covariance matrix whenever the\ndataset is centered. For quantum datasets, we exploit global phase symmetry to\nargue that there always exists a centered dataset consistent with\n$\\overline{\\rho}$, and hence $\\overline{\\rho}$ can always be interpreted as a\ncovariance matrix. This provides a simple means for preparing the covariance\nmatrix for arbitrary quantum datasets or centered classical datasets. For\nuncentered classical datasets, our method is so-called \"PCA without centering\",\nwhich we interpret as PCA on a symmetrized dataset. We argue that this closely\ncorresponds to standard PCA, and we derive equations and inequalities that\nbound the deviation of the spectrum obtained with our method from that of\nstandard PCA. We numerically illustrate our method for the MNIST handwritten\ndigit dataset. We also argue that PCA on quantum datasets is natural and\nmeaningful, and we numerically implement our method for molecular ground-state\ndatasets.",
    "descriptor": "\nComments: 13 + 3 pages, 8 figures\n",
    "authors": [
      "Max Hunter Gordon",
      "M. Cerezo",
      "Lukasz Cincio",
      "Patrick J. Coles"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2204.03495"
  },
  {
    "id": "arXiv:2204.03547",
    "title": "Evaluating Procedures for Establishing Generative Adversarial  Network-based Stochastic Image Models in Medical Imaging",
    "abstract": "Modern generative models, such as generative adversarial networks (GANs),\nhold tremendous promise for several areas of medical imaging, such as\nunconditional medical image synthesis, image restoration, reconstruction and\ntranslation, and optimization of imaging systems. However, procedures for\nestablishing stochastic image models (SIMs) using GANs remain generic and do\nnot address specific issues relevant to medical imaging. In this work,\ncanonical SIMs that simulate realistic vessels in angiography images are\nemployed to evaluate procedures for establishing SIMs using GANs. The GAN-based\nSIM is compared to the canonical SIM based on its ability to reproduce those\nstatistics that are meaningful to the particular medically realistic SIM\nconsidered. It is shown that evaluating GANs using classical metrics and\nmedically relevant metrics may lead to different conclusions about the fidelity\nof the trained GANs. This work highlights the need for the development of\nobjective metrics for evaluating GANs.",
    "descriptor": "\nComments: Published in SPIE Medical Imaging 2022: Image Perception, Observer Performance, and Technology Assessment\n",
    "authors": [
      "Varun A. Kelkar",
      "Dimitrios S. Gotsis",
      "Frank J. Brooks",
      "Kyle J. Myers",
      "Prabhat KC",
      "Rongping Zeng",
      "Mark A. Anastasio"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Medical Physics (physics.med-ph)"
    ],
    "url": "https://arxiv.org/abs/2204.03547"
  },
  {
    "id": "arXiv:2204.03564",
    "title": "RF Signal Transformation and Classification using Deep Neural Networks",
    "abstract": "Deep neural networks (DNNs) designed for computer vision and natural language\nprocessing tasks cannot be directly applied to the radio frequency (RF)\ndatasets. To address this challenge, we propose to convert the raw RF data to\ndata types that are suitable for off-the-shelf DNNs by introducing a\nconvolutional transform technique. In addition, we propose a simple 5-layer\nconvolutional neural network architecture (CONV-5) that can operate with raw RF\nI/Q data without any transformation. Further, we put forward an RF dataset,\nreferred to as RF1024, to facilitate future RF research. RF1024 consists of 8\ndifferent RF modulation classes with each class having 1000/200 training/test\nsamples. Each sample of the RF1024 dataset contains 1024 complex I/Q values.\nLastly, the experiments are performed on the RadioML2016 and RF1024 datasets to\ndemonstrate the improved classification performance.",
    "descriptor": "\nComments: Accepted in SPIE conference: Big Data IV: Learning, Analytics, and Applications\n",
    "authors": [
      "Umar Khalid",
      "Nazmul Karim",
      "Nazanin Rahnavard"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.03564"
  },
  {
    "id": "arXiv:2204.03565",
    "title": "Adaptive Spike-Like Representation of EEG Signals for Sleep Stages  Scoring",
    "abstract": "Recently there has seen promising results on automatic stage scoring by\nextracting spatio-temporal features from electroencephalogram (EEG). Such\nmethods entail laborious manual feature engineering and domain knowledge. In\nthis study, we propose an adaptive scheme to probabilistically encode, filter\nand accumulate the input signals and weight the resultant features by the\nhalf-Gaussian probabilities of signal intensities. The adaptive representations\nare subsequently fed into a transformer model to automatically mine the\nrelevance between features and corresponding stages. Extensive experiments on\nthe largest public dataset against state-of-the-art methods validate the\neffectiveness of our proposed method and reveal promising future directions.",
    "descriptor": "\nComments: 4 pages, accepted for EMBC 2022\n",
    "authors": [
      "Lingwei Zhu",
      "Koki Odani",
      "Ziwei Yang",
      "Guang Shi",
      "Yirong Kan",
      "Zheng Chen",
      "Renyuan Zhang"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.03565"
  },
  {
    "id": "arXiv:2204.03572",
    "title": "A Pathology-Based Machine Learning Method to Assist in Epithelial  Dysplasia Diagnosis",
    "abstract": "The Epithelial Dysplasia (ED) is a tissue alteration commonly present in\nlesions preceding oral cancer, being its presence one of the most important\nfactors in the progression toward carcinoma. This study proposes a method to\ndesign a low computational cost classification system to support the detection\nof dysplastic epithelia, contributing to reduce the variability of pathologist\nassessments. We employ a multilayer artificial neural network (MLP-ANN) and\ndefining the regions of the epithelium to be assessed based on the knowledge of\nthe pathologist. The performance of the proposed solution was statistically\nevaluated. The implemented MLP-ANN presented an average accuracy of 87%, with a\nvariability much inferior to that obtained from three trained evaluators.\nMoreover, the proposed solution led to results which are very close to those\nobtained using a convolutional neural network (CNN) implemented by transfer\nlearning, with 100 times less computational complexity. In conclusion, our\nresults show that a simple neural network structure can lead to a performance\nequivalent to that of much more complex structures, which are routinely used in\nthe literature.",
    "descriptor": "",
    "authors": [
      "Karoline da Rocha",
      "Jos\u00e9 C. M. Bermudez",
      "Elena R. C. Rivero",
      "M\u00e1rcio H. Costa"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.03572"
  },
  {
    "id": "arXiv:2204.03573",
    "title": "An optimized hybrid solution for IoT based lifestyle disease  classification using stress data",
    "abstract": "Stress, anxiety, and nervousness are all high-risk health states in everyday\nlife. Previously, stress levels were determined by speaking with people and\ngaining insight into what they had experienced recently or in the past.\nTypically, stress is caused by an incidence that occurred a long time ago, but\nsometimes it is triggered by unknown factors. This is a challenging and complex\ntask, but recent research advances have provided numerous opportunities to\nautomate it. The fundamental features of most of these techniques are electro\ndermal activity (EDA) and heart rate values (HRV). We utilized an accelerometer\nto measure body motions to solve this challenge. The proposed novel method\nemploys a test that measures a subject's electrocardiogram (ECG), galvanic skin\nvalues (GSV), HRV values, and body movements in order to provide a low-cost and\ntime-saving solution for detecting stress lifestyle disease in modern times\nusing cyber physical systems. This study provides a new hybrid model for\nlifestyle disease classification that decreases execution time while picking\nthe best collection of characteristics and increases classification accuracy.\nThe developed approach is capable of dealing with the class imbalance problem\nby using WESAD (wearable stress and affect dataset) dataset. The new model uses\nthe Grid search (GS) method to select an optimized set of hyper parameters, and\nit uses a combination of the Correlation coefficient based Recursive feature\nelimination (CoC-RFE) method for optimal feature selection and gradient\nboosting as an estimator to classify the dataset, which achieves high accuracy\nand helps to provide smart, accurate, and high-quality healthcare systems. To\ndemonstrate the validity and utility of the proposed methodology, its\nperformance is compared to those of other well-established machine learning\nmodels.",
    "descriptor": "\nComments: Data mining and Data analytics used for healthcare data\n",
    "authors": [
      "Sadhana Tiwari",
      "Sonali Agarwal"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.03573"
  },
  {
    "id": "arXiv:2204.03586",
    "title": "The combinator ${\\bf M}$ and the Mockingbird lattice",
    "abstract": "We study combinatorial and order theoretic structures arising from the\nfragment of combinatory logic spanned by the basic combinator ${\\bf M}$. This\nbasic combinator, named as the Mockingbird by Smullyan, is defined by the\nrewrite rule ${\\bf M} x_1 \\to x_1 x_1$. We prove that the reflexive and\ntransitive closure of this rewrite relation is a partial order on terms on\n${\\bf M}$ and that all connected components of its rewrite graph are Hasse\ndiagram of lattices. This last result is based on the introduction of new\nlattices on duplicative forests, which are sorts of treelike structures. These\nlattices are not graded, not self-dual, and not semidistributive. We present\nsome enumerative properties of these lattices like the enumeration of their\nelements, of the edges of their Hasse diagrams, and of their intervals. These\nresults are derived from formal power series on terms and on duplicative\nforests endowed with particular operations.",
    "descriptor": "\nComments: 29 pages. This is an extended version of arXiv:2204.02616\n",
    "authors": [
      "Samuele Giraudo"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2204.03586"
  },
  {
    "id": "arXiv:2204.03618",
    "title": "Pneumonia Detection in Chest X-Rays using Neural Networks",
    "abstract": "With the advancement in AI, deep learning techniques are widely used to\ndesign robust classification models in several areas such as medical diagnosis\ntasks in which it achieves good performance. In this paper, we have proposed\nthe CNN model (Convolutional Neural Network) for the classification of Chest\nX-ray images for Radiological Society of North America Pneumonia (RSNA)\ndatasets. The study also tries to achieve the same RSNA benchmark results using\nthe limited computational resources by trying out various approaches to the\nmethodologies that have been implemented in recent years. The proposed method\nis based on a non-complex CNN and the use of transfer learning algorithms like\nXception, InceptionV3/V4, EfficientNetB7. Along with this, the study also tries\nto achieve the same RSNA benchmark results using the limited computational\nresources by trying out various approaches to the methodologies that have been\nimplemented in recent years. The RSNA benchmark MAP score is 0.25, but using\nthe Mask RCNN model on a stratified sample of 3017 along with image\naugmentation gave a MAP score of 0.15. Meanwhile, the YoloV3 without any\nhyperparameter tuning gave the MAP score of 0.32 but still, the loss keeps\ndecreasing. Running the model for a greater number of iterations can give\nbetter results.",
    "descriptor": "",
    "authors": [
      "Narayana Darapaneni",
      "Ashish Ranjan",
      "Dany Bright",
      "Devendra Trivedi",
      "Ketul Kumar",
      "Vivek Kumar",
      "Anwesh Reddy Paduri"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.03618"
  },
  {
    "id": "arXiv:1602.06763",
    "title": "Algorithm 979: Recursive Algorithms for Dense Linear Algebra -- The  ReLAPACK Collection",
    "abstract": "Algorithm 979: Recursive Algorithms for Dense Linear Algebra -- The  ReLAPACK Collection",
    "descriptor": "",
    "authors": [
      "Elmar Peise",
      "Paolo Bientinesi"
    ],
    "subjectives": [
      "Mathematical Software (cs.MS)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/1602.06763"
  },
  {
    "id": "arXiv:1709.06172",
    "title": "On the Complexity of Robust Stable Marriage",
    "abstract": "Comments: Accepted for publication in COCOA'17",
    "descriptor": "\nComments: Accepted for publication in COCOA'17\n",
    "authors": [
      "Begum Genc",
      "Mohamed Siala",
      "Gilles Simonin",
      "Barry O'Sullivan"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/1709.06172"
  },
  {
    "id": "arXiv:1812.05447",
    "title": "Generating Hard Examples for Pixel-wise Classification",
    "abstract": "Comments: IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing (JSTARS)",
    "descriptor": "\nComments: IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing (JSTARS)\n",
    "authors": [
      "Hyungtae Lee",
      "Heesung Kwon",
      "Wonkook Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/1812.05447"
  },
  {
    "id": "arXiv:1812.10779",
    "title": "Semantic Driven Multi-Camera Pedestrian Detection",
    "abstract": "Comments: Preprint accepted in Springer Knowledge and Information Systems (KAIS)",
    "descriptor": "\nComments: Preprint accepted in Springer Knowledge and Information Systems (KAIS)\n",
    "authors": [
      "Alejandro L\u00f3pez-Cifuentes",
      "Marcos Escudero-Vi\u00f1olo",
      "Jes\u00fas Besc\u00f3s",
      "Pablo Carballeira"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/1812.10779"
  },
  {
    "id": "arXiv:1906.06717",
    "title": "Mo\u00cbT: Mixture of Expert Trees and its Application to Verifiable  Reinforcement Learning",
    "abstract": "Mo\u00cbT: Mixture of Expert Trees and its Application to Verifiable  Reinforcement Learning",
    "descriptor": "",
    "authors": [
      "Marko Vasic",
      "Andrija Petrovic",
      "Kaiyuan Wang",
      "Mladen Nikolic",
      "Rishabh Singh",
      "Sarfraz Khurshid"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1906.06717"
  },
  {
    "id": "arXiv:1907.12775",
    "title": "Linear Programming Complementation",
    "abstract": "Linear Programming Complementation",
    "descriptor": "",
    "authors": [
      "Maximilien Gadouleau",
      "George B. Mertzios",
      "Viktor Zamaraev"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/1907.12775"
  },
  {
    "id": "arXiv:1912.01059",
    "title": "GGNN: Graph-based GPU Nearest Neighbor Search",
    "abstract": "GGNN: Graph-based GPU Nearest Neighbor Search",
    "descriptor": "",
    "authors": [
      "Fabian Groh",
      "Lukas Ruppert",
      "Patrick Wieschollek",
      "Hendrik P.A. Lensch"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Databases (cs.DB)",
      "Data Structures and Algorithms (cs.DS)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/1912.01059"
  },
  {
    "id": "arXiv:2002.02601",
    "title": "Bidimensional linked matrix factorization for pan-omics pan-cancer  analysis",
    "abstract": "Comments: 26 pages, 5 figures",
    "descriptor": "\nComments: 26 pages, 5 figures\n",
    "authors": [
      "Eric F. Lock",
      "Jun Young Park",
      "Katherine A. Hoadley"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)",
      "Applications (stat.AP)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2002.02601"
  },
  {
    "id": "arXiv:2002.09745",
    "title": "Differentially Private Set Union",
    "abstract": "Comments: 23 pages, 7 figures",
    "descriptor": "\nComments: 23 pages, 7 figures\n",
    "authors": [
      "Sivakanth Gopi",
      "Pankaj Gulhane",
      "Janardhan Kulkarni",
      "Judy Hanwen Shen",
      "Milad Shokouhi",
      "Sergey Yekhanin"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2002.09745"
  },
  {
    "id": "arXiv:2006.00575",
    "title": "Neural Entity Linking: A Survey of Models Based on Deep Learning",
    "abstract": "Comments: Published in Semantic Web journal",
    "descriptor": "\nComments: Published in Semantic Web journal\n",
    "authors": [
      "Ozge Sevgili",
      "Artem Shelmanov",
      "Mikhail Arkhipov",
      "Alexander Panchenko",
      "Chris Biemann"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2006.00575"
  },
  {
    "id": "arXiv:2006.16129",
    "title": "Algebraic coherent confluence and higher globular Kleene algebras",
    "abstract": "Comments: Pre-print (third version)",
    "descriptor": "\nComments: Pre-print (third version)\n",
    "authors": [
      "Cameron Calk",
      "Eric Goubault",
      "Philippe Malbos",
      "Georg Struth"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Category Theory (math.CT)"
    ],
    "url": "https://arxiv.org/abs/2006.16129"
  },
  {
    "id": "arXiv:2008.09371",
    "title": "Towards Improving Selective Prediction Ability of NLP Systems",
    "abstract": "Comments: ACL 2022 RepL4NLP Workshop",
    "descriptor": "\nComments: ACL 2022 RepL4NLP Workshop\n",
    "authors": [
      "Neeraj Varshney",
      "Swaroop Mishra",
      "Chitta Baral"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2008.09371"
  },
  {
    "id": "arXiv:2010.05454",
    "title": "Joint Adaptive Graph and Structured Sparsity Regularization for  Unsupervised Feature Selection",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:2010.03728",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2010.03728\n",
    "authors": [
      "Zhenzhen Sun",
      "Yuanlong Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2010.05454"
  },
  {
    "id": "arXiv:2010.09059",
    "title": "Discrete Empirical Interpolation and unfitted mesh FEMs: application in  PDE-constrained optimization",
    "abstract": "Comments: -",
    "descriptor": "\nComments: -\n",
    "authors": [
      "Georgios Katsouleas",
      "Efthymios N. Karatzas",
      "Fotios Travlopanos"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2010.09059"
  },
  {
    "id": "arXiv:2011.02166",
    "title": "DAIS: Automatic Channel Pruning via Differentiable Annealing Indicator  Search",
    "abstract": "Comments: Accepted to IEEE TNNLS",
    "descriptor": "\nComments: Accepted to IEEE TNNLS\n",
    "authors": [
      "Yushuo Guan",
      "Ning Liu",
      "Pengyu Zhao",
      "Zhengping Che",
      "Kaigui Bian",
      "Yanzhi Wang",
      "Jian Tang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2011.02166"
  },
  {
    "id": "arXiv:2011.07401",
    "title": "RL-QN: A Reinforcement Learning Framework for Optimal Control of  Queueing Systems",
    "abstract": "RL-QN: A Reinforcement Learning Framework for Optimal Control of  Queueing Systems",
    "descriptor": "",
    "authors": [
      "Bai Liu",
      "Qiaomin Xie",
      "Eytan Modiano"
    ],
    "subjectives": [
      "Performance (cs.PF)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2011.07401"
  },
  {
    "id": "arXiv:2011.12844",
    "title": "Physics-informed neural networks for myocardial perfusion MRI  quantification",
    "abstract": "Comments: Published in Medical Image Analysis",
    "descriptor": "\nComments: Published in Medical Image Analysis\n",
    "authors": [
      "Rudolf L.M. van Herten",
      "Amedeo Chiribiri",
      "Marcel Breeuwer",
      "Mitko Veta",
      "Cian M. Scannell"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Medical Physics (physics.med-ph)"
    ],
    "url": "https://arxiv.org/abs/2011.12844"
  },
  {
    "id": "arXiv:2012.08024",
    "title": "Agglomeration-Based Geometric Multigrid Solvers for Compact  Discontinuous Galerkin Discretizations on Unstructured Meshes",
    "abstract": "Agglomeration-Based Geometric Multigrid Solvers for Compact  Discontinuous Galerkin Discretizations on Unstructured Meshes",
    "descriptor": "",
    "authors": [
      "Yulong Pan",
      "Per-Olof Persson"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2012.08024"
  },
  {
    "id": "arXiv:2102.04288",
    "title": "Revocation Statuses on the Internet",
    "abstract": "Comments: In proceedings of Passive and Active Measurement Conference (PAM 2021)",
    "descriptor": "\nComments: In proceedings of Passive and Active Measurement Conference (PAM 2021)\n",
    "authors": [
      "Nikita Korzhitskii",
      "Niklas Carlsson"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Cryptography and Security (cs.CR)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2102.04288"
  },
  {
    "id": "arXiv:2102.08850",
    "title": "Contrastive Learning Inverts the Data Generating Process",
    "abstract": "Comments: Presented at ICML 2021. The first three authors, as well as the last two authors, contributed equally. Code is available at this https URL",
    "descriptor": "\nComments: Presented at ICML 2021. The first three authors, as well as the last two authors, contributed equally. Code is available at this https URL\n",
    "authors": [
      "Roland S. Zimmermann",
      "Yash Sharma",
      "Steffen Schneider",
      "Matthias Bethge",
      "Wieland Brendel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2102.08850"
  },
  {
    "id": "arXiv:2103.03054",
    "title": "An Open-Source Low-Cost Mobile Robot System with an RGB-D Camera and  Efficient Real-Time Navigation Algorithm",
    "abstract": "Comments: Project Github: this https URL Video: this https URL",
    "descriptor": "\nComments: Project Github: this https URL Video: this https URL\n",
    "authors": [
      "Taekyung Kim",
      "Seunghyun Lim",
      "Gwanjun Shin",
      "Geonhee Sim",
      "Dongwon Yun"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2103.03054"
  },
  {
    "id": "arXiv:2103.03081",
    "title": "An Overview on Artificial Intelligence Techniques for Diagnosis of  Schizophrenia Based on Magnetic Resonance Imaging Modalities: Methods,  Challenges, and Future Works",
    "abstract": "An Overview on Artificial Intelligence Techniques for Diagnosis of  Schizophrenia Based on Magnetic Resonance Imaging Modalities: Methods,  Challenges, and Future Works",
    "descriptor": "",
    "authors": [
      "Delaram Sadeghi",
      "Afshin Shoeibi",
      "Navid Ghassemi",
      "Parisa Moridian",
      "Ali Khadem",
      "Roohallah Alizadehsani",
      "Mohammad Teshnehlab",
      "J. Manuel Gorriz",
      "Fahime Khozeimeh",
      "Yu-Dong Zhang",
      "Saeid Nahavandi",
      "U Rajendra Acharya"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2103.03081"
  },
  {
    "id": "arXiv:2103.03703",
    "title": "Semi-Supervised Federated Peer Learning for Skin Lesion Classification",
    "abstract": "Semi-Supervised Federated Peer Learning for Skin Lesion Classification",
    "descriptor": "",
    "authors": [
      "Tariq Bdair",
      "Nassir Navab",
      "Shadi Albarqouni"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.03703"
  },
  {
    "id": "arXiv:2103.04159",
    "title": "The gradient descent method for the convexification to solve boundary  value problems of quasi-linear PDEs and a coefficient inverse problem",
    "abstract": "The gradient descent method for the convexification to solve boundary  value problems of quasi-linear PDEs and a coefficient inverse problem",
    "descriptor": "",
    "authors": [
      "Thuy T. Le",
      "Loc. H. Nguyen"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)"
    ],
    "url": "https://arxiv.org/abs/2103.04159"
  },
  {
    "id": "arXiv:2103.06428",
    "title": "Covariate-assisted Sparse Tensor Completion",
    "abstract": "Comments: To Appear in Journal of the American Statistical Association",
    "descriptor": "\nComments: To Appear in Journal of the American Statistical Association\n",
    "authors": [
      "Hilda S Ibriga",
      "Will Wei Sun"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2103.06428"
  },
  {
    "id": "arXiv:2103.15362",
    "title": "Self-triggered Stabilization of Discrete-time Linear Systems with  Quantized State Measurements",
    "abstract": "Comments: 8 pages",
    "descriptor": "\nComments: 8 pages\n",
    "authors": [
      "Masashi Wakaiki"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2103.15362"
  },
  {
    "id": "arXiv:2103.15783",
    "title": "Multiscale Clustering of Hyperspectral Images Through Spectral-Spatial  Diffusion Geometry",
    "abstract": "Comments: (6 pages, 2 figures). Proceedings of IEEE IGARSS 2021",
    "descriptor": "\nComments: (6 pages, 2 figures). Proceedings of IEEE IGARSS 2021\n",
    "authors": [
      "Sam L. Polk",
      "James M. Murphy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2103.15783"
  },
  {
    "id": "arXiv:2103.15980",
    "title": "A tutorial on $\\mathbf{SE}(3)$ transformation parameterizations and  on-manifold optimization",
    "abstract": "Comments: 68 pages, 6 figures; v2 in arXiv; see history of document versions on page 3 for full change log of the technical report since 2010",
    "descriptor": "\nComments: 68 pages, 6 figures; v2 in arXiv; see history of document versions on page 3 for full change log of the technical report since 2010\n",
    "authors": [
      "Jos\u00e9 Luis Blanco-Claraco"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.15980"
  },
  {
    "id": "arXiv:2104.05861",
    "title": "Evaluating Pre-Trained Models for User Feedback Analysis in Software  Engineering: A Study on Classification of App-Reviews",
    "abstract": "Comments: 55 pages, 13 tables, 6 figures, EMSE 2022",
    "descriptor": "\nComments: 55 pages, 13 tables, 6 figures, EMSE 2022\n",
    "authors": [
      "Mohammad Abdul Hadi",
      "Fatemeh H. Fard"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.05861"
  },
  {
    "id": "arXiv:2104.08676",
    "title": "Distributed NLI: Learning to Predict Human Opinion Distributions for  Language Reasoning",
    "abstract": "Comments: ACL 2022 Findings (16 pages)",
    "descriptor": "\nComments: ACL 2022 Findings (16 pages)\n",
    "authors": [
      "Xiang Zhou",
      "Yixin Nie",
      "Mohit Bansal"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.08676"
  },
  {
    "id": "arXiv:2104.11123",
    "title": "Universal Horn Sentences and the Joint Embedding Property",
    "abstract": "Comments: 16 pages",
    "descriptor": "\nComments: 16 pages\n",
    "authors": [
      "Manuel Bodirsky",
      "Jakub Rydval",
      "Andr\u00e9 Schrottenloher"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Logic (math.LO)"
    ],
    "url": "https://arxiv.org/abs/2104.11123"
  },
  {
    "id": "arXiv:2104.12948",
    "title": "High-order accurate finite difference discretisations on fully  unstructured dual quadrilateral meshes",
    "abstract": "High-order accurate finite difference discretisations on fully  unstructured dual quadrilateral meshes",
    "descriptor": "",
    "authors": [
      "Yulong Pan",
      "Per-Olof Persson"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2104.12948"
  },
  {
    "id": "arXiv:2105.03038",
    "title": "Lambek pregroups are Frobenius spiders in preorders",
    "abstract": "Comments: 21 pages, 16 diagrams. Final journal version: DOI kindly inserted by Fosco Loregian",
    "descriptor": "\nComments: 21 pages, 16 diagrams. Final journal version: DOI kindly inserted by Fosco Loregian\n",
    "authors": [
      "Dusko Pavlovic"
    ],
    "subjectives": [
      "Category Theory (math.CT)",
      "Computation and Language (cs.CL)",
      "Formal Languages and Automata Theory (cs.FL)",
      "Logic in Computer Science (cs.LO)",
      "Logic (math.LO)"
    ],
    "url": "https://arxiv.org/abs/2105.03038"
  },
  {
    "id": "arXiv:2105.13280",
    "title": "Coarse-Grid Selection Using Simulated Annealing",
    "abstract": "Comments: 22 pages, 12 figures",
    "descriptor": "\nComments: 22 pages, 12 figures\n",
    "authors": [
      "Tareq. U. Zaman",
      "Scott P. MacLachlan",
      "Luke N. Olson",
      "Matt West"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2105.13280"
  },
  {
    "id": "arXiv:2106.02190",
    "title": "Spatial Graph Attention and Curiosity-driven Policy for Antiviral Drug  Discovery",
    "abstract": "Spatial Graph Attention and Curiosity-driven Policy for Antiviral Drug  Discovery",
    "descriptor": "",
    "authors": [
      "Yulun Wu",
      "Mikaela Cashman",
      "Nicholas Choma",
      "\u00c9rica T. Prates",
      "Ver\u00f3nica G. Melesse Vergara",
      "Andrew Chen",
      "Manesh Shah",
      "Austin Clyde",
      "Thomas S. Brettin",
      "Wibe A. de Jong",
      "Neeraj Kumar",
      "Martha S. Head",
      "Rick L. Stevens",
      "Peter Nugent",
      "Daniel A. Jacobson",
      "James B. Brown"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Biomolecules (q-bio.BM)"
    ],
    "url": "https://arxiv.org/abs/2106.02190"
  },
  {
    "id": "arXiv:2106.04564",
    "title": "Are Pretrained Transformers Robust in Intent Classification? A Missing  Ingredient in Evaluation of Out-of-Scope Intent Detection",
    "abstract": "Comments: ACL 2022 Workshop on NLP for Conversational AI",
    "descriptor": "\nComments: ACL 2022 Workshop on NLP for Conversational AI\n",
    "authors": [
      "Jianguo Zhang",
      "Kazuma Hashimoto",
      "Yao Wan",
      "Zhiwei Liu",
      "Ye Liu",
      "Caiming Xiong",
      "Philip S. Yu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.04564"
  },
  {
    "id": "arXiv:2106.06411",
    "title": "Zero-Shot Controlled Generation with Encoder-Decoder Transformers",
    "abstract": "Comments: Accepted at AAAI 2022",
    "descriptor": "\nComments: Accepted at AAAI 2022\n",
    "authors": [
      "Devamanyu Hazarika",
      "Mahdi Namazifar",
      "Dilek Hakkani-T\u00fcr"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.06411"
  },
  {
    "id": "arXiv:2106.06841",
    "title": "Quantum Algorithms and Simulation for Parallel and Distributed Quantum  Computing",
    "abstract": "Comments: Adding funding information",
    "descriptor": "\nComments: Adding funding information\n",
    "authors": [
      "Rhea Parekh",
      "Andrea Ricciardi",
      "Ahmed Darwish",
      "Stephen DiAdamo"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2106.06841"
  },
  {
    "id": "arXiv:2106.09179",
    "title": "Amortized Auto-Tuning: Cost-Efficient Bayesian Transfer Optimization for  Hyperparameter Recommendation",
    "abstract": "Amortized Auto-Tuning: Cost-Efficient Bayesian Transfer Optimization for  Hyperparameter Recommendation",
    "descriptor": "",
    "authors": [
      "Yuxin Xiao",
      "Eric P. Xing",
      "Willie Neiswanger"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.09179"
  },
  {
    "id": "arXiv:2106.14836",
    "title": "Understanding Dynamics of Nonlinear Representation Learning and Its  Application",
    "abstract": "Understanding Dynamics of Nonlinear Representation Learning and Its  Application",
    "descriptor": "",
    "authors": [
      "Kenji Kawaguchi",
      "Linjun Zhang",
      "Zhun Deng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.14836"
  },
  {
    "id": "arXiv:2107.02375",
    "title": "SplitAVG: A heterogeneity-aware federated deep learning method for  medical imaging",
    "abstract": "SplitAVG: A heterogeneity-aware federated deep learning method for  medical imaging",
    "descriptor": "",
    "authors": [
      "Miao Zhang",
      "Liangqiong Qu",
      "Praveer Singh",
      "Jayashree Kalpathy-Cramer",
      "Daniel L. Rubin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2107.02375"
  },
  {
    "id": "arXiv:2107.04276",
    "title": "Secure Consensus via Objective Coding: Robustness Analysis to Channel  Tampering",
    "abstract": "Comments: 12 pages, 5 figures, submitted to IEEE Transactions on Systems, Man and Cybernetics: Systems",
    "descriptor": "\nComments: 12 pages, 5 figures, submitted to IEEE Transactions on Systems, Man and Cybernetics: Systems\n",
    "authors": [
      "Marco Fabris",
      "Daniel Zelazo"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2107.04276"
  },
  {
    "id": "arXiv:2107.06336",
    "title": "Improving Cooperative Game Theory-based Data Valuation via Data Utility  Learning",
    "abstract": "Improving Cooperative Game Theory-based Data Valuation via Data Utility  Learning",
    "descriptor": "",
    "authors": [
      "Tianhao Wang",
      "Yu Yang",
      "Ruoxi Jia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.06336"
  },
  {
    "id": "arXiv:2107.07649",
    "title": "Reed-Muller Identification",
    "abstract": "Comments: V3: capacity statement fixed; V2: published version in proceedings at International Zurich Seminar on Information and Communication (IZS) 2022 with wrong capacity statement; V1: wrong capacity statement (wrong proof that the codes do not achieve capacity while they do), submitted to 2021 IEEE Globecom: Workshop on Channel Coding beyond 5G",
    "descriptor": "\nComments: V3: capacity statement fixed; V2: published version in proceedings at International Zurich Seminar on Information and Communication (IZS) 2022 with wrong capacity statement; V1: wrong capacity statement (wrong proof that the codes do not achieve capacity while they do), submitted to 2021 IEEE Globecom: Workshop on Channel Coding beyond 5G\n",
    "authors": [
      "Mattia Spandri",
      "Roberto Ferrara",
      "Christian Deppe"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2107.07649"
  },
  {
    "id": "arXiv:2108.00916",
    "title": "2-D Directed Formation Control Based on Bipolar Coordinates",
    "abstract": "2-D Directed Formation Control Based on Bipolar Coordinates",
    "descriptor": "",
    "authors": [
      "Farhad Mehdifar",
      "Charalampos P. Bechlioulis",
      "Julien M. Hendrickx",
      "Dimos V. Dimarogonas"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Multiagent Systems (cs.MA)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2108.00916"
  },
  {
    "id": "arXiv:2108.03706",
    "title": "Online Bootstrap Inference For Policy Evaluation in Reinforcement  Learning",
    "abstract": "Comments: Removed the varying truncation step; added new experiments on off-policy evaluation; added new experiments on second-order accuracy of the bootstrap procedure; added discussions on nonlinear functional approximation, model-misspecification, and semi-parametric efficiency",
    "descriptor": "\nComments: Removed the varying truncation step; added new experiments on off-policy evaluation; added new experiments on second-order accuracy of the bootstrap procedure; added discussions on nonlinear functional approximation, model-misspecification, and semi-parametric efficiency\n",
    "authors": [
      "Pratik Ramprasad",
      "Yuantong Li",
      "Zhuoran Yang",
      "Zhaoran Wang",
      "Will Wei Sun",
      "Guang Cheng"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2108.03706"
  },
  {
    "id": "arXiv:2108.08244",
    "title": "Scarce Data Driven Deep Learning of Drones via Generalized Data  Distribution Space",
    "abstract": "Comments: 9 pages, 6 figures",
    "descriptor": "\nComments: 9 pages, 6 figures\n",
    "authors": [
      "Chen Li",
      "Schyler C. Sun",
      "Zhuangkun Wei",
      "Antonios Tsourdos",
      "Weisi Guo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.08244"
  },
  {
    "id": "arXiv:2108.08648",
    "title": "Exact solution for Riemann problems of the shear shallow water model",
    "abstract": "Exact solution for Riemann problems of the shear shallow water model",
    "descriptor": "",
    "authors": [
      "Boniface Nkonga",
      "Praveen Chandrashekar"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2108.08648"
  },
  {
    "id": "arXiv:2108.12864",
    "title": "Well-mixing vertices and almost expanders",
    "abstract": "Comments: accepted in PAMS",
    "descriptor": "\nComments: accepted in PAMS\n",
    "authors": [
      "Debsoumya Chakraborti",
      "Jaehoon Kim",
      "Jinha Kim",
      "Minki Kim",
      "Hong Liu"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2108.12864"
  },
  {
    "id": "arXiv:2109.03620",
    "title": "Jacobi's Bound. Jacobi's results translated in K{\u00d6}nig's,  Egerv{\u00e1}ry's and Ritt's mathematical languages",
    "abstract": "Comments: 104 pages, 10 figures",
    "descriptor": "\nComments: 104 pages, 10 figures\n",
    "authors": [
      "Fran\u00e7ois Ollivier"
    ],
    "subjectives": [
      "History and Overview (math.HO)",
      "Symbolic Computation (cs.SC)"
    ],
    "url": "https://arxiv.org/abs/2109.03620"
  },
  {
    "id": "arXiv:2109.08228",
    "title": "ROOAD: RELLIS Off-road Odometry Analysis Dataset",
    "abstract": "Comments: 7 pages, 6 figures, 5 tables, IV 2022 conference",
    "descriptor": "\nComments: 7 pages, 6 figures, 5 tables, IV 2022 conference\n",
    "authors": [
      "George Chustz",
      "Srikanth Saripalli"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.08228"
  },
  {
    "id": "arXiv:2109.08567",
    "title": "A Direct Construction of GCP and Binary CCC of Length Non Power of Two",
    "abstract": "A Direct Construction of GCP and Binary CCC of Length Non Power of Two",
    "descriptor": "",
    "authors": [
      "Praveen Kumar",
      "Sudhan Majhi",
      "Subhabrata Paul"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2109.08567"
  },
  {
    "id": "arXiv:2109.09395",
    "title": "Unsupervised Cycle-consistent Generative Adversarial Networks for  Pan-sharpening",
    "abstract": "Comments: 14 pages, 8 figures, and 7 tables. Accepted by TGRS",
    "descriptor": "\nComments: 14 pages, 8 figures, and 7 tables. Accepted by TGRS\n",
    "authors": [
      "Huanyu Zhou",
      "Qingjie Liu",
      "Dawei Weng",
      "Yunhong Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2109.09395"
  },
  {
    "id": "arXiv:2109.10476",
    "title": "Self-Supervised Learning to Prove Equivalence Between Programs via  Semantics-Preserving Rewrite Rules",
    "abstract": "Comments: 18 pages",
    "descriptor": "\nComments: 18 pages\n",
    "authors": [
      "Steve Kommrusch",
      "Martin Monperrus",
      "Louis-No\u00ebl Pouchet"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2109.10476"
  },
  {
    "id": "arXiv:2109.12153",
    "title": "Mixed-precision explicit stabilized Runge-Kutta methods for single- and  multi-scale differential equations",
    "abstract": "Comments: 38 pages, 11 figures",
    "descriptor": "\nComments: 38 pages, 11 figures\n",
    "authors": [
      "Matteo Croci",
      "Giacomo Rosilho de Souza"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2109.12153"
  },
  {
    "id": "arXiv:2109.12800",
    "title": "Machine Learning based Medical Image Deepfake Detection: A Comparative  Study",
    "abstract": "Machine Learning based Medical Image Deepfake Detection: A Comparative  Study",
    "descriptor": "",
    "authors": [
      "Siddharth Solaiyappan",
      "Yuxin Wen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.12800"
  },
  {
    "id": "arXiv:2110.04121",
    "title": "On the Limitations of Multimodal VAEs",
    "abstract": "Comments: ICLR 2022 camera-ready version",
    "descriptor": "\nComments: ICLR 2022 camera-ready version\n",
    "authors": [
      "Imant Daunhawer",
      "Thomas M. Sutter",
      "Kieran Chin-Cheong",
      "Emanuele Palumbo",
      "Julia E. Vogt"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.04121"
  },
  {
    "id": "arXiv:2110.05319",
    "title": "Efficient Training of 3D Seismic Image Fault Segmentation Network under  Sparse Labels by Weakening Anomaly Annotation",
    "abstract": "Comments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Yimin Dou",
      "Kewen Li",
      "Jianbing Zhu",
      "Timing Li",
      "Shaoquan Tan",
      "Zongchao Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)",
      "Geophysics (physics.geo-ph)"
    ],
    "url": "https://arxiv.org/abs/2110.05319"
  },
  {
    "id": "arXiv:2110.06864",
    "title": "ByteTrack: Multi-Object Tracking by Associating Every Detection Box",
    "abstract": "ByteTrack: Multi-Object Tracking by Associating Every Detection Box",
    "descriptor": "",
    "authors": [
      "Yifu Zhang",
      "Peize Sun",
      "Yi Jiang",
      "Dongdong Yu",
      "Fucheng Weng",
      "Zehuan Yuan",
      "Ping Luo",
      "Wenyu Liu",
      "Xinggang Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.06864"
  },
  {
    "id": "arXiv:2110.07349",
    "title": "A Functional Abstraction of Typed Invocation Contexts",
    "abstract": "Comments: 29 pages, 9 figures, Submitted to LMCS special issue on FSCD 2021",
    "descriptor": "\nComments: 29 pages, 9 figures, Submitted to LMCS special issue on FSCD 2021\n",
    "authors": [
      "Youyou Cong",
      "Chiaki Ishio",
      "Kaho Honda",
      "Kenichi Asai"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2110.07349"
  },
  {
    "id": "arXiv:2111.00185",
    "title": "Convergence and Optimality of Policy Gradient Methods in Weakly Smooth  Settings",
    "abstract": "Convergence and Optimality of Policy Gradient Methods in Weakly Smooth  Settings",
    "descriptor": "",
    "authors": [
      "Matthew S. Zhang",
      "Murat A. Erdogdu",
      "Animesh Garg"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2111.00185"
  },
  {
    "id": "arXiv:2111.00507",
    "title": "Introduction to probabilistic concurrent systems",
    "abstract": "Comments: Extended version of the Petri Net 2021 conference paper arXiv:2008.07233 \"Deterministic concurrent systems\" by the same author. 33 pages, 9 figures, 17 references",
    "descriptor": "\nComments: Extended version of the Petri Net 2021 conference paper arXiv:2008.07233 \"Deterministic concurrent systems\" by the same author. 33 pages, 9 figures, 17 references\n",
    "authors": [
      "Samy Abbes"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2111.00507"
  },
  {
    "id": "arXiv:2111.01533",
    "title": "A comparison of mixed-variables Bayesian optimization approaches",
    "abstract": "Comments: Accepted for publication in Advanced Modeling and Simulation in Engineering Sciences, march 2022",
    "descriptor": "\nComments: Accepted for publication in Advanced Modeling and Simulation in Engineering Sciences, march 2022\n",
    "authors": [
      "Jhouben Cuesta-Ramirez",
      "Rodolphe Le Riche",
      "Olivier Roustant",
      "Guillaume Perrin",
      "Cedric Durantin",
      "Alain Gliere"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)",
      "Computation (stat.CO)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.01533"
  },
  {
    "id": "arXiv:2111.04063",
    "title": "LiMuSE: Lightweight Multi-modal Speaker Extraction",
    "abstract": "Comments: Submitted to INTERSPEECH 2022",
    "descriptor": "\nComments: Submitted to INTERSPEECH 2022\n",
    "authors": [
      "Qinghua Liu",
      "Yating Huang",
      "Yunzhe Hao",
      "Jiaming Xu",
      "Bo Xu"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2111.04063"
  },
  {
    "id": "arXiv:2111.05113",
    "title": "Membership Inference Attacks Against Self-supervised Speech Models",
    "abstract": "Comments: Submitted to Interspeech 2022. Code will be available in the future",
    "descriptor": "\nComments: Submitted to Interspeech 2022. Code will be available in the future\n",
    "authors": [
      "Wei-Cheng Tseng",
      "Wei-Tsung Kao",
      "Hung-yi Lee"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2111.05113"
  },
  {
    "id": "arXiv:2111.06284",
    "title": "Optimal Physical Sorting of Mobile Agents",
    "abstract": "Optimal Physical Sorting of Mobile Agents",
    "descriptor": "",
    "authors": [
      "Dmitry Rabinovich",
      "Michael Amir",
      "Alfred M. Bruckstein"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2111.06284"
  },
  {
    "id": "arXiv:2111.06476",
    "title": "Automated question generation and question answering from Turkish texts",
    "abstract": "Comments: 14 pages, 1 figure, 13 tables",
    "descriptor": "\nComments: 14 pages, 1 figure, 13 tables\n",
    "authors": [
      "Fatih Cagatay Akyon",
      "Devrim Cavusoglu",
      "Cemil Cengiz",
      "Sinan Onur Altinuc",
      "Alptekin Temizel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.06476"
  },
  {
    "id": "arXiv:2111.07483",
    "title": "Tradeoffs for small-depth Frege proofs",
    "abstract": "Comments: FOCS 2021. Fixed typo in Theorem 1.1",
    "descriptor": "\nComments: FOCS 2021. Fixed typo in Theorem 1.1\n",
    "authors": [
      "Toniann Pitassi",
      "Prasanna Ramakrishnan",
      "Li-Yang Tan"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2111.07483"
  },
  {
    "id": "arXiv:2111.07548",
    "title": "Unsupervised Lightweight Single Object Tracking with UHP-SOT++",
    "abstract": "Comments: updated content: comparison with state-of-the-art deep unsupervised methods",
    "descriptor": "\nComments: updated content: comparison with state-of-the-art deep unsupervised methods\n",
    "authors": [
      "Zhiruo Zhou",
      "Hongyu Fu",
      "Suya You",
      "C.-C. Jay Kuo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.07548"
  },
  {
    "id": "arXiv:2111.08853",
    "title": "NNSynth: Neural Network Guided Abstraction-Based Controller Synthesis  for Stochastic Systems",
    "abstract": "NNSynth: Neural Network Guided Abstraction-Based Controller Synthesis  for Stochastic Systems",
    "descriptor": "",
    "authors": [
      "Xiaowu Sun",
      "Yasser Shoukry"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2111.08853"
  },
  {
    "id": "arXiv:2111.09266",
    "title": "GFlowNet Foundations",
    "abstract": "GFlowNet Foundations",
    "descriptor": "",
    "authors": [
      "Yoshua Bengio",
      "Tristan Deleu",
      "Edward J. Hu",
      "Salem Lahlou",
      "Mo Tiwari",
      "Emmanuel Bengio"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.09266"
  },
  {
    "id": "arXiv:2111.09456",
    "title": "Improved Rates for Derivative Free Gradient Play in Strongly Monotone  Games",
    "abstract": "Improved Rates for Derivative Free Gradient Play in Strongly Monotone  Games",
    "descriptor": "",
    "authors": [
      "Dmitriy Drusvyatskiy",
      "Maryam Fazel",
      "Lillian J Ratliff"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2111.09456"
  },
  {
    "id": "arXiv:2111.10520",
    "title": "StylePart: Image-based Shape Part Manipulation",
    "abstract": "Comments: 10 pages, Project page: this https URL",
    "descriptor": "\nComments: 10 pages, Project page: this https URL\n",
    "authors": [
      "I-Chao Shen",
      "Li-Wen Su",
      "Yu-Ting Wu",
      "Bing-Yu Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2111.10520"
  },
  {
    "id": "arXiv:2111.13419",
    "title": "KazNERD: Kazakh Named Entity Recognition Dataset",
    "abstract": "Comments: 10 pages, 1 figure, 8 tables, accepted to LREC 2022",
    "descriptor": "\nComments: 10 pages, 1 figure, 8 tables, accepted to LREC 2022\n",
    "authors": [
      "Rustem Yeshpanov",
      "Yerbolat Khassanov",
      "Huseyin Atakan Varol"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2111.13419"
  },
  {
    "id": "arXiv:2111.14465",
    "title": "Motion-from-Blur: 3D Shape and Motion Estimation of Motion-blurred  Objects in Videos",
    "abstract": "Comments: CVPR 2022 camera-ready",
    "descriptor": "\nComments: CVPR 2022 camera-ready\n",
    "authors": [
      "Denys Rozumnyi",
      "Martin R. Oswald",
      "Vittorio Ferrari",
      "Marc Pollefeys"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.14465"
  },
  {
    "id": "arXiv:2111.14507",
    "title": "SPIN: Simplifying Polar Invariance for Neural networks Application to  vision-based irradiance forecasting",
    "abstract": "Comments: CVPR 2022 - OmniCV workshop (oral)",
    "descriptor": "\nComments: CVPR 2022 - OmniCV workshop (oral)\n",
    "authors": [
      "Quentin Paletta",
      "Anthony Hu",
      "Guillaume Arbod",
      "Philippe Blanc",
      "Joan Lasenby"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.14507"
  },
  {
    "id": "arXiv:2111.14826",
    "title": "Nonuniform-to-Uniform Quantization: Towards Accurate Quantization via  Generalized Straight-Through Estimation",
    "abstract": "Comments: CVPR 2022",
    "descriptor": "\nComments: CVPR 2022\n",
    "authors": [
      "Zechun Liu",
      "Kwang-Ting Cheng",
      "Dong Huang",
      "Eric Xing",
      "Zhiqiang Shen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.14826"
  },
  {
    "id": "arXiv:2112.01967",
    "title": "IRShield: A Countermeasure Against Adversarial Physical-Layer Wireless  Sensing",
    "abstract": "IRShield: A Countermeasure Against Adversarial Physical-Layer Wireless  Sensing",
    "descriptor": "",
    "authors": [
      "Paul Staat",
      "Simon Mulzer",
      "Stefan Roth",
      "Veelasha Moonsamy",
      "Markus Heinrichs",
      "Rainer Kronberger",
      "Aydin Sezgin",
      "Christof Paar"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2112.01967"
  },
  {
    "id": "arXiv:2112.02072",
    "title": "Deep learning method for identifying mass composition of  ultra-high-energy cosmic rays",
    "abstract": "Comments: 19 pages, 5 figures",
    "descriptor": "\nComments: 19 pages, 5 figures\n",
    "authors": [
      "O. Kalashev",
      "I. Kharuk",
      "M. Kuznetsov",
      "G. Rubtsov",
      "T. Sako",
      "Y. Tsunesada",
      "Ya. Zhezher"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "High Energy Astrophysical Phenomena (astro-ph.HE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.02072"
  },
  {
    "id": "arXiv:2112.02573",
    "title": "Symplectic and Cosymplectic Reduction for simple hybrid forced  mechanical systems with symmetries",
    "abstract": "Comments: Preprint submitted to a Journal. Comments Welcome! arXiv admin note: text overlap with arXiv:2003.07484",
    "descriptor": "\nComments: Preprint submitted to a Journal. Comments Welcome! arXiv admin note: text overlap with arXiv:2003.07484\n",
    "authors": [
      "Leonardo J. Colombo",
      "Manuel de Le\u00f3n",
      "Mar\u00eda Emma Eyrea Iraz\u00fa",
      "Asier L\u00f3pez-Gord\u00f3n"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Dynamical Systems (math.DS)",
      "Symplectic Geometry (math.SG)"
    ],
    "url": "https://arxiv.org/abs/2112.02573"
  },
  {
    "id": "arXiv:2112.03288",
    "title": "Dense Depth Priors for Neural Radiance Fields from Sparse Input Views",
    "abstract": "Comments: CVPR 2022, project page: this https URL , video: this https URL",
    "descriptor": "\nComments: CVPR 2022, project page: this https URL , video: this https URL\n",
    "authors": [
      "Barbara Roessle",
      "Jonathan T. Barron",
      "Ben Mildenhall",
      "Pratul P. Srinivasan",
      "Matthias Nie\u00dfner"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.03288"
  },
  {
    "id": "arXiv:2112.05198",
    "title": "Reinforcement Learning with Almost Sure Constraints",
    "abstract": "Comments: Accepted to L4DC 2022",
    "descriptor": "\nComments: Accepted to L4DC 2022\n",
    "authors": [
      "Agustin Castellano",
      "Hancheng Min",
      "Juan Bazerque",
      "Enrique Mallada"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.05198"
  },
  {
    "id": "arXiv:2112.06510",
    "title": "Do Data-based Curricula Work?",
    "abstract": "Do Data-based Curricula Work?",
    "descriptor": "",
    "authors": [
      "Maxim K. Surkov",
      "Vladislav D. Mosin",
      "Ivan P. Yamshchikov"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.06510"
  },
  {
    "id": "arXiv:2112.06881",
    "title": "Generalization Bounded Implicit Learning of Nearly Discontinuous  Functions",
    "abstract": "Comments: Accepted to the 4th annual Learning for Dynamics and Control (L4DC) Conference, to be published in Proceedings of Machine Learning Research (PMLR). 23 pages, 3 figures",
    "descriptor": "\nComments: Accepted to the 4th annual Learning for Dynamics and Control (L4DC) Conference, to be published in Proceedings of Machine Learning Research (PMLR). 23 pages, 3 figures\n",
    "authors": [
      "Bibit Bianchini",
      "Mathew Halm",
      "Nikolai Matni",
      "Michael Posa"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2112.06881"
  },
  {
    "id": "arXiv:2112.07225",
    "title": "Margin Calibration for Long-Tailed Visual Recognition",
    "abstract": "Comments: Technical report; 9 pages",
    "descriptor": "\nComments: Technical report; 9 pages\n",
    "authors": [
      "Yidong Wang",
      "Bowen Zhang",
      "Wenxin Hou",
      "Zhen Wu",
      "Jindong Wang",
      "Takahiro Shinozaki",
      "Tao Qin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.07225"
  },
  {
    "id": "arXiv:2112.07305",
    "title": "An unfitted finite element method using level set functions for  extrapolation into deformable diffuse interfaces",
    "abstract": "An unfitted finite element method using level set functions for  extrapolation into deformable diffuse interfaces",
    "descriptor": "",
    "authors": [
      "Dmitri Kuzmin",
      "Jan-Phillip B\u00e4cker"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2112.07305"
  },
  {
    "id": "arXiv:2112.07535",
    "title": "Scientific Discovery and the Cost of Measurement -- Balancing  Information and Cost in Reinforcement Learning",
    "abstract": "Comments: To appear in: 1st Annual AAAI Workshop on AI to Accelerate Science and Engineering (AI2ASE)",
    "descriptor": "\nComments: To appear in: 1st Annual AAAI Workshop on AI to Accelerate Science and Engineering (AI2ASE)\n",
    "authors": [
      "Colin Bellinger",
      "Andriy Drozdyuk",
      "Mark Crowley",
      "Isaac Tamblyn"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.07535"
  },
  {
    "id": "arXiv:2112.08884",
    "title": "Skeleton Abstraction for Universal Temporal Properties",
    "abstract": "Skeleton Abstraction for Universal Temporal Properties",
    "descriptor": "",
    "authors": [
      "Sophie Wallner",
      "Karsten Wolf"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2112.08884"
  },
  {
    "id": "arXiv:2112.09873",
    "title": "An effective coaxiality measurement for twist drill based on line  structured light sensor",
    "abstract": "Comments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible.13 pages, 22 figures",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible.13 pages, 22 figures\n",
    "authors": [
      "Ailing Cheng",
      "Jiaojiao Ye",
      "Fei Yang",
      "Shufang Lu",
      "Fei Gao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.09873"
  },
  {
    "id": "arXiv:2112.10043",
    "title": "Reconfigurable Intelligent Surface for Physical Layer Key Generation:  Constructive or Destructive?",
    "abstract": "Comments: 7 pages, 5 figures",
    "descriptor": "\nComments: 7 pages, 5 figures\n",
    "authors": [
      "Guyue Li",
      "Lei Hu",
      "Paul Staat",
      "Harald Elders-Boll",
      "Christian Zenger",
      "Christof Paar",
      "Aiqun Hu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2112.10043"
  },
  {
    "id": "arXiv:2112.10646",
    "title": "Raw High-Definition Radar for Multi-Task Learning",
    "abstract": "Comments: 12 pages, 7 figures, 6 tables",
    "descriptor": "\nComments: 12 pages, 7 figures, 6 tables\n",
    "authors": [
      "Julien Rebut",
      "Arthur Ouaknine",
      "Waqas Malik",
      "Patrick P\u00e9rez"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2112.10646"
  },
  {
    "id": "arXiv:2112.11901",
    "title": "On the stability of multigraded Betti numbers and Hilbert functions",
    "abstract": "Comments: 19 pages, 4 figures; v2: adds section on efficient computability of lower bounds, section on consequences of main results, no-go result (Prop. 4), generalization of Thm. 1 (Thm. 26), and improves exposition",
    "descriptor": "\nComments: 19 pages, 4 figures; v2: adds section on efficient computability of lower bounds, section on consequences of main results, no-go result (Prop. 4), generalization of Thm. 1 (Thm. 26), and improves exposition\n",
    "authors": [
      "Steve Oudot",
      "Luis Scoccola"
    ],
    "subjectives": [
      "Algebraic Topology (math.AT)",
      "Computational Geometry (cs.CG)",
      "Representation Theory (math.RT)"
    ],
    "url": "https://arxiv.org/abs/2112.11901"
  },
  {
    "id": "arXiv:2112.14315",
    "title": "A New Method for Computing Stationary Distribution and Steady-State  Performance Measures of a Continuous-State Markov Chain with a Queuing  Application",
    "abstract": "Comments: 25 pages",
    "descriptor": "\nComments: 25 pages\n",
    "authors": [
      "Shukai Li",
      "Sanjay Mehrotra"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2112.14315"
  },
  {
    "id": "arXiv:2112.14417",
    "title": "Control Theoretic Analysis of Temporal Difference Learning",
    "abstract": "Control Theoretic Analysis of Temporal Difference Learning",
    "descriptor": "",
    "authors": [
      "Donghwan Lee"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.14417"
  },
  {
    "id": "arXiv:2112.14692",
    "title": "Emergence of Cascading Risk and Role of Spatial Locations of Collisions  in Time-Delayed Platoon of Vehicles",
    "abstract": "Comments: Submitted to CDC 2022",
    "descriptor": "\nComments: Submitted to CDC 2022\n",
    "authors": [
      "Guangyi Liu",
      "Christoforos Somarakis",
      "Nader Motee"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.14692"
  },
  {
    "id": "arXiv:2201.03398",
    "title": "Multiplayer Performative Prediction: Learning in Decision-Dependent  Games",
    "abstract": "Multiplayer Performative Prediction: Learning in Decision-Dependent  Games",
    "descriptor": "",
    "authors": [
      "Adhyyan Narang",
      "Evan Faulkner",
      "Dmitriy Drusvyatskiy",
      "Maryam Fazel",
      "Lillian J. Ratliff"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2201.03398"
  },
  {
    "id": "arXiv:2201.06409",
    "title": "Search and Score-based Waterfall Auction Optimization",
    "abstract": "Comments: Published as a conference paper at LION 2022",
    "descriptor": "\nComments: Published as a conference paper at LION 2022\n",
    "authors": [
      "Dan Halbersberg",
      "Matan Halevi",
      "Moshe Salhov"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2201.06409"
  },
  {
    "id": "arXiv:2201.07116",
    "title": "Robust Computation Tree Logic",
    "abstract": "Comments: 23 pages, 1 figure, to be published in the proceedings of NASA Formal Methods (NFM), 2022",
    "descriptor": "\nComments: 23 pages, 1 figure, to be published in the proceedings of NASA Formal Methods (NFM), 2022\n",
    "authors": [
      "Satya Prakash Nayak",
      "Daniel Neider",
      "Rajarshi Roy",
      "Martin Zimmermann"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2201.07116"
  },
  {
    "id": "arXiv:2201.07537",
    "title": "Graph Neural Network-based Android Malware Classification with Jumping  Knowledge",
    "abstract": "Comments: will appear in IEEE Conference on Dependable and Secure Computing 2022",
    "descriptor": "\nComments: will appear in IEEE Conference on Dependable and Secure Computing 2022\n",
    "authors": [
      "Wai Weng Lo",
      "Siamak Layeghy",
      "Mohanad Sarhan",
      "Marcus Gallagher",
      "Marius Portmann"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.07537"
  },
  {
    "id": "arXiv:2201.07736",
    "title": "The Query Complexity of Certification",
    "abstract": "Comments: 30 pages, to appear in STOC'22. Edit: fixed typos and added references",
    "descriptor": "\nComments: 30 pages, to appear in STOC'22. Edit: fixed typos and added references\n",
    "authors": [
      "Guy Blanc",
      "Caleb Koch",
      "Jane Lange",
      "Li-Yang Tan"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2201.07736"
  },
  {
    "id": "arXiv:2201.08877",
    "title": "Variational Autoencoder based Metamodeling for Multi-Objective Topology  Optimization of Electrical Machines",
    "abstract": "Comments: 4 pages, 15 This article will appear in the proceedings of the IEEE transactions on magnetics as a conference paper",
    "descriptor": "\nComments: 4 pages, 15 This article will appear in the proceedings of the IEEE transactions on magnetics as a conference paper\n",
    "authors": [
      "Vivek Parekh",
      "Dominik Flore",
      "Sebastian Sch\u00f6ps"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2201.08877"
  },
  {
    "id": "arXiv:2201.12991",
    "title": "Federated Learning with Erroneous Communication Links",
    "abstract": "Comments: The paper is submitted to IEEE Communications Letters",
    "descriptor": "\nComments: The paper is submitted to IEEE Communications Letters\n",
    "authors": [
      "Mahyar Shirvanimoghaddam",
      "Yifeng Gao",
      "Aradhika Guha",
      "Ayoob Salari"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2201.12991"
  },
  {
    "id": "arXiv:2201.13291",
    "title": "Metrics for saliency map evaluation of deep learning explanation methods",
    "abstract": "Metrics for saliency map evaluation of deep learning explanation methods",
    "descriptor": "",
    "authors": [
      "Tristan Gomez",
      "Thomas Fr\u00e9our",
      "Harold Mouch\u00e8re"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2201.13291"
  },
  {
    "id": "arXiv:2202.01665",
    "title": "On Monte Carlo Tree Search for Weighted Vertex Coloring",
    "abstract": "Comments: 16 pages, 2 tables, 4 plots",
    "descriptor": "\nComments: 16 pages, 2 tables, 4 plots\n",
    "authors": [
      "Cyril Grelier",
      "Olivier Goudet",
      "Jin-Kao Hao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.01665"
  },
  {
    "id": "arXiv:2202.02596",
    "title": "Does elastic stress modify the equilibrium corner angle?",
    "abstract": "Comments: 32 pages, 11 figures",
    "descriptor": "\nComments: 32 pages, 11 figures\n",
    "authors": [
      "Weiqi Wang",
      "Brian J. Spencer"
    ],
    "subjectives": [
      "Analysis of PDEs (math.AP)",
      "Materials Science (cond-mat.mtrl-sci)",
      "Soft Condensed Matter (cond-mat.soft)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.02596"
  },
  {
    "id": "arXiv:2202.04175",
    "title": "Federated Learning of Generative Image Priors for MRI Reconstruction",
    "abstract": "Federated Learning of Generative Image Priors for MRI Reconstruction",
    "descriptor": "",
    "authors": [
      "Gokberk Elmas",
      "Salman UH Dar",
      "Yilmaz Korkmaz",
      "Emir Ceyani",
      "Burak Susam",
      "Muzaffer \u00d6zbey",
      "Salman Avestimehr",
      "Tolga \u00c7ukur"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.04175"
  },
  {
    "id": "arXiv:2202.06934",
    "title": "Slicing Aided Hyper Inference and Fine-tuning for Small Object Detection",
    "abstract": "Comments: Submitted to ICIP 2022, 5 pages, 4 figures, 2 tables",
    "descriptor": "\nComments: Submitted to ICIP 2022, 5 pages, 4 figures, 2 tables\n",
    "authors": [
      "Fatih Cagatay Akyon",
      "Sinan Onur Altinuc",
      "Alptekin Temizel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.06934"
  },
  {
    "id": "arXiv:2202.07073",
    "title": "Discriminability-enforcing loss to improve representation learning",
    "abstract": "Comments: Accepted in CVPR Workshops",
    "descriptor": "\nComments: Accepted in CVPR Workshops\n",
    "authors": [
      "Florinel-Alin Croitoru",
      "Diana-Nicoleta Grigore",
      "Radu Tudor Ionescu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.07073"
  },
  {
    "id": "arXiv:2202.07305",
    "title": "ViNTER: Image Narrative Generation with Emotion-Arc-Aware Transformer",
    "abstract": "ViNTER: Image Narrative Generation with Emotion-Arc-Aware Transformer",
    "descriptor": "",
    "authors": [
      "Kohei Uehara",
      "Yusuke Mori",
      "Yusuke Mukuta",
      "Tatsuya Harada"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.07305"
  },
  {
    "id": "arXiv:2202.08712",
    "title": "Mining On Alzheimer's Diseases Related Knowledge Graph to Identity  Potential AD-related Semantic Triples for Drug Repurposing",
    "abstract": "Comments: Submitted to the BMC Bioinformatics",
    "descriptor": "\nComments: Submitted to the BMC Bioinformatics\n",
    "authors": [
      "Yi Nian",
      "Xinyue Hu",
      "Rui Zhang",
      "Jingna Feng",
      "Jingcheng Du",
      "Fang Li",
      "Yong Chen",
      "Cui Tao"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.08712"
  },
  {
    "id": "arXiv:2202.08771",
    "title": "Realistic Blur Synthesis for Learning Image Deblurring",
    "abstract": "Realistic Blur Synthesis for Learning Image Deblurring",
    "descriptor": "",
    "authors": [
      "Jaesung Rim",
      "Geonung Kim",
      "Jungeon Kim",
      "Junyong Lee",
      "Seungyong Lee",
      "Sunghyun Cho"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.08771"
  },
  {
    "id": "arXiv:2202.09301",
    "title": "Illuminating the Space of Dungeon Maps, Locked-door Missions and Enemy  Placement Through MAP-Elites",
    "abstract": "Comments: 9 pages, 7 figures, submitted to FDG '22",
    "descriptor": "\nComments: 9 pages, 7 figures, submitted to FDG '22\n",
    "authors": [
      "Breno M. F. Viana",
      "Leonardo T. Pereira",
      "Claudio F. M. Toledo"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.09301"
  },
  {
    "id": "arXiv:2202.11200",
    "title": "Quantum Distributed Deep Learning Architectures: Models, Discussions,  and Applications",
    "abstract": "Quantum Distributed Deep Learning Architectures: Models, Discussions,  and Applications",
    "descriptor": "",
    "authors": [
      "Yunseok Kwak",
      "Won Joon Yun",
      "Jae Pyoung Kim",
      "Hyunhee Cho",
      "Minseok Choi",
      "Soyi Jung",
      "Joongheon Kim"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Emerging Technologies (cs.ET)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2202.11200"
  },
  {
    "id": "arXiv:2203.00483",
    "title": "A Survey on How Test Flakiness Affects Developers and What Support They  Need To Address It",
    "abstract": "Comments: 11 pages, to be published in the Proceedings of the IEEE International Conference on Software Testing, Verification and Validation (ICST 2022)",
    "descriptor": "\nComments: 11 pages, to be published in the Proceedings of the IEEE International Conference on Software Testing, Verification and Validation (ICST 2022)\n",
    "authors": [
      "Martin Gruber",
      "Gordon Fraser"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2203.00483"
  },
  {
    "id": "arXiv:2203.02700",
    "title": "ECMG: Exemplar-based Commit Message Generation",
    "abstract": "ECMG: Exemplar-based Commit Message Generation",
    "descriptor": "",
    "authors": [
      "Ensheng Shia",
      "Yanlin Wang",
      "Lun Du",
      "Hongyu Zhang",
      "Shi Han",
      "Dongmei Zhang",
      "Hongbin Sun"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.02700"
  },
  {
    "id": "arXiv:2203.03605",
    "title": "DINO: DETR with Improved DeNoising Anchor Boxes for End-to-End Object  Detection",
    "abstract": "DINO: DETR with Improved DeNoising Anchor Boxes for End-to-End Object  Detection",
    "descriptor": "",
    "authors": [
      "Hao Zhang",
      "Feng Li",
      "Shilong Liu",
      "Lei Zhang",
      "Hang Su",
      "Jun Zhu",
      "Lionel M. Ni",
      "Heung-Yeung Shum"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.03605"
  },
  {
    "id": "arXiv:2203.05551",
    "title": "Cellular automata can classify data by inducing trajectory phase  coexistence",
    "abstract": "Cellular automata can classify data by inducing trajectory phase  coexistence",
    "descriptor": "",
    "authors": [
      "Stephen Whitelam",
      "Isaac Tamblyn"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Statistical Mechanics (cond-mat.stat-mech)"
    ],
    "url": "https://arxiv.org/abs/2203.05551"
  },
  {
    "id": "arXiv:2203.05774",
    "title": "Reinforcement Learning for Linear Quadratic Control is Vulnerable Under  Cost Manipulation",
    "abstract": "Comments: This paper is yet to be peer-reviewed; Typos are corrected in ver 2",
    "descriptor": "\nComments: This paper is yet to be peer-reviewed; Typos are corrected in ver 2\n",
    "authors": [
      "Yunhan Huang",
      "Quanyan Zhu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2203.05774"
  },
  {
    "id": "arXiv:2203.05845",
    "title": "Flexible Amortized Variational Inference in qBOLD MRI",
    "abstract": "Flexible Amortized Variational Inference in qBOLD MRI",
    "descriptor": "",
    "authors": [
      "Ivor J.A. Simpson",
      "Ashley McManamon",
      "Bal\u00e1zs \u00d6rzsik",
      "Alan J. Stone",
      "Nicholas P. Blockley",
      "Iris Asllani",
      "Alessandro Colasanti",
      "Mara Cercignani"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.05845"
  },
  {
    "id": "arXiv:2203.06416",
    "title": "Concentration Network for Reinforcement Learning of Large-Scale  Multi-Agent Systems",
    "abstract": "Comments: AAAI-2022",
    "descriptor": "\nComments: AAAI-2022\n",
    "authors": [
      "Qingxu Fu",
      "Tenghai Qiu",
      "Jianqiang Yi",
      "Zhiqiang Pu",
      "Shiguang Wu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2203.06416"
  },
  {
    "id": "arXiv:2203.06970",
    "title": "Hard Homogeneous Spaces from the Class Field Theory of Imaginary  Hyperelliptic Function Fields",
    "abstract": "Hard Homogeneous Spaces from the Class Field Theory of Imaginary  Hyperelliptic Function Fields",
    "descriptor": "",
    "authors": [
      "Antoine Leudi\u00e8re",
      "Pierre-Jean Spaenlehauer"
    ],
    "subjectives": [
      "Symbolic Computation (cs.SC)",
      "Cryptography and Security (cs.CR)",
      "Number Theory (math.NT)"
    ],
    "url": "https://arxiv.org/abs/2203.06970"
  },
  {
    "id": "arXiv:2203.09475",
    "title": "CaRTS: Causality-driven Robot Tool Segmentation from Vision and  Kinematics Data",
    "abstract": "CaRTS: Causality-driven Robot Tool Segmentation from Vision and  Kinematics Data",
    "descriptor": "",
    "authors": [
      "Hao Ding",
      "Jintan Zhang",
      "Peter Kazanzides",
      "Jie Ying Wu",
      "Mathias Unberath"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.09475"
  },
  {
    "id": "arXiv:2203.10297",
    "title": "Incremental Few-Shot Learning via Implanting and Compressing",
    "abstract": "Incremental Few-Shot Learning via Implanting and Compressing",
    "descriptor": "",
    "authors": [
      "Yiting Li",
      "Haiyue Zhu",
      "Xijia Feng",
      "Zilong Cheng",
      "Jun Ma",
      "Cheng Xiang",
      "Prahlad Vadakkepat",
      "Tong Heng Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.10297"
  },
  {
    "id": "arXiv:2203.12273",
    "title": "DAN: a Segmentation-free Document Attention Network for Handwritten  Document Recognition",
    "abstract": "DAN: a Segmentation-free Document Attention Network for Handwritten  Document Recognition",
    "descriptor": "",
    "authors": [
      "Denis Coquenet",
      "Cl\u00e9ment Chatelain",
      "Thierry Paquet"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.12273"
  },
  {
    "id": "arXiv:2203.12720",
    "title": "Towards Backwards-Compatible Data with Confounded Domain Adaptation",
    "abstract": "Towards Backwards-Compatible Data with Confounded Domain Adaptation",
    "descriptor": "",
    "authors": [
      "Calvin McCarter"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.12720"
  },
  {
    "id": "arXiv:2203.13366",
    "title": "Recommendation as Language Processing (RLP): A Unified Pretrain,  Personalized Prompt & Predict Paradigm (P5)",
    "abstract": "Recommendation as Language Processing (RLP): A Unified Pretrain,  Personalized Prompt & Predict Paradigm (P5)",
    "descriptor": "",
    "authors": [
      "Shijie Geng",
      "Shuchang Liu",
      "Zuohui Fu",
      "Yingqiang Ge",
      "Yongfeng Zhang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.13366"
  },
  {
    "id": "arXiv:2203.13926",
    "title": "CICERO: A Dataset for Contextualized Commonsense Inference in Dialogues",
    "abstract": "Comments: ACL 2022",
    "descriptor": "\nComments: ACL 2022\n",
    "authors": [
      "Deepanway Ghosal",
      "Siqi Shen",
      "Navonil Majumder",
      "Rada Mihalcea",
      "Soujanya Poria"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.13926"
  },
  {
    "id": "arXiv:2203.13948",
    "title": "AI-augmented histopathologic review using image analysis to optimize DNA  yield and tumor purity from FFPE slides",
    "abstract": "AI-augmented histopathologic review using image analysis to optimize DNA  yield and tumor purity from FFPE slides",
    "descriptor": "",
    "authors": [
      "Boles\u0142aw L. Osinski",
      "A\u00efcha BenTaieb",
      "Irvin Ho",
      "Ryan D. Jones",
      "Rohan P. Joshi",
      "Andrew Westley",
      "Michael Carlson",
      "Caleb Willis",
      "Luke Schleicher",
      "Brett M. Mahon",
      "Martin C. Stumpe"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.13948"
  },
  {
    "id": "arXiv:2203.15202",
    "title": "SimT: Handling Open-set Noise for Domain Adaptive Semantic Segmentation",
    "abstract": "Comments: Accepted to CVPR 2022",
    "descriptor": "\nComments: Accepted to CVPR 2022\n",
    "authors": [
      "Xiaoqing Guo",
      "Jie Liu",
      "Tongliang Liu",
      "Yixuan Yuan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.15202"
  },
  {
    "id": "arXiv:2203.15937",
    "title": "Improving Mispronunciation Detection with Wav2vec2-based Momentum  Pseudo-Labeling for Accentedness and Intelligibility Assessment",
    "abstract": "Comments: Submitted to Interspeech 2022",
    "descriptor": "\nComments: Submitted to Interspeech 2022\n",
    "authors": [
      "Mu Yang",
      "Kevin Hirschi",
      "Stephen D. Looney",
      "Okim Kang",
      "John H. L. Hansen"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.15937"
  },
  {
    "id": "arXiv:2203.16005",
    "title": "Deep Joint Source-Channel Coding for CSI Feedback: An End-to-End  Approach",
    "abstract": "Comments: 12 pages, 11 figure",
    "descriptor": "\nComments: 12 pages, 11 figure\n",
    "authors": [
      "Jialong Xu",
      "Bo Ai",
      "Ning Wang",
      "Wei Chen"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2203.16005"
  },
  {
    "id": "arXiv:2203.16063",
    "title": "Pay Attention to Hidden States for Video Deblurring: Ping-Pong Recurrent  Neural Networks and Selective Non-Local Attention",
    "abstract": "Comments: also attached the supplementary material",
    "descriptor": "\nComments: also attached the supplementary material\n",
    "authors": [
      "JoonKyu Park",
      "Seungjun Nah",
      "Kyoung Mu Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.16063"
  },
  {
    "id": "arXiv:2203.16345",
    "title": "An Algebraic Framework for Structured Epidemic Modeling",
    "abstract": "Comments: 38 pages, 8 figures",
    "descriptor": "\nComments: 38 pages, 8 figures\n",
    "authors": [
      "Sophie Libkind",
      "Andrew Baas",
      "Micah Halter",
      "Evan Patterson",
      "James Fairbanks"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2203.16345"
  },
  {
    "id": "arXiv:2203.16995",
    "title": "Message Passing Neural Networks for Hypergraphs",
    "abstract": "Message Passing Neural Networks for Hypergraphs",
    "descriptor": "",
    "authors": [
      "Sajjad Heydari",
      "Lorenzo Livi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.16995"
  },
  {
    "id": "arXiv:2203.17067",
    "title": "CADG: A Model Based on Cross Attention for Domain Generalization",
    "abstract": "CADG: A Model Based on Cross Attention for Domain Generalization",
    "descriptor": "",
    "authors": [
      "Cheng Dai",
      "Fan Li",
      "Xiyao Li",
      "Donglin Xie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.17067"
  },
  {
    "id": "arXiv:2203.17090",
    "title": "PanGu-Bot: Efficient Generative Dialogue Pre-training from Pre-trained  Language Model",
    "abstract": "PanGu-Bot: Efficient Generative Dialogue Pre-training from Pre-trained  Language Model",
    "descriptor": "",
    "authors": [
      "Fei Mi",
      "Yitong Li",
      "Yulong Zeng",
      "Jingyan Zhou",
      "Yasheng Wang",
      "Chuanfei Xu",
      "Lifeng Shang",
      "Xin Jiang",
      "Shiqi Zhao",
      "Qun Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.17090"
  },
  {
    "id": "arXiv:2204.00762",
    "title": "Do learned representations respect causal relationships?",
    "abstract": "Do learned representations respect causal relationships?",
    "descriptor": "",
    "authors": [
      "Lan Wang",
      "Vishnu Naresh Boddeti"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.00762"
  },
  {
    "id": "arXiv:2204.00790",
    "title": "SAD: A Large-scale Dataset towards Airport Detection in Synthetic  Aperture Radar Images",
    "abstract": "SAD: A Large-scale Dataset towards Airport Detection in Synthetic  Aperture Radar Images",
    "descriptor": "",
    "authors": [
      "Daochang Wang",
      "Fan Zhang",
      "Fei Ma",
      "Wei Hu",
      "Yu Tang",
      "Yongsheng Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.00790"
  },
  {
    "id": "arXiv:2204.00840",
    "title": "Rotated Object Detection via Scale-invariant Mahalanobis Distance in  Aerial Images",
    "abstract": "Comments: 5 pages, 7 figures",
    "descriptor": "\nComments: 5 pages, 7 figures\n",
    "authors": [
      "Siyang Wen",
      "Wei Guo",
      "Yi Liu",
      "Ruijie Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.00840"
  },
  {
    "id": "arXiv:2204.00870",
    "title": "Differential Cost Analysis with Simultaneous Potentials and  Anti-potentials",
    "abstract": "Comments: Extended version of the PLDI 2022 paper",
    "descriptor": "\nComments: Extended version of the PLDI 2022 paper\n",
    "authors": [
      "\u0110or\u0111e \u017dikeli\u0107",
      "Bor-Yuh Evan Chang",
      "Pauline Bolignano",
      "Franco Raimondi"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2204.00870"
  },
  {
    "id": "arXiv:2204.00998",
    "title": "AutoOpt: A Methodological Framework of Automatically Designing  Metaheuristics for Optimization Problems",
    "abstract": "AutoOpt: A Methodological Framework of Automatically Designing  Metaheuristics for Optimization Problems",
    "descriptor": "",
    "authors": [
      "Qi Zhao",
      "Bai Yan",
      "Yuhui Shi"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.00998"
  },
  {
    "id": "arXiv:2204.01303",
    "title": "GraFN: Semi-Supervised Node Classification on Graph with Few Labels via  Non-Parametric Distribution Assignment",
    "abstract": "Comments: SIGIR 2022(Short Paper)",
    "descriptor": "\nComments: SIGIR 2022(Short Paper)\n",
    "authors": [
      "Junseok Lee",
      "Yunhak Oh",
      "Yeonjun In",
      "Namkyeong Lee",
      "Dongmin Hyun",
      "Chanyoung Park"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.01303"
  },
  {
    "id": "arXiv:2204.01438",
    "title": "How Can We Develop Explainable Systems? Insights from a Literature  Review and an Interview Study",
    "abstract": "How Can We Develop Explainable Systems? Insights from a Literature  Review and an Interview Study",
    "descriptor": "",
    "authors": [
      "Larissa Chazette",
      "Jil Kl\u00fcnder",
      "Merve Balci",
      "Kurt Schneider"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2204.01438"
  },
  {
    "id": "arXiv:2204.01543",
    "title": "Causality, Causal Discovery, and Causal Inference in Structural  Engineering",
    "abstract": "Causality, Causal Discovery, and Causal Inference in Structural  Engineering",
    "descriptor": "",
    "authors": [
      "M.Z. Naser"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2204.01543"
  },
  {
    "id": "arXiv:2204.01830",
    "title": "WiFiEye -- Seeing over WiFi Made Accessible",
    "abstract": "WiFiEye -- Seeing over WiFi Made Accessible",
    "descriptor": "",
    "authors": [
      "Philipp H. Kindt",
      "Cristian Turetta",
      "Florenc Demrozi",
      "Alejandro Masrur",
      "Graziano Pravadelli",
      "Samarjit Chakraborty"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2204.01830"
  },
  {
    "id": "arXiv:2204.01915",
    "title": "An Exploration of Active Learning for Affective Digital Phenotyping",
    "abstract": "An Exploration of Active Learning for Affective Digital Phenotyping",
    "descriptor": "",
    "authors": [
      "Peter Washington",
      "Cezmi Mutlu",
      "Aaron Kline",
      "Cathy Hou",
      "Kaitlyn Dunlap",
      "Jack Kent",
      "Arman Husic",
      "Nate Stockham",
      "Brianna Chrisman",
      "Kelley Paskov",
      "Jae-Yoon Jung",
      "Dennis P. Wall"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.01915"
  },
  {
    "id": "arXiv:2204.01956",
    "title": "PSDoodle: Fast App Screen Search via Partial Screen Doodle",
    "abstract": "PSDoodle: Fast App Screen Search via Partial Screen Doodle",
    "descriptor": "",
    "authors": [
      "Soumik Mohian",
      "Christoph Csallner"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2204.01956"
  },
  {
    "id": "arXiv:2204.01968",
    "title": "PSDoodle: Searching for App Screens via Interactive Sketching",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:2204.01956",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2204.01956\n",
    "authors": [
      "Soumik Mohian",
      "Christoph Csallner"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2204.01968"
  },
  {
    "id": "arXiv:2204.02128",
    "title": "Computing in Anonymous Dynamic Networks Is Linear",
    "abstract": "Comments: 31 pages, 8 figures",
    "descriptor": "\nComments: 31 pages, 8 figures\n",
    "authors": [
      "Giuseppe A. Di Luna",
      "Giovanni Viglietta"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2204.02128"
  },
  {
    "id": "arXiv:2204.02287",
    "title": "Rethinking Visual Geo-localization for Large-Scale Applications",
    "abstract": "Comments: CVPR 2022",
    "descriptor": "\nComments: CVPR 2022\n",
    "authors": [
      "Gabriele Berton",
      "Carlo Masone",
      "Barbara Caputo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.02287"
  },
  {
    "id": "arXiv:2204.02301",
    "title": "A multiphysics modeling approach for in-stent restenosis: Theoretical  aspects and finite element implementation",
    "abstract": "Comments: 47 pages, 22 figures, 5 tables",
    "descriptor": "\nComments: 47 pages, 22 figures, 5 tables\n",
    "authors": [
      "Kiran Manjunatha",
      "Marek Behr",
      "Felix Vogt",
      "Stefanie Reese"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2204.02301"
  },
  {
    "id": "arXiv:2204.02311",
    "title": "PaLM: Scaling Language Modeling with Pathways",
    "abstract": "PaLM: Scaling Language Modeling with Pathways",
    "descriptor": "",
    "authors": [
      "Aakanksha Chowdhery",
      "Sharan Narang",
      "Jacob Devlin",
      "Maarten Bosma",
      "Gaurav Mishra",
      "Adam Roberts",
      "Paul Barham",
      "Hyung Won Chung",
      "Charles Sutton",
      "Sebastian Gehrmann",
      "Parker Schuh",
      "Kensen Shi",
      "Sasha Tsvyashchenko",
      "Joshua Maynez",
      "Abhishek Rao",
      "Parker Barnes",
      "Yi Tay",
      "Noam Shazeer",
      "Vinodkumar Prabhakaran",
      "Emily Reif",
      "Nan Du",
      "Ben Hutchinson",
      "Reiner Pope",
      "James Bradbury",
      "Jacob Austin",
      "Michael Isard",
      "Guy Gur-Ari",
      "Pengcheng Yin",
      "Toju Duke",
      "Anselm Levskaya",
      "Sanjay Ghemawat",
      "Sunipa Dev",
      "Henryk Michalewski",
      "Xavier Garcia",
      "Vedant Misra",
      "Kevin Robinson",
      "Liam Fedus",
      "Denny Zhou",
      "Daphne Ippolito",
      "David Luan",
      "Hyeontaek Lim",
      "Barret Zoph",
      "Alexander Spiridonov",
      "Ryan Sepassi",
      "David Dohan",
      "Shivani Agrawal",
      "Mark Omernick",
      "Andrew M. Dai",
      "Thanumalayan Sankaranarayana Pillai",
      "Marie Pellat",
      "Aitor Lewkowycz",
      "Erica Moreira"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.02311"
  },
  {
    "id": "arXiv:2204.02524",
    "title": "Simple and Effective Unsupervised Speech Synthesis",
    "abstract": "Comments: preprint, equal contribution from first two authors",
    "descriptor": "\nComments: preprint, equal contribution from first two authors\n",
    "authors": [
      "Alexander H. Liu",
      "Cheng-I Jeff Lai",
      "Wei-Ning Hsu",
      "Michael Auli",
      "Alexei Baevskiv",
      "James Glass"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2204.02524"
  },
  {
    "id": "arXiv:2204.02552",
    "title": "Quantum Approximate Counting for Markov Chains and Application to  Collision Counting",
    "abstract": "Comments: 15 pages; corrected Lemma 4.1",
    "descriptor": "\nComments: 15 pages; corrected Lemma 4.1\n",
    "authors": [
      "Fran\u00e7ois Le Gall",
      "Iu-Iong Ng"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2204.02552"
  },
  {
    "id": "arXiv:2204.02585",
    "title": "SqueezeNeRF: Further factorized FastNeRF for memory-efficient inference",
    "abstract": "Comments: 9 pages, 3 figures, 5 tables. CVPR ECV 2022",
    "descriptor": "\nComments: 9 pages, 3 figures, 5 tables. CVPR ECV 2022\n",
    "authors": [
      "Krishna Wadhwani",
      "Tamaki Kojima"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.02585"
  },
  {
    "id": "arXiv:2204.02611",
    "title": "Cloning Outfits from Real-World Images to 3D Characters for  Generalizable Person Re-Identification",
    "abstract": "Comments: The paper is accepted by CVPR 2022, including the appendix",
    "descriptor": "\nComments: The paper is accepted by CVPR 2022, including the appendix\n",
    "authors": [
      "Yanan Wang",
      "Xuezhi Liang",
      "Shengcai Liao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.02611"
  },
  {
    "id": "arXiv:2204.02663",
    "title": "Towards An End-to-End Framework for Flow-Guided Video Inpainting",
    "abstract": "Comments: Accepted to CVPR 2022",
    "descriptor": "\nComments: Accepted to CVPR 2022\n",
    "authors": [
      "Zhen Li",
      "Cheng-Ze Lu",
      "Jianhua Qin",
      "Chun-Le Guo",
      "Ming-Ming Cheng"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.02663"
  },
  {
    "id": "arXiv:2204.02697",
    "title": "VNIbCReg: VICReg with Neighboring-Invariance and better-Covariance  Evaluated on Non-stationary Seismic Signal Time Series",
    "abstract": "VNIbCReg: VICReg with Neighboring-Invariance and better-Covariance  Evaluated on Non-stationary Seismic Signal Time Series",
    "descriptor": "",
    "authors": [
      "Daesoo Lee",
      "Erlend Aune",
      "Nad\u00e8ge Langet",
      "Jo Eidsvik"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Geophysics (physics.geo-ph)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2204.02697"
  },
  {
    "id": "arXiv:2204.02766",
    "title": "Data-Centric Green AI: An Exploratory Empirical Study",
    "abstract": "Comments: 11 pages, 3 figures, 2 tables. Accepted at the 8th ICT for Sustainability Conference (ICT4S) 2022",
    "descriptor": "\nComments: 11 pages, 3 figures, 2 tables. Accepted at the 8th ICT for Sustainability Conference (ICT4S) 2022\n",
    "authors": [
      "Roberto Verdecchia",
      "Lu\u00eds Cruz",
      "June Sallou",
      "Michelle Lin",
      "James Wickenden",
      "Estelle Hotellier"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2204.02766"
  },
  {
    "id": "arXiv:2204.02810",
    "title": "Expression-preserving face frontalization improves visually assisted  speech processing",
    "abstract": "Expression-preserving face frontalization improves visually assisted  speech processing",
    "descriptor": "",
    "authors": [
      "Zhiqi Kang",
      "Mostafa Sadeghi",
      "Radu Horaud",
      "Xavier Alameda-Pineda"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2204.02810"
  },
  {
    "id": "arXiv:2204.02821",
    "title": "drsphelps at SemEval-2022 Task 2: Learning idiom representations using  BERTRAM",
    "abstract": "drsphelps at SemEval-2022 Task 2: Learning idiom representations using  BERTRAM",
    "descriptor": "",
    "authors": [
      "Dylan Phelps"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.02821"
  },
  {
    "id": "arXiv:2204.02841",
    "title": "Spectral Denoising for Microphone Classification",
    "abstract": "Comments: 8 pages, 10 images, 3 tables, ACM-ICMR conference 2022, MAD 2022 workshop",
    "descriptor": "\nComments: 8 pages, 10 images, 3 tables, ACM-ICMR conference 2022, MAD 2022 workshop\n",
    "authors": [
      "L. Cuccovillo",
      "A. Giganti",
      "P. Bestagini",
      "P. Aichroth",
      "S. Tubaro"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2204.02841"
  },
  {
    "id": "arXiv:2204.02921",
    "title": "A survey on recently proposed activation functions for Deep Learning",
    "abstract": "Comments: 7 pages, 2 figures, 15 cited papers",
    "descriptor": "\nComments: 7 pages, 2 figures, 15 cited papers\n",
    "authors": [
      "Murilo Gustineli"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.02921"
  }
]
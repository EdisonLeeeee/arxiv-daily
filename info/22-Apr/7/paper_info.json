[
  {
    "id": "arXiv:2204.02399",
    "title": "Multi-Modal Hypergraph Diffusion Network with Dual Prior for Alzheimer  Classification",
    "abstract": "The automatic early diagnosis of prodromal stages of Alzheimer's disease is\nof great relevance for patient treatment to improve quality of life. We address\nthis problem as a multi-modal classification task. Multi-modal data provides\nricher and complementary information. However, existing techniques only\nconsider either lower order relations between the data and single/multi-modal\nimaging data. In this work, we introduce a novel semi-supervised hypergraph\nlearning framework for Alzheimer's disease diagnosis. Our framework allows for\nhigher-order relations among multi-modal imaging and non-imaging data whilst\nrequiring a tiny labelled set. Firstly, we introduce a dual embedding strategy\nfor constructing a robust hypergraph that preserves the data semantics. We\nachieve this by enforcing perturbation invariance at the image and graph levels\nusing a contrastive based mechanism. Secondly, we present a dynamically\nadjusted hypergraph diffusion model, via a semi-explicit flow, to improve the\npredictive uncertainty. We demonstrate, through our experiments, that our\nframework is able to outperform current techniques for Alzheimer's disease\ndiagnosis.",
    "descriptor": "",
    "authors": [
      "Angelica I. Aviles-Rivero",
      "Christina Runkel",
      "Nicolas Papadakis",
      "Zoe Kourtzi",
      "Carola-Bibiane Sch\u00f6nlieb"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2204.02399"
  },
  {
    "id": "arXiv:2204.02400",
    "title": "What can predictive speech coders learn from speaker recognizers?",
    "abstract": "This paper compares the speech coder and speaker recognizer applications,\nshowing some parallelism between them. In this paper, some approaches used for\nspeaker recognition are applied to speech coding in order to improve the\nprediction accuracy. Experimental results show an improvement in Segmental SNR\n(SEGSNR).",
    "descriptor": "\nComments: 7 pages, published in ITRW on Non-Linear Speech Processing (NOLISP 03), May 20-23, 2003, Le Croisic, France, paper 001. arXiv admin note: text overlap with arXiv:2204.02101\n",
    "authors": [
      "Marcos Faundez-Zanuy"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2204.02400"
  },
  {
    "id": "arXiv:2204.02402",
    "title": "Comment on \"Black Box Prediction Methods in Sports Medicine Deserve a  Red Card for Reckless Practice: A Change of Tactics is Needed to Advance  Athlete Care\"",
    "abstract": "In this paper we examine the claims made by Bullock et. al. on the\napplicability of black-box injury risk approaches in the sports injury domain.\nOverall, we agree that transparency is necessary for Machine Learning models to\nbe useful in this field. However, there are areas of research that address\nprecisely the concerns of the authors and strongly temper their conclusions. In\nthe following we look at how these issues are being tackled by the Machine\nLearning community.",
    "descriptor": "",
    "authors": [
      "Jakim Berndsen",
      "Derek McHugh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.02402"
  },
  {
    "id": "arXiv:2204.02411",
    "title": "Texturify: Generating Textures on 3D Shape Surfaces",
    "abstract": "Texture cues on 3D objects are key to compelling visual representations, with\nthe possibility to create high visual fidelity with inherent spatial\nconsistency across different views. Since the availability of textured 3D\nshapes remains very limited, learning a 3D-supervised data-driven method that\npredicts a texture based on the 3D input is very challenging. We thus propose\nTexturify, a GAN-based method that leverages a 3D shape dataset of an object\nclass and learns to reproduce the distribution of appearances observed in real\nimages by generating high-quality textures. In particular, our method does not\nrequire any 3D color supervision or correspondence between shape geometry and\nimages to learn the texturing of 3D objects. Texturify operates directly on the\nsurface of the 3D objects by introducing face convolutional operators on a\nhierarchical 4-RoSy parametrization to generate plausible object-specific\ntextures. Employing differentiable rendering and adversarial losses that\ncritique individual views and consistency across views, we effectively learn\nthe high-quality surface texturing distribution from real-world images.\nExperiments on car and chair shape collections show that our approach\noutperforms state of the art by an average of 22% in FID score.",
    "descriptor": "\nComments: Project Page: this https URL\n",
    "authors": [
      "Yawar Siddiqui",
      "Justus Thies",
      "Fangchang Ma",
      "Qi Shan",
      "Matthias Nie\u00dfner",
      "Angela Dai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2204.02411"
  },
  {
    "id": "arXiv:2204.02415",
    "title": "Non-Binary Polar Codes for Spread-Spectrum Modulations",
    "abstract": "This paper proposes a new coded modulation scheme for reliable transmission\nof short data packets at very low signal-to-noise ratio, combining cyclic code\nshift keying modulation and non-binary polar coding. We consider non-binary\npolar codes defined over Galois fields, and propose a new design methodology,\naimed at optimizing the choice of the kernel coefficients. Numerical results\nshow that the system performance is close to the achievable limits in the\nfinite blocklength regime.",
    "descriptor": "",
    "authors": [
      "Valentin Savin"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2204.02415"
  },
  {
    "id": "arXiv:2204.02426",
    "title": "OccamNets: Mitigating Dataset Bias by Favoring Simpler Hypotheses",
    "abstract": "Dataset bias and spurious correlations can significantly impair\ngeneralization in deep neural networks. Many prior efforts have addressed this\nproblem using either alternative loss functions or sampling strategies that\nfocus on rare patterns. We propose a new direction: modifying the network\narchitecture to impose inductive biases that make the network robust to dataset\nbias. Specifically, we propose OccamNets, which are biased to favor simpler\nsolutions by design. OccamNets have two inductive biases. First, they are\nbiased to use as little network depth as needed for an individual example.\nSecond, they are biased toward using fewer image locations for prediction.\nWhile OccamNets are biased toward simpler hypotheses, they can learn more\ncomplex hypotheses if necessary. In experiments, OccamNets outperform or rival\nstate-of-the-art methods run on architectures that do not incorporate these\ninductive biases. Furthermore, we demonstrate that when the state-of-the-art\ndebiasing methods are combined with OccamNets results further improve.",
    "descriptor": "",
    "authors": [
      "Robik Shrestha",
      "Kushal Kafle",
      "Christopher Kanan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.02426"
  },
  {
    "id": "arXiv:2204.02437",
    "title": "AAAI SSS-22 Symposium on Closing the Assessment Loop: Communicating  Proficiency and Intent in Human-Robot Teaming",
    "abstract": "The proposed symposium focuses understanding, modeling, and improving the\nefficacy of (a) communicating proficiency from human to robot and (b)\ncommunicating intent from a human to a robot. For example, how should a robot\nconvey predicted ability on a new task? How should it report performance on a\ntask that was just completed? How should a robot adapt its proficiency criteria\nbased on human intentions and values?\nCommunities in AI, robotics, HRI, and cognitive science have addressed\nrelated questions, but there are no agreed upon standards for evaluating\nproficiency and intent-based interactions. This is a pressing challenge for\nhuman-robot interaction for a variety of reasons. Prior work has shown that a\nrobot that can assess its performance can alter human perception of the robot\nand decisions on control allocation. There is also significant evidence in\nrobotics that accurately setting human expectations is critical, especially\nwhen proficiency is below human expectations. Moreover, proficiency assessment\ndepends on context and intent, and a human teammate might increase or decrease\nperformance standards, adapt tolerance for risk and uncertainty, demand\npredictive assessments that affect attention allocation, or otherwise reassess\nor adapt intent.",
    "descriptor": "",
    "authors": [
      "Michael Goodrich",
      "Jacob Crandall",
      "Aaron Steinfeld",
      "Holly Yanco"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.02437"
  },
  {
    "id": "arXiv:2204.02441",
    "title": "Imaging Conductivity from Current Density Magnitude using Neural  Networks",
    "abstract": "Conductivity imaging represents one of the most important tasks in medical\nimaging. In this work we develop a neural network based reconstruction\ntechnique for imaging the conductivity from the magnitude of the internal\ncurrent density. It is achieved by formulating the problem as a relaxed\nweighted least-gradient problem, and then approximating its minimizer by\nstandard fully connected feedforward neural networks. We derive bounds on two\ncomponents of the generalization error, i.e., approximation error and\nstatistical error, explicitly in terms of properties of the neural networks\n(e.g., depth, total number of parameters, and the bound of the network\nparameters). We illustrate the performance and distinct features of the\napproach on several numerical experiments. Numerically, it is observed that the\napproach enjoys remarkable robustness with respect to the presence of data\nnoise.",
    "descriptor": "\nComments: 29 pp, 9 figures\n",
    "authors": [
      "Bangti Jin",
      "Xiyao Li",
      "Xiliang Lu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2204.02441"
  },
  {
    "id": "arXiv:2204.02443",
    "title": "Efficient Table-based Function Approximation on FPGAs using Interval  Splitting and BRAM Instantiation",
    "abstract": "This paper proposes a novel approach for the generation of memory-efficient\ntable-based function approximation circuits for FPGAs. Given a function f(x) to\nbe approximated in a given interval [x0,x0+a] and a maximum approximation error\nEa, the goal is to determine a function table implementation with a minimized\nmemory footprint, i.e., number of entries that need to be stored. Rather than\nstate-of-the-art work performing an even sampling of the given interval by\nso-called breakpoints and using linear interpolation between two adjacent\nbreakpoints to determine f(x) at the maximum error bound, first, we propose\nthree interval-splitting algorithms to reduce the required memory footprint\ndrastically based on the observation that in sub-intervals of low gradient, a\ncoarser sampling grid may be assumed to satisfy the maximum interpolation error\nbound. Experiments on elementary mathematical functions show that a large\nfraction in memory footprint may be saved. Second, a hardware architecture\nimplementing the sub-interval selection, breakpoint lookup and interpolation at\na latency of just 9 clock cycles is introduced. Third, within each generated\ncircuit design, BRAMs are automatically instantiated rather than synthesizing\nthe reduced footprint function table using LUT primitives providing an\nadditional degree of resource efficiency.",
    "descriptor": "\nComments: 23 pages\n",
    "authors": [
      "Chetana Pradhan",
      "Martin Letras",
      "J\u00fcrgen Teich"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2204.02443"
  },
  {
    "id": "arXiv:2204.02445",
    "title": "CHORE: Contact, Human and Object REconstruction from a single RGB image",
    "abstract": "While most works in computer vision and learning have focused on perceiving\n3D humans from single images in isolation, in this work we focus on capturing\n3D humans interacting with objects. The problem is extremely challenging due to\nheavy occlusions between human and object, diverse interaction types and depth\nambiguity. In this paper, we introduce CHORE, a novel method that learns to\njointly reconstruct human and object from a single image. CHORE takes\ninspiration from recent advances in implicit surface learning and classical\nmodel-based fitting. We compute a neural reconstruction of human and object\nrepresented implicitly with two unsigned distance fields, and additionally\npredict a correspondence field to a parametric body as well as an object pose\nfield. This allows us to robustly fit a parametric body model and a 3D object\ntemplate, while reasoning about interactions. Furthermore, prior pixel-aligned\nimplicit learning methods use synthetic data and make assumptions that are not\nmet in real data. We propose a simple yet effective depth-aware scaling that\nallows more efficient shape learning on real data. Our experiments show that\nour joint reconstruction learned with the proposed strategy significantly\noutperforms the SOTA. Our code and models will be released to foster future\nresearch in this direction.",
    "descriptor": "\nComments: 19 pages, 7 figures\n",
    "authors": [
      "Xianghui Xie",
      "Bharat Lal Bhatnagar",
      "Gerard Pons-Moll"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.02445"
  },
  {
    "id": "arXiv:2204.02446",
    "title": "Detecting Cloud-Based Phishing Attacks by Combining Deep Learning Models",
    "abstract": "Web-based phishing attacks nowadays exploit popular cloud web hosting\nservices and apps such as Google Sites and Typeform for hosting their attacks.\nSince these attacks originate from reputable domains and IP addresses of the\ncloud services, traditional phishing detection methods such as IP reputation\nmonitoring and blacklisting are not very effective. Here we investigate the\neffectiveness of deep learning models in detecting this class of cloud-based\nphishing attacks. Specifically, we evaluate deep learning models for three\nphishing detection methods--LSTM model for URL analysis, YOLOv2 model for logo\nanalysis, and triplet network model for visual similarity analysis. We train\nthe models using well-known datasets and test their performance on phishing\nattacks in the wild. Our results qualitatively explain why the models succeed\nor fail. Furthermore, our results highlight how combining results from the\nindividual models can improve the effectiveness of detecting cloud-based\nphishing attacks.",
    "descriptor": "",
    "authors": [
      "Medha Atre",
      "Birendra Jha",
      "Ashwini Rao"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.02446"
  },
  {
    "id": "arXiv:2204.02448",
    "title": "Predicting and Explaining Mobile UI Tappability with Vision Modeling and  Saliency Analysis",
    "abstract": "We use a deep learning based approach to predict whether a selected element\nin a mobile UI screenshot will be perceived by users as tappable, based on\npixels only instead of view hierarchies required by previous work. To help\ndesigners better understand model predictions and to provide more actionable\ndesign feedback than predictions alone, we additionally use ML interpretability\ntechniques to help explain the output of our model. We use XRAI to highlight\nareas in the input screenshot that most strongly influence the tappability\nprediction for the selected region, and use k-Nearest Neighbors to present the\nmost similar mobile UIs from the dataset with opposing influences on\ntappability perception.",
    "descriptor": "\nComments: CHI'22\n",
    "authors": [
      "Eldon Schoop",
      "Xin Zhou",
      "Gang Li",
      "Zhourong Chen",
      "Bj\u00f6rn Hartmann",
      "Yang Li"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.02448"
  },
  {
    "id": "arXiv:2204.02453",
    "title": "A Comprehensive Framework based on Dynamic and Steady State Analysis to  Evaluate Power System Resiliency to Extreme Weather Conditions",
    "abstract": "Power system robustness against high impact low probability events is\nbecoming a major concern. To depict distinct phases of a system response during\nthese disturbances, an irregular polygon model is derived from the conventional\ntrapezoid model and the model is analytically investigated for transmission\nsystem performance, based on which resiliency metrics are developed for the\nsame. Furthermore, the system resiliency to windstorm is evaluated on the IEEE\nreliability test system (RTS) by performing steady state and dynamic security\nassessment incorporating protection modelling and corrective action schemes\nusing the software Power System Simulator for Engineering (PSS/E). Based on the\nresults of steady state and dynamic analysis, modified resiliency metrics are\nquantified. Finally, this paper quantifies the interdependency of operational\nand infrastructure resiliency as they cannot be considered as discrete\ncharacteristics of the system.",
    "descriptor": "\nComments: 8 pages\n",
    "authors": [
      "Giritharan Vijay Iswaran",
      "Ramin Vakili",
      "Mojdeh Khorsand"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2204.02453"
  },
  {
    "id": "arXiv:2204.02455",
    "title": "Improving Voice Trigger Detection with Metric Learning",
    "abstract": "Voice trigger detection is an important task, which enables activating a\nvoice assistant when a target user speaks a keyword phrase. A detector is\ntypically trained on speech data independent of speaker information and used\nfor the voice trigger detection task. However, such a speaker independent voice\ntrigger detector typically suffers from performance degradation on speech from\nunderrepresented groups, such as accented speakers. In this work, we propose a\nnovel voice trigger detector that can use a small number of utterances from a\ntarget speaker to improve detection accuracy. Our proposed model employs an\nencoder-decoder architecture. While the encoder performs speaker independent\nvoice trigger detection, similar to the conventional detector, the decoder\npredicts a personalized embedding for each utterance. A personalized voice\ntrigger score is then obtained as a similarity score between the embeddings of\nenrollment utterances and a test utterance. The personalized embedding allows\nadapting to target speaker's speech when computing the voice trigger score,\nhence improving voice trigger detection accuracy. Experimental results show\nthat the proposed approach achieves a 38% relative reduction in a false\nrejection rate (FRR) compared to a baseline speaker independent voice trigger\nmodel.",
    "descriptor": "\nComments: Submitted to InterSpeech 2022\n",
    "authors": [
      "Prateeth Nayak",
      "Takuya Higuchi",
      "Anmol Gupta",
      "Shivesh Ranjan",
      "Stephen Shum",
      "Siddharth Sigtia",
      "Erik Marchi",
      "Varun Lakshminarasimhan",
      "Minsik Cho",
      "Saurabh Adya",
      "Chandra Dhir",
      "Ahmed Tewfik"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2204.02455"
  },
  {
    "id": "arXiv:2204.02458",
    "title": "Robust Active Visual Perching with Quadrotors on Inclined Surfaces",
    "abstract": "Autonomous Micro Aerial Vehicles are deployed for a variety tasks including\nsurveillance and monitoring. Perching and staring allow the vehicle to monitor\ntargets without flying, saving battery power and increasing the overall mission\ntime without the need to frequently replace batteries. This paper addresses the\nActive Visual Perching (AVP) control problem to autonomously perch on inclined\nsurfaces up to $90^\\circ$. Our approach generates dynamically feasible\ntrajectories to navigate and perch on a desired target location, while taking\ninto account actuator and Field of View (FoV) constraints. By replanning in\nmid-flight, we take advantage of more accurate target localization increasing\nthe perching maneuver's robustness to target localization or control errors. We\nleverage the Karush-Kuhn-Tucker (KKT) conditions to identify the compatibility\nbetween planning objectives and the visual sensing constraint during the\nplanned maneuver. Furthermore, we experimentally identify the corresponding\nboundary conditions that maximizes the spatio-temporal target visibility during\nthe perching maneuver. The proposed approach works on-board in real-time with\nsignificant computational constraints relying exclusively on cameras and an\nInertial Measurement Unit (IMU). Experimental results validate the proposed\napproach and shows the higher success rate as well as increased target\ninterception precision and accuracy with respect to a one-shot planning\napproach, while still retaining aggressive capabilities with flight envelopes\nthat include large excursions from the hover position on inclined surfaces up\nto 90$^\\circ$, angular speeds up to 750~deg/s, and accelerations up to\n10~m/s$^2$.",
    "descriptor": "",
    "authors": [
      "Jeffrey Mao",
      "Stephen Nogar",
      "Christopher Kroninger",
      "Giuseppe Loianno"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2204.02458"
  },
  {
    "id": "arXiv:2204.02460",
    "title": "Electrostatic Brakes Enable Individual Joint Control of Underactuated,  Highly Articulated Robots",
    "abstract": "Highly articulated organisms serve as blueprints for incredibly dexterous\nmechanisms, but building similarly capable robotic counterparts has been\nhindered by the difficulties of developing electromechanical actuators with\nboth the high strength and compactness of biological muscle. We develop a\nstackable electrostatic brake that has comparable specific tension and weight\nto that of muscles and integrate it into a robotic joint. Compared to\nelectromechanical motors, our brake-equipped joint is four times lighter and\none thousand times more power efficient while exerting similar holding torques.\nOur joint design enables a ten degree-of-freedom robot equipped with only one\nmotor to manipulate multiple objects simultaneously. We also show that the use\nof brakes allows a two-fingered robot to perform in-hand re-positioning of an\nobject 45% more quickly and with 53% lower positioning error than without\nbrakes. Relative to fully actuated robots, our findings suggest that robots\nequipped with such electrostatic brakes will have lower weight, volume, and\npower consumption yet retain the ability to reach arbitrary joint\nconfigurations.",
    "descriptor": "\nComments: 17 pages, 15 figures\n",
    "authors": [
      "Patrick Lancaster",
      "Christoforos Mavrogiannis",
      "Siddhartha Srinivasa",
      "Joshua Smith"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2204.02460"
  },
  {
    "id": "arXiv:2204.02461",
    "title": "Less is More: Fairness in Wide-Area Proof-of-Work Blockchain Networks",
    "abstract": "Blockchain is rapidly emerging as an important class of network application,\nwith a unique set of trust, security and transparency properties. In a\nblockchain system, participants record and update the `server-side' state of an\napplication as blocks of a replicated, immutable ledger using a consensus\nprotocol over the Internet. Mining blocks has become lucrative in recent years;\ne.g., a miner receives over USD 200,000 per mined block in Bitcoin today. A key\nfactor affecting mining rewards, is the latency of broadcasting blocks over the\nnetwork. In this paper, we consider the problem of topology design for\noptimizing mining rewards in a wide-area blockchain network that uses a\nProof-of-Work protocol for consensus. Contrary to general wisdom that a faster\nnetwork is always better for miners, we show a counter intuitive result where a\nslower network is actually beneficial to some miners. This is because competing\nminers must choose neighbors that not only decrease their own latency to\nothers, but also ensure that the latency between other miners do not decrease\nbecause of itself. We formalize this problem, and provide both theoretical\nanalysis and experimental results to support our claim.",
    "descriptor": "",
    "authors": [
      "Yifan Mao",
      "Shaileshh Bojja Venkatakrishnan"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2204.02461"
  },
  {
    "id": "arXiv:2204.02462",
    "title": "Quadratic Approximation Manifold for Mitigating the Kolmogorov Barrier  in Nonlinear Projection-Based Model Order Reduction",
    "abstract": "A quadratic approximation manifold is presented for performing nonlinear,\nprojection-based, model order reduction (PMOR). It constitutes a departure from\nthe traditional affine subspace approximation that is aimed at mitigating the\nKolmogorov barrier for nonlinear PMOR, particularly for convection-dominated\ntransport problems. It builds on the data-driven approach underlying the\ntraditional construction of projection-based reduced-order models (PROMs); is\napplication-independent; is linearization-free; and therefore is robust for\nhighly nonlinear problems. Most importantly, this approximation leads to\nquadratic PROMs that deliver the same accuracy as their traditional\ncounterparts using however a much smaller dimension -- typically, $n_2 \\sim\n\\sqrt n_1$, where $n_2$ and $n_1$ denote the dimensions of the quadratic and\ntraditional PROMs, respectively. The computational advantages of the proposed\nhigh-order approach to nonlinear PMOR over the traditional approach are\nhighlighted for the detached-eddy simulation-based prediction of the Ahmed body\nturbulent wake flow, which is a popular CFD benchmark problem in the automotive\nindustry. For a fixed accuracy level, these advantages include: a reduction of\nthe total offline computational cost by a factor greater than five; a reduction\nof its online wall clock time by a factor greater than 32; and a reduction of\nthe wall clock time of the underlying high-dimensional model by a factor\ngreater than two orders of magnitude.",
    "descriptor": "",
    "authors": [
      "Joshua Barnett",
      "Charbel Farhat"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2204.02462"
  },
  {
    "id": "arXiv:2204.02464",
    "title": "BeeTS: Smart Distributed Sensor Tuple Spaces combined with Agents using  Bluetooth and IP Broadcasting",
    "abstract": "Most Internet-of-Things (IoT) devices and smart sensors are connected via the\nInternet using IP communication driectly accessed by a server that collect\nsensor information periodically or event-based. Although, Internet access is\nwidely available, there are places that are not covered and WLAN and mobile\ncell communication requires a descent amount of power not always available.\nFinally, the spatial context (the environment in which the sensor or devices is\nsituated) is not considered (or lost) by Internet connectivity. In this work,\nsmart devices communicate connectionless and ad-hoc by using low-energy\nBluetooth broadcasting available in any smartphone and in most embedded\ncomputers, e.g., the Raspberry PI devices. Bi-directional connectionless\ncommunication is established via the advertisements and scanning modes. The\ncommunication nodes can exchange data via functional tuples using a tuple space\nservice on each node. Tuple space access is performed by simple evenat-based\nagents. Mobile devices act as tuple carriers that can carry tuples between\ndifferent locations. Additionally, UDP-based Intranet communication can be used\nto access tuple spaces on a wider spatial range. The Bluetooth Low Energy Tuple\nSpace (BeeTS) service enables opportunistic, ad-hoc and loosely coupled device\ncommunication with a spatial context.",
    "descriptor": "",
    "authors": [
      "Stefan Bosse"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.02464"
  },
  {
    "id": "arXiv:2204.02467",
    "title": "The Extended and Asymmetric Extended Krylov Subspace in  Moment-Matching-Based Order Reduction of Large Circuit Models",
    "abstract": "The rapid growth of circuit complexity has rendered Model Order Reduction\n(MOR) a key enabler for the efficient simulation of large circuit models. MOR\ntechniques based on moment-matching are well established due to their\nsimplicity and computational performance in the reduction process. However,\nmoment-matching methods based on the ordinary Krylov subspace are usually\ninadequate to accurately approximate the original circuit behavior, and at the\nsame time do not produce reduced-order models as compact as needed. In this\npaper, we present a moment-matching method which utilizes the extended and the\nasymmetric extended Krylov subspace (EKS and AEKS), while it allows the\nparallel computation of the transfer function in order to deal with circuits\nthat have many terminals. The proposed method can handle large-scale regular\nand singular circuits and generate accurate and efficient reduced-order models\nfor circuit simulation. Experimental results on industrial IBM power grids\ndemonstrate that the EKS method can achieve an error reduction up to 85.28%\nover a standard Krylov subspace method, while the AEKS method greatly reduces\nthe runtime of EKS, introducing a negligible overhead in the reduction error.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2007.01948\n",
    "authors": [
      "Pavlos Stoikos",
      "Dimitrios Garyfallou",
      "George Floros",
      "Nestor Evmorfopoulos",
      "George Stamoulis"
    ],
    "subjectives": [
      "Other Computer Science (cs.OH)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2204.02467"
  },
  {
    "id": "arXiv:2204.02470",
    "title": "Combining Spectral and Self-Supervised Features for Low Resource Speech  Recognition and Translation",
    "abstract": "Self-Supervised Learning (SSL) models have been successfully applied in\nvarious deep learning-based speech tasks, particularly those with a limited\namount of data. However, the quality of SSL representations depends highly on\nthe relatedness between the SSL training domain(s) and the target data domain.\nOn the contrary, spectral feature (SF) extractors such as log Mel-filterbanks\nare hand-crafted non-learnable components, and could be more robust to domain\nshifts. The present work examines the assumption that combining non-learnable\nSF extractors to SSL models is an effective approach to low resource speech\ntasks. We propose a learnable and interpretable framework to combine SF and SSL\nrepresentations. The proposed framework outperforms significantly both baseline\nand SSL models on Automatic Speech Recognition (ASR) and Speech Translation\n(ST) tasks on three low resource datasets. We additionally design a mixture of\nexperts based combination model. This last model reveals that the relative\ncontribution of SSL models over conventional SF extractors is very small in\ncase of domain mismatch between SSL training set and the target language data.",
    "descriptor": "\nComments: 5 pages, 2 figures, submitted to Interspeech 2022\n",
    "authors": [
      "Dan Berrebbi",
      "Jiatong Shi",
      "Brian Yan",
      "Osbel Lopez-Francisco",
      "Jonathan D. Amith",
      "Shinji Watanabe"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2204.02470"
  },
  {
    "id": "arXiv:2204.02471",
    "title": "Configuration Path Control",
    "abstract": "Reinforcement learning methods often produce brittle policies -- policies\nthat perform well during training, but generalize poorly beyond their direct\ntraining experience, thus becoming unstable under small disturbances. To\naddress this issue, we propose a method for stabilizing a control policy in the\nspace of configuration paths. It is applied post-training and relies purely on\nthe data produced during training, as well as on an instantaneous\ncontrol-matrix estimation. The approach is evaluated empirically on a planar\nbipedal walker subjected to a variety of perturbations. The control policies\nobtained via reinforcement learning are compared against their stabilized\ncounterparts. Across different experiments, we find two- to four-fold increase\nin stability, when measured in terms of the perturbation amplitudes. We also\nprovide a zero-dynamics interpretation of our approach.",
    "descriptor": "\nComments: 12 pages, 3 figures, accepted for publication\n",
    "authors": [
      "Sergey Pankov"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2204.02471"
  },
  {
    "id": "arXiv:2204.02472",
    "title": "Equivalence of coupled parametric oscillator dynamics to Lagrange  multiplier primal-dual optimization",
    "abstract": "There has been a recent surge of interest in physics-based solvers for\ncombinatorial optimization problems. We present a dynamical solver for the\nIsing problem that is comprised of a network of coupled parametric oscillators\nand show that it implements Lagrange multiplier constrained optimization. We\nshow that the pump depletion effect, which is intrinsic to parametric\noscillators, enforces binary constraints and enables the system's continuous\nanalog variables to converge to the optimal binary solutions to the\noptimization problem. Moreover, there is an exact correspondence between the\nequations of motion for the coupled oscillators and the update rules in the\nprimal-dual method of Lagrange multipliers. Though our analysis is performed\nusing electrical LC oscillators, it can be generalized to any system of coupled\nparametric oscillators. We simulate the dynamics of the coupled oscillator\nsystem and demonstrate that the performance of the solver on a set of benchmark\nproblems is comparable to the best-known results obtained by digital algorithms\nin the literature.",
    "descriptor": "",
    "authors": [
      "Sri Krishna Vadlamani",
      "Tianyao Patrick Xiao",
      "Eli Yablonovitch"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2204.02472"
  },
  {
    "id": "arXiv:2204.02473",
    "title": "\"Does it come in black?\" CLIP-like models are zero-shot recommenders",
    "abstract": "Product discovery is a crucial component for online shopping. However,\nitem-to-item recommendations today do not allow users to explore changes along\nselected dimensions: given a query item, can a model suggest something similar\nbut in a different color? We consider item recommendations of the comparative\nnature (e.g. \"something darker\") and show how CLIP-based models can support\nthis use case in a zero-shot manner. Leveraging a large model built for\nfashion, we introduce GradREC and its industry potential, and offer a first\nrounded assessment of its strength and weaknesses.",
    "descriptor": "\nComments: Pre-print. Accepted ACL 2022 (ECNLP)\n",
    "authors": [
      "Patrick John Chia",
      "Jacopo Tagliabue",
      "Federico Bianchi",
      "Ciro Greco",
      "Diogo Goncalves"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.02473"
  },
  {
    "id": "arXiv:2204.02475",
    "title": "Artificial SA-I, RA-I and RA-II/Vibrotactile Afferents for Tactile  Sensing of Texture",
    "abstract": "Robot touch can benefit from how humans perceive tactile textural\ninformation, from the stimulation mode to which tactile channels respond, then\nthe tactile cues and encoding. Using a soft biomimetic tactile sensor (the\nTacTip) based on the physiology of the dermal-epidermal boundary, we construct\ntwo biomimetic tactile channels based on slowly-adapting SA-I and\nrapidly-adapting RA-I afferents, and introduce an additional sub-modality for\nvibrotactile information with an embedded microphone interpreted as an\nartificial RA-II channel. These artificial tactile channels are stimulated\ndynamically with a set of 13 artificial rigid textures comprising raised-bump\npatterns on a rotating drum that vary systematically in roughness. Methods\nemploying spatial, spatio-temporal and temporal codes are assessed for texture\nclassification insensitive to stimulation speed. We find: (i) spatially-encoded\nfrictional cues provide a salient representation of texture; (ii) a simple\ntransformation of spatial tactile features to model natural afferent responses\nimproves the temporal coding; and (iii) the harmonic structure of induced\nvibrations provides a pertinent code for speed-invariant texture\nclassification. Just as human touch relies on an interplay between\nslowly-adapting (SA-I), rapidly-adapting (RA-I) and vibrotactile (RA-II)\nchannels, this tripartite structure may be needed for future robot applications\nwith human-like dexterity, from prosthetics to materials testing, handling and\nmanipulation.",
    "descriptor": "",
    "authors": [
      "Nicholas Pestell",
      "Nathan F. Lepora"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2204.02475"
  },
  {
    "id": "arXiv:2204.02481",
    "title": "Adversarial Robustness through the Lens of Convolutional Filters",
    "abstract": "Deep learning models are intrinsically sensitive to distribution shifts in\nthe input data. In particular, small, barely perceivable perturbations to the\ninput data can force models to make wrong predictions with high confidence. An\ncommon defense mechanism is regularization through adversarial training which\ninjects worst-case perturbations back into training to strengthen the decision\nboundaries, and to reduce overfitting. In this context, we perform an\ninvestigation of 3x3 convolution filters that form in adversarially-trained\nmodels. Filters are extracted from 71 public models of the linf-RobustBench\nCIFAR-10/100 and ImageNet1k leaderboard and compared to filters extracted from\nmodels built on the same architectures but trained without robust\nregularization. We observe that adversarially-robust models appear to form more\ndiverse, less sparse, and more orthogonal convolution filters than their normal\ncounterparts. The largest differences between robust and normal models are\nfound in the deepest layers, and the very first convolution layer, which\nconsistently and predominantly forms filters that can partially eliminate\nperturbations, irrespective of the architecture. Data & Project website:\nhttps://github.com/paulgavrikov/cvpr22w_RobustnessThroughTheLens",
    "descriptor": "\nComments: Accepted at the CVPR 2022 \"The Art of Robustness\" Workshop\n",
    "authors": [
      "Paul Gavrikov",
      "Janis Keuper"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.02481"
  },
  {
    "id": "arXiv:2204.02482",
    "title": "PDNPulse: Sensing PCB Anomaly with the Intrinsic Power Delivery Network",
    "abstract": "The ubiquitous presence of printed circuit boards (PCBs) in modern electronic\nsystems and embedded devices makes their integrity a top security concern. To\ntake advantage of the economies of scale, today's PCB design and manufacturing\nare often performed by suppliers around the globe, exposing them to many\nsecurity vulnerabilities along the segmented PCB supply chain. Moreover, the\nincreasing complexity of the PCB designs also leaves ample room for numerous\nsneaky board-level attacks to be implemented throughout each stage of a PCB's\nlifetime, threatening many electronic devices. In this paper, we propose\nPDNPulse, a power delivery network (PDN) based PCB anomaly detection framework\nthat can identify a wide spectrum of board-level malicious modifications.\nPDNPulse leverages the fact that the PDN's characteristics are inevitably\naffected by modifications to the PCB, no matter how minuscule. By detecting\nchanges to the PDN impedance profile and using the Frechet distance-based\nanomaly detection algorithms, PDNPulse can robustly and successfully discern\nmalicious modifications across the system. Using PDNPulse, we conduct extensive\nexperiments on seven commercial-off-the-shelf PCBs, covering different design\nscales, different threat models, and seven different anomaly types. The results\nconfirm that PDNPulse creates an effective security asymmetry between attack\nand defense.",
    "descriptor": "",
    "authors": [
      "Huifeng Zhu",
      "Haoqi Shan",
      "Dean Sullivan",
      "Xiaolong Guo",
      "Yier Jin",
      "Xuan Zhang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2204.02482"
  },
  {
    "id": "arXiv:2204.02483",
    "title": "Considerations for Multilingual Wikipedia Research",
    "abstract": "English Wikipedia has long been an important data source for much research\nand natural language machine learning modeling. The growth of non-English\nlanguage editions of Wikipedia, greater computational resources, and calls for\nequity in the performance of language and multimodal models have led to the\ninclusion of many more language editions of Wikipedia in datasets and models.\nBuilding better multilingual and multimodal models requires more than just\naccess to expanded datasets; it also requires a better understanding of what is\nin the data and how this content was generated. This paper seeks to provide\nsome background to help researchers think about what differences might arise\nbetween different language editions of Wikipedia and how that might affect\ntheir models. It details three major ways in which content differences between\nlanguage editions arise (local context, community and governance, and\ntechnology) and recommendations for good practices when using multilingual and\nmultimodal data for research and modeling.",
    "descriptor": "\nComments: Accepted to Wiki-M3L workshop as part of ICLR 2022\n",
    "authors": [
      "Isaac Johnson",
      "Emily Lescak"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.02483"
  },
  {
    "id": "arXiv:2204.02484",
    "title": "From implicit learning to explicit representations",
    "abstract": "Using the reservoir computing framework, we demonstrate how a simple model\ncan solve an alternation task without an explicit working memory. To do so, a\nsimple bot equipped with sensors navigates inside a 8-shaped maze and turns\nalternatively right and left at the same intersection in the maze. The analysis\nof the model's internal activity reveals that the memory is actually encoded\ninside the dynamics of the network. However, such dynamic working memory is not\naccessible such as to bias the behavior into one of the two attractors (left\nand right). To do so, external cues are fed to the bot such that it can follow\narbitrary sequences, instructed by the cue. This model highlights the idea that\nprocedural learning and its internal representation can be dissociated. If the\nformer allows to produce behavior, it is not sufficient to allow for an\nexplicit and fine-grained manipulation.",
    "descriptor": "\nComments: 6 pages, 7 figures, conference\n",
    "authors": [
      "Naomi Chaix-Eichel",
      "Snigdha Dagar",
      "Quentin Lanneau",
      "Karen Sobriel",
      "Thomas Boraud",
      "Fr\u00e9d\u00e9ric Alexandre",
      "Nicolas P. Rougier"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2204.02484"
  },
  {
    "id": "arXiv:2204.02485",
    "title": "Training-Free Robust Multimodal Learning via Sample-Wise Jacobian  Regularization",
    "abstract": "Multimodal fusion emerges as an appealing technique to improve model\nperformances on many tasks. Nevertheless, the robustness of such fusion methods\nis rarely involved in the present literature. In this paper, we propose a\ntraining-free robust late-fusion method by exploiting conditional independence\nassumption and Jacobian regularization. Our key is to minimize the Frobenius\nnorm of a Jacobian matrix, where the resulting optimization problem is relaxed\nto a tractable Sylvester equation. Furthermore, we provide a theoretical error\nbound of our method and some insights about the function of the extra modality.\nSeveral numerical experiments on AV-MNIST, RAVDESS, and VGGsound demonstrate\nthe efficacy of our method under both adversarial attacks and random\ncorruptions.",
    "descriptor": "",
    "authors": [
      "Zhengqi Gao",
      "Sucheng Ren",
      "Zihui Xue",
      "Siting Li",
      "Hang Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2204.02485"
  },
  {
    "id": "arXiv:2204.02488",
    "title": "Discovering and forecasting extreme events via active learning in neural  operators",
    "abstract": "Extreme events in society and nature, such as pandemic spikes or rogue waves,\ncan have catastrophic consequences. Characterizing extremes is difficult as\nthey occur rarely, arise from seemingly benign conditions, and belong to\ncomplex and often unknown infinite-dimensional systems. Such challenges render\nattempts at characterizing them as moot. We address each of these difficulties\nby combining novel training schemes in Bayesian experimental design (BED) with\nan ensemble of deep neural operators (DNOs). This model-agnostic framework\npairs a BED scheme that actively selects data for quantifying extreme events\nwith an ensemble of DNOs that approximate infinite-dimensional nonlinear\noperators. We find that not only does this framework clearly beat Gaussian\nprocesses (GPs) but that 1) shallow ensembles of just two members perform best;\n2) extremes are uncovered regardless of the state of initial data (i.e. with or\nwithout extremes); 3) our method eliminates \"double-descent\" phenomena; 4) the\nuse of batches of suboptimal acquisition points compared to step-by-step global\noptima does not hinder BED performance; and 5) Monte Carlo acquisition\noutperforms standard minimizers in high-dimensions. Together these conclusions\nform the foundation of an AI-assisted experimental infrastructure that can\nefficiently infer and pinpoint critical situations across many domains, from\nphysical to societal systems.",
    "descriptor": "\nComments: 19 pages, 7 figures, Submitted to Nature Computational Science\n",
    "authors": [
      "Ethan Pickering",
      "George Em Karniadakis",
      "Themistoklis P. Sapsis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Chaotic Dynamics (nlin.CD)",
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2204.02488"
  },
  {
    "id": "arXiv:2204.02489",
    "title": "Pareto-optimal clustering with the primal deterministic information  bottleneck",
    "abstract": "At the heart of both lossy compression and clustering is a trade-off between\nthe fidelity and size of the learned representation. Our goal is to map out and\nstudy the Pareto frontier that quantifies this trade-off. We focus on the\nDeterministic Information Bottleneck (DIB) formulation of lossy compression,\nwhich can be interpreted as a clustering problem. To this end, we introduce the\n{\\it primal} DIB problem, which we show results in a much richer frontier than\nits previously studied dual counterpart. We present an algorithm for mapping\nout the Pareto frontier of the primal DIB trade-off that is also applicable to\nmost other two-objective clustering problems. We study general properties of\nthe Pareto frontier, and give both analytic and numerical evidence for\nlogarithmic sparsity of the frontier in general. We provide evidence that our\nalgorithm has polynomial scaling despite the super-exponential search space;\nand additionally propose a modification to the algorithm that can be used where\nsampling noise is expected to be significant. Finally, we use our algorithm to\nmap the DIB frontier of three different tasks: compressing the English\nalphabet, extracting informative color classes from natural images, and\ncompressing a group theory inspired dataset, revealing interesting features of\nfrontier, and demonstrating how the structure of the frontier can be used for\nmodel selection with a focus on points previously hidden by the cloak of the\nconvex hull.",
    "descriptor": "\nComments: 26 pages, 11 figures\n",
    "authors": [
      "Andrew K. Tan",
      "Max Tegmark",
      "Isaac L. Chuang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2204.02489"
  },
  {
    "id": "arXiv:2204.02491",
    "title": "Text2LIVE: Text-Driven Layered Image and Video Editing",
    "abstract": "We present a method for zero-shot, text-driven appearance manipulation in\nnatural images and videos. Given an input image or video and a target text\nprompt, our goal is to edit the appearance of existing objects (e.g., object's\ntexture) or augment the scene with visual effects (e.g., smoke, fire) in a\nsemantically meaningful manner. We train a generator using an internal dataset\nof training examples, extracted from a single input (image or video and target\ntext prompt), while leveraging an external pre-trained CLIP model to establish\nour losses. Rather than directly generating the edited output, our key idea is\nto generate an edit layer (color+opacity) that is composited over the original\ninput. This allows us to constrain the generation process and maintain high\nfidelity to the original input via novel text-driven losses that are applied\ndirectly to the edit layer. Our method neither relies on a pre-trained\ngenerator nor requires user-provided edit masks. We demonstrate localized,\nsemantic edits on high-resolution natural images and videos across a variety of\nobjects and scenes.",
    "descriptor": "\nComments: Project page: this https URL\n",
    "authors": [
      "Omer Bar-Tal",
      "Dolev Ofri-Amar",
      "Rafail Fridman",
      "Yoni Kasten",
      "Tali Dekel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.02491"
  },
  {
    "id": "arXiv:2204.02492",
    "title": "Towards End-to-end Unsupervised Speech Recognition",
    "abstract": "Unsupervised speech recognition has shown great potential to make Automatic\nSpeech Recognition (ASR) systems accessible to every language. However,\nexisting methods still heavily rely on hand-crafted pre-processing. Similar to\nthe trend of making supervised speech recognition end-to-end, we introduce\n\\wvu~which does away with all audio-side pre-processing and improves accuracy\nthrough better architecture. In addition, we introduce an auxiliary\nself-supervised objective that ties model predictions back to the input.\nExperiments show that \\wvu~improves unsupervised recognition results across\ndifferent languages while being conceptually simpler.",
    "descriptor": "\nComments: Preprint\n",
    "authors": [
      "Alexander H. Liu",
      "Wei-Ning Hsu",
      "Michael Auli",
      "Alexei Baevski"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2204.02492"
  },
  {
    "id": "arXiv:2204.02494",
    "title": "Leveraging Disentangled Representations to Improve Vision-Based  Keystroke Inference Attacks Under Low Data",
    "abstract": "Keystroke inference attacks are a form of side-channel attacks in which an\nattacker leverages various techniques to recover a user's keystrokes as she\ninputs information into some display (e.g., while sending a text message or\nentering her pin). Typically, these attacks leverage machine learning\napproaches, but assessing the realism of the threat space has lagged behind the\npace of machine learning advancements, due in-part, to the challenges in\ncurating large real-life datasets. We aim to overcome the challenge of having\nlimited number of real data by introducing a video domain adaptation technique\nthat is able to leverage synthetic data through supervised disentangled\nlearning. Specifically, for a given domain, we decompose the observed data into\ntwo factors of variation: Style and Content. Doing so provides four learned\nrepresentations: real-life style, synthetic style, real-life content and\nsynthetic content. Then, we combine them into feature representations from all\ncombinations of style-content pairings across domains, and train a model on\nthese combined representations to classify the content (i.e., labels) of a\ngiven datapoint in the style of another domain. We evaluate our method on\nreal-life data using a variety of metrics to quantify the amount of information\nan attacker is able to recover. We show that our method prevents our model from\noverfitting to a small real-life training set, indicating that our method is an\neffective form of data augmentation, thereby making keystroke inference attacks\nmore practical.",
    "descriptor": "",
    "authors": [
      "John Lim",
      "Jan-Michael Frahm",
      "Fabian Monrose"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2204.02494"
  },
  {
    "id": "arXiv:2204.02495",
    "title": "Efficient Pragmatic Program Synthesis with Informative Specifications",
    "abstract": "Providing examples is one of the most common way for end-users to interact\nwith program synthesizers. However, program synthesis systems assume that\nexamples consistent with the program are chosen at random, and do not exploit\nthe fact that users choose examples pragmatically. Prior work modeled program\nsynthesis as pragmatic communication, but required an inefficient enumeration\nof the entire program space. In this paper, we show that it is possible to\nbuild a program synthesizer that is both pragmatic and efficient by\napproximating the joint distribution of programs with a product of independent\nfactors, and performing pragmatic inference on each factor separately. This\nfactored distribution approximates the exact joint distribution well when the\nexamples are given pragmatically, and is compatible with a basic neuro-symbolic\nprogram synthesis algorithm. Surprisingly, we find that the synthesizer\nassuming a factored approximation performs better than a synthesizer assuming\nan exact joint distribution when evaluated on natural human inputs. This\nsuggests that humans may be assuming a factored distribution while\ncommunicating programs.",
    "descriptor": "\nComments: 9 pages, Meaning in Context Workshop 2021\n",
    "authors": [
      "Saujas Vaduguru",
      "Kevin Ellis",
      "Yewen Pu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.02495"
  },
  {
    "id": "arXiv:2204.02497",
    "title": "Privacy-Preserving Federated Learning via System Immersion and Random  Matrix Encryption",
    "abstract": "Federated learning (FL) has emerged as a privacy solution for collaborative\ndistributed learning where clients train AI models directly on their devices\ninstead of sharing their data with a centralized (potentially adversarial)\nserver. Although FL preserves local data privacy to some extent, it has been\nshown that information about clients' data can still be inferred from model\nupdates. In recent years, various privacy-preserving schemes have been\ndeveloped to address this privacy leakage. However, they often provide privacy\nat the expense of model performance or system efficiency and balancing these\ntradeoffs is a crucial challenge when implementing FL schemes. In this\nmanuscript, we propose a Privacy-Preserving Federated Learning (PPFL) framework\nbuilt on the synergy of matrix encryption and system immersion tools from\ncontrol theory. The idea is to immerse the learning algorithm, a Stochastic\nGradient Decent (SGD), into a higher-dimensional system (the so-called target\nsystem) and design the dynamics of the target system so that: the trajectories\nof the original SGD are immersed/embedded in its trajectories, and it learns on\nencrypted data (here we use random matrix encryption). Matrix encryption is\nreformulated at the server as a random change of coordinates that maps original\nparameters to a higher-dimensional parameter space and enforces that the target\nSGD converges to an encrypted version of the original SGD optimal solution. The\nserver decrypts the aggregated model using the left inverse of the immersion\nmap. We show that our algorithm provides the same level of accuracy and\nconvergence rate as the standard FL with a negligible computation cost while\nrevealing no information about the clients' data.",
    "descriptor": "",
    "authors": [
      "Haleh Hayati",
      "Carlos Murguia",
      "Nathan van de Wouw"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2204.02497"
  },
  {
    "id": "arXiv:2204.02498",
    "title": "On the Sustainability of Lightweight Cryptography Based on PUFs  Implemented on NAND Flash Memories Using Programming Disturbances",
    "abstract": "In this work, we examine the potential of Physical Unclonable Functions\n(PUFs) that have been implemented on NAND Flash memories using programming\ndisturbances to act as sustainable primitives for the purposes of lightweight\ncryptography. In particular, we investigate the ability of such PUFs to\ntolerate temperature and voltage variations, and examine the current\nshortcomings of existing NAND-Flash-memory PUFs that are based on programming\ndisturbances as well as how these could potentially be addressed in order to\nprovide more robust and more sustainable security solutions.",
    "descriptor": "\nComments: This work was accepted for and presented at the Workshop on Sustainability in Security, Security for Sustainability, which took place on 18 March 2022 and was co-located with the 25th Design, Automation and Test in Europe Conference & Exhibition (DATE 2022)\n",
    "authors": [
      "Nikolaos Athanasios Anagnostopoulos",
      "Yufan Fan",
      "Muhammad Umair Saleem",
      "Nico Mexis",
      "Florian Frank",
      "Tolga Arul",
      "Stefan Katzenbeisser"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2204.02498"
  },
  {
    "id": "arXiv:2204.02500",
    "title": "User-Level Differential Privacy against Attribute Inference Attack of  Speech Emotion Recognition in Federated Learning",
    "abstract": "Many existing privacy-enhanced speech emotion recognition (SER) frameworks\nfocus on perturbing the original speech data through adversarial training\nwithin a centralized machine learning setup. However, this privacy protection\nscheme can fail since the adversary can still access the perturbed data. In\nrecent years, distributed learning algorithms, especially federated learning\n(FL), have gained popularity to protect privacy in machine learning\napplications. While FL provides good intuition to safeguard privacy by keeping\nthe data on local devices, prior work has shown that privacy attacks, such as\nattribute inference attacks, are achievable for SER systems trained using FL.\nIn this work, we propose to evaluate the user-level differential privacy (UDP)\nin mitigating the privacy leaks of the SER system in FL. UDP provides\ntheoretical privacy guarantees with privacy parameters $\\epsilon$ and $\\delta$.\nOur results show that the UDP can effectively decrease attribute information\nleakage while keeping the utility of the SER system with the adversary\naccessing one model update. However, the efficacy of the UDP suffers when the\nFL system leaks more model updates to the adversary. We make the code publicly\navailable to reproduce the results in\nhttps://github.com/usc-sail/fed-ser-leakage.",
    "descriptor": "",
    "authors": [
      "Tiantian Feng",
      "Raghuveer Peri",
      "Shrikanth Narayanan"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2204.02500"
  },
  {
    "id": "arXiv:2204.02504",
    "title": "Recursive Restoration Refinement: A Fast Heuristic for Near-Optimal  Restoration Prioritization in Power Systems",
    "abstract": "The prioritization of restoration actions after large power system outages\nplays a key role in how quickly power can be restored. It has been shown that\nfast and intuitive heuristics for restoration prioritization most often result\nin low-quality restoration plans. Meanwhile, mathematical optimization tools\nthat find high-quality restoration plans are too slow to be applied to\nrestoration planning problems of practical interest. This work makes a\nsignificant step in closing this quality vs compute time gap by proposing the\nRecursive Restoration Refinement heuristic for power system restoration. This\nheuristic is shown to produce near-optimal restoration plans up to 1,000 times\nfaster than other state-of-the-art solution methods on a range of test cases\nwith up to 500 buses and 700 damaged components. The potential impact of this\nnew heuristic is demonstrated by a preliminary analysis of the key features of\nhigh-quality restoration plans. The recursive restoration refinement algorithm\nand other methods explored in this work have been made available as part of the\nopen-source software package, PowerModelsRestoration, to support ongoing\nresearch in power restoration algorithms.",
    "descriptor": "",
    "authors": [
      "Noah Rhodes",
      "Carleton Coffrin",
      "Line Roald"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2204.02504"
  },
  {
    "id": "arXiv:2204.02506",
    "title": "Deep Graphic FBSDEs for Opinion Dynamics Stochastic Control",
    "abstract": "In this paper, we present a scalable deep learning approach to solve opinion\ndynamics stochastic optimal control problems with mean field term coupling in\nthe dynamics and cost function. Our approach relies on the probabilistic\nrepresentation of the solution of the Hamilton-Jacobi-Bellman partial\ndifferential equation. Grounded on the nonlinear version of the Feynman-Kac\nlemma, the solutions of the Hamilton-Jacobi-Bellman partial differential\nequation are linked to the solution of Forward-Backward Stochastic Differential\nEquations. These equations can be solved numerically using a novel deep neural\nnetwork with architecture tailored to the problem in consideration. The\nresulting algorithm is tested on a polarized opinion consensus experiment. The\nlarge-scale (10K) agents experiment validates the scalability and\ngeneralizability of our algorithm. The proposed framework opens up the\npossibility for future applications on extremely large-scale problems.",
    "descriptor": "",
    "authors": [
      "Tianrong Chen",
      "Ziyi Wang",
      "Evangelos A. Theodorou"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.02506"
  },
  {
    "id": "arXiv:2204.02507",
    "title": "Co-optimization of power line shutoff and restoration for electric grids  under high wildfire ignition risk",
    "abstract": "Electric power infrastructure has ignited several of the most destructive\nwildfires in recent history. Preemptive power shut-offs are an effective tool\nto mitigate the risk of ignitions from power lines, but at the same time can\ncause widespread power outages. Electric utilities are thus faced with the\nchallenging trade-off of where and when to implement these shut-offs, as well\nas how to most efficiently restore power once the wildfire risk is reduced.\nThis work proposes a mathematical optimization problem to help utilities make\nthese decisions. Our model co-optimizes the power shut-off (considering both\nwildfire risk reduction and power outages) as well as the post-event inspection\nand energization of lines. It is implemented as a rolling horizon optimization\nproblem that is resolved whenever new forecasts of load and wildfire risk\nbecome available. We demonstrate our method on the IEEE RTS-GMLC test case\nusing real wildfire risk data US Geological Survey, and investigate the\nsensitivity of the results to the forecast quality, decision horizon and system\nrestoration budget. The software implementation is available in the open source\nsoftware package PowerModelsWildfire.jl.",
    "descriptor": "",
    "authors": [
      "Noah Rhodes",
      "Line Roald"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2204.02507"
  },
  {
    "id": "arXiv:2204.02509",
    "title": "Depth-Guided Sparse Structure-from-Motion for Movies and TV Shows",
    "abstract": "Existing approaches for Structure from Motion (SfM) produce impressive 3-D\nreconstruction results especially when using imagery captured with large\nparallax. However, to create engaging video-content in movies and TV shows, the\namount by which a camera can be moved while filming a particular shot is often\nlimited. The resulting small-motion parallax between video frames makes\nstandard geometry-based SfM approaches not as effective for movies and TV\nshows. To address this challenge, we propose a simple yet effective approach\nthat uses single-frame depth-prior obtained from a pretrained network to\nsignificantly improve geometry-based SfM for our small-parallax setting. To\nthis end, we first use the depth-estimates of the detected keypoints to\nreconstruct the point cloud and camera-pose for initial two-view\nreconstruction. We then perform depth-regularized optimization to register new\nimages and triangulate the new points during incremental reconstruction. To\ncomprehensively evaluate our approach, we introduce a new dataset (StudioSfM)\nconsisting of 130 shots with 21K frames from 15 studio-produced videos that are\nmanually annotated by a professional CG studio. We demonstrate that our\napproach: (a) significantly improves the quality of 3-D reconstruction for our\nsmall-parallax setting, (b) does not cause any degradation for data with\nlarge-parallax, and (c) maintains the generalizability and scalability of\ngeometry-based sparse SfM. Our dataset can be obtained at\nhttps://github.com/amazon-research/small-baseline-camera-tracking.",
    "descriptor": "",
    "authors": [
      "Sheng Liu",
      "Xiaohan Nie",
      "Raffay Hamid"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.02509"
  },
  {
    "id": "arXiv:2204.02515",
    "title": "Inferring Rewards from Language in Context",
    "abstract": "In classic instruction following, language like \"I'd like the JetBlue flight\"\nmaps to actions (e.g., selecting that flight). However, language also conveys\ninformation about a user's underlying reward function (e.g., a general\npreference for JetBlue), which can allow a model to carry out desirable actions\nin new contexts. We present a model that infers rewards from language\npragmatically: reasoning about how speakers choose utterances not only to\nelicit desired actions, but also to reveal information about their preferences.\nOn a new interactive flight-booking task with natural language, our model more\naccurately infers rewards and predicts optimal actions in unseen environments,\nin comparison to past work that first maps language to actions (instruction\nfollowing) and then maps actions to rewards (inverse reinforcement learning).",
    "descriptor": "\nComments: ACL 2022. Code and dataset: this https URL\n",
    "authors": [
      "Jessy Lin",
      "Daniel Fried",
      "Dan Klein",
      "Anca Dragan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.02515"
  },
  {
    "id": "arXiv:2204.02519",
    "title": "Maintaining Expander Decompositions via Sparse Cuts",
    "abstract": "In this article, we show that the algorithm of maintaining expander\ndecompositions in graphs undergoing edge deletions directly by removing sparse\ncuts repeatedly can be made efficient.\nFormally, for an $m$-edge undirected graph $G$, we say a cut $(S, \\bar{S})$\nis $\\phi$-sparse if $|E_G(S, \\bar{S})| < \\phi \\cdot \\min\\{vol_G(S),\nvol_G(\\bar{S})\\}$. A $\\phi$-expander decomposition of $G$ is a partition of $V$\ninto sets $X_1, X_2, \\ldots, X_k$ such that each cluster $G[X_i]$ contains no\n$\\phi$-sparse cut (meaning it is a $\\phi$-expander) with $\\tilde{O}(\\phi m)$\nedges crossing between clusters. A natural way to compute a $\\phi$-expander\ndecomposition is to decompose clusters by $\\phi$-sparse cuts until no such cut\nis contained in any cluster. We show that even in graphs undergoing edge\ndeletions, a slight relaxation of this meta-algorithm can be implemented\nefficiently with amortized update time $m^{o(1)}/\\phi^2$.\nOur approach naturally extends to maintaining directed $\\phi$-expander\ndecompositions and $\\phi$-expander hierarchies and thus gives a unifying\nframework while having simpler proofs than previous state-of-the-art work. In\nall settings, our algorithm matches the run-times of previous algorithms up to\nsubpolynomial factors. Moreover, our algorithm provides stronger guarantees for\n$\\phi$-expander decompositions, for example, for graphs undergoing edge\ndeletions, our approach achieves the first sublinear $\\phi m^{o(1)}$ recourse\nbounds on the number of edges to become crossing between clusters.\nOur techniques also give by far the simplest, deterministic algorithms for\nmaintaining Strongly-Connected Components (SCCs) in directed graphs undergoing\nedge deletions, and for maintaining connectivity in undirected fully-dynamic\ngraphs, both matching the current state-of-the-art run-times up to\nsubpolynomial factors.",
    "descriptor": "",
    "authors": [
      "Yiding Hua",
      "Rasmus Kyng",
      "Maximilian Probst Gutenberg",
      "Zihang Wu"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2204.02519"
  },
  {
    "id": "arXiv:2204.02521",
    "title": "Service resource allocation problem in the IoT driven personalized  healthcare information platform",
    "abstract": "With real-time monitoring of the personalized healthcare condition, the IoT\nwearables collect the health data and transfer it to the healthcare information\nplatform. The platform processes the data into healthcare recommendations and\nthen delivers them to the users. The IoT structures in the personalized\nhealthcare information service allows the users to engage in the loop in\nservitization more convenient in the COVID-19 pandemic. However, the\nuncertainty of the engagement behavior among the individual may result in\ninefficient of the service resource allocation. This paper seeks an efficient\nway to allocate the service resource by controlling the service capacity and\npushing the service to the active users automatically. In this study, we\npropose a deep reinforcement learning method to solve the service resource\nallocation problem based on the proximal policy optimization (PPO) algorithm.\nExperimental results using the real world (open source) sport dataset reveal\nthat our proposed proximal policy optimization adapts well to the users'\nchanging behavior and with improved performance over fixed service resource\npolicies.",
    "descriptor": "",
    "authors": [
      "Ji Fang",
      "Vincent CS Lee",
      "Haiyan Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2204.02521"
  },
  {
    "id": "arXiv:2204.02522",
    "title": "Solving integer multi-objective optimization problems using TOPSIS,  Differential Evolution and Tabu Search",
    "abstract": "This paper presents a method to solve non-linear integer multiobjective\noptimization problems. First the problem is formulated using the Technique for\nOrder Preference by Similarity to Ideal Solution (TOPSIS). Next, the\nDifferential Evolution (DE) algorithm in its three versions (standard DE, DE\nbest and DEGL) are used as optimizer. Since the solutions found by the DE\nalgorithms are continuous, the Tabu Search (TS) algorithm is employed to find\ninteger solutions during the optimization process. Experimental results show\nthe effectiveness of the proposed method.",
    "descriptor": "\nComments: 8 pages\n",
    "authors": [
      "Renato A. Krohling",
      "Erick R. F. A. Schneider"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2204.02522"
  },
  {
    "id": "arXiv:2204.02524",
    "title": "Simple and Effective Unsupervised Speech Synthesis",
    "abstract": "We introduce the first unsupervised speech synthesis system based on a\nsimple, yet effective recipe. The framework leverages recent work in\nunsupervised speech recognition as well as existing neural-based speech\nsynthesis. Using only unlabeled speech audio and unlabeled text as well as a\nlexicon, our method enables speech synthesis without the need for a\nhuman-labeled corpus. Experiments demonstrate the unsupervised system can\nsynthesize speech similar to a supervised counterpart in terms of naturalness\nand intelligibility measured by human evaluation.",
    "descriptor": "\nComments: preprint, equal contribution from first two authors\n",
    "authors": [
      "Alexander H. Liu",
      "Cheng-I Jeff Lai",
      "Wei-Ning Hsu",
      "Michael Auli",
      "Alexei Baevskiv",
      "James Glass"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2204.02524"
  },
  {
    "id": "arXiv:2204.02525",
    "title": "Mars: Near-Optimal Throughput with Shallow Buffers in Reconfigurable  Datacenter Networks",
    "abstract": "The performance of large-scale computing systems often critically depends on\nhigh-performance communication networks. Dynamically reconfigurable topologies,\ne.g., based on optical circuit switches, are emerging as an innovative new\ntechnology to deal with the explosive growth of datacenter traffic.\nSpecifically, periodic reconfigurable datacenter networks (RDCNs) such as\nRotorNet (SIGCOMM 2017), Opera (NSDI 2020) and Sirius (SIGCOMM 2020) have been\nshown to provide high throughput, by emulating a complete graph through fast\nperiodic circuit switch scheduling.\nHowever, to achieve such a high throughput, existing reconfigurable network\ndesigns pay a high price: in terms of potentially high delays, but also, as we\nshow as a first contribution in this paper, in terms of the high buffer\nrequirements. In particular, we show that under buffer constraints, emulating\nthe high-throughput complete-graph is infeasible at scale, and we uncover a\nspectrum of unvisited and attractive alternative RDCNs, which emulate regular\ngraphs of lower node degree.\nWe present Mars, a periodic reconfigurable topology which emulates a\n$d$-regular graph with near-optimal throughput. In particular, we\nsystematically analyze how the degree $d$ can be optimized for throughput given\nthe available buffer and delay tolerance of the datacenter.",
    "descriptor": "",
    "authors": [
      "Vamsi Addanki",
      "Chen Avin",
      "Stefan Schmid"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2204.02525"
  },
  {
    "id": "arXiv:2204.02526",
    "title": "Emphasis on the Minimization of False Negatives or False Positives in  Binary Classification",
    "abstract": "The minimization of specific cases in binary classification, such as false\nnegatives or false positives, grows increasingly important as humans begin to\nimplement more machine learning into current products. While there are a few\nmethods to put a bias towards the reduction of specific cases, these methods\naren't very effective, hence their minimal use in models. To this end, a new\nmethod is introduced to reduce the False Negatives or False positives without\ndrastically changing the overall performance or F1 score of the model. This\nmethod involving the careful change to the real value of the input after\npre-training the model. Presenting the results of this method being applied on\nvarious datasets, some being more complex than others. Through experimentation\non multiple model architectures on these datasets, the best model was found. In\nall the models, an increase in the recall or precision, minimization of False\nNegatives or False Positives respectively, was shown without a large drop in F1\nscore.",
    "descriptor": "\nComments: 5 pages, 6 figures\n",
    "authors": [
      "Sanskriti Singh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.02526"
  },
  {
    "id": "arXiv:2204.02530",
    "title": "Prosodic Alignment for off-screen automatic dubbing",
    "abstract": "The goal of automatic dubbing is to perform speech-to-speech translation\nwhile achieving audiovisual coherence. This entails isochrony, i.e.,\ntranslating the original speech by also matching its prosodic structure into\nphrases and pauses, especially when the speaker's mouth is visible. In previous\nwork, we introduced a prosodic alignment model to address isochrone or\non-screen dubbing. In this work, we extend the prosodic alignment model to also\naddress off-screen dubbing that requires less stringent synchronization\nconstraints. We conduct experiments on four dubbing directions - English to\nFrench, Italian, German and Spanish - on a publicly available collection of TED\nTalks and on publicly available YouTube videos. Empirical results show that\ncompared to our previous work the extended prosodic alignment model provides\nsignificantly better subjective viewing experience on videos in which on-screen\nand off-screen automatic dubbing is applied for sentences with speakers mouth\nvisible and not visible, respectively.",
    "descriptor": "\nComments: 5 pages, 2 figures, 3 tables, Submitted to Interspeech 2022\n",
    "authors": [
      "Yogesh Virkar",
      "Marcello Federico",
      "Robert Enyedi",
      "Roberto Barra-Chicote"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2204.02530"
  },
  {
    "id": "arXiv:2204.02531",
    "title": "Improving Zero-Shot Event Extraction via Sentence Simplification",
    "abstract": "The success of sites such as ACLED and Our World in Data have demonstrated\nthe massive utility of extracting events in structured formats from large\nvolumes of textual data in the form of news, social media, blogs and discussion\nforums. Event extraction can provide a window into ongoing geopolitical crises\nand yield actionable intelligence. With the proliferation of large pretrained\nlanguage models, Machine Reading Comprehension (MRC) has emerged as a new\nparadigm for event extraction in recent times. In this approach, event argument\nextraction is framed as an extractive question-answering task. One of the key\nadvantages of the MRC-based approach is its ability to perform zero-shot\nextraction. However, the problem of long-range dependencies, i.e., large\nlexical distance between trigger and argument words and the difficulty of\nprocessing syntactically complex sentences plague MRC-based approaches. In this\npaper, we present a general approach to improve the performance of MRC-based\nevent extraction by performing unsupervised sentence simplification guided by\nthe MRC model itself. We evaluate our approach on the ICEWS geopolitical event\nextraction dataset, with specific attention to `Actor' and `Target' argument\nroles. We show how such context simplification can improve the performance of\nMRC-based event extraction by more than 5% for actor extraction and more than\n10% for target extraction.",
    "descriptor": "",
    "authors": [
      "Sneha Mehta",
      "Huzefa Rangwala",
      "Naren Ramakrishnan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.02531"
  },
  {
    "id": "arXiv:2204.02537",
    "title": "Nearly Tight Spectral Sparsification of Directed Hypergraphs by a Simple  Iterative Sampling Algorithm",
    "abstract": "Spectral hypergraph sparsification, which is an attempt to extend well-known\nspectral graph sparsification to hypergraphs, has been extensively studied over\nthe past few years. For undirected hypergraphs, Kapralov, Krauthgamer, Tardos,\nand Yoshida (2022) have recently obtained an algorithm for constructing an\n$\\varepsilon$-spectral sparsifier of optimal $O^*(n)$ size, where $O^*$\nsuppresses the $\\varepsilon^{-1}$ and $\\log n$ factors, while the optimal\nsparsifier size has not been known for directed hypergraphs. In this paper, we\npresent the first algorithm for constructing an $\\varepsilon$-spectral\nsparsifier for a directed hypergraph with $O^*(n^2)$ hyperarcs. This improves\nthe previous bound by Kapralov, Krauthgamer, Tardos, and Yoshida (2021), and it\nis optimal up to the $\\varepsilon^{-1}$ and $\\log n$ factors since there is a\nlower bound of $\\Omega(n^2)$ even for directed graphs. For general directed\nhypergraphs, we show the first non-trivial lower bound of\n$\\Omega(n^2/\\varepsilon)$.\nOur algorithm can be regarded as an extension of the spanner-based graph\nsparsification by Koutis and Xu (2016). To exhibit the power of the\nspanner-based approach, we also examine a natural extension of Koutis and Xu's\nalgorithm to undirected hypergraphs. We show that it outputs an\n$\\varepsilon$-spectral sparsifier of an undirected hypergraph with $O^*(nr^3)$\nhyperedges, where $r$ is the maximum size of a hyperedge. Our analysis of the\nundirected case is based on that of Bansal, Svensson, and Trevisan (2019), and\nthe bound matches that of the hypergraph sparsification algorithm by Bansal et\nal. We further show that our algorithm inherits advantages of the spanner-based\nsparsification in that it is fast, can be implemented in parallel, and can be\nconverted to be fault-tolerant.",
    "descriptor": "",
    "authors": [
      "Kazusato Oko",
      "Shinsaku Sakaue",
      "Shin-ichi Tanigawa"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2204.02537"
  },
  {
    "id": "arXiv:2204.02538",
    "title": "IoT-Scan: Network Reconnaissance for the Internet of Things",
    "abstract": "Network reconnaissance is a core networking and security procedure aimed at\ndiscovering devices and their properties. For IP-based networks, several\nnetwork reconnaissance tools are available, such as Nmap. For the Internet of\nThings (IoT), there is currently no similar tool capable of discovering devices\nacross multiple protocols. In this paper, we present IoT-Scan, a universal IoT\nnetwork reconnaissance tool.\nIoT-Scan is based on software defined radio (SDR) technology, which allows\nfor a flexible software-based implementation of radio protocols. We present a\nseries of passive, active, multi-channel, and multi-protocol scanning\nalgorithms to speed up the discovery of devices with IoT-Scan. We benchmark the\npassive scanning algorithms against a theoretical traffic model based on the\nnon-uniform coupon collector problem. We implement the scanning algorithms and\ncompare their performance for four popular IoT protocols: Zigbee, Bluetooth LE,\nZ-Wave, and LoRa. Through extensive experiments with dozens of IoT devices, we\ndemonstrate that our implementation experiences minimal packet losses and\nachieves performance near the theoretical benchmark. Using multi-protocol\nscanning, we further demonstrate a reduction of 70\\% in the discovery times of\nBluetooth and Zigbee devices in the 2.4\\,GHz band and of LoRa and Z-Wave\ndevices in the 900\\,MHz band, compared to sequential passive scanning. We make\nour implementation and data available to the research community to allow\nindependent replication of our results and facilitate further development of\nthe tool.",
    "descriptor": "",
    "authors": [
      "Stefan Gvozdenovic",
      "Johannes K Becker",
      "John Mikulskis",
      "David Starobinski"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2204.02538"
  },
  {
    "id": "arXiv:2204.02541",
    "title": "Towards Better Test Coverage: Merging Unit Tests for Autonomous Systems",
    "abstract": "We present a framework for merging unit tests for autonomous systems.\nTypically, it is intractable to test an autonomous system for every scenario in\nits operating environment. The question of whether it is possible to design a\nsingle test for multiple requirements of the system motivates this work. First,\nwe formally define three attributes of a test: a test specification that\ncharacterizes behaviors observed in a test execution, a test environment, and a\ntest policy. Using the merge operator from contract-based design theory, we\nprovide a formalism to construct a merged test specification from two unit test\nspecifications. Temporal constraints on the merged test specification guarantee\nthat non-trivial satisfaction of both unit test specifications is necessary for\na successful merged test execution. We assume that the test environment remains\nthe same across the unit tests and the merged test. Given a test specification\nand a test environment, we synthesize a test policy filter using a receding\nhorizon approach, and use the test policy filter to guide a search procedure\n(e.g. Monte-Carlo Tree Search) to find a test policy that is guaranteed to\nsatisfy the test specification. This search procedure finds a test policy that\nmaximizes a pre-defined robustness metric for the test while the filter\nguarantees a test policy for satisfying the test specification. We prove that\nour algorithm is sound. Furthermore, the receding horizon approach to\nsynthesizing the filter ensures that our algorithm is scalable. Finally, we\nshow that merging unit tests is impactful for designing efficient test\ncampaigns to achieve similar levels of coverage in fewer test executions. We\nillustrate our framework on two self-driving examples in a discrete-state\nsetting.",
    "descriptor": "\nComments: Conference Paper\n",
    "authors": [
      "Josefine Graebener",
      "Apurva Badithela",
      "Richard M. Murray"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2204.02541"
  },
  {
    "id": "arXiv:2204.02545",
    "title": "Stateful Greybox Fuzzing",
    "abstract": "Many bugs in protocol implementations may only manifest when the system is in\na particular \"state\". For instance, to trigger one of the bugs we found in an\nRTSP implementation, the fuzzer must first send two different types of messages\nto usher the protocol implementation from the INIT via the READY to the PLAY\nstate where the bug is exposed. Without knowledge of the protocol, it is\ninherently difficult for a fuzzer to discover such stateful bugs. A key\nchallenge in fuzzing stateful systems, therefore, is to cover the state space\nwithout an explicit specification of the protocol.\nSo, how can we help our fuzzer navigate an unknown state space? In our\nanalysis of the Top-50 most widely used open-source protocol implementations,\nwe found that every implementation uses state variables that are assigned named\nconstants (such as INIT, READY) to represent the current state. In this work,\nwe propose to automatically identify such state variables and track the\nsequence of values assigned to them during fuzzing to produce a \"map\" of the\nexplored state space. Our stateful greybox fuzzing approach uses this map to\nfocus on the most promising regions of the code and state space.\nOur experiments confirm that our stateful fuzzer discovers stateful bugs\ntwice as fast as the baseline greybox fuzzer that we extended. The state\nsequence for an input is determined by the sequence of values assigned to the\nstate variables during its execution. Starting from the initial state, our\nfuzzer exercises one order of magnitude more state sequences and covers the\nsame code two times faster than the baseline fuzzer. Several zero-day bugs in\nprominent protocol implementations were found by our fuzzer, and 8 CVEs have\nbeen assigned.",
    "descriptor": "",
    "authors": [
      "Jinsheng Ba",
      "Marcel B\u00f6hme",
      "Zahra Mirzamomen",
      "Abhik Roychoudhury"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2204.02545"
  },
  {
    "id": "arXiv:2204.02546",
    "title": "Quick Starting Dialog Systems with Paraphrase Generation",
    "abstract": "Acquiring training data to improve the robustness of dialog systems can be a\npainstakingly long process. In this work, we propose a method to reduce the\ncost and effort of creating new conversational agents by artificially\ngenerating more data from existing examples, using paraphrase generation. Our\nproposed approach can kick-start a dialog system with little human effort, and\nbrings its performance to a level satisfactory enough for allowing actual\ninteractions with real end-users. We experimented with two neural paraphrasing\napproaches, namely Neural Machine Translation and a Transformer-based seq2seq\nmodel. We present the results obtained with two datasets in English and in\nFrench:~a crowd-sourced public intent classification dataset and our own\ncorporate dialog system dataset. We show that our proposed approach increased\nthe generalization capabilities of the intent classification model on both\ndatasets, reducing the effort required to initialize a new dialog system and\nhelping to deploy this technology at scale within an organization.",
    "descriptor": "",
    "authors": [
      "Louis Marceau",
      "Raouf Belbahar",
      "Marc Queudot",
      "Eric Charton",
      "Marie-Jean Meurs"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.02546"
  },
  {
    "id": "arXiv:2204.02547",
    "title": "Modeling Motion with Multi-Modal Features for Text-Based Video  Segmentation",
    "abstract": "Text-based video segmentation aims to segment the target object in a video\nbased on a describing sentence. Incorporating motion information from optical\nflow maps with appearance and linguistic modalities is crucial yet has been\nlargely ignored by previous work. In this paper, we design a method to fuse and\nalign appearance, motion, and linguistic features to achieve accurate\nsegmentation. Specifically, we propose a multi-modal video transformer, which\ncan fuse and aggregate multi-modal and temporal features between frames.\nFurthermore, we design a language-guided feature fusion module to progressively\nfuse appearance and motion features in each feature level with guidance from\nlinguistic features. Finally, a multi-modal alignment loss is proposed to\nalleviate the semantic gap between features from different modalities.\nExtensive experiments on A2D Sentences and J-HMDB Sentences verify the\nperformance and the generalization ability of our method compared to the\nstate-of-the-art methods.",
    "descriptor": "\nComments: Accepted to CVPR2022\n",
    "authors": [
      "Wangbo Zhao",
      "Kai Wang",
      "Xiangxiang Chu",
      "Fuzhao Xue",
      "Xinchao Wang",
      "Yang You"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.02547"
  },
  {
    "id": "arXiv:2204.02548",
    "title": "Style-Hallucinated Dual Consistency Learning for Domain Generalized  Semantic Segmentation",
    "abstract": "In this paper, we study the task of synthetic-to-real domain generalized\nsemantic segmentation, which aims to learn a model that is robust to unseen\nreal-world scenes using only synthetic data. The large domain shift between\nsynthetic and real-world data, including the limited source environmental\nvariations and the large distribution gap between synthetic and real-world\ndata, significantly hinders the model performance on unseen real-world scenes.\nIn this work, we propose the Style-HAllucinated Dual consistEncy learning\n(SHADE) framework to handle such domain shift. Specifically, SHADE is\nconstructed based on two consistency constraints, Style Consistency (SC) and\nRetrospection Consistency (RC). SC enriches the source situations and\nencourages the model to learn consistent representation across\nstyle-diversified samples. RC leverages real-world knowledge to prevent the\nmodel from overfitting to synthetic data and thus largely keeps the\nrepresentation consistent between the synthetic and real-world models.\nFurthermore, we present a novel style hallucination module (SHM) to generate\nstyle-diversified samples that are essential to consistency learning. SHM\nselects basis styles from the source distribution, enabling the model to\ndynamically generate diverse and realistic samples during training. Experiments\nshow that our SHADE yields significant improvement and outperforms\nstate-of-the-art methods by 5.07% and 8.35% on the average mIoU of three\nreal-world datasets on single- and multi-source settings respectively.",
    "descriptor": "",
    "authors": [
      "Yuyang Zhao",
      "Zhun Zhong",
      "Na Zhao",
      "Nicu Sebe",
      "Gim Hee Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.02548"
  },
  {
    "id": "arXiv:2204.02549",
    "title": "C3KG: A Chinese Commonsense Conversation Knowledge Graph",
    "abstract": "Existing commonsense knowledge bases often organize tuples in an isolated\nmanner, which is deficient for commonsense conversational models to plan the\nnext steps. To fill the gap, we curate a large-scale multi-turn human-written\nconversation corpus, and create the first Chinese commonsense conversation\nknowledge graph which incorporates both social commonsense knowledge and dialog\nflow information. To show the potential of our graph, we develop a\ngraph-conversation matching approach, and benchmark two graph-grounded\nconversational tasks.",
    "descriptor": "\nComments: Accepted by ACL 2022 Findings. Our code and data could be found in this https URL\n",
    "authors": [
      "Dawei Li",
      "Yanran Li",
      "Jiayi Zhang",
      "Ke Li",
      "Chen Wei",
      "Jianwei Cui",
      "Bin Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.02549"
  },
  {
    "id": "arXiv:2204.02550",
    "title": "Continuous LWE is as Hard as LWE & Applications to Learning Gaussian  Mixtures",
    "abstract": "We show direct and conceptually simple reductions between the classical\nlearning with errors (LWE) problem and its continuous analog, CLWE (Bruna,\nRegev, Song and Tang, STOC 2021). This allows us to bring to bear the powerful\nmachinery of LWE-based cryptography to the applications of CLWE. For example,\nwe obtain the hardness of CLWE under the classical worst-case hardness of the\ngap shortest vector problem. Previously, this was known only under quantum\nworst-case hardness of lattice problems. More broadly, with our reductions\nbetween the two problems, any future developments to LWE will also apply to\nCLWE and its downstream applications.\nAs a concrete application, we show an improved hardness result for density\nestimation for mixtures of Gaussians. In this computational problem, given\nsample access to a mixture of Gaussians, the goal is to output a function that\nestimates the density function of the mixture. Under the (plausible and widely\nbelieved) exponential hardness of the classical LWE problem, we show that\nGaussian mixture density estimation in $\\mathbb{R}^n$ with roughly $\\log n$\nGaussian components given $\\mathsf{poly}(n)$ samples requires time\nquasi-polynomial in $n$. Under the (conservative) polynomial hardness of LWE,\nwe show hardness of density estimation for $n^{\\epsilon}$ Gaussians for any\nconstant $\\epsilon > 0$, which improves on Bruna, Regev, Song and Tang (STOC\n2021), who show hardness for at least $\\sqrt{n}$ Gaussians under polynomial\n(quantum) hardness assumptions.\nOur key technical tool is a reduction from classical LWE to LWE with\n$k$-sparse secrets where the multiplicative increase in the noise is only\n$O(\\sqrt{k})$, independent of the ambient dimension $n$.",
    "descriptor": "",
    "authors": [
      "Aparna Gupte",
      "Neekon Vafa",
      "Vinod Vaikuntanathan"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.02550"
  },
  {
    "id": "arXiv:2204.02553",
    "title": "RODD: A Self-Supervised Approach for Robust Out-of-Distribution  Detection",
    "abstract": "Recent studies have addressed the concern of detecting and rejecting the\nout-of-distribution (OOD) samples as a major challenge in the safe deployment\nof deep learning (DL) models. It is desired that the DL model should only be\nconfident about the in-distribution (ID) data which reinforces the driving\nprinciple of the OOD detection. In this paper, we propose a simple yet\neffective generalized OOD detection method independent of out-of-distribution\ndatasets. Our approach relies on self-supervised feature learning of the\ntraining samples, where the embeddings lie on a compact low-dimensional space.\nMotivated by the recent studies that show self-supervised adversarial\ncontrastive learning helps robustify the model, we empirically show that a\npre-trained model with self-supervised contrastive learning yields a better\nmodel for uni-dimensional feature learning in the latent space. The method\nproposed in this work referred to as \\texttt{RODD}, outperforms SOTA detection\nperformance on an extensive suite of benchmark datasets on OOD detection tasks.\nOn the CIFAR-100 benchmarks, \\texttt{RODD} achieves a 26.97 $\\%$ lower\nfalse-positive rate (FPR@95) compared to SOTA methods.",
    "descriptor": "\nComments: Accepted in CVPR Workshop Proceedings\n",
    "authors": [
      "Umar Khalid",
      "Ashkan Esmaeili",
      "Nazmul Karim",
      "Nazanin Rahnavard"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.02553"
  },
  {
    "id": "arXiv:2204.02557",
    "title": "MixFormer: Mixing Features across Windows and Dimensions",
    "abstract": "While local-window self-attention performs notably in vision tasks, it\nsuffers from limited receptive field and weak modeling capability issues. This\nis mainly because it performs self-attention within non-overlapped windows and\nshares weights on the channel dimension. We propose MixFormer to find a\nsolution. First, we combine local-window self-attention with depth-wise\nconvolution in a parallel design, modeling cross-window connections to enlarge\nthe receptive fields. Second, we propose bi-directional interactions across\nbranches to provide complementary clues in the channel and spatial dimensions.\nThese two designs are integrated to achieve efficient feature mixing among\nwindows and dimensions. Our MixFormer provides competitive results on image\nclassification with EfficientNet and shows better results than RegNet and Swin\nTransformer. Performance in downstream tasks outperforms its alternatives by\nsignificant margins with less computational costs in 5 dense prediction tasks\non MS COCO, ADE20k, and LVIS. Code is available at\n\\url{https://github.com/PaddlePaddle/PaddleClas}.",
    "descriptor": "\nComments: CVPR2022 Oral\n",
    "authors": [
      "Qiang Chen",
      "Qiman Wu",
      "Jian Wang",
      "Qinghao Hu",
      "Tao Hu",
      "Errui Ding",
      "Jian Cheng",
      "Jingdong Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.02557"
  },
  {
    "id": "arXiv:2204.02558",
    "title": "DouZero+: Improving DouDizhu AI by Opponent Modeling and Coach-guided  Learning",
    "abstract": "Recent years have witnessed the great breakthrough of deep reinforcement\nlearning (DRL) in various perfect and imperfect information games. Among these\ngames, DouDizhu, a popular card game in China, is very challenging due to the\nimperfect information, large state space, elements of collaboration and a\nmassive number of possible moves from turn to turn. Recently, a DouDizhu AI\nsystem called DouZero has been proposed. Trained using traditional Monte Carlo\nmethod with deep neural networks and self-play procedure without the\nabstraction of human prior knowledge, DouZero has outperformed all the existing\nDouDizhu AI programs. In this work, we propose to enhance DouZero by\nintroducing opponent modeling into DouZero. Besides, we propose a novel coach\nnetwork to further boost the performance of DouZero and accelerate its training\nprocess. With the integration of the above two techniques into DouZero, our\nDouDizhu AI system achieves better performance and ranks top in the Botzone\nleaderboard among more than 400 AI agents, including DouZero.",
    "descriptor": "",
    "authors": [
      "Youpeng Zhao",
      "Jian Zhao",
      "Xunhan Hu",
      "Wengang Zhou",
      "Houqiang Li"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.02558"
  },
  {
    "id": "arXiv:2204.02559",
    "title": "X-CAR: An Experimental Vehicle Platform for Connected Autonomy Research  Powered by CARMA",
    "abstract": "Autonomous vehicles promise a future with a safer, cleaner, more efficient,\nand more reliable transportation system. However, the current approach to\nautonomy has focused on building small, disparate intelligences that are closed\noff to the rest of the world. Vehicle connectivity has been proposed as a\nsolution, relying on a vision of the future where a mix of connected autonomous\nand human-driven vehicles populate the road. Developed by the U.S. Department\nof Transportation Federal Highway Administration as a reusable, extensible\nplatform for controlling connected autonomous vehicles, the CARMA Platform is\none of the technologies enabling this connected future. Nevertheless, the\nadoption of the CARMA Platform has been slow, with a contributing factor being\nthe limited, expensive, and somewhat old vehicle configurations that are\nofficially supported. To alleviate this problem, we propose X-CAR (eXperimental\nvehicle platform for Connected Autonomy Research). By implementing the CARMA\nPlatform on more affordable, high quality hardware, X-CAR aims to increase the\nversatility of the CARMA Platform and facilitate its adoption for research and\ndevelopment of connected driving automation.",
    "descriptor": "",
    "authors": [
      "Goodarz Mehr",
      "Prasenjit Ghorai",
      "Ce Zhang",
      "Anshul Nayak",
      "Darshit Patel",
      "Shathushan Sivashangaran",
      "Azim Eskandarian"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2204.02559"
  },
  {
    "id": "arXiv:2204.02566",
    "title": "Modeling Temporal-Modal Entity Graph for Procedural Multimodal Machine  Comprehension",
    "abstract": "Procedural Multimodal Documents (PMDs) organize textual instructions and\ncorresponding images step by step. Comprehending PMDs and inducing their\nrepresentations for the downstream reasoning tasks is designated as Procedural\nMultiModal Machine Comprehension (M3C). In this study, we approach Procedural\nM3C at a fine-grained level (compared with existing explorations at a document\nor sentence level), that is, entity. With delicate consideration, we model\nentity both in its temporal and cross-modal relation and propose a novel\nTemporal-Modal Entity Graph (TMEG). Specifically, graph structure is formulated\nto capture textual and visual entities and trace their temporal-modal\nevolution. In addition, a graph aggregation module is introduced to conduct\ngraph encoding and reasoning. Comprehensive experiments across three Procedural\nM3C tasks are conducted on a traditional dataset RecipeQA and our new dataset\nCraftQA, which can better evaluate the generalization of TMEG.",
    "descriptor": "\nComments: Accepted by ACL-2022\n",
    "authors": [
      "Huibin Zhang",
      "Zhengkun Zhang",
      "Yao Zhang",
      "Jun Wang",
      "Yufan Li",
      "Ning jiang",
      "Xin wei",
      "Zhenglu Yang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2204.02566"
  },
  {
    "id": "arXiv:2204.02567",
    "title": "FairNeuron: Improving Deep Neural Network Fairness with Adversary Games  on Selective Neurons",
    "abstract": "With Deep Neural Network (DNN) being integrated into a growing number of\ncritical systems with far-reaching impacts on society, there are increasing\nconcerns on their ethical performance, such as fairness. Unfortunately, model\nfairness and accuracy in many cases are contradictory goals to optimize. To\nsolve this issue, there has been a number of work trying to improve model\nfairness by using an adversarial game in model level. This approach introduces\nan adversary that evaluates the fairness of a model besides its prediction\naccuracy on the main task, and performs joint-optimization to achieve a\nbalanced result. In this paper, we noticed that when performing backward\npropagation based training, such contradictory phenomenon has shown on\nindividual neuron level. Based on this observation, we propose FairNeuron, a\nDNN model automatic repairing tool, to mitigate fairness concerns and balance\nthe accuracy-fairness trade-off without introducing another model. It works on\ndetecting neurons with contradictory optimization directions from accuracy and\nfairness training goals, and achieving a trade-off by selective dropout.\nComparing with state-of-the-art methods, our approach is lightweight, making it\nscalable and more efficient. Our evaluation on 3 datasets shows that FairNeuron\ncan effectively improve all models' fairness while maintaining a stable\nutility.",
    "descriptor": "",
    "authors": [
      "Xuanqi Gao",
      "Juan Zhai",
      "Shiqing Ma",
      "Chao Shen",
      "Yufei Chen",
      "Qian Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2204.02567"
  },
  {
    "id": "arXiv:2204.02569",
    "title": "Gait Recognition in the Wild with Dense 3D Representations and A  Benchmark",
    "abstract": "Existing studies for gait recognition are dominated by 2D representations\nlike the silhouette or skeleton of the human body in constrained scenes.\nHowever, humans live and walk in the unconstrained 3D space, so projecting the\n3D human body onto the 2D plane will discard a lot of crucial information like\nthe viewpoint, shape, and dynamics for gait recognition. Therefore, this paper\naims to explore dense 3D representations for gait recognition in the wild,\nwhich is a practical yet neglected problem. In particular, we propose a novel\nframework to explore the 3D Skinned Multi-Person Linear (SMPL) model of the\nhuman body for gait recognition, named SMPLGait. Our framework has two\nelaborately-designed branches of which one extracts appearance features from\nsilhouettes, the other learns knowledge of 3D viewpoints and shapes from the 3D\nSMPL model. In addition, due to the lack of suitable datasets, we build the\nfirst large-scale 3D representation-based gait recognition dataset, named\nGait3D. It contains 4,000 subjects and over 25,000 sequences extracted from 39\ncameras in an unconstrained indoor scene. More importantly, it provides 3D SMPL\nmodels recovered from video frames which can provide dense 3D information of\nbody shape, viewpoint, and dynamics. Based on Gait3D, we comprehensively\ncompare our method with existing gait recognition approaches, which reflects\nthe superior performance of our framework and the potential of 3D\nrepresentations for gait recognition in the wild. The code and dataset are\navailable at https://gait3d.github.io.",
    "descriptor": "\nComments: 16 pages, 11 figures, CVPR 2022 accepted, project page: this https URL\n",
    "authors": [
      "Jinkai Zheng",
      "Xinchen Liu",
      "Wu Liu",
      "Lingxiao He",
      "Chenggang Yan",
      "Tao Mei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.02569"
  },
  {
    "id": "arXiv:2204.02570",
    "title": "Optimal Sublinear Sampling of Spanning Trees and Determinantal Point  Processes via Average-Case Entropic Independence",
    "abstract": "We design fast algorithms for repeatedly sampling from strongly Rayleigh\ndistributions, which include random spanning tree distributions and\ndeterminantal point processes. For a graph $G=(V, E)$, we show how to\napproximately sample uniformly random spanning trees from $G$ in\n$\\widetilde{O}(\\lvert V\\rvert)$ time per sample after an initial\n$\\widetilde{O}(\\lvert E\\rvert)$ time preprocessing. For a determinantal point\nprocess on subsets of size $k$ of a ground set of $n$ elements, we show how to\napproximately sample in $\\widetilde{O}(k^\\omega)$ time after an initial\n$\\widetilde{O}(nk^{\\omega-1})$ time preprocessing, where $\\omega<2.372864$ is\nthe matrix multiplication exponent. We even improve the state of the art for\nobtaining a single sample from determinantal point processes, from the prior\nruntime of $\\widetilde{O}(\\min\\{nk^2, n^\\omega\\})$ to\n$\\widetilde{O}(nk^{\\omega-1})$.\nIn our main technical result, we achieve the optimal limit on domain\nsparsification for strongly Rayleigh distributions. In domain sparsification,\nsampling from a distribution $\\mu$ on $\\binom{[n]}{k}$ is reduced to sampling\nfrom related distributions on $\\binom{[t]}{k}$ for $t\\ll n$. We show that for\nstrongly Rayleigh distributions, we can can achieve the optimal\n$t=\\widetilde{O}(k)$. Our reduction involves sampling from $\\widetilde{O}(1)$\ndomain-sparsified distributions, all of which can be produced efficiently\nassuming convenient access to approximate overestimates for marginals of $\\mu$.\nHaving access to marginals is analogous to having access to the mean and\ncovariance of a continuous distribution, or knowing \"isotropy\" for the\ndistribution, the key assumption behind the Kannan-Lov\\'asz-Simonovits (KLS)\nconjecture and optimal samplers based on it. We view our result as a moral\nanalog of the KLS conjecture and its consequences for sampling, for discrete\nstrongly Rayleigh measures.",
    "descriptor": "",
    "authors": [
      "Nima Anari",
      "Yang P. Liu",
      "Thuy-Duong Vuong"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)",
      "Probability (math.PR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2204.02570"
  },
  {
    "id": "arXiv:2204.02571",
    "title": "Post-Quantum Cryptography Algorithms Standardization and Performance  Analysis",
    "abstract": "Quantum computer is no longer a hypothetical idea. It is the worlds most\nimportant technology and there is a race among countries to get supremacy in\nquantum technology. Its the technology that will reduce the computing time from\nyears to hours or even minutes. The power of quantum computing will be a great\nsupport for the scientific community. However, it raises serious threats to\ncybersecurity. Theoretically, all the cryptography algorithms are vulnerable to\nattack. The practical quantum computers, when available with millions of qubits\ncapacity, will be able to break nearly all modern public-key cryptographic\nsystems. Before the quantum computers arrive with sufficient qubit capacity, we\nmust be ready with quantum-safe cryptographic algorithms, tools, techniques,\nand deployment strategies to protect the ICT infrastructure. This paper\ndiscusses in detail the global effort for the design, development, and\nstandardization of various quantum-safe cryptography algorithms along with the\nperformance analysis of some of the potential quantum-safe algorithms. Most of\nthe quantum-safe algorithms need more CPU cycles, higher runtime memory, and\nlarge key size. The objective of the paper is to analyze the feasibility of the\nvarious quantum-safe cryptography algorithms.",
    "descriptor": "\nComments: 37 pages, 29 figures, 18 tables\n",
    "authors": [
      "Manish Kumar"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2204.02571"
  },
  {
    "id": "arXiv:2204.02572",
    "title": "Greedier is Better: Selecting Multiple Neighbors per Iteration for  Sparse Subspace Clustering",
    "abstract": "Sparse subspace clustering (SSC) using greedy-based neighbor selection, such\nas orthogonal matching pursuit (OMP), has been known as a popular\ncomputationally-efficient alternative to the popular L1-minimization based\nmethods. This paper proposes a new SSC scheme using generalized OMP (GOMP), a\nsoup-up of OMP whereby multiple neighbors are identified per iteration, along\nwith a new stopping rule requiring nothing more than a knowledge of the ambient\nsignal dimension. Compared to conventional OMP, which identifies one neighbor\nper iteration, the proposed GOMP method involves fewer iterations, thereby\nenjoying lower algorithmic complexity; advantageously, the proposed stopping\nrule is free from off-line estimation of subspace dimension and noise power.\nUnder the semi-random model, analytic performance guarantees, in terms of\nneighbor recovery rates, are established to justify the advantage of the\nproposed GOMP. The results show that, with a high probability, GOMP (i) is\nhalted by the proposed stopping rule, and (ii) can retrieve more true neighbors\nthan OMP, consequently yielding higher final data clustering accuracy. Computer\nsimulations using both synthetic data and real human face data are provided to\nvalidate our analytic study and evidence the effectiveness of the proposed\napproach.",
    "descriptor": "",
    "authors": [
      "Jwo-Yuh Wu",
      "Liang-Chi Huang",
      "Wen-Hsuan Li",
      "Chun-Hung Liu",
      "Rung-Hung Gau"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.02572"
  },
  {
    "id": "arXiv:2204.02573",
    "title": "Detecting key Soccer match events to create highlights using Computer  Vision",
    "abstract": "The research and data science community has been fascinated with the\ndevelopment of automatic systems for the detection of key events in a video.\nSpecial attention in this field is given to sports video analytics which could\nhelp in identifying key events during a match and help in preparing a strategy\nfor the games going forward. For this paper, we have chosen Football (soccer)\nas a sport where we would want to create highlights for a given match video,\nthrough a computer vision model that aims to identify important events in a\nSoccer match to create highlights of the match. We built the models based on\nFaster RCNN and YoloV5 architectures and noticed that for the amount of data we\nused for training Faster RCNN did better than YoloV5 in detecting the events in\nthe match though it was much slower. Within Faster RCNN using ResNet50 as a\nbase model gave a better class accuracy of 95.5% as compared to 92% with VGG16\nas base model completely outperforming YoloV5 for our training dataset. We\ntested with an original video of size 23 minutes and our model could reduce it\nto 4:50 minutes of highlights capturing almost all important events in the\nmatch.",
    "descriptor": "",
    "authors": [
      "Narayana Darapaneni",
      "Prashant Kumar",
      "Nikhil Malhotra",
      "Vigneswaran Sundaramurthy",
      "Abhaya Thakur",
      "Shivam Chauhan",
      "Krishna Chaitanya Thangeda",
      "Anwesh Reddy Paduri"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.02573"
  },
  {
    "id": "arXiv:2204.02574",
    "title": "FocalClick: Towards Practical Interactive Image Segmentation",
    "abstract": "Interactive segmentation allows users to extract target masks by making\npositive/negative clicks. Although explored by many previous works, there is\nstill a gap between academic approaches and industrial needs: first, existing\nmodels are not efficient enough to work on low power devices; second, they\nperform poorly when used to refine preexisting masks as they could not avoid\ndestroying the correct part. FocalClick solves both issues at once by\npredicting and updating the mask in localized areas. For higher efficiency, we\ndecompose the slow prediction on the entire image into two fast inferences on\nsmall crops: a coarse segmentation on the Target Crop, and a local refinement\non the Focus Crop. To make the model work with preexisting masks, we formulate\na sub-task termed Interactive Mask Correction, and propose Progressive Merge as\nthe solution. Progressive Merge exploits morphological information to decide\nwhere to preserve and where to update, enabling users to refine any preexisting\nmask effectively. FocalClick achieves competitive results against SOTA methods\nwith significantly smaller FLOPs. It also shows significant superiority when\nmaking corrections on preexisting masks. Code and data will be released at\ngithub.com/XavierCHEN34/ClickSEG",
    "descriptor": "\nComments: CVPR2022\n",
    "authors": [
      "Xi Chen",
      "Zhiyan Zhao",
      "Yilei Zhang",
      "Manni Duan",
      "Donglian Qi",
      "Hengshuang Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.02574"
  },
  {
    "id": "arXiv:2204.02577",
    "title": "A Vergleichsstellensatz of Strassen's Type for a Noncommutative  Preordered Semialgebra through the Semialgebra of its Fractions",
    "abstract": "Preordered semialgebras and semirings are two kinds of algebraic structures\noccurring in real algebraic geometry frequently and usually play important\nroles therein. They have many interesting and promising applications in the\nfields of real algebraic geometry, probability theory, theoretical computer\nscience, quantum information theory, \\emph{etc.}. In these applications,\nStrassen's Vergleichsstellensatz and its generalized versions, which are\nanalogs of those Positivstellens\\\"atze in real algebraic geometry, play\nimportant roles. While these Vergleichsstellens\\\"atze accept only a commutative\nsetting (for the semirings in question), we prove in this paper a\nnoncommutative version of one of the generalized Vergleichsstellens\\\"atze\nproposed by Fritz [\\emph{Comm. Algebra}, 49 (2) (2021), pp. 482-499]. The most\ncrucial step in our proof is to define the semialgebra of the fractions of a\nnoncommutative semialgebra, which generalizes the definitions in the\nliterature. Our new Vergleichsstellensatz characterizes the relaxed preorder on\na noncommutative semialgebra induced by all monotone homomorphisms to\n$\\mathbb{R}_+$ by three other equivalent conditions on the semialgebra of its\nfractions equipped with the derived preorder, which may result in more\napplications in the future.",
    "descriptor": "\nComments: 28 pages\n",
    "authors": [
      "Tao Zheng",
      "Lihong Zhi"
    ],
    "subjectives": [
      "Symbolic Computation (cs.SC)"
    ],
    "url": "https://arxiv.org/abs/2204.02577"
  },
  {
    "id": "arXiv:2204.02581",
    "title": "Banana Sub-Family Classification and Quality Prediction using Computer  Vision",
    "abstract": "India is the second largest producer of fruits and vegetables in the world,\nand one of the largest consumers of fruits like Banana, Papaya and Mangoes\nthrough retail and ecommerce giants like BigBasket, Grofers and Amazon Fresh.\nHowever, adoption of technology in supply chain and retail stores is still low\nand there is a great potential to adopt computer-vision based technology for\nidentification and classification of fruits. We have chosen banana fruit to\nbuild a computer vision based model to carry out the following three use-cases\n(a) Identify Banana from a given image (b) Determine sub-family or variety of\nBanana (c) Determine the quality of Banana. Successful execution of these\nuse-cases using computer-vision model would greatly help with overall inventory\nmanagement automation, quality control, quick and efficient weighing and\nbilling which all are manual labor intensive currently. In this work, we\nsuggest a machine learning pipeline that combines the ideas of CNNs, transfer\nlearning, and data augmentation towards improving Banana fruit sub family and\nquality image classification. We have built a basic CNN and then went on to\ntune a MobileNet Banana classification model using a combination of\nself-curated and publicly-available dataset of 3064 images. The results show an\noverall 93.4% and 100% accuracy for sub-family/variety and for quality test\nclassifications respectively.",
    "descriptor": "",
    "authors": [
      "Narayana Darapaneni",
      "Arjun Tanndalam",
      "Mohit Gupta",
      "Neeta Taneja",
      "Prabu Purushothaman",
      "Swati Eswar",
      "Anwesh Reddy Paduri",
      "Thangaselvi Arichandrapandian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.02581"
  },
  {
    "id": "arXiv:2204.02585",
    "title": "SqueezeNeRF: Further factorized FastNeRF for memory-efficient inference",
    "abstract": "Neural Radiance Fields (NeRF) has emerged as the state-of-the-art method for\nnovel view generation of complex scenes, but is very slow during inference.\nRecently, there have been multiple works on speeding up NeRF inference, but the\nstate of the art methods for real-time NeRF inference rely on caching the\nneural network output, which occupies several giga-bytes of disk space that\nlimits their real-world applicability. As caching the neural network of\noriginal NeRF network is not feasible, Garbin et.al. proposed \"FastNeRF\" which\nfactorizes the problem into 2 sub-networks - one which depends only on the 3D\ncoordinate of a sample point and one which depends only on the 2D camera\nviewing direction. Although this factorization enables them to reduce the cache\nsize and perform inference at over 200 frames per second, the memory overhead\nis still substantial. In this work, we propose SqueezeNeRF, which is more than\n60 times memory-efficient than the sparse cache of FastNeRF and is still able\nto render at more than 190 frames per second on a high spec GPU during\ninference.",
    "descriptor": "\nComments: 9 pages, 3 figures, 5 tables. CVPR ECV 2022\n",
    "authors": [
      "Krishna Wadhwani",
      "Tamaki Kojima"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.02585"
  },
  {
    "id": "arXiv:2204.02586",
    "title": "Hypergraph-based Source Codes for Function Computation Under Maximal  Distortion",
    "abstract": "This work investigates functional source coding problems with maximal\ndistortion, motivated by approximate function computation in many modern\napplications. The maximal distortion treats imprecise reconstruction of a\nfunction value as good as perfect computation if it deviates less than a\ntolerance level, while treating reconstruction that differs by more than that\nlevel as a failure. Using a geometric understanding of the maximal distortion,\nwe propose a hypergraph-based source coding scheme for function computation\nthat is constructive in the sense that it gives an explicit procedure for\ndefining auxiliary random variables. Moreover, we find that the\nhypergraph-based coding scheme achieves the optimal rate-distortion function in\nthe setting of coding for computing with side information and the Berger-Tung\nsum-rate inner bound in the setting of distributed source coding for computing.\nIt also achieves the El Gamal-Cover inner bound for multiple description coding\nfor computing and is optimal for successive refinement and cascade multiple\ndescription problems for computing. Lastly, the benefit of complexity reduction\nof finding a forward test channel is shown for a class of Markov sources.",
    "descriptor": "",
    "authors": [
      "Sourya Basu",
      "Daewon Seo",
      "Lav R. Varshney"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2204.02586"
  },
  {
    "id": "arXiv:2204.02587",
    "title": "Learning to Anticipate Future with Dynamic Context Removal",
    "abstract": "Anticipating future events is an essential feature for intelligent systems\nand embodied AI. However, compared to the traditional recognition task, the\nuncertainty of future and reasoning ability requirement make the anticipation\ntask very challenging and far beyond solved. In this filed, previous methods\nusually care more about the model architecture design or but few attention has\nbeen put on how to train an anticipation model with a proper learning policy.\nTo this end, in this work, we propose a novel training scheme called Dynamic\nContext Removal (DCR), which dynamically schedules the visibility of observed\nfuture in the learning procedure. It follows the human-like curriculum learning\nprocess, i.e., gradually removing the event context to increase the\nanticipation difficulty till satisfying the final anticipation target. Our\nlearning scheme is plug-and-play and easy to integrate any reasoning model\nincluding transformer and LSTM, with advantages in both effectiveness and\nefficiency. In extensive experiments, the proposed method achieves\nstate-of-the-art on four widely-used benchmarks. Our code and models are\npublicly released at https://github.com/AllenXuuu/DCR.",
    "descriptor": "\nComments: CVPR 2022\n",
    "authors": [
      "Xinyu Xu",
      "Yong-Lu Li",
      "Cewu Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.02587"
  },
  {
    "id": "arXiv:2204.02591",
    "title": "Contextual Attention Mechanism, SRGAN Based Inpainting System for  Eliminating Interruptions from Images",
    "abstract": "The new alternative is to use deep learning to inpaint any image by utilizing\nimage classification and computer vision techniques. In general, image\ninpainting is a task of recreating or reconstructing any broken image which\ncould be a photograph or oil/acrylic painting. With the advancement in the\nfield of Artificial Intelligence, this topic has become popular among AI\nenthusiasts. With our approach, we propose an initial end-to-end pipeline for\ninpainting images using a complete Machine Learning approach instead of a\nconventional application-based approach. We first use the YOLO model to\nautomatically identify and localize the object we wish to remove from the\nimage. Using the result obtained from the model we can generate a mask for the\nsame. After this, we provide the masked image and original image to the GAN\nmodel which uses the Contextual Attention method to fill in the region. It\nconsists of two generator networks and two discriminator networks and is also\ncalled a coarse-to-fine network structure. The two generators use fully\nconvolutional networks while the global discriminator gets hold of the entire\nimage as input while the local discriminator gets the grip of the filled region\nas input. The contextual Attention mechanism is proposed to effectively borrow\nthe neighbor information from distant spatial locations for reconstructing the\nmissing pixels. The third part of our implementation uses SRGAN to resolve the\ninpainted image back to its original size. Our work is inspired by the paper\nFree-Form Image Inpainting with Gated Convolution and Generative Image\nInpainting with Contextual Attention.",
    "descriptor": "",
    "authors": [
      "Narayana Darapaneni",
      "Vaibhav Kherde",
      "Kameswara Rao",
      "Deepali Nikam",
      "Swanand Katdare",
      "Anima Shukla",
      "Anagha Lomate",
      "Anwesh Reddy Paduri"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.02591"
  },
  {
    "id": "arXiv:2204.02592",
    "title": "Thinking inside The Box: Learning Hypercube Representations for Group  Recommendation",
    "abstract": "As a step beyond traditional personalized recommendation, group\nrecommendation is the task of suggesting items that can satisfy a group of\nusers. In group recommendation, the core is to design preference aggregation\nfunctions to obtain a quality summary of all group members' preferences. Such\nuser and group preferences are commonly represented as points in the vector\nspace (i.e., embeddings), where multiple user embeddings are compressed into\none to facilitate ranking for group-item pairs. However, the resulted group\nrepresentations, as points, lack adequate flexibility and capacity to account\nfor the multi-faceted user preferences. Also, the point embedding-based\npreference aggregation is a less faithful reflection of a group's\ndecision-making process, where all users have to agree on a certain value in\neach embedding dimension instead of a negotiable interval. In this paper, we\npropose a novel representation of groups via the notion of hypercubes, which\nare subspaces containing innumerable points in the vector space. Specifically,\nwe design the hypercube recommender (CubeRec) to adaptively learn group\nhypercubes from user embeddings with minimal information loss during preference\naggregation, and to leverage a revamped distance metric to measure the affinity\nbetween group hypercubes and item points. Moreover, to counteract the\nlong-standing issue of data sparsity in group recommendation, we make full use\nof the geometric expressiveness of hypercubes and innovatively incorporate\nself-supervision by intersecting two groups. Experiments on four real-world\ndatasets have validated the superiority of CubeRec over state-of-the-art\nbaselines.",
    "descriptor": "\nComments: To appear in SIGIR'22\n",
    "authors": [
      "Tong Chen",
      "Hongzhi Yin",
      "Jing Long",
      "Quoc Viet Hung Nguyen",
      "Yang Wang",
      "Meng Wang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2204.02592"
  },
  {
    "id": "arXiv:2204.02597",
    "title": "Fine-Grained Predicates Learning for Scene Graph Generation",
    "abstract": "The performance of current Scene Graph Generation models is severely hampered\nby some hard-to-distinguish predicates, e.g., \"woman-on/standing on/walking\non-beach\" or \"woman-near/looking at/in front of-child\". While general SGG\nmodels are prone to predict head predicates and existing re-balancing\nstrategies prefer tail categories, none of them can appropriately handle these\nhard-to-distinguish predicates. To tackle this issue, inspired by fine-grained\nimage classification, which focuses on differentiating among\nhard-to-distinguish object classes, we propose a method named Fine-Grained\nPredicates Learning (FGPL) which aims at differentiating among\nhard-to-distinguish predicates for Scene Graph Generation task. Specifically,\nwe first introduce a Predicate Lattice that helps SGG models to figure out\nfine-grained predicate pairs. Then, utilizing the Predicate Lattice, we propose\na Category Discriminating Loss and an Entity Discriminating Loss, which both\ncontribute to distinguishing fine-grained predicates while maintaining learned\ndiscriminatory power over recognizable ones. The proposed model-agnostic\nstrategy significantly boosts the performances of three benchmark models\n(Transformer, VCTree, and Motif) by 22.8\\%, 24.1\\% and 21.7\\% of Mean Recall\n(mR@100) on the Predicate Classification sub-task, respectively. Our model also\noutperforms state-of-the-art methods by a large margin (i.e., 6.1\\%, 4.6\\%, and\n3.2\\% of Mean Recall (mR@100)) on the Visual Genome dataset.",
    "descriptor": "",
    "authors": [
      "Xinyu Lyu",
      "Lianli Gao",
      "Yuyu Guo",
      "Zhou Zhao",
      "Hao Huang",
      "Heng Tao Shen",
      "Jingkuan Song"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.02597"
  },
  {
    "id": "arXiv:2204.02601",
    "title": "Probing Structured Pruning on Multilingual Pre-trained Models: Settings,  Algorithms, and Efficiency",
    "abstract": "Structured pruning has been extensively studied on monolingual pre-trained\nlanguage models and is yet to be fully evaluated on their multilingual\ncounterparts. This work investigates three aspects of structured pruning on\nmultilingual pre-trained language models: settings, algorithms, and efficiency.\nExperiments on nine downstream tasks show several counter-intuitive phenomena:\nfor settings, individually pruning for each language does not induce a better\nresult; for algorithms, the simplest method performs the best; for efficiency,\na fast model does not imply that it is also small. To facilitate the comparison\non all sparsity levels, we present Dynamic Sparsification, a simple approach\nthat allows training the model once and adapting to different model sizes at\ninference. We hope this work fills the gap in the study of structured pruning\non multilingual pre-trained models and sheds light on future research.",
    "descriptor": "\nComments: ACL 2022 Main Conference, Camera-ready version\n",
    "authors": [
      "Yanyang Li",
      "Fuli Luo",
      "Runxin Xu",
      "Songfang Huang",
      "Fei Huang",
      "Liwei Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.02601"
  },
  {
    "id": "arXiv:2204.02602",
    "title": "Distributed Transition Systems with Tags for Privacy Analysis",
    "abstract": "We present a logical framework that formally models how a given private\ninformation P stored on a given database D, can get captured progressively, by\nan agent/adversary querying the database repeatedly.Named DLTTS (Distributed\nLabeled Tagged Transition System), the frame-work borrows ideas from several\ndomains: Probabilistic Automata of Segala, Probabilistic Concurrent Systems,\nand Probabilistic labelled transition systems. To every node on a DLTTS is\nattached a tag that represents the 'current' knowledge of the adversary,\nacquired from the responses of the answering mechanism of the DBMS to his/her\nqueries, at the nodes traversed earlier, along any given run; this knowledge is\ncompleted at the same node, with further relational deductions, possibly in\ncombination with 'public' information from other databases given in advance. A\n'blackbox' mechanism is also part of a DLTTS, and it is meant as an oracle; its\nrole is to tell if the private information has been deduced by the adversary at\nthe current node, and if so terminate the run. An additional special feature is\nthat the blackbox also gives information on how 'close',or how 'far', the\nknowledge of the adversary is, from the private information P , at the current\nnode. A metric is defined for that purpose, on the set of all 'type compatible'\ntuples from the given database, the data themselves being typed with the\nheaders of the base. Despite the transition systems flavor of our framework,\nthis metric is not 'behavioral' in the sense presented in some other works. It\nis exclusively database oriented,and allows to define new notions of adjacency\nand of -indistinguishabilty between databases, more generally than those\nusually based on the Hamming metric (and a restricted notion of adjacency).\nExamples are given all along to illustrate how our framework works.\nKeywords:Database, Privacy, Transition System, Probability, Distribution.",
    "descriptor": "",
    "authors": [
      "Siva Anantharaman",
      "Sabine Frittella",
      "Benjamin Nguyen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2204.02602"
  },
  {
    "id": "arXiv:2204.02604",
    "title": "Interactive Evolutionary Multi-Objective Optimization via  Learning-to-Rank",
    "abstract": "In practical multi-criterion decision-making, it is cumbersome if a decision\nmaker (DM) is asked to choose among a set of trade-off alternatives covering\nthe whole Pareto-optimal front. This is a paradox in conventional evolutionary\nmulti-objective optimization (EMO) that always aim to achieve a well balance\nbetween convergence and diversity. In essence, the ultimate goal of\nmulti-objective optimization is to help a decision maker (DM) identify\nsolution(s) of interest (SOI) achieving satisfactory trade-offs among multiple\nconflicting criteria. Bearing this in mind, this paper develops a framework for\ndesigning preference-based EMO algorithms to find SOI in an interactive manner.\nIts core idea is to involve human in the loop of EMO. After every several\niterations, the DM is invited to elicit her feedback with regard to a couple of\nincumbent candidates. By collecting such information, her preference is\nprogressively learned by a learning-to-rank neural network and then applied to\nguide the baseline EMO algorithm. Note that this framework is so general that\nany existing EMO algorithm can be applied in a plug-in manner. Experiments on\n$48$ benchmark test problems with up to 10 objectives fully demonstrate the\neffectiveness of our proposed algorithms for finding SOI.",
    "descriptor": "",
    "authors": [
      "Ke Li",
      "Guiyu Lai",
      "Xin Yao"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2204.02604"
  },
  {
    "id": "arXiv:2204.02607",
    "title": "A collocation IGA-BEM for 3D potential problems on unbounded domains",
    "abstract": "In this paper the numerical solution of potential problems defined on 3D\nunbounded domains is addressed with Boundary Element Methods (BEMs), since in\nthis way the problem is studied only on the boundary, and thus any finite\napproximation of the infinite domain can be avoided. The isogeometric analysis\n(IGA) setting is considered and in particular B-splines and NURBS functions are\ntaken into account. In order to exploit all the possible benefits from using\nspline spaces, an important point is the development of specific cubature\nformulas for weakly and nearly singular integrals. Our proposal for this aim is\nbased on spline quasi-interpolation and on the use of a spline product formula.\nBesides that, a robust singularity extraction procedure is introduced as a\npreliminary step and an efficient function-by-function assembly phase is\nadopted. A selection of numerical examples confirms that the numerical\nsolutions reach the expected convergence orders.",
    "descriptor": "\nComments: 17 pages, 4 figures\n",
    "authors": [
      "Antonella Falini",
      "Carlotta Giannelli",
      "Tadej Kanduc",
      "Maria Lucia Sampoli",
      "Alessandra Sestini"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2204.02607"
  },
  {
    "id": "arXiv:2204.02608",
    "title": "Face recognition in a transformed domain",
    "abstract": "This paper proposes the use of a discrete cosine transform (DCT) instead of\nthe eigenfaces method (Karhunen-Loeve Transform) for biometric identification\nbased on frontal face images. Experimental results show better recognition\naccuracies and reduced computational burden. This paper includes results with\ndifferent classifiers and a combination of them.",
    "descriptor": "\nComments: 9 pages, published in IEEE 37th Annual 2003 International Carnahan Conference on Security Technology, 2003. Proceedings. 14-16 Oct. 2003 Taipei (Taiwan)\n",
    "authors": [
      "Marcos Faundez-Zanuy"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.02608"
  },
  {
    "id": "arXiv:2204.02609",
    "title": "A New Nonlinear speaker parameterization algorithm for speaker  identification",
    "abstract": "In this paper we propose a new parameterization algorithm based on nonlinear\nprediction, which is an extension of the classical LPC parameters. The\nparameters performances are estimated by two different methods: the\nArithmetic-Harmonic Sphericity (AHS) and the Auto-Regressive Vector Model\n(ARVM). Two different methods are proposed for the parameterization based on\nthe Neural Predictive Coding (NPC): classical neural networks initialization\nand linear initialization. We applied these two parameters to speaker\nidentification. The fist parameters obtained smaller rates. We show for the\nfirst parameters how they can be combined with the classical parameters (LPCC,\nMFCC, etc.) in order to improve the results of only one classical\nparameterization (MFCC provides 97.55% and MFCC+NPC 98.78%). For the linear\ninitialization, we obtain 100% which is great improvement. This study opens a\nnew way towards different parameterization schemes that offer better accuracy\non speaker recognition tasks.",
    "descriptor": "\nComments: 5 pages, published in The speaker and Language recognition Workshop. ISCA tutorial and research Workshop. ISBN 84-7490-722-5, May 31 -- June 3, 2004\n",
    "authors": [
      "Mohamed Chetouani",
      "Marcos Faundez-Zanuy",
      "Bruno Gas",
      "Jean-Luc Zarader"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2204.02609"
  },
  {
    "id": "arXiv:2204.02610",
    "title": "Efficient Test-Time Model Adaptation without Forgetting",
    "abstract": "Test-time adaptation (TTA) seeks to tackle potential distribution shifts\nbetween training and testing data by adapting a given model w.r.t. any testing\nsample. This task is particularly important for deep models when the test\nenvironment changes frequently. Although some recent attempts have been made to\nhandle this task, we still face two practical challenges: 1) existing methods\nhave to perform backward computation for each test sample, resulting in\nunbearable prediction cost to many applications; 2) while existing TTA\nsolutions can significantly improve the test performance on out-of-distribution\ndata, they often suffer from severe performance degradation on in-distribution\ndata after TTA (known as catastrophic forgetting). In this paper, we point out\nthat not all the test samples contribute equally to model adaptation, and\nhigh-entropy ones may lead to noisy gradients that could disrupt the model.\nMotivated by this, we propose an active sample selection criterion to identify\nreliable and non-redundant samples, on which the model is updated to minimize\nthe entropy loss for test-time adaptation. Furthermore, to alleviate the\nforgetting issue, we introduce a Fisher regularizer to constrain important\nmodel parameters from drastic changes, where the Fisher importance is estimated\nfrom test samples with generated pseudo labels. Extensive experiments on\nCIFAR-10-C, ImageNet-C, and ImageNet-R verify the effectiveness of our proposed\nmethod.",
    "descriptor": "\nComments: 15 pages, conference\n",
    "authors": [
      "Shuaicheng Niu",
      "Jiaxiang Wu",
      "Yifan Zhang",
      "Yaofo Chen",
      "Shijian Zheng",
      "Peilin Zhao",
      "Mingkui Tan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.02610"
  },
  {
    "id": "arXiv:2204.02611",
    "title": "Cloning Outfits from Real-World Images to 3D Characters for  Generalizable Person Re-Identification",
    "abstract": "Recently, large-scale synthetic datasets are shown to be very useful for\ngeneralizable person re-identification. However, synthesized persons in\nexisting datasets are mostly cartoon-like and in random dress collocation,\nwhich limits their performance. To address this, in this work, an automatic\napproach is proposed to directly clone the whole outfits from real-world person\nimages to virtual 3D characters, such that any virtual person thus created will\nappear very similar to its real-world counterpart. Specifically, based on UV\ntexture mapping, two cloning methods are designed, namely registered clothes\nmapping and homogeneous cloth expansion. Given clothes keypoints detected on\nperson images and labeled on regular UV maps with clear clothes structures,\nregistered mapping applies perspective homography to warp real-world clothes to\nthe counterparts on the UV map. As for invisible clothes parts and irregular UV\nmaps, homogeneous expansion segments a homogeneous area on clothes as a\nrealistic cloth pattern or cell, and expand the cell to fill the UV map.\nFurthermore, a similarity-diversity expansion strategy is proposed, by\nclustering person images, sampling images per cluster, and cloning outfits for\n3D character generation. This way, virtual persons can be scaled up densely in\nvisual similarity to challenge model learning, and diversely in population to\nenrich sample distribution. Finally, by rendering the cloned characters in\nUnity3D scenes, a more realistic virtual dataset called ClonedPerson is\ncreated, with 5,621 identities and 887,766 images. Experimental results show\nthat the model trained on ClonedPerson has a better generalization performance,\nsuperior to that trained on other popular real-world and synthetic person\nre-identification datasets. The ClonedPerson project is available at\nhttps://github.com/Yanan-Wang-cs/ClonedPerson.",
    "descriptor": "\nComments: The paper is accepted by CVPR 2022, including the appendix\n",
    "authors": [
      "Yanan Wang",
      "Xuezhi Liang",
      "Shengcai Liao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.02611"
  },
  {
    "id": "arXiv:2204.02617",
    "title": "Fault Diagnosis of Discrete-Event Systems under Non-Deterministic  Observations with Output Fairness",
    "abstract": "In this paper, we revisit the fault diagnosis problem of discrete-event\nsystems (DES) under non-deterministic observations. Non-deterministic\nobservation is a general observation model that includes the case of\nintermittent loss of observations. In this setting, upon the occurrence of an\nevent, the sensor reading may be non-deterministic such that a set of output\nsymbols are all possible. Existing works on fault diagnosis under\nnon-deterministic observations require to consider all possible observation\nrealizations. However, this approach includes the case where some possible\noutputs are permanently disabled. In this work, we introduce the concept of\noutput fairness by requiring that, for any output symbols, if it has infinite\nchances to be generated, then it will indeed be generated infinite number of\ntimes. We use an assume-guarantee type of linear temporal logic formulas to\nformally describe this assumption. A new notion called output-fair\ndiagnosability (OF-diagnosability) is proposed. An effective approach is\nprovided for the verification of OF-diagnosability. We show that the proposed\nnotion of OF-diagnosability is weaker than the standard definition of\ndiagnosability under non-deterministic observations, and it better captures the\nphysical scenario of observation non-determinism or intermittent loss of\nobservations.",
    "descriptor": "",
    "authors": [
      "Weijie Dong",
      "Shang Gao",
      "Xiang Yin",
      "Shaoyuan Li"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2204.02617"
  },
  {
    "id": "arXiv:2204.02618",
    "title": "Data-Driven Approach for Log Instruction Quality Assessment",
    "abstract": "In the current IT world, developers write code while system operators run the\ncode mostly as a black box. The connection between both worlds is typically\nestablished with log messages: the developer provides hints to the (unknown)\noperator, where the cause of an occurred issue is, and vice versa, the operator\ncan report bugs during operation. To fulfil this purpose, developers write log\ninstructions that are structured text commonly composed of a log level (e.g.,\n\"info\", \"error\"), static text (\"IP {} cannot be reached\"), and dynamic\nvariables (e.g. IP {}). However, as opposed to well-adopted coding practices,\nthere are no widely adopted guidelines on how to write log instructions with\ngood quality properties. For example, a developer may assign a high log level\n(e.g., \"error\") for a trivial event that can confuse the operator and increase\nmaintenance costs. Or the static text can be insufficient to hint at a specific\nissue. In this paper, we address the problem of log quality assessment and\nprovide the first step towards its automation. We start with an in-depth\nanalysis of quality log instruction properties in nine software systems and\nidentify two quality properties: 1) correct log level assignment assessing the\ncorrectness of the log level, and 2) sufficient linguistic structure assessing\nthe minimal richness of the static text necessary for verbose event\ndescription. Based on these findings, we developed a data-driven approach that\nadapts deep learning methods for each of the two properties. An extensive\nevaluation on large-scale open-source systems shows that our approach correctly\nassesses log level assignments with an accuracy of 0.88, and the sufficient\nlinguistic structure with an F1 score of 0.99, outperforming the baselines. Our\nstudy shows the potential of the data-driven methods in assessing instructions\nquality and aid developers in comprehending and writing better code.",
    "descriptor": "\nComments: This paper is accepted for publication at the 30th International Conference on Program Comprehension under doi: 10.1145/3524610.3527906. The copyrights are handled following the corresponding agreement between the author and publisher\n",
    "authors": [
      "Jasmin Bogatinovski",
      "Sasho Nedelkoski",
      "Alexander Acker",
      "Jorge Cardoso",
      "Odej Kao"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.02618"
  },
  {
    "id": "arXiv:2204.02620",
    "title": "Towards Robust Adaptive Object Detection under Noisy Annotations",
    "abstract": "Domain Adaptive Object Detection (DAOD) models a joint distribution of images\nand labels from an annotated source domain and learns a domain-invariant\ntransformation to estimate the target labels with the given target domain\nimages. Existing methods assume that the source domain labels are completely\nclean, yet large-scale datasets often contain error-prone annotations due to\ninstance ambiguity, which may lead to a biased source distribution and severely\ndegrade the performance of the domain adaptive detector de facto. In this\npaper, we represent the first effort to formulate noisy DAOD and propose a\nNoise Latent Transferability Exploration (NLTE) framework to address this\nissue. It is featured with 1) Potential Instance Mining (PIM), which leverages\neligible proposals to recapture the miss-annotated instances from the\nbackground; 2) Morphable Graph Relation Module (MGRM), which models the\nadaptation feasibility and transition probability of noisy samples with\nrelation matrices; 3) Entropy-Aware Gradient Reconcilement (EAGR), which\nincorporates the semantic information into the discrimination process and\nenforces the gradients provided by noisy and clean samples to be consistent\ntowards learning domain-invariant representations. A thorough evaluation on\nbenchmark DAOD datasets with noisy source annotations validates the\neffectiveness of NLTE. In particular, NLTE improves the mAP by 8.4\\% under 60\\%\ncorrupted annotations and even approaches the ideal upper bound of training on\na clean source dataset.",
    "descriptor": "\nComments: CVPR-2022 Version\n",
    "authors": [
      "Xinyu Liu",
      "Wuyang Li",
      "Qiushi Yang",
      "Baopu Li",
      "Yixuan Yuan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.02620"
  },
  {
    "id": "arXiv:2204.02624",
    "title": "There Are a Thousand Hamlets in a Thousand People's Eyes: Enhancing  Knowledge-grounded Dialogue with Personal Memory",
    "abstract": "Knowledge-grounded conversation (KGC) shows great potential in building an\nengaging and knowledgeable chatbot, and knowledge selection is a key ingredient\nin it. However, previous methods for knowledge selection only concentrate on\nthe relevance between knowledge and dialogue context, ignoring the fact that\nage, hobby, education and life experience of an interlocutor have a major\neffect on his or her personal preference over external knowledge. Without\ntaking the personalization issue into account, it is difficult to select the\nproper knowledge and generate persona-consistent responses. In this work, we\nintroduce personal memory into knowledge selection in KGC to address the\npersonalization issue. We propose a variational method to model the underlying\nrelationship between one's personal memory and his or her selection of\nknowledge, and devise a learning scheme in which the forward mapping from\npersonal memory to knowledge and its inverse mapping is included in a closed\nloop so that they could teach each other. Experiment results show that our\nmethod outperforms existing KGC methods significantly on both automatic\nevaluation and human evaluation.",
    "descriptor": "\nComments: Accepted by ACL 2022 (main conference). First two authors contributed equally\n",
    "authors": [
      "Tingchen Fu",
      "Xueliang Zhao",
      "Chongyang Tao",
      "Ji-Rong Wen",
      "Rui Yan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.02624"
  },
  {
    "id": "arXiv:2204.02625",
    "title": "Bridging the Gap of AutoGraph between Academia and Industry: Analysing  AutoGraph Challenge at KDD Cup 2020",
    "abstract": "Graph structured data is ubiquitous in daily life and scientific areas and\nhas attracted increasing attention. Graph Neural Networks (GNNs) have been\nproved to be effective in modeling graph structured data and many variants of\nGNN architectures have been proposed. However, much human effort is often\nneeded to tune the architecture depending on different datasets. Researchers\nnaturally adopt Automated Machine Learning on Graph Learning, aiming to reduce\nthe human effort and achieve generally top-performing GNNs, but their methods\nfocus more on the architecture search. To understand GNN practitioners'\nautomated solutions, we organized AutoGraph Challenge at KDD Cup 2020,\nemphasizing on automated graph neural networks for node classification. We\nreceived top solutions especially from industrial tech companies like Meituan,\nAlibaba and Twitter, which are already open sourced on Github. After detailed\ncomparisons with solutions from academia, we quantify the gaps between academia\nand industry on modeling scope, effectiveness and efficiency, and show that (1)\nacademia AutoML for Graph solutions focus on GNN architecture search while\nindustrial solutions, especially the winning ones in the KDD Cup, tend to\nobtain an overall solution (2) by neural architecture search only, academia\nsolutions achieve on average 97.3% accuracy of industrial solutions (3)\nacademia solutions are cheap to obtain with several GPU hours while industrial\nsolutions take a few months' labors. Academic solutions also contain much fewer\nparameters.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2110.05802\n",
    "authors": [
      "Zhen Xu",
      "Lanning Wei",
      "Huan Zhao",
      "Rex Ying",
      "Quanming Yao",
      "Wei-Wei Tu",
      "Isabelle Guyon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.02625"
  },
  {
    "id": "arXiv:2204.02626",
    "title": "A Weakly Supervised Propagation Model for Rumor Verification and Stance  Detection with Multiple Instance Learning",
    "abstract": "The diffusion of rumors on microblogs generally follows a propagation tree\nstructure, that provides valuable clues on how an original message is\ntransmitted and responded by users over time. Recent studies reveal that rumor\ndetection and stance detection are two different but relevant tasks which can\njointly enhance each other, e.g., rumors can be debunked by cross-checking the\nstances conveyed by their relevant microblog posts, and stances are also\nconditioned on the nature of the rumor. However, most stance detection methods\nrequire enormous post-level stance labels for training, which are\nlabor-intensive given a large number of posts. Enlightened by Multiple Instance\nLearning (MIL) scheme, we first represent the diffusion of claims with\nbottom-up and top-down trees, then propose two tree-structured weakly\nsupervised frameworks to jointly classify rumors and stances, where only the\nbag-level labels concerning claim's veracity are needed. Specifically, we\nconvert the multi-class problem into a multiple MIL-based binary classification\nproblem where each binary model focuses on differentiating a target stance or\nrumor type and other types. Finally, we propose a hierarchical attention\nmechanism to aggregate the binary predictions, including (1) a bottom-up or\ntop-down tree attention layer to aggregate binary stances into binary veracity;\nand (2) a discriminative attention layer to aggregate the binary class into\nfiner-grained classes. Extensive experiments conducted on three Twitter-based\ndatasets demonstrate promising performance of our model on both claim-level\nrumor detection and post-level stance classification compared with\nstate-of-the-art methods.",
    "descriptor": "\nComments: Accepted by SIGIR 2022\n",
    "authors": [
      "Ruichao Yang",
      "Jing Ma",
      "Hongzhan Lin",
      "Wei Gao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.02626"
  },
  {
    "id": "arXiv:2204.02627",
    "title": "Cluster Synchronization of Kuramoto Oscillators and Brain Functional  Connectivity",
    "abstract": "The recent progress of functional magnetic resonance imaging techniques has\nunveiled that human brains exhibit clustered correlation patterns of their\nspontaneous activities. It is important to understand the mechanism of cluster\nsynchronization phenomena since it may reflect the underlying brain functions\nand brain diseases. In this paper, we investigate cluster synchronization\nconditions for networks of Kuramoto oscillators. The key analytical tool that\nwe use is the method of averaging, and we provide a unified framework of\nstability analysis for cluster synchronization. The main results show that\ncluster synchronization is achieved if (i) the inter-cluster coupling strengths\nare sufficiently weak and/or (ii) the natural frequencies are largely different\namong clusters. Moreover, we apply our theoretical findings to empirical brain\nnetworks. Discussions on how to understand brain functional connectivity and\nfurther directions to investigate neuroscientific questions are provided.",
    "descriptor": "",
    "authors": [
      "Rui Kato",
      "Hideaki Ishii"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2204.02627"
  },
  {
    "id": "arXiv:2204.02629",
    "title": "An Automated Conversion Between Selected Robot Kinematic Representations",
    "abstract": "This paper presents a methodology that forms an automated tool for robot\nkinematic representation conversion, called the RobKin Interpreter. It is a set\nof analytical algorithms that can analyze an input robot representation,\nexpress the joints globally in matrix form, and map to other representations\nsuch as standard Denavit-Hartenberg parameters, Roll-Pitch-Yaw angles with\ntranslational displacement, and Product of Exponentials with a possibility to\ngenerate a URDF (Universal Robot Description Format) file from any of them. It\nworks for revolute and prismatic joints and can interpret even arbitrary\nkinematic structures that do not have orthogonally placed joints.",
    "descriptor": "",
    "authors": [
      "Daniel Huczala",
      "Tom\u00e1\u0161 Kot",
      "Martin Pfurner"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2204.02629"
  },
  {
    "id": "arXiv:2204.02630",
    "title": "IterVM: Iterative Vision Modeling Module for Scene Text Recognition",
    "abstract": "Scene text recognition (STR) is a challenging problem due to the imperfect\nimagery conditions in natural images. State-of-the-art methods utilize both\nvisual cues and linguistic knowledge to tackle this challenging problem.\nSpecifically, they propose iterative language modeling module (IterLM) to\nrepeatedly refine the output sequence from the visual modeling module (VM).\nThough achieving promising results, the vision modeling module has become the\nperformance bottleneck of these methods. In this paper, we newly propose\niterative vision modeling module (IterVM) to further improve the STR accuracy.\nSpecifically, the first VM directly extracts multi-level features from the\ninput image, and the following VMs re-extract multi-level features from the\ninput image and fuse them with the high-level (i.e., the most semantic one)\nfeature extracted by the previous VM. By combining the proposed IterVM with\niterative language modeling module, we further propose a powerful scene text\nrecognizer called IterNet. Extensive experiments demonstrate that the proposed\nIterVM can significantly improve the scene text recognition accuracy,\nespecially on low-quality scene text images. Moreover, the proposed scene text\nrecognizer IterNet achieves new state-of-the-art results on several public\nbenchmarks. Codes will be available at https://github.com/VDIGPKU/IterNet.",
    "descriptor": "\nComments: Accepted by ICPR2022\n",
    "authors": [
      "Xiaojie Chu",
      "Yongtao Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.02630"
  },
  {
    "id": "arXiv:2204.02632",
    "title": "DeFTA: A Plug-and-Play Decentralized Replacement for FedAvg",
    "abstract": "Federated learning (FL) is identified as a crucial enabler for large-scale\ndistributed machine learning (ML) without the need for local raw dataset\nsharing, substantially reducing privacy concerns and alleviating the isolated\ndata problem. In reality, the prosperity of FL is largely due to a centralized\nframework called FedAvg, in which workers are in charge of model training and\nservers are in control of model aggregation. However, FedAvg's centralized\nworker-server architecture has raised new concerns, be it the low scalability\nof the cluster, the risk of data leakage, and the failure or even defection of\nthe central server. To overcome these problems, we propose Decentralized\nFederated Trusted Averaging (DeFTA), a decentralized FL framework that serves\nas a plug-and-play replacement for FedAvg, instantly bringing better security,\nscalability, and fault-tolerance to the federated learning process after\ninstallation. In principle, it fundamentally resolves the above-mentioned\nissues from an architectural perspective without compromises or tradeoffs,\nprimarily consisting of a new model aggregating formula with theoretical\nperformance analysis, and a decentralized trust system (DTS) to greatly improve\nsystem robustness. Note that since DeFTA is an alternative to FedAvg at the\nframework level, \\textit{prevalent algorithms published for FedAvg can be also\nutilized in DeFTA with ease}. Extensive experiments on six datasets and six\nbasic models suggest that DeFTA not only has comparable performance with FedAvg\nin a more realistic setting, but also achieves great resilience even when 66%\nof workers are malicious. Furthermore, we also present an asynchronous variant\nof DeFTA to endow it with more powerful usability.",
    "descriptor": "\nComments: 12 pages, 5 figures\n",
    "authors": [
      "Yuhao Zhou",
      "Minjia Shi",
      "Yuxin Tian",
      "Qing Ye",
      "Jiancheng Lv"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.02632"
  },
  {
    "id": "arXiv:2204.02633",
    "title": "DAGAM: Data Augmentation with Generation And Modification",
    "abstract": "Text classification is a representative downstream task of natural language\nprocessing, and has exhibited excellent performance since the advent of\npre-trained language models based on Transformer architecture. However, in\npre-trained language models, under-fitting often occurs due to the size of the\nmodel being very large compared to the amount of available training data. Along\nwith significant importance of data collection in modern machine learning\nparadigm, studies have been actively conducted for natural language data\naugmentation. In light of this, we introduce three data augmentation schemes\nthat help reduce underfitting problems of large-scale language models.\nPrimarily we use a generation model for data augmentation, which is defined as\nData Augmentation with Generation (DAG). Next, we augment data using text\nmodification techniques such as corruption and word order change (Data\nAugmentation with Modification, DAM). Finally, we propose Data Augmentation\nwith Generation And Modification (DAGAM), which combines DAG and DAM techniques\nfor a boosted performance. We conduct data augmentation for six benchmark\ndatasets of text classification task, and verify the usefulness of DAG, DAM,\nand DAGAM through BERT-based fine-tuning and evaluation, deriving better\nresults compared to the performance with original datasets.",
    "descriptor": "",
    "authors": [
      "Byeong-Cheol Jo",
      "Tak-Sung Heo",
      "Yeongjoon Park",
      "Yongmin Yoo",
      "Won Ik Cho",
      "Kyungsun Kim"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.02633"
  },
  {
    "id": "arXiv:2204.02634",
    "title": "Federated Reinforcement Learning with Environment Heterogeneity",
    "abstract": "We study a Federated Reinforcement Learning (FedRL) problem in which $n$\nagents collaboratively learn a single policy without sharing the trajectories\nthey collected during agent-environment interaction. We stress the constraint\nof environment heterogeneity, which means $n$ environments corresponding to\nthese $n$ agents have different state transitions. To obtain a value function\nor a policy function which optimizes the overall performance in all\nenvironments, we propose two federated RL algorithms, \\texttt{QAvg} and\n\\texttt{PAvg}. We theoretically prove that these algorithms converge to\nsuboptimal solutions, while such suboptimality depends on how heterogeneous\nthese $n$ environments are. Moreover, we propose a heuristic that achieves\npersonalization by embedding the $n$ environments into $n$ vectors. The\npersonalization heuristic not only improves the training but also allows for\nbetter generalization to new environments.",
    "descriptor": "\nComments: Artificial Intelligence and Statistics 2022\n",
    "authors": [
      "Hao Jin",
      "Yang Peng",
      "Wenhao Yang",
      "Shusen Wang",
      "Zhihua Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2204.02634"
  },
  {
    "id": "arXiv:2204.02635",
    "title": "PVI-DSO: Leveraging Planar Regularities for Direct Sparse  Visual-Inertial Odometry",
    "abstract": "The monocular Visual-Inertial Odometry (VIO) based on the direct method can\nleverage all the available pixels in the image to estimate the camera motion\nand reconstruct the environment. The denser map reconstruction provides more\ninformation about the environment, making it easier to extract structure and\nplanar regularities. In this paper, we propose a monocular direct sparse\nvisual-inertial odometry, which exploits the plane regularities (PVI-DSO). Our\nsystem detects coplanar information from 3D meshes generated from 3D point\nclouds and uses coplanar parameters to introduce coplanar constraints. In order\nto reduce computation and improve compactness, the plane-distance cost is\ndirectly used as the prior information of plane parameters. We conduct ablation\nexperiments on public datasets and compare our system with other\nstate-of-the-art algorithms. The experimental results verified leveraging the\nplane information can improve the accuracy of the VIO system based on the\ndirect method.",
    "descriptor": "",
    "authors": [
      "Bo Xu",
      "Xin Li",
      "JianCheng Li",
      "Chau Yuen",
      "JiCheng Dai",
      "YiQun Gong"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2204.02635"
  },
  {
    "id": "arXiv:2204.02636",
    "title": "Failure Identification from Unstable Log Data using Deep Learning",
    "abstract": "The reliability of cloud platforms is of significant relevance because\nsociety increasingly relies on complex software systems running on the cloud.\nTo improve it, cloud providers are automating various maintenance tasks, with\nfailure identification frequently being considered. The precondition for\nautomation is the availability of observability tools, with system logs\ncommonly being used. The focus of this paper is log-based failure\nidentification. This problem is challenging because of the instability of the\nlog data and the incompleteness of the explicit logging failure coverage within\nthe code. To address the two challenges, we present CLog as a method for\nfailure identification. The key idea presented herein based is on our\nobservation that by representing the log data as sequences of subprocesses\ninstead of sequences of log events, the effect of the unstable log data is\nreduced. CLog introduces a novel subprocess extraction method that uses\ncontext-aware neural network and clustering methods to extract meaningful\nsubprocesses. The direct modeling of log event contexts allows the\nidentification of failures with respect to the abrupt context changes,\naddressing the challenge of insufficient logging failure coverage. Our\nexperimental results demonstrate that the learned subprocesses representations\nreduce the instability in the input, allowing CLog to outperform the baselines\non the failure identification subproblems - 1) failure detection by 9-24% on F1\nscore and 2) failure type identification by 7% on the macro averaged F1 score.\nFurther analysis shows the existent negative correlation between the\ninstability in the input event sequences and the detection performance in a\nmodel-agnostic manner.",
    "descriptor": "\nComments: This paper is accepted for publication at IEEE CCGrid 2022. For fairest citation, please use the original proceedings credentials\n",
    "authors": [
      "Jasmin Bogatinovski",
      "Sasho Nedelkoski",
      "Li Wu",
      "Jorge Cardoso",
      "Odej Kao"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.02636"
  },
  {
    "id": "arXiv:2204.02638",
    "title": "Monotone Improvement of Information-Geometric Optimization Algorithms  with a Surrogate Function",
    "abstract": "A surrogate function is often employed to reduce the number of objective\nfunction evaluations for optimization. However, the effect of using a surrogate\nmodel in evolutionary approaches has not been theoretically investigated. This\npaper theoretically analyzes the information-geometric optimization framework\nusing a surrogate function. The value of the expected objective function under\nthe candidate sampling distribution is used as the measure of progress of the\nalgorithm. We assume that the surrogate function is maintained so that the\npopulation version of the Kendall's rank correlation coefficient between the\nsurrogate function and the objective function under the candidate sampling\ndistribution is greater than or equal to a predefined threshold. We prove that\ninformation-geometric optimization using such a surrogate function leads to a\nmonotonic decrease in the expected objective function value if the threshold is\nsufficiently close to one. The acceptable threshold value is analyzed for the\ncase of the information-geometric optimization instantiated with Gaussian\ndistributions, i.e., the rank-$\\mu$ update CMA-ES, on a convex quadratic\nobjective function. As an alternative to the Kendall's rank correlation\ncoefficient, we investigate the use of the Pearson correlation coefficient\nbetween the weights assigned to candidate solutions based on the objective\nfunction and the surrogate function.",
    "descriptor": "\nComments: accepted for GECCO 2022\n",
    "authors": [
      "Youhei Akimoto"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2204.02638"
  },
  {
    "id": "arXiv:2204.02641",
    "title": "The Swiss Army Knife for Image-to-Image Translation: Multi-Task  Diffusion Models",
    "abstract": "Recently, diffusion models were applied to a wide range of image analysis\ntasks. We build on a method for image-to-image translation using denoising\ndiffusion implicit models and include a regression problem and a segmentation\nproblem for guiding the image generation to the desired output. The main\nadvantage of our approach is that the guidance during the denoising process is\ndone by an external gradient. Consequently, the diffusion model does not need\nto be retrained for the different tasks on the same dataset. We apply our\nmethod to simulate the aging process on facial photos using a regression task,\nas well as on a brain magnetic resonance (MR) imaging dataset for the\nsimulation of brain tumor growth. Furthermore, we use a segmentation model to\ninpaint tumors at the desired location in healthy slices of brain MR images. We\nachieve convincing results for all problems.",
    "descriptor": "",
    "authors": [
      "Julia Wolleb",
      "Robin Sandk\u00fchler",
      "Florentin Bieder",
      "Philippe C. Cattin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.02641"
  },
  {
    "id": "arXiv:2204.02643",
    "title": "Modular pre-processing for automated reasoning in dependent type theory",
    "abstract": "The power of modern automated theorem provers can be put at the service of\ninteractive theorem proving. But this requires in particular bridging the\nexpressivity gap between the logics these provers are respectively based on.\nThis paper presents the implementation of a modular suite of pre-processing\ntransformations, which incrementally bring certain formulas expressed in the\nCalculus of Inductive Constructions closer to the first-order logic of\nSatifiability Modulo Theory solvers. These transformations address issues\nrelated to the axiomatization of inductive types, to polymorphic definitions or\nto the different implementations of a same theory signature. This suite is\nimplemented as a plugin for the Coq proof assistant, and integrated to the\nSMTCoq toolchain.",
    "descriptor": "",
    "authors": [
      "Valentin Blot",
      "Denis Cousineau",
      "Enzo Crance",
      "Louise Dubois de Prisque",
      "Chantal Keller",
      "Assia Mahboubi",
      "Pierre Vial"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2204.02643"
  },
  {
    "id": "arXiv:2204.02646",
    "title": "Black-Box Min--Max Continuous Optimization Using CMA-ES with Worst-case  Ranking Approximation",
    "abstract": "In this study, we investigate the problem of min-max continuous optimization\nin a black-box setting $\\min_{x} \\max_{y}f(x,y)$. A popular approach updates\n$x$ and $y$ simultaneously or alternatingly. However, two major limitations\nhave been reported in existing approaches. (I) As the influence of the\ninteraction term between $x$ and $y$ (e.g., $x^\\mathrm{T} B y$) on the\nLipschitz smooth and strongly convex-concave function $f$ increases, the\napproaches converge to an optimal solution at a slower rate. (II) The\napproaches fail to converge if $f$ is not Lipschitz smooth and strongly\nconvex-concave around the optimal solution. To address these difficulties, we\npropose minimizing the worst-case objective function $F(x)=\\max_{y}f(x,y)$\ndirectly using the covariance matrix adaptation evolution strategy, in which\nthe rankings of solution candidates are approximated by our proposed worst-case\nranking approximation (WRA) mechanism. Compared with existing approaches,\nnumerical experiments show two important findings regarding our proposed\nmethod. (1) The proposed approach is efficient in terms of $f$-calls on a\nLipschitz smooth and strongly convex-concave function with a large interaction\nterm. (2) The proposed approach can converge on functions that are not\nLipschitz smooth and strongly convex-concave around the optimal solution,\nwhereas existing approaches fail.",
    "descriptor": "\nComments: accepted for GECCO 2022\n",
    "authors": [
      "Atsuhiro Miyagi",
      "Kazuto Fukuchi",
      "Jun Sakuma",
      "Youhei Akimoto"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2204.02646"
  },
  {
    "id": "arXiv:2204.02650",
    "title": "Spatio-Temporal Dynamic Graph Relation Learning for Urban Metro Flow  Prediction",
    "abstract": "Urban metro flow prediction is of great value for metro operation scheduling,\npassenger flow management and personal travel planning. However, it faces two\nmain challenges. First, different metro stations, e.g. transfer stations and\nnon-transfer stations, have unique traffic patterns. Second, it is challenging\nto model complex spatio-temporal dynamic relation of metro stations. To address\nthese challenges, we develop a spatio-temporal dynamic graph relational\nlearning model (STDGRL) to predict urban metro station flow. First, we propose\na spatio-temporal node embedding representation module to capture the traffic\npatterns of different stations. Second, we employ a dynamic graph relationship\nlearning module to learn dynamic spatial relationships between metro stations\nwithout a predefined graph adjacency matrix. Finally, we provide a\ntransformer-based long-term relationship prediction module for long-term metro\nflow prediction. Extensive experiments are conducted based on metro data in\nBeijing, Shanghai, Chongqing and Hangzhou. Experimental results show the\nadvantages of our method beyond 11 baselines for urban metro flow prediction.",
    "descriptor": "",
    "authors": [
      "Peng Xie",
      "Minbo Ma",
      "Tianrui Li",
      "Shenggong Ji",
      "Shengdong Du",
      "Zeng Yu",
      "Junbo Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.02650"
  },
  {
    "id": "arXiv:2204.02651",
    "title": "Scheduling Coflows for Minimizing the Total Weighted Completion Time in  Identical Parallel Networks",
    "abstract": "Coflow is a recently proposed network abstraction to capture communication\npatterns in data centers. The coflow scheduling problem in large data centers\nis one of the most important $NP$-hard problems. Previous research on coflow\nscheduling focused mainly on the single-switch model. However, with recent\ntechnological developments, this single-core model is no longer sufficient.\nThis paper considers the coflow scheduling problem in identical parallel\nnetworks. The identical parallel network is an architecture based on multiple\nnetwork cores running in parallel. Coflow can be considered as divisible or\nindivisible. Different flows in a divisible coflow can be transmitted through\ndifferent network cores. Considering the divisible coflow scheduling problem,\nwe propose a $(6-\\frac{2}{m})$-approximation algorithm with arbitrary release\ntimes, and a $(5-\\frac{2}{m})$-approximation without release time, where $m$ is\nthe number of network cores. On the other hand, when coflow is indivisible, we\npropose a $(7-\\frac{2}{m})$-approximation algorithm with arbitrary release\ntimes, and a $(6-\\frac{2}{m})$-approximation without release time.",
    "descriptor": "",
    "authors": [
      "Chi-Yeh Chen"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2204.02651"
  },
  {
    "id": "arXiv:2204.02653",
    "title": "Using Synthetic Data for Conversational Response Generation in  Low-resource Settings",
    "abstract": "Response generation is a task in natural language processing (NLP) where a\nmodel is trained to respond to human statements. Conversational response\ngenerators take this one step further with the ability to respond within the\ncontext of previous responses. While there are existing techniques for training\nsuch models, they all require an abundance of conversational data which are not\nalways available for low-resource languages. In this research, we make three\ncontributions. First, we released the first Filipino conversational dataset\ncollected from a popular Philippine online forum, which we named the PEx\nConversations Dataset. Second, we introduce a data augmentation (DA)\nmethodology for Filipino data by employing a Tagalog RoBERTa model to increase\nthe size of the existing corpora. Lastly, we published the first Filipino\nconversational response generator capable of generating responses related to\nthe previous 3 responses. With the supplementary synthetic data, we were able\nto improve the performance of the response generator by up to 12.2% in\nBERTScore, 10.7% in perplexity, and 11.7% in content word usage as compared to\ntraining with zero synthetic data.",
    "descriptor": "",
    "authors": [
      "Gabriel Louis Tan",
      "Adrian Paule Ty",
      "Schuyler Ng",
      "Denzel Adrian Co",
      "Jan Christian Blaise Cruz",
      "Charibeth Cheng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.02653"
  },
  {
    "id": "arXiv:2204.02654",
    "title": "Adversarial Analysis of the Differentially-Private Federated Learning in  Cyber-Physical Critical Infrastructures",
    "abstract": "Differential privacy (DP) is considered to be an effective\nprivacy-preservation method to secure the promising distributed machine\nlearning (ML) paradigm-federated learning (FL) from privacy attacks (e.g.,\nmembership inference attack). Nevertheless, while the DP mechanism greatly\nalleviates privacy concerns, recent studies have shown that it can be exploited\nto conduct security attacks (e.g., false data injection attacks). To address\nsuch attacks on FL-based applications in critical infrastructures, in this\npaper, we perform the first systematic study on the DP-exploited poisoning\nattacks from an adversarial point of view. We demonstrate that the DP method,\ndespite providing a level of privacy guarantee, can effectively open a new\npoisoning attack vector for the adversary. Our theoretical analysis and\nempirical evaluation of a smart grid dataset show the FL performance\ndegradation (sub-optimal model generation) scenario due to the differential\nnoise-exploited selective model poisoning attacks. As a countermeasure, we\npropose a reinforcement learning-based differential privacy level selection\n(rDP) process. The rDP process utilizes the differential privacy parameters\n(privacy loss, information leakage probability, etc.) and the losses to\nintelligently generate an optimal privacy level for the nodes. The evaluation\nshows the accumulated reward and errors of the proposed technique converge to\nan optimal privacy policy.",
    "descriptor": "\nComments: 11 pages, 5 figures, 4 tables. This work has been submitted to IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Md Tamjid Hossain",
      "Shahriar Badsha",
      "Hung",
      "Haoting Shen",
      "Shafkat Islam",
      "Ibrahim Khalil",
      "Xun Yi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2204.02654"
  },
  {
    "id": "arXiv:2204.02655",
    "title": "Location-assisted precoding in 5G LEO systems: architectures and  performances",
    "abstract": "Satellite communication systems are a fundamental component in support of\nEurope's ambition to deploy smart and sustainable networks and services for the\nsuccess of its digital economy. To cope with the 5G and beyond ever increasing\ndemand for larger throughput, aggressive frequency reuse schemes (i.e., full\nfrequency reuse), with the implementation of precoding/beamforming to cope with\nthe massive co-channel interference, are recognised as one of the key\ntechnologies. While the best performance can be obtained with the knowledge of\nthe Channel State Information (CSI) at the transmitter, this also poses some\ntechnical challenges related to signalling and synchronisation. In this paper,\nwe focus on precoding solutions that only needs the knowledge of the users'\npositions at the transmitter side, namely the recently introduced Switchable\nMulti-Beam (MB) and Spatially Sampled MMSE (SS-MMSE) precoding. Compared to the\nvast majority of the studies in the literature, we take into account both the\nusers' and the satellite movement in a Low Earth Orbit (LEO)\nmega-constellation, also proposing two system architectures. The extensive\nnumerical assessment provides a valuable insight on the performance of these\ntwo precoding schemes compared to the optimal MMSE solution.",
    "descriptor": "\nComments: Accepted for publication to EuCNC 2022\n",
    "authors": [
      "Alessandro Guidotti",
      "Carla Amatetti",
      "Fabrice Arnal",
      "Baptiste Chamaillard",
      "Alessandro Vanelli-Coralli"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2204.02655"
  },
  {
    "id": "arXiv:2204.02656",
    "title": "CHIEF: Clustering with Higher-order Motifs in Big Networks",
    "abstract": "Clustering a group of vertices in networks facilitates applications across\ndifferent domains, such as social computing and Internet of Things. However,\nchallenges arises for clustering networks with increased scale. This paper\nproposes a solution which consists of two motif clustering techniques: standard\nacceleration CHIEF-ST and approximate acceleration CHIEF-AP. Both algorithms\nfirst find the maximal k-edge-connected subgraphs within the target networks to\nlower the network scale, then employ higher-order motifs in clustering. In the\nfirst procedure, we propose to lower the network scale by optimizing the\nnetwork structure with maximal k-edge-connected subgraphs. For CHIEF-ST, we\nillustrate that all target motifs will be kept after this procedure when the\nminimum node degree of the target motif is equal or greater than k. For\nCHIEF-AP, we prove that the eigenvalues of the adjacency matrix and the\nLaplacian matrix are relatively stable after this step. That is, CHIEF-ST has\nno influence on motif clustering, whereas CHIEF-AP introduces limited yet\nacceptable impact. In the second procedure, we employ higher-order motifs,\ni.e., heterogeneous four-node motifs clustering in higher-order dense networks.\nThe contributions of CHIEF are two-fold: (1) improved efficiency of motif\nclustering for big networks; (2) verification of higher-order motif\nsignificance. The proposed solutions are found to outperform baseline\napproaches according to experiments on real and synthetic networks, which\ndemonstrates CHIEF's strength in large network analysis. Meanwhile,\nhigher-order motifs are proved to perform better than traditional triangle\nmotifs in clustering.",
    "descriptor": "",
    "authors": [
      "Feng Xia",
      "Shuo Yu",
      "Chengfei Liu",
      "Ivan Lee"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.02656"
  },
  {
    "id": "arXiv:2204.02658",
    "title": "Yunshan Cup 2020: Overview of the Part-of-Speech Tagging Task for  Low-resourced Languages",
    "abstract": "The Yunshan Cup 2020 track focused on creating a framework for evaluating\ndifferent methods of part-of-speech (POS). There were two tasks for this track:\n(1) POS tagging for the Indonesian language, and (2) POS tagging for the Lao\ntagging. The Indonesian dataset is comprised of 10000 sentences from Indonesian\nnews within 29 tags. And the Lao dataset consists of 8000 sentences within 27\ntags. 25 teams registered for the task. The methods of participants ranged from\nfeature-based to neural networks using either classical machine learning\ntechniques or ensemble methods. The best performing results achieve an accuracy\nof 95.82% for Indonesian and 93.03%, showing that neural sequence labeling\nmodels significantly outperform classic feature-based methods and rule-based\nmethods.",
    "descriptor": "",
    "authors": [
      "Yingwen Fu",
      "Jinyi Chen",
      "Nankai Lin",
      "Xixuan Huang",
      "Xinying Qiu",
      "Shengyi Jiang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.02658"
  },
  {
    "id": "arXiv:2204.02659",
    "title": "ConvSearch: A Open-Domain Conversational Search Behavior Dataset",
    "abstract": "Conversational Search has been paid much attention recently with the\nincreasing popularity of intelligent user interfaces. However, compared with\nthe endeavour in designing effective conversational search algorithms,\nrelatively much fewer researchers have focused on the construction of benchmark\ndatasets. For most existing datasets, the information needs are defined by\nresearchers and search requests are not proposed by actual users. Meanwhile,\nthese datasets usually focus on the conversations between users and agents\n(systems), while largely ignores the search behaviors of agents before they\nreturn response to users. To overcome these problems, we construct a Chinese\nOpen-Domain Conversational Search Behavior Dataset (ConvSearch) based on\nWizard-of-Oz paradigm in the field study scenario. We develop a novel\nconversational search platform to collect dialogue contents, annotate dialogue\nquality and candidate search results and record agent search behaviors. 25\nsearch agents and 51 users are recruited for the field study that lasts about\n45 days. The ConvSearch dataset contains 1,131 dialogues together with\nannotated search results and corresponding search behaviors. We also provide\nthe intent labels of each search behavior iteration to support intent\nunderstanding related researches. The dataset is already open to public for\nacademic usage.",
    "descriptor": "\nComments: 10 pages\n",
    "authors": [
      "Zhumin Chu",
      "Zhihong Wang",
      "Yiqun Liu",
      "Yingye Huang",
      "Min Zhang",
      "Shaoping Ma"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2204.02659"
  },
  {
    "id": "arXiv:2204.02661",
    "title": "CAIPI in Practice: Towards Explainable Interactive Medical Image  Classification",
    "abstract": "Would you trust physicians if they cannot explain their decisions to you?\nMedical diagnostics using machine learning gained enormously in importance\nwithin the last decade. However, without further enhancements many\nstate-of-the-art machine learning methods are not suitable for medical\napplication. The most important reasons are insufficient data set quality and\nthe black-box behavior of machine learning algorithms such as Deep Learning\nmodels. Consequently, end-users cannot correct the model's decisions and the\ncorresponding explanations. The latter is crucial for the trustworthiness of\nmachine learning in the medical domain. The research field explainable\ninteractive machine learning searches for methods that address both\nshortcomings. This paper extends the explainable and interactive CAIPI\nalgorithm and provides an interface to simplify human-in-the-loop approaches\nfor image classification. The interface enables the end-user (1) to investigate\nand (2) to correct the model's prediction and explanation, and (3) to influence\nthe data set quality. After CAIPI optimization with only a single\ncounterexample per iteration, the model achieves an accuracy of $97.48\\%$ on\nthe Medical MNIST and $95.02\\%$ on the Fashion MNIST. This accuracy is\napproximately equal to state-of-the-art Deep Learning optimization procedures.\nBesides, CAIPI reduces the labeling effort by approximately $80\\%$.",
    "descriptor": "\nComments: Manuscript accepted at IFIP AIAI 2022\n",
    "authors": [
      "Emanuel Slany",
      "Yannik Ott",
      "Stephan Scheele",
      "Jan Paulus",
      "Ute Schmid"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2204.02661"
  },
  {
    "id": "arXiv:2204.02662",
    "title": "Accelerating Backward Aggregation in GCN Training with Execution Path  Preparing on GPUs",
    "abstract": "The emerging Graph Convolutional Network (GCN) has now been widely used in\nmany domains, and it is challenging to improve the efficiencies of applications\nby accelerating the GCN trainings. For the sparsity nature and exploding scales\nof input real-world graphs, state-of-the-art GCN training systems (e.g.,\nGNNAdvisor) employ graph processing techniques to accelerate the message\nexchanging (i.e. aggregations) among the graph vertices. Nevertheless, these\nsystems treat both the aggregation stages of forward and backward propagation\nphases as all-active graph processing procedures that indiscriminately conduct\ncomputation on all vertices of an input graph.\nIn this paper, we first point out that in a GCN training problem with a given\ntraining set, the aggregation stages of its backward propagation phase (called\nas backward aggregations in this paper) can be converted to partially-active\ngraph processing procedures, which conduct computation on only partial vertices\nof the input graph. By leveraging such a finding, we propose an execution path\npreparing method that collects and coalesces the data used during backward\npropagations of GCN training conducted on GPUs. The experimental results show\nthat compared with GNNAdvisor, our approach improves the performance of the\nbackward aggregation of GCN trainings on typical real-world graphs by\n1.48x~5.65x. Moreover, the execution path preparing can be conducted either\nbefore the training (during preprocessing) or on-the-fly with the training.\nWhen used during preprocessing, our approach improves the overall GCN training\nby 1.05x~1.37x. And when used on-the-fly, our approach improves the overall GCN\ntraining by 1.03x~1.35x.",
    "descriptor": "",
    "authors": [
      "Shaoxian Xu",
      "Zhiyuan Shao",
      "Ci Yang",
      "Xiaofei Liao",
      "Hai Jin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.02662"
  },
  {
    "id": "arXiv:2204.02667",
    "title": "Familiarity-based Collaborative Team Recognition in Academic Social  Networks",
    "abstract": "Collaborative teamwork is key to major scientific discoveries. However, the\nprevalence of collaboration among researchers makes team recognition\nincreasingly challenging. Previous studies have demonstrated that people are\nmore likely to collaborate with individuals they are familiar with. In this\nwork, we employ the definition of familiarity and then propose MOTO\n(faMiliarity-based cOllaborative Team recOgnition algorithm) to recognize\ncollaborative teams. MOTO calculates the shortest distance matrix within the\nglobal collaboration network and the local density of each node. Central team\nmembers are initially recognized based on local density. Then MOTO recognizes\nthe remaining team members by using the familiarity metric and shortest\ndistance matrix. Extensive experiments have been conducted upon a large-scale\ndata set. The experimental results show that compared with baseline methods,\nMOTO can recognize the largest number of teams. The teams recognized by MOTO\npossess more cohesive team structures and lower team communication costs\ncompared with other methods. MOTO utilizes familiarity in team recognition to\nidentify cohesive academic teams. The recognized teams are in line with\nreal-world collaborative teamwork patterns. Based on team recognition using\nMOTO, the research team structure and performance are further analyzed for\ngiven time periods. The number of teams that consist of members from different\ninstitutions increases gradually. Such teams are found to perform better in\ncomparison with those whose members are from the same institution.",
    "descriptor": "",
    "authors": [
      "Shuo Yu",
      "Feng Xia",
      "Chen Zhang",
      "Kathleen Keogh",
      "Honglong Chen"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2204.02667"
  },
  {
    "id": "arXiv:2204.02668",
    "title": "Disentangling the Computational Complexity of Network Untangling",
    "abstract": "We study the network untangling problem introduced by Rozenshtein, Tatti, and\nGionis [DMKD 2021], which is a variant of Vertex Cover on temporal graphs --\ngraphs whose edge set changes over discrete time steps. They introduce two\nproblem variants. The goal is to select at most $k$ time intervals for each\nvertex such that all time-edges are covered and (depending on the problem\nvariant) either the maximum interval length or the total sum of interval\nlengths is minimized. This problem has data mining applications in finding\nactivity timelines that explain the interactions of entities in complex\nnetworks.\nBoth variants of the problem are NP-hard. In this paper, we initiate a\nmultivariate complexity analysis involving the following parameters: number of\nvertices, lifetime of the temporal graph, number of intervals per vertex, and\nthe interval length bound. For both problem versions, we (almost) completely\nsettle the parameterized complexity for all combinations of those four\nparameters, thereby delineating the border of fixed-parameter tractability.",
    "descriptor": "",
    "authors": [
      "Vincent Froese",
      "Pascal Kunz",
      "Philipp Zschoche"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Artificial Intelligence (cs.AI)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2204.02668"
  },
  {
    "id": "arXiv:2204.02670",
    "title": "MDS and AMDS symbol-pair codes are constructed from repeated-root codes",
    "abstract": "Symbol-pair codes introduced by Cassuto and Blaum in 2010 are designed to\nprotect against the pair errors in symbol-pair read channels. One of the\ncentral themes in symbol-error correction is the construction of maximal\ndistance separable (MDS) symbol-pair codes that possess the largest possible\npair-error correcting performance. In this paper, we propose three new classes\nof MDS symbol-pair codes with the length $lp$ or $3p$ and we also give two new\nclasses of (almost maximal distance separable) AMDS symbol-pair codes with the\nlength $lp$ or $4p$ by virtue of repeated-root cyclic codes. The main results\nare obtained by determining the solutions of certain equations over finite\nfields.",
    "descriptor": "\nComments: 23 pages\n",
    "authors": [
      "Xiuxin Tang",
      "Rong Luo"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2204.02670"
  },
  {
    "id": "arXiv:2204.02674",
    "title": "Faster-TAD: Towards Temporal Action Detection with Proposal Generation  and Classification in a Unified Network",
    "abstract": "Temporal action detection (TAD) aims to detect the semantic labels and\nboundaries of action instances in untrimmed videos. Current mainstream\napproaches are multi-step solutions, which fall short in efficiency and\nflexibility. In this paper, we propose a unified network for TAD, termed\nFaster-TAD, by re-purposing a Faster-RCNN like architecture. To tackle the\nunique difficulty in TAD, we make important improvements over the original\nframework. We propose a new Context-Adaptive Proposal Module and an innovative\nFake-Proposal Generation Block. What's more, we use atomic action features to\nimprove the performance. Faster-TAD simplifies the pipeline of TAD and gets\nremarkable performance on lots of benchmarks, i.e., ActivityNet-1.3 (40.01%\nmAP), HACS Segments (38.39% mAP), SoccerNet-Action Spotting (54.09% mAP). It\noutperforms existing single-network detector by a large margin.",
    "descriptor": "\nComments: 16 pages,5 figures\n",
    "authors": [
      "Shimin Chen",
      "Chen Chen",
      "Wei Li",
      "Xunqiang Tao",
      "Yandong Guo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.02674"
  },
  {
    "id": "arXiv:2204.02675",
    "title": "Rolling Colors: Adversarial Laser Exploits against Traffic Light  Recognition",
    "abstract": "Traffic light recognition is essential for fully autonomous driving in urban\nareas. In this paper, we investigate the feasibility of fooling traffic light\nrecognition mechanisms by shedding laser interference on the camera. By\nexploiting the rolling shutter of CMOS sensors, we manage to inject a color\nstripe overlapped on the traffic light in the image, which can cause a red\nlight to be recognized as a green light or vice versa. To increase the success\nrate, we design an optimization method to search for effective laser parameters\nbased on empirical models of laser interference. Our evaluation in emulated and\nreal-world setups on 2 state-of-the-art recognition systems and 5 cameras\nreports a maximum success rate of 30% and 86.25% for Red-to-Green and\nGreen-to-Red attacks. We observe that the attack is effective in continuous\nframes from more than 40 meters away against a moving vehicle, which may cause\nend-to-end impacts on self-driving such as running a red light or emergency\nstop. To mitigate the threat, we propose redesigning the rolling shutter\nmechanism.",
    "descriptor": "\nComments: To be published in USENIX Security 2022\n",
    "authors": [
      "Chen Yan",
      "Zhijian Xu",
      "Zhanyuan Yin",
      "Xiaoyu Ji",
      "Wenyuan Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2204.02675"
  },
  {
    "id": "arXiv:2204.02676",
    "title": "Detecting Outlier Patterns with Query-based Artificially Generated  Searching Conditions",
    "abstract": "In the age of social computing, finding interesting network patterns or\nmotifs is significant and critical for various areas such as decision\nintelligence, intrusion detection, medical diagnosis, social network analysis,\nfake news identification, national security, etc. However, sub-graph matching\nremains a computationally challenging problem, let alone identifying special\nmotifs among them. This is especially the case in large heterogeneous\nreal-world networks. In this work, we propose an efficient solution for\ndiscovering and ranking human behavior patterns based on network motifs by\nexploring a user's query in an intelligent way. Our method takes advantage of\nthe semantics provided by a user's query, which in turn provides the\nmathematical constraint that is crucial for faster detection. We propose an\napproach to generate query conditions based on the user's query. In particular,\nwe use meta paths between nodes to define target patterns as well as their\nsimilarities, leading to efficient motif discovery and ranking at the same\ntime. The proposed method is examined on a real-world academic network, using\ndifferent similarity measures between the nodes. The experiment result\ndemonstrates that our method can identify interesting motifs, and is robust to\nthe choice of similarity measures.",
    "descriptor": "",
    "authors": [
      "Shuo Yu",
      "Feng Xia",
      "Yuchen Sun",
      "Tao Tang",
      "Xiaoran Yan",
      "Ivan Lee"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2204.02676"
  },
  {
    "id": "arXiv:2204.02681",
    "title": "PP-LiteSeg: A Superior Real-Time Semantic Segmentation Model",
    "abstract": "Real-world applications have high demands for semantic segmentation methods.\nAlthough semantic segmentation has made remarkable leap-forwards with deep\nlearning, the performance of real-time methods is not satisfactory. In this\nwork, we propose PP-LiteSeg, a novel lightweight model for the real-time\nsemantic segmentation task. Specifically, we present a Flexible and Lightweight\nDecoder (FLD) to reduce computation overhead of previous decoder. To strengthen\nfeature representations, we propose a Unified Attention Fusion Module (UAFM),\nwhich takes advantage of spatial and channel attention to produce a weight and\nthen fuses the input features with the weight. Moreover, a Simple Pyramid\nPooling Module (SPPM) is proposed to aggregate global context with low\ncomputation cost. Extensive evaluations demonstrate that PP-LiteSeg achieves a\nsuperior trade-off between accuracy and speed compared to other methods. On the\nCityscapes test set, PP-LiteSeg achieves 72.0% mIoU/273.6 FPS and 77.5%\nmIoU/102.6 FPS on NVIDIA GTX 1080Ti. Source code and models are available at\nPaddleSeg: https://github.com/PaddlePaddle/PaddleSeg.",
    "descriptor": "",
    "authors": [
      "Juncai Peng",
      "Yi Liu",
      "Shiyu Tang",
      "Yuying Hao",
      "Lutao Chu",
      "Guowei Chen",
      "Zewu Wu",
      "Zeyu Chen",
      "Zhiliang Yu",
      "Yuning Du",
      "Qingqing Dang",
      "Baohua Lai",
      "Qiwen Liu",
      "Xiaoguang Hu",
      "Dianhai Yu",
      "Yanjun Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.02681"
  },
  {
    "id": "arXiv:2204.02683",
    "title": "Beyond Separability: Analyzing the Linear Transferability of Contrastive  Representations to Related Subpopulations",
    "abstract": "Contrastive learning is a highly effective method which uses unlabeled data\nto produce representations which are linearly separable for downstream\nclassification tasks. Recent works have shown that contrastive representations\nare not only useful when data come from a single domain, but are also effective\nfor transferring across domains. Concretely, when contrastive representations\nare trained on data from two domains (a source and target) and a linear\nclassification head is trained to predict labels using only the labeled source\ndata, the resulting classifier also exhibits good transfer to the target\ndomain. In this work, we analyze this linear transferability phenomenon,\nbuilding upon the framework proposed by HaoChen et al (2021) which relates\ncontrastive learning to spectral clustering of a positive-pair graph on the\ndata. We prove that contrastive representations capture relationships between\nsubpopulations in the positive-pair graph: linear transferability can occur\nwhen data from the same class in different domains (e.g., photo dogs and\ncartoon dogs) are connected in the graph. Our analysis allows the source and\ntarget classes to have unbounded density ratios and be mapped to distant\nrepresentations. Our proof is also built upon technical improvements over the\nmain results of HaoChen et al (2021), which may be of independent interest.",
    "descriptor": "",
    "authors": [
      "Jeff Z. HaoChen",
      "Colin Wei",
      "Ananya Kumar",
      "Tengyu Ma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.02683"
  },
  {
    "id": "arXiv:2204.02684",
    "title": "Domain-Agnostic Prior for Transfer Semantic Segmentation",
    "abstract": "Unsupervised domain adaptation (UDA) is an important topic in the computer\nvision community. The key difficulty lies in defining a common property between\nthe source and target domains so that the source-domain features can align with\nthe target-domain semantics. In this paper, we present a simple and effective\nmechanism that regularizes cross-domain representation learning with a\ndomain-agnostic prior (DAP) that constrains the features extracted from source\nand target domains to align with a domain-agnostic space. In practice, this is\neasily implemented as an extra loss term that requires a little extra costs. In\nthe standard evaluation protocol of transferring synthesized data to real data,\nwe validate the effectiveness of different types of DAP, especially that\nborrowed from a text embedding model that shows favorable performance beyond\nthe state-of-the-art UDA approaches in terms of segmentation accuracy. Our\nresearch reveals that UDA benefits much from better proxies, possibly from\nother data modalities.",
    "descriptor": "",
    "authors": [
      "Xinyue Huo",
      "Lingxi Xie",
      "Hengtong Hu",
      "Wengang Zhou",
      "Houqiang Li",
      "Qi Tian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.02684"
  },
  {
    "id": "arXiv:2204.02685",
    "title": "Language Model for Text Analytic in Cybersecurity",
    "abstract": "NLP is a form of artificial intelligence and machine learning concerned with\na computer or machine's ability to understand and interpret human language.\nLanguage models are crucial in text analytics and NLP since they allow\ncomputers to interpret qualitative input and convert it to quantitative data\nthat they can use in other tasks. In essence, in the context of transfer\nlearning, language models are typically trained on a large generic corpus,\nreferred to as the pre-training stage, and then fine-tuned to a specific\nunderlying task. As a result, pre-trained language models are mostly used as a\nbaseline model that incorporates a broad grasp of the context and may be\nfurther customized to be used in a new NLP task.\nThe majority of pre-trained models are trained on corpora from general\ndomains, such as Twitter, newswire, Wikipedia, and Web. Such off-the-shelf NLP\nmodels trained on general text may be inefficient and inaccurate in specialized\nfields. In this paper, we propose a cybersecurity language model called\nSecureBERT, which is able to capture the text connotations in the cybersecurity\ndomain, and therefore could further be used in automation for many important\ncybersecurity tasks that would otherwise rely on human expertise and tedious\nmanual efforts. SecureBERT is trained on a large corpus of cybersecurity text\ncollected and preprocessed by us from a variety of sources in cybersecurity and\nthe general computing domain. Using our proposed methods for tokenization and\nmodel weights adjustment, SecureBERT is not only able to preserve the\nunderstanding of general English as most pre-trained language models can do,\nbut also effective when applied to text that has cybersecurity implications.",
    "descriptor": "\nComments: This is the initial draft of this work and it may contain errors and typos. The revised version has already been submitted to a venue\n",
    "authors": [
      "Ehsan Aghaei",
      "Xi Niu",
      "Waseem Shadid",
      "Ehab Al-Shaer"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2204.02685"
  },
  {
    "id": "arXiv:2204.02687",
    "title": "Learning to Adapt Clinical Sequences with Residual Mixture of Experts",
    "abstract": "Clinical event sequences in Electronic Health Records (EHRs) record detailed\ninformation about the patient condition and patient care as they occur in time.\nRecent years have witnessed increased interest of machine learning community in\ndeveloping machine learning models solving different types of problems defined\nupon information in EHRs. More recently, neural sequential models, such as RNN\nand LSTM, became popular and widely applied models for representing patient\nsequence data and for predicting future events or outcomes based on such data.\nHowever, a single neural sequential model may not properly represent complex\ndynamics of all patients and the differences in their behaviors. In this work,\nwe aim to alleviate this limitation by refining a one-fits-all model using a\nMixture-of-Experts (MoE) architecture. The architecture consists of multiple\n(expert) RNN models covering patient sub-populations and refining the\npredictions of the base model. That is, instead of training expert RNN models\nfrom scratch we define them on the residual signal that attempts to model the\ndifferences from the population-wide model. The heterogeneity of various\npatient sequences is modeled through multiple experts that consist of RNN.\nParticularly, instead of directly training MoE from scratch, we augment MoE\nbased on the prediction signal from pretrained base GRU model. With this way,\nthe mixture of experts can provide flexible adaptation to the (limited)\npredictive power of the single base RNN model. We experiment with the newly\nproposed model on real-world EHRs data and the multivariate clinical event\nprediction task. We implement RNN using Gated Recurrent Units (GRU). We show\n4.1% gain on AUPRC statistics compared to a single RNN prediction.",
    "descriptor": "\nComments: Accepted at 20th International Conference on Artificial Intelligence in Medicine (AIME) 2022\n",
    "authors": [
      "Jeong Min Lee",
      "Milos Hauskrecht"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2204.02687"
  },
  {
    "id": "arXiv:2204.02688",
    "title": "SEAL: A Large-scale Video Dataset of Multi-grained Spatio-temporally  Action Localization",
    "abstract": "In spite of many dataset efforts for human action recognition, current\ncomputer vision algorithms are still limited to coarse-grained spatial and\ntemporal annotations among human daily life. In this paper, we introduce a\nnovel large-scale video dataset dubbed SEAL for multi-grained Spatio-tEmporal\nAction Localization. SEAL consists of two kinds of annotations, SEAL Tubes and\nSEAL Clips. We observe that atomic actions can be combined into many complex\nactivities. SEAL Tubes provide both atomic action and complex activity\nannotations in tubelet level, producing 49.6k atomic actions spanning 172\naction categories and 17.7k complex activities spanning 200 activity\ncategories. SEAL Clips localizes atomic actions in space during two-second\nclips, producing 510.4k action labels with multiple labels per person.\nExtensive experimental results show that SEAL significantly helps to advance\nvideo understanding.",
    "descriptor": "\nComments: 17 pages,6 figures\n",
    "authors": [
      "Shimin Chen",
      "Wei Li",
      "Chen Chen",
      "Jianyang Gu",
      "Jiaming Chu",
      "Xunqiang Tao",
      "Yandong Guo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.02688"
  },
  {
    "id": "arXiv:2204.02693",
    "title": "Exploration with Global Consistency Using Real-Time Re-integration and  Active Loop Closure",
    "abstract": "Despite recent progress of robotic exploration, most methods assume that\ndrift-free localization is available, which is problematic in reality and\ncauses severe distortion of the reconstructed map. In this work, we present a\nsystematic exploration mapping and planning framework that deals with drifted\nlocalization, allowing efficient and globally consistent reconstruction. A\nreal-time re-integration-based mapping approach along with a frame pruning\nmechanism is proposed, which rectifies map distortion effectively when drifted\nlocalization is corrected upon detecting loop-closure. Besides, an exploration\nplanning method considering historical viewpoints is presented to enable active\nloop closing, which promotes a higher opportunity to correct localization\nerrors and further improves the mapping quality. We evaluate both the mapping\nand planning methods as well as the entire system comprehensively in simulation\nand real-world experiments, showing their effectiveness in practice. The\nimplementation of the proposed method will be made open-source for the benefit\nof the robotics community.",
    "descriptor": "",
    "authors": [
      "Yichen Zhang",
      "Boyu Zhou",
      "Luqi Wang",
      "Shaojie Shen"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2204.02693"
  },
  {
    "id": "arXiv:2204.02697",
    "title": "VNIbCReg: VIbCReg with Neighboring-Invariance and better-Covariance  Evaluated on Non-stationary Seismic Signal Time Series",
    "abstract": "One of the latest self-supervised learning (SSL) methods, VICReg, showed a\ngreat performance both in the linear evaluation and the fine-tuning evaluation.\nHowever, VICReg is proposed in computer vision and it learns by pulling\nrepresentations of random crops of an image while maintaining the\nrepresentation space by the variance and covariance loss. However, VICReg would\nbe ineffective on non-stationary time series where different parts/crops of\ninput should be differently encoded to consider the non-stationarity. Another\nrecent SSL proposal, Temporal Neighborhood Coding (TNC) is effective for\nencoding non-stationary time series. This study shows that a combination of a\nVICReg-style method and TNC is very effective for SSL on non-stationary time\nseries, where a non-stationary seismic signal time series is used as an\nevaluation dataset.",
    "descriptor": "",
    "authors": [
      "Daesoo Lee",
      "Erlend Aune",
      "Nad\u00e8ge Langet",
      "Jo Eidsvik"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Geophysics (physics.geo-ph)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2204.02697"
  },
  {
    "id": "arXiv:2204.02701",
    "title": "Aesthetic Text Logo Synthesis via Content-aware Layout Inferring",
    "abstract": "Text logo design heavily relies on the creativity and expertise of\nprofessional designers, in which arranging element layouts is one of the most\nimportant procedures. However, few attention has been paid to this task which\nneeds to take many factors (e.g., fonts, linguistics, topics, etc.) into\nconsideration. In this paper, we propose a content-aware layout generation\nnetwork which takes glyph images and their corresponding text as input and\nsynthesizes aesthetic layouts for them automatically. Specifically, we develop\na dual-discriminator module, including a sequence discriminator and an image\ndiscriminator, to evaluate both the character placing trajectories and rendered\nshapes of synthesized text logos, respectively. Furthermore, we fuse the\ninformation of linguistics from texts and visual semantics from glyphs to guide\nlayout prediction, which both play important roles in professional layout\ndesign. To train and evaluate our approach, we construct a dataset named as\nTextLogo3K, consisting of about 3,500 text logo images and their pixel-level\nannotations. Experimental studies on this dataset demonstrate the effectiveness\nof our approach for synthesizing visually-pleasing text logos and verify its\nsuperiority against the state of the art.",
    "descriptor": "\nComments: Accepted by CVPR 2022. Code and Dataset: this https URL\n",
    "authors": [
      "Yizhi Wang",
      "Guo Pu",
      "Wenhan Luo",
      "Yexin Wang",
      "Pengfei Xiong",
      "Hongwen Kang",
      "Zhouhui Lian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.02701"
  },
  {
    "id": "arXiv:2204.02704",
    "title": "Fundamental limits to learning closed-form mathematical models from data",
    "abstract": "Given a finite and noisy dataset generated with a closed-form mathematical\nmodel, when is it possible to learn the true generating model from the data\nalone? This is the question we investigate here. We show that this\nmodel-learning problem displays a transition from a low-noise phase in which\nthe true model can be learned, to a phase in which the observation noise is too\nhigh for the true model to be learned by any method. Both in the low-noise\nphase and in the high-noise phase, probabilistic model selection leads to\noptimal generalization to unseen data. This is in contrast to standard machine\nlearning approaches, including artificial neural networks, which are limited,\nin the low-noise phase, by their ability to interpolate. In the transition\nregion between the learnable and unlearnable phases, generalization is hard for\nall approaches including probabilistic model selection.",
    "descriptor": "",
    "authors": [
      "Oscar Fajardo-Fontiveros",
      "Ignasi Reichardt",
      "Harry R. De Los Rios",
      "Jordi Duch",
      "Marta Sales-Pardo",
      "Roger Guimera"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Computational Physics (physics.comp-ph)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ],
    "url": "https://arxiv.org/abs/2204.02704"
  },
  {
    "id": "arXiv:2204.02709",
    "title": "Evolutionary Diversity Optimisation for The Traveling Thief Problem",
    "abstract": "There has been a growing interest in the evolutionary computation community\nto compute a diverse set of high-quality solutions for a given optimisation\nproblem. This can provide the practitioners with invaluable information about\nthe solution space and robustness against imperfect modelling and minor\nproblems' changes. It also enables the decision-makers to involve their\ninterests and choose between various solutions. In this study, we investigate\nfor the first time a prominent multi-component optimisation problem, namely the\nTraveling Thief Problem (TTP), in the context of evolutionary diversity\noptimisation. We introduce a bi-level evolutionary algorithm to maximise the\nstructural diversity of the set of solutions. Moreover, we examine the\ninter-dependency among the components of the problem in terms of structural\ndiversity and empirically determine the best method to obtain diversity. We\nalso conduct a comprehensive experimental investigation to examine the\nintroduced algorithm and compare the results to another recently introduced\nframework based on the use of Quality Diversity (QD). Our experimental results\nshow a significant improvement of the QD approach in terms of structural\ndiversity for most TTP benchmark instances.",
    "descriptor": "\nComments: To appear at GECCO 2022\n",
    "authors": [
      "Adel Nikfarjam",
      "Aneta Neumann",
      "Frank Neumann"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2204.02709"
  },
  {
    "id": "arXiv:2204.02710",
    "title": "Mix-and-Match: Scalable Dialog Response Retrieval using Gaussian Mixture  Embeddings",
    "abstract": "Embedding-based approaches for dialog response retrieval embed the\ncontext-response pairs as points in the embedding space. These approaches are\nscalable, but fail to account for the complex, many-to-many relationships that\nexist between context-response pairs. On the other end of the spectrum, there\nare approaches that feed the context-response pairs jointly through multiple\nlayers of neural networks. These approaches can model the complex relationships\nbetween context-response pairs, but fail to scale when the set of responses is\nmoderately large (>100). In this paper, we combine the best of both worlds by\nproposing a scalable model that can learn complex relationships between\ncontext-response pairs. Specifically, the model maps the contexts as well as\nresponses to probability distributions over the embedding space. We train the\nmodels by optimizing the Kullback-Leibler divergence between the distributions\ninduced by context-response pairs in the training data. We show that the\nresultant model achieves better performance as compared to other\nembedding-based approaches on publicly available conversation data.",
    "descriptor": "\nComments: 10 pages, 2 figures\n",
    "authors": [
      "Gaurav Pandey",
      "Danish Contractor",
      "Sachindra Joshi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.02710"
  },
  {
    "id": "arXiv:2204.02712",
    "title": "A New Dataset for Topic-Based Paragraph Classification in  Genocide-Related Court Transcripts",
    "abstract": "Recent progress in natural language processing has been impressive in many\ndifferent areas with transformer-based approaches setting new benchmarks for a\nwide range of applications. This development has also lowered the barriers for\npeople outside the NLP community to tap into the tools and resources applied to\na variety of domain-specific applications. The bottleneck however still remains\nthe lack of annotated gold-standard collections as soon as one's research or\nprofessional interest falls outside the scope of what is readily available. One\nsuch area is genocide-related research (also including the work of experts who\nhave a professional interest in accessing, exploring and searching large-scale\ndocument collections on the topic, such as lawyers). We present GTC (Genocide\nTranscript Corpus), the first annotated corpus of genocide-related court\ntranscripts which serves three purposes: (1) to provide a first reference\ncorpus for the community, (2) to establish benchmark performances (using\nstate-of-the-art transformer-based approaches) for the new classification task\nof paragraph identification of violence-related witness statements, (3) to\nexplore first steps towards transfer learning within the domain. We consider\nour contribution to be addressing in particular this year's hot topic on\nLanguage Technology for All.",
    "descriptor": "\nComments: Preprint. Accepted to appear in Proceedings of LREC 2022\n",
    "authors": [
      "Miriam Schirmer",
      "Udo Kruschwitz",
      "Gregor Donabauer"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2204.02712"
  },
  {
    "id": "arXiv:2204.02718",
    "title": "Annotation-Scheme Reconstruction for \"Fake News\" and Japanese Fake News  Dataset",
    "abstract": "Fake news provokes many societal problems; therefore, there has been\nextensive research on fake news detection tasks to counter it. Many fake news\ndatasets were constructed as resources to facilitate this task. Contemporary\nresearch focuses almost exclusively on the factuality aspect of the news.\nHowever, this aspect alone is insufficient to explain \"fake news,\" which is a\ncomplex phenomenon that involves a wide range of issues. To fully understand\nthe nature of each instance of fake news, it is important to observe it from\nvarious perspectives, such as the intention of the false news disseminator, the\nharmfulness of the news to our society, and the target of the news. We propose\na novel annotation scheme with fine-grained labeling based on detailed\ninvestigations of existing fake news datasets to capture these various aspects\nof fake news. Using the annotation scheme, we construct and publish the first\nJapanese fake news dataset. The annotation scheme is expected to provide an\nin-depth understanding of fake news. We plan to build datasets for both\nJapanese and other languages using our scheme. Our Japanese dataset is\npublished at https://hkefka385.github.io/dataset/fakenews-japanese/.",
    "descriptor": "\nComments: 13th International Conference on Language Resources and Evaluation (LREC), 2022\n",
    "authors": [
      "Taichi Murayama",
      "Shohei Hisada",
      "Makoto Uehara",
      "Shoko Wakamiya",
      "Eiji Aramaki"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2204.02718"
  },
  {
    "id": "arXiv:2204.02720",
    "title": "Efficient attack sequences in m-eternal domination",
    "abstract": "We study the m-eternal domination problem from the perspective of the\nattacker. For many graph classes, the minimum required number of guards to\ndefend eternally is known. By definition, if the defender has less than the\nrequired number of guards, then there exists a sequence of attacks that ensures\nthe attacker's victory. Little is known about such sequences of attacks, in\nparticular, no bound on its length is known.\nWe show that if the game is played on a tree $T$ on $n$ vertices and the\ndefender has less than the necessary number of guards, then the attacker can\nwin in at most $n$ turns. Furthermore, we present an efficient procedure that\nproduces such an attacking strategy.",
    "descriptor": "",
    "authors": [
      "V\u00e1clav Bla\u017eej",
      "Jan Maty\u00e1\u0161 K\u0159i\u0161\u0165an",
      "Tom\u00e1\u0161 Valla"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2204.02720"
  },
  {
    "id": "arXiv:2204.02725",
    "title": "Improving Multi-task Generalization Ability for Neural Text Matching via  Prompt Learning",
    "abstract": "Text matching is a fundamental technique in both information retrieval and\nnatural language processing. Text matching tasks share the same paradigm that\ndetermines the relationship between two given texts. Evidently, the\nrelationships vary from task to task, e.g. relevance in document retrieval,\nsemantic alignment in paraphrase identification and answerable judgment in\nquestion answering. However, the essential signals for text matching remain in\na finite scope, i.e. exact matching, semantic matching, and inference matching.\nRecent state-of-the-art neural text matching models, e.g. pre-trained language\nmodels (PLMs), are hard to generalize to different tasks. It is because the\nend-to-end supervised learning on task-specific dataset makes model\noveremphasize the data sample bias and task-specific signals instead of the\nessential matching signals, which ruins the generalization of model to\ndifferent tasks. To overcome this problem, we adopt a\nspecialization-generalization training strategy and refer to it as\nMatch-Prompt. In specialization stage, descriptions of different matching tasks\nare mapped to only a few prompt tokens. In generalization stage, text matching\nmodel explores the essential matching signals by being trained on diverse\nmultiple matching tasks. High diverse matching tasks avoid model fitting the\ndata sample bias on a specific task, so that model can focus on learning the\nessential matching signals. Meanwhile, the prompt tokens obtained in the first\nstep are added to the corresponding tasks to help the model distinguish\ndifferent task-specific matching signals. Experimental results on eighteen\npublic datasets show that Match-Prompt can significantly improve multi-task\ngeneralization capability of PLMs in text matching, and yield better in-domain\nmulti-task, out-of-domain multi-task and new task adaptation performance than\ntask-specific model.",
    "descriptor": "",
    "authors": [
      "Shicheng Xu",
      "Liang Pang",
      "Huawei Shen",
      "Xueqi Cheng"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.02725"
  },
  {
    "id": "arXiv:2204.02728",
    "title": "Co-constructing Shared Values and Ethical Practice for the Next  Generation: Lessons Learned from a Curriculum on Information Ethics",
    "abstract": "We present the motivation, design, outline, and lessons learned from an\nonline course in scientific integrity, research ethics, and information ethics\nprovided to over 2000 doctoral and engineering students in STEM fields, first\nat the University Paris-Saclay, and now expanded to an online MOOC available to\nstudents across the world, in English. Unlike a course in scientific domains,\nmeant to provide students with methods, tools, and concepts they can apply in\ntheir future career, the goal of such a training is not so much to equip them,\nbut to make them aware of the impact of their work on society, care about the\nresponsibilities that befall on them, and make them realize not all share the\nsame opinions on how should technology imprint society. While we provide\nconceptual tools, this is more to sustain interest and engage students. We want\nthem to debate on concrete ethical issues and realize the difficulty of\nreconciling positions on contemporary dilemma such as dematerialized\nintellectual property, freedom of expression online and its counterparts, the\nprotection of our digital selves, the management of algorithmic decision, the\ncontrol of autonomous systems, and the resolution of the digital divide. As a\nbold shortcut, our course is about introducing and motivating Hegelian\ndialectics in STEM curricula, usually more bent on an Aristotelian perspective.",
    "descriptor": "\nComments: 21 pages, 7 figures, Book Chapter\n",
    "authors": [
      "Thomas Baudel"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2204.02728"
  },
  {
    "id": "arXiv:2204.02733",
    "title": "Georeferencing of Photovoltaic Modules from Aerial Infrared Videos using  Structure-from-Motion",
    "abstract": "To identify abnormal photovoltaic (PV) modules in large-scale PV plants\neconomically, drone-mounted infrared (IR) cameras and automated video\nprocessing algorithms are frequently used. While most related works focus on\nthe detection of abnormal modules, little has been done to automatically\nlocalize those modules within the plant. In this work, we use incremental\nstructure-from-motion to automatically obtain geocoordinates of all PV modules\nin a plant based on visual cues and the measured GPS trajectory of the drone.\nIn addition, we extract multiple IR images of each PV module. Using our method,\nwe successfully map 99.3 % of the 35084 modules in four large-scale and one\nrooftop plant and extract over 2.2 million module images. As compared to our\nprevious work, extraction misses 18 times less modules (one in 140 modules as\ncompared to one in eight). Furthermore, two or three plant rows can be\nprocessed simultaneously, increasing module throughput and reducing flight\nduration by a factor of 2.1 and 3.7, respectively. Comparison with an accurate\northophoto of one of the large-scale plants yields a root mean square error of\nthe estimated module geocoordinates of 5.87 m and a relative error within each\nplant row of 0.22 m to 0.82 m. Finally, we use the module geocoordinates and\nextracted IR images to visualize distributions of module temperatures and\nanomaly predictions of a deep learning classifier on a map. While the\ntemperature distribution helps to identify disconnected strings, we also find\nthat its detection accuracy for module anomalies reaches, or even exceeds, that\nof a deep learning classifier for seven out of ten common anomaly types. The\nsoftware is published at https://github.com/LukasBommes/PV-Hawk.",
    "descriptor": "",
    "authors": [
      "Lukas Bommes",
      "Claudia Buerhop-Lutz",
      "Tobias Pickel",
      "Jens Hauch",
      "Christoph Brabec",
      "Ian Marius Peters"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.02733"
  },
  {
    "id": "arXiv:2204.02735",
    "title": "Distilling Robust and Non-Robust Features in Adversarial Examples by  Information Bottleneck",
    "abstract": "Adversarial examples, generated by carefully crafted perturbation, have\nattracted considerable attention in research fields. Recent works have argued\nthat the existence of the robust and non-robust features is a primary cause of\nthe adversarial examples, and investigated their internal interactions in the\nfeature space. In this paper, we propose a way of explicitly distilling feature\nrepresentation into the robust and non-robust features, using Information\nBottleneck. Specifically, we inject noise variation to each feature unit and\nevaluate the information flow in the feature representation to dichotomize\nfeature units either robust or non-robust, based on the noise variation\nmagnitude. Through comprehensive experiments, we demonstrate that the distilled\nfeatures are highly correlated with adversarial prediction, and they have\nhuman-perceptible semantic information by themselves. Furthermore, we present\nan attack mechanism intensifying the gradient of non-robust features that is\ndirectly related to the model prediction, and validate its effectiveness of\nbreaking model robustness.",
    "descriptor": "\nComments: NeurIPS 2021\n",
    "authors": [
      "Junho Kim",
      "Byung-Kwan Lee",
      "Yong Man Ro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.02735"
  },
  {
    "id": "arXiv:2204.02737",
    "title": "Adversarial Learning to Reason in an Arbitrary Logic",
    "abstract": "Existing approaches to learning to prove theorems focus on particular logics\nand datasets. In this work, we propose Monte-Carlo simulations guided by\nreinforcement learning that can work in an arbitrarily specified logic, without\nany human knowledge or set of problems. Since the algorithm does not need any\ntraining dataset, it is able to learn to work with any logical foundation, even\nwhen there is no body of proofs or even conjectures available. We practically\ndemonstrate the feasibility of the approach in multiple logical systems. The\napproach is stronger than training on randomly generated data but weaker than\nthe approaches trained on tailored axiom and conjecture sets. It however allows\nus to apply machine learning to automated theorem proving for many logics,\nwhere no such attempts have been tried to date, such as intuitionistic logic or\nlinear logic.",
    "descriptor": "",
    "authors": [
      "Stanis\u0142aw J. Purga\u0142",
      "Cezary Kaliszyk"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.02737"
  },
  {
    "id": "arXiv:2204.02738",
    "title": "Masking Adversarial Damage: Finding Adversarial Saliency for Robust and  Sparse Network",
    "abstract": "Adversarial examples provoke weak reliability and potential security issues\nin deep neural networks. Although adversarial training has been widely studied\nto improve adversarial robustness, it works in an over-parameterized regime and\nrequires high computations and large memory budgets. To bridge adversarial\nrobustness and model compression, we propose a novel adversarial pruning\nmethod, Masking Adversarial Damage (MAD) that employs second-order information\nof adversarial loss. By using it, we can accurately estimate adversarial\nsaliency for model parameters and determine which parameters can be pruned\nwithout weakening adversarial robustness. Furthermore, we reveal that model\nparameters of initial layer are highly sensitive to the adversarial examples\nand show that compressed feature representation retains semantic information\nfor the target objects. Through extensive experiments on three public datasets,\nwe demonstrate that MAD effectively prunes adversarially trained networks\nwithout loosing adversarial robustness and shows better performance than\nprevious adversarial pruning methods.",
    "descriptor": "\nComments: CVPR 2022\n",
    "authors": [
      "Byung-Kwan Lee",
      "Junho Kim",
      "Yong Man Ro"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.02738"
  },
  {
    "id": "arXiv:2204.02739",
    "title": "P4RROT: Generating P4 Code for the Application Layer",
    "abstract": "Throughput and latency critical applications could often benefit of\nperforming computations close to the client. To enable this, distributed\ncomputing paradigms such as edge computing have recently emerged. However, with\nthe advent of programmable data planes, computations cannot only be performed\nby servers but they can be offloaded to network switches. Languages like P4\nenable to flexibly reprogram the entire packet processing pipeline. Though\nthese devices promise high throughput and ultra-low response times,\nimplementing application-layer tasks in the data plane programming language P4\nis still challenging for an application developer who is not familiar with\nnetworking domain. In this paper, we first identify and examine obstacles and\npain points one can experience when offloading server-based computations to the\nnetwork. Then we present P4RROT, a code generator (in form of a library) which\nallows to overcome these limitations by providing a user-friendly API to\ndescribe computations to be offloaded. After discussing the design choices\nbehind P4RROT, we introduce our proof-of-concept implementation for two P4\ntargets: Netronome SmartNIC and BMv2.",
    "descriptor": "",
    "authors": [
      "Csaba Gy\u00f6rgyi",
      "S\u00e1ndor Laki",
      "Stefan Schmid"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2204.02739"
  },
  {
    "id": "arXiv:2204.02743",
    "title": "Towards Multi-Scale Speaking Style Modelling with Hierarchical Context  Information for Mandarin Speech Synthesis",
    "abstract": "Previous works on expressive speech synthesis focus on modelling the\nmono-scale style embedding from the current sentence or context, but the\nmulti-scale nature of speaking style in human speech is neglected. In this\npaper, we propose a multi-scale speaking style modelling method to capture and\npredict multi-scale speaking style for improving the naturalness and\nexpressiveness of synthetic speech. A multi-scale extractor is proposed to\nextract speaking style embeddings at three different levels from the\nground-truth speech, and explicitly guide the training of a multi-scale style\npredictor based on hierarchical context information. Both objective and\nsubjective evaluations on a Mandarin audiobooks dataset demonstrate that our\nproposed method can significantly improve the naturalness and expressiveness of\nthe synthesized speech.",
    "descriptor": "\nComments: Submitted to INTERSPEECH 2022\n",
    "authors": [
      "Shun Lei",
      "Yixuan Zhou",
      "Liyang Chen",
      "Jiankun Hu",
      "Zhiyong Wu",
      "Shiyin Kang",
      "Helen Meng"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2204.02743"
  },
  {
    "id": "arXiv:2204.02744",
    "title": "Universal Representations: A Unified Look at Multiple Task and Domain  Learning",
    "abstract": "We propose a unified look at jointly learning multiple vision tasks and\nvisual domains through universal representations, a single deep neural network.\nLearning multiple problems simultaneously involves minimizing a weighted sum of\nmultiple loss functions with different magnitudes and characteristics and thus\nresults in unbalanced state of one loss dominating the optimization and poor\nresults compared to learning a separate model for each problem. To this end, we\npropose distilling knowledge of multiple task/domain-specific networks into a\nsingle deep neural network after aligning its representations with the\ntask/domain-specific ones through small capacity adapters. We rigorously show\nthat universal representations achieve state-of-the-art performances in\nlearning of multiple dense prediction problems in NYU-v2 and Cityscapes,\nmultiple image classification problems from diverse domains in Visual Decathlon\nDataset and cross-domain few-shot learning in MetaDataset. Finally we also\nconduct multiple analysis through ablation and qualitative studies.",
    "descriptor": "\nComments: Multi-task Learning, Multi-domain Learning, Cross-domain Few-shot Learning, Universal Representation Learning, Balanced Optimization, Dense Prediction, Code will be available at this https URL arXiv admin note: text overlap with arXiv:2103.13841\n",
    "authors": [
      "Wei-Hong Li",
      "Xialei Liu",
      "Hakan Bilen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.02744"
  },
  {
    "id": "arXiv:2204.02752",
    "title": "Multi-Objective Evolutionary Beer Optimisation",
    "abstract": "Food production is a complex process which can benefit from many optimisation\napproaches. However, there is growing interest in methods that support\ncustomisation of food properties to satisfy individual consumer preferences.\nThis paper addresses the personalisation of beer properties. Having identified\ncomponents of the production process for craft beers whose production tends to\nbe less standardised, we introduce a system which enables brewers to map the\ndesired beer properties into ingredients dosage and combination. Previously\nexplored approaches include direct use of structural equations as well as\nglobal machine learning methods. We introduce a framework which uses an\nevolutionary method supporting multi-objective optimisation. This work\nidentifies problem-dependent objectives, their associations, and proposes a\nworkflow to automate the discovery of multiple novel recipes based on\nuser-defined criteria. The quality of the solutions generated by the\nmulti-objective optimiser is compared against solutions from multiple runs of\nthe method, and those of a single objective evolutionary technique. This\ncomparison provides a road-map allowing the users to choose among more varied\noptions or to fine-tune one of the favourite identified solution. The\nexperiments presented here demonstrate the usability of the framework as well\nas the transparency of its criteria.",
    "descriptor": "\nComments: 13 pages, 3 figures, 6 tables, GECCO\n",
    "authors": [
      "Mohammad Majid al-Rifaie",
      "Marc Cavazza"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2204.02752"
  },
  {
    "id": "arXiv:2204.02758",
    "title": "Computing expected multiplicities for bag-TIDBs with bounded  multiplicities",
    "abstract": "In this work, we study the problem of computing a tuple's expected\nmultiplicity over probabilistic databases with bag semantics (where each tuple\nis associated with a multiplicity) exactly and approximately. We consider\nbag-TIDBs where we have a bound $c$ on the maximum multiplicity of each tuple\nand tuples are independent probabilistic events (we refer to such databases as\nc-TIDBs. We are specifically interested in the fine-grained complexity of\ncomputing expected multiplicities and how it compares to the complexity of\ndeterministic query evaluation algorithms -- if these complexities are\ncomparable, it opens the door to practical deployment of probabilistic\ndatabases. Unfortunately, our results imply that computing expected\nmultiplicities for c-TIDBs based on the results produced by such query\nevaluation algorithms introduces super-linear overhead (under parameterized\ncomplexity hardness assumptions/conjectures). We proceed to study approximation\nof expected result tuple multiplicities for positive relational algebra queries\n($RA^+$) over c-TIDBs and for a non-trivial subclass of block-independent\ndatabases (BIDBs). We develop a sampling algorithm that computes a\n1$\\pm\\epsilon$ approximation of the expected multiplicity of an output tuple in\ntime linear in the runtime of the corresponding deterministic query for any\n$RA^+$ query.",
    "descriptor": "",
    "authors": [
      "Su Feng",
      "Boris Glavic",
      "Aaron Huber",
      "Oliver Kennedy",
      "Atri Rudra"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2204.02758"
  },
  {
    "id": "arXiv:2204.02765",
    "title": "Code Search: A Survey of Techniques for Finding Code",
    "abstract": "The immense amounts of source code provide ample challenges and opportunities\nduring software development. To handle the size of code bases, developers\ncommonly search for code, e.g., when trying to find where a particular feature\nis implemented or when looking for code examples to reuse. To support\ndevelopers in finding relevant code, various code search engines have been\nproposed. This article surveys 30 years of research on code search, giving a\ncomprehensive overview of challenges and techniques that address them. We\ndiscuss the kinds of queries that code search engines support, how to\npreprocess and expand queries, different techniques for indexing and retrieving\ncode, and ways to rank and prune search results. Moreover, we describe\nempirical studies of code search in practice. Based on the discussion of prior\nwork, we conclude the article with an outline of challenges and opportunities\nto be addressed in the future.",
    "descriptor": "",
    "authors": [
      "Luca Di Grazia",
      "Michael Pradel"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2204.02765"
  },
  {
    "id": "arXiv:2204.02766",
    "title": "Data-Centric Green AI: An Exploratory Empirical Study",
    "abstract": "With the growing availability of large-scale datasets, and the popularization\nof affordable storage and computational capabilities, the energy consumed by AI\nis becoming a growing concern. To address this issue, in recent years, studies\nhave focused on demonstrating how AI energy efficiency can be improved by\ntuning the model training strategy. Nevertheless, how modifications applied to\ndatasets can impact the energy consumption of AI is still an open question. To\nfill this gap, in this exploratory study, we evaluate if data-centric\napproaches can be utilized to improve AI energy efficiency. To achieve our\ngoal, we conduct an empirical experiment, executed by considering 6 different\nAI algorithms, a dataset comprising 5,574 data points, and two dataset\nmodifications (number of data points and number of features). Our results show\nevidence that, by exclusively conducting modifications on datasets, energy\nconsumption can be drastically reduced (up to 92.16%), often at the cost of a\nnegligible or even absent accuracy decline. As additional introductory results,\nwe demonstrate how, by exclusively changing the algorithm used, energy savings\nup to two orders of magnitude can be achieved. In conclusion, this exploratory\ninvestigation empirically demonstrates the importance of applying data-centric\ntechniques to improve AI energy efficiency. Our results call for a research\nagenda that focuses on data-centric techniques, to further enable and\ndemocratize Green AI.",
    "descriptor": "\nComments: 11 pages, 3 figures, 2 tables. Accepted at the 8th ICT for Sustainability Conference (ICT4S) 2022\n",
    "authors": [
      "Roberto Verdecchia",
      "Lu\u00eds Cruz",
      "June Sallou",
      "Michelle Lin",
      "James Wickenden",
      "Estelle Hotellier"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2204.02766"
  },
  {
    "id": "arXiv:2204.02772",
    "title": "Semi-DRDNet Semi-supervised Detail-recovery Image Deraining Network via  Unpaired Contrastive Learning",
    "abstract": "The intricacy of rainy image contents often leads cutting-edge deraining\nmodels to image degradation including remnant rain, wrongly-removed details,\nand distorted appearance. Such degradation is further exacerbated when applying\nthe models trained on synthetic data to real-world rainy images. We raise an\nintriguing question -- if leveraging both accessible unpaired clean/rainy yet\nreal-world images and additional detail repair guidance, can improve the\ngeneralization ability of a deraining model? To answer it, we propose a\nsemi-supervised detail-recovery image deraining network (termed as\nSemi-DRDNet). Semi-DRDNet consists of three branches: 1) for removing rain\nstreaks without remnants, we present a \\textit{squeeze-and-excitation}\n(SE)-based rain residual network; 2) for encouraging the lost details to\nreturn, we construct a \\textit{structure detail context aggregation}\n(SDCAB)-based detail repair network; to our knowledge, this is the first time;\nand 3) for bridging the domain gap, we develop a novel contrastive\nregularization network to learn from unpaired positive (clean) and negative\n(rainy) yet real-world images. As a semi-supervised learning paradigm,\nSemi-DRDNet operates smoothly on both synthetic and real-world rainy data in\nterms of deraining robustness and detail accuracy. Comparisons on four datasets\nshow clear visual and numerical improvements of our Semi-DRDNet over thirteen\nstate-of-the-arts.",
    "descriptor": "\nComments: 17 pages\n",
    "authors": [
      "Yiyang Shen",
      "Sen Deng",
      "Wenhan Yang",
      "Mingqiang Wei",
      "Haoran Xie",
      "XiaoPing Zhang",
      "Jing Qin",
      "Meng Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.02772"
  },
  {
    "id": "arXiv:2204.02773",
    "title": "Fast Fuzzing for Memory Errors",
    "abstract": "Greybox fuzzing is a proven effective testing method for the detection of\nsecurity vulnerabilities and other bugs in modern software systems. Greybox\nfuzzing can also be used in combination with a sanitizer, such as\nAddressSanitizer (ASAN), to further enhance the detection of certain classes of\nbug such as buffer overflow and use-after-free errors. However, sanitizers also\nintroduce additional performance overheads, and this can degrade the\nperformance of greybox fuzzing -- measured in the order of 2.36x for fuzzing\nwith ASAN -- potentially negating the benefit of using a sanitizer in the first\nplace. Recent research attributes this to extra overheads to additional page\nfaults that are generated when the disjoint sanitizer metadata is accessed at\nruntime.\nIn this paper, we present a new design that can detect memory errors without\na proliferation of page faults. The basic idea is to track memory validity\nusing randomized tokens that are stored directly in the memory itself, rather\nthan in disjoint metadata. All read/write operations are instrumented to check\nfor the token, and if present, a memory error will be detected. We implement\nour design in the form of the ReZZan -- a sanitizer specifically optimized for\nfuzz testing. Since there is no disjoint metadata access, no additional page\nfaults are generated, minimizing the performance overhead to around 1.14-1.27x\n(depending on the configuration).",
    "descriptor": "",
    "authors": [
      "Jinsheng Ba",
      "Gregory J. Duck",
      "Abhik Roychoudhury"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2204.02773"
  },
  {
    "id": "arXiv:2204.02776",
    "title": "3D face reconstruction with dense landmarks",
    "abstract": "Landmarks often play a key role in face analysis, but many aspects of\nidentity or expression cannot be represented by sparse landmarks alone. Thus,\nin order to reconstruct faces more accurately, landmarks are often combined\nwith additional signals like depth images or techniques like differentiable\nrendering. Can we keep things simple by just using more landmarks? In answer,\nwe present the first method that accurately predicts 10x as many landmarks as\nusual, covering the whole head, including the eyes and teeth. This is\naccomplished using synthetic training data, which guarantees perfect landmark\nannotations. By fitting a morphable model to these dense landmarks, we achieve\nstate-of-the-art results for monocular 3D face reconstruction in the wild. We\nshow that dense landmarks are an ideal signal for integrating face shape\ninformation across frames by demonstrating accurate and expressive facial\nperformance capture in both monocular and multi-view scenarios. This approach\nis also highly efficient: we can predict dense landmarks and fit our 3D face\nmodel at over 150FPS on a single CPU thread.",
    "descriptor": "",
    "authors": [
      "Erroll Wood",
      "Tadas Baltrusaitis",
      "Charlie Hewitt",
      "Matthew Johnson",
      "Jingjing Shen",
      "Nikola Milosavljevic",
      "Daniel Wilde",
      "Stephan Garbin",
      "Toby Sharp",
      "Ivan Stojiljkovic",
      "Tom Cashman",
      "Julien Valentin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.02776"
  },
  {
    "id": "arXiv:2204.02777",
    "title": "Walk this Way! Entity Walks and Property Walks for RDF2vec",
    "abstract": "RDF2vec is a knowledge graph embedding mechanism which first extracts\nsequences from knowledge graphs by performing random walks, then feeds those\ninto the word embedding algorithm word2vec for computing vector representations\nfor entities. In this poster, we introduce two new flavors of walk extraction\ncoined e-walks and p-walks, which put an emphasis on the structure or the\nneighborhood of an entity respectively, and thereby allow for creating\nembeddings which focus on similarity or relatedness. By combining the walk\nstrategies with order-aware and classic RDF2vec, as well as CBOW and skip-gram\nword2vec embeddings, we conduct a preliminary evaluation with a total of 12\nRDF2vec variants.",
    "descriptor": "\nComments: accepted at the ESWC Posters and Demos Track\n",
    "authors": [
      "Jan Portisch",
      "Heiko Paulheim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.02777"
  },
  {
    "id": "arXiv:2204.02782",
    "title": "How Do Graph Networks Generalize to Large and Diverse Molecular Systems?",
    "abstract": "The predominant method of demonstrating progress of atomic graph neural\nnetworks are benchmarks on small and limited datasets. The implicit hypothesis\nbehind this approach is that progress on these narrow datasets generalize to\nthe large diversity of chemistry. This generalizability would be very helpful\nfor research, but currently remains untested. In this work we test this\nassumption by identifying four aspects of complexity in which many datasets are\nlacking: 1. Chemical diversity (number of different elements), 2. system size\n(number of atoms per sample), 3. dataset size (number of data samples), and 4.\ndomain shift (similarity of the training and test set). We introduce multiple\nsubsets of the large Open Catalyst 2020 (OC20) dataset to independently\ninvestigate each of these aspects. We then perform 21 ablation studies and\nsensitivity analyses on 9 datasets testing both previously proposed and new\nmodel enhancements. We find that some improvements are consistent between\ndatasets, but many are not and some even have opposite effects. Based on this\nanalysis, we identify a smaller dataset that correlates well with the full OC20\ndataset, and propose the GemNet-OC model, which outperforms the previous\nstate-of-the-art on OC20 by 16%, while reducing training time by a factor of\n10. Overall, our findings challenge the common belief that graph neural\nnetworks work equally well independent of dataset size and diversity, and\nsuggest that caution must be exercised when making generalizations based on\nnarrow datasets.",
    "descriptor": "",
    "authors": [
      "Johannes Gasteiger",
      "Muhammed Shuaibi",
      "Anuroop Sriram",
      "Stephan G\u00fcnnemann",
      "Zachary Ulissi",
      "C. Lawrence Zitnick",
      "Abhishek Das"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Materials Science (cond-mat.mtrl-sci)",
      "Chemical Physics (physics.chem-ph)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2204.02782"
  },
  {
    "id": "arXiv:2204.02785",
    "title": "Reinforcement Learning Agents in Colonel Blotto",
    "abstract": "Models and games are simplified representations of the world. There are many\ndifferent kinds of models, all differing in complexity and which aspect of the\nworld they allow us to further our understanding of. In this paper we focus on\na specific instance of agent-based models, which uses reinforcement learning\n(RL) to train the agent how to act in its environment. Reinforcement learning\nagents are usually also Markov processes, which is another type of model that\ncan be used. We test this reinforcement learning agent in a Colonel Blotto\nenvironment1, and measure its performance against Random agents as its\nopponent. We find that the RL agent handily beats a single opponent, and still\nperforms quite well when the number of opponents are increased. We also analyze\nthe RL agent and look at what strategies it has arrived by looking at the\nactions that it has given the highest and lowest Q-values. Interestingly, the\noptimal strategy for playing multiple opponents is almost the complete opposite\nof the optimal strategy for playing a single opponent.",
    "descriptor": "",
    "authors": [
      "Joseph Christian G. Noel"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.02785"
  },
  {
    "id": "arXiv:2204.02787",
    "title": "DiffSearch: A Scalable and Precise Search Engine for Code Changes",
    "abstract": "The source code of successful projects is evolving all the time, resulting in\nhundreds of thousands of code changes stored in source code repositories. This\nwealth of data can be useful, e.g., to find changes similar to a planned code\nchange or examples of recurring code improvements. This paper presents\nDiffSearch, a search engine that, given a query that describes a code change,\nreturns a set of changes that match the query. The approach is enabled by three\nkey contributions. First, we present a query language that extends the\nunderlying programming language with wildcards and placeholders, providing an\nintuitive way of formulating queries that is easy to adapt to different\nprogramming languages. Second, to ensure scalability, the approach indexes code\nchanges in a one-time preprocessing step, mapping them into a feature space,\nand then performs an efficient search in the feature space for each query.\nThird, to guarantee precision, i.e., that any returned code change indeed\nmatches the given query, we present a tree-based matching algorithm that checks\nwhether a query can be expanded to a concrete code change. We present\nimplementations for Java, JavaScript, and Python, and show that the approach\nresponds within seconds to queries across one million code changes, has a\nrecall of 80.7% for Java, 89.6% for Python, and 90.4% for JavaScript, enables\nusers to find relevant code changes more effectively than a regular\nexpression-based search, and is helpful for gathering a large-scale dataset of\nreal-world bug fixes.",
    "descriptor": "",
    "authors": [
      "Luca Di Grazia",
      "Paul Bredl",
      "Michael Pradel"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2204.02787"
  },
  {
    "id": "arXiv:2204.02790",
    "title": "Global Readiness of Language Technology for Healthcare: What would it  Take to Combat the Next Pandemic?",
    "abstract": "The COVID-19 pandemic has brought out both the best and worst of language\ntechnology (LT). On one hand, conversational agents for information\ndissemination and basic diagnosis have seen widespread use, and arguably, had\nan important role in combating the pandemic. On the other hand, it has also\nbecome clear that such technologies are readily available for a handful of\nlanguages, and the vast majority of the global south is completely bereft of\nthese benefits. What is the state of LT, especially conversational agents, for\nhealthcare across the world's languages? And, what would it take to ensure\nglobal readiness of LT before the next pandemic? In this paper, we try to\nanswer these questions through survey of existing literature and resources, as\nwell as through a rapid chatbot building exercise for 15 Asian and African\nlanguages with varying amount of resource-availability. The study confirms the\npitiful state of LT even for languages with large speaker bases, such as\nSinhala and Hausa, and identifies the gaps that could help us prioritize\nresearch and investment strategies in LT for healthcare.",
    "descriptor": "\nComments: Under Revision\n",
    "authors": [
      "Ishani Mondal",
      "Kabir Ahuja",
      "Mohit Jain",
      "Jacki O Neil",
      "Kalika Bali",
      "Monojit Choudhury"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.02790"
  },
  {
    "id": "arXiv:2204.02791",
    "title": "Implicit Motion-Compensated Network for Unsupervised Video Object  Segmentation",
    "abstract": "Unsupervised video object segmentation (UVOS) aims at automatically\nseparating the primary foreground object(s) from the background in a video\nsequence. Existing UVOS methods either lack robustness when there are visually\nsimilar surroundings (appearance-based) or suffer from deterioration in the\nquality of their predictions because of dynamic background and inaccurate flow\n(flow-based). To overcome the limitations, we propose an implicit\nmotion-compensated network (IMCNet) combining complementary cues\n($\\textit{i.e.}$, appearance and motion) with aligned motion information from\nthe adjacent frames to the current frame at the feature level without\nestimating optical flows. The proposed IMCNet consists of an affinity computing\nmodule (ACM), an attention propagation module (APM), and a motion compensation\nmodule (MCM). The light-weight ACM extracts commonality between neighboring\ninput frames based on appearance features. The APM then transmits global\ncorrelation in a top-down manner. Through coarse-to-fine iterative inspiring,\nthe APM will refine object regions from multiple resolutions so as to\nefficiently avoid losing details. Finally, the MCM aligns motion information\nfrom temporally adjacent frames to the current frame which achieves implicit\nmotion compensation at the feature level. We perform extensive experiments on\n$\\textit{DAVIS}_{\\textit{16}}$ and $\\textit{YouTube-Objects}$. Our network\nachieves favorable performance while running at a faster speed compared to the\nstate-of-the-art methods.",
    "descriptor": "\nComments: 14 pages, 13 figures\n",
    "authors": [
      "Lin Xi",
      "Weihai Chen",
      "Xingming Wu",
      "Zhong Liu",
      "Zhengguo Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.02791"
  },
  {
    "id": "arXiv:2204.02799",
    "title": "Scandium Nitride as a Gateway III-Nitride Semiconductor for  Optoelectronic Artificial Synaptic Devices",
    "abstract": "Traditional computation based on von Neumann architecture is limited by the\ntime and energy consumption due to data transfer between the storage and the\nprocessing units. The von Neumann architecture is also inefficient in solving\nunstructured, probabilistic, and real-time problems. To address these\nchallenges, a new brain-inspired neuromorphic computational architecture is\nrequired. Due to absence of resistance-capacitance (RC) delay, high bandwidth\nand low power consumption, optoelectronic artificial synaptic devices are\nhighly attractive. Yet stable, scalable, and\ncomplementary-metal-oxide-semiconductor (CMOS)-compatible synapses have not\nbeen demonstrated. In this work, persistence in the photoconductivity of\nundoped and magnesium-doped scandium nitride (ScN) is equated to the inhibitory\nand excitatory synaptic plasticity of the biological synapses responsible for\nmemory and learning. Primary functionalities of a biological synapse like\nshort-term memory (STM), long-term memory (LTM), the transition from\nSTM-to-LTM, learning and forgetting, frequency-selective optical filtering,\nfrequency-dependent potentiation and depression, Hebbian learning, and logic\ngate operations are demonstrated.",
    "descriptor": "\nComments: 14 pages, 5 figures. It is currently under review\n",
    "authors": [
      "Dheemahi Rao",
      "Bivas Saha"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Applied Physics (physics.app-ph)"
    ],
    "url": "https://arxiv.org/abs/2204.02799"
  },
  {
    "id": "arXiv:2204.02802",
    "title": "Dimensionality Expansion and Transfer Learning for Next Generation  Energy Management Systems",
    "abstract": "Electrical management systems (EMS) are playing a central role in enabling\nenergy savings. They can be deployed within an everyday household where they\nmonitor and manage appliances and help residents be more energy efficient and\nsubsequently also more economical. One of they key functionalities of EMS is to\nautomatically detect and identify appliances within a household through the\nprocess of load monitoring. In this paper, we propose a new transfer learning\napproach for building EMS (BEMS) and study the trade-offs in terms of numbers\nof samples and target classes in adapting a backbone model during the transfer\nprocess. We also perform a first time analysis of feature expansion through\nvideo-like transformation of time series data for device classification in non\nintrusive load monitoring (NILM) and propose a deep learning architecture\nenabling accurate appliance identification. We examine the relative performance\nof our method on 5 different representative low-frequency datasets and show\nthat our method performs with an average F1 score of 0.88 on these datasets.",
    "descriptor": "\nComments: 11 pages, 2 figures\n",
    "authors": [
      "Bla\u017e Bertalani\u010d",
      "Jakob Jenko",
      "Carolina Fortuna"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2204.02802"
  },
  {
    "id": "arXiv:2204.02803",
    "title": "A Transformer-Based Contrastive Learning Approach for Few-Shot Sign  Language Recognition",
    "abstract": "Sign language recognition from sequences of monocular images or 2D poses is a\nchallenging field, not only due to the difficulty to infer 3D information from\n2D data, but also due to the temporal relationship between the sequences of\ninformation. Additionally, the wide variety of signs and the constant need to\nadd new ones on production environments makes it infeasible to use traditional\nclassification techniques. We propose a novel Contrastive Transformer-based\nmodel, which demonstrate to learn rich representations from body key points\nsequences, allowing better comparison between vector embedding. This allows us\nto apply these techniques to perform one-shot or few-shot tasks, such as\nclassification and translation. The experiments showed that the model could\ngeneralize well and achieved competitive results for sign classes never seen in\nthe training process.",
    "descriptor": "",
    "authors": [
      "Silvan Ferreira",
      "Esdras Costa",
      "M\u00e1rcio Dahia",
      "Jampierre Rocha"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.02803"
  },
  {
    "id": "arXiv:2204.02804",
    "title": "Federated Self-supervised Speech Representations: Are We There Yet?",
    "abstract": "The ubiquity of microphone-enabled devices has lead to large amounts of\nunlabelled audio data being produced at the edge. The integration of\nself-supervised learning (SSL) and federated learning (FL) into one coherent\nsystem can potentially offer data privacy guarantees while also advancing the\nquality and robustness of speech representations. In this paper, we provide a\nfirst-of-its-kind systematic study of the feasibility and complexities for\ntraining speech SSL models under FL scenarios from the perspective of\nalgorithms, hardware, and systems limits. Despite the high potential of their\ncombination, we find existing system constraints and algorithmic behaviour make\nSSL and FL systems nearly impossible to build today. Yet critically, our\nresults indicate specific performance bottlenecks and research opportunities\nthat would allow this situation to be reversed. While our analysis suggests\nthat, given existing trends in hardware, hybrid SSL and FL speech systems will\nnot be viable until 2027. We believe this study can act as a roadmap to\naccelerate work towards reaching this milestone much earlier.",
    "descriptor": "",
    "authors": [
      "Yan Gao",
      "Javier Fernandez-Marques",
      "Titouan Parcollet",
      "Abhinav Mehrotra",
      "Nicholas D. Lane"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2204.02804"
  },
  {
    "id": "arXiv:2204.02809",
    "title": "Hammer PDF: An Intelligent PDF Reader for Scientific Papers",
    "abstract": "Reading scientific papers has been an essential way for researchers to\nacquire academic knowledge, and most papers are in PDF format. However,\nexisting PDF Readers only support reading, editing, annotating and other basic\nfunctions, and lack of multi-granularity analysis for academic papers.\nSpecifically, taking a paper as a whole, these PDF Readers cannot access\nextended information of the paper, such as related videos, blogs, codes, etc.;\nmeanwhile, for the content of a paper, these PDF Readers also cannot extract\nand display academic details of the paper, such as terms, authors, citations,\netc. In this paper, we introduce Hammer PDF, a novel intelligent PDF Reader for\nscientific papers. Beyond basic reading functions, Hammer PDF comes with four\ninnovative features: (1) locate, mark and interact with spans (e.g., terms)\nobtained by information extraction; (2) citation, reference, code, video, blog,\nand other extended information are displayed with a paper; (3) built-in Hammer\nScholar, an academic search engine that uses academic information collected\nfrom major academic databases; (4) built-in Q\\&A bot to support asking for\ninterested conference information. Our product helps researchers, especially\nthose who study computer science, to improve the efficiency and experience of\nreading scientific papers. We release Hammer PDF, available for download at\nhttps://pdf.hammerscholar.net/face.",
    "descriptor": "",
    "authors": [
      "Sheng-Fu Wang",
      "Shu-Hang Liu",
      "Tian-Yi Che",
      "Yi-Fan Lu",
      "Song-Xiao Yang",
      "Heyan Huang",
      "Xian-Ling Mao"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2204.02809"
  },
  {
    "id": "arXiv:2204.02810",
    "title": "Expression-preserving face frontalization improves visually assisted  speech processing",
    "abstract": "Face frontalization consists of synthesizing a frontally-viewed face from an\narbitrarily-viewed one. The main contribution of this paper is a frontalization\nmethodology that preserves non-rigid facial deformations in order to boost the\nperformance of visually assisted speech communication. The method alternates\nbetween the estimation of (i)~the rigid transformation (scale, rotation, and\ntranslation) and (ii)~the non-rigid deformation between an arbitrarily-viewed\nface and a face model. The method has two important merits: it can deal with\nnon-Gaussian errors in the data and it incorporates a dynamical face\ndeformation model. For that purpose, we use the generalized Student\nt-distribution in combination with a linear dynamic system in order to account\nfor both rigid head motions and time-varying facial deformations caused by\nspeech production. We propose to use the zero-mean normalized cross-correlation\n(ZNCC) score to evaluate the ability of the method to preserve facial\nexpressions. The method is thoroughly evaluated and compared with several state\nof the art methods, either based on traditional geometric models or on deep\nlearning. Moreover, we show that the method, when incorporated into deep\nlearning pipelines, namely lip reading and speech enhancement, improves word\nrecognition and speech intelligibilty scores by a considerable margin.\nSupplemental material is accessible at\nhttps://team.inria.fr/robotlearn/research/facefrontalization-benchmark/",
    "descriptor": "",
    "authors": [
      "Zhiqi Kang",
      "Mostafa Sadeghi",
      "Radu Horaud",
      "Jacob Donley",
      "Anurag Kumar",
      "Xavier Alameda-Pineda"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2204.02810"
  },
  {
    "id": "arXiv:2204.02811",
    "title": "BMD: A General Class-balanced Multicentric Dynamic Prototype Strategy  for Source-free Domain Adaptation",
    "abstract": "Source-free Domain Adaptation (SFDA) aims to adapt a pre-trained source model\nto the unlabeled target domain without accessing the well-labeled source data,\nwhich is a much more practical setting due to the data privacy, security, and\ntransmission issues. To make up for the absence of source data, most existing\nmethods introduced feature prototype based pseudo-labeling strategies to\nrealize self-training model adaptation. However, feature prototypes are\nobtained by instance-level predictions based feature clustering, which is\ncategory-biased and tends to result in noisy labels since the visual domain\ngaps between source and target are usually different between categories. In\naddition, we found that a monocentric feature prototype may be ineffective to\nrepresent each category and introduce negative transfer, especially for those\nhard-transfer data. To address these issues, we propose a general\nclass-Balanced Multicentric Dynamic prototype (BMD) strategy for the SFDA task.\nSpecifically, for each target category, we first introduce a global inter-class\nbalanced sampling strategy to aggregate potential representative target\nsamples. Then, we design an intra-class multicentric clustering strategy to\nachieve more robust and representative prototypes generation. In contrast to\nexisting strategies that update the pseudo label at a fixed training period, we\nfurther introduce a dynamic pseudo labeling strategy to incorporate network\nupdate information during model adaptation. Extensive experiments show that the\nproposed model-agnostic BMD strategy significantly improves representative SFDA\nmethods to yield new state-of-the-art results, e.g., improving SHOT from 82.9\\%\nto 85.8\\% on VisDA-C and NRC from 52.6\\% to 57.0\\% on PointDA. The code is\navailable at https://github.com/ispc-lab/BMD.",
    "descriptor": "",
    "authors": [
      "Sanqing Qu",
      "Guang Chen",
      "Jing Zhang",
      "Zhijun Li",
      "Wei He",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.02811"
  },
  {
    "id": "arXiv:2204.02813",
    "title": "An Algebraic Approach to Learning and Grounding",
    "abstract": "We consider the problem of learning the semantics of composite algebraic\nexpressions from examples. The outcome is a versatile framework for studying\nlearning tasks that can be put into the following abstract form: The input is a\npartial algebra A and a finite set of samples ({\\phi}1, O1), ({\\phi}2, O2),\n..., each consisting of an algebraic term {\\phi}i and a set of objects Oi. The\nobjective is to simultaneously fill in the missing algebraic operations in A\nand ground the variables of every {\\phi}i in Oi, so that the combined value of\nthe terms is optimised. We demonstrate the applicability of this framework\nthrough case studies in grammatical inference, picture-language learning, and\nthe grounding of logic scene descriptions.",
    "descriptor": "",
    "authors": [
      "Johanna Bj\u00f6rklund",
      "Adam Dahlgren Lindstr\u00f6m",
      "Frank Drewes"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Formal Languages and Automata Theory (cs.FL)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2204.02813"
  },
  {
    "id": "arXiv:2204.02814",
    "title": "Aggression in Hindi and English Speech: Acoustic Correlates and  Automatic Identification",
    "abstract": "In the present paper, we will present the results of an acoustic analysis of\npolitical discourse in Hindi and discuss some of the conventionalised acoustic\nfeatures of aggressive speech regularly employed by the speakers of Hindi and\nEnglish. The study is based on a corpus of slightly over 10 hours of political\ndiscourse and includes debates on news channel and political speeches. Using\nthis study, we develop two automatic classification systems for identifying\naggression in English and Hindi speech, based solely on an acoustic model. The\nHindi classifier, trained using 50 hours of annotated speech, and English\nclassifier, trained using 40 hours of annotated speech, achieve a respectable\naccuracy of over 73% and 66% respectively. In this paper, we discuss the\ndevelopment of this annotated dataset, the experiments for developing the\nclassifier and discuss the errors that it makes.",
    "descriptor": "\nComments: To appear in the Proceedings of Conference on Sanskrit and Indian Languages: Technology\n",
    "authors": [
      "Ritesh Kumar",
      "Atul Kr. Ojha",
      "Bornini Lahiri",
      "Chingrimnng Lungleng"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2204.02814"
  },
  {
    "id": "arXiv:2204.02821",
    "title": "drsphelps at SemEval-2022 Task 2: Learning idiom representations using  BERTRAM",
    "abstract": "This paper describes our system for SemEval-2022 Task 2 Multilingual\nIdiomaticity Detection and Sentence Embedding sub-task B. We modify a standard\nBERT sentence transformer by adding embeddings for each idioms, which are\ncreated using BERTRAM and a small number of contexts. We show that this\ntechnique increases the quality of idiom representations and leads to better\nperformance on the task. We also perform analysis on our final results and show\nthat the quality of the produced idiom embeddings is highly sensitive to the\nquality of the input contexts.",
    "descriptor": "",
    "authors": [
      "Dylan Phelps"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.02821"
  },
  {
    "id": "arXiv:2204.02822",
    "title": "Language Resources and Technologies for Non-Scheduled and Endangered  Indian Languages",
    "abstract": "In the present paper, we will present a survey of the language resources and\ntechnologies available for the non-scheduled and endangered languages of India.\nWhile there have been different estimates from different sources about the\nnumber of languages in India, it could be assumed that there are more than\n1,000 languages currently being spoken in India. However barring some of the 22\nlanguages included in the 8th Schedule of the Indian Constitution (called the\nscheduled languages), there is hardly any substantial resource or technology\navailable for the rest of the languages. Nonetheless there have been some\nindividual attempts at developing resources and technologies for the different\nlanguages across the country. Of late, some financial support has also become\navailable for the endangered languages. In this paper, we give a summary of the\nresources and technologies for those Indian languages which are not included in\nthe 8th schedule of the Indian Constitution and/or which are endangered.",
    "descriptor": "\nComments: To appear in Proceedings of Conference on Sanskrit and Indian Languages: Technology\n",
    "authors": [
      "Ritesh Kumar",
      "Bornini Lahiri"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.02822"
  },
  {
    "id": "arXiv:2204.02823",
    "title": "\"Merging Results Is No Easy Task\": An International Survey Study of  Collaborative Data Analysis Practices Among UX Practitioners",
    "abstract": "Analysis is a key part of usability testing where UX practitioners seek to\nidentify usability problems and generate redesign suggestions. Although\nprevious research reported how analysis was conducted, the findings were\ntypically focused on individual analysis or based on a small number of\nprofessionals in specific geographic regions. We conducted an online\ninternational survey of 279 UX practitioners on their practices and challenges\nwhile collaborating during data analysis. We found that UX practitioners were\noften under time pressure to conduct analysis and adopted three modes of\ncollaboration: independently analyze different portions of the data and then\ncollaborate, collaboratively analyze the session with little or no independent\nanalysis, and independently analyze the same set of data and then collaborate.\nMoreover, most encountered challenges related to lack of resources,\ndisagreements with colleagues regarding usability problems, and difficulty\nmerging analysis from multiple practitioners. We discuss design implications to\nbetter support collaborative data analysis.",
    "descriptor": "\nComments: In CHI Conference on Human Factors in Computing Systems (CHI'22)\n",
    "authors": [
      "Emily Kuang",
      "Xiaofu Jin",
      "Mingming Fan"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2204.02823"
  },
  {
    "id": "arXiv:2204.02824",
    "title": "ShowFace: Coordinated Face Inpainting with Memory-Disentangled  Refinement Networks",
    "abstract": "Face inpainting aims to complete the corrupted regions of the face images,\nwhich requires coordination between the completed areas and the non-corrupted\nareas. Recently, memory-oriented methods illustrate great prospects in the\ngeneration related tasks by introducing an external memory module to improve\nimage coordination. However, such methods still have limitations in restoring\nthe consistency and continuity for specificfacial semantic parts. In this\npaper, we propose the coarse-to-fine Memory-Disentangled Refinement Networks\n(MDRNets) for coordinated face inpainting, in which two collaborative modules\nare integrated, Disentangled Memory Module (DMM) and Mask-Region Enhanced\nModule (MREM). Specifically, the DMM establishes a group of disentangled memory\nblocks to store the semantic-decoupled face representations, which could\nprovide the most relevant information to refine the semantic-level\ncoordination. The MREM involves a masked correlation mining mechanism to\nenhance the feature relationships into the corrupted regions, which could also\nmake up for the correlation loss caused by memory disentanglement. Furthermore,\nto better improve the inter-coordination between the corrupted and\nnon-corrupted regions and enhance the intra-coordination in corrupted regions,\nwe design InCo2 Loss, a pair of similarity based losses to constrain the\nfeature consistency. Eventually, extensive experiments conducted on CelebA-HQ\nand FFHQ datasets demonstrate the superiority of our MDRNets compared with\nprevious State-Of-The-Art methods.",
    "descriptor": "",
    "authors": [
      "Zhuojie Wu",
      "Xingqun Qi",
      "Zijian Wang",
      "Wanting Zhou",
      "Kun Yuan",
      "Muyi Sun",
      "Zhenan Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.02824"
  },
  {
    "id": "arXiv:2204.02825",
    "title": "An Empirical Study of Remote Sensing Pretraining",
    "abstract": "Deep learning has largely reshaped remote sensing research for aerial image\nunderstanding. Nevertheless, most of existing deep models are initialized with\nImageNet pretrained weights, where the natural images inevitably presents a\nlarge domain gap relative to the aerial images, probably limiting the\nfinetuning performance on downstream aerial scene tasks. This issue motivates\nus to conduct an empirical study of remote sensing pretraining (RSP). To this\nend, we train different networks from scratch with the help of the largest\nremote sensing scene recognition dataset up to now-MillionAID, to obtain the\nremote sensing pretrained backbones, including both convolutional neural\nnetworks (CNN) and vision transformers such as Swin and ViTAE, which have shown\npromising performance on computer vision tasks. Then, we investigate the impact\nof ImageNet pretraining (IMP) and RSP on a series of downstream tasks including\nscene recognition, semantic segmentation, object detection, and change\ndetection using the CNN and vision transformers backbones. We have some\nempirical findings as follows. First, vision transformers generally outperforms\nCNN backbones, where ViTAE achieves the best performance, owing to its strong\nrepresentation capacity by introducing intrinsic inductive bias from\nconvolutions to transformers. Second, both IMP and RSP help deliver better\nperformance, where IMP enjoys a versatility by learning more universal\nrepresentations from diverse images belonging to much more categories while RSP\nis distinctive in perceiving remote sensing related semantics. Third, RSP\nmitigates the data discrepancy of IMP for remote sensing but may still suffer\nfrom the task discrepancy, where downstream tasks require different\nrepresentations from the scene recognition task. These findings call for\nfurther research efforts on both large-scale pretraining datasets and effective\npretraining methods.",
    "descriptor": "\nComments: Submitted to IEEE TGRS, codes and pretrained models are available at this https URL\n",
    "authors": [
      "Di Wang",
      "Jing Zhang",
      "Bo Du",
      "Gui-Song Xia",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.02825"
  },
  {
    "id": "arXiv:2204.02828",
    "title": "WeChat uptake of Chinese scholarly journals: an analysis of  CSSCI-indexed journals",
    "abstract": "The study of how science is discussed and how scholarly actors interact on\nsocial media has increasingly become popular in the field of scientometrics in\nrecent years. While most prior studies focused on research outputs discussed on\nglobal platforms, such as Twitter or Facebook, the presence of scholarly\njournals on local platforms was seldom studied, especially in the Chinese\nsocial media context. To fill this gap, this study investigates the uptake of\nWeChat (a Chinese social network app) by the Chinese scholarly journals indexed\nby the Chinese Social Sciences Citation Index (CSSCI). The results show that\n65.3% of CSSCI-indexed journals have created WeChat public accounts and posted\nover 193 thousand WeChat posts in total. At the journal level, bibliometric\nindicators (e.g., citations, downloads, and journal impact factors) and WeChat\nindicators (e.g., clicks, likes, replies, and recommendations) are weakly\ncorrelated with each other, reinforcing the idea of fundamentally\ndifferentiated dimensions of indicators between bibliometrics and social media\nmetrics. Results also show that journals with WeChat public accounts slightly\noutperform those without WeChat public accounts in terms of citation impact,\nsuggesting that the WeChat presence of scientific journals is mostly positively\nassociated with their citation impact.",
    "descriptor": "",
    "authors": [
      "Ting Cong",
      "Zhichao Fang",
      "Rodrigo Costas"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2204.02828"
  },
  {
    "id": "arXiv:2204.02837",
    "title": "Online Feedback Droop Scheduling in Distribution Grids for Frequency and  Local Voltage Control",
    "abstract": "This paper presents a novel framework for collective control of Distributed\nEnergy Resources (DERs) in active Distribution Networks (DNs). The proposed\napproach unifies the commonly employed local (i.e., decentralized) voltage and\nfrequency droop control schemes into a transfer matrix relating frequency and\nvoltage magnitude measurements to active and reactive power injection\nadjustments. Furthermore, the transfer matrices of individual DER units are\nadaptively tuned in real-time via slow communication links using an online gain\nscheduling approach, with the objective to enable frequency support provision\nto the transmission system and ensure that the DN voltages are kept within the\nallowable limits. A global asymptomatic stability condition of the analyzed\ndroop-controlled DN is analytically established. The considered gain scheduling\nproblem is solved by leveraging an online primal-dual gradient-based method and\na suitable linearized power flow model. Additional ancillary service providers\ncan be trivially incorporated into the proposed framework in a plug-and-play\nfashion. Numerical simulations of the 37-bus IEEE test system confirm the\nvalidity of the approach and demonstrate numerous advantages of the proposed\nscheme over the state-of-the-art.",
    "descriptor": "",
    "authors": [
      "Ognjen Stanojev",
      "Yi Guo",
      "Gabriela Hug"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2204.02837"
  },
  {
    "id": "arXiv:2204.02843",
    "title": "Tensor train based isogeometric analysis for PDE approximation on  parameter dependent geometries",
    "abstract": "This work develops a numerical solver based on the combination of\nisogeometric analysis (IGA) and the tensor train (TT) decomposition for the\napproximation of partial differential equations (PDEs) on parameter-dependent\ngeometries. First, the discrete Galerkin operator as well as the solution for a\nfixed geometry configuration are represented as tensors and the TT format is\nemployed to reduce their computational complexity. Parametric dependencies are\nincluded by considering the parameters that control the geometry configuration\nas additional dimensions next to the physical space coordinates. The parameters\nare easily incorporated within the TT-IGA solution framework by introducing a\ntensor product basis expansion in the parameter space. The discrete Galerkin\noperators are accordingly extended to accommodate the parameter dependence,\nthus obtaining a single system that includes the parameter dependency. The\nsystem is solved directly in the TT format and a low-rank representation of the\nparameter-dependent solution is obtained. The proposed TT-IGA solver is applied\nto several test cases which showcase its high computational efficiency and\ntremendous compression ratios achieved for representing the parameter-dependent\nIGA operators and solutions.",
    "descriptor": "\nComments: Submitted manuscript\n",
    "authors": [
      "Ion Gabriel Ion",
      "Dimitrios Loukrezis",
      "Herbert De Gersem"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2204.02843"
  },
  {
    "id": "arXiv:2204.02844",
    "title": "Learning to Generate Realistic Noisy Images via Pixel-level Noise-aware  Adversarial Training",
    "abstract": "Existing deep learning real denoising methods require a large amount of\nnoisy-clean image pairs for supervision. Nonetheless, capturing a real\nnoisy-clean dataset is an unacceptable expensive and cumbersome procedure. To\nalleviate this problem, this work investigates how to generate realistic noisy\nimages. Firstly, we formulate a simple yet reasonable noise model that treats\neach real noisy pixel as a random variable. This model splits the noisy image\ngeneration problem into two sub-problems: image domain alignment and noise\ndomain alignment. Subsequently, we propose a novel framework, namely\nPixel-level Noise-aware Generative Adversarial Network (PNGAN). PNGAN employs a\npre-trained real denoiser to map the fake and real noisy images into a nearly\nnoise-free solution space to perform image domain alignment. Simultaneously,\nPNGAN establishes a pixel-level adversarial training to conduct noise domain\nalignment. Additionally, for better noise fitting, we present an efficient\narchitecture Simple Multi-scale Network (SMNet) as the generator. Qualitative\nvalidation shows that noise generated by PNGAN is highly similar to real noise\nin terms of intensity and distribution. Quantitative experiments demonstrate\nthat a series of denoisers trained with the generated noisy images achieve\nstate-of-the-art (SOTA) results on four real denoising benchmarks.",
    "descriptor": "\nComments: NeurIPS 2021\n",
    "authors": [
      "Yuanhao Cai",
      "Xiaowan Hu",
      "Haoqian Wang",
      "Yulun Zhang",
      "Hanspeter Pfister",
      "Donglai Wei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2204.02844"
  },
  {
    "id": "arXiv:2204.02849",
    "title": "KNN-Diffusion: Image Generation via Large-Scale Retrieval",
    "abstract": "While the availability of massive Text-Image datasets is shown to be\nextremely useful in training large-scale generative models (e.g. DDPMs,\nTransformers), their output typically depends on the quality of both the input\ntext, as well as the training dataset. In this work, we show how large-scale\nretrieval methods, in particular efficient K-Nearest-Neighbors (KNN) search,\ncan be used in order to train a model to adapt to new samples. Learning to\nadapt enables several new capabilities. Sifting through billions of records at\ninference time is extremely efficient and can alleviate the need to train or\nmemorize an adequately large generative model. Additionally, fine-tuning\ntrained models to new samples can be achieved by simply adding them to the\ntable. Rare concepts, even without any presence in the training set, can be\nthen leveraged during test time without any modification to the generative\nmodel. Our diffusion-based model trains on images only, by leveraging a joint\nText-Image multi-modal metric. Compared to baseline methods, our generations\nachieve state of the art results both in human evaluations as well as with\nperceptual scores when tested on a public multimodal dataset of natural images,\nas well as on a collected dataset of 400 million Stickers.",
    "descriptor": "",
    "authors": [
      "Oron Ashual",
      "Shelly Sheynin",
      "Adam Polyak",
      "Uriel Singer",
      "Oran Gafni",
      "Eliya Nachmani",
      "Yaniv Taigman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.02849"
  },
  {
    "id": "arXiv:2204.02850",
    "title": "Influence of Color Spaces for Deep Learning Image Colorization",
    "abstract": "Colorization is a process that converts a grayscale image into a color one\nthat looks as natural as possible. Over the years this task has received a lot\nof attention. Existing colorization methods rely on different color spaces:\nRGB, YUV, Lab, etc. In this chapter, we aim to study their influence on the\nresults obtained by training a deep neural network, to answer the question: \"Is\nit crucial to correctly choose the right color space in deep-learning based\ncolorization?\". First, we briefly summarize the literature and, in particular,\ndeep learning-based methods. We then compare the results obtained with the same\ndeep neural network architecture with RGB, YUV and Lab color spaces.\nQualitative and quantitative analysis do not conclude similarly on which color\nspace is better. We then show the importance of carefully designing the\narchitecture and evaluation protocols depending on the types of images that are\nbeing processed and their specificities: strong/small contours, few/many\nobjects, recent/archive images.",
    "descriptor": "",
    "authors": [
      "Coloma Ballester",
      "Aur\u00e9lie Bugeau",
      "Hernan Carrillo",
      "Micha\u00ebl Cl\u00e9ment",
      "R\u00e9mi Giraud",
      "Lara Raad",
      "Patricia Vitoria"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.02850"
  },
  {
    "id": "arXiv:2204.02854",
    "title": "Retrieval-based Spatially Adaptive Normalization for Semantic Image  Synthesis",
    "abstract": "Semantic image synthesis is a challenging task with many practical\napplications. Albeit remarkable progress has been made in semantic image\nsynthesis with spatially-adaptive normalization and existing methods normalize\nthe feature activations under the coarse-level guidance (e.g., semantic class).\nHowever, different parts of a semantic object (e.g., wheel and window of car)\nare quite different in structures and textures, making blurry synthesis results\nusually inevitable due to the missing of fine-grained guidance. In this paper,\nwe propose a novel normalization module, termed as REtrieval-based Spatially\nAdaptIve normaLization (RESAIL), for introducing pixel level fine-grained\nguidance to the normalization architecture. Specifically, we first present a\nretrieval paradigm by finding a content patch of the same semantic class from\ntraining set with the most similar shape to each test semantic mask. Then,\nRESAIL is presented to use the retrieved patch for guiding the feature\nnormalization of corresponding region, and can provide pixel level fine-grained\nguidance, thereby greatly mitigating blurry synthesis results. Moreover,\ndistorted ground-truth images are also utilized as alternatives of\nretrieval-based guidance for feature normalization, further benefiting model\ntraining and improving visual quality of generated images. Experiments on\nseveral challenging datasets show that our RESAIL performs favorably against\nstate-of-the-arts in terms of quantitative metrics, visual quality, and\nsubjective evaluation. The source code and pre-trained models will be publicly\navailable.",
    "descriptor": "",
    "authors": [
      "Yupeng Shi",
      "Xiao Liu",
      "Yuxiang Wei",
      "Zhongqin Wu",
      "Wangmeng Zuo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.02854"
  },
  {
    "id": "arXiv:2204.02855",
    "title": "SPIDER-WEB enables stable, repairable, and encryptible algorithms under  arbitrary local biochemical constraints in DNA-based storage",
    "abstract": "DNA has become an attractive medium for storing digital information\ngradually. Despite the biochemical progress on DNA synthesis and sequencing,\nnovel coding algorithms need to be constructed under the specific constraints\nin DNA-based storage. In recent years, a growing number of functional\noperations and storage carriers were introduced, bringing in various\nbiochemical constraints including but not confined to long single-nucleotide\nrepeats and abnormal GC content. Given several local biochemical constraints\nand their combinations, existing coding algorithms are not applicable or\nunstable. In this paper, we design a graph-based architecture, named\nSPIDER-WEB, to generate corresponding graph-based algorithms under arbitrary\nlocal biochemical constraints. These generated coding algorithms could be used\nto encode arbitrary digital data as DNA sequences directly or served as a\nbenchmark for the follow-up construction of coding algorithms. To further\nconsider recovery and security issues existing in the storage field, it also\nprovides pluggable algorithmic patches based on the generated coding\nalgorithms: path-based correcting and mapping shuffling. They provide\napproaches for probabilistic error correction and symmetric encryption\nrespectively.",
    "descriptor": "\nComments: 30 pages; 12 figures; 2 tables\n",
    "authors": [
      "Jia-Qi Wang",
      "Yuan-Hao Yang",
      "Ming Li",
      "Hai-Qi Zhou",
      "Xin-Biao Xu",
      "Ji-Zhe Zhang",
      "Chun-Hua Dong",
      "Guang-Can Guo",
      "Chang-Ling Zou"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Information Theory (cs.IT)",
      "Combinatorics (math.CO)",
      "Genomics (q-bio.GN)"
    ],
    "url": "https://arxiv.org/abs/2204.02855"
  },
  {
    "id": "arXiv:2204.02857",
    "title": "Primal-dual Estimator Learning: an Offline Constrained Moving Horizon  Estimation Method with Feasibility and Near-optimality Guarantees",
    "abstract": "This paper proposes a primal-dual framework to learn a stable estimator for\nlinear constrained estimation problems leveraging the moving horizon approach.\nTo avoid the online computational burden in most existing methods, we learn a\nparameterized function offline to approximate the primal estimate. Meanwhile, a\ndual estimator is trained to check the suboptimality of the primal estimator\nduring execution time. Both the primal and dual estimators are learned from\ndata using supervised learning techniques, and the explicit sample size is\nprovided, which enables us to guarantee the quality of each learned estimator\nin terms of feasibility and optimality. This in turn allows us to bound the\nprobability of the learned estimator being infeasible or suboptimal.\nFurthermore, we analyze the stability of the resulting estimator with a bounded\nerror in the minimization of the cost function. Since our algorithm does not\nrequire the solution of an optimization problem during runtime, state estimates\ncan be generated online almost instantly. Simulation results are presented to\nshow the accuracy and time efficiency of the proposed framework compared to\nonline optimization of moving horizon estimation and Kalman filter. To the best\nof our knowledge, this is the first learning-based state estimator with\nfeasibility and near-optimality guarantees for linear constrained systems.",
    "descriptor": "",
    "authors": [
      "Wenhan Cao",
      "Jingliang Duan",
      "Shengbo Eben Li",
      "Chen Chen",
      "Chang Liu",
      "Yu Wang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2204.02857"
  },
  {
    "id": "arXiv:2204.02861",
    "title": "Transport Layer Networking",
    "abstract": "In this paper we focus on the invention of new network forwarding behaviors\nbetween network Layers 4 and Layer 7 in the OSI network model. Our design goal\nis to propose no changes to L3 - The IP network layer, thus maintaining 100%\ncompatibility with the existing internet. Small changes are made to L4 the\ntransport layer, and a new design for a session ( L5 ) is proposed. This new\ncapability is intended to have minimal or no impact on the application layer,\nexcept for exposing the ability for L7 to select this new mode of data transfer\nor not. The invention of new networking technologies is frequently done in an\nacademic setting, however the design needs to be constrained by practical\nconsiderations for cost, operational feasibility, robustness and scale. Our\ngoal is to improve the production data infrastructure for HEP 24/7 on a global\nscale.",
    "descriptor": "\nComments: contribution to Snowmass 2021\n",
    "authors": [
      "Yatish Kumar",
      "Stacey Sheldon",
      "Dale Carder"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2204.02861"
  },
  {
    "id": "arXiv:2204.02863",
    "title": "Demonstrate Once, Imitate Immediately (DOME): Learning Visual Servoing  for One-Shot Imitation Learning",
    "abstract": "We present DOME, a novel method for one-shot imitation learning, where a task\ncan be learned from just a single demonstration and then be deployed\nimmediately, without any further data collection or training. DOME does not\nrequire prior task or object knowledge, and can perform the task in novel\nobject configurations and with distractors. At its core, DOME uses an\nimage-conditioned object segmentation network followed by a learned visual\nservoing network, to move the robot's end-effector to the same relative pose to\nthe object as during the demonstration, after which the task can be completed\nby replaying the demonstration's end-effector velocities. We show that DOME\nachieves near 100% success rate on 7 real-world everyday tasks, and we perform\nseveral studies to thoroughly understand each individual component of DOME.",
    "descriptor": "",
    "authors": [
      "Eugene Valassakis",
      "Georgios Papagiannis",
      "Norman Di Palo",
      "Edward Johns"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.02863"
  },
  {
    "id": "arXiv:2204.02868",
    "title": "Solving Severely Ill-Posed Linear Systems with Time Discretization Based  Iterative Regularization Methods",
    "abstract": "Recently, inverse problems have attracted more and more attention in\ncomputational mathematics and become increasingly important in engineering\napplications. After the discretization, many of inverse problems are reduced to\nlinear systems. Due to the typical ill-posedness of inverse problems, the\nreduced linear systems are often ill-posed, especially when their scales are\nlarge. This brings great computational difficulty. Particularly, a small\nperturbation in the right side of an ill-posed linear system may cause a\ndramatical change in the solution. Therefore, regularization methods should be\nadopted for stable solutions. In this paper, a new class of accelerated\niterative regularization methods is applied to solve this kind of large-scale\nill-posed linear systems. An iterative scheme becomes a regularization method\nonly when the iteration is early terminated. And a Morozov's discrepancy\nprinciple is applied for the stop criterion. Compared with the conventional\nLandweber iteration, the new methods have acceleration effect, and can be\ncompared to the well-known accelerated v-method and Nesterov method. From the\nnumerical results, it is observed that using appropriate discretization\nschemes, the proposed methods even have better behavior when comparing with\nv-method and Nesterov method.",
    "descriptor": "",
    "authors": [
      "Gong Rongfang",
      "Huang Qin"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2204.02868"
  },
  {
    "id": "arXiv:2204.02869",
    "title": "Characterization of different user behaviors for demand response in data  centers",
    "abstract": "Digital technologies are becoming ubiquitous while their impact increases. A\ngrowing part of this impact happens far away from the end users, in networks or\ndata centers, contributing to a rebound effect. A solution for a more\nresponsible use is therefore to involve the user. As a first step in this\nquest, this work considers the users of a data center and characterizes their\ncontribution to curtail the computing load for a short period of time by solely\nchanging their job submission behavior.The contributions are: (i) an\nopen-source plugin for the simulator Batsim to simulate users based on real\ndata; (ii) the exploration of four types of user behaviors to curtail the load\nduring a time window namely delaying, degrading, reconfiguring or renouncing to\ntheir job submissions. We study the impact of these behaviors on four different\nmetrics: the energy consumed during and after the time window, the mean waiting\ntime and the mean slowdown. We also characterize the conditions under which the\ninvolvement of users is the most beneficial.",
    "descriptor": "",
    "authors": [
      "Ma\u00ebl Madon",
      "Georges Da Costa",
      "Jean-Marc Pierson"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2204.02869"
  },
  {
    "id": "arXiv:2204.02874",
    "title": "ECLIPSE: Efficient Long-range Video Retrieval using Sight and Sound",
    "abstract": "We introduce an audiovisual method for long-range text-to-video retrieval.\nUnlike previous approaches designed for short video retrieval (e.g., 5-15\nseconds in duration), our approach aims to retrieve minute-long videos that\ncapture complex human actions. One challenge of standard video-only approaches\nis the large computational cost associated with processing hundreds of densely\nextracted frames from such long videos. To address this issue, we propose to\nreplace parts of the video with compact audio cues that succinctly summarize\ndynamic audio events and are cheap to process. Our method, named ECLIPSE\n(Efficient CLIP with Sound Encoding), adapts the popular CLIP model to an\naudiovisual video setting, by adding a unified audiovisual transformer block\nthat captures complementary cues from the video and audio streams. In addition\nto being 2.92x faster and 2.34x memory-efficient than long-range video-only\napproaches, our method also achieves better text-to-video retrieval accuracy on\nseveral diverse long-range video datasets such as ActivityNet, QVHighlights,\nYouCook2, DiDeMo and Charades.",
    "descriptor": "\nComments: project page: this https URL\n",
    "authors": [
      "Yan-Bo Lin",
      "Jie Lei",
      "Mohit Bansal",
      "Gedas Bertasius"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2204.02874"
  },
  {
    "id": "arXiv:2204.02877",
    "title": "PAnDR: Fast Adaptation to New Environments from Offline Experiences via  Decoupling Policy and Environment Representations",
    "abstract": "Deep Reinforcement Learning (DRL) has been a promising solution to many\ncomplex decision-making problems. Nevertheless, the notorious weakness in\ngeneralization among environments prevent widespread application of DRL agents\nin real-world scenarios. Although advances have been made recently, most prior\nworks assume sufficient online interaction on training environments, which can\nbe costly in practical cases. To this end, we focus on an\n\\textit{offline-training-online-adaptation} setting, in which the agent first\nlearns from offline experiences collected in environments with different\ndynamics and then performs online policy adaptation in environments with new\ndynamics. In this paper, we propose Policy Adaptation with Decoupled\nRepresentations (PAnDR) for fast policy adaptation. In offline training phase,\nthe environment representation and policy representation are learned through\ncontrastive learning and policy recovery, respectively. The representations are\nfurther refined by mutual information optimization to make them more decoupled\nand complete. With learned representations, a Policy-Dynamics Value Function\n(PDVF) (Raileanu et al., 2020) network is trained to approximate the values for\ndifferent combinations of policies and environments. In online adaptation\nphase, with the environment context inferred from few experiences collected in\nnew environments, the policy is optimized by gradient ascent with respect to\nthe PDVF. Our experiments show that PAnDR outperforms existing algorithms in\nseveral representative policy adaptation problems.",
    "descriptor": "\nComments: Preprint, work presented at the Generalizable Policy Learning in the Physical World Workshop (ICLR 2022)\n",
    "authors": [
      "Tong Sang",
      "Hongyao Tang",
      "Yi Ma",
      "Jianye Hao",
      "Yan Zheng",
      "Zhaopeng Meng",
      "Boyan Li",
      "Zhen Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.02877"
  },
  {
    "id": "arXiv:2204.02883",
    "title": "Data-driven Robust LQR with Multiplicative Noise via System Level  Synthesis",
    "abstract": "This paper aims to develop a data-driven method for solving the closed-loop\nstate-feedback control of a discrete-time LQR problem for systems affected by\nmultiplicative norm bounded model uncertainty. To synthesize a tractable robust\nstate feedback policy, first, we adopt the recently developed system-level\nsynthesis (SLS) framework to reformulate the LQR control design closed-loop\nsystem responses rather than the control gain. In many situations, however, the\nsolution to this worst-case optimization problem may be too conservative since\nit sets out to enforce the design constraints for every possible value of the\nuncertainty. To deal with this issue, we reformulate this optimization problem\nas a chance-constrained program (CCP), where the guarantees are not expressed\nas deterministic satisfaction against all possible uncertainty outcomes but\nrather expressed as guarantees against uncertainty outcomes. To approximately\nsolve the CCP without requiring prior knowledge of how the uncertainties in the\nsystem matrices are described, we employ the so-called scenario approach, which\nprovides probabilistic guarantees based on a finite number of samples and\nresults in a convex optimization program with moderate computational\ncomplexity. Finally, numerical simulations are presented to illustrate the\ntheoretical findings.",
    "descriptor": "",
    "authors": [
      "Majid Mazouchi",
      "Hamidreza Modares"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2204.02883"
  },
  {
    "id": "arXiv:2204.02887",
    "title": "Sampling-based Fast Gradient Rescaling Method for Highly Transferable  Adversarial Attacks",
    "abstract": "Deep neural networks have shown to be very vulnerable to adversarial examples\ncrafted by adding human-imperceptible perturbations to benign inputs. After\nachieving impressive attack success rates in the white-box setting, more focus\nis shifted to black-box attacks. In either case, the common gradient-based\napproaches generally use the $sign$ function to generate perturbations at the\nend of the process. However, only a few works pay attention to the limitation\nof the $sign$ function. Deviation between the original gradient and the\ngenerated noises may lead to inaccurate gradient update estimation and\nsuboptimal solutions for adversarial transferability, which is crucial for\nblack-box attacks. To address this issue, we propose a Sampling-based Fast\nGradient Rescaling Method (S-FGRM) to improve the transferability of the\ncrafted adversarial examples. Specifically, we use data rescaling to substitute\nthe inefficient $sign$ function in gradient-based attacks without extra\ncomputational cost. We also propose a Depth First Sampling method to eliminate\nthe fluctuation of rescaling and stabilize the gradient update. Our method can\nbe used in any gradient-based optimizations and is extensible to be integrated\nwith various input transformation or ensemble methods for further improving the\nadversarial transferability. Extensive experiments on the standard ImageNet\ndataset show that our S-FGRM could significantly boost the transferability of\ngradient-based attacks and outperform the state-of-the-art baselines.",
    "descriptor": "",
    "authors": [
      "Xu Han",
      "Anmin Liu",
      "Yifeng Xiong",
      "Yanbo Fan",
      "Kun He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.02887"
  },
  {
    "id": "arXiv:2204.02889",
    "title": "A Cognitive Framework for Delegation Between Error-Prone AI and Human  Agents",
    "abstract": "With humans interacting with AI-based systems at an increasing rate, it is\nnecessary to ensure the artificial systems are acting in a manner which\nreflects understanding of the human. In the case of humans and artificial AI\nagents operating in the same environment, we note the significance of\ncomprehension and response to the actions or capabilities of a human from an\nagent's perspective, as well as the possibility to delegate decisions either to\nhumans or to agents, depending on who is deemed more suitable at a certain\npoint in time. Such capabilities will ensure an improved responsiveness and\nutility of the entire human-AI system. To that end, we investigate the use of\ncognitively inspired models of behavior to predict the behavior of both human\nand AI agents. The predicted behavior, and associated performance with respect\nto a certain goal, is used to delegate control between humans and AI agents\nthrough the use of an intermediary entity. As we demonstrate, this allows\novercoming potential shortcomings of either humans or agents in the pursuit of\na goal.",
    "descriptor": "\nComments: This work was partially funded by the following projects. European Union's Horizon 2020 research and innovation programme: HumaneAI-Net (No 952026). CHIST-ERA program: SAI project (grant CHIST-ERA-19-XAI-010, funded by MUR, grant number not yet available)\n",
    "authors": [
      "Andrew Fuchs",
      "Andrea Passarella",
      "Marco Conti"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.02889"
  },
  {
    "id": "arXiv:2204.02890",
    "title": "DBF: Dynamic Belief Fusion for Combining Multiple Object Detectors",
    "abstract": "In this paper, we propose a novel and highly practical score-level fusion\napproach called dynamic belief fusion (DBF) that directly integrates inference\nscores of individual detections from multiple object detection methods. To\neffectively integrate the individual outputs of multiple detectors, the level\nof ambiguity in each detection score is estimated using a confidence model\nbuilt on a precision-recall relationship of the corresponding detector. For\neach detector output, DBF then calculates the probabilities of three hypotheses\n(target, non-target, and intermediate state (target or non-target)) based on\nthe confidence level of the detection score conditioned on the prior confidence\nmodel of individual detectors, which is referred to as basic probability\nassignment. The probability distributions over three hypotheses of all the\ndetectors are optimally fused via the Dempster's combination rule. Experiments\non the ARL, PASCAL VOC 07, and 12 datasets show that the detection accuracy of\nthe DBF is significantly higher than any of the baseline fusion approaches as\nwell as individual detectors used for the fusion.",
    "descriptor": "\nComments: TPAMI publication\n",
    "authors": [
      "Hyungtae Lee",
      "Heesung Kwon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.02890"
  },
  {
    "id": "arXiv:2204.02892",
    "title": "Sub-Task Decomposition Enables Learning in Sequence to Sequence Tasks",
    "abstract": "The field of Natural Language Processing (NLP) has experienced a dramatic\nleap in capabilities with the recent introduction of huge Language Models\n(LMs). Despite this success, natural language problems that involve several\ncompounded steps are still practically unlearnable, even by the largest LMs.\nThis complies with experimental failures for end-to-end learning of composite\nproblems that were demonstrated in a variety of domains. A known mitigation is\nto introduce intermediate supervision for solving sub-tasks of the compounded\nproblem. Recently, several works have demonstrated high gains by taking a\nstraightforward approach for incorporating intermediate supervision in\ncompounded natural language problems: the sequence-to-sequence LM is fed with\nan augmented input, in which the decomposed tasks' labels are simply\nconcatenated to the original input. In this paper, we prove a positive learning\nresult that motivates these recent efforts. We show that when concatenating\nintermediate supervision to the input and training a sequence-to-sequence model\non this modified input, an unlearnable composite problem becomes learnable. We\nprove this for the notoriously unlearnable composite task of bit-subset parity,\nwith the intermediate supervision being parity results of increasingly large\nbit-subsets. Beyond motivating contemporary empirical efforts for incorporating\nintermediate supervision in sequence-to-sequence language models, our positive\ntheoretical result is the first of its kind in the landscape of results on the\nbenefits of intermediate supervision: Until now, all theoretical results on the\nsubject are negative, i.e., show cases where learning is impossible without\nintermediate supervision, while our result is positive, showing a case where\nlearning is facilitated in the presence of intermediate supervision.",
    "descriptor": "",
    "authors": [
      "Noam Wies",
      "Yoav Levine",
      "Amnon Shashua"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.02892"
  },
  {
    "id": "arXiv:2204.02898",
    "title": "End-to-End Instance Edge Detection",
    "abstract": "Edge detection has long been an important problem in the field of computer\nvision. Previous works have explored category-agnostic or category-aware edge\ndetection. In this paper, we explore edge detection in the context of object\ninstances. Although object boundaries could be easily derived from segmentation\nmasks, in practice, instance segmentation models are trained to maximize IoU to\nthe ground-truth mask, which means that segmentation boundaries are not\nenforced to precisely align with ground-truth edge boundaries. Thus, the task\nof instance edge detection itself is different and critical. Since precise edge\ndetection requires high resolution feature maps, we design a novel transformer\narchitecture that efficiently combines a FPN and a transformer decoder to\nenable cross attention on multi-scale high resolution feature maps within a\nreasonable computation budget. Further, we propose a light weight dense\nprediction head that is applicable to both instance edge and mask detection.\nFinally, we use a penalty reduced focal loss to effectively train the model\nwith point supervision on instance edges, which can reduce annotation costs. We\ndemonstrate highly competitive instance edge detection performance compared to\nstate-of-the-art baselines, and also show that the proposed task and loss are\ncomplementary to instance segmentation and object detection.",
    "descriptor": "",
    "authors": [
      "Xueyan Zou",
      "Haotian Liu",
      "Yong Jae Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.02898"
  },
  {
    "id": "arXiv:2204.02902",
    "title": "Efficient Bayesian Network Structure Learning via Parameterized Local  Search on Topological Orderings",
    "abstract": "In Bayesian Network Structure Learning (BNSL), one is given a variable set\nand parent scores for each variable and aims to compute a DAG, called Bayesian\nnetwork, that maximizes the sum of parent scores, possibly under some\nstructural constraints. Even very restricted special cases of BNSL are\ncomputationally hard, and, thus, in practice heuristics such as local search\nare used. A natural approach for a local search algorithm is a hill climbing\nstrategy, where one replaces a given BNSL solution by a better solution within\nsome pre-defined neighborhood as long as this is possible. We study\nordering-based local search, where a solution is described via a topological\nordering of the variables. We show that given such a topological ordering, one\ncan compute an optimal DAG whose ordering is within inversion distance $r$ in\nsubexponential FPT time; the parameter $r$ allows to balance between solution\nquality and running time of the local search algorithm. This running time bound\ncan be achieved for BNSL without structural constraints and for all structural\nconstraints that can be expressed via a sum of weights that are associated with\neach parent set. We also introduce a related distance called `window inversions\ndistance' and show that the corresponding local search problem can also be\nsolved in subexponential FPT time for the parameter $r$. For two further\nnatural modification operations on the variable orderings, we show that\nalgorithms with an FPT time for $r$ are unlikely. We also outline the limits of\nordering-based local search by showing that it cannot be used for common\nstructural constraints on the moralized graph of the network.",
    "descriptor": "",
    "authors": [
      "Niels Gr\u00fcttemeier",
      "Christian Komusiewicz",
      "Nils Morawietz"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.02902"
  },
  {
    "id": "arXiv:2204.02905",
    "title": "EMMT: A simultaneous eye-tracking, 4-electrode EEG and audio corpus for  multi-modal reading and translation scenarios",
    "abstract": "We present the Eyetracked Multi-Modal Translation (EMMT) corpus, a dataset\ncontaining monocular eye movement recordings, audio and 4-electrode\nelectroencephalogram (EEG) data of 43 participants. The objective was to\ncollect cognitive signals as responses of participants engaged in a number of\nlanguage intensive tasks involving different text-image stimuli settings when\ntranslating from English to Czech.\nEach participant was exposed to 32 text-image stimuli pairs and asked to (1)\nread the English sentence, (2) translate it into Czech, (3) consult the image,\n(4) translate again, either updating or repeating the previous translation. The\ntext stimuli consisted of 200 unique sentences with 616 unique words coupled\nwith 200 unique images as the visual stimuli.\nThe recordings were collected over a two week period and all the participants\nincluded in the study were Czech natives with strong English skills. Due to the\nnature of the tasks involved in the study and the relatively large number of\nparticipants involved, the corpus is well suited for research in Translation\nProcess Studies, Cognitive Sciences among other disciplines.",
    "descriptor": "\nComments: Submitted to Nature Scientific Data\n",
    "authors": [
      "Sunit Bhattacharya",
      "V\u011bra Kloudov\u00e1",
      "Vil\u00e9m Zouhar",
      "Ond\u0159ej Bojar"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2204.02905"
  },
  {
    "id": "arXiv:2204.02906",
    "title": "Knowledge Base Index Compression via Dimensionality and Precision  Reduction",
    "abstract": "Recently neural network based approaches to knowledge-intensive NLP tasks,\nsuch as question answering, started to rely heavily on the combination of\nneural retrievers and readers. Retrieval is typically performed over a large\ntextual knowledge base (KB) which requires significant memory and compute\nresources, especially when scaled up. On HotpotQA we systematically investigate\nreducing the size of the KB index by means of dimensionality (sparse random\nprojections, PCA, autoencoders) and numerical precision reduction.\nOur results show that PCA is an easy solution that requires very little data\nand is only slightly worse than autoencoders, which are less stable. All\nmethods are sensitive to pre- and post-processing and data should always be\ncentered and normalized both before and after dimension reduction. Finally, we\nshow that it is possible to combine PCA with using 1bit per dimension. Overall\nwe achieve (1) 100$\\times$ compression with 75%, and (2) 24$\\times$ compression\nwith 92% original retrieval performance.",
    "descriptor": "\nComments: To be presented at Spa-NLP workshop at ACL 2022\n",
    "authors": [
      "Vil\u00e9m Zouhar",
      "Marius Mosbach",
      "Miaoran Zhang",
      "Dietrich Klakow"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.02906"
  },
  {
    "id": "arXiv:2204.02908",
    "title": "Question Generation for Reading Comprehension Assessment by Modeling How  and What to Ask",
    "abstract": "Reading is integral to everyday life, and yet learning to read is a struggle\nfor many young learners. During lessons, teachers can use comprehension\nquestions to increase engagement, test reading skills, and improve retention.\nHistorically such questions were written by skilled teachers, but recently\nlanguage models have been used to generate comprehension questions. However,\nmany existing Question Generation (QG) systems focus on generating literal\nquestions from the text, and have no way to control the type of the generated\nquestion. In this paper, we study QG for reading comprehension where\ninferential questions are critical and extractive techniques cannot be used. We\npropose a two-step model (HTA-WTA) that takes advantage of previous datasets,\nand can generate questions for a specific targeted comprehension skill. We\npropose a new reading comprehension dataset that contains questions annotated\nwith story-based reading comprehension skills (SBRCS), allowing for a more\ncomplete reader assessment. Across several experiments, our results show that\nHTA-WTA outperforms multiple strong baselines on this new dataset. We show that\nthe HTA-WTA model tests for strong SCRS by asking deep inferential questions.",
    "descriptor": "\nComments: ACL-2022, 9 pages\n",
    "authors": [
      "Bilal Ghanem",
      "Lauren Lutz Coleman",
      "Julia Rivard Dexter",
      "Spencer McIntosh von der Ohe",
      "Alona Fyshe"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.02908"
  },
  {
    "id": "arXiv:2204.02915",
    "title": "Shorter Signatures from Proofs of Knowledge for the SD, MQ, PKP and RSD  Problems",
    "abstract": "The MPC in the head introduced in [IKOS07] has established itself as an\nimportant paradigm in order to design efficient digital signatures. In\nparticular, it has been leveraged in the Picnic scheme [CDG+ 20] that is\ncurrently considered in the third round of NIST Post-Quantum Standardization\nprocess. In addition, it has been used in [Beu20] to introduce the Proof of\nKnowledge (PoK) with Helper paradigm. This construction permits to design\nshorter signatures but induces a non negligible performance overhead. In this\npaper, our contributions are twofold. Firstly, we introduce a new PoK with\nHelper for the Syndrome Decoding (SD) problem. This construction relies on\nideas from [BGKM22] and [FJR21] and improve the latter using a new technique\nthat can be seen as performing the cut and choose with a meet in the middle\napproach. Secondly and most importantly, we introduce a new paradigm to design\nPoK that brings improvements over the PoK with Helper one. Indeed, we show how\none can substitute the Helper in these constructions by leveraging the\nunderlying structure of the considered problem. This new approach does not\nsuffer from the performance overhead inherent to the PoK with Helper paradigm\nhence offers different trade-offs between signature sizes and performances.\nInterestingly, our new approach is quite generic and can be applied to many\nproblems and their associated PoK. In order to demonstrate this versatility, we\nprovide new PoK related to the SD, MQ, PKP and RSD problems. In practice, these\nPoK lead to shorter signatures for the aforementioned problems. Indeed,\nconsidering (public key + signature), we get sizes below 12 kB for our\nsignature related to the SD problem, below 8 kB for our signature related to\nthe MQ problem, below 9 kB for our signature related to the PKP problem and\nbelow 7 kB for our signature related to the RSD problem.",
    "descriptor": "",
    "authors": [
      "Lo\u00efc Bidoux",
      "Philippe Gaborit"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2204.02915"
  },
  {
    "id": "arXiv:2204.02918",
    "title": "How SVC enables Distributed Caching in MEC?",
    "abstract": "With an ever increasing demand for the delivery of internet video service,\nthe service providers are facing a huge challenge to deliver ultra-HD (2k/4k)\nvideo at sub-second latency. The multi-access edge computing (MEC) platform\nactually helps in achieving this objective by caching popular contents at the\nedge of cellular network. This not only reduces the delivery latency, but also\nthe load and the cost of the backhaul links. However, MEC platforms are\nafflicted by constrained resources in terms of storage and processing\ncapabilities; and centralized caching of contents may nullify the advantage of\nreduced latency by lowering the offloading probability. Distributed caching at\nthe edge not only improves the offloading probability, but also dynamically\nadjusts the load distribution among the MEC servers. In this article, we\npropose an architecture for deployment of MEC platforms by exploiting the\ncharacteristics of a scalable video encoding technique. The layered video\ncoding techniques, such as the scalable video coding (SVC), is used by the\ncontent providers to adjust to the network dynamics, by dynamically dropping\npackets in order to reduce latency. We show how an SVC video easily lends\nitself to distributed caching at the edge. Then we investigate the\nlatency-storage trade-off by storing the video layers at different parts of the\naccess networks.",
    "descriptor": "",
    "authors": [
      "Suvadip Batabyal"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2204.02918"
  },
  {
    "id": "arXiv:2204.02919",
    "title": "Branch Decomposition-Independent Edit Distances for Merge Trees",
    "abstract": "Edit distances between merge trees of scalar fields have many applications in\nscientific visualization, such as ensemble analysis, feature tracking or\nsymmetry detection. In this paper, we propose branch mappings, a novel approach\nto the construction of edit mappings for merge trees. Classic edit mappings\nmatch nodes or edges of two trees onto each other, and therefore have to either\nrely on branch decompositions of both trees or have to use auxiliary node\nproperties to determine a matching. In contrast, branch mappings employ branch\nproperties instead of node similarity information, and are independent of\npredetermined branch decompositions. Especially for topological features, which\nare typically based on branch properties, this allows a more intuitive distance\nmeasure which is also less susceptible to instabilities from small-scale\nperturbations. We describe a quartic runtime algorithm for computing optimal\nbranch mappings, which is faster than the only other branch\ndecomposition-independent method in the literature by more than a linear\nfactor. Furthermore, we compare the results of our method on synthetic and\nreal-world examples to demonstrate its practicality and utility.",
    "descriptor": "",
    "authors": [
      "Florian Wetzels",
      "Heike Leitte",
      "Christoph Garth"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2204.02919"
  },
  {
    "id": "arXiv:2204.02921",
    "title": "A survey on recently proposed activation functions for Deep Learning",
    "abstract": "Artificial neural networks (ANN), typically referred to as neural networks,\nare a class of Machine Learning algorithms and have achieved widespread\nsuccess, having been inspired by the biological structure of the human brain.\nNeural networks are inherently powerful due to their ability to learn complex\nfunction approximations from data. This generalization ability has been able to\nimpact multidisciplinary areas involving image recognition, speech recognition,\nnatural language processing, and others. Activation functions are a crucial\nsub-component of neural networks. They define the output of a node in the\nnetwork given a set of inputs. This survey discusses the main concepts of\nactivation functions in neural networks, including; a brief introduction to\ndeep neural networks, a summary of what are activation functions and how they\nare used in neural networks, their most common properties, the different types\nof activation functions, some of the challenges, limitations, and alternative\nsolutions faced by activation functions, concluding with the final remarks.",
    "descriptor": "\nComments: 7 pages, 2 figures, 15 cited papers\n",
    "authors": [
      "Murilo Gustineli"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.02921"
  },
  {
    "id": "arXiv:2204.02922",
    "title": "Paying More Attention to Self-attention: Improving Pre-trained Language  Models via Attention Guiding",
    "abstract": "Pre-trained language models (PLM) have demonstrated their effectiveness for a\nbroad range of information retrieval and natural language processing tasks. As\nthe core part of PLM, multi-head self-attention is appealing for its ability to\njointly attend to information from different positions. However, researchers\nhave found that PLM always exhibits fixed attention patterns regardless of the\ninput (e.g., excessively paying attention to [CLS] or [SEP]), which we argue\nmight neglect important information in the other positions. In this work, we\npropose a simple yet effective attention guiding mechanism to improve the\nperformance of PLM by encouraging attention towards the established goals.\nSpecifically, we propose two kinds of attention guiding methods, i.e., map\ndiscrimination guiding (MDG) and attention pattern decorrelation guiding (PDG).\nThe former definitely encourages the diversity among multiple self-attention\nheads to jointly attend to information from different representation subspaces,\nwhile the latter encourages self-attention to attend to as many different\npositions of the input as possible. We conduct experiments with multiple\ngeneral pre-trained models (i.e., BERT, ALBERT, and Roberta) and\ndomain-specific pre-trained models (i.e., BioBERT, ClinicalBERT, BlueBert, and\nSciBERT) on three benchmark datasets (i.e., MultiNLI, MedNLI, and\nCross-genre-IR). Extensive experimental results demonstrate that our proposed\nMDG and PDG bring stable performance improvements on all datasets with high\nefficiency and low cost.",
    "descriptor": "",
    "authors": [
      "Shanshan Wang",
      "Zhumin Chen",
      "Zhaochun Ren",
      "Huasheng Liang",
      "Qiang Yan",
      "Pengjie Ren"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.02922"
  },
  {
    "id": "arXiv:2204.02929",
    "title": "Beam Search: Faster and Monotonic",
    "abstract": "Beam search is a popular satisficing approach to heuristic search problems\nthat allows one to trade increased computation time for lower solution cost by\nincreasing the beam width parameter. We make two contributions to the study of\nbeam search. First, we show how to make beam search monotonic; that is, we\nprovide a new variant that guarantees non-increasing solution cost as the beam\nwidth is increased. This makes setting the beam parameter much easier. Second,\nwe show how using distance-to-go estimates can allow beam search to find better\nsolutions more quickly in domains with non-uniform costs. Together, these\nresults improve the practical effectiveness of beam search.",
    "descriptor": "\nComments: 9 pages, 15 figures, 3 algorithms, published in the International Conference on Automated Planning and Scheduling ICAPS 2022\n",
    "authors": [
      "Sofia Lemons",
      "Carlos Linares L\u00f3pez",
      "Robert C. Holte",
      "Wheeler Ruml"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.02929"
  },
  {
    "id": "arXiv:2204.02932",
    "title": "An Empirical Study of End-to-End Temporal Action Detection",
    "abstract": "Temporal action detection (TAD) is an important yet challenging task in video\nunderstanding. It aims to simultaneously predict the semantic label and the\ntemporal interval of every action instance in an untrimmed video. Rather than\nend-to-end learning, most existing methods adopt a head-only learning paradigm,\nwhere the video encoder is pre-trained for action classification, and only the\ndetection head upon the encoder is optimized for TAD. The effect of end-to-end\nlearning is not systematically evaluated. Besides, there lacks an in-depth\nstudy on the efficiency-accuracy trade-off in end-to-end TAD. In this paper, we\npresent an empirical study of end-to-end temporal action detection. We validate\nthe advantage of end-to-end learning over head-only learning and observe up to\n11\\% performance improvement. Besides, we study the effects of multiple design\nchoices that affect the TAD performance and speed, including detection head,\nvideo encoder, and resolution of input videos. Based on the findings, we build\na mid-resolution baseline detector, which achieves the state-of-the-art\nperformance of end-to-end methods while running more than 4$\\times$ faster. We\nhope that this paper can serve as a guide for end-to-end learning and inspire\nfuture research in this field. Code and models are available at\n\\url{https://github.com/xlliu7/E2E-TAD}.",
    "descriptor": "\nComments: Accepted by CVPR 2022. 13 pages, including supplementary\n",
    "authors": [
      "Xiaolong Liu",
      "Song Bai",
      "Xiang Bai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.02932"
  },
  {
    "id": "arXiv:2204.02934",
    "title": "Parallel, Portable Algorithms for Distance-2 Maximal Independent Set and  Graph Coarsening",
    "abstract": "Given a graph, finding the distance-2 maximal independent set (MIS-2) of the\nvertices is a problem that is useful in several contexts such as algebraic\nmultigrid coarsening or multilevel graph partitioning. Such multilevel methods\nrely on finding the independent vertices so they can be used as seeds for\naggregation in a multilevel scheme. We present a parallel MIS-2 algorithm to\nimprove performance on modern accelerator hardware. This algorithm is\nimplemented using the Kokkos programming model to enable performance\nportability. We demonstrate the portability of the algorithm and the\nperformance on a variety of architectures (x86/ARM CPUs and NVIDIA/AMD GPUs).\nThe resulting algorithm is also deterministic, producing an identical result\nfor a given input across all of these platforms. The new MIS-2 implementation\noutperforms implementations in state of the art libraries like CUSP and\nViennaCL by 3-8x while producing similar quality results. We further\ndemonstrate the benefits of this approach by developing parallel graph\ncoarsening scheme for two different use cases. First, we develop an algebraic\nmultigrid (AMG) aggregation scheme using parallel MIS-2 and demonstrate the\nbenefits as opposed to previous approaches used in the MueLu multigrid package\nin Trilinos. We also describe an approach for implementing a parallel\nmulticolor \"cluster\" Gauss-Seidel preconditioner using this MIS-2 coarsening,\nand demonstrate better performance with an efficient, parallel, multicolor\nGauss-Seidel algorithm.",
    "descriptor": "\nComments: Accepted for publication in IPDPS 2022\n",
    "authors": [
      "Brian Kelley",
      "Sivasankaran Rajamanickam"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2204.02934"
  },
  {
    "id": "arXiv:2204.02937",
    "title": "Last Layer Re-Training is Sufficient for Robustness to Spurious  Correlations",
    "abstract": "Neural network classifiers can largely rely on simple spurious features, such\nas backgrounds, to make predictions. However, even in these cases, we show that\nthey still often learn core features associated with the desired attributes of\nthe data, contrary to recent findings. Inspired by this insight, we demonstrate\nthat simple last layer retraining can match or outperform state-of-the-art\napproaches on spurious correlation benchmarks, but with profoundly lower\ncomplexity and computational expenses. Moreover, we show that last layer\nretraining on large ImageNet-trained models can also significantly reduce\nreliance on background and texture information, improving robustness to\ncovariate shift, after only minutes of training on a single GPU.",
    "descriptor": "\nComments: Code is available at this https URL\n",
    "authors": [
      "Polina Kirichenko",
      "Pavel Izmailov",
      "Andrew Gordon Wilson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2204.02937"
  },
  {
    "id": "arXiv:2204.02939",
    "title": "S-R2F2U-Net: A single-stage model for teeth segmentation",
    "abstract": "Precision tooth segmentation is crucial in the oral sector because it\nprovides location information for orthodontic therapy, clinical diagnosis, and\nsurgical treatments. In this paper, we investigate residual, recurrent, and\nattention networks to segment teeth from panoramic dental images. Based on our\nfindings, we suggest three single-stage models: Single Recurrent R2U-Net\n(S-R2U-Net), Single Recurrent Filter Double R2U-Net (S-R2F2U-Net), and Single\nRecurrent Attention Enabled Filter Double (S-R2F2-Attn-U-Net). Particularly,\nS-R2F2U-Net outperforms state-of-the-art models in terms of accuracy and dice\nscore. A hybrid loss function combining the cross-entropy loss and dice loss is\nused to train the model. In addition, it reduces around 45% of model parameters\ncompared to the R2U-Net model. Models are trained and evaluated on a benchmark\ndataset containing 1500 dental panoramic X-ray images. S-R2F2U-Net achieves\n97.31% of accuracy and 93.26% of dice score, showing superiority over the\nstate-of-the-art methods. Codes are available at\nhttps://github.com/mrinal054/teethSeg_sr2f2u-net.git.",
    "descriptor": "\nComments: GitHub link is mentioned in the abstract. The main manuscript contains 4 figures and 4 tables. The supplementary document contains 7 figures and 1 table\n",
    "authors": [
      "Mrinal Kanti Dhar",
      "Zeyun Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.02939"
  },
  {
    "id": "arXiv:2204.02942",
    "title": "A Design Methodology for Fault-Tolerant Computing using Astrocyte Neural  Networks",
    "abstract": "We propose a design methodology to facilitate fault tolerance of deep\nlearning models. First, we implement a many-core fault-tolerant neuromorphic\nhardware design, where neuron and synapse circuitries in each neuromorphic core\nare enclosed with astrocyte circuitries, the star-shaped glial cells of the\nbrain that facilitate self-repair by restoring the spike firing frequency of a\nfailed neuron using a closed-loop retrograde feedback signal. Next, we\nintroduce astrocytes in a deep learning model to achieve the required degree of\ntolerance to hardware faults. Finally, we use a system software to partition\nthe astrocyte-enabled model into clusters and implement them on the proposed\nfault-tolerant neuromorphic design. We evaluate this design methodology using\nseven deep learning inference models and show that it is both area and power\nefficient.",
    "descriptor": "\nComments: Accepted at ACM Computing Frontiers, 2022\n",
    "authors": [
      "Murat I\u015f\u0131k",
      "Ankita Paul",
      "M. Lakshmi Varshika",
      "Anup Das"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2204.02942"
  },
  {
    "id": "arXiv:2204.02943",
    "title": "Intervertebral Disc Labeling With Learning Shape Information, A Look  Once Approach",
    "abstract": "Accurate and automatic segmentation of intervertebral discs from medical\nimages is a critical task for the assessment of spine-related diseases such as\nosteoporosis, vertebral fractures, and intervertebral disc herniation. To date,\nvarious approaches have been developed in the literature which routinely relies\non detecting the discs as the primary step. A disadvantage of many cohort\nstudies is that the localization algorithm also yields false-positive\ndetections. In this study, we aim to alleviate this problem by proposing a\nnovel U-Net-based structure to predict a set of candidates for intervertebral\ndisc locations. In our design, we integrate the image shape information (image\ngradients) to encourage the model to learn rich and generic geometrical\ninformation. This additional signal guides the model to selectively emphasize\nthe contextual representation and suppress the less discriminative features. On\nthe post-processing side, to further decrease the false positive rate, we\npropose a permutation invariant 'look once' model, which accelerates the\ncandidate recovery procedure. In comparison with previous studies, our proposed\napproach does not need to perform the selection in an iterative fashion. The\nproposed method was evaluated on the spine generic public multi-center dataset\nand demonstrated superior performance compared to previous work. We have\nprovided the implementation code in\nhttps://github.com/rezazad68/intervertebral-lookonce",
    "descriptor": "",
    "authors": [
      "Reza Azad",
      "Moein Heidari",
      "Julien Cohen-Adad",
      "Ehsan Adeli",
      "Dorit Merhof"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.02943"
  },
  {
    "id": "arXiv:2204.02944",
    "title": "\"The Pedestrian next to the Lamppost\" Adaptive Object Graphs for Better  Instantaneous Mapping",
    "abstract": "Estimating a semantically segmented bird's-eye-view (BEV) map from a single\nimage has become a popular technique for autonomous control and navigation.\nHowever, they show an increase in localization error with distance from the\ncamera. While such an increase in error is entirely expected - localization is\nharder at distance - much of the drop in performance can be attributed to the\ncues used by current texture-based models, in particular, they make heavy use\nof object-ground intersections (such as shadows), which become increasingly\nsparse and uncertain for distant objects. In this work, we address these\nshortcomings in BEV-mapping by learning the spatial relationship between\nobjects in a scene. We propose a graph neural network which predicts BEV\nobjects from a monocular image by spatially reasoning about an object within\nthe context of other objects. Our approach sets a new state-of-the-art in BEV\nestimation from monocular images across three large-scale datasets, including a\n50% relative improvement for objects on nuScenes.",
    "descriptor": "\nComments: Accepted to CVPR 2022\n",
    "authors": [
      "Avishkar Saha",
      "Oscar Mendez",
      "Chris Russell",
      "Richard Bowden"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.02944"
  },
  {
    "id": "arXiv:2204.02947",
    "title": "Marrying Fairness and Explainability in Supervised Learning",
    "abstract": "Machine learning algorithms that aid human decision-making may inadvertently\ndiscriminate against certain protected groups. We formalize direct\ndiscrimination as a direct causal effect of the protected attributes on the\ndecisions, while induced discrimination as a change in the causal influence of\nnon-protected features associated with the protected attributes. The\nmeasurements of marginal direct effect (MDE) and SHapley Additive exPlanations\n(SHAP) reveal that state-of-the-art fair learning methods can induce\ndiscrimination via association or reverse discrimination in synthetic and\nreal-world datasets. To inhibit discrimination in algorithmic systems, we\npropose to nullify the influence of the protected attribute on the output of\nthe system, while preserving the influence of remaining features. We introduce\nand study post-processing methods achieving such objectives, finding that they\nyield relatively high model accuracy, prevent direct discrimination, and\ndiminishes various disparity measures, e.g., demographic disparity.",
    "descriptor": "\nComments: 23 pages, 17 figures\n",
    "authors": [
      "Przemyslaw Grabowicz",
      "Nicholas Perello",
      "Aarshee Mishra"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2204.02947"
  },
  {
    "id": "arXiv:2204.02948",
    "title": "Guaranteed Bounds for Posterior Inference in Universal Probabilistic  Programming",
    "abstract": "We propose a new method to approximate the posterior distribution of\nprobabilistic programs by means of computing guaranteed bounds. The starting\npoint of our work is an interval-based trace semantics for a recursive,\nhigher-order probabilistic programming language with continuous distributions.\nTaking the form of (super-/subadditive) measures, these lower/upper bounds are\nnon-stochastic and provably correct: using the semantics, we prove that the\nactual posterior of a given program is sandwiched between the lower and upper\nbounds (soundness); moreover the bounds converge to the posterior\n(completeness). As a practical and sound approximation, we introduce a\nweight-aware interval type system, which automatically infers interval bounds\non not just the return value but also weight of program executions,\nsimultaneously. We have built a tool implementation, called GuBPI, which\nautomatically computes these posterior lower/upper bounds. Our evaluation on\nexamples from the literature shows that the bounds are useful, and can even be\nused to recognise wrong outputs from stochastic posterior inference procedures.",
    "descriptor": "\nComments: PLDI 2022\n",
    "authors": [
      "Raven Beutner",
      "Luke Ong",
      "Fabian Zaiser"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Machine Learning (cs.LG)",
      "Logic in Computer Science (cs.LO)",
      "Computation (stat.CO)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2204.02948"
  },
  {
    "id": "arXiv:2204.02952",
    "title": "Inducing Positive Perspectives with Text Reframing",
    "abstract": "Sentiment transfer is one popular example of a text style transfer task,\nwhere the goal is to reverse the sentiment polarity of a text. With a sentiment\nreversal comes also a reversal in meaning. We introduce a different but related\ntask called positive reframing in which we neutralize a negative point of view\nand generate a more positive perspective for the author without contradicting\nthe original meaning. Our insistence on meaning preservation makes positive\nreframing a challenging and semantically rich task. To facilitate rapid\nprogress, we introduce a large-scale benchmark, Positive Psychology Frames,\nwith 8,349 sentence pairs and 12,755 structured annotations to explain positive\nreframing in terms of six theoretically-motivated reframing strategies. Then we\nevaluate a set of state-of-the-art text style transfer models, and conclude by\ndiscussing key challenges and directions for future work.",
    "descriptor": "\nComments: ACL 2022 main conference\n",
    "authors": [
      "Caleb Ziems",
      "Minzhi Li",
      "Anthony Zhang",
      "Diyi Yang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.02952"
  },
  {
    "id": "arXiv:2204.02953",
    "title": "Scheduling to Minimize Age of Information with Multiple Sources",
    "abstract": "We consider a G/G/1 queueing system with a single server, where updates\narrive from different sources stochastically with possibly different update\ninter-generation time distributions. The server can transmit/serve at most one\nupdate at any time, with potentially different transmission/service times for\nupdates belonging to distinct sources. The age of information (AoI) of any\nsource is a function of the time difference between the departure time of\nsuccessive updates of that source. Each fully/partially transmitted update\nincurs a fixed (energy) cost, and the goal of the scheduler is to minimize the\nlinear combination of the sum of the age of information across all sources and\nthe total energy cost. We propose a simple non-preemptive randomized scheduling\nalgorithm that randomly marks arriving updates from a source to be eligible for\ntransmission with a fixed probability and discards them otherwise. Every time\nthe server becomes free, it chooses a source for transmission randomly with\nanother fixed probability and begins to transmit the most recently marked\nupdate of the chosen source. Both the respective probabilities are chosen by\nsolving a convex program. The competitive ratio of the proposed algorithm\n(against a non-preemptive offline optimal algorithm) is shown to be 3 plus the\nmaximum of the ratio of the variance and the mean of the inter-arrival time\ndistribution of sources. For several common distributions such as exponential,\nuniform and Rayleigh, the competitive ratio is at most 4. For preemptive\npolicies, a G/M/1 system is considered and a non-preemptive policy is shown to\nhave competitive ratio (against a preemptive offline optimal algorithm) at most\n5 plus the maximum of the ratio of the variance and the mean of the\ninter-arrival time distribution of sources.",
    "descriptor": "\nComments: 39 pages, 12 figures\n",
    "authors": [
      "Kumar Saurav",
      "Rahul Vaze"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2204.02953"
  },
  {
    "id": "arXiv:2204.02957",
    "title": "Video Demoireing with Relation-Based Temporal Consistency",
    "abstract": "Moire patterns, appearing as color distortions, severely degrade image and\nvideo qualities when filming a screen with digital cameras. Considering the\nincreasing demands for capturing videos, we study how to remove such\nundesirable moire patterns in videos, namely video demoireing. To this end, we\nintroduce the first hand-held video demoireing dataset with a dedicated data\ncollection pipeline to ensure spatial and temporal alignments of captured data.\nFurther, a baseline video demoireing model with implicit feature space\nalignment and selective feature aggregation is developed to leverage\ncomplementary information from nearby frames to improve frame-level video\ndemoireing. More importantly, we propose a relation-based temporal consistency\nloss to encourage the model to learn temporal consistency priors directly from\nground-truth reference videos, which facilitates producing temporally\nconsistent predictions and effectively maintains frame-level qualities.\nExtensive experiments manifest the superiority of our model. Code is available\nat \\url{https://daipengwa.github.io/VDmoire_ProjectPage/}.",
    "descriptor": "",
    "authors": [
      "Peng Dai",
      "Xin Yu",
      "Lan Ma",
      "Baoheng Zhang",
      "Jia Li",
      "Wenbo Li",
      "Jiajun Shen",
      "Xiaojuan Qi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.02957"
  },
  {
    "id": "arXiv:2204.02958",
    "title": "LEAD: Self-Supervised Landmark Estimation by Aligning Distributions of  Feature Similarity",
    "abstract": "In this work, we introduce LEAD, an approach to discover landmarks from an\nunannotated collection of category-specific images. Existing works in\nself-supervised landmark detection are based on learning dense (pixel-level)\nfeature representations from an image, which are further used to learn\nlandmarks in a semi-supervised manner. While there have been advances in\nself-supervised learning of image features for instance-level tasks like\nclassification, these methods do not ensure dense equivariant representations.\nThe property of equivariance is of interest for dense prediction tasks like\nlandmark estimation. In this work, we introduce an approach to enhance the\nlearning of dense equivariant representations in a self-supervised fashion. We\nfollow a two-stage training approach: first, we train a network using the BYOL\nobjective which operates at an instance level. The correspondences obtained\nthrough this network are further used to train a dense and compact\nrepresentation of the image using a lightweight network. We show that having\nsuch a prior in the feature extractor helps in landmark detection, even under\ndrastically limited number of annotations while also improving generalization\nacross scale variations.",
    "descriptor": "\nComments: WACV 2022. Project Page at this http URL\n",
    "authors": [
      "Tejan Karmali",
      "Abhinav Atrishi",
      "Sai Sree Harsha",
      "Susmit Agrawal",
      "Varun Jampani",
      "R. Venkatesh Babu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.02958"
  },
  {
    "id": "arXiv:2204.02960",
    "title": "Simple and Effective Synthesis of Indoor 3D Scenes",
    "abstract": "We study the problem of synthesizing immersive 3D indoor scenes from one or\nmore images. Our aim is to generate high-resolution images and videos from\nnovel viewpoints, including viewpoints that extrapolate far beyond the input\nimages while maintaining 3D consistency. Existing approaches are highly\ncomplex, with many separately trained stages and components. We propose a\nsimple alternative: an image-to-image GAN that maps directly from reprojections\nof incomplete point clouds to full high-resolution RGB-D images. On the\nMatterport3D and RealEstate10K datasets, our approach significantly outperforms\nprior work when evaluated by humans, as well as on FID scores. Further, we show\nthat our model is useful for generative data augmentation. A\nvision-and-language navigation (VLN) agent trained with trajectories\nspatially-perturbed by our model improves success rate by up to 1.5% over a\nstate of the art baseline on the R2R benchmark. Our code will be made available\nto facilitate generative data augmentation and applications to downstream\nrobotics and embodied AI tasks.",
    "descriptor": "",
    "authors": [
      "Jing Yu Koh",
      "Harsh Agrawal",
      "Dhruv Batra",
      "Richard Tucker",
      "Austin Waters",
      "Honglak Lee",
      "Yinfei Yang",
      "Jason Baldridge",
      "Peter Anderson"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.02960"
  },
  {
    "id": "arXiv:2204.02961",
    "title": "SMU-Net: Style matching U-Net for brain tumor segmentation with missing  modalities",
    "abstract": "Gliomas are one of the most prevalent types of primary brain tumours,\naccounting for more than 30\\% of all cases and they develop from the glial stem\nor progenitor cells. In theory, the majority of brain tumours could well be\nidentified exclusively by the use of Magnetic Resonance Imaging (MRI). Each MRI\nmodality delivers distinct information on the soft tissue of the human brain\nand integrating all of them would provide comprehensive data for the accurate\nsegmentation of the glioma, which is crucial for the patient's prognosis,\ndiagnosis, and determining the best follow-up treatment. Unfortunately, MRI is\nprone to artifacts for a variety of reasons, which might result in missing one\nor more MRI modalities. Various strategies have been proposed over the years to\nsynthesize the missing modality or compensate for the influence it has on\nautomated segmentation models. However, these methods usually fail to model the\nunderlying missing information. In this paper, we propose a style matching\nU-Net (SMU-Net) for brain tumour segmentation on MRI images. Our co-training\napproach utilizes a content and style-matching mechanism to distill the\ninformative features from the full-modality network into a missing modality\nnetwork. To do so, we encode both full-modality and missing-modality data into\na latent space, then we decompose the representation space into a style and\ncontent representation. Our style matching module adaptively recalibrates the\nrepresentation space by learning a matching function to transfer the\ninformative and textural features from a full-modality path into a\nmissing-modality path. Moreover, by modelling the mutual information, our\ncontent module surpasses the less informative features and re-calibrates the\nrepresentation space based on discriminative semantic features. The evaluation\nprocess on the BraTS 2018 dataset shows a significant results.",
    "descriptor": "",
    "authors": [
      "Reza Azad",
      "Nika Khosravi",
      "Dorit Merhof"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.02961"
  },
  {
    "id": "arXiv:2204.02964",
    "title": "Unleashing Vanilla Vision Transformer with Masked Image Modeling for  Object Detection",
    "abstract": "We present an approach to efficiently and effectively adapt a masked image\nmodeling (MIM) pre-trained vanilla Vision Transformer (ViT) for object\ndetection, which is based on our two novel observations: (i) A MIM pre-trained\nvanilla ViT can work surprisingly well in the challenging object-level\nrecognition scenario even with random sampled partial observations, e.g., only\n25% ~ 50% of the input sequence. (ii) In order to construct multi-scale\nrepresentations for object detection, a random initialized compact\nconvolutional stem supplants the pre-trained large kernel patchify stem, and\nits intermediate features can naturally serve as the higher resolution inputs\nof a feature pyramid without upsampling. While the pre-trained ViT is only\nregarded as the third-stage of our detector's backbone instead of the whole\nfeature extractor, resulting in a ConvNet-ViT hybrid architecture. The proposed\ndetector, named MIMDet, enables a MIM pre-trained vanilla ViT to outperform\nhierarchical Swin Transformer by 2.3 box AP and 2.5 mask AP on COCO, and\nachieve even better results compared with other adapted vanilla ViT using a\nmore modest fine-tuning recipe while converging 2.8x faster. Code and\npre-trained models are available at \\url{https://github.com/hustvl/MIMDet}.",
    "descriptor": "\nComments: Preprint. Work in progress. Code and pre-trained models are available at \\url{this https URL}\n",
    "authors": [
      "Yuxin Fang",
      "Shusheng Yang",
      "Shijie Wang",
      "Yixiao Ge",
      "Ying Shan",
      "Xinggang Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.02964"
  },
  {
    "id": "arXiv:2204.02965",
    "title": "LilNetX: Lightweight Networks with EXtreme Model Compression and  Structured Sparsification",
    "abstract": "We introduce LilNetX, an end-to-end trainable technique for neural networks\nthat enables learning models with specified accuracy-rate-computation\ntrade-off. Prior works approach these problems one at a time and often require\npost-processing or multistage training which become less practical and do not\nscale very well for large datasets or architectures. Our method constructs a\njoint training objective that penalizes the self-information of network\nparameters in a reparameterized latent space to encourage small model size\nwhile also introducing priors to increase structured sparsity in the parameter\nspace to reduce computation. We achieve up to 50% smaller model size and 98%\nmodel sparsity on ResNet-20 while retaining the same accuracy on the CIFAR-10\ndataset as well as 35% smaller model size and 42% structured sparsity on\nResNet-50 trained on ImageNet, when compared to existing state-of-the-art model\ncompression methods. Code is available at\nhttps://github.com/Sharath-girish/LilNetX.",
    "descriptor": "",
    "authors": [
      "Sharath Girish",
      "Kamal Gupta",
      "Saurabh Singh",
      "Abhinav Shrivastava"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.02965"
  },
  {
    "id": "arXiv:2204.02967",
    "title": "Enhanced Direct Speech-to-Speech Translation Using Self-supervised  Pre-training and Data Augmentation",
    "abstract": "Direct speech-to-speech translation (S2ST) models suffer from data scarcity\nissues as there exists little parallel S2ST data, compared to the amount of\ndata available for conventional cascaded systems that consist of automatic\nspeech recognition (ASR), machine translation (MT), and text-to-speech (TTS)\nsynthesis. In this work, we explore self-supervised pre-training with unlabeled\nspeech data and data augmentation to tackle this issue. We take advantage of a\nrecently proposed speech-to-unit translation (S2UT) framework that encodes\ntarget speech into discrete representations, and transfer pre-training and\nefficient partial finetuning techniques that work well for speech-to-text\ntranslation (S2T) to the S2UT domain by studying both speech encoder and\ndiscrete unit decoder pre-training. Our experiments show that self-supervised\npre-training consistently improves model performance compared with multitask\nlearning with a BLEU gain of 4.3-12.0 under various data setups, and it can be\nfurther combined with data augmentation techniques that apply MT to create\nweakly supervised training data. Audio samples are available at:\nhttps://facebookresearch.github.io/speech_translation/enhanced_direct_s2st_units/index.html .",
    "descriptor": "\nComments: Submitted to Interspeech 2022\n",
    "authors": [
      "Sravya Popuri",
      "Peng-Jen Chen",
      "Changhan Wang",
      "Juan Pino",
      "Yossi Adi",
      "Jiatao Gu",
      "Wei-Ning Hsu",
      "Ann Lee"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2204.02967"
  },
  {
    "id": "arXiv:2204.02968",
    "title": "Temporal Alignment Networks for Long-term Video",
    "abstract": "The objective of this paper is a temporal alignment network that ingests long\nterm video sequences, and associated text sentences, in order to: (1) determine\nif a sentence is alignable with the video; and (2) if it is alignable, then\ndetermine its alignment. The challenge is to train such networks from\nlarge-scale datasets, such as HowTo100M, where the associated text sentences\nhave significant noise, and are only weakly aligned when relevant. Apart from\nproposing the alignment network, we also make four contributions: (i) we\ndescribe a novel co-training method that enables to denoise and train on raw\ninstructional videos without using manual annotation, despite the considerable\nnoise; (ii) to benchmark the alignment performance, we manually curate a\n10-hour subset of HowTo100M, totalling 80 videos, with sparse temporal\ndescriptions. Our proposed model, trained on HowTo100M, outperforms strong\nbaselines (CLIP, MIL-NCE) on this alignment dataset by a significant margin;\n(iii) we apply the trained model in the zero-shot settings to multiple\ndownstream video understanding tasks and achieve state-of-the-art results,\nincluding text-video retrieval on YouCook2, and weakly supervised video action\nsegmentation on Breakfast-Action; (iv) we use the automatically aligned\nHowTo100M annotations for end-to-end finetuning of the backbone model, and\nobtain improved performance on downstream action recognition tasks.",
    "descriptor": "\nComments: CVPR2022 Oral, 16 pages\n",
    "authors": [
      "Tengda Han",
      "Weidi Xie",
      "Andrew Zisserman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.02968"
  },
  {
    "id": "arXiv:2204.02403",
    "title": "Explainable Deep Learning Algorithm for Distinguishing Incomplete  Kawasaki Disease by Coronary Artery Lesions on Echocardiographic Imaging",
    "abstract": "Background and Objective: Incomplete Kawasaki disease (KD) has often been\nmisdiagnosed due to a lack of the clinical manifestations of classic KD.\nHowever, it is associated with a markedly higher prevalence of coronary artery\nlesions. Identifying coronary artery lesions by echocardiography is important\nfor the timely diagnosis of and favorable outcomes in KD. Moreover, similar to\nKD, coronavirus disease 2019, currently causing a worldwide pandemic, also\nmanifests with fever; therefore, it is crucial at this moment that KD should be\ndistinguished clearly among the febrile diseases in children. In this study, we\naimed to validate a deep learning algorithm for classification of KD and other\nacute febrile diseases.\nMethods: We obtained coronary artery images by echocardiography of children\n(n = 88 for KD; n = 65 for pneumonia). We trained six deep learning networks\n(VGG19, Xception, ResNet50, ResNext50, SE-ResNet50, and SE-ResNext50) using the\ncollected data.\nResults: SE-ResNext50 showed the best performance in terms of accuracy,\nspecificity, and precision in the classification. SE-ResNext50 offered a\nprecision of 76.35%, a sensitivity of 82.64%, and a specificity of 58.12%.\nConclusions: The results of our study suggested that deep learning algorithms\nhave similar performance to an experienced cardiologist in detecting coronary\nartery lesions to facilitate the diagnosis of KD.",
    "descriptor": "",
    "authors": [
      "Haeyun Lee",
      "Yongsoon Eun",
      "Jae Youn Hwang",
      "Lucy Youngmin Eun"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.02403"
  },
  {
    "id": "arXiv:2204.02404",
    "title": "Hospital-Agnostic Image Representation Learning in Digital Pathology",
    "abstract": "Whole Slide Images (WSIs) in digital pathology are used to diagnose cancer\nsubtypes. The difference in procedures to acquire WSIs at various trial sites\ngives rise to variability in the histopathology images, thus making consistent\ndiagnosis challenging. These differences may stem from variability in image\nacquisition through multi-vendor scanners, variable acquisition parameters, and\ndifferences in staining procedure; as well, patient demographics may bias the\nglass slide batches before image acquisition. These variabilities are assumed\nto cause a domain shift in the images of different hospitals. It is crucial to\novercome this domain shift because an ideal machine-learning model must be able\nto work on the diverse sources of images, independent of the acquisition\ncenter. A domain generalization technique is leveraged in this study to improve\nthe generalization capability of a Deep Neural Network (DNN), to an unseen\nhistopathology image set (i.e., from an unseen hospital/trial site) in the\npresence of domain shift. According to experimental results, the conventional\nsupervised-learning regime generalizes poorly to data collected from different\nhospitals. However, the proposed hospital-agnostic learning can improve the\ngeneralization considering the low-dimensional latent space representation\nvisualization, and classification accuracy results.",
    "descriptor": "\nComments: Accepted for presentation at the 44th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC'22)\n",
    "authors": [
      "Milad Sikaroudi",
      "Shahryar Rahnamayan",
      "H.R. Tizhoosh"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.02404"
  },
  {
    "id": "arXiv:2204.02405",
    "title": "Zero-shot Blind Image Denoising via Implicit Neural Representations",
    "abstract": "Recent denoising algorithms based on the \"blind-spot\" strategy show\nimpressive blind image denoising performances, without utilizing any external\ndataset. While the methods excel in recovering highly contaminated images, we\nobserve that such algorithms are often less effective under a low-noise or real\nnoise regime. To address this gap, we propose an alternative denoising strategy\nthat leverages the architectural inductive bias of implicit neural\nrepresentations (INRs), based on our two findings: (1) INR tends to fit the\nlow-frequency clean image signal faster than the high-frequency noise, and (2)\nINR layers that are closer to the output play more critical roles in fitting\nhigher-frequency parts. Building on these observations, we propose a denoising\nalgorithm that maximizes the innate denoising capability of INRs by penalizing\nthe growth of deeper layer weights. We show that our method outperforms\nexisting zero-shot denoising methods under an extensive set of low-noise or\nreal-noise scenarios.",
    "descriptor": "\nComments: 8 pages, 3 figures\n",
    "authors": [
      "Chaewon Kim",
      "Jaeho Lee",
      "Jinwoo Shin"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.02405"
  },
  {
    "id": "arXiv:2204.02406",
    "title": "A deep learning framework for the detection and quantification of drusen  and reticular pseudodrusen on optical coherence tomography",
    "abstract": "Purpose - To develop and validate a deep learning (DL) framework for the\ndetection and quantification of drusen and reticular pseudodrusen (RPD) on\noptical coherence tomography scans.\nDesign - Development and validation of deep learning models for\nclassification and feature segmentation.\nMethods - A DL framework was developed consisting of a classification model\nand an out-of-distribution (OOD) detection model for the identification of\nungradable scans; a classification model to identify scans with drusen or RPD;\nand an image segmentation model to independently segment lesions as RPD or\ndrusen. Data were obtained from 1284 participants in the UK Biobank (UKBB) with\na self-reported diagnosis of age-related macular degeneration (AMD) and 250\nUKBB controls. Drusen and RPD were manually delineated by five retina\nspecialists. The main outcome measures were sensitivity, specificity, area\nunder the ROC curve (AUC), kappa, accuracy and intraclass correlation\ncoefficient (ICC).\nResults - The classification models performed strongly at their respective\ntasks (0.95, 0.93, and 0.99 AUC, respectively, for the ungradable scans\nclassifier, the OOD model, and the drusen and RPD classification model). The\nmean ICC for drusen and RPD area vs. graders was 0.74 and 0.61, respectively,\ncompared with 0.69 and 0.68 for intergrader agreement. FROC curves showed that\nthe model's sensitivity was close to human performance.\nConclusions - The models achieved high classification and segmentation\nperformance, similar to human performance. Application of this robust framework\nwill further our understanding of RPD as a separate entity from drusen in both\nresearch and clinical settings.",
    "descriptor": "\nComments: 26 pages, 7 figures\n",
    "authors": [
      "Roy Schwartz",
      "Hagar Khalid",
      "Sandra Liakopoulos",
      "Yanling Ouyang",
      "Coen de Vente",
      "Cristina Gonz\u00e1lez-Gonzalo",
      "Aaron Y. Lee",
      "Robyn Guymer",
      "Emily Y. Chew",
      "Catherine Egan",
      "Zhichao Wu",
      "Himeesh Kumar",
      "Joseph Farrington",
      "Clara I. S\u00e1nchez",
      "Adnan Tufail"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.02406"
  },
  {
    "id": "arXiv:2204.02450",
    "title": "Federated Cross Learning for Medical Image Segmentation",
    "abstract": "Federated learning (FL) can collaboratively train deep learning models using\nisolated patient data owned by different hospitals for various clinical\napplications, including medical image segmentation. However, a major problem of\nFL is its performance degradation when dealing with the data that are not\nindependently and identically distributed (non-iid), which is often the case in\nmedical images. In this paper, we first conduct a theoretical analysis on the\nFL algorithm to reveal the problem of model aggregation during training on\nnon-iid data. With the insights gained through the analysis, we propose a\nsimple and yet effective method, federated cross learning (FedCross), to tackle\nthis challenging problem. Unlike the conventional FL methods that combine\nmultiple individually trained local models on a server node, our FedCross\nsequentially trains the global model across different clients in a round-robin\nmanner, and thus the entire training procedure does not involve any model\naggregation steps. To further improve its performance to be comparable with the\ncentralized learning method, we combine the FedCross with an ensemble learning\nmechanism to compose a federated cross ensemble learning (FedCrossEns) method.\nFinally, we conduct extensive experiments using a set of public datasets. The\nexperimental results show that the proposed FedCross training strategy\noutperforms the mainstream FL methods on non-iid data. In addition to improving\nthe segmentation performance, our FedCrossEns can further provide a\nquantitative estimation of the model uncertainty, demonstrating the\neffectiveness and clinical significance of our designs. Source code will be\nmade publicly available after paper publication.",
    "descriptor": "\nComments: 10 pages, 4 figures\n",
    "authors": [
      "Xuanang Xu",
      "Tianyi Chen",
      "Han Deng",
      "Tianshu Kuang",
      "Joshua C. Barber",
      "Daeseung Kim",
      "Jaime Gateno",
      "Pingkun Yan",
      "James J. Xia"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.02450"
  },
  {
    "id": "arXiv:2204.02474",
    "title": "Generative Enriched Sequential Learning (ESL) Approach for Molecular  Design via Augmented Domain Knowledge",
    "abstract": "Deploying generative machine learning techniques to generate novel chemical\nstructures based on molecular fingerprint representation has been well\nestablished in molecular design. Typically, sequential learning (SL) schemes\nsuch as hidden Markov models (HMM) and, more recently, in the sequential deep\nlearning context, recurrent neural network (RNN) and long short-term memory\n(LSTM) were used extensively as generative models to discover unprecedented\nmolecules. To this end, emission probability between two states of atoms plays\na central role without considering specific chemical or physical properties.\nLack of supervised domain knowledge can mislead the learning procedure to be\nrelatively biased to the prevalent molecules observed in the training data that\nare not necessarily of interest. We alleviated this drawback by augmenting the\ntraining data with domain knowledge, e.g. quantitative estimates of the\ndrug-likeness score (QEDs). As such, our experiments demonstrated that with\nthis subtle trick called enriched sequential learning (ESL), specific patterns\nof particular interest can be learnt better, which led to generating de novo\nmolecules with ameliorated QEDs.",
    "descriptor": "\nComments: 6 pages\n",
    "authors": [
      "Mohammad Sajjad Ghaemi",
      "Karl Grantham",
      "Isaac Tamblyn",
      "Yifeng Li",
      "Hsu Kiang Ooi"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.02474"
  },
  {
    "id": "arXiv:2204.02480",
    "title": "Learning Optimal K-space Acquisition and Reconstruction using  Physics-Informed Neural Networks",
    "abstract": "The inherent slow imaging speed of Magnetic Resonance Image (MRI) has spurred\nthe development of various acceleration methods, typically through\nheuristically undersampling the MRI measurement domain known as k-space.\nRecently, deep neural networks have been applied to reconstruct undersampled\nk-space data and have shown improved reconstruction performance. While most of\nthese methods focus on designing novel reconstruction networks or new training\nstrategies for a given undersampling pattern, \\textit{e.g.}, Cartesian\nundersampling or Non-Cartesian sampling, to date, there is limited research\naiming to learn and optimize k-space sampling strategies using deep neural\nnetworks. This work proposes a novel optimization framework to learn k-space\nsampling trajectories by considering it as an Ordinary Differential Equation\n(ODE) problem that can be solved using neural ODE. In particular, the sampling\nof k-space data is framed as a dynamic system, in which neural ODE is\nformulated to approximate the system with additional constraints on MRI\nphysics. In addition, we have also demonstrated that trajectory optimization\nand image reconstruction can be learned collaboratively for improved imaging\nefficiency and reconstruction performance. Experiments were conducted on\ndifferent in-vivo datasets (\\textit{e.g.}, brain and knee images) acquired with\ndifferent sequences. Initial results have shown that our proposed method can\ngenerate better image quality in accelerated MRI than conventional\nundersampling schemes in Cartesian and Non-Cartesian acquisitions.",
    "descriptor": "\nComments: Accepted by CVPR2022\n",
    "authors": [
      "Wei Peng",
      "Li Feng",
      "Guoying Zhao",
      "Fang Liu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.02480"
  },
  {
    "id": "arXiv:2204.02493",
    "title": "Distributed Robust Control for Systems with Structured Uncertainties",
    "abstract": "We present D-Phi iteration: an algorithm for distributed, localized, and\nscalable robust control of systems with structured uncertainties. This\nalgorithm combines the System Level Synthesis (SLS) parametrization for\ndistributed control with stability criteria from L1, L-infinity, and nu robust\ncontrol. We show in simulation that this algorithm achieves near-optimal\nnominal performance (within 12% of the LQR controller) while doubling or\ntripling the stability margin (depending on the stability criterion) compared\nto the LQR controller. To the best of our knowledge, this is the first\ndistributed and localized algorithm for structured robust control; furthermore,\nalgorithm complexity depends only on the size of local neighborhoods and is\nindependent of global system size. We additionally characterize the suitability\nof different robustness criteria for distributed and localized computation, and\ndiscuss open questions on the topic of distributed robust control.",
    "descriptor": "\nComments: Submitted to CDC 2022\n",
    "authors": [
      "Jing Shuang Li",
      "John C. Doyle"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2204.02493"
  },
  {
    "id": "arXiv:2204.02513",
    "title": "In-Pocket 3D Graphs Enhance Ligand-Target Compatibility in Generative  Small-Molecule Creation",
    "abstract": "Proteins in complex with small molecule ligands represent the core of\nstructure-based drug discovery. However, three-dimensional representations are\nabsent from most deep-learning-based generative models. We here present a\ngraph-based generative modeling technology that encodes explicit 3D\nprotein-ligand contacts within a relational graph architecture. The models\ncombine a conditional variational autoencoder that allows for activity-specific\nmolecule generation with putative contact generation that provides predictions\nof molecular interactions within the target binding pocket. We show that\nmolecules generated with our 3D procedure are more compatible with the binding\npocket of the dopamine D2 receptor than those produced by a comparable\nligand-based 2D generative method, as measured by docking scores, expected\nstereochemistry, and recoverability in commercial chemical databases. Predicted\nprotein-ligand contacts were found among highest-ranked docking poses with a\nhigh recovery rate. This work shows how the structural context of a protein\ntarget can be used to enhance molecule generation.",
    "descriptor": "\nComments: 5 pages, 3 figures\n",
    "authors": [
      "Seung-gu Kang",
      "Jeffrey K. Weber",
      "Joseph A. Morrone",
      "Leili Zhang",
      "Tien Huynh",
      "Wendy D. Cornell"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Machine Learning (cs.LG)",
      "Biological Physics (physics.bio-ph)"
    ],
    "url": "https://arxiv.org/abs/2204.02513"
  },
  {
    "id": "arXiv:2204.02552",
    "title": "Quantum Approximate Counting for Markov Chains and Application to  Collision Counting",
    "abstract": "In this paper we show how to generalize the quantum approximate counting\ntechnique developed by Brassard, H{\\o}yer and Tapp [ICALP 1998] to a more\ngeneral setting: estimating the number of marked states of a Markov chain (a\nMarkov chain can be seen as a random walk over a graph with weighted edges).\nThis makes it possible to construct quantum approximate counting algorithms\nfrom quantum search algorithms based on the powerful \"quantum walk based\nsearch\" framework established by Magniez, Nayak, Roland and Santha [SIAM\nJournal on Computing 2011]. As an application, we apply this approach to the\nquantum element distinctness algorithm by Ambainis [SIAM Journal on Computing\n2007]: for two injective functions over a set of $N$ elements, we obtain a\nquantum algorithm that estimates the number $m$ of collisions of the two\nfunctions within relative error $\\epsilon$ by making\n$\\tilde{O}\\left(\\frac{1}{\\epsilon^{25/24}}\\big(\\frac{N}{\\sqrt{m}}\\big)^{2/3}\\right)$\nqueries, which gives an improvement over the\n$\\Theta\\big(\\frac{1}{\\epsilon}\\frac{N}{\\sqrt{m}}\\big)$-query classical\nalgorithm based on random sampling when $m\\ll N$.",
    "descriptor": "\nComments: 15 pages\n",
    "authors": [
      "Fran\u00e7ois Le Gall",
      "Iu-Iong Ng"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2204.02552"
  },
  {
    "id": "arXiv:2204.02583",
    "title": "PAGP: A physics-assisted Gaussian process framework with active learning  for forward and inverse problems of partial differential equations",
    "abstract": "In this work, a Gaussian process regression(GPR) model incorporated with\ngiven physical information in partial differential equations(PDEs) is\ndeveloped: physics-assisted Gaussian processes(PAGP). The targets of this model\ncan be divided into two types of problem: finding solutions or discovering\nunknown coefficients of given PDEs with initial and boundary conditions. We\nintroduce three different models: continuous time, discrete time and hybrid\nmodels. The given physical information is integrated into Gaussian process\nmodel through our designed GP loss functions. Three types of loss function are\nprovided in this paper based on two different approaches to train the standard\nGP model. The first part of the paper introduces the continuous time model\nwhich treats temporal domain the same as spatial domain. The unknown\ncoefficients in given PDEs can be jointly learned with GP hyper-parameters by\nminimizing the designed loss function. In the discrete time models, we first\nchoose a time discretization scheme to discretize the temporal domain. Then the\nPAGP model is applied at each time step together with the scheme to approximate\nPDE solutions at given test points of final time. To discover unknown\ncoefficients in this setting, observations at two specific time are needed and\na mixed mean square error function is constructed to obtain the optimal\ncoefficients. In the last part, a novel hybrid model combining the continuous\nand discrete time models is presented. It merges the flexibility of continuous\ntime model and the accuracy of the discrete time model. The performance of\nchoosing different models with different GP loss functions is also discussed.\nThe effectiveness of the proposed PAGP methods is illustrated in our numerical\nsection.",
    "descriptor": "",
    "authors": [
      "Jiahao Zhang",
      "Shiqi Zhang",
      "Guang Lin"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Analysis of PDEs (math.AP)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2204.02583"
  },
  {
    "id": "arXiv:2204.02593",
    "title": "Nonlinear gradient mappings and stochastic optimization: A general  framework with applications to heavy-tail noise",
    "abstract": "We introduce a general framework for nonlinear stochastic gradient descent\n(SGD) for the scenarios when gradient noise exhibits heavy tails. The proposed\nframework subsumes several popular nonlinearity choices, like clipped,\nnormalized, signed or quantized gradient, but we also consider novel\nnonlinearity choices. We establish for the considered class of methods strong\nconvergence guarantees assuming a strongly convex cost function with Lipschitz\ncontinuous gradients under very general assumptions on the gradient noise. Most\nnotably, we show that, for a nonlinearity with bounded outputs and for the\ngradient noise that may not have finite moments of order greater than one, the\nnonlinear SGD's mean squared error (MSE), or equivalently, the expected cost\nfunction's optimality gap, converges to zero at rate~$O(1/t^\\zeta)$, $\\zeta \\in\n(0,1)$. In contrast, for the same noise setting, the linear SGD generates a\nsequence with unbounded variances. Furthermore, for the nonlinearities that can\nbe decoupled component wise, like, e.g., sign gradient or component-wise\nclipping, we show that the nonlinear SGD asymptotically (locally) achieves a\n$O(1/t)$ rate in the weak convergence sense and explicitly quantify the\ncorresponding asymptotic variance. Experiments show that, while our framework\nis more general than existing studies of SGD under heavy-tail noise, several\neasy-to-implement nonlinearities from our framework are competitive with state\nof the art alternatives on real data sets with heavy tail noises.",
    "descriptor": "\nComments: Submitted for publication Nov 2021\n",
    "authors": [
      "Dusan Jakovetic",
      "Dragana Bajovic",
      "Anit Kumar Sahu",
      "Soummya Kar",
      "Nemanja Milosevic",
      "Dusan Stamenkovic"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.02593"
  },
  {
    "id": "arXiv:2204.02606",
    "title": "Consensual Aggregation on Random Projected High-dimensional Features for  Regression",
    "abstract": "In this paper, we present a study of a kernel-based consensual aggregation on\nrandomly projected high-dimensional features of predictions for regression. The\naggregation scheme is composed of two steps: the high-dimensional features of\npredictions, given by a large number of regression estimators, are randomly\nprojected into a smaller subspace using Johnson-Lindenstrauss Lemma in the\nfirst step, and a kernel-based consensual aggregation is implemented on the\nprojected features in the second step. We theoretically show that the\nperformance of the aggregation scheme is close to the performance of the\naggregation implemented on the original high-dimensional features, with high\nprobability. Moreover, we numerically illustrate that the aggregation scheme\nupholds its performance on very large and highly correlated features of\npredictions given by different types of machines. The aggregation scheme allows\nus to flexibly merge a large number of redundant machines, plainly constructed\nwithout model selection or cross-validation. The efficiency of the proposed\nmethod is illustrated through several experiments evaluated on different types\nof synthetic and real datasets.",
    "descriptor": "",
    "authors": [
      "Sothea Has"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.02606"
  },
  {
    "id": "arXiv:2204.02616",
    "title": "Mockingbird lattices",
    "abstract": "We study combinatorial and order theoretic structures arising from the\nfragment of combinatory logic spanned by the basic combinator ${\\bf M}$. This\nbasic combinator, named as the Mockingbird by Smullyan, is defined by the\nrewrite rule ${\\bf M} x_1 \\to x_1 x_1$. We prove that the reflexive and\ntransitive closure of this rewrite relation is a partial order on terms on\n${\\bf M}$ and that all connected components of its rewrite graph are Hasse\ndiagrams of lattices. This last result is based on the introduction of lattices\non some forests. We enumerate the elements, the edges of the Hasse diagrams,\nand the intervals of these lattices with the help of formal power series on\nterms and on forests.",
    "descriptor": "\nComments: 12 pages\n",
    "authors": [
      "Samuele Giraudo"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2204.02616"
  },
  {
    "id": "arXiv:2204.02623",
    "title": "Attention-based CNN-LSTM and XGBoost hybrid model for stock prediction",
    "abstract": "Stock market plays an important role in the economic development. Due to the\ncomplex volatility of the stock market, the research and prediction on the\nchange of the stock price, can avoid the risk for the investors. The\ntraditional time series model ARIMA can not describe the nonlinearity, and can\nnot achieve satisfactory results in the stock prediction. As neural networks\nare with strong nonlinear generalization ability, this paper proposes an\nattention-based CNN-LSTM and XGBoost hybrid model to predict the stock price.\nThe model constructed in this paper integrates the time series model, the\nConvolutional Neural Networks with Attention mechanism, the Long Short-Term\nMemory network, and XGBoost regressor in a non-linear relationship, and\nimproves the prediction accuracy. The model can fully mine the historical\ninformation of the stock market in multiple periods. The stock data is first\npreprocessed through ARIMA. Then, the deep learning architecture formed in\npretraining-finetuning framework is adopted. The pre-training model is the\nAttention-based CNN-LSTM model based on sequence-to-sequence framework. The\nmodel first uses convolution to extract the deep features of the original stock\ndata, and then uses the Long Short-Term Memory networks to mine the long-term\ntime series features. Finally, the XGBoost model is adopted for fine-tuning.\nThe results show that the hybrid model is more effective and the prediction\naccuracy is relatively high, which can help investors or institutions to make\ndecisions and achieve the purpose of expanding return and avoiding risk. Source\ncode is available at\nhttps://github.com/zshicode/Attention-CLX-stock-prediction.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2202.13800\n",
    "authors": [
      "Zhuangwei Shi",
      "Yang Hu",
      "Guangliang Mo",
      "Jian Wu"
    ],
    "subjectives": [
      "Statistical Finance (q-fin.ST)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.02623"
  },
  {
    "id": "arXiv:2204.02631",
    "title": "Super-resolved multi-temporal segmentation with deep  permutation-invariant networks",
    "abstract": "Multi-image super-resolution from multi-temporal satellite acquisitions of a\nscene has recently enjoyed great success thanks to new deep learning models. In\nthis paper, we go beyond classic image reconstruction at a higher resolution by\nstudying a super-resolved inference problem, namely semantic segmentation at a\nspatial resolution higher than the one of sensing platform. We expand upon\nrecently proposed models exploiting temporal permutation invariance with a\nmulti-resolution fusion module able to infer the rich semantic information\nneeded by the segmentation task. The model presented in this paper has recently\nwon the AI4EO challenge on Enhanced Sentinel 2 Agriculture.",
    "descriptor": "\nComments: IGARSS 2022\n",
    "authors": [
      "Diego Valsesia",
      "Enrico Magli"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.02631"
  },
  {
    "id": "arXiv:2204.02637",
    "title": "Global HRTF Interpolation via Learned Affine Transformation of  Hyper-conditioned Features",
    "abstract": "Estimating Head-Related Transfer Functions (HRTFs) of arbitrary source points\nis essential in immersive binaural audio rendering. Computing each individual's\nHRTFs is challenging, as traditional approaches require expensive time and\ncomputational resources, while modern data-driven approaches are data-hungry.\nEspecially for the data-driven approaches, existing HRTF datasets differ in\nspatial sampling distributions of source positions, posing a major problem when\ngeneralizing the method across multiple datasets. To alleviate this, we propose\na deep learning method based on a novel conditioning architecture. The proposed\nmethod can predict an HRTF of any position by interpolating the HRTFs of known\ndistributions. Experimental results show that the proposed architecture\nimproves the model's generalizability across datasets with various coordinate\nsystems. Additional demonstrations using coarsened HRTFs demonstrate that the\nmodel robustly reconstructs the target HRTFs from the coarsened data.",
    "descriptor": "\nComments: Submitted to Interspeech 2022\n",
    "authors": [
      "Jin Woo Lee",
      "Sungho Lee",
      "Kyogu Lee"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2204.02637"
  },
  {
    "id": "arXiv:2204.02642",
    "title": "Unconstrained Proximal Operator: the Optimal Parameter for the  Douglas-Rachford Type Primal-Dual Methods",
    "abstract": "In this work, we propose an alternative parametrized form of the proximal\noperator, of which the parameter no longer needs to be positive. That is, the\nparameter can be a non-zero scalar, a full-rank square matrix, or, more\ngenerally, a bijective bounded linear operator. We demonstrate that the\npositivity requirement is essentially due to a quadratic form. We prove several\nkey characterizations for the new form in a generic way (with an operator\nparameter). We establish the optimal choice of parameter for the\nDouglas-Rachford type methods by solving a simple unconstrained optimization\nproblem. The optimality is in the sense that a non-ergodic worst-case\nconvergence rate bound is minimized. We provide closed-form optimal choices for\nscalar and orthogonal matrix parameters under zero initialization.\nAdditionally, a simple self-contained proof of a sharp linear convergence rate\nfor a $ (1/L) $-cocoercive fixed-point sequence with $ L\\in(0,1) $ is provided\n(as a preliminary result).\nTo our knowledge, an operator parameter is new. To show its practical use, we\ndesign a dedicated parameter for the 2-by-2 block-structured semidefinite\nprogram (SDP). Such a structured SDP is strongly related to the quadratically\nconstrained quadratic program (QCQP), and we therefore expect the proposed\nparameter to be of great potential use. At last, two well-known applications\nare investigated. Numerical results show that the theoretical optimal\nparameters are close to the practical optimums, except they are not a priori\nknowledge. We then demonstrate that, by exploiting problem model structures,\nthe theoretical optimums can be well approximated. Such approximations turn out\nto work very well, and in some cases almost reach the underlying limits.",
    "descriptor": "",
    "authors": [
      "Yifan Ran",
      "Wei Dai"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2204.02642"
  },
  {
    "id": "arXiv:2204.02663",
    "title": "Towards An End-to-End Framework for Flow-Guided Video Inpainting",
    "abstract": "Optical flow, which captures motion information across frames, is exploited\nin recent video inpainting methods through propagating pixels along its\ntrajectories. However, the hand-crafted flow-based processes in these methods\nare applied separately to form the whole inpainting pipeline. Thus, these\nmethods are less efficient and rely heavily on the intermediate results from\nearlier stages. In this paper, we propose an End-to-End framework for\nFlow-Guided Video Inpainting (E$^2$FGVI) through elaborately designed three\ntrainable modules, namely, flow completion, feature propagation, and content\nhallucination modules. The three modules correspond with the three stages of\nprevious flow-based methods but can be jointly optimized, leading to a more\nefficient and effective inpainting process. Experimental results demonstrate\nthat the proposed method outperforms state-of-the-art methods both\nqualitatively and quantitatively and shows promising efficiency. The code is\navailable at https://github.com/MCG-NKU/E2FGVI.",
    "descriptor": "\nComments: Accepted to CVPR 2022\n",
    "authors": [
      "Zhen Li",
      "Cheng-Ze Lu",
      "Jianhua Qin",
      "Chun-Le Guo",
      "Ming-Ming Cheng"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.02663"
  },
  {
    "id": "arXiv:2204.02671",
    "title": "Behavioral uncertainty quantification for data-driven control",
    "abstract": "This paper explores the problem of uncertainty quantification in the\nbehavioral setting for data-driven control. Building on classical ideas from\nrobust control, the problem is regarded as that of selecting a metric which is\nbest suited to a data-based description of uncertainties. Leveraging on\nWillems' fundamental lemma, restricted behaviors are viewed as subspaces of\nfixed dimension, which may be represented by data matrices. Consequently,\nmetrics between restricted behaviors are defined as distances between points on\nthe Grassmannian, i.e., the set of all subspaces of equal dimension in a given\nvector space. A new metric is defined on the set of restricted behaviors as a\ndirect finite-time counterpart of the classical gap metric. The metric is shown\nto capture parametric uncertainty for the class of autoregressive (AR) models.\nNumerical simulations illustrate the value of the new metric with a data-driven\nmode recognition and control case study.",
    "descriptor": "\nComments: Submitted to the 61st IEEE Conference on Decision and Control\n",
    "authors": [
      "Alberto Padoan",
      "Jeremy Coulson",
      "Henk J. van Waarde",
      "John Lygeros",
      "Florian D\u00f6rfler"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2204.02671"
  },
  {
    "id": "arXiv:2204.02678",
    "title": "Double Descent in Random Feature Models: Precise Asymptotic Analysis for  General Convex Regularization",
    "abstract": "We prove rigorous results on the double descent phenomenon in random features\n(RF) model by employing the powerful Convex Gaussian Min-Max Theorem (CGMT) in\na novel multi-level manner. Using this technique, we provide precise asymptotic\nexpressions for the generalization of RF regression under a broad class of\nconvex regularization terms including arbitrary separable functions. We further\ncompute our results for the combination of $\\ell_1$ and $\\ell_2$ regularization\ncase, known as elastic net, and present numerical studies about it. We\nnumerically demonstrate the predictive capacity of our framework, and show\nexperimentally that the predicted test error is accurate even in the\nnon-asymptotic regime.",
    "descriptor": "\nComments: 22 pages, 6 figures\n",
    "authors": [
      "David Bosch",
      "Ashkan Panahi",
      "Ayca \u00d6zcelikkale",
      "Devdatt Dubhash"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.02678"
  },
  {
    "id": "arXiv:2204.02690",
    "title": "A Hessian inversion-free exact second order method for distributed  consensus optimization",
    "abstract": "We consider a standard distributed consensus optimization problem where a set\nof agents connected over an undirected network minimize the sum of their\nindividual local strongly convex costs. Alternating Direction Method of\nMultipliers ADMM and Proximal Method of Multipliers PMM have been proved to be\neffective frameworks for design of exact distributed second order methods\ninvolving calculation of local cost Hessians. However, existing methods involve\nexplicit calculation of local Hessian inverses at each iteration that may be\nvery costly when the dimension of the optimization variable is large. In this\npaper we develop a novel method termed INDO Inexact Newton method for\nDistributed Optimization that alleviates the need for Hessian inverse\ncalculation. INDO follows the PMM framework but unlike existing work\napproximates the Newton direction through a generic fixed point method, e.g.,\nJacobi Overrelaxation, that does not involve Hessian inverses. We prove exact\nglobal linear convergence of INDO and provide analytical studies on how the\ndegree of inexactness in the Newton direction calculation affects the overall\nmethods convergence factor. Numerical experiments on several real data sets\ndemonstrate that INDOs speed is on par or better as state of the art methods\niterationwise hence having a comparable communication cost. At the same time,\nfor sufficiently large optimization problem dimensions n (even at n on the\norder of couple of hundreds), INDO achieves savings in computational cost by at\nleast an order of magnitude.",
    "descriptor": "\nComments: Submitted for publication Feb 10, 2022\n",
    "authors": [
      "Dusan Jakovetic",
      "Natasa Krejic",
      "Natasa Krklec Jerinkic"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2204.02690"
  },
  {
    "id": "arXiv:2204.02694",
    "title": "Customizable End-to-end Optimization of Online Neural Network-supported  Dereverberation for Hearing Devices",
    "abstract": "This work focuses on online dereverberation for hearing devices using the\nweighted prediction error (WPE) algorithm. WPE filtering requires an estimate\nof the target speech power spectral density (PSD). Recently deep neural\nnetworks (DNNs) have been used for this task. However, these approaches\noptimize the PSD estimate which only indirectly affects the WPE output, thus\npotentially resulting in limited dereverberation. In this paper, we propose an\nend-to-end approach specialized for online processing, that directly optimizes\nthe dereverberated output signal. In addition, we propose to adapt it to the\nneeds of different types of hearing-device users by modifying the optimization\ntarget as well as the WPE algorithm characteristics used in training. We show\nthat the proposed end-to-end approach outperforms the traditional and\nconventional DNN-supported WPEs on a noise-free version of the WHAMR! dataset.",
    "descriptor": "\nComments: \\copyright 2022 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works\n",
    "authors": [
      "Jean-Marie Lemercier",
      "Joachim Thiemann",
      "Raphael Koning",
      "Timo Gerkmann"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2204.02694"
  },
  {
    "id": "arXiv:2204.02716",
    "title": "A Novel Cloud-Based Framework for Standardised Simulations in the Latin  American Giant Observatory (LAGO)",
    "abstract": "LAGO, the Latin American Giant Observatory, is an extended cosmic ray\nobservatory, consisting of a wide network of water Cherenkov detectors located\nin 10 countries. With different altitudes and geomagnetic rigidity cutoffs,\ntheir geographic distribution, combined with the new electronics for control,\natmospheric sensing and data acquisition, allows the realisation of diverse\nastrophysics studies at a regional scale. It is an observatory designed, built\nand operated by the LAGO Collaboration, a non-centralised alliance of 30\ninstitutions from 11 countries.\nWhile LAGO has access to different computational frameworks, it lacks\nstandardised computational mechanisms to fully grasp its cooperative approach.\nThe European Commission is fostering initiatives aligned to LAGO objectives,\nespecially to enable Open Science and its long-term sustainability. This work\nintroduces the adaptation of LAGO to this paradigm within the EOSC-Synergy\nproject, focusing on the simulations of the expected astrophysical signatures\nat detectors deployed at the LAGO sites around the World.",
    "descriptor": "\nComments: 10 pages, 3 figures, Invited Talk at the Winter Simulation Conference WSC2021, Phoenix, AZ, USA\n",
    "authors": [
      "Antonio Juan Rubio-Montero",
      "Ra\u00fal Pag\u00e1n-Mu\u00f1oz",
      "Rafael Mayo-Garc\u00eda",
      "Alfonso Pardo-Diaz",
      "Iv\u00e1n Sidelnik",
      "Hern\u00e1n Asorey"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2204.02716"
  },
  {
    "id": "arXiv:2204.02741",
    "title": "Neural Network-augmented Kalman Filtering for Robust Online Speech  Dereverberation in Noisy Reverberant Environments",
    "abstract": "In this paper, a neural network-augmented algorithm for noise-robust online\ndereverberation with a Kalman filtering variant of the weighted prediction\nerror (WPE) method is proposed. The filter stochastic variations are predicted\nby a deep neural network (DNN) trained end-to-end using the filter residual\nerror and signal characteristics. The presented framework allows for robust\ndereverberation on a single-channel noisy reverberant dataset similar to\nWHAMR!. The Kalman filtering WPE introduces distortions in the enhanced signal\nwhen predicting the filter variations from the residual error only, if the\ntarget speech power spectral density is not perfectly known and the observation\nis noisy. The proposed approach avoids these distortions by correcting the\nfilter variations estimation in a data-driven way, increasing the robustness of\nthe method to noisy scenarios. Furthermore, it yields a strong dereverberation\nand denoising performance compared to a DNN-supported recursive least squares\nvariant of WPE, especially for highly noisy inputs.",
    "descriptor": "\nComments: submitted to INTERSPEECH\n",
    "authors": [
      "Jean-Marie Lemercier",
      "Joachim Thiemann",
      "Raphael Koning",
      "Timo Gerkmann"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2204.02741"
  },
  {
    "id": "arXiv:2204.02760",
    "title": "BFRnet: A deep learning-based MR background field removal method for QSM  of the brain containing significant pathological susceptibility sources",
    "abstract": "Introduction: Background field removal (BFR) is a critical step required for\nsuccessful quantitative susceptibility mapping (QSM). However, eliminating the\nbackground field in brains containing significant susceptibility sources, such\nas intracranial hemorrhages, is challenging due to the relatively large scale\nof the field induced by these pathological susceptibility sources. Method: This\nstudy proposes a new deep learning-based method, BFRnet, to remove background\nfield in healthy and hemorrhagic subjects. The network is built with the\ndual-frequency octave convolutions on the U-net architecture, trained with\nsynthetic field maps containing significant susceptibility sources. The BFRnet\nmethod is compared with three conventional BFR methods and one previous deep\nlearning method using simulated and in vivo brains from 4 healthy and 2\nhemorrhagic subjects. Robustness against acquisition field-of-view (FOV)\norientation and brain masking are also investigated. Results: For both\nsimulation and in vivo experiments, BFRnet led to the best visually appealing\nresults in the local field and QSM results with the minimum contrast loss and\nthe most accurate hemorrhage susceptibility measurements among all five\nmethods. In addition, BFRnet produced the most consistent local field and\nsusceptibility maps between different sizes of brain masks, while conventional\nmethods depend drastically on precise brain extraction and further brain edge\nerosions. It is also observed that BFRnet performed the best among all BFR\nmethods for acquisition FOVs oblique to the main magnetic field. Conclusion:\nThe proposed BFRnet improved the accuracy of local field reconstruction in the\nhemorrhagic subjects compared with conventional BFR algorithms. The BFRnet\nmethod was effective for acquisitions of titled orientations and retained whole\nbrains without edge erosion as often required by traditional BFR methods.",
    "descriptor": "\nComments: 23 pages, 8 figures, 2 tables\n",
    "authors": [
      "Xuanyu Zhu",
      "Yang Gao",
      "Feng Liu",
      "Stuart Crozier",
      "Hongfu Sun"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2204.02760"
  },
  {
    "id": "arXiv:2204.02768",
    "title": "Quantum Computers, Predictability, and Free Will",
    "abstract": "This article focuses on the connection between the possibility of quantum\ncomputers, the predictability of complex quantum systems in nature, and the\nissue of free will.",
    "descriptor": "\nComments: 32 pages, 7 figures\n",
    "authors": [
      "Gil Kalai"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "General Literature (cs.GL)",
      "History and Philosophy of Physics (physics.hist-ph)"
    ],
    "url": "https://arxiv.org/abs/2204.02768"
  },
  {
    "id": "arXiv:2204.02779",
    "title": "A Dempster-Shafer approach to trustworthy AI with application to fetal  brain MRI segmentation",
    "abstract": "Deep learning models for medical image segmentation can fail unexpectedly and\nspectacularly for pathological cases and for images acquired at different\ncenters than those used for training, with labeling errors that violate expert\nknowledge about the anatomy and the intensity distribution of the regions to be\nsegmented. Such errors undermine the trustworthiness of deep learning models\ndeveloped for medical image segmentation. Mechanisms with a fallback method for\ndetecting and correcting such failures are essential for safely translating\nthis technology into clinics and are likely to be a requirement of future\nregulations on artificial intelligence (AI). Here, we propose a principled\ntrustworthy AI theoretical framework and a practical system that can augment\nany backbone AI system using a fallback method and a fail-safe mechanism based\non Dempster-Shafer theory. Our approach relies on an actionable definition of\ntrustworthy AI. Our method automatically discards the voxel-level labeling\npredicted by the backbone AI that are likely to violate expert knowledge and\nrelies on a fallback atlas-based segmentation method for those voxels. We\ndemonstrate the effectiveness of the proposed trustworthy AI approach on the\nlargest reported annotated dataset of fetal T2w MRI consisting of 540 manually\nannotated fetal brain 3D MRIs with neurotypical or abnormal brain development\nand acquired from 13 sources of data across 6 countries. We show that our\ntrustworthy AI method improves the robustness of a state-of-the-art backbone AI\nfor fetal brain MRI segmentation on MRIs acquired across various centers and\nfor fetuses with various brain abnormalities.",
    "descriptor": "\nComments: preprint\n",
    "authors": [
      "Lucas Fidon",
      "Michael Aertsen",
      "Florian Kofler",
      "Andrea Bink",
      "Anna L. David",
      "Thomas Deprest",
      "Doaa Emam",
      "Fr/'ed/'eric Guffens",
      "Andr\u00e1s Jakab",
      "Gregor Kasprian",
      "Patric Kienast",
      "Andrew Melbourne",
      "Bjoern Menze",
      "Nada Mufti",
      "Ivana Pogledic",
      "Daniela Prayer",
      "Marlene Stuempflen",
      "Esther Van Elslander",
      "S\u00e9bastien Ourselin",
      "Jan Deprest",
      "Tom Vercauteren"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.02779"
  },
  {
    "id": "arXiv:2204.02784",
    "title": "Quantum Machine Learning for Software Supply Chain Attacks: How Far Can  We Go?",
    "abstract": "Quantum Computing (QC) has gained immense popularity as a potential solution\nto deal with the ever-increasing size of data and associated challenges\nleveraging the concept of quantum random access memory (QRAM). QC promises\nquadratic or exponential increases in computational time with quantum\nparallelism and thus offer a huge leap forward in the computation of Machine\nLearning algorithms. This paper analyzes speed up performance of QC when\napplied to machine learning algorithms, known as Quantum Machine Learning\n(QML). We applied QML methods such as Quantum Support Vector Machine (QSVM),\nand Quantum Neural Network (QNN) to detect Software Supply Chain (SSC) attacks.\nDue to the access limitations of real quantum computers, the QML methods were\nimplemented on open-source quantum simulators such as IBM Qiskit and TensorFlow\nQuantum. We evaluated the performance of QML in terms of processing speed and\naccuracy and finally, compared with its classical counterparts. Interestingly,\nthe experimental results differ to the speed up promises of QC by demonstrating\nhigher computational time and lower accuracy in comparison to the classical\napproaches for SSC attacks.",
    "descriptor": "\nComments: 2022 IEEE Computers, Software, and Applications Conference\n",
    "authors": [
      "Mohammad Masum",
      "Mohammad Nazim",
      "Md Jobair Hossain Faruk",
      "Hossain Shahriar",
      "Maria Valero",
      "Md Abdullah Hafiz Khan",
      "Gias Uddin",
      "Shabir Barzanjeh",
      "Erhan Saglamyurek",
      "Akond Rahman",
      "Sheikh Iqbal Ahamed"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2204.02784"
  },
  {
    "id": "arXiv:2204.02793",
    "title": "The Challenge of Sixfold Integrals: The Closed-Form Evaluation of Newton  Potentials between Two Cubes",
    "abstract": "The challenge of explicitly evaluating, in elementary closed form, the weakly\nsingular sixfold integrals for potentials and forces between two cubes has been\ntaken up at various places in the mathematics and physics literature. It\ncreated some strikingly specific results, with an aura of arbitrariness, and a\nsingle intricate general procedure due to Hackbusch. Those scattered instances\nwere mostly addressing the problem heads on, by successive integration while\nkeeping track of a thicket of primitives generated at intermediate stages.\nIn this paper we present a substantially easier and shorter approach, based\non a Laplace transform of the kernel. We clearly exhibit the structure of the\nresults as obtained by an explicit algorithm, just computing with rational\npolynomials. The method extends, up to the evaluation of single integrals, to\nhigher dimensions. Among other examples, we easily reproduce Fornberg's\nstartling closed form solution of Trefethen's two-cubes problem and Waldvogel's\nsymmetric formula for the Newton potential of a rectangular cuboid.",
    "descriptor": "\nComments: 23 pages; sources include Mathematica code\n",
    "authors": [
      "Folkmar Bornemann"
    ],
    "subjectives": [
      "Classical Analysis and ODEs (math.CA)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2204.02793"
  },
  {
    "id": "arXiv:2204.02797",
    "title": "Classification of NEQR Processed Classical Images using Quantum Neural  Networks (QNN)",
    "abstract": "A quantum neural network (QNN) is interpreted today as any quantum circuit\nwith trainable continuous parameters. This work builds on previous works by the\nauthors and addresses QNN for image classification with Novel Enhanced Quantum\nRepresentation of (NEQR) processed classical data where Principal component\nanalysis (PCA) and Projected Quantum Kernel features (PQK) were investigated\npreviously by the authors as a path to quantum advantage for the same classical\ndataset. For each of these cases the Fashion-MNIST dataset was downscaled using\nPCA to convert into quantum data where the classical NN easily outperformed the\nQNN. However, we demonstrated quantum advantage by using PQK where quantum\nmodels achieved more than ~90% accuracy surpassing their classical counterpart\non the same training dataset as in the first case. In this current work, we use\nthe same dataset fed into a QNN and compare that with performance of a\nclassical NN model. We built an NEQR model circuit to pre-process the same data\nand feed the images into the QNN. Our results showed marginal improvements\n(only about ~5.0%) where the QNN performance with NEQR exceeded the performance\nof QNN without NEQR. We conclude that given the computational cost and the\nmassive circuit depth associated with running NEQR, the advantage offered by\nthis specific Quantum Image Processing (QIMP) algorithm is questionable at\nleast for classical image dataset. No actual quantum computing hardware\nplatform exists today that can support the circuit depth needed to run NEQR\neven for the reduced image sizes of our toy classical dataset.",
    "descriptor": "",
    "authors": [
      "Santanu Ganguly"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.02797"
  },
  {
    "id": "arXiv:2204.02833",
    "title": "High Probability Bounds for a Class of Nonconvex Algorithms with AdaGrad  Stepsize",
    "abstract": "In this paper, we propose a new, simplified high probability analysis of\nAdaGrad for smooth, non-convex problems. More specifically, we focus on a\nparticular accelerated gradient (AGD) template (Lan, 2020), through which we\nrecover the original AdaGrad and its variant with averaging, and prove a\nconvergence rate of $\\mathcal O (1/ \\sqrt{T})$ with high probability without\nthe knowledge of smoothness and variance. We use a particular version of\nFreedman's concentration bound for martingale difference sequences (Kakade &\nTewari, 2008) which enables us to achieve the best-known dependence of $\\log (1\n/ \\delta )$ on the probability margin $\\delta$. We present our analysis in a\nmodular way and obtain a complementary $\\mathcal O (1 / T)$ convergence rate in\nthe deterministic setting. To the best of our knowledge, this is the first high\nprobability result for AdaGrad with a truly adaptive scheme, i.e., completely\noblivious to the knowledge of smoothness and uniform variance bound, which\nsimultaneously has best-known dependence of $\\log( 1/ \\delta)$. We further\nprove noise adaptation property of AdaGrad under additional noise assumptions.",
    "descriptor": "\nComments: 27 pages, acccepted to ICLR 2022\n",
    "authors": [
      "Ali Kavis",
      "Kfir Yehuda Levy",
      "Volkan Cevher"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.02833"
  },
  {
    "id": "arXiv:2204.02836",
    "title": "A note on the van der Waerden conjecture on random polynomials with  symmetric Galois group for function fields",
    "abstract": "Let f(x) = x^n + (a[n-1] t + b[n-1]) x^(n-1) + ... + (a[0] t + b[0]) be of\nconstant degree n in x and degree <= 1 in t, where all a[i],b[i] are randomly\nand uniformly selected from a finite field GF(q) of q elements. Then the\nprobability that the Galois group of f over the rational function field\nGF(q)(t) is the symmetric group S(n) on n elements is 1 - O(1/q). Furthermore,\nthe probability that the Galois group of f(x) over GF(q)(t) is not S(n) is >=\n1/q.",
    "descriptor": "",
    "authors": [
      "Erich L. Kaltofen"
    ],
    "subjectives": [
      "Number Theory (math.NT)",
      "Symbolic Computation (cs.SC)"
    ],
    "url": "https://arxiv.org/abs/2204.02836"
  },
  {
    "id": "arXiv:2204.02839",
    "title": "CCAT-NET: A Novel Transformer Based Semi-supervised Framework for  Covid-19 Lung Lesion Segmentation",
    "abstract": "The spread of the novel coronavirus disease 2019 (COVID-19) has claimed\nmillions of lives. Automatic segmentation of lesions from CT images can assist\ndoctors with screening, treatment, and monitoring. However, accurate\nsegmentation of lesions from CT images can be very challenging due to data and\nmodel limitations. Recently, Transformer-based networks have attracted a lot of\nattention in the area of computer vision, as Transformer outperforms CNN at a\nbunch of tasks. In this work, we propose a novel network structure that\ncombines CNN and Transformer for the segmentation of COVID-19 lesions. We\nfurther propose an efficient semi-supervised learning framework to address the\nshortage of labeled data. Extensive experiments showed that our proposed\nnetwork outperforms most existing networks and the semi-supervised learning\nframework can outperform the base network by 3.0% and 8.2% in terms of Dice\ncoefficient and sensitivity.",
    "descriptor": "",
    "authors": [
      "Mingyang Liu",
      "Li Xiao",
      "Huiqin Jiang",
      "Qing He"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.02839"
  },
  {
    "id": "arXiv:2204.02841",
    "title": "Spectral Denoising for Microphone Classification",
    "abstract": "In this paper, we propose the application of denoising to microphone\nclassification, to enable its usage on content with unfavorable noisy\nconditions. We first describe the proposed integrated approach; afterwards we\ndiscuss the baseline algorithm for microphone classification, and the various\ndenoising procedures which can be combined with it in the time or spectral\ndomain; lastly, we determine the best performing denoising procedure, and\nevaluate the performance of the integrated approach with several SNR levels of\nadditive input noise. In comparison to the reference baseline, the proposed\nmethod achieves an average accuracy increase of about 25% on denoised content.",
    "descriptor": "",
    "authors": [
      "L. Cuccovillo",
      "A. Giganti",
      "P. Bestagini",
      "P. Aichroth",
      "S. Tubaro"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2204.02841"
  },
  {
    "id": "arXiv:2204.02842",
    "title": "Open-Source Tools for Behavioral Video Analysis: Setup, Methods, and  Development",
    "abstract": "Recently developed methods for video analysis, especially models for pose\nestimation and behavior classification, are transforming behavioral\nquantification to be more precise, scalable, and reproducible in fields such as\nneuroscience and ethology. These tools overcome long-standing limitations of\nmanual scoring of video frames and traditional \"center of mass\" tracking\nalgorithms to enable video analysis at scale. The expansion of open-source\ntools for video acquisition and analysis has led to new experimental approaches\nto understand behavior. Here, we review currently available open source tools\nfor video analysis, how to set them up in a lab that is new to video recording\nmethods, and some issues that should be addressed by developers and advanced\nusers, including the need to openly share datasets and code, how to compare\nalgorithms and their parameters, and the need for documentation and\ncommunity-wide standards. We hope to encourage more widespread use and\ncontinued development of the tools. They have tremendous potential for\naccelerating scientific progress for understanding the brain and behavior.",
    "descriptor": "\nComments: 20 pages, 2 figures, 2 tables; this is a commentary on video methods for analyzing behavior in animals that emerged from a working group organized by the OpenBehavior project (openbehavior.com)\n",
    "authors": [
      "Kevin Luxem",
      "Jennifer J. Sun",
      "Sean P. Bradley",
      "Keerthi Krishnan",
      "Talmo D. Pereira",
      "Eric A. Yttri",
      "Jan Zimmermann",
      "Mark Laubach"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2204.02842"
  },
  {
    "id": "arXiv:2204.02846",
    "title": "Evidence for positive long- and short-term effects of vaccinations  against COVID-19 in wearable sensor metrics -- Insights from the German  Corona Data Donation Project",
    "abstract": "Vaccines are among the most powerful tools used to combat the COVID-19\npandemic. They are highly effective against infection and substantially reduce\nthe risk of severe disease, hospitalization, ICU admission, and death. However,\ntheir potential for attenuating long-term effects of a SARS-CoV-2 infection,\ncommonly denoted as Long COVID, remains elusive and is still subject of debate.\nSuch long-term effects can be effectively monitored at the individual level by\nanalyzing physiological data collected by consumer-grade wearable sensors.\nHere, we investigate changes in resting heart rate, daily physical activity,\nand sleep duration in response to a SARS-CoV-2 infection stratified by\nvaccination status. Data was collected over a period of two years in the\ncontext of the German Corona Data Donation Project with currently around\n190,000 monthly active donors. Compared to their unvaccinated counterparts, we\nfind that vaccinated individuals on average experience smaller changes in their\nvital data that also return to normal levels more quickly. Likewise, extreme\nchanges in vitals during the acute phase of the disease occur less frequently\nin vaccinated individuals. Our results solidify evidence that vaccines can\nmitigate long-term detrimental effects of SARS-CoV-2 infections both in terms\nof duration and magnitude. Furthermore, they demonstrate the value of large\nscale, high-resolution wearable sensor data in public health research.",
    "descriptor": "",
    "authors": [
      "Marc Wiedermann",
      "Annika H. Rose",
      "Benjamin F. Maier",
      "Jakob J. Kolb",
      "David Hinrichs",
      "Dirk Brockmann"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2204.02846"
  },
  {
    "id": "arXiv:2204.02901",
    "title": "Visualizing Multidimensional Linear Programming Problems",
    "abstract": "The article proposes an n-dimensional mathematical model of the visual\nrepresentation of a linear programming problem. This model makes it possible to\nuse artificial neural networks to solve multidimensional linear optimization\nproblems, the feasible region of which is a bounded non-empty set. To visualize\nthe linear programming problem, an objective hyperplane is introduced, the\norientation of which is determined by the gradient of the linear objective\nfunction: the gradient is the normal to the objective hyperplane. In the case\nof searching a maximum, the objective hyperplane is positioned in such a way\nthat the value of the objective function at all its points exceeds the value of\nthe objective function at all points of the feasible region, which is a bounded\nconvex polytope. For an arbitrary point of the objective hyperplane, the\nobjective projection onto the polytope is determined: the closer the objective\nprojection point is to the objective hyperplane, the greater the value of the\nobjective function at this point. Based on the objective hyperplane, a finite\nregular set of points is constructed, called the receptive field. Using\nobjective projections, an image of a polytope is constructed. This image\nincludes the distances from the receptive points to the corresponding points of\nthe polytope surface. Based on the proposed model, parallel algorithms for\nvisualizing a linear programming problem are constructed. An analytical\nestimation of its scalability is performed. Information about the software\nimplementation and the results of large-scale computational experiments\nconfirming the efficiency of the proposed approaches are presented.",
    "descriptor": "",
    "authors": [
      "Nikolay A. Olkhovsky",
      "Leonid B. Sokolinsky"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2204.02901"
  },
  {
    "id": "arXiv:1701.07447",
    "title": "An Explicit, Coupled-Layer Construction of a High-Rate Regenerating Code  with Low Sub-Packetization Level, Small Field Size and $d< (n-1)$",
    "abstract": "Comments: In the revised version, a correction is made in the rate calculation. The rate reduces and the code fails to be an MSR code. arXiv admin note: text overlap with arXiv:1607.07335",
    "descriptor": "\nComments: In the revised version, a correction is made in the rate calculation. The rate reduces and the code fails to be an MSR code. arXiv admin note: text overlap with arXiv:1607.07335\n",
    "authors": [
      "Birenjith Sasidharan",
      "Myna Vajha",
      "P. Vijay Kumar"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/1701.07447"
  },
  {
    "id": "arXiv:1704.01069",
    "title": "ME R-CNN: Multi-Expert R-CNN for Object Detection",
    "abstract": "Comments: IEEE Transactions on Image Processing",
    "descriptor": "\nComments: IEEE Transactions on Image Processing\n",
    "authors": [
      "Hyungtae Lee",
      "Sungmin Eum",
      "Heesung Kwon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/1704.01069"
  },
  {
    "id": "arXiv:1806.07709",
    "title": "Notes on Abstract Argumentation Theory",
    "abstract": "Comments: 100 pages, 39 figures, 6 tables",
    "descriptor": "\nComments: 100 pages, 39 figures, 6 tables\n",
    "authors": [
      "Anthony Peter Young"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/1806.07709"
  },
  {
    "id": "arXiv:1902.03871",
    "title": "Learning V1 Simple Cells with Vector Representation of Local Content and  Matrix Representation of Local Motion",
    "abstract": "Learning V1 Simple Cells with Vector Representation of Local Content and  Matrix Representation of Local Motion",
    "descriptor": "",
    "authors": [
      "Ruiqi Gao",
      "Jianwen Xie",
      "Siyuan Huang",
      "Yufan Ren",
      "Song-Chun Zhu",
      "Ying Nian Wu"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1902.03871"
  },
  {
    "id": "arXiv:1909.12326",
    "title": "Model Pruning Enables Efficient Federated Learning on Edge Devices",
    "abstract": "Comments: Accepted for publication in IEEE Transactions on Neural Networks and Learning Systems (TNNLS)",
    "descriptor": "\nComments: Accepted for publication in IEEE Transactions on Neural Networks and Learning Systems (TNNLS)\n",
    "authors": [
      "Yuang Jiang",
      "Shiqiang Wang",
      "Victor Valls",
      "Bong Jun Ko",
      "Wei-Han Lee",
      "Kin K. Leung",
      "Leandros Tassiulas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1909.12326"
  },
  {
    "id": "arXiv:1911.09419",
    "title": "Learning Hierarchy-Aware Knowledge Graph Embeddings for Link Prediction",
    "abstract": "Comments: Accepted to AAAI 2020",
    "descriptor": "\nComments: Accepted to AAAI 2020\n",
    "authors": [
      "Zhanqiu Zhang",
      "Jianyu Cai",
      "Yongdong Zhang",
      "Jie Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1911.09419"
  },
  {
    "id": "arXiv:1912.00628",
    "title": "Spatially Adapted First and Second Order Regularization for Image  Reconstruction: From an Image Surface Perspective",
    "abstract": "Spatially Adapted First and Second Order Regularization for Image  Reconstruction: From an Image Surface Perspective",
    "descriptor": "",
    "authors": [
      "Qiuxiang Zhong",
      "Ryan Wen Liu",
      "Yuping Duan"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Differential Geometry (math.DG)"
    ],
    "url": "https://arxiv.org/abs/1912.00628"
  },
  {
    "id": "arXiv:2001.04508",
    "title": "CATVI: Conditional and Adaptively Truncated Variational Inference for  Hierarchical Bayesian Nonparametric Models",
    "abstract": "CATVI: Conditional and Adaptively Truncated Variational Inference for  Hierarchical Bayesian Nonparametric Models",
    "descriptor": "",
    "authors": [
      "Yirui Liu",
      "Xinghao Qiao",
      "Jessica Lam"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2001.04508"
  },
  {
    "id": "arXiv:2004.10703",
    "title": "ktrain: A Low-Code Library for Augmented Machine Learning",
    "abstract": "Comments: 9 pages",
    "descriptor": "\nComments: 9 pages\n",
    "authors": [
      "Arun S. Maiya"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2004.10703"
  },
  {
    "id": "arXiv:2005.04035",
    "title": "Spectral Ranking with Covariates",
    "abstract": "Spectral Ranking with Covariates",
    "descriptor": "",
    "authors": [
      "Siu Lun Chau",
      "Mihai Cucuringu",
      "Dino Sejdinovic"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2005.04035"
  },
  {
    "id": "arXiv:2006.09365",
    "title": "Byzantine-Robust Learning on Heterogeneous Datasets via Bucketing",
    "abstract": "Comments: v5 is the camera-ready version of this paper on ICLR 2022",
    "descriptor": "\nComments: v5 is the camera-ready version of this paper on ICLR 2022\n",
    "authors": [
      "Sai Praneeth Karimireddy",
      "Lie He",
      "Martin Jaggi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.09365"
  },
  {
    "id": "arXiv:2008.06069",
    "title": "Semantically Adversarial Learnable Filters",
    "abstract": "Comments: 13 pages",
    "descriptor": "\nComments: 13 pages\n",
    "authors": [
      "Ali Shahin Shamsabadi",
      "Changjae Oh",
      "Andrea Cavallaro"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2008.06069"
  },
  {
    "id": "arXiv:2008.09790",
    "title": "On the Hill relation and the mean reaction time for metastable processes",
    "abstract": "On the Hill relation and the mean reaction time for metastable processes",
    "descriptor": "",
    "authors": [
      "Manon Baudel",
      "Arnaud Guyader",
      "Tony Leli\u00e8vre"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2008.09790"
  },
  {
    "id": "arXiv:2009.02207",
    "title": "Fair and Useful Cohort Selection",
    "abstract": "Comments: This is a merger of the previous version and arXiv:2102.07684",
    "descriptor": "\nComments: This is a merger of the previous version and arXiv:2102.07684\n",
    "authors": [
      "Konstantina Bairaktari",
      "Paul Langton",
      "Huy L. Nguyen",
      "Niklas Smedemark-Margulies",
      "Jonathan Ullman"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2009.02207"
  },
  {
    "id": "arXiv:2009.04544",
    "title": "Self-Adaptive Physics-Informed Neural Networks using a Soft Attention  Mechanism",
    "abstract": "Comments: Submitted to Journal of Computational Physics",
    "descriptor": "\nComments: Submitted to Journal of Computational Physics\n",
    "authors": [
      "Levi McClenny",
      "Ulisses Braga-Neto"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2009.04544"
  },
  {
    "id": "arXiv:2010.08572",
    "title": "Horizon-independent Preconditioner Design for Linear Predictive Control",
    "abstract": "Comments: Accepted for publication in IEEE Transactions on Automatic Control",
    "descriptor": "\nComments: Accepted for publication in IEEE Transactions on Automatic Control\n",
    "authors": [
      "Ian McInerney",
      "Eric C. Kerrigan",
      "George A. Constantinides"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2010.08572"
  },
  {
    "id": "arXiv:2011.05907",
    "title": "Algebraic deformation for (S)PDEs",
    "abstract": "Comments: To appear in the Journal of the Mathematical Society of Japan",
    "descriptor": "\nComments: To appear in the Journal of the Mathematical Society of Japan\n",
    "authors": [
      "Yvain Bruned",
      "Dominique Manchon"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Analysis of PDEs (math.AP)",
      "Numerical Analysis (math.NA)",
      "Rings and Algebras (math.RA)"
    ],
    "url": "https://arxiv.org/abs/2011.05907"
  },
  {
    "id": "arXiv:2012.01675",
    "title": "Federated Learning for Personalized Humor Recognition",
    "abstract": "Comments: 18 pages",
    "descriptor": "\nComments: 18 pages\n",
    "authors": [
      "Xu Guo",
      "Han Yu",
      "Boyang Li",
      "Hao Wang",
      "Pengwei Xing",
      "Siwei Feng",
      "Zaiqing Nie",
      "Chunyan Miao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2012.01675"
  },
  {
    "id": "arXiv:2012.02328",
    "title": "MLPerf Mobile Inference Benchmark",
    "abstract": "MLPerf Mobile Inference Benchmark",
    "descriptor": "",
    "authors": [
      "Vijay Janapa Reddi",
      "David Kanter",
      "Peter Mattson",
      "Jared Duke",
      "Thai Nguyen",
      "Ramesh Chukka",
      "Ken Shiring",
      "Koan-Sin Tan",
      "Mark Charlebois",
      "William Chou",
      "Mostafa El-Khamy",
      "Jungwook Hong",
      "Tom St. John",
      "Cindy Trinh",
      "Michael Buch",
      "Mark Mazumder",
      "Relia Markovic",
      "Thomas Atta",
      "Fatih Cakir",
      "Masoud Charkhabi",
      "Xiaodong Chen",
      "Cheng-Ming Chiang",
      "Dave Dexter",
      "Terry Heo",
      "Gunther Schmuelling",
      "Maryam Shabani",
      "Dylan Zika"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2012.02328"
  },
  {
    "id": "arXiv:2101.05043",
    "title": "Video action recognition for lane-change classification and prediction  of surrounding vehicles",
    "abstract": "Comments: Accepted Manuscript IEEE Transactions on Intelligent Vehicles. arXiv admin note: substantial text overlap with arXiv:2008.10869",
    "descriptor": "\nComments: Accepted Manuscript IEEE Transactions on Intelligent Vehicles. arXiv admin note: substantial text overlap with arXiv:2008.10869\n",
    "authors": [
      "Mahdi Biparva",
      "David Fern\u00e1ndez-Llorca",
      "Rub\u00e9n Izquierdo-Gonzalo",
      "John K. Tsotsos"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2101.05043"
  },
  {
    "id": "arXiv:2101.06843",
    "title": "Resolution Limits of Non-Adaptive 20 Questions Search for Multiple  Targets",
    "abstract": "Comments: To appear in IEEE Transactions on Information Theory. Copyright (c) 2017 IEEE. Personal use of this material is permitted. However, permission to use this material for any other purposes must be obtained from the IEEE by sending a request to pubs-permissions@ieee.org",
    "descriptor": "\nComments: To appear in IEEE Transactions on Information Theory. Copyright (c) 2017 IEEE. Personal use of this material is permitted. However, permission to use this material for any other purposes must be obtained from the IEEE by sending a request to pubs-permissions@ieee.org\n",
    "authors": [
      "Lin Zhou",
      "Lin Bai",
      "Alfred Hero"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2101.06843"
  },
  {
    "id": "arXiv:2101.08903",
    "title": "Newcomer OSS-Candidates: Characterizing Contributions of Novice  Developers to GitHub",
    "abstract": "Comments: Empirical Software Engineering",
    "descriptor": "\nComments: Empirical Software Engineering\n",
    "authors": [
      "IFraz Rehman",
      "Dong Wang",
      "Raula Gaikovina Kula",
      "Takashi Ishio",
      "Kenichi Matsumoto"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2101.08903"
  },
  {
    "id": "arXiv:2101.09644",
    "title": "Mean-field Approximations for Stochastic Population Processes with  Heterogenous Interactions",
    "abstract": "Comments: 32 pages, 2 figures",
    "descriptor": "\nComments: 32 pages, 2 figures\n",
    "authors": [
      "Anirudh Sridhar",
      "Soummya Kar"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Multiagent Systems (cs.MA)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2101.09644"
  },
  {
    "id": "arXiv:2102.03765",
    "title": "Tactical Optimism and Pessimism for Deep Reinforcement Learning",
    "abstract": "Tactical Optimism and Pessimism for Deep Reinforcement Learning",
    "descriptor": "",
    "authors": [
      "Ted Moskovitz",
      "Jack Parker-Holder",
      "Aldo Pacchiano",
      "Michael Arbel",
      "Michael I. Jordan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.03765"
  },
  {
    "id": "arXiv:2102.07064",
    "title": "NeRF--: Neural Radiance Fields Without Known Camera Parameters",
    "abstract": "Comments: Project page see this https URL Add a break point analysis experiment and release a BLEFF dataset",
    "descriptor": "\nComments: Project page see this https URL Add a break point analysis experiment and release a BLEFF dataset\n",
    "authors": [
      "Zirui Wang",
      "Shangzhe Wu",
      "Weidi Xie",
      "Min Chen",
      "Victor Adrian Prisacariu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2102.07064"
  },
  {
    "id": "arXiv:2103.00683",
    "title": "Decision Making in Monopoly using a Hybrid Deep Reinforcement Learning  Approach",
    "abstract": "Comments: accepted in IEEE TETCI",
    "descriptor": "\nComments: accepted in IEEE TETCI\n",
    "authors": [
      "Trevor Bonjour",
      "Marina Haliem",
      "Aala Alsalem",
      "Shilpa Thomas",
      "Hongyu Li",
      "Vaneet Aggarwal",
      "Mayank Kejriwal",
      "Bharat Bhargava"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2103.00683"
  },
  {
    "id": "arXiv:2103.11399",
    "title": "Learning Calibrated-Guidance for Object Detection in Aerial Images",
    "abstract": "Learning Calibrated-Guidance for Object Detection in Aerial Images",
    "descriptor": "",
    "authors": [
      "Zongqi Wei",
      "Dong Liang",
      "Dong Zhang",
      "Liyan Zhang",
      "Qixiang Geng",
      "Mingqiang Wei",
      "Huiyu Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.11399"
  },
  {
    "id": "arXiv:2103.13342",
    "title": "The Shapley Value of coalition of variables provides better explanations",
    "abstract": "Comments: This paper has been withdrawn by the authors, because it has now been merged with (and superseded by) a parallel work arXiv:2106.03820",
    "descriptor": "\nComments: This paper has been withdrawn by the authors, because it has now been merged with (and superseded by) a parallel work arXiv:2106.03820\n",
    "authors": [
      "Salim I. Amoukou",
      "Nicolas J-B. Brunel",
      "Tangi Sala\u00fcn"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.13342"
  },
  {
    "id": "arXiv:2104.01546",
    "title": "Graph Sampling Based Deep Metric Learning for Generalizable Person  Re-Identification",
    "abstract": "Comments: This paper has been accepted by CVPR 2022",
    "descriptor": "\nComments: This paper has been accepted by CVPR 2022\n",
    "authors": [
      "Shengcai Liao",
      "Ling Shao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2104.01546"
  },
  {
    "id": "arXiv:2104.05642",
    "title": "Common Limitations of Image Processing Metrics: A Picture Story",
    "abstract": "Comments: This is a dynamic paper on limitations of commonly used metrics. The current version discusses metrics for image-level classification, semantic segmentation, object detection and instance segmentation. For missing use cases, comments or questions, please contact a.reinke@dkfz.de or l.maier-hein@dkfz.de. Substantial contributions to this document will be acknowledged with a co-authorship",
    "descriptor": "\nComments: This is a dynamic paper on limitations of commonly used metrics. The current version discusses metrics for image-level classification, semantic segmentation, object detection and instance segmentation. For missing use cases, comments or questions, please contact a.reinke@dkfz.de or l.maier-hein@dkfz.de. Substantial contributions to this document will be acknowledged with a co-authorship\n",
    "authors": [
      "Annika Reinke",
      "Minu D. Tizabi",
      "Carole H. Sudre",
      "Matthias Eisenmann",
      "Tim R\u00e4dsch",
      "Michael Baumgartner",
      "Laura Acion",
      "Michela Antonelli",
      "Tal Arbel",
      "Spyridon Bakas",
      "Peter Bankhead",
      "Arriel Benis",
      "M. Jorge Cardoso",
      "Veronika Cheplygina",
      "Beth Cimini",
      "Gary S. Collins",
      "Keyvan Farahani",
      "Ben Glocker",
      "Patrick Godau",
      "Fred Hamprecht",
      "Daniel A. Hashimoto",
      "Doreen Heckmann-N\u00f6tzel",
      "Michael M. Hoffmann",
      "Merel Huisman",
      "Fabian Isensee",
      "Pierre Jannin",
      "Charles E. Kahn",
      "Alexandros Karargyris",
      "Alan Karthikesalingam",
      "Bernhard Kainz",
      "Emre Kavur",
      "Hannes Kenngott",
      "Jens Kleesiek",
      "Thijs Kooi",
      "Michal Kozubek",
      "Anna Kreshuk",
      "Tahsin Kurc",
      "Bennett A. Landman",
      "Geert Litjens",
      "Amin Madani",
      "Klaus Maier-Hein",
      "Anne L. Martel",
      "Peter Mattson",
      "Erik Meijering",
      "Bjoern Menze",
      "David Moher",
      "Karel G.M. Moons",
      "Henning M\u00fcller"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2104.05642"
  },
  {
    "id": "arXiv:2104.06939",
    "title": "Zero-Inertia Limit: from Particle Swarm Optimization to Consensus Based  Optimization",
    "abstract": "Comments: 28 pages, 11 figures",
    "descriptor": "\nComments: 28 pages, 11 figures\n",
    "authors": [
      "Cristina Cipriani",
      "Hui Huang",
      "Jinniao Qiu"
    ],
    "subjectives": [
      "Dynamical Systems (math.DS)",
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2104.06939"
  },
  {
    "id": "arXiv:2105.00854",
    "title": "Emotional Contagion-Aware Deep Reinforcement Learning for Antagonistic  Crowd Simulation",
    "abstract": "Comments: 14 pages, 9 figures",
    "descriptor": "\nComments: 14 pages, 9 figures\n",
    "authors": [
      "Pei Lv",
      "Qingqing Yu",
      "Boya Xu",
      "Chaochao Li",
      "Bing Zhou",
      "Mingliang Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)",
      "Graphics (cs.GR)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2105.00854"
  },
  {
    "id": "arXiv:2105.05821",
    "title": "SimNet: Accurate and High-Performance Computer Architecture Simulation  using Deep Learning",
    "abstract": "SimNet: Accurate and High-Performance Computer Architecture Simulation  using Deep Learning",
    "descriptor": "",
    "authors": [
      "Lingda Li",
      "Santosh Pandey",
      "Thomas Flynn",
      "Hang Liu",
      "Noel Wheeler",
      "Adolfy Hoisie"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.05821"
  },
  {
    "id": "arXiv:2105.12824",
    "title": "Huygens' equations and the gradient-flow equations in information  geometry",
    "abstract": "Comments: 19 pages, no figure, submitted to Journal of Information Geometry",
    "descriptor": "\nComments: 19 pages, no figure, submitted to Journal of Information Geometry\n",
    "authors": [
      "Tatsuaki Wada",
      "Antonio M. Scarfone",
      "Hiroshi Matsuzoe"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Statistical Mechanics (cond-mat.stat-mech)"
    ],
    "url": "https://arxiv.org/abs/2105.12824"
  },
  {
    "id": "arXiv:2105.13928",
    "title": "DMInet: An Accurate and Highly Flexible Deep Learning Framework for Drug  Membrane Interaction with Membrane Selectivity",
    "abstract": "DMInet: An Accurate and Highly Flexible Deep Learning Framework for Drug  Membrane Interaction with Membrane Selectivity",
    "descriptor": "",
    "authors": [
      "Guang Chen"
    ],
    "subjectives": [
      "Biological Physics (physics.bio-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.13928"
  },
  {
    "id": "arXiv:2106.03479",
    "title": "FINet: Dual Branches Feature Interaction for Partial-to-Partial Point  Cloud Registration",
    "abstract": "FINet: Dual Branches Feature Interaction for Partial-to-Partial Point  Cloud Registration",
    "descriptor": "",
    "authors": [
      "Hao Xu",
      "Nianjin Ye",
      "Guanghui Liu",
      "Bing Zeng",
      "Shuaicheng Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.03479"
  },
  {
    "id": "arXiv:2106.04263",
    "title": "On the Connection between Local Attention and Dynamic Depth-wise  Convolution",
    "abstract": "Comments: ICLR 2022 Spotlight",
    "descriptor": "\nComments: ICLR 2022 Spotlight\n",
    "authors": [
      "Qi Han",
      "Zejia Fan",
      "Qi Dai",
      "Lei Sun",
      "Ming-Ming Cheng",
      "Jiaying Liu",
      "Jingdong Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.04263"
  },
  {
    "id": "arXiv:2106.05087",
    "title": "Who Is the Strongest Enemy? Towards Optimal and Efficient Evasion  Attacks in Deep RL",
    "abstract": "Comments: In the 10th International Conference on Learning Representations (ICLR 2022)",
    "descriptor": "\nComments: In the 10th International Conference on Learning Representations (ICLR 2022)\n",
    "authors": [
      "Yanchao Sun",
      "Ruijie Zheng",
      "Yongyuan Liang",
      "Furong Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2106.05087"
  },
  {
    "id": "arXiv:2106.09917",
    "title": "Envy-freeness and Relaxed Stability for Lower-Quotas : A Parameterized  Perspective",
    "abstract": "Comments: 13 pages, 2 figures. improved presentation, stronger kernelization result for MAXEFM, fixed an error in the FPT result's proof",
    "descriptor": "\nComments: 13 pages, 2 figures. improved presentation, stronger kernelization result for MAXEFM, fixed an error in the FPT result's proof\n",
    "authors": [
      "Girija Limaye"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2106.09917"
  },
  {
    "id": "arXiv:2106.14836",
    "title": "Understanding Dynamics of Nonlinear Representation Learning and Its  Application",
    "abstract": "Understanding Dynamics of Nonlinear Representation Learning and Its  Application",
    "descriptor": "",
    "authors": [
      "Kenji Kawaguchi",
      "Linjun Zhang",
      "Zhun Deng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.14836"
  },
  {
    "id": "arXiv:2106.15850",
    "title": "Exploring Robust Architectures for Deep Artificial Neural Networks",
    "abstract": "Comments: 27 pages, 16 figures",
    "descriptor": "\nComments: 27 pages, 16 figures\n",
    "authors": [
      "Asim Waqas",
      "Ghulam Rasool",
      "Hamza Farooq",
      "Nidhal C. Bouaynaya"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.15850"
  },
  {
    "id": "arXiv:2107.00710",
    "title": "Long-Short Ensemble Network for Bipolar Manic-Euthymic State Recognition  Based on Wrist-worn Sensors",
    "abstract": "Comments: Published in IEEE Pervasive Computing in 2022. 12 pages + 2. 2 Figures and 3 tables",
    "descriptor": "\nComments: Published in IEEE Pervasive Computing in 2022. 12 pages + 2. 2 Figures and 3 tables\n",
    "authors": [
      "Ulysse C\u00f4t\u00e9-Allard",
      "Petter Jakobsen",
      "Andrea Stautland",
      "Tine Nordgreen",
      "Ole Bernt Fasmer",
      "Ketil Joachim Oedegaard",
      "Jim Torresen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.00710"
  },
  {
    "id": "arXiv:2107.01189",
    "title": "NTIRE 2021 Multi-modal Aerial View Object Classification Challenge",
    "abstract": "Comments: The paper needs to be withdrawn since it did not properly go through the public release process. We will soon release a new version to replace this one",
    "descriptor": "\nComments: The paper needs to be withdrawn since it did not properly go through the public release process. We will soon release a new version to replace this one\n",
    "authors": [
      "Jerrick Liu",
      "Nathan Inkawhich",
      "Oliver Nina",
      "Radu Timofte",
      "Sahil Jain",
      "Bob Lee",
      "Yuru Duan",
      "Wei Wei",
      "Lei Zhang",
      "Songzheng Xu",
      "Yuxuan Sun",
      "Jiaqi Tang",
      "Xueli Geng",
      "Mengru Ma",
      "Gongzhe Li",
      "Xueli Geng",
      "Huanqia Cai",
      "Chengxue Cai",
      "Sol Cummings",
      "Casian Miron",
      "Alexandru Pasarica",
      "Cheng-Yen Yang",
      "Hung-Min Hsu",
      "Jiarui Cai",
      "Jie Mei",
      "Chia-Ying Yeh",
      "Jenq-Neng Hwang",
      "Michael Xin",
      "Zhongkai Shangguan",
      "Zihe Zheng",
      "Xu Yifei",
      "Lehan Yang",
      "Kele Xu",
      "Min Feng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.01189"
  },
  {
    "id": "arXiv:2107.02084",
    "title": "Artificial SA-I and RA-I Afferents for Tactile Sensing of Ridges and  Gratings",
    "abstract": "Artificial SA-I and RA-I Afferents for Tactile Sensing of Ridges and  Gratings",
    "descriptor": "",
    "authors": [
      "Nicholas Pestell",
      "Thom Griffith",
      "Nathan F. Lepora"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2107.02084"
  },
  {
    "id": "arXiv:2107.05821",
    "title": "Detect and Locate: Exposing Face Manipulation by Semantic- and  Noise-level Telltales",
    "abstract": "Comments: 12 pages, 10 figures",
    "descriptor": "\nComments: 12 pages, 10 figures\n",
    "authors": [
      "Chenqi Kong",
      "Baoliang Chen",
      "Haoliang Li",
      "Shiqi Wang",
      "Anderson Rocha",
      "Sam Kwong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.05821"
  },
  {
    "id": "arXiv:2107.06773",
    "title": "Relational graph convolutional networks for predicting blood-brain  barrier penetration of drug molecules",
    "abstract": "Relational graph convolutional networks for predicting blood-brain  barrier penetration of drug molecules",
    "descriptor": "",
    "authors": [
      "Yan Ding",
      "Xiaoqian Jiang",
      "Yejin Kim"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.06773"
  },
  {
    "id": "arXiv:2107.07649",
    "title": "Reed-Muller Identification",
    "abstract": "Comments: V2: published version in proceedings at International Zurich Seminar on Information and Communication (IZS) 2022 with wrong capacity statement; V1: wrong capacity statement (wrong proof that the codes do not achieve capacity while they do), submitted to 2021 IEEE Globecom: Workshop on Channel Coding beyond 5G",
    "descriptor": "\nComments: V2: published version in proceedings at International Zurich Seminar on Information and Communication (IZS) 2022 with wrong capacity statement; V1: wrong capacity statement (wrong proof that the codes do not achieve capacity while they do), submitted to 2021 IEEE Globecom: Workshop on Channel Coding beyond 5G\n",
    "authors": [
      "Mattia Spandri",
      "Roberto Ferrara",
      "Christian Deppe"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2107.07649"
  },
  {
    "id": "arXiv:2107.10497",
    "title": "Patterns of Patterns",
    "abstract": "Comments: 24 pages; To appear in the Proceedings of Pattern Languages of Programs 2021, and in the collected volume \"CLA 3.0: 30 Years of Transformative and Critical Futures Research\"",
    "descriptor": "\nComments: 24 pages; To appear in the Proceedings of Pattern Languages of Programs 2021, and in the collected volume \"CLA 3.0: 30 Years of Transformative and Critical Futures Research\"\n",
    "authors": [
      "Joseph Corneli",
      "Alex Murphy",
      "Raymond S. Puzio",
      "Leo Vivier",
      "Noorah Alhasan",
      "Charles J. Danoff",
      "Vitor Bruno",
      "Charlotte Pierce"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2107.10497"
  },
  {
    "id": "arXiv:2107.11965",
    "title": "Playtesting: What is Beyond Personas",
    "abstract": "Playtesting: What is Beyond Personas",
    "descriptor": "",
    "authors": [
      "Sinan Ariyurek",
      "Elif Surer",
      "Aysu Betin-Can"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.11965"
  },
  {
    "id": "arXiv:2107.12192",
    "title": "Accelerating Video Object Segmentation with Compressed Video",
    "abstract": "Comments: 17 pages",
    "descriptor": "\nComments: 17 pages\n",
    "authors": [
      "Kai Xu",
      "Angela Yao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.12192"
  },
  {
    "id": "arXiv:2107.14415",
    "title": "Connecting Compression Spaces with Transformer for Approximate Nearest  Neighbor Search",
    "abstract": "Comments: 13 pages, 3 figures and 5 tables",
    "descriptor": "\nComments: 13 pages, 3 figures and 5 tables\n",
    "authors": [
      "Haokui Zhang",
      "Buzhou Tang",
      "Wenze Hu",
      "Xiaoyu Wang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2107.14415"
  },
  {
    "id": "arXiv:2108.02271",
    "title": "Daft-Exprt: Cross-Speaker Prosody Transfer on Any Text for Expressive  Speech Synthesis",
    "abstract": "Comments: Submitted to Interspeech 2022, 5 pages, 5 figures, 2 tables",
    "descriptor": "\nComments: Submitted to Interspeech 2022, 5 pages, 5 figures, 2 tables\n",
    "authors": [
      "Julian Za\u00efdi",
      "Hugo Seut\u00e9",
      "Benjamin van Niekerk",
      "Marc-Andr\u00e9 Carbonneau"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2108.02271"
  },
  {
    "id": "arXiv:2108.02571",
    "title": "Learning Linearized Assignment Flows for Image Labeling",
    "abstract": "Learning Linearized Assignment Flows for Image Labeling",
    "descriptor": "",
    "authors": [
      "Alexander Zeilmann",
      "Stefania Petra",
      "Christoph Schn\u00f6rr"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2108.02571"
  },
  {
    "id": "arXiv:2108.13556",
    "title": "Linguistic Characterization of Divisive Topics Online: Case Studies on  Contentiousness in Abortion, Climate Change, and Gun Control",
    "abstract": "Linguistic Characterization of Divisive Topics Online: Case Studies on  Contentiousness in Abortion, Climate Change, and Gun Control",
    "descriptor": "",
    "authors": [
      "Jacob Beel",
      "Tong Xiang",
      "Sandeep Soni",
      "Diyi Yang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2108.13556"
  },
  {
    "id": "arXiv:2109.03775",
    "title": "FedZKT: Zero-Shot Knowledge Transfer towards Resource-Constrained  Federated Learning with Heterogeneous On-Device Models",
    "abstract": "Comments: This paper has been accepted to ICDCS 2022",
    "descriptor": "\nComments: This paper has been accepted to ICDCS 2022\n",
    "authors": [
      "Lan Zhang",
      "Dapeng Wu",
      "Xiaoyong Yuan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2109.03775"
  },
  {
    "id": "arXiv:2109.04106",
    "title": "Function recovery on manifolds using scattered data",
    "abstract": "Comments: 21 pages, removed disclaimer, added Cor. 2",
    "descriptor": "\nComments: 21 pages, removed disclaimer, added Cor. 2\n",
    "authors": [
      "David Krieg",
      "Mathias Sonnleitner"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2109.04106"
  },
  {
    "id": "arXiv:2109.06096",
    "title": "The Grammar-Learning Trajectories of Neural Language Models",
    "abstract": "Comments: ACL camera-ready",
    "descriptor": "\nComments: ACL camera-ready\n",
    "authors": [
      "Leshem Choshen",
      "Guy Hacohen",
      "Daphna Weinshall",
      "Omri Abend"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.06096"
  },
  {
    "id": "arXiv:2109.07627",
    "title": "Adversarially Regularized Policy Learning Guided by Trajectory  Optimization",
    "abstract": "Comments: Accepted at L4DC 2022",
    "descriptor": "\nComments: Accepted at L4DC 2022\n",
    "authors": [
      "Zhigen Zhao",
      "Simiao Zuo",
      "Tuo Zhao",
      "Ye Zhao"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.07627"
  },
  {
    "id": "arXiv:2109.09180",
    "title": "Lifelong Robotic Reinforcement Learning by Retaining Experiences",
    "abstract": "Comments: Supplementary website at this https URL",
    "descriptor": "\nComments: Supplementary website at this https URL\n",
    "authors": [
      "Annie Xie",
      "Chelsea Finn"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.09180"
  },
  {
    "id": "arXiv:2109.09559",
    "title": "Contrastive Learning of Subject-Invariant EEG Representations for  Cross-Subject Emotion Recognition",
    "abstract": "Comments: 23 pages, 13 figures, journal paper. IEEE Transactions on Affective Computing, 2022",
    "descriptor": "\nComments: 23 pages, 13 figures, journal paper. IEEE Transactions on Affective Computing, 2022\n",
    "authors": [
      "Xinke Shen",
      "Xianggen Liu",
      "Xin Hu",
      "Dan Zhang",
      "Sen Song"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2109.09559"
  },
  {
    "id": "arXiv:2109.11752",
    "title": "Internal Feedback in Biological Control: Diversity, Delays, and Standard  Theory",
    "abstract": "Comments: To appear in 2022 ACC; Companion paper to arXiv:2110.05029, arXiv:2109.11757; Version updates: author + content changes, T.J.S., G.C., E.S.H., N.K. and their contributions have migrated to to arXiv:2110.05029",
    "descriptor": "\nComments: To appear in 2022 ACC; Companion paper to arXiv:2110.05029, arXiv:2109.11757; Version updates: author + content changes, T.J.S., G.C., E.S.H., N.K. and their contributions have migrated to to arXiv:2110.05029\n",
    "authors": [
      "Josefin Stenberg",
      "Jing Shuang Li",
      "Anish A. Sarma",
      "John C. Doyle"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2109.11752"
  },
  {
    "id": "arXiv:2109.11757",
    "title": "Internal Feedback in Biological Control: Locality and System Level  Synthesis",
    "abstract": "Comments: To appear in 2022 ACC; Companion paper to arXiv:2110.05029, arXiv:2109.11752; Version updates: author change (J. C. D. has been consulted), additional material + figures",
    "descriptor": "\nComments: To appear in 2022 ACC; Companion paper to arXiv:2110.05029, arXiv:2109.11752; Version updates: author change (J. C. D. has been consulted), additional material + figures\n",
    "authors": [
      "Jing Shuang Li"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2109.11757"
  },
  {
    "id": "arXiv:2109.12555",
    "title": "On Stability and Consensus of Signed Networks: A Self-loop Compensation  Perspective",
    "abstract": "On Stability and Consensus of Signed Networks: A Self-loop Compensation  Perspective",
    "descriptor": "",
    "authors": [
      "Haibin Shao",
      "Lulu Pan",
      "Dewei Li",
      "Yugeng Xi"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2109.12555"
  },
  {
    "id": "arXiv:2109.13168",
    "title": "Scalable and Accurate Test Case Prioritization in Continuous Integration  Contexts",
    "abstract": "Comments: 27 pages, LaTeX; Minor writing corrections in the abstract; Major revision",
    "descriptor": "\nComments: 27 pages, LaTeX; Minor writing corrections in the abstract; Major revision\n",
    "authors": [
      "Ahmadreza Saboor Yaraghi",
      "Mojtaba Bagherzadeh",
      "Nafiseh Kahani",
      "Lionel Briand"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2109.13168"
  },
  {
    "id": "arXiv:2109.15285",
    "title": "Improving Neural Ranking via Lossless Knowledge Distillation",
    "abstract": "Comments: 15 pages",
    "descriptor": "\nComments: 15 pages\n",
    "authors": [
      "Zhen Qin",
      "Le Yan",
      "Yi Tay",
      "Honglei Zhuang",
      "Xuanhui Wang",
      "Michael Bendersky",
      "Marc Najork"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2109.15285"
  },
  {
    "id": "arXiv:2110.05116",
    "title": "Towards Explainable Real Estate Valuation via Evolutionary Algorithms",
    "abstract": "Towards Explainable Real Estate Valuation via Evolutionary Algorithms",
    "descriptor": "",
    "authors": [
      "Sebastian Angrick",
      "Ben Bals",
      "Niko Hastrich",
      "Maximilian Kleissl",
      "Jonas Schmidt",
      "Vanja Dosko\u010d",
      "Maximilian Katzmann",
      "Louise Molitor",
      "Tobias Friedrich"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2110.05116"
  },
  {
    "id": "arXiv:2110.05798",
    "title": "Adapting TTS models For New Speakers using Transfer Learning",
    "abstract": "Comments: Submitted to Interspeech 2022",
    "descriptor": "\nComments: Submitted to Interspeech 2022\n",
    "authors": [
      "Paarth Neekhara",
      "Jason Li",
      "Boris Ginsburg"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.05798"
  },
  {
    "id": "arXiv:2110.08868",
    "title": "Accurate Baryon Acoustic Oscillations reconstruction via semi-discrete  optimal transport",
    "abstract": "Comments: Accepted for publication in PRL. 7 pages incl. references; 2 figures; 1 table. v1 initial submission. v2 fixed affiliation. v3 matches published version, but larger figures",
    "descriptor": "\nComments: Accepted for publication in PRL. 7 pages incl. references; 2 figures; 1 table. v1 initial submission. v2 fixed affiliation. v3 matches published version, but larger figures\n",
    "authors": [
      "Sebastian von Hausegger",
      "Bruno L\u00e9vy",
      "Roya Mohayaee"
    ],
    "subjectives": [
      "Cosmology and Nongalactic Astrophysics (astro-ph.CO)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Analysis of PDEs (math.AP)",
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2110.08868"
  },
  {
    "id": "arXiv:2110.10757",
    "title": "TPARN: Triple-path Attentive Recurrent Network for Time-domain  Multichannel Speech Enhancement",
    "abstract": "Comments: Accepted for publication in ICASSP 2022",
    "descriptor": "\nComments: Accepted for publication in ICASSP 2022\n",
    "authors": [
      "Ashutosh Pandey",
      "Buye Xu",
      "Anurag Kumar",
      "Jacob Donley",
      "Paul Calamia",
      "DeLiang Wang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.10757"
  },
  {
    "id": "arXiv:2110.13130",
    "title": "Multichannel Speech Enhancement without Beamforming",
    "abstract": "Comments: Accepted for publication in ICASSP 2022",
    "descriptor": "\nComments: Accepted for publication in ICASSP 2022\n",
    "authors": [
      "Asutosh Pandey",
      "Buye Xu",
      "Anurag Kumar",
      "Jacob Donley",
      "Paul Calamia",
      "DeLiang Wang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.13130"
  },
  {
    "id": "arXiv:2110.13146",
    "title": "Reduce the rank calculation of a high-dimensional sparse matrix based on  network controllability theory",
    "abstract": "Comments: 10 pages, 4 figures",
    "descriptor": "\nComments: 10 pages, 4 figures\n",
    "authors": [
      "Chen Zhao",
      "Yuqing Liu",
      "Li Hu",
      "Zhengzhong Yuan"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.13146"
  },
  {
    "id": "arXiv:2110.14170",
    "title": "Meta-Knowledge Transfer for Inductive Knowledge Graph Embedding",
    "abstract": "Comments: SIGIR 2022",
    "descriptor": "\nComments: SIGIR 2022\n",
    "authors": [
      "Mingyang Chen",
      "Wen Zhang",
      "Yushan Zhu",
      "Hongting Zhou",
      "Zonggang Yuan",
      "Changliang Xu",
      "Huajun Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.14170"
  },
  {
    "id": "arXiv:2111.01622",
    "title": "Towards an Optimal Hybrid Algorithm for EV Charging Stations Placement  using Quantum Annealing and Genetic Algorithms",
    "abstract": "Comments: 6 pages, 6 figures",
    "descriptor": "\nComments: 6 pages, 6 figures\n",
    "authors": [
      "Aman Chandra",
      "Jitesh Lalwani",
      "Babita Jajodia"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2111.01622"
  },
  {
    "id": "arXiv:2111.02403",
    "title": "WORD: A large scale dataset, benchmark and clinical applicable study for  abdominal organ segmentation from CT image",
    "abstract": "Comments: Tech report (13 pages, 5 figures and 10 tables), work is ongoing, any comments and suggestions are welcome, dataset at: this https URL",
    "descriptor": "\nComments: Tech report (13 pages, 5 figures and 10 tables), work is ongoing, any comments and suggestions are welcome, dataset at: this https URL\n",
    "authors": [
      "Xiangde Luo",
      "Wenjun Liao",
      "Jianghong Xiao",
      "Tao Song",
      "Xiaofan Zhang",
      "Kang Li",
      "Dimitris N. Metaxas",
      "Guotai Wang",
      "Shaoting Zhang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.02403"
  },
  {
    "id": "arXiv:2111.03142",
    "title": "Inapproximability of Positive Semidefinite Permanents and Quantum State  Tomography",
    "abstract": "Comments: 21 pages, 3 figures",
    "descriptor": "\nComments: 21 pages, 3 figures\n",
    "authors": [
      "Alex Meiburg"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2111.03142"
  },
  {
    "id": "arXiv:2111.06171",
    "title": "Convergence and Stability of the Stochastic Proximal Point Algorithm  with Momentum",
    "abstract": "Comments: 24 pages, 2 figures, 4th Annual Conference on Learning for Dynamics and Control",
    "descriptor": "\nComments: 24 pages, 2 figures, 4th Annual Conference on Learning for Dynamics and Control\n",
    "authors": [
      "Junhyung Lyle Kim",
      "Panos Toulis",
      "Anastasios Kyrillidis"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.06171"
  },
  {
    "id": "arXiv:2111.07494",
    "title": "Federated Learning for Internet of Things: Applications, Challenges, and  Opportunities",
    "abstract": "Federated Learning for Internet of Things: Applications, Challenges, and  Opportunities",
    "descriptor": "",
    "authors": [
      "Tuo Zhang",
      "Lei Gao",
      "Chaoyang He",
      "Mi Zhang",
      "Bhaskar Krishnamachari",
      "Salman Avestimehr"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.07494"
  },
  {
    "id": "arXiv:2111.09162",
    "title": "It's About Time: Analog Clock Reading in the Wild",
    "abstract": "Comments: CVPR 2022. Project page: this https URL",
    "descriptor": "\nComments: CVPR 2022. Project page: this https URL\n",
    "authors": [
      "Charig Yang",
      "Weidi Xie",
      "Andrew Zisserman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.09162"
  },
  {
    "id": "arXiv:2111.09771",
    "title": "Transformer-S2A: Robust and Efficient Speech-to-Animation",
    "abstract": "Comments: Accepted by ICASSP 2022",
    "descriptor": "\nComments: Accepted by ICASSP 2022\n",
    "authors": [
      "Liyang Chen",
      "Zhiyong Wu",
      "Jun Ling",
      "Runnan Li",
      "Xu Tan",
      "Sheng Zhao"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Graphics (cs.GR)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2111.09771"
  },
  {
    "id": "arXiv:2111.11426",
    "title": "Neural Fields in Visual Computing and Beyond",
    "abstract": "Comments: Equal advising: Vincent Sitzmann and Srinath Sridhar",
    "descriptor": "\nComments: Equal advising: Vincent Sitzmann and Srinath Sridhar\n",
    "authors": [
      "Yiheng Xie",
      "Towaki Takikawa",
      "Shunsuke Saito",
      "Or Litany",
      "Shiqin Yan",
      "Numair Khan",
      "Federico Tombari",
      "James Tompkin",
      "Vincent Sitzmann",
      "Srinath Sridhar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.11426"
  },
  {
    "id": "arXiv:2111.11660",
    "title": "Non-invasive hemodynamic analysis for aortic regurgitation using  computational fluid dynamics and deep learning",
    "abstract": "Non-invasive hemodynamic analysis for aortic regurgitation using  computational fluid dynamics and deep learning",
    "descriptor": "",
    "authors": [
      "Derek Long",
      "Cameron McMurdo",
      "Edward Ferdian",
      "Charlene A. Mauger",
      "David Marlevi",
      "Alistair A. Young",
      "Martyn P. Nash"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2111.11660"
  },
  {
    "id": "arXiv:2111.12294",
    "title": "An Image Patch is a Wave: Phase-Aware Vision MLP",
    "abstract": "Comments: This paper is accepted by CVPR 2022 (oral presentation)",
    "descriptor": "\nComments: This paper is accepted by CVPR 2022 (oral presentation)\n",
    "authors": [
      "Yehui Tang",
      "Kai Han",
      "Jianyuan Guo",
      "Chang Xu",
      "Yanxi Li",
      "Chao Xu",
      "Yunhe Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.12294"
  },
  {
    "id": "arXiv:2111.12580",
    "title": "UDA-COPE: Unsupervised Domain Adaptation for Category-level Object Pose  Estimation",
    "abstract": "Comments: Accepted to CVPR 2022",
    "descriptor": "\nComments: Accepted to CVPR 2022\n",
    "authors": [
      "Taeyeop Lee",
      "Byeong-Uk Lee",
      "Inkyu Shin",
      "Jaesung Choe",
      "Ukcheol Shin",
      "In So Kweon",
      "Kuk-Jin Yoon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.12580"
  },
  {
    "id": "arXiv:2111.13151",
    "title": "Computing weakly singular and near-singular integrals in high-order  boundary elements",
    "abstract": "Computing weakly singular and near-singular integrals in high-order  boundary elements",
    "descriptor": "",
    "authors": [
      "Hadrien Montanelli",
      "Matthieu Aussal",
      "Houssem Haddar"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2111.13151"
  },
  {
    "id": "arXiv:2111.15222",
    "title": "SP-SEDT: Self-supervised Pre-training for Sound Event Detection  Transformer",
    "abstract": "Comments: Submitted to interspeech 2022; added experiments for section 4",
    "descriptor": "\nComments: Submitted to interspeech 2022; added experiments for section 4\n",
    "authors": [
      "Zhirong Ye",
      "Xiangdong Wang",
      "Hong Liu",
      "Yueliang Qian",
      "Rui Tao",
      "Long Yan",
      "Kazushige Ouchi"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2111.15222"
  },
  {
    "id": "arXiv:2111.15234",
    "title": "NeRFReN: Neural Radiance Fields with Reflections",
    "abstract": "Comments: Accepted to CVPR 2022. Project page: this https URL",
    "descriptor": "\nComments: Accepted to CVPR 2022. Project page: this https URL\n",
    "authors": [
      "Yuan-Chen Guo",
      "Di Kang",
      "Linchao Bao",
      "Yu He",
      "Song-Hai Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2111.15234"
  },
  {
    "id": "arXiv:2111.15491",
    "title": "PolyWorld: Polygonal Building Extraction with Graph Neural Networks in  Satellite Images",
    "abstract": "PolyWorld: Polygonal Building Extraction with Graph Neural Networks in  Satellite Images",
    "descriptor": "",
    "authors": [
      "Stefano Zorzi",
      "Shabab Bazrafkan",
      "Stefan Habenschuss",
      "Friedrich Fraundorfer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.15491"
  },
  {
    "id": "arXiv:2112.02244",
    "title": "LAVT: Language-Aware Vision Transformer for Referring Image Segmentation",
    "abstract": "Comments: CVPR 2022",
    "descriptor": "\nComments: CVPR 2022\n",
    "authors": [
      "Zhao Yang",
      "Jiaqi Wang",
      "Yansong Tang",
      "Kai Chen",
      "Hengshuang Zhao",
      "Philip H.S. Torr"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.02244"
  },
  {
    "id": "arXiv:2112.08627",
    "title": "On the Use of Quality Diversity Algorithms for The Traveling Thief  Problem",
    "abstract": "Comments: To appear at GECCO 2022",
    "descriptor": "\nComments: To appear at GECCO 2022\n",
    "authors": [
      "Adel Nikfarjam",
      "Aneta Neumann",
      "Frank Neumann"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2112.08627"
  },
  {
    "id": "arXiv:2112.08628",
    "title": "Explainable Natural Language Processing with Matrix Product States",
    "abstract": "Comments: 25 pages, 7 figures. Accepted for publication in New Journal of Physics",
    "descriptor": "\nComments: 25 pages, 7 figures. Accepted for publication in New Journal of Physics\n",
    "authors": [
      "Jirawat Tangpanitanon",
      "Chanatip Mangkang",
      "Pradeep Bhadola",
      "Yuichiro Minato",
      "Dimitris G. Angelakis",
      "Thiparat Chotibut"
    ],
    "subjectives": [
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2112.08628"
  },
  {
    "id": "arXiv:2112.11347",
    "title": "Watch It Move: Unsupervised Discovery of 3D Joints for Re-Posing of  Articulated Objects",
    "abstract": "Comments: CVPR2022, 16 pages, Project page: this https URL",
    "descriptor": "\nComments: CVPR2022, 16 pages, Project page: this https URL\n",
    "authors": [
      "Atsuhiro Noguchi",
      "Umar Iqbal",
      "Jonathan Tremblay",
      "Tatsuya Harada",
      "Orazio Gallo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.11347"
  },
  {
    "id": "arXiv:2112.12777",
    "title": "Cross Modal Retrieval with Querybank Normalisation",
    "abstract": "Comments: Accepted at CVPR 2022",
    "descriptor": "\nComments: Accepted at CVPR 2022\n",
    "authors": [
      "Simion-Vlad Bogolin",
      "Ioana Croitoru",
      "Hailin Jin",
      "Yang Liu",
      "Samuel Albanie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.12777"
  },
  {
    "id": "arXiv:2112.13613",
    "title": "Variable step-size BDF3 method for Allen-Cahn equation",
    "abstract": "Variable step-size BDF3 method for Allen-Cahn equation",
    "descriptor": "",
    "authors": [
      "Minghua Chen",
      "Fan Yu",
      "Qingdong Zhang",
      "Zhimin Zhang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2112.13613"
  },
  {
    "id": "arXiv:2112.13677",
    "title": "Agent Smith: Teaching Question Answering to Jill Watson",
    "abstract": "Comments: 11 Pages, 9 Figures",
    "descriptor": "\nComments: 11 Pages, 9 Figures\n",
    "authors": [
      "Ashok Goel",
      "Harshvardhan Sikka",
      "Eric Gregori"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2112.13677"
  },
  {
    "id": "arXiv:2112.13809",
    "title": "Improving Deep Image Matting via Local Smoothness Assumption",
    "abstract": "Comments: 9 pages, accepted by IEEE ICME 2022",
    "descriptor": "\nComments: 9 pages, accepted by IEEE ICME 2022\n",
    "authors": [
      "Rui Wang",
      "Jun Xie",
      "Jiacheng Han",
      "Dezhen Qi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.13809"
  },
  {
    "id": "arXiv:2112.15594",
    "title": "A Neural Network Solves, Explains, and Generates University Math  Problems by Program Synthesis and Few-Shot Learning at Human Level",
    "abstract": "Comments: 180 pages, 8 figures, 280 tables",
    "descriptor": "\nComments: 180 pages, 8 figures, 280 tables\n",
    "authors": [
      "Iddo Drori",
      "Sarah Zhang",
      "Reece Shuttleworth",
      "Leonard Tang",
      "Albert Lu",
      "Elizabeth Ke",
      "Kevin Liu",
      "Linda Chen",
      "Sunny Tran",
      "Newman Cheng",
      "Roman Wang",
      "Nikhil Singh",
      "Taylor L. Patti",
      "Jayson Lynch",
      "Avi Shporer",
      "Nakul Verma",
      "Eugene Wu",
      "Gilbert Strang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.15594"
  },
  {
    "id": "arXiv:2201.00006",
    "title": "AttentionLight: Rethinking queue length and attention mechanism for  traffic signal control",
    "abstract": "Comments: 11 pages, 9 figures",
    "descriptor": "\nComments: 11 pages, 9 figures\n",
    "authors": [
      "Liang Zhang",
      "Qiang Wu",
      "Jianming Deng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2201.00006"
  },
  {
    "id": "arXiv:2201.00248",
    "title": "Transfer RL across Observation Feature Spaces via Model-Based  Regularization",
    "abstract": "Comments: In the 10th International Conference on Learning Representations (ICLR 2022)",
    "descriptor": "\nComments: In the 10th International Conference on Learning Representations (ICLR 2022)\n",
    "authors": [
      "Yanchao Sun",
      "Ruijie Zheng",
      "Xiyao Wang",
      "Andrew Cohen",
      "Furong Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.00248"
  },
  {
    "id": "arXiv:2201.03740",
    "title": "A Grammar-Based Approach for Applying Visualization Taxonomies to  Interaction Logs",
    "abstract": "A Grammar-Based Approach for Applying Visualization Taxonomies to  Interaction Logs",
    "descriptor": "",
    "authors": [
      "Sneha Gathani",
      "Shayan Monadjemi",
      "Alvitta Ottley",
      "Leilani Battle"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2201.03740"
  },
  {
    "id": "arXiv:2201.05545",
    "title": "Multimodal registration of FISH and nanoSIMS images using convolutional  neural network models",
    "abstract": "Multimodal registration of FISH and nanoSIMS images using convolutional  neural network models",
    "descriptor": "",
    "authors": [
      "Xiaojia He",
      "Christof Meile",
      "Suchendra M. Bhandarkar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.05545"
  },
  {
    "id": "arXiv:2201.07036",
    "title": "Performance Analysis of IEEE 802.11p Preamble Insertion in C-V2X  Sidelink Signals for Co-Channel Coexistence",
    "abstract": "Performance Analysis of IEEE 802.11p Preamble Insertion in C-V2X  Sidelink Signals for Co-Channel Coexistence",
    "descriptor": "",
    "authors": [
      "Alessandro Bazzi",
      "Stefania Bartoletti",
      "Alberto Zanella",
      "Vincent Martinez"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2201.07036"
  },
  {
    "id": "arXiv:2201.09381",
    "title": "vCLIMB: A Novel Video Class Incremental Learning Benchmark",
    "abstract": "Comments: An updated version of our CVPR 2022 paper (oral); v2 adds minor text changes. The code of our benchmark can be found at: this https URL",
    "descriptor": "\nComments: An updated version of our CVPR 2022 paper (oral); v2 adds minor text changes. The code of our benchmark can be found at: this https URL\n",
    "authors": [
      "Andr\u00e9s Villa",
      "Kumail Alhamoud",
      "Juan Le\u00f3n Alc\u00e1zar",
      "Fabian Caba Heilbron",
      "Victor Escorcia",
      "Bernard Ghanem"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.09381"
  },
  {
    "id": "arXiv:2201.09953",
    "title": "Challenges in Migrating Imperative Deep Learning Programs to Graph  Execution: An Empirical Study",
    "abstract": "Comments: International Conference on Mining Software Repositories, MSR 2022. ACM/IEEE, ACM, May 2022",
    "descriptor": "\nComments: International Conference on Mining Software Repositories, MSR 2022. ACM/IEEE, ACM, May 2022\n",
    "authors": [
      "Tatiana Castro V\u00e9lez",
      "Raffi Khatchadourian",
      "Mehdi Bagherzadeh",
      "Anita Raja"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2201.09953"
  },
  {
    "id": "arXiv:2201.10015",
    "title": "Automatic Recognition and Digital Documentation of Cultural Heritage  Hemispherical Domes using Images",
    "abstract": "Automatic Recognition and Digital Documentation of Cultural Heritage  Hemispherical Domes using Images",
    "descriptor": "",
    "authors": [
      "Reza Maalek",
      "Shahrokh Maalek"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.10015"
  },
  {
    "id": "arXiv:2201.10113",
    "title": "Multimodal data matters: language model pre-training over structured and  unstructured electronic health records",
    "abstract": "Comments: 30 pages, 5 figures",
    "descriptor": "\nComments: 30 pages, 5 figures\n",
    "authors": [
      "Sicen Liu",
      "Xiaolong Wang",
      "Yongshuai Hou",
      "Ge Li",
      "Hui Wang",
      "Hui Xu",
      "Yang Xiang",
      "Buzhou Tang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.10113"
  },
  {
    "id": "arXiv:2201.10709",
    "title": "Metropolitan Optical Networks: A Survey on New Architectures and Future  Trends",
    "abstract": "Comments: 59 pages, 27 figures and 18 tables",
    "descriptor": "\nComments: 59 pages, 27 figures and 18 tables\n",
    "authors": [
      "L\u00e9ia Sousa de Sousa",
      "Andr\u00e9 Costa Drummond"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2201.10709"
  },
  {
    "id": "arXiv:2201.11903",
    "title": "Chain of Thought Prompting Elicits Reasoning in Large Language Models",
    "abstract": "Chain of Thought Prompting Elicits Reasoning in Large Language Models",
    "descriptor": "",
    "authors": [
      "Jason Wei",
      "Xuezhi Wang",
      "Dale Schuurmans",
      "Maarten Bosma",
      "Ed Chi",
      "Quoc Le",
      "Denny Zhou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2201.11903"
  },
  {
    "id": "arXiv:2201.13425",
    "title": "Don't Change the Algorithm, Change the Data: Exploratory Data for  Offline Reinforcement Learning",
    "abstract": "Don't Change the Algorithm, Change the Data: Exploratory Data for  Offline Reinforcement Learning",
    "descriptor": "",
    "authors": [
      "Denis Yarats",
      "David Brandfonbrener",
      "Hao Liu",
      "Michael Laskin",
      "Pieter Abbeel",
      "Alessandro Lazaric",
      "Lerrel Pinto"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2201.13425"
  },
  {
    "id": "arXiv:2202.01731",
    "title": "Fast Online Video Super-Resolution with Deformable Attention Pyramid",
    "abstract": "Fast Online Video Super-Resolution with Deformable Attention Pyramid",
    "descriptor": "",
    "authors": [
      "Dario Fuoli",
      "Martin Danelljan",
      "Radu Timofte",
      "Luc Van Gool"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.01731"
  },
  {
    "id": "arXiv:2202.02474",
    "title": "Importance Weighting Approach in Kernel Bayes' Rule",
    "abstract": "Importance Weighting Approach in Kernel Bayes' Rule",
    "descriptor": "",
    "authors": [
      "Liyuan Xu",
      "Yutian Chen",
      "Arnaud Doucet",
      "Arthur Gretton"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.02474"
  },
  {
    "id": "arXiv:2202.05008",
    "title": "EvoJAX: Hardware-Accelerated Neuroevolution",
    "abstract": "Comments: GECCO 2022. Project website at this https URL",
    "descriptor": "\nComments: GECCO 2022. Project website at this https URL\n",
    "authors": [
      "Yujin Tang",
      "Yingtao Tian",
      "David Ha"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2202.05008"
  },
  {
    "id": "arXiv:2202.05452",
    "title": "Information Design for Differential Privacy",
    "abstract": "Information Design for Differential Privacy",
    "descriptor": "",
    "authors": [
      "Ian M. Schmutte",
      "Nathan Yoder"
    ],
    "subjectives": [
      "Theoretical Economics (econ.TH)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.05452"
  },
  {
    "id": "arXiv:2202.06014",
    "title": "Multi-direction and Multi-scale Pyramid in Transformer for Video-based  Pedestrian Retrieval",
    "abstract": "Comments: 10 pages, 6 figures, Accepted for publication in IEEE Transactions on Industrial Informatics",
    "descriptor": "\nComments: 10 pages, 6 figures, Accepted for publication in IEEE Transactions on Industrial Informatics\n",
    "authors": [
      "Xianghao Zang",
      "Ge Li",
      "Wei Gao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.06014"
  },
  {
    "id": "arXiv:2202.06280",
    "title": "On the complexity of All $\\varepsilon$-Best Arms Identification",
    "abstract": "On the complexity of All $\\varepsilon$-Best Arms Identification",
    "descriptor": "",
    "authors": [
      "Aymen Al Marjani",
      "Tom\u00e1\u0161 Koc\u00e1k",
      "Aur\u00e9lien Garivier"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.06280"
  },
  {
    "id": "arXiv:2202.12183",
    "title": "Large-scale Stochastic Optimization of NDCG Surrogates for Deep Learning  with Provable Convergence",
    "abstract": "Comments: 29 pages, 7 figures",
    "descriptor": "\nComments: 29 pages, 7 figures\n",
    "authors": [
      "Zi-Hao Qiu",
      "Quanqi Hu",
      "Yongjian Zhong",
      "Lijun Zhang",
      "Tianbao Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.12183"
  },
  {
    "id": "arXiv:2202.12599",
    "title": "Making Life More Confusing for Firefighters",
    "abstract": "Making Life More Confusing for Firefighters",
    "descriptor": "",
    "authors": [
      "Samuel Hand",
      "Jessica Enright",
      "Kitty Meeks"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Complexity (cs.CC)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2202.12599"
  },
  {
    "id": "arXiv:2202.13457",
    "title": "Enhancing Legal Argument Mining with Domain Pre-training and Neural  Networks",
    "abstract": "Enhancing Legal Argument Mining with Domain Pre-training and Neural  Networks",
    "descriptor": "",
    "authors": [
      "Gechuan Zhang",
      "Paul Nulty",
      "David Lillis"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.13457"
  },
  {
    "id": "arXiv:2202.13873",
    "title": "Stability analysis of RBF-FD and WLS based local strong form meshless  methods on scattered nodes",
    "abstract": "Comments: Mipro conference paper",
    "descriptor": "\nComments: Mipro conference paper\n",
    "authors": [
      "Mitja Jan\u010di\u010d",
      "Gregor Kosec"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.13873"
  },
  {
    "id": "arXiv:2203.00064",
    "title": "Piezoelectric Strain FET (PeFET) based Non-Volatile Memories",
    "abstract": "Comments: 8 pages, 13 figures In the peer review process of the journal of IEEE Transactions on Electron Devices",
    "descriptor": "\nComments: 8 pages, 13 figures In the peer review process of the journal of IEEE Transactions on Electron Devices\n",
    "authors": [
      "Niharika Thakuria",
      "Reena Elangovan",
      "Anand Raghunathan",
      "Sumeet K. Gupta"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2203.00064"
  },
  {
    "id": "arXiv:2203.00843",
    "title": "X-Trans2Cap: Cross-Modal Knowledge Transfer using Transformer for 3D  Dense Captioning",
    "abstract": "Comments: To appear in CVPR2022",
    "descriptor": "\nComments: To appear in CVPR2022\n",
    "authors": [
      "Zhihao Yuan",
      "Xu Yan",
      "Yinghong Liao",
      "Yao Guo",
      "Guanbin Li",
      "Zhen Li",
      "Shuguang Cui"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.00843"
  },
  {
    "id": "arXiv:2203.03166",
    "title": "HRTF measurement for accurate sound localization cues",
    "abstract": "Comments: 39 pages, 27 figures, and 1 table",
    "descriptor": "\nComments: 39 pages, 27 figures, and 1 table\n",
    "authors": [
      "Gyeong-Tae Lee",
      "Sang-Min Choi",
      "Byeong-Yun Ko",
      "Yong-Hwa Park"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2203.03166"
  },
  {
    "id": "arXiv:2203.04172",
    "title": "Distributed Control using Reinforcement Learning with  Temporal-Logic-Based Reward Shaping",
    "abstract": "Comments: 12 pages, 4 figures, accepted by L4DC 2022",
    "descriptor": "\nComments: 12 pages, 4 figures, accepted by L4DC 2022\n",
    "authors": [
      "Ningyuan Zhang",
      "Wenliang Liu",
      "Calin Belta"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.04172"
  },
  {
    "id": "arXiv:2203.04746",
    "title": "SkinningNet: Two-Stream Graph Convolutional Neural Network for Skinning  Prediction of Synthetic Characters",
    "abstract": "Comments: CVPR 2022",
    "descriptor": "\nComments: CVPR 2022\n",
    "authors": [
      "Albert Mosella-Montoro",
      "Javier Ruiz-Hidalgo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.04746"
  },
  {
    "id": "arXiv:2203.05399",
    "title": "Designing ML-Resilient Locking at Register-Transfer Level",
    "abstract": "Comments: Proceedings of the 59th ACM/IEEE Design Automation Conference (DAC '22)",
    "descriptor": "\nComments: Proceedings of the 59th ACM/IEEE Design Automation Conference (DAC '22)\n",
    "authors": [
      "Dominik Sisejkovic",
      "Luca Collini",
      "Benjamin Tan",
      "Christian Pilato",
      "Ramesh Karri",
      "Rainer Leupers"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2203.05399"
  },
  {
    "id": "arXiv:2203.05931",
    "title": "FedSyn: Synthetic Data Generation using Federated Learning",
    "abstract": "FedSyn: Synthetic Data Generation using Federated Learning",
    "descriptor": "",
    "authors": [
      "Monik Raj Behera",
      "Sudhir Upadhyay",
      "Suresh Shetty",
      "Sudha Priyadarshini",
      "Palka Patel",
      "Ker Farn Lee"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.05931"
  },
  {
    "id": "arXiv:2203.06313",
    "title": "Performance Analysis of Intelligent Reflecting Surface Assisted  Opportunistic Communications",
    "abstract": "Comments: 13 pages, 8 figures",
    "descriptor": "\nComments: 13 pages, 8 figures\n",
    "authors": [
      "L. Yashvanth",
      "Chandra R. Murthy"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2203.06313"
  },
  {
    "id": "arXiv:2203.06498",
    "title": "The worst of both worlds: A comparative analysis of errors in learning  from data in psychology and machine learning",
    "abstract": "The worst of both worlds: A comparative analysis of errors in learning  from data in psychology and machine learning",
    "descriptor": "",
    "authors": [
      "Jessica Hullman",
      "Sayash Kapoor",
      "Priyanka Nanayakkara",
      "Andrew Gelman",
      "Arvind Narayanan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.06498"
  },
  {
    "id": "arXiv:2203.06783",
    "title": "Adaptive Model Predictive Control by Learning Classifiers",
    "abstract": "Comments: To appear in the 4th Annual Learning for Dynamics & Control Conference (L4DC) 2022",
    "descriptor": "\nComments: To appear in the 4th Annual Learning for Dynamics & Control Conference (L4DC) 2022\n",
    "authors": [
      "Rel Guzman",
      "Rafael Oliveira",
      "Fabio Ramos"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.06783"
  },
  {
    "id": "arXiv:2203.07302",
    "title": "Do DNNs trained on Natural Images organize visual features into  Gestalts?",
    "abstract": "Comments: submitted to eLife",
    "descriptor": "\nComments: submitted to eLife\n",
    "authors": [
      "Valerio Biscione",
      "Jeffrey S. Bowers"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.07302"
  },
  {
    "id": "arXiv:2203.08392",
    "title": "Patch-Fool: Are Vision Transformers Always Robust Against Adversarial  Perturbations?",
    "abstract": "Comments: Accepted at ICLR 2022",
    "descriptor": "\nComments: Accepted at ICLR 2022\n",
    "authors": [
      "Yonggan Fu",
      "Shunyao Zhang",
      "Shang Wu",
      "Cheng Wan",
      "Yingyan Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.08392"
  },
  {
    "id": "arXiv:2203.08403",
    "title": "Precise Onboard Aircraft Cabin Localization using UWB and ML",
    "abstract": "Precise Onboard Aircraft Cabin Localization using UWB and ML",
    "descriptor": "",
    "authors": [
      "Fabien Geyer",
      "Dominic Schupke"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Human-Computer Interaction (cs.HC)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2203.08403"
  },
  {
    "id": "arXiv:2203.09127",
    "title": "ERNIE-GeoL: A Geography-and-Language Pre-trained Model and its  Applications in Baidu Maps",
    "abstract": "Comments: Submitted to KDD 2022 ADS Track",
    "descriptor": "\nComments: Submitted to KDD 2022 ADS Track\n",
    "authors": [
      "Jizhou Huang",
      "Haifeng Wang",
      "Yibo Sun",
      "Yunsheng Shi",
      "Zhengjie Huang",
      "An Zhuo",
      "Shikun Feng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.09127"
  },
  {
    "id": "arXiv:2203.09414",
    "title": "Medium Transmission Map Matters for Learning to Restore Real-World  Underwater Images",
    "abstract": "Medium Transmission Map Matters for Learning to Restore Real-World  Underwater Images",
    "descriptor": "",
    "authors": [
      "Yan Kai",
      "Liang Lanyue",
      "Zheng Ziqiang",
      "Wang Guoqing",
      "Yang Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.09414"
  },
  {
    "id": "arXiv:2203.09435",
    "title": "Expanding Pretrained Models to Thousands More Languages via  Lexicon-based Adaptation",
    "abstract": "Comments: ACL 2022",
    "descriptor": "\nComments: ACL 2022\n",
    "authors": [
      "Xinyi Wang",
      "Sebastian Ruder",
      "Graham Neubig"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.09435"
  },
  {
    "id": "arXiv:2203.11171",
    "title": "Self-Consistency Improves Chain of Thought Reasoning in Language Models",
    "abstract": "Comments: V2: added PaLM based results",
    "descriptor": "\nComments: V2: added PaLM based results\n",
    "authors": [
      "Xuezhi Wang",
      "Jason Wei",
      "Dale Schuurmans",
      "Quoc Le",
      "Ed Chi",
      "Sharan Narang",
      "Aakanksha Chowdhery",
      "Denny Zhou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.11171"
  },
  {
    "id": "arXiv:2203.12201",
    "title": "Towards Expressive Speaking Style Modelling with Hierarchical Context  Information for Mandarin Speech Synthesis",
    "abstract": "Comments: Accepted by ICASSP 2022",
    "descriptor": "\nComments: Accepted by ICASSP 2022\n",
    "authors": [
      "Shun Lei",
      "Yixuan Zhou",
      "Liyang Chen",
      "Zhiyong Wu",
      "Shiyin Kang",
      "Helen Meng"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.12201"
  },
  {
    "id": "arXiv:2203.12899",
    "title": "Expression Classification using Concatenation of Deep Neural Network for  the 3rd ABAW3 Competition",
    "abstract": "Expression Classification using Concatenation of Deep Neural Network for  the 3rd ABAW3 Competition",
    "descriptor": "",
    "authors": [
      "Kim Ngan Phan",
      "Hong-Hai Nguyen",
      "Van-Thong Huynh",
      "Soo-Hyung Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2203.12899"
  },
  {
    "id": "arXiv:2203.12949",
    "title": "Duality-Induced Regularizer for Semantic Matching Knowledge Graph  Embeddings",
    "abstract": "Comments: Accepted to TPAMI. This work is a journal extension of our NeurIPS'20 paper arXiv:2011.05816",
    "descriptor": "\nComments: Accepted to TPAMI. This work is a journal extension of our NeurIPS'20 paper arXiv:2011.05816\n",
    "authors": [
      "Jie Wang",
      "Zhanqiu Zhang",
      "Zhihao Shi",
      "Jianyu Cai",
      "Shuiwang Ji",
      "Feng Wu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.12949"
  },
  {
    "id": "arXiv:2203.13273",
    "title": "On Exploiting Layerwise Gradient Statistics for Effective Training of  Deep Neural Networks",
    "abstract": "Comments: 9 pages",
    "descriptor": "\nComments: 9 pages\n",
    "authors": [
      "Guoqiang Zhang",
      "Kenta Niwa",
      "W. Bastiaan Kleijn"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.13273"
  },
  {
    "id": "arXiv:2203.14009",
    "title": "Combining Evolution and Deep Reinforcement Learning for Policy Search: a  Survey",
    "abstract": "Combining Evolution and Deep Reinforcement Learning for Policy Search: a  Survey",
    "descriptor": "",
    "authors": [
      "Olivier Sigaud"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.14009"
  },
  {
    "id": "arXiv:2203.14328",
    "title": "On the Neural Tangent Kernel Analysis of Randomly Pruned Wide Neural  Networks",
    "abstract": "On the Neural Tangent Kernel Analysis of Randomly Pruned Wide Neural  Networks",
    "descriptor": "",
    "authors": [
      "Hongru Yang",
      "Zhangyang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.14328"
  },
  {
    "id": "arXiv:2203.14550",
    "title": "CenterLoc3D: Monocular 3D Vehicle Localization Network for Roadside  Surveillance Cameras",
    "abstract": "Comments: 15 pages, 15 figures. v2. This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible",
    "descriptor": "\nComments: 15 pages, 15 figures. v2. This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Tang Xinyao",
      "Song Huansheng",
      "Wang Wei",
      "Zhao Chunhui"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.14550"
  },
  {
    "id": "arXiv:2203.14557",
    "title": "Visual Mechanisms Inspired Efficient Transformers for Image and Video  Quality Assessment",
    "abstract": "Visual Mechanisms Inspired Efficient Transformers for Image and Video  Quality Assessment",
    "descriptor": "",
    "authors": [
      "Junyong You"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.14557"
  },
  {
    "id": "arXiv:2203.14963",
    "title": "Deep Learning and Artificial General Intelligence: Still a Long Way to  Go",
    "abstract": "Comments: Accepted as a poster at 3rd Polish Conference on Artificial Intelligence (PP-RAI'2022)",
    "descriptor": "\nComments: Accepted as a poster at 3rd Polish Conference on Artificial Intelligence (PP-RAI'2022)\n",
    "authors": [
      "Maciej \u015awiechowski"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.14963"
  },
  {
    "id": "arXiv:2203.15112",
    "title": "Domain Knowledge Driven Pseudo Labels for Interpretable Goal-Conditioned  Interactive Trajectory Prediction",
    "abstract": "Domain Knowledge Driven Pseudo Labels for Interpretable Goal-Conditioned  Interactive Trajectory Prediction",
    "descriptor": "",
    "authors": [
      "Lingfeng Sun",
      "Chen Tang",
      "Yaru Niu",
      "Enna Sachdeva",
      "Chiho Choi",
      "Teruhisa Misu",
      "Masayoshi Tomizuka",
      "Wei Zhan"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.15112"
  },
  {
    "id": "arXiv:2203.15491",
    "title": "Improving the Learnability of Machine Learning APIs by Semi-Automated  API Wrapping",
    "abstract": "Comments: The definitive Version of Record was published in New Ideas and Emerging Results (ICSE-NIER'22), May 21-29, 2022, Pittsburgh, PA, USA",
    "descriptor": "\nComments: The definitive Version of Record was published in New Ideas and Emerging Results (ICSE-NIER'22), May 21-29, 2022, Pittsburgh, PA, USA\n",
    "authors": [
      "Lars Reimann",
      "G\u00fcnter Kniesel-W\u00fcnsche"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.15491"
  },
  {
    "id": "arXiv:2203.15619",
    "title": "Classification of Hyperspectral Images Using SVM with Shape-adaptive  Reconstruction and Smoothed Total Variation",
    "abstract": "Comments: 5 pages, 3 figures",
    "descriptor": "\nComments: 5 pages, 3 figures\n",
    "authors": [
      "Ruoning Li",
      "Kangning Cui",
      "Raymond H. Chan",
      "Robert J. Plemmons"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.15619"
  },
  {
    "id": "arXiv:2203.16939",
    "title": "Hypergraph Convolutional Networks via Equivalency between Hypergraphs  and Undirected Graphs",
    "abstract": "Hypergraph Convolutional Networks via Equivalency between Hypergraphs  and Undirected Graphs",
    "descriptor": "",
    "authors": [
      "Jiying Zhang",
      "Fuyang Li",
      "Xi Xiao",
      "Tingyang Xu",
      "Yu Rong",
      "Junzhou Huang",
      "Yatao Bian"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.16939"
  },
  {
    "id": "arXiv:2203.17089",
    "title": "Quantum-Aided Meta-Learning for Bayesian Binary Neural Networks via Born  Machines",
    "abstract": "Comments: submitted for publication",
    "descriptor": "\nComments: submitted for publication\n",
    "authors": [
      "Ivana Nikoloska",
      "Osvaldo Simeone"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.17089"
  },
  {
    "id": "arXiv:2203.17225",
    "title": "A Baseline Readability Model for Cebuano",
    "abstract": "A Baseline Readability Model for Cebuano",
    "descriptor": "",
    "authors": [
      "Lloyd Lois Antonie Reyes",
      "Michael Antonio Iba\u00f1ez",
      "Ranz Sapinit",
      "Mohammed Hussien",
      "Joseph Marvin Imperial"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.17225"
  },
  {
    "id": "arXiv:2204.00172",
    "title": "A Unified Framework for Domain Adaptive Pose Estimation",
    "abstract": "A Unified Framework for Domain Adaptive Pose Estimation",
    "descriptor": "",
    "authors": [
      "Donghyun Kim",
      "Kaihong Wang",
      "Kate Saenko",
      "Margrit Betke",
      "Stan Sclaroff"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.00172"
  },
  {
    "id": "arXiv:2204.00763",
    "title": "Metaphorical User Simulators for Evaluating Task-oriented Dialogue  Systems",
    "abstract": "Comments: There are important errors in the article. We are very sorry, please withdraw it as soon as possible",
    "descriptor": "\nComments: There are important errors in the article. We are very sorry, please withdraw it as soon as possible\n",
    "authors": [
      "Weiwei Sun",
      "Shuyu Guo",
      "Shuo Zhang",
      "Pengjie Ren",
      "Zhumin Chen",
      "Maarten de Rijke",
      "Zhaochun Ren"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2204.00763"
  },
  {
    "id": "arXiv:2204.00764",
    "title": "A Study of Real-World Data Races in Golang",
    "abstract": "Comments: To appear in the proceedings of the 43rd Programming Language Design and Implementation (PLDI 2022)",
    "descriptor": "\nComments: To appear in the proceedings of the 43rd Programming Language Design and Implementation (PLDI 2022)\n",
    "authors": [
      "Milind Chabbi",
      "Murali Krishna Ramanathan"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2204.00764"
  },
  {
    "id": "arXiv:2204.01028",
    "title": "MSCCD: Grammar Pluggable Clone Detection Based on ANTLR Parser  Generation",
    "abstract": "Comments: ICPC2022",
    "descriptor": "\nComments: ICPC2022\n",
    "authors": [
      "Wenqing Zhu",
      "Norihiro Yoshida",
      "Toshihiro Kamiya",
      "Eunjong Choi",
      "Hiroaki Takada"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2204.01028"
  },
  {
    "id": "arXiv:2204.01365",
    "title": "Deep learning, stochastic gradient descent and diffusion maps",
    "abstract": "Deep learning, stochastic gradient descent and diffusion maps",
    "descriptor": "",
    "authors": [
      "Carmina Fjellstr\u00f6m",
      "Kaj Nystr\u00f6m"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.01365"
  },
  {
    "id": "arXiv:2204.01487",
    "title": "Identifying Security Risks in NFT Platforms",
    "abstract": "Identifying Security Risks in NFT Platforms",
    "descriptor": "",
    "authors": [
      "Yash Gupta",
      "Jayanth Kumar",
      "Dr. Andrew Reifers"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2204.01487"
  },
  {
    "id": "arXiv:2204.01585",
    "title": "Langevin Diffusion: An Almost Universal Algorithm for Private Euclidean  (Convex) Optimization",
    "abstract": "Comments: Added a comparison to the work of Asi et al",
    "descriptor": "\nComments: Added a comparison to the work of Asi et al\n",
    "authors": [
      "Arun Ganesh",
      "Abhradeep Thakurta",
      "Jalaj Upadhyay"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2204.01585"
  },
  {
    "id": "arXiv:2204.01618",
    "title": "Deep-Ensemble-Based Uncertainty Quantification in Spatiotemporal Graph  Neural Networks for Traffic Forecasting",
    "abstract": "Deep-Ensemble-Based Uncertainty Quantification in Spatiotemporal Graph  Neural Networks for Traffic Forecasting",
    "descriptor": "",
    "authors": [
      "Tanwi Mallick",
      "Prasanna Balaprakash",
      "Jane Macfarlane"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.01618"
  },
  {
    "id": "arXiv:2204.01708",
    "title": "MRI-based Multi-task Decoupling Learning for Alzheimer's Disease  Detection and MMSE Score Prediction: A Multi-site Validation",
    "abstract": "Comments: 15 pages",
    "descriptor": "\nComments: 15 pages\n",
    "authors": [
      "Xu Tian",
      "Jin Liu",
      "Hulin Kuang",
      "Yu Sheng",
      "Jianxin Wang",
      "Alzheimer's Disease Neuroimaging Initiative"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.01708"
  },
  {
    "id": "arXiv:2204.01732",
    "title": "A high-order tensor completion algorithm based on Fully-Connected Tensor  Network weighted optimization",
    "abstract": "Comments: 12 pages",
    "descriptor": "\nComments: 12 pages\n",
    "authors": [
      "Peilin Yang",
      "Yonghui Huang",
      "Yuning Qiu",
      "Weijun Sun",
      "Guoxu Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.01732"
  },
  {
    "id": "arXiv:2204.01734",
    "title": "On Explaining Multimodal Hateful Meme Detection Models",
    "abstract": "On Explaining Multimodal Hateful Meme Detection Models",
    "descriptor": "",
    "authors": [
      "Ming Shan Hee",
      "Roy Ka-Wei Lee",
      "Wen-Haw Chong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2204.01734"
  },
  {
    "id": "arXiv:2204.01943",
    "title": "Unified Implicit Neural Stylization",
    "abstract": "Unified Implicit Neural Stylization",
    "descriptor": "",
    "authors": [
      "Zhiwen Fan",
      "Yifan Jiang",
      "Peihao Wang",
      "Xinyu Gong",
      "Dejia Xu",
      "Zhangyang Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.01943"
  },
  {
    "id": "arXiv:2204.01971",
    "title": "Non-Local Latent Relation Distillation for Self-Adaptive 3D Human Pose  Estimation",
    "abstract": "Comments: NeurIPS 2021. Project page: this https URL",
    "descriptor": "\nComments: NeurIPS 2021. Project page: this https URL\n",
    "authors": [
      "Jogendra Nath Kundu",
      "Siddharth Seth",
      "Anirudh Jamkhandi",
      "Pradyumna YM",
      "Varun Jampani",
      "Anirban Chakraborty",
      "R. Venkatesh Babu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.01971"
  },
  {
    "id": "arXiv:2204.02041",
    "title": "Automating Reinforcement Learning with Example-based Resets",
    "abstract": "Comments: 8 pages, 6 figures; accepted for publication in the IEEE Robotics and Automation Letters (RA-L); source code available at this https URL ; supplementary video available at this https URL",
    "descriptor": "\nComments: 8 pages, 6 figures; accepted for publication in the IEEE Robotics and Automation Letters (RA-L); source code available at this https URL ; supplementary video available at this https URL\n",
    "authors": [
      "Jigang Kim",
      "J. hyeon Park",
      "Daesol Cho",
      "H. Jin Kim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2204.02041"
  },
  {
    "id": "arXiv:2204.02112",
    "title": "GP-BART: a novel Bayesian additive regression trees approach using  Gaussian processes",
    "abstract": "GP-BART: a novel Bayesian additive regression trees approach using  Gaussian processes",
    "descriptor": "",
    "authors": [
      "Mateus Maia",
      "Keefe Murphy",
      "Andrew C. Parnell"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2204.02112"
  },
  {
    "id": "arXiv:2204.02128",
    "title": "Computing in Anonymous Dynamic Networks Is Linear",
    "abstract": "Comments: 31 pages, 8 figures",
    "descriptor": "\nComments: 31 pages, 8 figures\n",
    "authors": [
      "Giuseppe A. Di Luna",
      "Giovanni Viglietta"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2204.02128"
  },
  {
    "id": "arXiv:2204.02130",
    "title": "SemanticCAP: Chromatin Accessibility Prediction Enhanced by Features  Learning from a Language Model",
    "abstract": "SemanticCAP: Chromatin Accessibility Prediction Enhanced by Features  Learning from a Language Model",
    "descriptor": "",
    "authors": [
      "Yikang Zhang",
      "Xiaomin Chu",
      "Yelu Jiang",
      "Hongjie Wu",
      "Lijun Quan"
    ],
    "subjectives": [
      "Genomics (q-bio.GN)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.02130"
  },
  {
    "id": "arXiv:2204.02148",
    "title": "Dual-AI: Dual-path Actor Interaction Learning for Group Activity  Recognition",
    "abstract": "Comments: CVPR 2022 Oral presentation",
    "descriptor": "\nComments: CVPR 2022 Oral presentation\n",
    "authors": [
      "Mingfei Han",
      "David Junhao Zhang",
      "Yali Wang",
      "Rui Yan",
      "Lina Yao",
      "Xiaojun Chang",
      "Yu Qiao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.02148"
  },
  {
    "id": "arXiv:2204.02169",
    "title": "Hybrid Predictive Coding: Inferring, Fast and Slow",
    "abstract": "Comments: 05/04/22 initial upload. 06/04/22 added acknowledgements section",
    "descriptor": "\nComments: 05/04/22 initial upload. 06/04/22 added acknowledgements section\n",
    "authors": [
      "Alexander Tschantz",
      "Beren Millidge",
      "Anil K Seth",
      "Christopher L Buckley"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.02169"
  },
  {
    "id": "arXiv:2204.02197",
    "title": "Penalised FTRL With Time-Varying Constraints",
    "abstract": "Penalised FTRL With Time-Varying Constraints",
    "descriptor": "",
    "authors": [
      "Douglas J. Leith",
      "George Iosifidis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2204.02197"
  },
  {
    "id": "arXiv:2204.02199",
    "title": "On an ecumenical natural deduction with stoup -- Part I: The  propositional case",
    "abstract": "Comments: 26 pages",
    "descriptor": "\nComments: 26 pages\n",
    "authors": [
      "Luiz Carlos Pereira",
      "Elaine Pimentel"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2204.02199"
  },
  {
    "id": "arXiv:2204.02301",
    "title": "A multiphysics modeling approach for in-stent restenosis: Theoretical  aspects and finite element implementation",
    "abstract": "Comments: 47 pages, 22 figures, 5 tables",
    "descriptor": "\nComments: 47 pages, 22 figures, 5 tables\n",
    "authors": [
      "Kiran Manjunatha",
      "Marek Behr",
      "Felix Vogt",
      "Stefanie Reese"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2204.02301"
  },
  {
    "id": "arXiv:2204.02351",
    "title": "Test Against High-Dimensional Uncertainties: Accelerated Evaluation of  Autonomous Vehicles with Deep Importance Sampling",
    "abstract": "Test Against High-Dimensional Uncertainties: Accelerated Evaluation of  Autonomous Vehicles with Deep Importance Sampling",
    "descriptor": "",
    "authors": [
      "Mansur Arief",
      "Zhepeng Cen",
      "Zhenyuan Liu",
      "Zhiyuang Huang",
      "Henry Lam",
      "Bo Li",
      "Ding Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2204.02351"
  }
]